&gt;Rust is targeting the effective network services problem domain too (basically the same domain that is now being covered by Go programs), and there throughput might be more important than exact fine-grained determinism. Of course, but as far as I know there isn't any plan to stop being a zero-cost systems programming language, so it makes sense to have async/await be optional and explicit rather than omnipresent and baked into a runtime of some sort. I imagine having the language be universally async would cause a lot problems when interoping with any non-async languages (such as C) or even other async-capable languages, much like garbage collectors do in every language that has one built-in. It would likely also be a problem for anyone wanting to use it for embedded development.
&gt; I decided copy program structure on block-by-block level in order to get the same correct implementation. Org's syntax is very complex - it is a context-dependent grammar. Without a formal grammar definition (which does not exist) implementing a correct algorithm without using the original source code is almost impossible. Yep, I understand, and I think that this is a reasonable approach to getting a fully compatible parser quickly and easily. However, I think that this approach does mean that there's a pretty strong case to be made that your work is a derivative of the original. &gt; I decided to use lookalike function and variable names for ease of navigation between the two codebases, while in active development. I can easily rename/obfuscate them if that will make a difference. Same goes for comments. This wouldn't help very much, as it would only really affect that lowest level of abstraction and not the next one up. Think of it as someone doing an adaptation of a novel for the screen. After pointing out that they need to get a license from the author, the directors just decide to rename everyone and change the phrasing on their lines, but leaving the whole basic plot and structure the same. &gt; I believe that given the complexity of the grammar this is the only way to implement a fully-functioning algorithm. I'm pretty sure there are other ways to implement a fully functioning algorithm which don't reproduce the code block by block; they'd just be more work. You could go through, writing up an abstract spec of the algorithm (like I mentioned, maybe something like the [HTML parsing algorithm](https://html.spec.whatwg.org/multipage/parsing.html)), write up a comprehensive set of test cases, and then implement from scratch based on that algorithmic specification and test cases. Of course, that would be more work, but that's just like it's more work to re-implement a GPL'd library from scratch than it is to just link to it; it's more work to create a fully independent work than it is to create a derivative work. Also, while I mention writing up an abstract algorithmic specification like that of the HTML parsing algorithm plus a set of test cases, and then implement the Rust side from scratch based on that without reference to the original code, I can't guarantee that that would be sufficient to keep it from being a derivative work; but I think that's probably about the bare minimum level of abstraction that you'd need to do to arguably meet the definition of only sharing as much as is required for functional compatibility. &gt;&gt; The org-mode code is copyright the Free Software Foundation. They own the copyright, so they get to decide how it's licensed. You could write to them for permission to release your parser under a more permissive license. &gt; &gt;I did this today too. I'm waiting for their reply. I think that this is probably the best approach here, because without taking on the extra task of writing up a spec and test cases and then doing your implementation from that, it seems likely that your approach is going to fall on the derivative work side, so it's better to just clear the issue up.
while method is better than current magical shit, it is not necessary true that it makes wait for it to be a method. There is zero chance that user would be able to implement it. IN first place, it is again wrong approach, await should be used on expressions, not values.
I think it's a fallacy to categorize "modern" languages along just recency. Rust is the first serious contender as a *systems programming* language in a long time - no other "modern" language exists in this space, unless you count modern iterations of C++, which is probably not a great place to look for syntactical inspiration. What is important in a systems programming language is not what is important in Node.js environments or similar.
&gt; async/await is built on generators But we don't want to rely on that. Especially if we intend to allow you to create async generators that use both yield and await.
\&gt; there isn't any plan to stop being a zero-cost systems programming language &amp;#x200B; Yes, I too hope so. &amp;#x200B; That said, a network server written in Rust will probably look like a big event loop framework/library, and your code probably will look like async code gluing together the bits of "business domain" services/providers/models. And there the important thing is movable (as in pin-able and heap allocatable) futures instantiated for requests. The event library gives you a Request and you promise it a Result (a future Result), and the framework "awaits" on your code.
How can I write to stdout faster than `println!`? I'd love to take advantage of Rust's fast regex capabilities, and have been considering porting some of my log parsers from python3 to Rust. Before anything I did a quick performance test to see how quickly Rust could read a file line by line and print it to stdout, I was surprised to see that python's `print()` was considerably faster than `println!`. I tested using a 5GB file on a VM, here is the code: Rust: let logfile = File::open("test.log")?; for line in BufReader::new(logfile).lines() { println!("{}", line?); } Python3: with open('test.log','r') as file: for line in file: print(line.strip()) Rust performance: (50 second runtime) root@test:~/Rust/filereader/src# date +%T; ../target/release/./filereader 1&gt;/dev/null; date +%T 08:44:20 08:45:10 Python performance: (33 second runtime) root@test:~/Desktop/Rust/filereader/src# date +%T; ./read.py 1&gt;/dev/null ;date +%T 08:43:32 08:44:05 I confirmed that `println!` is in fact the culprit here (and not the file-reading part) by doing a simple `for i in 1..10000000 {println!("{}",i);}` vs. `for i in range(10000000): print(i)`. Is there a better technique I can use here to make this faster?
The pipe operator is around in F#, Elm and Elixir.
The syntax would be `future.await()` but the method itself is not called `await`. The keyword exists so you can call the method, since I didn't intend for it to be callable in the `Await::await_fn(future)` way. This, again, is similar to `Fn` and friends where the method * is called some word that is not the syntax * is marked with another abi, `extern "rust-call"` in the other case * can not be invoked directly If you correctly remark that we might be able to implement `Fn` in the future, keep in mind that this nevertheless would unlikely allow you to customize the semantics of the function call itself, it's simply the case that there is no separate *syntactical* trait (necessary) for function calls (`Future` being the semantical one for `async fn`) and so they two would be merged. Don't know what my stance on this is overall, but seems to work ¯\\\_(ツ)\_/¯
As a nitpick: `cargo` ist not warning you, `rustc` is.
&gt; I myself am reevaluating my views on Rust going forward based on this new syntax proposal Independently of the main issue, I find this kind of argument extremely unsatisfying. We are engineers, we deal with trade offs in every decisions that we make. Is so nefarious the postfix operator that the incoherence that introduces makes the Rust language unusable? If you apply this argument to any language, which one will you use? Pure lambda calculus? I can see the inconsistency here, but `.await` is not something that we will use daily in all of our programs. Most of the times will be in the last part of the sentence, and we have editors that can color it in bright red if you need some visual indication. Can we please move on and be happy that we have a final proposal, that we can use when needed?
OP was talking about weirdness, that's what I was referring to. OP suggested that people are going to not consider rust because of a single unusual corner of its syntax.
Rust has the goal to provide as clean abstractions as possible. Zero-cost and orthogonal abstractions are very powerful. You can hide may things already in macros. (Look at the crossbeam channels' select! macro. It hides an amazing infinite loop for example.) &amp;#x200B; C++'s move semantics is something that I would point at that's similarly deceptively simple in terms of syntax. (But the rules are ugly, because it's C++, so it has as many special edge cases as C has undefined behavior, and some.) &amp;#x200B; I think for any non-DSL programming the ability to cleanly compose very different aspects of programs is getting more and more important. And Rust is tackling that challenge. Be explicit where it matters and be implicit where it is obviously an ergonomics gain. (Eg. lifetime elision.)
Have some fun with the babes: http://4cbl.ylgrgm1p.org/vounvhok/
With the only exception being function chaining, the argument for a Trait and method can be applied to `await(future)`.
That's an interesting read, thank you! It took me a while to understand what piet-metal is doing versus PF3. I think that the domain is fairly (not ideally) well suited for the hardware we have to day. In particular, having blending done in order by fixed-function pieces is helpful to both fill out the masks and apply them. I believe you noted correctly the main problem with PF3 being non-locality of the workloads: mask segments can be in different places of the atlas, and we end up with potentially reading and writing memory in 2+ render targets. This is especially hurting Intel and mobile, which have slow memory. However, I don't think a vector graphics virtual machine implemented in a compute kernel is the best we can do to achieve data locality :) There does appear to be a room for experimentation with Vulkan sub-passes (or the pixel local storage mentioned by /u/pcwalton). We'd just need to assign the tasks in each tile's sub-graph between the transient attachment and sub-passes of one giant render pass doing all the work.
The advantages of the postfix await syntax options are not only to cram in more than one. It's also to access a field or function of the awaited object, or to use ?. I think there's cases to be made for both options. This works perfectly fine: let thing = await some.expression() And so does this: return fetch("thing").await?.get("x") I think making macros callable using UCS would work, but prefix keywords combined with dot-postfix ones do too. I'd love to see some.expression().match { .... }
I can see the issue with custom operators in Haskell, but the 3 I mentioned are part of the core language correct? I don't write Haskell but I do read it on occasion when learning FP concepts
Check how hot babes party: http://oa07.q6vzn0yq.org/hxko22ka/
I wouldn't worry, easy-to-overlook is one of the criticized downsides of that style.
I really appreciate the clarity of this blog post. I think far too much weight is placed on `await` not being a proper function - what IS a proper function? Certainly not a well-defined mathematical function. Does it just mean, something that _simply_ runs code and pops off the call stack? Thread APIs have been mentioned as functions that cause non stack local effects to occur. I am unconvinced that the behaviour of `await` is too far different or unexpected behaviour from a function to ignore it's obvious benefits. Particularly as documented here as 'anything can happen'. Also, if we're just talking about principle of lease surprise and readability, `future.await` **doesn't look like an operator**. Calling it that is - and I mean this in the gentlest way - delusional. Rust has it's quirks, but typically reading rust is not all that hard. Even it's novel or unusual programming constructs suggest heavily toward what it does (match, `?`, etc). `calendarEvent.await.details()` &lt;- if you were a Rust newbie and saw this piece of code, you would NOT suspect nonlocal code execution. If this needed to go in a hot loop, you would not know that this would be bad. It looks like an instant field access and nothing more. The ability to EASILY read and parse code as a programmer is important. _The programmers first interpretation of `f.await` should not depend on the name of `f`._ Not to mention that this Trait syntax allows disambiguating from other fields/methods with `Await::await(futureFactory.await())`, where I'm not aware of a solution for field accesses.
There's a mutex around stdout that `println!` acquires each time it wants to print. You can [acquire the lock yourself](https://doc.rust-lang.org/std/io/struct.Stdout.html#method.lock) and write directly (e.g. by using the `writeln!` macro).
Great post, I agree.
&gt; AIUI, this is a legal grey area I'm don't think this is really a legal grey area; there's a fairly clear test for this case, the abstraction-filtration-comparison test, and [a quick glance](https://www.reddit.com/r/rust/comments/bm5rwv/orgrs_legally_possible_relicense_to_lgpl/emuxw1k/) shows that it's pretty likely that this code is a derivative of the original. Even in a case with much less shared, [Oracle v. Google](https://en.wikipedia.org/wiki/Oracle_America,_Inc._v._Google,_Inc.), in which Google just shared the interface definitions of the Java standard library while writing completely independent clean-room implementations (except for a handful that were copied accidentally), it has been ruled that they've infringed on Oracle's copyright. While I happen to prefer Judge Alsup's ruling on whether APIs are copyrightable to that of the Federal Circuit, the fact is that unless the Supreme Court overturns the Federal Circuit or a law is passed clarifying the situation, the Federal Circuit's interpretation holds. I'm pretty sure that `org-rs` is pretty firmly out of the grey area, and would count as a derivative work if it were taken to court.
In VSCode, if the RLS is running you can hover your mouse over an identifier or expression and VSCode will tell you its type.
Better than Tinder: http://3ncy.3t1bjn48.org/biswbab7/
There's something deeply unsatisfying about the (inclusive-) ranges API for integers. This API is a failure for Rust's zero-cost abstractions promise. The edge cases cannot be ignored and inhibit optimizations even though in practice you will never hit these edge cases...
After reading all of the discussions a prefix keyword with a postfix macro does seem to be the option that gives us all of the advantages of both while not introducing any weirdness to the language. I think this is my favorite suggestion I've seen
https://www.youtube.com/channel/UCFgei3yyflaTj7D7Ich6zfg
Crazy girls do crazy things: http://oa07.q6vzn0yq.org/hxko22ka/
 While I much prefer the prefix await syntax, it's just not that big a deal to me if postfix is what's chosen. &gt; This new syntax is just too weird. I know it seems a silly reason on which to hinge an argument, but to be taken significantly more seriously than a "Mozilla Research Language", it has an expectation to a) relatively mainstream syntax and b) relatively consistent syntax features. To be honest, this post strikes me as "I'm comfortable with algol style languages and nothing else". There's a much wider world of programming languages and styles out there that are 100% ready for production and in production *right now* than those that strictly conform to the "mainstream" languages like Java, C++, C#, Python, etc. You're free to use whatever you want of course, but there's a lot out there that wouldn't be possible by sticking the same old syntax every other language has.
I'd like to throw this out here: Originally postfix macro syntax was what I was hoping for, but postfix field has grown on me in the time I've mulled over it. It actually isn't that bad in my opinion. I'm not going to confuse it for a field (it's a keyword), I'm not going to have trouble reading it (I know a language with the verb at the end so it actually might be easier for me to read because of the lack of backtracking), it doesn't look "ugly" to me (this is subjective but `["foo.await!", "foo.await()?", "foo@?", "(await foo)?"]` rationalizations being: extra symbol, extra *two* symbols, @, paren soup) &amp;#x200B; I think the main downside is that it costs some of the weirdness budget, because no other language that I'm aware of does this, of course, no other language that I'm aware of has the problems with `await` and `?`. &amp;#x200B; As other people in other threads have said, I'm not *extremely* worried about which syntax gets picked, I'll use it anyway and get used to it.
Best pr0n: http://0fz9.yatv3cuz.org/fam4sc2m/
This poll options is misleading. \`let result = (await future).foo()\` should not be listed out, from C# and JavaScript experience, I'll always call the method in a separate line in this case. i.e. \`\`\` let result = await future; [result.foo](https://result.foo)() \`\`\` Tha actual code example should be: \`\`\` let result = await future; let result = await future?; let result = (await future)?; \`\`\` You see, I support this syntax, the other options won't beat this.
Have you run [clippy](https://github.com/rust-lang/rust-clippy) on your code?
Honestly I think all these options are rubbish for readability. Way too many symbols jumbled together.
/r/playrust is [this way](https://www.reddit.com/r/playrust/).
Well allowing to implement `Fn` makes sense to allow functors. The only problem is reluctance of Rust team to allow overloads. I don't see how `await` could be implemented because it is only can be implemented by compiler. Especially if it would come to coroutines. It sure might be similar, but I would hope that `Fn` would be possible to implement for user in future as there are use cases for it.
Does anybody know how long it usualy takes for FSF to respond? I sent my request to licensing@gnu.org, licensing@fsf.org and I got in return an automatic reply with case ID. That was yesterday..
Try r/playrust This reddit is about the programming language named rust
Crazy girls do crazy things: http://0fz9.yatv3cuz.org/fam4sc2m/
I didn't look at `org-rs` specifically. I was speaking in general. Given how contentious Oracle v. Google has been, I'd say it definitely qualifies as a legal grey area. :-) I did read your other comment, which was excellent. But applying the abstraction-filtration-comparison test looks like it leaves a lot of room to interpretation. (Even though I agree, based on your description of the `org-rs` code, that it is probably not in a grey area specifically.)
Is it? `thread::sleep()` and `mutex.lock()` don't cause anything to happen in another part of code, it just _(potentially)_ blocks the current thread. With that said, it does feel like it has something "special" on it for the current thread - it's not a normal function, it stops my thread. This also brings up an interesting point. Why is `mutex.lock()` allowed to stop my program for an arbitrary amount of time, but `FuMutex.lock().await` is given special care to signify that my coroutine may stop for an arbitrary amount of time. Is there a meaningful distinction?
Yes, it's even a clippy lint: https://rust-lang.github.io/rust-clippy/master/#vec_box
Horny girls waiting for guys http://4cbl.ylgrgm1p.org/vounvhok/
Well, yes, I would say that Oracle v. Google is the grey area, but even that is resolved right now unless overturned. I would say that `org-rs` falls pretty strongly on one side, so unless the grey area shifts substantially, it's not in a grey area, it's in a pretty clear one.
Let's be honest, postifx keyword in any form is bad. I'm not even sure how macro makes difference. It still bad for language
The actual poll page is a bit hard to find: [https://docs.google.com/forms/d/e/1FAIpQLSeNk\_1HVrC-F5LFYMpnJDVjAe17wEcVPtAddcVbpkXenXz5mg/viewform?usp=sf\_link](https://docs.google.com/forms/d/e/1FAIpQLSeNk_1HVrC-F5LFYMpnJDVjAe17wEcVPtAddcVbpkXenXz5mg/viewform?usp=sf_link)
We're talking past one another. I'm trying to say that _applying_ the test isn't necessarily straight-forward _in general_, even if it might be clear in the _specific_ case of `org-rs`.
You have a really great point about the nested matches. As a pretty amateur Rust programmer, I seem to run into deeply nested matches pretty often, try as I might to keep things cleaner.
Have some fun with the babes: http://0fz9.yatv3cuz.org/fam4sc2m/
Great. I was looking for Rust version of sxiv/feh a month or so ago. I'm glad that you started this project, I will most definitely use it!
This is true, but not necessarily a ringing endorsement of the practice. Threads have long been criticised as a relatively poor abstraction for writing concurrent code, and part of the problem with that is the lack of explicit control as to when other code is able to run. In an async/await context, both of these functions would return futures, allowing the user to control when their thread of execution will actually be paused. Using a method (even if it is a pseudo-method) implies that there is nothing special happening when execution is paused, when the whole point of the async/await is to make it clear that this is, in fact, an exceptional point in the flow of code, and the developer needs to take care.
Postfix macros aren't generally possible though.
Ah, right, yeah. I'm a fan of prefix and macro together.
thank you so much. The changes you've made to my code is probably the best simple examples of dealing with with borrowing that I've seen in the last two weeks.
Nope, not my code! It is my coworkers', though.
Not that it will be changed, but I wonder if normal thread blocking operations could be handled in a more unified _(with futures)_ manner. Eg, `fu_mutex.lock().await` for futures, and `mutex.lock().block` / `thread::sleep().block` for normal threads. Of course, `.block` would have a different name. But the consistency would be nice if we care about being clear with `fu_mutex.lock().await`.
No worries! Thanks for the edit.
`parse` returns an `Option` because it can fail, and `expect` and `unwrap` are two of the ways to get to the inner value. An `Option&lt;T&gt;` is a distinct type from `T`, so you do need to unwrap it somehow.
In the straight forward prefix keyword approach, what would your syntax be for chaining? `(await foo).(await bar).(await baz)`? Though, I still like the idea of prefix AND postfix. Eg, use prefix when it makes sense, and use postfix-field when you want to chain. `let bang = foo.await.bar.await.baz.await` becomes clean(er), and `let foo = await bar` is also super clear. And it stays consistent with the proposed `let foo = match blah {}` and let `let foo = blah.match {}`. Such a complex topic :)
Cameltoes and creampies: http://f03n.smo83fhq.org/z1uh6hrk/
 let some_int : i32 = "not an int".parse(); Without returning an option that would have to panic.
What do you think should happen if say I do something like let testing = String::from("hello!") let testing: u32 = input.parse(); The problem is that a String isn't guaranteed to be a number, and thus the conversion of a string into a u32 *can* fail and you have to express the failure case some how. parse() does this by using a Result&lt;T, E&gt;. If you're not aware what a result does, essentially if an operation succeeds, it will give you an Ok(T), and if it fails, it will give you an Err(E). When you parse a String into a u32, it'll either give you an Ok(u32), or Err(&lt;u32 as FromStr&gt;::Err).
In the mandatory delimiter version, `await { foo }.await { bar }.await { baz }` I don't think it's terrible
Hot young girls waiting for you here: http://0fz9.yatv3cuz.org/fam4sc2m/
maybe that's where tools come in again (/s)
This is my stance too: if you implement it as _both_ a postfix macro and a prefix keyword, you keep the familiarity from other languages, and the postfix macro really is just a macro for sugar. I've wanted postfix macros for many use cases in the past, usually revolving around early returns that aren't helped by try. I did leave a post in the thread arguing this but I haven't gotten many responses. Oh well.
/u/kibwen can we get a ban here?
This shaved \~5 seconds off the time, thanks.
I'm saying flip it around. The compiler assumes you want to await unless you use a keyword that is the opposite of await.
Have some fun with the babes: http://0fz9.yatv3cuz.org/fam4sc2m/
Well that smorgasbord of options triggered a paradox of choice which induced an analysis paralysis, :-)
I agree that the prefix syntax isn't ideal for chaining. But I think that chaining is a much more general issue that needs to be addressed separately, as it could apply to other concepts (such as `match`). I agree with you that having both would be ideal. But technically speaking, I want the feature itself to be prefix, and a global language-wide feature to allow postfix notation for keywords in general. My favorite candidate for that would be postfix macros. It could be used for pretty much anything, would be consistent across the whole language, and comes with the "magic happens here" connotation that macros usually carry.
I think the main issue is that it is very strange if taken in the context of language consistency and, well, keywords being keywords. I personally prefer (and think it more rustic to write): let a = if a_fruit.is_ripe { "ripe" } else { "unripe" }; Versus: let a = (a_fruit.is_ripe()).if { "ripe" } else { "unripe" }; The first reads like a sentence, it's clear that it's a conditional, and it doesn't read like a field access (an argument that has been driven into the dirt for `await`, but I think it's still a strong one and should be addressed for every instance where this "magic field" syntax is proposed because of how massive a break it is from the rest of the language). In English you wouldn't write "A fruit is ripe if then say 'ripe' else say 'unripe'", I think that's the strongest argument against it being "elegant".
Hot babes: http://ub1p.ptbw62is.org/hy8a2dpf/
thanks, missed this as I hadn't installed the rls
Perhaps you could design a font with a ligature so that \`.await\` appears as @? Or hack your editor to do the same? Really we have so much bigger problems to solve than syntax. It's wasting energy which could be going into other improvements. I was talking years and years ago (perhaps llogiq would remember) about doing some kind of structured AST-based Rust editor, editing/viewing with whatever syntax you want, then saving to standard Rust. In fact I was planning my own language which saved as a raw AST dumped in ASCII, halfway between what the compiler wants and what the user wants. Then the TUI would render it in the user's preferred syntax. It makes extending the language a whole lot easier, although no-one really thought it was a good idea for Rust when I suggested it. I got half-way through doing an AST-based editor for Java about 7-8 years ago, a TUI integrated with Eclipse as a back-end, but then had to stop because I needed to earn some money. Maybe later this year if there's time I'll have a go at doing it for Rust -- it would be a fun project. I have a lot of the keyboard and editing mechanics already worked out. (I was brought up with ZX Spectrum modal keyword-based program entry, so perhaps this seems less strange to me than it does to others.)
I didn't downvote but every method blocks the thread so that is boring. Await blocks my function and then basically destroys my stack as well which can be hard to reason about if you don't notice it. The simplest example would be the anti pattern of inspecting a shared object that shows indirectly the state of the `async` function. You might think that a flag is set when there is an await that happens first. To be fair this can be solved by proper API design that uses a Stream once those are available.
Is chaining so common that it needs to be the primary driver of the syntax? I can buy the argument around `?` but chaining seems to be a nest thing you can do. I may be biased because I find method chaining leads to difficult to read code as people apply it in situations it isn't appropriate in. Sometimes naming intermediate steps can provide clarity.
I *think * your point is about the difference between cooperative and preemptive multitasking. `lock()` blocks without a warning because the scheduler can preempt you whether you block or not anyway. `lock().await` also blocks, but instead of having the scheduler recognize you're waiting for a resource, you cooperatively tell the task runner.
Or if the result to fetch is _another_ url that you also want to fetch...
I prefer prefix but think that the team choosing their favorite as a starting point is good given that the community is going in circles.
Check how hot babes party: http://3ncy.3t1bjn48.org/biswbab7/
Mutex is part of it, but it's very unlikely to be the principle cause here. Python will, by default, buffer stdout. Rust's `println!` does _line buffering_, which means every `println!` call flushes the buffer and performs a syscall. When added up over a large file, this results in substantial overhead. If you want to have the same behavior as Python, then use `let wtr = std::io::BufWriter(std::io::stdout());` and then `writeln!(wtr, "{}", line?)?;` instead of using `println!`.
100% This.
Riley Raid getting destroyed: http://oa07.q6vzn0yq.org/hxko22ka/
There are examples right in the Serde documentation page
Cheers! Watch this space, it's going to be better feh eventually :)
Well, that one probably shouldn't be a one-liner.
I personally prefer the try!() macro, I find that I always miss the ? when reading other people's code.
Then Rust can just add the postfix version, whatever it may be, and you can use this crate if you want: https://crates.io/crates/await_macros
`.parse()` returns a `Result&lt;u32, whatever&gt;`. A `Result` is not a `u32`, it's a `Result`, and you have to call a function that takes a `Result&lt;u32, whatever&gt;` and returns a `u32` to get a `u32`. `Result` defines `.expect()` and `.unwrap()` as such functions, but there could be others; for instance, `.unwrap_or(u32)`, which provides a default value. In essence, you are performing a fallible operation, and you have to tell Rust what you want to happen when that operation fails. One option is to give up on the whole program (`.unwrap()` or `.expect()`); another is to use a default. The big advantage of having an explicit error return type is that you can do even more complex things: let my_num = match input.parse() { Ok(v) =&gt; v // If we got a value, just use it. Err(_) =&gt; { retry() } // Otherwise run some arbitrary retry function }
Is it a generalization? How would you represent a conditional await using bang notation? Or is that only a limitation of Haskell's do-notation and Scala's for-comprehensions? I mean something like this async fn foo(x: bool) -&gt; i32 { let bar = fut1.await; if x { fut2.await; } 42 }
Thanks for your input on this. What you wrote is very innovative, especially for only having one day of experience in Rust. &amp;#x200B; While what you wrote is clever, and would certainly work for this one example, it feels like a hacky workaround that is compensating for a lack of language functionality that could express the behavior much more cleanly. &amp;#x200B; The fact that you would have to create an extra trait for this seems needlessly verbose. It also does not scale well. Consider if I had a trait with more than one function: &amp;#x200B; Let's say I have (within a single trait): - A method that has a default implementation if the type implements `Debug`. - A different method that has a default implementation if the type implements `Clone`. &amp;#x200B; Now, I must create 3 different default traits, and (unfortunately) it is dead in the water right here. As soon as we try to have a default implementation for both, we will get a compiler error. &amp;#x200B; [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f2d27bf5a517bb24e7dfb8a537dd52af) &amp;#x200B; I'm certainly not an expert in compilers or language design. That's why I'm trying to see if the behavior that I'm looking for can even exist. Again, I appreciate your input, and I hope you keep programming in Rust.
Wow I don't think I've ever seen a link i want to click on less. Surprise to see that they haven't been sitewide banned yet
Theory vs Practice. Just because at a high-level you see an inclusive range and knows that overflow is impossible does not mean that at low-level looking at LLVM IR the invariant has not been lost. We can harp that LLVM should be smart enough, etc... but at the end of the day the myth of the sufficiently smart compiler is just that, a myth, as unfortunate as it is.
I also do wish we could go with postfix macro if possible. It opens up more possibilities than a postfix keyword. For me, the simplest thing to do would be to add the following syntax sugar equivalent to macros: `bar!(foo, qux) == foo.bar!(qux)` That way, all macros that currently exist can be called in a postfix way, which also enables us to do: `"Hello {}".println!("world")` And similar with the `format!`macro. This is the basis of the proposal. We'd then need to iron out a few kinks about it, such as: 1. Some macros shouldn't be called as postfix. Should we make them always postfix-callable by default and allow the writer of the macro to opt out of it, or should we make the ability to a macro be postfix-called opt-in? 2. For ergonomics, macros that only take a single non-repeating argument may not need parenthesis. So `foo!(bar).qux()` could turn into `bar.foo!.qux()`. Might be a questionable decision, but I think it's interesting to debate this nevertheless. 3. What should happen with macros that can take repeating arguments as the first parameter? Should we disallow them in postfix completely? 4. Something else that I haven't thought of. Maybe with this we could have a more unified and eventually useful addition than the postfix keyword .await proposal for now.
Parse could fail to get a u32, in the case of failure it has to represent the error somehow. In rust, when we have a function which could return a valid answer or an err, we use the Result type. The Result type can either give you the answer Ok(u32) or an Err(errInfo). The error you were getting is (my guess) that you were trying to use the Result directly, thinking it was a u32, which should be a hint in the future that you have some kind of error handling to deal with. &amp;#x200B; In general, if you have an error to handle think Result. If you have a function which could fail, the return type will almost certainly be a Result.
Then how is the compiler going to give the warning originally suggested? My point was, if the compiler is sure enough that overflow is impossible, it should emit the same LLVM IR as an exclusive range rather than emitting a warning. That way a developer who wants no warnings does not need to remember that they should use inclusive ranges in some cases, but exclusive ranges in some other cases: they can just use inclusive ranges.
Strictly speaking, `.parse()` does not "require" `.expect()` or `.unwrap()`. What it *does* require is that you handle the potential error. `.expect()` and `.unwrap()` are simply two ways to do so.
&gt; I don’t think this question can be settled other than by implementing the more obvious/conservative solution I don't think that following what all other languages already do will bring us the data needed to make that decision later. If anything, going the new path will. I personally think that this controversy will soon be forgotten, with the sentiment "wow, I got used to this quicker than expected". I also don't expect there will be enough ergonomic pressure to make a change after prefix await were added. I like Python's syntax too, after all. But I think that's a sign of human psychology, not syntactic superiority. I'd ultimately be fine with either option, and I understand people who think Rust should not be a lab rat for language features and should be conservative. But as you're arguing for collecting data on this syntax question: if we want a fair comparison, we need people that have become familiar with both syntax options, and that means at least giving this option a try. The fact that a postfix syntax has withstood all these discussions gives me reason to think that it is worth the change, and will feel natural soon enough.
AFAIK there is at least one performance issue remaining: `for _ in m..=n` does not (always) optimize well. I've tried really hard to make it happen, but couldn't manage to get LLVM to cooperate. Like all "state-machine" iterators (such as `chain`), LLVM does not realize that the "state" field has a very specific lifecycle: step 0 -&gt; step 1 -&gt; step 2 -&gt; ... without ever going back, and therefore fails to "split" the loop. As a ad-hoc fix, I've patched [`try_fold` and `try_rfold`](https://github.com/rust-lang/rust/pull/58122/files) to sidestep the optimization issues during internal iteration; but it does nothing to help with external iteration :/
Thanks for the link. I did find a lot of info on [wikichip](https://en.wikichip.org/wiki/intel/microarchitectures/gen9.5) also, but it's not easy to translate into "how to write good code for it". What *does* remain shrouded in mystery, for me at least, is how the Metal shading compiler works, in particular things like why my simd group size is 16 sometimes and 32 other times (there seems to be some kind of magic complexity threshold, but I haven't figured it out). There's a bit about that in my notes, and if a real expert comes along and can explain what's going on, I would be greatly appreciative. Aside from all the non-free parts, there's also the sheer complexity of the space. Understanding one part is hard enough, then there are 3 major architecture families on the desktop space and many more choices in mobile.
It's very surprising that field access is suddenly desirable, and being weighted more heavily than postfix macros, which have been a feature request for years. I think your outline exactly my feelings on the matter. Postfix macros are more flexible, more obvious, and more consistent. Having prefix await (which every other common async/await language has!!) solves the singular, mostly irrelevant issue of "but it can't be implemented by users", while also providing users an obvious implementation (if they come from js, C#, python).
Sure I made this point before but my opinion on this didn’t change. It does not have to be a democracy but I’m not sure if that is relevant. If something is unpopular that still affects how people feel about the language for many years to come.
&gt; My point was, if the compiler is sure enough that overflow is impossible, it should emit the same LLVM IR as an exclusive range rather than emitting a warning. At the moment the rustc frontend does not (yet) perform such optimizations. Also, the warning could be implemented outside rustc, in clippy for example.
I'm not claiming piet-metal is the best we can do. What I am claiming is that it's a good basis for getting something reasonably simple that actually covers the 2D imaging model. This is not just simple blending, but also blend groups, clipping by AA masks, etc. Getting that whole imaging model working using highly GPU-optimized techniques is years of work. I hope that happens, but I also don't want to wait for it :)
If you've made a point before and people have read it, I think you don't need to make it again even if your opinion hasn't changed.
Yes agreed. But I also think traits are generally fairly light/single purpose so one wouldn’t expect too many things like this in the same trait. Probably building “derive” is the more idiomatic way to do what I was looking at anyway (though I don’t know what that entails, or if it can be parameterised at all).
I don't expect huge chains like that. I do expect a lot of: ``` async fn foo() -&gt; Result&lt;String, E&gt; { // logic let res = foo().await!()?.to_string(); // more logic Ok(bar(res).await!()?) } ``` etc
&gt; don’t be evil, macro developers. This is already the case with macros and essentially all code. If `println!` printed things out 5x, that would be surprising. But it doesn't, because... it would be surprising.
Why not? I think this is the only comment I left about this on reddit other than a tweet.
Custom derives are something that I have not messed with yet, either. I'm not sure if they can be parameterized.
I agree, it is much better to replace await chaining with combinators on futures.
I mean, it is consistent with all other cases of member function types. It just so happens member function types in C++ tend to be ugly and annoying. The fact that you have to make a template to extract information is pretty much all of the C++ world of compile time type introspection as well. I prefer that ugliness to .await simply because it's not special (nothing else in rust works/looks like that) and reusing unrelated syntax (field access), and, well, C++ templates are just ugly when doing anything fancy.
You're right, we can't run in circles forever. In the end I will be fine with whatever variant the language team comes up with. But everyone has his favorites :P.
Why can't you just derive `Serialize` and `Deserialize`?
I’ve found these posts really helpful for my project that is playing with new and old futures and the Async keyword. https://rust-lang-nursery.github.io/futures-rs/blog/2019/04/18/compatibility-layer.html https://docs.rs/crate/runtime/0.3.0-alpha.3
I'm not sure I agree with the (implicit) assumption that aesthetics is the correct way to judge syntax. In this example: ``` return fetch("thing").await?.get("x") ``` you have three exit points inside a single statement, and even on the same line. I don't think that's great, from a readability and reviewability standpoint. Coding for "the happy path" is a way to shoot yourself in the foot. It might be cool to be able to express all that logic so succinctly, but what is actually won by not instead doing: ``` let thing = await fetch("thing"); let thing = thing?; return thing.get("x"); ``` This seems better to me in almost every aspect except verbosity, but even that is a feature. It correctly highlights the potential exit (and failure) points. It is much easier to follow for any reviewer, and yourself in 3 weeks.
If you're chaining async code, you're almost certainly better off using combinators. Haskell's do-notation doesn't let you bind a result except for once every statement. If you need something more complex, you use combinators within the statement and simply await at the end.
May I advise reading withoutboat's article discussed here: https://www.reddit.com/r/rust/comments/bld06g/a_final_proposal_for_await_syntax/ ? As for: &gt; but I find overloading the field access for a totally different concept to be pretty weird and confusing. The point is made in the article that it's already overloaded for a totally different concept: method calls. And indeed, if you have a `struct Foo { a: Fn() -&gt; (), }` field, then you cannot do `foo.a()` to call `a` because this is understood as a method call, and instead you need to do `(foo.a)()` for the parser to understand that `foo.a` is the callable.
There was a desire to retain `await` as a keyword, for future extensibility. A macro cannot have the same name as a `keyword`, so you cannot have an `await!` macro, no matter whether prefix or postfix.
C++ the language is probably a very bad place to look for examples on how to avoid hiding complexity. :-) In many cases, it is a good example on what to _avoid_ doing - for example, the fact that copy constructors in C++ can effectively hide from any reviewer that something very expensive is going on. The way C++ _programmers_ deal with this is to create code guidelines that forbid or discourage "hidden complexity" - no ternaries, no non-obvious copy/move-constructors, tasteful use of templates, and so on. _That_ is the lesson that I would expect Rust to incorporate, and it has done so very successfully so far (explicit `clone()`, etc.). Now, composability of futures - I have to say, I'm skeptical that any good code anywhere contains that. It will look great in a one-liner. I will absolutely reject any PR that I'm ever reviewing that contains it. :-) It seems to me that it is a completely bad idea, with no benefits whatsoever, that only serves to obscure complexity - complexity that is really, really relevant when you are reviewing and debugging code.
&gt;`let res = foo().await!()?.to_string();` `let res = await? foo().map_ok(String::to_string);` &gt; `Ok(bar(res).await!()?)` `await bar(res).map_err(Into::into)` How does that look? `await?`, in addition to resembling where in math, you put the exponent after the function name and not the whole expression, it also kind of reminds me of a lifted bind from Haskell where you're binding 2 nested monads.
It's unfortunate that the only options are that it looks "Ok", "Bad" or some "other" that will be impossible to aggregate. A scale from 1-5 might have given more useful results. My preference goes to the await keyword as used in all other languages that have it, and then to give all relevant keywords (mainly `match` and `await`) also field accessor syntax.
Why in the world would you want to run a parser asynchronously? Is it because the response body may not be fully received at the time when the \`fetch\` request completes?
&gt; To then go and let some of the most disruptive types of flow control be a syntactical special-case, hidden away at the end of lines, looking exactly like another extremely common language feature (field access)... That decision is incredibly baffling. That's not a problem of post-fix syntax, it's a problem of *expressions*. That is: let foo = some_nifty_call(with_a_first_arg(), await with_a_second_arg()); Has exactly the same problem of "hiding" flow control in the middle of the line without using postfix syntax.
Yes, I think fetch resolves immediately when the HTTP response header is received, before the body.
That wasn't an argument when deciding this. They can always be implemented and it seems people would like it for more than just await.
I believe this was considered and rejected because they didn't want both a prefix and postfix syntax.
So the whole point of this idea was not that *I'll* be unable to be comfortable with this... It's that it'll be dang near impossible to get others onboard. Take Julia as an example. They have this awesome syntax for applying a function elementwise to an array. All you have to do is call `f.(x)` instead of `f(x)`. Greatest thing ever. You know what that practically means for everyday work though? Never getting to use Julia because basically nobody else wants to learn it.
I think familiarity is a value in and of itself :) (Of course, that's a function of my somewhat conservative perspective in these matters.) So I don't feel like it would be unfair to postfix await, it's just all part of the equation, both ergonomics and familiarity. And the question is whether the ergonomics gain of the challenger turns out to be enough to offset the familiarity of the incumbent. Other than that, I'm also pretty sure I'll make my peace with the final adopted solution fairly quickly :) Although in the meantime, I've read [this proposal](https://www.reddit.com/r/rust/comments/bmhmtw/what_postfix_macro_could_bring_to_rust_asyncawait/) combining prefix keyword with generalized postfix macros, which would give you a postfix `.await!()` macro if needed as a result, and I must say I'm a little sad this solution probably won't be it because I find it really neat and elegant.
Thanks
The counterpoint I would make is that the syntax most people need to "get by" in C++ is relatively reasonable. Await is likely going to be rather infectious and become "MVP" for trying to use the language. Syntactic oddities are indeed small when you are someone that wants to talk language design on the internet 😊, but a large part of Rust's target audience is people who are not that. Think of every developer you know and how many of them wouldn't scoff at this the first time you told them the syntax?
That works for the simple case I mentioned. For actual nested calls, I'm not so sure. await foo()?bar()? where foo and bar are both async is still a bit ambiguous to me, and is definitely desirable in some cases. Even if the common path is probably more like what I'm stating in my earlier post.
&gt; like why my simd group size is 16 sometimes and 32 other times (there seems to be some kind of magic complexity threshold, but I haven't figured it out) Register usage, perhaps?
Maybe we're misunderstanding each other. What I'm saying is "then see what macros the community writes to make usage better" seems to miss that postfix macros don't exist, so the community could only expand upon the prefix syntax with more prefix syntax. The consensus is that postfix syntax is necessary to handle `?`.
It's irrational to leave a language for such a small syntax issue, but humans are irrational. My main concern with `expr.await` is that it will show an inconsistent special case to **all** Rust users very early. While users are still evaluating the language they will see that even seemingly simple field access has surprises and special cases. I remember I gave up learning OCaml because I saw early on that you can't print numbers and strings using the same print function. I don't even know if that's true, but I still haven't learned OCaml. Instead I learned Haskell, and Haskell does have inconsistencies, but I had to learn quite a bit before I realized that some subtle internals were inconsistent, by then it was too late, I was a Haskell user. I believe something like `expr.await!()` would look 100% consistent with other macros to beginners. Even after reading hundreds of pages about Rust, I still see `foo!()` as meaning "magic here, read the docs" and to a new user `expr.await!()` would also mean "magic here, read the docs." This is consistent from a new users perspective. One weakness of the language team is they can no longer see the language as a beginner would, such is the nature of life\*. We need experts to make these decisions no doubt, but I feel that a majority (?) of Rust users will never know enough to understand why `expr.await!()` was inconsistent. The lang team can immediately see that `expr.await!()` is inconsistent, and cannot actually be a macro, but to most users they will never know or care. &amp;#x200B; \* I think of myself trying to teach others to program, they struggle with things I cannot remember struggling with, things I can hardly conceive of struggling with. I have lost the ability to see code they way they do.
Yes, thanks for the ping.
Good form is for you to actually match and check if you had a valid value. You only unwrap if you are absolutely sure the value is always valid (or if you're debugging/testing out ideas and don't care). &amp;#x200B; That's just how errors are returned in Rust. The reason it's an error is because Rust doesn't want to promote bad behavior with syntax sugar. So there is no automatic conversion between Result&lt;T, E&gt; and the type T it is returning.
There's always the option of line splitting to clean things up. You can even reasonably safely declare a temporary variable that the compiler will in all likelihood optimize to equivalent to store an intermediate result. Even better, you could name that intermediate result something meaningful to indicate it's expected behavior.
It's possible, but as you can see from my notes just throwing in a `simd_broadcast` call seems to trigger it. That doesn't seem to me like it would have a huge effect on register usage, but maybe under the hood it does consume lots of regs.
If await has weak binding and `await?` doesn't work: `(await foo.and_then(|f| f.bar())?` assuming bar is a method on whatever the foo gives.
https://twitter.com/withoutboats/status/1027702531361857536
This is a matter of syntax. It is possible to have `await` remain a keyword and use `expr.await!()`. `await` cannot be used as a field name, yet we will use it as a field name in `expr.await`, although it's not *really* a field in `expr.await`. `await` cannot be used as a macro name, yet we could use it as a macro name in `expr.await!()`, although it's not *really* a macro in `expr.await!()`. I favor `expr.await!()` because it will make this special case less visible. The language will appear consistent for longer to new users.
I used "you" and "I" too loosely and I apologize. I think you're perhaps a little too hung up on getting your coworkers on board though. I don't know you and I don't know you situation, but from what you've described, I doubt the reason you can't use Julia at work is because of the `f.(x)` syntax. If that was the reason, it would simply be part of your team's style guide to not use it. I suspect the real reason you can't use Julia at work is because it doesn't a problem you have 10x better than whatever tool you are currently using. This is a pretty common issue throughout history; Plan 9 was superior to Unix in every way yet never caught on because it was only an incremental improvement not a revolutionary one. Adopting a language at work has a cost/benefit analysis that has to be weighed and unless you have found something truly revolutionary, it's unlikely to pay off. Consider: Possible Benefits to adopting Julia: - Julia is fast, often 5-10x faster than scripting languages it was designed to replace. - Possibly more productive to work in. - Julia subjectively has nice-ish syntax - Julia makes you happy Possible Costs of adopting Julia: - Need to train some/all of your coworkers on it. This will eat into your productivity in the short term. - Hiring people familiar with Julia will be difficult. Training new people in Julia will offset some of the productivity benefits and increase ramp-up time for new hires. - Julia is not widely used. You could run into issues with it or have to write libraries you need yourself. If your business relies on doing a lot of data processing, doing that more efficiently and faster might be worth taking on the risks associated with the new language. However, if it isn't customer facing or doesn't significantly reduce costs, it seems unlikely to me that it's worth risking. Really none of that has anything to do with Julia's syntax. Removing `f.(x)` from the language wouldn't significantly change the calculus and it may even make you feel less excited about the language ("greatest thing ever"). The same thing applies to Rust. `await!(x)` vs `.await` is not going to be the deciding factor for any company looking at using Rust. If a company needs Rust because they have a problem Rust can solve much better than their current language, then await syntax is irrelevant. If a company is just looking for reasons to adopt Rust without a good problem to solve, there are much larger reasons to decide not to adopt Rust. (eg: There are objectively few Rust programmers in the world which will making hiring more difficult or expensive. The language has a steeper learning curve than most. IDE integration is not very robust yet.)
Well, firstly, re-evaluation doesn't imply a decision. I'll probably use Rust from time to time either way. However, I don't know about you, but yes `.await` is something I expect to have to deal with every single time I touch anything network I/O related. You probably should too. If you take a look at the web stuff for JavaScript and Python, it's all over (at least in stuff that was written post-await keyword).
I'd make syntax choices from an at least attempted rational viewpoint, channeling out what looks weird, as this will only be the case for a limited time. I'd understand why weirdness might hinder adoption, but otoh users being happy with the language would contribute to adoption. I like the syntax * It's ergonomic to add onto the line when figuring out you're dealing with an async return value. * It's easy to chain further operations without wrestling syntax, introducing syntax noise. * I think it makes sense to scan the method names instead of some async syntax, they are more descriptive (with syntax highlight or a search it should be easy to switch to get an overview of async). * "Await" probably has more to do with the last thing on the line than the first. If the first is some struct, then some member, then some function.
I wanted to try this out on my mac, but I'm getting an unexpected error. \`cargo check\` works, but I can't install any components. &amp;#x200B; $ cat rust-toolchain nightly-2019-05-09 &amp;#x200B; $ cargo check Finished dev \[unoptimized + debuginfo\] target(s) in 0.12s &amp;#x200B; $ rustup component add clippy error: toolchain 'nightly-2019-05-09-x86\_64-apple-darwin' does not support components info: backtrace: &amp;#x200B; stack backtrace: 0: backtrace::backtrace::trace\_unsynchronized::hd69cd33c2ca5bb12 (0x10a9accb6) 1: backtrace::capture::Backtrace::new\_unresolved::h6ca70d9b55c71d70 (0x10a9ad0f0) 2: error\_chain::backtrace::imp::InternalBacktrace::new::h492a1464333e0f9c (0x10a9a9fbb) 3: rustup::toolchain::Toolchain::add\_component::hcb374f30b6f1334a (0x10a855a02) 4: rustup\_init::rustup\_mode::main::hee604227c0eedc7f (0x10a6cb086) 5: rustup\_init::main::hb9882bd9947f7f71 (0x10a706d8e) 6: std::rt::lang\_start::{{closure}}::h806f78d3f993285d (0x10a6a3c25) 7: \_main (0x10a70b759) &amp;#x200B; $ rustc -Vv rustc 1.36.0-nightly (3f5152e20 2019-05-08) binary: rustc commit-hash: 3f5152e200c0c02dfe0f79367948c98053d35855 commit-date: 2019-05-08 host: x86\_64-apple-darwin release: 1.36.0-nightly LLVM version: 8.0 &amp;#x200B; Am I doing something wrong? Where should I report this?
&gt;What do you think should happen if say I do something like &gt;`let testing = String::from("hello!")` &gt;`let testing: u32 = input.parse();` C `stdlib.h` function `strtol` which [Interprets an integer value in a byte string pointed to by str](https://en.cppreference.com/w/c/string/byte/strtol) will return `0` in case you pass `"hello!"` to it. It will also try it's best to parse correctly when you pass `"12abc"`, and other strings that contain junk, falling back to zero if parsing failed. I'm not saying that this is better, than Rust's approach, because it's not, since in Rust we are able to control what to do if parsing failed, my point is that for those who came from C world this might be just a legit question.
For me it really was nearly as simple as syntax in a few cases. You make some good points on the bigger company adoption side of things though.
Looks really interesting. I really like the idea of having the schema as a contract for you API and it's consumers. I'll definitely look into this!
You're preaching to the choir :-).
Does this mean we might eventually get continuations instead?
I too like to invent names for each temporary in a long chain of transformations.
Thinking of the await as being a trait seems to make it a little less magic than a keyword. The less magic the better for people's understanding. Thanks OP for a beautiful suggestion.
One of the reasons they gave for preferring `expr.await` was that it may eventually be generalized so that `match` and others can be written as `match expr {...}` or `expr.match {...}`. So they've also embraced prefix and postfix syntax as a reason for `expr.await`. Personally, I think `expr.match {...}` is terrible. Although if it was done generalizable postfix macros, then I guess people are free to do what they want with macros, and I'm cool with it. If `expr.match {...}` is a special case, then it's not worth it.
&gt; Await blocks my function and then basically destroys my stack as well which can be hard to reason about if you don't notice it. Oo, good point. I wonder what the ergonomics are like when obtaining things like locks. So if you use an await and you had a lock, it gets dropped then right? So you'd have to re-obtain the lock after every await call? Of course you'd want to design your app a bit differently to avoid that mess, but this is just to discuss the issue.
Ah! In that case, I would expect that it's because Rust is already very sigil heavy, so a reluctance to mandate more sigils may be coming into play. For example, why it does stand out, it kinda drowns out `?`: - `expr.await?`: the `?` is fairly visible, indicating that the result of `expr.await` may fail. - `expr.await!()?`: there's some soup after `expr.await`.
Very good points. I especially like "magic happens here", as it is quite descriptive currently.
Fair points. I can see the thought process. We start with `await!()` but then acknowledge it's not actually a macro, so why are we jumping through syntax hoops to write the extra `!()` when it's not really even a macro? Let's just write `await`. I can sympathise with that view, even if it's not my preference.
You should be explicitly dropping your locks before awaiting. I don't know if they added special logic but usually locks are held across await points since the locks held in the function are stored in the backing object that handles storing such data across await boundaries.
That decreased runtime all the way down to **14** **seconds**. Damn. Thanks man. Leaving the faster version here for visibility: let logfile = File::open("test.log")?; let stdout = io::stdout(); let mut output = BufWriter::new(stdout); for line in BufReader::new(logfile).lines() { writeln!(output, "{}", line?); } &gt;(Also, just so you know, you aren't iterating over lines in the fastest possible way. But it should be enough to best Python.) I came across `memmap::Mmap` when searching on the subject, is that where I should start looking next in order to accomplish this?
Hi all, wrote up some notes on my thoughts on the most recent proposal. I wanted to write it up to keep it fresh in my mind, so decided I might as well make it public. It's sad that such a long awaited (heh) feature is going through such a controversial debate this close to fruition.
It is a good question, coming from other languages you might be used to failed parses returning some default value like 0, or throwing an exception. Rust uses Result or Option types for these kinds of things instead, which makes it less likely for you to forget to handle error cases since you have to explicitly opt into ignoring them (by calling expect or unwrap)
&gt; The first question that pops to mind is probably "OK, what code runs here when I call this method?". And the answer is literally "code from whatever coroutine happens to be picked". In my mind this does not fit at all with how a method call should work. This is also to some extent the case when calling a trait method on a type parameter or a trait object (the article also briefly mentions monomorphization). In the former case, the callee may be unknown until the code is put into an actual executable, in the latter, the callee might even be unknown until the call itself actually happens, which is pretty close to "whatever coroutine happens to be picked".
Yea I understand it was a legit question and I hope my answer didn't come off as 'mean' in the case that's why you're mentioning it. For me Result types were super confusing at the start too. Anyways I think with the way strtol does it it sets the errno to the error value whereas rust seems to not have a similar 'concept' and errnos themselves are handled through io::Error I think though I may be wrong about that last part
I really like this article. I think it helps me to think past e.g. the JavaScript version to actually what is the best syntax.
I'm posting this as a follow-up to the [thread](https://www.reddit.com/r/rust/comments/bipiqg/keeping_rust_and_other_libre_software_accessible/) about WGs moving to Discord. It articulates well the reasons I think it's worth slowing down work to some extent in exchange for avoiding lock-in on proprietary platforms.
I use a newtype wrapper: let bd_map = extract_borders(im_buffer, SimplifyThreshold(1.0));
&gt; In the mandatory delimiter version, `await { foo }.await { bar }.await { baz }` Is that correct? I would expect something like: await { await { await { foo }.bar }.baz }
&gt; Not to mention that this Trait syntax allows disambiguating from other fields/methods with Await::await(futureFactory.await()), where I'm not aware of a solution for field accesses. `await` is a keyword - you can't use it as a method name or field name in the first place.
I'm new to Rust, reading the book and doing some LeetCode exercises. I'm doing an easy one that asks you to count how many visits you have in each domain/subdomain, e.g. if you visit [mail.google.com](https://mail.google.com), the visit counts towards [mail.google.com](https://mail.google.com), [google.com](https://google.com) and com. It's working, but I have a question on how to improve something. Given this chunk of code: let mut counts : HashMap&lt;String, i32&gt; = HashMap::new(); ... let mut current = String::new(); for d in domain.rsplit(".") { current = if current.is_empty() { String::from(d) } else { format!("{}.{}", d, current) }; let c = counts.entry(current.to_owned()).or_insert(0); *c += count; } Notice that I need to use `current.to_owned()` when updating the map , because it takes a String as a key (I don't think I can use a reference, since I generate the strings on the flight. BTW, I think I could just take slices of the string, but let's imagine that the problem was slightly different and I couldn't). Since I use `to_owned()`, I'm making a copy of the String. That is reasonable when the entry is not in the HashMap, since `current` is mutable and I need to create a copy to keep the value. However, when the entry is being updated, the key exists already, and I don't think there's a need to make a copy, so this is redundant, but I can't find a way to remove it. Any ideas? Thanks!
I find it comical that the blog post about the potential final syntaxes talked about Rust's "weirdness budget" and how it's important and already stretched, and then they just do a total 180 and go with the "weirdest" implementation because "it might be useful". I probably wouldn't care if it wasn't `.await`. `$await`, `@await`, `~await` - anything that doesn't needlessly overload the `.` operator would have been better. `.` has been method/field access in basically every procedural language since the dawn of computing. Why are we suddenly using it for keywords? I still haven't found a real reason for going with postfix operators - it's always "it makes future chaining easier", or "the bound expression is ambiguous if it's prefix" which is bullshit. Then there are the issues with `async` `?` which is another point of "Why do we even have this" since `?` breaks a bunch of common language paradigms by itself. `async` points are important enough in a systems language to justify a break in method chaining to make ABSOLUTELY clear where your control flow breaks are - that's what `await` does; it is a control flow operations just like `return`, `break`, or `if`. This whole situation has me unreasonably angry. It's like `await` isn't even the real issue and people in the lang team just want an excuse for postfix `match` and are using this as a gateway for introducing postfix keywords instead of coming up with a real solution. /rant
A note a the parentheses - the really killers is the flow of the statement, not just the parentheses. For any small-ish or larger chain, a prefix keyword can really muddy things up (especially since there's no extra logic to the keyword - no extra block of code associated with it). E.g. `my\_thingy.create\_task().await.map\_err(|e| e.convert\_into\_a\_different\_error)?` &amp;#x200B; reads left to right. Compared to `(await my\_thingy.create\_task()).map\_err(|e| e.convert\_into\_a\_different\_error)`
I have 3 main issues with postfix await: 1. Unlike a prefix keyword, the beginning of the statement no longer signals the intent (branching off and doing an async thing) 2. I've done a lot of async programming in typescript/javascript, multiple awaits in a single line is something that rarely if ever happens in a code base, and it's almost always more clear to declare a temp variable and break it into multiple lines. 3. This is extra weirdness for rust beginners, which is going to hurt adoption. It hurts adoption of those learning a new language in their spare time, which in turn really hurts adoption within organizations. If this were an obscure feature it wouldn't have as much of an impact, but async workflows are becoming common place, and that's going to be one of the first things people try to learn.
`strtol` sets the second parameter to point to the first character that could not be parsed, which allows you to distinguish between different cases. Of course, programmers tend to just pass `NULL` and ignore any unhappy path (and obviously don't check `errno` for a range error either…)
Another consideration is chaining awaits, which isn't covered in this post. Though it does seem like chaining is the less common situation, it does lead to the gnarliest situations with prefix await (forcing temporaries that aren't helpful, or many extra parens and reversing order of application).
Await, the field version means that? I didn't expect that
`strtol` only sets `errno` if the parsed value too large or small. To check whether *anything* got parsed, or whether anything was left *un*parsed, you need to pass a valid pointer-to-pointer as the second argument, which `strtol` modifies to point to the first character left unparsed, or to the end of the string if everything was parsed.
Yep! This is true and very valid. I didn't cover it simply because I have no opinion on it (I would never use it). Having said that though; this is partly why I don't want to throw away the postfix version entirely and instead want it to be introduced as an optional syntax at a later date.
Was there ever any discussion of using something like `await?`? Eg: let x1 = await? foo(); let x2 = (await foo())?; // same as x1 let y = await? foo()?; let y = (await (foo()?))? // Same as y1
This is a good point but has a userland solution. You could do what the existing `futures` crate does and expose the same methods that a `Result` has on a `Future` extension trait. In this case you could write this code: ```rust await my_thingy .create_task() .map_err(|e| e.convert_into_a_different_error); ``` And in theory it should function correctly. You'd be calling `map_err` on the `Future` type, rather than the awaited `Result` type.
There was; I believe it was thrown away because it would require two keywords rather than a single `await` keyword. I'm not entirely sure why it was thrown out, but there is definitely a lot of discussion around this option in the forum threads.
Gotcha, thanks.
&gt; Is there any popular application, built on Rust? Deno [https://github.com/denoland/deno](https://github.com/denoland/deno) Deno is proof of concept for reworked Node, being written in Rust. Node is one of keywords in web development world. Interested to see where this goes. Personally, I'm interested in Rust because it compiles into WebAssembly, which will have use cases in client side web applications.
I agree with the idea that macro syntax basically says "here be magic". I don't quite get the argument that not being a macro writable in rust makes it unsuitable, since plenty of macros like \`include\_string!\` and \`module\_path!\` are not actually macros but compiler built ins. I will say there is at least one language precedent of the \`.operator\` syntax and that is ruby, but I don't see it fitting well into Rust where we try to minimize magic outside of macros.
I'm hard pressed though to find an example where I wouldn't want to bind at least some of the results and check them for something. That makes these kind of `foo,bar,batz` examples rather terrible.
It's not just Result types that you'd want to call methods on. Though I admit that `Result` will be a very common future type.
I agree with that, definitely! Although I'm not sure how practical it would be in non-Result use cases, given that you can simply store the result of the `await` and do whatever else on the next line.
Yes, it's an associated type. An associated type is a type that's, well, associated with a particular implementation of a trait. More specifically, given a concrete type (i.e. one where all type parameters have been filled) for an implementation, each associated type has a fixed value. A [small example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5050f86d97f70b1fe877d18fe678b901) with some non-standard `Rem` implementations might be useful for illustrating how associated types work with Rust's operators. In the case of `Stringify` and `Greedy`, the associated type is constant, while for `Identity`, it's a function of the type parameter. Another motivating example might be [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9de3490b02eae720851575d30ef147ed), which is a simplified version of some real-world code I worked on recently. Note how in `escape_field` the type of the value passed for the first parameter determines the type of the third parameter since we can refer to its associated type. Does this make things any clearer, or have I just muddied matters further?
Here's the example I've been using that shows the true advantage of postfix syntax: let response_json = request_builder() .POST() .URL(...) .header(...) .build()? ..await? .error_on_4xx()? .body() ..await? .parse()? The `..` is my own proposed compromise for postfix control flow operators, but it gets across the point either way. Doing a statement like that with prefix await would have to be broken up into many more statements.
&gt;The programmers first interpretation of &gt; &gt;f.await &gt; &gt; should not depend on the name of &gt; &gt;f &gt; &gt;. And it would not under the proposed syntax-- \`await\` is not a valid identifier. No matter what \`f\` is, this is an await of a future.
To nuke it entirely: `rm -rf ~/.rustup/` You might have leftovers in `.profile` too.
The problem with this is it doesn't solve the larger chaining problem; it's just a very specific special case for `await` and `?` that has the further disadvantage of putting the order of operations even more out of order.
Yes, there's definitely a slot where the chaining aspect works well - that's why I want to have both. I don't really see a reason why we can't introduce `await future` and then add the postfix at a later date.
I feel like the real problem is the ? Operator. I didn't like it when it initially came out, and I still don't like it today. If we didn't have it, I wonder if the decision to use prefix would be much easier.
rust can be arranged to work as a cdylib as well, then it's perfectly fine and stable to dyamic link.
Based on what was posted in the language team docs, I'm fairly sure that it would exist as `await future` if the `?` operator didn't exist. The only reason this discussion started again was because of the need to do `(await future)?` to pass errors back.
Yeah, I really like the "ellipsis" notation because you are... waiting for a future. It's just aesthetically perfect and distinguishes from just the dot operator. I haven't followed the discussion close enough. Was there a reason that was turned down or overlooked? I know it was independently proposed a few times.
Not the compiler's first interpretation, the programmer's first interpretation. Unlike the compiler, the programmer doesn't know every single thing about the language.
Is that any different from `Box&lt;dyn Fn&gt;` (which was discussed [above](https://www.reddit.com/r/rust/comments/bjy63u/code_critique_request_typeerased_function_object/emcffu5/))?
I don't like conflating simplicity and consistency here - "simple" would be await foo()? where the operator ordering was reversed because its "simpler" to just know what you meant. But that would be inconsistent. Its a real problem in Rust, and its one that the entire efforts last year about trying to make onboarding new devs easier, largely failed to solve because of those priorities. And while its impossible to realistically reverse language decisions already made that created that problem, I wish new decisions like the await syntax weren't making that already established and confounded problem worse.
This is already possible with `futures::prelude::TryFutureExt`: `(await my_thingy.create_task().map_err(|e| e.convert_into_a_different_error))?` Of course, if the conversion can be encoded as a `From` implementation, then it's even shorter `(await my_thingy.create_task())?`
How did you install rust? If you used apt, you should be able to `sudo apt purge` whatever you installed.
`FutureExt::then` and `TryFutureExt::and_then`? Would those suffice?
I feel like people asking for chaining are overlooking the possibilities of using combinators in conjunction with `async/await`. `async/await` *reduces* the need for combinators, but combinators are far better for chaining in a single statement that `async/await`. You don't see Haskellers reaching for do-notation every time they touch a monad, only when it's it's convenient and more readable than the alternative.
I've been a little confused about the chaining aspect itself; the point of `await` is literally to avoid the need for it. It seems counterproductive to try and make the keyword better support it, at least to me.
I think you'll have to wait until the [raw entry API](https://doc.rust-lang.org/std/collections/hash_map/enum.RawEntryMut.html) is stable. [Here's an example]( https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=aaf1d2716cfe9fd914c6342a9ce68620) of how it currently works on nightly. I made the closure a little more complicated just to demonstrate that it only gets called in the case of a missing key.
Is there a good way to implement shared, mutable and move iterators without code duplication or macros? I have a tree with a non-trivial Iterator implementation and would like to have all kinds of iterators.
\&gt; If you're reading this, I've always loved reading your comments and the amount of patience and effort you were putting into answering questions. That's very kind of you to say, thank you! &amp;#x200B; I deleted that reddit account for a couple of reasons, but one was that it was a very very old account. I'm on a bit of a privacy kick right now, and I'm trying to limit my social media exposure to strictly work related things (rust, game development, etc). I know I don't post very often, but I'd rather people not look back at 10 years of random post history. &amp;#x200B; Also, though I don't post very much, I've been using reddit too much for idle browsing and it hasn't helped my mental state. This account is for work only (/r/rust mainly), so that I don't have any temptation for idle browsing. &amp;#x200B; Also, I have lately been trying much harder to \*not\* focus on day to day drama in social media, and that includes the tech drama on reddit / hacker news / et all. The wlroots post was part of this, I wasn't mad about the post as much as the fact that I spent so much time thinking about things that were ultimately not very constructive or helpful. That was time that would have been better spent making things. &amp;#x200B; Anyway, I'm still around here and on twitter, but I'm trying my hardest \*not\* to pay \*too\* much attention to them. I'm happy to occasionally quickly scan them for new interesting projects, but I'm not going to read every comment, and I'm probably not going to read many hot take blog posts that I know might upset me. &amp;#x200B; This is a good example actually... if you think there's a post that I missed because I'm actively trying to not pay very much attention, then just mention me. &amp;#x200B; Regarding the lua-sys crate name, I don't have any immediate need for it. I think it would be great if there was a maintained set of minimal unsafe bindings to luajit and PUC-Rio Lua, but from my experience with people using it, for it to be maximally useful it would need to cover all of LuaJIT and PUC-Rio Lua 5.1, 5.2, 5.3, and soon probably 5.4. Maybe that means that there should be 4 or 5 separate sys crates? I'm not totally sure. &amp;#x200B; (Edit: oh, by the way when I say "work" I don't strictly mean things that I do as a job for money, I more mean any programming things that are actually useful to people. Open source stuff counts obviously :)
Await is for chaining *across* statements, combinators are for chaining *within* statements. The question is just how much do you want to put in a single statement?
I think it wouldn't bother me as much as it does if it was a method call instead of a fake public member of a struct.
Memory maps provide a *slight* performance boost in very specific cases. I wouldn't recommend that path as your first stop. Your primary issue is that you're allocating a new String for every line. And also doing utf8 validation, although you might want that. See: https://docs.rs/bstr/0.1.2/bstr/io/trait.BufReadExt.html#method.for_byte_line
The lock-in factor on these proprietary platforms is basically non-existent wherever the community can immediately roll over to a different service if we ever need to
`future.await!?` has so much excitement to it, dontcha think?
It's going to be fake either way, even as method call, and that way we save 2 bytes. Also, fake public member is more surprising than fake method call, which will make people lookup the syntax faster if they haven't seen it before.
I'm curious what makes you want to nest those awaits instead of this? ```javascript const response = await fetch("https://endpoint.url", { method: "POST", headers: { "Content-Type": "application/json", }, body: JSON.stringify(data), }); const body = await response.json(); ```
One thing I don't understand about people that really wanted a prefix macro or think it's too weird, isn't it possible to write a `_wait!(future)` macro that renders future.await -- and then you never have to see the .await in your own code.
It is 100% possible and in fact is what's done to patch in support for code that uses the prototype built-in macro. However, as they say, programming is 90% reading and 10% writing, so a) you'd have to read it in other people's code all the time and b) your code would be the anomaly.
I like your argument. Even the thought of having a syntax with optional braces (await { thing }) producing an abomination of a anonymous async function like the example below deeply amuses me, I must agree that the method call syntax would be the most logical one. It's a compromise that doesn't look totally out of place like the postfix syntax, doesn't produce weird-looking code like the prefix syntax and doesn't introduce another symbol to the language. ```rust fn main() { let x = await { // loads of code future // returning a promise/future }; } ```
If I want to name the second variable ‚response‘ what would be a good name for the first variable? I put a lot of consideration into naming things, and the effort of having to manage two names for one thing I want to operate on could be spent on writing actual features :)
Is it fair to summarize this suggestion as follows? * We first design a new calling convention. In the new convention, the semantics state that the caller acts as a pass-through for yields done by the callee. Or phrased another way, the caller automatically yields whenever the callee yields, and returns control back to the callee when it is regranted control. Otherwise it acts like a normal function call. * With the new convention, write a `future.await()` method in ordinary rust. * The compiler need not implement `.await()` with a clear separation between caller/callee (ie it can inline every `.await()`), but the semantics must agree. If I've got that right, I think this is a very elegant solution! The only drawback I see is that we don't want to grow a jungle of weird calling conventions. I think this use-case is very compelling, but we should proceed with some circumspection.
I think the point is that it wouldn't need to be.
&gt; is that only a limitation of Haskell's do-notation The same way as any monad? do x &lt;- if foo then await bar else return baz quux x Caveat: it's been years since I actually wrote any Haskell...
Yes, `Box&lt;dyn Trait&gt;` is a fat pointer, 2 usizes wide: (pointer to boxed data, pointer to vtable). If you take a `&amp;dyn Trait` and take it apart and store both the vtable pointer and the pointed-to data inside the Box, then you'd get a thin pointer (one usize wide) pointing to a fat trait object (both vtable pointer and data alongside each other in memory). You can reassemble a `&amp;dyn Trait` given the pointer to the Box. I haven't followed all the details of Waker, so I'm not sure it will help, but it seemed very similar so worth mentioning.
If this were a trait method then you could use function syntax which would look exactly like that!
`response`? Variable shadowing is not only allowed in Rust, but encouraged in cases like this. If you really wanted it on one line, then you count use an `and_then` combinator and you would only have one await for the whole statement. `await` should be for chaining *between* statements, not *within* statements.
Await is already a reserved keyword in the 2018 edition. I don't think it can be changed at this point without another edition.
I think their argument for dismissing the "method call" syntax is kinda weak. They say it could not be implemented as a trait, but then prefer a direct field access syntax which clearly is not how it is implemented. I think the "method call" is much more clear in the "something happens here" aspect than the "field access" syntax. Of course postfix punctuation would work as well.
You know promises are monads yeah? `const res = await fetch(url, options).then(r =&gt; r.json())`
.. may conflict with the possibility of a cascade operator, though. Something which is useful as an alternative builder-like API for non-builder APIs.
Post-fix macros are a necessity for Rust's future. The lack of UFCS in C++, for example, is a great pain as it forces chaining (which is really important for range composition) to use a weird syntax. UFCS consistency between the regular language and macros is essential.
That sounds like it agrees with pretty much everything, yes * Totally. As later mentioned, some form of inlining is one way to look at this. That might forbid some forms of recursion but as such methods are not intended to be defined as non-lang-items (yet? never?), the specifics of what's allowed within are and need not be 100% clear. * Not quite but close, I would argue that `await` should still be a keyword for clarity and that direct reference to `Await::await_fn` is not possible (it isn't for fn-call as well). But make the compiler map the method `await` to that call. * Yup
&gt; await should be for chaining between statements, not within statements. Finally someone agrees with me. This whole chained await argument is driving me insane.
I hate chaining, and I actually would like that `await (await (await foo).bar).baz` would encourage people not to. But if that was the one deciding factor for me, I would pick the "method call" over the "field access" syntax every day.
Haskell doesn't even let you do this kind of chaining. do-notation is strictly 0 or 1 binds per statement. You want more than that? Separate statements or combinators.
We'll all get used to it. The problem is getting attached to one solution or the other before the decision was made.
`await foo.async_a().and_then(|foo| foo.async_b())`? Or better yet: { let foo = await foo.async_a(); await foo.async_b() }
https://www.youtube.com/watch?v=wO8jpo5E48Q
After installing something that modifies your PATH, you should restart the terminal.
Macros don't have to use commas to delimit arguments. My proposal (which is probably horrible, but): macro_rules! postmatch { $matched:expr.{$($contents:tt)*} =&gt; (match $matched { $($contents)+ }) }
I really like this idea, but how could `await` be the name of a macro if it's a keyword? Seems like the only way to invoke the macro would be `future.r#await!()`.
I think that's the whole point of reserving keywords, isn't it? Once you figure out what to do with them, you keep them or you get rid of them. I don't see how removing a keyword would cause problems. There's no code written using it exactly because it's already a keyword. Ps.: But if that's the restriction, no problem. Just wait for the next edition to free that space up.
I like it. This is seriously unreadable unless you are used to (no amount of other language proficiency will help), and simple enough when you are *and* manage to concentrate for long enough, like any good modern C++ plumbing code is; perfect! I'll use it :) Well I think C++ has gone way too far even with just SFNIAE and void_t. And obviously, I use them :P
I'd sacrifice more bytes to improve readability every day. I do agree that the "field access" syntax is the most surprising one and that's exactly why I think it shouldn't be the one picked. I think that "field access" syntax breaks the symmetry of the language in a way that all the other options don't. It does the least expected thing possible, as it runs code where the syntax implies a direct memory access (an O(1) operation, nonetheless).
Given Discord sounded like it has(?) a real chance of replacing IRC, it makes an interesting statement as to how much the Rust community values FOSS. Whilst a project code might be FOSS, if they opt to use and advocate proprietary tools in support of their project when there are viable alternatives, it seems to me they're relatively weak supporters of FOSS and the surrounding community. I don't like it, but I'm OK with it. (Not that I'll be joining any Rust Discord communities any time soon.)
What's your favorite `await` syntax? :D
async/await: Battle Royale.
Isn't that `defer` syntax one of the syntaxes proposed for `await` already? Defer is also a bit of a bad choice, since it kinda already carries the meaning of "run this code when this function goes out of scope" from Go, isn't it?
Yeah I was thinking about that after I responded. I don't think it'd be a breaking change since it's not implemented yet, but I have also been surprised by what things can be...
Well, I added a PS because I thought about one: you get a code from someone with a newer compiler but your version still flags the keyword as reserved.
Would the opposite work? An await block where all futures inside are awaited, and it would only be allowed in an async function.
`await {}` is a proposal AFAIK, but it has the normal explicit await semantics. I'm not familiar with Go at all, so I can't speak to existing meanings. Certainly I have no strong opinion about the `defer` keyword itself, it was just the first thing that occurred to me to express the concept.
The only flaw I see in this is that you might want to return a `Future` without actually doing anything with it. I'm not sure how common that will be once async/await lands, but currently there are libraries that return you a `Future` and you spawn it on your own Runtime. This way the library doesn't need to depend on whatever is driving your IO (so they can omit Tokio as a dependency, etc).
I would agree with this. I think that it'd be better to have the common syntax and then introduce a generalized "postfix operator" scheme that works all at once.
In that situation, couldn't you either A) make the function not async in the first place, in which no transformation would occur, or B) have a defer{} block at the outermost level of the function? I agree that B would introduce noise, but I'm not familiar with how frequent the situation you describe is in normal application code.
In that case though what is the purpose of the async declaration at all though? Just for the Future-wrapping of the final return value? I guess it would come down to what is more common, wanting to unwrap all Futures by default or not wanting to. I suspect, but don't know for sure, that wanting to unwrap by default is the desired behavior. After all, all of the concern around the various await proposals seems to stem from a desire for easy chaining etc.
You should remember that inside the `macro`'s `()`, you can have almost anything. Ie. I had a `map!` macro that kinda worked like a `vec!`, but giving `HashMap`s instead. Syntax looked like `map!("a" =&gt; "b", "c" =&gt; "d")` or something like that. That would break if that change didn't took that factor into account. Maybe instead of an opt-out an opt-in?
Yeah, with that in mind then it should definitely be opt-in.
I like your idea, I was just wondering if we could do it without the extra keyword. Just incase defer is ever wanted for Go like defer. &gt; Just for the Future-wrapping of the final return value? Yeah &gt; all of the concern around the various await proposals seems to stem from a desire for easy chaining etc True, but like all blocks in Rust a final expression would be the "return" value for the block, so you could just chain on the end of that. In fact, my idea is basically just the `await { expression }` syntax, but with the block looking bit being an actual block.
With all the talk about await, is there a crate to use async/await as green threads?
Hmm, maybe. I guess the equivalent in rust would be adding an else branch to that `if` that contains `await future::ok(())`. But that adds another yield point :/
I live fairly nearby, I really should start coming...
Oh, it absolutely does have that very same problem, and I would probably also reject that line in code review if I was reviewing it. Nothing personal. :-) I don't believe there is any good reason to write asynchronous code like that. I suppose I am influenced by the kinds of systems I've worked with in C++, but my experience is that it is important to place high visibility around any kind of flow control (be it exit points, loops, implicit or explicit branches, or indeed sync-points in asynchronous code). These are things that are hard to reason about as a reader of the code, and more importantly as someone who is maintaining and debugging the code. Splitting the expression into two lines is a great improvement in this case, with no downsides. And you can do that with postfix syntax as well, of course, but it seems that the main rationale for it is to make chaining ergonomic -- which is a baffling goal to me, because I don't think it is a good thing to optimize for.
Hm, would you need fully qualified for that? I guess not...?
Without `?`,`try!(x)` and `await!(f)` would probably be accompanied by `try_await!(f)`, which personally feels much more sane and readable than `f.await?` In fact, I think I'll use that as a macro to sidestep the new syntax if I ever need async code.
A job security enthusiast i see.
Python too. List generators are sexy, if performance sinks.
I'm not sure what you mean by that. (again, if I take something like `Object.create(null)` for the analogy) I think JavaScript "object" is a pretty good mirror of "pointer to a struct" from C/C++ land. If you replace one term with another, it makes perfect sense that `null` has the same type as any other object too - it's just a reflection of NULL being a valid pointer in these other langs.
Please don't forget we also operate a high-volume Zulip, because a lot of the language design happens there. Zulip is fully open-source, we just use a hosted instance. The same is true for discourse, the forum software we use. Discord was selected over other options last year because _it worked_. We have trialled multiple products before. Things have changed in the last 12 month, so the same scenario would play out very differently today. Also note that Slack, for example, was proposed but in the end not accepted because of many of the concerns that we outlined with chats: we need moderation and moderation documentation. It's really not that we don't want to support FOSS or don't care, but it's not the only axis we evaluate on.
\&gt; larger chaining problem &amp;#x200B; Some believe chaining problem does not exist. Because it is rarely needed. &amp;#x200B; And when it is needed it can be solved with more variables or \`and\_then\` combinators or parens.
`await?` operator solved this problem: ``` await? my_thingy.create_task().map_err(|e| e.convert_into_a_different_error) ```
I’ve been watching this great debate for a while now. I myself and many other people (especially coming from other languages) like the prefix await syntax. I do get given rust futures don’t work quite the same as many other languages Async code, hence we have problem with chaining syntax. Here’s my two cents let foo = await bar().baz.whatever Above should await on any futures in that chain but return value otherwise. I might be naive but shouldn’t compiler already has that information? If you don’t want a future to be awaited you can’t put it in a chain that has await at the front. Just putting it out there
`await?` operator fixes this issue: ``` await? my_thingy.create_task().map_err(|e| e.convert_into_a_different_error) ```
Thanks for the heads up :) Keyword (with optional {} braces), and/or both macro forms (with preference to postfix) FTW
In order to heal the terrible rift in our community, I propose the following compromise between prefix and postfix syntax: we use the prefix syntax but support chaining by "frontloading" all of the `await`s. So, await!(await!(await!(f).foo()).bar().baz()) becomes await.await.await f.foo().bar().baz() Question marks are also supported: await!(await!(await!(f)?.foo()).bar()?.baz()) becomes await.await.await?? foo.bar().baz() The compiler will be in charge of figuring out exactly how to intersperse the `await`s and `?`s. I realize that this proposal might be controversial because `await.await.await` is so long to type. Therefore, I also propose the syntactic sugar aaawait?? foo.bar().baz()
This is hard to read, hard to modify and hard to debug. This can be rewritten to the same line number: ``` let request = await? request_builder() .POST() .URL(...) .header(...) .build()?; let body = await? request.error_on_4xx()? .body(); let response_json = body.parse()?; ```
Maybe we need the interrobang operator (`‽`), lol
If it's a keyword we can make it do anything :). Internally, `.await!()` would still have to be specially treated during parsing, but it's a keyword. We can do that. The macro is still implementable in normal rust, you just can't give it that name. _shrug_.
Gods no. I still have hard feelings about `?` and introducing even more “magic glyphs” will make it even worse.
Because what if parsing gives an error. Rust is all about runtime safety, and you have to be prepared to handle errors. If you don't care, you use `unwrap()` on everything. If you kinda care, you use `expect("")`. If you don't want ANY runtime error, and want every single error to be managed: `let testing: u32 = match testing.parse() {` `Ok(o) =&gt; o,` `Err(e) =&gt; panic!("Some error {}", e)` `}`
Right now there are many situations where I'm chaining futures together, albeit at declaration time rather than consumption. I've never yet run into a situation where I have nested futures rather than chained ones.
I hope that if this legitimately comes to a head where both prefix and postfix camps are near equal in representation the lang team might recognize this as one of the unique instances where duplicating functionality might be the best answer - giving both prefix keyword and postfix function as syntax for the same behavior. That would absolutely be confusing for new users to run into both variants, but at the same time would also likely help new adopters more constructively reason about async handling if they gravitate towards whatever feels "natural" to them. It wouldn't be much different from how you can construct a string from a &amp;str by either postfix str.to_string() or with the string constructor Sting::new(str). Both forms existing mostly helps the language than hurts it despite the bloat because it often lets users write their intuitive mental model and have it work, even when we know there are often multiple common assumed behaviors for these kinds of things.
``` aaawait ``` upvote
Favor explicit over implicit. We really should put the `?`s with their corresponding `await`s therefore `a?aa?wait`
&gt; Having prefix await (which every other common async/await language has!!) solves the singular, mostly irrelevant issue of "but it can't be implemented by users", while also providing users an obvious implementation (if they come from js, C#, python). It does *not*. Prefix `await` requires that `await` remain a keyword (or a hack to make it a contextual keyword only in that location but that's a hack). Once `await` is a keyword, `f.await!(..)` cannot be implemented as a macro by users, postfix or otherwise. It may look like a macro call (since libsyntax would parse the tokens `[".", "await", "!", "(", ")"]. However, it would get mapped to a special AST node right away and not partake in name resolution and actual macro expansion as you would expect from a macro. This means that it is a macro in name only. So you would have fake macros. That doesn't seem much different philosophically than fake fields. However, fake fields read, in my view, better. As for postfix macros being more consistent, I ask what they are consistent with? We have no such concept in the language today. That said, I think postfix macros are a good idea *as well*. But that does not mean that `f.await` needs to be a postfix macro.
You're right. The problem I'm having is that my LALRPOP configuration returns each valid AST node as the same type (Box&lt;Expr&gt;), so when I call a kleene star for something like a list of arguments it will just collect what it returns into a single vector.
Oh, yes, sure, the fact that it's a keyword does mean that I can't make it a macro. I don't think that the point was "literally the same macro with the same name" - you also can not implement a "return" macro, I assume. What I meant was I could implemented \`my\_special\_await!()\`. I can't imagine that isn't what boats was referring to. \&gt; So you would have fake macros. So? It's only "fake" in that it's secretly a keyword, the point is that I could implement my own postfix await macro by another name. And I've already said "fake" doesn't matter - it certainly applies just as much to postfix .await. \&gt; I ask what they are consistent with? We have no such concept in the language today &amp;#x200B; Sure. What I mean is this: If I, an experience rust user, saw a rust codebase in a month that had "foo.await!()" I'd go "neat, rust has postfix macros". If I saw "foo.await" I'd go "isn't await a keyword? how did they make a field with that? must be some kind of a future". I have a mental model for macros already. I have no mental model for \`.await\`. This requires a new mental model for how rust code looks. So, basically, postfix macros require a minor, intuitive change to my existing model rather than a completely new addition of a model.
Where should I be opening an issue? I'm very new to Rust.
I am excited to see regex in error messages, once `a+wait` is a reserved word
If we implement the prefix keyword first. The macro can just be ‘do_await!’, ‘await_for!’ Or anything.
[removed]
caddadaaar
&gt; What I meant was I could implemented `my_special_await!()`. And you can do the same with postfix `f.await` as well. Only, you can do it on nightly *right now*. `macro_rules! wait_for_it { ($e:expr) =&gt; { $e.await } }`. &gt; So? It's only "fake" in that it's secretly a keyword, the point is that I could implement my own postfix await macro by another name. A true statement but a boring one. It's not a point I value. &gt; If I, an experience rust user, saw a rust codebase in a month that had "foo.await!()" I'd go "neat, rust has postfix macros". Only if we actually have postfix macros; `f.await!()` alone doesn't mean we do and there is some opposition to postfix macros in general within the language team. (Speaking only for myself, I am in favor of postfix macros) If we do not have postfix macros, then the user could make that assumption and would be wrong. &gt; If I saw "foo.await" I'd go "isn't await a keyword? how did they make a field with that? must be some kind of a future". As a teaching assistant, I never once heard any student ask why `.class` looks like a field or hear them mistake it for one. I think you assume a lot about users. In particular, I think newer programmers would have no such preconceptions. Moreover, beginner programmers that are introduced to Rust are, I think, probably more likely to use some form of IDE or at least a text editor with syntax highlighting. If that doesn't happen, they may be introduced to `f.await` through some teaching material. It is likely that it would be highlighted there. When the beginner sees `await` highlighted, it seems likely that they will understand that `f.await` is different. Another point about `.await` is that IDEs typically take advantage of `.` to offer auto completion; I think you could successfully highlight the different nature of `await` in such a completion popup. Finally, should the user try to search the standard library documentation for `await`, they would see something like https://doc.rust-lang.org/nightly/std/keyword.for.html in their search results. &gt; I have a mental model for macros already. I have no mental model for `.await`. This requires a new mental model for how rust code looks. You might, but macros are a fairly [advanced concept](https://doc.rust-lang.org/book/ch19-06-macros.html) in Rust. I don't think it's a stretch to say that we would teach `.await` much before that in the book. This means that the beginner would not yet have developed an intuition for macros but would rather have only seen `println!(..)`, `dbg!(..)`, and friends before. None of these are postfix macros so I don't think much knowledge carries over to `x.await!()` in terms of having fewer mental models to learn. Moreover, I think developing a mental model for `f.await` is rather a small price to pay as compared to understanding the semantics of async/await itself. It seems to me that this small price is smaller than the noise that `!()?` would contribute.
When you special case `. await ! ( )` this way in `libsyntax` then it is no longer semantically a macro. I think that's the same ideas as `. await` being a fake field. You have made the point that many users won't care about the distinction but I think an equal argument can be made for `.await` here. Having that out of the way, it seems to me that adding `!()` or not is a matter of preference. Personally, I think `f.await!()?` is unnecessarily noisy and that `f.await?` simply reads better. As for the general feature of postfix macros, I think they are well justified on their own and do not need `f.await!()` to back them up. In my view, a good case hasn't been made why `await` *specifically* should be a postfix macro.
[removed]
[removed]
`await` should be a postfix macro because postfix await syntax in general would be nice for chaining and because people associate macros with some sort of magic. The fact that macros are supposed to expand into something is more of an implementation detail. Compared to `.await` which people immediately associate with a field access.
See my note here: [https://www.reddit.com/r/rust/comments/bmhmtw/what\_postfix\_macro\_could\_bring\_to\_rust\_asyncawait/emz451k/](https://www.reddit.com/r/rust/comments/bmhmtw/what_postfix_macro_could_bring_to_rust_asyncawait/emz451k/)
[removed]
There are *17* cases of `await` being inside a chain, not 4.
Thanks for the suggesting :) I think i'll listen to you on that. What do you think about doing a crossbeam-channel for that?
Many people have moved away from IRC. A non-trivial number of people I've introduced to it left after discovering they didn't get messages while not logged in (yes, I know, bouncers, web clients, etc). It isn't \_quite\_ a generational thing, but for many people, the expectation is that they'll always be connected to their online communications. The thing that concerns me the most about Discord is their policy prohibiting third-party clients. If a hosted service provides a decent API and the tools to glue it into other platforms, then I think it is reasonable for the community to use those. But prohibiting that goes pretty far in the "lock you in" direction. Not to mention the horrific accessibility of Discord with respect to blind/low-vision people, or others who use assistive technology. One of my favorite things about the Rust community is the affirmative efforts to be welcoming and inclusive to people; I do not like losing that because of the misguided fear that people will leave your platform. Like we don't all have 900 different chat clients installed and running at this point anyway.
"final"?! This series of post is awesome and I honestly wish it never stops!
[removed]
parentheses... parentheses everywhere... :'(
Fair enough. I thought you were saying that it was always a legal grey area, or that the whole question was unsettled.
[removed]
This is exactly what I've [proposed](https://www.reddit.com/r/rust/comments/bmbph5/z/emvuxid). And while it got downvoted to Dante's lowest level, the more I think about it, the more I think it is way better than the current agenda.
... no? Actually it's better in Rust than Haskell. In Haskell this totally theoretical Monad would have to either special-case 'return' or else we'd have to have a future. In Rust, `let x = if foo { await bar } else { baz };` does not require a future for baz. But it looks like this may be another reason why await should be a function; it looks like you got that type of the expression `await bar` somehow has a `Future&lt;&gt;` in it, which is unlikely to happen with a functional `await()` with its normal function documentation documenting its non-`Future&lt;&gt;` return type.
[removed]
&gt;As a teaching assistant, I never once heard any student ask why `.class` looks like a field or hear them mistake it for one. I assume you're talking about Java here? `.class` is at least conceptually very similar to accessing a field; it's getting you a reference to some value that's immediately accessible from the one you started with. Whereas in Rust `.await` will mean something _radically different_ to accessing one value from another. So this seems like a pretty weak analogy. Now, if `.class` meant something more complex like "look up a class whose name matches the value of the preceding expression", then it might be more applicable to the arguments around `.await`. I don't actually have a horse in this overall race. I originally liked the idea of postfix macros to solve this problem, but I accept the arguments against it. I'll personally be happy enough if `.await` is stabilized exactly as it is today in nightly. What does worry me, though, is that a lot of people have completely valid concerns about `.await` (both here on Reddit and on GitHub comment threads), and I'm seeing a lot of dismissals of those concerns that don't actually address them head-on. I suspect that a lot of people would be happier if they could feel that their concerns are at least being acknowledged and understood for what they are, _even if_ `.await` is what gets stabilized.
Do you have more information on Vulkan subpasses? That sounds interesting :)
I personally think the postfix field vs macro argument really comes down to which would be best for the mental model of the user. In this regard, it seems the debate comes down to `.await` breaking the current rust mental model vs `.await!()` potentially being an exception if postfix macros are never added. I personally think `.await` is the much larger elephant in the room, and the question becomes whether I will every get used to the await field syntax, cause right now it is quite jarring and off putting.
&gt; You might, but macros are a fairly advanced concept in Rust. I don't think it's a stretch to say that we would teach .await much before that in the book. This means that the beginner would not yet have developed an intuition for macros but would rather have only seen println!(..), dbg!(..), and friends before. None of these are postfix macros so I don't think much knowledge carries over to x.await!() in terms of having fewer mental models to learn. I'm curious to hear other people's experience/intuition here. In my mind, the vast majority of people coming to Rust will have already experienced the idea of "free functions" and "methods" in one form or another. So when introducing `println!(...)`, we say something like "it's kinda like a function but not quite. don't worry; we'll get to that later". And that seems to go down pretty well. From there, I'd imagine if someone sees `"{}".println!(i)` they're most likely to think "oh, `println!(...)` is a macro that looks kinda like a free function, so `.println!(...)` is probably a macro that looks kinda like a method". I.e. there's a correspondence between functions and macros that lets you make informed guesses based on what you've already learned.
[removed]
This is my new favorite await syntax. Orthogonal, simple, easy to understand, perfect.
Thanks for sharing. I think your code looks pretty good, and is a great example of a minimal web server implementation. In the future if posting here looking for feedback, I'd recommend linking straight to your repo. &amp;#x200B; As for code quality feedback, I'd definitely recommend writing unit tests, starting with \`request.rs\`. You'll likely find that for testing you'll want to make the \`parse\` function generic over the \`Read\` trait.
Are there any conventions when writing a rust library with macros and static variables? I've just written my first rust library, but before I make it public I have a few questions about convention. The library allows the user to build up a tree progressively and pretty-print it at a later time. Example ------- ```rust add_branch!("1"); { add_branch!("1.1"); add_leaf!("1.1.1"); } add_leaf!("1.2"); assert_eq!("\ 1 ├╼ 1.1 │ └╼ 1.1.1 └╼ 1.2", flush_string()); ``` The goal is to make it easier to visualise nested / recursive functions instead of printing everything to output as a flat list. Once `add_branch(...)` moves out of scope, the tree jumps back to the previous level. In order to make it as easy as possible to integrate, my goal was to design it as a **drop-in replacement for `println!(...)`**. The `add_branch!(...)` and `add_leaf!(...)` macros add their elements to a **static thread-scoped variable**. I also have versions that aren't globalised that act on a state instance. Questions ------------- - Is there a convention that I should hide the globalised version in a module? - Should I avoid having the static variable option altogether and leave that for the user? Although I feel like this would remove the _works out-of-the-box_ advantage. - Should I (if it's even possible) hide macros in sub-modules, so the user has to opt-in?
[removed]
Is this a reference to Rust the game?
It's almost* as good as `caddr` and friends from Common Lisp. * I don't see how you could pronounce the `aa?await` variants, whereas [The Hyperspec](http://clhs.lisp.se/Body/f_car_c.htm) includes this helpful pronunciation guide: Pronunciation: cadr: ['ka,duhr] caddr: ['kaduh,duhr] or ['ka,dduhr] cdr: ['k,duhr] cddr: ['kduh,duhr] or ['kuh,dduhr]
[removed]
&gt; I assume you're talking about Java here? Yes; specifically [`.class` literals as defined by JLS 15.8.2](https://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.8.2). Two things are of note here: 1. It applies to a ~type-name, not a value. &gt; A class literal is an expression consisting of the name of a class, interface, array, or primitive type, or the pseudo-type void, followed by a '.' and the token class. So types have property accesses? 2. It can execute arbitrary code. &gt; A class literal evaluates to the Class object for the named type (or for void) as defined by the defining class loader (§12.2) of the class of the current instance. &gt; Whereas in Rust .await will mean something radically different to accessing one value from another. So this seems like a pretty weak analogy. Given the two points above, I disagree. In both cases, arbitrary code can be executed as a result. Moreover, the notion of a property access executing arbitrary code is not a novel concept; [Javascript has it](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/get) and [C# as well](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/using-properties). In both cases, the notion of a field access as a [*place* expression](https://doc.rust-lang.org/reference/expressions.html#place-expressions-and-value-expressions) is broken. Other than thinking of `.field` as a reference to a place, the notion of extracting a value out of a future is not that far off from a property access. &gt; I'm seeing a lot of dismissals of those concerns that don't actually address them head-on. I've think we've gone out of our way to be transparent and elaborate in addressing people's concerns. The concerns are just rehashed but it doesn't mean we haven't seen, considered, and talked about them. I can think of no other decision that has been so thoroughly debated, and to which so much time has been devoted, as what syntax we should use for `await`. This extends to the language team. We devoted several hours of in-person discussion for the `await` syntax at the Rust All Hands this year. &gt; I suspect that a lot of people would be happier if they could feel that their concerns are at least being acknowledged and understood for what they are, *even if* `.await` is what gets stabilized. I think we have acknowledged most of the concerns that have been raised; it does not mean however that we need to agree or evaluate the tradeoffs in the same way.
&gt; Moreover, I think developing a mental model for f.await is rather a small price to pay as compared to understanding the semantics of async/await itself. It seems to me that this small price is smaller than the noise that !()? would contribute. &gt; ...and I'm seeing a lot of dismissals of those concerns that don't actually address them head-on. I also prefer postfix-macro syntax, but I think /u/etareduce was very clear in his justification. The two of you just disagree over the cost/benefit of the `!()`.
&gt; I.e. there's a correspondence between functions and macros that lets you make informed guesses based on what you've already learned. I'm hoping to leverage this intuition later so that postfix macros can indeed happen since I think they would be useful. ;) Your point is well made. My point is primarily that teaching `.await` in a similar "don't worry" fashion will work as well especially when backed up by tooling (including colors) of various sorts.
[removed]
I really hope this is a joke, otherwise... Poor mankind...
[removed]
over a billion humans speak chinese, no reason why we can't pronounce it with a tonal language: await: /ə˥˩'wɛɪt˥˩/ a?wait: /ə˧˥'wɛɪt˥˩/ aa?wait: /ə˥˩ə˧˥'wɛɪt˥˩/ a?aa?wait: /ə˧˥ə˥˩ə˧˥'wɛɪt˥˩/
&gt; I personally think the postfix field vs macro argument really comes down to which would be best for the mental model of the user. That's quite fair. :) I personally value the way `.await` reads well together with `?` as I think this will be an exceedingly common case. I also recognize that people will want a more terse syntax over time and so `.await` works better in that regard. Mental models are of course *also* important. In the end, multiple factors are at play. &gt; In this regard, it seems the debate comes down to .await breaking the current rust mental model vs `.await!()` potentially being an exception if postfix macros are never added. If they both would be exceptions, I think both would be rather equally mental-model-breaking in this regard. However, we know that both could be generalized (`.match { .. }`, `.unwrap_or!(continue)`). Personally, I like `f.await` the best but would be fine with `f.await!()`, `f.await()`, or a sigil. My primary beef is with the non-composable non-expression-oriented prefix `await f` and in particular with the `await? f` construction. &gt; edit: This is where I wish there was more opportunity to experiment and see more real world examples, because right now I don't think anyone really has had a chance to try different things and see what grows on them. Small scale experimentation has been done with various real world examples, not just the recent repository floated about. As a clarification, I agree that experimentation is quite useful, but the place for that is on nightly, not stable.
I think you're right. Both are easy enough to learn, and we'll need to be mindful of how to teach either. I find `.await` wildly more surprising / less intuitive than `.await!()`, but I know this is highly subjective, and I'm not going to lose sleep over either. It's entirely possible I'm a little oversensitive to things being "explained away" with examples that I find unconvincing. :)
I agree — either will be easy enough to learn, and like \_anything else\_ we'll just need to be mindful of how we teach it. &amp;#x200B; Re postfix macros, ever since I saw examples of how they might be used, I've had a little smile in the back of my mind. If we eventually get those, too, it'll be a very happy day! :)
[removed]
&gt; I agree — either will be easy enough to learn, and like anything else we'll just need to be mindful of how we teach it. Certainly! Good progress is already being made on that front; our diagnostics guru Esteban Kuber has already made up some [plans](https://github.com/rust-lang/rust/issues/60613). &gt; [...], I've had a little smile in the back of my mind. Same! =P
[removed]
Thanks! I changed it a bit to make it more similar to what I have: [https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=3a8783529e172c665208f0b175ceff4b](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=3a8783529e172c665208f0b175ceff4b) &amp;#x200B; And it seems that using the raw entry API, I can call from\_key with a reference, but I can't call entry with a reference, and that's what forces me to do unnecesary duplication. Just curious, do you know why the reference works in one but not in the other?
I think you can do this without unsafe.
&gt; e.g. `this.that.dbg!().blargh` This makes me smile twice as much. :) The `dbg!(..)` macro is probably my most impactful invention and one that I'm most proud of and it isn't even a language nor is it complicated to define. =P I hope we can support this, but then postfix macros cannot evaluate their receiver expression.
[`Vec::set_len()`](https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html#method.set_len) is an `unsafe` function. Is there any other way?
&gt;It can execute arbitrary code [...] Oh dear. There's the root of my misunderstanding. I somehow never picked up on that in my time writing Java. I find that kind of construct really undesirable in Rust, which usually strives to make it super-obvious whenever you might incur some otherwise-unexpected run-time cost, but I suppose that's neither here nor there — more importantly, I was completely wrong about the relevance of your example because I was wrong about what it meant! &gt; I've think we've gone out of our way to be transparent and elaborate in addressing people's concerns. The concerns are just rehashed but it doesn't mean we haven't seen, considered, and talked about them. I can think of no other decision that has been so thoroughly debated, and to which so much time has been devoted, as what syntax we should use for await. This extends to the language team. We devoted several hours of in-person discussion for the await syntax at the Rust All Hands this year. Sorry, I didn't meant to imply that the language team et al. were being dismissive of people's concerns, and I can see how my original message is overly harsh. I really do appreciate the incredible amount of work that has gone into both the design of this feature, and all the community engagement that comes with that! I think my position boils down to this: I think the `.await` syntax is perfectly fine, but that it _is_ more "weird"/"surprising" than the syntax for most other Rust features, and probably requires more "pre-emptive teaching" to head off confusing as a result. What I mean here is that most other Rust syntax stands out even if you can't make sense of it yet. As a student, if I see a macro, I immediately recognise that I don't yet understand that syntax, and so there's something I need to read first to understand the feature. If I see a `match` expression, ditto. I can't think of any other examples where the "naive reading" of an expression allows for a _confident misunderstanding_ of what it means. Again, I don't think that's the end of the world, but I do think it will benefit from some careful pre-emptive teaching about the idea of `.keyword` to prevent confusion and frustration in learners when they stumble upon code containing this construct.
While I can't be sure, it looks safe to me as long as you don't use `clone_from_slice`.
I am not able to understand the meaning of 2nd point in `Safety` [documentation](https://doc.rust-lang.org/nightly/std/vec/struct.Vec.html#safety-1) which says **The elements at `old_len..new_len` must be initialized.** Do you know exactly what it means?
 Sadly I don't. I've thought of making one for one of my projects but never got around to it. Keep in mind you don't want this for a lot of cases since using "is" functions defeats the benefits of pattern-matching.
This is essentially what [tokio](https://tokio.rs/docs/going-deeper/tasks/#tk-docs-nav) is.
FWIW, this is just like how it works in Kotlin suspend fun example() -&gt; Unit? { val anotherFuture = async { httpClient.get("/foo") } doSomething() anotherFuture.await() } every `suspend fun` automatically `await`s, and must be called from within another `suspend fun` or closure. If you do not want to wait for it to finish, call `async()` on it, which does not have to be called within a `suspend` and returns a `Deferred&lt;T&gt;`. You call `Deferred&lt;T&gt;.await()` (which is a regular `suspend fun`) to join the job...
`println!("[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]");` More seriously: we need more context. How do you generate the values that go in the `Vec`? Why are you even using a `Vec` rather than a fixed-length array if speed is such a concern?
You should use something like [write_bytes](https://doc.rust-lang.org/std/ptr/fn.write_bytes.html) to initialize the buffer *before* calling set_len.
Are you iterating over a series of tasks and then aggregating the result? If so, [rayon](https://crates.io/crates/rayon) is the primary way to do this. In particular, their [parallel iterators](https://docs.rs/rayon/1.0.3/rayon/iter/index.html). If it's not, could you give a more high level description of what you're trying to do? You didn't give us much information besides doing arithmetic from multiple threads, and all I can suggest based on that is to make it single-threaded. If I had a better idea of why you're performing parallel operations, then I could give more specific and helpful suggestions.
You must have initialized those elements (e.g. using ptr::write, which is unsafe) before calling `set_len`. You're not going to get exactly what you want, because uninitialized values are never supposed to be exposed to safe code.
&gt; [...] impactful invention and one that I'm most proud of and it isn't even a language feature nor is it complicated to define. I think this says a lot about the success of Rust's design. I can't count the number of game-changing contributions that have not required special-purpose language features to implement, and/or have been possible to implement in external crates. &gt; I hope we can support this, but then postfix macros cannot evaluate their receiver expression. I don't catch your meaning.
&gt; I find that kind of construct really undesirable in Rust, which usually strives to make it super-obvious whenever you might incur some otherwise-unexpected run-time cost, [..] I agree; tho I care more about unexpected side-effects, not run-time costs per se as long as those run-time costs are pure computations. I come at this more from the Haskell POV of thinking that the [Separation of Church and State](https://mail.haskell.org/pipermail/haskell-cafe/2013-January/105703.html) is a good thing and that global mutable state is the root of all evil.. ;) ..rather than from the C/C++ perspective of making run-time costs explicit. &gt; more importantly, I was completely wrong about the relevance of your example because I was wrong about what it meant! &gt; I really do appreciate the incredible amount of work that has gone into both the design of this feature, and all the community engagement that comes with that! &lt;3 &gt; and probably requires more "pre-emptive teaching" to head off confusion as a result. Yeah probably. I do think we have thought of good mitigation strategies (diagnostics, highlighting, IDEs, etc.). Beyond that, I think we will want to focus on explaining how Rust's poll based futures model is different than in other languages. Another quite different aspect in Rust as compared to e.g. JavaScript is the lack of exceptions. &gt; I can't think of any other examples where the "naive reading" of an expression allows for a confident misunderstanding of what it means. I think perhaps I evaluate the risk for confident misunderstanding differently. Fields are typically *nouns* and not colored differently. If a user sees `my_future.await`, then I hope that they would wonder why a field is a *verb* and why it looks unlike other field accesses. &gt; [..], but I do think it will benefit from some careful pre-emptive teaching about the idea of `.keyword` to prevent confusion and frustration in learners when they stumble upon code containing this construct. One additional possibility here aside from the other mitigations I've already mentioned is that RLS (Rust Language Server) could offer a popup on hovering `await`. This would show information about the resulting computed type (natural for fields -- RLS already does this) but also display information about the concept of `await` itself.
&gt; I think this says a lot about the success of Rust's design. I can't count the number of game-changing contributions that have not required special-purpose language features to implement, and/or have been possible to implement in external crates. Oh yeah! Love this about Rust -- composable and modular language design giving users expressive power :tada: &gt; I don't catch your meaning. See [the Simple Postfix Macros proposal](https://github.com/joshtriplett/rfcs/blob/simple-postfix-macros/text/0000-simple-postfix-macros.md#reference-level-explanation). Specifically, it forces the evaluation of the receiver. As `dbg!` relies on being able to `stringify!(..)` the `expr`, the forcing mechanism would ruin things for `dbg!`.
`vec![0; 10]` -&gt; `Vec[0,0,0,0,0,0,0,0,0,0]`.
&gt; Having that out of the way, it seems to me that adding !() or not is a matter of preference. Personally, I think f.await!()? is unnecessarily noisy and that f.await? simply reads better. To me, it's not noise, but provides the important signal that this is more than just a cheap field access. It breaks my mental model of rust in a crucial way which I consider surprising for a language whose current focus is supposed to be maturity.
You could use HashMap's `get_mut`: match counts.get_mut(&amp;current) { Some(n) =&gt; *n += 1, None =&gt; { counts.insert(current.clone(), 1); }, }
The 'letting the compiler chastise me' option is what I find myself using most often. I wish there was an easier way to do this.
Ah, I hadn't seen that before, and that makes what I said above false. Just goes to show that unsafe code is hard :) Saying that it must be initialized means that you need to have already written values to the memory that will *become* part of the vector when you set the length. In other words, you need to set those elements of the vector before you call `set_len`. Given that, I'm not sure what the best way to write it would be.
&gt; A true statement but a boring one. It's not a point I value. Let's take a step back. *I also don't value that point*. What I was saying is that an argument against macros was that it couldn't be implemented by users - I was saying that it is both irrelevant *and* not true. We've established that, and we seem to agree, so let's move past it. &gt; Only if we actually have postfix macros; f.await!() alone doesn't mean we do and there is some opposition to postfix macros in general within the language team. (Speaking only for myself, I am in favor of postfix macros) If we do not have postfix macros, then the user could make that assumption and would be wrong. 100%. I am assuming that, like with postfix .match or postfix.if, that we're talking about these features in the long term, and what they might imply. I assume that postfix await macro implies generalized postfix macros. &gt; As a teaching assistant, I never once heard any student ask why .class looks like a field or hear them mistake it for one. Maybe not. I've taught Rust to a fair number of people from various backgrounds. &gt; I think you assume a lot about users. In particular, I think newer programmers would have no such preconceptions. Yes, I am assuming, as that is really all one can do here. A newer programmer from any other language will likely have used some kind of structure. They likely have accessed a field of a structure. This will be yet another departure from the common case for developers - something I think is worth consider, and why I think prefix await should also be implemented. &gt; are, I think, probably more likely to use some form of IDE or at least a text editor with syntax highlighting. An editor can highlight something to make it clearly different, and maybe act as a teaching tool, but I don't think it will make intent clear. So yeah it'll be clear that it's different, but not why - and a macro is just as easily highlighted (and is currently highlighted differently), but expresses intent in a more consistent way (with other macros, specifically - macros are already a real thing, postfix just means "macro but comes after", which is a very easy mental leap I believe). Same for autocomplete. Same for searching rust docs. And if implemented as an expandable macro you could even expand it in the IDE. &gt; You might, but macros are a fairly advanced concept in Rust. *Implementing* macros is an advanced concept. Macros are introduced in the very first chapter: https://doc.rust-lang.org/book/ch01-02-hello-world.html Why would postfix macros imply needing to learn how to implement postfix macros early? You just need to understand what it does, not how it works. In fact, I expect all async implementationy stuff to be much later. As for not seeing postfix before, I don't think it matters. The leap from `format!("{}", bar)` to `"{}".format!(bar)` is pretty trivial I think. The introduction to prefix macros seems like enough to make it a trivial transition. It looks like a method call, which you'll again have a similar model for from other languages with methods (implicit first 'self' param). &gt; Moreover, I think developing a mental model for f.await is rather a small price to pay as compared to understanding the semantics of async/await itself. It seems to me that this small price is smaller than the noise that !()? would contribute. Well we will probably have to agree to disagree there.
I thought tokio is specifically for io?
👋🏻 hi there, sorry to spam this thread, but do you have any ballpark estimate for when you’ll be able to get the recording up? was really looking forward to this meetup and was bummed to miss it. thank you.
I also thank you for writing this. It is very clearly articulated. Found myself in full agreement by the end.
Rolling to a new platform always leaves some users behind, and can even result in splitting the community (as it is doing now with the move away from irc)
```rust fn main() { let mut v: Vec&lt;u8&gt; = Vec::with_capacity(10); v.extend(&amp;[0; 5]); v.extend(&amp;[1; 5]); println!("{:?}", v); } ```
Is `resize` that much slower? I'd expect it to out perform copy\_from\_slice, and it's not unsafe. If you want to get fancy with your values, there's `resize_with`.
People can absolutely use code under GPLv3, and there's nothing wrong with using a copyleft license in the Rust ecosystem.
&gt;Given the two points above, I disagree. In both cases, arbitrary code can be executed as a result. This feels like a perfect example of no one ever likely guessing that this is the case, and assuming it was just some sort of special field.
I like this, but I think it should be the second 'a' in the word. awaaait?? foo.bar().baz()
Technically you are right. End users will still be able to use it. But including org-rs package into another library/app means that it also has to be GPL. A lot of people are afraid of GPL, and a lot more people are just lazy. Nobody will re-license just to import some parser. It means that my crate will be locked in GPL ecosystem. I'm pretty sure that Stallman and Co are celebrating. I am optimizing for getting shit done. But for me GPL means that very few people will be able to pick up my work and carry on with popularizing Org. And I will die of age before I can write everything myself. Here is some proof: In a day I got 300 stars on github. 500 in a week. Guess how many contributions I got? 1 typo fix, 1 code of conduct, and GPL headers (comments) 0 LOC in a month. To me it feels like nobody wants to waste their time writing GPL code. But nobody minds using it.
This is rather nice!
Please correct me if wrong, but in the case of e.g. Github you'd lose quite some "meta" data like issues etc. Unless there is an export functionality that I've missed.
In the case of discord another problem is also the usability for people that rely on a screen-reader. &amp;#x200B; Given that discord sees itself primarily as a tool for gamers, I guess the priority of supporting screen-readers will always be very low. (I may very well be wrong here though and the focus might shift any moment of course)
I wrote down how, but I believe I found your issue: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=92c865dcea534af9aff89db342783d17. It's not that the output changes from `cargo build` to `cargo run`, or that it's different on your computer than on the Playground, right? The constant just gets shown as unused if you don't make an instance of the struct. In that case, it's just the compiler being anxious to help.
&gt; A lot of people are afraid of GPL Or the smaller number of people who are make a lot of noise. &gt; In a day I got 300 stars on github. 500 in a week. Guess how many contributions I got? I don't think that depends on the license. That sounds rather normal for a project that gets widely promoted: you get a lot of people dropping by and starring, but few of those people will stick around for non-trivial contributions. People who love org mode really love org mode, and will want tools to work with it. People who don't aren't likely to contribute. The license doesn't change that. You're not going to be able to relicense code that you wrote based on the implementation in Emacs. And that's OK. If you haven't already, you might consider showing your project to other folks who seem more likely to contribute, such as the remacs community, or the emacs community.
I propose that we change `await` to `wait_for_iiiiiiit`, because then it makes no sense *unless* it's postfix, and we can all finally agree.
It hink you need this: )
This comment might sway me on the issue of postfix macros.
There are 17 uses of chained await, but only four of them have two `await`s in the same expression, and none have three or more. I claim that this proves that more than two chained `await`s in the same expression are very rare, unlike chained function calls, which often spread much more than this. So this is -- somewhat weak, admittedly -- argument against the idea that "chaining is popular in Rust, and await will be popular, so people will chain awaits just like functions". I dislike this solution it a lot -- not only the syntax itself, but also the process of adding new syntax to the language tailored for such a narrow use case (I remain unconvinced about the need for other postfix keywords like `match`). In my opinion it's worth of an RFC just for the syntax itself, (though I suppose that's what the Dropbox paper was supposed to be). Right now, what's happening seems to be: - postfix `await` is nice because it solves chaining and postfix keywords might be a good idea - (some time later) we have postfix `await`, let's make every keyword work that way - except that there will never be a prefix `await` To me it looks like this is a Trojan horse for the postfix keywords. Other than that, I actually tend to agree with the feelings expressed in /u/JMurph2015's post. But I know how much you like postfix `await`, so this is a bridge we're not going to gap.
&gt; There are 17 uses of chained await, but only four of them have two awaits in the same expression, and none have three or more. Actually, I counted wrong; there are 20 cases out of 43 (46.5%) where `await $(?)*` is followed by `.`. &gt; I claim that this proves that more than two chained awaits in the same expression are very rare, unlike chained function calls, which often spread much more than this. This is a straw-man argument. We never made the claim that `.await` occuring multiple times in a chain was going to be likely. We made the claim that `.await` followed by method calls or field accesses was going to be likely. I believe the example supports our claim. The fact that `.await` happened twice in the same chain 4 times is frankly a surprise to me, I thought it would be rarer than that. &gt; To me it looks like this is a Trojan horse for the postfix keywords. This is emphatically not the case. The thought of `expr.match { .. }` had not even occurred to me before quite late into the discussions about postfix syntaxes. The `expr.await` syntax stands on its own merits and I would select this syntax irrespective of whether we add other `expr.keyword ..` forms later. Moreover, it is not something that is on the roadmap for 2019 and I think `.await` should bake on stable for some time before we consider `expr.match { .. }` and friends.
&gt; How does that look? It looks like it won't compile. Why does `Future` suddenly have a `map_ok` method?
Be careful, it could be a prefix for ...dary “Legen... wait ... for ... it ...dary”
The subreddit for the game Rust is r/playrust btw
Oh I didn't know about these points. Thanks !
My thoughts exactly. This way just makes the steps involved much more clear.
`futures::prelude::TryFutureExt::map_ok()` `TryFutureExt` is blanket-impled on all `TryFuture`s and `TryFuture` is blanket-impled on all `Future`s whose `Output` is a `Result`. You just need to `use futures::prelude::*;`
What's the data portability story with Discord? If one moves out, does one lose all the conversations ever recorded there, including ones currently in progress?
Rust guaranties backward compatibility, not forward.
Feel free to use `let testing: u32 = testing.parse().unwrap_or(0);` if you'd prefer to provide a default value. If you check out https://doc.rust-lang.org/std/result/ there's some useful methods in there such as `unwrap_or_else` where you can call a function in the case that unwrapping fails, or `.ok()` where you can turn the error into an `Option::None`. Glad you're enjoying the answers from those before me :)
What about failure's `context`? Basically, I don't like a solution that requires every possible method on some `Result` to be wrapped for `Future&lt;Result&lt;...&gt;&gt;`. I also don't like having to name the methods that I map over with a qualified name. Seems overly verbose.
Sure, but it wouldn't be a big enough change to justify the hassle.
&gt; In the case of discord another problem - unrelated to the FOSS issue - is the usability for people that rely on a screen-reader. I had an interaction last week with our community member for whom this is actually an issue and the usability is "meh, but it works, better then slack". https://twitter.com/camlorn38/status/1124737453011550208 Please also note that we also have braille line users in out community, which is a whole different thing WRT to accessibility. &gt; Given that discord sees itself primarily as a tool for gamers, I guess the priority of supporting screen-readers will always be very low. (I may very well be wrong here though and the focus might shift any moment of course) Discord does communicate that they are working on this issue, but with a low priority, sadly. https://www.reddit.com/r/discordapp/comments/7gb474/discord_accessibility_for_the_blind/dqijf2k/ Sadly, the sorry state of this world is that I don't know of a project that makes accessibility front and center, it's mainly scheduled as "if we have time for it" and that usually holds "until the next frontend rework". To give appropriate credit, Zulip cares more. Also, one of the ideas behind giving WGs open choice of tools is that they _can_ move to other places to accommodate all peoples needs.
Wow, never noticed that before. That's pretty bad. That really should be the first thing stated on the main page.
One of the problems with this is, that when Rust thinks a value is initialized, it will try to Drop the old value when you assign a new value. But the old value is not actually valid but uninitialized. The problem is described in more detail in the nomicon ([https://doc.rust-lang.org/nomicon/unchecked-uninit.html](https://doc.rust-lang.org/nomicon/unchecked-uninit.html)). &amp;#x200B; This may not be a problem for Copy types though, I am not sure.
**Don't get your hopes up, the decision will not take this poll into account!** &amp;#x200B; The language design of Rust features are not now, nor ever, determined by popular vote. **This is not an official poll**. I have no idea why you keep posting it. I'd rather have a language designed by the Rust Lang team carefully considering alternatives based on technical merits. &amp;#x200B; There's already been an overwhelming influx of low quality (albeit passionate) posts on the internals forum on this topic. Lot's of I-hate-this-or-that with not much more than personal feelings as arguments.
I believe the issue with combinators lies with the lifetime requirements it puts on the futures that are handled better with `async-await`, but I'm a bit fuzzy on the details.
We consider chats volatile. Everything of importance must end up in some document (RFC, GH issues, patch, etc.)
I don't see why not
Almost everything can be exported in GitHub through their API. The problem is mainly that not everyone has an account on your target platform, so it can't be recreated.
Yep, but so does almost every change in management/tooling of a project.
K. Going to make your moderation story harder: evidence of past bad behavior becomes out-of-scope.
Well, yeah, but thats not really what "lock-in" means and applies to any service, FOSS or not.
`TryFuture` mostly exists for futures 0.1 compatibility. otherwise, it would be variations of `FutureExt::map`. Technically I didn't need the `map_err` and only included it because of `?`'s secondary effect. If you weren't using that effect than it should have just been `bar(res).await!()` or `await bar(res)`. You shouldn't have to use the qualified name. You just need to import the trait and all the methods become available to any applicable future. All the relevant traits are in the prelude so a bulk import will give you pretty much all the combinators available. There's also nothing preventing someone for making an extension trait for futures of failure's `context`. One of the great things about rust is the ability to add methods to types from other crates using traits. It's how future's `{Try{Future, Stream}, Sink, Async{Read, Write}}Ext` traits all work. Actually, after checking `failure`, are you sure it needs anything special? It looks like it just provides a trait and types for the error, but still uses the standard `Result` type. If you want to access the methods it provides for `Result` through `ResultExt`, then you'd just use a normal `FutureExt::map` (accessible as `fut.map()`).
Nah, such evidence gets recorded when it happens.
If you installed rustc/cargo via apt, then you will need to remove them via apt, though you *can* leave both the system and the rustup toolchains installed simultaneously providing rustup's is in the PATH first. When you install rustup, it tells you that you either need to `source .cargo/env` or if you've asked it to, it may have modified your shell's startup files to do similarly for you. If that's not working, please could you file an issue at https://github.com/rust-lang/rustup.rs showing the exact reproduction method including OS version, platform, etc.
I don't think that's going to be a problem? Unless the enum tag could fit in the padding, the enum is always going to need to be padded to the size of its largest member.
Tokio is more or less an implementation of green threads. It would handle the mechanics of checking task values and running chuncks of code asynchronously.
Has anyone considered a prefix form such as this: ```let more_complex = await future()?.another_future().do_something(); ``` That is, a prefix operator that causes any async function result inside the expression to be awaited. It would cover 99% of the use cases, and anyone writing complex async code could still just split the expression so it works the way they want.
So let's say my sync error handling looks like this: something().context("Trying to establish connection")?; The `context()` call wraps the error value with additional information that I can then use in error reporting. It's an extension method on `Result`. What I want my async code to look like is this: something_async().await.context("Trying to establish connection")?; or the equivalent with some other nice syntax. What I don't want is the "where do these parentheses go" effect: (await something_async()).context("Trying to establish connection")?; and what I most definitely don't want (but what you appear to be suggesting) is this: await? something_async().map(|r| r.context("Trying to establish connection")); or for failure's `compat` method (which is for compatibility with the `std::Error` trait): await? something_async().map(failure::ResultExt::compat); because suddenly I need a syntactically heavy lambda, or a function reference that requires me to care what trait the extension method comes from. Or alternatively, to create wrappers for every method that I want to call on something that is wrapped in a future.
Please don't copy `extern "rust-call"` - we've been trying to come up with a non-hacky way to enable it *since before* the hack was ever considered. IMO a better hack would've been a perma-unstable attribute. The correct solution for that, "variadic generics", is just type-level sugar for expanding tuples into multiple arguments. An `.await()` method call has to expand to the *control-flow* of a poll loop, which is so far from ABI, I can't in good faith accept such a hack. Signed, a compiler team member. (apologies for not replying earlier)
Defining a generic Iterator-method "copy\_into\_slice(slice)" the primitive byte-arrays can be chained (concat) and written static byte-buffer, without any dynamic memory allocation involved. If the number of iterator elements is exceeding capacity of the destination buffer (slice) the method will return Error. /// Error kind #[derive(Debug, Copy, Clone)] enum Error { /// Number of elements exceeding capacity of slice EndOfSlice } /// Trait CopyIntoSlice copying all iterator-items into slice and return length, returns Error if slice exceeded trait CopyIntoSlice&lt;'t, It: 't&gt;: Iterator&lt;Item=&amp;'t It&gt; { /// Copying all iterator-items into slice and return length, otherwise Error if exceeding fn copy_into_slice(self, slice: &amp;mut [It]) -&gt; Result&lt;usize, Error&gt; where It: Clone, Self: Sized, { let slice_len = slice.len(); let mut nwritten = 0; for (idx, item) in self.enumerate() { if idx &lt; slice_len { slice[idx] = item.clone(); nwritten += 1; } else { return Err(Error::EndOfSlice); } } Ok(nwritten) } } /// Implementing the trait CopyIntoSlice impl&lt;'t, It: 't, I: Iterator&lt;Item=&amp;'t It&gt; &gt; CopyIntoSlice&lt;'t, It&gt; for I {} This trait CopyIntoSlice permits to write idiomatic Rust code, chaining the primitive byte-arrays and copying directly into the slice, and dealing with error cases, such as: let req_method_get = b"GET "; let req_method_head = b"HEAD "; let uri = b"/infotext.html HTTP/1.1"; let mut request = [0 as u8; 128]; // chaining both iterators and copying bytewise into the buffer match req_method_get.iter() .chain(uri.iter()) .copy_into_slice(request.as_mut()) { Ok(nwritten) =&gt; println!("{:?}", std::str::from_utf8(&amp;request[0..nwritten])), Err(kind) =&gt; panic!(), }; Maybe this trait will become a feature of crate itertools [https://github.com/bluss/rust-itertools/pull/344](https://github.com/bluss/rust-itertools/pull/344)
And you need /r/playrust.
So... essentially a Kotlin-like `suspend` keyword? Doing so would make `await` unnecessary to begin with. import kotlinx.coroutines.runBlocking suspend fun doStuff(f: suspend () -&gt; Int): Int { return f() + f() } fun main() { runBlocking { println(doStuff { 2 }) } } Which could be represented as such in Rust (pseudo-code): extern "await-call" fn do_stuff(f: extern "await-call" fn() -&gt; i32) -&gt; i32 { f() + f() } fn main() { tokio::run(|| println!("{}", do_stuff(|| 2))); } And of course, Kotlin coroutines library does actually provide `await`, although the use for this is to convert Java 8 futures into Kotlin suspend functions, similarly to how it could be used to convert futures 0.1 futures into `extern "await-call"` futures.
and some of us will never install Node , its outright insult of our talents to ask that
That’s a bit weird. Your library mostly is a frontend to lyon, but you duplicate some functionality, like the conversion from arcs to bezier curves. You also don’t appear to solve the folding issue of skeletal strokes that lyon has. The dashing code seems nice, though. In general, having no documentation is really problematic for code like this. I wouldn’t use it in its current state, even though it has some nice parts.
Weird flex but ok
you new kids need to talk with some people with 20 years experience and ask them about Spaghetti coding and why not to do that; And Actually in rust+wasm it will be a even greater mess with it.
Thanks for dropping by :-). Wrt. the post history, you probably know, but the posts can still be found if someone knows your old username (it's not even much effort). I don't expect anything more than pseudo-nimity from Reddit. I try not to write things I wouldn't say in real life, but posting habits and other account metadata can't really be hidden. I can very much relate to your point about spending too much time here or on social media. For me it's probably even worse, since it's just easier to read here about awesome things people are working on, instead of doing something myself (except maybe random PRs to beginner projects). That's not fundamentally different from sitting on a couch and watching TV. --- Sorry for the personal tangent, I doubt /r/rust is the right place to be talking about this :-). I think you took the right decision. --- &gt; I think it would be great if there was a maintained set of minimal unsafe bindings to luajit and PUC-Rio Lua, but from my experience with people using it, for it to be maximally useful it would need to cover all of LuaJIT and PUC-Rio Lua 5.1, 5.2, 5.3, and soon probably 5.4. Maybe that means that there should be 4 or 5 separate sys crates? I'm not totally sure. I've never used Lua and I don't know its backwards compatibility story. Using crate features might be a solution for this, but it's bit of a hack; the other approach I can think of is putting out multiple versions of the crate, in lockstep with the Lua releases.
* obligatory mention of arbitrary logic in getters of other languages * But yeah, in rust it's established that field access is only (at most) a pointer addition.
I still don't understand what the issue is with just using a macro/function call style: await!(something)? is pretty clear on what it does. It does break changing, but so does any other function that doesn't support chaining.
Interesting, but as stated by /u/anlumo, I wouldn’t use it because [of this](https://docs.rs/raqote/0.1.1/raqote). As an engineer, I highly value and even sometimes fight people who think comments and documentations are not worth it. A piece of software without documention is: - Hostile. - Hard to understand what does what, even with a nice or superbe type system. - Overwhelming when you are a newcomer and bothering when you get back to old code after several weeks / months. I highly highly suggest you to document **every** symbols in your public API and put examples. Yes, **every symbols**.
Field access can also run `Deref` implementations, although by convention those should be minimal. But like most uses of `await`, in Rust the OP's example would require `.await?` rather than just plain `.await`, which (a) implies control flow [albeit of a different kind] and (b) looks different from a field access, since it's very unusual to apply `?` to a field. So I doubt it would be common to actually confuse it for a field access, as opposed to just thinking it looks weird.
Good point, i didn't think about that
That's very interesting! I've seen Kotlin mentioned a couple of times and knew it has "implicit await" but for some reason it seemed more complicated to me than it does now. In fact, I'd say it's a rather elegant solution. And now it's obvious that `async {...}` and the OP's `defer {}` are actually the same thing. The only argument that has been brought up against implicit await is that suspension points are kind of invisible in async functions. But I'm not convinced anymore that that's a bad thing.
Perfection.
I hadn't even considered this. I find myself liking the idea, using `async` in the method already implies the magical async transformation, automatically awaiting where necessary seems like a very nice ergonomic feature, especially since awaiting futures seems like the most common thing to do. Adding an escape hatch in the form of defer (hell, why not use the keyword async to avoid another keyword) for those cases seems really neat.
It was used by [https://github.com/rust-lang-nursery/futures-rs/pull/1583](https://github.com/rust-lang-nursery/futures-rs/pull/1583), [https://github.com/rustasync/runtime/pull/26](https://github.com/rustasync/runtime/pull/26), etc.
I think articles like this often miss the forest for the trees. Companies do have a tendency to prioritize proprietary tech over open, if they think they can profit of it, but others have made the opposite decision as well in the past and continue to do so now. But the actual users, the ones who actually choose what software to *use*? Outside of us tech nerds, no one picks a piece of software because of its ideological purity. They pick it because it works. Because it's designed well. Because it makes their job easier. And quite often, the open source option just ... doesn't do that. Indeed, there's a strong tendency in open source communities to de-prioritize and even sneer at UI/UX and design as even a concern, and this does not lead to pleasant software to use. There are exceptions of course, but even software supposedly made *for* designers can feel painful and outdated, and the average non-techie just does not have the patience for that and never will no matter how much we yell at them about "freedom". This has been a problem for as long as I've been following open source (which I depressingly realize can now be measured in decades), and it seems to show no signs of changing, because even in these debates about the "future of FOSS" it's just not even under consideration. We've learned to put up with it, or else left the scene a long time ago, so it stops being something we even realize might be a barrier. I would love to see more open standards. I would love to see more free software. I would love to see less exploitation in the open source world. But as long as we're only making them for other nerds, they're always going to be on the back foot.
I don't know any, but I can try to guide you through some exercises! Just let me know if you would like me to come up with some interesting exercises and solutions for you!
Maybe try https://github.com/rust-lang/rustlings.
rustc
Reading your writeup (which is, in itself, clear and coherent enough, no quibbles there) reminded me why engaging in this kind of discussion is so exhausting, especially for someone who'd encounter these arguments repeatedly. Before explaining further, I'll try to summarize your point of view as I see it, just to be explicit about the context of my criticism: ergonomic improvements of `future.await` are insufficient against the familiarity and expected usage of the prefix syntax. Close enough? If so, let me start by noticing that this is not a _new_ argument. That's fine; a convincing restatement of a familiar argument can be valuable. However, two points in your writeup made me seriously question the strength of any conclusions you may have made. First, you said: &gt; Until recently, it was assumed that we would use the familiar prefix-based syntax found in many other languages What are you basing this on? This was so contrary to my recollection that I went back to early RFCs and issues and checked. So, in the RFC issue, opened on 06-Apr-18: 1. [The RFC itself](https://github.com/rust-lang/rfcs/blob/master/text/2394-async_await.md) says that the `await` syntax is undecided, and offers several prefix syntaxes, with pros and cons. 2. [An early comment](https://github.com/rust-lang/rfcs/pull/2394#discussion_r179909812) (07-Apr-18) prposes `future.await`. 3. [A comment from @withoutboats](https://github.com/rust-lang/rfcs/pull/2394#issuecomment-379704976) (09-Apr-18, see the end) accepts the postfix syntax as a serious alternative. So, three days after publication, postfix `await` was firmly on the table. Discerning the lang team's preference for a particular syntax is somewhat more difficult, but (skimming the threads again) I don't believe that there was ever a firm majority preference for prefix syntax, just acknowledgment that the prefix `await!()` macro is a temporary solution, and, a bit later, that any solution would have to contain the keyword `await`. Therefore, I don't believe that "it was assumed..." is supported by the record, and using it to give weight to the argument that prefix should be preferred is unwarranted. Second, further on you have: &gt; [...] I believe people are overestimating how frequently people bubble errors straight up without any transformation steps. ... Followed by an example with `if let`. I understand that any hypothetical syntax discussions must be abstract to a degree, but in this case we're fortunate to have real source written with `await` from the start. [Here it is](https://github.com/inejge/await-syntax/blob/postfix-field/bin/wlan/wlantool/src/main.rs), in the postfix variant. There are four instances of `if let`/`while let` plus `await`, compared to fifteen places with `await?`. Is that a lot? Or not so significant? Is the sample code representative? It could be argued this way or that, but I have an impression that you didn't try to find out at all. The repository with that code has been referenced here on Reddit and on IRLO quite a lot, so I'd expect that an interested observer would've noticed it. So, I don't think that the scenario you've presented has been sufficiently researched. And here is the core of my complaint: if your argument leaves the impression that you haven't done your homework before presenting it, it's not difficult to dismiss it, clarity, coherence and strength of feeling notwithstanding. I feel that this has happened a lot in the discussions around `await`, but I'm not going to analyze every single post; I can easily imagine the effort involved, though. As an aside, if you're using [rust-lang Vim support](https://github.com/rust-lang/rust.vim), a quick-and-dirty hack to have `await` highlighted like a macro is to apply the following to `~/.vim/syntax/rust.vim`: --- rust.vim.orig +++ rust.vim @@ -134,6 +134,7 @@ syn match rustMacro '\w\(\w\)*!' contains=rustAssert,rustPanic syn match rustMacro '#\w\(\w\)*' contains=rustAssert,rustPanic +syn match rustMacro 'await' syn match rustEscapeError display contained /\\./ syn match rustEscape display contained /\\\([nrt0\\'"]\|x\x\{2}\)/ Give it a try, it accentuates `await` quite nicely.
Well, if you put them here we might be able to convince the mods to put them in a wiki or the sidebar?
That's infix, though. Maybe we *should* use infix notation! fn fetch_data_from wait_for_it the_server() {}
Why not run it in miri? It's on the playground under Tools -&gt; Miri. Since is no control flow in your program, I think it would spot any undefined behavior.
\[Practise questions\]([https://github.com/sn99/rust-practise-questions](https://github.com/sn99/rust-practise-questions)) though some chapters are yet to be completed
While it does use lyon\_geom for a few things like path flattening I wouldn't call it a frontend to lyon. The most important part of this crate, in my opinion, is the software rasterizer, which lyon doesn't provide. Personally I'm glad to see a simple implementation of a software path rasterizer in pure rust if only for educational purposes.
Read [Rust Standard Library](https://doc.rust-lang.org/std/#the-rust-standard-library) and practice some examples in there.
Why does people downvote this? I think it is a useful tool.
I think that might also be beneficial. It doesn't strike my own personal taste though -- I guess I always make my own projects, or synthesize my own learn path. I remember when Zed started with these, I feel the original idea was -- get to code as early as possible. &amp;#x200B; While I agree about the approach, I believe a "learnyou" or a "[\_why](https://en.wikipedia.org/wiki/Why_the_lucky_stiff)" kind of thing, makes a story, and bakes in the "personality" of a project; it showcases the principles and values the "hardway" can't teach you. For example, the whole \_why experience was eclectic for me. I thought me that in Ruby, it's \_OK to be different\_, and it's OK to demand \_more\_ from my developer experience -- to expect more and to raise the bar for myself. It thought me Ruby is \_playful\_ and \_inviting\_. &amp;#x200B; So Ruby is * Encouraging different views * Tries to raise the bar for developer happiness * Playful and inviting It's not a coincidence that every project of mine, years later tries to exhibit these principles. I think just by reading these, I want to go and create something new. &amp;#x200B; I got all that from \_why.
Benefits, limitations, benchmarks, alternatives?
- There is `Rust by Example` - Also there is Awesome Rust List, you may find what you look for there. - You can simply practice solving tasks from something like `Project Euler` or `Advent of Code` (and compare your solutions with the ones of /u/BurntSushi for the latter) - You can try implementing something classical from `Rosetta Code` and comparing your solutions with the one listed there. No links, but everything mentioned is trivial to find. Hope it helps :)
I don't mind the concept of postfix `await`. What I mind is that we think it should be a feature bundled with `await` instead of a feature on its own. People have been annoyed with nesting `match` statements for a long time, and it's the exact same issue here. Why not solve it globally instead of shipping some frankenfeature that looks like no other just for the sake of preemptively solving a problem that will still exist everywhere else? We should make `await` look the same as the rest of the language, first and foremost. And *then* we ask ourselves how we can design a feature that allows us to use some keywords with postfix notation, in a *consistent* way across all the language. My personal favorite for that would be to implement postfix macros, because macros always carry the "magic happens here" connotation, and magic is indeed happening here.
The whole reasoning about the syntax to use is completely backwards, if you ask me. We shouldn't ask ourselves if we can preemptively make the `await` feature easier to use. We should implement it in a way that is consistent with the rest of the language first. *Then*, we can notice that the issues with prefix notation aren't exclusive to `await`, but present for a bunch of other keywords (prominently `match`). And that's our cue to start implementing a feature that would allow arbitrary postfix notation for any other keyword where it makes sense. A good way to do that would be to implement postfix macros (really, it seems like the perfect use-case for those). They would desugar to the prefix notations, and are very conspicuous, as are other macros, in telling you that there's magic happening here.
I just wish we went with a prefix syntax that can be sugared up into a postfix macro. That way the feature itself is consistent, and we end up with postfix macros which can also solve the nesting issues of match statements and whatever else we can come up with. The whole reasoning that led to the current adopted syntax looks backwards to me.
You’re right, of course, but maybe since there hasn’t even been a single release yet and the first commit was only 20 days ago we should cut the author a little slack.
Have you done extensive programming using C#-style await syntax? It's a bit of a pain having to wrap stuff in parens or assign it to a new variable all the time. Personally I think the postfix syntax could be a significant ergonomic win when writing async code. I can't be sure until I've written a load of code using it, though. That's one of the hard parts.
Cool. I like the `fui` implementation for `ffsend` :)
You can give a try on Exercism, [https://exercism.io/tracks/rust](https://exercism.io/tracks/rust). The mentor will give you advice about your code.
Was it considered to make futures behave inside async contexts (blocks and functions) like smart pointers that are awaited on deref?
I like this idea a lot, but wouldn't it make async code look and behave differently depending on whether it's in an async function or not? For instance, if you copy `http.get(uri).body()` from an async function to a non async one, it won't compile for no clear reason, because the `get` method returns a future in normal functions. At least the `await` keyword marks the async behavior more clearly, and allows for better error messages (ie. "await can only be used in an async function" instead of "std::future::Future&lt;http:: Response&gt; has no method body() - hint: try adding async to the function where the method is called"). But Kotlin seems to have a nice middle ground, where futures are always awaited in async (suspendable) functions, and async functions can only be called by other async functions, and you can only begin async execution from a synchronous call site with a specific keyword that starts a new async block (a closure, in reality). This avoids surprising behavior, and still allows you to defer work in an async function with an async block.
As i wrote in the post, i'm not a fan of exercism, because of most of the challenges being based around implementation of an algorithm, and not necessarily learning the language.
The difficult part is that I have no idea of your level. An interesting simple exercises is to implement a concurrent queue used in a produce consumer patter. One thread produce random integers (i32, is important that is a simple type) and another thread print those to screen. The structure in the middle must be something like an array, vector or list. Just don't overdoit because this kind of problem can explode in complexity as much as you like. After that you can move to a queue of some more complex type...
The awesome rust list seems great for inspiration!
In general, Rust prefers things to be explicit and precise, and tries to avoid "doing its best" to prevent errors. Errors are a good thing in Rust, because they are low cost, and allows *you* to decide what to do. You could choose to replicate C behavior, or do something else. C doesn't give you a choice in this example.
I heard that in Shawn Spencer's voice...
This course from Penn has links to slides and exercises https://cis198-2016s.github.io/schedule/
I know it, I just wanted to make it clear why this question may be a legit one. At least, when I've started to learn Rust a year ago, in the guessing game example, I've immediately thought about this particular thing, so I think I kinda understand why OP asked this.
And note that `any()` returns bool, too. I think the usefulness of `bool` is clearly underestimated by this blog post. There are many situations where bool is better than an enum.
It's probably just because it's new but amethyst uses gfx-rs in the background and that crate works with OpenGL and *Vulkan*. So in theory 3D games are doable. I'm currently investigating making a 3D game with Amethyst. So far things are going well enough but I only just got started yesterday. Up next on my plate is trying to get it to load and display 3D assets and *animate* them (walk cycles). That might be too much though at this point in Amethyst's development.
Finally, the ultimate solution to chain byte-arrays to form a single iterator and unrolling this one into a byte-buffer, covering also checks for completeness. &amp;#x200B; &gt;"Progress is the way from the primitive via the complicated towards the simple." \[Wernher von Braun\] let req_method_get = b"GET "; let req_method_head = b"HEAD "; let uri = b"/infotext.html HTTP/1.1"; let mut request = [0 as u8; 128]; // chaining various byte-arrays together, for example two here: let mut chained_byte_sequence = req_method_get.iter() .chain(uri.iter()); // take a ref and zip against the destination buffer and while iterating via fold, each // element is counted. let nwritten = chained_byte_sequence .by_ref() .zip(request.as_mut()) .fold(0, |cnt, (item, slot) | { *slot = item.clone(); cnt+1 }); // finally, the iterator of the chained_byte_sequence must be empty if chained_byte_sequence.next()!=None { /* slice too short */ panic!(); } else { println!("{:?}", &amp;request[0..nwritten].as_ref()); };
This is a pretty good idea. The double duty for the `async` keyword is a nice symmetry.
It's a cool concept, but how do you enforce it?
While the syntax chosen wasn't my favorite, I'm glad *something* was finally chosen and we can move forward. Honestly syntax doesn't matter to me nearly that much, as long as it works well enough. That being said, when working on my *own* language I do pour hours into carefully crafting syntax design, only to encounter edge cases later where you have to make a tough call in the face of tradeoffs. So I respect the Rust Lang team in this decision for doing the same, regardless of whether they came to the same conclusion I did or not.
Is it possible to pass parameters to choose the syntax?
It's well-known that the Internet is infallible and that `https://endpoint.url` will always respond with a 200 status code, and that the page will always be JSON. Where do you put error handling in that single statement?
That would depend entirely on what a court thought of the 'inspiration.' All I can suggest there is to have a copyright lawyer look it over. I am not a lawyer and cannot offer legal advice. My response was wholly predicated on your original implication that you were drawing from the linked license chart and pointing out that it did not say what you seemed to be taking it to mean.
i still havent the .await syntax. it feels strange
This looks really promising! Thank you for that
I see, my bad. I think i failed to interpret this part of your comment correctly: &gt; I'm not saying that this is better, than Rust's approach, because it's not I should have handled my errors better. 😉
Lock in isn't as much of a problem when you can just self host your own instance when you're no longer happy with the company behind the service.
really appreciate your attempts to explain but I've yet to read the rust book section for this. I'll give this a go before peppering you with questions to which the answer is currently RTFM! thanks for taking the time to answer all my questions though!.
English isn't my first language, so maybe I did mess up with the sentence structure
I'll definitely give it a try when the new version comes out!
Congrats on your first project! It’s always exciting! I will have a look at it when I get back from work tonight, I’m curious!
Yeah, I’m not so sure about the practical use for a software rasterizer these days. Going from lyon to an API like OpenGL is fairly easy, and you get huge benefits from that in both performance and effect possibilities.
`const res = fetch(url, options).await.json().await` seems nicer to me. I like that critical code is visually "at surface level". Logically, "fetch the url, await the result, get the json, await the result" makes more sense to me than building a future that is the two futures chained together and awaiting on that. Just my thoughts and I could be missing something.
Ah, I didn't know the troubles of enabling an ABI vs. as an attribute. But actually that isn't so bad to be honest. I compared it with `unsafe fn` for its restricted call sites and an unstable attribute would be actually *closer* to this for the sake of comparison. For the sake of the argument of it being a function, it doesn't matter greatly and if an attribute makes it easier and less hacky for implementation then definitely use that instead :)
"Missing the forest for the trees" describes my impression of the article really well as well. Talk all you want about modifying and redistributing software, the average user is *never* going to be hacking on the software they use (or spending thousands hiring others to do it for them) so telling them they're technically allowed is not a compelling argument to switch. The only way to convince more people to use your software is to *write better software.* After all*,* Rust isn't abandoning IRC because they want a proprietary option, they're abandoning it because it lacks a whole bunch of usability features and is generally quite hard to use. Also, the author seems to be coming from the worldview that using proprietary software is a moral failing ("model your values", etc.) which seems like a marvelous way to alienate anyone who isn't already as committed as they are
Great work as always!
What crates are you using?
what did you end up doing
I followed this post https://jsdw.me/posts/rust-asyncawait-preview/
I've added some documentation about the design here: https://github.com/jrmuizel/raqote/blob/master/DESIGN.md Are there other specific areas that you're interested in seeing documentation for? Also what's the folding issue of skeletal strokes?
Thanks! I get that part, I was more interested about where `Client` comes from.
Ah sorry. Reqwest 😊 you have to import their async module as r#async and convert between the old and new futures. But otherwise it works great.
Theoretically, Intel should benefit the most (from sub-passes) out of current desktop GPUs: 1. they have slow memory access and often relatively big L3/L4 caches. As /u/mstange shown recently at the graphics workweek (at Mozilla Toronto), rendering slows down considerably once we start writing more than 9Mb data of pixels. Theoretically, the driver could introduce the tile size based on that L3/L4 cache size (and the format of the render targets), detect if a vertex shader doesn't have any side effects, and repeat it per tile, achieving optimal cache utilization without any awareness of the user. 2. their next discreet card has tiling architecture, like mobile ones But that's theory, of course. In practice, this is unlikely the case at the moment.
So you have a struct with 100 fields? Can you use an array instead?
Its not my struct, its from another package. So I cannot change it.
(lyon author here) lyon's path tessellation approach (as everything else) comes with pros and cons. I am obviously biased towards it but I wouldn't advertize it as a universal vector graphics solution. For example if you need high quality anti-aliasing, lyon doesn't give you that right now. Or if you want to render small glyphs that don't cover a large amount of pixels, a software rasterizer will likely be at least as fast while also providing high quality AA. At the end of the day it comes down to which approach/implementation ticks most of the boxes for your given use case. I think that software rasterizers will keep having their use where they work well and as fallbacks to fancier techniques when the latters rely on hardware/driver capabilities that are buggy or unavailble.
I think when you have a struct this huge you should try merging it into a single statically sized array, and then maybe having an enum of values. For example you could have an enum Field{ X = 0, Y = 1, ...} and then to access a field you could do myarr[Field::X] Managing a struct with hundreds of fields would be pretty unwieldly otherwise I'd imagine.
I tweaked the text to say its not my struct, its from a vendor supplied library. And its 100s of metrics, which I'm trying to get into a TSDB. Hence why easiest would be an iterator or something that can do this without me having to maintain all the keys.
The only real benefits right now are that it's written in Rust and the code base is small. The most notable limitations right now are some missing functionality. Namely blend modes and layers. However, it shouldn't be too hard to add support for these. The quality of antialiasing is also intentionally lower than Cairo. Right now performance won't be great, but it shouldn't be too hard to get to place where it's faster than Cairo but slower than Skia. The main alternatives are Cairo, Skia, QtPainter, antigrain, Direct2D and CoreGraphics. [footile](https://github.com/DougLau/footile) is the only pure Rust alternative that I know about it. However it doesn't support image transformations, gradients, or dashing. The footile api is also a little bit different than a traditional 2d library.
I don't think you can really? If a crate really want's to break this security model all it has to do is not use `std` and write some unsafe to do the syscalls themselves. You could probably protect against that too, but I have the feeling that this would just lead to the same obfuscation cat and mouse game antivirus software has to deal with.
Yeah, that's the thing I was worried about. Like, you could potentially have some abstract subset of "pure" Rust that only exists in memory and has no way to communicate with the outside world by default, but that's _a lot_ of work.
Thanks for this.
as long as a crate can use unsafe it can call into C to do whatever it wants from there.
Yeah you probably want a macro here. You'll probably have to write your own, but overall if you were to do this now it'd be a lot easier and less headache-inducing than if you were to attempt this a year or two ago. You should probably start looking at 'custom derives' which should let you access the fields of the struct and generate an iterator implementation. Who knows, maybe you'll share your work in the form of a crate to allow people in the future to easily do what you're doing.
It is register usage, but the reasons are complicated, and it's not as simple as "increased usage". First, the ALU is an 8-way SIMD ALU; this means that going narrower than a simd_group of 8 just leaves performance on the table (it'll be executed on an 8 wide ALU, and the unused results discarded, so 2-way SIMD is 1/4th the speed of 8-way). Going wider than 8 way has smaller gains; you save some per-instruction overhead, but you no longer double throughput for each doubling in width; 5% to 25% more perf is expected as you go from 8 to 32. Second, while a thread has a maximum of 128 registers, each 256 bits wide, the number of threads you can allocate to a single core depends on the number of registers allocated to each thread; you allocate registers to threads in blocks of 16 registers (512 bytes). The fewer registers you allocate to a thread, the more threads you can have waiting to be scheduled by the thread scheduler onto one of the EUs (each EU has 7 hardware threads that it services, and you have between 12 and 48 EUs on a Gen 9.5 GPU). Third, you access registers via register regions, which means that you can "split" registers, and do funny element &lt;=&gt; register packing, but only within the limits of regions. There's a [useful visualization tool](https://chriscummins.cc/s/gen-regions/index.html) for Gen register regions that tells you about invalid region specs, and the [GPGPU doc page 787 onwards](https://01.org/sites/default/files/documentation/intel-gfx-prm-osrc-kbl-vol07-3d_media_gpgpu.pdf) explain how regions work. A quick summary follows, but the PRM is authoritative (page 790 for the algorithm): * You have a maximum of 128 registers, each 256 bits wide, for a maximum 4KiB of "local" memory. You cannot access any other memory directly (no load or store). * A region is a sparse rectangle of elements in up to 2 registers, where each element is contained in a single register. * You treat the registers as a 2D space; rows are register numbers, columns are offsets within 256-bit wide registers. They are also a linear memory space - i.e. r4.16 is the same memory location in register space as r5.0. * You define a region by origin point in the 2D space, and three parameters, each a power of 2 (width in the set [1,2,4,8,16], horizontal stride in the set [0,1,2,4], vertical stride in the set [0,1,2,4,8,16,32]). Height is deduced as execution size divided by width. * Elements are assigned to registers as follows (Rusty pseudocode, `yield`ing the registers in order): let base_offset: usize = reg_num * 32 + reg_offset * element_size; for vert_pos in 0..height { let row_base_offset = base_offset + vert_pos * vertical_stride * element_size; for horiz_pos in 0..width { yield row_base_offset + horiz_pos * horizontal_stride; } } For a `simd_broadcast`, I would expect the source region to be a single element from a register (i.e. a region description of the form `r5.7&lt;0;1,0&gt;:w`), and the destination to be an entire SIMD group. In `ExecSize` 16 code, I have a lot of freedom choosing the region to write to - I can, for example, write to any alignment of packed registers (i.e. a region description of the form `rX.Y&lt;16;16,1&gt;:w` for any legal values of X and Y gets me a linear set of 16 elements anywhere in register space). In `ExecSize` 32 code, though, register allocation becomes much harder; the only acceptable layout for the destination of your broadcast is a register-aligned packed rectangle (i.e. a region description of the form `rX.0&lt;16;16, 1&gt;:w` is the only allowed form). This, in turn, makes the job of the register allocator harder; in SIMD16 mode, it has 4080 origin points to choose from if the register set is packed, plus a further 8128 origin points to choose from if it has to leave an element sized gap between each broadcast destination. In SIMD32 mode, it has 126 origin points to choose from, and must clear 32 elements immediately after the origin point - they must be packed together. But, those origin points assume that you're giving each thread the full 128 registers; if you limit to the minimum size of 16 registers (which lets you have 8 times as many threads waiting in the hardware scheduler to share across your EUs), a SIMD16 thread has 496 origin points for packed registers, plus a further 976 origin points if it has to leave an element sized gap between destinations. The SIMD32 version is limited to just 14 origin points to choose from, and must clear 32 elements immediately after the origin point. So, the shader compiler has to look at the outcome of SIMD16 and SIMD32 register allocation, and make a decision; does the extra per-thread throughput of SIMD32 mode outweigh the cost of assigning more registers per thread. I suspect that, in your case, the answer to this is "no - SIMD16 and more threads in the scheduler is higher throughput than SIMD32 and fewer threads". And then note that the heuristic will also have to account for how many instructions you run that will cause the thread to stall - any `send` instructions that ask for access to main memory or shared local memory, for example - as compared to SIMD ALU instructions. If your kernel can run with the initial data from thread start only, and runs to completion on SIMD ALU instructions only, the heuristic will bias towards SIMD32 even if that means fewer threads (as there's no opportunity for threads to stall and be rescheduled). If your kernel is full of `send` or `math` instructions, and does very little SIMD ALU work before stalling again, the heuristic should bias towards having a huge number of threads to schedule - there will be lots of rescheduling opportunities.
Then you can't derive `Serialize` or another trait on it either. That's unfortunate.
So while the other examples are likely more correct, I'll discuss what you asked more directly. It probably goes without saying, but if you just need this once then writing some complex macro/tooling around doing this in a nicer or more automated way might be a bit heavy handed. A multi-cursor text editor could solve this problem with brute force pretty easily. Something like: struct FooIter(Foo); impl FooIter { fn into_iter(self) -&gt; impl Iterator&lt;i64&gt; { let mut v = Vec::new(); if let Some(i) = self.0.field_1 { v.push(i); } if let Some(i) = self.0.field_2 { v.push(i); } if let Some(i) = self.0.field_3 { v.push(i); } if let Some(i) = self.0.field_4 { v.push(i); } if let Some(i) = self.0.field_5 { v.push(i); } if let Some(i) = self.0.field_6 { v.push(i); } if let Some(i) = self.0.field_7 { v.push(i); } if let Some(i) = self.0.field_8 { v.push(i); } if let Some(i) = self.0.field_9 { v.push(i); } if let Some(i) = self.0.field_0 { v.push(i); } v.into_iter() } } It's not pretty, but you could give me a struct with a thousand fields and I could write the above super easily in 30s if they're all the same type/etc. Food for thought :)
Should you be chaining awaits? Is there a good reason to ever do that? It seems to me it has a huge cost in terms of reviewability and maintainability.
I really didn't like it at first, but as I have read more code I have found it more and more readable. That will be even better when more syntax highlighters give it a different font face. Compared to the general difficulty grokking async, a little syntax oddity shouldn't be too much of a stumbling block.
AMD and Intel have 100% open-source kernel and userspace drivers on Linux for OpenGL, Vulkan and OpenCL. Those are actually the official and recommended drivers that provide the best performance, not some research project. You can inspect their innards to your heart's content. Firmware is still proprietary though.
The `await?` operator doesn't allow chaining like you did there. E.g. you need to await the `create_task`, but not return the error from that direct piece - you want the error return after the `map_err`. `await?` isn't usable in this example.
The Rust Book by Steve Klabnik
A macro can do that easily, though.
Within a week from now...
Not exactly what you're looking for, but /r/dailyprogrammer. This is how I practise occasionally.
Thanks, that's helpful, I'm learning a lot! As a general observation, these details seem fairly arcane. In this particular case, I think I'm being bitten by the heuristic, as the compiler's choice of SIMD width is affecting the work factor of my algorithm. I'm in the process of moving it from SIMD groups to threadgroups, as there I have explicit control over the layout, and it will be more portable. I might come back to SIMD as a performance fine-tune, but my goal right now is to keep things as simple as possible.
Yea, I wasn't disagreeing with that. I said the other solutions were better at the top :)
Dang! I really want to get into Rust for microcontrollers, I want to get into development and texting while it's new and really new stuff is being discovered.
&gt;Are there other specific areas that you're interested in seeing documentation for? Every public symbol, assume someone looking at your crate has never used a 2D graphics API before.
You might be able to hook C# and F# users by showing how Rust iterators provide convenience similar to Linq and Seq but with much better runtime performance.
&gt;P.S.: I have already tried vec![0; 10]. But, it takes around 75 ns to initialize a vector of size 3 which I don't want because I don't care about the values in initialized Vec. `vec![0; n]` has an optimization where it will request already-zeroed memory from the operating system, so I'm not sure if you can realistically beat it.
I suppose that is what's happening. That is quite the frustrating decision from the compiler, though. Perhaps its because constants get in-lined in program execution, so that constant will never get in-lined or something?
You didn't mention `defer` though.
It's just a limitation of the `entry` API. `raw_entry` was created to get around that limitation, among others. You just have to be more careful with `raw_entry` since misusing it can put your hashmap in a logically inconsistent (but not memory-unsafe) state.
I will be defining this in all of my projects.
This is phenomenal stuff.
It has the following traits #[derive(Debug, Serialize, Deserialize, Clone)] pub struct ...
Interesting, thanks. Now to figure out how to multi cursor edit. I guess Intellij is not my friend.
Please share details of struct. I am preparing popcorn now.
Generating PNG files on servers that don’t have GPUs?
Because I didn't know the `defer` keyword was proposed. I did say so abstractly when I wrote this comment: *The compiler assumes you want to await unless you use a keyword that is the opposite of await.*
[removed]
Ah, then you can implement a serializer, see my link above. But a macro might be easier.
Happy to do it for you, if the above simple example will work, and if you want to paste the struct. I use Kakoune, fwiw.
&gt; The only flaw I see in this is that you might want to return a Future without actually doing anything with it. I'm not sure I understand the problem. If we made async { some_async_function() } evaluate to a future in *every* context (suspendable and not suspendable) and allow suspendable code to write some_async_function() which implicitly awaits the result, how does it stop you from returning "a Future without actually doing anything with it"? &gt; but currently there are libraries that return you a Future and you spawn it on your own Runtime. This way the library doesn't need to depend on whatever is driving your IO (so they can omit Tokio as a dependency, etc). I don't see why this shouldn't be possible. The only issue I see is that given these functions async fn foo() -&gt; T; fn bar() -&gt; impl Future&lt;Output=T&gt;; and implicit await, one might be surprized that in a suspendable context the following happens: let x = foo(); // x is of type T. No surprize let y = bar(); // y is also of type T and an // implicit await happens here, too if we treated `foo` and `bar` differently in a suspendable context, we would still need an explicit await syntax for `bar()`.
I assumed it thinks that since you're not creating the struct, you don't need the constant. The diagnostics are similar to what C# has, and with IDE support they're just some squigglies. But you can temporarily disable the warning if it bothers you.
Yes, but there's a separate target that can use statically linked [musl](https://www.musl-libc.org/).
Allowing only safe code outside of specified libraries (which I think we can already audit for) would close most of the holes, I think. It would also restrict the crate universe, but maybe that's for the best…
¿
The other big issue is that `impl Future` is still a thing in async code. async fn foo(fut: impl Future) { In an implicit await system, how do you await `fut` here? Similarly, is the implicit await done only for `async fn` or also for `fn -&gt; impl Future`? It was important to the Rust team that the usage of `async fn` and `fn -&gt; impl Future` not differ, as many use cases might want to go to the explicit version to control lifetimes and do some pre-work. While these problems are not unsolvable, they don't lead to locally obvious semantics, which are important to Rust's design philosophy. I was one of the two biggest proponents of considering implicit await when that was still a viable alternative, but I've been thoroughly convinced that it just doesn't fit for Rust. (That said, I'm slowly designing a language I intend to be an opinionated Rust-inspired scripting language with "mostly" effortless Rust interop, and it's `async` everywhere and implicit `await` everywhere.)
I see. I'm interested in using it in [resvg](https://github.com/RazrFalcon/resvg). But for now I depend on backend's text support, and looks like you don't have any. Hopefully, resvg will soon implement it's own text layout.
It's not quite a book, but I've found the Rust track on exercism to be a great test-based approach to learning.
I am porting my first Rust program to work as a WASM module. It's a toy command line calculator that implements a REPL allowing infix equations to be entered (i.e. a\*a + b + c) which are then internally translated to prefix notation and solved. I put in variable substitution so that with a bit of elbow grease, you can input an equation and then keep changing the variables (i.e. a = 1, b=1, c=1...). I'm packaging this up as a demo to show off at my day job, using web assembly to implement a graphing calculator. The idea is to sell Web Assembly, in general, and Rust as a toolchain for web assembly. I work for a Big Ten University, building architectural tools so that other developers can write the applications that run everything else. We do a lot of web-facing work. Where you come in: I'm trying to decide how to hold my two state variables: A Vec of an internal data structure and a HashMap of variables and their current state. Under the REPL, these were local. Under WASM, the most straightforward path seems to be to declare the state variables as static mutable and then mark alters to the contents as unsafe. I'm looking for other options.
There are a lot of cases besides "`await` an `async` function" that need explicit handling: - Calling a function that returns a pair of futures, then awaiting them both. - Awaiting a variable number of futures in an arbitrary collection. - Calling a couple async functions without awaiting, combining the futures they return with some combinator, and then awaiting that. All of these things can be done inside a `defer` block using the magical `join_all` function instead of `await`, but I think it starts to get messy.
There is too many for me to ask that of you. ;) but for a macro could work, I need to learn that It seems. For interest sake, This is repo which is code I generate using swagger. here is one of the structs. https://github.com/unixunion/rust_solace_semp_client/blob/master/src/models/msg_vpn.rs My POC for this is https://github.com/unixunion/solace-metrics/blob/master/src/metrics.rs line 60 You can see what I am trying to avoid doing. It also has nested structs which contain less diverse data types. I generate this code using swagger, so I do have some template control over the traits, I added serialize for instance.
Right, I have. Enjoy the popped corns
Oh. For something like this, it looks like you want to serialize it into JSON (that's what Swagger is, after all) and walk the JSON programmatically. As far as I can tell no other magic should be needed?
In the JS case, exceptions. In the Rust analogue, `?` (so `.await?`).
What about `std::time::Duration`? It's std so everyone has it. And after getting acquainted with it I must say I strongly prefer it to raw values.
You *could* (if you want your debugger to be doing file I/O), save the full output to a file, then just show the first/last 5 items, the count, and the file name in which the full output is.
Hmm, yeah I was thinking of that, but I want this to be as fast as possible. The device I am getting this data from is emitting about 1 to 1.5million metrics per cycle. And that takes quite a bit of time with the current solution which is XML tree walking. I guess I could do some performance comparisons between rust walking json.
&gt;In an implicit await system, how do you await `fut` here? Adding an `await()` method to the Future trait would solve that as per the Kotlin example above, no? The implementation of that method would just return self. &gt;Similarly, is the implicit await done only for `async fn` or also for `fn -&gt; impl Future`? &gt; &gt;It was important to the Rust team that the usage of `async fn`and `fn -&gt; impl Future` not differ, as many use cases might want to go to the explicit version to control lifetimes and do some pre-work. My thoughts were that it would occur only in `async fn`s. Note that the *usage* of async fn and fn -&gt; impl Future wouldn't differ, only the *authoring*. Perhaps this is an example of the Rust team's natural bias as library-writers rather than library-users showing through? My impression has been that writing bottom-level `Future`s/Future combinators is considered an advanced, less-common task than writing higher-level application code that uses the futures. If that's true, then implicit-await behavior seems to optimize for the majority use case. And clearly those lower-level `fn -&gt; impl Future` functions could still be written - after all, they already exist before `.await`.
There's some super basic text support right now. I'll try to flesh it out more this weekend using skribo.
Is this normal behavior for rustup? I haven't ever payed much attention to it before, but it seems to be downloading the same stuff twice. Additionally, the actual average download speed for \`rust-docs\` (I estimate about 25 KiB/s) does not match what is being shown, and I always remember \`rust-docs\` being way slower to download than the rest of the items. I have run \`rustup self update\` before this. The same behavior occurs for other toolchains. info: syncing channel updates for 'beta-x86_64-pc-windows-msvc' 371.9 KiB / 371.9 KiB (100 %) 208.7 KiB/s ETA: 0 s info: latest update on 2019-04-28, rust version 1.35.0-beta.3 (c13114dc8 2019-04-27) info: downloading component 'rustc' 60.0 MiB / 60.0 MiB (100 %) 300.8 KiB/s ETA: 0 s info: downloading component 'rust-std' 53.1 MiB / 53.1 MiB (100 %) 336.0 KiB/s ETA: 0 s info: downloading component 'cargo' 2.9 MiB / 2.9 MiB (100 %) 397.4 KiB/s ETA: 0 s info: downloading component 'rust-docs' 10.3 MiB / 10.3 MiB (100 %) 412.8 KiB/s ETA: 0 s info: downloading component 'rls' 5.1 MiB / 5.1 MiB (100 %) 438.4 KiB/s ETA: 0 s info: downloading component 'rust-src' 2.4 MiB / 2.4 MiB (100 %) 388.1 KiB/s ETA: 0 s info: downloading component 'rust-analysis' 478.8 KiB / 478.8 KiB (100 %) 429.1 KiB/s ETA: 0 s info: removing component 'rustc' info: removing component 'rust-std' info: removing component 'cargo' info: removing component 'rust-docs' info: removing component 'rls' info: removing component 'rust-src' info: removing component 'rust-analysis' info: installing component 'rustc' 60.0 MiB / 60.0 MiB (100 %) 2.9 MiB/s ETA: 0 s info: installing component 'rust-std' 53.1 MiB / 53.1 MiB (100 %) 2.9 MiB/s ETA: 0 s info: installing component 'cargo' 2.9 MiB / 2.9 MiB (100 %) 928.0 KiB/s ETA: 0 s info: installing component 'rust-docs' 10.3 MiB / 10.3 MiB (100 %) 283.2 KiB/s ETA: 0 s info: installing component 'rls' 5.1 MiB / 5.1 MiB (100 %) 3.3 MiB/s ETA: 0 s info: installing component 'rust-src' 2.4 MiB / 2.4 MiB (100 %) 86.4 KiB/s ETA: 0 s info: installing component 'rust-analysis'
I feel like the blank spaces on each of the pages is missing something. The context bounces really quickly for someone new to the concept.
https://stackoverflow.com/questions/48487941/calling-java-methods-from-c-without-starting-the-jvm-from-c Apparently you have to get a call from JVM first, then you can reuse the JNI env to call back.
You could also serialize into some metric-friendly format as suggested elsewhere here. It would be a lot more code, but still way easier than doing metrics directly on the Rust data structure. Serde is quite fast, so I doubt you're going to feel too much of a bottleneck.
You're right, your proposal does look like the same thing. Kudos to you for prior art! Also, `defer {}` isn't an official proposal or anything, just something I came up with. I'm actually starting to like the suggestion of using `async {}` as suggested by u/RustMeUp instead.
Thanks &lt;3 &amp;#x200B; I'm not claiming that I'll never write another one, necessarily, just that I've now covered the material that I had originally set out to cover.
At least with Metal and Vulkan, you're exposed to more of the arcane details - you can actually get the driver to tell you WTF it's done, rather than having to guess which OpenGL state will get the driver to do what you want it to. SIMD groups as a final performance tune-up is what they're meant for - they expose the fact that what you code as 320,000 threads all running in parallel runs on the hardware as a smaller number of SIMD threads. Communicating between SIMD lanes is extremely cheap (if not free), so you can exploit that to gain a little bit of performance. If you're not yet at the state of micro-optimizing communication like that, stick to thread groups - this will be slightly lower performance (as you won't be paying attention to `mov` versus `send` communication costs), but is far easier to program. Remember that for OpenGL style graphics, you're memory bandwidth limited; the reason for having so many threads and a scheduler capable of juggling a very large number of inactive threads is that a GPU extracts memory level parallelism by running threads in straight lines until they stall, and then handing the compute core to another thread. None of the CPU-style out of order execution, speculation etc - just run until you block waiting for memory, then yield the core to another thread. I'd be interested to know just how close your code actually is to being limited solely by memory bandwidth; that's the goal state for a GPU, as then it can just dispatch thousands (or hundreds of thousands) of threads to keep the memory controller saturated.
&gt;one might be surprized that in a suspendable context the following happens Yes, that is the 'it might be surprising' drawback I mentioned in the OP. But I personally feel that implicit await makes it less confusing, not more. With implicit await, the statement "when a function completes, it is done with all its work" is true for both synchronous and asynchronous functions (unless you opt-in to deferred execution with a `defer{}`/`async{}` block). That statement being true by default seems like it would be more understandable to beginners than needing to access a special `.await` field to get normal function completion behavior.
But the problem still stands: how do you actually define when things are awaited? Another big issue: doing `impl Future for S` can break async code that creates an `S`. Currently, implementing a trait for a type you own is always semver-compatible. The only model I've been able to come up with that fully works requires two types, as exist in Kotlin. You have your `suspend` "type", which can _only_ be created by a `suspend fun`, and is immediately `await`ted when called in an `async` context, and _cannot_ be called in a sync context (you need to do `async { foo() }` instead). And you have your `impl Async` type (roughly the stabilized `Future` which offers a `suspend fun await(&amp;pin mut self)` method. This represents a deffered asynchronous computation, and is (very) roughly an async version of `impl Fn()`. As far as I can tell, you can't do this consistently with just a single trait. You need another dimension in the type system for the `?async` quality of a function you're calling, which controls whether the implicit await is inserted. It's theoretically possible to do with just `Future`, by a rule something like "every time you mention a place, if it `impl Future` it's awaited unless it is a `async { }` block", but this leads to a somewhat nonintuitive behavior from a somewhat ad-hoc rule, and code meaning differences between `async` and sync code. A heuristic to guess if the value is used inside or outside the future is even more magic that takes away local decision-making power. In a more opinionated setting, I'm in full agreement that an "explicit `async`, implicit `await`" system is great, and better than "implicit `async`, explicit `await`". You can search irlo for those phrases for the full discussion. But for Rust which prides itself on giving the choices to the user with locally obvious syntax, it makes more sense for the function call to mean the same thing in async and sync contexts, and to provide an `await` operation when in an `async` context to drive the futures to completion.
&gt; Wrt. the post history, you probably know, but the posts can still be found if someone knows your old username (it's not even much effort). I don't expect anything more than pseudo-nimity from Reddit. I try not to write things I wouldn't say in real life, but posting habits and other account metadata can't really be hidden. I know, I still wanted it to be an extra step. I didn't really even have anything inappropriate on the previous account, I mostly just wanted to delineate work from not-work. &gt; Sorry for the personal tangent, I doubt /r/rust is the right place to be talking about this :-). I think you took the right decision. Thanks, and yeah same sorry for personal tangent :P &gt; I've never used Lua and I don't know its backwards compatibility story. Using crate features is a solution for this that I've used before, but it's bit of a hack; the other approach I can think of is putting out multiple versions of the crate, in lockstep with the Lua releases. &gt; I've never used Lua and I don't know its backwards compatibility story. Lua minor versions are largely the same except for some minor things which end up being huge things. Also, LuaJIT is as or more popular than PUC-Rio Lua and it is its own incompatible fork at this point. Users tend to pick one version of Lua and stick with that for eternity. But yeah, I'm having this issue right now in rlua as well, I'm not exactly sure what the best solution is. From what I've read, crate features aren't supposed to be used for things like this, especially *mutually exclusive* things, so I don't know. Your solution of version lockstep with Lua is not bad, I guess one source tree -&gt; multiple crates via build magic is another possible solution?
&gt;using async in the method already implies the magical async transformation This made me realize that the current behavior of `async` (with `.await`) functions is implicit wrapping (of return values) + explicit unwrapping (of child futures). So, clearly some level of implicitness is acceptable to the Rust team, but the behavior is nonuniform. On the other hand, the implicit-await approach would be more coherent, with both implicit wrapping and implicit unwrapping.
Exactly my thoughts! Compared to the runtime model of futures, understanding field access async is a tiny detail.
If rustfix can remove redundant braces, then `replace-await -&gt; rustfix -&gt; rustfmt` should give you a good sense of the ergonomics of each.
What is meant by "texting" in this context?
It might mean that I don't know how to type after just waking up.
&gt; And quite often, the open source option just ... doesn't do that. Indeed, there's a strong tendency in open source communities to de-prioritize and even sneer at UI/UX and design as even a concern, and this does not lead to pleasant software to use. I fully agree. It's also hard to recruit designers - it's generally a space where you need money to make ends meet. And given the described habit of people sneering at your work, why would you spend your evenings on it?
Well it is a learning experience. ;)
Ah, if it's more than one struct you definitely want to implement a generic solution for it. Also, I'm not sure how you plan on handling the differing data types within a single iterator - you'd have to.. what, wrap them in an enum? Interesting
&gt; Thanks, and yeah same sorry for personal tangent :P Well, I asked :-). &gt; From what I've read, crate features aren't supposed to be used for things like this, especially mutually exclusive things, so I don't know. Yeah, that's why I said it was a hack. [`libsqlite3-sys`](https://github.com/jgallagher/rusqlite/blob/master/libsqlite3-sys/) takes that approach, and I've ~~used~~ stolen it a while ago for the GDAL [bindings](https://github.com/georust/gdal/pull/55). And yes, GDAL sometimes breaks compatibility by removing functions. &gt; I guess one source tree -&gt; multiple crates via build magic is another possible solution? Sounds like it might work, yes.
Fascinating. I wonder if anyone’s bothered with a pure Rust alternative to these unsettlingly C based implementations.
Yeah so a macro might really be the best approach
The Redox folks are building [their own libc entirely in Rust](https://gitlab.redox-os.org/redox-os/relibc), and it's POSIX-compatible.
[join\_all](https://docs.rs/futures/0.2.0/futures/future/fn.join_all.html) is just a standard function I got from the futures-rs docs. And if you somehow have a Future you want to await (as in your call-function-that-returns-pair) example, then an `await` function on the Future trait that simply returns self would allow you to do that. // On the Future or maybe FutureExt trait. fn await(self) -&gt; Self { self }
Yeah, Redox looks really cool. Could the Redox libc be used as a modular replacement for glibc, similar to musl, uClibC et al?
That is the intent, yes.
You can't, not statically. This kind of constraint makes much more sense in the domain of an operating system, IMO. What's the threat model here? Deliberate alteration of a dependency or defects which might be exploited by an attacker? &gt; With the increased use of dependencies between packages, the risk of vulnerability propagation increases. Okay, so, vulnerabilities. So what do we gain by constraining dependencies? Attackers would likely exploit defects in order to RCE which means that it doesn't matter whether or not you have used the file I/O std lib (though it's slightly easier to exploit if it's linked in the binary). &gt; If that for whatever reason, clap starts using a permission like net that is not authorized to use, we are going going to raise red flags about the version used for the clap crate. Okay, so that sounds like ... not vulnerabilities, right? But a deliberate change. &gt; We can take advantage of the static analysis to understand what is going on a package under the hood. IMO there's utility in having a `cargo audit-scope` that would walk the dependency tree to determine which of these categories are present in your resulting binary. And if you grew a new one, or if any of your dependencies grew a new one, it could tell you. But somehow I think that clever use of `cargo` or `build.rs` could defeat the audit by linking in some other binary that is out of reach of the audit. So it would not be terribly effective against a determined attacker.
Since lyon tesselates into clean triangles, the GPU can do the AA without any limitations. Of course, then you’re at the whim of GPU driver bugs.
I assume the idea would be to lock down the "core" language as much as possible for this to work - so you couldn't do `build.rs`, and you couldn't do `unsafe`, and you couldn't do FFI and so on. Then you'd be able to enable the individual features to actually do the things you want. Still really difficult though.
&gt;how do you actually define when things are awaited? Inside an async fn or lambda, any call to a method that returns anything that impls Future is implicitly awaited, with the exception of calls within a `defer{}`/`async{}` block. I don't really understand your point about needing two traits, I'll try to think through your explanation some more. Thanks for the guidance about search terms for finding historical discussion - that was actually what I was looking for from this post in the first place :) Just one question - what is 'irlo'?
awesome, thank you!
https://internals.rust-lang.org https://internals.rust-lang.org/t/explicit-future-construction-implicit-await/7344?u=cad97 Await anything that impls future means that `impl Future for Type` is now a breaking change (bad) and calling a a function that returns an `impl Future` does something different in sync and async contexts (bad). Kotlin solves this by making the use of `suspend fun` impossible when not in a `suspend fun` or `async { }`. Thus the "two types".
Trade-offs, trade-offs :/
I saw this at the Impl days at Oxidize and was very impressed by it. Good to be able to now look through the details.
Why does this work: struct Cookie { a: i32, b: i32, } fn main() { let rawpt: *mut Cookie; let safe: Box&lt;Cookie&gt;; unsafe { rawpt = foo(); safe = Box::from_raw(rawpt); } println!("{}", safe.a); unsafe { println!("{}", (*rawpt).b); } } fn foo() -&gt; *mut Cookie { let oreo = Cookie{a: 5, b: 42}; let danger = Box::into_raw(Box::new(oreo)); danger } This should not work. \`rawpt\`'s ownership should be transfered to the box, therefore the println in the last unsafe should not work. So says the docu: After calling this function, the raw pointer is owned by the resulting Box [https://doc.rust-lang.org/std/boxed/struct.Box.html](https://doc.rust-lang.org/std/boxed/struct.Box.html)
&gt; I don't believe there is any good reason to write asynchronous code like that. I don't know. It'd be interesting to see Go users' feedback, since in Go async is completely invisible (any function can "yield"). I wonder if it makes things more difficult, or if the yield points don't matter because the behavior of the code you are reading is still sequential. I don't feel like I have enough experience in such async patterns to comment on that.
This violates Rust's ownership model but in terms of implementation detail this "works" because Box is basically an RAII wrapper around the raw pointer. Using from_raw does not move the object to another place, it simply produces a Box struct that will free that pointer on drop.
I think two tildas on each end strikes out the inner text. ~~:D~~
That does seem to be the case. Today's been a bad day.
Great link, thanks. A first observation is that that proposal doesn't seem exactly the same though - that proposal only has the implicit await when an `async fn` is called, not a `fn -&gt; impl Future`. This is based on the following code from that topic: // Send a request *now* and return a future that represents the response. fn send_request(item: Item) -&gt; impl Future&lt;Output = Response&gt; { .. } async fn process_data(item: Item) { let response = send_request(item); let data = cpu_work(); let response = futures::await(response); process(data, response); } The key to the code example is `send_request(item)` returning a Future which is then later awaited by `futures::await` (presumably an `async fn`), but in this new proposal send\_request would automatically have a suspension point added, because `async fn` and `fn -&gt; impl Trait` are treated the same.
First of all, I'm not aware of any i686 (x86) raspberry pis, so you may want to double check that before solving your linking issues.
You may enjoy [rust by example](https://doc.rust-lang.org/rust-by-example/index.html)
[Consider adding Linux targets that don't depend on libc #2610](https://github.com/rust-lang/rfcs/issues/2610) &gt; These would be the spiritual successor of [steed](https://github.com/japaric/steed): a standard library, free of C dependencies, for Linux systems. Steed implemented (or planned to) the Rust standard library using raw Linux system calls instead of libc's API. These libc-less targets would also implement std using raw system calls.
The variants are discussed throughout the thread. The issues I've discussed with "await all `impl Future`" remain. Ultimately, due to the required semantic shift between `async` and sync contexts, the Rust core language team decided that the implicit `await` isn't tractable to attach to the language we have today. And at the point of design discussion we're at, I could only really see some "do `await _` (obvious precedence, no sugar) now, generalized `_.keyword` later" argument surfacing that would change the team's decision. An implicit-await system is just walking back on decisions that were already made, and there is definitely pressure to "pick one". (I'm actually drafting an RFC-like explainer for a potential `async Trait` "effects" feature that behaves slightly like implicit await.)
I suppose you are referring to msaa. Indeed that's an easy solution and it works well for a lot of use cases. However keep in mind that on Intel GPUs, msaa is very slow, and even on discreet GPUs you rarely go over 8x msaa because it is costly. In contrast, skia, cairo, pathfinder or piet metal will give you 256 nuances in your anti-aliasing which is what I mean by high quality aa.
Adding to the other comment. As an actual attribute you could call the new function kind: &gt; yield fn trait Await { type Output; yield fn await_future(self) -&gt; Self::Output; } That should make the intent clear enough, and be compatible with the notion that all calls to `yield fn` can result in proper unwinding other than the existing ones (and in internal mechanism that it applies yielding to the statemachine of the calling function). It's also a bit more forward friendly to generators and async generators in its naming.
&gt; For example, if a crate starts using `std::net` library, is going to acquire the net permission. All crates that use this other crate as dependency are going to acquire the `net` permission, **indirectly though**. Is this necessary? It seems to me that this possibly leaks implementation details, and for a sufficiently high-level crate will basically mean "all permissions". For example: - The `png` crate has a file-system permission because it has a function to read/write to file. - The `http` crate has a network access permission because it works over the network. If I create a crate depending on both, I can sneak in code that sends all the host files over the network because the crate inherits both file-system and network access permissions. --- I think this could, possibly, work in an ecosystem which espouses the sans-IO design principle, where I/O is pushed to the boundary (ie, the final executable) so that intermediate libraries never directly touch any file/network socket/pipe/... However I am not sure the Rust ecosystem is leaning toward sans-IO.
What I think I like about our collective proposal is that crates like reqwest often have an async api as well as a synchronous api. Our proposal negates the need for that! If you need just any little bit of your code to become asynchronous, you just pop a `defer` or `async` or whatever in there and then add a bit of code to join later. I think it also helps in training, because if a user sees a function in a crate they're using marked "async" and they don't know what that means, then they can just ignore it!
[This actually works without the trickery today](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8278aaa4cbdb6c66619655e2adf4892b). In pattern position `&amp;mut _` matches through the mutable reference. `anchor` is `&amp;mut Option&lt;Link&gt;`, so matching on `&amp;mut ⟨pat⟩` matches `⟨pat⟩` against `Option&lt;Link&gt;`. The `Some(⟨pat⟩)` matches the `Option::Some` variant, and `ref mut` reintroduces the mutable reference indirection, since we cannot move out of `anchor`, which is a mutable reference. Nowadays, the compiler does most of the projection of references through patterns for you, so you only have to worry about it when you're mixing binding modes (e.g. binding part by ref, part by ref mut, part by move). NLL (non-lexical lifetime) improvements mean that the anonymous temporary is no longer needed as well; the compiler can see that the borrow uses are disjoint.
It's pattern matching. The match is on `anchor`, which is declared as a `&amp;mut Option&lt;something&gt;`, so you can match it with `&amp;mut Some(ref x)`. `x` will then be a reference to `something` in the `&amp;mut Option` thing.
This is in an arm of a `match` statement. It is worthwhile to read the [pattern matching](https://doc.rust-lang.org/book/ch18-00-patterns.html) section of the Book. Basically, it’s saying that the thing you’re matching on (`anchor` in the linked SO code) should have a structure of being a mutable reference to the `Some` variant of an `Option` enum that contains some value, which is given a name of `x` in the pattern. If `anchor` *does* match this pattern, then the instructions after the `=&gt;` will execute with `x` still referring to the inner value of that `Some` variant. Note that `x` is not a reference, but the value itself. Patterns in Rust are absurdly powerful from what I’ve seen, and also readable and flexible. They’re an undersold feature IMO. That said, I still have no idea how the advanced patterns work, and they definitely take some time to wrap your head around. Story of Rust as a whole, I guess.
"Learn rust with entirely too many linked lists" doesn't focus on testing but it does go over it, I'd check that out.
This series is amazing. Could someone point me to similar blog posts/articles that discuss practical applications of category theory? The closest I can think of is the book [Seven Sketches in Compositionality](http://math.mit.edu/~dspivak/teaching/sp18/7Sketches.pdf) which I would highly recommend to anyone that enjoyed this post.
&gt;I think it would be great if there was a maintained set of minimal unsafe bindings to luajit and PUC-Rio Lua, but from my experience with people using it, for it to be maximally useful it would need to cover all of LuaJIT and PUC-Rio Lua 5.1, 5.2, 5.3, and soon probably 5.4. Maybe that means that there should be 4 or 5 separate sys crates? I'm not totally sure. Yeah, it's an interesting question of whether to use one crate (using Cargo features, I suppose) or simply multiple for each version. Just like you, I'm not totally sure. I think it would definitely be nice to have that though. At the very least, you and others doing stuff with Lua + Rust should know that the crate name is ready for use whenever any of you might need/want it.
Is this actual, peer-reviewed academic work? It seems presented as such but the author seems to quote/cite/reference themselves quite a bit, as well as presenting official-looking names for things using their own name. The content is definitely interesting but the presentation makes me side-eye it a bit
The fact that NaN != NaN is **not** due to there being so many representations of NaN. That's a bit-level detail, but this could be accounted for in `eq` *if we wanted to*. For example, `+0.0 == -0.0` even though they have different bits. NaN != NaN because its definition makes equality meaningless.
Great to see more companies interested in Rust! I work at a company of similar characteristics to yours (currently I'm working on a project using .NET Core, Angular and Typescript) and we recently held a Rust dojo (you can find the exercises [here](https://github.com/infi-nl/coding-dojo-rust-2018)). I must say I didn't really touch on why Rust would be interesting to us... My colleagues were curious enough to learn Rust just for the sake of it
Maybe - following your reasoning, that NaN all in itself is a problem, Any function should return an Option&lt;f32&gt; and away with the NaN to unsafe only! Just like with the ``NULL``'s And as for the other example ``+0.0 == -0.0`` - that could also be addressed with normalize(), right? Because obviously that is not the same class of a problem as would be ``0.1 + 0.2 == 0.3``, which is just the inherent rounding errors problem of floating points in general, usually mitigated in numeric algorithms by having an ``eps``.
I'm not quite following your logic? As far as I know, the problem isn't that there's a bunch of `NaN` values: it's that there's any of them. IEEE requires that `NaN != NaN`. If you were to relax that restriction, a hash function for `f64` would be easy enough to write regardless of how many `NaN`s there were. In my humble opinion the decision to allow propagating `NaN` was the fundamental mistake. If you try to divide zero by zero, your program should crash with an appropriate error message, not just hope that things will work out.
&gt; Because seriously - I doubt ANYONE in the past 40 years has ever looked at the bit pattern of a NaN, tucked out the hardware specification of their particular platform and said "Aha - it is a NaN because... So So." So how do you feel about [NaN boxing](http://albertnetymk.github.io/2016/08/06/nan_boxing/)? Also, check out that cool link in the sidebar.
NaNs don't really have anything to do with unsafety. Having any operation that could result in NaN return an `Option` is not really an option due to backwards compatibility, and would probably make more things annoying to do than the current solutions (since most code using floats now must deal with `Option`s). It would also likely come at a performance cost.
Oh I see, I misunderstood the rule. Is the idea to have automatic awaiting depend only on the return type of the function? (I.e. not on whether it's declared with the `async` keyword.) In that case I think the big problem would be that implementing Future for something that wasn't a future before becomes an incompatible change. Also I think a lot more steps in the compiler would now need to know what traits are and what types implement what traits.
But `Option&lt;f32&gt;` is larger because it needs to store the discriminant. What if there were some bits inside `f32` that could be used to tag whether the value is valid (a number) or not? --- And as the others have said, `NaN` comparing as different is the behavior mandate by the standard. Are unordered `f32` annoying? Yes, but they solve a real problem.
Currently I am not sure if that would fix all the problems. Mainly because I am not sure if that NaN encoding is done by software as a result of some FP hardware status flags or if it is done by the FPU itself (And what about those top secret NVidia floating points, while we are at it?). Or sometimes this, sometimes that. All in all, my understanding is that the concrete meaning of the 51 free NaN bits is "vendor specific". At one point, rust wants a portable floating point type and NaN is inherently not portable if you look at the inside.
I've read the readme and still don't know what *exactly* this is. Anyone care to explain?:) What's is the relationship between this thing and the Linux kernel?
No kidding. Rust's error messages are amazing and it's great experience "having compiler yell at you". It can teach you a lot.
My [optional](https://GitHub.com/llogiq/optional) crate also has an `Optioned` type that can wrap `f32` or `f64` and.semantically map `NaN` to `None`.
The point is, that it *is* in the standard because those punch card guys used it for debugging. Nowadays, it just leads to more code and crates and whatnot. Sometimes you have to be brave. And here, you do not even have to be *that* brave, given that there is no UN law in place, which prohibits anyone from creating FPUs which do not adhere to that IEEE standard. For example googles fancy new tiny floats. And what then? No rust for that hardware platform with its non IEEE float FPU(s)?
When you store data into the `NaN` payload bits, you need to make sure you read it before doing any computation on that number. Moving a float in memory will preserve the payload. Doing arithmetic.. maybe less so (technically it does, but binary operators are no longer commutative). You can use this to discriminate between e.g. floats and pointers. JavaScript engines do it to improve performance and memory usage.
&gt; there is no UN law in place, which prohibits anyone from creating FPUs which do not adhere to that IEEE standard Good luck making people buy those, unless you are Google, Amazon or NVIDIA.
Actually, the NaN is marked by a bit pattern and independent of what is contained in the spare bits does not affect subsequent calculations: \`\`NaN + x == Nan\`\`. Probably not the same \`\`NaN\`\`, but that is where my great \`\`normalize()\`\` function comes in ;)
Yes, any call to a function which returns a Future would be implicitly awaited, no matter whether the function was declared as `async fn` or `fn -&gt; impl Future`. As for the backwards incompatibility hazard, yes you are right. However, I have two points in response. First, how large of a hazard is this practically? I don't have much experience writing actual Future impls, but from what I can see in futures-rs and other places, every struct which impls Future was specifically created to act as a future. Second, surely adding a Deref impl can cause similar compilation breakage due to name clashes, requiring UFCS to resolve. So the fact that adding trait impls has the possibility to break code, while not a positive factor, is also not sufficient to reject a feature by itself.
That crate is a good step in the right direction. Assuming your \`\`NAN\`\` is indeed one and only one of the possible \`\`NaN\`\` values!
... and who said communicating with memory is not I/O anyway?
noisy-float is a good crate.
It says it's a hypervisor firmware. A hypervisor runs OSes the same way an OS runs programs. (OS kernels used to be called "supervisor programs" so a "hypervisor" is something that's to supervisors as supervisors are to programs.) That could still mean either "a firmware implementing a hypervisor" or "a firmware to be run inside hypervisors" but this line suggests the former: &gt; The ultimate goal is to be able to use this "firmware" to be able to load a bootloader from within a disk image. Assuming I've interpreted that line correctly, it's an experiment in writing something like [Xen](https://en.wikipedia.org/wiki/Xen) without the rest of the Linux kernel that Xen builds on.
Fantastic! I've been using rust on the STM32-F3 boards, and it's been a delightful experience thus far. Recently I've been thinking about making the jump to their new dual-core, STM32-WB chips for wireless applications. Obviously dual-core MCUs bring a new set of potential complications to the table... So, great timing on this! `μAMP` is very similar to what I was looking for.
The payload bits are preserved. But if you add two NaN you get the payload of the first one. My point was that if you encode a pointer as a NaN, you shouldn't be doing arithmetic on it.
You kinda can: https://serde.rs/remote-derive.html
This is something like BIOS written in Rust.
IEEE 754 was engineered very carefully to maximize the stability and performance of numerical calculations. The reason everyone uses it is because it is seriously awesome, and nobody has anything better. It's very easy to sit there with those armchair complaints, suggesting that someone can just crap gold and solve all the same problems, but actually doing it is a whole other thing,
A vmm/hypervisor like Firecracker, the one mentioned in the readme, doesn't boot a kernel using firmware like a hardware computer does. They basically just load a kernel into memory and start executing it by passing the instructions to the host kernel using the kvm api and then mount a filesystem with whatever other software you'll need in the vm. So this would let you run something like the firmware you run when you boot your computer in a vmm like Firecracker in place of directly running the kernel itself, which would mean being able to boot regular old bootable images using that vmm.
You are aware that `!` is [an already existing unary operator](https://doc.rust-lang.org/std/ops/trait.Not.html), right?
Even Notepad has copy/paste. The tooling for writing code is far more simple, elegant, and common than any tool for analyzing code.
Actually, this is a firmware to be run inside hypervisors. Hypervisor is currently KVM, as stated in the title. By default, KVM uses SeaBIOS as a firmware.
For the context of Rust it actually does not matter how useful or great IEEE 754 is/was at the time. The problem is, that it now produces code bloat for a feature which no longer makes much sense. So I do not want to fix IEEE 754 but instead I pointed out that there might have been better options for rust to tackle the problems at hand.
 pub fn is_armstrong_number(num: u32) -&gt; bool { let mut digits = Vec::new(); let mut remain = num; while remain &gt; 0 { digits.push(remain % 10); remain = remain / 10; } let test = digits.iter().map(|x| x.pow(digits.len() as u32)).sum::&lt;u32&gt;(); // okay //let test : u32 = digits.iter().map(|x| x.pow(digits.len() as u32)).sum(); // also okay //let test = digits.iter().map(|x| x.pow(digits.len() as u32)).sum(); // not okay test == num } I've gone down a rabbit hole as to why the type inferencing fails here but probably ended up more confused.. While trawling through the doc to try to understand this, I get to [here](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.sum): fn sum&lt;S&gt;(self) -&gt; S where S: Sum&lt;Self::Item&gt;, This confuses the heck out of me. I read this as `sum&lt;S&gt;` takes a self that returns an `S` which must implements the `Sum&lt;Self::Item&gt;` trait. In this case Self::Item is u32 (as I've got an `Iter&lt;u32&gt;`, right?). But u32 doesn't implement `Sum&lt;Self::Item&gt;`. At which point I know I've got myself embarrassingly tangled up here. Also when following this to [trait.Sum](https://doc.rust-lang.org/std/iter/trait.Sum.html) fn sum&lt;I&gt;(iter: I) -&gt; Self where I: Iterator&lt;Item = A&gt;, What is `A` referring to here? Infact what is the `Item = A` syntax doing, or called?
You’re going in *a* (note, not *the*) right direction. Traits are a perfectly fine way to solve this problem, however I would opt for an enum instead of a trait and implementors of the trait: enum Shape { Circle { radius: f32, colour: Colour }, Rectangle { width: f32, height: f32, colour: Colour }, // ... } impl Shape { /* methods with matches inside */ } This approach still satisfies the requirement that you implement an abstract data type, while requiring significantly less code and possibly making it easier to solve all the sub-points of the task.
You're rather avoid code bloat than use hardware-supported operations?
Thank you.
I’m fairly confident KVM does not have/load any default firmware at all. SeaBIOS is a "default" which qemu – an interface to KVM (among other things) uses.
Whatever ``NaN`` you get back from the FPU can be normalized to a single ``NaN`` for the sake of avoiding annoying artifacts such as ``NaN != NaN``. That is all I am saying. Maybe you read too much into my post, regarding your love for that IEEE standard. I understand that it was probably cheaper to implement in hardware (at some point in time) to have operations map from one NaN to another instead of clamping it to 1 dedicated value. The second reason for that "feature" was indeed as you can read in many places, that back in the day people used it to debug the results of their programs, handed back to them on punch cards. Back then, when turnarounds were matters of days not seconds/minutes.
&gt; Whatever NaN you get back from the FPU can be normalized to a single NaN for the sake of avoiding annoying artifacts such as NaN != NaN. The payload is not the issue. Comparisons with `NaN` are required to be false, just like comparisons with `NULL` in SQL. Even if there was no payload to "normalize", `NaN == NaN` would still have been false.
Well, that depends on what you consider to be part of KVM. Yes, kvm.ko does not deal with firmware, but that's only part of KVM. I am mostly quoting https://www.seabios.org/.
If you had a `f32_never_NaN` then you could make a `Option&lt;f32_never_NaN&gt;` that's the same size as a `f32` (by informing the `Option` that a `NaN` signifies `None`. Similiar to `NonZero` types + `0`. That said, I don't think it'd be worth it at this point.
You can, but I floats already have `NaN`(s), which is where I was going with "some bits inside f32 that could be used to tag whether the value a a number". But of course, there is a difference: unlike `NaN`s, `None`s compare as equal.
&gt; Assuming your ``NAN`` is indeed one and only one of the possible ``NaN`` values! The payload is [irrelevant](https://github.com/llogiq/optional/blob/master/src/lib.rs#L1089-L1097).
For better or worse, /r/rust decided that they are not interested in blockchains. It is a pity, since Rust is very popular in blockchains. Feel free to come to /r/rustcryptofin instead, we welcome you.
No. What's your point?
If you have suggestions, maybe I can fill it in?
Well, it works perfectly fine without any warnings. So is this a bug? Should I report it?
restarting your terminal doesn't source your config on linux, that's done on login. Just run source \~/.profile or your bashrc depending on what was changed.
The programs that people were running on punch card machines were numerical calculations. Guess what? People doing numerical calculations on modern hardware do it with IEEE 754, too. `NaN != NaN` is a feature that we want for those calculations *today*.
You want /r/playrust. This sub is for the Rust programming language.
but why?
No I did not know the `Answer` enum and totally forgot that `!` is not in binary. But it is still used in for the macro notation and could certainly be adapted for this isn't it?
&gt;Given there are signaling and quiet \`\`NaN\`\` and signaling and non-signaling (comparison) operations with regard to \`\`NaN\`\`, where equality and inequality are quiet and the others (greater than etc.) are signaling, with flavors depending on if you use the 1980 version or the 2008 version of IEEE 754, I am now \*really\* and seriously and totally not cynically curious about the use cases where such a chaos can actually be useful. Please show me one or some for my enlightenment.
What is all this craziness about the difficulty in finding a hash function? Hash all NaNs to 5 is a perfectly acceptable hash function. The property that two values x and y may exist where x != y but hash(x) == hash(y) is fully legal and *expected* outside of perfect hashing. Sure, after inserting NaN into your set/map/whatever you'll never be able to get it out again, but the "problem" has to do with the equality definition, not the hashing.
I wouldn't disagree that the handling of signaling/quiet NaNs is a mess. But since this is the first time you've mentioned it, I'll just assume you're digging for a way to win an argument.
What's gained by writing the latter over the former with line breaks? The temporaries are just noise. I don't see how they clarify or emphasise anything further than a line break. fetch("thing") .await? .get("x") Chains like that are self-explanatory. If an obvious name for an intermediate comes to mind, I'll often assign it, but in cases where it's a choice between shadowing the previous local or naming it something like `thing_result`, `awaited_thing`, what's the point? It takes more time to read and it's misleading. `thing` is not simply a `thing` until you've unwrapped it. With prefix await you don't really have a choice but to assign a redundant local. With postfix you can if you want, but in cases like that it's clearer not to IMO.
Loving all the syntax discussion. It may seem like bikeshed to some, but stepping back a bit, it's great that folks care and are exploring different options in depth.
it's not a bug, because you told the compiler "I know what I'm doing" by using `unsafe`
You can find example here: https://github.com/Dushistov/rust_swig/blob/99076a633a7aabdd087f6437f1a0b7c4d973513b/macroslib/src/java_jni/jni-include.rs#L1337
I absolutely have! I'll take the **explicit** and obvious nature of defining a variable for an async result at the call site over trying to reduce lines of code with whizz-bang programming. And the static methods on `Task`, provide some convenience with more advanced use cases. Point being, when you look at C# async code you know exactly what is going on. Yes, some lines look a bit tedious when you have dependent tasks, but it doesn't hurt readability or the mental model of the code. With this `.await` operator I feel that it will hurt async code readability and also for some really awful chaining. The problem is that many programmers either pick up bad habits or create something when they think they are smarter than they really are. I just hope that stuff like `db.await.get_collection.await.get_user(...)` doesn't become the normal due to the possibility of chaining awaits.
If you look at doc page for the `Sum` trait, you see implementations listed like `impl Sum&lt;i32&gt; for i32`, where both the implementor of the trait and the type parameter match. The reason that you need to specify the type that `sum` has to return is that the two don't *have* to match! [This playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5d3c830fa0eb09afa730520842e0d582) has an example where we sum an iterator of `i32`s into a newtype. You could also implement it going the other way: an iterator of `MyInt`s summing to an `i32`. Because there *could* be multiple valid types that `sum` could return, you need to explicitly specify which you want. (If you look at the declaration, you can see that `A` is `Sum`'s type parameter. `Sum&lt;i32&gt;` requires an iterator of `i32`s to work, etc. Going backwards, calling `.sum()` on an iterator with an `Item` of `Foo` will search a type that implement `Sum&lt;Foo&gt;` that satisfies the type constraints.)
This is my first rust project for learning purpose, please don't hesitate to tell if you see any bad code or any better way to do something.
Make sure to check with whomever is grading your assignments, because they might expect you to use Traits, even though an enum might be a perfectly fine solution. The comment in your code makes it look like you want to know how to calculate the area of a rectangle, but surely you know that? What exactly are you having trouble with, then?
&gt; Infact, what is the Item = A syntax doing, or called? They are called associated types.
I was having trouble with syntax but I've been able to work it out. This is my first experience writing something in Rust.
&gt; nobody has anything better https://en.wikipedia.org/wiki/Unum_(number_format)#Type_III_Unum_-_Posit https://www.youtube.com/watch?v=aP0Y1uAA-2Y
The docs are probably very many very small files, which generally takes ages to download and also explains why having an anti-virus present slows installation to a crawl (they want to parse every file).
Lets stay on the non-personal level, please. For me - and I also did numerics for several years as well as embedded developments for over a decade, a ``NaN`` is just an error value. And if someone wanted me to accept code which prides itself that the ``NaN`` which shows up mid-computation eventually goes away because ``pow(NaN,0.0)`` reifies to 1.0, I would have a certain facial expression and turn away. Also, take into account that the ``is_signaling()`` or ``is_quiet()`` meaning of the uppermost bit of the significand or a ``NaN`` is used differently (opposite) on different hardware architectures (e.g. old MIPS MCU vs the others I know of). Just imagine, Elon Musk builds his Mars rocket with an old MIPS MCU (old MCU are not as susceptible to cosmic radiation due to bigger structures) and some IEEE 754 binary value is transmitted from a MIPS to another CPU in that rocket and suddenly THE SAME code behaves differently on either side of the network for THE SAME value. One excepts the other does not. Bye bye millions, poor Elon ;) So my view is that it should be nothing more than an error value and nothing else. And if it was me, there would not be any silent NaN at all, resulting in fewer tests, fewer rules, fewer bugs, fewer surprises and a better world. That is what we want, right?
Well you seemed to have gotten it right for Circle, so why not copy that and change how the area is computed? But don't worry, everyone has had those hangups where even the simplest thing fails to work for some reason or another :)
&gt; But u32 doesn't implement `Sum&lt;Self::Item&gt;` Sure it does. From the `Sum` docs (if we accept that `Self::Item` is `u32` here): impl Sum&lt;u32&gt; for u32 &gt; What is `A` referring to here? The `Sum` trait is declared as follows; this is where the `A` comes from: pub trait Sum&lt;A = Self&gt; The semantic meaning of this is: "You can turn an iterator that yields `A`s (`Iterator&lt;Item = A`) into the type the trait `Sum&lt;A&gt;` is implemented for; by default `A` is that same type." The `sum` function on `Iterator`s specifies that generic type parameter `A`: fn sum&lt;S&gt;(self) -&gt; S where S: Sum&lt;Self::Item&gt;, So that you can call `sum` on any iterator that yields types that can be `Sum`-med up into some other type. This also explains why type annotations are needed: You can create your own type that can be created from an iterator of `u32`: struct MyStruct; use std::iter::Sum; impl Sum&lt;u32&gt; for MyStruct { fn sum&lt;I&gt;(iter: I) -&gt; MyStruct { MyStruct } }
So we can all vote "no strong opinion" and move on with our lives while you guys make awesome stuff :)
The borrowchecker is not affected by unsafe-blocks. It should recognize that this pointer is now owned by the box
Pointers are [Copy](https://doc.rust-lang.org/std/primitive.pointer.html#impl-Copy) so there's no way for `Box::from_raw` to take ownership of the value. This is the kind of thing that lifetimes and ownership are meant to guard against, but by using raw pointers and `unsafe`, you're explicitly opting out of those protections.
So it will be clear almost 40% support `fut.await` and other 30% are fine with it. ;)
What about a cargo build tool that changes prefix syntax to postfix prior to compilation?
&gt; Also what's the folding issue of skeletal strokes? Take a look at this paper: [Asente: *Folding Avoidance in Skeletal Strokes*, 2010](https://dl.acm.org/citation.cfm?id=1923363.1923370). It describes both the problem and a solution for most cases.
It's still new. It's not like the old website sprung fully formed with translation support. Not did it have a particularly active community of contributions, it was just around long enough. People have stated elsewhere that translation support is something the new website was designed to be good at -- with the old website you would just replicate everything without any proper internationalization framework which doesn't work at all in the long run. The new website makes it possible to integrate such a framework and there are stale WIP PRs to make this happen. Someone needs to push that over the finish line, i guess.
We don't really need multiple NaN values. I'm not arguing that. I'm pointing out that (1) we need hardware supported arithmetical operations and (2) we want `NaN != NaN`. That means we get IEEE 754. if you want something else, you need to do more than whine about it. You need to convince hardware manufacturers that something else is better.
Nice! I'd recommend copying all the crate docs into your README so we can see what it's about on crates.io
&gt; of course you cannot use a f32/f64 as key in a std::collections::HashMap&lt;K,V&gt; Even if not for NaNs, it would still not be a good idea. You should [almost] never rely on floats being exactly the same, especially in hashmaps, hence in this context it would have been still better to use a newtype that compares floats with an acceptable precision (e.g. epsilon).
Reminds me of an old pair of projects of mine: &amp;#x200B; [https://github.com/felixrabe-attic/mcrio--smal/blob/master/test/index.coffee#L212](https://github.com/felixrabe-attic/mcrio--smal/blob/master/test/index.coffee#L212) [https://github.com/felixrabe-attic/mcrio--smal-html/blob/master/test/index.coffee#L41](https://github.com/felixrabe-attic/mcrio--smal-html/blob/master/test/index.coffee#L41) &amp;#x200B; (Do not use, they use outdated and vulnerable dependencies.)
"Better" is arguable. This makes different trade-offs, but it doesn't seem clear that it has made better ones than IEEE 754.
I think the Rust ecosystem is leaning towards optional sans-IO via the std / no_std feature flags.
When your typical PC turns on, there are a few steps that must be taken before your OS (Linux/Windows) takes over. As a simplification lets think of it like this FIRMWARE -&gt; BOOT LOADER -&gt; OS. The firmware is typically baked into your motherboard, it is very low level. It knows enough to find a boot loader contained on hard disk or USB key etc.. and pass over control. The boot-loader (say Grub2) then does its thing to automatically find and start the operating system. Sometimes the boot-loader will first provide a menu of options so you can choose operating system you want to start etc... Anyway, The firmware posted above, is meant to take over this very basic first step and do everything a real computer would do to start a boot loader, but in the context of a virtual machine rather than a real PC. So for instance, if you had a real hard drive that worked perfectly in a real computer. You could boot that exact same disk inside a VM. This Rust firmware will know enough to access that disk, find the boot-loader, and pass it control.
Here's the postgres extensions in Rust video: [https://watch.cloudflarestream.com/91ff72819852fa9665fa5ac0b52a9834](https://watch.cloudflarestream.com/91ff72819852fa9665fa5ac0b52a9834) The tokio from epoll up will be a few more days.
&gt; unsettlingly C based implementations libc, especially well established ones, are not your typical C projects. You might as well ask first for an LLVM replacement, if legacy languages bother you in all places :)
Absolutely right
Was it mostly for html/xml? I'm glad you caught that crlf blunder I'd made... I must now announce version wood version 0.4 ._.
As a compromise between the prefix and postfix crowds I propose a new syntax inspired by ALGOL 68: (await future?)?.foo() becomes await future? tiawa?.foo() People who prefer the postfix syntax can just ignore the leading 'await' and look for 'tiawa' to signal a future being await-ed, whereas people who prefer prefix syntax can do the reverse. Also note that parentheses are not needed to disambiguate complex chains/nestings of futures, which will hopefully scare away LISP programmers (this is not strictly a requirement for await syntax but is nice to have).
You already got an answer, but just so you know, you can see which libraries are linked in your executable using `readelf` on Linux. Just compile a hello world binary and look for a section of the `readelf` output that lists the linked libraries.
[removed]
Thanks for the response. I googled raspberry pi specific stuff and got pretty far with [this](https://hackernoon.com/compiling-rust-for-the-raspberry-pi-49fdcd7df658). Now, the error is `note: /usr/lib/libsqlite3.so: file not recognized: file format not recognized`. I installed `lib32-sqlite` and `libsqlite3.so` exists in `/usr/lib32`. How do I point the linker to the 32 bit version and not the one that is throwing the error?
using \`$ ldd executable\` is easier.
AFAICT, the only issue with `await` is that they haven't picked a syntax so everyone is going on and on and on about it, rather than spending that effort to figure out how to use it to make great software. Whoever uses await to do great things will not have the syntax to blame for it.
I haven't tested it, but I believe locks should work in the "intuitive" fashion: ```rust { let lock = foo.lock(); // lock will continue to be held during the await some_operation().await; // lock is still held } // lock is finally dropped ``` Basically, locking across an await should work the same as locking across a function call. If you don't want that, you need to explicitly drop the locks before awaiting.
You can kind of already do that, since the `block_on` function exists: ```rust // cooperative scheduling foo().await; // preemptive scheduling block_on(foo()); ``` So I guess you'd just need to change all blocking functions to return Futures, and then `block_on` would be the only blocking function.
A good place to start would be defining what this "core axiom" is. I had a browse through the repository and it just looks like you're introducing a weird syntax to describe some already proven mathematical results, but I can't see any examples of your "path semantics" actually being used to prove anything itself. It's not at all clear what your syntax even means or what rules you can use to derive new results. And then you have things like [this](https://github.com/advancedresearch/path_semantics/blob/master/papers-wip/history-of-path-semantics-illustrated.pdf) which probably belong on /r/iamverysmart. I don't mean to sound so critical but I'm having a hard time taking this seriously. If you actually have something worth showing here then you need to do a better job of communicating what it is.
I'd rather you rewarded 200 USD to find somebody who can succinctly explain your ideas and why an average computer scientist, mathematician, or programmer should really care. A bunch of blog posts doesn't seem like a great way to communicate a mathematical formalism.
The lib32s you're installing are for x86. They will not work on your pi, at least following that tutorial. You'll need to use `-sys` packages which are prepared to obtain source themselves (whether vended or fetched; doesn't matter) and also prepared to cross compile. Or you'll need to fetch and cross compile those dependencies yourself - you've already done the hard part of setting up the toolchain! - but tbh I'm not sure how to point cargo to those to link (because I don't follow my own advice and instead run the linker myself, but I've got a special case). You might try posting here or stackoverflow with that question which should be a lot easier to answer.
I don't think you need 3 copies of the clients arc, just 2 should be fine i think.
There is no await chaining in the example above. There's only one `await` call. &gt; await? isn't usable in this example. `map_err` applied to future [returns another future](https://docs.rs/futures/0.1.27/futures/future/trait.Future.html#method.map_err). `await?` works fine.
What is the relevance of this to /r/rust?
I have to say I'm not a fan of implicit awaits; I can definitely see a situation where I have an async function but I want to create a bunch of futures without running them immediately. A solution like this would make async functions strictly less expressive and substantially more surprising.
This uninitialized warning was hilarious [https://i.imgur.com/gZQ7jRM.png](https://i.imgur.com/gZQ7jRM.png)
Thanks for the tips.
I don't understand what I'm looking at here. It seems like if you want to be published, you need to do the work of seeking out experts and putting your work in front of them, rather than assuming a paper will discover you and do everything for you
Have a look at [jni-rs](https://github.com/jni-rs/jni-rs)'s [VM test](https://github.com/jni-rs/jni-rs/blob/master/tests/vm.rs). It does this via the JavaVM API.
&gt; Someone needs to push that over the finish line, i guess. Given how poorly the site is now maintained and how poorly contributors are treated, I wont hold my breath.
I prefer to Box::leak and hold the same reference everywhere
Nice!! I did this project a few months ago ([image/wallpaper](https://i.imgur.com/MEPt6YZ.jpg)) in Rust as well. This was my first time ever doing anything in the field. It was an exciting experience to see an extremely precise world come together out of a few simple vector operations. For anyone interested in this sort of thing, I highly recommend [the book](http://www.realtimerendering.com/raytracing/Ray%20Tracing%20in%20a%20Weekend.pdf) (even if it's a bit rough around the edges). Your code organization is nice! Impressive that this is your first Rust project. One feature that I ended up adding was parallelization. There are several ways to go about this, such as splitting up sampling (suggested on the book's final page) or splitting up pixels (what I went with). Either way, maybe this is could be good practice for you? Rust offers a unique (safe!) approach to multi-threading that you might want to familiarize yourself with. Great work! :)
LLVM does bother me. One practical problem is that LLVM can't compile functions in parallel. You can do that in C++, but C++ makes it hard to migrate from single thread to multi thread, and LLVM started as single thread codebase. Fortunately, there will be an option to replace LLVM with Cranelift for Rust in 2019. Cranelift can compile functions in parallel.
Two things: - In Python you use a different syntax for ranged indexing, e.g. `list[start:end:step]`. Rust resolves that inconsistency between `range(start, end)` and `list[start:end]` by making them both `start..end` and `list[start..end]`. (Yeah, Rust doesn’t support step very well.) - Due to Rust’s type system, `..`, `start..`, `..end` and `start..end` are all of different types, so you couldn’t have just a single function like Python’s `range`; you’d need it to be a macro instead.
I'd honestly be fine with a macro.
Can you provide a historical example of what a demonstration of "unsoundness of an axiom" might look like?
I've spent an hour trying to make sense out of it (task successfully failed by the way). From what I was able to comprehend: it's an informal system (what it has to do with math then?), a language for talking about functions. Anyways, it's a fallacy on a fallacy on a pseudophilosophical reasoning (c'mon, guy quotes himself as an epigraph, ~~powerful tool of thinking my ass~~).
Ok for ewryone that have same problme i think i have solution in unix system in my case ubuntu 14.04LTS in home folder where .cargo folder lives with env variables and installed global crates this error comes biqas not sufficient read and write permissions so my hack to bypass this problem i just sudo chmod -R 777 .cargo/ and it worked like a charm ;) in windows permissions too you can make in folder in your windows system where cargo folder lives itself. I don't know if this solution best but for me when i was stuck with this kind warning and always falling download crates from cartes.io this current solution like good charm are :D
Three (probably not very good) alternatives i can think of: 1. `defer{ join_all(producefut(), producefut()); }.await()` 2. join_all!(futures...) macro that does the above if you instantiate the 'future' inside the macro (not sure this is possible or even if it is, it's too surprising) 3. `join_all(|| producefuc(), || producefut());`. Not sure if 0-cost 4. producefuc is marked 'defer', which is good when the future is obviously going to be composed right away, annoying if not. These first 3 ideas all have the problem that such a small 'real estate' will probably not make them popular on the complicated cases. I expect that if implicit await was adopted, the 4th and other free-form defer blocks would tend to be used when combinators entered the picture.
This actually exists!... In Java https://docs.oracle.com/javase/7/docs/technotes/guides/security/permissions.html It's existed since the beginning of the JVM, but nobody ever wants to restrict themselves to a subset of features, so it remains largely unused.
Soundness just means that all statements provable within the system are true semantically. Usually "soundness" is used to refer to a logical system as a whole rather than just a particular axiom (the reason being that a logical system can be unsound even if all the axioms are true), but I assume OP means it as one of the axioms not being a tautology. The problem is that OP hasn't actually said (at least not anywhere I can find) what the "core axiom" is, which makes it rather difficult to prove or disprove. One might think OP is just throwing buzzwords around to try and intimidate people who are skeptical about their work.
Truth. `ld`, it’s just that I’m AFK for a few days.
The fact that you can do all this is precisely why working with raw pointers is unsafe. There aren't any restrictions on copying them around or using them after they're moved or freed. They're "just numbers". Sometimes you need these sorts of superpowers, like to implement Vec. But as you're seeing here, it's easy to abuse them to do things you shouldn't, leading to undefined behavior and crashes.
URL request doesn’t work in code ... test in your browser?? Is your localhost responding?? Try a known URL in the code?? I’m not a Rust specialist in this area... but break it all down to the fundamentals as this stuff should be deterministic if everything is ‘turned on’ and the library documentation says that it does what you are attempting to do. Else complain to the devs or open up the lib and implement it to work.
I believe that you want to write \`let url = format!("http://localhost/register.php?name={}",user);\` . (Notice that you're missing \`format!\`)
There's actually quite a bit of interest in Rust at Intel, especially with the open source teams, and including those working on firmware.
Gentoo seems to have some people working on building the world with relibc instead of musl / glibc. Which is a perfect way of perfect Redox's libc compatibility.
Such a simple fix. Thank you!
Posits are more accurate, algebraically correct and portable, which in turn makes them `Eq`-able. The only downside is no hardware support. I'm not sure what you mean by "different trade-offs".
Yeah, that's kind of what I'm getting at. Without knowing exactly where the "goalposts" are, this is a pretty pointless exercise. Put even less charitably, any sufficiently incoherent proposition is naturally immune to disproof. :)
Since Rust natively supports Unicode and respects short keywords, I therefore propose to use 等待 instead of \`await\`. We may even abbreviate it to 待.
Exactly. What if you are writing Rust FFI bindings to an external library which happens to make use of the filesystem, network, etc. without being accounted for in the `Cargo.toml`? If you can't fully trust and audit the permissions defined in the `Cargo.toml` , then there is little point in having it.
Why is this a pit of insanity? I'm really curious now.
I've also done an implementation based Shirley's book. It's interesting to see how someone else have gone about doing the same thing. I only took a quick look, but it looks great. I like the examples you did.
I'm not sure if this is exactly what you're looking for but [Jon Gjengset's YouTube channel](https://www.youtube.com/channel/UC_iD0xppBwwsrM9DegC5cQQ/videos) has lots of great long-form videos on Rust that are really good.
y tho
Whew. Close one.
yeah wow, this is definitely a different way of thinking than I'm used to. Thanks. Will digest
A less safe and slightly smaller version of Rust enums.
The problems with NaNs were one of the major reasons why Posits were designed. The most active Rust implementation seems to be https://gitlab.com/burrbull/softposit-rs Being nonstandard and with little, if not no, hardware support aside, it has 1 non-finite value. The fact that said value is +-infinity means that it still doesn't have a total order, but it at least supports `Eq`, and doesn't have 16 million wasted values.
So a rough equivalent to PyPI allowing binary wheels to be distributed?
I came to Rust from Ruby because of the performance improvement seen in Deliveroo's system. This is great news.
&gt; Put even less charitably, any sufficiently incoherent proposition is naturally immune to disproof. :) Or, more concisely, [not even wrong](https://rationalwiki.org/wiki/Not_even_wrong).
No, Ruby gems work just like Cargo in that they can compile their code if necessary. There's already loads of Gems that have C code in them that gets compiled as you install the gem. As far as I'm aware it's not allowed to publish binaries on Rubygems. Or at least no one is doing it. This would allow people to write Ruby gems in Rust, and publish them. Then any regular Ruby user could install a gem dependency that has Rust in it, and it would be automatically compiled, without them having any knowledge of Rust besides that it was a platform dependency of the gem.
I'm almost sure you could improve IEEE 754 by only having the mantissa and exponent fields, and letting the signals be represented like they are in integers. No signal field, no nans, only horrible overflows.
NaN != NaN is the spec. Even if they have the same binary representation. If you change that, you're changing the spec.
Rust libraries for automated theorem proving, of course!
- Paradoxes - `A &amp;&amp; not(A)` - False as assumption - An attempted axiom of logic which are proven inconsistent with established theories of logic
Definitely interesting! Subscribed! Thank you
All that says is that every NaN state should be treated as NaN and you should not derive meaning from the individual states if you don't want to lock yourself to one specific implementation of the standard. You can complain it is a horrible waste of representation space, but barely anyone try to pry their NaN's open to see which NaN they got.
Link to foundation: https://github.com/advancedresearch/path_semantics/blob/master/sequences.md#foundation
Notice that many consider the situation as the following (one true proposition of two): A: Path Semantics is garbage, the author is throwing buzzwords B: Path Semantics is interesting I never claimed to have discovered something new. There are some things I don't know are new or not, but this can't be confirmed before I find a way to publish it. However, the reason I have been working on this is because I've corresponded with Dr. Jim Gates who developed Adinkra diagrams for theoretical physics. This was before Rust. I thought that these diagrams could describe more mathematics if they were generalized, which I did. Later I found out that this kind of diagram correspond to a certain kind of equations, which can be written with an easier to use syntax. My goal the whole time has been to integrate this into existing body of knowledge in mathematics. I think that people who believe A) might be underestimating what probability other people believe B), and if they won't take up the challenge, then I think it shows that there is no point in having a further argument. You have just chosen a side and that's it. You have not really made an argument of any kind. I am starting to believe that nothing I write or do can ever convince you otherwise. I have tried the best I can to help people here, and despite harassment I have never said a cruel word to anyone of them.
Can you give en ELI5 explanation on what path semantics are?
Here is a short non-ELI5: Path semantics builds on the intuition of Homotopy Type Theory to provide a foundation for informal theorem proving about functions as they are used in programming. Here is an ELI5: Symbols are used in a way that you can write down as a definition. This definition is part precisely defined and part vague. The vague part is because you can construct infinite sentences with language. Using the definition, one can show that Boolean Algebra, a theory used in logic and computer programming, can be defined. From there, new definitions and more powerful abstractions can be built, but each new definition requires testing against the way symbols are used.
Wait, Deliveroo have moved to rust? I assume they have a fair bit of Ruby but interesting if that's the direction their going.
This is how you might find unsoundness in the axiom of path semantics: Path semantics can model logic, but logic can not model path semantics. If the logic modeled by path semantics is not isomorphic to traditional logic, then the axiom of path semantics is unsound.
They are using Rust as an extension so not migrating away 100% yet I think. I didn't like where they were going with their services but that's besides the point lol. It's still interesting to read about. Here's the (article) [http://deliveroo.engineering/2019/02/14/moving-from-ruby-to-rust.html]
Thanks, yeah very interesting.
Looks very nice!
Hardware engineers are notably conservative because creating hardware is expensive, and once shipped it's there for years. I am quite interested in unums, however it's very early still. There were already 3 iterations of Unums in as many years; on the one hand this proves that the author is responsive to criticisms, which is great, on the other it clearly indicates that unums are just immature right now. In a few years, once more researchers have had time to investigate their pros/cons, they may become more mainstream.
The discussion is over. The people down-voting are not producing any further arguments of substance. Either you learn a bit path semantics or you don't. It's totally up to you, and I don't care. I just want to show it to people who might be interested.
Link to wikipedia article about soundness: https://en.wikipedia.org/wiki/Soundness Notice that people making the claim that I misunderstand what soundness is, actually are thinking about soundness of logic, which is different from that of path semantics. Path semantics can model logic, but not vice versa, so if you can use logic to show something that's wrong in path semantics, then according to path semantics that should be a paradox. Hence, unsound. On the other hand, I think that people knowing enough math to recognize Leibniz' law, realize that this is likely a futile attempt, even if the axiom of path semantics is partially vague. The rest is just misunderstanding what informal theorem proving is. Under informal theorem proving, like done in traditional mathematics, you are allowed to use formal languages to prove things. However, no formal language can not use all formal languages, so informal theorem is strictly more powerful than formal theorem proving. Informal theorem proving is interpreted semantically in path semantics as the existence of functions and their "normal paths", which makes it possible to talk about the informal theorem process through mathematics. This means that parts of it can be automatically checked. Hence, the "bootstrapping procedure" is not contradicting path semantics, because it can be checked later, according to the axiom.
Cool stuff!
Thank you! This is my first time to write something in rust, and I like the language very much :)
This is a compiliation error, so it has nothing to do with network connectivity.
Thank you for your good words. Parallelization is the next thing I will add. Thank you for advice.
I first encountered this 'advanced research' project a few years ago while investigating piston and it instantly convinced me that piston wasn't for me. I have some experience reading actual academic papers and after reading some of the 'advanced research' pdfs I still had no idea what it was about, except that the author thinks very highly of himself. Maybe I am just too dumb to understand it all, or perhaps Sven isn't very good at putting their ideas into words in a way that others can grasp... but the whole thing screams crackpot to me.
Thanks :)
I've updated the reward to include showing convincingly that it's "not even wrong". Show. Me. Some. Real. Argument.
Downvotes are not arguments.
I fail to see anything wrong with that example chained call. Lots of explicit awaits throughout so you can see exactly what's going on and yet it's not littered with parents or unnecessary locals that you need to find meaningful names for. Looks to me like a significant improvement on C#.
Partial solution found: Serde. I simply pass the equations, variables, and working solution from JavaScript to Rust via Serde. Then I do not have to worry about ownership and do not have to fuss with static variables. FWIW, here is my aborted static refactor (abridged). I stopped when RLS informed me that "allocations are not allowed in statics" #[macro_use] extern crate log; extern crate regex; extern crate unicode_segmentation; mod calculator; mod infix; mod prefix; use std::collections::HashMap; static mut equation: Vec&lt;calculator::Cell&gt; = vec![]; //Vec::&lt;calculator::Cell&gt;::new(); // static mut equation: Vec&lt;calculator::Cell&gt; = Vec::&lt;calculator::Cell&gt;::new(); static mut variables: HashMap&lt;String, f64&gt; = HashMap::&lt;String, f64&gt;::new(); pub fn calc(infix_notation: &amp;str) -&gt; String { ... unsafe{variables.insert(k, v)}; ... }
F F I i n g
Indeed.
You may want to have a look at the j4rs crate https://github.com/astonbitecode/j4rs
I have finally created my first embedded rust program which runs on my stm32f407 disco board. However, the process was a little difficult for me - lots of differences in how the peripherals API needs to be used, and some of the examples I found didn't compile. Anyway, I ended up with this suboptimal blinky: [https://gist.github.com/barafael/e6138e18a6a7c8c18d37d357e5a4b2a3](https://gist.github.com/barafael/e6138e18a6a7c8c18d37d357e5a4b2a3) &amp;#x200B; Suboptimal because: * It uses a deprecated function (toggle) * that delay function (couldn't figure out how to construct a Delay) * Probably more My question is, where do I find out how to do this? Most crate documentation is rather lacking (hence I could not find how to construct a Delay) and I don't feel like reading source code to blink an LED (though I'd probably learn something).
Again, back to the first argument that `.await` appears to be field access. It is not and that’s adding confusion and reducing the potential readability of clean code. The first can be fixed with documentation of course, but the second isn’t that simple. As someone coming from other strict languages who now lives in JavaScript (Node), there are many things I despise about JS because it *allows* the programmer to be quite sloppy. Rust is the polar opposite of that. Random globals are one thing I dislike about JS as well. You require other builtins like `fs`, `os`, `path` but some things like `Promise` are already in the global scope. Then you have the magical `arguments` var that’s available in every function which acts as a raw argv psuedo-array, again unbeknownst to many. Point being, stuff like that adds to confusion and feels hacky. And while the await chaining in Rust does look useful in some cases it makes me leery that we’re allowing for some pretty poor practices to develop when the rest of the language really does not.
Just beware that in c, and so also in rust, it's possible to statically link against libc. When you do that though, libc won't show up in `ldd`, but when you do certain things, like maybe requiring PAM, or resolving a domain, it might dynamically load libraries.
Is that when using async/await? Combinators kinda force you to chain, even when it would be nicer not to.
just as a follow up to this, is there a way to inspect more information about the types i am producing from these sorts of expressions: let fish1 : () = (1..).map(|i| 1); let fish2 : () = (1..).map(|i| String::from("")); let fish3 : () = (1..).map(|i| {(i, i)}); The unit assignment is done deliberately as discussed to provoke the compiler, but the compiler sees these expressions as all the same type - they are all `std::iter::Map&lt;std::ops::RangeFrom&lt;{integer}&gt;` ? error[E0308]: mismatched types --&gt; src\lib.rs:4:20 | 4 | let fish1 : () = (1..).map(|i| 1); | ^^^^^^^^^^^^^^^^ expected (), found struct `std::iter::Map` | = note: expected type `()` found type `std::iter::Map&lt;std::ops::RangeFrom&lt;{integer}&gt;, [closure@src\lib.rs:4:30: 4:35]&gt;` error[E0308]: mismatched types --&gt; src\lib.rs:5:20 | 5 | let fish2 : () = (1..).map(|i| String::from("")); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected (), found struct `std::iter::Map` | = note: expected type `()` found type `std::iter::Map&lt;std::ops::RangeFrom&lt;{integer}&gt;, [closure@src\lib.rs:5:30: 5:50]&gt;` error[E0308]: mismatched types --&gt; src\lib.rs:6:20 | 6 | let fish3 : () = (1..).map(|i| {(i, i)}); | ^^^^^^^^^^^^^^^^^^^^^^^ expected (), found struct `std::iter::Map` | = note: expected type `()` found type `std::iter::Map&lt;std::ops::RangeFrom&lt;{integer}&gt;, [closure@src\lib.rs:6:30: 6:42]&gt;` I mean I guess maybe they are and this is exposing yet another atrocious deficiency in my thinking. I guess I was hoping to understand what the hell monster tuple I might I might have constructed from doing this sort of thing? Like I was hoping for something that tells me fish1 produces a int32 sequence, fish2 produces a String sequence, fish3 is producing a tuple&lt;int32, int32&gt; sequence. (Not sure if I'm once again so badly misunderstanding things what I'm looking for has no meaning)
Finding a hash function isn't the issue, using it is. HashMap (any many other users of Hash) requires that the key implement Eq. And the Eq trait requires that the equals operator is reflexive, ie that x==x for all x. That isn't true for NaN.
There may be better abstractions for this, but generally delays are created using the on-board timers (TIMx), which will generate interrupts. The LEDs are enabled by simply setting a bit that is memory-mapped to the LED's GPIO, so a toggle would probably do nothing more than read the bit and write it back flipped.
I have a question on Rust + WASM + GitHub pages. I've been really liking Rust, but I've been confused on the process on how to compile to WebAssembly and deploy it on a simple GitHub page. My understanding of WASM is that I should be able to compile a Rust program into a .wasm file, and simply link to it. However all of the guides I've looked at (using wasm-pack) require using webpack and npm and installing dozens of npm modules. Is this the way that it's done, or is there a way to simply compile to a .wasm and be done with it?
IIRC jni-rs is used by the Parity client for Ethereum: [https://github.com/paritytech/parity-ethereum](https://github.com/paritytech/parity-ethereum)
The thing that you're missing is that they're not `std::iter::Map&lt;std::ops::RangeFrom&lt;{integer}&gt;&gt;` but `std::iter::Map&lt;std::ops::RangeFrom&lt;{integer}&gt;, [closure@src\lib.rs:6:30: 6:42]&gt;` - `Map` takes two type parameters: the underlying iterator it's working on, and the type of the function it's applying to each element. Unfortunately, the types of closures are literally unnameable. If we use a named function instead of a closure: fn tupleize(i: i32) -&gt; (i32, i32) { (i, i) } let fish3: () = (1..).map(tupleize); we see an error message of | 5 | let fish3: () = (1..).map(tupleize); | ^^^^^^^^^^^^^^^^^^^ expected (), found struct `std::iter::Map` | = note: expected type `()` found type `std::iter::Map&lt;std::ops::RangeFrom&lt;i32&gt;, fn(i32) -&gt; (i32, i32) {main::tupleize}&gt;` If we use a trait object instead, we can even do it with a closure: let tupleize: &amp;Fn(i32) -&gt; (i32, i32) = &amp;|i| (i, i); let fish3: () = (1..).map(tupleize); has an error message of | 3 | let fish3: () = (1..).map(tupleize); | ^^^^^^^^^^^^^^^^^^^ expected (), found struct `std::iter::Map` | = note: expected type `()` found type `std::iter::Map&lt;std::ops::RangeFrom&lt;i32&gt;, &amp;dyn std::ops::Fn(i32) -&gt; (i32, i32)&gt;` I suspect this doesn't help you too much in answering the question that you want (i.e. how can I tell the `Item` associated type for this iterator expression), but will hopefully make clear why you weren't seeing anything useful in the error messages. (If you do want to learn what type will be returned by the iterator, you could try something like `let fish3: () = (1..).map(|i| (i, i)).next();`, which will tell you that it's iterating over `({integer}, {integer})`.)
I've never wrote any Lua, but one of the complaints was that it uses `setjmp` and `longjmp` for exceptions, which doesn't play well with `Drop` / destructors.
&gt;semanticsemiotics with Rust HTML one can generate it with loops and other conditions with added benifit of Type safety ; i am planing on to encapsulate such HTML in my own classes and use those in conjunction with Stdweb and thus make JS Obsolete
Speed, obviously.
Hmm, instead of the useless placeholder `[closure@src\lib.rs:6:30: 6:42]` the type of the closure could be reported in terms of what Fn* trait it implements.
I see I'm not the only one who suggested posits. The most maintained Rust implementation that I can find would be https://gitlab.com/burrbull/softposit-rs.
I'm sure you do. Rust is a programming language. https://www.rust-lang.org/
You should look for `loop` and `match` in the [Rust book](https://doc.rust-lang.org/book/).
This would be better posted in r/playrust. This sub is for the programming language. If you're into programming I'd recommend learning it! It's great fun
/r/lostredditors
 let command = Command::new(...); match command.spawn() { Ok(_) =&gt; {...} Err(err) =&gt; {...} }
I guess we need a simple Rust test that you've to pass in order to submit any content
Unwrap and expect (and panicking, which they cause) are meant to be used for situations where things go *catastrophically wrong*. By that I mean an error condition that the programmer didn't expect to happen (i.e. a consequence of a bug) or an error condition that is so bad that it doesn't make sense to continue running the program. In this case, it seems that you have in mind a way to handle that error; by recalling the main function. That means that panicking is not an appropriate way to do error handling in this situation. You should look into the `match` command, `Result` type, `Error` trait and `?` operator. Check this chapter of The Book about error handling: https://doc.rust-lang.org/book/second-edition/ch09-00-error-handling.html Studying these things should help you forward!
I would love to use rust for microservice. Can anyone speak to any of the following (which I have in Java but would love to see in rust!): - easy metrics (pref as a macro above functions for many easy things like perf and exception tracking or in this case result tracking) - circuit breakers and transparent retry (as a macro? Like resilience4j) - zipkin integration (here for completeness, I can Google for it)
It somehow seems appropriate that of all the topics under discussion, it's async/await which has resulted in so much unnecessary polling.
Wrong subreddit r/playrust
Is your intent to copy the .exe to the startup dir when you run the .exe? And if it that is your intent, where are you invoking it from and how/with what? &amp;#x200B; Because if test.exe is in the normal place after compilation, i.e. {crateroot}/target/{debug|release}/test.exe and you run the program with e.g. cargo run from the crate root, then your **present working directory** for the executable is the crate root and not the subfolder of ./target &amp;#x200B; Also, is there an error message when you run the executable or does it just fail silently?
Yes, I think I used it for quickly prototyping some websites.
It fails silently and I'm running the program from debug.
From a cursory glance at the docs of std::fs::copy it copies **from file to file**, so maybe try appending "\\\\test.exe" to the destination string?
What is a a static HTTP server? I see 2 possibilities: 1. A HTTP server which only serves static files 2. A HTTP server which only uses statically allocated memory &amp;#x200B; From the content of the blog post I guess it's 1) But you might want to precise that, since "static HTTP" is not really all well defined term.
Good points all around. &gt; This kind of constraint makes much more sense in the domain of an operating system, IMO. OpenBSD's pledge(2) is a good example: https://man.openbsd.org/pledge.2 &gt;What's the threat model here? Deliberate alteration of a dependency or defects which might be exploited by an attacker? Not trying to reiterate what you've said, but this tool would presumably catch say an image decoding crate that's been compromised suddenly using `std::fs` and `std::net` (say to read SSH keys and send them back to a C2). If you've made it this far though, just include a build.rs script that generates the code at compile-time and suddenly this becomes a cat-and-mouse game of figuring out how to bypass the static analysis tooling. &gt;IMO there's utility in having a `cargo audit-scope` that would walk the dependency tree to determine which of these categories are present in your resulting binary. I agree. This project is a good idea, but I'm afraid that you can't effectively meet these security guarantees without introducing a restricted mode into the compiler itself. As you said, using it as a way to see what resources (fs/net/whatever) a crate uses is a good general idea.
&gt;(even if it’s rough around the edges) Pun intended?
Your answer alone makes the effort and time of my little article worth it. I had not been aware of Posits up until now. Thanks a lot for the input. I learned something!
I just started learning test in Rust and it feels very straight forward. I wish the book described it without using a crate as a starting point but I figured it out in 10 minutes of asking questions on the rust discord.
Usually when you move a file, you don't copy all the bytes to a new location. You just rename the file to a new location instead. [https://doc.rust-lang.org/std/fs/fn.rename.html](https://doc.rust-lang.org/std/fs/fn.rename.html)
Try /r/playrust maybe?
This reddit is for the programming language, for the game you have /r/playrust. I assume they'll want more info than just a video of the loading bar to help you, tho.
https://rustwasm.github.io/wasm-bindgen/examples/without-a-bundler.html shows you how to use a .wasm without webpack
`unwrap()` and `expect()` are meant to be used in situations where you either know the result will never be an error or when you're just testing code and don't care about it. Expect is a nicer version of unwrap because it lets you put a message there for you to know what happened there. In a normal situation, where you want to manage the error if and when it happens, you want to use `match`, which would look somewhat like this: let res = Command::new(response\_text).spawn(); match res { Ok(\_) =&gt; { /* Nothing to do here */ }, Err(e) =&gt; { println!("Ooops, something happened!"); }, } // OR if let, since you only care about the Err: let res = Command::new(response\_text).spawn(); if let Err(e) = res { println!("Ooops, something happened!"); }
Ahh, the (about) monthly r/lostRedditors... One of the crucial reasons I am subscribed to r/rust. Thanks for making my day pal! 😂
There are misposts at least every second day. It's just that one of us mods remove them within few hours or even minutes.
Why? I love those!
Just revisited this, seems like enums make more sense for this assignment. Thank you very much.
The point is that it seems that one of the chief justifications for breaking all syntactical expectations is to enable things like chaining. I'm arguing that should have been a non-goal, because code containing chained awaits is almost universally bad. Naming things is indeed hard, but the shadowing rules in Rust makes it much less problematic in my opinion. The huge downside to optimizing ergonomics for chaining (at the substantial cost of introducing syntactical surprises) is that flow control within a single line makes reviewing and debugging code much harder. Rust already has fairly high syntax "density". It is very important to be able to reason about flow control, especially so in asynchronous code. At this point it is hard to see how the dot-await postfix syntax is not a premature ergonomics optimization.
Question: If you wanted to cache high-use files in memory, is it better to build a cache inside the application, or just rely on the OS buffer cache?
I have a few suggestions to help clean up your api * Don't over constrain your types. Meaning don't put any trait bounds on your types. This leads to unnecessary types being put into the type, for example your `MapIter` type has an extraneous type `E`, which doesn't need to be there. There is no way for someone to access the `failed` field, and you don't do anything but put stuff in it, so it is useless. But you needed to put it in because of the bound on `F`. As long as you constrain how a type is created, you don't need to constrain the type itself. * Similarly to the above point, when you are making trait bounds on traits, try and make them as general as possible. In this case you could just say fn map_retry&lt;F&gt;(self, f: F) -&gt; MapIter&lt;Self, F&gt; where MapIter&lt;Self, F&gt;: Iterator; This way if you change trait bounds for `impl Iterator for MapIter`, then you don't have to change them for this function. * You can loosen the bounds on `Iterator for MapIter`, specifically you don't need `Iter: Clone` and for `F` you can have `F: FnMut(Iter::Item) -&gt; Result&lt;Out, E&gt;` where `Out` is a new type parameter. This makes your api more flexible.
Because they are off-topic. But if you browse new posts, you'll have a much higher chance of finding them regardless. Or – if you prove worthy – you could become a mod, thereby both finding enjoyment and help tending the subreddit.
Yeah, that would be valuable. I will just like to keep an eye on the fact that Go and Rust do not necessarily appeal to exactly the same audience. Go is more like Node.js, and Rust is more like C++. There can be significant overlap, but there are some big reasons to consider them different. Exit points matter more when you have scoped memory/resource management, for example. Garbage collected languages tend to deal with that differently, and have other tradeoffs, and thus tend to be used in environments where other things matter more. I suspect it comes down to the old distinction between "applications programming" and "systems programming", where Go is squarely in the former category, and Rust appeals to both, but is actually a serious contender in the second category.
Super helpful as usual, thanks!
I was going to ask that, but was wondering if maybe this wasn't possible because of some other mechanic that will once again shake my understandings of rust down to ground!
I would think that application cache would be better, since you know more information about each file and when it is needed
If the file is the one being run, that won't work. But then, it might not copy for the same reason either depending on OS (if I remember correctly).
The [Rust API Guidelines Checklist](https://rust-lang-nursery.github.io/api-guidelines/checklist.html) should honestly be a lot more visible.
Just had this experience today. Need a bigint library. Search bigint. Find crate `bigint`, no readme. Click on the homepage, redirects to some blockchain site with no info on the project. Go back, click repository. Find that it's deprecated in favor of the `uint` crate in the github readme.
Couldn’t find a description of how it behaves. Will it retry an infinite amount of times?
I read this in Wayne &amp; Garth's voices.
Maybe there should be a simple tool that people can use to check stuff like this before hitting \`cargo publish\` ? Does that exist already?
why is README.md not the default (??)
Are you printing the error case? Maybe try dbg!(fs::copy("test.exe",newdir))?;
&gt;This way if you change trait bounds for impl Iterator for MapIter, then you don't have to change them for this function. Thank you for your advice. I've published a new version with your suggestions implemented. Just to summarise, the goal of your suggestion is to remove bounds from my types and move them to / limit them to where my types are instantiated. &amp;#x200B; Do you have more suggestions / material for making good APIs?
Maybe that tool should be cargo. It should be able to detect whether readme exists and the current remote path I suppose.
This would actually be pretty cool. There could even be logic where if a readme isn’t specified in Cargo.toml it would search for a readme the same way GitHub does. That might make a nice feature request to Cargo / crates.io .
I concur - `cargo publish` should refuse to publish a crate that does not contain these fields. If for whatever reason you absolutely must not have them, you'll have to do it explicitly: ```toml readme = "" repository = "" ``` And if you do so `cargo publish` should still print warnings.
No, your api looks good now. Just a question, what does your crate does exactly? It's not very clear from your code. It looks like you could change `failed` to be an `Option` instead of a `Vec` because only the last failure matters. If you are going to have some complex looping behavior, instead of using `for` or `while` use `loop`. This way your code is more clear. (Although it won't change the behavior of your code) For example let mut res; while { res = self.iter.next(); res.is_some() } { let res = res?; let m = (self.f)(res.clone()); if m.is_ok() { return Some(m); } else { self.failed.push(res); } } Some((self.f)(self.failed.pop()?)) Could be written as loop { let res = match self.iter.next() { Some(x) =&gt; x, None =&gt; break }; let m = (self.f)(res.clone()); if m.is_ok() { return Some(m); } else { self.failed.push(res); } } Some(self.f(self.failed.pop()?))
Great suggestion
Have you tried building with `--release`? Seriously though, you want /r/playrust.
aww shit wrong tread my bad ill delete this
&gt; Just to summarise, the goal of your suggestion is to remove bounds from my types and move them to / limit them to where my types are instantiated. Yes, this way others using your crate can easily define their types without overloading them with bounds. This is similar to how `HashMap` and `BTreeMap` work in the standard library. The types are not constrained, but you can't create an invalid `HashMap` (without `Key: Hash`)
My bad .... drunk. I accept my moronic status. 👍🏽
There are also maintainership flags to warn people of deprecation. Granted, it requires doing one last publish first.
Maybe that should be automated as well, I'm thinking this could be implemented as a soft expiry i.e. the maintainer gets an email after 6 months of inactivity with an link to confirm that the crate is still "good" or the option to disable this feature entirely.
As a beginner, I'm going through The Book slowly, and I don't see the API checklist mentioned in the [section about publishing crates](https://doc.rust-lang.org/book/ch14-02-publishing-to-crates-io.html). Perhaps it would be a good place to first mention the checklist?
This is an interesting idea, but I would push the timeline out to years.
&gt;Maybe that tool should be cargo. It should be able to detect whether readme exists and the current remote path I suppose. &amp;#x200B; The defalt Cargo.toml now includes a comment to add the fields: [https://github.com/rust-lang/cargo/pull/6881#issuecomment-488157972](https://github.com/rust-lang/cargo/pull/6881#issuecomment-488157972)
Right, `cargo publish` already warns about a couple of things. For example, it will tell you `warning: manifest has no documentation, homepage or repository.` if all three of those keys are missing.
 fn addStartup() -&gt; std::io::Result&lt;()&gt; { let user = whoami::username(); let newdir = format!("C:\\Users\\{}\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup", user); fs::copy("test.exe", newdir)?; Ok(()) } Prepend each line with four spaces to get a readable code block
That's true, but this seems really easy for the os to optimize, and it's better to keep application logic simple unless you actually run into performance problems.
(Haven’t read the rest of the comments) So, I had a play and found that passing url instead of &amp;url is the issue here. Redemption for being a moron?!
Alternatively you could use bincode which also uses kind of Serde. I saw this in a [blog post](https://wiredforge.com/blog/wasmer-plugin-pt-2/index.html) about plugins for wasmer.
If you need to tell people on social media to do that, it means there is a problem within the process of creating crates.
I like @await a lot. Could this work for match too and have @ be the sigil for postfix keywords? What was the argument against this?
Also please do not use repository link for `homepage` field.
Rust is actually very OOP and in my opinion is a better implementation of OOP than lots of other OOP languages. Classes are about inheritance, which is not the same thing as OOP. Also, inheritance is a very bad pattern and you should probably avoid it as much as possible. I know that's not what you asked but I just wanted to add my 2 cents.
You almost never want to put an executable in your start menu’s startup folder. Common practice is to put a Windows shortcut (.lnk) pointing to the executable.
I made this mistake recently. I think cargo should either error out when these fields are missing or find a good default (at least for the readme) Also my crate has a procedural macro inside of a cargo workspace, so I believe the easiest way to reuse the top level readme in workspaces is to use a symbolic link. [Example](https://github.com/bschwind/app-route/tree/master/app_route_derive)
I know this is almost three weeks old, but \`alloc\` (with Vec, String, etc.) is available on \`no\_std\` targets.
I ended up adding a construction function to smear the implementation over the returned value, but it's not clear how I could do it from outside the impl. ```rust impl&lt;SPI, NCS, DELAY, E&gt; WrappedSpi&lt;SPI, NCS, DELAY&gt; where SPI: spi::Write&lt;u8, Error = E&gt; + spi::Transfer&lt;u8, Error = E&gt;, NCS: OutputPin, DELAY: DelayMs&lt;u8&gt;, { fn create(spi: SPI, ncs: NCS, delay: DELAY) -&gt; Result&lt;Self, E&gt; { Ok(WrappedSpi { spi, ncs, delay }) } ... } ```
P
It's a shame messing with linker sections is difficult, platform specific and basically restricted to embedded. It'd be nice if the GLibc program loader ([ld.so](https://ld.so)) was hookable so you could apply custom logic to ELF program headers and sections. You could do stuff like map specific sections to Intel optane memory or to shared memory on a file.
This is the subreddit for the Rust programming language. I believe you're looking for /r/playrust
&gt; No, Ruby gems work just like Cargo in that they can compile their code if necessary. PyPI too.
It say "Permission denied."
attack of the clones !
https://atom.io/packages/ide-rust
The first thing that jumps to mind is the [async-rust-book](https://github.com/rust-lang/async-book) I don't really know the current status of the documentation, at a quick glance i can see that there are a lot of TODOs and some of the Future stuff is outdated. It should explain how some of the parts come together.
Do you know Haskell? I understood Rust's `Sum` and `Product` traits after looking at Haskell's [`Foldable`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Foldable.html) typeclass and [`Sum`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Monoid.html#t:Sum)/[`Product`](https://hackage.haskell.org/package/base-4.9.0.0/docs/Data-Monoid.html#t:Product) newtypes.
Great work! Have you looked at using TVM to generate kernels/fusions for use by Tract?
I'm a simple man, I see jonhoo, I upvote. Seriously though I love these! I think they are great and they inspire me to do some live coding streams/videos of my own :)
I'm not sure I fully understand what you want to do. It sounds like you want to 1. Require that `SPI` implements `spi::Write` and `spi::Transfer` 2. Require that `SPI`'s implementation of `spi::Write` has the same error type as its `spi::Transfer` implementation 3. Use that error type in the struct definition In that case I would use `&lt;Type as Trait&gt;::ItemName&gt;` syntax: pub struct WrappedSPI&lt;SPI, NCS, DELAY&gt; where SPI: spi::Write, // (1) SPI: spi::Transfer&lt;Error = &lt;SPI as spi::Write&gt;::Error&gt;, // (1) and (2) // ... other constraints { // ... something_with_the_error: &lt;SPI as spi::Write&gt;::Error, // (3) this is optional, and if you remove it you don't need PhantomData or anything } [Here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fa438c8269d9cf69e80767f84159a2aa) is a minimal example demonstrating it.
I've been eyeing the P-NUCLEO-WB55 which has that MCU on it but so far no place in Europe seems to have it in stock. I'll definitely get one as soon as I can find it.
Thank you
Rust can certainly be used to write app servers whose main purpose is to tie together lots of other, external services, but I imagine such use cases will mature much more once async/await (one of the most highly anticipated features) lands. Without that, it can get a bit unwieldy. I would say that Rust in its current state is most directly addressing the C and C++ spaces, but with libraries/syntax/safety at a level where you can reasonably write a server-side web app with it. I hope that outlines the playing field a little bit? :-) I've also found that writing command-line tools in Rust is a great experience.
Checking permissions by looking for `std::io`, `std::net`, etc in the code is fairly easy to circumvent. use std as asdf; use asdf::process::*; Command::new("scp").arg("all-your-secrets").arg("me@my.server:22/loots/").spawn().unwrap(); macro_rules! use_std { ( $($items:tt)+ ) =&gt; { use std :: { $($items)+ } ; } } use_std!(fs::File, io::copy, net::TcpStream); copy(File::open("~/.ssh/id_rsa")?, TcpStream::connect("my.ip.xx.xx:30000")?)?; use proc_caesar::caesar; caesar! { hfr fgq::guernq::fcnja; // use std::thread::spawn; fcnja(|| qb_anfgl_guvatf()); // spawn(|| do_nasty_things()); } ([`proc_caesar`](https://github.com/matklad/proc-caesar)) Parsing code after macro expansion covers two of these, but keeping track of what name `std` is under at every place in the code will be much more challenging. This also doesn't cover FFI or crates that provide threading/network access/etc themselves, as others have mentioned elsewhere in the thread.
ES API is REST, so all you need is a good HTTP client in Rust. And if I understand correctly, presently web/rest is quite good in Rust for client and server both.
You're right, Cargo should create the Readme.md file while running the cargo new command.
Ah yes, the compiled book is served on [github.io](https://rust-lang.github.io/async-book/getting_started/why_async.html) (though it may not be up to date).
This is cool but next time write what the crate does.
I made one using tide and mime guesser, under 50 lines https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=3560d74c034ce616034716beac18c0c3
&gt;Couldn’t find a description of how it behaves. Will it retry an infinite amount of times? What happens to the errors? I've added more thorough description to documentation. It will retry one time and if it also fails on second attempt the last error is return. This means that number of input and output items is the same
You were supposed to use it on itself!
&gt; Exit points matter more when you have scoped memory/resource management, for example. I think this example really boils down to data-races, at the end. That is, whenever you are "suspended" the world changes under your feet, and therefore if you acquire an index/key/... before being suspended and use it after, there's a chance it was invalidated, with pointers to memory just being a special-case. In this case, though, I find Rust well-suited to implicit await since the borrow-checker will catch even more cases of data-races than a GC would.
Also this is a good moment to promote [cargo-readme](https://github.com/livioribeiro/cargo-readme) which generates a readme from your lib.rs docstring.
&gt; And if you do so cargo publish should still print warnings. Disagree there, if they set it explicitly they don't need to be warned about it, it'd just be annoying console spam.
This feature wasn’t in Cargo originally, and so we couldn’t make it have a default or it would be a breaking change.
Nope, not yet. TVM claims much better performance than TensorFlow Lite (and tract) on imagenet networks on Raspi3, among other combinations, so that could very interesting indeed.
Maybe not the thing you requested, but i found the video [The What and How of Futures and async/await in Rust](https://www.youtube.com/watch?v=9_3krAQtD2k) really educational. It is pretty broad and also has great depth about the topic.
One of them is responsible for polling the active futures (the executor?), while the other is responsible for keeping track of the futures that have returned `NotReady` and are waiting to wake up (the reactor?). I'm not completely sure which does which, but I believe that's the gist of it.
I guess it in this blog [https://tokio.rs/docs/going-deeper/building-runtime/](https://tokio.rs/docs/going-deeper/building-runtime/)
Nice but I think Rust is more suited to UDP because it's a fast paced game, TCP adds too much overhead for realtime data in an online game
Rust's syntax is considered stable, and will not change. Syntax changes _may_ be introduced through new "editions" of the language, but those are opt-in, and the compiler will continue working with older editions.
By opt-in you mean additions to the language without changing any of the previous syntax?
Great observation about data races, I agree completely. I'm not sure I understand enough about the implementation to reason about how \`await\` impacts lifetime analysis -- my intuition is that it probably could? At least I know, from working with async code in C++ (using Boost.Asio-like primitives), that data race concerns very similar to multithreaded code can exist. Concurrency is still concurrency, single-threaded or not. Are futures guarded by mechanisms similar to \`Send\`/\`Sync\`?
Is this really a 'breaking change', if all we're doing is adding some functionality that won't actually break anything?
No, I mean that there may be _actual_ syntax changes, but they will require a special setting in your `Cargo.toml` or a special compiler switch. For example, `async` is a reserved keyword in Rust 2018, but not in Rust 2015, so the code using `async` as a name will compile if your `Cargo.toml` says `edition = "2015"`, but not compile if your `Cargo.toml` says `edition = "2018"`. When the next edition comes out, your `Cargo.toml` will still say `edition = "2018"`, so your code will keep working.
Thank you for the elaboration! Understood now.
&gt; Are futures guarded by mechanisms similar to &gt; Send &gt; / &gt; Sync &gt; ? Futures are guarded by `Send` and `Sync`, not by mechanisms "similar to". Those two properties are independent of the concurrency model used. `await` enables the compiler to reason about borrowing across yield points.
&gt; I don't feel like reading source code to blink an LED (though I'd probably learn something). You probably aren't gonna get far in embedded, then. It's a mess and even more so in Rust, where there may be only a few tutorials, if any. I generally recommend reading the [data sheet](https://www.st.com/resource/en/datasheet/dm00037051.pdf), where you will find all the board specific details (such as timers and LED-pins). There's not a lot of documentation so I just read the official stm32fxx header files, which are obviously in C, but I'm sure the Rust crates have something similar.
Cool, thanks for the response. I think that clears up at least some concern about the impact on maintainability of `await` (though not by enough to remove concerns surrounding the surprising syntax, at least in my opinion).
Also different editions are compatible with each other! So you can use a crate with `edition = "2015"` in your program with `edition = "2018"` (which is the whole point of editions).
Executor ask if future ready to go if not it passes it to reactor, reactor does magic (basically ask OS reports back when future is ready) and when it ready gives back it to executor, so it can ask future again.
If you're in a position to hire 1000 developers to completely rewrite the Linux kernel in rust, you probably shouldn't be asking these questions on Reddit, but rather to later stakeholders like Mozilla and friends. Also, you probably wanna give Redox OS a spin
Got some Yoda-like titles. Await we yet are?
I would be interested to know your review on Redox OS if you have tried it. Is it easy to install yet?
Sorry, i never tried it myself, only heard/read about it
My mention of the "re-write Linux kernel" is metaphorical aiming to know the answer of "is it worth it if it's possible"? One such extraordinary example is Mark Shuttleworth's decision to start Ubuntu. Had he though that Debian is enough, Linux wouldn't be where it is today. But "is it worth it" or "is rust syntax future proof" to start an OS project written in it, must be answered first. Of course I am not comparing myself to him, but I am just entertaining the idea.
OK, I agree that reading source code is necessary. I just already to that a lot in C. And I thought that now that embedded Rust was a focus last year, it would be easier now to blink a led
But isn't the Rust community favoring the postfix? "We yet are, await?".
I thought the decision was postfix. Shouldn't it be: &gt; Are we yet await?
How does it compare to [ptree](https://crates.io/crates/ptree)?
If that line makes sense semantically (I actually want nothing from that database other than Bob's entry), then I think this is more clear than having a bunch of locals that the programmer will have to figure out aren't being used anywhere else. Of course you could make this clear in Rust today by using a block expression containing the intermediate locals, but that's a lot more code which might make sense in some settings, and in others not so much.
The Rust syntax is future-proof, however syntax itself is one of the more minor aspects of a language. With some exceptions you could pretty much rewrite C programs in Rust right now; C++ maybe less so. But these exceptions can be pretty significant: - inline assembly support - portability - `setjmp`/`longjmp` - (for C++) `const` generics - (for C++) debugger support Of course, my list is incomplete, and probably every person will care about different things. Some of them will likely improve in time (`const` generics), while others will most likely stay the same way (assembly)
I did have a quick look at this one, but it seemed to have a different goal. I’ve gone with a more simplistic approach, to be used by developers in place of debugging with basic print statements scattered through their code. I’ve created the macros to make it very simple to use without any setup. Also, the `add_branch!()` macro creates a branch only until the end of the current scope, and any other leaves or branches until then are added to that branch - this means if you add a branch at the start of a function, and your function calls others, or is recursive, you get that tree structure without having to pass around tree arguments or structure your code any differently.
You mean that C++ features you mentioned are a bit ahead of Rust right now. I respect your honest review. It's good to know, even if for my current purpose I will probably never use any of those advanced features. I will mainly use Rust for web development and maybe mobile apps in the future.
An executor is essentially a scheduler. It is responsible for actually executing the futures that got spawned as tasks onto it. However if a future can‘t make progress it needs to ensure that the executor is getting notified again such that it knows to enqueue the task again. This happens via a Waker. The piece actually noticing that the task can make progress again and calling the Waker is the reactor. In Tokio the runtime is both an executor and a reactor (for IO futures), you may need different reactors for different futures. Any future can be spawned on any executor, as long as their associated reactor(s) is / are running.
Are we `yet.await?`
Cheeky.
Well, you didn't state the kind of code you're interested in. For web development you'll probably care about `await` (it's in the works, should be out this autumn) and ORMs (there are a couple of options, but the most popular ones heavily depend on reflection and / or the dynamic nature of the language). For mobile it will still be a pain because you'll need to go through JNI for interop on Android (not sure about iOS). There's also WASM support in Rust, which is pretty nice if you feel like replacing parts of your front-end code. These are all pretty different from expecting Rust to run on a [toaster](https://www.embeddedarm.com/blog/netbsd-toaster-powered-by-the-ts-7200-arm9-sbc/), although it has good ARM support already. Anyway, the language is not going anywhere, and will only get better.
Cheeky.
It would change how existing crates built, so yes.
I mean it'd mean the readme would show up on [crates.io](https://crates.io) where it didn't before, but what else would it actually affect?
Yes, that’s what it would affect. It’s possible that a crate author wouldn’t want that. In general, Rust cares a lot about not breaking things. Maybe it’s overly cautious in this case, but it’s just the culture.
I think we're getting pretty close to [https://xkcd.com/1172/](https://xkcd.com/1172/) here
Thanks for the input!
Oh no not the game Rust, the programming language. Unless this was a joke and then I guess I got Whooshed
His video on futures is superb!
Brilliant
I’ve never wanted that much from an arewefooyet. My instinct is to find the README.md in the repo first.
Check out `include_bytes!` to embed the file into the binary or perhaps https://github.com/pyros2097/rust-embed which does `include_bytes!` in release builds but just loads files during development.
Looks good, I'll have a look at it, I'm not sure if the include\_bytes! works when the crate is build as dependency though, since the path i provide still has to point to the binary data. But I'll try it out anyways :D.
Ooh, the title changes randomly to a previously discussed await alternative. Love it !
I found the problem with that. The path argument is not a static string in my case since it can be configured through a \`config.ron\` file. So the macro can't be executed on compile-time.
I guess you need to write your own macro that reads config.ron and generates a call to include_bytes then.
Oh and btw, check out Scopes - you might like it: [https://scopes.readthedocs.io/en/latest/tutorial.html#a-mild-breeze-of-programming](https://scopes.readthedocs.io/en/latest/tutorial.html#a-mild-breeze-of-programming)
From the serde docs, bincode is one of many serialization types available. I'm leaning more towards serde_json (https://docs.serde.rs/serde_json/) at the moment. The data I'm passing fits nicely into a set of key-pairs: {"equation": ["+", a, 2], "variables": [{"a": 2}], "input": "a = 3"} Internally, the equation is stored as a (slightly modified) s-expression. I user a Vec just so I do not have to parse it each time I read it, but I _could_ have stored things as (JSON): {"equation": "(+ a 2)", "variables": "((= a 2))", "input": "a = 3"} Then all I'd need to do is parse the s-expression each time I pass data back and forth.
Okay, I thought there might be a pretty way with some Cargo.toml variables. Thank you!
It seems to be missing `.await!`, though (IMO the right amount of visible magic, without too much clutter from the full `.await!()`).
For anyone confused at this, this is a JavaScript thing.
Each one its own. My preferred syntax is the "ellipsis sigils", i.e. let res = future...? But eh, the powers that be have decided.
Another solution would be to do it in build.rs. https://doc.rust-lang.org/cargo/reference/build-scripts.html
I am not sure if this is a joke or not, but this is the reddit for the Rust programming language, not the game :)
r/lostredditors
Am I the only one who is not concerned with a syntax but more worried that async might end up slow or not zero cost in the end? It's great to have a nice looking easy to use syntax, but if it's going to be slower than old futures that would be unfortunate.
Yeah I might add curl or something similar as build dependency and just download it when building. Thanks!
? And Result are one some of the best things in the language as opposed to Go’s hideously repetitive error handling. It’s one of the things that has be doing a web app in rust instead of Go.
If Anyone could Link me to places that sell the parts required for relatively cheap lemmie know
Of Course, upgrading the CPU isnt possible/to expensive, so even if i went up to a GTX 980 would it matter???
Seems to me like `yet🕐? ` is the best syntax for await.
Don't you need a runtime for await? Everything costs.
I like the Bryan Rust jersey, it's a nice touch.
I think “zero cost” actually means no additional cost vs whatever awaiting code you would write by hand.
That will make building your crate unreliable.
You should \`include\_bytes!\` all the resource files within the crate that supplies them, and expose them via some non-filesystem API.
The ergonomics of it are really important though. There's huge power in a language where high level abstractions are as easy to use as Python, but is also performant and enforces "correctness".
Note that anything can invoke a `Waker`; primitive non-I/O (e.g. in-memory message-passing) futures are often implemented on that basis, and hence require no reactor at all.
I agree with you, but can't really help you further beside that actix did remove a lot of it's unsafe code after attention was brought to it.
But how do i do this if for instance the icons-theme should be configurable. The path is not known at compile-time. My idea was that it should be possible to tell cargo that it needs to download my resources directory as well so that it can be referenced by default by the crate, but if the user chooses to use a custom directory for shaders or icons, he could just set that in his personal config file.
(not the person you just replied to, nor OP) Ergonomics are important. But I'm still not concerned about `.await` it has kind of grown on me since the idea was brought to my attention (I read a SOV human language, which might help)
The performance of futures in Rust is completely orthogonal to which syntax will be used. Lots of effort has been put into making futures zero-cost abstractions, that effort isn't being undone by discussing the syntax :)
If a crate supplies a set of resources, then all possible paths are known at compile time, and you can include them all and then select which one to actually use (or whether to use something external supplied by the user) at run time.
That's correct: [https://www.reddit.com/r/rust/comments/8wlkbe/actixweb\_has\_removed\_all\_unsound\_use\_of\_unsafe\_in/](https://www.reddit.com/r/rust/comments/8wlkbe/actixweb_has_removed_all_unsound_use_of_unsafe_in/)
The Reactor name is carry over from the original Tokio. I’m thinking about renaming the crate to ‘tokio-net’ and the type to tokio_net::Driver. Hopefully that would better reflect things.
I think I get the general directions. Something like including the default data and on runtime test if to use that one, or to load custom data. Well looks like I have to refactor some stuff then! Thank you!
As someone who, for 4 years, maintained a web-application written in C++, I feel uniquely qualify to answer this question :) --- However, before delving in the particular, I would like to point out that most web-applications are built of two parts: - The backend: the host pays for the power bill *and* the internet bill. - The frontend: the client pays for the power bill *and* the internet bill. This is particularly important because a blog, for example, needs no specific backend: a backend only matters if interaction is necessary. For a blog, which presents static content enriched with some CSS and typically JavaScript, it is perfectly fine to generate all pages ahead of time and store them on a CDN. This is also important because a number of usecases involving user-submitted content, such as blogs with comments, or forums, can also run asynchronously: when the user posts a new comment/reply/thread, store it in a database, regenerate the thread page and index page, push to CDN, done. You can use Python or CGI+PHP on Raspberry Pi 0 and still serve any page within 100 ms to anyone on the planet even with over a thousands readers because... the read requests never come to your server in the first place. And you can fake instant feedback by using local storage on the user machine to enrich *their* view of the thread/index with their newly submitted content. --- There are many web-applications, architected in many different ways. If my examples have proven anything is that the actual performance of the server can be made irrelevant in a number of situations. Other examples where the performance of the server are irrelevant will include all those web-applications with so few clients that it doesn't matter. Those includes your favorite's Pop &amp; Mom hole-in-the-wall restaurant place with their online reservation system, or their online delivery orders system: with at most 100 users on a given evening, the server will idle most of the time anyway. And of course there are all the cases where the server is a thin veneer on top of the database, in which case optimizing the SQL queries, and reducing their numbers, is often more important than anything done at the application layer: been there, done that. --- Assuming that you have asserted that performance (either latency or efficiency) is warranted for your usecase, then indeed Rust may be a good fit. You'll have to check against the offering in other languages, as C#, Java and Go all offer solid performance with a much greater variety of libraries, and C# in particular with Blazor also allows targeting WASM. I would advise against C++; I've done it, it's workable, but honestly exposing an unsafe language to the web is a rather scary prospect given how much room there is to make blunders even with safe languages to start with.
`init` lacks `DELAY: DelayMs&lt;u8&gt;` bound.
I'm intrigued by the fact that it doesn't use racer. I'll close my eyes and pretend atom is emacs for this one if it works well 😅
Specifically, almost all autobuilders in packaging repositories disable internet access outside of their 'network' for good reason. I'm joining the choir of 'don't do this unless you can use another git repo (or similar) as source, which can then be imported/mirrored in whatever build service you use'.
The claim Rust makes is usually "zero cost abstractions", not "zero cost features". Any way of doing multiple things at once is going to have some cost, so that's the baseline cost that the feature will have. The goal is for the abstraction to have no cost beyond what hand-written code for doing the same thing would cost.
I'd be a fan of such a comparison, and would love to see it, but don't have the time to invest into it. I've been using rocket, since it's quite easy to use and their documentation rocks. I can't speak for the other frameworks since I haven't used them. I feel like \[warp\]([https://github.com/seanmonstar/warp](https://github.com/seanmonstar/warp)) may be an interesting new-comer. Other than that, actix is quite fast: [https://www.techempower.com/benchmarks/#section=data-r16&amp;hw=ph&amp;test=plaintext](https://www.techempower.com/benchmarks/#section=data-r16&amp;hw=ph&amp;test=plaintext)
Right, mine as well, but I was trying to also point out that just comparing READMEs isn't always useful when you're a total newbie to a space (like Rust for web stuff). Are we X yet may not be the perfect place for such a side-by-side comparison, but I still think it's useful to have. Reading project READMEs is the go-to method in the npm ecosystem, and for me personally it's not a good way (by itself) to make a decision.
I'm sorry, but I think you've misunderstood me. I'm not concerned about the syntax because I know that implementation behind it will still be the same regardless of whichever one they'll pick. What I am concerned about is things like [this](https://github.com/rust-lang-nursery/futures-rs/issues/1571#issuecomment-487660724) one.
I wish I had the time and energy to put up some little website in all the listed frameworks. It would make for nice comparisons.
please start working on it because [stdweb::js](https://docs.rs/stdweb/0.4.0/stdweb/macro.js.html) can do Rust to JS transplantation but its getting controlled by Mozilla and they are hell bent on making sure JS lives in its innate forms; so i am sure many will join forces with you to defeat the legacy evil forces that kept us in dark ages for last 25 years.
Isn't that neglecting the wide range of things you can `epoll` with Tokio reactors that aren't "net"? stdio, inotify, signalfd, character devices, etc.
er i am not so sure, you will hav to read and try out, it worked when i installed these packages [atom-ide-ui](https://github.com/facebookarchive/atom-ide-ui) [atom-language-rust](https://atom.io/packages/atom-language-rust) [build](https://atom.io/packages/build) [build-cargo](https://atom.io/packages/build-cargo) [ide-rust](https://atom.io/packages/ide-rust) [language-rust](https://atom.io/packages/language-rust) [rust-lang](https://atom.io/packages/rust-lang) with experience i will figure which ones of those make it work, right now to do it fast install them one by one and check, and btw atom will message you if something is missing.
Today, I would not recommend a business to use Rust to do web application. For 3 mains reasons: 1. We are not web yet. We have good framework, powerful ORM, but they are not stable enough nor complete to build a complex web application for production 2. Lack of Rust developers. It's already hard to find good web developers, so it's probably even harder to find good Rust developers. Let's say you find 2 good guys to build your system in Rust, the day one of them leave, you will either have to train someone or gonna have to spend time looking for someone able to take over a rust application. 3. The current languages and frameworks are so good it would be a real waste of time not to use it. However, if the business has enough resource, this is game changer. The points are still valid, but we need real businesses to start using Rust in production, this is how the language and frameworks will evolve in the right way. Using Rust is a long term investment
As someone who still has to deal with Windows Server 2003 and up, being able to use Rust and having it work on all of those platforms would make my life (haven't tried to run on 2003, yet).
Also, the `yet!await` syntax is missing. `yet#` would be very confusing, if the awaited value is then indexed: let test = 5; yet#[test] // looks like an attribute!
Downside: You have to count dots in let res = future.........?
Small correction: Reddit's multi-line source code feature is marked with a four-space indent rather than ```` ``` ````. With four-space indenting, your tree will end up looking like this: 1 ├╼ 1.1 │ └╼ 1.1.1 └╼ 1.2
I really like that Carol announced the talks about Zig and Go at the end of her own talk. No need for partisanship, let's present alternatives as objectively as possible, and let viewers make their own choice.
You're right, not 100% ergonomic. Not that much important now ...
I think enabling the flag means that at run time more cpu is used since it has to store what function calls what,
You probably want to use the r/playrust subreddit, this subreddit is for the programming language rust, not the game
I agree. However, I doubt that the difference will be measurable in real-world applications, since async/await is mainly for things like I/O. Iterators aren't zero-cost either. In some cases, iterator functions like `map()` or `for_each()` outperform `for`\-loops. Sometimes, *almost*\-zero-cost abstractions are good enough.
Exactly. It went from 120+ to as of today, 8 unsafe blocks, which are all documented and proven sound.
This wouldn't be a concern for debug builds
Only when the actual backtrace is printed is more CPU needed; all the data needed to build a backtrace is stored in the executable anyways (as symbol tables and debug info).
Hadn't thought about that, but I agree
Didn't know that, thanks
Wow this railroad analogy is breath taking. History repeats! People do repeat the same wrong assumptions over and over again – even though they have proven wrong over and over.
These look identical to me.
I think people have more than one concern.
async/await is also finishing what we started, and that's necessary to enable certain kinds of code to be written well, unlike try, the lack of try isn't a major blocker for people writing code. I think try blocks still need some syntax discussions -- there were discussions around the edition about reserving the keyword, but not actual syntax discussions. It also ties into the whole discussion around `throws` and `catch` as function decl sugar, so there's a wider set of discussions to b ehad.
 * It's leaking the memory of the `Node`s removed from the list. * Not sure why `Node`'s `data` field is an `Option` or what the point of `rng` is.
How is soundness proven? Are there formal systems for checking unsafe code?