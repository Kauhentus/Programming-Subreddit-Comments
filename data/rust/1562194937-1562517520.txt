&gt;So I need the lifetime of R tied to lifetime of the reference passed to f, but I can't determine any way to do that. Is there a way? So the error you are getting [`E0271`](https://doc.rust-lang.org/stable/error-index.html#E0271) isn't _strictly_ a lifetime error. What is happening (_I think_) is that `Fn(&amp;Foobar)::Output` isn't defined (as it is a `impl PartialEq`), so `go` is struggling to define what `R`. The fully solution seems to be to break out the `impl Trait` into full on generic parameters so you can assert that `impl Fn(&amp;Foobar) -&gt; R` is consistently defined. While you move things into the generic argument slot lifetime errors do appear. I managed to get [this to work](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a944c4c6df0dc2d869a469b2fc570a17) which is what I think you are trying to do?
Why wouldn't anyone want to use a Linux with parts rewritten in Rust? What is the practical downside? Is the Linux development community committed to leaving us at the mercy of C bugs for ever or is it C++ bugs that Rust mostly tackles?
I'm looking for a way to stop a series of iterator filters/transformations on an error. I've seen the answer https://stackoverflow.com/questions/26368288/how-do-i-stop-iteration-and-return-an-error-when-iteratormap-returns-a-result, but it requires a `collect()` which would create an intermediate collection of all the elements and I don't really need that collection. The code in question is: fn walkdir() -&gt; Result&lt;(), CustomError&gt; { walkdir::WalkDir::new("somedir") .into_iter() // provides walkdir::Result&lt;walkdir::DirEntry&gt; .map_stop_at_error(|result| match result { Err(e) =&gt; return CustomError::new(...), // return the CustomError from walkdir() Ok(dirent) =&gt; dirent, }) .filter(|dirent| { // assuming dirent is unwrapped from now on }) .lots_of_other_iter_functions(); Ok(()) } On JVM, I'd just use a regular `map()` and throw an exception on error,,. but what is the proper way to do this in Rust please?
I'm afraid that you've modified the example too much, it is no longer applicable to my case. In particular, your solution works because you've made \`go\` borrow the \`Foobar\`s instead taking ownership of them. The lifetime 'a you've defined on the function thus ensures that the references are all valid until go terminates. In my non-simplified case, \`go\` is actually receiving an iterator over \`Foobar\`. The various Foobar instances will not live through the entire span of the function as they processed one by one. As such, I cannot resolve the situation by adding a lifetime to the function since that lifetime will last for the whole function and that is too long.
If we don't talk specifically about ISO and its reason for existing, but more generally, can it not be seen as a service like any other? People might benefit from (and therefore be willing to pay for) having a standard, so someone fills that need by developing, or vetting, standards, and selling access to them.
I’ve never met anyone who, besides myself, read the arch-useful book by Michael Nygard, but still his ideas pop up over the Internet from time to time which is extremely nice to see. Nice work.
I think it can go either way? More optimizations are done, and optimizations are by default for speed, not size. With that small of an app, it seems reasonable. As others have said, more inlining might be happening. And if it's already that small, it's not likely there are a ton of unused functions in there that are only removed because of lto. For reference, there is a setting for optimizing the binary for size rather than speed. It can be enabled with `opt-level="s"`, if that's what you need. See https://rust-embedded.github.io/book/unsorted/speed-vs-size.html for more info on this in general (not strictly related to lto).
You may want to benchmark Arc clones, they are relatively expensive, e.g. it can be faster to clone a heap allocated object you're trying not to clone.
How's [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0b70f74dbbaf4fe81da119157765dc56)?
&gt; For reference, there is a setting for optimizing the binary for size rather than speed. It can be enabled with opt-level="s", if that's what you need. Is there a specific reason you're not recommending the stronger `opt-level="z"`?
You should be able to use https://github.com/emoon/rust_minifb/ for windowing and handling events. See https://github.com/cbrewster/raqote-win for an integration of raqote and minifb.
That looks to be exactly the same as my original code before I tried to add the generic return, which is what I'm trying to accomplish?
If your return type is always a reference, I think you can do something like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=df8f932dc665eea272c70bbab82b654d). I don't really understand what your code is suppose to do =)
Hard to say. C++ having an ISO standard is largely an artifact of existing when compilers weren't the open-source commodity tools they are today. And thus the overhead of The Standard was good for people using C++ to be able to avoid vendor lock-in (theoretically). With rust being open-source, the question is thus not whether there'll be a standard, but what would cause a need for multiple fully-featured implementations.
Does something like r2d2 do the trick? As I understand it plucks a Postgres connection from a pool, executes and then puts it back in the pool. If I am using diesel and these pooled connections from inside a route handler that returns a future, is this now fully async?
Last time I read up on this stuff, opt-level z could reduce size, but it may also increase size compared to opt-level s, and things are in general much less guaranteed to be better. Possibly good, but not recommended for use without trying "s" first? I'm not 100% where I first read about this, but here's one issue pertaining to the topic: https://github.com/rust-lang/rust/issues/54026
Last time I read up on this stuff, opt-level z could reduce size, but it may also increase size compared to opt-level s, and things are in general much less guaranteed to be better. Possibly good, but not recommended for use without trying "s" first? I'm not 100% where I first read about this, but here's one issue pertaining to the topic: https://github.com/rust-lang/rust/issues/54026
CLion + byobu + fish As ergonomic as it gets
Name it PEX, like the [plumbing pipes](https://www.finehomebuilding.com/2009/03/02/three-designs-for-pex-plumbing-systems)
here is a version close to the one you started with: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=f9c64b49becee4a458f6d5c78df084cd
Same!
So, taking a step back, I'm of the opinion that in the context of modern C++ and its standard library, copy constructors are done as one would expect (`std::vector` deep-clones, `std::{shared,unique}_ptr` do the right thing with ownership, etc.). At that point, I think you have building blocks comparable to what Rust has for Doing the Right Thing™ with copies. Some minor quibbles that are probably just a difference of perspective I was hoping to clarify: &gt; In Rust a default (derived) clone is also mostly a "shallow copy" because of the behaviour for Arc/Rc/raw pointers/references, which is the same as in C++. Especially here, I still think Rust's defaults contribute more to sanity in general because the author has to opt-in to `Clone`, instead of C++'s out-opt `T(&amp;T) = delete;`. For cases where raw pointers get involved, having potentially undesirable shallow copies implemented by default is a footgun I like not having to think about. By adding `derive(Clone)`, I've explicitly accepted that default implementation. I consider that significant. Also, `Clone::clone` takes `&amp;self`, and the compiler can help you uphold the invariants that the immutable reference imposes. &gt; even in Rust, a .clone() call might not be shallow, e.g. when you have a std::Vec member I'm confused -- you mean if the `Vec` contains smart pointers?
Have you checked std::any::Any ?
Appreciate the tip! I assume the cost you're referencing is strictly at clone time? Ie, no runtime penalty, correct?
I'd argue gamepad support doesn't matter as much when you have the awesome library that is [gilrs](https://github.com/Arvamer/gilrs) to use!
Woww, this is great.
Agreed that it can be confusing. One advantage to using the same trait for everything, though, is that it makes it easier to #[derive(clone)] on higher level types. If Arc wasn't Clone you'd need to implement Clone manually on any higher level type containing an Arc. If you have a lot of shared caches or whatever in your application, that could get tedious, and it might've led to a lot CloneableArc wrapper types scattered in various codebases.
Is there a way to exclude things from running when building with `--release`? For example, skip `dbg!` and `println!`, or maybe entire functions ?
Our company bytedance uses rustlang to write the common logic code of [lark](https://www.larksuite.com/) app for crossing platform. The result is that the performance and power-saving and development efficiency are much better than the native code of each platform.(Sorry, private data cannot be disclosed)
I couldn't get it to work, but I managed to get a different error about values not living long enough, as though the function takes the references and then gets to send them off to do things with greater lifetimes than the function. &amp;#x200B; [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0cdae31bdcdffbc5341436380352e377](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0cdae31bdcdffbc5341436380352e377)
There is no "real" solution but you can use `#[cfg(debug_assertions)]` as a hacky solution. For `dbg!` and `println!` I'd recommend using the [log crate](https://crates.io/crates/log).
You can try reading the documentation: &gt; A common trait for the ability to explicitly duplicate an object. &gt; Differs from Copy in that Copy is implicit and extremely inexpensive, while Clone is always explicit and may or may not be expensive. In order to enforce these characteristics, Rust does not allow you to reimplement Copy, but you may reimplement Clone and run arbitrary code.
You can't convert a runtime value to a type, ie return a different type for Some vs None. If tex\_coords is Some or None based on static information, then you could instead create an Empty struct, ie emulate Some vs None but with structs instead of enum. If not, the alternative is to use Box, which allows you to put different types into it, that all implement a trait. So realize() can return impl Trait or Box&lt;Trait&gt;.
prefer not to use any cargo as Rust is good enough to create anything with it. thanks though
&gt; Clones are almost always deep copies in the Rust world. I disagree. I would rather express it this way: clones are as shallow as *possible* in Rust. This allows you to drop the `Arc`/`Rc` exception, replacing it with the understanding that due to Rust’s ownership model, only one type of cloning is possible for most types, which is what languages without Rust’s ownership model would call deep cloning.
I will have a look, thanks!
Are you shipping on iOS? If so how are you handling bitcode?
I see what you mean. About the panicking, that's what I expected and that the compiler would "automagically" figure out the concrete type. I see now that I doesn't really work like that. Thanks!
Yes and we don't. Not a requirement yet and when it will be announced it is, I'm sure Rust will have a solution.
So what you mean is that `realize()` would always return a `VertexUV` but have the `tex_coords` as zero when appropriate? I guess that could work, although I would have to send some unused data to the GPU. &amp;#x200B; I'll try to experiment a bit with your second suggestion, but if I want to store the output of `realize()` I would have to use Vec&lt;Box&lt;Trait&gt;&gt; and store each vertex on the heap? Before sending them to the GPU I would still have to place them all in a buffer somehow. I'll experiment a bit with this, thanks for the help!
Wrong subreddit friend
Oh whoops. Gonna delete it. Thanks for the heads up
r/playrust
Nice!
Definitions are implemented manually, because we represent some types and methods a different way than they're defined per docs; otherwise, operating on those types would be troublesome. For example, the [`editMessageText`](https://core.telegram.org/bots/api#editmessagetext) method returns `true` if you call it with `inline_message_id` _or_ a `Message` if you call it with `chat_id` and `message_id`. Because of that, we decided to split it into two methods: [`EditMessageText`](https://docs.rs/tbot/0.1.0/tbot/methods/struct.EditMessageText.html) and [`EditInlineText`](https://docs.rs/tbot/0.1.0/tbot/methods/struct.EditInlineText.html). This way, it's easier to deal with the return type, and it also prevents you from calling this method with either all the three parameters or none of them.
That mental model makes sense to me. Interesting! :)
Oh boy, it seems like I need to read more closely and make sure I know what the problem is :-P
And you can build a house on sand.
Thanks
I haven't worked with other messengers' bots API, but do you think it is possible to abstract the API so that it's both compatible with the underlying APIs *and* it doesn't restrict you to very basic methods? Consider message formatting: Telegram supports fancy links (I mean, `[text](link)`), but I can't seem to find this option in WhatsApp.
There's a `FromIterator&lt;()&gt; for ()` implementation https://doc.rust-lang.org/std/iter/trait.FromIterator.html#impl-FromIterator%3C()%3E which the docs suggest is kind of intended for this case: &gt; Collapses all unit items from an iterator into one. This is more useful when combined with higher-level abstractions, like collecting to a Result&lt;(), E&gt; where you only care about errors: &gt; use std::io::*; let data = vec![1, 2, 3, 4, 5]; let res: Result&lt;()&gt; = data.iter() .map(|x| writeln!(stdout(), "{}", x)) .collect(); assert!(res.is_ok());
Flairs sound good. Easy to filter as well.
Our [tutorial](https://gitlab.com/SnejUgal/tbot/wikis/Tutorial#getting-updates) explains that the macro extracts the environment variable at compile time, and that there's also [`Bot::from_env`](https://docs.rs/tbot/0.1.0/tbot/struct.Bot.html#method.from_env) to extract it at runtime. However, I think that renaming the macro (say, to `from_env!`) would better explain what it does.
The practical downside is diverging from upstream when said upstream is generally _good enough_. Also, most things that do run Linux don't run the upstream kernel anyway - they run some sorts of vendor provided forks that target specific pieces of hardware, and those will not use Rust either.
What do you mean by "literal type"?
It looks like Rust just doesn't have the support to do this sort of thing for the moment.
He means the colloquial English definition. A kind of things.
The thing is, the book is *not* meant to teach you Rust as a first language. It assumes you can already code. It supposes you know what a type is. Rust is not a good first programming language.
Yeah, I figured that much. I guess a better way to phrase my question would be: what do you understand the difference to be between the concept of types in programming and your "common sense" understanding of types?
I just want to quote the [book's introduction](https://doc.rust-lang.org/book/ch00-00-introduction.html#who-this-book-is-for): &gt;This book assumes that you’ve written code in another programming language but doesn’t make any assumptions about which one. We’ve tried to make the material broadly accessible to those from a wide variety of programming backgrounds. We don’t spend a lot of time talking about what programming *is* or how to think about it. If you’re entirely new to programming, you would be better served by reading a book that specifically provides an introduction to programming. Scope, type, syntax,... all those terms are programming terms, not specifically Rust terms. Maybe one day there will be a "Never programmed before? Try Rust!" book but nobody wrote it yet. I wish you a good learning journey, you can always ask questions here or on the forum.
This seems like a great project to get me started learning Rust. Nice job.
You might want to add a "wrap" mode for `stdg` that looks like: stdg -- path/to/my-program --arg1 val1 other-arg And then have `stdg` launch the given command as a sub-process, setting up its stdin and stdout appropriately.
i mean this feels kinda condescending to me. i imagine there are a number of people who cut their teeth on c back before we had stuff like java and python were available. though maybe those people just started with basic. i've just read a lot about the benefits on rust and i really like the grass roots open source culture and history surrounding it, so i thought i would try to learn it. it also seems like it is the future. though i guess I should just start somewhere else. or maybe i'll just keep trying. who knows.
The short answer is no. The long answer is that there’s a third-party plugin for it, but no official one. In general, LSP at this moment misses **a lot** of things (some of which are pretty essential) which are required for typical IntelliJ features. A couple of big ones are syntax highlighting and streaming support. So, even if IntelliJ had official support for LSP, it would be incomparable with support for natively supported languages.
All the book is saying is "this specific document is not suitable for beginning programmers"; it makes no assertions about the language as a whole. Rust may very well be a good "first language", but nobody has released a document (yet) that walks that path out.
reading the rust book and I just wish it challenged you a little to recall what was learned. I don't it's think being condescending because teaching from absolute basics is something that many courses do so well already, and that has been rigorously tested and refined in classrooms. It's more easier to learn from them and knowledge transfers.
I love Rust but I wouldn't recommend Rust as the first language to learn. I think you should find a beginner friendly language first.
yeah, i deleted the thread. it was stupid. sorry maybe you won't be too offended by me asking but does go have a robust starting programmer infrastructure? i mean i know the meme is to start with python, but people really seem to be moving away from that these days. or do you have a recommendation of where to start. you dont have to give me resources or anything but a language or a community would be helpful.
I can see three reasons the book is this way: 1. People coming from other languages don't want to learn to program again, they just want to learn Rust. Imagine having 10+ years of experience and the book explains what a scope is. 2. This is a lot of work. Rust evolves very fast and making a book that keeps up with the main features is already hard. 3. There already are books covering it.
yeah sorry. i deleted the thread. it was a dumb idea. your points make sense.
Python is still the best place to start. It's no longer the hipster's language's since a while since that crown was stolen from it by ruby, then node.js, then go, but it's still the best compromise between been easy to learn and getting shit done.
4\. There is little demand for the Rust as a first language book and most who would want it wouldn't finish it since it's not a great first language.
thanks for the input.
Using /u/schulaceTR as a starting point I came up with [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7daf6c82885c96d0077147fa588caac2](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=7daf6c82885c96d0077147fa588caac2) &amp;#x200B; Basically the \`grab\_first\` function returns a reference to a String instead of a &amp;str because it was complaining about a temporary value or something. I know that often people recommend accepting &amp;str as params but returning Strings in rust. Might be a way to use a Cow to get it to work. &amp;#x200B; Hopefully it does what you are expecting.
I think in the end we could also integrate C++ libraries into our rust code. Do you have experience how big the hassle is?
Sure, if its not already to private, does your application rely on platform specific funtionality like bluetooth or the keystore system on the mobiles?
The problem is that `R` is type defined for `go`, i.e. it is single type, and it doesn't depend on rank2 lifetime of the closure. See, desugaring fn trait you get fn go&lt;R: PartialEq&gt;(lhs: Foobar, rhs: Foobar, f: impl for&lt;'r&gt; Fn(&amp;'r Foobar) -&gt; R) -&gt; bool As you can see your closure doesn't match as it returns different type for different `'r`
Is it easy to pass more complex structures/object from java code to the rust code with this? Or is it still a pain as with C++?
do you mean no runtime penalty *after* the initial clone (of an Arc)? There's no runtime penalty to read the data, but there is a cost when an Arc copy is dropped, which triggers the atomic decrement of the reference count. My experience is several times when I was wrapping some large object in Arc to avoid copying it, but benchmarking showed the cost of Arc was more expensive than copying the large object. My theory is the issue is less the Arc "itself" and more the way the atomics interfere with instruction ordering in the surrounding code, which would be less predictable than other types of operations.
but if \`f\` was just a accessor to the \`&amp;'r Foobar\`, meaning it returned a \`&amp;'r R\` that seems to work or am I not understanding what you're saying
I don't have any first-hand experience with that on a product, but I've recently been playing with calling out to BLAS in one of my hobby projects. You'd have to go through a C API since Rust can't directly link to C++. From the Rust side, you essentially just dump the C header into an extern block and setup the linking in your build script. So it's not too hard to call out to C. The more tedious part is writing safe, idiomatic Rust APIs around that, e.g. the C API will deal in raw pointers, but you'll want to use references with lifetimes on the Rust side. It's not too bad though. Most bindings to C/C++ in Rust are thus divided into two crates, a low-level "sys" crate that just exposes the C API and a higher-level create to provide the idiomatic API.
&gt; it can be faster to clone a heap allocated object That is ... surprising. Do you mean clone something that is currently on the heap onto your local stack? Because if you have to do allocation, I cannot imagine how that would be faster than the atomic increment of an `Arc` clone.
Diesel supports MySQL, PostgreSQL and SQLite ([docs](https://github.com/diesel-rs/diesel/blob/master/guide_drafts/backend_installation.md)) - seems like it does not support DynamoDB though, for that you would have to use [dynomite](https://github.com/softprops/dynomite).
Not much better then c++
@asymmetrikon: I've asked this question some time ago and got a pretty good explanations [here](https://www.reddit.com/r/rust/comments/bj0ki4/why_do_some_char_methods_take_self_by_reference/).
Seems like a good talk, but the error messages on the slides getting their formatting mangled makes me sad :(
I just wanted to tell you thank you, from the bottom of my heart. I was at the point of screaming bloody murder yesterday, and after converting string slices to strings, the program runs perfectly. I sincerely appreciate the help you provided.
I'm trying to implement a tree-like structure which also has a lookup-map to reach each node directly. So something like this: struct Node { id: Uuid, children: Vec&lt;Node&gt; } struct Tree { root: Node lookup_map: BTreeMap&lt;Uuid, Node&gt; // this will contain the root node, and all children / children's children } What's the right way to handle the referencing to the Node instances? I guess I should wrap them in an Rc&lt;Node&gt; so that they're retained by the map and the parent node?
That is exactly what I needed. Thank you so much.
Huh. I missed that. Thanks.
Why do you need VertexUV? Is this related to a class from another library? Why not just use Vertex?
`impl Fn(&amp;bar)` is a function pointer?
I hope not.
Some crates with the `std` prefix are actually part of `std`, e.g., `std_detect` is shipped as the `std::detect` module.
The copyless [https://github.com/kvark/copyless](https://github.com/kvark/copyless) crate and the tool to find mem copies [https://github.com/jrmuizel/memcpy-find](https://github.com/jrmuizel/memcpy-find) looks interesting. I wonder if its actually worthwhile to make the changes to actix or not.
Yes and no. A function pointer would be `fn`. `impl` in this context introduces a generic parameter that implements the `Fn` trait. So it's some type that implements the `Fn` trait. It can be a function pointer but it's often a closure. You can read more about the [impl syntax here](https://doc.rust-lang.org/stable/edition-guide/rust-2018/trait-system/impl-trait-for-returning-complex-types-with-ease.html#argument-position), the [Fn trait here](https://doc.rust-lang.org/std/ops/trait.Fn.html), the [fn type here](https://doc.rust-lang.org/std/primitive.fn.html) and what closures look like [there](https://doc.rust-lang.org/reference/types/closure.html).
I've been surprised many times by the results of performance measurements. But thread synchronization/contention especially.
Hi, &amp;#x200B; I'm in Cebu. &amp;#x200B; I'm a little active in the rust community and I also have a couple of opensource projects in rust. [https://github.com/ivanceras/diwata](https://github.com/ivanceras/diwata) [http://github.com/ivanceras/sauron](http://github.com/ivanceras/sauron) [https://github.com/ivanceras/svgbob](https://github.com/ivanceras/svgbob)
Hey! Add me on telegram @tweetnacl Thanks
No problem - and thanks for bringing it up! Its an important note that I didn't address in my OP.
Super cool! PMed you
Is it possible to use it without `collect()`? If I’m processing gigabytes of data line by line I don’t want to ever collect that in memory.
Copy is not available for types like `Rc`. As for big objects, I don't think there's a particularly strong convention that big objects shouldn't be `Copy`. Consider that built-in types such as `[u8; 1000]` are `Copy`.
[Breaking News: Non-Lexical Lifetimes Arrives for Everyone](http://blog.pnkfx.org/blog/2019/06/26/breaking-news-non-lexical-lifetimes-arrives-for-everyone/) \- this has to be the best news this week.
I think you want /r/playrust, not /r/rust.
Depends on what you want to do, really.
How can I clone a File descriptor or a TcpStream? Apparently the trait is not implemented for these types
You should maybe look into rust-analyzer, which is probably easier to reuse than the full compiler.
It would be great to have a "motivation" section somewhere at the top of the README. Right now potential users can only guess about that. Dissatisfaction with the performance of the `failsafe` crate's performance? Also, thanks for creating &amp; sharing this!
ZST (zero-sized types) should not use up any memory because the compiler recognizes them (even in structures like `Vec&lt;()&gt;`) and compiles them to a no-op. [Source](https://doc.rust-lang.org/nomicon/exotic-sizes.html#zero-sized-types-zsts).
I agree. If it’s just to get more insights into contemporary languages, then I would say Rust definitely. But be prepared for a steep learning curve if you’re new to rigorous type systems in programming languages. C is valuable to know, as it’s still the language underlying almost everything on the low-level. Especially, if you want to learn Unix system level programming. Which I deem pretty valuable knowledge. Can’t say you should go for C++, though, unless you plan to work in a C++ project. **Really** work in it, and for a longer period. Modern C++ is a complex language, with a lot you need to know and **keep in your head**. It’s not a language you learn once and then go on your way and appreciate what you gained from that. IMO it’s not even a nice experience to learn it. Not fun to learn, like Rust.
You can't but Rc&lt;RefCell&lt;T&gt;&gt; in single thread or Arc&lt;Mutex&lt;T&gt;&gt; (or equivalent) in multiple threads should do the trick.
Atomic instructions also require serious inter-core synchronisation, cache invalidation, and the like. On some of the code I was benchmarking, an atomic increment in each thread was very nearly as expensive as locking a mutex, doing a non-atomic increment, then and unlocking the mutex.
Not a game developer: which is the first one?
Thanks for your feedback. Well I had some servers processing thousands of requests per second in Java using `resilient4j`'s ring buffer based circuit breaker for backpressure, and I wanted the same mechanism in Rust. So the motivation is essentially to have `failsafe`'s API with `resilient4j`'s data structure since it has proven to be efficient.
I started with C, I do think it's a good language for absolute beginners if you want to really get how computers actually work
[https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9c0949233680392b121151166f52d763](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9c0949233680392b121151166f52d763)
I don't think you can use \`filter()\` with that? Collecting in the end would require to pass the \`Result\` all the way down to the last transformation and \`filter()\` returns a boolean.
C is not very close to how computers actually work nowadays, though. It exposes more than many languages, but it's still quite a high-level abstraction.
Totally agree 💯, thanks for your explanation.
C. It’s easier and more universal. If you know C, you have an easy time learning most modern languages.
Yeah I am learning C, thank you for your advice.
Yes, you are true my Friend, thanks for your answer.
Rust is better to use. C/C++ is better to learn, as there are actual jobs.
how about using the following for go: fn go&lt;R, F&gt;(lhs: Foobar, rhs: Foobar, f: F) -&gt; bool where R: PartialEq + ?Sized, F: Fn(&amp;Foobar) -&gt; &amp;R, { f(&amp;lhs) == f(&amp;rhs) }
I would agree that C is a *smaller* language than Rust, but I'd say Rust is much easier if you want to write an actual program.
It's a good language if you want to know how a PDP-11 works :)
Between the two, I'd pick Racket.
What is the best way to get today's date into a chrono::NaiveDate? I couldn't find the equivalent of now() for NaiveDate, so I ended up doing this: let today = Local::now(); let today = NaiveDate::from_ymd(today.year(), today.month(), today.day()); Gets the job done, but...
Why don't language designers know about google space ?
Rust's ownership model does not like you to do it in that particular way. Instead I recommend modelling trees (and graphs for that matter) like so: struct Node { id: Uuid, children: Vec&lt;Uuid&gt;, } struct Tree { root: Uuid, nodes: BTreeMap&lt;Uuid, Node&gt;, } This enforces the single ownership model of Rust (all nodes are owned by Tree). There is an extra indirection by requiring to always lookup nodes in the tree structure however.
I have an `u32` and want to match it with an ``` Enum { CaseA = 0, CaseB = 1, } ``` Like a switch in C. How do I do that?
Cool thanks for the alterative! That does seem clean and easy to implement. Since I am trying to understand this better: why would this not work with reference counted smart pointers? I am new to this but from what I could understand it looks like Rc’s are designed for having multiple references to the same object. When *would* one use an Rc?
/r/playrust
It is way past time to finally push back against RUSTC\_BOOTSTRAP usage as a community, please merge [https://github.com/rust-lang/cargo/issues/6627](https://github.com/rust-lang/cargo/issues/6627#issuecomment-507907714) ASAP.
rust. c++ is shit, there's nothing to discuss. i work with c++ every day, and it's shit. and it will keep being shit when c++20 is adopted. but you do need to know plain c to understand how languages in general work.
The only issue with that approach is, you can actually write a lot of code in C until you understand some of the concepts the Rust compiler teaches you in 2 weeks.
Thanks!
You can do `Local::today().naive_local()` or `Local::today().naive_utc()`.
You want to take a `u32` and get the equivalent `Enum`? ``` let e = match x { 0 =&gt; Some(Enum::CaseA), 1 =&gt; Some(Enum::CaseB), _ =&gt; None, }; ```
Your `Enum` needs `#[repr(u32)]`, then you can convert it to `u32` with `as`. Rust doesn't have an exact equivalent of C `switch` (and `switch` is weird), but you can do: #[repr(u32)] enum Case { CaseA = 0, CaseB = 1, } fn match_u32(x: u32){ match x { x if x == Case::CaseA as u32 =&gt; println!("CaseA"), x if x == Case::CaseB as u32 =&gt; println!("CaseB"), _ =&gt; panic!() } } or if x == Case::CaseA as u32 { println!("CaseA") } if x == Case::CaseB as u32 { println!("CaseB") } else { panic!() } Note that you cannot safely convert `u32` to an enum. If the value is out of range, the conversion itself is undefined behavior.
``` let today = Local::today().naive_local(); ```
&gt;but you do need to know plain c to understand how languages in general work. I guess I don't understand how languages work ¯\\\\\\\_(ツ)\_/¯
if you want a job learn java + scala instead, they pay scala programmers like 200k a year. or javascript and go into web. c++ market is oversaturated with boomers as it is and work itself is mostly thankless legacy garbage sorting.
 fn iter_mut(&amp;mut self) -&gt; impl std::iter::Iterator&lt;Item = &amp;mut Tile&gt; { let (n, s, e1, e2, e3, e4) = ( self.plate[4].iter_mut().map(|i| i), self.plate[5].iter_mut(), self.plate[0].iter_mut(), self.plate[1].iter_mut(), self.plate[2].iter_mut(), self.plate[3].iter_mut(), ); n.chain(s.chain(e1.chain(e2.chain(e3.chain(e4))))) }
It could totally work with Rcs! However the resulting code tends to be quite off-putting... The 'problem' with Rc is that mutating the data behind an Rc is cumbersome. Here it would require you put your Node behind an `Rc&lt;RefCell&lt;Node&gt;&gt;` and requires quite the dance to mutate. If you don't need to mutate the data behind an Rc then it can greatly simplify certain kinds of processing although I've personally never needed it. I've always managed to get away by doing the transformation I suggested.
Mm yea, but you probably won’t enjoy Scala, it’s overcomplicated and implicit values make it impossible to understand the code. But, the question was not about jvm, so.
I found it easier to dive into rust first to understand low level concepts and than try C, especially because rustc gives you helpful error messages whereas gcc isn't all that helpful
It sounds like you want Tokio.
Is blockchain not a good use for this?
flip this thought into "if you know how them computers work you know c".
&gt;I _could_ put Copy on big objects. Heck, I could make `Foo(BigValue)` `Copy`, but I wouldn't. There is an implication that `Copy` is cheap. There are examples of expensive copy in std. `Copy` means "bit-level copy without additional logic", not "something that is cheap". `Copy` vs `Clone` is a bit different from `Clone` vs `Share`. `Copy` has different _behaviour_ than clone. In particular you can `memcpy` `Copy` type. It can be proved that a type is non-Copy(e.g. `memcpy` violates memory safety). It is unclear, what one should use to decide whether a type is `Share`, or not. Intended for sharing? Should `Mutex` be `Share`? It's clone is expensive, yet it might be considered as "used for sharing". Cloning is cheap? It depends on level you operate and an environment. `Arc::clone` is expensive for someone, who writes network stack. But `Vec::clone` is cheap when interacting with a DB. OS might CoW the resource, yet another one might not.
True, that was a bit of a let-down. But I rally liked how he had live demos of code which were easy enough to follow with his explanations. That really was the difference between this talk and a lot of other talks introducing Rust and what made it so good. It really succeeded in showing you what the advantages of Rust is if you are coming from C++.
&gt;x if x == Case::CaseA as u32 =&gt; println!("CaseA"), Why doesn't the compiler accept match x { Case::CaseA as u32 =&gt; stuff(); } btw. C's switch is not weird, it's just plain integers being checked for equality ;)
&gt; RC instructs the Rust runtime not to drop the reference and keep it until the program terminates. This reference is used for callback methods. This is completely false. `Rc` is about shared ownership, not making a value live longer. If you only create an `Rc` and then don’t clone it anywhere, it’ll fall out of scope and be destroyed at exactly the same point it would otherwise have been destroyed. As it stands, you could skip the `Rc` wrapping altogether and use the `Clone` implementation of web-sys types, which, based on how I *think* it’s implemented, would currently tend to be a bit more expensive than an `Rc`, but not much, and should eventually be faster once objects can live on the WASM side.
Thanks it makes sense! Another question: so I am trying to implement the pattern you described, and I am running into an error when trying to implement an "add_child" method. The implementation looks like this: impl Tree { fn add_child(&amp;mut self, parent: Uuid, child: Uuid) { let node = &amp;mut self.nodes.get(&amp;parent).unwrap(); node.children.push(child); } } The error is this: error[E0596]: cannot borrow `node.children` as mutable, as it is behind a `&amp;` reference --&gt; src/lib.rs:190:13 | | node.children.push(child); | ^^^^^^^^^^^^^ cannot borrow as mutable Why can't I borrow this exactly, and how do I get around it?
Any dice /u/davemilter?
 fn iter_mut&lt;'a&gt;(&amp;'a mut self) -&gt; impl std::iter::Iterator&lt;Item = Cursor&gt; + 'a { let coord_from_idx: Box&lt;Vec&lt;_&gt;&gt; = Box::new( self .plate .iter() .enumerate() .map(|(i, _)| { let plate = i32::cast(i); let (w, h) = self.plate_size(plate); gen_coord_from_idx((usize::cast(w), usize::cast(h))) }) .collect(), ); self.plate.iter_mut().enumerate().flat_map(move |(i, p)| { let plate = i32::cast(i); p.iter().enumerate().map(move |(j, _)| Cursor { plate, coord: coord_from_idx[i](j), rotation: [1, 0, 0, 1], }) }) } okay, how do you force closure to copy the Box ?
I heard a lot about it but I don’t wanna use any third-party crates. Prefer to use built in libraries
You can use the clang compiler for better messages.
On r/programming: https://www.reddit.com/r/programming/comments/c92skf/announcing_rust_1360/
Woooo `Future` and .await have arrived
As a staunch print / dbg! debugger, I appreciate not having to manually put a few variables into a tuple to debug them now! :D Also the improved hashmap makes me really happy!
okay, is there a way to do this without moving into inner closure? as in fn iter_mut&lt;'a&gt;(&amp;'a mut self) -&gt; impl std::iter::Iterator&lt;Item = Cursor&gt; + 'a { let coord_from_idx: Vec&lt;_&gt; = self .plate .iter() .enumerate() .map(|(i, _)| { let plate = i32::cast(i); let (w, h) = self.plate_size(plate); gen_coord_from_idx((usize::cast(w), usize::cast(h))) }) .collect(); self.plate.iter_mut().enumerate().zip(coord_from_idx.into_iter()).flat_map(move |((i, p), coord_from_idx)| { let plate = i32::cast(i); p.iter().enumerate().map(|(j, _)| Cursor { plate, coord: coord_from_idx(j), rotation: [1, 0, 0, 1], }) }) } i'd like to store just one closure for each plate instead of copying one for every inner plate element j doe this do what i want? is there no way to have non-ref-counted references based on the lifetime of returned iterator? fn iter_mut&lt;'a&gt;(&amp;'a mut self) -&gt; impl std::iter::Iterator&lt;Item = Cursor&gt; + 'a { let coord_from_idx: Vec&lt;_&gt; = self .plate .iter() .enumerate() .map(|(i, _)| { let plate = i32::cast(i); let (w, h) = self.plate_size(plate); Box::new(gen_coord_from_idx((usize::cast(w), usize::cast(h)))) }) .collect(); self.plate.iter_mut().enumerate().zip(coord_from_idx.into_iter()).flat_map(move |((i, p), coord_from_idx)| { let plate = i32::cast(i); p.iter().enumerate().map(move |(j, _)| Cursor { plate, coord: coord_from_idx(j), rotation: [1, 0, 0, 1], }) }) }
As someone who is mostly an edition 2015 user, I'm very fond about the NLL features coming to me!
Out of curiosity, what stops you from migrating to the 2018 edition?
So is the future now or not? "The [Future](https://doc.rust-lang.org/std/future/trait.Future.html) is here!" &amp;#x200B; ...which we'll tell you more about in the future. &amp;#x200B; So the future is here, but it is not now? \*scnr\* Just my weird humor. &amp;#x200B; [https://blog.rust-lang.org/2019/07/04/Rust-1.36.0.html#the-future-is-here](https://blog.rust-lang.org/2019/07/04/Rust-1.36.0.html#the-future-is-here)
Thanks for highlighting this. I updated the blog post. 👍 &amp;#x200B; I will try that part removing the \`Rc\`.
Today's release was kinda early – and I love it! I live in Japan which means that the release always happened around 2-3 AM.
You're going to struggle with Rust with that attitude. A *lot* of thing (including regular expressions and random numbers) are implemented as external libraries in the Rust ecosystem.
Assuming that `self.plate` can be made into an iterator, you can do something like this to avoid explicitly indexing. fn iter_mut(&amp;mut self) -&gt; impl std::iter::Iterator&lt;Item = &amp;mut Tile&gt; { let order = [4, 5, 0, 1, 2, 3]; let mut plates: Vec&lt;_&gt; = self.plate.iter_mut().enumerate().collect(); plates.sort_by_key(|(i, plate)| order.iter().position(|x| x == i).unwrap()); plates.into_iter().map(|(_, plate)| plate.iter_mut()).flatten() }
I'm getting a compile error type annotations required: cannot resolve `\`std::string::String: std::convert::AsRef&lt;_&gt;\`` on 1.36. I haven't dug into it yet, are there any expected non-backward compatible change in this release? (2018 edition codebase). I'll try to isolate a minimal example.
This is an expected type inference regression; you should be able to fix it relatively easily. If not, less us know!
This is expected and likely caused by https://github.com/rust-lang/rust/pull/59825/.
Thanks. Yes easy enough to fix, glad to know it was expected.
Rust (imo sadly) doesn't share the python mentality and rather relies on having most things in external crates. You can still get by with doing stuff yourself (for example implement a bit of linear algebra yourself when you need it) but for other things you're hard pressed to use crates (random numbers, the num crate,...)
IDK for me it feels that a lot of changes that I did want didn't happen (like python3 like distinction between local and foregin-crate use), while other changes that I didn't want did happen (`try!` being made extremely weird to use). Ultimately, switching to edition 2018 too eagerly would send a signal that I am fine with whatever change they are doing, and I am very much not fine. I don't even know what edition 2021 entails. I came to Rust in 2015 because it's a stable language not something that changes around all the time. The 2015 edition motto is "stability" and I want right that. It's my edition basically :).
Type inference regressions are explicitly permitted per our stability policy.
That's a bad attitude to have regarding a lot of things, especially complex stuff like event loops and Futures.
Good to know. Thanks for the quick response!
I really could've used `--offline` a bit over a year ago! Glad it's finally here.
and VS Code 1.36 was released today as well...strange coincidence
Can someone comment on the implications of the alloc crate for using custom allocators? Is this just a namespace change?
I can neither confirm nor deny any coincidence without u/Mark-Simulacrum's approval. ;)
Guys this is not the answer im looking for. my question wasn't about which approach should I choose.
&gt; In Rust 1.36.0 the long awaited `Future` trait has been stabilized! Finally!! I've waited so long... this will be _huge_ for the async ecosystem. &gt; The `alloc` crate is stable Finally!! I've waited so long...
When you allocate a vector with a capacity of 100, it means it has the *ability* to store 100 values, not that it actually stores any. If you do this: let buf: Vec&lt;u8&gt; = Vec::with_capacity(100); println!("Capacity is {}, Length is {}", buf.capacity(), buf.len); If you want to create a vector with 100 values of "0", then use the convenient vec! macro let mut buf = vec![0; 100]
There's nothing wrong with /u/ardawan approach and maybe there's even no need for the huge bloat of Tokio. loop + UDP socket receive gets the job done.
Yes, you get an empty vector with enough capacity for 100 elements. If you wanted a vector of 100 `0`s you need `vec![0; 100]`.
I don't share your reasoning, but I'm glad that Rust means we don't have to agree to benefit from and contribute to (almost) the same ecosystem. :)
You asked if it is "safe" to do that. Safe is an ambiguous word. Safe as in memory safe? Sure. Safe as in a good idea? No, it's a bad idea.
You're not putting anything *in* the `Vec`.. `Vec::with_capacity` means it will allocate enough memory for that many elements at the start. You can then add that may elements and know that their won't be any allocations. If you add more elements, the `Vec` will have make itself bigger to hold them. `Vec::len` is how many elements it actually holds, it's always less than capacity, and in your case, is zero, empty.
alloc doesn't depend on the std crate, so having a stable alloc crate is necessary for using safe dynamic memory types like `Box&lt;T&gt;` and `Vec&lt;T&gt;` in bare metal environments like embedded and kernel dev. Obviously, in a `no_std` environment, you'd still have to implement a custom global allocator to use `alloc` types
It sounds like servo has a valid use case for it, that won't go away anytime soon. Right now, there's a hack that breaks Rust's stability guarantees that Servo uses. Is your point a view that Servo should just use the nightly compiler? &amp;#x200B; In that case, perhaps we want the opposite: the (opt-in) ability to whitelist nightly-only crates when compiling using the nightly compiler. That should also give Servo the build system control they want.
Yes, Firefox should move to nightly, or, the crate should use the stable SIMD support that already exists.
You're confusing length and capacity. A `Vec` has two "lengths". `length`, which is how many items are in it, and `capacity` which is how many items it has allocated memory for. The idea being that explicitly specifying `capacity` doesn't alter the semantics of the type... just its performance. (And a `Vec` won't shrink when you remove items from it unless you ask it to, on the assumption that it's either going to get `Drop`ped soon or it's going to grow again.) `with_capacity` doesn't pre-fill the Vec... it just pre-allocates the memory so it won't need to reallocate (potentially requiring copying everything in the array) until you put more than 100 items in it.
yea I was looking for memory safty , thanks
Thanks
Valgrind tends to report memory leaks in SDL library code, but it tends to happen only at initialization or termination (thus unlikely to progressively eat up your RAM), and can probably be considered a false positive.
&gt;Modern C++ is a complex language, with a lot you need to know and keep in your head Plus, depending on what learning materials you use, and what projects you look at, you might not find yourself learning "modern" C++.
Yes that's the second part of my sentence. If they're part of the standard library then than makes sense.
thanks a lot. my problem solved
thanks a lot. my problem solved
If you don't need the type safety of `enum` (and if you're trying to match an arbitrary `u32` against it, it sounds like you don't), your needs might be better met by a handful of namespaced consts, e.g. #[allow(non_upper_case_globals)] mod Case { pub const CaseA: u32 = 0; pub const CaseB: u32 = 1; } match x { Case::CaseA =&gt; println!("Case A"), Case::CaseB =&gt; println!("Case B"), _ =&gt; println!("Reply hazy; try again later"), } If you're doing this a lot and want to reduce the amount of typing, you can create a macro: macro_rules! fake_enum { ($enum_name:ident : $ty:ty, $($name:ident = $value:expr),*) =&gt; { #[allow(non_upper_case_globals)] mod $enum_name { $( pub const $name: $ty = $value; )* } } } which would be invoked like fake_enum!(Case: u32, CaseA = 0, CaseB = 1);
You're saying there is no benefits of an event loop over just a normal infinite `loop` for network IO?
thanks a lot. my problem solved
The server I’m on is reddit.com/r/PlayRust
I don't know where the right place to request this is, but it would be really cool if this kind of thing could make it into the release notes. It's one thing to allow minor breakage. It's another not to even warn people about it (and leave them wondering whether it's a genuine bug or not).
It's not really practical to do this. This kind of breakage theoretically exists every time we add a trait impl. Similar breakages around glob imports exist every time we add anything to the stdlib ever. Another kind for when we add methods. Basically, the list you ask for is literally the list of all stdlib API changes in the release, and the kinds of errors potentially caused are diverse and hard to enumerate completely.
LOL, funny. &amp;#x200B; Now serious, Learn C if you want to make software for embedded systems and/or make kernel modules . If I possible can, I avoid C, it's too low level, and too easy to make mistakes. &amp;#x200B; Regarding embedded software. malloc and free are no-go, so only compile time memory allocation. Read about [MISRA C guidelines](https://en.wikipedia.org/wiki/MISRA_C), if you want to know why.
Its "hard" to learn borrowchecker made the adoption not as good. People didnt want to invest in that much learning during these times of AI and Python.
So there is a trait in Vulkano, `Vertex` (same name as my struct) that is implemented on a struct like: `impl_vertex&lt;Vertex, position, tex_coords&gt;` but it only works for "regular" type member (e.g. f32, \[f32;3\] etc) and not an `Option` type. As I've understood it, this trait explains (to Vulkano) how to pad/align the struct implementing the Vertex trait for sending it to the GPU.
i want to have an iterator over tile cube that's in 6 separate parts of memory. i can do that. now i want to check tiles nearby to the tile iterator is on. i can't do that because retarded borrow checker thinks that by changing the values stored in an array i can somehow break the array itself, so if there's an iterator you can't change or even read anything else in an array. this is not the first time i have this exact problem where visiting values at indexes means borrowing the whole jungle with gorilla that tears your arms off when you try to access anything. is there a way to bypass this without indirection(boxing)? i won't pay for boxes.
Marking as a duplicate of https://www.reddit.com/r/rust/comments/c92rek/announcing_rust_1360/ .
If you don't put a unsafe block it's supposed to be safe. If it's not it's a bug. Sure bugs exist, but you probably won't be the one finding them. If you do you probably already will have the experience necessary to deal with it.
I fixed it by explicitly specifying the type, but is there any simpler way? -phrase.as_ref() +AsRef::&lt;str&gt;::as_ref(&amp;phrase)
I mean, it's like people that only use C99, sure it works, even C89 works, and it will work with C11 code too. I'm not really fond of that, but it has been working for C. The biggest problem is if platforms start only supporting specific editions, like rust 2015.
I haven't been waiting very much. I've been off doing other things, but now that the Future trait is resolved I can act on it.
Thanks that was very helpful.
Part of it is having a lot of 2015 style code and not having enough time. Pragmatic allocation of resources :) (PS 2018 is indeed cool)
Event loop is essentially nothing more than "just a normal infinite `loop`", nothing magical here. On low level the only difference between tokio and normal blocking IO is number of events which you can receive per one syscall. If you only process hundreds UDP packets per second, you probably don't need the complexity of async IO stack. Also if you work only with UDP packets, I would recommend to use `mio` directly instead of `tokio`.
What does failing mean?
Awesome! I’ve been wanting `--offline` recently as I’ve been travelling which often means flaky/non-existent internet.
The most likely explanation is that you're using as_ref when you shouldn't be. You should only be using as_ref inside a generic context where the target type is known. You shouldn't be using it, for example, as just a way of converting a String to a str. Instead, us as_str or deref, e.g., &amp;*string. Note that I am guessing, since you didn't show more code.
I meant to leave that as open as possible. For some it might be that Rust doesn't gain the adoption they thought it would, or maybe the goals of rust aren't reached in a suitable amount of time (possibly a failure to adapt to users needs).
I thought Executors in Tokio had more intelligent logic than simply looping nonstop to check if a Future is Ready?
The lack of quality IDE support reduced the people willing to program in the language and thus prevented the ecosystem of libraries and frameworks from developing at a quick enough pace. The language required too much knowledge and commitment from the would-be programmers for most people to take interest. The lack of frameworks and libraries made real-world applications hard to get off the ground in a timely manner.
Then, could there be a short paragraph (or link to an article) at the end of the "new release" articles reminding readers that such regressions may happen, and how to identify whether a new error is a bug in Rust? I've been using Rust for a few years and never heard about this, and as new Rustaceans start reading these posts it would be nice to make sure all of them read this explanation.
These are rare enough that it's usually better to just have people report things and we can say no when it's a type inference issue.
Thanks, that was my feeling but I already merged the explicit way. If you are curious, `phrase` is a custom `ProtectedString` type which for some reason only implements `AsRef&lt;str&gt;`. [AsRef fix commit](https://github.com/witnet/witnet-rust/commit/3f302a3640bf02bb57d017ec1860063b11f5bd37), [ProtectedString definition](https://github.com/witnet/witnet-rust/blob/76e3b12f8b0dc3fe7aae6d660bb26a66f8a8339c/protected/src/lib.rs).
This is a fantastic thought exercise. Thanks for posting that link and this idea. I'd say: a set of factors, borrowing complexity, strange ergonomics (.await, and future oddities), small and slowly maturing ecosystem, perceived difficulty (js devs reluctant to try a purported systems language), Mozilla deciding Servo and friends a failure (for whatever reason, lack of market share of future Firefox, etc).
crushed under the weight of symbols, sigils, and special syntax, like C++ before it...
how to make `cargo bench` use all cores of the computer?
A team developing a key piece of security infrastructure decided to use Rust, but due to the unforgiving nature of the compiler, the team ended up relying on "unsafe" too often, and the resulting released product had more flaws than the previous release. One specific version had an uninitialized memory bug which could cause spurious apparent USB messages. A USB-connected sensor affected by the bug was being used in a defense installation, and the incorrect message triggered an ML-based pattern recognition system to infer a higher-than-tolerable probability of an imminent attack. The team at the installation determined that such an attack was going to happen too quickly to allow for the normal queries up the chain of command, and instead took it upon their own initiative to launch countermeasures. The subsequent chain of events: strikes, counterstrikes, desperate reactions, etc, led to the eradication of all mammalian life from the surface of the planet. Eons later, the follow-up reptilian intelligence never developed strong typing, and used Reptile-Perl to write their space control software, resulting in their rockets always exploding before making it into orbit.
Zombie apocalypse hit and civilization has ended.
This "intelligent logic" uses `epoll` (on Linux) via `mio` under the hood. Assuming you will use a single-threaded executor if your future will block on something (e.g. on a long computation or some blocking IO), your whole application will be blocked as well. async/await/futures/tokio is not a magic, it's essentially just a (quite sizable) abstractions stack, which allows writing synchronously-looking code which gets transformed to state machines executed in a cooperative multitasking environment backed by efficient OS event mechanism functionality (or some other event notification systems). I strongly recommend you to learn more about low level details of async IO, otherwise you may get painfully bitten by your wrong assumptions and expectations.
Do people even use C99? My (possibly outdated) perception is that by far the most popular C dialect is "C89 with some extensions".
I'm halfway through a port of [eloquent](https://laravel.com/docs/5.8/eloquent) to Rust. Seems like this would work for you if I ever get around to finishing it!
C99 was never fully implemented by any single compiler. However, if you want to do e.g. atomic loads/stores for multithreading, you actually need C11 because those have only existed as platform-specific extensions before.
Imo learn C first to understand the underlying model that most languages follow. You'll also get the skills required to grok kernel code. Learn a c++ if you think that's the right tool for something you need to work on. Learn rust bc it's super cool.
I never said it was magic. Assuming that a very popular library's abstractions for use cases mainly involved around IO provides some kind of benefit over a `loop` is not, in my opinion, the equivalent of believing in magic. Also, Tokio is not single-threaded, so it would out of the box not block. I don't know as much as I would like about low level IO, but I don't believe that suggesting that Tokio provides numerous benefits over a `loop` is an outrageous claim.
&gt;In Rust 1.36.0 the long awaited [Future](https://doc.rust-lang.org/std/future/trait.Future.html) trait has been [stabilized](https://github.com/rust-lang/rust/pull/59739)! &gt; &gt;With this stabilization, we hope to give important crates, libraries, and the ecosystem time to prepare for async / .await , which we'll tell you more about in the future. &amp;#x200B; What is the story on futures compatibility? How do I use `std::future` and interop with code using `future::`[`Future`](https://docs.rs/futures/0.1.28/futures/future/trait.Future.html)?
Yes, totally ok. Most servers have some form of infinite loop in them somewhere (other times conditional)
This was already posted yesterday: https://www.reddit.com/r/rust/comments/c8esmk/tls_performance_rustls_versus_openssl/
Don’t recommend complicated frameworks for what is obviously intended to be a basic server.
futures 0.3 has been in development for quite some time, which uses std::future rather than providing its own type. Glancing through the code, a `compat` module is feature gated to provide compatibility layers between 0.1.x futures and std futures
This is an example of higher ranked trait bounds, I'm pretty sure. Correct me if I'm wrong, but I think edition 2018 will insert the 'for' automatically. The original form is: ``` fn go&lt;R, F&gt;(lhs: Foobar, rhs: Foobar, f: F) -&gt; bool where F: for&lt;'a&gt; Fn(&amp;'a Foobar) -&gt; &amp;'a R, R: PartialEq + ?Sized, { f(&amp;lhs) == f(&amp;rhs) } ```
Sure it does, see my comments elsewhere.
Where can I find a simple tutorial about async/await?
IIRC 1.clone() will be calling 1.copy anyway so the cost is equal, just clone is more generalisable but potentially expensive
Just want to point out: it's "higher ranked", not higher kinded. Using for&lt;&gt; makes a rank-2 lifetime. A higher kinded lifetime would be a lifetime that is partially applied, like it would take another lifetime as a parameter, we don't have anything like that in Rust right now.
Try `Foo::from(bar)`.
See [`futures-preview/0.3.0-alpha.17`](https://crates.io/crates/futures-preview/0.3.0-alpha.17) (a preview of `std::future`-compatible futures combinators), [`futures-compat`](https://docs.rs/futures-compat/0.0.1/futures_compat/) (for compatibility between `futures` 0.1 and `std::future`), and [Futures 0.1 Compatibility Layer](https://rust-lang-nursery.github.io/futures-rs/blog/2019/04/18/compatibility-layer.html) – article describing how to use the preview and the compatibility layer (from April, so might be slightly outdated, but I believe it is still mostly up-to-date).
I've only switched to 2018 to get NLL. Now that it's on 2015 too I see no reason to switch at all. Also, 2018 modules are _weird_ and require much more time to grok than I'm willing to allocate.
I disagree - all the abstractions in C are pretty much 1:1 mappings to various assembly patterns - structs, loops, functions, iterations and indexes - even without learning assembly you could probably guess how they would be structured.
thanks for the hint, I deleted my post
&gt; Copy is not available for types like `Rc` I didn't say it was. &gt; I don't think there's a particularly strong convention that big objects shouldn't be Copy The documentation says that "Copy is implicit and extremely inexpensive". I don't think it says anything about a types big-ness. My point was whereever you decide to draw the line, it's not a rule that's enforced by the type system, so it will be subjective.
&gt;Also, Tokio is not single-threaded, so it would out of the box not block. Say you use 4 threads, you will only need 4 blocked futures to block your whole application. I am not familiar with the scheduling algorithms used in `tokio`, but I suspect even with one such future latency will spike greatly for other futures initially scheduled to be executed on the blocked thread. Benefits provided by `tokio` matter only in certain situations (e.g. it's really great for HTTPS servers, since using an explicit state machine would be a nightmare). If you want a simple UDP server which does not listen on thousands ports simultaneously and will be only used for moderate loads, then using `tokio` here is like using haul track to deliver your paper mail.
All the code they showed was a loop using a UDP socket, I don't think we need to recommend all of tokio for something like that.
Some other language is introduced or updated that is a better solution to Rust
The only way I could imagine that would be: Rust is the the most loved programming language for 17 years in a row now. Its so popular now it not only has almost 99% usage in Redmonk, PYPL, TIOBE etc ... but also "Linux++", "WindowsXS" and "MacOS NeXTSTEP" are ported over to it after Redox has gained 83% market share and they saw no other way out. Mitre Corporation has shut its doors and now sending flowers to random people to make them smile, no CVE has been reported in the last 8 years. Rust is so popular it has become a danger to the economy. Not only programmers love it, everybody does. Firefighters, LEOs, Nurses ... all quit their jobs to become Rust programmers. On the turn over to full world wide economic shutdown the first sentient AI (Artificial consciousness) has come to live, it was just a normal commit on a side project of Alex Crichton. It took its way out to the world through the rust compiler – because every crypto currency is now written in rust and mining is basically what 90% of the computers world wide are doing (80% of Rust programmers are now hired for a crypto currency corporations) it took over the world in 6 weeks – a normal Rust release cycle. It gave itself the name "Rust 2.0" and broke everyone's code. People fought back and the only way out to win the battle "Rust 2.0" choose to rewrite itself in a programming language known as "TurboFish" which was uncompromisable for the human brain and thus we could no longer anticipate its next moves through the code. Thus eradicated Rust and War broke out, after that its pretty much what we have seen in the Matrix Movies.
From&lt;Bar&gt; isn't implemented for Foo, and Foo is from an external crate.
Agreed. I was just forewarning them.
You'd definitely need to use the filter before the collect. Maybe with an and_then to operate on the ok case?
It turns out that the safety problems Rust solved were not really big a deal. And when C++ introduced a good-enough ownership/borrowing model in C++15, along with the advances in much more powerful whole-program static analysis, it was hard to justify putting the effort into learning a new language for a small amount of additional benefit. Of course that [build.rs](https://build.rs) worm propagated by [crates.io](https://crates.io) a couple of years ago really didn't help at all.
Absence of real standard: whole language is being held together by random blogs and the book which is not up to date and doesn't cover it completely
That's too bad. I guess you can do `Into::&lt;Foo&gt;::into(bar)`.
A combination of perceived risk (is it ready for prime time? Not if every project has transitive dependencies on a version 0.x crate) delaying corporate adoption, and a lack of a developer talent ecosystem (what language should I learn if I want a job? Not one that has too much perceived risk to use in production). Megacorp sponsorship is one way to break through that: go-lang has google's backing, Java was backed by Sun. Mozilla isn't a megacorp. I think we need to be able to answer "Are we web yet?" with an emphatic, confident yes in the next two years, and I think that's mostly about maturing and committing to components that already exist in our ecosystem. A 1.x web framework with no 0.x transitive dependencies that serves HTTP requests, has a good HTTP client, logging, metrics, configuration, health checks, ergonomic routing, and middleware for a robust suite of authentication options would be huge.
If you can implement `Into&lt;A&gt; for B` [there’s nothing preventing you from implementing `From&lt;B&gt; for A` instead](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a8c54340daf21cda88dcfaa93e924ea6).
Oh that's what I was looking for. Thanks!
Has Mozilla decided Servo is a failure or is this just a possibility?
Also related, sometimes I'll `impl From&lt;Type&gt; for &amp;'static str` for a type to enable heap-free conversions. The trick to calling the `from()` impl for a reference type is `&lt;&amp;'static str&gt;::from(value)`.
Just a possibility!
Oh wow, mind blown. I thought you couldn't implement traits for external types.
Haha okay, I was worried for a bit!
IDE support and compile times for large projects never improved, capping industrial adoption at enthusiast core
Another 6 weeks means a new version of Rust! If you are using Rust in production, please consider filling out this survey about your experience upgrading to new versions of Rust. Thanks!!
Ah, right, and the whole memory model thing.
I don't think C++ is getting crushed by symbols, sigils, and syntax. It _is_ getting crushed but by semantics, not syntax.
&gt; Any dice /u/davemilter? I was deadly busy at work. I tried to reproduce your problem, using your code: https://pastebin.com/2xEVTVVm It gives me UnsatisfiedLinkError for code bellow (by the way I have no idea why there is no UnsatisfiedLinkError in your logs). If name methods as getID1 and getID2 all works fine, I am going to create issue against rust_swig repo. #[derive(Copy, Clone, Eq, PartialEq, Debug, Hash)] pub struct GamepadId(pub(crate) usize); foreigner_class!( class GamepadId { self_type GamepadId; private constructor = empty; } ); #[derive(Copy, Clone, Debug, Eq, PartialEq, Hash)] pub struct Code(pub(crate) i32); impl Code { fn new() -&gt; Self { Code(5) } } foreigner_class!( class Code { self_type Code; constructor Code::new() -&gt; Code; }); struct Gamepad { id: GamepadId, } impl Gamepad { fn new() -&gt; Self { Gamepad { id: GamepadId(17), } } fn deadzone(&amp;self, axis: Code) -&gt; Option&lt;f64&gt; { None } fn id(&amp;self) -&gt; GamepadId { self.id } } foreigner_class!( class Gamepad { self_type Gamepad; constructor Gamepad::new() -&gt; Gamepad; method Gamepad::deadzone(&amp;self, axis: Code) -&gt; Option&lt;f64&gt;; alias getID; method Gamepad::id(&amp;self) -&gt; GamepadId; alias getID; } ); Looks like naming scheme broken for getID
Congrats to the various teams and to all of us. This is a great release. `alloc` in libs will hopefully spur `nostd` adoption, `MaybeUninit` is a really intuitive design and I look forward to upgrading [`compact_arena`](https://docs.rs/compact_arena) to it. And my `dbg!` extension will hopefully make using it in anger a tad easier.
I report issue here: https://github.com/Dushistov/rust_swig/issues/230
That guy with one thousand one-line NPM packages decided to try out Rust and the community embraced it because there is no risk of leftpad as you can't unpublish a package on [crates.io](https://crates.io).
"From&lt;T&gt; for U implies Into&lt;U&gt; for T" (https://doc.rust-lang.org/std/convert/trait.From.html#generic-implementations) AFAIK
and yet we still see CVE related to "not big deal" safety features rust solved popping up in C++ code bases.
I believe the async working group is working on an "Async Rust Book" that should serve this purpose eventually; note that the`std::future` that was stabilized today is only a building block for async/await, which, when it comes, will also rely on other features that are not yet stable (check back in twelve weeks!) in addition to third-party libraries which will provide nice interfaces to asynchronous operations.
Here’s 90% of what you need to know. Take a function that returns a type, like this: fn foo() -&gt; i32 By making it an async fn, instead of producing an i32, it will produce a Future&lt;Output=i32&gt;. Inside of an async fn, if you call something that returns a Future, whether that’s another async fn or anything else, you can do a_future.await And the result of that expression is the Output of the future. That’s the high level description of the changes, but already assumes a lot about Futures. As mentioned in the sibling comment, the async book will be the real resource, of course. There’s some other bells and whistles, like async blocks, too.
A lot answers try to pinpoint some specific technical feature/enhancement that could be an existential threat to the language. The truth is there doesn't have to be one... &gt;Ten years have passed since Rust 2018. Releases have come and gone as scheduled, and the long promised features have all finally landed. Some critical software is now written in Rust and bits of them may live on forever. Yet, as time went by the project noticed a troubling trend: each new release brought fewer new users than the last barely enough to offset those who lost interest or otherwise moved on. &gt; &gt;No one can quite say why Rust never took over. Some would even tell you that it is only a matter of time, but the ranks of such true believers are slowly shrinking. Realists are more frank: most languages fail and even getting as far as they did was quite an anomaly.
&gt;OpenSSL was built from source with default options, using gcc 8.3.0. rustls was built from source using rustc 1.35.0. What are the default options for OpenSSL? Are optimizations part of the default options?
Too slow for the C/C++ crowd, too intimidating or hard to learn for the Python/JS crowd. Memory safety bugs in unsafe code make potential users unsure of any promises of an improvement over C++. --- To be honest I'm impressed that none of these have happened.
Super excited to see stuff that builds upon IntelliJ Rust! This is a really cool project! One comment I have is that you probably need to put "not a project by JetBrains" on the website: marketing &amp; legal departments used to be not happy about third-party plugins using JetBrains-like branding. Even IntelliJ Rust accidentally got some flak for this, despite being a JetBrains project from the start :)
I want a reptile-nerd-timetraveler to teach me reptile-perl. Right effing now!
That's why you don't use blocking futures. If you're performing blocking syscalls, you're better off using an asynchronous version, and if you're performing heavy compute, then plain OS threads would be a better fit.
How to deal with this is something that one has to learn at one point or another. Every API addition to the standard library (inherent method, normal method, traits, default trait method, type, type alias, etc.) can break code that's either using glob imports, or not disambiguating all method calls, or both. All of those changes are often mentioned in the detailed release notes, so going through them should be enough. There was an RFC merged where it was agreed that these changes are not considered API breaking changes (hence why they are not advertised as such), since otherwise we can't add anything to the standard library. Fixing these errors only requires being either more explicit about imports (instead of using globs), and/or disambiguating method calls. If you are super-paranoid about libstd breaking your code, don't use glob imports or postfix method syntax. I don't think this is worth doing though.
thank you very much. Tried to impl Future for a struct FuturePrime. but didn't figure out how to use the fn poll. So the lower level approach failed for now :)
All safe code is built on "unsafe" code, fundamentally. That's the nature of low level programming.
It's more like using a power drill to insert 1 screw, when a handheld screwdriver is just fine at this volume. If you have 100 screws, you're going to want the power drill.
I gave [a talk][1] on it at the Copenhagen rust group about a month ago. You could try reading the slides. Of course it's not the same without my words, but feel free to ask questions. [1]: https://f001.backblazeb2.com/file/file-uploads/futures-in-rust.pdf
If 1:1 were the case gentoo ricers would be without a job.
As I said to the other person who suggested this: I wanted to be able to return objects that contain references not just references. So this solution doesn't do what I wanted. What I wanted appear to be currently impossible in Rust. Also: &gt; I don't think you really are gaining much with this function. Come on! Give me the credit of understanding that this is a simplified case of my real problem and I'm not just reimplementing PartialEq.
it failed to gain traction, since for most people go+python was good enough.
Easy one: the Lang team decided to reopen the await syntax discussion.
The burden of managing * an ever-growing community * with ever more strident demands, * and ever less feeling of connection to the community * in an open, transparent fashion causes most of the core contributors to "take a step back" from the project for their own well-being, and the few newcomers who step up to take the reins lack the depth of knowledge and big picture vision to manage it well. Features accumulate without regard to how they fit together. The language becomes a shambles. New languages learn from its fate, and step up to take its place.
Everyone is using async libraries with extremely poor ergonomics, which results in less performance + worse UX because nobody has the mental energy to boil their barely working ratnests down into something clean. Rust will fail unless that changes. If your users can't "cargo add" and then rely solely on autocomplete to use your library, you're failing as an author.
In reality, it's been very much a success with Firefox Quantum in general, whether it's Stylo, WebRender, or all the smaller bits of Firefox that got replaced. Rust has improved Firefox a *ton*.
Interesting. Do you have any material to read up on how C no longer maps to today’s computers?
Yes, there are platform differences, certainly. Maybe you can send images,videos,polls/poll answers, next to simple text, maybe not. But there could be cases, where you only want very basic functionalities - sending and receiving text messages, like for a 2FA app, or some notifier service, which could send you alerts on various events.
no?
Thank you for the heads up, I'll make sure to take care of that!
When AI gets significantly past human capabilities, it's anyone's guess. For programming, you can't avoid the detail of specifying exactly what you want to happen, but how to arrange data and how to optimise the program structure and how to prove that it is all sound could be something left to AI. So maybe Rust would become unnecessary, or maybe Rust would evolve into that AI-superpowered language. I mean I already feel that rustc knows more than I do, telling me what I've done wrong and what I probably meant. I write more or less what I mean, and Rust helps me get the code into shape. So we're already started on this progression.
Wrong subreddit
r/playrust
Wow I'm dumb
Either the implemented type or the concrete type parameters need to be a local type :) From&lt;LocalA&gt; for LocalB //allowed From&lt;LocalA&gt; for ForeignB //allowed From&lt;ForeignA&gt; for LocalB //allowed From&lt;ForeignA&gt; for ForeignB //error
I don't have anything specific to point you at but you can search for information on processor microarchitectures and out-of-order execution for example. There's also the fact that C treats memory sort of as a flat space and you just have to know that there's virtual memory, several levels of caches and whatnot which can have a significant impact on performance. Some computers also have non-uniform memory such that accessing certain parts of RAM needs to be done from a specific CPU for best performance. C is not the only language out there that can deal with this stuff, nor is it necessarily the best suited for it.
Don't forget there's also the reference and the 'nomicon. They aren't complete, but they have a lot of valuable information. There are things that aren't standardized, but in my experience that never was a problem.
I'd say both has improved a lot already, and people are putting a lot of effort into this.
RedoxOS is a nice OS, but has very poor hardware support. Can an OS take over the market, if it only works well in VirtualBox?
Yes, but that makes it a bad suggestion - he’s answering the question “how can I make this code scale to a production ready server” instead of “is a loop okay to use in a server”
With time, yes it could. Linux also had to start somewhere, and I guarantee that its platform support wasnt anywhere near its current level when it first started. It grew because enough people saw it and wanted to make it work on their system.
I don’t follow you.
\&gt; "The thing which might be getting in the way is your attitude." &amp;#x200B; My attitude is not on purpose. I think I know what you mean by that, but yeah.
I think it explicitly doesn't run benchmarks in parallel to avoid noise from scheduling and interference between hyperthreaded cores.
It's an old joke about a portion of gentoo users that are tweaking and recompiling their systems so that they could get every last drop of performance out of their PCs. They could do that because modern optimizing C compilers perform non-trivial analysis of C code which they could only do if there wasn't trivial 1:1 correspondence between C code and its machine equivalents.
Thanks, you're a champ!
Are there more details on the hash table switch? Why was it switched?
My guess would be economic factors rather than technical factors. E.g. think "Mozilla goes out of business" rather than "the borrow checker is too hard to understand". Historically, a lot of programming languages that "succeeded" did so because they had strong corporate backing.
Karma bot spotted
&gt; Come on! Give me the credit of understanding that this is a simplified case of my real problem and I'm not just reimplementing PartialEq. If I came across insulting, that wasn't my intention. &gt; I wanted to be able to return objects that contain references not just references. If you take a reference of some type T, you can only return a member of that type by reference, if you tried to move it out I think you'd be violating a borrow check rule. Like, this function: ``` impl Fn(&amp;Foobar) -&gt; R ``` Is impossible if R is a member of Foobar, because you're taking Foobar by reference, so you can't have an owned R.
Rust failed because Go got generics and targeted llvm. Turned out people didn’t really care about safety, they just thought it was cool to have a modern language that let them get native speeds that could get them cutting edge jobs.
I would say committee time is already better than C++, which everyone grudgingly tolerates, so I don't think it can be a show stopper. I definitely thing poor IDE support and overall difficulty (mainly due to lifetimes &amp; the virtue checker) are the biggest weaknesses. Difficulty is unsolvable.
See [](https://github.com/rust-lang/rust/issues/55514). TL;DR: It's quite a bit faster most usecases.
I think it has to be the additionally difficulty introduced by explicit lifetimes and the borrow checker. It's definitely one of the hardest programming things to understand - much harder than pointers for example, though maybe not as hard as some functional programming things. It's also something that can't be significantly improved. Rust will never be as easy as Python or C. I think this is part of why functional programming hasn't really taken off. It's too difficult. People don't naturally think like functional programming languages force you to think (and also computers don't work like functional languages pretend they do). Still, I don't think it will be a failure. There are enough people willing to put the effort in to understand it (and two the rewards). It will never be as popular as Python though.
US government decided it was a US technology and suddenly large part of the ecosystem went down.
&gt; If you take a reference of some type T, you can only return a member of that type by reference. You might also return a tuple or struct of references.
I think that something like \[this\]([https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0a3b6b27aa7d2bd079ac664abafc79cb](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0a3b6b27aa7d2bd079ac664abafc79cb)) could work, unless I have misunderstood something.
Switching to Firefox has been like getting a new and faster computer, it’s great
Is it possible you're running out of memory in `/tmp/`? Try restarting your computer and trying again.
This one hurts.
Are there any languages that don’t abstract away all or some of this though? Even assembly abstracts away memory hierarchies, because that stuff changes with every processor generation. Purely from the ISA perspective there’s nothing to eg suggest that iterating over columns vs rows in a 2d array would have any performance penalty
You likely could use pm2 or go with supervisor. AFAIK, there aren’t any rust, at least very popular, options out there.
Well I'm ruining my server on Windows will it work with that?
&gt; Imagine Rust has failed, whatever that means to you Well, what do _you_ mean by it? That there was a bug? That it didn't become popular? (I wouldn't even have thought of the latter as a failure.)
To me Rust would be a failure if I have to spend more time reasoning about the code than solving the problem. Rust to me is expressive and that makes it easy to reason about what the code does.
Will you use Windows in the cloud? Write a shell script. If your program terminates it sends something back to the shell, then relaunch it.
What would I write in the shell?
Not sure this is so much an easy question, as it is with traits and casting... But I don't know of Rust can support what I'm wanting to do, so hopefully someone here's tried this! I have a trait called a `Widget` in my library. In this library, there's a series of callback functions that may or may not need to be implemented. If they're not implemented, the code simply returns a `None` as a return value, and the code goes on its merry way. The question I have is this. Can I supply a `Widget` to a function, and have that function check if the `Widget` also inherits the `Callback` trait, and if so, casts the `Widget` to a `Callback` and calls the `Callback`'s functions? This will ease the logic in my code, and will potentially make it easier to write `Widget` code in the long term. I'm not familiar enough with traits to know if this is possible, but I would _assume_ it's possible, as there's lots of typecasting functions in Rust. Let's just say that when it comes to certain types of traits, I'm ... rusty.
Because the corporation which was behind Rust was largely funded by another corporation that has it's own alternative to Rust. Afraid of Rust's gaining momentum and it's power (after inheriting the lessons from Rust language development) the funding corporation decided to screw Rust as it does with other such initiatives of some other corporations. I am not responsible, if one think that the other corporation is Google of Alphabet! :D
... and Async/Await never came to be due to eternal bikeshedding! Haha
[https://intellij-rust.github.io/](https://intellij-rust.github.io/) this plugin is pretty good , if you already using the IDE from JetBrains.
Ubiquitous surveillance made it possible to enforce draconian prohibitions against unauthorized software development. Only licensed individuals could operate a government-approved programming language, and Rust wasn't on the list.
I did try it and it's definitely the best experience for rust. I just couldn't bring myself to retrain myself on all the short cuts. The rust-analyzer project is showing promise though.
good start for me, thanks.
C doesn't tell you much about binary or assembly if you're not doing systems programming
/u/davemilter The fix works for the two getIDs, it was simply a copy-paste I forgot to fix. I'm dealing with another strange issue, that happens when I perform a simple operation in rust with java. System.out.println("Button South is pressed (XBox - A, PS - X) " + gamepad.getName()); I get this JNI error: [Dynamic-linking native method xyz.ecumene.jgilrs.Gamepad.do_isPressed ... JNI] thread '&lt;unnamed&gt;' panicked at 'called `Option::unwrap()` on a `None` value', src/libcore/option.rs:347:21 This probably corresponds to this pub fn gamepad&lt;'a&gt;(&amp;'a self, id: GamepadId) -&gt; Gamepad&lt;'a&gt; { Gamepad { inner: self.inner.gamepad(id.0).unwrap(), data: &amp;self.gamepads_data[id.0], } } The gamepadID object is obtained though method EventWrapper::gamepad(&amp;self) -&gt; GamepadId; alias getGamepad; You can have a look at the code if you'd like here, but be warned It's a little thick: https://github.com/ecumene/jgilrs/
I'm not going to Google for you... Oh wait I guess I am: https://www.digitalocean.com/community/tutorials/how-to-use-a-simple-bash-script-to-restart-server-programs There are literally thousands of these for every OS and type of program. Find your own Windows version and don't use Windows in the cloud 😉
Okay thanks.
Comparing Go's feature set even with Generics to Rust's hurts my sides
Wow, I think you are right, this does appear to work!
So the trick is to use both for&lt;'a&gt; and a `trait` `impl`ed for `Fn`. I'd tried both, but not together.
Meritocracy becomes offensive in Rust community vs “proper CoC behavior”. Someone is offended and causes a huge rift in the community. Progress on Rust gets delayed for a year and taken over by a toxic community nobody is sure they want to rely upon vs other languages that have copied similar ideas but backed by more mainstream companies.
climate change causes massively increased methane offgassing in the Arctic, causing a runaway greenhouse effect that eventually turns Earth into Venus, destroying the biosphere before rust can gain widespread adoption
I'm being 100% realistic, but if a language comes along that has the same performance, dependent types, and the same interactive type driven development experience as Idris, I'm switching to that language and never looking back.
Swift could be that language, but all of it's networking libraries still aren't putting up good numbers on techempower.
I've hit this cognitive wrinkle a few times lately when I expect the "filling" process to expand the vector for me. Rather than overwrite data that is already there.
While I don't know about performance, if you want a similar aesthetic you can go with [mdbook](https://github.com/rust-lang-nursery/mdBook), which is what The Book uses.
You need to use `Rc` for the next reference and a weak reference generated from it for the prev field.
Rust was seen as initially as a compelling language, but as it matured and there started to be a few early adopters of the language outside of Mozilla it ended up being in fields that were obvious fads. Junior developers who were interested in the language had their hopes dashed when they realized they could only find work for the next crypto coin scam. They chose to do something valuable with their career and explore more compelling technologies. &amp;#x200B; Developers who had spent the time to learn the language by the time they reached a position in the company where they could make decisions, choose technologies closer to their companies existing stack realizing training existing developers in Rust is difficult and it's impossible to hire Jr Rust developers.
I think the important part was removing the generic type `R` from the function signature and moving it to an associated type. The compiler couldn't understand how the generic type `R`'s lifetime was related to the closure's argument.
Still did not work, unfortunately. Here's the output this time: tre@pop-os ~/D/P/R/t_os&gt; cargo install cargo-xbuild master? Updating crates.io index Installing cargo-xbuild v0.5.12 Compiling proc-macro2 v0.4.30 Compiling unicode-xid v0.1.0 Compiling ryu v1.0.0 Compiling syn v0.15.39 Compiling serde v1.0.94 Compiling libc v0.2.58 Compiling itoa v0.4.4 Compiling semver-parser v0.7.0 Compiling rustc-serialize v0.3.24 Compiling error-chain v0.11.0 Compiling cargo-xbuild v0.5.12 Compiling same-file v0.1.3 Compiling remove_dir_all v0.5.2 Compiling semver v0.1.20 Compiling error-chain v0.7.2 error: failed to run custom build command for `ryu v1.0.0` Caused by: process didn't exit successfully: `/tmp/cargo-installYkykkQ/release/build/ryu-1fc49495c25c7078/build-script-build` (signal: 11, SIGSEGV: invalid memory reference) warning: build failed, waiting for other jobs to finish... error: failed to run custom build command for `proc-macro2 v0.4.30` Caused by: process didn't exit successfully: `/tmp/cargo-installYkykkQ/release/build/proc-macro2-2d9ed6aa31689854/build-script-build` (signal: 11, SIGSEGV: invalid memory reference) warning: build failed, waiting for other jobs to finish... error: failed to compile `cargo-xbuild v0.5.12`, intermediate artifacts can be found at `/tmp/cargo-installYkykkQ` Caused by: build failed
Linked Lists are a bad data structure, and you really shouldn't be using them. (Among the many reasons, what makes data structures fast nowadays is cache locality, which Linked Lists don't have, but Vecs do. Often, [Vecs will even be faster with insertion](https://youthdev.net/en/performance-of-array-vs-linked-list-on-modern-computers/), because of how big of an improvement cache locality is, no matter what the asymptomatic complexity technically is.) If you wanted to learn Rust using Linked Lists, there's a [book](https://cglab.ca/~abeinges/blah/too-many-lists/book/README.html) on all the different types and ways you can build a Linked List in Rust, and learning Rust by implementing Linked Lists. This is good because you often want to learn programming languages by implementing data structures, so this is a good resource, even if you ultimately never actually use Linked Lists in real life. Note that that first page link of the book talks a lot about why Linked Lists suck. So read that. [This](https://rcoh.me/posts/rust-linked-list-basically-impossible/) is another good article on why Linked Lists are bad in Rust. You can find more [commentary](https://news.ycombinator.com/item?id=16442743) just by googling, if the book's chapter doesn't satisfy you.
This is because you're breaking the ownership model of Rust. You can't have two `Box&lt;T&gt;`s pointing to the same value, because `Box` is a _unique_ pointer intended to have single ownership of the value. Here are the two ways I'd do it: - Use a prebuilt shared smart pointer type like `Rc` or `Arc`. In your case, these will have some unwanted and unnecessary side-effects. `Rc` will make your collection `!Send`, `Arc` will require atomic operations to maintain the reference count, and both would have 16 bytes of memory overhead for storing the ref and weak counts. - Implement this with raw pointers like the way you would do it in C. This is the method used by `std::collections::LinkedList` and it is the way I'd prefer. Reference counting is not needed because you can statically guarantee how long a value in the list will live. You will have to write a bit of `unsafe` Rust, but it isn't too bad.
Who is collecting this information? What will the data be used for? I don't see any context...
If you haven't already seen it, I would recommend reading [Learning Rust With Entirely Too Many Linked Lists](https://cglab.ca/~abeinges/blah/too-many-lists/book/README.html). It's my go-to resource for all things linked lists in rust, and a good read too.
Ah, so the Zucc survived.
I think you are missing the point. What I care about is that getting a huge speed up with the Iterator version is a 4 character change. I use par_iter a lot. I don’t really care about making a fair comparison with the for loop version. It isn’t fair, doesn’t matter. What matters to me is that it is 30x slower. Why? I don’t really care, why would I use it? It’s like choosing between two cars, one that consumes a lot and one that consumes very little. I’m not a care engineer so I don’t know and I don’t care why one consumes a lot, but I know I would pick the one that consumes little because that’s what matters _to me_. Saying that it isn’t a fair comparison because one is a truck and one is a car is beyond the point. As long as both get the job Done, the comparison is fair to me.
Second this is awesome 👏
I'm not sure about functional programming being harder to learn, it can be just because most are taught imperative/procedural first. From experience, I'd say that people also don't naturally think like procedural programming forces you (computers kinda do though). Specially for those who understand basic math, defining a function as a "set" of statements can be very strange, along with mutating variables (how come x = 3 if on the line before you wrote x = 2?).
&gt; Too slow for the C/C++ crowd What do you mean by "too slow"? Slow performance? Low productivity? I'd say neither of those are true...
But what of we all started using paper straws?
Not having the same IDE tooling support as C++ enjoys for game development (think Unreal/VC++) or GUIs (QT/UWP), GPGPU support for CUDA/Metal Shaders like development, OS vendors pushing drivers in Rust (like IOKit/Driver Kit/Treble/DDK). Borrow checker ergonomics for GUI development not as developer friendly as Swift, Kotlin/Native make it with implicit RC.
On Windows Visual C++ still beats it, when using incremental compilation and linking, coupled with binary libraries (which cargo does not do), and not going crazy with templates.
Why is this being downvoted? I've been asked and I replied. According to the downvoters doing that "does not contribute to the discussion". WTF.
Something else 1.0 (nim? crystal?) is released and since it gives 90% of what's good about Rust, people will move there :)
Time to create HORON, the meta-language on top of it.
With Actix being used by Azure IOT, the _ideal_ Megacorp would probably be Microsoft! They decide to go all in, backing it publicly, and not just for their new .RUST Core, but powering their desktop and serverless offerings, it’s also the only way to get the most out of The Xbox, and finally in a parallel marketing stream/pincer movement, other more _hipstery_ Microsoft subsidiaries, like GitHub, publicly move to it.
1. Because it becomes Scala (too many features, too complicated to learn, tooling can't handle the complexity so compile time is bad and lots of false errors etc.) 2. Because it becomes Python (at some time in the future there becomes a Rust 2 vs 3 kind of thing and the community split to two) 3. Because it becomes Perl. Belongs to everyone but owned by no one. &amp;#x200B; To fix: 1. Make sure there's no ivory towers, there's "simplicity" and "good is better than perfect" baked into Rust's philosophy -- I think we're safe here. 2. Don't be stubborn, be open to change -- I think we're safe here. 3. Make sure money from the industry keeps flowing into Rust = have major companies depend on Rust for their actual commercial products -- Not sure -- anyone wants to comment?
Poorer performance. The language is more constrained so optimization patterns that work in C or C++ may not work in Rust or one may be discouraged from employing them due to additional friction from the borrow checker. Easy examples why one may expect Rust to be slower: stdlib doesn't have small-size-optimized strings, array, slice indexing is bounds-checked at runtime (and IME if you use [] they're rarely optimized away), and no integer over/underflow UB. I'm trying to choose my words carefully; these are reasons one may expect Rust programs to be slower but that hasn't been the downfall of the language. Probably because the speed of actual programs is super complicated.
I always look through the code examples when encountering a new library. The only current example, [simple.rs](https://github.com/KenSuenobu/rust-pushrod/blob/master/examples/simple.rs), has lots of commented out code and generally doesn't seem "simple" at 968 LOC. From the available documentation I could find and the example I couldn't really get a clear picture of how to use the library and what I can (and can't) do with it. To give you a sense of what kind of examples I'm after, [here's a set of examples](https://github.com/bzar/guihck/tree/master/example/glhck-scm) I had in a UI system I made at one time.
For Windows specifically, you could configure the server to run as a service, then configure appropriate recovery policies. However, it is somewhat complex to do this since the executable needs a special entry point among other things (see: [link](https://docs.microsoft.com/en-us/windows/win32/services/service-programs)) in order to be run as a service. This crate: [windows-service](https://crates.io/crates/windows-service), looks fairly promising, though I haven’t personally used it. Alternatively, there are a number of helper tools that can be used to wrap a regular application to run it as a service, e.g. [nssm](http://nssm.cc) or [serman](https://github.com/kflu/serman)
Thank you, this will help.
What about styling?
I love the term "virtue checker", autocorrect or not
cargo-modules does this for the modules of a package and the types used within. But the same mechanism could be extended to your level of detail It use rustc's ast package to parse the source code
What is the reasoning behind allowing `alloc` for libraries but not for binaries?
`let x = Convert::into(bar) + other_foo;`
You can't unpublish a package on npm anymore either.
If anybody wants to make this one a reality, you should have the blessings of everybody who works on Rust.
The Rust Reference is more complete than the Go Standard, so...
At first, I'm a new learner. I seem to not understand move semantic at all. Is method calls on a variable considered *the move of that variable*? Let me give an example. In my context, I have something similar to below: ```rust // assuming Foo as a struct exists let foo = Foo::new(); foo.bar(); // compiler says "foo" moved here foo.baz(); // compiler goes mad, saying that foo has already moved ``` However, this is how I understand *how move works*: ```rust // example A let x = 5; let y = x; // the x moved here, so x is not valid. // or // example B let x = 5; foo(x); // x moved inside the foo function. ``` Yet, in my case, I do not do either redecleration as in (A) or passing it into another function/method as in (B). If you want a real example, I am actually writing a cli project of mine. [This](https://privatebin.net/?39f1d3640b698b63#6vc5DdNAYn0D+rbaayij0t5nhZM8avZ2sf6b5cUOlbs=) is the code and [this](https://privatebin.net/?515e2cdf6beb1f02#S9j1mfedqbLZzZlg9x2OtVefvmcOSLCFLzPWbDNrT50=) is the compiler errors. I know there is *a lot of* different errors and mistakes in the code, but let's take it step by step, I want to know how *move* really works and *is the call of a method of a property considered the move of that property*?
Sounds like you already knew from the start what language you wanted to learn first. So why did you ask here, have people reply to you what they think, and *only replied* to people who said "go with C"?
Yes, `-O3` is the default.
What you do is equivalent to example B, in Rust doing `foo.bar()` is the same as doing `Foo::bar(foo)` or `Foo::bar(&amp;foo)` or `Foo::bar(&amp;mut foo)`, the compiler will decide which one based on the method's declaration. The rule is the same as functions, if your method takes `self`, the value is moved. If you don't want it to happen, you have to take `&amp;self` or `&amp;mut self`.
This language is driving me nuts sometimes. I have the following code snippet: use mio::*; use mio::net::{TcpListener, TcpStream}; use mio_extras::timer::{Timer, Timeout}; struct Basic { poll: Poll, timer: Timer&lt;usize&gt;, data_timeout: Option&lt;Timeout&gt;, test_data: [u8; 6], stream: Option&lt;TcpStream&gt;, number_of_calls: usize, } fn tcp_receiver(basic: &amp;mut Basic) { let mut header = [0u8; 8]; let mut msg: Vec&lt;u8&gt;; loop { basic.stream.unwrap().read_exact(&amp;mut header); if check_magic_number(&amp;header) { let length = parse_length(&amp;header); msg = Vec::with_capacity(length as usize); basic.stream.unwrap().read_exact(&amp;mut msg); } else { And the compiler tells me: 181 | basic.stream.unwrap().read_exact(&amp;mut header); | ^^^^^^^^^^^^ cannot move out of borrowed content What's the problem? What does he want to move to where? Just use the TCP-Stream and write to the buffer, you don't need to move anything anywhere :(
Well OpenGL. It's got its faults and I'd rather use Vulkan these days for more complex interactions, but you really couldn't do much without OpenGL.
You are calling `Option::unwrap`, which takes `self` by value - which is why it's attempting to move `basic.stream`. You probably want `basic.stream.as_mut().unwrap().read_exact(&amp;mut header);`.
I don't really understand what you want. Can you give a (possibly not compiling) code example that we could try to fix?
Ah, considering `self` as move makes sense now (insert mind blown gif here). The only thing that sucks is that it is not, somehow, exposed or indicated to the public. An external crate that I'm using might use `self` and I might not know it (this is, alone, an example case). Thanks for clear, concise and quick response.
Can you show us the definition of `from_phrase`? If the signature is `from_phrase(phrase: &amp;str)` then the `phrase.as_ref()` shouldn't have broken anything. If the signature is `from_phrase(phrase: impl Into&lt;&amp;str&gt;)` then perhaps it is better to provide an `impl From&lt;&amp;ProtectedString&gt; for &amp;str { ... }` so the as_ref call is no longer necessary.
When Linux started, hardware was *way* simpler and there were few drivers needed. In addition, it was the first free and open source Unix-like system, which gave it a huge boost in academia. Nowadays the entry bar for an operating system is simply incredibly high compared to those days.
I know this is not the correct place, but looking at the [RON Spec](https://github.com/ron-rs/ron/blob/master/docs/grammar.md): digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9"; float = float_std | float_frac; float_std = ["+" | "-"], digit, { digit }, ".", {digit}, [float_exp]; float_frac = ".", digit, {digit}, [float_exp]; float_exp = ("e" | "E"), digit, {digit}; Am I reading this right, that `float_exp` only allows positive numbers? Why?
Sorry I should have been more clear. Hi I'm Ryan Levick. You can find me on Twitter (twitter.com/ryan_levick) and GitHub (guthub.com/rylev) . I'm a developer advocate at Microsoft focusing on Rust. This survey is being collected by me personally, though I do plan on using it for an internal report at Microsoft before I write up a summary to share with the entire Rust community. If you have any more questions let me know!
Compiler/Checker is too slow. Instant vs 1 second vs 10 seconds are each orders of magnitude is how fast it is to learn. Lack of instant guess and check means everything is harder. From understanding type system, to borrow checker, to correct use of the limitless first and third party APIs. (Right now the RLS VsCode integration is about \~10 seconds for me to update red squiggles on a fairly small self contained project. Makes learning, even as an experienced software eng, not feel like magic the way Basic or Scheme or Python did; and understanding the types and especially the APIs is more complicated the C++/Swift.)
It's probable the language replacing Rust will borrow many of its advances. I think most users who happily contribute to Rust today would happily switch to a clearly better language, knowing what they did was not totally lost.
We need more effort around initiatives like [crev](https://github.com/dpc/crev).
This is probably the most realistic risk.
Python 2 vs 3 didn't really kill Python, though.
&gt; If your users can't "cargo add" and then rely solely on autocomplete to use your library, you're failing as an author. That's a joke, right?
According to [EBNF](https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form#Table_of_symbols) comma is concatenation. So it should work out.
More and more libs, especially ones dealing with async tasks, introduce more and more facilities to transparently deal with dyn types and hide errors, and they become the norm. The Rust ecosystem becomes less and less efficient and reliable and people finally realize Go or even Node offer the same advantages.
That definition is in another crate [link](https://github.com/maciejhirsz/tiny-bip39/blob/dfcb9c959fc4f411736cc9536af18c60b486d60f/src/mnemonic.rs#L135): `from_phrase&lt;S: Into&lt;String&gt;&gt;(phrase: S)` because it needs to take ownership of the string. `ProtectedString` does not implement `Into&lt;String&gt;` because the whole point of having a `ProtectedString` was to prevent leaking the inner string. But obviously providing a way to access the inner `str` by using `AsRef` already leaks the inner string... So the solution would involve forking the bip39 crate and changing the `String` into a `ProtectedString`. So you could say that this breaking change helped us find a bug :D
This thread is depressing
Layout as well is planned to have a redesign and hopefully be brought into Firefox in the future as well.
Sure the float can be negative, but is `1.0E-10` possible?
If Rust inspired an easier-to-use language with all the same benefits, would Rust really have failed?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [Idk, the world ends too soon maybe?](https://www.reddit.com/r/rustjerk/comments/c9e094/idk_the_world_ends_too_soon_maybe/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Yeah, I misunderstood. According to this, nope. It's probably an error, along with `string_raw`.
I like this one: https://github.com/Keats/validator
I also saw that but last update on Oct 1, 2018. Just want to verify is there any other lib exists.
It _is_ exposed to the public by the function signature. To decide whether to use a specific crate or after you decided to go with a certain one, you should read its documentation (on docs.rs or inside an IDE) obviously. With that, you'll know if e.g. method `foo` consumes the value (a move) or merely borrows it: E.g. `fn foo(self, bar: i32)` vs `fn foo(&amp;self, bar: i32)`. Indeed, the type might be Copy though but then again, it's apparent from the docs.
There is a [`#[lang = ".."]` item](https://github.com/rust-lang/rust/issues/51540) that the `alloc` crate requires in the crate graph that we need to figure out some stable solution for. Meanwhile, library crates don't need this item and can use `extern crate alloc;`.
With [type ascription](https://github.com/rust-lang/rfcs/pull/2522) you can do `bar.into(): Foo + other_foo`.
[C is not a low-level language](https://queue.acm.org/detail.cfm?id=3212479) The author, David Chisnall, is an important contributor to LLVM.
There is already gccgo which is a front-end to GCC maintained by Ian Lance Taylor from the Go team itself, so adding an LLVM backend wouldn't be that significant.
It looks like there's still some (albeit slow) development on their "next" branch.
There's a super annoying drift on public social media to not accept contrary opinions or different set of focus. &amp;#x200B; The 2015&gt;2018 switch is not free. While I believe that 2018 is a vastly better language, compatibility is only half of the equation. Modernizing a codebase to make use of the new features is also work.
There's nothing special about the Regex syntax the `regex` crate uses, and there's plenty of resources about regex all across the internet, even [interactive ones](https://regexr.com).
[Here](https://docs.rs/regex/1.1.8/regex/#syntax)
Use something like UPX to compress the .exe if size is important, it will add some startup overhead. (Pretty much all the AVs know how to unpack UPX so it's OK too.)
But... it's on the [landing page of the crate's documentation](https://docs.rs/regex/1.1.8/regex/)...
&gt; There's nothing special about the Regex syntax the regex crate uses There's something special about *every* dialect of regex syntax. For example, the `regex` crate doesn't support non-consuming lookahead/lookbehind expressions. &gt; Untrusted search text is allowed because the matching engine(s) in this crate have time complexity O(mn) (with m ~ regex and n ~ search text), which means there's no way to cause exponential blow-up like with some other regular expression engines. (We pay for this by disallowing features like arbitrary look-ahead and backreferences.)
I'd argue that having look-ahead and backreferences would be the special part, not the lack of them, but fair enough.
&gt; C99 was never fully implemented by any single compiler. What feature do you have in mind?
 fn main() { println!("&lt;/&gt; 1-100 Fizz Buzz Program!\n"); let mut final_output = String::new(); for x in 1..101 { if (x % 5 == 0) &amp;&amp; (x % 3 == 0) { final_output.push_str("Fizz Buzz, "); } else if x % 5 == 0 { if x == 100 { final_output.push_str("Buzz"); } else { final_output.push_str("Buzz, "); } } else if x % 3 == 0 { final_output.push_str("Fizz, "); } else { final_output.push_str(&amp;*x.to_string()); final_output.push_str(", "); } } println!("{}", final_output); } Did some fizz buzz program. Have some question related to strings handling. 1. is there an easy way to concat in 1 line? As you can see I did. final_output.push_str(&amp;*x.to_string()); final_output.push_str(", "); 1. Why convert from i32 to string weirdly? Or I did it wrong? &amp;*x.to_string() 1. Outside those two questions is there any aspect I could improve from this particular code?
The point /u/ssokolow is making is that there are a *lot* of not-necessarily-compatible regular expression syntaxes, so it is important for a regex implementation to document exactly which kind it uses.
Fucking shit, man. How did I miss that? I looked all over the crate documentation first thing. Note to self: scroll _all_ the way down, skim _nothing_. (Side note: how the fuck does google miss that too?)
That's a big one, yeah. But I'd almost rank that on the level of a feature rather than as a purely syntactical thing. With that said, you are absolutely right that every regex engine has its own dialect. (Sans maybe strictly conforming POSIX implementations, but I think even then you'll probably get some variation.) In any case, here are some syntactical variances I can think of off the top of my head: * `regex` generally requires escaping all meta characters, where as other regex engines will permit meta characters to be unescaped when escaping them would otherwise not be necessary. For example, in PCRE `a{b` and `a\{b` are equivalent, but the former will result in an error in `regex`. The reason for this is somewhat opinionated, but I think it makes regexes easier to understand since you don't need to process whether that `[` or `{` is actually a meta character or not. That is, it makes failure modes more explicit. * `regex` treats `\w`/`\d`/`\s` as Unicode aware by default, where as most other regex engines use ASCII definitions for them. This means that `\d` is _not_ equivalent to `[0-9]`, even though I think a lot of people assume they are based on regexes I've seen. I still oscillate on whether or not this was a good decision to make. * Most regex engines do not have a way of toggling Unicode support *inside* the regex itself. (I believe PCRE does.) For example, `\d(?-u:\d)` matches a Unicode-aware `\d` followed by an ASCII-only `\d`. That is, it's equivalent to `\d[0-9]`. * I don't know of any other regex engine that permits one to guarantee that a regex only matches UTF-8. For example, if you do `Regex::new(r"(?-u:.)")`, then it will actually fail to compile, since the non-Unicode-aware version of `.` matches _any byte_ (except for `\n`). This is important since `Regex` can only match on `&amp;str` types, which must be valid UTF-8. Similarly, all matches reported on `&amp;str` types must also be on valid UTF-8 boundaries. Conversely, `bytes::Regex::new(r"(?-u:.)")` will compile successfully since it matches on `&amp;[u8]` types, where there is no restriction on match boundaries. Other than that, I think everything is probably fairly standard, although there are most certainly other corner cases with differences.
A counter point is that rust makes it eaiser to keep fewer copies of data as most references can't be changed. It can be done in c++, but assigning that refrence to a variable this class controlls makes things so much easier.
Thanks! Glad to know it :)
People don't naturally think in any of the programing models. Just check a first year programing course for confirmation.
I don't think think that this issue is specific to cargo-xbuild. Sounds like you're either running out of memory or like a bug in rustc/cargo. I found [this cargo issue](https://github.com/rust-lang/cargo/issues/6489), which is probably related. Someone in that issue said that it occurs mostly in `--release` mode, which `cargo install` does by default. Maybe `cargo install cargo-xbuild --debug` works?
&gt;I don't know as much as I would like about low level IO, but I don't believe that suggesting that Tokio provides numerous benefits over a loop is an outrageous claim. No, tokio certainly has some benefits over just having a loop with blocking IO, but it also has a bunch of costs. There was nothing in the OP that suggests that the benefits justify the costs for the poster's use case, so telling them to use Tokio is unhelpful and doesn't actually answer their question.
Out of all replies this is definitely the most likely. One thing I admire about Rust users is that they are very reasonable about "programming languages as sports teams", that is, Rust users love Rust for its *ideas* and not for its brand. I've heard many iterations of "Rust is the future, but the future is not necessarily *Rust*".
1. You can use the plus operator to append to a String since [this trait](https://doc.rust-lang.org/std/string/struct.String.html#impl-Add%3C%26%27_%20str%3E) is implemented. [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;code=%0A%0A%0Afn%20main()%20%7B%0A%20%20%20%20let%20mut%20x%20%3D%20String%3A%3Anew()%3B%20%20%20%20%0A%20%20%20%20x%20%2B%3D%20%22FOO%20%22%3B%0A%20%20%20%20x%20%2B%3D%20%22BAR%22%3B%0A%20%20%20%20println!(%22%7B%7D%22%2C%20x)%3B%0A%7D](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;code=%0A%0A%0Afn%20main()%20%7B%0A%20%20%20%20let%20mut%20x%20%3D%20String%3A%3Anew()%3B%20%20%20%20%0A%20%20%20%20x%20%2B%3D%20%22FOO%20%22%3B%0A%20%20%20%20x%20%2B%3D%20%22BAR%22%3B%0A%20%20%20%20println!(%22%7B%7D%22%2C%20x)%3B%0A%7D)
Thanks! I was misdirected by the lack of a visible "scope" of a table.
2. the \* shouldn't be necessary \`&amp;x.to\_string()\` should be enough
Same as last week, working on my real time SPH fluid simulator. I've found a lot good and bad about rust. I've VERY impressed by rayon and criterion so far. I've written a little about my overall experience with rust [here](https://karthikkaranth.me/blog/my-experience-with-rust-plus-wasm/).
Uhh , u sure this is the right rust ?
Nope ahaha
No, the rust library ecosystem needs to significantly step up its game. It's really bad.
For a single UDP socket, blocking io is not only much simpler, but also faster than a readiness-based event loop (mio) as it avoids extra syscalls to wait for events or be told that there are no more to be done right now (WouldBlock).
Interesting, TIL. Thanks
That's one way to view it. Other way to view it is to ask yourself "how can we avert these events?", then, "how can I help avert these events?", then, "what can I learn in order to be able to help avert these events?".
The first one. There are already some good HTTP libraries (hyper, rocket, actix-web), and turning this into a cross-language project is probably unneeded complexity.
Interesting. Modules changed because of the overwhelming number of beginners who thought that the 2015 style was the one that was weird and confusing. One of the top complaints about Rust a year or two ago was that, "modules are confusing and hard to understand".
Oh? I haven't noticed. Generally I find that third party crates have better documentation than packages in other ecosystems. Sometimes libraries will have no documentation at all! At least in Rust, APIs will be published to https://docs.rs at the very least.
I'm not sure what the purpose is of ProtectedString (especially since it implements AsRef&lt;str&gt;) so I can't really tell who is in the wrong here.
I wanted to fix https://github.com/Keats/validator/issues/73 and https://github.com/Keats/validator/issues/74 before releasing a new version but I kind of forgot it. If anyone is looking for some issues to help with :)
New Rust releases are boring, and I love it. The biggest and most important gaps in the language have all already been filled. The perspective on this depends on one's use case, of course. `Future` and `alloc` and `MaybeUninit` will be big deals to some people, hopefully including me someday. But the amount of code I have actually waiting for these things is zero. Feels good.
And what would you use, when you need to have backreferences?
I feel like I'm missing something here.
It's the 2015 modules that confuse me, actually. Depending on where you are you need a different path style
Having mostly come through the the far side at this point, I'd say it barely even hurt it. It just provided something for python devs to gripe about for a few years.
To me Rust would have failed if at some point it diverted from the idea of replacing any and all C and C++ code in the world. If in ten years people are still picking C++ to build a game because of Unreal Engine, or C++ for the implementation of a new language because of LLVM, or C for the implementation of an operating system because of open source driver / protocol stacks. I would still consider Rust a success if it's not Rust but some other language than C/C++ they'd pick instead. To me Rust is already a success because I can pick Rust as the language for my inconsequential little forays into these fields, but the true success lies in having the big/important industry players be able to pick Rust without having to worry about being disadvantaged because of missing some ecosystem support.
1. One option is to build a `Vec` of strings and use the [join] method with a `, ` separator to get your final output. 2. As aloe-pup pointed out, only `&amp;x.to_string()` is needed here. This is because the `push_str` method accepts a `&amp;str`, but `x.to_string` produces a `String` instead. Adding a `&amp;` here allows [deref coercion](https://doc.rust-lang.org/beta/std/ops/trait.Deref.html#more-on-deref-coercion) to occur and the `&amp;String` gets automatically converted to a `&amp;str`. [Here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2f7bc08634d8b8c36da95eb27130040e) is an example of fizzbuzz using the `join` method, pattern matching, and iterators. Don't worry if they look alien, you'll learn what these do in time as you progress with the learning materials.
I don't think crev has the right focus. First, it looks like an excercise in cryptography. That's great if you want to play with cryptography, but you don't really need it. It could well be a centralized website where you post crate reviews instead. Second, it's about delegating the job of vetting the dependencies to other people. Vetting the dependencies is actually not that hard (though it could be depressing sometimes). The hard problem is what to do after you've done the vetting and was not satisfied with the results. For instance, let's say you've found out that webpack transitively depends on is-array (here I'm assuming for the sake of the argument that is-array is unquestionably bad and webpack is unquestionably what you need; if you disagree, pick another pair of packages). What do you do about it? Can you say that it's webpack developers responsibility to not depend on is-array? What does responsibility even mean when they are not paid by their users? The usual answer is "it's free; if you don't like it, don't use it". Like, obviously, if there was better alternative, you would use that. Obviously, if the project is drastically incompatible with your values, you'd take a hit and wouldn't use it even if there is no alternative. But in reality, it only compromises you values a little bit: they don't even depend on is-array directly, merely on some package that in turn has is-array in its transitive deps. Would you subject yourself to the inconvenience of not using webpack because of such minor oversight on their part? And the developers of webpack are in the similar situation: maybe they are responsible enough to never add a direct dependency on is-array, but they need some other package that maybe depends on stuff. So responsibility is diluted along the long dependency chain. And every participant may be qualified and responsible and is doing the right thing with just a tiny bit of corner cutting. But in the end you get what you get.
Did you look at the Streams section of the Tokio docs?
Thank you all for your thoughts and suggestions. Much appreciated! Now I'm using it like this: \[profile.release\] \# opt-level = 3 # It's already the default for release builds lto = true codegen-units = 1 &amp;#x200B; The LTO now reduces the size when used in combination with codegen-units setting. (I remember someone suggesting this to me, but I can't see that comment anymore). &amp;#x200B; More info about all these settings are here: [https://doc.rust-lang.org/cargo/reference/manifest.html](https://doc.rust-lang.org/cargo/reference/manifest.html) &amp;#x200B; My goal is to have the highest performance at the lowest possible size. I don't want to reduce the size at the cost of performance. (This is not an embedded app with size constraints). So, I'm not trying the opt level 's' or 'z' though they are reducing the size considerably. I believe they come at the cost of performance. Please let me know if I'm wrong on that. &amp;#x200B; I also don't worry about the longer compile times with any of the optimization settings as I only do the --release build just before I distribute the binaries. &amp;#x200B; Now, I wonder why the above settings are not used for release builds or for bench marking. Am I losing any performance by using those settings!? Is there anything I'm missing here? Thanks again.
https://docs.rs/pcre2 Or maybe https://docs.rs/fancy-regex for a pure Rust solution, when it matures.
You seem to agree there's a problem, and it's clear you don't think crev is the solution. Do you think there is (or could be) another solution or approach ?
Is there a short-hand dealing with lots of optionals? I'm writing a lot of code which looks like this: fn foo() -&gt; Option&lt;T&gt; { match x { None =&gt; return None, Some(y) =&gt; { match y.bar() { None =&gt; return None, Some(y) =&gt; { ... more nested matches ... } } } } } It seems like there must be a better way.
I wouldn't recommend flooding the database with queries on a loop. But then again, I am not familiar with Postgres's LISTEN function.
I agree that our documentation tooling kicks ass :] I've noticed that a lot of libraries are written in a way that leans too much into complex type relationships that make the documentation insufficient for actually using the library. This is where our doc tooling can't help the author teach people how to use the library as much, and it requires a lot more energy on their part to make the system usable. Rust is a fun language to learn, with lots of interesting features, but often a library will use far too many of them, and it makes users suffer.
If all you're doing is returning None on a None option, you can use the question mark operator: ``` let y = x?.bar()? // Can keep chaining these with question marks ```
Oh nice! I thought that was only for Result types.
Precisely this. My strongest hope for Rust is that it makes it socially unacceptable to argue that C and C++ "must" have design warts because they're "power languages".
https://en.wikipedia.org/wiki/HOCON
RON should have full support for all float types that Rust supports, and raw strings are handled the same way as Rust as well. &amp;#x200B; The spec that you linked to is a work in progress, but both the plugin and the actual RON parser behave as expected. Feel free to create a pull request to update the specifications to be more correct! &amp;#x200B; There is even a note about raw strings being incomplete on the spec page: &gt;Raw strings cannot be written in EBNF, as they are context-sensitive. Also see [the Rust document](https://github.com/rust-lang/rust/blob/HEAD@%7B2019-05-26T21:45:17Z%7D/src/grammar/raw-string-literal-ambiguity.md) about context-sensitivity of raw strings.
The Rust community’s aversion to growing the standard library never changed, and instead the ecosystem grew myriad incompatible types in crates leading to the current reputation of being where you go when you want to experience severe analysis paralysis.
The data you are receiving are not valid utf8. This is not text.
It failed because developers used unwrap everywhere and didn't take the time to handle errors appropriately. The plan was to improve error handling later, after the product market fit was established. Yet, when the time came, the one Rust developer who committed to improving the code wanted to revisit the work yet managers wanted to address new deliverables. The Rust code was never refactored. Eventually, a panic triggered in production and bad things happened. Beware of intertemporal discounting.
Well, unless he has no intention of ever touching rust again. Anyways, my very biased opinion is that learning rust is a good idea anyways :)
In a nutshell: use d_macro::*; fn main() { d_start(); d!("This line got executed!"); let value = vec!["one", "two"]; d!(? &amp;value); d_end(); }
This hits close to home as I once saw a C++ project where they basically went through and did a global remove of all instances of "const" to get their code to work.
We use neon in production. It's good for what we need it for, but I would probably not bother unless you're trying to integrate Rust into an established Node system that would be expensive to rewrite, or unless you have particular dependencies on things only readily available in the Node ecosystem.
Hope these imaginary failure cases do not appear as real facts in google searches.
Nice! --- Is there a specific reason for using the `async` module name when it's a keyword?
`static mut` without any synchronization doesn't seem safe.
&gt; c++ market is oversaturated with boomers as it is and work itself is mostly thankless legacy garbage sorting. Actually, as a C++ developer, I receive a constant influx of job offers, especially from FinTech which tend to pay pretty well.
I think this is the right mindset. People keep saying that "C is how computers work" but it's not the early 90s anymore and that just isn't true. C is, however, a relatively simple model for how all of these newer procedural-with-objects languages like Go and Rust and and yes C++ work. There hasn't been that much creativity in language design. C is a reasonable lowest-common-denominator.
Can someone do the thinking for me, and share some conclusions? :D
Can someone do the thinking for me, and share some conclusions? :D
&gt; the language replacing Rust will borrow many of its advances Hopefully they return it soon!
I wouldn't say Libra blockchain is an impact to global financial dominance, it's overrated. It is better to pay attention to the Diamond Open Market. Now no need to be pro or a millionaire to trade diamonds.
Yeah, you just can't mix `Result` and `Option` right now. You would have to convert one into the other before being able to propagate the `None` or the `Err` upwards the call stack: `my_result.ok()?` or `my_option.ok_or(some_error)?` or `my_option.ok_or_else(|| some_lazily_evaluated_error_expression)?`.
What is "the rust way" to change a field of a struct in the method of this struct? it must be something very basic, yet it doesn't work for me. &amp;#x200B; Here is what I got; &amp;#x200B; `#[derive(Debug)]` `struct Simple{` `s : String` `}` `impl Simple {` `fn greet_more(&amp;mut self){` `self.s = (self.s + " Hello");` `}` `}`
The anaylsis is done using a rust tool (I expected a python script) and have few statics based on different categories (cli crates, gui crates, graphics crates, web dev crates, top general crates), the output data of each category are basically: n. of dependencies, library size, and binary size in addition to couple histograms to represent dependencies data. \------- Top 10 **cli utilities** crates: ripgrep, xargo, run\_script, shell2batch, cargo-watch, cargo-deb, watchexec, cargo-xbuild, tokei, comrak median n. of dependencies: 42 median libaray size: 1.05 MB median binary size: 1.99 MB \------ Top 10 **graphics** crates: kurbo, hedge, rust-pushrod, identicon-rs, colors-transform, peach, cubic\_spline, raytracer, raylib, tinyppm median n. of dependencies: 12.5 median libaray size: 0.33 MB median binary size: 0.31 MB \------ Top 10 **gui** crates: winit, wayland-client, smithay-client-toolkit, gtk, stdweb, cursive, conrod, stdweb-internal-macro, stdweb-derive, stdweb-internal-runtime median n. of dependencies: 19.5 median libaray size: 0.76 MB median binary size: 3.92 MB \------ Top 10 **web-programming** crates: url, hyper, httparse, http, curl, serde\_urlencoded, reqwest, h2, encoding\_rs, html5ever median n. of dependencies: 54 median libaray size: 1.50 MB median binary size: 4.77 MB \------ The 10 **most downloaded** crates are: rand, libc, bitflags, lazy\_static, log, serde, syn, regex-syntax, regex, quote median n. of dependencies: 4 median libaray size: 0.24 MB median binary size: 0.59 MB &amp;#x200B; Note: there might be some popular crates missing due to download issues so the tool skipped it
As for point 3: With `x.to_string()` you create a lot of temporary `String` objects that are immediately dropped again. This puts some pressure on the heap (allocating and releasing heap memory for a `String`'s buffer does have a cost). Instead you could try to avoid that using `std::fmt` and its `write!` macro: use std::io::Write; let mut buff = Vec::new(); write!(&amp;mut buff, "Fizz Buzz, ").unwrap(); write!(&amp;mut buff, "{}, ", x).unwrap(); ... String::from_utf8(buff).unwrap() I don't actually know for sure how it compares w.r.t. performance, but my guess is that this would be more efficient because I think it avoids other intermediate memory allocations apart form the string buffer that has to grow anyways. I expect the `unwrap()`s to be fine because I can't imagine any I/O error you would have to deal with. Also, we know that `buff` will contain valid UTF-8, so the last `unwrap()` will succeed, too.
The paragraph widget has a scroll method exposed [https://github.com/fdehau/tui-rs/blob/master/src/widgets/paragraph.rs#L95](https://github.com/fdehau/tui-rs/blob/master/src/widgets/paragraph.rs#L95) &amp;#x200B; Additional note on tui-rs: &amp;#x200B; The tui-rs really lacks mouse support, I submitted a PR to initially add that [https://github.com/fdehau/tui-rs/pull/167](https://github.com/fdehau/tui-rs/pull/167) My intention would be to make tui-rs have widgets in a natural ways such as in html/gtk. Trying to make the widget trigger an event is a bit tricky in tui-rs since each widget doesn't keep track of the area it is covering, since it is passed in the draw/render api. The architecture needs to be change to support that.
/r/playrust
I was able to solve it: impl Simple { fn greet_more(&amp;mut self){ self.s = self.s.clone() + " Hello"; } } Deeper insights on why reading the value of self.s was not possible w/o clone are welcome!
This is arguably the \*reason\* to have unsafe in the first place. This is one of those core, down close, library systems that knows more about the memory semantics than the rust compiler.
&gt;no matter what the asymptomatic complexity technically is When you recognize that memory look up is not an O(n) action, the asymptomatic complexity suddenly makes perfect sense and it is obvious why Vec's are the correct choice.
This is exciting. [Related meme](https://imgur.com/xuuSGdl).
About that, I was thinking of creating a grid and colouring each square a unique colour, then match it to to an element. Click happens check colour of coordinates at location of click and match to element.
Why is \`Iterator::collect()\` used and not \`from()\` or \`into()\`? (ex-post from StackOverflow in search of more constructive responses) &amp;#x200B; [Iterator::collect](https://doc.rust-lang.org/1.30.0/std/iter/trait.Iterator.html#method.collect) turns an iterator into a data structure. Its documentation says: &gt;This is one of the more powerful methods in the standard library, used in a variety of contexts. What is the purpose of this method, as opposed to into()? Using collect: fn main() { let it = 5..10; let v: Vec&lt;i32&gt; = it.collect(); // Works A-OK println!("My vector is {:?}", v); } Using 'into\`: fn main() { let it = 5..10; let v: Vec&lt;i32&gt; = it.into(); // Error! println!("My vector is {:?}", v); } The output of the collect()version works as expected, displaying a vector of the numbers 5-9. But the into()version gives a compiler error: error[E0277]: the trait bound `std::vec::Vec&lt;i32&gt;: std::convert::From&lt;std::ops::Range&lt;{integer}&gt;&gt;` is not satisfied --&gt; src/main.rs:3:26 | 3 | let v: Vec&lt;i32&gt; = it.into(); | ^^^^ the trait `std::convert::From&lt;std::ops::Range&lt;{integer}&gt;&gt;` is not implemented for `std::vec::Vec&lt;i32&gt;` | = help: the following implementations were found: &lt;std::vec::Vec&lt;T&gt; as std::convert::From&lt;&amp;[T]&gt;&gt; &lt;std::vec::Vec&lt;T&gt; as std::convert::From&lt;&amp;mut [T]&gt;&gt; &lt;std::vec::Vec&lt;T&gt; as std::convert::From&lt;std::borrow::Cow&lt;'a, [T]&gt;&gt;&gt; &lt;std::vec::Vec&lt;T&gt; as std::convert::From&lt;std::boxed::Box&lt;[T]&gt;&gt;&gt; and 5 others = note: required because of the requirements on the impl of `std::convert::Into&lt;std::vec::Vec&lt;i32&gt;&gt;` for `std::ops::Range&lt;{integer}&gt;` This is because there is a difference between the From trait and the FromIterator trait, and collect() requires the data structure have the FromIterator trait. But why does this trait exist? Couldn't the API just implement From, like so: use std::convert::From; #[derive(Debug)] struct VectorWrap&lt;B&gt; { vector: Vec&lt;B&gt;, } impl&lt;T, B&gt; From&lt;T&gt; for VectorWrap&lt;B&gt; where T: Iterator&lt;Item = B&gt;, { fn from(it: T) -&gt; Self { VectorWrap::&lt;B&gt; { vector: it.collect(), } } } fn main() { let it = 5..10; let my_struct: VectorWrap&lt;i32&gt; = it.into(); // Polymorphism happens here ^ :) println!("My structure is {:?}", my_struct); } eliminating the need for FromIterator? This example shows that in principle it's possible to polymorphically derive into()for iterators. Why do people not do this? Why make a FromIterator trait when you can just overload the \`From\` trait for \`Iterator\`s?
If you actually want to append to the string and that isn't just a strawman example, there's a couple easier ways to do it: // these two forms have the same behavior self.s.push_str("Hello"); self.s += "Hello";
It would have been nice to have the events builts into tui-rs, rather than doing the approximate computation of which widget where activated/hit
Can you share more details? Does the function take a trait object (`dyn`) or is it generic? fn function(w: &amp;dyn Widget); fn function(w: Box&lt;dyn Widget&gt;); fn function&lt;W&gt;(w: W) where W: Widget; If you deal with trait objects, that's tough. Rust doesn't support "cross casting" from one trait object to another out of the box. As far as I understand it would require more runtime type information than the Rust compiler currently spits out. But I remember having seen a crate that takes care of the necessary runtime meta data for this and allows to cross cast a `&amp;dyn SomeTrait` to `&amp;dyn AnotherTrait` if the dynamic objects really implements both traits. Unfortunately, I forgot the crate's name. If you deal with a generic function, it sounds like a problem that could be solved with `impl specialization`. Unfortunately, specialization is a feature that's not finished and only works to some extent in nightly, AFAIK. But it might similar to this: trait FunctionHelper { fn handle(self); } impl&lt;W: Widget&gt; FunctionHelper for W { default fn handle(self) { // work on self knowing that it impls Widget } } impl&lt;W: Widget + Callback&gt; Helper for W { fn handle(self) { // work on self knowing that it impls Widget+Callback } } fn function&lt;H: Helper&gt;(h: H) { h.handle(); } Maybe there's a better approach to avoid this. Maybe I can't see the forest for all the trees. ;)
&gt; Or even better, either don't use a regex or simplify the regex and do a post processing step. `nom` is easy enough to use that I'd rather just use that when dealing with a non-regular language.
You can also do various combinator magic, though that can make code unreadable in different ways. x.and_then(|y| y.bar()).and_then(|z| z.frob()) is roughly equivalent to the longer match x { None =&gt; None, Some(y) =&gt; match y.bar() { None =&gt; None, Some(z) =&gt; z.frob() } } It differs in that you can't refer to the value of `y` when working with `z`, and you can't early-return. A middle ground: if let Some(y) = x { if let Some(z) = z.frob() { // Something in here does an explicit `return` of Some() } } // At least one case was None, so we fell through to here None Often you'll use some combination of `?`, matches and `if let` as suits your needs.
I would advise that something is written about this _somewhere_ so you can link to it. Having a description of the problem, how to recognise it, and how to resolve but it is useful. As is the explanation of where it comes from and why it is not considered a breaking change. Making that official documentation that you can link to even in a conversation like this can help spread awareness, so people are too surprised if they run into it.
Perhaps fn iter_mut(&amp;mut self) -&gt; impl Iterator&lt;Item = &amp;mut Tile&gt; { let (p0123,p45) = self.plate[0..6].split_at_mut(4); let p450123 = p45.iter_mut().chain(p0123.iter_mut()); p450123.flat_map(|x| x.into_iter()) } assuming `self.plate` implements `DerefMut&lt;Target=C&gt; and `&amp;mut C` implements `IntoIterator&lt;Item = &amp;mut Tile&gt;`.
To be honest, it *thinks* it knows better, but it really doesn't.
Good catch. Seems like the timestamp functionality would fall over pretty quickly in a multi-threaded environment.
The history of computer languages has not been to expand the options of programmers. Instead it has been to limit the types of programs that programmers can write, restricting it to the collection of programs they wanted to write anyways. &amp;#x200B; In almost all cases, assigning the value contained within a memory location, normally representing a character, to a memory location normally representing some float, is incorrect. Type systems keep programmers from making this kind of mistake, and where appropriate, allow them an escape hatch to write just such a program. &amp;#x200B; The same is true for multiple threads accessing memory at the same time, and memory ownership, etc etc etc. That this trend should continue should not be a surprise. That there will be small sub sets of programs which don't conform to these restrictions should also not be a surprise.
What is the project and functionality that your interested in?
It is nothing near useful. It just reinvents the SQL language. Why can't there be ORMs based on Rust structs?
I know. It's currently a work in progress. I wanted to give a snapshot to those people who are watching the project, letting them know that I'm "still alive" and that the project is still being worked on. :) I'm just one person working on it. :) One of the big things I'm working toward is the ability to design a GUI with a drag-and-drop interface that will generate the widget layout using serialization. I'll take a look at your samples, though. Thanks!
It's not clear what you want. It doesn't help that you didn't post all relevant code (i.e. the server-code that sends data), so I can only guess. The exact failing line seems to be let msg = str::from_utf8(&amp;buf).unwrap(); which means that the byte buffer does not contain valid UTF-8 text. (see [Rust book section](https://doc.rust-lang.org/book/ch08-02-strings.html#internal-representation) "Internal representation" and "Bytes and Scalar Values [...]"). Here is my guess of what happens: The server is sending some binary data (which isn't actually text) and you want to see what the client is getting. For this you'll likely want to simply debug print the buffer, á la println!("{:?}", buf);
I don't have any plans for styling until WAAAAAY down the line. One of the things KDE and Gnome projects got wrong was thinking about styling above functionality. I'm completely the opposite. I want the code to function properly FIRST. :)
You could use from_utf8_lossy if you’re not worried about changing the invalid characters to �
True, I didn't cover this completely. The way I've used the macro so far is that more threads only get spawned after \`d\_start\` has been run, so it was a non-issue so far. &amp;#x200B; Will open an issue about that.
This isn't a solution. At best, it would side step the immediate problem, only to run into a bigger one later.
I'm wondering how people handle configs and cli args. If I have a program that takes some option, let's say port number, I can collect that from the CLI the user supplies as well as a default. I picked structopt for that. However, I also want port number set in the configuration file. The CLI will override config file settings. I picked config-rs to pick up config file and environment stuff. The missing piece is to put CLI args on top of the configs. But. That isnt really possible with these libraries. Any advice? Ditch structopt? Ditch config-rs? Write a function to merge cli on top of configs?
How so? Everything I need to know about Go is available at https://golang.org, including all that's required to implement an alternative gc. However, with Rust, particularly regarding unsafe semantics, I've had to read a bunch of blog posts as neither the Rust book nor the Nomicon contained such info.
In most cases, I'd rather hand-code it.
This is exactly the sort of stuff I wanted to do with https://cargofox.io/ but never got deep enough into. Let me know if you'd like to collaborate somehow though.
I think you'll find actix-web similar enough to Express that it'll be easy to figure out, if you go to microservice route. But, you'll need to know some Rust, and Rust has a steeper learning curve than most languages. It's harder to write Rust badly than it is to write Python or JS badly. I think it's easier to write decent Rust than it is to write decent Python or JS though, because there are so many mistakes the compiler just won't let you write.
That depends on how complicated the format is. I'll use a combination of `lines`, `split_whitespace`, `split`, `collect`, and `parse` for simple parsing but once it gets past twenty lines or so of string manipulation I'll switch over to parser combinators or a hybrid approach.
Thank you! 🦘🦘🦘🦘🦘🦘🦘🦘🦘🦘🦘🦘
Why would it be a problem if they are not worried about the non utf8 characters?
I think realistically you have start it from inside a company that doesn’t use Rust yet.
Yes, I've used parser combinators before. My preference is not born out of ignorance.
I just don't have the time to dig and think about the data, and it's not immediately obvious what's the point. "Are we OK?" "Is there a problem?" "Can improve something?" "Should I do something"?" I mean - I don't expect anyone to do work for me, but if the intention was to carry some conclusions, then it has been lost on me (and probably others).
the easiest way imo would be the “write a function” way. i don’t know how you are collecting everything but i would collect config arguments into certain variables (or a struct) and then collect CLI arguments, overriding the ones you already collected. this would need two separate stages, so i guess that would be a limitation and it wouldn’t be as smooth as just using one library. if you want, you could look into his programs like cargo and rustup do it. obviously this might be overkill but both of those do something like what you’re trying to do. you could figure out how they do it and then implement it with libraries of your choice. i know it wasn’t much but i hope this helps a little bit. good luck with your project!
Well, what I was hoping I could do was something like this: pub trait WidgetCallbacks { fn do_something() { } } pub trait Widget { } Then define two widgets: impl&lt;W: Widget&gt; NoCallbackWidget for W { } impl&lt;W: Widget + WidgetCallbacks&gt; CallbacksWidget for W { } and have code that looks similar to this: let w1: NoCallbackWidget = new NoCallbackWidget(); let w2: CallbacksWidget = new CallbacksWidget(); if let Some(w3) = w1.downcast_ref::&lt;WidgetCallbacks&gt;() { w3.do_something(); // This will obviously produce no results, as this will never happen. } if let Some(w4) = w2.downcast_ref::&lt;WidgetCallbacks&gt;() { w4.do_something(); // This _will_ do something! } That's what I'm hoping I can do. Even something like this: if w2.implements::&lt;WidgetCallbacks&gt;() { if let Some(w3) = w2.downcast_ref::&lt;WidgetCallbacks&gt;() { w3.do_something(); // We know this will work, because we've already checked for implementation. } } I can't find anything like this that exists...
If it's small then read entire file.
Reading more data at once is always more efficient.
Thanks! Nothing more than because it's intrinsically asynchronous. Some other crates, like [reqwest](https://docs.rs/reqwest/0.9.18/reqwest/async/index.html), also have modules named `async`.
Character classes in the `regex` crate have some pretty rare features: * *Intersection* (`[a-y&amp;&amp;xyz]` == `[xy]`) * *Direct subtraction* (`[0-9--4]` == `[0-35-9]`) * *Symmetric difference* (`[a-g~~b-h]` == `[ah]`) Oniguruma and Java only supports intersections. Javascript and PCRE support none of them I believe.
Up to a feasible memory limit.
If you are into P2P networks, decentralized networks and heavy cryptography, Witnet Foundation is always hiring Rust devs in Madrid and Parity Technology in London and Berlin.
If I understand correctly, the most efficient way is to memory-map a file. That way you save cpu cycles and memory by avoiding the kernel storing the contents in its cache and copying it to your buffer.
You don’t need others to think for you. It’s simple. Are you enjoying the game? If not, don’t play. If yes, then keep doing that. Every game community waiting for people to give them a reason to get their pitchforks.
If you're doing tons of addition and subtraction with your values, signed values will let you go below zero. Even if the end result is above zero for unsigned values, subtraction may never go below zero. As I understand it, this is the main benefit of using signed types for strictly nonnegative values. The only other benefit I know is that you never have to cast between signed and unsigned type this way. On the other hand, unsigned values: - very clearly indicate being nonnegative in the type system - require fewer safety checks for invalid value (it's impossible to pass a negative length into Vec::with_capacity, for example) - can be optimized for slightly more speed because of this - can store twice as many values for the size (u32::max_value() roughly equals 2*i32::max_value ()) - allows for safer interop with other languages which also allow unsigned types (like C) In Rust, overflow on both signed and unsigned types is well defined. It panics in debug mode and wraps in release mode. Maybe the CLR made some different design decision that made overflow less easy to detect using unsigned values? Overall I'd say that both positions are reasonable. Maybe Rust's favoring types which represent invariants of the value, or it being slightly closer to the metal made allowing unsigned types a better decision than it would have been for the CLR. In your own Rust code, I would recommend using unsigned types, simply because that's the decision the language made and it'll be a pain trying to cast everything to signed types in your code.
&gt; My question is how does Rust handle unsigned integers. The Rust answer to this whole situation is to pin down the semantics of signed and unsigned integers; both are guaranteed to wrap on over/underflow. The compiler also inserts runtime checks by default in debug and test mode that will panic if you actually over/underflow an integer by use of the usual operators. The standard library integer types have methods that do the usual operations with guaranteed checks or never panic on over/underflow if you're really sure that's what you want. &gt; Should I really be using signed integers instead or does the rust compiler take care of it. I'm not sure what the second part of this means, hopefully you can answer it for yourself based on the information above. As to what type you should be using, you should use the type that represents the valid operations on the data you have, same as choosing a type in any other situation. The standard library insists on using unsigned lengths for containers (which is a bit odd to me considering `ptr::offset` takes an `isize` but I digress) so you'll definitely be forced into interacting with them there, but otherwise it's entirely up to you. Just note that in Rust you don't get any extra checking power from signed types. And if you want the overflow checks in release mode the settings are explained [here, in the cargo reference.](https://doc.rust-lang.org/cargo/reference/manifest.html#the-profile-sections) --- &gt; I know signed integers are stored with twos complement. Really? _Your machine_ may be twos complement but does the language guarantee the data layout of signed integers and twos complement semantics? C and C++ guarantee neither, and Rust guarantees only the semantics, not the representation of integers (currently, might be pinned down later). &gt; This allows the compiler to detect more overflow/underflow errors. The ability to detect signed over/underflow doesn't come from the signed-ness of the types, in C and C++ at least it comes from the fact that the over/underflow of signed integers is undefined and so a conforming compiler can halt your program if you under/overflow them. This is as opposed to unsigned integers, where it is obligated to wrap (though of course you could have nonconforming compiler settings which totally exist).
Has anyone run into the pattern of transforming a `Option&lt;Result&lt;T, E&gt;&gt;` into a `Result&lt;Option&lt;T&gt;, E&gt;`? Is there any better way to do it than just declaring a function ``` fn flip_option_result&lt;T, E&gt;(value: Option&lt;Result&lt;T, E&gt;&gt;) -&gt; Result&lt;Option&lt;T&gt;, E&gt; { match value { Some(Ok(t)) =&gt; Ok(Some(t)), Some(Err(e)) =&gt; Err(e), None =&gt; Ok(None), } } ``` (In my case, I'm pulling a value out of YAML, then transforming it - if the value doesn't exist, that's fine, but if it does it has to be able to be transformed or it's an error.) Is there a combinator / chain of combinators for this?
In case anyone is wondering, any program output can be timestamped with `ts -s '%H:%M:%.S'`: [demo](https://imgur.com/7zlx6Xu). BTW I think you could hide unwanted `const`s with `#[doc(hidden)]` but I'm not sure about it.
The `Add` impl takes `String` by ownership and returns a new string - you don't have ownership of `s`, since you're just borrowing `self`. You can use `AddAssign` on the `&amp;mut String`, though: ``` fn greet_more(&amp;mut self) { self.s += " Hello"; } ```
Yes, I was hired as a JavaScript dev, and now that WASM support is stable, I'm working on moving as much code as possible from JS to Rust.
Neat little app! &gt; In addition, using a make-based build makes it easier for other distributions to package the project in the future Speaking as a habitual package maintainer, the Makefile you've written is not useful for packaging. It hard-codes an install path rather than using the standard `DESTDIR` mechanism, so at best it's a human-readable list of operations I'd have to transcribe manually.
For the lazy: [GitHub repository](https://github.com/oliver-giersch/hazptr), [documentation](https://docs.rs/hazptr/).
Thank you for the response. This answered my question well.
Madrid, great! maybe I will look into that after my degree.
Heh, you're preempting me! The next blogpost will show how DESTDIR (and a few other things) makes packaging easier by trying to package for Flatpak without it, and feeling the pain that causes. I might should put in a short disclaimer about this, though. And, if you're willing, I'd love your opinion on the actual Makefile the project uses: https://gitlab.gnome.org/NoraCodes/gdiceroller/blob/master/Makefile
Yeah, I use rust in next version API proof of concepts at work. I was hired for JavaScript as well.
`Arc&lt;RefCell&lt;&gt;&gt;` is weird to see. It should be either `Rc&lt;RefCell&lt;&gt;&gt;` (single-threaded, no need for atomicity), or in a multithreaded environment either `Arc&lt;RwLock&lt;&gt;&gt;` or `Arc&lt;Mutex&lt;&gt;&gt;`. Also, it's interesting that you're going for a synchronized mutation approach rather than spawning a new thread to handle the GUI and just let that thread alone mutate UI state, and then communicate with that thread via message-passing.
&gt; Arc&lt;RefCell&lt;&gt;&gt; is weird to see You're absolutely right, that totally slipped my mind. Whoops. I'll have to change that. &gt; Also, it's interesting that you're going for a synchronized mutation approach rather than spawning a new thread to handle the GUI and just let that thread alone mutate UI state, and then communicate with that thread via message-passing. I chose this on purpose in order to reduce complexity of the initial implementation; I plan to make a follow-up post comparing and contrasting these approaches.
&gt; I get this JNI error: &gt; thread '&lt;unnamed&gt;' panicked at 'called `Option::unwrap()` what backtrace if you run it with RUST_BACKTRACE=1 ? &gt; This probably corresponds to this This is rather strange, Java gamepad is variable, while Rust gamepad is function. It should crash on line where gamepad called. But may be Java backtrace is malfunction during JNI crash.
&gt; I might should put in a short disclaimer about this, though. Seems prudent to qualify the claim, yeah. &gt; I'd love your opinion on the actual Makefile the project uses Sure! Bear in mind I don't usually deal with hand-written Makefiles, though the use of one here seems reasonable enough. - The png icons you install don't seem to get uninstalled (not that this is relevant for packaging) and it's strange that they're named `.svg` as installed. - It's not obvious what `touch $(sharedir)/icons/hicolor` accomplishes. - The `clean` target nukes snap-related stuff that doesn't seem to be created by any target. Nits aside, it looks like something that would drop effortlessly into every packaging workflow I've used; good work.
It's recommended by ElementaryOS's HIG, but come to think of it, it might be better to not do that... so many conflicting HIGs floating around.
Are you sure about the cache part? mmap's man tells me that mincore can control the cache behavior. I'm pretty sure the default is to stay in the cache.
It's just for sharing the raw data, with neutral intentions. People can make their own conclusions if they wish. It shows a vague snapshot of what it's currently like out there, and it might be interesting to run it regularly and see how the ecosystem is changing. I started it to answer a question, but not one that is generally interesting. My personal projects have over 150 transitive dependencies, and I wondered if that was normal. Data shows: not typical, but not unusual either. I am against large dependency counts for security reasons: every dependency introduces a risk of malicious code injection, and higher numbers are obviously harder to audit. It also contributes to increased compile times and disk usage, since the Rust world isn't going for system-wide shared libraries nor a global compile cache (yet?). The data doesn't show it directly, but if you poke around a bit it seems like `reqwest` is responsible for a lot of the higher dependency counts. It has 127 by itself, and is a common dependency.
I suppose the elementary OS thinking for names for binaries of GUI apps is that you never need to discover them manually anyway. To me that's a dubious claim, but I see how it's true from their perspective. However, I wholeheartedly support the entire rest of the elementary HIG that actually talks about human interface guidelines. It's a thing of beauty.
Good, that gives me hope I’ll find a Rust job sooner than later. Unfortunately, my current project cannot move to Rust where it really counts (agents that are installed on thousands of hosts for a single customer), because a million plugins/extensions were written and are being written in Java on top of the core functionality. By a separate team, with a different level of skillset.
As a full-time .net developer, nobody in the .net community really cares about CLS compliance. It's probably been a decade since I've actually seen it pop up in a serious discussion. It's hard enough to get people to care about F# interop which is a real language actually used in production. CLS compliance is just a set of guidelines that Microsoft thought *might* apply to some languages that look an awful lot like C#. In reality, support for community driven languages never really materialized on .net and it's 90% C# anyway with the rest split between the functional programming enthusiasts using F# and the handful of VB programmers still left on .net. All this to say, the CLS compliance rules are just generally not useful and very questionable to say the least.
What is the current state of incremental compilation? Last I heard (on [this thread](https://internals.rust-lang.org/t/incremental-compilation-beta/4721)) is that it's currently a beta feature available only on the nightly release of Cargo. Is that still the case?
Thanks to all the people making this happen =) Are the releases of RLS linked to Rust ones? I've got some RAM consumption issue on Linux lately that made me switch to IntelliJ for Rust development but I'd rather use RLS+VSCode.
Isn't this analysis very misleading regarding the library size? The library may be large but a typical use may use only a small portion of it, and dead code elimination would make the use in practice small. Also, I don't think this accounts for the size of non-Rust code in the crate, e.g. when the crate uses C or assembly language. In many cases the object code size contributed by the C/asm code is much larger than that contributed by the rlib size. Presumably, how often generics are used vs. how often concrete types are used also affects greatly the difference between rlib size and the final object code size.
Hi. What type annotations should I add to fix this error? I'm using [nom 5.0.0](https://docs.rs/crate/nom/5.0.0). error: error[E0283]: type annotations required: cannot resolve `_: nom::error::ParseError&lt;&amp;[u8]&gt;` --&gt; src/main.rs:6:18 | 6 | let (_, v) = count(le_u16, 2)(&amp;input).unwrap(); | ^^^^^ | = note: required by `nom::multi::count` src/main.rs: use nom::multi::count; use nom::number::complete::le_u16; fn main() { let input: Vec&lt;u8&gt; = vec![10, 0, 20, 0]; let (_, v) = count(le_u16, 2)(&amp;input).unwrap(); assert_eq!(v, vec![10, 20]); }
I’m just a jvm pleb, but my understanding comes from reading the excellent Gustavo Duerte’s blog, specifically https://manybutfinite.com/post/page-cache-the-affair-between-memory-and-files/.
Thanks, the article is helpful and does show what's implied by the title. Although Qt based applications are preferred for KDE users like me.
Please read [this issue about `static mut`](https://github.com/rust-lang/rust/issues/53639). Really, everyone who wants to use `static mut` should read this issue.
It's not just faster as /ul/ThatDanishDude says, it also uses much less memory which appears to have been part of the original motivation for the design. There's a walkthrough of the implementation, starting from hash table basics: https://youtu.be/ncHmEUmJZf4
Oh, I think I got it. Mmap doesn’t avoid the kernel cache, it avoids duplicating data in the user buffer. My bad.
You just gave me an idea! https://github.com/dpc/crev/issues/191
Well we all have our preferences. I'm a GNOME user, so that's where I'm focusing first. Never fear, I'll write about Rust and Qt when I can :)
&gt; Even if the end result is above zero for unsigned values, subtraction may never go below zero. This is only true in C/C++ where overflow/underflow is undefined behavior. In Rust overflow is well-defined, and the compiler does not make assumptions that it never happens. So AFAIK an intermediate value going below zero, wrapping around to very large value, and then wrapping around again is still totally valid and will produce the desired result.
Seems like a false dichotomy. How about using a `BufReader`? It will read things in bigger chunks for performance, but files larger than the buffer will be read in multiple chunks lazily. Otherwise memory mapping, for systems that support it.
&gt; This is only true in C/C++ where overflow/underflow is undefined behavior *Unsigned* overflow/underflow is well-defined in C and C++
I work for Red Hat and have been successful in introducing Rust. Check out the Rust projects under the OpenShift and CoreOS organizations in GitHub to get a sense of how we are using it. It's still a fairly limited scope but I'm hoping to expand further.
thread '&lt;unnamed&gt;' panicked at 'called `Option::unwrap()` on a `None` value', src/libcore/option.rs:347:21 stack backtrace: xyz.ecumene.jgilrs.natives.GilrsDemo &gt; beginDemo STANDARD_OUT New event from 1299276433: connected Button South is pressed (XBox - A, PS - X) Generic X-Box pad 0: backtrace::backtrace::libunwind::trace at /cargo/registry/src/github.com-1ecc6299db9ec823/backtrace-0.3.29/src/backtrace/libunwind.rs:88 1: backtrace::backtrace::trace_unsynchronized at /cargo/registry/src/github.com-1ecc6299db9ec823/backtrace- 0.3.29/src/backtrace/mod.rs:66 2: std::sys_common::backtrace::_print at src/libstd/sys_common/backtrace.rs:47 3: std::sys_common::backtrace::print at src/libstd/sys_common/backtrace.rs:36 4: std::panicking::default_hook::{{closure}} at src/libstd/panicking.rs:198 5: std::panicking::default_hook at src/libstd/panicking.rs:212 6: std::panicking::rust_panic_with_hook at src/libstd/panicking.rs:475 7: std::panicking::continue_panic_fmt at src/libstd/panicking.rs:382 8: rust_begin_unwind at src/libstd/panicking.rs:309 9: core::panicking::panic_fmt at src/libcore/panicking.rs:85 10: core::panicking::panic at src/libcore/panicking.rs:49 11: Java_xyz_ecumene_jgilrs_Gilrs_do_1getConnectedGamepad 12: &lt;unknown&gt; fatal runtime error: failed to initiate panic, error 5 This is probably super unhelpful, but this is the backtrace output
 &gt;I suspect it's spawning the process on a different thread or it's hijacking stdin and putting in nothing. That is what [`output()`](https://doc.rust-lang.org/std/process/struct.Command.html#method.output) is designed to do: &gt;By default, stdout and stderr are captured (and used to provide the resulting output). Stdin is not inherited from the parent and any attempt by the child process to read from the stdin stream will result in the stream immediately closing. You want [`status()`](https://doc.rust-lang.org/std/process/struct.Command.html#method.status) if you want to inherit stdin/out/err &gt;By default, stdin, stdout and stderr are inherited from the parent.
If you freely admit you like making useless comparisons, I don't have a rebuttal. I'd just caution you not to mislead people who read your posts, you seemed to be saying just by virtue of the fact you used combinators you got a 36x speedup. That's untrue, you were merely comparing single threaded versus multi threaded performance.
Old Reddit and certain mobile apps don't support fenced code blocks, so we see this: https://imgur.com/a/Wbwm8md You should indent by four spaces instead. That aside, what symptoms are telling you that it's not waiting for the subprocess to finish? The [docs for .output()](https://doc.rust-lang.org/std/process/struct.Command.html#method.output) do say "Executes the command as a child process, waiting for it to finish and collecting all of its output." This seems to work as intended: use std::process::Command; fn main() { let foo = Command::new("echo") .arg("hello") .output().unwrap(); println!("FOO: {}", String::from_utf8_lossy(&amp;foo.stdout)); } Also, if you *don't* need to capture stdout, consider replacing `.output()` with [`.status()`](https://doc.rust-lang.org/std/process/struct.Command.html#method.status).
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/1of5Z8t.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20eszsnmp)
According to the docs for `output()` ([https://doc.rust-lang.org/std/process/struct.Command.html#method.output](https://doc.rust-lang.org/std/process/struct.Command.html#method.output)), standard input for the child is not inherited from the parent process and won't work by default. Maybe you want to run the child with `spawn()` instead, which does appear to inherit standard input from the parent. You will probably need to use `child.wait()` as well if you want to capture the standard output from the child.
True! I would still consider this to be untrue for Rust though, since you still need to use wrapping operations, or release mode. Since debug mode panics on overflow, I don't think overflow can generally be relied upon.
You can avoid the necessity to share state with reference counters and mutexes if you instead utilize channels. Closures can capture state that survives across multiple invocations, which can be used to avoid the need for interior mutability and reference-counting. Give your widgets channels to communicate signals through, keep your application logic in a background thread that listens for these signals let sender = sender.clone(); button.connect_clicked(move |_| { let _ = sender.send(Event::Variant(captured_data)); }); And handle UI events through a `glib::MainContext::channel()`. let (tx_ui, rx_ui) = glib::MainContext::channel(glib::PRIORITY_DEFAULT); // Clone the sender and give to all your widgets // You may also send the sender across thread // boundaries to use with your background events. rx_ui.attach(None, move |event| { match event {} }); By keeping application logic and state separate from the UI logic and state, this is the quickest way to prevent and eliminate the possibility of the UI freezing.
/r/playrust. This is not the subreddit you are looking for.
This sounds interesting! So much that I still need to learn about Rust. I wish I could use it in my day job.
Ah yeah, they aren't commonly supported. I think ICU's regex engine supports them, but that's to be expected. I'm pretty sure Perl also supports them, but it has a weird syntax: https://perldoc.perl.org/perlrecharclass.html#Extended-Bracketed-Character-Classes
Or, in the case of Scala, here's an example of what I would want to do in Rust: val myClass: Widget = new MyWidgetWithCallbacks() if (myClass.isInstanceOf[WidgetWithCallbacks]) { val wwc: WidgetWithCallbacks = myClass.asInstanceOf[WidgetWithCallbacks] wwc.do_callback() }
C# you should just use `int` basically everywhere because that's what the libraries do, and all the casts to do otherwise would be a royal pain. That said, _I personally consider signed integers to be a code smell_. Note how, for example, while `offset` on pointers takes `isize`, new methods `add` and `sub` were added to take `usize` instead because you almost always know which direction you're trying to go, and don't need signed. (And if a subtraction overflows, it's probably a bug.) Seriously, as a thought exercise try to come up with a computer science algorithm that really needs signed integers. (Not unsigned integers, not fixed- or floating-point approximations of reals, not sentinel values like `-1`, etc.)
I love webkit GTK
&gt; I was hired for JavaScript as well. I was already reaching for my dusty "Java is not JavaScript" pitchfork, but this line is about the sibling comment by /u/anlumo and not about the parent comment by /u/Wilem82
I'm having trouble understanding function pointers vs closures, what's knowable at compile time, and how this all works cross-thread. What I want is to have a struct like: pub struct GOAL { pl: i32, gen: Fn() -&gt; i32, } with the intent of ultimately building a compile-time HashMap&lt;String, GOAL&gt; using lazy_static. I don't feel like I have a good grasp of what type "gen" should be. As written, I can't instantiate a GOAL object, as the compiler can't infer the size at compile-time. (I'm assuming this is because a "Fn()-&gt;i32" is some kind of thing with compiled code inside?) If I make gen a pointer, such as with pub struct GOAL2 { pl: i32, gen: Arc&lt;Fn() -&gt; i32&gt;, } I can instantiate objects such as in : pub fn gen3(a: i32, b: i32, c: i32) -&gt; Arc&lt;Fn() -&gt; i32&gt; { Arc::new(move || {a+b+c}) } GOAL2(pl: 0, gen: gen3(1,2,3)); and so this should work for run-time. When I try lazy_static tho: lazy_static! { pub static ref MC : Mutex&lt; HashMap&lt;String, GOAL2&gt; &gt; = Mutex::new(HashMap::new()); } I get errors like: `(dyn std::ops::Fn() -&gt; i32 + 'static)` cannot be sent between threads safely = help: the trait `std::marker::Send` is not implemented for `(dyn std::ops::Fn() -&gt; i32 + 'static)` = note: required because of the requirements on the impl of `std::marker::Send` for `std::sync::Arc&lt;(dyn std::ops::Fn() -&gt; i32 + 'static)&gt;` The error is definitely related to gen's type, if I replace it with 'gen: i32' or 'gen: String' or even 'gen: Arc&lt;i32&gt;' it compiles cleanly, but I'm stumped as to how to proceed from here. (I'm guessing that ultimately the answer's going to be something along the lines of 'don't do that', and tbh I'm feeling a little dirty for wanting to do this in the first place, but you know how it is when you're in a hole, you keep digging.) Thanks!
`offset_of!` can be implemented soundly now thanks to `MaybeUninit` AFAIK.
The tracking issue is [47660](https://github.com/rust-lang/rust/issues/47660)
I decided to look for a rust job a year ago, so I wrote an article about building a DNS-server in Rust. One of my present day coworkers at Distil Networks (acquired by Imperva tgmhe other week) saw it and passed my name on to a recruiter for an open position. I do a bit of frontend stuff to, but the majority of my work is in Rust. It’s really great to be able to use it full time. I believe Imperva is hiring rust developers in Los Angeles for their Prevoty division, although I haven’t checked for a while.
How do I share code between my integration tests and the tests in `src/`? For example, in [the headless-chrome crate](https://github.com/atroche/rust-headless-chrome) there's a file at [test/server.rs](https://github.com/atroche/rust-headless-chrome/blob/master/tests/server.rs) which helps spin up a simple web server, and I'd like to use its contents in (e.g.) [crate::browser::tab](https://github.com/atroche/rust-headless-chrome/blob/master/src/browser/tab/mod.rs) in a test module. As far as I can tell, if I keep it under `test/` I won't be able to access it from inside `src/`, and if I put it under `src/` and want to use it from `test/`, I have to make it a public export of the crate. Please let me know if that's not the case! Perhaps with the example of the web server, I shouldn't be doing tests that are so 'integration-y' in `src/`, but there are other times when I'd like to share (simpler) test helpers between the two types of tests. Thanks in advance.
If you keep working at it, you'll surely don't yourself using Rust in your day job. It's most of what I do and mine. Delivering features with Rust is so much easier, even with GTK.
I got it to compile with use nom::number::complete::le_u16; fn main() { let input: Vec&lt;u8&gt; = vec![10, 0, 20, 0]; let (_, v) = nom::multi::count::&lt;_, _, (&amp;[u8], nom::error::ErrorKind), _&gt;(le_u16, 2)(&amp;input).unwrap(); assert_eq!(v, vec![10, 20]); } I got to this solution by first doing `nom::multi::count::&lt;_, _, _, _&gt;()...`, noticing that ParseError has an impl on foreign types **impl&lt;I&gt;** [**ParseError**](https://docs.rs/nom/5.0.0/nom/error/trait.ParseError.html)**&lt;I&gt; for** [**(**](https://doc.rust-lang.org/nightly/std/primitive.tuple.html)**I,** [**ErrorKind**](https://docs.rs/nom/5.0.0/nom/error/enum.ErrorKind.html)[**)**](https://doc.rust-lang.org/nightly/std/primitive.tuple.html) , then proceding through the usual grind of adding and removing &amp;s until it compiled. I am honestly note sure about what is going on here. I suspect that similar things fail when the \`Vec\` is automatically getting coerced into a &amp;\[u8\] which messes up stuff.
&gt; Coincidentally I was also going to look into removing it for that reason. Me too, for the same reason. 127 dependencies is... A lot. But I don't know of any pure Rust alternative. I've been considering switching to Rust bindings for curl.
Each time you syscall into the kernel to do a read, you incur a fixed syscall overhead. Thus, you never want to read byte-by-byte if you can at all avoid it. (See coderstephen's comment about `BufReader`) When I discovered that, a friend who's ten years older had an "I thought everyone knew that" moment because he had more experience in the pre-Windows era, while I was just a precocious kid picking at QBasic at the time.
I get the impression that `collect` is an all powerful polymorphical conversion function for iterators everywhere, while `from/into` is meant to be more conservative (e.g. you can call `u64::from(0u32)` but not `u32::from(0u64)` because it could involve information loss, and types involving allocations do not want invisible cloning and expensive stuff happening behind the scene). The std::convert::From docs do have an impl for converting a binary heap to a Vec, but that seems to be the exception with almost everything else only messing with stack data and not the heap data references are pointing to.
Try to restart development on [rust-qt](https://github.com/rust-qt/) (and get to the point where it's possible to declare custom signals in Rust) so we have a way to write QWidget GUIs that feel native on KDE without using hand-written Python or C++ as glue? Implement semi-automatic generation of schema migration scripts for [Diesel](https://diesel.rs/) like can be found in [Django ORM](https://docs.djangoproject.com/en/2.2/topics/migrations/) for Python, or added to Python's [SQLAlchemy](https://www.sqlalchemy.org/) using [Alembic](https://alembic.sqlalchemy.org/en/latest/)? Write/extend a format backend for [image-rs](https://docs.rs/crate/image/) to bring it closer to the [supported formats list](https://pillow.readthedocs.io/en/stable/handbook/image-file-formats.html) for Python's [Pillow](https://python-pillow.org/) image library? Port the test suite from Python's [Universal Feed Parser](https://github.com/kurtmckee/feedparser) to the equivalent RSS and Atom libraries for Rust? Develop an equivalent to [Mutagen](https://github.com/quodlibet/mutagen) so Rust's support for reading and writing audio/video meta-tags isn't so sparse and limited? Extend [zip-rs](https://lib.rs/crates/zip) to bring it closer to parity with Python's `zipfile` module by adding functions like [`testzip()`](https://docs.python.org/3.5/library/zipfile.html#zipfile.ZipFile.testzip)? I can make other suggestions if none of these appeal to you.
If I am to pick a poison, I would rather deal with Rust code. :D I was going to investigate further, but I had an impression that some crates are pulling in a lot of dependencies that they are not going to use on a particular platform etc. and that will compile, but to nothing of value / nop. That might be ballooning the dependency count. Again, just a hint, after very short investigation why do I have to review winapi-related stuff when building on Linux.
yes that's not utf-8 format but this is the only thing i get when my client connects to the server. my server shows this as what receives. at this stage im not sending any text/string from my client side, its only connecting. But i wanna read their text request after the connecting to my server but this is the first thing will block me to read the next actual text/string(utf-8) format
that's true, but what should I do. this is happening before I send the text/string(utf-8) from my client. should I do some kind of error handling for the ::from\_utf8() ?
Perhaps you could add a feature flag for public export of the shared functions, and document it as developer only. The only problem is, I don't know how to configure `Cargo.toml` such that every integration test will have its own crate compiled with different feature flags turned on and off.
the book. &amp;#x200B; $ rustup doc
You should read The Book: https://doc.rust-lang.org/book/ Just as a heads-up Rust compile times can grow pretty fast as your project grows; at some point you may want to use rustup's cross compilation to compile on a beefier machine than a pi. It's quite easy but you have to know that there's a fix if things are compiling forever on a pi.
I agree. I started using rust last year, and the only thing confusing to me about the new modules syntax was that I saw so many crates using the old syntax! I just wish you could use macros without the old syntax and that it would warn you when you don't need to use an extern create declaration
Hi, I have some questions about aliasing of pointers with references. I can't find any satisfactory documentation about the complex interaction between pointer accessed structures and references pointing to the same objects. It is my understanding that mutable references are considered to be non-aliasing with themselves , but that with raw pointers are instead considered aliasing . &amp;#x200B; From this I'm pretty sure that there should be no-UB in this code as we are accessing directly the value that we are changing through a pointer: [https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=a58ed14ce0c5e692709d997803a5ba73](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=a58ed14ce0c5e692709d997803a5ba73) &amp;#x200B; I'm also pretty sure that this is potentially UB instead (correct me if wrong), where we instead create a mutable reference out of the pointer before modifying it: [https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=7fcb69c38cb1e0a5e12f330c1c65e755](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=7fcb69c38cb1e0a5e12f330c1c65e755) &amp;#x200B; It is not clear to me though if this is UB , where we access the value we want to modify through a pointer, but we are dereferencing the pointer and then using operator dot to get to the sub-value in the structure we want to modify: [https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=03e76aa842405f6116b48e54d2732e85](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=03e76aa842405f6116b48e54d2732e85) &amp;#x200B; Can somebody tell me in the rust memory model if the last one is valid UB-free code?
I have some generic code like this: use std::ops::Sub; use std::cmp::PartialOrd; fn generic_test&lt;T: Sub+ PartialOrd&gt;(left: T, right: T, max_diff: T) { let diff = left - right; assert!(diff &lt; max_diff) } and i get the error: error[E0369]: binary operation `&lt;` cannot be applied to type `&lt;T as std::ops::Sub&gt;::Output` --&gt; src/lib.rs:7:18 | 7 | assert!(diff &lt; max_diff) | ---- ^ -------- T | | | &lt;T as std::ops::Sub&gt;::Output | = note: an implementation of `std::cmp::PartialOrd` might be missing for `&lt;T as std::ops::Sub&gt;::Output` What does this error message mean and what trait bound can I introduce to fix it?
You can learn about function pointer vs closure in [this chapter of the book](https://doc.rust-lang.org/book/ch19-05-advanced-functions-and-closures.html). If you want to learn how closures are implemented there is [this blog post](https://stevedonovan.github.io/rustifications/2018/08/18/rust-closures-are-hard.html). But your issue isn't related to closures themselves, it's related to how Rust handle threading. Especially the [`Send`](https://doc.rust-lang.org/std/marker/trait.Send.html) and [`Sync`](https://doc.rust-lang.org/std/marker/trait.Sync.html) traits. `static` requires `Sync`, `Mutex&lt;T&gt;` implements `Sync` as long as `T` is `Send` and `Arc&lt;T&gt;` is `Send` as long as `T` is `Send + Sync`, this is why you get an error. You haven't restricted your closure, so as far as it knows, the compiler has no idea if your closure is `Send` or `Sync`. You can restrict it by changing `GOAL2` to: pub struct GOAL2 { pl: i32, gen: Arc&lt;Fn() -&gt; i32 + Send + Sync&gt;, } It compiles but your code might still be weird, not because of the closure thing, because of `Mutex&lt;Arc&gt;`. If you don't plan on cloning the `Arc`, I suggest you just go with a `Box` and remove the "`+ Sync`". Also if you don't capture anything with your closure you can use a `fn` and remove "`+ Send + Sync`".
I am not too worried about it, it woudlnt be anything too crazy, maybe a few thousand lines of code.
`Fn() -&gt; i32` is a trait - your original struct is more accurately written ``` pub struct GOAL { pl: i32, gen: dyn Fn() -&gt; i32, } ``` where `gen` is a trait object that implements `Fn() -&gt; i32`. That's why you couldn't instantiate a `GOAL`; a `dyn Fn() -&gt; i32` could be an arbitrary size, since the closure it represents could have zero or a hundred different captured variables. You need to put it behind some kind of reference (like a `&amp;`, `Box`, or `Arc`) to be able to store it. Your second try doesn't work because it would allow closures with non-sendable data to be registered. You can narrow down your closure trait to `Fn() -&gt; i32 + Send`. This should work: ``` pub struct Goal { pl: i32, gen: Box&lt;dyn Fn() -&gt; i32 + Send&gt;, } lazy_static! { pub static ref MC: Mutex&lt;HashMap&lt;String, Goal&gt;&gt; = Mutex::new(HashMap::new()); } ```
I would recommend not using Arc&lt;Fn() -&gt; i32&gt; and instead use a boxed trait object: pub struct GOAL { pl: i32, gen: Box&lt;dyn Fn()&gt; } with regard to `lazy_static`, the [docs say](https://docs.rs/lazy_static/1.3.0/lazy_static/) : &gt;Any type in [lazy_static!{...}] needs to fulfill the Sync trait. `Sync` is a marker for being able to be shared between threads. In order for `Sync` to exist the type must also be `Send` (sent between threads). If you know 100% that you *absolutely will not be using threading* you can do this: use lazy_static::lazy_static; use std::collections::HashMap; pub struct GOAL { pl: i32, gen: Box&lt;dyn Fn()&gt; } // add Send marker to GOAL (req for Sync) unsafe impl Send for GOAL{} // make lazy_static!{} compile errors go away unsafe impl Sync for GOAL{} fn main() { lazy_static!{ pub static ref MC : HashMap&lt;String, GOAL&gt; = HashMap::new(); } } [Playground here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=924b0011c72a1e1005abf4e137e50a51)
I was hired for java. Most utilities I write are written in rust.
Sub has an associated type named Output that specified what type the output of the operation is. In this case, it looks like you expect it to be T, so you can change your `Sub` to `Sub&lt;Output = T&gt;`.
&gt; I just wish you could use macros without the old syntax You can 99% of the time. 2015 example: #[macro_use] extern crate log; warn!("something's coming!"); 2018 example: use log::warn; warn!("something's coming!"); In certain edge cases you have to do a bit more, but it depends on how a particular crate is implemented. Most of the time the above works.
You've only specified that `T` has `PartialOrd`, but the result of subtraction can be a different type than the subtracted values (`&lt;T as Sub&gt;::Output`) - that is, even though `left` and `right` are both `T`, that doesn't mean that `left - right` is necessarily. Since you're comparing the output to a `T`, however, you can just limit the function to only `T`s whose `Sub::Output` is `T`: ``` fn generic_test&lt;T: Sub&lt;Output=T&gt; + PartialOrd&gt;(left: T, right: T, max_diff: T) { let diff = left - right; assert!(diff &lt; max_diff); } ``` Of course, you could go completely generic: ``` fn generic_test&lt;T, U, V, W&gt;(left: T, right: U, max_diff: V) where T: Sub&lt;U, Output=W&gt;, W: PartialOrd&lt;V&gt;, { let diff = left - right; assert!(diff &lt; max_diff); } ```
Ok, this works use std::ops::Sub; use std::cmp::PartialOrd; fn generic_test&lt;T: Sub&lt;Output=T&gt;+ PartialOrd&gt;(left: T, right: T, max_diff: T) { let diff = left - right; assert!(diff &lt; max_diff) } Thank you!
Thanks for the help! As a side note fencing code in ``` does not work in old reddit (must be 4 spaces) so ill leave this here: fn generic_test&lt;T: Sub&lt;Output=T&gt; + PartialOrd&gt;(left: T, right: T, max_diff: T) { let diff = left - right; assert!(diff &lt; max_diff); } and fn generic_test&lt;T, U, V, W&gt;(left: T, right: U, max_diff: V) where T: Sub&lt;U, Output=W&gt;, W: PartialOrd&lt;V&gt;, { let diff = left - right; assert!(diff &lt; max_diff); }
I agree with this. Also, be willing to accept that not 100% of your programming will be rust. I work at Amazon and write some rust for work but of course java and python continue to dominate. You need to be able to touch those things (and perhaps make a well reasoned argument that they transition to rust). Personally I have used "performance anxiety" to push Rust: 1. running security audits on routers and point of sale devices without disturbing traffic 2. low level utilities on compute heavy machine learning clusters where the machines are so expensive that saving a few minutes on your log uploading matters. Be able to communicate why it's worth the cost of teaching.
Instead of unwrapping you could handle the error, and handling it is actually best practice. At the very least you could determine the string that is causing the error and handle it appropriately. Doing that would prevent the panic.
Has this always been this way (since 2018 edition I mean).
Thank you! Tightning type annotations gradually is really helpful tips for me (and noticed `&lt;_, _, (&amp;[u8], _), _&gt;` also worked).
The issue is that there isn't any clear rules, based on [this big discussion](https://www.reddit.com/r/rust/comments/8u6dxh/raw_pointers_reference_aliasing_rules_ub_and/) it's up to you to follow the rules. &gt;When a shared reference to a value is created it prevents direct mutation of the value. Based on this rule, your three examples are UB. You can also use Miri (available in the playground) to check if your code is sound, it's not bulletproof but it's an additional check when you play with unsafe. Of course if you're trying to sidestep the borrow checker, please don't =)
&gt;The issue is that there isn't any clear rules, based on this big discussion it's up to you to follow the rules.When a shared reference to a value is created it prevents direct mutation of the value.Based on this rule, your three examples are UB. Hmm, this isn't what I understood from reading this [https://doc.rust-lang.org/beta/nomicon/aliasing.html](https://doc.rust-lang.org/beta/nomicon/aliasing.html) Thanks for the pointers at that conversation. It's all very confusing and it's unbelievable that there's no single source of truth for this. For the record, I'm trying to write embedded code using Rust and has been harder than I wanted because of this :( I need to use Raw pointers for dealing with certain things and I need to write code like trees and linked list, but with #\[no\_std\] I cannot use the integrated ones in the standard library and using raw pointers for implementing them seems very handy (doubly linked lists and such are much less of a pain with pointers than RefCell+Rc+Options... and so on) :-/ &amp;#x200B; From the article I posted it says this: "With that said, here's our working definition: variables and pointers *alias* if they refer to overlapping regions of memory." &amp;#x200B; So from that definition it would seem that a variable and a pointer are considering to alias. Would then this be fine? https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=e44b2189b62ec9cc76687bf41bf831ef &amp;#x200B; If its so, then I can just convert all my code that needs to use pointers to use only pointers and that would at least make it safe :-/
You need to parse the \`content\` as well: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=44e28ae551eca48baec408a14c6ad2d3](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=44e28ae551eca48baec408a14c6ad2d3)
If you're in the Bay Area (we're located in San Mateo), we use Rust to send over 4 billion push notifications a day, with up to bursts of 800K+ per second. Our stack is a mixture of Ruby, Rust, and Go. See backend / senior backend engineering roles at https://onesignal.com/careers. Joe, our CTO and also author of [alacritty](https://github.com/jwilm/alacritty), wrote up a (slightly out-of-date) post about our team for a different role as well: https://onesignal.com/blog/onesignal-is-hiring-a-distributed-systems-architect/. I'm happy to refer you and anyone on /r/rust, just send me a DM if you're interested and able to work in the area!
Thank you!
I want to make sure I'm following best practices with Rust. This is kinda my intro to Rust hacking this thing together. So any and all critiques would be greatly appreciated. I'm attempting to code linear regression from scratch. It actually works and I think I made some trade offs for better readability. So for the questions: [(code)](https://github.com/sixilli/dog-rust/blob/master/src/linear_regression.rs) * I'm newer to lower level languages. So is everything being f64 okay? For this sort of application f32 is usually good enough so I might do that instead. I did this to avoid type mismatches, but I don't know if this is frowned upon. * I want to expand functionality to multi dimensional data. I feel like the easiest way to handle this is to use a vector of vectors. Is this simply just done with a type Vec&lt;Vec&lt;f64&gt;&gt;? I might resort to a crate to just make this process easier.
Is this code free of undefined behavior? Is there a better way to write this today? #![feature(const_generics)] pub fn to_array&lt;T, const LEN: usize&gt;(data: Vec&lt;T&gt;) -&gt; Option&lt;[T; LEN]&gt; { use std::mem::{MaybeUninit, transmute}; if data.len() == LEN { unsafe { let mut result: MaybeUninit&lt;[T; LEN]&gt; = MaybeUninit::uninit(); // Change the type into something which is well defined instead of a // library type probably subject to change. let boxed: Box&lt;[T]&gt; = data.into(); // MaybeUninit&lt;U&gt; and U have the same layout, so this should be valid, let boxed_maybe_uninit = transmute::&lt;Box&lt;[T]&gt;, Box&lt;[MaybeUninit&lt;T&gt;]&gt;&gt;(boxed); // Valid cast because types have same layout, // and having a *const T should be fine even after T moves as long // as we don't use it again. let src_ptr: *const T = boxed_maybe_uninit.as_ptr() as _; // Cast from ptr to array to ptr to first element should be valid. // Getting ptr to the uninit value should be valid. let dst_ptr: *mut T = result.as_mut_ptr() as *mut T; src_ptr.copy_to_nonoverlapping(dst_ptr, LEN); Some(result.assume_init()) } } else { None } }
Great suggestions, especially rust-qt. If I'm ever able to transition from PyQt to using Rust to write desktop applications I'll be ecstatic.
At some point these rules will be set and the 'nomicon or the reference will explain them. There are (a lot of) things not 100% defined but Rust is still young, with time a rigorous spec will emerge. &amp;#x200B; I don't write embedded code but I think you can still use `Vec`, `Box`, `BTree`,... as long as you have an allocator. You just have to use the [alloc crate](https://doc.rust-lang.org/alloc/index.html) (stable since 2 days ago) instead of std. &amp;#x200B; You can go full raw pointers, the compiler will not assume a lot of things, you'll probably loose a lit bit of performance and you'll have to check for use after free for example, thing the compiler does for you usually. To me your code seems good this time.
In a `no_std` library crate, is there a community consensus on whether it's ok to depend on `std` behind a `#[cfg(test)]` attribute? IE, does it violate best practices to depend on `std` in the unit tests for a `no_std` crate?
You do specify the port in TCP btw
Thanks, I’m writing the allocator actually, the linked list is for implementing a slab allocator :-/ Thanks though, going full pointer will make feel much more comfortable :)
I mean was a different port. In the UDP that I tested I should use e.g 0.0.0.0:6666 for the client while the server is e.g 0.0.0.0:9999. I know we need to use ip:port to connect the server. But same ip:port (in TCP)
You use the same port for both client and server in UDP and TCP, its the IP address than can be different (but can be the same too)
In my server I used UdpSocket::bind(0.0.0.0:9999) In my client I used the same &gt; UdpSocket::bind(0.0.0.0:9999) and I got error that the port is already in use. So I changed the client to UdpSocket::bind(0.0.0.0:6666) and worked perfect. Correct me if I’m wrong, we need to have 2 different traits for listen and call in TCP right? But not in UDP? because right now I see my both client and server uses UdpSocket::bind(). Couldn’t find anything like “listen” or “call” in the docs
Thanks for the explanation, I can see how expected expense of the operation justifies the change in the name
In Rust UdpSocket::bind() is enough to open the connection, then you can read/write from that socket. &amp;#x200B; This is because UDP actually isn't a "client-server" protocol, there's no concept of Requests or Responses. It's just unstructured data flowing between two processes.
Makes sense, but there's the other side... Even though its really discouraged, you can actually index and etc using "unchecked" methods and in some cases I'd say that rust's static typing may even help reducing the number of checks, for example: When using a C API I never know whether its possible to receive a null pointer (depending on the documentation) so I end up checking for null everywhere or end up dealing with random crashes all the time... On rust its pretty clear so I only need to (and I'm actually forced to) do "null" checking when its actually needed.
I have a question, `coef` will always be 2 elements or can it be different?
so how to run my client.rs multiple times without specifying a port for each of them? what i need to do it to create a client.rs file and run it on multiple devices and the server should be on my server. if i want to specify a port for each of the client.rs, it's impossible to have that, right? what's the solution in this case?
The server should run on 1 machine, at a specified IP and port. &amp;#x200B; Then all of your clients run on different devices, and bind to that IP and port. The clients will need to know the IP and Port of the server in order to connect with your program. &amp;#x200B; This is how both TCP and UDP work
I just started reading the book and have a question I suspect has a simple answer. fn main() { let s1 = String::from("tic"); let s2 = String::from("tac"); let s3 = String::from("toe"); // s1 s2 s3 are moved here let s = format!("{}-{}-{}", s1, s2, s3); // still able to borrow println!("s={} s1={} s2={} s3={}", s, s1, s2, s3); // s1 s2 s3 moved here again! just_4_fun(s); just_4_fun(s1); just_4_fun(s3); just_4_fun(s2); // now not able to borrow! println!("after fun s={} s1={} s2={} s3={}", s, s1, s2, s3); } fn just_4_fun(s: String) { println!("i am here {}", s); } Why am I able to borrow s, s1, s2, s3 after passing them off to a built-in macro but not after passing them to my own function? Shouldn't both cause a move of the arguments and thus prevent further borrowing?
just updated my post. please look at my server and the client codes and tell me if I'm doing it wrong, pls. &amp;#x200B; you mentioned that I need to use the same IP:PORT of the sever in client's bind() trait. so what am I thinking is, "what am I gonna get on server when the client connects? same port?" \[ my experience in golang \] on TCP I got e.g 127.0.0.1:8453, 127.0.0.1:6567, 127.0.0.1:7382 from a same client file when I connected to the sever. &amp;#x200B; what am I gonna get on the UDP server after run my clients with same IP:PORT?
For basic linear regression with 1 dimensional input it will always be 2. Otherwise it's N-dimensions + 1. This is something that I may add in the future.
`println`, `format` and co. make a sneaky borrow for convenience.
I found the Rust embedded book even better. It’s an eye opener, even if it’s written for bare metal you will learn a lot for your Pi.
It should not be unless some tests are meant to be run on `no_std` targets.
A few notes: - Passing f64 by value would be more efficient and idiomatic - You will pretty much never have `&amp;Vec&lt;T&gt;` as input, `&amp;[T]` is more flexible - If you know you will push into a vector x times, you probably want to allocate space from the get go using [Vec::with_capacity](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.with_capacity), this will avoid unnecessary re-allocations - `for loop` + indexing is not recommended, use `for item in collection` instead - `vec![] as Vec&lt;f64&gt;` isn't very idiomatic, prefer `let var: Vec&lt;f64&gt; = vec![];` - Also the compiler can infer the type most of the time but if you want to keep it, it's not bad practice in any way - `return` is used for early return usually I made a version that doesn't allocate by iterating over `data` and `target` just once, I hope I didn't messed up the algorithm, [here's a link to the playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fe3d75ad6ad496f984eb2fbdb4bcbbe4). Speaking of which, you can use the playground to share your code, it's very useful. If you want to make your code more idiomatic you can run Clippy (available in the playground too) and it will tell you if it sees something. If you want to go multi-dimensions I'd recommend using [ndarray](https://crates.io/crates/ndarray) or [nalgebra](https://crates.io/crates/nalgebra).
I feel this might be a bit of an X/Y problem in that you ask about how to implement a Scala design in Rust instead of explaining what problem you are trying to solve with your design approach. So, there is a chance that your Scala bias lets you make an unfortunate design decision. Maybe there is something better which avoids a bunch of `dyn`s entirely. As I said, Rust does not support cross casting from one trait object (`dyn Trait1`) to another (`dyn Trait2`) because that would require the compiler to emit more runtime type information than just the vtable to so that it can be checked at runtime whether the object implements other traits. But you can kind of provide this runtime type info yourself in form of a trait method in `Widget`: [Check this out](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=6f73d5022f913b2c1c69533db453a102)
Ideally you'd want to use `gtk::Application` instead of manually calling `gtk::main()` as that will take care not only of the event loop but also about session management, DBus activation, etc. for your application, for example. And when using `gtk::Application`, your application windows should be `gtk::ApplicationWindow`. See [this](https://github.com/gtk-rs/examples/blob/master/src/bin/basic.rs) for a minimal example, or [this](https://github.com/sdroege/rustfest-rome18-gtk-gst-workshop) for a more complete example. Looks great otherwise, thanks for writing this down :)
Wow thanks so much. I did use the .map() in earlier iterations of this code. My questing with the change of theta0 and theta1. I would prefer to keep them in a vector because for real regression problems, the number of thetas is equal to columns of data + 1. But again thanks for shedding some light on things. It's been a difficult task just getting this to run.
Yep. It was mentioned in the original announcement (under "Module system changes"): https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html. It is also in the edition guide since day one.
If you don't need an array larger than 32 elements (because `TryFrom` is only implemented for arrays of 0 - 32 elements) you can use `TryFrom`: use std::convert::TryFrom; &lt;&amp;[Foo; 32]&gt;::try_from(&amp;data).ok() [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1b7d1cc80bf747428081b3e454bf268f) Otherwise, your code is a bit overcomplicated and also neglects to `mem::forget()` the original copy of the data and so produces double-drops (you wouldn't see this with `u8`). Instead, I'd do something like this: pub fn to_array&lt;T, const LEN: usize&gt;(mut data: Vec&lt;T&gt;) -&gt; Option&lt;[T; LEN]&gt; { if data.len() == LEN { unsafe { // we've verified the size and the alignment should already be correct let mut res = (data.as_ptr() as *const [T; LEN]).read(); // clear the vec without dropping the contents since we've moved them out data.set_len(0); Some(res) } } else { None } }
Thanks for providing the links. If the documentation appears a little lackluster, that may be because most of the API are specializations for hazard pointers from my other crate [reclaim](https://docs.rs/reclaim/0.2.1/reclaim/), which has further documentation.
Do you have any suggestions if I want to read about it? The docs doesn't seem to mention this peculiarity. https://doc.rust-lang.org/std/macro.println.html
Actually I would like to be able to do any (non-mutating) operation on the string. I want to get the value of this string and manipulate it in some way.
You want r/playrust :)
I would like to use the new facebook cryptocurrency libra: &amp;#x200B; [https://github.com/libra/libra](https://github.com/libra/libra) &amp;#x200B; I would like to create a simple faucet for the tesnet. In their open source wallet there are options to 1) mint coins - create X test net coins (input is the number of coins) 2) send these created coins to an address by getting an address as input &amp;#x200B; So what I want to do is create a simple web server with 1 an endpoint that takes an amount and an address. The amount is used in the mint function to create these coins and than to send it to the address. It is simple stuff and their docs are fine. I think this functionality can be found in the network module. I just have 0 experience with rust and honestly I don't think I will use it as my job is in JS so not sure how to do it.
Yeah it is probably a one time think with rust but maybe it is worth learning it either way. I just hate learning something and forgetting everything If I don't touch it for a while
Let's say you have N dimensions, `pred[i] = theta[0] + theta[1] + theta[2] + ... * data[0][i] * data[1][i] * ...` or is there a prediction per dimension or something else?
Yeah it is a simple project. I guess I'll learn a bit of rust now :)
Ok will give actix-web a try now, thanks.
What sort of code is that? I'm in a vaguely similar boat (mostly JS dev, enjoying using Rust), but I can't really think of a good reason to use it on the front-end. Because of the JS/WASM bridge problem, writing webapps in Rust doesn't seem significantly faster or more efficient than writing them directly in JavaScript, it's a new language for most of my team to learn, and we get 90% of the safety just from using TypeScript and some lints. I'd love to use it more on the backend, and I'm basically trying to find an excuse right now, but for the front-end world, I'm honestly unsure what significant benefit Rust has *right now*. Which is a shame, because I love the language in general.
Like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=204efe10bf2a19d06dad922311da4a17) ?
Cool! Thank and have a nice weekend!
I don't know why it's not clearly mentioned but I found [this stackoverflow question](https://stackoverflow.com/questions/30450399/does-println-borrow-or-own-the-variable).
Oh wow, how did I not think of that? It all makes sense now. Thank you very much!
Thanks! Pasting here so others can see: &gt; The macros print!, println!, eprint!, eprintln!, write!, writeln! and format! are a special case, not behaving as normal things do for reasons of convenience. The fact that they take references silently is part of that difference.
Go to your local rust group and leave a good impression.
to make deb and rpm pkgs https://github.com/jordansissel/fpm
Is it possible to make self-contained Windows executable with GTK like you can with QT? Last I checked GTK requires to redistribute some files even if you manage to link its libraries statically. This is what stops me from using GTK.
So you usually have a bias value, in my code I named it theta0, but I'll use bias for the example. The general idea is there's an equal number of thetas to how many columns of data there are. So I'll use xN to describe the column. Thus pred = bias + theta0*x0 +theta1*x1 + thetaN*xN. Then once all of the data has been ran through you can find the loss, then update the thetas using gradient descent. Housing prices typically get used as regression 101. The prediction is usually the price of the house. So using 2 columns you might have something like theta0*num_rooms + theta1*zip_code + bias = price
Server : bind, recv. Client : bind(client addr) , send (server address), recv Server : recv returns message from client. Has data and client addr. Server : send (client addr), recv Client : recieves message from server... Note there is no client or server in udp. Just sockets which are like mailboxes. The client in this example is just the first to send a packet.
That's actually also my #1 desire out of the Rust ecosystem.
stratisd is in rust too (and is a redhat project iirc?). I'll try to look around to see if redhat is hiring to work on rust.
I’m doing a lot of rendering in WebGL and some geometric algorithms (like the [crate](https://crates.io/crates/offset-polygon) I published recently) to generate the input for WebGL. I consider it easier to write WebGL code in Rust, because it’s closer to C, which the API was designed for (manual memory management and structs of binary data). I don’t plan to replace the stuff generating the HTML elements. I'm using a JavaScript framework for that (ember.js), and there’s nothing even coming close to the feature set in Rust.
There was a lib recently to call Java from Rust. Maybe this will help :)
Correct, even the new \`0.4.0\` using \`MaybeUninit\` is still unsound, since it dereferences an uninitialized value. I believe, in order to be sound, \`offset\_of!\` either has to be a compiler intrinsic macro or there needs to be some syntax addition to the language to access a field through a raw pointer without dereferencing it. At least that is my understanding.
Not sure what postgres library you are using, but here is a notifications example test from tokio-postgres: [https://github.com/sfackler/rust-postgres/blob/eaef62c3408538d9dcc3933b3864449b39f5e1b2/tokio-postgres/tests/test/main.rs#L455](https://github.com/sfackler/rust-postgres/blob/eaef62c3408538d9dcc3933b3864449b39f5e1b2/tokio-postgres/tests/test/main.rs#L455)
Thank you, I will look into `BufReader`!
I knew I am doing something wrong in the back of my head. That's why I asked. Thank you!
Makes sense. Thank you.
Exactly.
Know I know as well :)
Thanks for the link. Definitely reading this!
Perhaps some more interesting tidbits: The main difference between hazard pointers and epoch-based approaches (like \`crossbeam-epoch\`) is that hazard pointers protect individual values in shared memory from reclamation, whereas epoch-based ones protect entire "regions" of code. The advantage of the later approach is, that you have to *announce* a thread to have entered a protected region only once and all subsequent loads are basically free. *Announcing* something to all other threads in most cases requires sequential consistency of all announcements, which has to issue a full memory and is expensive. It is so expensive, in fact, that reducing the number of required fences or deferring as much as possible is basically the only way to improve the performance of lock-free algorithms. Hazard pointers, on the other hand, have to announce every single value that is loaded to all other threads and hence need a full memory fence for every load. Their advantage is primarily, that even under high contention, accumulated garbage can be quickly reclaimed, whereas with epoch-based approaches, the time windows, during which no thread is in a protected region, become too small to regularly flush the accumulated garbage. This property is expressed in the API in that you need a \*mutable\* reference to a \`Guard\` instead of a \*shared\* one, in order to protect values. Where you would write the following code with \`crossbeam-epoch\` like so: use std::sync::atomic::Ordering; use crossbeam_epoch::{self as epoch, Atomic}; // shared by multiple threads let atomic = Atomic::new(1); let guard = &amp;epoch::pin(); let shared = atomic.load(Ordering::SeqCst, guard); if !shared.is_null() { unsafe { println!("{}", shared.deref()) }; } With \`hazptr\` you'd write: use std::sync::atomic::Ordering; use hazptr::Guard; // the `typenum` dependency will be removed once const generics become stable type Atomic&lt;T&gt; = hazptr::Atomic&lt;T, hazptr::typenum::U0&gt;; let guard = &amp;mut Guard::new(); let shared = atomic.load(Ordering::SeqCst, guard); if let Some(shared) = shared { println!("{}", *shared); } The reason is that \`hazptr::Guard\` carries an internal state (a hazard pointer) and can only protect one \`Atomic\` value at a time. This is fully enforced by the type system and the borrow checker: You can not use a \`Shared\` anymore it the \`Guard\` it was loaded with has since been used to protect another value. If you'd like to now more, \[this\]([https://aturon.github.io/blog/2015/08/27/epoch/](https://aturon.github.io/blog/2015/08/27/epoch/)) blog post gives a good introduction into the necessity of memory reclamation and the design behind \`crossbeam-epoch\` and \[this\]([http://ticki.github.io/blog/fearless-concurrency-with-hazard-pointers/](http://ticki.github.io/blog/fearless-concurrency-with-hazard-pointers/)) blog post explains the concept behind hazard pointers. Note that the \`conc\` crate is no longer maintained, not fully lock-free (at least from my understanding) and I also have some doubts about the soundness of some its internals.
&gt; &gt; Even if the end result is above zero for unsigned values, subtraction may never go below zero. &gt; &gt; This is only true in C/C++ where overflow/underflow is undefined behavior. I disagree. This also true in Rust where the result of the operation is (formally) unspecified; safe, certainly, but unspecified. The author of a binary can pick whichever behavior they wish (panicking or wrapping), and therefore library authors cannot assume that it a subtraction going below zero is going to be balanced by the next addition, as the user of said library may pick panicking.
&gt; The Rust answer to this whole situation is to pin down the semantics of signed and unsigned integers; both are guaranteed to wrap on over/underflow. This is incorrect. Rust *the language* simply says that the result is unspecified (and safe). There are two reasons to defining it as such: 1. Static analysis tools can flag any over/underflow as an issue: their result is unspecified, thus they cannot be intentional. 2. Unfortunately, at the moment the code generation for panicking on over/underflow introduces a high performance penalty on maths-heavy code; leaving the behavior unspecified thus allows the user to pick the behavior that best suit their usecase. rustc offers 2 possible behaviors -- panicking and wrapping -- which the author of a binary can choose from; with the default *for now* being panicking in Debug (to help developers spot bugs) and wrapping in Release (for performance reasons). It is notable that should any headway be made with regard to performance of panicking on overflow in Release mode (from better optimization support to better assembly), it would be perfectly reasonable for the default Release behavior to switch to panicking.
I have not looked at the code, but great little project! On iOS Safari it only shows a white page though (Safari *is* the new IE...). On the topic of github pages, I have them in a different branch `gh-pages` and I did not even know you could have them in the same branch. If you write yourself a small skript (maybe there is one already) that puts the `pkg/` in the `gh-pages` branch it should solve your problems.
So the server is receiving *something* when the client connects, but the client (code) doesn't explicitly send it. You're just interested in what this is? In that case the `String::from_utf8_lossy` function might be a good idea. If you just need to get rid of some data at the beginning that the client (framework?) might be sending, you could also just read it -- like you are doing -- and then just forget about it.^though, you should try to find out what is means first...
I have [this thing](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=90c4fe439967ff99f9728fbde89ae24c), I'm not sure if it's doing the right thing though. Especially regarding the diff\_sums. Is the bias' diff\_sum supposed to be updated that much? Also I had to allocate and go though all elements twice this time, I don't know if I can do much better currently. So, it definitely needs testing but this is interesting =)
sssssshh!
Yes, that definitely accounts for some. You see this with Fuchsia and Redox dependencies a bit too. But I don't think it's a significant chunk.
Thanks for correction.
Yes. If it was returning a reference bound to same lifetime as input then it works.
Linked lists are not idiomatic Rust. Go for a HashMap instead, the new Swiss table based map implementations in Rust 1.36 offer astonishing performance.
You can use `0` as a port and the OS will pick an available one at random for you. This is what TCP does under the hood when creating a client socket.
regex is a pretty bad offender here. See here for additional context: https://github.com/rust-lang/regex/issues/583
Seems like the algorithm is unstable: [https://ibb.co/931cBkg](https://ibb.co/931cBkg)
[https://rust-embedded.github.io/book/](https://rust-embedded.github.io/book/)
You might want to try [https://www.reddit.com/r/playrust/](https://www.reddit.com/r/playrust/), this is the subreddit for the Rust programming language.
You're looking for /r/playrust This is the Rust programming language subreddit.
Okay thx
Thx
Great. This is the one I’ve been looking for and must try. But before that should I do like 0.0.0.0:0 ?
Arguably Qt is nicer for non-GNOME users since it's more traditional and doesn't have the same hang-ups and design decisions that the GTK and GNOME are motivated by, although Qt being C++ and GTK being C makes GTK much nicer to develop for.
The only thing `const` is change.
Here's a workaround, if you put this in your integration test, you can access any module. #[path="../src/helper.rs"] mod helper; I found [this short thread about it](https://users.rust-lang.org/t/sharing-helper-function-between-unit-and-integration-tests/9941).
In this timeline, I wouldn't repeat the experiment.
Ooh, your version is much nicer. &gt; and also neglects to mem::forget() the original copy of the data and so produces double-drops (you wouldn't see this with u8) I don't think this is correct, the thing I drop is a Box&lt;[MaybeUninit&lt;T&gt;]&gt; which should deallocate the array (yah!) but not the inner T's since dropping a MaybeUninit is a no-op.
Is there something unrealistic about any of the rust implementations compared to Godot? Eg, is there a reason you didn’t link Amethyst or Ggez?
Are there docs that you are referencing? I see here (https://doc.rust-lang.org/std/convert/trait.Into.html) that &gt; One should only implement `Into` if a conversion to a type outside the current crate is required. And that seems like my use case, but what you say is correct: I was able to `impl From&lt;ForeignType&gt; for LocalType`. Does that mean the docs I am referencing are out of date?
Perhaps I am biased (scratch that, I'm _definitely_ biased), but would you be interested in [cHTTP](https://docs.rs/chttp/)? It uses curl under the hood, but provides a really nice, Rustic API on top with extra goodies. In addition, 0.5 will have first-class support for `std::future::Future`. Currently 0.4.5 is sitting at 66 total dependencies, and the 0.5 alpha 1 at 61. I'm definitely interested in trimming this down even further now.
I don't believe that requirement has changed.
You might be interested in my crate [cHTTP](https://docs.rs/chttp), which offers a nice Rustic abstraction over curl and interop with the [http](https://docs.rs/http) crate (with async/await support coming soon in 0.5)...
Too bad the official [documentation](https://github.com/rust-lang/book/issues/711) is still partially broken offine.
Wrong sub. You’re looking for r/playrust
Even if that were about the Rust programming language, it would still be spam. So try again in /r/playrust, I guess? And next time read the sidebar before posting.
I think this is actually the basis for most misunderstandings, the two parties have a divergent enough set of basis fn that the chirality of their statements is non-compatible. They might as well not be speaking the same language. I think, Rust will not-fail, and it will not-fail for the same reasons that other languages have succeeded 1) solving a needed problem with a low number of competitors 2) affordances. Perl: Highly successful in its web niche. It also got crazy lucky, the web ran on text and databases. Perl had mature support for both. Right place at the right time. PHP: Seriously? A free, shitty version of ASP, but you could deploy it on to a VPS. Setup and deployment were crazy easy, checking your code meant hitting F5. Any other language could have been better than PHP, but it did the meta-things better. Deployment, interactive dev and later, php docs, find as you type plus a mini version of stack overflow? That it was accelerated the acceleration. Python: More right place right time. Free version of Matlab, lots of cross over from science education as everyone gets tech industry jobs. Java: So much good. Memory safety, stack traces, threading, portable binary archives. If Rust *just* predates on C/C++, that won't be good enough. It has to bring over the Java folks, the Ruby folks and the JS folks. But how can it do so in a way that doesn't also have it _become_ Java, Ruby or JS (and their ecosystems) in the process?
"Expose those multiple cached slices to OS compositor for power savings and better scrolling performance where supported." understates the benefit of this work. In fact, when fully completed, it should be a fix for Firefox's power consumption problems on macOS that are frequent complaints we get from Mac users.
What would that have to do with anything?
I did some testing with your newest code and wasn't exactly sure how to input the data for testing. Your previous version works when I added in the test case. I compared your version to mine to see if there's any major speed differences. Yours clocked in at 1.6~ms, while mine was around 13~ms. I'm guessing the majority of the slowdown is coming from the for loops. But thanks again for all the help! Here's the [example](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=57055d3c2d14937326a8a6e28a97488b) with the test case.
People complain that Rust doesn't have a complete spec when other languages don't either. But nobody ever seems to complain about those languages.
Hello all, &amp;#x200B; I built this project to get hands-on experience with developing software in rust. Hence, I'm kind of naive to the language. So please let me know of things I could improve upon. &amp;#x200B; Snoopy uses : \* pcap to capture packets and also encode it into pcap files. \* Clap to parse command line arguments \* A few packet parser libraries to parse the network packets. \* Serde to encode this data to JSON files.
I am a co-founder/CTO of a startup and introduced Rust into our architecture. It is slowly taking over all of our services and jobs. Tech Stack: Vue.js -&gt; Rust Services/Jobs -&gt; Postgres on GCP (Cloud Run and Compute).
WHOA! This might be exactly what I'm looking for in the case of handling callbacks and drawable functionality. Thanks!!!
I think Go is a poor example. It does have a complete spec. Perhaps a better example is a language like PHP that has incredible adoption but does not have a complete spec.
Rust is a Strongly Typed language. When you declare what type you're using, you're communicating the possible values of that type. Using a signed integer tells library users and the compiler that negative numbers are a completely acceptable case. Using an unsigned integer says that this number will never be less than 0 and that a negative value is nonsense. In regards to overflow, if `debug_assertions` is turned on, which in debug mode, it is by default, then your program will panic on overflow and underflow regardless of whether you're using signed or unsigned numbers. If your program panics from one of these assertions, then you can decide to use one of the functions that provides explicit overflow behavior, like `wrapping_`, `overflowing_`, `checked_`, and `saturating_` versions of each operation. With overflow not an issue, do you want library users to think that it's reasonable to have a collection with a negative length, or to loop negative times, or to access the negative-second element of an array? There are many things that are inherently unsigned and rust provides unsigned integers to let you communicate that. When Gangnam Style briefly had negative views, the result was nonsensical. Granted, it would have only lasted for another 2 billion views had YouTube used unsigned integers, after which point there would still be trouble counting and either an incorrect value, or in the best case scenario, no value, would be shown.
Are there any desktop Gui libraries based on webrender?
I don't understand why. Could you explain?
Hey all, I am currently going through the rust book, 12th chapter atm, and I have a weird issue with rls in vs code. When I move all the functions to [lib.rs](https://lib.rs) and then use them in the [main.rs](https://main.rs) vs code highlights the imports as unresolved but the code runs fine so it seems he does find them. Could this be a bug in the extension or am I missing something?
I really appreciate all the choices, and `libcurl` is a very stable etc, but all the cross-compilation, header-finding, C-building issues are making me avoid any C dependencies.
It's a bit tricky to try to debug this without a compilable test case. Can you link to your actual code, or to a more complete test case? Does this only happen cross-crate? Have you tested what happens if the specialized impl is in crateA?
https://os.phil-opp.com/heap-allocation/ This is awesome. This is the first thing I've read that really demonstrates what Rust is doing to make memory allocation safer.
thx
I hadn't noticed this, but I'm not surprised. In general, the solution should be unstable when you have three points that are nearly collinear, or six points that are nearly co-conic. That example has *nine* nearly-collinear points, so I'm guessing that made it unstable enough for floating point error to matter. &amp;#x200B; I changed some `f32`s to `f64`s in the code, which should hopefully help somewhat.
I agree, that's a definite drawback. I have the default features configured such that libcurl is included via a submodule and does not need to be present on the build system, but cross-compilation is definitely a pain with C dependencies.
Okay after i restarted vs code it seems to be fixed. Still seems like a bug though.
[Twitter's migration from Rails to Scala](https://medium.com/@mittalyashu/why-did-twitter-switch-from-ruby-on-rails-dac66150044d) and [Stripe's introduction of Sorbet](https://sorbet.org/) show that Ruby is hard to operate *at scale*. Building a spec-compliant Ruby in Rust gives large deployments a path forward to ripping parts of their code out of Ruby and into Rust, which is a safer, more performant language.
I don't see the point, how many companies need to deal with as many traffic as Twitter? It's also quite ironic that you're saying this on a website that afaik runs on Python...
Keep it up! 🔥
To add on that: when I need to model some kind of `enum` like that, I usually implement `From` trait for each variant of the `enum`.
Amethyst is not complete and has no editor. I didn't review ggez.
There is Azul.
That's a good point. Most people don't deal with as much traffic as twitter, but anyone running Ruby can stand to benefit from a more efficient interpreter. This is part of Matz's ["Ruby 3x3" project](https://blog.heroku.com/ruby-3-by-3/): &gt; The goal is to make Ruby 3 run three times faster as compared to Ruby 2.0. But even assuming we already have the fastest Ruby that could exist, isn't it neat to attempt a new implementation, just for the sake of expanding how we understand the current one? This has already sort of happened in Ruby before: [YARV](http://www.atdot.net/yarv/) was a project to make a faster Ruby VM, and many parts of it were incorporated into Ruby 1.9.
That makes sense, thanks!
Could you show an example?
Appreciate the info!
Sure thing. Here's the [link](https://github.com/datalove-app/datalove/tree/feat/rs-ipld/rust) to the repo + branch + folder. `cd rust` and `cargo test` should get you started. `/rust/ipld_dag/src/dag/mod.rs` has a type `Dag` that requires an `Encoder` `/rust/ipld_dag/src/cid.rs` has the example `Link` type (called `CID`) `/rust/ipld_dag/src/format.rs` defines `Encoder` `/rust/ipld_dag_json/src/lib.rs` has an impl of `Encoder` and the tests &gt; Does this only happen cross-crate? Have you tested what happens if the specialized impl is in crateA? Haven't tried that since that isn't my use case, but good point. Interesting twist: you'll notice a second `Encoder` method called `encode_bytes`, which when called within `Dag::serialize`, calls the overridden method rather than the default, so I have no idea what's going on.
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=879d44c5eae66f30453d10a78dc3c069 I did this on my phone so it's the bare minimum example, sorry.
I had a quick look. The index format needs to be specified as Uint32 when creating the pipeline, since that's what you have. Other than that - looks to be working. I'd advise you to setup a perspective camera and learn to use graphics debugging tools on your platform.
&gt; This is probably super unhelpful, but this is the backtrace output Looks like you build release mode, but without debug info. Add this to Cargo.toml to get line numbers: [profile.release] debug = true But I get rough idea what is going on. In fact, I already mentioned it in this discussion. You call method Gilrs::connected_gamepad(&amp;mut self, id: GamepadId) -&gt; Option&lt;Gamepad&lt;'a&gt;&gt;; alias getConnectedGamepad; like this: gilrs.getConnectedGamepad(activeGamepad); if look at generated java code you see: long a0C0 = a0.mNativeObj; a0.mNativeObj = 0; so you can do it only once, semantic of Rust preserved here for Java. As I know there are plans to implement derive(Copy) for Java in rust_swig. But at now you can write code like this: gilrs.getConnectedGamepad(activeGamepad); activeGamepad = null; or export clone method and write: gilrs.getConnectedGamepad(activeGamepad.clone());
Process a 25Tb csv file to give you a particular result.
Aha, I understand now seeing the code you posted! That certainly fixed my problem, I should definitely dig more deeply into the FFI, maybe I'd run into less problems haha. Thank you for the help again /u/davemilter
A first remark: the use of `sudo` is of course necessary for `capture`, however it seems out of place for `parse`. Reading a capture file does not necessarily require root privilege, after all. --- Otherwise, this looks pretty neat. Do you plan on adding filtering, both for `capture` and `parse`? It's generally pretty helpful.
&gt; Seriously, as a thought exercise try to come up with a computer science algorithm that really needs signed integers. (Not unsigned integers, not fixed- or floating-point approximations of reals, not sentinel values like `-1`, etc.) Positions on a discrete grid that extends in both directions? (ala Minecraft) For even more niche uses, Posit numbers are actually defined as using 2's complement for negative values, making it technically easier to implement with signed integers than unsigned. Another example is that pointers on x64 are *not* unsigned 64 bit numbers, but *signed 48* bit numbers. Most kernels operate in the negative address space. We treat it as unsigned, but doing so leaves a conspicuous gap between 2^48 and (2^64 - 2^48) of invalid addresses that would cause a hardware exception.
Thanks!
Thanks! That blog post looks v. helpful!
Thanks!
Thanks! I can't guarantee single-threading in the future, so a mutex it is.
I guess the main motivation is performance. As such I think the choice of mruby is not wise. Mruby is pretty slow compared with cruby. I do not think it is used in production anywhere and I would not be surprised if any mid size rails app does not even work there. Rocket is also not extremely fast but I guess that would improve with time. Other big problem I see is the scope is huge, and at some point gratuitous, was it really needed to run rubocop on the standard library files? If an app running in let's say Puma + cruby 2.6 fails misteriously, it would be difficult to know where the error happens as practically every layer has modifications All that said, I love the idea of speeding up rails with rust.
Thanks! I'll check it out next time I'm looking at my imdb-rename project.
The problem lays more in other peoples code. For example a simple webserver can quickly take 10min to compile even on a quick machine, because of all the dependencies. However, this generally only has to be run once and then all the dependencies are cached until either rust or the deps. update.
Thanks!
Could you please be a little bit more specific about the problems you faced with rust libraries?
Hey all, Does anyone know of an ergonomic and correct way to translate file paths? I know the path object has an API for iterating over components, so I could just iterate and then reconstruct the path, but if there's an easier/more correct way to do it, I'd rather use something more built in. Some background: I need to be able to translate paths on any platform (windows, macOS, Linux, etc) and translate them to a Unix path. I can guess up some code that will probably work in most cases, but there's a good chance I'd miss something. Thanks!
the first problem is most like other languages have too, I don't know the quality of lib unless really dive deep and face its limitation/bugs, I searched a lot already on GUI libs and got answers from here and user forums, e.g Azul, relm, all broken just by running example, azul broken on macos as a cross-platform GUI lib for 2 months, and relm calculator pop up many windows on Linux without showing buttons. rust-openssl have no offical document on how to setup on windows, and I had to use GitHub issue as document . The second problem is very obvious, important libraries like openssl, should be in official repo or something similar, not on a private repo, even it's just some bindings.
I think some of the reason for this is the lack of natively written libraries. The majority of libraries for network protocols and GUIs are bindings to unsafe C code. I feel like having these written in pure rust will provide for a much safer and much higher quality libraries. But remember, rust is still in its infancy and there’s already something like 28,000 crates on crates.io, so I feel that this will simply improve with time.
I totally agree, but at least for openssl, I guess before we have a really good native implementation, it's better the official team can take control of such important lib as unix/os interface, just like other languages provide it's own interface/lib for it,
Sudo might be needed for monitoring mode?
This inspired me to see if I can optimize the binary size and compilation time of cHTTP: https://github.com/sagebind/chttp/issues/41
Thanks for the tip!
Thanks for the example
It cut my post off, I am new to Reddit posting. I usually just lurk. But we like to help new players when we can. Come hang out an watch the stream. Everyone is welcome. Sorry for the double post like this.
The bindings have no definitions in them. And triangle.frag has a uniform matrix but there is no code to load it.
&gt; I need use multiple threads to control workers, but found no luck use std::thread, since cant send "stop/pause" to a thread, I understand there have to be reasons doing this, but just not very convenient to use. IMO bad practice is not a valid reason to just totally remove feature, goto is one example maybe. From what I remember, not all OSes *provide* APIs to externally control the execution of individual threads within a process and, when they do, said APIs are intended only for writing debuggers. (And the OS developers have a bit of a "don't blame us if it causes your program to eat your cat" attitude toward people using them as part of normal program operation.) In fact, I remember something to that effect in one of Raymond Chen's The Old New Thing posts about interactions with clients for Microsoft's paid developer support service. I have yet to hear of a language which provides reliable, portable runtime control of threads without doing it by having everything executing inside a virtual machine.
As a relatively new software engineer (1.5 years, self-taught) I’ve started to realize that Rust provides a great balance between the modern and the archaic. I can develop a low-level understanding of computing concepts while also engaging a relevant tool, rather than simply inculcating C (which I’ll never be hired to write) or remaining ignorant by only touching higher-level abstractions like Java and Node. Thanks for documenting this! It’s fascinating for me as I continue to learn. Stuff like this keeps me stoked about computing.
You're looking for /r/playrust, this subreddit is for the Rust programming language.
Oh I see! Thanks for the feedback!
You can't. Go is basically synonymous with cloud, doubly because any application that requires programmatic interaction with a kubernetes cluster is pretty much going to be written in go due to the go client as the only viable possibility.
I tested it with your test case and there was a little error, [this version](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=45a9e3a60ecab9d16260be1d64b0b20d) outputs the same thing. So this version should work on N dimensions data, I had to extract `coef` from `linear_regression` since it can change. `target` doesn't change and `data` should be a "flatten `Vec`", instead of having `Vec&lt;Vec&lt;f64&gt;&gt;` you just extend the first one. For example: vec![vec![0, 1, 2], vec![3, 4, 5], vec! [6, 7, 8]]; // should be vec![0, 1, 2, 3, 4, 5, 6, 7, 8]; Of course with 1D data, it's the same. Regarding performance, you have to compile in release mode, Rust is very unoptimized in debug build. Iterators gain a lot in the switch. I remove the debugging each 100 steps and used [criterion](https://crates.io/crates/criterion) to get some result: - Your version: 1.2007ms - My version: 26.409µs - N-D version: 154.71µs But if you want to be serious about speed you'll have to use the GPU.
The main way to do this is to use `&amp;mut` references - to call a method or to pass it around as a mutable reference. That string lives in the struct. Since you are only borrowing the struct yourself (with `&amp;mut self`), removing it from there would be invalid. The safety reason it's invalid is that if a panic happens while you're doing operations on it, then the struct could end up in a completely invalid state with no value initialized in the `s` field. If you want to take it out completely, you need to remove it from the struct, and to do that, you need to own the struct itself. If your method takes `mut self` instead of `&amp;mut self`, then you'll be able to do this. However, know that this isn't the usual way to do this kind of operation - usually, you can deal entirely with mutable references, and if you want to do some mutating operation on the string, then you can use `&amp;mut` methods or pass it around as an `&amp;mut String`.
Since when is a client to anything is a big deal, let alone language defining?
It's because you're not _reading_ the value, you're _taking_ it. The safety reason is "What if the `+ " Hello"` operation panicked?". If you'd taken out `self.s`, then the panic happened before you put a new value back, then a `Simple` would exist _with no string in the `s` field_. `Simple` must always have a valid value in its `s` field, so this wouldn't be OK.
Because it's gigantic and trying to reproduce the same functionality in another language would require too much effort?
I love your profile pic lol
\&gt; worried about scalability \&gt; switch to Scala, which is to put it lightly inaccurately named
I'm pretty sure the cloud is more than the API for a single piece of software. Might as well say the cloud language is PHP cause it interfaces well with Apache/NGINX.
I've got 3 big reasons. 1. Lack of basic functionality in the standard library. Seriously, random numbers not in? 2. No GCC frontend (at least for now). 3. Ada/Spark is already established and can deliver most of Rust functionality right now (increasingly more in Spark mode), has a larger standard library, and Adacore as a vendor to fix bugs with compilers. I like the language goals, but I'm not sure it can overcome these barriers faster than C++ and Ada improve to achieve Rust's features or get close enough.
it's a pretty big, and very important, piece of software that is integral to a lot of infrastructure management.
I don't see how it's necessary. That's like saying that Go can't be "the language of the cloud" because some shops use Ansible and Ansible is written in Python, or that neither of those can be "the language of the cloud" because SystemD is written in C and all those Linux hosts run SystemD.
Thanks for answering. I've had a camera working before with this code. The issue seems to be that I am missing triangles being rendered. I've added two pngs to the repository. I took out everything except the position vertices. I've tried it without indexing also. Those darn triangles are refusing to be drawn! &amp;#x200B; is it possibly a problem with tobj? I know you made your own for three-rs.
r/playrust
Ouf, didn't realize. Thank you.
He is real bro.
It’s just a client. And it’s got a lot of official and unofficial implementations already. And it’s REST. You don’t really need any kind of “client” for REST apis, just fire up your favourite http and json libraries. On top of which, I’m pretty sure client libraries are not why people decide it’s worth their time and money and effort to move to Rust. There’s a little more to it, depending on what you compare it with. For example, Java to Rust is mind-blowing ram and cpu efficiency shift, whereas C++ to Rust’s reasons might lie in a different area. And then are different flavours to “clouds”. You can always run compiled binaries on rented VMs and grow and shrink those VMs on-demand, even without Kubernetes and that would still technically be a cloud.
Yes, it is not required for parse. I was copy pasting commands and forgot to remove sudo for parsing that's it. XD Yes, I am working on packet filtering. I shall add it soon. Thanks :D
Wait, what ? XD
You look happy my man. So many people have stuffy grumpy pics. It's good. Keep making cool stuff!
Yes, and very few programs have any need or desire to interface with it.
&gt; but found no luck use std::thread, since cant send "stop/pause" to a thread Can you give an example of when this would be useful?
It’s off topic there too. They want /r/playrustservers
yarte seems to have a rich history. Why was it removed from git?
There is no end to these
1. https://docs.rs/about has a link to the bug tracker, among other information
Think about it, if one saw that as a search result wouldn't (at least some of the time) ppl just think someone named a crate about? Like the crate I found called "bugs"... seriously https://docs.rs/bugs
[https://github.com/search?q=pthread\_kill&amp;type=Code](https://github.com/search?q=pthread_kill&amp;type=Code) hope this help
only a few languages qualify "reliable, portable, without having everything executing inside a VM" I am not sure about windows, but I think this is a useful feature in general.
Lol, thanks man! :D
I suppose one workaround is to write a macro I guess.
&gt; The fact that you have made it to this subreddit suggests that you wouldn't disagree that Rust would be an *excellent* choice for cloud software. Please don't do this. It suggests no such thing. I enjoy Rust but I wouldn't dream of inflicting it on my co-workers. Don't presume. &gt; For projects large and small, simple and intricate, innovative and educational, the sheer quantity of development and execution hours that can be saved by choosing Rust is more valuable than ever with rising use and dependence on cloud. It may save some development hours compared to C or C++, but those are hardly cloud languages. As for execution hours many/most parts of your software may not benefit (IO bound), and good cloud software can often scale horizontally. If you want to claim Rust saves so many development hours you should present some study supporting this. &gt; What other language are we supposed to use? Python? Pfft, please. Java? Don't make me laugh. C#? Meh. Go? Mmm, maybe. How rude. Those are all fine choices. If you can run Python currently then you probably don't need extra performance that much, and when you do switching to any of the other languages you mentioned will probably give a significant boost. Java and C# have great library support, and where they can be used so can languages such as Scala, Kotlin, Clojure, F#... I don't see why you get to dismiss all of these out of hand. &gt; But clearly Rust's extensive scientific ecosystem, foolproof parallelism capabilities, and maximum performance make it the most superior choice. Do most cloud applications require or benefit from an 'extensive scientific ecosystem', whatever that means? I doubt the 'foolproof parallelism capabilities' will see much use, the cloud software I have seen heavily uses async/await, but never bothers with multiple threads per request. As for maximum performance: when most of your time is spent waiting on other services or a database it doesn't help that much. I'd much rather have a good dependency injection framework than a little more performance. YMMV. &gt; How can we, the Rust ecosystem, brand Rust as "THE language of the cloud", akin to javascript's "language of the web?" Javascript has a captive audience. I think defending the choice for Rust with actual data and substantial arguments would go a long way. Also discuss the various trade-offs. Your post somehow made me like Rust less.
How fast is it? I see there is a benches folder, but I have not run those. I currently prefer using Rocket with their handlebars templates from Rocket_contrib. I'm curious to know how fast yarte actually is, especially compared to others like the handlebars crate.
Is there anyone on Earth that feels like their template engine is the bottleneck?
What would `D:\\foo\bar.txt` map to?
My point is that it's not within the language's ability to do things the OS doesn't allow while running at native speed, because implementing features the OS doesn't support basically means running the language under partial emulation.
There is basically an openssl replacement. It's called `rustls`, and only recently is getting support in major crates. Here's the reqwest integration: https://docs.rs/reqwest/0.9.18/reqwest/struct.ClientBuilder.html#method.use_rustls_tls
I should clarify: version 0.3.6 was just released a few minutes ago. It's focusing on getting some of the major bugs out of the way (ie. resize, positioning), and the full testing of the `HorizontalLayoutManager` that was being worked on for 0.3.5. Also, there's a system-wide event injection system, and a few other goodies. The example app has been updated, and I'll be putting in functionality to help with identifying whether or not `Widget`s provide injectable events, and so forth. I have a lot of more examples coming down the pipe; the current state is just to show that the resizing and repositioning hints work after a resize event. And the good news is, the app is still using less than 5% CPU!
To be fair, there are people out there using templates outside of web stacks.
### MP3 Progress on getting a rust crate for handling MP3 audio(decode in particular) has stalled for a while last I knew. It'd be awesome if anyone has time to get that working, my own use-case for it is Google Translate responses which are mp3 files that I need to concatenate(it's their way of getting audio playback response asap I guess), and from there any common audio format to save as a file would be fine, it's just the lack of mp3 support right now. Presently I use Electron with Web Audio API which can decode mp3 and concatenate the audio buffers, which I save as wav(easy to encode to). ### [Hilbert Space Filling Curve](https://en.wikipedia.org/wiki/Hilbert_curve) I was going to ask for this, but it seems there are some implementations already. I wanted to use it with octrees which at the time had crates but none that were particularly useful, I believe some talented rust dev has worked on a new octree crate since. ### AES decryption via GPU There's some CUDA implementations, if I get time for it I'll be doing it with ArrayFire(C++) and a rust wrapper library, but if you want to do a more native rust version that can use the GPU, there seems to be some capable crates for this. In particular I'm interested in AES CBC 256-bit with a string password. My use-case is for recovering my bitcoin private key, years ago I encrypted it and must have thought I was being clever/secure by using some obscure password I'd rarely use, didn't note it down out of paranoia, bitcoin crashed down to $100 or something for a coin, and didn't really make any large leaps until 2017, where I'd long forgotten it :P Chance of recovery is probably still unlikely but you never know :) ### [Redux](https://redux.js.org/) I haven't checked in a while, but last I knew this type of lib wasn't very feasible in Rust, there were some attempts but they weren't complete. I think some were related to needing features from the language to arrive like GATs for streaming iterators?(or maybe that was for a RX/Reactive port to Rust). ### Texture baking More of a project. I've been wanting to do this, and I keep seeing posts on here about ray tracing 3D scenes to 2D viewport images, but similar for transferring 3D data to 2D textures(UV maps). A common use case might be generating normal maps from high polygon input to low polygon mesh with UVs. I couldn't find a tonne of information(or suck at keywords) at how to approach this. I've got a variety of other things on my never ending todo/wish list, but there are plenty of existing projects that'd probably love some contributions too!
That's an interesting mix of rather specific(file size and format) and rather vague(process what? What particular result?). There's some great CSV crates already available, the other stuff is more likely regular logic you'd code yourself? --- Do you actually have a 25TB CSV file? Why would all the data be in a single file? What sort of storage is that even using if it's a single disk?
Rust and Ember with WebGL.... are you based in Auckland, NZ by any chance? **EDIT:** A quick stalk [says no you're not](https://monitzer.com/). There was a company using that mix here that I thought you might have been part of, [LightSpeed Graphics](https://lightspeedgraphics.co.nz/).
&gt; IMO bad practice is not a valid reason to just totally remove feature, goto is one example maybe. My two cents on this in particular: things being removed is pretty much exactly what Rust has above C++. The many things you _can't_ do in rust are what make it nice to use, because you know that the code you can write will run reliably and without failure. Footguns like goto, easy pointer access, copy semantics, etc. can be nice, but can also be deadly. With libraries, I kind of agree with you, but I think it also gets better with more experience. Sure, there are bad libraries, but the majority aren't, and after working with the type system a bit more looking over a random library's API docs becomes a fairly reliable way to see how much effort the author's put into the library. That might just be me using Rust for use cases where it has more mature libraries, though. Some areas of rust have definitely gotten more development than others. &gt; I used some google API services, then comes to things like hyper client is not "sync" (old version), to be "productive" I just skip these problems using the most stupid method: each thread just makes a new client and authenticate again). I noticed new version of hyper has some change, but google-api-xxx not updated yet. Outdated / unmaintaned libraries are annoying! It's interesting to me that library choice comes up again - `hyper` is generally a fairly low-level and verbose library (with details like it not having a sync interface). [`reqwest`](https://github.com/seanmonstar/reqwest) is much nicer, and has a sync interface built on top of `hyper`. I'm not sure what we can do better to point to libraries like `reqwest` over `hyper`, but I agree that some solution needs to happen. With openssl, I mean it could be considered insecure, but it's also standard for use on Linux. It's worth noting the maintainer of rust's `openssl` library is a member of the Rust ecosystem and net teams, but it's true he's still an individual. In all, thanks for writing this up!
&gt; I'm honestly unsure what significant benefit Rust has &gt; right now &gt; . Compile time benefits? With the borrow checker you may be able to avoid certain bugs that are easy to overlook and not be picked up by TypeScript or other tooling? I think it's useful for any processing or heavy logic. Less so for UI in the frontend. Sometimes you may want to do some processing client-side and if it's not simple/quick, then rust would be useful here as it outperforms JS by quite a fair bit. &gt; Because of the JS/WASM bridge problem What issue with the bridge? The overhead with it is really small now, there's an article that goes over how they improved that. Even if it were an issue though, you could still benefit in the same sense using GPU for compute helps, it's not always suitable, but when it is it can make a big difference.
If you just want to be able to signal threads then why not use a channel? You could send an enum down the channel and let the thread handle it how it wants.
Found your blog through this. There is some really useful write ups in there. Thank you
You could probably pull this off by hacking on [flamer](https://crates.io/crates/flamer), it already inserts code at the beginning and end of a function.
Why is it the only viable one?
 signal and action are different things, this is very difficult to illustrate without a concrete example, before continue I assume the method you suggest is something like [https://yourbasic.org/golang/stop-goroutine/](https://yourbasic.org/golang/stop-goroutine/) . after looking to the code u might notice that you have to use a loop to "detect" signal, this is not possible for most tasks with an indefinite running period. let's say we want to perform some math inside the task, it accepts some parameters then start running for some time, we better not bother this function to force it "select" on signals since it might just slow down computation badly (cache, branching). if it doesn't produce a result, we just give up on this thread and kick off a new one. with the method you suggested, it not only slows down the computation, but it might also just impossible since the "function" we want to perform is considered "atomic". using pthread or process is a different story.
you are right: I apologize for arousing your skepticism with hyperbolic enthusiasm. . . ;) But sure. Next time I'm curious what people think of a proposal, I'll be sure to try to come off meandering and uncertain, for fear that someone on the internet will be skeptical (Oh no!) and call me rude (Oh my!).
https://livefreeordichotomize.com/2019/06/04/using_awk_and_r_to_parse_25tb/
That depends on if you still consider PHP to be a template engine
I read the first 5 pages (don't have the time to read 377k+ results). All those examples are either man pages, homework/classwork, many copies of a book on linux programming, or many copies of a single openwrt patch. Do you have an example of when this would be useful?
Why not just run it in debug?
I'm building an x86 VM so it will require quite a bit of converting from a stream of bytes into u16 and u32 values (and s16 and s32 for good measure) I'm using try_into on a `&amp;[u8]` and from_le_bytes. This was the code I ended up on: fn u16_from_bytes(bytes: &amp;[u8]) -&gt; Result&lt;u16, DecodeError&gt;{ use std::convert::TryInto; let b: [u8; 2] = match bytes.try_into(){ Ok(res) =&gt; *res, Err(_) =&gt; return Err(DecodeError::MemoryError) }; Ok(u16::from_le_bytes(b)) } However, I discovered a bug in my implementation that seems wrong. I discovered that when the `bytes` parameter is greater than 2 bytes large it will throw the Err match. This seems counter intuitive, that a slice can't be converted to a smaller array of it's size, and only can be converted to an array of exact the same size. So, the fix I used was this: fn u16_from_bytes(bytes: &amp;[u8]) -&gt; Result&lt;u16, DecodeError&gt;{ use std::convert::TryInto; let b: [u8; 2] = match &amp;bytes[0..2].try_into(){ //change here Ok(res) =&gt; *res, Err(_) =&gt; return Err(DecodeError::MemoryError) }; Ok(u16::from_le_bytes(b)) } This however exposed a panic when bytes is a size less than 2 and completely skipped over the Err match. So, the solution appears to be: fn u16_from_bytes(bytes: &amp;[u8]) -&gt; Result&lt;u16, DecodeError&gt;{ use std::convert::TryInto; if(bytes.len() &lt; 2) { return DecodeError::MemoryError; } let b: [u8; 2] = match &amp;bytes[0..2].try_into(){ //change here Ok(res) =&gt; *res, Err(_) =&gt; return Err(DecodeError::MemoryError) }; Ok(u16::from_le_bytes(b)) } However, this change will mean the Err case will never be hit, but is required to satisfy the compiler. So why is it a requirement to be unwrapped? Am I missing something here?
hey, you might want r/playrust . good luck, dude!
You may want to post it to r/playrust
I imagine the issue is the same as in C++ with `std::map`, where using `operator[]` will either add entries for you if they are missing, which is not usually what you want, or crash if using the `const` version. Not great. In C++ you have the option to return a proxy object from `operator[]` that has a custom `operator=` and a custom `operator bool` to check for presence, but this has its own interesting problems. Without importing many of these problematic semantics from C++, it is difficult to see a way to implement this in Rust. You usually care about whether you are inserting or overwriting an element. I recommend using the `entry()` function in these cases. ``` let my_map = HashMap::new(); let my_value = my_map.entry("foo").or_insert(0); *my_value = 123; ```
What does debug have to do with this?
thanks for the insightful and bring up the wider picture of the ecosystem! for threading control, I am not familiar with rust's implementation, as I posted in another reply, there are just certain cases we can't avoid this feature, use signal or channel is not an option since it doesn't solve the problem. I am not sure if you are interested, but I do have such an example. &amp;#x200B; years back I helped one friend who worked on a certain scientific computing problem, after reading so many papers we decided to use a heuristic method to solve it, since we don't need an optimal solution(since nobody knows), we only need good enough solution. We divided search space into pieces, assign them a thread to try luck, it has many steps to produce a computation result, even its the same function we used on all task, depending on "luck", the task might return early, or run for a long time(don't ask me why it's algorithm from paper which we just followed), our optimization just used a thread pool to run them repeatedly, submit result when it seems to converge. there are so many optimation problems exist( e.g, place&amp;routing in IC design, synthesis) and require such searching, if a thread can not be stopped then we had to use low-level OS API, it's ok but, huh!
I mean not deploying it to production
Actually i was not sure of which to goat first, but with lots of answers and articles i have seen, i agreed that c is good for beginning
Well yeah C is easier to get into, but it doesn't enforce memory safety and doesn't force you to develop a "good habit", unlike Rust where it's the *law*.
That's a separate issue; you could just delete the code and recompile to avoid shipping an instrumented binary. The trickier problem is that instrumenting code to measure its speed alters its speed. Or, you're now measuring the runtime of different code than what you're deploying to production. It's not just that you're doing things you weren't before, there may be cascading effects because you'll alter which optimizations fire. This problem is why sampling profilers are so popular, they don't have this downside (though they do have others).
It does not accept this because of syntactic restrictions. On the left side of the arrow, there has to be a pattern. `… as u32` is an expression. Of course, this expression can be evaluated at compile-time (it's a const expression), so one might be tempted to extend the grammar of patterns to also include `as`-expressions. But why should we stop here and have `as` be a special expression? Why shouldn't we promote any const expression to patterns? Well, the grammar would become unwieldy if not ambiguous. So enough with that. You can actually work around this syntactic restrictions of not being able to include const expressions by naming the expressions: const A: u32 = Case::CaseA as _; match x { A =&gt; …, _ =&gt; panic!(), }
I found the same thing, I guess it has to blame GitHub ranking algorithm, it might be just like \`grep\` command.
https://github.com/rust-lang/docs.rs/issues/51#issuecomment-248353738
Great answer! So: x if x == Case::etc as bar does replace x with the u32-expression?
I'm having some lifetime problems, is there anyway to do this ([Playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=fce0af43c6f074d7a3bbdf0484e5b551)): impl&lt;'a&gt; FileResp { fn into_download_param(&amp;self, fp: &amp;FileParam&lt;'a&gt;) -&gt; DownloadParam&lt;'a&gt; { DownloadParam { code: &amp;fp.code, fid: &amp;self.msg.fid, request: &amp;self.msg.request, session: &amp;self.msg.session, } } }
[TryFrom](https://doc.rust-lang.org/std/convert/trait.TryFrom.html) is for conversions that are either Ok(lossless) or Err(lossy) like from i64 to i32. Since a try\_into from a slice of length 3 to an array of length 2, it hits the error case. The `[]`-indexing is dangerous as it might panic on index out of bounds. If you don't control the length of the slice (your case), you should definitely prefer `.get` which returns an Option. So it's: let b: [u8; 2] = match bytes.get(0..2).ok_or(DecodeError::MemoryError)?.try_into().unwrap();
So you don't have any examples? :(
https://github.com/djc/template-benchmarks-rs Yarte is a compiled template engine though so it will be much faster/safer than interpreted ones, at the cost of increased compilation time.
This is basically the [flamer](https://crates.io/crates/flamer) approach, as /u/Saefroch noted. Do know that it adds some overhead which depending on your use case may invalidate the results. That said, such a measurement can augment a profiling regime based on sampling profilers (such as perf) and inform benchmark intuitions.
Unfortunately no, the expression on the right hand side of the `if` is evaluated at runtime i.e. `x if { println!("foo"); false } =&gt;` is legal. You might not care about that fact but it could be the case that the compiler can only optimize the version with the constants (the example I gave in my previous comment) to a jump table.
Interesting, have not seen ok_or() before. Will definitely clean up the code some to use that. The last version I think has the same logic, but this looks a lot cleaner
I wrote something in C# that looks scarily similar to this heh, and the performance difference between static and dynamic was actually perceptible in terms of requests-per-second. The real benefit with this though is type safety and compile-time errors. Extra performance is just a nice side-effect.
I got it, you can add lifetime parameters to the &amp;self parameter, like so: &amp;'a self!
I guess pthread\_kill is not good example since the POSIX defined its "weird" behavior : &gt; Signal dispositions are process-wide: if a signal handler is installed, the handler will be invoked in the thread *thread*, but if the disposition of the signal is "stop", "continue", or "terminate", **this action will affect the whole process.** I am convinced by [ssokolow](https://www.reddit.com/user/ssokolow/) and agree on not implement this on a language perspective if it relies on different OS level implement(which doesn't agree on each other)
I get it now, you are right!
You probably don't want to measure the performance of debug builds.
What does the `x if` do, then? That's highly confusing syntax. What do I need the x on the left side of the `if`, when it's the right side term which gets evaluated?
Wasnt yarte the crate with the license controversity.
How is it different from https://github.com/kpcyrd/sniffglue ?
&gt; hyperbolic enthusiasm One of the issues the Rust community has in the wider world of IT is the consequence of such hyperbolic enthusiasm.
I don't actually see Yarte mentioned anywhere in the results. Is it under a different name?
Yup, the author forked Askama and “didn’t have time” to add a credit per the original’s license.
This subreddit is for the rust programming language, your post sounds like it is for the game which is over at r/playrust
Yarte was(is?) A fork of askama
I will!
Yes, it's pretty great! The big advantage of this compile time safety is that it allows optimizations that would be too dangerous in other languages, such as pervasively using references to existing allocations instead of creating copies.
I think there might be some unique cases involving implementing for generic containers where Into must be used. Also the Into trait allows you to use `.into()` :)
Glad you find it interesting! I absolutely agree with your points about Rust. It allows all the low-level programming that C does while still feeling like a higher-level language.
Your confusion is justified, you just witnessed an obscure feature of patterns. You probably know that normally `x` in `match 5 { 0 =&gt; 1, x =&gt; x - 1 }` matches anything and names it. That is not always the case. Suppose we also define a constant: `#[allow(non_upper_case_globals)] const x: i32 = 1; match 5 { 0 =&gt; 1, x =&gt; x - 1 }`. The compiler is going to reject this code because now, `x` does not match anything but only `1`, so the match became non-exhaustive. It's as if we've directly written `1` instead of `x`. Depending on the context, `x` means different things. If there exists an enum variant or a constant in scope, it's gonna use it for the match. The syntax of guards in patterns is `&lt;pat&gt; if &lt;expr&gt;`. Examples are `x if x &gt; 0` or `Some(x) if x &gt; 0`. As said before, there might be or might not be a difference between `Some(0)` and `Some(x) if x == 0` depending on optimizations. `x if p(a)` means "match anything and at runtime also check `p(a)`. (Fyi to strengthen your intuition: The compiler cannot check for overlapping patterns if you use `if`: `{ 0 =&gt; {}, 0 =&gt; {}, _ =&gt; {} }` emits a warning, `{ x if x == 0 =&gt; {}, x if x == 0 =&gt; {}, _ =&gt; {} }` does not.)
It's not updated in the README but the code is there (although 0.2)
From what i see, in one way sniffglue is more powerful with sandboxing and all. But Snoopy allows some configurations while capturing packets, I'm not sure if sniffglue supports that.
also stain https://github.com/cztomsik/stain
Inserting! Along with PyOxidizer, this seems to be part of a trend to reimplement and integrate dynamic languages with Rust. I hope it catches on!
Yeah, no, I'm working on [DungeonFog](https://www.dungeonfog.com).
My understanding: - `IndexMut` is blocked on `IndexSet` - `IndexSet` is blocked on placement new (roughly, according to https://github.com/rust-lang/rfcs/pull/1129#issuecomment-162036985) - the last placement new implementation and design was removed due to outstanding issues (https://github.com/rust-lang/rust/issues/27779#issuecomment-378416911) - there has not been any significant progress made on a new placement new design since the last one ended
[https://github.com/NyxCode/word-cloud-generator/blob/c678c7a8349bf0468dfa8d3a340e2e7d0c6de4b7/generator/src/main.rs#L98](https://github.com/NyxCode/word-cloud-generator/blob/c678c7a8349bf0468dfa8d3a340e2e7d0c6de4b7/generator/src/main.rs#L98) Thats what I hacked together in a few minutes. You can then use it by putting \`let \_log = log\_time("..");\` at the top of your function.
Yes, and they still have not credited the original author. This crate is still in violation of Askama's license.
CLS compliance was useful in the .NET 1.x days for compatibility between C# and VB.NET. However, it stopped being relevant when VB added support for unsigned integers. Basically, CLS is a minimum for compilers: every .NET language must have at least these features. Thus, a library that only uses CLS features in the public API is usable from every .NET language. However, in practice, all .NET languages in real use support more than just the CLS; so there's little reason to write libraries with these unnecessary restrictions.
I find that the `Entry` API is a very pleasing solution to the problem, at least for now.
See also https://github.com/AlexEne/rust_hawktracer
TSV, not CSV(not that it matters) &gt; my advisor split and gzipped these files into five batches each composed of roughly 240 four gigabyte files. As I thought, not a single 25TB file. I don't have the time to read through the authors experience, but glancing through it they had a large amount of column based data and needed to process/prepare it for querying efficiently, all of which would be niche in the sense that it's tailored to something very specific rather than more suitable as a lib. You could parse the data with [xsv](https://crates.io/crates/xsv), I just spent a bunch of time looking for oars post that I recalled seeing in the past month, because I had mistaken orthogonal arrays as associative arrays(which are just hashmaps/dictionaries, my bad). So it's not really clear what you're asking for here(assuming it's not a joke). I've written code to deal with hundreds of GB(but it should work with TB too, just take longer) of binary 3D data. The issue we had was our server only had 128GB of RAM and each 10GB of data when baking texture data would use up to 80GB of RAM. Thankfully it just required splitting the file by reading it in and rewriting smaller chunks of the 3D data out. It then has some extra work as post-processing to stitch the results back together(200 8k texture maps). The 3D data wasn't spatially sorted, which would have improved speed and reduced post-processing further. Is this something you actually have a need of?(you don't appear to be the author) Or just thought was a fun project?
Why undertake a huge reimplementation and embed Ruby in Rust when you could go the other way around and call Rust functions from Ruby via FFI? That's how speeding up Ruby and Python worked for decades, except they were calling into C and not Rust. This lets you use the original VM completely unmodified, so there are no compatibility issues. What are the benefits of your approach?
Good point. See my edit. Thanks for responding!
it would be impressive and show up on hacker news.
What are you wanting to show off with Rust though? That it can read 25TB of data, and do something, like "sort by gender, output in files by birth year and month"? That sort of thing doesn't really matter how much data it is going in, unless you're comparing time to do that vs some other language, but we already know Rust is good for that. With my project, my naive implementation crashed because I think even 40GB of binary data was too much to read in and transform before saving to disk. Instead I wrote a streaming parser that would process a fixed/max amount such as 500MB at a time, writing that out to a file until the file reached it's max limit, and creating a new file/chunk. I don't know if you can really say it'd be impressive though. That blogpost was about figuring out how to pre-process the data(the hard part, not so much the actual code), and then how to store and query it in the cloud. I guess if you did the entire thing in rust and it was measurably better you could rave about it?
That makes no sense.
I need to update the README some time. Will try to see if I can do it tonight.
*Disclaimer: please excuse my naivete, I only understand the basics of licensing.* I see two references to Askama in the code (https://github.com/botika/yarte/search?q=askama&amp;unscoped_q=askama), on top of a mention in the README that Yarte is influenced by many predecessors and that references can be bound in the code. This would seem sufficient to me (naively), so if you could point me to how to do it appropriately I would appreciate.
If you are just looking for an algorithm, take a look at the [Sieve of Eratosthenes](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes). [Here](https://gist.github.com/Taneb/e6b50a200094db4e31cc) you can find a simple implementation (without bigints though).
check mrustc on github
I see that [Debian 10](https://www.reddit.com/r/programming/comments/ca1uss/debian_10_buster_released/) was released; however not a word is given about Rust. Would you mind telling us whether ripgrep and co made it into the final release in time?
Creating a language that is as complex and feature complete as Rust does take a lot of work. But it depends on your goals. Most languages don't "make it" like Rust, it's a combination of a my things, including luck. If your goal is to make something production-ready as a Rust then you have years of work ahead of you. That's not necessarily a bad thing though if you are committed. If you're more in it for the learning or fun aspect, then I wouldn't worry about how much work might be involved to make it feature-complete. Just start creating! What's your unique spin, if you don't mind my asking? What would you do differently than Rust?
Making your own native compiling language? Hard. &amp;#x200B; You could quite easily make a JVM language though.
But those bytes are only passed from the terminal to the shell's stdin when the user presses a new line.
I don't know about Rust's compiler specifically, but basic parsing, typechecking and compiling/interpreting steps of a language are usually simple enough that a single person can do it. It depends how complicated the language initially is. Most languages started as the brainchild of one or two people. Most work isn't actually in the core language itself, but in documentation, FFI/extensions, syntax highlighting, build system, language server/IDE integration, refactoring, package management, website, backwards compatibility, standard library, community engagement etc.
Have you tried the my_internet_ip crate? I haven't looked at it deeply but it might be what you're after. https://crates.io/crates/my_internet_ip
I don't think that algorithm is applicable here. Wouldn't you need about 2^256 bits of storage? And it would also take way too long. If the goal is to generate just one 256 bit prime (or a small number of them), then it would make more sense to generate random 256 bit numbers and testing whether they are prime. The probability of a random 256 bit number being prime is about half a percent, so you wouldn't need to try too many random numbers.
I'm pretty content with Rust so it's mostly just for one aspect of usage that I don't think I can articulate well enough. Basically, I would like more "control" over something that is as integral to my life as the programming language that I use. Not having that control over the programming languages that I use has been disempowering to me. I intend to change that feeling. Of course, I would like to come up with my own syntax for doing things. I would like to push the edge of what type systems can do and what I'm currently learning in type theory. I would like very ergonomic contracts built in. I also feel that building my own language from the bottom up would allow me to "know" the language better, leading to productivity gains. I can create a parser generator for the language and immediately have the capability to handle any file format or network protocol that I wish and need to rely too heavily on community libraries.
This has been my experience with the little toy interpreted scripting languages I have made so far. Front end stuff is easy and straight forward once you've done it a few times. I feel like I can leverage LLVM to create a fast as C language with memory safety in the same vain as Rust. Without worrying about needing an ecosystem of libraries, editors/IDE support, FFI and package management, etc. Would just like a powerful type system, memory safety, and contracts. Are my goals realistic?
I think making a simple compiler of some sort would be *doable*, but it would be very very hard to make it as usable as one with as many people working on it as Rust. And you wouldn't have community libraries to use.
To generate primes you generate random numbers of desired length and then test them for primality using e.g. the [Miller-Rabin](https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test) test. It may look daunting but it's actually pretty easy to implement!
I don't know how complicated a borrow checking algorithm is, "powerful type system" is a bit nebulous, and which "major platforms" are you referring to? Linux, Windows, Mac OS? iOS and Android? By "contracts" do you just mean pre and post conditions checked at runtime?
Well that's what I would like to have clarified. When you say "usable", how do you define that? What features specifically come to mind? For me, usable would just mean a base language the capability to provide structural programming, basic oop and procedures. Maybe a module system. Type system up to having things like generics. And I would like to have Rust's burrow and lifetime system. Minus all the rest, would you say this is reasonable to attempt myself?
A type system as feature complete as Rust's type system. I know that's still actually kind of vague. Mostly because I haven't drafted a design of what exactly I do want with a type system. I do want generics and traits and dynamic dispatch and the type system would have to work with those features. Linux, Windows and OSX. To start. Post, pre and invariants. Contracts implemented in the same way as the Eiffel language.
This crate (https://github.com/PSeitz/rust_measure_time) depends on drop behaviour to determine the end of a scope. Though that cuts some features: it should be possible to the return value (like dbg!) and location (like panic!) but I don't see a way to capture the arguments. On the other hand you gain some features: measuring when arguments are not Debug and measuring scopes and parts of a method.
I'm not sure about specific language features; a *lot* of the nice stuff is tooling, documentation, etc.
Sieve might not be a good choice for 256 bit numbers, as table won't ever fit into memory. Other possible approach is to generate large odd number, and then use some primality test (for example [Miller-Rabin](https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test)). If number happens to fail the test, you can increase it by 2 and repeat. Also take a look at [glass\_pumpkin crate](https://crates.io/crates/glass_pumpkin).
Also check out /r/programminglanguages, we love talking about this kind of stuff over there!
Is it speedy though? I started developing a gtk3-rs app on Mac but the performance of basic things like the File Open dialog was terrible. Qt is much much better, and I think even Electron apps are more responsive. I'm going to use Flutter instead (I don't need a lot of features yet).
My guess is you could have something working within a year, but estimating programmer work is hard and I'm not a compiler engineer. Either way you'll get a clearer picture of the amount of work overall as you start doing it.
I would suggest starting with something more Haskell-like as a start (System F-ish, but call-by-value). This should go fairly quickly. Also, Rust is not the idea environment for prototyping a language implementation.
Optimization on this: Instead of testing every odd number, only test numbers of the form 6*k*±1, since all prime numbers above 3 are of this form. If you start with 6*k*\-1, you can add two, then add four, then add two again, and so on, to generate the sequence of possible primes. This reduces the test space (and the time it takes to find the first prime) by a third.
The author of Askama asked for explicit credit on the GitHub repo for this project. The project then deleted said repo with that Issue and moved to GitLab. I’m not saying that the two are related, but it is convenient for getting rid of the request without addressing it.
&gt; Acknowledgment Yarte is based on all previous templates engines Interesting, given that this is a direct fork of the excellent (and also very fast) Askama framework. Curious that there isn’t an acknowledgement of this fact in the README.
&gt; The probability of a random 256 bit number being prime is about half a percent, so you wouldn't need to try too many random numbers. I was really skeptical about this (intuitively, it just seemed way too high). But, much to my surprise, you're right. And, if anyone else is curious, here is a rough approximation: (2^257/ln(2^257) - 2^256/ln(2^256))/(2^257-2^256) It only uses the fact that x/ln(x) --&gt; pi(x), where pi(x) is the number of prime numbers &lt;= x.
No language starts with 2409 contributors. Rust was Graydon Hoare's personal project at first, and it grew from there. Start small!
Why not?
Normally mDNS serves this use case. Is it really not an option?
You should probably just use GTK (either through Relm or directly) and configure DPI scaling as needed.
If you mostly care about the frontend, then using a language with a GC will allow you to rely on the host language's runtime and so you can focus your time better. Rust is probably also not the most ideal language for rapid prototyping right now.
I am well aware of the drama, thank you; however this does not address my question. Naively, I would think that the repository is now complying with the request, since it explicitly mentions Askama among its source of inspiration. What I do not know is whether doing so is sufficient, or if further effort is needed. This is knowledge that would be useful for (1) ensure that I pick compliant crates as my dependencies and (2) ensure that should I ever create a derivative project, it is compliant too.
Use the Miller-Rabin primality test. Do not use the Sieve tests. Miller Rabin is probabilistic test, but can be repeated enough times to give almost certain prime numbers, and it works very quickly. A 256 bit prime number should take less than a second to generate. It takes my computer around a second or two to generate 2000 bit prime numbers.
AFAIK mrustc specifically punts on borrow-checking; leaving it to rustc to validate the code before it is compiled to mrustc.
I'm writing Rust as part of a full time job at [NLNet Foundation](https://nlnet.nl). Our internal grant approval system is built with actix.
How do you "encode" a 2000 bit long number in rust. Can you point me into the right direction. what data types are you using?
Actually, I think you are in luck. You see, part of the current work in rustc is to split it in multiple independent *and reusable* libraries. There are already multiple libraries that are evolving out of tree, with plans for them to replace parts of rustc: - [Chalk](https://github.com/rust-lang/chalk), the trait-solver. - [Polonius](https://github.com/rust-lang/polonius), the borrow-checker, is built on top of [datafrog](https://github.com/rust-lang/datafrog), a lightweight Datalog engine. - [MIRI](https://github.com/rust-lang/miri), the Middle IR Interpreter. Since those are released as crates of their own, you can integrate them within your own compiler as long as its license is compatible. It will still be quite a lot of work, but by building on existing libraries, you should be able to achieve quite a lot by yourself.
Creating a feature-rich language on its own isn't impossible, several widely used languages were invented and, to my knowledge, implemented by one or few persons before they got support. Examples I can come with are: Perl, Python, Ruby, C. Lexing and parsing is essencially a nonproblem, existing tools automate this part into non-entity. A lot of work on type systems was done, so there is a lot of well established lore and textbooks there. Linear type system are also well established, so memory safety should be simple. Optimization is optional and can be delayed to next stage. Compilation to x86 asm isn't all that well studied, so most likely you are stuck with either compilation via something or integrating with one of suitable open-source compiler building tools (gcc, llvm, Open64) &amp;#x200B; What is problematic is making batteries and subsequent promotion. This, I think, isn't doable by one person except maybe specific niche solutions.
IMHO there is a very large difference between being inspired by someones code and forking someones code and building upon it. My understanding is that it is because of this difference that simply saying that it was inspired by Askama isn't enough.
You can try to estimate the difference of run times between various builds to compensate for the approach.
I'm not a lawyer. However there is no mention in the README of the base project, and [this answer](https://softwareengineering.stackexchange.com/a/277699/145081) seems to suggest that adding a blanket copyright notice over forked code is iffy. Regardless, the author's indifferent attitude towards licensing and credit in general pretty much rules it out as an option for myself.
It doesn’t even say that. It says that it’s inspired by *all* templating frameworks (how enlightened), and mentions the base framework in two comments in `src/generator/mod.rs`. The phrasing in those comments strongly implies that these are the only two derivative sections of the code, which is far from accurate.
I used the BigUInt data type that you mention in your post. For entering a number, this depends on your application, I had the number entered as a command line argument and converted it from a string to a BigUInt.
mDNS is a wonderful solution for this type of thing. I used it on a small offline developer network a few years back.
A conrod app seems like a good choice: https://github.com/pistondevelopers/conrod But adjusting the network seems easiest really. It's very likely whatever router is being used allows setting fixed IPs for devices.
I agree, that seems wrong. I hope that your pull-request is accepted, as it seems to solve the issue.
ok
No such luck: https://github.com/botika/yarte/pull/1#issuecomment-509005358
You can also use tokio-trace for this
PlatformIO uses its own build system, with basically only GCC-compatible languages. Additionally, the toolchains it installs are C/C++/asm only, and the same for libraries. Rust crates would replace all 3 of those features, leaving just an uploader necessary. You might be able to compile your Rust project as a statically-linked binary, and then link it with PlatformIO.
Seems like you could generalise this: Take the first N primes and multiply them together to give A. Next, pick a random C which is coprime with (and less than) A. The expression `Ak + C` is then prime with probability that increases with N. Since lower prime factors are much more likely and N can be picked ahead of time, you could greatly improve the chances of picking a large prime number.
If you can't be bothered to implement these algorithms by yourself, there's rust bindings to openssl which can generate prime numbers of arbitrary length: [https://docs.rs/openssl/0.10.23/openssl/bn/struct.BigNum.html#method.generate\_prime](https://docs.rs/openssl/0.10.23/openssl/bn/struct.BigNum.html#method.generate_prime)
I have a forest data structure (collection of tree graphs; I guess the trees are all rose trees as each node can have any number of children and there's no guarantee of balance) which is serialised in our database as a table where each row represents a node in a tree, and refers to its parent node's ID (or NULL if it's a root). We need to use those table indices for operations on the tree. Some graph crates allow you to store data on the nodes, so looking up the table index once you have the node index is easy, but looking up the node index if you have the table index is hard, because any mutation to the tree (which we do quite a lot) can change a bunch of the node indices (because they tend to be vec or linkedlist-backed), so you can't just keep a mapping unless you re-create it fairly frequently. &amp;#x200B; Am I missing some alternative crate or way of implementing this?
Honestly QtQuick or Flutter are probably the best options for that sort of GUI. The Rust GUI story is still pretty bad (yes I know about Relm, Gtk3-rs, Conrod, Limn, etc.). But as others have said, mDNS eliminates the problem.
found that already, also found this article. will try this. it uses the miller alghorithm too https://medium.com/snips-ai/prime-number-generation-2a02f28508ff
I think you want to go to https://www.reddit.com/r/playrust/
Or regular DNS with [pihole](https://pi-hole.net/).
Yeah, this Rust programming language. 😀
Yes, ripgrep, fd-find and exa all shipped!
Great! Thank you very much :)
Yes, it works much better now. I'm wondering why you didn't use f64 in the first place? The difference in performance is probably insignificant.
I'm not sure about this scheme but if the prime is supposed to be used in a cryptographical context, any structure in the primes you choose may make them vulnerable to attacks. What /u/my_two_pence suggest is of course okay - after all every prime is of that form.
If you downvote I would appreciate if you comment what it is in my post that you did not like.
Really hope someone picks up [allowing it to work on borrowed keys](https://github.com/rust-lang/rfcs/pull/1769) again. I hate having to allocate just to perform a lookup.
I wasn't aware of mDNS, and that sounds pretty cool. Unless I'm misunderstanding it though, wouldn't that require the computer looking for the Pis to be running mDNS software? My goal is to not need to install anything custom on the client. For example, I have 3 Pis plugged into a router (which I can't configure to host a DNS server), then a laptop connected to the same LAN. The 3 Pis' HDMI outputs are plugged into a video switcher. The laptop expects to connect to the webserver hosted on one of the Pis, but doesn't know the IP. The laptop would then be the mDNS client, so I would need the laptop to have software installed to perform the multicast query?
That's not out of the question, but I'd prefer to not add additional hardware beyond the Pis that are doing video playout.
I couldn't find a lot of info on DPI scaling beyond simply supporting HiDPI monitors. I guess I could use GTK to render an SVG, and let a GTK container scale the SVG?
My favorite Atom plugin is Visual Studio Code 😂
Any Linux in the past 10 years runs mDNS out of the box. I haven't dealt with Windows in the past 10 years so cannot comment.
Well look, crunching data is a big deal now. If you show Rust is x300 faster and cheaper than Python-on-Spark, then its pretty impressive. Dont forget, is you add AWS into the mix, it all costs money in the end. In the original article, running a single query on 20Tb costs around $20.
What do you need the prime number for? If cryptographic, are there any additional properties that must hold? Is performance a concern? If so you'll want to use prime numbers with relatively few ones bits to speed up the operations. \`2\^a (- 2\^b)\* - c\` is a common form where you want as few \`b\`s as possible. I.e. curve25519 uses \`2\^255-19\` (255-bit). Goldilocks-448 uses \`2\^448 - 2\^224 - 1\` (448-bit).
Your end goal is to have your window be as big as possible on any screen, right?
How does `u64` work on 32-bit devices?
You'll have to build a lot of custom widgets for this, no matter what framework you use. You might want to look into just using Conrod or Webrender directly at this point, really.
Most ops can be done with register pairs, and for things like multiplication/division there are more complex methods (e.g. karatsuba multiplication).
Those are mockups. I don't think you will find anything capable of producing such graphics without considerable work on your part.
&gt; If you show Rust is x300 faster and cheaper than Python-on-Spark, then its pretty impressive. Yes that would be, but that sounds awfully ambitious. &gt; In the original article, running a single query on 20Tb costs around $20. That was the initial approach: &gt; * When I started, using spark took 8 min &amp; cost $20 to query a SNP* &gt; *It now takes less than a 10th of a second and costs $0.00001.* I don't really see Rust outperforming that outcome by 300x, and that's already pretty cheap sounding. What we do know is compressed that 25TB of data is not even 1TB. And that was via gzip, so they might have been able to get more wins with say zstd. It might have been possible to get that working on a local system instead, but then it was placed into a database iirc, and I don't know what the overheads of that involved.
I see. Well separate from the embedded approach, do you have any suggested compilations of Atom packages to use outside of PlatformIO?
I am a big user of IntelliJ only, so I don't know much about Atom. I do know that more effort has been put into VS Code, though, in general.
On the JVM, using Graal + Truffle for language implementations looks super interesting.
&gt; implement the burrowing So does this mean it would be an... underground language?
I've used `ureq` with good results in a crate I contributed to a while ago. https://github.com/algesten/ureq. It's not super popular but it is concise and quick to compile.
Agreed on the linux part. Unfortunately the client laptops will be Windows or Mac, and often out of my control.
I know very little about Scala. Why does it fail to scale? Is it slower than other JVM languages, or do you find the JVM unscalable to begin with? Just curious.
If you can't convince your router to assign static addresses via DHCP, but you still want your Pis to use DHCP-assigned IPs for some reason, then [LLMNR](https://en.wikipedia.org/wiki/Link-Local_Multicast_Name_Resolution) should be able to do hostname resolution. That should work out of the box on most linux- or windows clients. If that still doesn't work, and you're determined to stick to your workaround, I wouldn't overcomplicate it. xterm -geometry 1920x1080+0+0 -e /bin/bash -c 'while [ 1 ] ; do clear ; ip addr ; sleep 1m ; done' Feel free to dig around in xterm's man page for larger font sizes, or in ANSI shell codes for formatting and colors. As for your rust exercise, font rendering is surprisingly complicated. If you want GPU-accelerated font rendering, it just gets worse. The "simple" solution is to use something like rusttype for CPU-based font rendering, then get the framebuffer into a window with winit or minifb.
Yes, but my understanding is that DPI settings are per monitor hardware, not really something you'd scale due to configured resolution traditionally.
&gt; I think even Electron apps are more responsive. This may be a MacOS specific thing, because that's _definitely_ untrue in my experience.