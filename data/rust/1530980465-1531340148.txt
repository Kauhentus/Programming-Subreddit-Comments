Thank you. I was mightily confused.
One would have to write language bindings for all of those. While possible in practice, I would rather take serde-json (or some other Rust JSON crate) directly and wrap it up in a language-specific package. hyperjson is tightly bound to Python as it uses pyo3 to generate Python objects. That said, if you want to try the same in any other language, there are a few nice Rust bindings around: * [Neon](https://github.com/neon-bindings/neon) for node.js. * [Helix](https://github.com/tildeio/helix) for Ruby * many many more on [awesome-rust](https://github.com/rust-unofficial/awesome-rust#ffi)
On Linux at least, compilers these days following the [Itanium C++ ABI specification for name mangling](http://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangling). I think MSVC has a proprietary and undocumented name mangling scheme, though there's [a description here](https://en.wikiversity.org/wiki/Visual_C%2B%2B_name_mangling).
Thanks a lot for taking a look! Interesting I had read about Copy types, but this does definitely make it more clear what that means. I didn't bother with compiling in --release mode because the code easily runs fast enough (at least for the small worlds I built so far). Definitely something to keep in mind for my other projects though. Thank you!
last I heard, it was in maintenance mode and not being actively developed, though now the blog post indicates that new maintainers are being onboarded. https://www.reddit.com/r/rust/comments/8ni53t/the_state_of_gotham/
/u/bradley_hardy is spot-on, that's exactly why I included "on its own." The point is that monads aren't something people should *have* to learn about or understand *in the context of a calling convention paper.* It's simply unnecessary complication- talk about monads when they make things simpler, not "just because."
Because that's how the new lightweight "throwing values" C++ proposal works. Old-style C++ exceptions, which tend to use unwinding, are closer to panics; new-style C++ exceptions, which are specified to use this `_Expected` calling convention, are closer to `Result`. Rust and C++ have different idioms. Interoperability shouldn't mean forcing those idioms across the boundary. Imagine the inverse of what you're asking- would you want a lightweight C++ exception (already implemented like `Result`) to translate into a panic when entering Rust? Certainly not!
The main problem, as I mentioned upthread, is that giving `_Either` a memory layout in addition to a function-return ABI over-constrains things. If `_Either` is a full type on the C side, and `Result` is a full type on the Rust side, we have two options: * Make their memory layouts compatible (and presumably their function-argument ABI). This would be unfortunate, as it would limit our options for further memory layout optimizations, and probably lead to a separate `#[repr(C)] enum c_result` type like in the paper. * Make only their function-return ABIs compatible. This would be unfortunate for obvious reasons- confusion and hard-to-explain rules. Further, I would ask what is the advantage of making `_Either` a full type? Using it in other contexts in C doesn't really give you much, because without function polymorphism it can't really become a "vocabulary type." Its syntax isn't really any nicer or less error-prone (at least on the use side) than a tagged union.
&gt; Those inline assembly macros are basically optimization barriers I got the impression that those were for demonstration purposes only- they don't even work in the general case of multiple `_Expected` automatic-storage variables, because they just clobber the carry flag. A real implementation wouldn't use inline assembly at all. &gt; The proposed ABI would not allow these optimizations when doing C FFI, the paper should explore this. The paper does at least touch on it lightly, proposing that *all* functions should clear the carry flag even if they don't return `_Expected`. The rationale IIRC is optimization of callers, which can do more folding of carry flag operations? Also, `_Expected(T, void)` is not obviously the same as `Result&lt;T, !&gt;`- you can't construct an object of type `void`, but you *can* return `void`, making it equivalent to Rust `()`. In that case you would still need the discriminant. But I agree, it would be worth exploring the optimization potential for non-`_Expected`-returning functions. Maybe if the carry flag can be assumed to be clear on function entry as well as return, the two approaches would be closer?
In your opinion, what would extern C++ do then?
It's a joke referring to the original meaning of the _trans-_ (across) and _cis-_ (on the same side) prefixes. That way, if you go from GLSL to GLSL it's a _cis-_ piler instead of a _trans-_ piler.
Regarding SIMD algorithm with branches, I think [Sierra](http://sierra-lang.github.io/) is the right approach. One writes code with if, while, etc. and Sierra transforms code to SIMD mask management. Then scalar case can use untransformed code.
Thanks!
I was thinking of the `conduit` Haskell library (when I first saw this headline on HN). Blindly upvoted there, not realizing it's some fancy cloud thing instead :D
Just wondering; in what situations would this be desirable? 
You could write in `Cargo.toml` [profile.release] debug = true I suppose there is detailed description about it somewhere in cargo documentation 
That sounds useful, thank you!
I can think of two uses: 1. Quick access: Extract just a few pieces of information from a large document. 2. Statistics: Index a document once, then explore its content without ever holding the whole (decoded) document in memory.
Amazing, thanks so much for sharing! I'm about to start building C bindings for [hypercore](https://github.com/datrs/hypercore), and I'm sure this will come on useful! ✨
That doesn't require it to be non-parallel, right? Although for **very** small documents parallelism clould cause some overhead. But the library itself would be able to mitigate that at runtime. 
I feel that calling statistical functions outside of Rust might be the best option as of right now until the necessary libraries are built. It would allow you to start rewriting things slowly in Rust and have something that works. Then once the necessary libraries are written you can sub out your FFI calls with pure Rust calls. Another option, since the OP is using python, is to use [rust-numpy](https://github.com/rust-numpy/rust-numpy) and rewrite certain functions in Rust and still be able to use your python scripts until the scientific computing libraries for Rust mature.
Awesome. How different is this book from the official free first/second edition books online in Rusts documentation? 
"Rust leadership" is an ill defined term. We're an open project, so many people chime in even if they are not officially in a working group. Those people do that through internals.rust-lang.org. If you circulated a draft with a couple of people, that's great and fine, but if you want project review, please post it to internals. Especially because there are people that don't hang around Reddit.
So not as much a Rust question as a VS Code RLS question but figured I'd ask here. I have the following: src/main.rs extern crate crisp; fn main() { crisp::parse(); } src/lib.rs pub fn parse() -&gt; String { ... } But RLS flags my "crisp::parse()" call, saying "cannot find function `parse` in module `crisp`". I set up my directory with "cargo new --bin crisp" and created the lib.rs file manually. Haven't found anything helpful online.
Thank you for what you do here!
I thought nalgebra was more geared towards elementary linear algebra, such as that used in games.
Oh sorry; I thought you had answered to another comment :( For optimum efficiency of an application, scheduling has to be coordinated at the application level, taking into account the various urgency/priority of each concurrent task. For example, imagine that a running application receives periodic updates of its configuration via a REST API, JSON-encoded. Do you really want to pause all cores to run a parallel JSON-decoding task rather than having them work on the *actual* application work? If it took a few dozens/hundreds of milliseconds to prepare the update anyway, does it matter if it takes a few more milliseconds to process it? As another example, consider a parallel REST service. You send a JSON request, get a JSON reply. If one client sends a massive request, or requires a massive response, do you really want to stop processing of other clients because the library you use is aggressively using all cores? I've actually seen a few disasters, using the Oracle database, when queries were sent with parallel clauses, hogging all the CPUs and starving other clients. It's uncomfortably close to a self-inflicted DOS attack. So, personally, I refuse to use a library which automatically parallelize things outside of my control. I'll decide whether to parallelize or not, and how much cores I'm willing to dedicate to the thing.
Yep, which is mainly done with 2d and 3d matrices.
Yes. That is correct. I'm sorry, but for optimum efficiency you shouldn't use Python as a programming language. I believe changes like this are extremely mininal when comparing it to the overhead of abstractions in Python itself. If having great performance is important, use something like Rust directly. Don't get me wrong though, yes you're correct that having the ability to change such properties can have a great effect in performance, for some things at least. But, if JSON documents get so large that parsing them is becoming troublesome, the actual problem might be something else. Concurrency is hard though. There are many different ways of implementing it each having **very** different characters with regard to latency, overhead and so on. Also, it's your OSs job to properly schedule concurrent tasks over theads. When talking about datases; I think the problem you've experienced wasn't because of the database saturating all CPU cores causing other programs to have problems. I'd rather believe this would have been caused by a locking issue, getting other programs/tasks stuck that depend on the database. But of course, I'm not sure.
Precisely. So it's fair to assume that scientific computation libraries ought to be built on top of ndarray instead
I agree with this wholeheartedly. As an actix user, I'm pleased, but this feels like a Pyrrhic victory. Most of the `unsafe` code has yet to be written. I hope that, when we encounter UB again in a popular crate, we can avoid rhetoric around UB like "It might do what you expect, it might segfault, it might kill your neighbor's cat". We can make our technical points without the last bit of snarky moralizing.
That thread made me deeply uncomfortable. Not so much single responses, but the general atmosphere... Imo, the good outcome we see right now is despite, and not because of the tone in the original thread. 
Is _Expected just a derivative of std::variant then or is there some semantic difference I'm missing?
It's... basically the same thing, but in practice not really. `std::variant` is a C++-only template-based type, that distinguishes its variants based on type rather than a tag. `_Expected` is a C "metatype," not usable in data structures, purely for use in function return positions for ABI reasons, which can only have two variants and which distinguishes them based on a tag rather than on type. And because `_Expected` is designed as the ABI for the new-style C++ exceptions I mentioned (which, again, work far more like `Result` than `panic!`, despite syntactically looking like exceptions), those new-style exceptions are what it translates to in C++.
Ah, so _Expected is basically a tagged union rvalue limited only to function returns. Do you have a definition of a "C Metatype", my searching on google hasn't led me to any answers and I am curious what exactly the implementation is, be it standard code or compiler intrinsic. 
I the use of of unsafe and the resulting _refactoring_ shows how powerful unsafe is, both as a guarantee for safety and the ability to increase developer velocity. Unsafe is like the ultimate todo. Without unsafe, we would have not known where to focus our efforts. If folks have any consternation over this event, they should rechannel it into wonder. Because no other language has the affordances that Rust has in controlling unsafe code. 
It's a compiler intrinsic. "Metatype" may just be a term unique to this paper- and it's certainly not anything more than an explanatory term for "this doesn't behave like a real type"
As I understand it, the content is identical because No Starch Press contributed their edits back.
Presumably the one determined by the platform ABI- C++ doesn't specify those either. (And for that matter, Clang-on-Windows also uses the MSVC name mangling scheme.)
service mesh is another layer to be featured in war stories everybody loves to read: https://community.monzo.com/t/resolved-current-account-payments-may-fail-major-outage-27-10-2017/26296/95
I assume https://www.reddit.com/r/cpp/comments/5oe74y/status_of_stdexpected_proposal/ has hints considering OP has significant contributions to it. Can't say what I see impresses me much but there you are.
What is the difference between having a lifetime in the return type and not struct Foo&lt;'a&gt; { bar: &amp;'a str } impl&lt;'a&gt; Foo&lt;'a&gt; { fn new(string: &amp;'a str) -&gt; Foo { Self { bar: string } } } vs struct Foo&lt;'a&gt; { bar: &amp;'a str } impl&lt;'a&gt; Foo&lt;'a&gt; { fn new(string: &amp;'a str) -&gt; Foo&lt;'a&gt; { Self { bar: string } } } also why is `new(string: &amp;'a str) -&gt; Foo&lt;'a&gt;`allowed but `new(string: &amp;'a str) -&gt; Self&lt;'a&gt;`not allowed?
Is all this pointer casting different from just transmuting &amp; to &amp;mut which is very explicitly listed as &gt; Transmuting as &amp; to &amp;mut is always UB In the [rustinomicon](https://doc.rust-lang.org/nomicon/transmutes.html) I would think an UnsafeCell would be required here (or a Rc/Arc for safe code). If this code is well defined can someone explain the difference. I wonder if [intrusive-rs](https://github.com/Amanieu/intrusive-rs) or a similar crate would work here. Then the work to review the correctness of the unsafe code could benefit other projects that need a similar data structure.
How did you find working with cap'n proto? I struggled with the lack of docs for the rust library and ended up using grpc, even though I find capn proto as a language to be better in literally every way.
I guess my benefit was that I already knew capnproto. For me the protocol definition is one of the best out there, no comparison to proto2/3. Are you using grpc in some web frontend context? Sounds interesting to me, since I also did some evaluations on this topic and always ended at the capnp.
Oh yeah totally. But given we're talking about numpy and friends I though the use case for OP is more oriented to the interactive part
Not web frontend, just backend service-to-service communication. I wanted to use capnproto because the language is just far, far more expressive - I'm always running into things I greatly dislike in proto3. But I ended up just finding grpc to be easier to work with from the rust ecosystem. tower-grpc is great, and it was easy to get started. I had problems with capnproto where I'd have to read C++ tutorials and map it to rust - and the generated code for capnproto was considerably uglier, from what I recall.
You want /r/playrust
I do not believe the rust compiler has any networking functionality, but compile times can be pretty long for certain crates. Maybe you're thinking of /r/playrust?
Not really a fix, but wouldn't using Vulkan and MoltenVK fix this problem at the core? Perhaps I've misunderstood your problem, but to me it seems like you're avoiding writing otherwise correct GLSL code.
Neat and very well documented! This is similar to the DIY eager expansion you get with [tt-call](https://github.com/dtolnay/tt-call) but more concise and more convenient for some use cases. One major difference between the two approaches is tt-call's eager call and return do not involve any one-token-at-a-time passes over the macro input. The overhead of a call and return (as counted toward the recursion\_limit) is always a small constant number of expansions independent of the size of input. In my experience this avoids the problem of compiler error messages becoming exponentially more cryptic further down the call hierarchy. As a challenge, to get a feel for how `eager!` behaves in a more elaborate context and to work out some broadly applicable best practices and idioms, you could try implementing a Rust type parser using `eager!`. - Sample input: `eager!(parse_type!(Vec&lt;fn() -&gt; [u8; 64]&gt;, compressed=true))` - Expands to: `(Vec&lt;fn() -&gt; [u8; 64]&gt;) (, compressed=true)` In other words the output is `(/* the type */) (/* any tts after the part that is a type */)`.
What is your overall strategy for beating the performance of mature libraries like ujson, that are explicitly designed for speed themselves? Are there any areas where you are expecting to make large gains?
I'll be tacking the \`Cargo.lock\` file out, thanks for the references. I'll also do dual licensing, as you mentioned it's better to be consistent throughout the ecosystem.
Hmmm, I'll certainly look into this, I'm not sure how this stuff works. :)
You should do some reading comprehension exercises. Does this subreddit look like the subreddit for the game Rust to you? :-)
Plenty. It may not make sense to rely on parallelism at the request level, depending on the work you're doing. That may not be enough to saturate your CPU. Most Java web servers I've worked on have a few threadpools for various tasks, not just for handling requests.
Sorry, English is my first language. 
Get better grades!
get more ram!
No because it's overpriced
you're looking for r/playrust
Have you tried compiling with `--release`?
The author makes some good points, especially regarding the initial learning curve to Rust. However, I do not think he fully appreciates how rock solid and time saving Rust can be once you become proficient in it. As for the phenomena of, "fighting the borrow checker", I found after a period this stopped, almost unconsciously. It was highly annoying at first though. I now compare my use of Rust to that of Python in terms of simplicity. I also feel I have more confidence in the safety and stability of the final product. I certainly notice less hard to find errors in code. Just my thoughts!
Then I think there's no hope for you, you should re-roll your character and hope for more int. 
I'm intellectually superior to you
https://doc.rust-lang.org/std/macro.unreachable.html
Awesome! I knew there must be something like this. Thanks.
Maybe just do an if / else if they’re are only two branches though? At least that’s what clippy would say 
Thanks for the explanation! The huh was more because I had never really thought about the need for a A -&gt; A "compiler," or what it would be called. 
I believe the currently recommended way to represent opaque types over FFI is to use a normal ZST with a private field to prevent construction rather than an uninhabited type. IIRC Bindgen currently generates something like this: #[repr(C)] pub struct OpaqueStruct(_unused: [u8; 0]) An array of zero size is used instead of `()` to avoid triggering the non-FFI types over FFI lint.
Something you could mention in the arrays section: How to setup a mutable array that you pass a pointer to for c to fill. Things like Vec being guaranteed to be tightly packed, `from_raw_parts`, etc.
Thanks for the pointer! That zero-length array solution is definitely a lot nicer than using a pointer to an uninhabited type which may or may not be UB and optimized out. I just had a look at how `std` and `libc` represent `c_void` and it seems like both use a C-style enum with 2 variants. Do you know why they'd use something different to bindgen? 
just make the second match be the wildcard \_. Since you know it can only be zero or one, and you've already tested for 0, then using a wildcard match "\_" will satisfy the compiler.
&gt; How to setup a mutable array that you pass a pointer to for c to fill. I'd say it's more because `Vec` derefs to a `&amp;[T]`. Either way, it's probably a good idea to show using `slice::from_raw_parts()` and a `Vec&lt;T&gt;` to copy data from one language to another. I was actually thinking of writing an example where Rust calls a C function that reads data from a file but changed my mind because it seemed "too simple".
I'd actually disagree with Clippy here. If the value could only hold 0 or 1 and if/else would be perfect, but in this case the value could hold a whole range of values outside 0 or 1. We know logically it will only *be* 0 or 1, but a match statement with an unreachable! macro explicitly and unambiguously tells future readers of the code what you were thinking, and what values are valid.
Ah yes, for some reason I didn't think of that. It's a bit asymmetric looking, but definitely an option.
&gt; I'd say it's more because Vec derefs to a &amp;[T] Unless I'm misunderstanding something this isn't it at all. You're passing a mutable pointer to the start of the first element and because you have that guarantee it's safe to read up until `vec.len()*sizeof(item)`.
I agree with you, and this is the main reason I posted this. I tend to prefer very explicit code, and didn't really want either case to be subsumed by an "else".
In this specific case, I would just use an if-else statement, or use the catch-all arm for the other possible case. let x: i32 = if vals.len() % 2 == 0 { VALUE_FOR_EVEN_CASE } else { VALUE_FOR_UNEVEN_CASE }; let x : i32 = match vals.len() % 2 { 0 =&gt; VALUE_FOR_EVEN_CASE, _ =&gt; VALUE_FOR_UNEVEN_CASE, }; Why? Because handling the "impossible" case adds another branch, which lowers performance (by however small amount). This is especially true if the handler panics (like in the case of the `unreachable!` macro), since panic handling generates a lot of extra code.
If I had to guess, perhaps it's because maybe "pointer to `void`" in C is different from "pointer to a specific opaque type". But I don't really know for sure.
\#\[do\_not\_congratulate\]
&gt; You're passing a mutable pointer to the start of the first element and it works because you have that guarantee it's safe to read up until pointer + vec.len()*sizeof(item). Yep, this is 100% correct. What happens is you create a `Vec` with a bunch of zeroed out items (e.g. with `vec![0; 1024]`), this is effectively a pointer to an array allocated on the heap where `some_vec.len()` elements are logically initialized and the rest (`some_vec.capacity() - some_vec.len()`) are garbage. When we want C to fill our buffer (`some_vec`), we pass a pointer to it's first element using `some_vec.as_mut_ptr()` (because `Vec&lt;T&gt;` derefs to `&amp;[T]` which has a `as_mut_ptr()` method) and the length. I'd argue that those guarantees on reads being safe are because a slice can only contain initialized data, and a `Vec&lt;T&gt;` is just a boxed slice which has a little extra capacity so we can add and remove elements. The easiest way to see that you don't actually need to allocate a `Vec&lt;T&gt;` to copy data from one language to another is to use a normal array on the stack ([playground](https://play.rust-lang.org/?gist=8fb8e55073377156a295f0f5c26dd25a&amp;version=stable&amp;mode=debug&amp;edition=2015) - compiles but linking fails because `fill_buffer()` is just a made up function).
Nice article. Didn't know about yew!
The compiler can easily eliminate the extra branch and will produce identical assembly. http://play.integer32.com/?gist=4d91af65ed52352386d509bd32f5a4b6&amp;version=stable&amp;mode=release&amp;edition=2015 So really it only makes a difference to human readers, in which case I'm not really sure if it's clearer to have an `unreachable!` arm or nor.
Another thing I noticed is the use of `assert!` in Rust functions called by C. Note that `assert!` will `panic!` if the assertion failed. And by default, panicking is followed by stack unwinding. And unwinding from Rust into C = no bueno.
By the way, this is subtly wrong when dealing with signed integers, where `% 2` can return `-1`, `0` or `1`. Of course, it doesn't matter in this case, because `len` is `usize`, but something worth noting.
Is actix-web developed by MS too? Or only actix? 
Great demonstration of the various libraries. Nice to see this kind of content.
Yeah, I'm planning to create a whole chapter on exception safety and making sure a panic/exception doesn't cross the FFI barrier. I'll go back through and get rid of any `assert!()` calls so we don't accidentally teach people bad habits. From memory a couple releases back they made it so the unwinding mechanism detects when it crosses the FFI boundary and will abort, but that's definitely not something I'd like to rely on. In the `ffi_helpers` crate I use at work, there's [a bunch of machinery](https://docs.rs/ffi_helpers/0.1.0/ffi_helpers/panic/index.html) for catching panics and integrating it into the C-style error handling mechanism. I was thinking I'd introduce something similar.
The first goal is to match the speed of other libraries, but doing so safely. Rust has proven time and again, that safety doesn't need to be sacrificed for speed. This step, I guess, will mostly involve finding bottlenecks through benchmarking an profiling and finding ways to fix those hotspots. If we get a safe encoder that is as fast as the competition, that's already huge. The next step would be trying completely new approaches to solve the problem. As mentioned above, modern processors are not really well-used by other C-based libraries - simply because they work on a different layer of abstraction and it would be harder to debug multi-threading (race conditions) or maintain low-level SIMD code. In my opinion, this is where we have a chance with Rust. Older libraries may carry a lot of legacy code around. Many of them still implement flags from the `json` module, which were long since deprecated, or they support older Python versions (sometimes even before 2.0). While this is not bad per se, it adds to the maintenance burden and can slow down development. Hyperjson only supports Python 3.x officially, so we are not afraid to go new ways. Rusts crate system could help to create multiple alternative approaches that all use the same interface. For example, with async being supported beautifully by both, Python and Rust, it might even be thinkable to return a `Future` from hyperjson. This part could be completely optional and located in a separate crate. I guess the overall strategy is not to (only) beat other libraries on raw performance, but have an environment where it's safe to try new ideas and see how Rust can add value to an already mature ecosystem.
Thanks for replying! I'll try to get an example and send it to you.
Yeah, I brought up the unwinding thing because while Rust 1.24 turned panics into abort on FFI boundaries, version 1.24.1 came out and immediately reverted the change ([details here](https://blog.rust-lang.org/2018/03/01/Rust-1.24.1.html)), and I'm not sure if it was ever un-reverted.
Thanks for the link, I remember reading about unwinding being converted to aborts but didn't know it had been reverted.
Ome thing that I al struggling at the moment is how to don't free objects that will need to be managed by the C part in your rust code. If you are writing a callback you will most likely get a pointer from C that you use for doing whatever, then, before to exit you may want or not to free such pointer. If you don't want to free the pointer it get hairy quite quickly. 
Great answer. I hope to be able to get involved!
I found the easiest way to handle this is by making sure all non-Copy types have a `foo_destroy()` function which will unbox the object then explicitly call `drop()`. &gt; If you are writing a callback you will most likely get a pointer from C that you use for doing whatever, then, before to exit you may want or not to free such pointer. &gt; &gt; If you don't want to free the pointer it get hairy quite quickly. I assume you're talking about the practice of providing a `void*` pointer alongside a function pointer so you can keep track of some state? As a general rule I try to keep my FFI code super simple (KISS) and make sure the ownership story is well defined. So this means I wouldn't want to free the state object in a callback, instead waiting until the end of the application so C can call a `foo_destroy()` method to clean up the object. Would you be able to show me an example so I can get a better idea of what you're talking about? I believe I solved a similar problem [as part of the dynamic loading chapter](https://s3.amazonaws.com/temp.michaelfbryan.com/dynamic-loading/index.html#injecting-plugins-into-a-c-application) where the `PluginManager` needs to manage the lifetime of our plugin and make sure it's destroyed properly.
Thank you very much! 
Thanks! :)
Ah, very cool! Still, I don't like to be at the mercy of the optimizer, if I can easily help it. Sometimes it's a bit unreliable.
&gt; What is the difference between having a lifetime in the return type and not Rust tries to fill in lifetimes in simple cases for you (which it does not do with generic types), but this is not one of those cases. You've explicitly said that there is no lifetime relationship between the input and the output in the first example. In the second example, you *have* said there is a relationship between the two. &gt; also why is `new(string: &amp;'a str) -&gt; Foo&lt;'a&gt;`allowed but `new(string: &amp;'a str) -&gt; Self&lt;'a&gt;`not allowed? Because `Self` *is* `Foo&lt;'a&gt;`. It's a bit like if you were implementing for `Vec&lt;i32&gt;`, and wrote `Self&lt;i32&gt;`; that'd be `Vec&lt;i32&gt;&lt;i32&gt;`, which doesn't make any sense.
I would not call it "performance compromise". An incorrect but faster program is still incorrect, so it's not really comparable to a correct program.
The maiplace wher I'd be happy to use nll is control flow where some branches borrows and some are not
If you don't want to rely on the compiler, then explicitly build something like this: #[inline(always)] fn nope() -&gt; ! { if cfg!(debug_assertions) { unreachable!() } else { unsafe { ::core::hint::unreachable_unchecked() } } } The hint is guaranteed to trigger dead code elimination, no fancy panicing and what else not. On debug mode, this function still has the panicing `unreachable!()`, so that your Unit tests can ensure that you stuff works as intended.
Really nice blog post. Looking forward to seeing more people start using Yew / Rust for web front-end. 
If you install the ARM toolchain with rustup, why the need for a VM? Can't I just install the toolchain on whatever host I have?
Let's not casually introduce potential UB just because we know or "know" we're right
Indeed you can, but there are still a few issues: https://github.com/rust-lang-nursery/rustup.rs/issues/1410 The main reason for cross-compilation is though speed (for larger projects) and in my case deploying to different architectures from the same developing machine.
Soon this might no longer be needed. `rustup` already packages the LLVM linker (`lld`) as the `llvm-tools` component, and that one is cross platform. I couldn't get it to work, but keep an eye on https://github.com/rust-lang/rust/issues/39915.
That function should be marked unsafe, since it has the potential to trigger undefined behavior without debug assertions enabled. More to the point, when I said I can easily help it, emphasis was on easily. I don't consider introducing unsafe code to be an easy solution, as you should always think very carefully about what you're doing when dealing with unsafe code.
#[chuck_testa]
`unreachable!` is a way to go but still feels a bit hacky to me. To do it “correctly” you would need dependent typing, something Rust doesn’t have right now. However, you don’t need DT here to already improve. You can simply use (or write) a function `odd` or `even`, which returns a `bool`. And then your function is total without the need to use `unreachable`.
It's not a spin lock. Mio uses kqueue + epoll to "wake up" the thread when there's an io event. Tokio converts futures into tasks which basically wait to receive a message. You might be interested in reading the tokio.rs docs to get a better understanding
[removed]
Why are you wrapping `AtomicUsize` with `Arc`?
This is really about testing of a number is even or odd. The most unambiguous way to do that is by using `is_odd` or `is_even` from the `num` crate: I prefer: use num::Integer; let x: i32 = if vals.len().is_odd() { } else { } 
Happens to be my undergrad thesis project to bring PIC to LLVM again ( existed in 2.8 for a specific model, the PIC16 ). Unfortunately wont be released to public in whatever form it ends up being till supervisor approval or end of year after I present.
I've been recently reading about developing backend services using Rust and this was an excellent read, thank you so much!
The 8bit PIC's do not have a hardware stack for memory only for return address's and its limited to 31 in the "Advanced" models. So function calls are precious and other hardware decisions make the PIC's "interesting" to deal with in higher languages. My undergrad thesis/project is to see if I can get LLVM support for all the 8bits again. The architecture feels very much like a blank slate with some helpers on the side if you want them. Like you could ignore the "return address stack" and implement it all in software or you can have whatever amount of general purpose registers you want ( but they cant do anything except hold values ).
One of the responsibilities of futures is to notify the top-level task it's running under when it can make progress. Most code using futures won't have to worry about this because they use combinators or w/e on top of "primitives" that already take care of that. For everything socket-like, that's gonna be handled via some file descriptor being added to a set that's selected on or equivalent, like you expect, and I think there's probably also special support for timers, and other stuff uses background threads or something I guess.
For a second I thought rust had some syntax unknown to me because of your coding style lol.
I disagree - an incorrect but faster program may be incorrect, but it's still faster. It's interesting to see if making the program correct makes it slower. 
I don't understand the error I get: [playground](http://play.rust-lang.org/?gist=0e243e5286f424baa0ac330e4355a4dd&amp;version=stable&amp;mode=debug&amp;edition=2015) Looks like a bug to me, or can this be explained?
You don't need to shell out to `tput` for this - just print `\a` (or the byte `0x07`).
On which example? Is something of my style not idiomatic? 😶
In your struct declaration you do `field :Type` instead of `field: Type`, which makes it look like ruby symbols.
Ah okay, I guess `cargo fmt` did this. :)
&gt; The first goal is to match the speed of other libraries, but doing so safely. Have you verified that serde and serde-json contain no uses of `unsafe`? I've just checked and turns out that they do, in fact, use `unsafe`. The two `unsafe`s in serde core seem harmless (*assuming correct `write_fmt()` implementation in API client,* which actually may be a problem when that data comes from FFI), but it is not obvious to me that serde-json is actually safe and [code comments like these](https://github.com/serde-rs/json/blob/7531208/src/read.rs#L487) do not inspire confidence. Sure, you can argue that Rust isolates unsafety so it's *mostly* safe, but it does not help you much in practice. This only means that unsafe code becomes easier to audit, and does not mean that someone has actually audited it. Case in point: `inflate` crate had a single line under `unsafe` which turned out to be a devastating security vulnerability, and it was not discovered until me and the crate author looked at it *together.* Now if you'd have added a config option to serde that turns off all `unsafe` optimizations and used serde built in that mode (ideally also in no_std mode so you don't have to trust all the `unsafe`s in the standard library), you could have actually guaranteed something about safety. Also, FFI is unsafe by definition, and I have personally discovered a bug in FFI a few years ago that was a nasty security vulnerability and even got a CVE assigned to it. Do you have a strategy to make FFI safer than the usual handwritten bindings? Automatic generation helps sometimes, but pyo3 is largely written by the same guys as actix and actix-web, who have a [dubious](https://www.reddit.com/r/rust/comments/8s7gei/) track record. They've caved and stopped ignoring the issues in actix after the issues were given a lot of publicity - in fact, the issues were [resolved](https://www.reddit.com/r/rust/comments/8wlkbe/) just yesterday. So far pyo3 did not get the same treatment.
I've never liked modulus returning negative integers; it's very counter-intuitive :(
Has there even been a push for some kind of configuration flag that disables unsafe optimizations? For example, `inflate` crate contains a single line of unsafe code that turned out to be a security vulnerability. I've added extra checks around it, but that merely means that I no longer know how to exploit it, and does not mean that it's not exploitable. I have failed to rewrite the code in a safer way without losing 10% in performance, and I can't just cut off 10% performance for everyone and say "hey, this is an improvement!". But I could add a config option that says "I'm willing to take some performance hit for guaranteed safety" and then use it when safety is more important than performance.
...huh? Pretty sure default `rustfmt` puts the colon first, are you using custom rules in your `rustfmt.toml`?
Uhm, not really. I also had a closer look at the code and did not found any mentioned style: ``` &gt; rg -t rust " :" &gt; ```
The way I've seen people do this is to just expose a Cargo feature that permits turning off the use of `unsafe` code. In the code itself, you need to `cfg` it out based on whether the feature is set. This isn't something I would personally pursue though. I think we should just spend the effort to convince ourselves that we're using `unsafe` correctly. Making `unsafe` code optional has its own demons. It makes the code more complex and makes it all too easy to test one path through the code but not the other.
It's not necessarily about correctness. A program that uses unsafe can be correct but making it not use `unsafe` could require checked index accesses, `RefCell`, or other things that have performance overhead.
A `Node` is using `* mut` internally, and it is legal to transmute/cast that to a `&amp;mut`.
That is capnproto input, not Rust code, I think.
Also made this one a while ago https://gitlab.com/edvorg/spray
You have a point: we can't guarantee safety, nobody can. Even the Rust compiler has lots of unsafe code in it, that could reveal safety holes in the future. There is also [unsound behavior](https://github.com/rust-lang/rust/issues/24292) that pops up here and there. serde-json is one of the most used crates out there and even though that is no safety guarantee, I have high hopes that security issues will get closed quickly. u/dtolnay is doing a remarkable job there. In the end, we're standing on the shoulders of giants, but even giants can stumble. But just because there is no safety guarantee, that doesn't mean that we can't try to improve the situation. Rust at least allows us to actively fight unsafe code. &gt; Do you have a strategy to make FFI safer than the usual handwritten bindings? No. Apart from rigorous testing I don't. But all other extensions suffer from the same problem: we are dealing with fragile foundations. Rust, the Python FFI, pyo3, serde-json, hyperjson - they all have bugs and there's only one way to improve the situation: by fixing them. In the end, all of those parts are replaceable. Hyperjson will be in alpha for a long time. The final goal is to provide safe abstractions, but it's a long way to get there. &gt; pyo3 is largely written by the same guys as actix and actix-web, who have a dubious track record. They've caved and stopped ignoring the issues in actix after they were given a lot of publicity - in fact, the issues were resolved just yesterday. So far pyo3 did not get the same treatment. In my opinion, the criticism against actix and actix-web was very harsh, especially on Reddit. Somehow people forgot that those projects are maintained by volunteers in their free-time. Actix is well documented, and it is pushing the boundaries of what is possible with Rust; the maintainers deserve some credit for that. On top of that, the issues were addressed quickly. If I was one of the maintainers, I think I would have cried and not touched the keyboard for a while. I want Rust to stay a welcoming, friendly community where we can talk about such issues in a constructive way. So if we find a problem in pyo3, we'll just try to fix it.
Just want to point out that this article is about ARM***v***7, not ARM7. Unfortunately, they’re very different. Think Galaxy S5 vs Gameboy Advance, respectively.
It was remarkably welcoming and friendly during this episode compared to, well, pretty much anything I've ever seen. Instead of just damning the code forever because of the authors attitude, people have actually *spent their time* to audit the code and describe the issues, over and over. [This comment](https://github.com/actix/actix-web/issues/289#issuecomment-398140594) is pure gold. &gt; Some people said it would be best to not touch any project the actix team members ever worked on These comments were made at the moment when the team was denying that the unsound `unsafe`s are an issue, and it is solid advice. Despite what it might seem, this is nothing personal, just a statement about the code. In fact, I stand by that statement, with a slight correction: do not use any code written by actix team *prior to fixing unsafes in actix* without auditing it first. This is also a statement about the code that is not meant to be personal in any way - everyone makes mistakes and nobody knows everything.
[removed]
Can you explain what dependent typing is?
if you can prove that the arm is unreachable, you should use \`unsafe { std::hint::unreachable\_unchecked() }\` That informs the compiler that there really only are those two options and it can optimize better.
It was very annoying to spend ages trying to compile GCC for Mac OS targeting Raspberry Pi and have a million different things not work just to rustup target add and set lld in .cargo/config and it work perfectly first time.
Have you considered implementing [embedded-hal](https://crates.io/crates/embedded-hal) traits for your gpio?
Would you consider adding language-specific chapters? Python, Ruby, JavaScript have libraries to extend with Rust.
&gt; In my opinion, the criticism against actix and actix-web was very harsh, especially on Reddit. I do not necessarily disagree with you on this, but this is orthogonal to the point I was trying to make. I feel we need to separate the interaction between people and the code. Could the discussion of the issues in actix be more friendly? Probably. Now, please consider this in the abstract, without tying it to specific people or events: is it a good idea to blindly trust a library that is written by people who do not recognize safety issues as something that needs to be fixed, when safety is an explicit goal for a project that uses that library? The answer is obviously no. &gt; You have a point: we can't guarantee safety, nobody can That is not true. You can, in fact, *prove* correctness - or at least, prove that your code adheres to a certain formal specification. See [sel4](https://sel4.systems/) or [CompCert](http://compcert.inria.fr/) as examples of projects with proven correctness. There is also proof of correctness for a practical subset of Rust type system, *including* certain primitives from the standard library that use `unsafe` internally. See [paper](https://dl.acm.orgcitation.cfm?doid=3177123.3158154), [conference talk](https://www.youtube.com/watch?v=Cy9NUVaiYUg). The talk makes reference to [Derek Dreyer's keynote at the same conference](https://www.youtube.com/watch?v=8Xyk_dGcAwk). You can also approximate proofs of correctness in various ways, such as verifying that certain invariants hold on arbitrary inputs, comparison to a test oracle, fuzzing, mutation testing, symbolic execution, etc. For more information on formal verification see [this excellent talk](https://media.ccc.de/v/31c3_-_6574_-_en_-_saal_1_-_201412301245_-_why_are_computers_so_and_what_can_we_do_about_it_-_peter_sewell).
Why the need for Vagrant and going through an actual virtual machine? Isn't it easier to use docker for this? Just asking, because I am not so experienced with cross compilation and there might be advantages to Vagrant over docker that I am not seeing. In particular, I am thinking of this docker image ([github](https://github.com/dlecan/rust-crosscompiler-arm), [docker hub](https://hub.docker.com/r/dlecan/rust-crosscompiler-arm/)). The docker image I linked to also works for Raspberry Pi Zero (and siblings) and 1st Generation Raspberry Pi, as these are armv6 with hardware floats (hf). If you try and run armv7 on the Pi0, you can expect segfaults. 
So.... You gonna provide any more details about the mistakes in the design of `Result`? 😄
There already exists an implementation for the Pi that I've been using called linux-embedded-hal.
&gt; You can, in fact, prove correctness - or at least, prove that your code adheres to a certain formal specification. You're right, I forgot about that. Fuzzing is also a great idea, which could even be integrated into our test framework at some point. If somebody would like to take a stab at it, I've opened an issue [here](https://github.com/mre/hyperjson/issues/30). Thanks for the feedback.
You were right, it's here: https://doc.rust-lang.org/book/second-edition/ch14-01-release-profiles.html
&gt; It was very annoying to spend ages trying to compile GCC for Mac OS targeting Raspberry Pi You don't have to. You can use [this](https://github.com/japaric/cross), it has some Docker images with the GCC toolchains. &gt; just to rustup target add and set lld in .cargo/config and it work perfectly first time Yeah, for some reason it didn't work for me when I tried it today (with the `llvm-tools` linker).
Could you say a little bit about the differences between this crate and the `linux-embedded-hal` crate?
In any case, for *unsigned* numbers, rust knows that it can only be either 0 or 1, and if you have an unreachable! macro as a catchall, that code doesn't even get compiled in. So a unreachable_unchecked won't do anything here, and I'd probably just use a unreachable!() macro, since the released code hasn't changed. Difference being that if you're wrong it's a panic rather than UB.
If you need the performance, then that's not a problem. Just be careful.
In 99.9% of the cases `unreachable!` is the preferred solution. Sometimes for very specific performance reasons you might want to promise the optimizer that the catch-all is never taken. This is possible in Rust using `unsafe`, and the more or less standard way to do this is with the `unreachable` crate. (Internally this is done by invoking `match x {}` where `x` has a type with no values, i.e. `enum EmptyType {}`. It won't be possible to initialize `x` in safe Rust, but unsafe Rust has `uninitialized!() This is a Faustian bargain, though. If the program ever enters a state where it is guaranteed to reach an unreachable branch, anything and everything is allowed to happen. It's best to check the least significant bit using the `&amp;` operator, since it works on signed integers. And the optimizer is probably smart enough to figure out that `x &amp; 1` can only equal 0 or 1. If you want parity in the wire-communications sense (number of set bits modulo 2), that's `n.count_ones() &amp; 1`.
Good post. I've been trying to do something similar (`yew` on the frontend, `rocket` and plain `r2d2` on the backend) and have been struggling with the lacking and sometimes contradictory documentation for `yew`. How did you find it?
You probably *shouldn't* use that in many cases, since it's easy to think you've thought of everything, or for some other code to later change. Having a cold branch that panics is much better than UB.
`is_odd()` and `is_even()` for the standard integral types need to be in `std`. There's no way I'm including an extra crate dependency just to get them.
Thanks, I didn't know something like that existed! I'll definitely take a look at it.
Types *depend* on their values. As in '1' is a different type from '2'. Then you can reason about these values at compile time, because they're encoded as types. Generic integers are one example of encoding a value into the type - Array&lt;0&gt;, Array&lt;1&gt;, Array&lt;N&gt;, Array&lt;N + 1&gt; etc are all different types, and operations between them may or may not be defined.
well, that’s more of a social argument – is there the slightest possibility that someone changes something in a way that invalidates the assumptions here? i’d say no: \`len()\` will always be ≥0, Z^(+)&amp;#37;2 will always be 0 or 1.
DT is when a type depends on a value expression. That is, for instance, it gives you compile time assertions that adding an element to a `Vec&lt;..&gt;` will make its length grow by 1. You could express it as (non-existing syntax there): ``` fn snoc&lt;T, N: usize&gt;(vec: Vec&lt;T, N&gt;, item: T) -&gt; Vec&lt;T, N + 1&gt; ``` With that kind of things, you could express the modulo with something like: ``` fn modulo(f: i32, m: i32) -&gt; &lt;i32 as r verifying 0 &lt;= r &amp;&amp; r &lt; f&gt; ``` In the OP case, you would then have a static path like: ``` &lt;i32 as r verifying 0 &lt;= r &amp;&amp; r &lt; 2&gt; ``` `r` now has only two valid values at compile time: `0` and `1`. Pattern-matching against the result of `x % 2` would be total with cases `0` and `1`. If you’re interested with DTs, have a look at `Idris`, `ATS` or any other dependent-typed language. :)
Just FYI, for Linux, a simple `notify-send` would work in almost all cases. 
&gt; This is possible in Rust using unsafe, and the more or less standard way to do this is with the unreachable crate. This is actually part of std now as [std::hint::unreachable_unchecked](https://doc.rust-lang.org/std/hint/fn.unreachable_unchecked.html)
In OPs case, ya it probably won't get changed. I read your comment as suggesting that in general if someone thinks they've proved it, use unchecked. For someone newer, (and in general) it's safer to just use the macro.
&gt; Having a cold branch that panics is much better than UB. Unless the compiler can do something clever based on the fact there's only 2 possible values. Like turning a match 0 =&gt; false 1 =&gt; true into 3 instructions (and, mov, ret) which is branchless. A simple example, sure, but if the compiler can write easy code to map the input to the output, it'll do that. Forcing it to care about other values screws that up.
Sounds interesting. The documentation is clearly a problem of yew, but I guess this is just a matter of time until it gets better. The examples helped a lot.
totally agree! for a proof, you need in-depth knowledge about the APIs and types involved. it shouldn’t be done lightly.
First, this is mainly for my own enrichment. In most cases, I prefer writing my own libraries for my projects because I do learn much more about the low-level systems. I don't find satisfaction in taking someone else's code that "just works" if I know I can study/understand the same systems and write it the way I want it to work. That being said, this is also a public, free/libre project (hence this post) that I am willing to support if others benefit from it. Implementation-wise, `linux-embedded-hal` appears to use the sysfs filesystem for accessing GPIO (which is more generic across devices) , whereas mine directly accesses certain segments in the Pi's memory that are available only on BCM283x chips. I am unsure whether this direct memory access has a measurable performance benefit in application compared to going through the kernel's FS; there is also the downside that my crate requires root privileges to map memory from `/dev/mem`. Regardless, I can say that I do understand the inner workings of the Pi's SoC much better than before.
Yep, I've been bitten by this before in other languages.
Cant you emulate raspberry pi on virtual box or something? I feel like there’s gotta be a way to text without buying the hardware 
Unfortunately, the crate depends on features that are provided by the chip itself, and there are additional complexities in virtualizing an ARM system on other architectures. Because of these problems, performing testing on virtualized hardware would require the hardware itself, including the SoC, to be virtualized. There may be specialized tools to do this, but certainly not vanilla VirtualBox.
Going around the sysfs framework is not a good idea, you are essentially undermining the hardware abstraction that the kernel provides. The files exposed there are the "safe" gpios for you to access. The kernel can reserve certain pins that it deems important (eg that are used by other nodes in the device tree). Additionally, if the SoC has hardware changes in later revisions, you have to implement some sort of versioning system to account for that. This will insert a delay between when the the hardware is released and when your software is ready for the users, which wouldn't exist if you used the sysfs framework. I think what your doing is great as a learning experience, but at the current moment in time is not a scalable solution. Source: years of kernel devolpment for ARM SoC's
&gt; These comments were made at the moment when the team was denying that the unsound unsafes are an issue I don't see many of them being taken back, get relativised or anything. &gt; when the team was denying that the unsound unsafes are an issue I've read the entire issue, and was not under the impression that they did that, but that's open to interpretation. &gt; it is solid advice. No. It's unfair for the actix members because if this mindset was pervasive, they would have to cease working on open source projects altogether. It's also unfair for the other contributors to the projects in question, because their efforts are also thrown away. What *is* solid advice OTOH is your corrected version. Unfortunately, that's not what people said.
Does it work for git bash?
I just realized how I really want to do this, and it's something like this: let x = match vals.len().parity() { Even =&gt; ..., Odd =&gt; ..., }; But it seems there's no support in the standard library for anything like that&amp;mdash;probably because parity is already easily obtainable with `% 2` or `&amp; 1`.
Ah I see. So the [typenum](https://crates.io/crates/typenum) crate would be an example of this?
&gt; The author's first responses were quite dismissive of the issue I think the problem was that the issue creator apparently wanted to go all in and remove literally all occurrences of `unsafe`. Since I'm not a fan of that attitude, I would likely have reacted like the maintainer. The maintainers also never sounded dismissive to me, but that's where we get into nuanced speech territory. Neither I nor the first maintainer to respond are native English speakers, so it's possible that what he said sounded way more angry in English than he intended or I interpreted it as ;) &gt; As a moderator of r/rust, it was a though thread to handle That I believe! It's one of the situations where some people get into this doomsday-lock-down-the-bunker mindset and prepare to take extreme measures - similar to when the GitHub acquisition was announced.
Most WG21 discussion is not documented publicly, in fact there is a rule that people's comments at a WG21 meeting must not be made public outside the committee. And much of the to and fro minutiae during committee debate tends to be missed in the minutes taken. A great deal of discussion also occurs verbally. Much of Expected's current (reduced) form came together during a barbecue at a C++ Now conference, for example. And finally lots more discussion happens by private email. C++ comes from a time and culture where decisions were not taken publicly. It's getting better, the Boost C++ Libraries were a sea change in terms of openness, but it remains a conservative ecosystem.
Nothing documented in a single place that I am aware of. 
&gt; It was giving tough love From those who actually offered help, definitely. Many on reddit went a bit overboard on the "tough" and ignored the "love" part, hence my comment.
That would take a lot of time to do well. And I don't think there is any value add, unless you're planning to completely refactor your error handling mechanism. Better to spend time on what can be changed, not on what is unchangeable.
&gt; In that case you would still need the discriminant. Only if `T` does not contain a `NonNull` though. E.g. `Result&lt;NonNull&lt;T&gt;, ()&gt;`, `Result&lt;Option&lt;NonNull&lt;T&gt;&gt;, ()&gt;`, `Result&lt;Vec&lt;Option&lt;T&amp;&gt;, ()&gt;`, ... do not need a discriminant.
It is proposed that C++ is to gain "panics", in fact. These are the proposed triggers: - OOM - Contract violation - Logic error No unwinding occurs. Default action is immediate process termination.
I think this is probably the cleanest way given the current stdlib. let x : i32 = match vals.len() % 2 == 0 { true =&gt; ..., false =&gt; ..., }; `unreachable!()` is the answer to the more general question.
Metatypes are stuff which describes types. C++ plans to add them for C++ 26 maybe so you can perform, at compile time, AST transformations i.e. rewrite oneself. What I proposed in the proposal paper is fixed feature, almost preprocessor macro in simplicity, and fitting perfectly into C idomatic notation. Currently WG14 is feeling that my proposal is nowhere near radical enough. They're actually currently talking about breaking binary compatibility by making *all* C functions implicitly return a union type, which is *very* radical for C.
Also, for C at least, you can implement an Either type by hand which is exactly as efficient as any builtin implementation. C historically does not do language support for stuff which can be done by library.
Shameless plug, but I've implemented this behavior in [pantheon-terminal](https://github.com/elementary/terminal) a while back. You do not need to prefix the commands with anything, it just works out of the box for all commands for both `bash` and `fish` shells. It's integrated with the terminal emulator so it's a lot smarter than any solution that isn't, and will not distract you if you're currently looking at the terminal tab where the task has completed. The initial version looked like [this](https://www.youtube.com/watch?v=WLhTmnifAro), but it's a lot sexier now, and also reports exit code.
Though love is the worst thing ever. Dont fucking propagate it thinking it's ok. Nobody asked for you to give rude criticism, you just decided to be rude
There definitely might be a portability benefit from `/dev/mem` :) But I'd probably write `freebsd-embedded-hal` if I ever needed to actually do something with GPIO on the Pi.
Does that run Ion tests inside redox?
Sure. (Though you're slightly off with which cases can collapse the discriminant- `Result&lt;Option&lt;NonNull&lt;T&gt;&gt;, ()&gt;` can't, for example.)
Yes, I'm aware- but that's not really relevant here? C++ process termination doesn't really involve any interop with Rust. Also, FWIW, Rust panics *do* unwind by default.
&gt; Checking in `Cargo.lock` is recommended by the Cargo book. Did you mistype something here? That page (and the FAQ) says to check in `Cargo.lock` for executable crates but not libraries. Frankly I'm happy to have an excuse to not commit `Cargo.lock` files. It's annoying having commits to update it, ending up with `Cargo.lock` changes in commits where you add a dependency, trying to avoid unrelated `Cargo.lock` changes in that commit, or ending up with those unrelated changes...
Yeah I typed the opposite of what I meant... I've edited it - good catch!
Agreed. GitLab CI is pretty nice and well integrated; and it's a good thing to advertise for why you're using GitLab instead of GitHub (other than just "grr, Microsoft is going to eat your code!"). GitLab has other nice features, but that's probably the big one.
Thanks for the help :) That makes lifetimes a lot clearer for me.
It's because of the issue I'm referring to above. It's very frustrating at the moment, so for me cross compiling is a great solution (plus personally I have a few other reasons to go that way).
Just teach yourself to call it the remainder operator.
We can be constructive without any assholery. Grade school kids learn this skill.
As I mentioned last night on the /r/cpp thread, apologies for being away from Reddit for 48 hours. I was having fun with my children. Rust's `Result` design fits well with the rest of Rust, which is to be an abundance of restrictive specification. Some in C++ would liken Rust's design principles to a huge menu of straightjackets to choose from. And I think everybody gets the appeal: it always seems better to be specific rather than ambiguous, and to give users standardised choice rather than to force them to constantly reinvent locally. And maybe due to those strengths Rust will replace C++ as the obvious choice for systems programming one day. We'll see. However C++ still isn't the obvious choice for systems programming even yet - C still predominates, and C-with-bits-from-C++ is actually what most people write when they write C++. If you look at the really big multi-million line codebases which are many decades old, what is very obvious is how *much* ambiguity is used, and how *much* local reinvention is performed. This would suggest that ambiguity and local reinvention are actually a feature, not a bug, for really large and old code bases. My current contract is working with two million lines of 1990s C++. This product is shipping to huge organisations world wide, entire governments and multinationals use it for mission critical operations. Like most code bases of its age, it is mostly C with bits from C++. It avoids using the C++ standard library, preferring to reinvent locally. It has tons of ambiguity and inconsistent design patterns. And here's the thing: I just can't imagine this code base being possible in Rust. Rust's straightjackets couldn't permit such incomplete refactoring as the code was maintained over the decades. I suspect, in practical terms, that means a large Rust codebase must be rewritten as it ages, rather than code unrecompiled since 1992 being linked into a production binary from a prebuilt binary blob. And I don't know if big multinationals won't consider those Rust straightjackets as too high a price to pay for really big, long lived, code bases. I'm sure we will find out with the Firefox rewrite, but to make this specific to `Result`, one of the key things which lets you scale into many millions of lines of code is type erasure in your error handling mechanism. So, if code A calls code B which calls code A, and code A fails, then code B must be able to return the original failure, *intact*, to the code A further up the call stack to recover from. Doing that in Rust, today, is non-trivial when you don't and can't control code B. You need to resort to workarounds like stuffing failure detail into TLS, and recovering it later. And those workarounds get tricky at scale. If you have a hundred third party libraries in your code base, each with their own TLS stuffing, *and* needing to work across multiple threads which are not under your control, each needing to repack the TLS stuffing between thread traversals, it all gets very brittle. In C++, you subclass the exception type with your own type which has whatever failure detail you need. You throw your own type. Intervening code can inspect the thrown exception as far as it is a able given the types available to that compiland. Code at the top of the call stack can view the failure detail in full, if it knows of the precise thrown type. Point is, *this scales*, and the deterministic exception mechanism proposed replicates this ability to type erase failure detail in a way fully reconstitutable by code far away up a call stack, or in another thread. This I think was a consensus opinion by WG21 (and indeed Boost) on why Rust's `Result` based design does not scale well, and why its design choices ought to be (and have been) avoided in C++. Obviously with all of the above, I am stating my own opinion only and none of the above is any formal opinion or position by any organisation or body in C++ about Rust. I wish to emphasise that as a general rule, we in C++ have found Rust's emergence quite motivating, and useful, and none of what I said above should be interpreted as an attack on Rust, which as I mentioned above, has different design principles to C++ which lead to different design conclusions. In other words, what suits Rust well may be perfect for Rust. And what suits C++ well may be perfect for C++. I hope people found the above useful.
There is no need to install Rust on the Raspberry Pi, you seem to have misunderstood /u/MrMinimal's question. You can cross-compile either with the `cross` tool I linked, or with the built-in support in `rustc` and `lld`.
Thank you @LulzCop for the correction :) Indeed, I am talking about Cortex family cores and the Instruction Set Architecture (ISA) v7. I just corrected this above to ARMv7! 
It works well on my Raspberry Pi 3. The library uses physical pin numbers and not BCM pin numbers, which should be noted in the docs.
It's more than OK but welcome. It's rare to get constructive criticism for one's code. Who has time for that? Programmers are busy people. You see this as rude? That's on you.
I don't want to get involved in holy wars here; My personal reason is that I found that Vagrant was the easiest way to install a VM on my MAC OSx and deploy consistently in different architectures (including BSD which isn't supported by docker).
Somewhat tangential question, but I've been putting off even looking at this stuff, because, a) I was still somewhat noobish, and have been learning Rust basics, but also, b) I got the impression it was still churning heavily, and that it might be worth waiting a bit longer for things to settle. since I am now moving past (a) i'm wondering if (b) is still the case, any opinions?
I have 2 raspberry pi 3. What do you testing, as I'm not very tech savvy myself
This does not work in general. If you trade correctness for performance, you might as well replace your program with hello world. You have to set a line somewhere.
I only asked you to give us a link to the discussion. If this happened in a WG21 meeting, which is what you seemed to convey, there would be minutes of it in the EDG wiki page of the paper that was being discussed when the discussion on Rust's result type happened. If it happened in a meeting of one of the WG21 working groups, that would be part of the minutes of that meeting as well. If it happened in one of the mailing lists of the WG21, there would be a link to it as well. If it happen in reddit, Boost mailing list, cpplang's slack, IRC, and pretty much anywhere else, there would be logs. Of course, if it happened privately between you and your buddies, then there aren't any logs, but then you shouldn't be saying that it was discussed a lot during the discussions about `std::expected`/`boost::expected` because all of those have logs and minutes that you can easily give us the link to. 
Using `unsafe` was not the problem. Using it in an unsound way was.
Though love is not constructive, you don't need to be an ***hole to give constructive criticism. Constructive criticism is always welcome if it's not rude.
Could you link me some kind of policy document that supports this claim? I'm currently looking at a [piece of unsafe code in serde](https://github.com/serde-rs/serde/blob/84e3841/serde/src/ser/impls.rs#L585) that trusts `Display` trait on an arbitrary input object to report the length correctly, and presents an information disclosure security vulnerability otherwise.
No, it just builds the binary for Redox. Tests are done on Linux.
At the lowest level, *everything* works like the file descriptor case- sockets, timers, etc. all need to be based on some mechanism for waking up the event loop. Everything else is just built on top of that. For example, let's look at two futures- one that works directly with file descriptors, and an `and_then` combinator on top of it that runs a closure in response to its completion. When the first future is `poll`ed (ignore who actually does that, for now), it receives a `Waker` from its caller (either as an argument or in thread-local storage, depending on the `futures` version). It tries to read from its file descriptor, and determines whether its job is complete. If it's not done yet, it stashes that `Waker` with the event loop and returns `Pending`. In the second case, it returns `Ready` with the data. The second future, on the other hand, doesn't know anything about file descriptors. When it is `poll`ed (again, ignoring who does that), it also receives a `Waker` from its caller. It then calls `poll` on the first future, *passing in this same `Waker`*. When the first future returns `Pending`, this second one does as well. When it returns `Ready`, this second one can run its closure and *then* return `Ready` itself. Thing that kicks the whole process off is when you `spawn` the second future. It gets `poll`ed by Tokio, which is what actually creates the `Waker` that both futures will use. Then the first future stashes the `Waker`, it's actually the second, outer-most future that the event loop will re-`poll` when the event happens. Together, this set of futures that share a `Waker` is called a "task." The *entire* thing is woken up when any of its lower-level/inner-most futures need to respond to an event, and the outer futures are in charge of routing that in to the appropriate place.
Some API details have churned, and a few are still churning to make way for `async`/`await`, but on the whole the basic mechanisms around futures and `poll` have remained the same. If you want to wait for the final API, I'd watch for announcements around `async`/`await` and `futures` 0.3.
Crap. What I was looking for is how to run the tests on Redox itself. For other archs I just use a cargo test runner that executes the tests via `qemu-user`, but I don't know if that works for redox or how to set it up (e.g. `qemu-system` should work).
That wasn't my intention at all. I have never used vagrant myself, and docker gave me headaches (probably because I haven't used it too much). Docker not supporting BSD is good to know.
Oh, it's not a matter of name; it's a matter of cases. The modulus operation with a right-hand side operand of N can yield N different results, whereas the remainder operation can yield twice that. There is more information in the latter result, but it's also somewhat harder to deal with.
I'm not a native speaker either, so my grasp of English is not exactly stellar either :(
It's always good to *understand* the flaws in a design, even if you can't change them at the moment.
Give Vagrant a go, for me it's a bless I getting a VM with only 3 commands.
This is a very weak definition of a dependent typing system… People seem to mislead promoted singleton types with DTs, but they’re different.
[removed]
If you don't want to talk about something, _then don't talk about it._ What you're doing is tantamount to sticking a carrot on a stick and dangling it out in front of us just beyond our reach. That's not cool.
This all has far more to do with the error types themselves than anything to do with `Result` or `std::expected`. `Result` can and does accommodate type-erased errors- for example, see the [`failure`](https://boats.gitlab.io/failure/) crate, particularly its `std::error`-like [`Error`](https://docs.rs/failure/0.1.1/failure/struct.Error.html) type. Were there any actual changes to `std::expected` itself? Or was this all the stuff you've been referring to?
[removed]
I have two questions: 1. Why did they use a linked list? Those are among the slowest data structures in existence, even when inserting midway. 2. How does it preserve type safety? I see a lot of type erasures in that unsafe piece of code. If I'm not mistaken it allows to form a linked list where every single node can have a different type, although I cannot phantom why one would want to forget the type of a node. 
I don't see where the issue is. This code is not exported, which means it cannot be called with arbitrary `Display`. The `Display` implementations that it calls are trusted to be properly implemented.
It's a very simplified answer intended for someone with no background. I don't think it's particularly misleading. The first chapter of TDD With Idris uses Matrices as the example of dependent types.
That's not immediately obvious to me from reading the code. It relies on `write!` macro to return correctly resized slice, which is a non-local invariant that I didn't dig into yet. A code comment on why that holds would be very helpful.
Those functions are really just a special case of modulo though.
`write!` macro is called on `&amp;mut [u8]`, which is not an arbitrary object.
It writes *to* `remaining: &amp;mut [u8]`, but the data comes from `value` which is arbitrary input to this macro. The `Display` implementation is invoked on the `value` - or at least, that's how I understood that code. Please correct me of I'm wrong.
Most terminal emulators will probably react to `\a` as you expect, although I have not tested them. `pantheon-terminal` in particular doesn't, probably because nobody uses bell like ever and so nobody has complained about missing functionality yet. If you want to flash the icon in some other way, you'd have to find the terminal emulator process, then get its window and do something with it, with the logic differing between X11 and Wayland... in other words, not pretty. Desktop notifications, however, are standardized and will work the same in any desktop environment. There is even `notify-rust` crate for sending them. However, Linux users already have other options such as pantheon-terminal and [undistract-me](https://github.com/jml/undistract-me/). Plus, Linux shell scripting is really powerful, the equivalent of your tool is a one-liner: `"$@"; echo -e '\a'` for the bell character or `"$@"; notify-send "Command complete: $1"` for a notification.
Are you using a separate port for the WebSocket on the back end or are you running everything (including regular http) on the same port?
That's awesome! Even if it's a long way off, it's nice to know that someone is working on it.
The use of "Nanny State" makes this article complete garbage. Not worthy of reading.
[removed]
I would say that in general, you probably shouldn't use `unreachable_unchecked` unless a profile has shown that code to be particularly hot and it's something that you need to optimize for performance. Having some unsafe guidelines for Rust is something that's been discussed before. I don't know if there are already some best practices that people follow, but what I'd probably say is that any unsafe code should have an assertion about the invariants it relies on; and only have those assertions changed from `assert!` to `debug_assert!` if there is a compelling performance reason to do so (which would be the case for most of them in lower level data structures, but might not be if it's some initialization code in a microcontroller poking at arbitrary memory, for example). The equivalent here would be to use `unreachable!` unless the code is hot, at which point using `unreachable_unchecked` is reasonable to give the compiler and CPU better ability to optimize performance.
Welcome! Some quick thoughts: 1) There's no need to wrap all of your `lib.rs` code in a `mod`, when others import your library as a crate, the crate identity will provide a useful top-level namespace. 2) If you mark a `mod` with `[cfg(test)]` that roughly means , "only compile this module for testing purposes". Non-testing code probably doesn't belong in such modules. 3) While it is passable for personal projects, using `String` as the error-type of a `Result` is not common for libraries that get put into use, since there is little programmatic recourse to decide on an appropriate remediation beyond passing the buck to the human operator. My personal go-to here is a custom error enum, but there are a number of patterns available. See also: https://boats.gitlab.io/failure/ 4) Using non-idiomatic naming techniques is also usually restricted to internal-facing identifiers or maintained for the sake of some external interop requirements.
Everything runs on the same port. The websocket Händler is available on `/ws`
Awesome! I've been waiting a long time for a rust framework to support this type of web service (all on one port).
It's probably still worth learning, because even if it is undergoing churn, knowing where it churned *from* and *why* can lead to insight and understanding for the final design. With that said, the Tokio docs are a bit too cryptic for my taste, but I was able to grok them after spending six-ish hours or so digging through (without any prior relevant experience.)
is there a more elegant way to cast a `Unique&lt;T&gt;` or `NonNull&lt;T&gt;` to `*mut u8` other than `as_ptr() as *mut _`?
Decisions avoided tend to not get minuted unless there is a sizeable faction which was disappointed. And as I've already said several times now, I am unaware of any published digest of said discussion in any single location I could refer you to.
I don't understand. You say 'I've never liked modulus returning negative integers'. I say there is no "modulus" in Rust. You can't not like it, it doesn't exist :p There is the [remainder operator](https://doc.rust-lang.org/std/ops/trait.Rem.html), which I agree is a bit annoying because the result can be negative, but I imagine it can be considered a feature that code using `%` does the same thing in Rust as it does in C, C++, C#, Erlang, Fortran, Go, Kotlin, Java, Javascript, OCaml, PHP, Ruby, Scala, Swift... I probably missed some. 
I think it would be more idiomatic to take a string slice as an input in your api pub fn parse_vars(source: &amp;str) -&gt; Result instead of a `String`. That way you don't force your user to a particular data type.
You sometimes manually unwrap an `Option`, for example in [https://github.com/pixlark/vars-parser/blob/9661df32b814826bdc101dcdf2681fb57478b70f/src/lib.rs#L274](https://github.com/pixlark/vars-parser/blob/9661df32b814826bdc101dcdf2681fb57478b70f/src/lib.rs#L274) : match vars.get(&amp;key) { Some(val) =&gt; { match val { Value::Integer(n) =&gt; { assert_eq!(*n, -15); }, _ =&gt; panic!("Integer literal didn't parse correctly") } }, None =&gt; panic!("Name didn't get parsed correctly") } This should be equivalent to ([documentation](https://doc.rust-lang.org/std/option/enum.Option.html#method.expect)): match vars.get(&amp;key).expect("Name didn't get parsed correctly") { Value::Integer(n) =&gt; { assert_eq!(*n, -15); }, _ =&gt; panic!("Integer literal didn't parse correctly") } Also, there are two instances of trailing whitespace: * [https://github.com/pixlark/vars-parser/blob/9661df32b814826bdc101dcdf2681fb57478b70f/src/lib.rs#L31](https://github.com/pixlark/vars-parser/blob/9661df32b814826bdc101dcdf2681fb57478b70f/src/lib.rs#L31) * [https://github.com/pixlark/vars-parser/blob/9661df32b814826bdc101dcdf2681fb57478b70f/src/lib.rs#L224](https://github.com/pixlark/vars-parser/blob/9661df32b814826bdc101dcdf2681fb57478b70f/src/lib.rs#L224) This could be fixed by using [rustfmt](https://github.com/rust-lang-nursery/rustfmt). You use tabs which is totally fine (preferred by me personally). But you do not have a `rustfmt.toml` file. Something like `hard_tabs = true` should be fine.
Well, `num` is a _super_ standard crate, which was previously part of `std` but made separate while it stabilised. I would include it as a dependency almost by default.
As a general point of feedback as far as the API goes, wouldn't it be better for parse\_vars\_file to not expose the hashmap here, but instead some general concept of the parsed configuration? Behind the scenes it could be a hashmap of course. My rust is still very rusty, can't comment on that :)
A crack in the hull might sink a ship outright, but thoughts and words are actually a bit more resilient than that.
Trowing C and C++ in one bucket is very thin. The C++ standard lib has a lot of primitives and the author did not mention a single one. For C, pthreads is widely used. Also, why is Rust capitalized in the heading? It is not an abbreviation. How does this have &gt;400 claps?
`%` is commonly known as the modulus operator in other languages. Googling "modulus operator" will show you as much; it seems like a synonym. So I don't know why you think it's a distinct thing from the "remainder operator"?
Sort of. They are a pretty common special case, and their special result type (you couldn't really have a `bool` result for modulo 3 or more) makes them work better with `match`, which is part of what this discussion is about.
&gt; This all has far more to do with the error types themselves than anything to do with Result or std::expected. That's the surface reading, yes, but is not accurate. &gt; Result can and does accommodate type-erased errors- for example, see the failure crate, particularly its std::error-like Error type. Very interesting. Basically a library reinvention of type-based throws + `exception_ptr` like C++ has had for ages. I appreciate it'll be hard to see the wood from the trees, but `std::error` is orthogonally designed to `Error`. Specifically, `std::error` is deliberately a pain to customise, that way we can avoid implicit memory allocation and all the other hidden overhead which comes with type-based C++ exception throws. Many thanks for the link to that incidentally, I can incorporate it into my paper, it'll hugely simplify things in the Rust section. &gt; Were there any actual changes to std::expected itself? Or was this all the stuff you've been referring to? You are perhaps missing the bigger picture. Expected started life as a full fat monadic programming framework allowing the writing of entirely monadic C++. What is to be standardised is a far cry from the original. During the weight loss, various questions were asked: Why call this *expected/unexpected* and not *ok/error*? Why choose a success-orientated design (implicit construction from expected, tagged construction from unexpected) rather that equally weighted success/failure (e.g. both tagged Ok/Err)? Why model an enhanced `std::optional` interface instead of a restricted `std::variant` interface? Why make some observers narrow contract vs wide contract? Why implement a strong valueless guarantee? None of these decisions were taken lightly. Lots of people argued - including myself - that Expected has a suboptimal design. Some criticisms were acted upon, many others were rejected. Not just Rust's experience informed those decisions. Swift's experience played a part too. The discussion during Boost's peer review of Outcome played a significant part in reshaping Expected early on, I wrote up a partial account at https://ned14.github.io/outcome/history/. In the end, the folk standardising C++ do have interests outside C++. They study prior art, and bring in case studies of what other languages do when it is salient. I know Bjarne has studied Rust in depth, he sometimes mentions what Rust does when making a comment on a proposed C++ feature. But he also mentions OCaml, Lisp, Prolog and a ton of other languages. He's a widely read guy. And there are lots of his calibre and wide knowledge and experience outside of C++ on WG21. I appreciate you guys want high quality opinions wrapped up in a bow for you to digest, but what I'd suggest instead is to attend some C++ conferences, and perhaps even a standards meeting. You'll get a font of high quality opinions on Rust stuff if you ask the right questions of the right people. But you really need to go to them, and do your own writeups digesting those verbal opinions. Writing high quality opinion is very time consuming, much more so than giving a verbal opinion. So somebody else needs to do the writing, most WG21 are at maximum capacity just keeping up with WG21 papers. That's also why I'm unwilling to get into detail on Rust stuff. Sorry.
This is technically true, but in practice I am the one who loses if I do that.
I don’t agree.
That's how I see it. Permissive says "Everyone should have freedom, including the freedom to restrain freedom." Copyleft says "Everyone should have freedom, and it's okay to not have the freedom to restrain freedom". Contributing to permissive-licensed code is just a roundabout way of contributing to proprietary software. I urge people to only do this if they're getting paid well.
For mod 3, you have three results, and `==` and `!=` convert them to bool, just the same as it would in mod 2. In fact, it is even clearer in a match statement, because you don't need to convert to bool at all: match a.mod(3) { 0 =&gt; ..., 1 =&gt; ..., 2 =&gt; ..., } The `is_odd` and `is_even` functions are the exact same thing with one less arm. They're only 'special' in the sense that we have special words for parity in base two.
I made https://github.com/polachok/toykio to understand this myself. Check it out if you like learning by reading code.
Haskell doesn't have `%`, it has `mod` and `rem`.
It also works correctly for signed numbers as well.
That feels like a slippery slope argument. Surely you can have something that's faster and works mostly as intended without resorting to hello world? 
I'm trying to create a macro for the first time, and I can't begin to understand the error: macro_rules! returnerrifwinerror { ($hn:ident, $err:expr) =&gt; { if !winerror:SUCCEEDED($hn) { return Err($err); } }; } impl SFence { pub fn waitforvalue(&amp;self, val: u64, event: &amp;SEventHandle, duration: u64) { if unsafe { self.fence.GetCompletedValue() } &lt; val { let hn = unsafe { self.fence.SetEventOnCompletion(val, event.event) }; returnerrifwinerror!(hn, "Could not set fence event on completion."); synchapi::WaitForSingleObject(event.event, duration as DWORD); } } } Here's the compile error: src\rusd3d12.rs|640 col 36 error| expected type, found `hn` || | || 640 | if !winerror:SUCCEEDED($hn) { || | ^^^ expecting a type here because of type ascription || ... || 650 | returnerrifwinerror!(hn, "Could not set fence event on completion."); || | --------------------------------------------------------------------- in this macro invocation
 let mut stream = Stream { stream: &amp;mut source.chars().peekable() }; You shouldn't need a `&amp;mut` here, as the Chars iterator already borrows the input string. The `#[allow]` declarations look suspicious. Like in C, code should compile without warnings. I would return an `Iterator` of `(String, Value)` pairs instead of a `HashMap`. That way, the user can choose what kind of map to use, or even handle duplicate keys.
This is a pretty content-free post. It makes only a very brief description of each language's philosophy, writes off Erlang as "too hard", says "Go is like Erlang, but less restrictive" which completely glosses over the critical differences between the two, and then writes off Rust (which the author writes as "RUST" for some reason?) as something that "no one likes" because "Humans are not that good with delayed gratification". Then they go on to advertise their own funny-looking language called "Ballerina". This could have been a really interesting article if it had, say, code samples of some more-or-less equivalent behavior using each language's native concurrency primitive(s) - Say one using Java's intrinsic locks, one using concurrent data structures in C#, one using message passing in Erlang, etc. and compared the performance characteristics of each one versus code complexity. That way they could have demonstrated HOW they think Erlang is more confusing than the alternative, or gone into detail with the problems they experienced writing the Rust version. Instead, it's just a bunch of complaining about programming languages the author doesn't like.
I've bookmarked this excellent article that does an in-depth tour of Tokio and futures: https://cafbit.com/post/tokio_internals/ I has been discussed on r/rust too: https://www.reddit.com/r/rust/comments/7klghl/tokio_internals_understanding_rusts_asynchronous/
&gt; Cheddar is a superset of GLSL, a shading language, that adds several features like modules, functional interface and constructs sharing.
That makes sense. The `#[allow]`s are just for development so I don't get a bunch of error spat at me when I'm halfway through writing a function. I disable them and resolve any issues before each commit. Well, except for the camelcase one, but that's just because I vastly prefer `This_Kind_Of_Convention` over `ThisKindOfConvention`, I find it easier to read.
That makes a lot of sense, thanks. I wasn't sure which one was more idiomatic, so I went with what had more utility, but I suppose it can always be converted to `String` inside the function and then back to a slice when returning.
Thanks, I wasn't sure what `[cfg(test)]` meant, but it was in the example library code so I just left it in, whoops. Tonight I'll fix everything up probably. One question: is non-idiomatic naming heavily frowned upon in the community? I vastly prefer using `This_Naming_Convention` over `ThisNamingConvention` but if it's really such a taboo I suppose I can switch over when writing Rust.
I don't have direct experience with Prometheus, but a quick search for "Prometheus monitor process (resident OR RSS)" turned up these candidates for externally monitoring the metrics of a specific process: * [ncabatoff/process-exporter: Prometheus exporter that mines /proc to report on selected processes ](https://github.com/ncabatoff/process-exporter) * [albertodonato/process-stats-exporter: Export process and task stats Prometheus metrics](https://github.com/albertodonato/process-stats-exporter) Both support matching processes by regular expression. According to [this Google Groups thread](https://groups.google.com/forum/#!topic/prometheus-users/BNAPDf2RqlQ), the "systemd" collector in node_exporter might also do the trick.
Naming is fairly uniform within the community so if you make something with the intent of sharing and/or looking for collaboration you should stick with the idiomatic way. If it's for personal use only, well who cares :)
I'm planning to create a couple worked examples towards the end where you either use a Rust library from a managed language or embed a managed language into a Rust program. The big problem I see is that it's easy for these sorts of things to bitrot and I don't want to be telling people outdated information. Another thing to consider is that once you have an understanding of the basics of FFI, working with a specific language is more or less just a case of reading their docs. One of the major things I want to do is pass on that fundamental knowledge and way of thinking so people have the necessary tools to solve things themselves. Does that make sense?
You can sorta offload this problem by using using futures mpsc , where the receiver is a stream. Then u can mostly treat the stream like an iterator
&gt; I have not yet found a way to pass those mmaps to an unprivileged process besides potentially changing the UID/GID after obtaining them Look into fd passing over Unix domain sockets.
/u/ehsanul: Well, he's technically right, despite the name other languages give it. I'd also like to note that /u/thiez is 100% justified in Rust's case, because the trait for the `%` is literally called `Rem` and the first sentence of documentation says: &gt; The remainder operator %. Docs link [here](https://doc.rust-lang.org/beta/std/ops/trait.Rem.html). :)
Another way to think about it is that Rust has had official style guidelines, some compiler enforcement, and a primary code formatting tool (rustfmt) for pretty much its entire post-1.0 existence. This has had a strong unifying effect on public APIs. That said, the point of such guidelines and tools are usually to reduce collaborative friction. If your chief collaborator (yourself in the future) can't stand a particular style, then it's reasonable to optimize your development experience appropriately.
If you turn it into a `String` 100% of the time, taking a `String` is more idiomatic. That way the user can give you ownership if they have it so as to not be inefficient. If you don't ever need to have it as a `String` though, taking an `&amp;str` lets the user give you slices/parts of a string and then still use the string afterwards too. `parse_vars` falls into this category since `.chars()` is always available for `&amp;str`.
Frankly, this doesn't really answer anything. You've chosen some different names, added implicit construction for the `Ok` variant, and removed some utility methods. None of this points to a flaw in `Result`, it's hardly even related! &gt; I appreciate you guys want high quality opinions wrapped up in a bow for you to digest... I understand it takes time to explain things, but you've been claiming things like "everybody agreed on the "obvious" mistakes in your Result." If the mistakes are so obvious, why do you write entire essays dodging the question? Why does nobody on /r/cpp have any clue what you mean either?
 These are well established languages that aren't going to dramatically change over the time that your documentation is used. So, the drift (bitrot?) ought to be minimal. People will still need to think about keeping values alive and other concerns from the dynamic language, and there is a general lack of documentation about this requirement. The Rust community is very active in bridge building related exercises. This content would be consistent with those goals. Whatever you decide to add will add value. I am sharing with you feedback on what I think would make it even more valuable. Thanks for considering.
&gt; I'm trying to implement an "strided chunks"/"overlapping chunks" iterator. [..] However, I want a mutable version! You fundamentally cannot do this. No way, no how. You'd need to ensure that the iterator is never advanced whilst a previously produced item still exists, which is impossible. &gt; How can I do this without breaking Rust's mutability guarantees? You don't use an iterator. You can write something that looks vaguely like an iterator, but which has the proper lifetimes for ensuring you can't have multiple sub-slices simultaneously. Or you require the caller to pass in a closure to which the subslices get passed. Or you change the underlying storage to contain `RefCell&lt;T&gt;`s instead of `T`s, and use the immutable slice iterator. But the specific thing you've asked for isn't possible without grossly violating Rust's safety guarantees.
&gt; Or you require the caller to pass in a closure to which the subslices get passed. Doesn't this have the same problem? Have a Vec outside of the closure, and inside the callback, push the slices you get into the Vec
The borrow-checker won't let you do that. That's what it's *for*.
I'm having the strangest issue right now, no idea what is wrong. Running `cargo build` or `cargo run` works fine (got both a library and a binary). However, when I run `cargo test`, I get `crate plex not found` inside `lib.rs`, although I've got it both under `dependencies` and under `dev-dependencies`. If I run `cargo bench`, then it keeps compiling the `lalrpop-snap` package without no end in site. Any suggestions for debugging?
Thank you for all the links. I didn't even know the keywords to search to start with. I really appreciate it :)
After looking into it some more, I understand why: https://play.rust-lang.org/?gist=1c5b3bac59a28d07dcdeb39fa4be46b5&amp;version=stable&amp;mode=debug&amp;edition=2015 On line 17, it creates a new borrow, in the lifetime of the loop body, and therefore the lifetime of the slice can't extend past the loop body? Alternatively, the compiler error implies that this some dedicated rule of closures, where borrows as parameters to closures can't outlive the closure, ever?
It's because the parameter to the closure is a new, temporary lifetime that lasts for the duration of the call to the closure. You can rearrange the lifetimes so that you *could* store a borrow outside the closure, but at that point the compiler would likely complain about multiple mutable borrows of the base slice.
Yeah, in the parameters to for_each I tried changing mut iter_fn: impl FnMut(&amp;mut [T]) to mut iter_fn: impl FnMut(&amp;'a mut [T]) and it then complained about having multiple borrows across multiple iterations of the loop.
I'm a node developer trying to wrap my head around some rust error handling. My first attempt has been to simply make a function that calls an url and returns a bool if it receives a `200` or `404`, and an error of some kind otherwise. I can't for the life of me figure out a way to get an error of some sort to be returned with a simple match guard. ```rust extern crate reqwest; // 0.8.6 use reqwest::StatusCode; fn is_there(url: &amp;str) -&gt; Result&lt;bool, reqwest::StatusCode&gt; { let uri = format!("{}", url) .parse() .unwrap(); let response = reqwest::get(uri)?; match response.status() { StatusCode::Ok =&gt; Ok(true), StatusCode::NotFound =&gt; Ok(false), _ =&gt; Err(response.status()), } } fn main() { if let Ok(there) = is_there("http://httpbin.org/status/404") { assert_eq!(there, false) } } ``` [Playground link](https://play.rust-lang.org/?gist=e53b91e931c2f87db3124bc1d9e788ce&amp;version=stable&amp;mode=debug&amp;edition=2015) I want to get more acquainted with a more lower level http library like hyper, but I thought to try out reqwest first. StatusCode implements Display and Debug, so shouldn't it be a valid error value? Also, I would probably want to more to using my own custom errors, so would a next step be implementing an Error which can be constructed from StatusCode, or try to figure out how to convert a response into a `reqwest::Error` and create an Error that can be converted from this?
Glad I could help. For future reference, the `(resident OR RSS)` I searched for refers to the [resident set size](https://en.wikipedia.org/wiki/Resident_set_size).
**Resident set size** In computing, resident set size (RSS) is the portion of memory occupied by a process that is held in main memory (RAM). The rest of the occupied memory exists in the swap space or file system, either because some parts of the occupied memory were paged out, or because some parts of the executable were never loaded. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I think you’re looking for r/playrust. You posted to r/rust, which is dedicated to the Rust Programming Language. 
I think your match won't compile, since the static checker doesn't know the actual range of the mod function. You'd need a default arm I think. On my phone so can't check right now. 
Thank you!
&gt; I appreciate you guys want high quality opinions wrapped up in a bow for you to digest, but what I'd suggest instead is to attend some C++ conferences, and perhaps even a standards meeting. You'll get a font of high quality opinions on Rust stuff if you ask the right questions of the right people. But you really need to go to them, and do your own writeups digesting those verbal opinions. Writing high quality opinion is very time consuming, much more so than giving a verbal opinion. So somebody else needs to do the writing, most WG21 are at maximum capacity just keeping up with WG21 papers. That's also why I'm unwilling to get into detail on Rust stuff. Sorry. For context, you've come into Rust spaces and made grand pronouncements about some features having obvious flaws and how C++ is taking inspiration for its future but (paraphrased) "fixing up the problems". It's *very* expected that people will pick up on this and want, at the least, some vague hints about what the flaws are. I really appreciate that you've taken the time to follow up and try to provide that for us. However this whole discussion seems unnecessarily confrontational in parts especially given there's clearly some gaps in knowledge on your part (which, to be clear, is not a bad thing, and is in fact *totally* normal and expected: you're a C++ expert, not a Rust one). It would be far better to approach this whole thing as a learning experience: people who are experts in C++ can teach the Rust experts about its design, and vice versa. There's a relatively long history of public misunderstandings of Rust by prominent people in non-Rust language communities, and this thread is fitting into that history, at the moment.
That is not portable to other terminal types. Better to use some terminfo-aware mechanism, like `tput(1)` or [the term crate](https://crates.io/crates/term).
You never need to convert it to a `String`. It [looks like you only need `chars()`](https://github.com/pixlark/vars-parser/blob/a1a07de52a927ea756e4b9f6cbfc2cf8db98b5bb/src/lib.rs#L233), and that [exists on `&amp;str` also](https://doc.rust-lang.org/std/primitive.str.html#method.chars), so you can make this function more general without changing any code ;)
You probably want /r/playrust, this subreddit is for the rust programming language.
First, start with a small rock. Then, add more rocks. Continue adding rocks until gravity forces the rock pile into a rough sphere. Now add some water, oxygen, nitrogen; whatever you can get your hands on. Asteroids may be useful here. You might also want to make sure you position your rocks around a star. You can do this by standing at a comfortable distance from the star, and then throwing your first rock sideways very, very fast. If the rock falls into the star, you didn't throw it hard enough. Don't be tempted to install life on the rock; it's more trouble than its worth.
Is there a way to restrict the returned Item's lifetime on the Iterator's `&amp;mut self` borrow? Roughly, have `fn next(&amp;mut 'b self) -&gt; Option&lt;MutSlice&lt;'a, 'b, T&gt;&gt;` Probably not expressable in today's Rust as there's no way to write the type of `Item`. But maybe this is technically possible?
&gt; Is there a way to restrict the returned Item's lifetime on the Iterator's `&amp;mut self` borrow? No. I meant it when I said it was impossible. You can define a function with this signature, but then it's not an `Iterator`. You want a "streaming iterator", which last I heard couldn't be done safely in Rust due to a lack of HKT/ATC.
...and don't even think about blessing the whole thing - This is not Perl...!
 enum Parity { Even, Odd } use Parity::*; trait HasParity { fn parity(self) -&gt; Parity; } impl HasParity for usize { fn parity(self) -&gt; Parity { match self % 2 { 0 =&gt; Even, _ =&gt; Odd, } } }
I mean, yes, but also consider there is nothing malicious a `Display` implementation can do - taking a `Formatter` and all. - It can panic - whatever, this code is panic-safe. - It can write valid UTF-8 (`Formatter` doesn't provide a way to write invalid UTF-8) to a slice. Note that it needs to pass a string to `Write` implementation, which will handle write and updating the length. That's all what `Display` implementation can really do.
Can you use [/dev/gpiomem](https://github.com/raspberrypi/linux/pull/1112) instead?
Does Rust have a modulus operator? I assumed that's what `%` was to be honest. It's upsetting that they decided to make it a remainder, given that the **vast** majority of the time you want a modulus. Now I may have to look through my code to see if I ever do something like: my_arr[x % my_arr.len()]
If you're going to go that route, an if/else would be far cleaner than a match statement.
Step 1: acquire old CD drive. Step 2: extract stepper motor. Step 3: jury-rig the stepper motor to the front of the case using USB for power and duct tape. Step 4: attach standard car windscreen wiper to motor. Step 5: use cron job to, once a month, engage the stepper motor to wipe your server. Step 6: check what a subreddit is about *before* posting, and pay attention to explicit warnings that this one in particular is not for Rust-the-game, which is at /r/playrust.
What's a "streaming iterator"? What would that look like?
An iterator where the `Item` type has a lifetime bound to the `self` borrow in the `next` method. It doesn't look like anything right now because, as far as I know, you can't do it without features that Rust doesn't have yet.
Your code could benefit from more tests. I'm not sure what is considered valid variable names in the config file format, but from `scan_name` it seems that var_name#!" is allowed, and I suspect that's invalid. 
That's intended. I don't see any reason to restrict symbols like that in the grammar when the only reserved symbols are := and "
or the expression could be rewritten as ``` match vals.len() &amp; 1 == 0 { true =&gt; ..., false =&gt; ..., } ```
Maybe [cadvisor](https://github.com/google/cadvisor) which can give you info on container resource usage?
perf is to intrusive and its going to have a bunch of overhead. if you want the processes memory usage you just need rss. if you need more detailed information you can look at proc/pid/stat, status, statm or one of the others. You can probably add something into your app that looks at /proc/self/stat or status or one of the others to get information about the process and export it whatever format you need
You can simplify the scanning if you only allow latin letters, for example. You could also possibly prevent the users of your config library from writing erroneous or possibly malicious configs. Most people expect variable names to be alphanumerics, after all. If you look closely, the variable name I gave contains the double quotes that you said are reserved. Your code also has a `#` reserved for comments, which the variable name also contains.
Completely missed that, whoops. Yep, that's definitely going on the list
I disagree, `% 2 == 0` stands in for `.parity()`, `true` stands in for even, and `false` stands in for odd. This is a switch/case/match statement not an if/else statement. It just happens to be binary, and the cleanest way to write the code happens to represent that binary enum as a boolean. Using `match` gives a better image of what the code should be interpreted as doing.
Oh my gosh this looks so cool! GLSL definitely needed a superset language the way CSS had SCSS, and to give it a functional twist is just asking for GitHub 🌟's. 
You absolutely can do this. There is simple workarounds for some HKL usecases. ``` trait StreamingIterator&lt;'a&gt; { type Item: 'a; fn next(&amp;'a mut self) -&gt; Option&lt;Self::Item&gt;; ``` 
My memory on this is hazy, but I *believe* the problem with this formulation is that because the lifetime is tied to the implementation and *not* just the `next` method, it can cause problems in generic code where you can't narrow borrows properly.
It depends on what exactly "mostly as intended" means. In this case, there was undefined behavior in a library that is supposed to be exposed to the Internet. This is likely exploitable, and any "performance advantages" don't matter at all.
Creation of an WebPortal as UI for Webassembly Apps with Rust. This was a decision about UI Lib Frustration. My First App will be my from c/c++ to rust ported software renderer.
/dev/gpiomem only gives access to a single page - specifically, the registers for the GPIO. With that, I can only perform digital I/O; it doesn't give access to the PWM generators, clocks, SPI, I2C, UART, etc. which I also plan to support.
Thanks for pointing that out - I knew there were multiple conventions for pin numbers, but I forgot to add that / thought it was the most common standard (pinout.xyz, etc)
I gave this a try and ended up with a borrow checker error that I can't decipher. [playground link](https://play.rust-lang.org/?gist=f10f2e7151261f3e74cffd8e96c5a1a9&amp;version=stable&amp;mode=debug&amp;edition=2015) ``` error[E0495]: cannot infer an appropriate lifetime for lifetime parameter in function call due to conflicting requirements --&gt; src/main.rs:30:33 | 30 | let subslice = &amp;mut self.buffer[self.pos..self.pos + self.chunk_size]; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | note: first, the lifetime cannot outlive the lifetime 'iter as defined on the impl at 25:1... --&gt; src/main.rs:25:1 | 25 | impl&lt;'iter, 'slice: 'iter, T: 'slice&gt; StreamingIterator&lt;'iter&gt; for StridedChunksMut&lt;'slice, T&gt; { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ note: ...so that reference does not outlive borrowed content --&gt; src/main.rs:30:33 | 30 | let subslice = &amp;mut self.buffer[self.pos..self.pos + self.chunk_size]; | ^^^^^^^^^^^ note: but, the lifetime must be valid for the lifetime 'slice as defined on the impl at 25:1... --&gt; src/main.rs:25:1 | 25 | impl&lt;'iter, 'slice: 'iter, T: 'slice&gt; StreamingIterator&lt;'iter&gt; for StridedChunksMut&lt;'slice, T&gt; { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ = note: ...so that the types are compatible: expected StreamingIterator&lt;'iter&gt; found StreamingIterator&lt;'_&gt; ``` I don't understand the "but, the lifetime must be valid for ..." part, especially as it says "as defined on the impl" and then quotes the entire line, but not say _which part_ of the impl.
Maybe a dumb question, but why do DNS over HTTPS as opposed to HTTP?
Thanks so much for your feedback, I totally understand how sysfs can be more safe and platform-agnostic; however, there's still a couple of reasons that people might want to use mmap instead. The main reason is performance and lack of feature support in the current drivers - I was reading a that someone else posted here, and [it was mentioned](https://github.com/raspberrypi/linux/pull/1112#issuecomment-133030649) how kernel ops are much slower than mmap and that pullups weren't currently supported (though that was two years ago and may have changed since). There are libraries in other languages that continue to support register access (wiringPi is a common example), and I think there should be an equivalent in Rust, even if sysfs is preferred for most cases. Regarding hardware changes, I do currently have to deal with differences between BCM283{5,6,7} models. Right now, that's simply a platform-specific offset for peripherals, and I can get all of the information I need from `/proc/cpuinfo` to detect the chip model. I'm unsure right now how I will support any major breaking changes to the low-level interface, but I'd probably either separate those into modules for different SoCs or write a completely new major revision for a newer model.
Or ideally: ``` if let Value::Integer(n) = vars.get(&amp;key).expect("Name didn't get parsed correctly") { assert_eq!(*n, -15); } else { panic!("Integer literal didn't parse correctly"); } ```
Working on a package for Monte Carlo integration. Rust is a nice language for this in a few ways. First and foremost: it’s fast. If I didn’t care about the speed, I’d write it in Python. NumPy would probably do a pretty good job, actually. Second and secondmost: Rust is a nice language for scientists, in certain ways. Scientists don’t want to learn to code more than they have to (for the most part). So that fact that Rust means I won’t be debugging obscure memory errors to write this library is not only great, but necessary. Third, it seems like there are some good packages out there for interfacing with Python, which is where more and more scientific computation is heading. I especially like the ndarray crate. 
You're surprised you can't do the thing I keep insisting you can't do? :P Well, first of all, it looks like you're trying to create a reference cycle, which is *never* going to work. I can't tell why the `iter` field of `MutSlice` is even there, so I removed that and combined the lifetimes. Then I had to fix a multiple borrow problem with the order you calculate `advance_amount`. Fixing those led to: https://play.rust-lang.org/?gist=4960a96d70c172cde2050e07e46492ca&amp;version=stable&amp;mode=debug&amp;edition=2015 Which *also* fails, but this time it's because the mutable borrow is outliving the `while` loop, which means you can't use the iterator more than once. That's probably because it's tying the lifetime of the iterator borrow to the lifetime of the underlying storage. You can't re-introduce the `'iter` lifetime, because then the subslice borrow is constrained to live that long because it's being *derived* from the iterator's borrow. The way to fix this is to have the `Item` type be parameterised over the lifetime of the `next` borrow, not the iterator, and now we're right back to where we started.
Using Vulkan with compat layers is a thing we are looking into but not as a fix to this problem. Inevitably we'll trade some of our current bugs with other bugs because nothing is bug-free especially when there is a complex translation layer in the middle. So there will always be things to work around, although it's true that a spectacular number of these are currently coming from GLSL compilation bugs on Mac. 
To encrypt the DNS requests. It is difficult to put that backwards compatible in DNS and using https ensures that most clients can reach the servers and don't get blocked by firewalls
We use [prometrics](https://docs.rs/prometrics/0.1.11/prometrics/) for our monitoring purposes. It doesn't have builtin HTTP metrics export, but it's pretty easy to add (thinking about it now, I should just publish our solution on crates.io).
The goal is to encrypt your connection. With regular DNS &amp; HTTP everything about your connection is in plain text, which means anyone can read along. With HTTPS only enough information is public to route packets to the right IP. DNS over HTTPS is neat because it makes a regular HTTPS connection more robust. E.g. less susceptible to MITM attacks because the initial DNS response can't be forged. (Hope I got most of this right haha; not an expert. It's probably also worth reading up on all this stuff separately).
I assume you’re asking that from the perspective of, “DNS is public, so why encrypt the channel”? DNS-over-HTTPS as well as DNS-over-TLS (also support in trust-dns), allow for hiding what you’re querying from other parties, such as your ISP or the hotel you might be staying in. Now, since SNI in TLS is currently unencrypted, and IPs for various entities are well known, this isn’t a full solution to securing and privatizing your web activity, but it’s a step in that direction. In addition, these also prevent any tampering with DNS responses, which is easy to do over UDP when DNSSEC is not being validated. In a nutshell, DNS-over-HTTPS/TLS is about privacy and authentication of the upstream DNS Resolver. DNSSEC is about authenticity of the records in a zone.
Thanks a lot for reconsidering DNS-over-HTTPS.
&gt; You're surprised you can't do the thing I keep insisting you can't do? :P Hi -- it's not like I don't believe you. I want to know *why* I can't do something, not just that I can't do it. &gt; Well, first of all, it looks like you're trying to create a reference cycle, which is never going to work. I can't tell why the iter field of MutSlice is even there, so I removed that and combined the lifetimes. I wanted to make sure MutSlice has a borrow on StridedChunksMut so that the former does not outlive the latter. That must be where the problem is coming from, I guess? (Where's the reference cycle, by the way? I tried to specify that 'slyce always outlives 'iter) Thanks in advance for your help.
&gt; I want to know why I can't do something, not just that I can't do it. Fair enough. &gt; I wanted to make sure MutSlice has a borrow on StridedChunksMut so that the former does not outlive the latter. You don't have to introduce extra fields and borrows; either the lifetimes are correct, or they aren't. At most, you'd need to use `PhantomData` to "use" the lifetimes and tell the compiler what the type's variance is. &gt; Where's the reference cycle, by the way? Actually, I was wrong; there's no cycle. But you *do* have both `MutSlice` *and* the iterator borrowing the slice at the same time. You can reach the elements of the slice through both fields of `MutSlice`.
While I still don’t see it as a big benefit over DNS-over-TLS (security wise), with the H2 library being available, it was a fairly straight forward change to pull it in. People seem to really want to play with it, so we’ll see where it goes. I still have some other concerns about the long term, and what happens when web servers start monkeying with DNS when the connections might be shared between web requests and DNS requests, we’ll see what happens with that.
Alternatively, derive PartialEq on value and just assert_eq!(vars.get(&amp;key), Some(&amp;Value::Integer(-15)));
Sorry about that, I've updated the post with more detailed instructions.
Just gauging interest: Would anyone like to use printable rust worksheets to do exercises on paper? (Not sure if this fits the post, but didn't want to create a separate one)
[removed]
Rust is a perfect language which can provide both speed at runtime whilst keeping development time low - the latter is something C and C++ are terrible at.
&gt; but when I write high performance numerical simulations, I find Rust to work quite well thanks to its flexible and efficient data structures, type safety and expressiveness, and ability to control memory allocations. Are you able to share any examples? 
[removed]
[roguelike summer jam week 04](https://github.com/Lokathor/roguelike-tutorial-2018/blob/master/lessons/week04.md) This week: pathfinding and lifetime juggling.
This is the best solution.
That makes sense. &gt; And as I've already said several times now, I am unaware of any published digest of said discussion in any single location I could refer you to. FWIW, this is not the impression I got from your other comments _at all_, so I apologize for nagging into this. I thought that the material would already be available somewhere and really wanted to give it a read.
I’m happy you like it. It needs a loooooot of other things to make it completely usable. My first plan is to add to the `glsl` crate a semantics and type checker. It will benefit people using raw GLSL and people using Cheddar (and it should open the door to SPIR-V transpiling).
Sadly the experience of developing with Rust in an HPC environment is horrible.
If you need some process information, some crates exist already like [sysinfo](https://crates.io/crates/sysinfo).
Super nice! Your site however has some UX problems, first of all that it violates Fitt’s law: You should max the clickable area in your header: Make the whole area around the symbols clickable (There should be no unclickable pixel in the header) and highlight the hovered symbol. Also why not show some textual description of the header links when the viewer’s screen is big enough?
Because I suck at website UX, that’s why. Thanks for the feedback, I’ll address that! \o/
Thanks. I got rid of the `iter` field so MutSlice is basically just a wrapper around `&amp;mut 'iter [T]`, so I got rid of it as well. The code now is basically the same as your version except for that impl line ([playground link](https://play.rust-lang.org/?gist=a1623acd2c964663e23a8486e1d991be&amp;version=stable&amp;mode=debug&amp;edition=2015)), and it still has the same error from before. Could you help decipher it?
Remainder is identical to modulus for unsigned numbers, so your code example is still correct. It only gets messy in the presence of negative numbers.
The fact you don't know how doesn't make it impossible. You need to apply trait bounds like this: `T: for&lt;'a&gt; StreamedIterator&lt;'a&gt;` Now it is possible to call `next` with any lifetime, including those internal for a function.
The problem is that in `next` you try to borrow both subslice and entire self mutably
I like to look at meltdown/spectre as an example. Those were vulnerabilities that allowed data leaks to occur, but were fixed by disabling functionality. Rita fixed the exploitability problem, but also had a significant performance impact. It's good to know that your code will run X% slower as a result of said fix so you can accommodate for it, and I don't understand why it should be any different for actix-web.
I am still working on [azul](https://github.com/maps4print/azul), my GUI library. I did a [presentation](https://docs.google.com/presentation/d/12adMyK81Siv9auXEOBOGzcXXYh8BHWC71mfwunhCwLQ/edit#slide=id.p) about it last Friday at a Rust meetup. My largest problem right now is that OpenGL doesn't play nicely with webrender, which breaks the SVG renderer when rendering more than one frame. I hope I'll be able to do text rendering in SVG or basic layout this week. Layout is fun, now that the DOM works correctly, text rendering sadly not so much.
It took quite a long time to return back to this library project. Any comments/recommendations are appreciated.
Ah, I get it now. Thanks a lot for the explanation!
You're way over focusing on the Expected &lt;=&gt; Result equivalence. I'm telling you that we *specifically went out of our way* to make them highly non-equivalent because we didn't want to repeat Result into C++ at that time. In other words, Expected looks like Expected and not Result because we didn't get consensus on Result, and more specifically, *what Result would mean*, but we did on Expected. Does that make more sense? You may view my responses as "dodging the question". I would view them as illuminating what the actual problem domain really is, which is not the one you are asking. I appreciate it's frustrating. You should be aware that such responses are literally what a WG21 meeting is, for sixteen hours per day, for six days, four times a year. Regarding why nobody on /r/cpp/ appears to have a clue of what I am talking about, there are two parts to that. Firstly you're not seeing those who don't post. Most on WG21 monitor /r/cpp. They've gotten badly bitten in the past by not doing so e.g. Graphics, which was basically killed by a /r/cpp campaign. But only a few ever engage, and a very few engage widely. There is a perceived problem of low signal to noise ratio which I personally find short sighted, but it is what it is. Secondly, there is a lot of specialisation in C++. A large majority on WG21 do not understand this specific specialisation, firstly it's very new, only been around a few years, and secondly they have other concerns and other priorities to tend to, and it's not worth their time to invest the effort to understand every niche, so they don't. So, like everybody, they rely on the arguments of those who are domain experts in a given specialisation, and trust that they are right, which they usually are. And there's only a handful of us involved in advancing error handling in C++, I just looped in a few more from WG14 these past few days, and together we'll see if we can arrive at a consensus on a common plan forwards. If relevant people from Rust wish to participate too, they are welcome.
I am sorry if I have come across as confrontational. I appreciate that the demand for more, better written, information is a constant in all software development. It's essentially the high quality documentation problem, where the main problem is the lack of communal investiture in writing decent documentation, which forces rediscovery costs upon the whole industry. But you must also be aware that my work contract has zero time for any of this. I do all of it, everything, on the train to and from work, with maybe an hour grabbed just before sleep each night. Weekends are exclusively for family. So I appreciate the frustration with me not being more forthcoming, but I just don't have the spare bandwidth, sorry.
Snapdragons are ARM chips and Rust supports cross-compiling to that environment. A mobile _operating_ system is quite a different beast though, it needs device drivers usually only available in binary and just booting a phone isn't the simplest thing. So, expect that none of the options mentioned supports it out of the box and I don't know of anyone who tried. Probably, the best way to try things out is to build a small android app and load a Rust library into it. Find a detailed guide here: https://mozilla.github.io/firefox-browser-architecture/experiments/2017-09-21-rust-on-android.html That being said: if you want to get your hands dirty on that and would like to try that out, I'd be very interested in progress reports. 
I think it would be rather confusing, if there exists a macro and a non-macro version of println. But if you'd appreciate to have one, you could use this fn println(s: &amp;str) { use std::io::Write; use std::io; let stdout = io::stdout(); stdout.lock() .write(s.as_bytes()); }
Thanks! I won't do that I just wanted to know why :)
On a side note, how do you reckon we can get round the SNI problem?
&gt; pullups weren't currently supported The last time I checked they were supported.
https://boiethios.gitlab.io/blog/2018-06-21_GATs_iterators.html this is a good article explaining why it can't be done* in current rust (and should be doable when GATs are available). * as a normal Iterator. as /u/Quxxy said it can be worked around
Working on [rpds](https://github.com/orium/rpds/) (a crate for persistent data structures) to add support for [parameterizable containers of the data structure elements](https://github.com/orium/rpds/issues/36). Normally you would put the elements in an `Arc`, but after implementing this you can use `Arc`, `Rc`, or "`Owned`", where `Owned` means exclusively hold the element, and clone when needed. The `Rc` can improve performance if you don't need to share the data structures between threads. The `Owned` container can improve performance if your elements are cheap to clone (e.g. integers, etc). Note that this is just the container of the elements. The links between nodes of the data structures will still be `Arc` for the time being ([there is an issue for that](https://github.com/orium/rpds/issues/7)).
I'm going to implement custom taxonomies for Gutenberg, as shown in https://github.com/Keats/gutenberg/issues/246
Took me a moment to realize the ingeniousness of the name :D
Continuing the thermodynamic temperature vs. temperature interval saga in [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis). But this time I have a [PR](https://github.com/iliekturtles/uom/pull/96) with a lot of the work done. There are rough edges, but the end is in sight.
I think the author meant it as a compliment. "No one likes a nanny state" should be read as "Rust is not as popular as it deserves to be, because too many short-sighted devs are annoyed by Rust's strictness, instead of appreciating the immense power they gain from that strictness."
I am not sure if you intended to write all of the code from scratch as a learning experience, but crates.io has libraries like nom that you can use to write good and fast parsers with much less effort. Typically a parser combinator library is used in Rust to do parsing like this. A few others exist that I haven't tried, but nom is currently the most popular.
I'm slightly surprised to see that be the case for both debug and release!: [https://play.rust-lang.org/?gist=8255e44c2d1f13f5b74bef94580891ae&amp;version=stable&amp;mode=release&amp;edition=2015](https://play.rust-lang.org/?gist=8255e44c2d1f13f5b74bef94580891ae&amp;version=stable&amp;mode=release&amp;edition=2015)
Thanks. I am not able to write drivers for the devices on the phone, though I thought, at least writing to the VGA memory in text mode should be possible as far as I understood what's written in the link I provided. The ideal short term goal for me would be: - root phone - install / config boot loader - boot "medox" (mobile rust os) from an external SD card (VGA Text mode), like I'd would boot any other live system, or installation routine. If that would work, a Installation routine would be written, to install a rust fs ie. TFS (ticki), to the internal SD. However, I am not a good programmer, and would have trouble at every error message I see. I'll make a github repo with an experience blog and let you know. 
Well, you didn't want to be *"at the mercy of the optimiser"*. =) Also, I specifically showed a code example that triggers `panic!`s on debug mode, so you can use fuzz testing or clever unit testing to ensure that there is indeed no way to trigger UB where you use that function. The price one pays for hand-crafted optimisations. Or rather... the price one should pay.
There’s a sample app on the actix web site - might be in the examples page - with user with authentication/authorization if you’re interested in looking. The developer keeps it up to date with actix web releases
VGA is an old video standard that was only ever available for x86 PCs. As far as I know, there isn't any ARM graphics hardware that supports it.
Thanks for pointing to that crate. That would be useful to expose some specific business metrics of the services
That would be very useful for sure, given we use containers to deploy already.
It also exposes process metrics with [https://docs.rs/prometrics/0.1.11/prometrics/metrics/struct.ProcessMetricsCollector.html](ProcessMetricsCollector)!
&gt;Well, you didn't want to be *"at the mercy of the optimiser"*. =) I already explained in my reply, that emphasis was on when I can **easily** avoid it, and that I don't consider `unsafe` an easy solution. &gt;Also, I specifically showed a code example that triggers `panic!`s on debug mode, so you can use fuzz testing or clever unit testing to ensure that there is indeed no way to trigger UB where you use that function. The price one pays for hand-crafted optimisations. Or rather... the price one should pay. This is not an idiomatic use of Rust's unsafety isolation feature, and it would fail review in a serious Rust project. A function should only be safe if it can't be used in a way that can trigger undefined behavior. A user can call this somewhere, and either forget to test in debug mode, or testing in debug mode just doesn't trigger that specific path of execution, while real-world use could, causing undefined behavior. Therefore, it should be marked unsafe, so when the user tries to call it, they are forced to do it in an unsafe context, where they are aware that it can cause undefined behavior if used in the wrong way.
Ah. That's bad. So without a graphics driver for the chip in the phone, there's no way to display anything? How would one write a driver outside the system? 
Realistically, you don't. Unless you're the sort of person who is able to reverse-engineer graphics chips without documentation. There are open source reverse-engineering attempts for some of the more popular mobile gpus, but even these aren't very complete. Pretty much everyone with these devices is using the closed drivers provided by the device manufacturers. But these usually only work with android.
DNS-over-HTTPS is badly named, as the specification requires HTTP/2: HTTP/2 [RFC7540] is the minimum RECOMMENDED version of HTTP for use with DoH. The messages in classic UDP based DNS [RFC1035] are inherently unordered and have low overhead. A competitive HTTP transport needs to support reordering, parallelism, priority, and header compression to achieve similar performance. Those features were introduced to HTTP in HTTP/2 [RFC7540]. Earlier versions of HTTP are capable of conveying the semantic requirements of DoH but may result in very poor performance.
Well, you can at least [put postmarketOS on there](https://wiki.postmarketos.org/wiki/HTC_Desire_HD_(htc-ace)) to get a non-Android, regular GNU Linux. Look into porting [EFIDroid](http://efidroid.org), it would allow you to make your new custom kernel as an EFI binary instead of… whatever very-Linux-like-thing LittleKernel expects. I think it might offer the EFI framebuffer API (UGA or GOP), so getting stuff on screen would be easier.
Some of those limitations, even for associated types, could be lifted if it automatically used Box to add them to the heap. I couldn't think of too many issues with doing that, since you can't know the type in generic code anyways. Profile guided optimization could be used by the compiler to decide if its better to box something and add it to the heap and make it dynamic. It could also elid the move to heap if you only use Sized things to access references to it, like using a reference raw or using an index to get a reference to the generic value from a slice.
I see. So unless there is an open source GPU manufacturer the is no chance to write drivers for proprietary chip designs without criminal intentions. Maybe a stupid question, but why aren't the Chinese trying to develop their own chips? There's a never ending dependency from a handful of chips manufacturers while hundreds of car manufacturers compete globally.
I never got why so many languages exclusively use symbols for operators instead of meaningful keywords like the above where appropriate.
Well, yes, the function should be marked `unsafe`. The basic principle stands, though. And as you don't consider `unsafe` usage to be an easy solution *(rightfully so)*, I guess your only option remains to be relying on the optimiser and good ol' `unreachable!`. Or using the catch-all match arms in a way that does not communicate the intent properly.
Is it possible to install a CPU/GPU emulator for open source chip designs and write a driver for the emulator until a real chip of that open source design is built into a smartphone?
In most cases that won't actually be faster than `unreachable!`, LLVM is good at eliminating dead code and the CPU is good at predicting branches. `unreachable_unchecked` is for very specific circumstances where profiling shows that it's necessary and you have carefully audited the code to ensure that the relevant invariants are upheld. `unreachable_unchecked` is not just unsafe, it's the single most unsafe construct in Rust. There is literally no predicting what would happen if you ever reach an `unreachable_unchecked`, it's immediate undefined behaviour. The best-case scenario is that you start executing random memory and get an illegal instruction exception. 
I don't think its illegal to attempt to write GPU drivers for closed chips. It's just very difficult as they are complicated and undocumented. I believe the Chinese are making their own chips. Off the top of my head there is MediaTek[0] which is Taiwanese not Chinese. But I don't think they care much about releasing open driving either. I think making chips is just more difficult than making cars. If I really wanted I could probably learn all the engineering techniques necessary to make a car, even if I couldn't then mass produce them profitably. But there are probably only a handful of people who really understand how modern (e.g. 14nm, 10nm) CMOS processes work. They are creating transistors that are only ~200 atoms across. That's pretty crazy. That said, I agree that economically it's a problem that we depend on so few manufacturers. I hope that as Moore's Law slows down, and we unable to get speed gains in processors so quickly, the upside will that more companies will be able to compete and bring prices down. [0] https://en.wikipedia.org/wiki/MediaTek
A struct containing an enum and the type would be better since the type would always be bound the same.
I totally understand where you're coming from: time and energy for volunteer work is a very limited resource, and it's definitely something I struggle with. I wanted to try to emphasize the good parts of a conversation like this (enough humility, and everyone gets to learn, yay!), and avoid the bad bits (too much arrogance/unclarified-pronouncements, and everyone gets annoyed, and nothing productive happens). I'll also note that my experience is that everyone is always very busy, as I'm sure you know, and so people who are active experts in one area usually aren't able to become true experts in other area. In particular, it has come up several times that prominent people in other language communities have inaccurate conceptions about Rust (and Swift, too), as I'm sure Rust people have about C++ too. That is, just like what a Rust person says about C++ may not be quite right, what C++ people (even the "heroes") have said about Rust may not be fully accurate and should be used as guidance rather than a definite (I'm sure it's approximately right, but they may've missed details, such as `Result` being used with type erasure, as mentioned above).
The Chinese are, see Huawei. But it is still proprietary. Open sourcing something like a GPU or SoC worth billions of dollars is not what any company would do, and most individuals can't afford it.
It didn't come across that way. It just sounded to me like an uninformed dismissal. I regretted reading the article as I felt it had nothing useful to say. The "Nanny State" thing reminds me of .... never mind....not going to go there.
A clippy lint for using `%` on signed numbers, telling you to use either `.rem` or `.mod` might be a good idea.
Does this allow using `concat_idents` to actually generate an identifier?
On approach taken in this situation is to extract the binary blob of the driver from an existing installation and build your OS around it. This still means that you need to figure out how to use the driver properly. This is an approach that for example CyanogenMod takes, if I remember right.
&gt;Or using the catch-all match arms in a way that does not communicate the intent properly. I don't think it's so bad. `% 2 == 0` is a very common way to check if a number is even or odd. In fact, [that is how the `num` crate implements `is_even`](https://rust-num.github.io/num/src/num_integer/lib.rs.html#558), and `is_odd` is just `!is_even()`, which is effectively the same as if you hand rolled an if-else expression, or a match expression with 0 and `_`.
Send bugs upstream! Often people don’t know. 
Yeah this is a bit unfortunate. Often if the crate is just providing some algorithm(s) or data structure(s) it should work just fine, but if it's more involved you definitely have to just try it out and see if it works. And even if it compiles, that may not be an indicator as some algorithms spawn threads which doesn't error until the code is actually running. Maybe we could create a list of crates that have known support for wasm?
I am currently using this and i am really happy with it :) there is also an implementation for \`fcm\` and \`webpush\` from the same authors and its working well together. 
so you think, even though risc-v is open source, the usual supects will use that to make their own prorprietary chips based on the risc-v architecture, at the end only a few will produce chips for consumer products? How different will be RISC-V 'based' chips, that are further developed by companies? 
Replies, of any kind, written in less than five minutes can come off with the wrong tone. Almost all my Reddit contributions are made when waiting for build or test for example. So they're always very rushed, incomplete, and often too long, perversely enough, because I didn't have time to make them shorter. The older generation than I will tend to write or reply nothing if they don't have the time to write something well. That's where the insistence at WG21 on everything being a formal paper comes from. I'm more of the opinion that it's better to write *something* poorly than nothing at all, even those it raises hackles, offends people, and causes annoyance with perceived arrogance or grand standing, when really it's more lack of any editing and often consideration for wording at all. FYI it looks like WG14 are not liking the _Either proposal. The metatyping is the main issue. They're currently debating between "go large" i.e. add deterministic exception throwing to C, and therefore to all POSIX. Which is just so huge I really struggle to imagine what such a change would mean. And then there is the opposite of "go small", which is basically adding direct support for manipulation of the CPU's flags register. We'll see how it bubbles out.
This should be the top (correct) answer.
https://tools.ietf.org/html/draft-ietf-tls-sni-encryption-03 discusses the issue in depth, draft 2 and earlier of it also had proposals. It's not clear if they were removed because they were disliked or if it was a document focus type thing.
stupid me. I am having a Gigaset GS170 smartphone now. It's running on a MediaTek. Are MediaTek chips a complete new design, or based on x86? Crazy world we live in. Gigaset was part of Siemens, then sold to an Chinese Investor. The most important thing the CPU is a Taiwanese design, and the model Gigaset is manufactured in Bocholt, Germany. 
I'm primarily a network guy and protocol wise I agree it's dumb; TLS is the clear answer and HTTP Sisn't providing value. In the enterprise networking world though TCP 853 is unlikely to be opened everywhere anytime soon whereas TCP/UDP 443 is already open anywhere that wants to let you out already. It's also unlikely in place content or security filters will be supporting DNSoTLS quickly whereas HTTP/HTTPS filter rules are done every day as is. I get it, it's dumb, no problems are actually being solved by doing it this way, and things are just shifted around for the convenience of what can be done now vs what can be done right. The same problem exists with NATing the hell out of IPv4 instead of switching to a better protocol yet IPv6 hasn't went far in the last 20 years (outside of mobile phones). Unless it becomes a direct problem for anyone in the middle DNSoTLS is going to have a hard time being fully rolled out and people don't like when something only works at some places.
Short answer: No, though other macros could. Long answer: To allow a macro to be eagerly expanded using `eager!` it must declared with `eager_macro_rules!`. Since `concat_idents!` is not, it won't work. Though other macros, declared in the right way, may generate identifiers. The documentation has an example showing a struct who's identifier is generated by a macro. Implementing `eager!`-support for `concat_idents!` should be easy, but you'll have to get it through the RFC process.
Very cool!
This makes me wonder if there should be more visible documentation on how crate authors can effectively offer a nostd mode for their crate (best practices, common conventions, known gotchas, etc). I am interested in making my crates usable in environments like wasm32-unknown-unknown, but i'm not really sure where to start
Gotcha. 
Usually the first step to port OS to some ARM chip is getting working serial/UART/RS232. So you can see output of program/os running on ARM via minicom. Though if you using not debug board, like rasberry pi / beagle board and so on, you need to find rs232 pins on the board and manufacture some kind of connector for these pins.
Most of my use cases center on digital IO (turning a switch on / off, or doing RF transmissions), and so I have helped transition a couple libraries from /dev/mem to /dev/gpiomem, so they no longer depend on root access or workarounds. You might consider that as an option — letting users leverage gpiomem when possible and only requiring root access for additional functionality.
You don't need *nostd* for wasm, std works fine. Just don't start threads or sockets or access filesystem. For example, don't start Rayon thread pools on wasm. That was about the only thing preventing [oxipng from working](https://github.com/shssoichiro/oxipng/pull/112).
Ahh so it is being worked on, nice! I think once this is sorted the world of snooping will be really shaken up.
If you're going to quote IETF RFCs use IETF terminology as "RECOMMENDS" definitely does not mean "requires". &gt; 1. MUST This word, or the terms "REQUIRED" or "SHALL", mean that the definition is an absolute requirement of the specification. &gt; SHOULD This word, or the adjective "RECOMMENDED", mean that there may exist valid reasons in particular circumstances to ignore a particular item, but the full implications must be understood and carefully weighed before choosing a different course. https://www.ietf.org/rfc/rfc2119.txt
I'm having a bit of trouble figuring out if an `unsafe` operation is safe. I have code like the following: enum Storage { Small(small::SmallString), Static(&amp;'static str), Dynamic(sync::Arc&lt;str&gt;), } pub struct Text&lt;K&gt; { storage: Storage, _kind: marker::PhantomData&lt;*const K&gt;, } The `K` parameter is only used for validation of the stored value. I'm now wondering how to go from `&amp;Text&lt;T&gt;` to `&amp;Text&lt;U&gt;`. For example, to go from `&amp;Text&lt;Identifier&gt;` to `&amp;Text&lt;Title&gt;` after verifying that the identifier value is a valid `Title`. I know that this should be doable via pointer cast. But I'm unsure on how to make sure that it actually is safe. Is there anything in here that could make the structure casting incompatible, such as unexpected layout changes? Does it make sense to use some fixed layout to achieve this? Intuition says that it would be like casting `&amp;Storage` to `&amp;Storage` (a no-op) since `PhantomData` is a ZST. But I'm not sure my intuition holds.
Another very big thank you for making these lists every week! It makes following Rust in detail a lot more accessible! I'm personally interested in Update from Rust Core, New and Approved RFCs and final comment periods.
There's some internal discussion around this; many people want the "portability lint" to replace the core/std split. If that happens, then best practices will change, so we're waiting on that to sort out before documenting it more. &gt; i'm not really sure where to start $ rustup target add wasm32-unknown-unknown $ cd to/my/project $ cargo build --target wasm32-unknown-unknown and see what happens.
i would fully support a "portability lint" as the solution to this kind of problem! maybe as a *separate* issue i'm also looking for more documentation on when/how/why to write a nostd capable crate. regarding your quickstart guide there (cargo build with the wasm32-unknown-unknown target) -- that's only half the story, right? i would still need to maually write javascript support code to load and execute my wasm code? (it would be **really cool** to be able to do `cargo test --target wasm32-unknown-unknown`)
The compiler does that anyway.
&gt; that's only half the story, right? i would still need to maually write javascript support code to load and execute my wasm code? Only if you want javascript to be able to call your library directly; anyone who is using your library via Rust is just fine. Think of it this way: If I want to use the `rand` crate from JavaScript, I need special bindings. But if my library depends on `rand`, it's just Rust code calling it, so nothing special is needed. Also, for *that* case, you don't even need to write the stuff by hand: https://github.com/ashleygwilliams/wasm-pack has got your back. &gt; (it would be really cool to be able to do cargo test --target wasm32-unknown-unknown) Yeah; hopefully sometime soonish. We'll see!
An implementation of the [feedly API](https://developer.feedly.com/) ([gitlab](https://gitlab.com/news-flash/feedly/blob/master/src/api/mod.rs)). Started to rewrite some components of my [rss application](https://jangernert.github.io/FeedReader/) in Rust. If all goes well, I'll try to rewrite the whole thing. Not happy with the original code anymore.
I'm looking for a combination of crates to display an image to the screen on pre-metal OS X and wasm32-unknown-unknown using as much shared code as possible. It's my strong preference not to use emscripten. Any suggestions? I'm looking at gfx-rs but a) I can't get the demos to work on gl and b) I was hoping for something a bit more high level.
Serously,the only advantage would ne bypassing some firewall, but at the cost of losing state of the session..
This is awesome!! I've always thought GLSL's imperative nature betrays the true nature of the GPU. That is parallel pure functions on vector data. A push in this direction is refreshing! REGL is in similar spirit for JS, but doesn't implement a custom language. Another thought. Could something like Cheddar be lifted into Rust as a DSL instead of an opaque string? This would offer a better development experience with autocomplete, linting, type checking, etc. Basically all the RLS goodies :D
More work on [ggez](https://github.com/ggez/ggez/), a lightweight 2D game framework in pure Rust. Last week involved getting out the ol' code mop and scouring the edges of the codebase for dust bunnies and spiderwebs. Drawing got a bit simpler, mouse and keyboard API's got more consistent (and introduced a couple of issues), and I started working on making hidpi support actually work *properly*. It's going to be a bit of an uphill battle, because what users want (ie, if you ask for a window that's 800x600 pixels you get a window that's 800x600 bloody pixels) and what OS's want to provide (ie, on Mac Retina devices, a window that's 1600x1200 pixels) doesn't line up very well. Unfortunately, neither of these are the Objectively Right answer (of which there are several, such as asking for a window that's 1/3 the size of the monitor it's on) so it's probably going to turn into a horrible pile of fudge factors and un-fudge factors. I'm trying to implement this pile of hacks in `winit`, and the `winit` maintainer would quite sensibly prefer `ggez` does them, and in general [no-one ate dinner that night](https://www.youtube.com/watch?v=w7lj9qI8VFc).
It *could* but I will not invest my own time in this because I prefer having my executable compiled and running and “tweak it on the fly” with `warmy`. I used to think like you but the day I decided to use hot-reloading, I became way more productive and I will not change my mind, especially for dev. purposes. However, that could be planned for release code and I’ve always wanted to achieve something like that. It’s doable.
Holy reloading! I just assumed hot-reloading wasn't possible in the Rust ecosystem yet. `warmy` looks fantastic; nice work :) Totally agreed on the emphasis of developer experience if you have to make the trade off. A release mode would be cool, but I could see there being undesirable override maintaining two parallel APIs -- even if they are isomorphic. Perhaps we won't have to make the trade off in the future if proper hot-reloading for Rust code happens. But that's of course a big "if". Anyways, I'm excited to try Cheddar out when I get the chance. Rock on :D
&gt; How do you approach finding compatible crates? Just check if the crate is `!#[no_std]` or has a feature to become `!#[no_std]`. If it does, it should often work without issues (unless it uses `libc` to do `std`-like stuff when compiled as `!#[no_std]`..
&gt; You're way over focusing on the Expected &lt;=&gt; Result equivalence. I'm telling you that we *specifically went out of our way* to make them highly non-equivalent because we didn't want to repeat Result into C++ at that time. You're the one who made claims about the `std::expected` &lt;=&gt; `Result` non-equivalence. I'm only asking you to clarify what you yourself said, and continue to say! Instead, you spend pages and pages unable to tell me a single thing you "went out of your way" to do to the `std::expected` type itself, except to rename things and remove some methods. If that's really all you did, then I see no problem with my original suggestion that you use the same terminology for `Result` and `std::expected` *instead of "monad"*- even if the idioms and use cases are different, they're still both generic, two-variant sum types. And if the "obvious problem with `Result`" really is more about the difference in approach to error type erasure, then I see no problem with talking about *that* candidly, instead. It's something the Rust community thinks about a lot!
Hey Steve, Your comment made my try it out one one of my libraries which have cfg on windows/unix specific things. While the library compiles fine, the binaries it comes with do not. This makes a build without `--lib` fail. I tried to fix it by adding `#![cfg(any(windows, unix))]` to the binaries but then the compiler complains these bins do not contain a `fn main()`. What is the right approach here? Perhaps I don't need to do anything as if you build for wasm then the binaries won't be compiled, only the library. Still cfg'ing out the binaries/examples for unsupported platforms is kind of awkward. Perhaps rust can be taught that cfg'ing out a binary doesn't make it complain about a missing `fn main()`? Thanks!
The same way that you have `Stream::next` implemented with `unwrap_or`, you could implement `Stream::peek` with `map_or` self.stream.peek().map_or('\0', |c| *c);
Is there gonna be a Livestream or recording of the talks? I would very much be interested, but can't possibly join.
I have an android smartphone and run a rust version on Termux.
I guess that means that you could implement a custom concat_idents as a proc macro and this could allow it to work in ident position
The other thing to point out is that Redox hasn't been fully ported to arm yet. There were people working on trying to port it the raspberry pi. [https://medium.com/@wizofe/rsoc-porting-redox-to-aarch64-0x01-3dee87644c97](https://medium.com/@wizofe/rsoc-porting-redox-to-aarch64-0x01-3dee87644c97)
I'd add #![cfg(not(any(windows, unix)))] fn main() { panic!("This platform is not supported by the binary."); } and leave it at that.
On the other hand, often people don't care. I wouldn't expect a crate to want to be `nostd` unless it specifically said `nostd` on the tin.
I'll work on my [netlink library](https://github.com/little-dude/netlink). I'm starting to see the pieces coming together, and by the end of the week I expect to have significant coverage for link manipulation (`ip link [..]` commands). After that, I'll probably make a post on r/rust asking for contributions, because there is still a lot of stuff to do for addresses, arp tables and routes manipulation.
Sometimes, making it work is as easy as adding the #[nostd] attribute. It really just depends.
I can't share any code, but things like: * Efficient ordered data structures like `BTreeMap` and a reverse indexed `Vec` + binary search * Fast allocation-free matrix-vector multiplication using `nalgebra`'s fixed-size matrices * Compile-time dimension checking/math using `typenum` (soon to be replaced by language-level integer generics) * Easy and efficient multithreading using `rayon` without having to worry about memory issues * Zero-cost bidirectional conversions of structs of named fields into a single backing array * Easy reuse of large thread\_local `Vec`s between iterations, avoiding allocation and zeroing
I have a crate with a lib and some binaries. In my `.cargo/config` I specify `-Clto` because these programs needs to be fast! One of the binaries does `#[macro_use] extern crate serde_derive;` and it fails to compile: error: cannot prefer dynamic linking when performing LTO note: only 'staticlib', 'bin', and 'cdylib' outputs are supported with LTO error: aborting due to previous error error: Could not compile `serde_derive`. Some websearching suggest I use the environment variable `CARGO_INCREMENTAL=0` which doesn't have any effect. How can I fix this? Or at least can I just disable LTO for only the binary that uses `serde_derive`? 
CloudFlare, and similar load balancers. Check out the 'What isn't fixed with TRR' section of the Mozilla post on TLS over HTTPS: https://hacks.mozilla.org/2018/05/a-cartoon-intro-to-dns-over-https/
Is there a straightforward way to create a static/const HashMap? 
&gt; Can your crate expand macros that don't use your conventions eagerly? If you could we wouldn't even need crates like these! Right? 
I'm still missing it.
Nice, just ordered it myself.
I'm working on a binary space partition programme and have run into the classic recursive struct problem. I've got a left and right leaf which need to be mutable, and each recursively update. That part's working ok, but I then can't do anything with the output because I've already moved the struct, ie root.generate(); println!("{:?}", root); // err: use of moved value and I can't implement `Copy` because I'm using `Box`. Any tips on how to get around this? [Playground link](https://play.rust-lang.org/?gist=c7309ac212c4d30300c217a4f91f50aa&amp;version=stable&amp;mode=debug&amp;edition=2015)
Why not call it apns2-client or something? The current name seems meaningless to me. 
Read both words out loud: cheddar, shader
Working on https://github.com/rbalicki2/jsx_compiler , which is a nightly-only proc macro that compiles jsx to HtmlToken's. I presented on it at Rust NYC (https://docs.google.com/presentation/d/11KK06J-p-Q2XLg1VW7GK02rSCn3z-pvfKf59WMxNirA) last week. Next step is to hook it up to an (existing, just probably not-super-ideally designed) wasm connection to get a demo React-in-Rust (ish) wasm app going. I'm very excited about it!
It's tricky to write a fully generic "StreamingIterator" trait, without ATC, but it's easy to write a concrete streaming iterator: [Playground Example 1](https://play.rust-lang.org/?gist=220dc05188afd0378d80d9cc376245a9&amp;version=stable&amp;mode=debug&amp;edition=2015) You can even make this a trait pretty easily, if you don't mind the trait being limited to returning items of type `&amp;mut T`: [Playground Example 2](https://play.rust-lang.org/?gist=2ea0892231a5e016e3d09fe5f4193b6e&amp;version=stable&amp;mode=debug&amp;edition=2015)
I bought this up on one of the RFC-related threads [here](https://internals.rust-lang.org/t/blog-post-proposal-for-a-staged-rfc-process/7766/33), but didn't get much response other than a comment about it being down for maintenance. I'm interested in this as well!
`map` gives the closure ownership of the iterator's elements, so they can be transformed and new elements returned. However, `filter` returns the *original* elements when the closure returns true. Thus, it can't give away ownership to the closure, so there will always be an extra level of reference. This is part of `filter`'s type signature, so it doesn't change even if the element type is actually copyable. 
Great work! It's sad that actix has been denounced so hard lately, but I'm happy to see that ones just do their job and implement such a great services. Thank you for sharing your experience, looking forward new projects and news.
Super excited about Azul. I expect to be using it regularly once it stabilizes.
Maybe its a regional thing? Those words don't sound very similar to me 
This is an awesome post. Thank you for sharing, glad to see Rust get such intensive use, and come out shining. 
Instead of setting rustflags in `.cargo/config` (which apply to all `rustc` invocations), set `lto = true` in the [profile section of Cargo.toml](https://doc.rust-lang.org/cargo/reference/manifest.html#the-profile-sections), which applies only where appropriate.
You can change `generate` to take `&amp;mut self`, and use `Option::as_mut` to get references to the children: [Playground 1](https://play.rust-lang.org/?gist=19b474b50088715f431d43c571604c05&amp;version=stable&amp;mode=debug&amp;edition=2015)
I’m from Germany, so it’s probably regional 😅 I mean, they do not sound exactly the same, but I would say close enough.
[`lazy_static`](https://crates.io/crates/lazy_static) is the most common way. [`phf`](https://github.com/sfackler/rust-phf) is also useful in some cases.
Working a crate to help extract data from a stream of xml parsing events. Basically you register selectors which fire callbacks when they match. The callbacks are responsible for storing or emitting the data in whatever format your application uses. I did consider using serde-xml, but it required creating an intermediate struct that exactly matches the app's native data structure. I'm hoping that my approach will offer higher performance. Once thing I'm curious about: how is this normally solved? Do most people use the raw event stream directly, or am I missing a library that already exists?
I'm not aware of anything that could make this invalid, but just to be paranoid, I tend to use `#[repr(C)]` on any struct that gets cast unsafely, whether it's done with raw pointers or transmute. Then you have a 100% solid guarantee.
I don't want the `lto` option to apply to a profile, I want it to apply to a binary. How can I do that?
It will apply to everything compiled with the profile you set it on (e.g. debug or release). 
I don't understand. Then on one profile, one of the binaries won't build, and in the other profile, LTO won't be enabled.
Releasing [tarpaulin](https://github.com/xd009642/tarpaulin) 0.6.3 and working on closing more issues adding more things. I might work on some of my embedded rust just because I still haven't got something onto an ARM chip that doesn't just HardFault in the svd2rust take peripherals function and it's slightly frustrating
Cheers!
That's excellent advice, thanks. I was assuming something like that, but was unsure how ZST's and `repr(C)` might interact. Thinking more about it, a test checking that the size of `Text&lt;Something&gt;` equals the size of `Storage` might increase my confidence as well.
This is awesome! /u/fafhrd91 &lt;3 :D
Any detailed info on recent denouncement?
[removed]
I've been been thinking about it, but I have not worked with procedural macros yet so am not sure how to do it. I will experiment with it, and update if I get a good result
They don’t sound the same but still, very alike: [ˈtʃɛdə](https://translate.google.com/#en/ht/cheddar) [ʃeɪdə](https://translate.google.com/#en/ht/shader)
Bad uses of unsafe/UB
Yep. Those were side-channel attacks and arguably not really about correctness of the program (unless you consider side channels to be part of correctness, which definitely makes sense for crypto). This example is indeed similar, because not applying the fix is not acceptable. However, I think remote-code execution due to undefined behavior is much scarier.
Awesome. Thanks for listing out the other dependencies as well - I'm really curious to try sentry out, for example. Glad to hear someone had a good experience with it.
https://www.reddit.com/r/rust/comments/8wlkbe/actixweb_has_removed_all_unsound_use_of_unsafe_in/?st=jjekuhaf&amp;sh=46dbf48c from yesterday and the first link in the top comment
Yeah... I was hoping there was some nifty hack I was missing
&gt; It's sad that actix has been denounced so hard lately, but I'm happy to see that ones just do their job and implement such a great services. To be honest, the following made me a bit uncomfortable. &gt; Here comes rust with high speed and no-crash guarantee. It's was very easy to detect all logic bottlenecks and all unwraps are verified. Error management gave me an easy way to control all the flow and easily respond to some "bad situations". In the light of undefined behavior, it can get much worse than panics due to unverified unwraps.
Finishing up adding addressing modes to my MIPS I Assembler, also writing a small init binary to try out in place of runit sysvinit or systemd.
I'm so glad to hear someone is working on this.
Conciseness mostly. With how many times you add 2 numbers together, the 2 saved keystrokes start to add up, and that's before taking into account the saved whitespace needed to separate the tokens.
I wouldn't call it denouncement, but there were some issues with undefined behavior in Actix's unsafe code: https://www.reddit.com/r/rust/comments/8s7gei/unsafe_rust_in_actixweb_other_libraries/ https://www.reddit.com/r/rust/comments/8wlkbe/actixweb_has_removed_all_unsound_use_of_unsafe_in/
I believe the problem is that setting `-Clto` in `.cargo/config` is causing `serde_derive` to be LTO'd when it should not be. `serde_derive` is a procedural macro crate, meaning that the crate itself is not included as a part of your binary. Instead it generates code that gets included in your program. Therefore you shouldn't care whether `serde_derive` itself is LTO'd, and if LTOing it breaks things, then you should do LTO in a way that only applies to your final binary. Which is what setting `lto = true` in your `Cargo.toml` will do. And if you want it to apply to both profiles, then put it in both profiles.
We're currently planning recording the talks, but going forward we will try to go even further and provide a livestream. Out of curiosity, is there a difference for you between the two?
Is there an accepted pattern for wrapping data of different types, so you can store them all in a Vec? The reason I ask is because I want to try and make it ergonomic for people using my crate to pass arguments to runtime bound .Net CLR objects. Something like clr_obj.invoke("Add", &amp;[1, "2", true]) where the slice gets converted to a wrapper trait? 
Both binaries can build with LTO enabled. The problem is that `serde_derive` cannot. If your profile has `lto = true` then Cargo will automatically enable it for your binaries, but not for `serde_derive`. Try it with `cargo build -v` and see!
If you have uses cases in mind feel free to open issues with feature requests. Once I'm satisfied enough the API and have more documentation (hopefully before the weekend) I'll start accepting contributions.
Can you talk about the choice to use Rust due to safety guarantees on the one hand, then mongodb which has a history of \*not\* having safety guarantees? Being acid compliant as of 4.0 is a good step but there are other DB for which that has been the case for a long time and are perhaps more proven? Was it a concern?
There was a [thread on uses of `unsafe` in Actix](https://www.reddit.com/r/rust/comments/8s7gei/unsafe_rust_in_actixweb_other_libraries/), in which people discussed the fact that there was an awful lot of usage of `unsafe`, and due to that it provided interfaces that were marked as safe that were unsoud; that is, they could relatively easily cause undefined behavior. Many people in that thread showed some frustration that the primary author of Actix initially brushed off the bug report about this, and didn't seem to see it as a priority. However, despite the author's initial reaction, he did proceed to do work on cleaning up the uses of `unsafe`. There was recently a [followup thread](https://www.reddit.com/r/rust/comments/8wlkbe/actixweb_has_removed_all_unsound_use_of_unsafe_in/) in which it was announced that all of the unsound uses of `unsafe` had been removed from Actix.
I've had some success with hot-reloading rust code with this library: https://github.com/emoon/dynamic_reload
Aha, I was missing that they actually are different things, and that every other language out there mis-names it apparently (or the programmers using the operators do at least).
I understand the criticism but doesn't mongo just passes the responsibility to the kernel? And the kernel is pretty robust ensuring data is written. So is mongo really a danger? That said, 400k users, does that really need a NoSQL db?
Really interesting read, and cool to see Actix being used in production like this! I think I voice a question many readers would have: why Mongo over Postgres? Postgres performs great, and has a long history of reliability that Mongo definitely doesn't have. Postgres also supports strict typing and the ability to design a strong schema, which fits with Rust's philosophies nicely, and which Mongo lacks. For the amount of traffic being discussed, you would have probably been 10x to 100x below the amount of traffic where Postgres would even start to be a performance concern, and once that happens, it can always be sharded or other things done to improve performance further.
Worth noting they immediately cleaned up the code base. Everyone makes mistakes,but Luther’s quick response makes me want to use it even more.
Mongo has caused massive data loss due to bugs in their own code so many times that I've lost track of how many people have written blog posts on it. And those are just the people that have written blog posts.
Using trait objects: fn invoke(&amp;mut self, func: &amp;str, &amp;[&amp;dyn Trait]) { unimplemented!(); } where `Trait` is e.g. `std::fmt::Display` or `std::any::Any`. Calling the function: clr_obj.invoke("Add", &amp;[&amp;1, &amp;"2", &amp;true]);
[removed]
[removed]
Very cool! This looks super dense and I'm going to go over it slowly this evening. Question: one of the goals you list is &gt; a commandline tool/repl for loading and analysing data from CSV files Do you have plans to grow this repl into a kdb-esque scripting environment? Or will it remain fairly constrained?
We had a naming competition but got no contest. This was forked from the solicit-using apns2 to hyper/h2 and named after h2 to a2. Naming is hard, caching a bit easier...
Thanks.
I understand now and that works, thank you! (also /u/FenrirW0lf)
These would be classes, objects, types etc, loaded at runtime, and late-bound into a Rust wrapper object. So you can't generate enums or types, etc, at compile time. 
Reddit comments are not a literary genre for faint-hearted. But are there huge objections with regards to library’s public API?
I'm still wondering how hard it would be to replace wkhtmltopdf with some well-placed servo calls.
Have you thought about using Erlang/Elixir as an "ingress" while using Rust to do the heavy lifting? This might not be relevant if you don't have anything that requires persistent connections.
[removed]
Only one chapter left in TRPL!!! So looking for a project to contribute to. Thinking about finding a way to contribute to [Mimble Wimble/Grin](https://github.com/mimblewimble/grin) -- maybe a new block explorer that could compile to some WASM awesomeness
Only one chapter left in TRPL!!! So looking for a project to contribute to. Thinking about finding a way to contribute to [Mimble Wimble/Grin](https://github.com/mimblewimble/grin) -- maybe a new block explorer that could compile to some WASM awesomeness
I know Postgres and Mongo are like apples and oranges when it comes to many things but I do have some more faith in Mongo since version 3.4 [passed the Jepsen test](https://www.mongodb.com/mongodb-3.4-passes-jepsen-test). This is a scrupulous test ensuring that the distributed nature of the database being tested handles various scenarios. More information about Jepsen can be found on that link. With that being said, Postgres is wonderful and would be what I reach for 99% of the time.
Part of the objections were that the unsafety leaked into the library's public API (though in purportedly safe interfaces). I don't know how that has changed since the removal, I haven't worked with Actix much. It would be worth taking a look at the recent commits removing unsafety if you are interested in seeing what changes were made.
I agree that unsoun holes in Rust are scaring things, but I think it was too harsh. As far as I know author was highly demotivated to do anything when it happened. I'm glad that he have found his free will strong enough to overcome that. But there is possibility that someone who is really a great developer may be not so solid and we could lose some great project. @fafhrd91 behave well, but I think that we as the community should consider all consequences of what we do and be more polite and correct with criticism.
Is there a joke here about why you're asking yourself this that is flying way over my head?
I don't think Servo has a very good printing situation and thus can't really produce pdfs.
You mentioned the word 'joke'. Chuck Norris doesn't joke. Here is a fact about Chuck Norris: &gt;James Cameron wanted Chuck Norris to play the Terminator. However, upon reflection, he realized that would have turned his movie into a documentary, so he went with Arnold Schwarzenegger.
If somebody could give me some pointers how to implement the next generation aes128gcm encryption I would be thankful. Been reading all the RFC drafts and no pushes seem to go through with my aes128gcm implementation. The web push client knows aesgcm from a few years ago, seems to work with different browsers and I have no idea when it might stop working completely. Seems like nobody else does either...
&gt; They've gotten badly bitten in the past by not doing so e.g. Graphics, which was basically killed by a /r/cpp campaign. I didn't realize that is the feeling within the working groups. I've not seen this perspective come up in any of the post-mortem discussions on Graphics. Granted, I might be biased because I was one of the people who felt it wasn't a good match for the std library.
There was posts like "I will NEVER have any project written by the fafhrd91 because he creates such big holes that he couldn't be trusted anymore". I find it to harsh, as I said earlier.
Oooh, this might come in handy. Thank you for writing it! I wonder, what did the switch to a "data-oriented model" actually entail, and how did it improve performance? I'm still not great at optimizing low-level code such as Rust, so I try to understand how any performance improvements I come across were actually achieved.
I'm studying concurrency, asynchronous programming, and networking, with a focus on Rust. In the short term my goal is to both continue studying these things as well as to perhaps start working on an EquiHash implementation in pure Rust. EquiHash is a memory hard proof of work with asymmetric memory requirements such that the verifier needs only to allocate a small amount of memory to check the proof of work but the prover needs substantial memory allocated to perform an otherwise substantially performance constrained task. I plan to integrate this proof of work system with my blind signature crate BlindSign to fashion a membership registration system capable of requiring substantial proof of memory constrainment over arbitrary periods of computational time, such that to attain a blind signature on a 'pass token' to engage in non-registration protocols with the server the user must originally demonstrate resource constrainment over time to the server. Then the blind signed token can be exchanged for new tokens after completions of non-registration protocols with the server, to cryptographically unlink the protocol engagement instances from one another on the application layer, which is required for anonymity. However, a period of delay can be required between actions during which previous actions are subject to moderation, with the ability for moderators to prevent the server from signing a new blind signature pass token, resulting in the user with the revoked token needing to engage in the proof of work system again in order to attain a new valid pass token. This sort of cryptosystem is called revocable anonymity. A more concrete example would be an IRC server that requires the completion of an algorithm that requires say several gigabytes of memory to be allocated for several hours of computational time (on some machine, of course). After this, the user receives a blind signature on a token pass allowing them to send a message to the server with a shared pseudonym 'anonymous' that others use as well. After sending a message that spends a token, the server will wait a period of time in which moderators can terminate its continued progression, and thereafter will progress to signing a new token for that client, cryptographically unlinkably to the original token due to the blind signature scheme's properties. If the user does things such as spam, moderators can cancel the cheap re-blinding of the pass token and cause the client to need to complete the very expensive protocol to receive an original blind signature token. Of course Tor circuit rotations are required between actions for network level unlinkability, but my system will provide cryptographic unlinkability on the application layer for revocable anonymity to support moderation and anonymity simultaneously. I plan to use this for a secure forum system I am developing. However I am also currently working on bringing my Rust interface to Tor up to par. 
Just trying out Rust (1.27.0) for the first time with CLion (2018.1.5) and anytime I try to run the debugger in CLion I get "Error creating process ...\target\debug\hello_world.exe, (error 50)". I've tried looking around but no luck. Any ideas whats going on here? 
Is there an official Discord or easy way to find people to team up with?
I feel like I haven't seen this in years.
This looks interesting but could really use a better description. The "embedded tutorial" just jumps right into the code, with little motivation as well. An answer to this question: "What is hot-reloading in warmy, and why you should care", would go a long way here. Specifically, how is this related to serialization if at all, or to DLLs if at all, and what is meant by the term "object", in this context, is it hot code reloading a la Erlang, if so is it a subset of Rust that can be reloaded, etc.
Amazing! I'd really be interested in any monitoring data if you recorded any. How many requests did you process during peaks? What kind of system was this running on, and how did it handle the load? Also, would you do something different _next time_? 
Fair enough, that definitely is too harsh. I only read the highest posts, and they seemed mostly reasonable.
Agreed. And to be clear, trust-dns does not support anything other than HTTP2, basically for the reasons mentioned in the parent comment's reference to the RFC.
And to replace Maud by Askama.
but why would you pick Mongo over Postgres? I've just never seen it be very good at anything.
[They've worked openly with aphyr to use pass all sorts of Jepsen tests now](https://jepsen.io/analyses/mongodb-3-4-0-rc3). &gt;In April 2015, we discussed stale and dirty reads in MongoDB 2.6.7. However, writes appeared to be safe; update-only workloads with majority write concern were linearizable. This conclusion was not entirely correct. In this Jepsen analysis, we develop new tests which show the MongoDB v0 replication protocol is intrinsically unsafe, allowing the loss of majority-committed documents. In addition, we show that the new v1 replication protocol has multiple bugs, allowing data loss in all versions up to MongoDB 3.2.11 and 3.4.0-rc4. While the v0 protocol remains broken, **fixes for v1 are available in MongoDB 3.2.12 and 3.4.0, and now pass the expanded Jepsen test suite.** This work was funded by MongoDB, and conducted in accordance with the Jepsen ethics policy.
Can the faster fallbacks from SIMDeez be integrated into Faster, or there's some kind of architectural reason preventing that? I'm trying to avoid writing unsafe code so I'd prefer the safe Rust iterator interface that Faster provides. But since SIMD has been stabilized only on x86 so far, I also care about fallbacks a lot because for some use cases performance on slow CPUs like ARM is often more critical than performance on already fast CPUs like x86. I am aware that Faster currently only works on nightly, but I'm trying to be somewhat forward-looking here.
Ooh, this looks nice. I really want to dive back into automating as much of this as possible (a really hacky initial attempt at it [here](https://github.com/samscott89/swiggen), based on work written [here](https://libpasta.github.io/blog/bindings/)). There is a ton of stuff I haven't got around to implementing yet, so will keep an eye on this guide.
I mean, I can quote from another part of that: &gt; Furthermore, many of the atomic state transitions in Raft–for instance, voting–are not serialized through the log and applied to the state machine once committed; rather, MongoDB uses mutexes and direct updates of the storage system to handle meta-operations. If that mutex scope is not enforced carefully concurrency errors can result. or from here: &gt; For example, a recently discovered race condition in the voting process could allow secondaries to forget about votes, potentially voting twice if a node restarts during an election. Mongo may not be as forgetful as it used to be if you're using the new protocol on the strictest "majority" concern setting, but that just brings it on-par with the existing databases. It doesn't actually give someone a reason to pick Mongo. What is Mongo *actually* better at?
Have you tried Thrift by any chance ? Support for Rust landed a while ago, but it's missing a few things like exceptions. I'm not sure how grpc compares.
&gt; It's all static linking for now. Ooof. Security updates in dependency crates are going to be a problem.
&gt; cross-compiling from outside is often impossible because the libraries one needs to link to are not available Very interesting, didn't realize that compiling usually takes place on the cluster. Does this mean that the development of the code takes place on the cluster too? (Since the libraries are not available outside of it that is). Never dealt with a HPC environment so I find it rather intriguing. 
Sure they can, its just up the maintainers, I raised an issue about it and linked them to one of the options. 
Thanks for the links! I've mainly written manual FFI bindings so far because it's a massive pain to automate, but after looking at that `libpasta` article I might give SWIG a go.
Great article. I am very curious if the lifetime issue has a solution, or does it require HKT or something, and that's why it can't be expressed.
Excellent. Thanks!
Here's my function: ``` use std::fmt::Display; fn print_disp&lt;T&gt;(items: &amp;[T]) where for&lt;'a&gt; &amp;'a T: Display, { for item in items { println!("{}", item); } } ``` This works: ``` let list: &amp;[&amp;Display] = &amp;[ &amp;1, &amp;"abc"]; print_disp(list); ``` But this won't compile: ``` print_disp( &amp;[&amp;1, &amp;"abc"] ); ```
&gt; Fast allocation-free matrix-vector multiplication Is it possible for you to elaborate? This sounds very interesting! &gt; Zero-cost bidirectional conversions of structs of named fields into a single backing array Trying to understand this, does this mean that an array is initialized using the struct's values like below? #[derive(Debug)] struct Point { x: u8, y: u8, } trait ToArray { fn to_array(&amp;self) -&gt; [u8; 2]; } impl ToArray for Point { fn to_array(&amp;self) -&gt; [u8; 2] { let array: [u8; 2] = [self.x, self.y]; array } } fn main() { let point = Point { x:12, y:27 }; println!("{:?}", point); } https://play.rust-lang.org/?gist=de6baf31e80a325da682e2d106b3621e&amp;version=stable&amp;mode=debug&amp;edition=2015
I got into rust specifically for wasm. Haven't done any significant rust development other than wasm. Just speaking on personal experience, rayon is the number one killer of crates on wasm-unknown-unknown. Wasm on the wasm-bindgen side also struggles with seeding any kind of random number generator right now, (hash map salts are brought to us by the numbers ["1" and "2"](https://xkcd.com/221/)), but I expect that to be fixed soon. But other than that? Most crates surprisingly just work.
And adding a panic to this “_” arm would be a good thing to do since this should never fail. 
I have not.
I agree that `mmap`'ing from `/dev/mem` is likely faster (in terms of function call to register change), but what is your goal for "performance"? Minimum amount of CPU cycles, consistent io latency, easiest code to write, etc? The reason I ask is, normally when people are concerned with CPU cycles relative to GPIO's, the problem they are actually running in to is latency due to the Linux scheduler (*especially* when processing interrupts). Likely they are trying to drive some signal or bitbang a driver and have some real-time requirements - and I don't necessarily see this approach fixing that issue. Because of this, I don't think the fact that sysfs taking a few more cycles to reflect the register change is the biggest deal. At this point the most common solutions that I've seen are to apply some real time patches to your kernel, offload the task to dedicated hardware, use an RTOS instead of Linux, etc. If your approach is to sell this as the most "performant GPIO Rust Library," I think you should get out a scope and take some measurements of both your software and `linux-embedded-hal` and see if you can observe any differences. Start with a 1 Hz square wave and go up in orders of magnitude until things are really bad, and measure things like deviation from the expected frequency, range of deviation (maybe one wave is always off by 10&amp;#37;, but another varies from 5&amp;#37; to 15&amp;#37;). Measuring the difference from function call to register change will likely be tricky, but I bet there's probably some information out there on the best way to do so with a quick search. Try and figure out tests with other features as well where you can measure performance differences. Good luck.
I looked at it and I'm not sure what the right answer is. I don't think a `for&lt;'a&gt;` is needed, because all the lifetimes are present. I've tried a few variations though without success, so I could be off base.
I am trying to wrap my head around the syntax for a the impl of a generic struct with a trait bound. Here's an example: use std::ops::Add; struct Foo&lt;A: Add&gt; { a: A, } impl&lt;A: Add&gt; Foo&lt;A&gt; { fn new(b: A) -&gt; Foo&lt;A&gt; { Foo{ a: b, } } } fn main() { println!("{}", Foo::&lt;u32&gt;::new(1u32).a); } I am curious about this part: impl&lt;A: Add&gt; Foo&lt;A&gt; { Why do I specify A twice? Are there legitimate cases when would only specify it once?
One thing that is pretty minor: I had a trouble finding parts 2-4 of your blog, might just be me though. Maybe having a list at the top or something to make it more pronounced?
Yes. And this is why I implemented it. It just makes me a little sad that we’re devolving into a single protocol world, only HTTPS...
When you say you had to specify `A` twice, do you mean as in the type parameter `A` shows up twice in `impl&lt;A&gt; Foo&lt;A&gt; {` or are you referring to the fact that you had to specify the bound `A: Add` twice (i.e., once when defining the struct and another time when defining the implementation)?
Which then suggests if values.len() &amp; 1 == 0 { ... } else { ... } :)
Arrays elements in rust must be of the same type. The problem with your code is that the type checker is not smart enough to figure out that you want to make a list of `&amp;Display` if you don't tell it to. There might be other traits that both types implement, so there is no way to know what type to coerce things to if you don't provide context *in advance*. In your example, you are explicitly indicating to the type checker what type `list` should have, that is why it works. Below is a link to the playground that shows you a couple ways to fix the problem. https://play.rust-lang.org/?gist=677cc5e9bf24a85a743e4f9702f84d34&amp;version=stable&amp;mode=debug&amp;edition=2015
My original question was intended to be the former (A type twice), but I am also interested in learning the answer to the later (bound twice).
Thanks for the suggestions! This works: fn print_disp(items: &amp;[&amp;Display]) { ... } print_disp( &amp;[&amp;1, &amp;"abc"] ); How is the non-generic form different -- and why does it even compile?
Yeah. When reading a series, I've always found it helpful to have a list of the all other articles in the series at the top of each article, with previous and next links at the bottom.
Sure thing. In `impl&lt;A&gt; Foo&lt;A&gt;`, `A` is shows up twice because you are defining methods for `Foo&lt;A&gt;` where `A` is any type. You can also write, for example, `impl Foo&lt;usize&gt;` wherein methods would only be defined for the concrete type `Foo&lt;usize&gt;`. So the weird looking `impl&lt;A&gt; ` informs the compiler that `A` is a type parameter rather than an actual type. [Here](https://docs.rs/hyper/0.12.5/hyper/struct.Request.html) is an example of this, where the generic type `Request&lt;T&gt;` has an specialized implementation for `Request&lt;()&gt;`, `impl Request&lt;()&gt;` and a more general implementation `impl&lt;T&gt; Request&lt;T&gt;`
Now that I'm looking at it - what's the point of `GenericVec`? It doesn't take `self` in `unwrap` so there is nothing to connect lifetimes there ...
Why should the creators of BSD care what you "like?" You need to provide concrete points here. If the creators of BSD don't care about mindshare (or at least, they don't value it that much), I don't see any reason for them to disallow proprietary forks.
You didn't ask, but there's [a similar platform called arguman](http://en.arguman.org/) that could be interesting to explore
&gt; and then rewrite the software under a proprietary license while abandoning their open fork. Doesn't this depend on exactly the level of "rewriting?" Intentionally trying to imitate the implementation of code could still be considered a violation of copyright?
servo doesn't really aim towards PDF backends - but [printpdf](https://crates.io/crates/printpdf) may have been better suited in this situation (disclaimer - I am the author of that library). It doesn't have features like page breaking, margins or alignment - you'd have to calculate them yourself. So if OP needed that, wkhtmltopdf would be a sensible choice. But if its only for fixed-size tickets like OP mentioned - car tickets or system information - where (I assume) you don't need these features and can use absolute positioning, it would have maybe been a better choice than wkhtmltopdf - because it doesn't need any HTML middleware, it has smaller PDF file size, higher output speed and better PDF quality than wkhtmltopdf.
Fantastic news! Looking forward to this day
Why is [this library](https://github.com/serde-rs/json/blob/master/src/value/mod.rs#L207) able to use a recursive type? ``` enum Value { Null, Bool(bool), Number(Number), String(String), Array(Vec&lt;Value&gt;), Object(Map&lt;String, Value&gt;), } ``` When I try the same thing, I get E0072: ``` enum Value { String(String), Int(u32), List(Vec&lt;Value&gt;), Dict(Map&lt;String, Value&gt;) } ``` recursive type has infinite size insert indirection (e.g., a `Box`, `Rc`, or `&amp;`) at some point to make `bencode::Value` representable 
Graphs are a PITA in Rust. https://docs.rs/petgraph/0.4.12/petgraph/
[removed]
Serde uses its own [internal map representation](https://github.com/serde-rs/json/blob/master/src/map.rs) while I'm assuming you're using something else?
I find postgres a pain to use in production when I need fault tolerance. I'm no expert (unfortunately), but to achieve fault tolerance I need to use https://github.com/sorintlab/stolon, which is a great piece of software, but I hate adding third party dependencies because I can't tell for how long they will be supported.
[removed]
You're right. I was using `std::iter::Map`. Switching to `BTreeMap` fixed the problem. I'm still not sure why it doesn't work, but at least it's working now. Thank you.
Right, but it is not because of the trait syntax. The reason why the non-generic form works is you are declaring the types explicitly beforehand (in the function definition). So the compiler knows what to coerce the elements in the list to.
I replied with this in SO also, but there's no reason at all you can't use a \`Box\` to model this tree: [http://play.rust-lang.org/?gist=1428eb805412eb499282496a5a7e819c&amp;version=stable&amp;mode=debug&amp;edition=2015](http://play.rust-lang.org/?gist=1428eb805412eb499282496a5a7e819c&amp;version=stable&amp;mode=debug&amp;edition=2015)
Ah, so an additional constraint that exists in LocustDB is that integers are stored as raw values rather than pointers. So the return type on the `GenericVec` method has to be `&amp;'b [T]` to allow for that.
Ha, matching kdb+/q is a tall order! One feature that would be relatively easy to add is to store results from queries in a variable as a new queryable table, which would get you some of kdb+/q's capabilities. But of course it would still leave you with a large number of operations and useful functions that are not usually available or even expressible in SQL, or may be very cumbersome to express in SQL. The query language for LocustDB doesn't really have to be SQL necessarily (it certainly isn't standard SQL at the moment). Still, I think it would be quite difficult to design a language that is actually better than SQL and reaching full feature parity with kdb+ is a significant undertaking. But if LocustDB ever reaches the point where the expressiveness or ergonomics of the query language becomes a major pain point, doing so may well be worthwhile.
And the bound twice thing is because the bound on the structure definition is optional. You can write an `impl` block with a trait-bound type parameter for a generic type, like `impl&lt;T: SomeTrait&gt; MyType&lt;T&gt; { ... }`, even if `MyType&lt;T&gt;` does not have any bounds on `T`. In that case, the methods that you define within the `impl` block will only be accessible when your concrete type `MyType&lt;X&gt;` is so that `X` implements trait `SomeTrait`.
Yeah you're right, the default pagination is pretty terrible. I added a bunch of cross-page links, hopefully that helps a bit.
Interesting, I didn't realize Box was BorrowMut-able. That definitely makes it much cleaner. Otherwise, do you have any other style suggestions? One of the first things I've written in Rust.
`std::iter::Map` is suggested wrongly by the compiler in this case. It's actually a struct you can only get when you're using iterator functions, not something you can create manually. It's not actually a map as you'd understand it. In other words: It's getting a bit confused.
True, but it is no worse than Go packages already in Debian. Debian knows how to handle this.
There are now three projects in this space and I am in awe of each of them. Timely-dataflow and datafusion are also incredible pieces of software engineering. 
I still don't get it. So should that trait have a self in its method? 
I wanted to see how long I could go on for without getting caught, read the other comment chain. It's hilarious :)
Well if you want to know what "data oriented" mean, then I can recommend to watch this video from CPP Con 2016: https://youtu.be/rX0ItVEVjHc As for changes, I'd call them "data oriented in quotes". What gave me a performance boost is placing all the nodes and values in vectors and referencing them with indicies. This reduced the overhead on Rc and RefCell usage in runtime.
[removed]
&gt; Is it possible for you to elaborate? This sounds very interesting! See http://nalgebra.org/rustdoc/nalgebra/base/type.MatrixMN.html and http://nalgebra.org/rustdoc/nalgebra/base/struct.Matrix.html#impl-Mul%3CN%3E `MatrixMN` is the stack version of `Matrix`, so it can be used for any matrix with dimensions known at compile-time. &gt; Trying to understand this, does this mean that an array is initialized using the struct's values like below? That's the idea, but probably involves copying memory. It should be free with something like (also using `nalgebra`, but would also work with plain arrays): pub type N1 = U6; pub type N2 = U10; pub type N3 = U4; pub type NW = U121; #[repr(C)] pub struct W { pub b2:VectorN&lt;f64,N2&gt;, pub b3:VectorN&lt;f64,N3&gt;, pub w2:MatrixMN&lt;f64,N2,N1&gt;, //pub wh:MatrixN&lt;f64,N2&gt;, pub w3:MatrixMN&lt;f64,N3,N2&gt;, pub params:Params, } impl Deref for W { type Target = VectorN&lt;f64,NW&gt;; fn deref(&amp;self) -&gt; &amp;Self::Target { unsafe { &amp;*(self as *const _ as *const _) } } } impl DerefMut for W { fn deref_mut(&amp;mut self) -&gt; &amp;mut Self::Target { unsafe { &amp;mut *(self as *mut _ as *mut _) } } } pub fn w(x:VectorN&lt;f64,NW&gt;) -&gt; W { unsafe { mem::transmute(x) } } 
Ahhh. I saw that first, but didn't get the joke.
Building out a full kdb+ equivalent language is... well, here's the thing: It's great for slapped together analytics. If you end up having to engineer a data processing system in it, it's a nightmare (I've built about three different versions over 10 years, please believe me, it stinks). That said, whenever someone compares any given data-processing query-like tool to KDB, the one thing they always forget about is [asof joins](http://code.kx.com/q/ref/joins/#aj-aj0-ajf-ajf0-asof-join). And when that happens, I *have* to point out that KDB is almost entirely engineered around asof joins. KDB's main storage regime of db's comprised of directories of dates containing directories of tables containing files for each column where the data is sorted by an enumerated primary symbol (doesn't strictly have to be an enumerated symbol, could be an integer [sort of the same thing though]) and then by a time column: all in service of running an asof join on two tables. It's a little harsh to say but, any comparison of any given data "thing' to kdb that *doesn't* talk directly about asof join performance is not really worth the energy it takes to write it.
Awesome! :) Well, the only difference would be a visual presentation, whether it is just showing someone's IDE with code, or a PowerPoint with snippets and bullet points. Maybe the PowerPoints could be asked for and the code shared be added to some collective repository? Just thinking out loud here, I don't know what's feasible.
I think service mesh is a good name. Most people working with microservice architectures should be somewhat familiar with the term. u/Mister_101 gave an excellent explenation, but another nice analogy for me is: Service meshes are somewhat similiar to a middleware in web frameworks, enabling secure connection establishment and relatively low-effort routing, tracing, logging and debugging capabilities.
Damn! Really like this platform
I used sentry in an app I wrote, it's a great service! Never had to use it in rust though.
I'm not actually sure that `Box` would be unequivocally better, now that I think about it -- you'll need to do a lot of `.clone()` calls, which may be less cheap than simply using ref-counting pointers, esp. in the case of nested structures. Benchmark it and let me know! A few other things I've noticed is: 1. Some minor points of some method bodies don't immediately make sense to me, like that of `union`: pub fn union(mut self, mut other: Sequence) -&gt; Sequence { let end = State::accepting(); let start = State::split(self.start.clone(), other.start.clone()); // Why not just hoist the assignment to `self.start` up here? *(self.end.borrow_mut()) = State::Epsilon(end.clone()); *(other.end.borrow_mut()) = State::Epsilon(end.clone()); self.start = start; self.end = end; // Wait, why did you make the previous assignment to `self.end`? Aren't you just throwing it away here? self } I'm not sure if this is just because what you've linked might not be serious code. 2. Anything of the form `*(x.borrow_mut()) = ...` can be simplified to `*x = ...`. :) 3. Rust's design really does obviate the need for POD constructors like one might use in Java, C#, or Python. Your `wrap` method is, to me, noise (since it essentially is a forward to `Box::new`!), though it's arguable that the other "constructor-ish" methods that do some `Box::new` and some other work might be worth it. My personal opinion is that hyper-optimizing to eliminate `Box::new` calls is not usually very interesting, and just creates more mental burden for a maintainer in the long run. I understand that it can make things much easier to write initially, though!
&gt;wkhtmltopdf Wow it took me a minute to realize `wkhtmltopdf` was not a typo.
So how I would start this endeavor is by going to https://forum.xda-developers.com/htc-desire-hd/development and finding a ROM for the phone that works. Then just on the kernel, you can start building a text display because it is mostly a Linux kernel. Then when you've got the hang of it, you can start rewriting parts of the kernel in rust, that is if you can find the source code for the kernel. Companies do sometimes release the sources, I believe, so if you can find that then you can try translate the C into Rust until you've got a minimal working example in pure Rust
Side question - are there any CQRS style crates at all in the Rust ecosystem?
Great job! For me, one of the most interesting parts of the article was this: &gt;On all but one of the results that allow for direct comparison, LocustDB comes out ahead of both ClickHouse and kdb+. I am unsure how exactly I am able to get these speedups. What LocustDB already does very well is generating close-to-optimal query plans that contain very few superfluous operations and are specialized to work directly on column data without any type conversions. E.g. 95&amp;#37; of runtime in query 1 is spent on just 7 machine code instructions that are part of [this loop](https://github.com/cswinter/LocustDB/blob/106acb1aad11676b099abd2c81ff1018e2364433/src/engine/vector_op/count.rs#L37). So far I have not made any attempts at improving the operators used by the query engine through use of SIMD, loop unrolling, elimination of bounds checks, not using `Vec::push` everywhere, or other micro-optimizations. I think there are still significant gains to be made in that fashion before hitting fundamental limitations of the hardware. Another great example against premature optimization.
Brill, thanks!
`warmy` is just a plus, the core principle of Cheddar is not in hot-reloading. I could add more motivation if you think it’s confusing though, I agree! 
I also [gave it a try](https://phaazon.net/blog/spectra_plugins) a few months ago, but eventually dropped it from `spectra` as I was not convinced.
Don't try to capture reference, instead, just capture the sender and receiver by value. I think you'll need to use a `move` closure. (`move |args| ...`)
What are the advantages of using your crate vs using `toml` and `serde`?
What do you mean you weren't convinced? For me it's useful in a project that has a tedious startup process.
Boxing the closure does not do anything to make it `'static` - it will still contain the same references, which won't become `'static` because of the box. Without seeing more code I'm not sure, but I suspect that you are not making it a `move` closure, so it captures its environment by reference. [Here's an example](https://play.rust-lang.org/?gist=f7db456de344caa7e666c8369f29703d&amp;version=stable&amp;mode=debug&amp;edition=2015). The error itself mentions that you should add `move`, or are you getting some other error message?
I've tried using a move closure, but then the compiler complains that the closure must implement FnMut, and moving in the arguments causes it to only implement FnOnce.
Unfortunately no. The best is to call the interfaces to python or, if you want a better language for machine learning (ML)/statistics, use Julia. I doubt that rust will ever a top choice in this area since ML has different requirements that OS programming. For example when working on ML, you typically prefer an easy to use API (e.g. garbage collected) over general performance (e.g. performance in linear algebra, but not the rest like SciPy). Just look at the Julia issues and see how difficult it is to get linear algebra right, I question that it is possible to create a similar easy to use API in rust. But that's OK. Just use the right tool for the given job.
It was a bit hacky. It’d be more interesting if Rust had a real JIT or better support for dynamic linking.
This is closer to what I'm doing: [https://play.rust-lang.org/?gist=94efc189a3955d7921755a1286a08b85&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=94efc189a3955d7921755a1286a08b85&amp;version=stable&amp;mode=debug&amp;edition=2015)
/r/playrust 
For #1, the assignment is to *self.end, not self.end (which you mentioned can be written like this), the pointed to State. It's pointed to by the start state and was the Accepting state, so I need to update it to build the correct machine (Thompson's construction). You're right about my many functions, I'm mainly just tired of it writing very long lines of the same thing. Is this style something I will have to get used to?
Bypassing firewalls is a *huge* advantage. I get it, you are outside the firewall, but don't belittle the practical advantage.
I just inlined the \`use\_tx\` function and it compiles now. I find this to be a strange limitation.
You're moving `tx` _from_ the closure _to_ the `use_tx` function. (That's unrelated to the `move` keyword, that forces a move from `main` to the closure). Are you in control of `use_tx`, so you can change it to take a reference? If not, just `.clone()` the sender when passing to `use_tx`.
&gt; Does this mean that the development of the code takes place on the cluster too? (Since the libraries are not available outside of it that is). Yes, the cluster typically has some nodes used exclusively for logging in, developing, compiling, and launching jobs (these are typically called front-end nodes). It also has multiple queues for computing jobs; most clusters have a `test` queue that is using during development or while preparing a job. Also while the binary compiled libraries are typically not available outside the cluster, there are libraries that expose the same API (but often not the same ABI) that can be used to develop outside the cluster. The most common example would be MPI: there are many MPI libraries available (OpenMPI and MPICH being the two largest open source ones), but every cluster vendor has their own (e.g. Cray MPI) and when using a cluster of a vendor, you have to link against their library. Since these libraries are not ABI compatible, you cannot really cross-compile to them if you don't have the libraries available, which you don't outside the cluster, meaning that you can't cross-compile from outside the cluster.
Pet peeve: I pray people stop using Raspberry Pi 1. It is about the only thing using ARMv6 CPU, all others are at least ARMv7. Later Raspberry Pi's are ARMv7. Raspberry Pi 1 is singlehandedly forcing everybody to maintain v6 support. Please, buy later Raspberry Pi. This was a public service announcement. Thanks.
Nitpicking: Shouldn't a superset encompass the lower set? It states in the readme, that not all of GLSL is valid Cheddar.
Ah! I just realized you don't need a mutable reference of the Sender in order to send. Doy...
Took me a while to understand - `Sequence` is basically a singly linked list (kind of - you can have it branching out and then merging back later), where `start` is the start of the list, and `end` points right to the end. With this you can do stuff like `concat` (concatenate two lists) or `union` (at start split into two, at their ends merge back into same state) in constant time.
I still don't like Mongo for certain operational reasons, but they \_have\_ worked a lot on their reliability. It's definitely feasible to use it for such a project now and if that's a concious choice, I trust people there. My biggest problem is people defaulting for Mongo because it's "easier" and figuring out down the road that the upfront complexity they avoided costs them later.
Just to be clear - a version with mutable reference [also works](https://play.rust-lang.org/?gist=0de8381bc0033661da03b3de615367e4&amp;version=stable&amp;mode=debug&amp;edition=2015)!
It's a little confusing but moving in the captures (as in, `move`) doesn't cause that, but rather moving *out* of the captures inside the closure: after the first time it is called, those captures are no longer valid and so it would be a problem to call it again.
How many firewall block raw TSL?
Is it possible to measure the performance of rust program, by modifying the generated LLVM code, so that each odd line increments some \`instruction\_counter\`? The performance of any program is the number of instruction used (I assume all LLVM instructions are mostly atomic CPUs), which is the value of \`instruction\_counter\`.
You are forgetting the immensely popular Raspberry PI Zero, which is also using an armv6 CPU.
I have been working on my PPTX file serialization/deserialization crate. The bare minimum of the low-level API is complete, so i started to implement the parsing of the PPTX file format. I still don't think it's ready for publication, so i don't have a link to the repo yet. On a side note, i'm amazed how easy it is to write unit tests in Rust. As a C++ developer, working on a project that doesn't really need them, and our senior developers think they are pointless, i have never written unit tests. As I looked at the available options in C++, none felt as simple as Rust.
I guess it is a lost cause now then. What a missed opportunity.
For a summary of jemalloc's allocations there is the [jemalloc-ctl](https://github.com/sfackler/jemalloc-ctl) crate, which hooks into a subset of the jemalloc API. That should be far more than fast enough for monitoring. Note this misses anything allocating directly from the OS via other means, like mmaps or (s)brks. The the OS level rss or proportional set size is probably sufficient for most monitoring needs. I would collect the OS and jemalloc metrics, since the differences between different metrics can help limit possible causes of issues. The jemalloc heap profiler is more for finding leaks, or for figuring out what callstacks are eating the most memory. If you stick to the default probabilistic settings (where only a sampling of allocations are traced), then it's very performant, and the performance can be tuned with the sampling. I've enable it on our production settings and have only measured a couple percent overhead while actively tracing on some very allocator heavy code.
Still working on [graphql_client](https://github.com/tomhoule/graphql-client), just finished implementing copying the description strings from the GraphQL schema to the generated Rust types, and will continue with subscriptions support.
Well, you can refuse to support armv6 and compile only for armv7. Rasbian can run those as long as the CPU of the device supports those ISAs. 
I never said that, I just stated what is my view about the topic.
I am speaking of the fact that rustc can't remove ARMv6 support in foreseeable future. Individual applications can refuse to support ARMv6, but compilers realistically can't refuse to target ARMv6.
Is it a separate target, in rustc?
That's a great slide deck! Azul looks really nice.
On Linux you can use perf stat program For any program to get the number of executed instructions. The instruction count alone isn't a good metric on modern CPUs. Cache misses and branch mispredictions aren't instructions but can take as long as hundreds of instructions. Individual instructions can take a variable number of cycles for many reasons. Multiple instructions can also start executing at the same time. perf stat shows most of that info, perf record/top can show where slowdowns are in very fine detail.
It looks similar to Reddit: A tree based discussion with up and down votes. The interface for interacting is a bit different, and it distinguishes between pro and con. To me it seems like a less efficient interface to interact with the tree, because it only shows one level and has slow animations.
I like it more than Kialo, because it shows the tree instead of just one level. However, it still seems less scalable/efficient than Reddit.
In the last week I started working on a small project called slingr https://github.com/yuvadm/slingr It's a simple casting media player, that takes a video file from command line and streams it to a UPnP media renderer - usually some sort of cheap HDMI dongle. This is my first serious Rust undertaking, but I'm really starting to enjoy the language after a very long time of lurking around, and not doing anything real with it.
Hey everyone, author of the post here. The above post is a small side project I am currently trying out. Feel free to comment on the quality of the code, writing or idea overall. Would love to learn some more things and incorporate them in the project.
There's a layer available called meta-rust. It will download the rust source and build a cross compiler for the yocto target. There's also a tool called cargo bitbake which generate recipes for rust projects. 
Yeah, thinking about it it seems that the sharing with an `Rc` would be a better fit.
&gt;Using trait objects: ... Unfortunately I've found that this approach doesn't work out very well in practice. I've wrestled with this for a long time now and it seems more often than not an API user has a dynamic length list of values (ie a Vec) and that doesn't coerce to `&amp;[&amp;dyn Trait]` unless you have a second vec of pointers pointing to the original vec (which is not user friendly at all, and only gives you a heterogeneous array if you box the trait in the first vec). Just my two cents, but I'm starting to think enums are the way to go for heterogeneous arrays in Rust today. For example, you should be able to do something like `clr_obj.invoke("Add", vec![1.into(), "2".into(), true.into()])`. Maybe if we ever get method-like macros, we could do `clr_obj.invoke!("Add", [1, "2", true]);` and do the above behind the scenes. But if you don't mind the bulky two vec approach, you could probably create a macro for the user to call. Like `let items = hvec![1, "2", true];`
I think having convenient functions with straightforward logic inside is generally more maintainable, it just requires a human brain to do more work to do the initial conceptual load. I think I'm mostly projecting myself from a few years ago where I went crazy-OOP on all the things and I learned just how incompatible that can be with code clarity and maintainability...and how much that makes `rustc` complain. :) To be clear, the cases you've linked don't seem offensive at all -- I think it just reminds me of how I've been broken of a few of those habits that I didn't realize introduced additional safety hazards the way I was using them. A good example I can think of is writing closures. I used to scatter then around in tons of places to effectively compress my code's repetitive bits. It makes reasoning about lifetimes and intent much harder, though, and `rustc` would force me to confront the fact I sometimes just wanted a copy-paste of repetitive code instead of adding more state to a function call, which in retrospect is actually a meaningful distinction when it comes to how much load you're putting on future readers of the code. Also, as somebody who's been writing in Rust for a couple of years during hobby time, `Box` constructions don't really consciously register beyond "Going on the heap now". `rustfmt` usually does a really good job fluffing up denser code, and I'm used to using denser, MAYBE more human-brain-cache-friendly code. I believe all of the previous points culminated in my comment about your functions -- I don't think that they're problematic now that I've had some sleep and can recognize that I've just been expressing my preference. :) Generally Rust makes low-level operations like writing constructors pretty elegant but isn't perfect with everything, so please don't let me deceive you into thinking that Rust for some reason "needs” noisy ceremony!
Hmm. How did you evade excessive bounds checking when accessing everything by indices instead of iterators? Something like `assert!(largest_index &lt; vec.len())` to hint to LLVM that bounds checking can be elided?
Likely there's no advantage, this was written more as a personal tool than anything.
This was a really cool report, thank you!
Looks like you have an answer, but you may be interested in `filter_map` for this.
You only need the routers MAC address, not the MAC of the remote. That's how routing works. I set my dst ip to head off to where it needs to and the MAC to that of the router (unless the IP is on the same network then I can send the packet directly, no router required). The packet is delivered to the router which figures the next hop MAC and overwrites and the dance continues and eventually your packet will hit a router that is on the same network as the actual target ip at which point the ever changing MAC will be overwritten to the actual destination MAC and your packet will be delivered.
Awesome! I was thinking that was the case, this makes the whole destination MAC much easier. Thank you very much /u/benjumanji!
This code is indeed not correct in all cases, but it is correct in the given execution (i.e., with \`malloc\` returning the given values). We are focusing on a particular possible trace that exhibits interesting behavior. Taking non-determinism into account introduces plenty of overhead without adding anything to the actual discussion. We did this multiple times in the paper, though I agree the wording could probably be improved :)
Thanks. That seems interesting. Does it also add rustc/cargo to generated SDK if you want to compile Rust projects outside of Yocto?
I don't think so. It should be possible, but currently it is generating wrapper scripts for CC that need to be handled somehow. Cargo does not like a CC variable that contains flags. I usually work with devtool. Any particular reason for prefering the SDK? 
Your `use_tx` function should take a `Sender` by reference. Without doing that, your sender is moved into a function, which means you can call closure only once. https://play.rust-lang.org/?gist=a12e4b88f24b7df050f3576efbfd801f&amp;version=stable&amp;mode=debug&amp;edition=2015
Are you the owner of this piece or have you borrowed it somewhere?
Luckely [`mod_euc()`](https://doc.rust-lang.org/std/primitive.u32.html#method.mod_euc) is being added (currently in Nightly) 
The problem isn’t the protocol, it’s the port. When DNSoTLS was put together, there was a brief period where 443 was going to be the port. This was changed to 853, because of the obvious confusion that would happen by putting something other than HTTPS on the port designated for that service. Now my opinion, firewalls blocking by port have never been particularly effective as a means of security. They cause many more problems than they solve. But given what exists and the issues dealing with this, it makes sense to come up with a workaround. I just hope that we can do away with dumb firewalls at some point, but I don’t have high confidence in that happening.
&gt; it seems [...] an API user has a dynamic length list [...] and that doesn't coerce [...]. Care to give me a concrete example? It works for me to call `invoke` with for example `&amp;vec![&amp;1, &amp;true]`. There has to be pointer indirection. I **absolutely agree** with you on avoiding trait objects. Enums are really handy. In /u/ZerothLaw's case though, trait objects are the way to go, citing him: &gt; This would be [...], types, etc, loaded at runtime [...]. So you can't generate enums or types etc, at compile time. If you accept that you are limited to a specific amount of types an argument can have, you can generate an enum with macros.
Happy to help!
I guess it is partly a convention from projects started before eSDK/devtool (around dylan), so workflows, scripts, etc. have been set up around the standard SDK. Also, some projects need to be built for both Yocto targets and also for targets for which the toolchain/rootfs does not come from Yocto (usually some older HW). In that situation it is easier to use Yocto SDK and have clear separation between core Linux and application builds. Anyway, meta-rust is something I definitely should mention in the blog post. Need to update it.
Am I the only one who think this is overengineered ? \&gt; It's very important to have 100&amp;#37; uptime because a few seconds of delay can lead to long queues and suspend work of all festival. Here comes rust with high speed and no-crash guarantee. It's was very easy to detect all logic bottlenecks and all **unwraps** are verified. Error management gave me an easy way to control all the flow and easily respond to some "bad situations". I am working in scala and most of the safety garantee are met in scala. It is also used a lot more in production, especially in web dev (play2 framework is an industry standard) and since there is no memeory management, dev time is reduced.
My bad, I was talking only about warmy and not cheddar, I get what cheddar is, apologies for the confusion.
[removed]
[removed]
Just in case you want to see some more pnet code, I wrote a UDP packet crafter which you can see here: https://github.com/LivingInSyn/udp_crafter
Awesome thanks for this. I'm going to take inspiration on how you structured the packet as a whole. In the end I want to move over to \`build\_and\_send\` rather than send to and take some proper benchmarks.
It would be better to use a profiler for this, although i am not sure which profilers are available for rust.
Let me know if you'd like some help. Something I wish I had done from the beginning (but haven't had time to go back and fix) was support IPv6 right from the start
&gt;Let That's another good point. Funnily enough the same thought went through my head. It eventually boiled down to, "let's get some IPv4 stuff going first" and opted out of IPv6 support. That said, I can definitely rework that to support it and it would be pretty cool too.
This is a fascinating discussion. I've found that if my trait has either a generic type or associated types, then I can't hold heterogeneous items in a vec that all implement the same trait. 
What are the issues with the arch? This isn't familiar territory for me.
TL;DR. I'm creating a complex struct for a library which in almost all cases most of the fields should be \`Option::None\`. Looking for ideas for minimising the memory size of it. Sorry if this is the wrong place to ask. I wasn't sure I'd be able to formulate a question in a manner amenable to stackoverflow. ## Background: I'm looking at creating a solution to [actix/actix-web#310](https://github.com/actix/actix-web/issues/310). This requires creating a description of an openapi document in Rust, as part of which a JSON schema is required. ## The problem In a validation JSON schema, there are ~45 possible fields the schema can legally contain. This struct must also be used recursively to describe most types. In particular, for every property of a struct, this must be included. When this is [implemented naïvely](https://play.rust-lang.org/?gist=71bdb37fbecd425af6a259a97ff51f02&amp;version=stable&amp;mode=debug&amp;edition=2015), the `std::mem::size_of` of the resultant struct is *696*. This feels unacceptably large given that a new one must be created for every field of every type. ## Prior art The [valico crate](https://crates.io/crates/valico) allows the construction of json schemas. However, it simply wraps a jsonway::ObjectBuilder and manipulates the raw json structure at a slightly higher level. This feels like the best solution, but I was wondering if anyone had any different ideas
Say I have something which implements a trait X, and various functions accepting this trait. How can I tell (or maybe force or throw an error on compile time) that all the X::x_method() calls are devirtualized. Can there be a mix? Compare that to C++ where proper traits can only be implemented as templates (or soon concepts), so are always devirtualized.
Every packet I've ever send, every root I've ever been, it's it's a SYN
I'm working on my first crate: [Pierre-s-Distributed-Experiments](https://github.com/pierre-l/Pierre-s-Distributed-Experiments), where I simulate a blockchain network in order to validate my recently acquired knowledge about both Rust and blockchains. I am pretty proud to have been able to simulate a Proof of Work blockchain with 10k nodes and only \~100MB of memory! Rust is awesome! I would welcome any advice or comment :)
&gt; I am working in scala and most of the safety garantee are met in scala. It is also used a lot more in production, especially in web dev (play2 framework is an industry standard) and since there is no memeory management, dev time is reduced. Is it? By using Scala you are gaining ease of memory management and losing ownership. Ownership guarantees: - the absence of `ConcurrentModificationException`, when accidentally removing an item from a collection being iterated, - the absence of data-races. Given how easy memory management is (using RAII) most of the times, I'm not so sure you come ahead, especially for a multi-threaded application. 
They'll release an ARMv7 version of at least the Zero W at some point, it's just a matter of cost and to a lesser extent power consumption. I've got a lot of Zero W's in use 24/7 inside things I've built, and I'd swap in a newer board immediately if I could. The low-temp/high-endurance industrial microSD cards in each of them were 3x more expensive than the board itself after all :D 
Yeah agreed.
Is it Rust-like? ;-)
Why downvote this question? The responses to it are interesting. They'll be hidden soon.
&gt;So operators that work with strings take them by reference (`&amp;str`) which means they require a lifetime parameter corresponding to the lifetime of the object containing data that the string references. In some Rust programs it is possible to eliminate this type of lifetime by replacing the `&amp;str` with an index into the array storing the string values but that’s not workable in this case. First, we still need to access the actual string data. Second, there isn’t a single backing store for strings. They might come from a `Vec` packing multiple strings into a contiguous area of memory, a `String` that was originally part of the query string or created on-the-fly by the query engine, or a `Vec` used by a dictionary codec. It must be possible to uniformly merge and operate on all these different string values originating from many different columns and `&amp;str` is the only common representation that does not sacrifice performance. Maybe I don't understand the issue well enough, but by reading this description something strongly tells me, that `Cow` or something custom with more specific arms with different lifetimes and that coerces to `&amp;str`, may be the solution. I may suggest reading the [secret life of cows](https://deterministic.space/secret-life-of-cows.html).
I'm just spit-balling here, so bear with me. If I understand correctly, you're essentially trying to model a sparse key/value set with a struct? Something like struct Foo { field_a: Option&lt;T&gt;, field_b: Option&lt;U&gt;, field_c: Option&lt;V&gt;, ... } What if you used an Enum instead? enum FooItem { ItemA(T), ItemB(U), ItemC(V), } Then you could represent your JSON as a `Vec` of `FooItem`'s
Ahh, I think I get it now. The compiler _wants_ to turn the generic form into concrete types, though in this case it can't, while the `dyn` syntax is explicitly dynamic-dispatch.
First CVE, wooh! Didn't even know about plugins in rustdoc, so that makes sense. Also, I was getting deja vu on this point release being related to the match ergonomics, but I guess it's a second issue introduced at the time. It makes me wonder why the implementation was so difficult/error prone and just a little nervous.
I haven't thought much about it, but this sounds like a job for [https://ostinato.org/](https://ostinato.org/).
It seems to enforce dichotomous reasoning. That should be a non-starter for a platform for discussing engineering solutions.
The bugs happened because the current borrow checker is so hard to work with. None of these bugs ever popped up with the new NLL borrow checker. This is part of why we’ve been working on NLL so hard. :) It might suggest a few different things; possibly one of which is “this feature should have blocked on NLL”. Hindsight is 20/20...
That does sound quite interesting. I wonder if there would be a demand for something like that in Rust. Especially cross-platform. 
NLL can not come soon enough. But regardless, why aren't soundness issues better publicized? I scan the l-soundness tickets once in a while to make sure I'm up to date. I don't want to find out about a soundness hole when it's patched, I want to find out about it *before* it is patched.
Thanks for the plug for Barcoders! I am so happy that my work has been put to good use! :)
Thank you, that's the perfect way of saying what I wanted. I did consider that option, but wanted to see if there were any more idiomatic methods of doing it. I shouldn't actually need to handle deserialisation, only serialisation, which is easier. This does have the issue of allowing duplicate fields, but that should be solvable fairly easily, although unfortunately making insertion O(n). Ideally for this case, `serde_json` will just allow fields in a map to be overwritten, because that would things easier.
I'd answer your question with another question: What do you do with a drunken sailor?
We have a mailing list for "you want to be notified for a security issue" but nothing anagulous for soundness. That's an interesting idea!
Yeah that’s the impression that I got from reading the articles on the new NLL borrow checker and the related datafrog ones. The borrow checker lends itself well to being written as a series of logic rules and being able to then implement it like that in the code would make it much easier to reason about. The work on the borrow checker feels analogous to the stage in a startup where you’re running into scaling issues and need a new hotness to emerge onto the scene (especially considering I remember how the borrower came into being much later after Rust was born). I’m familiar with that stress, so all I’ll say is good luck, thanks, and I’ll be patiently waiting to see the results. What would be the right place to see the new borrow checker branch/code? I’d be interested in **attempting** to read it, even thought it’ll probably go over my head. 
Check the rustc guide; I’m not sure myself.
I really appreciated how they ended that post with: \&gt; It’s worth noting that while Rust does prevent a lot of issues in your code at compile time, they’re issues that result from memory unsafety. This bug is a logic error. Rust code is not inherently secure, or bug-free. Sometimes, people get enthusiastic and make overly-broad claims about Rust, and this incident is a good demonstration of how Rust’s guarantees can’t prevent all bugs.
What would the advantage be in removing the target? It's apparently a tier 2 target, and perhaps it could be moved to tier 3 one day instead of being entirely removed.
&gt; The compiler wants to turn the generic form into concrete types Exactly, it's a process called [monomorphization](https://doc.rust-lang.org/book/second-edition/index.html?search=monomorphization) and is part of the compilation process. &gt; the dyn syntax is explicitly dynamic-dispatch Also right, but as far as I know the `dyn` syntax is there to make it explicit that there are trait objects involved. `&amp;Trait` and `&amp;dyn Trait` are exactly the same (same type, same semantics, same run time costs, everything) only the `dyn` makes the trait object explicit to the programmer reading the code. That is my understanding, at least. Someone might correct me if I am wrong. Here is a new playground with more examples: https://play.rust-lang.org/?gist=cf4720326362faf7f1908b6054227173
&gt;there was a brief period where 443 was going to be the port i would have liked that as solution. Anyway the important is now if some big like MS and Google offer DNSoHTTPS with the same domains/ip of main domain, they will be basically impossible to censor unless you block the whole stuff.
I'm not sure if this is OT or not, but it gave me a chuckle. I found it fairly accurate. :)
[removed]
In order to use the code in your library from another crate you would need to mark it as `pub`. This will also fix this warning. You can read more about it in [the book](https://doc.rust-lang.org/book/second-edition/ch07-02-controlling-visibility-with-pub.html).
 | |hint: to prevent move, use `ref t` or `ref mut t` if match ergonomics means that explicit ref isn't ever going to be necessary, why is the compiler suggesting the use of ref in this pattern?
The code in the playground runs fine for me. I assume that your function is not used in your crate (except for test code which doesn't count). The only way it can be used is from outside. It can only be used from outside if it is visible/public. Not only the function has to be public, but also the module it is in etc. Rust functions and modules and everything are private by default. So this is unused: ```rust mod my_module { fn my_function() { } } ``` As is this: ```rust mod my_module pub fn my_function() { } } ``` Only if both module and function are public, it can be used: ```rust pub mod my_module { pub fn my_function() { } } ```
I just found an image of some rusty thing.
That would certainly be nice, and probably not that hard? ;)
I've actually written a similar library back in the day, but I feel dipping into low-level PDF primitives is really too much of a pain in practice, compared to rendering HTML/CSS into PDF.
I don't see the resemblance at all. Plan 9 does not use "url schemes", as it exposes all services through mounts on a root file namespace. All files look like "/net/tcp", or "/dev/cons".
I wonder why people seem to have suddenly started capitalizing Rust. I've seen it inappropriately capitalized in much of the recent reporting I've seen on it as well as in some guides on it even. 
Your zero-overhead code allows you to rescue 337,705 princesses per second. By the time it finishes compiling, the princess dies of old age.
All trait method calls are statically dispatched unless the implementation is coerced to a trait object, e.g. `Box&lt;Foo&gt;` or `&amp;Foo`/`&amp;mut Foo` (or `Box&lt;dyn Foo&gt;`/`&amp;dyn Foo`/`&amp;mut dyn Foo` with the new `dyn` keyword). You can prevent the trait from being made into a trait object by adding `Sized` as a supertrait: pub trait Foo: Sized { ... }
I believe this is essentially a shortcoming of the Rust linter, it has been the case the entire time I've used Rust and I've learned to simply live with it. Static analyzers commonly have false positives, and I perceive this as just being one of the primary false positives of the Rust static analyzer, which isn't that big of a deal though it is something that should be fixed if possible. 
The problem is that "virtualized" is basically a subset of "devirtualized". In other words, a function like `fn f&lt;T: MyTrait&gt;(x: T)` will accept any type that implements the Trait, devirtualized. However, one of the types implementing MyTrait is a special generated type called MyTrait which is a specific object that acts as a wrapper around arbitrary underlying values that implement MyTrait. As to if it is possible to prevent the compiler from providing trait objects for your trait? Not sure; I'll let someone else chime in hopefully.
"Are We Memory Safe Yet?"
\&gt; there is a feeling when it compiles and you don't care about everything. I can relate to that cause I had the same when I used rust and I have the same when I use scala. That being said application are not created for the programmers pleasure but to create business value. You can definitely create fast application using php and if it is good enough for business, go with PHP cause developement time, community/framework support and programmer recruitment in PHP is much lower than it is in PHP. Not that PHP is the way to do it, but if this is small web apps it might be a good choice. For bigger apps you want more strongly typed language with better safeguards use java or scala. Rust on the other has even more safeguard than scala (but not much), but adds a lot of complexity, has a much smaller community and is a hell to recruit for. All in all it is all about tradeoff. But I don't see how rust could pay for its disavantages over more mature ans easier languages (being it PHP, scala, java or others...)
First of all, Scala is a multi paradigm language, but its community and standard library lean strongly toward functionnal programing. When I'll say scala in the following post, it means "functionnal programming in scala". \&gt; the absence of data-races. In scala, everything is immutable by default, and provide strong abstractions to handle concurrency : \`Future\` in the standard library or actors using the vastly used \`Akka\` library. \&gt; the absence of ConcurrentModificationException In scala collections are modified by using \`filter\`, \`map\`, \`flatmap\` functions. There is no such problems. Note also that \`Option\` (exactly the same as rust \`[std::option](https://doc.rust-lang.org/std/option/)\`) prevent \`NullPointerException\` and errors are handled with the rust-like \`Either\` (equivalent of rust \`Result\`). That prevent throwing exception every where. \&gt; By using Scala you are gaining ease of memory management and losing ownership. If you lose ownership for something easier without giving away much of the protection it gives, this is a great thing ! I get the same "if it compile it works" when I am using both rust and scala, but scala is so much easier to understand and work with ! Not that rust doesn't have its uses cases (it definitely has), but since neither memory management nor ultra optimized performance are required for web apps, I don't think rust is a good fit for those kind of applications.
Every programming language subreddit thinks that its language is the best for every thing and I knew this post would be downvoted... The no zealotry code of conduct of the rust community is sometime forgotten. \&gt; The responses to it are interesting. Not the post itself ? :p
How suitable is \`nom\` for language parsing and building up an AST? I've only used for deserialization, but I also see a bunch of libraries using for higher level parsing. This is only vaguely a rust question, but I've been struggling for a long time on where to begin parsing DSLs. 
In this case it isn't a false positive, the code is and never can be used the way it's been written. Unless the function is called within the library itself, it must be made `pub`. The compiler is 100% correct in this instance.
My mistake then, I spoke too soon and should have looked at the code rather than commenting based off my first thought in response to the thread title. I've noted numerous times in developing library code that I will be spammed with warnings that code is dead, though I've I believe ascertained it isn't in such cases. The thought I was left with was that this was due to false positives, which I've had with things like splint as well for example. However perhaps I was just mistaken, and in this case I didn't actually look at the code so shouldn't have commented. 
&gt;Care to give me a concrete example? It works for me to call `invoke` with for example `&amp;vec!\[&amp;1, &amp;true\]`. There has to be pointer indirection. Yeah; it's great for literals but less so variables and esp loops. This is a scenario I find myself in [often](https://play.rust-lang.org/?gist=99a189ac3e56a35cadc9f5c1d99ff710&amp;version=stable&amp;mode=debug&amp;edition=2015). I suspect a half decent (but still insufficient feeling) solution is to change `use_values` from `&amp;[&amp;Foo]` to `&amp;[FooEnum]` since the number of `Foo` implementers is known ahead of time, and `Foo` is a hackily sealed trait. Then, the two vecs can become one.
I was incorrect in my previous post and have deleted it now. I don't know why I had in my head that it was a false positive, it must have been a remnant from my early understanding of Rust which was simply incorrect. Deleted my incorrectness from this thread and my brain, thanks for your correct answer! 
You got it, I forgot to `pub mod` my module. thanks!
The dragon claims he was merely borrowing the castle and now you can't move the princess out of it.
[removed]
This can't be more accurate
I'm going to have to research and play around with `Box` more, I'm not sure I see the difference between them just yet.
What you say is correct, but I was responding to your comment which sounded like it was working from outdated information. &gt;What is Mongo actually better at? MongoDB is web scale.
Maybe r/rustjerk is a better place. We appreciate more content.
The princess is safe, but you can't move her out of the castle
I think the magic happens in a crate called `polonius`, which can probably be found on the nursery. The integration into `rustc` is probably dotted throughout a whole bunch of PRs, so I’d search NLL in the rust repo and filter through for interesting ones
This is great. It's really nice that you don't have to frame a discussion in terms of pros and cons. I'd love to see this get more traction!
I think you have to do some trickery with the js shim. See how `setCallback` is implemented in stdweb here: https://github.com/koute/stdweb/blob/ab8a7ce81f57b831979c5c00f29fc8a9f21df819/src/webapi/window_or_worker.rs
I've used it, it's not great for a lot of reasons. See my post history for details
Wow, this is really great! Also want to give props for how many blue badges there are on the crates compared to last time I looked... 👏
http://ruster.xyz made in actix-web too!
Fabulous work &lt;3
now the data online is for tesing.
Since people rely on the borrow checker to prevent UaF, double frees, etc., and those problems are often security vulnerabilities, any borrow checker failure that allows UaF or similar should be considered a security vulnerability. During Rust code review, nobody is checking for UaF, unlike C/C++ code review. The likelihood that a borrow checker bug will lead to somebody exploiting a Rust application is higher than somebody exploiting this rustdoc plugin thing.
are you looking for /r/playrust this is about the programing language?
I wish there was a really good web framework for Rust that didn't require nightly/unstable features.
I've never imagined a cookbook could be so great. 
Lol yep, this is why I am an ex-Java-er.
haha, absolutely, thanks
Good stuff! I'm an ex-java developer myself and appreciate you posting this and these kind of raw numbers really help fight the myth that Java is fast or efficient.
actix-web?
I looked at that one, but it seems really hokey to me. Their example in their readme ([crates.io link](https://crates.io/crates/actix-web)) makes it seem un-ergonomic to use.
What was your base image? I'm impressed with the rust example only being 2MB.
What was your base image? I'm impressed that the rust example was only 2 MB.
Keep in mind that concurrent connections in rocket are based on OS threads so scaling can be an issue.
you can configure the JVM to use less memory but honestly optimizing something like REST services for memory usage is almost always going to be a waste of time and effort, and I struggle to even think of a scenario where startup time or container size matter
these are usually statically compiled (using musl instead of libc), the container is literally just the raw binary
What about thruster?
How about the Rust cookbook: &gt; This Rust Cookbook is a collection of simple examples that demonstrate good practices to accomplish common programming tasks, using the crates of the Rust ecosystem. https://rust-lang-nursery.github.io/rust-cookbook/ (shameless plug for my shorthand link if that link is too long to remember: https://cook.rustref.com)
It’s a fools errand. Even at large scale these aren’t the things you worry about if your half way decent at your container and LB operations. Diagnostics, productivity, readability and the ability to hire people productive in the language should trump these concerns every time. 
Actually, I didn't.
tower-web is hopefully coming soon
It's definitely usable and there are a lot of examples to go off of. It's uses an actor model for current work so it's definitely going to be different than what you'd normally have to work with in, say, Rocket or Iron. I like it. I was able to get some stuff going I felt good about. Would recommend giving a whirl if you're evaluating options.
Haven't looked at this one, I'll check it out tomorrow.
Writing a [Chip-8 interpreter](https://github.com/RyanLowerr/chip8rs). Received a print copy of the the Rust Book a few days ago and using this project as a learning exercise.
As nice as the performance improvements are, personally I don't think there are many frameworks that can come close to the productivity and ecosystem that Java + Spring provides (which is often needed in Enterprise settings).
I mostly agree, but don't consider it completely irrelevant. I have 143 different services in production, most of them based on wildfly-swarm. Some of them scale up, but some do not allow scaling due to session affinity. These can be uncomfortable waiting for node migration and service stabilization due to startup time, and I have had memory and CPU overload nodes before. But I'm sure that a lot of my problems are due to devops inexperience. The interesting thing about this comparison for me was the magnitude of the differences. Also, the greater amount of static analysis that I got out of rocket vs java (it even checked the routing parameters matched the corresponding functions statically), all in an approach that closely matched the problem domain. It doesn't feel "low level".
Just a scratch image. Unless you have some crate dependency that prevents it, static linking is super easy and results in just a single binary.
The payara-micro service used 12&amp;#37; of the CPU just idling.
Spring is hot trash like most other jvm things. 
Gotham?
&gt;Diagnostics, productivity, readability and the ability to hire people productive in the language should trump these concerns every time. Good point. Can't argue with that.
Is there a video or the presentation online at all?
Nope. It was streamed, but they usually take a week to post the videos.
Most likely you are running nightly. It contains some changes that make crates which have `#![deny(warnings)]` have issues. There have been some workarounds [applied on master](https://github.com/rust-lang/rust/pull/51956), should be in the next nightly. As a workaround you can use stable rustdoc. `cargo +stable doc`. In general, rustdoc *loves* to break stuff in various ways. E.g. the transition in the markdown parser or in what was considered a code block.
Chromecast support would be awesome too, don't know of a crate though.
The static analysis part of this is interesting. Theoretically with that you could have a formal verification of the inputs/outputs which while tedious could be a big win for the Rust type system over other languages. 
Whoops, found it. [https://www.twitch.tv/videos/283019651](https://www.twitch.tv/videos/283019651)
Just wanted to point out that serde-json isn't zero-copy because it will copy strings to turn escape sequences like "\n" and "\\" into the character they represent. To parse JSON without copying, you could make a custom string type, `JsonStr`, which is utf-8 like `str` but can contain escape sequences.
The way you make it sound is that you're getting offended on behalf of BSD, since you're taking issue with the fact that BSD isn't credited for their work when proprietary forks are made. Which is bizarre - if BSD wanted credit, they would use a different license. They intentionally chose a license that allows people to make proprietary forks. I don't understand why you think that this point would convince anybody to agree with you.
I have a java background. I looked at actic-web, it definitely felt dull. Rocket is something close to what I wish but it is *super* unstable. It probably breaks from every way every now and then. I use Rocket for some toys though 
What is that, is there a git repo?
What is that, is there a git repo?
&gt; What about thruster? I had quick look, I think it does not have enough batteries yet. Some people might it though. 
This is a solid app! Reminds me fondly of less cluttered forums from the 2000's. Is your source code publicly available?
tower-web is not public yet. https://medium.com/@carllerche/announcing-tower-a-library-for-writing-robust-network-services-with-rust-67273f052c40
Personally i found this code kind of badly structured generally, nesting too deep, functions too long, etc. I'd probably make the same criticism if this was C. Read up on how to write well-structured, well-factored code, those lessons will apply independent of language and will make your code easier to test and maintain the future :)
Right. But I think that is not an issue for 95% of apps. Also if you are comparing to Java apps, it will scale better than most of the Java frameworks. We can also do other ways of scaling like deploying into multiple machines etc.
What's the point of a container that only contains a single binary? Why does that trump a single binary? I don't understand. I don't know much about containers though.
The point of putting it into a container is that you can use the same tooling and monitoring tools to deploy, scale, and manage it. I would use the same tools to deploy my single-binary container as I use for a large java application. Normalization of tooling is important when you are doing quantities of services more than you have fingers on your hand.
I don't think they are anywhere near a COQ-style formal verification. But, I think the fact that rust macros can verify regexes for correctness and applicability to surrounding code at compile time (without the magic being baked into the compiler) is a WOW WOW WOW.
I understand the gravity-well that is the Productivity+Ecosystem of java. I've done plenty of spring, too. My nagging question is: At what cost? Once the disk and memory costs exceed 10x? 100x? Because that is where we are now.
Thanks for responding! I looked through the links you mentioned. I think that gives the way to call Rust closures from JavaScript, but I'm still not sure how to make that return a message that would get fed as an input into the Yew framework and trigger a model change. For instance, in the hookup code (I made a simplified version of my code so that there's something concrete) for the button my model's `Render::view` implementation, I don't have an immutable reference to my model that I could use to directly try to call `Component` methods on the model (and that sounds like that would be hairy to do even if it were allowed). Here's the area where I'd call the function to pass the callback: https://github.com/scooter-dangle/yew-callback-test/blob/9e6566b66207e1b4c9067fd4d72fef9b99270c31/src/main.rs#L75-L80
thruster requires some weird looking / obtuse boilerplate from what I've seen. Actix and Rouille are two nice choices for different ends of the design spectrum.
oh I forget it. It's base on [https://github.com/actix-cn/actix-cn](https://github.com/actix-cn/actix-cn)
That's fine. Rocket it a great project. In terms of selling points for Actix, you'll want to reach for Actix when you want clear separations of responsibility and a solid concurrency paradigm that isn't the fork-join model that Crossbeam gives you or the task-based like you'll get with Tokio and its a futures implementation. Actix is for long running processes that communicate with each other via message-passing. It seems to work really well as a web framework, but you're free to use to underlying actor library to do whatever, really. If you don't need that level of concurrency, no worries - if you do, it's available to you as an option.
can you explain where the ergonomics are lacking? defining routes and route handlers is really straightforward in the README example. Short of using function attribute macros (like Rocket), which requires nightly... I'm not sure what you would change to make it more ergonomic. What would you change? and would that even make a difference after your application no longer fits in 20 lines or less?
What're the LOC counts for the different versions? Not the best measure obviously but it is simple.
630MB of RAM before you even start doing anything useful is nothing to sneeze at.
trpl has this example([link here](https://doc.rust-lang.org/book/second-edition/ch18-03-pattern-syntax.html#destructuring-references)). &gt; If we had not included the &amp; in &amp;Point { x, y }, we’d get a type mismatch error, because iter would then iterate over references to the items in the vector rather than the actual values. But it does compile without the reference. Something changed in new rust compiler? #![allow(unused_variables)] fn main() { struct Point { x: i32, y: i32, } let points = vec![ Point { x: 0, y: 0 }, Point { x: 1, y: 5 }, Point { x: 10, y: -3 }, ]; let sum_of_squares: i32 = points .iter() .map(|&amp;Point { x, y }| x * x + y * y) .sum(); }
LoC is approximately the same, and could probably fit on your fingers (excluding pom files). BTW - the repo is linked above, if you want to check. The whole "benchmark" is reproducible with nothing but docker installed.
This is a consequence of a recent change to the language. That text was correct *when it was written*.
Why you did not choose Spring Web Flux as modern framework or Undertow as lightweight and fast library for Java?
&gt; you can configure the JVM to use less memory To a certain degree, but you ain't gotta get javaee to fit to lets say &lt;100M memory, nevermind single digit megabyte memory. 
Thanks for your reply. Just found out what changed in rust 1.26 release notes. Ping you for updated post.
&gt; Once the disk and memory costs exceed 10x? 100x? you mean Java deployment costs so much more or I misunderstood?
I am trying to implement the Vec for my own with following the nomicon. I have two questions: * The nomicon uses std:allocate::oom when allocation fails. But this not here anymore. Is the equivalent of this std::alloc::handle_alloc_error? * Is there way to allocate a block of memory ob stable rust? I don't want vec::new hence I want to implement vec myself.
I guess, the [error handling](https://rust-lang-nursery.github.io/rust-cookbook/about.html#a-note-about-error-handling) section should be updated.
The first section "Algorithms": what's the reason it's called that when it is really about random number generation with the \`rand\` crate?
Not exactly a fair comparison. Stripped rust binaries and almost no effort put into reducing the java footprint. Not that disk usage matters for the vast majorty of web apps.
This is great! 
I think the real lesson is that for smaller projects/services, it's worth it to look into straight binaries and frameworks like Rocket. As much as I love Rust, I don't think I'd write a real full web app or the like with it - Rust just isn't quite suited for that IMO with the amount of uncertainty and unsafety that comes with working with the internet and working with JavaScript on the front end. Having written a rather large side project web app in Java, the way the language is able to work with the restrictions of the domain is very nice (and the same goes for C#, though I have less experience there). I've also written a few small things in Rust using a few different web frameworks, mostly to test the waters, and while it was extremely pleasant for small projects I was already starting to feel the issues that come up with the way you essentially *have* to write safe code in Rust - sometimes things just break, and I've found that it's a lot easier to deal with that in a more forgiving language like Java where you can just throw an exception and forget about it until the top of the call stack vs. constantly dealing in Optionals and Results. While I feel like a lot of my complaints are things that would be resolved with more architecting and experience, there's another point - large services will have more data and more to process, in which case longer startup times and larger package sizes aren't much of an issue. But in cases where that might actually matter, Rust could be a godsend. Certainly not something to write off simply because Spring has "more", especially as the ecosystem matures and grows. 
Well it's public, it's just not on crates.io yet (not ready) https://github.com/tower-rs/tower Last commit was about a month ago
&gt;ability to hire people This is something I've heard countless times and I strongly disagree. Any developer worth his salary can and will learn new tools and programming languages, on the job if needed. In my experience, individuals who openly admit to "I only do/care for language/tool X" are the worst possible hire.
Did you see this recent showcase? [https://www.reddit.com/r/rust/comments/8xdsx5/rust\_actixweb\_in\_the\_on\_of\_the\_biggest\_music/](https://www.reddit.com/r/rust/comments/8xdsx5/rust_actixweb_in_the_on_of_the_biggest_music/) backend system for ticketing, entrance control, rfid tags, car management for 450k visitors to a lange music festival, all in actix-web. Pretty hokey indeed! ;)
So if you wrote that for yourself instead of using `toml`, you've been solving a particular problem. What was the problem?
No comparison to spring boot when it's the hottest in the industry for new services right now? (at least that's what it feels like where I am)
&gt; In general, rustdoc loves to break stuff in various ways. E.g. the transition in the markdown parser or in what was considered a code block. You're not being very fair on this one. We switched from a random unmaintained markdown renderer to specified and maintained one (which is wrote in Rust as a bonus). It took us 3 releases to apply this change by default and users had warnings and help to switch their docs content.
[Optimizing sozu's buffer management](https://twitter.com/gcouprie/status/1016643753115881472) :) I started using more `Rc` in my code recently, it solves design issues cheaply
Not OP, but somehow is hard to get diesel documentation in nightly: thread '&lt;unnamed&gt;' panicked at 'attempting to document proc-macro re-export', librustdoc/clean/inline.rs:474:39 note: Run with `RUST_BACKTRACE=1` for a backtrace. error: internal compiler error: unexpected panic 
&gt; Could Rust use a standard module for important stuff like http, json, ssh, sql etc is my ask. The problem is that you can't rush these sorts of things. Python tried and the result was `urllib` and `urllib2` in the standard library with everyone recommending that you use `requests` instead, which, along with its `urllib3` core, is intentionally kept out of the standard library. The APIs will be ready when they're ready. In fact, the standard library itself is intentionally minimalist to the point where things like the regex engine and the random number generator are distributed as separate crates, despite being maintained by the Rust team, because that grants more freedom to evolve them independently of the standard library. &gt; But, could we do better? find a way to expose complexity only when necessary and not for the beginner who just wants to read several files, process text or serve a simple API? The problem there is that the most commonly cited source of complexity is the borrow checker, and that generally comes about because, for the first time, Rust is requiring programmers to have a solid understanding of how memory actually works. (Despite having no experience with non-GCed languages outside of two university courses using C and C++ and no experience with statically typed GCed languages outside of two courses that used Java, I had no problem picking up Rust because I had a solid understanding of the relevant theoretical models going in.) Languages like Go get around that by having a big runtime with a garbage collector to pick up after you at the cost of needing substantial elbow room in memory to allow garbage to accumulate before being collected. Languages like C or C++ get around it by allowing you to make all sorts of subtle mistakes which could lie dormant for years before biting you when you least expect it. That said, efforts are being made in areas where it's feasible, such as match ergonomics and non-lexical lifetimes. &gt; The key is to get more and more people to use the same optimized modules. If not a standard library, a "preferred library collection" or "extended core" if you will that the community can count on for being maintained and optimised. That sort of thing has been attempted before with projects like [stdx](https://github.com/brson/stdx) but, so far, they haven't really excited the community enough to take off. See also the "libs blitz".
Fight on! Gotta love languages that get compiled down to native binaries. 
You could have talked about `ConcurrentModificationException` if you wanted to illustrate the benefits of the borrow checker to Java programmers. The borrow checker is not only to prevent segfaults, but also to prevent things like iterator invalidation, race conditions, etc. 
I can. Most of my applications run at will, either scheduled or in response to an event trigger. The faster they load and the lower amount of memory and CPU they use, the smaller I can make servers and containers, and the quicker they'll get their job done. All of my applications run on cloud servers. We pay for storage, memory, CPU cycles, you name it. Reducing those reduces cost. Significantly. If I ever hope to migrate my applications to a serverless reactive execution environment like AWS Lambda, the last thing I want is a 200MB container that uses 630MB idling and takes 22 seconds just to get started. That's a huge waste of resources, and thus a huge waste of cost. Now, when running on AWS Lambda one wouldn't also use a java-based webserver: Lambda would replace the webserver. Therefore my comparison isn't entirely fair. 
Thank you, now I see the full context of the new `dyn` keyword. So all the "template-y" syntax `fn foo&lt;T&gt;(arg : &amp;T ) -&gt; u32 where T: Foo` will be statically dispatched.
Nice! I always like looking at the ongoing benchmarks from TechEmpower and then filtering on Rust and Java: https://www.techempower.com/benchmarks/#section=data-r16&amp;hw=ph&amp;test=json&amp;l=h7atmn
I agree with this. I love Rust, but it does the community no favours to ignore progress being made in other technologies for the sake of a favourable comparison (particularly with regards to the modular JVM). That being said, I'd like to see what a standard Spring Boot deployment with equivalent features looks like compared to these. I expect I'd be able to embarrass some of my colleagues into adopting Rust once things stabilise a bit more. 
As a site-note to what softshellack stated, since a container is completely isolated in terms of files and processes, and can have its resources limited, any security issues of your application should be *contained*. This is helpful if you have a server that runs a lot of services.
Yes. In fact, every type parameter like that has an implicit `Sized` bound so you couldn't pass a trait object there unless you explicitly declared it like `fn foo&lt;T: Foo + ?Sized&gt;(arg: &amp;T)`. The one caveat is this is still possible if you have a blanket impl of your trait for trait objects, but that's a complex case.
Great work! It immediately answers a couple of questions I had regarding some best practices like logging and parsing command line arguments 😀
As someone who also does a lot of Go, I would say my main reason for staying with Go is how easy the compiler is to work with. Have you ever tried to get a web server running on Windows? Well, good luck: after having spent several days dealing with compiler toolchains, I still can't even get a simple to-do rest api running. I believe things like this keeps out more people than the fact that the language is difficult does. Cross platform compatibility doesn't seem to be something people care that much about in the rust community. In my opinion, being able to run a program on multiple platforms, without huge issues is likely some of the best that can be done for adoption. Look at languages like Go, Java, JavaScript and python: all very popular languages, with the main thing shared being that they are cross platform. Rust can compile on multiple platforms, but is very much a pain if you are not using Linux. Just my 2 cents.
On Twich, very interesting. Thanks for linking it though, awesome. 
&gt; The problem is that you can't rush these sorts of things. Python tried and the result was urllib and urllib2 in the standard library with everyone recommending that you use requests instead, which, along with its urllib3 core, is intentionally kept out of the standard library. &gt; &gt; The APIs will be ready when they're ready. Even so, there's now been three years since Rust 1.0 was released, and we *still* have no standard way of structuring (non-blocking) I/O. Futures was first announced in 2016 and we're currently in a limbo of "0.1 is released and used, 0.2 is kinda released, but never mind we're going to change it all soon". Everyone wants to like Tokio, but it's ever-changing and quite complex. `async/await` is coming soon and will *hopefully* solve all of our problems. And Mio, used as a foundation for all of this, has still not reached 1.0. Go's way of doing "blocking-looking I/O in a coroutine" is by no means perfect, but it's been extremely successful in the way that it allowed the community to build up a large set of libraries that works well together. I'm mostly doing web/network-development and I've been waiting for *years* for some stability. I love Rust as a language, but I get exhausted thinking about implementing a network server and keeping it up to date with the latest futures/tokio/async/await-features. I understand that creating good APIs take time, but I'm getting really tired of waiting.
What in particular is a pain on Windows? That should probably be improved upon. All platform differences should be abstracted away if possible.
I cannot agree to your last sentence: I use Rust on Windows as well as on macOS and it’s as simple and just works like on Linux.
A bug isn't a breaking change. :) (If there is no issue about it, you should open one btw!)
This is https://github.com/rust-lang/rust/issues/52129. Bugs happen, find them is why we have Nightly and Beta.
A regression is a breaking change IMHO. But you are right about the second point: https://github.com/rust-lang/rust/issues/52251
Lambda is the use case that keeps me coming back to look at Rust the most. I don't have a ton of perf sensitive code, but I keep dreaming about pulling pieces of that out and rewriting it in Rust on Lambda. Just curious, are you using Rust on Lambda in Production? If so, are you using something like Serverless to manage it?
I don't understand the complaint. Just consider that async I/O in Rust isn't ready yet unless you're willing to get involved with its development and/or brave unstable APIs. Otherwise, if you need async I/O, then use a different tool. When the async I/O APIs have been built out in Rust, then come back and re-evaluate it as a possible alternative. I mean, everybody is always waiting for something. If it isn't ready, then it isn't ready.
I think that you are right.
I agree people can and will learn new tools and programming languages; however, I think there is nothing wrong with disliking certain languages. For instance, I will never consider a job that uses PHP.
A few things that would make it more ergonomic (and I'm aware these might require nightly): * routes declaratively defined on functions * path parameters as function parameters * (optional) query parameters as function parameters It's unfortunate that you have to declare the path (with parameters) in one place, and then the unnamed parameters types elsewhere. The parameters are also unnamed when they're used.
I personally find handling Optionals and Results a lot more ergonomic than dealing with exceptions. My Java prof would've probably gutted me for considering 'just forgetting exceptions until the top of the call stack' a valid design decision, but if that's really a something you strive for, couldn't you just keep returning the Err upwards with the ? operator in rust to achieve roughly the same thing?
Take actix-web for instance. It depends on ring for implementing TLS, except ring 0.12 doesn’t compile on Visual Studio 2017. It’s been fixed in ring 0.13 but this sort of problem doesn’t inspire confidence. 
Java has massive problems with having to bypass the static type system very frequently. While Rust can use Macros and still throw you a compile time error If something is wrong. This happens in (De)Serialization, Route matching, Dependency Injection, Exception handling and a few other things. Rust can allow you to avoid much headache and forbid very bad patterns. 
That libraries requires different compilers, some requires the rust compiler, some requires a c/c++ compiler, son requires one build system, other requires another. Rust attempts to invoke all of these correctly, and points for that. However actually getting all those toolchains working are a pain, in my experience. And libraries that I have attempted to work with then doesn't care all that much for windows compatibility, especially when it can be broken for several months before someone gets around to fixing it (the last one I fought with was some cryptography library (ring-something).
&gt; This cookbook is intended eventually to provide expansive coverage of the Rust crate ecosystem, but today is limited in scope while we get it bootstrapped and work on the presentation. Hopefully, starting from a small scope and slowly expanding will help the cookbook become a high-quality resource sooner, and allow it to maintain consistent quality levels as it grows. &gt; &gt; At present the cookbook is focused on the standard library, and on "core", or "foundational", crates—those crates that make up the most common programming tasks, and that the rest of the ecosystem builds off of. https://rust-lang-nursery.github.io/rust-cookbook/about.html#a-note-about-crate-representation
I like this idea, hm.
In that case check out [this talk](https://passthesalt.ubicast.tv/videos/secure-programming-is-slow-really/), 17:00 and on. You might squeeze even more performance out of it that way.
It seems that cargo build and cargo update don't respect the .cargo/config paths override and still use the Cargo.toml from the original source (git repository for me). Is it the case? Is it a bug or a feature?
You'd need a streaming iterator for this, since if you do this currently then someone could just do `.collect::&lt;Vec&lt;_&gt;&gt;()` and get a vector of overlapping mutable references (which is undefined behaviour). Streaming iterators are currently impossible to write generically in Rust because of the lack of generic associated types.
&gt; for the first time, Rust is requiring programmers to have a solid understanding of how memory actually works &gt; git gud FTFY Except Rust only requires programmers to abide by the automatically enforced rules, which can easily appear arcane to a learner. Your description fits C much better, because whether your program works is random chance if you don't understand how memory works. In Rust, you can poke your code until borrowck is happy. You really only need deeper understanding when writing `unsafe` blocks because that's when you say "compiler, I know your rules and I have more information than you, step aside". The borrow checker is the most commonly cited source of complexity because it is restrictive, and one can only really have fun with the language once one memorises all the rules. You seem to have known them before getting into Rust, which is good for you, but unfortunately not applicable to the general user base.
&gt; Otherwise, if you need async I/O, then use a different tool. When the async I/O APIs have been built out in Rust, then come back and re-evaluate it as a possible alternative. Well, many people are pitching Rust as The Next Language to write network services in. In fact, the [2018 Roadmap](https://blog.rust-lang.org/2018/03/12/roadmap.html) mentions "Network services" as one of four specific domains the core team wants to demonstrate Rust's productivity. This seems a bit off considering the current async I/O situation? My comment was in the context of "what can we learn from Go". Rust has a great feature set for writing efficient and correct code, and yet people keep choosing Go. The often cited reason is that people "can't bother learning the borrow checker" or haven't "seen the light yet" or "aren't willing to spend time writing correct code". Well, I think there's something else that we don't talk much about: Rust's culture of attempting perfection that goes against stability. Look at crates.io: 7 out of the 10 most downloaded packages haven't reached 1.0. People are not willing to commit to a stable API because they want to find the "perfect API" before they stabilize it. That is admirable, but we must also acknowledge the disadvantages. As the Rust community continues trying to find the "perfect API" for async I/O, more and more packages are written in Go and their ecosystem increases.
It just so happened that Container size starts to get important for me after i managed to exchange one of our java service with a rust one and realized that time to deploy it drastically decreased from "i can get me a coffee" to "alt+tab to the browser and open it now". And this is not just because of lower startup time but especially because of lower transfer time.
A breaking change is intended whereas a bug isn't. Also, a breaking change is supposed to remain. But this is another debate. :)
&gt; the next language That's different from the current language 😁
&gt; really good I like the name though.
But releasing 1.0.0 means telling everyone it's ready. Rust did it and yet so many things are not ready. Yes, versioning is tricky, especially if important parts of the language are implemented in libraries and not shipped with the platform, but at the moment, people get a language that claims to be production ready, yet big parts are still in r&amp;d, there is no standard solution to be found for fundamental things like async IO, and advanced stuff often requires switching to nightly, which is a friendlier word for unstable.
Fuzzing all the things! [Rust-fuzz](https://github.com/rust-fuzz/) has excellent integration of fuzzers for Rust. Also hoping that someone would give some love to the DoS bugs I've found. I've fixed at least four of those myself in png crate but [this one](https://github.com/PistonDevelopers/image-png/issues/80) is beyond me, any help with that would be appreciated. If you want a simpler real-world crash to fix, try [the bug I've found in lewton](https://github.com/RustAudio/lewton/issues/27).
&gt; This seems a bit off considering the current async I/O situation? How so? The roadmap says that this will be ready before the end of 2018. We are not in 2019 yet AFAICT :D 
Crypto is hard, complex, and relies on low-level/hand written assembly to avoid things like timing attacks. Existing crypto libs have been built over decades, and continue to have security problems found. Ring is an amazing project that is an attempt to have a secure crypto lib in rust. To get going, it reused some C code and is now rewiting those bits in rust. AFAIK there haven't been any security problems found in ring yet. It now works on Windows. I really think that web is somewhere rust shines. If you want something to slag off, pick GUI instead.
I have a blog that I've been working on, it has a few examples and tutorials and stuff, vishus.net Also see the tutorials page https://vishus.net/content/tutorials And the Rust snippets https://vishus.net/content/rust-snippets
Is that a screenshot from elementary OS on the frontpage?
`ref` is necessary if you want to go from a `&amp;mut _` binding to a `&amp;_` one in one pattern match. But yeah, proposing `ref` when the matched type is `&amp;_` is odd.
&gt; And libraries that I have attempted to work with then doesn't care all that much for windows compatibility, especially when it can be broken for several months before someone gets around to fixing it (the last one I fought with was some cryptography library (ring-something). I have access to Linux machines, I have access to MacOSX machines, I can test against a huge body of hardware on these using qemu, ... The only thing I don't have access to, is a Windows machine, it is pretty hard to set up CI for Windows properly, Windows has its own scripting languages, broken toolchains (MSVC 2018 still is not a C++03 conforming compiler nor a C99 conforming compiler...), mixture of toolchains (clang-cl, mingw, ... are used to work around thigns), ...
Is this the cookbook that determines what crates are added to the playground?
The roadmap is a description of what is planned, so I now I _really_ don't understand your complaint. The relationship you've ascribed between "perfection," "1.0" and "0.x" also seems to be in error. "Perfection" is not necessarily the only thing holding back a `0.x` library from becoming a `1.0` library. Additionally, the implication that "they aren't working as quickly as I expect" means "they must be chasing perfection" also seems pretty uncharitable from my perspective.
I have a [[tests]] section like this one: [[test]] name = "compile_test" path = "tests/test.rs" #required-features = ["cli", "concurrency"] When I run cargo test like this it tries to run a test but if I uncomment the "required-features" statement than no tests are running. What could be the problem here? 
There will always be parts of the language that are in "R&amp;D." This is true for many languages, including those that are far older and more mature than Rust. &gt; people get a language that claims to be production ready, yet big parts are still in r&amp;d, there is no standard solution to be found for fundamental things like async IO, and advanced stuff often requires switching to nightly, which is a friendlier word for unstable. Async I/O is hardly fundamental. Plenty of people are putting Rust into production for use cases that don't require async I/O. Async I/O might be fundamental to _certain use cases_, and if you're in that category, then yeah, Rust might not be a good fit right now. Why is this a problem aside from an exercise in patience? If Rust didn't release 1.0 when they did, then where would we be today? Still without async I/O, and probably zero (or almost zero) production users. We probably wouldn't have any books. The community would be smaller. We'd have less experience with real production uses. Plenty of tools that people have built probably wouldn't have been built (ripgrep certainly wouldn't exist). Really, people, if Rust doesn't fit your use cases today, _that's OK_. The name of the game is steady incremental improvement. We don't need to be all things to all people all at once. That's just impossible.
Personal anecdote: anything involving the phrase "pkg-build" is going to be a huge pain. Similarly, "MSVC not supported". I've found myself wishing, on multiple occasions, that there was a directory somewhere that I could just dump the required pre-built libraries and have them ingested into the build. Actually, I recall there *used* to be a spot you could drop them, but that was just a side-effect, wasn't intended, and I believe it got "fixed".
I contribute a bit to https://github.com/uutils/coreutils It's good to work on if you know the core Linux tools and it's not too hard to find bugs. Plus the maintainer seems to know what he is talking about. 
Does "CN" mean "Chinese"?
So if it's not task based concurrency is it thread based then? 
\&gt; I really think that web is somewhere rust shines.. I have to disagree. It's where rust \*should\* shine, but... the web frameworks for rust are half baked at best; there's nothing even remotely production quality for web services, and for generic network services, the async I/O story means it's not particularly compelling. 'Simple' integrations like msgpack and protobuf are painful to use and have (as previously mentioned) some scary cross platform stories (like, they don't work). By comparison, as a 'pure' backend component (ie. no C dependencies) in a large GUI application (eg. firefox) rust \*does\* shine; right now, that's the compelling use case; secure high performance backend code. ...I don't think 'crypto is hard' is a reasonable excuse. Everything useful is hard; its just many of the crates to offer features are just half-baked c-bindings from bindgen, with no idiomatic wrapper over the top, and often, the basic expectation that someone has run 'aptget install libfoo' in order to make it work. I think the parent comment is very fair, for a \*lot\* of crates.
You can't run it in kubernetes without containerizing it
Mainly some bug fixes, but still be proud of Rust. It's keeping promises, following onto the roadmap. Connfident about Rust 2018. 
i think it uses tokio under the hood
True, async IO is not fundamental in the sense that nobody can work without it. I meant fundamental as in "if we don't standardise this, we're going to get serious interoperability issues in the future". I hear Scheme has this exact problem because everyone builds everything on their own. As you say, the release was a people decision, not a technical one. The thing is, if you make a promise for production readiness, you need to follow up on it somewhat quickly, which, when you look at the last three years, did not really happen. I wonder why. Is it not on the priority list? Are there still too many technical hurdles? Does it take longer than in other languages to write libraries with pleasant APIs? Are there too many big changes to the language that have a vast influence on API design and would mean a 2.0 release once they land in stable? Maybe a bit of all of the above. All this would not be a problem on its own, but you do not find out about this situation until after you have already invested time into learning the language. Nobody warns you about this. That's why I think people bring on this complaint.
What a sound and honest comparison! LOL
I am sorry we all know Javas problems but these benchmarks are nobrainer. I am tired of seeing all these from Python to Nodejs to Go to Elm to Elixir and then Rust. 
&gt; Support match ergonomics Great! I've been looking forward to this - match ergonomics were really hard to use before this because they threw errors all around the place.
C\# + ASP .NET Core will net you as much productivity, with performance numbers that are closer to rust (I get ~20MB and ~0.3s startup for a simple service - I don't have throughput numbers).
I'd not be so confident that 'most' java frameworks don't scale. Async network libs like Netty and Xnio have has serious amounts of time put into them. Anyone serious about perf is using something that builds on such a foundation. Look at undertows performance on the techempower benches. It's obvious that rust will always trash java if you need to lighten your memory footprint, but on most other metrics I wouldn't expect the gap to be so wide.
Is there a Maven plugin that can strip out unused java classes/packages from the resulting zip/binary
I never said it was easy, I agree it's hard. I have a couple of programs where I maintain cross platform support, and it's a pain in the butt. Yet somehow toolchains like go has managed to do this: flip two env variables, and you are pretty much good to go, at least for the compile side. (however C support it still clunky, and I imagine that is due to the same problems that rust is suffering) But the problem being hard doesn't make it any less of an issue in my opinion, and I'm as open to good solution as the next guy. Another problem this presents is: because windows and rust is difficult to get started with, very few windows developers will switch to rust, therefore there is no one to maintain the windows support. Catch 22, and therefore fewer windows users.
Oh, right. Sorry, I didn't word that properly - I even use tower-grpc myself.
It would be nice to include vert.x in this comparison
Just letting an exception bubble up the stack until it hits a high level handler (one actually high enough to truely \*handle\* the error) is what you should be doing, \*provided you are cleaning yourself up on the way up the stack in finallly blocks\*. Unfortunately, Java checked exceptions make this harder to do and I rarely see such code (It is quite common in C\#). Such code is also essentially the same as passing errors back up the stack in Rust.
Yes, there's a few I believe, most of them based around proguard. The main problem with using such tools in Java is that they cant detect classes accessed via reflection, so you need to manually specify any reflectively accessed classes.
I strongly feel that Go will not address complexity as a codebase grows. Go chooses conformity over expressivity. That makes code look fairly similar, but as your codebase grows this problem is a lot less significant than "I needed to jump through hoops to express this thing". An obvious example to me is filter/ map. Using 'for' everywhere is *consistent* but not *expressive* - combinators are *expressive*, and, frankly, quite consistent too, albeit less so than a single construct used everywhere. I find rust code to be much more readable (I have read many thousands of LOC in Go) for this reason. I am not a Go developer, so I can not draw from experiences writing Go (though I have read quite a lot of Go, and work at a company that uses it quite a lot).
yes, but you can easy and quckliy change it for your local language.
C does not require you to understand memory. It's the same as rust - it only requires you to get the code to compile. C is just willing to compile more code.
.cargo/config shouldn't be ignored. Maybe you have the syntax wrong? 
Well, you won't be using stable if you're going to dive into `std::alloc`, anyway. `Vec` *is* the way to allocate memory on stable -- it has been described as "the community's malloc". 
Right on the money with python, `urllibx` and `requests`. I applaud the decision to keep those thing out of `std` -- they only slow down the innovation. With `cargo` i could care less if `reqwest` is in `std` or a separate crate -- including and using it is seamless. The good thing here is competition -- every crate has an equal footing at achieving the "goto status". And if current "goto" gets stale or maintainer looses interest -- new one can easily take its place without a "committee" being involved. Stay lean, Rust!
I'm not aware of any broken promises, and I don't see any evidence that folks haven't followed up on making Rust production ready. If you think there has been some misleading communication, then you might consider finding explicit examples and giving constructive feedback on how we could avoid being misleading in the future. I do agree that it would be nice if the instability of async I/O in Rust were more apparent. hyper does a good job of telling you this, but neither the futures nor the tokio project READMEs give any kind of warning. I'm not sure your response is proportionate though.
The thing is that no language fits my use case, but rust is the closest, so I am in a perpetual state of "make rust do everything for me because it's the only language I like anymore". It is a frustrating place to be.
I’m guessing this is related to the game ”Rust”? Then you should visit /r/playrust .
Agreed. Netty is not "normal java" code either, as I recall - using stack allocation, a separate heap, etc.
That possibility went away a long time ago; the other people working on similar libraries quit them and threw their weight behind Tokio. The community is very understanding of these issues and has worked pretty hard to prevent them.
If the goal for the year is to make Rust good for production web services, doesn’t it reason that it’s *not* ready until next year? That’s why it needs a working group.
Bummer; I’ve never run into those issues. We must use very different crates!
I used Actix-web like a month ago using VS 2017. Is that situation new?
I agree with you. Writing C feels like programming a computer, or at least the computer C was developed for. Writing Rust on the other hand is like programming, well, Rust.
Personally, in the near term, I'd like to write a Rust web service as an Nginx module. I'm hoping [ngx-rust](https://github.com/nginxinc/ngx-rust) will make it easy soon. I've had an excellent experience working with [OpenResty](http://openresty.org/en) in the past, so I'd be psyched to do it with Rust.
As somebody who routinely programs in a bunch of different languages, I disagree with this approach. Using `reqwest` is seamless (for a definition of "seamless" in which your 5-line program is now required to use Cargo instead of just `rustc` because you want to pull from a URL). Finding `reqwest` and figuring out if you should use it in a complex crate ecosystem is quite difficult. Competition is great (I guess?) but as a language user at some point please just tell me who won. I'll use that. Heck I'll even help to maintain and extend that rather than writing my own competitor. Key crates must not depend on a single developer or even a small group for their maintenance and evolution: I've watched that fail over and over again in software engineering communities.
Thanks for the feedback. Are you specifically referring to the crate representation? [Error-chain deprecation](https://github.com/rust-lang-nursery/failure/issues/181)
1.0 doesn't mean "it's ready". 1.0 means "stable". 1.0 never meant Rust was "production ready" because being production ready means being stable, having a large ecosystem of libraries, having a pool of developers to employ, having lots of learning materials in a variety of forms such as books, blogs, documentation, videos, training courses, etc. 1.0 was the precursor to all of those things because without stability, the ecosystem won't form, people won't bother writing documentation or creating videos when the content will be outdated tomorrow, and developers won't bother learning a language just to see their knowledge obsoleted tomorrow. 
As is typical in open source, if people contribute, things can get done faster. I read plenty of complaints that networking or HTTP isn't ready yet in Rust. Yet somehow, lots of people manage to build excellent web services with it. If we could convert the energy from writing up complaints into contributions, I wonder how much more would be accomplished.
Declaring routes on functions is super magical IMO. I’d rather explicitly declare them in a routing block with some nice syntax. You can use an extractor struct for path and query parameters in your handler function parameters. Declaring them directly as parameters on your handler function would again require much syntactical magic. 
Thanks, good to know. The syntax is fine, it started to work when I pushed my update to the git repository. Maybe cargo clean could have helped me.
I don't really get the focus on performance in that thread. Rust is usually faster by default than Go, okay, sure? But they're both generally within the same order of magnitude. They're both Fast Languages, where the main performance advantage is that you usually don't need to worry much about performance. Just write code, and it will probably be fast enough that your performance will mostly be limited by I/O of some kind rather than CPU. For most applications, that's enough. Getting significantly better performance than that will be a question of how you design and organize your system, no matter what language you use. I don't think it would occur to me to tout speed as a big advantage of Rust over Go.
Well, it is a screenshot of the application with the elementary theme (eGtk) in use. So: kinda.
So the relationship was more organic than that, both being fed by the 2017 Lib Blitz. Here's when those crates were added to the playground: https://github.com/integer32llc/rust-playground/pull/198
I've used it for such things and it works fine, though it kind of combines the lexing and parsing steps that usually are separate... eventually just for the sake of my brain I wrote one `nom` parser for lexing tokens, and another one for parsing the token stream.
Last I checked, valgrind worked fine.
&gt; Have you ever tried to get a web server running on Windows? Well, good luck: after having spent several days dealing with compiler toolchains, I still can't even get a simple to-do rest api running. I believe things like this keeps out more people than the fact that the language is difficult does. FYI, Rust *does* compile out of the box for all OSes, just like Go. The difference is that in Go people generally stay away from any C what-so-ever, which means you don't need a C compiler for that platform. But then you try sqlite and yes you do need a C compiler for Go as well. Try a Rust program without any dependencies and it'll work just as out of the box as with Go.
Yes, your point is well taken. The presentation was a mess, and I'm flattered that you took the time to watch it. I'm selfish, so I usually do presentations only when I have something that I want to learn, and learning is motivated by having to explain it to others. I got a late start on this presentation, so it never came together. Once I finished with the perf-demo and had some scattered slides, I was out of time and winged it!
The reorganization aligned the sections with the categories as presented on crates.io as seen here: https://crates.io/categories There are a lot of crate-category relationships that could use some development. I've already heard a lot about categories on crates.io not aligning with expectations. For example https://github.com/rust-lang-nursery/rust-cookbook/pull/404#issuecomment-398108333
Just throwing my 2 cents in because I'm bored... Go * Quick to compile * Easy to learn * Good performance, not the fastest but definitely not slow * Easy to cross-compile for other targets * Solid standard library * Servers with high concurrency feels like its strong suit * Wide variety of quality libraries Rust * Not too fast of a compiler, but things like `cargo check` help a lot, and the team is always working to make it faster * High focus on performance and memory safety * Enums (one of my favorite features of Rust) * Good type system for modeling business logic in comparison to Go due to things like Option and not allowing uninitialized structs (Go has "zero values" but I like the explicit-ness in Rust) * Great package manager and build tool * Wide variety of quality libraries * A focus on "perfection" before stabilizing APIs and libraries. This can be painful but ultimately I think it's for the better * Easy binding to C libraries * Hygienic macros I like both quite a lot, and I've mostly settled on preferring Go for servers and Rust for everything else. At work I wrote a WebSocket server in Go and I can't imagine implementing it as quickly in Rust. On the other hand, I'm writing a CLI in Rust and with tools like [structopt](https://github.com/TeXitoi/structopt), [serde](https://github.com/serde-rs/serde), and [failure](https://github.com/rust-lang-nursery/failure), I can write something of high quality very quickly, with not a whole lot of lines of code. So as always, use what you're comfortable with and what you think will complete the job in a satisfactory way.
You probably could use `rustc` if you were to pull the crate by hand, but what's the point? I can see it being valuable when rust module is just part of your build for another language, but even then you'll have many more diverse libraries and settings to grapple with. Anything but a simple "hello world" pulls tens of crates anyway. I don't think it is a bad thing though, mainly because cargo makes it easy. Any useful real world app will use crates / libraries -- there is no way around it. Transcending back to python -- batteries may be included, but they are also old. You'd still use django or flask if you build a web app, not urllib! You'd still use Jinja for templates and not that shadow of a template library that is in std. I.e. after a while you never use built-ins, except for very core things like hashmaps, strings, etc... Crate selection will always be a "problem", but crates.io or other sites, with better ratings, popularity, comments systems will help. Eventually the eco-system will settle down and a tutorial that you use to learn a feature will give you the generally accepted "goto". I still don't see the need to prescribe the "winner" by including it into std. 
I disagree with that; if you have an idea of how stack frames are popped on and off, then Rust Just Works. Without that mental model, however, you're right, it can seem that the rules are weird.
You have to ship at some point; you can't keep waiting for the best language to be developed. Perfect is the enemy of good in this case
1.0.0 didn't mean "it's done". It meant "we promise that from now on, it will be stable." This allowed people to start relying on the parts that were done, and also rely on any new parts introduced to the language gradually.
I considered using ProGuard, but I have no experience with it and didn't think I could get it working well in time. Likewise for java 9. Do you think it would have made a qualitative difference? And the other thing that wasn't quite fair was the consideration that the bulk of the size was the java base image, which is shared among all the containers on the same node.
So how does vec itself uses to allocate memory? I looked the source code on github it looks like it uses unstable api. But source code is probably unstable release. Is stable vec is same?
I'm not sure what "deployment costs" means. I was speaking of runtime resources like disk and memory. As a java guy, I feel like I don't notice the overhead anymore. I don't worry about freeing memory, since I have GC. I use JEE standards or akka to make me not have to worry about concurrency, but there is additional runtime costs for that. I have always considered this worth it and the price to pay for productivity. But for this exercise I'm just taking a step back and trying to make that overhead explicit so that I can see it. Like a fish doesn't notice water, I usually don't notice jvm/java overhead.
Sure I get that too... But that's hardly a problem with Rust specifically. :-)
The problems we have with Windows &amp; Rust is because Rust crates typically have a dependency that interfaces with C at some point, and often that requires compiling C libraries as part of building a rust program. &gt; Yet somehow toolchains like go has managed to do this: Unless they are re-implementing everything in Go, or not interfacing with the OS at the low level, they must have the same problems. So the question is how are they doing is? My suspicion is that the dependency trees that you have worked with in Go just did not needed to compile any C code to build. That is, they have the same problems than Rust has, but they haven't solved them, yet because of the different application domains they are less noticeable.
Eh, I guess we'll have to disagree. I don't find it magical at all, and it makes a ton of sense to have the route tied to the function. It's like the name of the function. You still have a routing block where you specify which routes/functions to include, and you can mount them as sub paths too. At least that's how most good web frameworks in other languages work.
Try /r/playrust 
I have to disagree here. I've been building Rust web services at work now for two years and things have been getting very good. My toolbox has usually hyper, ring, kafka, tokio and futures, and my services just keep on running consuming small amount of resources, handling large amount of requests and without crashing for months. I open Grafana if there's some problem, but problems happen only a couple of times a year and have always something to do with the datacenter or network. Async/await will make writing async Rust easier and more fun for sure, but already now I have many success stories with Rust. It's hard to even consider using some other languages for the things I do for my company.
As much as I love the Intellij Rust plugin, I've had to move to Visual Code + RLS on my laptop since I was getting really bad performance, especially as my project became bigger. I really hope they try to focus on performance soon. 
I think the focus on performance can be explained, from the perspective as a Go programmer, as an important and legitimate use case for using Rust instead of Go for certain use cases. In this context, I use "Go programmer" to affectionately refer to someone who prefers the language design trade offs made in Go to the one's made in Rust. But there are certainly other reasons for which one might use Rust. As someone who uses Rust and Go daily, there are definitely a few other than performance. :-) And I will not list them, because it's just an invitation for a flame war. And everyone knows them already anyway.
Is there a way to make the rust linker do early binding of a COM interface? I'm using a com interface and it keeps giving me E_NOTIMPL (0x80004001 hresult) when I use the methods which is indicated on MSDN docs as happening due to: "Late-bound access using the COM IDispatch interface is not supported." The interface is listed as using IUnknown. I'm using the winapi crate and macro RIDL to bind the interface. 
People *are* writing network services in Rust. But. Go 1.0 happened in 2012 and Rust 1.0 in 2015. In addition, Go is a much simpler and less ambitious language, and async is core to both the language and its execution model. Rust does not compromise. So it takes more time to find an API that is safe, efficient, flexible, and compatible with its C-like execution model. This is cutting-edge stuff (C++, which puts a far greater burden on the programmer, is still only now possibly getting async/await), and it's not "just" an API. In Rust, the type system pulls a lot of weight. It sets the contract for what Rust code can do, and what guarantees it needs to uphold. If we get something as fundamental as futures or coroutines wrong the amount of refactoring needed throughout the ecosystem would be pretty horrendous. So it's really important that we get the best possible design. If anything I think Rust may be trying to rush async/await too much because it is one of the most glaring ergonomics advantages some other languages have. But the excitement for it is just too great, and it *does* appear to be shaping up pretty well after some false starts. But that's community development for you. If you don't want to join in that's fine, but you can't expect open source community projects to work in secret until they have a fully-formed 1.0 ready.
I'd imagine after some trial and error I could craft a whitelist of classes that are in fact needed. 
Could we get a moderated "official" list of recommended crates for various tasks that presents alternatives, pros, cons?
&gt; At least that's how most good web frameworks in other languages work. I don't know of any popular frameworks in any other language that allows you to define the route on the function declaration, but it's possible that I just don't have experience with them. Ruby on Rails doesn't, Flask doesn't, I'm pretty sure Django doesn't, I know that Go's `net/http` doesn't. Actix follows a pattern that is pretty common across languages and frameworks, except it provides more compile-time type safety than many of the others.
&gt; If all libraries were to check in their Cargo.lock, then multiple copies of the library would be used, and perhaps even a version conflict. This is incorrect, and is even contradicted by the previous paragraph in the FAQ. Cargo ignores Cargo.lock files of dependencies, so multiple dependencies providing Cargo.lock files would have no effect at all. It appears this text was based on [this comment](https://github.com/rust-lang/cargo/pull/534#issuecomment-54776481) which stated, "If each dependent library checked in a Cargo.lock, **and Cargo used it**, you would instead get multiple, duplicate copies of those dependencies" (emphasis mine). But it accidentally dropped a key part of that explanation.
&gt;Competition is great ... but as a language user at some point please just tell me who won. I'll use that. I think this statement summarised my thought better than when I wrote the post. Sure, I'm not advocating to add libraries like reqwest or SSH or serde into standard lib either, but we as a community need a way to see what won and could be relied upon (stable API) . There can be a few tens of implementation of http/2, but tell us which one does the Rust core team puts their weight upon, and the other novice users will safely use them. 
Yes, it is 100% a me problem. I just sympathize with wanting it all haha
I don't think that's plugin fault. IDEA is extremely slow by itself. I've tried to use VSCode + RLS, but it just doesn't work.
Just to clarify: Rust doesn't have its own linker, the linker has nothing to do with COM binding or linking, and rust has no built-in support for COM. So if something wrong with your COM code, it's in your code, not in Rust or any of the tools. Anyway, AFAIK, `RIDL!` doesn't support dynamic access through `IDispatch`. It does regular static binding to the described interface. So if the library is complaining about access through `IDispatch`, I would assume that you've either accidentally written code that goes through `IDispatch` (directly or no), or the library is lying (the error is caused by something else). Your best bet is to post as minimal an example as you can, including at least the interface definition, how you're creating the instance, and how you're using it. Something other people can compile and run to verify the behaviour will help the most.
The standard library is allowed to use unstable features in stable Rust, you're not. The justification is that the core developers can make sure the stable and unstable code are always updated in lockstep, so nothing ever breaks.
&gt; Expand macros in traits and impls Macro expansion improvements are often the biggest ergonomic wins for me.
It's actor-based concurrency, which is basically a form of loosely-coupled task-based concurrency where actors should _only_ be able to communicate through message passing. One of the more interesting experimental languages right now is [Pony](https://www.ponylang.org/discover/#what-is-pony), which is a programming language built on the actor model.
It does for me. What seems to be the problem for you?
The aforementioned problem with ring on windows is due to a not-silenced warning (fail on warning is enabled). The fix is quite simple for the maintainer but quite annoying for users, but for some reason that fix wasn't backported to the stable version. So the issue is all in all unrelated to the domain here
Thank you, that's useful information. I'll work on that. 
Specifically the documentation says that's the reason for that HRESULT value I'm getting. The documentation could be wrong.
Okay, that's what I thought. Thanks for fixing the wording!
I was able to get it to compile by borrowing \`tx\` without the need to inline. [https://play.rust-lang.org/?gist=52df21ea06572f3136c023d11d9a9013&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=52df21ea06572f3136c023d11d9a9013&amp;version=stable&amp;mode=debug&amp;edition=2015)
I'll concur that it likely isn't IntelliJRust's fault; IDEA can get RAM-hungry and low RAM can severely slow it down. There _was_ one release cycle where macro expansion was quite slow, and it can still be for complicated macros, but a) you can turn that off and b) it's been working great for me recently. It's also possible that another plugin is causing the problem. I know for a fact JetBrains has blacklisted certain big plugins that were causing large performance problems by misbehaving on the hot path (cough .ignore cough), and situations like that is actually why a lot of people say IDEA is slow. Part of the reason that vscode is quick is that its extension system is architectured in such a way that plugins have a lot harder time slowing down the editor itself. If you'd like to give IDEA a try again, try disabling all of the plugins you don't need. It will probably function better.
I mean that crypto is especially hard because the code can run fine, do exactly what it is meant to do, and still be insecure because a slower branch is run in some circumstances and this allows you to reconstruct secrets. So you need to write assembly with noops so that every branch takes the same amount of time. Or maybe you can take advantage of branch prediction to see if the same branch is always taken. This is why crypto is uniquely hard.
&gt; Unless they are re-implementing everything in Go, or not interfacing with the OS at the low level, they must have the same problems. So the question is how are they doing is? They've re-implemented everything in Go. Go apps don't even link to `libc`, they make syscalls directly into the kernel. It's really great for cross-compilation and portability but it's only possible because Google can pay that many engineers to reimplement every platform's `libc`. 
Flask does, I haven't used the others. We use some msf4j at work, a java microframework, which does. You can specify query params as function arguments too.
Hi Helpful Rustaceans, I'm trying to extend a HashMap, with &lt;K,V&gt; from HashMaps of the same type, but in parallel using Rayon. extern crate rayon; use rayon::prelude::*; use std::collections::HashMap; fn maps() -&gt; HashMap&lt;String,usize&gt;{ let mut h = HashMap::new(); h.insert(String::from("moke"), 0); h } fn main() { let mut h1 = HashMap::new(); let mut h2 = HashMap::new(); h2.insert("moke", 0); h1.par_extend(h2); h1.par_extend((0..5).into_par_iter().map(|x| maps())); println!("{:?}", h1); } Gives the error: error[E0277]: the trait bound `std::collections::HashMap&lt;&amp;str, {integer}&gt;: rayon::iter::ParallelExtend&lt;std::collections::HashMap&lt;std::string::String, usize&gt;&gt;` is not satisfied --&gt; src/main.rs:20:8 | 20 | h1.par_extend((0..5).into_par_iter().map(|x| maps())); | ^^^^^^^^^^ the trait `rayon::iter::ParallelExtend&lt;std::collections::HashMap&lt;std::string::String, usize&gt;&gt;` is not implemented for `std::collections::HashMap&lt;&amp;str, {integer}&gt;` | = help: the following implementations were found: &lt;std::collections::HashMap&lt;K, V, S&gt; as rayon::iter::ParallelExtend&lt;(&amp;'a K, &amp;'a V)&gt;&gt; &lt;std::collections::HashMap&lt;K, V, S&gt; as rayon::iter::ParallelExtend&lt;(K, V)&gt;&gt;
The guy who started that thread seems to me like a arm chair critic. Why stress about performance without measuring it yourself. Benchmarks are not norm, they are outliers. there are 100 different things that should be taken care of before optimization is even a factor. 
Ah interesting. I have 16gb of RAM, but definitely found typing slow, and switched to VSCode, much like OP. I don't think i have many plugins, but I can check that. I have android studio as a separate install.
Only other plugin I have is the vim emulation so I doubt it's that. It sometimes freezes for seconds at a time when typing. I do use clion on n'y Desktop, which has a way better CPU / more RAM.
16GB RAM is twice what I have, so likely not the issue. But yeah, the key thing to check is that you don't have unneeded work going on. It might also be a little bit slower while indexing (you'll see the progress bar in the bottom margin), but that should go away once it's finished. It's really a question of scale I think. Editors like vscode only concern themselves with the open files. IDEA's Intellisense requires maintaining an index of the entire project for its smart features. And it could be an OS thing as well; as much as the JVM is run anywhere, that's not equivalent to performant everywhere.
Oof. I've never had a seconds long freeze, thankfully. I've had a second-long _delay_ on typing before when macro expansion was first added as off-by-default-because-slow-af, but never that much of a pause. Note that you can turn Intellisense off for a file as well if one file is causing an issue.
Yeah i've found it to be up and down. While coding for a few hours in it, sometimes ill be typing smoothly, like I am into this text box. Others it'll lag. I do miss the reliable completion that I would get from intellij. But the consistent speed is less frustrating. My project isn't that big. A bit under 20 dependencies that ive listed, 5800 lines of code across 80 files.
If you are interested in modeling Finite State Automata in Rust, you should check out this classic article on the subject: [https://hoverbear.org/2016/10/12/rust-state-machine-pattern/](https://hoverbear.org/2016/10/12/rust-state-machine-pattern/)
It blew my mind the first time I wrote a Node.js web server and it used 0% CPU at idle. Like, not 0.5%, but literally nothing. I was used to Java Spring using 30MB of RAM and always having some background threads working.
Both C and Rust gets compiled down to the same machine code. What I meant was that a lot of stuff that is possible/allowed in the virtual machine described by mainstream CPU instructions map directly to C features. Coming from the world of C/Assembly requires you to rethink your habits. I was not in any way implying that Rust is harder, just that it's different.
For those who only care about a real debugger.. apparently IntelliJ Rust has a debugger when installed on CLion now. It's been in for at least a few months.
For http, the situation is: * hyper for low(er) level async client with a connection pool * h2 for http2 client/server with no pool * actix-web if going with the actix actor system * reqwest for sync client, batteries included It's all a matter of taste and what kind of system one's building. I'm using hyper when building a fast server or client, reqwest for scripting.
Come on, nowhere in the h2 readme does it say not to use the crate directly. And I quote: &gt; The intent is that this crate will eventually be used by hyper, which will provide all of these features. The readme lists a bunch of non goals and the link to hyper implies that **those non goals** will be handled by hyper. The intent is to prevent a bunch of people posting feature requests w/ those items.
Needs a specification what regexes are available. Will it always replace the full match? Submatches are valuable here, but might be out of scope [This line](https://github.com/ChuckDaniels87/rnr/blob/master/src/args.rs#L53) suggests it works only on unixes. Is that so? Is that neccessary? I see quite some unwraps, did you check no panic can happen? Imho, in a user facing application a panic is basically not acceptable. Might even check out `catch_unwind` to at least print something usefull in an oom situation or so. You're running the file arguments through [`String::from`](https://github.com/ChuckDaniels87/rnr/blob/master/src/args.rs#L72), so you're only accepting UTF8 file names. I'm not sure what you can with clap, but that's a restriction you should document, and make sure that you print out a nice error message if it is violated. I suggest more tests for extreme conditions. I say go publish on crates.io, that way you will probably get some users and therefore bug report/improvment ideas. Good luck! 
The debugger is pretty terrible. Even something as simple as a Vec is hard to read and a lot of staments get optimized out.
I was a little surprised not to see Spring Boot as well, but I imagine it would be in the range of the J2EE frameworks as well, especially if you're using Hibernate. We use this combination at work and Hibernate is such a memory hog, we have some services that slurp through 1GB of memory like it's nothing with only light traffic.
I just tried it today. I had to disable the default features on my actix-web dependency to avoid the TLS feature which causes this. Is there a way to override a transitive dependency? I.e. actix-web currently depends on ring 0.12, can I force it to use ring 0.13 instead?
 Ye but actor-based is a higher level of abstraction. lewisinc said Actix isn't task based, but if it's implemented on top of tokio then it is task based. 
Counterpoint: Not all libraries you end up using in most Scala projects are actually written in Scala, but plain-old Java. Thus these libraries do not have same guarantees as your in-house written Scala code.
If you're looking for the ram-eating java experience with Node, might I suggest electron? /s
Ah, bummer, I’ll give it a try too. Yeah with [patch].
Is there a more elegant way to express nextline = self.next(); if nextline.is_none() { return Default::default() } I feel this could be a one-liner, but can't put my finger on it.
These issues are why I made sure in \[SIMDeez\]([https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez)) you can opt to run SSE2 code even when the machine is capable of AVX2 . I'm wondering now if I should also expose an "AVX-Light" mode, where any floating point ops would fallback to SSE2, hmmm
Would this do what you want? if let Some(l) = self.next() { // do stuff } else { return Default::default() } or you could `match` on `self.next()`.
.unwrap_or_default()
Added a little doc to \[rustorm\]([https://github.com/ivanceras/rustorm\](https://github.com/ivanceras/rustorm)](https://github.com/ivanceras/rustorm](https://github.com/ivanceras/rustorm)) \- A simple ORM for rust which focus mostly on writing SQL and converting data types correctly.
Well it would, if I replace `// do stuff` by `nextline = Some(l)`, but it's not shorter or more elegant.
First, thanks for the comments and taking time to check the code! &gt; Needs a specification what regexes are available. Will it always replace the full match? Submatches are valuable here, but might be out of scope It uses replace from `regex` crate and it has the same limitations. I will document it. &gt; This line suggests it works only on unixes. Is that so? Is that neccessary? Not really, I will fix that. &gt; I see quite some unwraps, did you check no panic can happen? Imho, in a user facing application a panic is basically not acceptable. Might even check out catch_unwind to at least print something usefull in an oom situation or so. Some of them are checked before unwrapping but I'd like to refactor a bit. Also, I want to add more tests. &gt; You're running the file arguments through `String::from`, so you're only accepting UTF8 file names. I'm not sure what you can with clap, but that's a restriction you should document, and make sure that you print out a nice error message if it is violated. It already warns you that does not accept invalid UTF-8 characters about filenames here: walkdir .into_iter() .filter_map(|e| e.ok()) .filter_map(|x| match x.path().to_str() { Some(s) =&gt; Some(s.to_string()), None =&gt; { eprintln!( "{}File '{}' contains invalid characters", Yellow.paint("Warn: "), Yellow.paint(x.path().to_string_lossy()) ); None } }) However, you are right. I will validate input arguments too in `clap` to give a notice to the user. I will also document it somewhere. &gt; I suggest more tests for extreme conditions. On question that immidiately came to my mind is "What if you have a.txt and aa.txt and and run rnr '^' a * on it (syntax hopefully correct), will it fail? With what error message? What's the workaround? It absolutely need more test, you are right. In the example you gave, I will fail to change aa.txt name, but it will depend on the order of the execution of the file list. This is not acceptable, I will take a deeper look at this. $ rnr '^' a * aa.txt -&gt; aaa.txt Error: File already exists - a.txt -&gt; aa.txt &gt; I say go publish on crates.io, that way you will probably get some users and therefore bug report/improvment ideas. Good luck! Ok then! I've been told to separate in both `lib.rs` and `bin`. I'll fix your suggestions and publish it! &gt; (e) Oh yeah, dry-run-by-default: Good choice! I didn't want to accidentally bork my system, and I supposed nobody want!). ;) 
This code shows an error in the match statement although is valid: fn foo&lt;'a&gt;() -&gt; &amp;'a str { "bar" } fn main() { match foo() { "bar" =&gt; {} _ =&gt; {} } } 
I am so amazed that this example was published literally a day ago and I need it now.
If this is a common pattern, you could write a macro: macro_rules! try_default( ($try:expr) =&gt; { match $try { Some(val) =&gt; val, None =&gt; return Default::default(), } } ); nextline = try_default!(self.next());
Then you can just use `nextline.map(|x| {do stuff}).unwrap_or(Default::default())` if you want a 1 liner.
&gt; Your connection is not secure &gt; &gt; The owner of this-week-in-rust.org has configured their website improperly. To protect your information from being stolen, Firefox has not connected to this website. &gt; &gt; This site uses HTTP Strict Transport Security (HSTS) to specify that Firefox may only connect to it securely. As a result, it is not possible to add an exception for this certificate. Oh no! It's not just me right?
Glad it's of use! Feel free to follow the project. Few things down the pipeline coming. 
I like the guy who wrote the article about the complete frontend/backend implementation in rust. 🤭
Wow. TIL.