&gt; Sure, I could stick to a single nightly for a while Just to add that this is what I do, and on the very rare occasion I've had to roll back... it's not like it's difficult with rustup (`rustup default nightly-previous-version`). But I doubt either one of us is going to convince the other, it's not like it really matters :)
Unrelated, but you might want to update your rust plugin. I think the Kalita plugin is no longer supported. Another dev took it over and created a separate plugin. 
I don't know of any window manager that is cross-platform for mobile. So you can cross compile things like a "hello world" program, but nothing very useful. Everything graphics is platform specific for now. Here is a [relevant discussion](https://github.com/PistonDevelopers/piston/issues/116) for piston window, which is one window manager. They say that they want to support mobile, but haven't done the work yet.
Yeah, it really doesn't. I might even end up developing an beta instead. Who knows.
I think the main blocker is that `Add` and `str` are owned by libcore, while `String` is defined in libcollections. There's been [discussion](https://github.com/rust-lang/rust/issues/39018#issuecomment-273276843) about ways that this could be overcome, for this exact use case.
Close:) RustyCode by SaviorIsDead is abandoned, Rust by KalitaAlexey is the current fork of it. Unless this happened again within the last few weeks and I didn't hear about it
I think it could work! &gt; Your comment about the name being intrinsic to the item being stored applies to key/value pairs pretty well. Well, I guess the main limitation of `NamedVec` is that the keys *have* to be strings...but I think that would work just fine with TOML 
Like DB API 2.0 in Python? Never heard of such a thing, but it would be great to have, I agree. Would be really cool if, like diesel, it abused the macro system to allow directly embedded SQL-ish syntax, with translation layers to particular SQLs.
&gt; [performance audit Spring 2017](https://github.com/rust-lang/rust/pull/41469) There's lots of individual numbers (some of which seem awesomely large!) for subsections of the compiler for each commit, but is there an end-to-end number for the overall performance improvement of the whole set?
Refactoring the next version of the [Thrift runtime library](https://crates.io/crates/thrift) to avoid `Rc` and `Box` in the user-visible API. WIP is [in this branch](https://github.com/allengeorge/thrift/tree/rework_rust_transport), and requires you to build the [Thrift compiler](https://github.com/apache/thrift/) from source. If you're using the Rust Thrift binding library I'd love to hear from you!
I expect he's referring to Python's built-in `dict` type....
There's a lot more tutorials for learning 90s C++ than C++11/14/17 though, so beginners often get confused as to which disjoint set of features they should be using. JavaScript has the same problem (among many others...).
&gt; The only redundancy is saying Box twice, otherwise those are the three different parts of the operation. It's still redundant. new new Box Box This feels error prone. Can it be sugared? Why put it in a Box just to remove it? That seems like a procedure you'd have to follow at the Post Office or when using Visual Basic. Box::into_raw(Weldconf::new())? Box::into_raw(Box::new(Weldconf))? Raw(Weldconf::new())? This kind of thing frustrates me and is what pushes me away from C++ templates.
Yeah I cloned the Rust source code to see if I could think a way around this but any way I can think of to fix this would involve restructuring rustc in ways that I just don't feel I have the authority or qualifications to do. Perhaps someone with more authority in the rust project will have to look at how to accomplish this.
I guess the main advantage over `"Hello".to_string() + "world"` is that you save an allocation? Doing `["Hello", "world"].join()` should also only have 1 allocation, right? I'm not trying to argue against it, just to make sure I understand the situation.
The implementation I provided only does one allocation in String::with_capacity() so I don't see any real performance disadvantage to it
My c++ was in a high school AP comp sci class, which actually was a fantastic foundation. But the reason I'm a fast learner is I used to be a reporter, which is great training for learning new topics quickly. 
That looks useful! Why not allow any type for the hashmap keys, though?
What's the idiomatic, correct, and/or conventional way of indicating the C type `T[]` in Rust? I am writing an FFI wrapper that requires extensive use of pointers to arrays. In C, a `T name[]` is equivalent to a `T* name` mechanically and semantically, more or less. I would like to clearly indicate that the Rust wrapper is expecting a pointer to one *or more* `T` elements, not a pointer to one *and only one* element. I am under the impression that `*const T` and `*mut T` are usually considered to semantically indicate the latter -- pointers to one and only one. As such, I am currently using `*const [T]` and `*mut [T]` as the FFI-crossing types. I am somewhat nervous about doing this, as I know Rust represents slices as `{ ptr: *const T, len: usize, }` and I am *not* passing a pointer to a pointer/length tuple into the FFI functions, I'm passing that `ptr: *const T`. Should I just use `*const T` and document that pointers-to-arrays are permissible? The library I intend to write to go around these FFI bindings will only accept `&amp;(mut)? [T]` parameters and then internally send the pointer and length across FFI as required, so this is a moot point from a true Rust consumer's point of view, but I'd like to get the FFI bindings done nicely as well as the pure Rust superstructure.
That's just a more verbose way of saying "dynamically typed" though.
I sometimes write code over SSH on my VPS because I have access to it everywhere. I even occasionally `ssh` in with my phone when I'm bored and want to get some work done. I can't do that with an IDE, so I really like the flexibility of console editors like VIM.
F4 to go to next error, at least if I'm interpreting my muscle memory correctly. 
Yeah you definitely don't want to have `*const [T]` on one side and pass `T*` on the other. It's just going to be taking some garbage value out of one of the registers for the length (I guess if you fixup the length later that's not horrible, it's just a really bad potential footgun). ~~Of course if your C function prototype takes a pointer and a length, *in that order*, then taking `*const [T]` on the Rust side isn't as horrible. Some libraries just do that, like [cargo fuzz](https://github.com/rust-fuzz/cargo-fuzz) (in generated fuzzers).~~ (This has changed since I looked last.) If it's purely for documentation purposes, you could create type aliases: pub type CArray&lt;T&gt; = *const T; pub type CMutArray&lt;T&gt; = *mut T; Or if you want the types to have some meaning other than aesthetic, you could create wrapper structs: pub struct CArray&lt;T&gt;(*const T); pub struct CMutArray&lt;T&gt;(*mut T); (You can use these directly in your `extern "C" fn` declaration on the Rust side since they have an equivalent representation.) (Also, do single-field structs still need `#[repr(C)]`? Maybe include it anyways to be safe.) 
So `*const [T]` is the same repr as `&amp;[T]` then, pointer and length? Good to know; I'll rip them out. This is purely for documentation purposes. I'm currently mapping all the C functions exposed by the library into a block like #[link(name = "path/to/artifact")] extern "system" { // stdcall on Windows, normal on Linux pub fn SomeFunc(buf: *const u8, len: u32); } And I was hoping I'd have a type-level reminder that some items are pointers to arrays, whereas others are pointers to single elements. I guess I can just do type aliases; that's a good suggestion. I've already got a few in there to handle `typedef void *star_handle` and similar.
In the particular case they are talking about, I think the kind of programs they want to write over boxes (ie, `AST -&gt; AST` transformations) are probably better expressed by building a rewrite system into their language's implementation. This could be done in lots of ways, including using macros. In general, I agree that working with `Box` creates a lot of syntactic noise that I could do without.
Looks pretty nice! I don't think I personally have a use case for this library, but it is an interesting thing to do! With that said, here are a few things that I would suggest: First, in `azure.rs`, I would definitely agree with the comments saying that moving towards a Deserialize struct would be better instead of deserializing to `Value` xD. The non-snakecase names can be dealt with though, using `#[serde(rename)]` - an attribute to tell serde to deserialize a different key name than the rust field name. `extract_user_info` for instance could probably be completely removed by having `UserInfo` declared with this: #[derive(Deserialize, Debug)] struct UserInfoResponse { #[serde(rename = "userPrincipalName")] username: String, #[serde(rename = "displayName")] full_name: String, #[serde(rename = "immutableId")] user_id: u32, } The only other big thing I would change is the url handling in `azure.rs`. Almost everything is done with `format!()`, which might work, but won't be ideal for performance or any non-url-encodable characters. At the final step of the hyper call, `.post` will turn any String you give it into a "Url" object; in short, you can be much more efficient by using a single [`Url`](https://docs.rs/url/1.4.0/url/struct.Url.html) from the start for each request, and [`Url::join`](https://docs.rs/url/1.4.0/url/struct.Url.html#method.join) to add path components on while transparently encoding any special characters. Even these two things are just my nitpicking mostly, can be an improvement if you want to be more "rusty" - but not required. Looks like a pretty nice library in either case!
Cool, thanks! Slice pointers are stripped and I'll get around to aliasing eventually.
Which are named like `str` and `String` and contain `C`-valid, `Os`-valid and `Path` valid strings. Simple! :]
Sorry. I'm not the author, so I'd have to poke at it myself to try and come up with an answer to that. (And, while I am a bit curious, I don't really have the time.)
[removed]
I agree. It's an awesome site. Bookmarked and will use in the future. 
`String` is only ~12 bytes (in the current implementation; this isn't guaranteed by Rust AFAIK) if allocated on the stack. The actual string data is on the heap. `str` is just a pointer and length; a `Box&lt;str&gt;` is just heap-allocating that pointer-and-length, but I'm not sure that implies that the string data itself is also heap allocated. (Since you can make a `str` from data on the stack with `from_utf8`), and put the `str` on the stack too. I expect trying to move such a thing into a `Box` would limit the lifetime of the `Box`, but I'm not sure.)
¯\\\_(ツ)\_/¯
I don't think the actual *time* matters, it's more about how many samples get generated. Which relates both the the count of events to trigger the sampling (eg `-c`) and the actual event type (some are more frequent than others ‒ you're likely going to generate far more instruction events than TLB misses).
It's not the most ideal solution, but I have a project which calls cargo from cmake to build a mixed code (C &amp; Rust) shared lib.
I went to a talk about using Rust inside of Ruby last week, but it was using RuRu. What is the difference between these two libraries, or do they do the same thing?
How does it compare to ruru? I wonder whether helix would have been a better idea for imag...
I had to use a gzip decompressor, and I noticed two things that needed to be fixed: 1) It wasn't as easy to use as, say, gzip in Python because it seemed like you needed to know the algorithm name for the gzip stream. 2) Between libflate (pure Rust) and flate2 (Rust bindings for a C library), it seemed like flate2 was noticeably faster. Since I needed to decompress a fair amount of data, I ended up making a platform dependency (ick) to use flate2 on Linux and libflate otherwise. That being said, I'm not sure why I thought I couldn't use flate2 on Windows.
I've wondered how people handle that particular can of worms. So libraries should prefer `Arc` to allow client code thread-flexibiliy? I know that `Rc` is optimized for the non-threading case, what are the performance implications of always using `Arc`?
Oh right, yeah you're totally right. I don't remember having a problem with those when I was learning so I guess I put them in a different mental category 
I just read another article on HN making the exact same mistake, so no worries
https://www.reddit.com/r/rust/comments/67sq59/helix_native_ruby_extensions_without_fear/dgtcp95/
Short in the dark, but has anyone got any experience unpacking nested `BufReader` / `Read` instances to get a hold of progress for this kind of thing? Looking to wrap progress bars around something like this, and I'm kind of at a loss for where to start: let data = fs::File::open(tarname)?; let decompressed = flate2::read::GzDecoder::new(data)?; tar::Archive::new(decompressed); Getting the file size as a total length for the progress bar is easy enough, but then you need to manage all the buffers yourself from there on, just because you want to see how far along one of the readers is?
This guy: https://www.reddit.com/r/rust/comments/65txea/whats_everyone_working_on_this_week_162017/dgdspxj/
gfx-rs + glutin + cargo-apk works relatively fine on android for my ZoC. &gt; Here is a relevant discussion It's from 2014!
Definitely IntelliJ with the Rust plugin. Proper syntax and error highlighting, quick refactoring (doesn't work in all cases sadly) inline documentation, quick way to run tests, etc. etc.
It's not lambda calculus, just some discrete math notation
I integrate gradle and cargo in such way: https://github.com/Dushistov/rust_swig/blob/master/android-example/app/build.gradle#L45 So you can work with rust and java code from `android studio` without additional efforts, just press build/run and you get your app on your device. Of course to edit rust you ned idea rust plugin.
Yeah, it wasn't directed at you. I just thought I'd reply to the comment that provided the link to the code.
This is false. String is 3 words (24b on a 64 bit machine, 12 on 32.) in the stack. `&amp;str` and `Box&lt;str&gt;` are both the same representation -- 2 words on the stack; a pointer and the length. The boxed version owns the allocation and string data. The pointer and length are not allocated on the heap in any of these cases; that is `Box&lt;String&gt;` or `Box&lt;&amp;str&gt;` `str` is a dynamically sized type, it is incomplete and has no representation that makes sense in isolation. `Box&lt;str&gt;` is not the same thing as `Box&lt;&amp;str&gt;`. `Box&lt;str&gt;` is an immutable `String`, basically, and can be obtained from a string at zero cost.
Thanks for the link!
That makes a lot of sense. Thanks
Emacs with rust-mode and cargo-minor-mode. Running in terminal with TERM=screen-256color in gnome-terminal using the dark theme colors: Why? It has a wonderfully pleasent colors: http://imgur.com/a/dfEye
What is the -sys convention? EDIT: &gt; [Cargo has a convention of package naming and functionality](http://doc.crates.io/build-script.html#-sys-packages). Any package named foo-sys will provide two major pieces of functionality: &gt; &gt; • The library crate will link to the native library libfoo. This will often probe the current system for libfoo before resorting to building from source. &gt; &gt; • The library crate will provide declarations for functions in libfoo, but it does not provide bindings or higher-level abstractions. 
No to say that editing in console isn't viable, but if you needed to you could still use a conventional IDE over ssh as long as you have an X server on your client to forward to (I doubt it's viable on phones though).
Note to OP: Your link to the gamingbolt article is broken.
&gt; LinkedHashMap is a linked list + hash map I think. &gt; NamedVec is a Vec + hash map I'd say it's a `Vec` of things that have names. The hash map is just an implementation detail.
I suppose, but I've tried that and it's really slow and unusable (well, not the IDE, but other X applications).
I would love to get patches to make this work better on windows. I tried a bit to make it work on my machine and it was not too bad, but I run quite a vanilla version of windows. &gt; single is printing 60 characters and then wrapping even though my terminal is 120 characters wide; this naturally throws things off. Something incorrectly reckoning the character width as 2 rather than 1, I’m guessing? This is bizarre and I can't even repo it :(
It does, but would love to get patches to make it work better there.
[removed]
I think you're a bit too quick to draw conclusions about the field of data science. I'm not familiar with indeed.com or how they come to their trends, but Scala positions often list Java experience as a requirement. Scala is nowhere near as well known as Java, so many companies just look for Java developers to train. Scala is often _just a plus_, even if that's what the company actually uses. The likes of caffe seem to be mostly popular among academics who love overfitting on the three same data sets over and over. Depending on the amount of data that's being processed, distributed computation becomes quite essential and Spark is pretty damn good at that. 
&gt; what feature is only available in beta? I'm not sure; I just tried to build it but got weird errors. &gt; and shouldn't it be stabilized later today? Yes, there's a release today. &gt; it just seems odd to make a big deal about requiring beta less than a week before the new stable is available. Unfortunately, RailsConf does not schedule their conference around Rust release schedules :) (That's where this was announced)
Hi, Thermite author here. Just for clarification, it works without using ruru too. For example, there's a PR that i need to finish (when I have more time) to integrate with faster_path, which doesn't use ruru. However, I have not investigated lately whether Thermite and Helix work well together.
&gt; Do you need a fancy build script?... No, just `cargo apk` and a couple of lines in `Cargo.toml` to show `cargo-apk` where my assets are: https://github.com/ozkriff/zoc/blob/f96451fac/Cargo.toml#L12-L13 Though I'm using a tiny makefile rule to automatize actions with a device: https://github.com/ozkriff/zoc/blob/f96451fac/Makefile#L19-L26 &gt; ...I'd really like to know more, if this is a possibility. https://github.com/tomaka/android-rs-glue ;)
I avoid them because they're another layer of abstraction with their own language that you have to reason about. It's not straightforward to translate from a macro definition to its actual compilable implementation. Debugging is harder, and often editors and IDEs don't give you the same level of support.
Thanks! It's fixed now.
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
Thermite was actually the part that I had the least problems with. It lacked proper instructions for initially setting it up though. Not sure if that changed. I also looked at Helix, which at the time didn't even provide working examples to run on Linux. It lacked documentation and the API felt a bit too heavy. The other thing I looked at was Ruru. While I was able to set up a minimal Gem with it more easily, it could still use more documentation. I also think combining a few of the ideas of Helix and Ruru would makes sense (but I would have to look into it again to see what I meant by that) (Above is a quick recap from [my slides back then](https://badboy.github.io/rust-and-ruby/) [in German])
Depends on your bandwidth and latency, I guess. I have no trouble using Firefox over SSH, for example.
[removed]
I don't, but I'm not very clued-in to the internal dev community. What I do is... kind of weird, at least within MS, as I'm sure you can imagine based on the fact that I'm writing glibc plugins for Linux hosts in Rust, and not MFC DLLs in C# :-D
I currently use spacemacs, but I would love to try VSCode if it had a really good VIM-mode and preferably spacemacs shortcuts (the dream).
[removed]
Their experience with Go wasn't bad, though they only ever tackled some fairly simple low hanging fruit while I was there. The main reason for the choice of Go is that it was a Google App Engine language, which is what we were using, and we had been hitting time and memory limits for a while. A big reason why it worked out was because everyone on the team was able to pick it fairly quickly, and then convince the powers that be to give them a weeklong sprint to try rewriting some of the parsing logic. No idea how much of the benefit's were a second system effect, but it was faster in the end. Personally, I find Go insufferable to work with. It really strongly encourages copy pasting piles of shitty procedural glue code instead of building abstractions, and I find more to be annoyed at every time I have to use it. For example, I was recently updating some Go code, and had to remove duplicates from a list of strings. There is no method for this. There is no Set collection you can use. There is no user definable generics, so there is no way for anyone else to define a Set collection without resorting to some kind of preprocessor shenanigans. In the end, the correct solution (as far as I can tell from extensive stack overflow research) is to: - Make a string to bool hashmap as a ghetto set. - Use a for loop to put each item from the list into the map. - Create a new list. - Use a second for loop to iterate over all the entries of the hashmap and copy the keys over. - Make a new copy of this code for each type you want to dedup, cause again, no generics. If that sort of code appeals to you then you might like Go. 
You don't need to put constraints on the type itself, you can insert them on the methods that need them. That way you can pass the type around without having to type all necessary traits to use it. If you want to use the methods of those traits, you obviously still have to use those bounds, but IMO that serves as a useful bit of documentation.
A little Off-Topic but i never really get the problem people have with checked exception and favor unchecked ones in general. Its just horrible if you ask me! Checked exceptions is on the positive site if you're using exceptions at all if you ask me. I don't really get the point littering your code with unchecked exceptions especially transforming every checked exception in your code to unchecked ones (had a codebase i temporarily worked with with that "pattern" ... it was just pure horror!) 
Great. Thanks!
That's pretty much exactly what turns me off about Go: the design decisions that basically force you to copy-pasta stuff all over the place (or litter your code with casts). It baffles me that they still don't have a solution for generic containers.
On the other hand, if [implied bounds](https://internals.rust-lang.org/t/lang-team-minutes-implied-bounds/4905) are implemented, then putting bounds on the type could save a lot of repetition in some cases.
sshfs?
mandatory evil/spacemacs reference.
What alphabet do you use where vee-eye-em is pronounced "nah-no"
Added a section on it, thanks for pointing that out!
Thanks for pointing all that out, I've gone head and corrected the article. I'm really loving the shorthand for lambdas, never saw that before. 
I think Java checked exceptions are the wrong solution to the wrong problem. Exactly because of the reasons you mention, and others, they're leaky and unreliable by nature. I've also encountered libraries that used checked exceptions for what in my code were weird edge cases that can literally never happen, while unchecked exceptions for things that would actually occur. Checked exceptions are the `sudo` of programming, where for most people it's merely an annoyance, and just brute force a way around the problem, while others will religiously do their diligence in tuning it to their benefit. It's still annoying when you get out of the safe space and meet real world where people have no clue how to use this tool.
There's no better benchmark then your app, Rust even loses in a number of those benchmarks to languages like C++, Ada and Fortran. And performance isn't everything, some languages win in memory usage which would matter for server-side apps on the cloud for instance. I'll add a disclaimer to it, I just didn't want to add such a disclaimer every time I reference the benchmark game since I did do one in a previous post about JavaScript. The benchmarks are also pretty specific, K-Nucleotide isn't something we're going to be doing a lot of in our applications, but it does help to show Rust is in that high performance space dominated by older languages. 
[removed]
[removed]
Ah, I see.
\_/¯(ツ)¯\\_
If I have an `OggStream&lt;T&gt;` to read Ogg packets from a file/cusor I want to be able to require `T` to impl `Read`, because otherwise the entire thing is useless. Trait bounds on structs *are* useful.
[removed]
[removed]
The macro system on 1.16 chocks on Rust keywords, that is fixed in 1.17 (which should be out today). As Steve said, it was an unfortunate timing/artifact between RailsConf and Rust release schedule.
I really like how the Atom editor is structured and it's package focused concept, however it's really heavy (slow startup, high ram usage) considering it's "just" an editor.
source code: https://github.com/paritytech/parity-bitcoin
Yep!
Yeah, we decided to ship the unstable book with the stable docs so that you can see what's coming up and get involved if you want a feature badly, just like we've always done with the API docs.
Rust gaining significant mind share in gamedev is a long way away. The likeliest path is going to be smaller PC only indie games being developed in rust, and if/when one becomes a commercial success you'll see some more adoption. Adoption by large studios is not going to happen till MS and Sony support a rust toolchain to compile for XB1 and PS4 and even then people are more likely to use established game engines like UE4 or Unity. Most folks don't write engines from scratch. At best they will start writing tools and plugins in rust as a way to test the waters. Crashes in games are really not as big a concern as in other software domains. My day job is to fix crashes in games and there are very few I encounter that could've been avoided with rust's strict semantics. It would be a nice bonus though.
I contributed a very tiny, but hopefully useful feature to cargo: [Cargo search results on the command line can now be directly copied into a Cargo.toml](http://i.imgur.com/kQc1E7b.png)
Very nice! Not sure if this would be in-scope for parity-bitcoin, but I wrote a [BIP39](https://crates.io/crates/bip39) implementation in Rust a while back for use in a non-bitcoin project, might be useful in the future :)
&gt; Alex is not a single human being. The entity we know as "Alex" is actually an agglomeration of autonomous agents, powered by an advanced AI. &gt; &gt; At least, that's the most reasonable explanation I've been able to figure out. Seems plausible to me. :)
Awesome! I see rust is getting better with each release. Congratulations to the team an community. I hoped some compiler performance improvements though.
Thanks! ❤️
Those new error messages are certainly useful for beginners, but I think they will quickly become too noisy for more advanced programmers. Perhaps there should be a configuration flag in cargo/rustc somewhere that activates "advanced mode", and makes the messages short and to the point, without the added explanations?
&gt; Doing `["Hello", "world"].join()` should also only have 1 allocation, right? Right.
this is a very rough implementation of a [ranged integer type here](https://play.rust-lang.org/?code=use%20std%3A%3Afmt%3B%0A%0A%23%5Bcfg\(not\(debug_assertions\)\)%5D%0A%23%5Bderive\(Copy%2C%20Clone%2C%20Debug\)%5D%0Astruct%20Ranged%20%7B%0A%20%20%20%20val%3A%20i64%0A%7D%0A%0A%23%5Bcfg\(not\(debug_assertions\)\)%5D%0Aimpl%20Ranged%20%7B%0A%20%20%20%20fn%20new\(val%3A%20i64%2C%20_%3A%20i64%2C%20_%3A%20i64\)%20-%3E%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20val%3A%20val%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0A%23%5Bcfg\(not\(debug_assertions\)\)%5D%0Aimpl%20std%3A%3Aops%3A%3AAdd%20for%20Ranged%20%7B%0A%20%20%20%20type%20Output%20%3D%20Ranged%3B%0A%20%20%20%20%0A%20%20%20%20fn%20add\(self%2C%20rhs%3A%20Ranged\)%20-%3E%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20val%3A%20self.val%20%2B%20rhs.val%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0A%23%5Bcfg\(not\(debug_assertions\)\)%5D%0Aimpl%20std%3A%3Aops%3A%3ASub%20for%20Ranged%20%7B%0A%20%20%20%20type%20Output%20%3D%20Ranged%3B%0A%20%20%20%20%0A%20%20%20%20fn%20sub\(self%2C%20rhs%3A%20Ranged\)%20-%3E%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20val%3A%20self.val%20-%20rhs.val%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0A%23%5Bcfg\(debug_assertions\)%5D%0A%23%5Bderive\(Copy%2C%20Clone%2C%20Debug\)%5D%0Astruct%20Ranged%20%7B%0A%20%20%20%20min%3A%20i64%2C%0A%20%20%20%20max%3A%20i64%2C%0A%20%20%20%20val%3A%20i64%0A%7D%0A%0A%23%5Bcfg\(debug_assertions\)%5D%0Aimpl%20Ranged%20%7B%0A%20%20%20%20fn%20new\(val%3A%20i64%2C%20min%3A%20i64%2C%20max%3A%20i64\)%20-%3E%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20val%3A%20val%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20min%3A%20min%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max%3A%20max%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0A%23%5Bcfg\(debug_assertions\)%5D%0Aimpl%20std%3A%3Aops%3A%3AAdd%20for%20Ranged%20%7B%0A%20%20%20%20type%20Output%20%3D%20Ranged%3B%0A%20%20%20%20%0A%20%20%20%20fn%20add\(self%2C%20rhs%3A%20Ranged\)%20-%3E%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20if%20self.min%20!%3D%20rhs.min%20%7C%7C%20self.max%20!%3D%20rhs.max%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20panic!\(%22incompatible%20ranges%20being%20added!%22\)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20let%20val%20%3D%20self.val%20%2B%20rhs.val%3B%0A%20%20%20%20%20%20%20%20if%20val%20%3E%20self.max%20%7C%7C%20val%20%3C%20self.min%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20panic!\(%22value%20is%20out%20of%20range!%22\)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20val%3A%20val%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20min%3A%20self.min%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max%3A%20self.max%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0A%23%5Bcfg\(debug_assertions\)%5D%0Aimpl%20std%3A%3Aops%3A%3ASub%20for%20Ranged%20%7B%0A%20%20%20%20type%20Output%20%3D%20Ranged%3B%0A%20%20%20%20%0A%20%20%20%20fn%20sub\(self%2C%20rhs%3A%20Ranged\)%20-%3E%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20if%20self.min%20!%3D%20rhs.min%20%7C%7C%20self.max%20!%3D%20rhs.max%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20panic!\(%22incompatible%20ranges%20being%20subtracted!%22\)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20let%20val%20%3D%20self.val%20-%20rhs.val%3B%0A%20%20%20%20%20%20%20%20if%20val%20%3E%20self.max%20%7C%7C%20val%20%3C%20self.min%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20panic!\(%22value%20is%20out%20of%20range!%22\)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20Ranged%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20val%3A%20val%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20min%3A%20self.min%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max%3A%20self.max%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%7D%0A%0Aimpl%20fmt%3A%3ADisplay%20for%20Ranged%20%7B%0A%20%20%20%20fn%20fmt\(%26self%2C%20f%3A%20%26mut%20fmt%3A%3AFormatter\)%20-%3E%20fmt%3A%3AResult%20%7B%0A%20%20%20%20%20%20%20%20write!\(f%2C%20%22%7B%7D%22%2C%20self.val\)%0A%20%20%20%20%7D%0A%7D%0A%0A%0Afn%20main\(\)%20%7B%0A%20%20%20%20let%20some_val%20%3D%20Ranged%3A%3Anew\(10%2C%200%2C%2030\)%3B%0A%20%20%20%20let%20some_other%20%3D%20Ranged%3A%3Anew\(12%2C%200%2C%2030\)%3B%0A%20%20%20%20let%20new_val%20%3D%20some_val%20%2B%20some_other%3B%0A%20%20%20%20println!\(%22%7B%7D%20%2B%20%7B%7D%20%3D%20%7B%7D%22%2C%20some_val%2C%20some_other%2C%20new_val\)%3B%0A%20%20%20%20println!\(%22but%2C%20%7B%7D%20-%20%7B%7D%20will%20crash%20in%20debug%20mode...%22%2C%20some_val%2C%20some_other\)%3B%0A%20%20%20%20let%20new_negative%20%3D%20some_val%20-%20some_other%3B%0A%20%20%20%20println!\(%22still%20here%3F%20must%20be%20release%20mode.%20here%27s%20the%20value%3A%20%7B%7D%22%2C%20new_negative\)%3B%0A%7D&amp;version=stable&amp;backtrace=0) with only addition and subtraction implemented at the moment. If you run it with the Mode at the top set to Debug, it will panic when it falls outside the contractual range. If you run it in Release mode, it will not. It's certainly possible to implement arbitrary contracts, ranges, and other things in Rust, and it is possible to remove them in Release mode (which I would argue should not be done), without even needing macros. In release mode, there is no added cost to using this type that I implemented here for demo purposes, since you'll notice there are two implementations of everything, one for Debug mode and one for Release mode. Someone could make a library with a set of primitive types that support various types of contracts, and then it would be easy for a library user to consume and use in an application. With the [typenum](https://crates.io/crates/typenum) crate, you could avoid checking the min/max value compatibility between two values in each operation and just make the min/max be part of the type system itself, probably. You would still have to check at runtime whether the new value is between the min and the max, of course. [This crate](https://github.com/nrc/libhoare) is old, but it might be interesting to you as well.
/u/steveklabnik1: I came across this feature by reading the [docs](http://doc.crates.io/manifest.html#the-required-features-field-optional) before this hit stable and had to do some digging to find why it wasn't working. Is there any plans to improve versioning of the docs?
Probably in preparation for PolkaDot which is Parity-Technologies (formerly known as EthCore) cross-blockchain communications network. I'm not sure on the details exactly, but the 30K ft view is like a blockchain of blockchains, so the Ethereum and Bitcoin chains can talk to each other and sends assets back and forth. Although PolkaDot is supposed to be able to add more than just those two chains... probably will include Monero or ZCash... But frankly, if it doesn't with Dogecoin, I don't see the point of it...
Ive been looking at xamarin as it appears to be the most mature tool for the job. But i was hoping for a rust solution. I might have to play around with this idea, but I feel at a certain point if I'm already bringing xamarin in to the tool chain I may as well just use c#
&gt; Alex is not a single human being. The entity we know as "Alex" is actually an agglomeration of autonomous agents, My advisor in grad school apparently really did think that "Nicolas Bourbaki" was the name of a single person, and was extremely impressed at his astonishing productivity.
Thank you for pointing out this usecase; it's something I always want to do but somehow didn't put 2 and 2 together to realize this could be used for that!
Yes, but a heretofore unreleased version of Rust from the future. You see, for Alex, stranded here from the year 2063, improving Rust to the point where he can compile himself is a matter most existential.
For people new to RustConf, it'd be really nice to have access to a previous year's website to get an estimate on when to expect updates, content relevance, cost, etc to tide people over until the information for this year is actually available.
This comment is a big teaser! You didn't say what feature you are excited for! :-p
Any chance of a virtualbox image?
There are always plans to improve all the docs, but there's only so much time :) You should submit what you figured out as a PR!
That's really nifty good job!
This is good to know, wasn't aware format! wasn't a good way to do string concatenation
vim
It happened last year, but why are releases on Thursday now? I liked them on Fridays.
At least the first few releases were Fridays. I noticed around the end of February 2016 that it'd changed I think Edit: I'm wrong. 1.0 was a Friday I guess, but it seems after that was Thursday.
Yeah, it's [a trend](http://wren.io/performance.html) with language devs.
OMG yes! I have run into this more than once.
&gt; "foo".chars().chain("bar".chars()); If the compiler returned that as a suggestion, a beginner would despise it, I assure you. We would then end up with even more beginner blog posts ranting about Rust strings.
The gamedev section is too optimistic... The author is fond of Vulkan support yet failed to spell it properly. No game has been released on Rust Vulkan that I'm aware of. I don't think you can get far with Vulkan alone anyway, since it's not OpenGL-class portable - it got sucked into API wars. More importantly, I don't see Rust gamedev following the steps of C++ gamedev by replicating the same kinds of engines and walled gardens, due to the following spects: 1. Rust gamedev is much smaller, it would take ages to follow the same path 2. Rust has great package management story, which encourages developers to enclose pieces of logic into small-ish libraries that can be combined together. I think we'll find our way, but haven't yet figured it out.
I didn't even know `cargo search` was a thing 0_o TIL, thanks!
Speaking was a ton of fun last year, and it was great to meet everyone I'd been talking to online. Highly suggest anyone who's considering it goes for it.
Try /r/playrust :-)
This is subreddit about programming language called Rust, for game follow /r/playrust
The underlying structures are basically just really inefficient. I'm not aware of any reason why they couldn't be made fast, but at minimum it'd take someone stepping up to do so. There might be a practical reason, though I didn't spot it last time I looked at that part of the code.
Thanks for the amazing feedback. This is what I was hoping for. I'm incredibly curious about the problems that Rust will face in different industries. I'd say incremental compilation and the Rust Language Server will bring us a little closer towards broader adoption in the game industry.
Never change /u/kibwen​. Never change
&gt; a blockchain of blockchains https://twitter.com/shit_rbtc_says/status/576601239619698688
My take (also a AAA game developer) is that Rust is perhaps a better match on the server than the client wrt to games. The Rust semantic that is most interesting to games compared to C++ is its focus on concurrency, and C++ isn't sitting still in that arena. Some Rust semantics are actively harmful to games, though; when you can't even implement an intrusive linked list in Rust without using `unsafe`, that's a sign that the Rust language was designed to primarily address a different sort of problem than an ideal language for games would have addressed. The acrobatics around `Rc&lt;RefCell&lt;T&gt;&gt;` or bounds checked array overhead or the like are further examples. Rust was designed for safety first, performance second, build speed third; games (clients) demand performance first, build speed second, safety third, typically. Rust and games just aren't the match made in heaven that some Rust proponents seem to think it is. Further roadblocks are SDK compatibility. A lot of big game middleware libraries used extensively in the industry are written in C++ and expose interfaces that are heavy on templates or other C++-isms are aren't as easy to wrap in Rust as your typical C library. Until I can do the moral equivalent of `#include &lt;Scaleform.h&gt;` in Rust and have it Just Work(tm), it's going to be hard to get many major game companies to switch. The same goes for incremental transition in general; many of us have multi-million-line codebases written in C++ with non-trivial interfaces and dependencies between tools, pipelines, engines, servers, etc. Incremental adoption of Rust is the only real path forward there, and Rust's C++ interoperability is still weak. I think perhaps by the time we're talking about Rust 2.0, the language may have evolved enough that many of the complains above are invalidated. However, by that timeframe, we may well be comparing the language to C++23 or later, so then we're back to the _real_ question: does Rust offer enough an improvement to games to be worth the hassle of even just the retraining?
Especially coming from dynamic languages like Python, JS, or Ruby where this is easy to do.
Complaining about strings because strings are complicated. Not complaining about Rust because strings are complicated.
I have ripgrep = "0.5.0" installed as a cargo binary. The latest release is 0.5.1 Is this the proper way to update? cargo install --force ripgrep I just feel uncomfortable saying force at the command line for a routine operation, so if a more genteel way is available, that would be of interest.
Upvoted for GooglePepsiMusk.
Maybe. Honestly, with modern C++ (which is a far easier transition for existing game companies), outright memory corruption or crashes are rare enough to not be _that_ significant an issue, client-side. I honestly can't even remember the last time we hit a legit memory corruption bug in our project, and we've had dozens of developers of all experience levels banging on it for years, and the engine's original core design isn't even all that modern (most of it predates C++11). :) Logic bugs, bad content, and overly aggressive assert macros are far more frequently blockers and time wasters for us than the kinds of crashes that Rust in any way would protect against. Not to say that Rust wouldn't still provide a nice improvement to build stability in games. It's definitely still an open question of whether it provides _enough_ of an improvement to be worth the cost of switching. :)
Emacs is also excellent for this use case, since it natively supports remote editing. You can use your local Emacs session (graphical or console) and edit remote file/directories as if they were local. 
Is this too long for QotW?
Oh! I'm pretty sure I just ran into this a week ago, but it was in super deep type trickery, so I thought it was my fault
&gt; It makes fewer allocations Couldn't the compiler somehow optimize this? That is, compile `"a".to_owned() + "b" + ... + "n"` into the same thing `["a", "b", ..., "n"].concat()` is compiled.
We'll need to write a RFC to change the QotW rules
Cargo and package management in rust make it pretty handy to write tools IMO. Recently, I've found found myself writing quick rust projects instead of python for small stuff like parsing perf/debug data. While python gets me running faster, I usually have to spend time doing some optimization if my data set is large enough. Haven't had to do that in rust yet.
I don't see it as much about the memory corruption as about containing damage in general. A logic bug can lead to many things, including corruption, with a random null pointer being a relatively easy outcome. It may propagate itself deep into the program state and reveal itself late, making the investigation difficult. Same for bad content. One thing is your `serde` deserializer failing on an enum in Rust. Another thing is debugging an intermittent random access caused by unmapped enum value that got loaded and processed by some fearless C++ code. Rust allows preventing the bug infiltration early on, preferably at compile time.
Is there any place for a non-allocating view rather than (in essence) cloning both strings in a concatenation? struct ConcatStr&lt;'a,'b&gt; { a: &amp;'a str, b: &amp;'b str } impl &lt;'a,'b&gt; ConcatStr&lt;'a,'b&gt; { // all the str methods } fn concat&lt;'a,'b&gt;(a: &amp;'a str, b: &amp;'b str) -&gt; ConcatStr&lt;'a,'b&gt; { ConcatStr{a, b} } Introduce a special concatenation operator? let c: ConcatStr = a ~ b; Dunno, just thinking aloud.
If someone's editing the post anyway, the following paragraph's "unnecessary" is missing an s.
&gt; Due to Rust's incredible productivity benefits, they completed their task in a mere 22 seconds--and thanks to the Rust compiler's incredible performance, spent only nine months waiting for it compile. Is that supposed to be a euphemism? :p
&gt; C++ Guru: &amp;hellip; you obviously don’t realize that we now have modern extensions to these languages like C99, C++98, C++03, C++11, C++14, C++17, C++20 which all help to write smart, modern object-oriented code. \*sigh\* No, no one is saying this. C++14 is not an extension, and no one is pushing for modern object-oriented C++. What is the worth of a rationale based on fallacies? Why post a sales pitch for Rust to /r/rust in the first place? Who is this for?
I found it exquisite, thank you!
Working on [teleborg](https://github.com/voider1/teleborg). Going to implement logging before continuing implementing everything.
&gt; but that just isn't happening (much) in my experience That's an interesting point, since my experience is quite different ;) &gt; preventing those bugs just isn't _by itself_ worth the astronomical cost of switching a studio and its tech library to a new development language Yes, I agree the transition is not (yet) justified enough. Hopefully, one day...
That's not really within the scope of LLVM optimizations (which are generally fairly "dumb" code transformations), and it doesn't seem trivial at the language level if you want to keep `String` as a user-defined struct. 
[This](https://github.com/google/angle/blob/master/doc/DevSetup.md#to-use-angle-in-your-application) looks like an important chunk of information. Unfortunately, hardware-accelerated graphics is one of my weakest areas as a mature programmer. I really need to develop a basic competency in raw OpenGL at a minimum.
Is pub(restricted) stable? I can't find it in any version's release notes.
&gt; That's an interesting point, since my experience is quite different ;) A transition to modern C++ on an engine that was a heavy user of Boost (and all the smart pointers and the like that _became_ modern C++) probably helps a lot here. :) Really, if there's an bane to our reliability story, it's the use of `weak_ptr`'s analog in our engine. I swear it just causes some devs to think it's a magic solution to everything and that they can just throw sense out the window as soon as they start using it. I'm also of the opinion that it's probably more useful to incrementally improve C++ for game dev than it is to wholesale adopt a new language. Sum types with pattern matching and principled destructuring are all things folks are trying to get into C++. Lifetime extension and analysis rules as well. C++ can't ever hit 100% of what Rust does in this arena, but it can close the gap to make that cost/benefit ratio of switching even less in Rust's favor. Again, for big games. I think Rust has a bright future (soon) in smaller indie or hobby games.
I had my own partial concept implementation of ranged types a while ago, I just wrapped a result type so you could panic/unwrap wherever you wanted to with a message pointing to the cause of any error
It might become possible with something like [GHC's `RULES` system](https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#rewrite-rules).
I started a quickie implementation of this, as /u/coder543 and I were discussing, only generic over integer types. https://github.com/paholg/ranged If there's interest, I'd be happy to flesh it out and publish it to crates.io.
Exactly my thoughts. How does he manage to do all the things he does! Kudos.
Everything about this is beautiful.
&gt; 𝕽𝖚𝖘𝖙 𝕺𝖓𝖊-𝕻𝖔𝖎𝖓𝖙-𝕱𝖔𝖚𝖗-𝕳𝖚𝖓𝖉𝖗𝖊𝖉-𝕬𝖓𝖉-𝕾𝖊𝖛𝖊𝖓𝖙𝖊𝖊𝖓 Assuming I'm not completely mis-remembering Rust's release cycle, that'd be some time around December 2024. Only seven and a half years from now.
You may also want to take a look at https://github.com/servo/angle which includes rust bindings to at least some of ANGLE.
Rust releases every 6th Thursday, so that is 2400 weeks from now, which is, apparently, April 26, 2063.
a CString is just a byte sequence with no interior nulls, it doesn't have to be UTF-8, and that's what's usually recommended for interaction with Unix-like OSes, although OSString might be more appropriate.
Just today after having been tutored by the compiler messages, I thought to myself, "it might be worth it for a team to switch to Rust just for the compiler messages." Seriously. If the tooling is so good, it won't matter how good the language is. People will have to use it. 
...I just realized where my math error was. (I accidentally treated the number of releases (1.417 - 1.17 = 400 releases) as the number of weeks when dividing by number of weeks in a year.) I really shouldn't math when I'm running on 5.5 hours of sleep. (And I should also check whether GNU Units offers a comfortable way to coin an ad-hoc unit like "1 release = 6 months" for the scope of one calculation so I can break my habit of using Python's REPL as my calculator.)
It'll be in 1.18: https://github.com/rust-lang/rust/issues/32409#issuecomment-297080960
I've looked into the how of doing this a few times. If we only cared about making it fast, then several things can be changed. We could unroll the `Arguments`. We could stop casting to function pointers, allowing inlining of the all the `Display::fmt` calls. However, the reason it exists the way it does was to prevent code bloat. It was a goal of the system to not put much into the calling function, but have it all in a separate `fmt::write`, and let LLVM inline when it determines it's worth it. The problem is that LLVM can't inline much of it at all, since it's all dynamic function pointers. I'd be interested in changing the `format_args!` macro to inline everything write in the call site, if increased code size were an acceptable trade off (I'd like to say it would be better to default to fast, and allow someone to slow down for smaller binaries when they really want it.)
Is `stable/unstable-book` a 6~12 weeks old snapshot? 
I just wish there was a way in `rustup` to not install the docs. Having docs in build environments like Docker images or CI is pointless and wastes time and disk. There's issue [#747](https://github.com/rust-lang-nursery/rustup.rs/issues/747) about this. And in some environments installing the docs can take a long time (issue [#763](https://github.com/rust-lang-nursery/rustup.rs/issues/763)).
(Nit pick: `OsStr` on Unix is arbitrary bytes, not necessarily WTF-8. It is WTF-8 on Windows.)
Thanks for the info. What does bindgen do for structs with bitfields? And are there any downsides to use the std::os::raw ctypes, assuming I'm not calling any libc functions?
Yes. This is part of why linking to the tracking issue is very prominently up-front. (This is exactly what happens with API docs too; they'll show something is unstable even after it's been stabilized in nightly.)
Interesting read, thank you for putting this together! One thing I'm wondering about: in a http API library I'm working on, I've been reluctant to add too many macros in fear of scaring off newer contributors, since the extra indirection can sometimes make it much less clear what's actually happening. Would you put any specific number on how many times you repeat something until putting it in a macro would make it more maintainable rather than less?
Yeah. `OsString` is a wrapper around a `Vec&lt;u8&gt;` on `unix` platforms and around a `Wtf8Buf` on `windows`, so, API concerns aside, it's a convenient way to get free portability. (I just refreshed my memory of the relevant bits of stdlib's innards.) (As the docs clarify, the decision to do it that way was so that any `String` is also a valid `OsString` and, if a conversion penalty is necessary at all, it'll happen only when finally passing the `OsString` to the Win32 APIs.)
1. it's controversial 2. with coherence it's impossible right now, see https://www.reddit.com/r/rust/comments/67rjii/question_about_adding_strs_to_string_concatenate/
I'll try to find the time to take another look
To be honest, I'm still not sure what the first 2 code samples do. Is it getting a user profile from a username? What's the `following()` doing in the middle if we specify a username? If it's really just fetching a user profile from a username, something like `client.get_user_by_username("mgattozzi")` would be clearer. But the `following` makes me thing it's not exactly that. Good read but the new API makes it hard to understand what's happening imo. For the last example, I would prefer a `client.repo.get("mgattozzi", "github-rs")?` that returns a `GithubResult&lt;T, E&gt;` which can contain the `status` and `headers` if necessary. The `T ` in that case would be a `Repo` struct that the user can manipulate to get branches or anything else. 
I actually think there are not enough strings. E.g. `NullTerminatedUtf8` and `NullTerminatedOSString` are missing for zero-cost conversions (currently `File::open()` has to allocate just to create a zero-terminated version of `OsStr`...). `ASCIIString might be useful too.` I was thinking about creating a crate for this but I'm low on time. :(
One other optimisation I was thinking about was adding size hint to `fmt::Display`, so `String` could be pre-allocated with correct size in `format!()`
I like it too. It'd be nice to add `const LOCALHOST: [u8, 4] = [127, 0, 0, 1];` somewhere too...
1. is because it involves allocation?
On my way to RustFest.
That should work combined with serializing the data first, I'll give it a shot. Thanks
I can't upvote this enough! Rust + Bitcoin == Love I'm looking forward to try it.
&gt; a twiξ a what?
This makes we wonder if a discussion about strings in practice in Rust should have a page (or a section) in [The Rust Programming Language](http://rust-lang.github.io/book/index.html).
The end result would probably look more like `(LazyStr::new(a, b) + c).to_string()` mostly because I don't see a use for a lazy type with only one element other than enabling this syntax. However yes I had been thinking about providing an Add implementation so sure I'd be happy to! It'll likely be in version 1.0.1 Edit: it's also worth noting that the lazy_cat macro can be fed LazyStr. That was how I originally intended for this to be used.
I think you linked the wrong thing
But helix/ruru creates Ruby classes and functions? So both libraries literally depend on MRI??
I tried deoplete w/ supertab but never could get go to definitiom working. Fortunately YouCompleteMe worked perfectly and is what I use now.
Its also unbearably slow. It feels like I'm typing into a remote desktop.
While that's being worked on, the wayback machine does have snapshots of the content (sometimes without CSS so it looks a bit strange unfortunately): - [Homepage](https://web-beta.archive.org/web/20160726122350/rustconf.com) - [Sessions](https://web-beta.archive.org/web/20160726120509/http://rustconf.com:80/program.html) And if you click the "View details" button in the upper right on [the eventbrite page](https://www.eventbrite.com/e/rustconf-2016-registration-25658921525#), eventbrite will let you see the details about the event even though it's in the past.
Depends, sometimes it might be better as a function rather than a macro for instance. Usually if I do something 3 times I consider making it a macro, but it's not a hard and fast rule.
Why would I need this stuff? I know my codebase!
Then they're not going to get to use Rust.
Interfacing with other code bases? I use it when doing compiler hacks to move around rustc source and its infinitely easier. 
This is cute, quite apart from the name. You could implement `Deref` so that we can do `some_str_fun(&amp;lazy_cat!("answer ",42))`
For bitfields, it should Do The Right Thing. If it doesn't then, please file a bug. https://gist.github.com/fitzgen/91592df6522aeeebd6a20e0d99f220f3 &gt; And are there any downsides to use the std::os::raw ctypes, assuming I'm not calling any libc functions? I'm not aware of any.
That sounds right to me.
&gt; The VSCode extension uses racer, rustsym, and rustfmt Or rls and racer, which makes for an even better experience IME.
The docs live in https://crates.io/ (click "Docs" on the top menu). More specifically, [here](http://doc.crates.io/manifest.html#examples). Yeah, not too discoverable. Perhaps it should be a part of the Rust book.
I used YCM, but it was buggy and hard to maintain for me (compiling and running the completion server... 😬), so I switched to Vim's built in completion (with deoplete and supertab) and it works much better.
Yeah, well, okay... I have to admit that when hacking on code bases as large as rustc or servo, I'd use an IDE, too. But for my "small" program with only ~70 dependencies and about 20kloc I don't want to fire up a heavyweight IDE all the time...
It's not so hard to do it manually, starting with one digit and moving towards five digit. As you move along, you can find patterns and take some short cuts, that's what you do when you work things out manually. For one digit, you get one number divisible by 3, two numbers with remainder 1, and two numbers with remainder 2. For two digits, you get nine numbers divisible by 3, eight numbers with remainder 1, and eight numbers with remainder 2. For three digits, you get 41 numbers divisible by 3, and 42 numbers each with remainders 1 and 2. This is because for the nine old numbers divisible by 3, you get nine new numbers divisible by three, 18 new numbers with remainder 1 and 18 new numbers with remainder 2. For the eight old numbers with remainder 1 you get eight new numbers with remainder 1, 16 new numbers with remainder 2, and 16 new numbers divisible by three. For the eight old numbers with remainder 2 you get eight new numbers with remainder 2, 16 new numbers divisible by three, and 16 new numbers with remainder 1. And you repeat for the last two digits.
Sure I can see that. Admittedly i haven't used YCM too long so I'm sure the honeymoon period is going to wear off, but so far its been great.
True. And theres probably only a few projects it would make sense for anyways. But you can get pretty good gotodef in vim with plugins. Sure it adds some startup time (.5s) 
&gt; I honestly can't even remember the last time we hit a legit memory corruption bug in our project, and we've had dozens of developers of all experience levels banging on it for years, and the engine's original core design isn't even all that modern (most of it predates C++11). :) When using modern C++, the first thing that shocks me every time after coming back from Rust is how easy it is to get a segfault, which then you need to debug and how much time this takes. My three most common segfaults are due to dangling references to variables in stack frames, misaligned SIMD types, and iterator invalidation. - dangling reference to variables in stack frames: when using range-v3 and returning adaptors/views from functions, one uses lambdas a lot. It is so _easy_ to, by mistake, capture a function argument by reference in a lambda that gets returned, and it is so hard to debug due to the types of the lambdas and chains of views/adaptors being horrendous, that this is a major time sink for something that the compiler should _always_ reject. Yet neither clang-tidy nor static-analyzer catch this, valgrind has a bad time tracking these down, and the only reliable tool to debug these is MemorySanitizer which requires full instrumentation down to libc, and doesn't work on MacOS (only Linux AFAIK). - misaligned SIMD types segfault. For example, if I put some Eigen3 type in a struct, and forget to _manually_ extend the alignment of that struct using `alignas` my code might segfault randomly depending on where that struct lands on the stack. Also when putting that same struct on the heap, I need to manually add an overload of operator new to correctly align it. When you have layers of struct containing each other (one of those types is captured by a lambda! shrug!), tracking down where the problem is through chains of constructor calls is no fun. Mostly because some of these constructors are implicitly generated :/ - iterator invalidation: for fast processing most of the code i deal with put data into vectors. For more complex operations, it builds other data-structures with iterators to this data. It is hard to mentally keep track about which operators might invalidate those iterators, and how to fix them. When something subtle is screwed up, typically tests start failing on "some platforms" due to different vector growth factors :/ these are also fun to track. Finally, when using OpenMP, everything is shared and non-private by default (yay! FUN!) so that code ends up with _huge_ pragmas that explicitly make everything non-shared and private and that any type of refactor needs to properly modify (or you get data-races, false sharing, and what not... ). In Rust, on the other hand, once I finish writing a line that might produce any of this problems, emacs starts blinking in red. I re-read the line I just wrote, fix the issue, and keep going. I don't even need to compile my code to avoid these things... switching to debugging-mental mode, open a debugger, track it down, read other people's code, modify, compile, run-tests, modify, compile run-tests... If I am lucky a trivial segfault costs me 10-15min :/ An unlucky one can easily costs me a couple of hours... If you already have very good low-level C++ libraries, and most of the code you write is application like code (that is, high level as opposed to low-level), then you might never hit segfaults. In this case a higher-level language might buy you more than Rust. For us, the main difference between C++ and Rust is that all the time we spend debugging segfaults in C++ is spent shipping code in Rust. We need to interoperate with C++ and do write lots of C++ code, but every time I hit a segfault I am like "we should be using Rust for this as well...". 
1. Yes, rustup is maintained, and is actually [the recommended way of installing Rust](https://www.rust-lang.org/en-US/install.html). 2. You can `cargo install rustfmt`, etc., and the binaries will be in `~/.cargo/bin`. Just add that directory to your `$PATH`.
Maybe use https://capnproto.org/ for zero-cost deserialization. P.S. I've used capnproto in Rust. It can be made to work fast, but for me it is rather complex, slowed the development down a bit. (Depends on how good the code completion engine your IDE uses, I guess. The generated deserializers aren't easy to parse for some of them. Depends on how you generate and include them, too).
One tip: you could use `rayon` to make it multi-threaded and use all your CPU cores. :)
[Like I mentioned a few days ago](https://www.reddit.com/r/rust/comments/677esy/whats_everyone_working_on_this_week_172017/dgoiq6y/), I've been dabbling in Rust async by working on a small -- but non-trivial -- project. This post is a recap of the experience, including some conclusions about the current state of the ecosystem and its viability for production-grade microservices.
This is great!! These "real world" type reports are super useful to convey to people what it's like working with Rust, refactoring, redesigning, etc over time. I also love that you learned from marketing and product that it's important to consider the end user constantly :) I also also love the high praise you have for the book &lt;3 It means a lot to me &lt;3 &lt;3 &lt;3
Looks interesting. I'll keep it in mind for future projects. I'm not loading too much data, so it doesn't take all that long. Not sure if it's worth the extra complexity.
No. What you are pointing out is rustup from https://sh.rustup.rs which is indeed the new way recommended way to install rust. What I use, and wondering if it is maintain, is https://static.rust-lang.org/rustup.sh which is a different script and does install in /usr/local/bin. &gt; Just add that directory to your $PATH If you're happy to work that way, that's great! Some of us though, like and want to work out of /usr/local/bin for a whole bunch of reasons, which we could discuss, but really that is a different discussion.
Right... And can the new one install rustc and cargo in /usr/local/bin ?
You can set `$RUSTUP_HOME` (and then `$CARGO_HOME` for `rustfmt` et al.) to whatever directory you want. It will still mirror the layout of `~/.rustup` though. If you want to install directly to `/usr`, you should probably use your distro's packaging tools.
Aaaand [it's out](https://www.reddit.com/r/rust/comments/6830au/asynchronous_rust_for_fun_profit/)! :)
I'm not sure I follow why this is a strong desirable? I really like that rustup installs to my user home dir. 
I have a question, actually. This wasn't an issue last year, but if I were to submit a proposal - what if it's like... really *obviously* me? Like what if you're the sole maintainer of a project/ library that you want to give a talk on?
Thanks! On a related note, are there any opportunities to help with planning or running it?
Those slides may be in German, but they're also 90% in English.
What was the feedback?
I would say fill out the abstract without the name of the library, but include some context. Something like: &gt; In this talk, you'll learn how [redacted], a library that frobs glorps, uses Rust and is faster than other comparable tools in other languages and then in the "details" section maybe mention that you'll fill in the actual library name if selected, that this is an actual library that exists (rather than one that might exist by the conference, for example), but that you've redacted the name to preserve anonymity. Even if "frobs glorps" is something really specific and your crate is the only one that does such a thing, when I've reviewed talks I don't go out of my way to try to figure out who someone is in order to avoid injecting my own biases. So as long as you don't literally have the name in there, it should be fine.
I'm not sure about RustConf, /u/aturon? If you'd like to help out with Rust Belt Rust at all, I'm always interested in volunteers :) What kinds of things are you interested in helping with? (Feel free to PM me on here or email me, carol dot nichols at gmail, if you want to continue discussing this somewhere else :))
Are there any good online courses yet that are worth the time and money? I'm thinking something as good as Kate Gregory's stuff for C++. Of course I'd also be happy with a good youtube series, but everything I've found so far is kind of bad when compared to material available for C/C++. (I do realise it's not exactly a fair comparison with C having a number of university courses on YT/iTunes U and Rust being pretty new.)
This week in xi. Incidentally, I did soft-launch [xi-win](https://github.com/google/xi-win) but it's not exciting, it doesn't actually edit text yet. I'm looking whether to share bits of code (especially the line cache) with the new [gxi](https://github.com/bvinc/gxi), a front-end written in gtk-rs.
That's definitely not the case. I myself have run GNOME, KDE, LXDE, XFCE, MATE and a whole bunch of other things on Arch with no issues. 
My `Send` problems were actually related to _not_ using `BoxFuture` at the [site where a thread-based future was created](https://github.com/Xion/rofld/blob/19d37cef4bb2e917e54c862ef138c7da4378d03e/src/caption/mod.rs#L100), and using the less restrictive `Box&lt;Future&lt;Item=..., Error=...&gt;&gt;` instead. In my case at least, the `Send` requirement that `BoxFuture` enforces &amp; preserves was in fact absolutely necessary. (Not sure about `'static`; I haven't encountered any issues with that).
Oh thanks for pointing that out, I think I have been to the page before but only skimmed it because it was relating to the file format as opposed to the CLI arguments (man page) that I was looking for.
&gt; I know this is not trendy right now, with container etc... That sounds like being stuck in different worlds where you can't `write` or `zwrite` to each other! :-O
Cool, thanks a lot.
See: https://github.com/rust-lang-nursery/rustup.rs/issues/618 I don't think installing to /usr/local/bin would work very well as I believe cargo also uses $CARGO_HOME as a cache directory. But you could do something like install to /usr/local/cargo and then symlink the binaries to /usr/local/bin
&gt; editor.formatOnPaste It doesn't have any effect. Indentation is still ruined after copying a block from one indentation level to another, and so I have to manually correct all but the first line. Atom has never had an issue with this. &gt; Maybe it's been a while since you tried it? :-] I try it out each time there is a new release. I've given it way too many chances.
But you could define a `lazy_cats!` macro that did call `to_string` and then there would be happiness? macro_rules! lazy_cats { ( $( $x:expr ),+ ) =&gt; ( lazy_cat!( $($x),+ ).to_string() ) } 
Arch doesn't even have its own desktop :) Like K900_ I've run a bunch of different one's on Arch: Gnome, KDE, XFCE, i3, awesomewm, ... They all work fine, just follow the wiki's instructions for whatever desktop you want.
And here's the recording of the 4-hour(!) breakdown stream! https://www.youtube.com/watch?v=woqksTHNbvk
As a Go and Python user, I find it amusing to see Rust considered *worse* than Python. Python finally has async, but I find it highly un-ergonomic. Go is excellent, though: abstracting channels and goroutines to make future-alikes is a lot of overhead for a future, but the pattern works well. I do think Rust can do a lot better than either, and a first-class Future object already points in that direction. I'd just love to see a greenthreading solution to rival goroutines, now.
Using `Debug` would mean that `lazy_cat!("Hello", " world!")` would return `"\"Hello\"\" world!\""` (i.e., it would add quotes around each argument, and would also embed character escapes for certain input characters).
&gt; &gt; Consistent with the philosophy behind Rust, it proclaims to deliver its abstractions without any overhead. &gt; &gt; This is not really accurate. The term "zero cost abstraction" doesn't refer to a total lack of overhead, but rather to a parity between the overhead of abstract version and a hand-coded version without the extraction, at runtime. You go on to convincingly argue that Tokio doesn't do that either, but it's important to make this distinction. Thanks! Too often people equate Zero-Cost Abstractions with just Zero-Cost
There is a bug in the version. I am about to publish another version. Sorry)
Done.
&gt;you're missing the biggest optimization! By a **lot**. Optimizing instructions might take you from 3 seconds to 2.5 seconds, but finding the tricky algorithm that solves it in an order of magnitude fewer steps will take you from 3 seconds to 0.3 seconds.
~~kind of weird, I have installed `rls` via `rustup component add rls` but the plugin requires always installing `rls`.~~ Update: it works now, I haven't noticed that the plugin is updated just several minutes ago.
I've switched back to `*mut T` when the function needs to write into it and `*const T` when it doesn't, and have comments indicating whether there can be an array behind that pointer. I wish Rust supported doc comments with function signatures: /// Function documentation fn funcname( /// Parameter documentation param: i32 ) -&gt; i32;
As written your example 'other library' looks incorrect to me. Usually such a pattern would be accompanied by a 'pub use' reexport, to make the types public from the outer module, like // other library mod lib { pub use self::error::*; // this is the difference. mod error { #[derive(Debug)] pub enum LibraryError { Hello } } // These errors are using the public-facing path pub fn hello() -&gt; Result&lt;(), LibraryError&gt; { Err(LibraryError::Hello) } } 
Unfortunately `cargo` is lagging slightly $ pacman -Si cargo Repository : community Name : cargo Version : 0.17.0-2 Description : Rust package manager Architecture : x86_64 URL : http://crates.io/ Licenses : APACHE MIT custom Groups : None Provides : None Depends On : curl rust Optional Deps : gcc: for compiling C source code with gcc clang: for compiling C source code with clang Conflicts With : None Replaces : None Download Size : 1819.40 KiB Installed Size : 6446.00 KiB Packager : Johannes Löthberg &lt;johannes@kyriasis.com&gt; Build Date : Wed 22 Mar 2017 11:00:09 AM UTC Validated By : MD5 Sum SHA-256 Sum Signature $ cargo --version cargo 0.18.0 (fe7b0cdcf 2017-04-24)
Yeah, I know the solution. The problem is that people forget it, which makes me wonder why Rust even allows it. For example this was the case with osm-xml: https://github.com/orva/osm-xml/pull/1/commits/91d396de8af19325758931d88ed3e04afe04af2f Now look at the parse() function in osm-xml before the fix: https://docs.rs/osm-xml/0.5.0/osm_xml/struct.OSM.html#method.parse and after: https://docs.rs/osm-xml/0.5.1/osm_xml/struct.OSM.html#method.parse It returns an Error, but that Error is completely undocumented as to what it contains, pretty much the only choice left to the library user is to `unwrap()` and hope for the best. People make errors like this. Most libraries do not, but it's a pitfall. Mostly it's just because people forget to reexport the errors or make the module public. I think that it's an inconsistency and a pitfall in Rust. My rule for this would be: "If an enum / struct is accessible through a public interface, the full path to the struct (like `library::container::wrapper::struct`) must be public or the path (to that struct) must be exported otherwise (via `pub use`)." Yes, you can trust library designers to do this, but I thought Rust was all about getting annoyances like this out of the way.
`pub const LOCALHOST_4: [u8, 4] = [127, 0, 0, 1];` would be a great addition to `std::net`, I think. Same for `pub const LOCALHOST_6: [u16, 8] = [0, 0, 0, 0, 0, 0, 0, 1];` 
Cargo tasks (build, check, etc.) aren't working now (with 0.3.13 + RLS), through either the command palette or custom keyboard bindings. :-[
I couldn't read the article due to all the memes.
Do you know what's going on with Ruru, by the way? The repo hasn't been touched since January.
Wow, that's awesome!
The bulky additional keywords that break everything if you forget even one instance, in some cases, are probably the nastiest bit for me. All the `async` and `await` spam everywhere looks bad enough when it *does* work. And, it doesn't even give you concurrency for that. Multiprocessing offers a few nice things like `Pool`, but they're not ideal either because you don't, AFAIK, get immunity from races. So if your workers are all writing to the same file, expect broken lines, I think. The analogue in Rust, as I see it, is Rayon, which does thread based, iterator centric concurrency, but comes with race safety and a much, much cleaner syntax. But, I'd still prefer a general-purpose greenthreading solution..
Thanks. &gt; The downsides of using these methods Valid trade offs depending what you need. I see a place for both use case.
I wonder if this is considered trivial enough for PR or if RFC would be needed. I guess it's trivial...
Ah, I didn't realise `const` doesn't actually declare any backing storage. I'd only previously used it for numbers that I assumed where just being constant-folded. Is there any reason to use `const` over `static` given that constant-folded presumably applies to the latter?
I have opened a PR which fixes the problem, but I have no idea why the problem appeared. https://github.com/editor-rs/vscode-rust/pull/212
&gt; weeks tho At least that time, I had the right concept in mind when I wrote the wrong thing. Now that "it's tomorrow" and I've started to make up for the sleep debt, hopefully, that kind of mistake will drop off quickly. &gt; I use Ruby's PRY as my calculator, because honestly who doesn't use a semi truck to putz around their yard *chuckle*
That's a neat way of calculating! Another way to get the same result with some linear-algebra machinery is by introducing a recurrence relation for C(n;k) = (the number of n digits numbers written with the digits 1-5 that are = k mod 3). Observe C(n;1) = C(n;2). Then C(n;0) = C(n-1;0) + 4 C(n-1;1) C(n;1) = 2 C(n-1;0) + 3 C(n-1;1) or as a matrix equation n [C(n;0)] = [1 4] [1] [C(n;1)] [2 3] [0] and diagonalizing gives the answer you gave.
NOTE: This is now a Pre-RFC: https://internals.rust-lang.org/t/pre-rfc-do-not-allow-public-structs-in-private-modules/5156
&gt; How could Rust get closer? It compiles to machine code and doesn't have any runtime to speak of. That's bare metal performance. &gt; In this case, there could be scenarios where a hand-coded application (in C, let's say) using `epoll()` (or similar multiplexing API) could beat Rust with futures + mio.
The thing is all optimizations that reduce branching and such are mathematical optimizations themselves. We have to choose not to implement optimizations that makes this a *O(1)* but instead have to choose optimizations that convert the boolean logic into arithmetic that can then be formed. The frustrating thing about your request is that you are asking us to limit ourselves to arbitrarily understandable optimizations, with no clear guideline as to what makes one more or less understandable. With that said here's my attempt at choosing something. The solution is to convert hard branching into mathematical operations. Basically given an integer `N` the formula `((N % 3) + 1) / 2` will return 1 if the number is not a multiple of three and 0 if it is a multiple of three. The way this works is that `N%3 +1` is either 2 or 3 for any non-multiples, and `2/2` and `3/2` both equal 1 in integer division, OTOH `1/2` is 0, which is what happens with multiples. Now we have a way to check if a number is, or is not, a multiple. If I had an iterator `i` that contains all the numbers I want to check I can find how many numbers are not multiple of three by simply calling `i.map(|n| ((n % 3) + 1) / 2 ).sum()`. Assuming that I know how many numbers are in `i` (and we should in this case) I can say `i.len - i.map(|n| ((n % 3) + 1) / 2 ).sum()` and that should give me what you want. Not only is it an elegant one-liner but it shouldn't have excessive branching. Generating the `i` iterator (and finding out its size) efficiently is left as an exercise, but it should be trivial using similar iterator magic. Could we optimize it even further? Of course, but then we'd need to understand more about mathematics and limits to reduce the test cases even further (eventually to 1 actually). This is a harder problem, but your code shows that you are smart enough to understand this, just be patient with yourself it, math, as programming, or any other skill, takes a while to just "click" (but it's awesome when it does). TL;DR: There's no "only optimization, no proper mathematics". Computers are a mathematical construct, and the way we map language to machine is mathematical constructs. There's a few physical limitations (memory issues and such) but these are what you do when you are desperate and have proven mathematically there's no better way. Optimizing is an exercise in mathematical proofs and statistical analysis.
Would anyone be interested in a computer vision crate for Rust? If not maybe a genetic algorithms crate?
&gt; Saying it bluntly, right now Rust doesn’t really support the async style at all. All the combined API surface of futures/Tokio/Hyper/etc. is a clever, but ultimately contrived design, and it has no intentional backing in the Rust language itself. This is because we're determining the correct system for futures using the `futures` crate before baking them forever into the language.
Do we have to defend everything said ever about rust?
I would guess PR but idk
Well by compile time hit I meant not only execution time of the build.rs, but also time which compiler will spend on parsing and compilation of the generated code. For example if you take country borders from OSM without any simplification I think compilation time of resulting rs files will be very much noticeable to say at least.
Or unless you have "1 click rollback" which includes all dependent services. 
You're absolutely right. They should be in a library, not baked into the language.
Hmm, I'm not seeing it... Oh, a fairly recent version is in `testing` of course. That's something to really look forward to, maybe I'll migrate my entire system from the Ubuntu repos to debian Stretch once it's marked stable (soon?), as Rust is not in my current LTS repos anyway. As seen below by the mention of an older version, maybe official Rust repositories could be an idea for more timely updates? Both the debian(-derived) community and the Rust community seem to be full of people who rightly refuse to compromise where this isn't necessary. Best of both worlds. Admittedly, having Rust in official repos at all, like Stretch and 16.04, is a big plus already. Thank you very much for the mention! That's very impressive from whoever went through the effort on the debian community's behalf!
I didn't think of that, makes sense.
You'll probably either want to wrap an existing pointer like Box, or write one in unsafe code. If it is for educational purposes, I'd just say look at how Rc and Arc themselves are implemented - they are built in pure rust code in the standard library using unsafe code and raw pointers. For example, here's the definition of `Arc`: https://github.com/rust-lang/rust/blob/ea376822a17dd911244c313c5b07dffdfe3c023a/src/liballoc/arc.rs#L156. You might need to jump around the files in there a bit to get all of the implementation details, but it's all implemented in plain rust code which you can replicate in another library/crate..
I am trying to use Rust MPI binding library at [1]. However when I try to compile the example there I get the following error apparently from bindgen. ... Compiling quasi v0.32.0 Compiling syntex v0.58.1 error: renaming of the library `` was specified, however this crate contains no #[link(...)] attributes referencing this library. error: aborting due to previous error error: Could not compile `bindgen`. I am on rustc 1.18.0-nightly (2564711e8 2017-04-04) and mpi = 0.4.0. What should I try in order to fix that?
The defining trait of smart pointers as we've defined in [the second edition of the book](http://rust-lang.github.io/book/second-edition/ch15-00-smart-pointers.html) is `Deref`, so that you can say `*whatever` on your smart pointer and it acts just like a pointer. Also commonly implemented is the `Drop` trait, but not all smart pointers implement `Drop`, it's just how you'd clean up after a smart pointer or decrease the reference count or whatever you want to do, so it's common.
`Deref` and `DerefMut` traits are the special sauce. You don't necessarily need unsafe code; in fact sometimes people use `Deref` to fake up object inheritance. I guess those are not smart pointers *per se*. But smart pointers do frequently involve `unsafe` code because you are teaching Rust about some ownership / memory management paradigm it doesn't understand natively. C code would be rare unless you are wrapping a C library's custom allocator for use by Rust. I agree with others that you should check out the source for `Rc` as well as the more complicated `Arc`. `Box` is unfortunately still a magic compiler built-in.
There's only one algorithm in the gzip RFC, it's called "deflate". If the lib accepts more than one algorithm, then it must be supporting formats other than gzip (maybe zip or zlib).
Another kind of smart pointer are the `Ref&lt;'a, T&gt;` and `RefMut&lt;'a, T&gt;` returned by `RefCell`'s `borrow` / `borrow_mut`. These act mostly like `&amp;'a T` and `&amp;'a mut T` respectively, but their `Drop` implementation un-sets the run-time borrow flag. `MutexGuard` is also similar.
Thanks for the tip! I think that fits my goal of being really naive and just trying to run an inefficient/useless recursive algorithm, but as fast as possible. :D
I have started a blog about Rust and embedded development, and this is the first (real) post :tada:. In this post I cover how to build 100% Rust applications for any ARM Cortex-M microcontroller starting from a template that handles all the low level details so this is as easy as it can get. The really exciting stuff comes in the next post though! I'll introduce a concurrency model and walk you through building an application than runs more than one task concurrently and efficiently. I won't say more about that post; you'll have to wait ;-). I'd be happy to answer any question about this post!
&gt; in fact sometimes people use Deref to fake up object inheritance. [Which btw is an anti-pattern](https://github.com/rust-unofficial/patterns/blob/master/anti_patterns/deref.md). The rusty way is to either create a trait (so that a bunch of different types can implement the same methods) or to include the parent struct in a field (which is called composition) if you need to access data from the parent as well.
Have you seen this issue (https://github.com/rust-embedded/rfcs/issues/20)? AFAIK, the current status is - rustc supports the architecture as in the LLVM backend is enabled. Though the MSP430 backend is still considered experimental in LLVM (at least that was the case for LLVM 3.9; I haven't checked for LLVM 4.0) - The core crate can be compiled for the MSP430 architecture (using e.g. Xargo) - there's no built-in target in the compiler but you can use a custom target definition. (I think it's already time we add the target definition to the compiler since the backend has been enabled for quite some time) That's as far as Rust support for a target goes, I think. The rest is ecosystem work which is up to the interested parties. I can't really comment about the MSP430 crate ecosystem but here's one starting point I know of: https://github.com/pftbest/rust_on_msp You shoud probably contact pftbest and awygle (see link at the top) for more information about the state of the ecosystem.
We work out of some other directory (as suggested by shadow31) which is not located under our home directory. Programs from there are allowed. Most of the staff are not programmers (not a programming company) and it is deemed more secure to prevent users from running programs from the home directory. Whether that is true or not, convenient or not, etc. does not matter much, since I don't make the policies (and frankly have little influence on them ;-) ). It is usually not that much of a problem really, but for installing rust, it means using a the .msi installer. At least for now. I have not played with CARGO_HOME and RUSTUP_HOME. Maybe I will.
The best thing that could happen right now is to get more people trying to use either Rust or just the LLVM backend, uncovering bugs like the one towards the bottom of that issue /u/japaric linked (thanks for the nod btw!). I have a personal list of things that need to be improved to bring support up to snuff and I've been working through it ve-e-e-e-ery slowly. Here's an abbreviated version of it: * Convert the LLVM backend to generate libcalls which comply with the EABI from TI for things like multiplication and division so that we can link in libgcc and do useful stuff (in progress, stalled on an issue with 8-bit libcalls that I can't figure out) * Add EABI-compatible definitions to compiler-rt to avoid the need to link libgcc (possibly also to compiler_builtins, the rustc version of compiler-rt) * Add assembler support to the MSP430 backend to avoid the need for binutils (at this point I think we'd be fully away from needing the gcc toolchain at all?) * Add support in rustc and possibly LLVM for some of the useful/tricky intrinsics, such as __bic_SR_on_exit as mentioned in the RFC issue * Whip up a quick crt0 implementation based on the r0 crate and the startup code given by TI (this is very simple) * Add support in LLVM for the two MSP430 architectures (vanilla and MSP430X) and proper differentiation between the two * Add support in LLVM and eventually rustc for the 20-bit pointers of the "large memory model" (this is going to break everything, I can't wait) All that being said, if I can get those libcall patches landed then it'll be 100% usable, if a slight pain in the ass. And if you want to work on any of these, I'd be happy to point you in the right direction to the extent that I know what that direction is. EDIT: I forgot about the linker - unless I misunderstand something we probably won't be GCC-independent for a while
I have fixed it in the master branch. You can install it from there right now. https://github.com/editor-rs/vscode-rust/blob/master/doc/install_extension_from_source.md Some people also complain about other things so I am going to fix them also. 
That's true. Maybe do it in the same module Ipv4Addr is defined, so instead of function, put the numbers directly into the struct?
If you try "Go to Symbol in File..." it should work. If you try "Go to Symbol in Workspace..." it shouldn't because RLS does not support it.
Search crates.io . If it isn't there, than I guess noone wrote it yet. It would be reasonably simple to port to Rust. The whole magic happens here: https://github.com/facebookgo/grace/blob/master/gracenet/net.go#L206 Existing process forks, closes all `fd`s other than the "restartable" ones, then passes the list of open fds as an environment variable to a newly started instance of itself. Something along those lines... I think it could actually be made better, but I just glanced. I guess in Rust this could be even generalized as some `RestartPersisting&lt;T&gt; where T : AsRawFd` I see if you want it, go for it! Ping me on gitter if you need help with unixy details. :) 
If you use multi-stage builds then wouldn't the intermediate layers with the deps downloaded be cached by Docker?
This is amazing. Looks like rust on embedded has come a long way. Looking forward to trying this out when I have some time. 
I'm not sure.
Cool. You can also say `$crate::LazyStr` in your macro and then you don't need to import it directly.
I released the crates: https://crates.io/keywords/tm4c
 &gt; &gt; In some cases, however, it was found that when the OS is scheduling the threads, it introduces too much overhead on the frequent pause/resume state changes (context switching). &gt; &gt; Modern kernels are very fast at context switching. The performance difference between async IO and thread-per-connection sync IO is marginal. I feel very silly now, but thank you. :D Being a `mioco` author it's a lesson in humility for me. Inspired by your comment, I actually run a benchmark of the same example code of mioco vs std::thread -based http server (8 logical cpus, 4 real cores in both cases; 8 listeners threads/fibers + 1 thread/fiber per every connection) and got: Requests/sec: 526941.92 for threaded Requests/sec: 600284.01 for fibers I should have checked that long time ago, but I didn't ... . For some reason I lived with old time assumptions, where threads were really slow. The difference is not that big, and considering the complications... I don't know if it's really worth it... And as far as I know, in newer mioco implementation, that I copied the reactor machinism from tokio, mioco performance is really similar to tokio. I guess I should stop worrying and start spawning more threads ...
Somewhat off-topic: as somebody who has no experience in toolchain engineering, I wonder how people test the output of something like a compiler systematically? Is there some other way than just trying it out and checking whether it generates correct assembly output?
&gt; &gt; in fact sometimes people use Deref to fake up object inheritance. &gt; Which btw is an anti-pattern. How does one challenge that? Sorry if this is a bit of a side track, but the link's main argument is "it'll be surprising" - which is just a matter of usage (use this pattern enough and others will get used to it - it won't be surprising).
You're welcome and thank you!
In my opinion, it's just not a good mechanism for emulating OO, because it's too leaky. The type `A` will behave as `B` when calling a method, but functions that receive `B` will still not accept `A` as parameter. There's also the pain that `A` won't automatically implement `B` traits so generic code can't treat it as if it were a `B` either. So it's not just surprising, it's also unergonomic. I'd prefer to have a trait implemented by `A` and `B`. Then, that function that would receive `B` now receives any type that implements this trait. This is both more explicit (good for documentation) and more composable (you can bound a generic type with `Trait1+Trait2` which doesn't have the downsides of multiple inheritance). If that's not convenient, I would prefer to just call `a.b.method()` if `a : A` and `a.b : B`, instead of `a.method()`. A little bit more verbose, but fits Rust better IMO. Now, if Rust had better facilities to make this kind of operation more ergonomic, it would be more widely used. (But then in this case I would fault the language for making magic too widely available).
Constant folding only (and always) works for `const`, not `static`, and that's why you need static in this case. Static puts it in a read-only section of the binary where the data stays for the whole course of the program, so a reference can be safely returned. `const` would inline the value, and thus it would only live till the end of the function call, and you can't return a reference to it.
Try with 10000 connections and get back to us
Why not staying platform independent and using gtk-rs? http://gtk-rs.org/
Which is why we should give users the choice.
Yeah. I think Stellaris was a brand they bought (from Luminary?) and the LM4F was late and buggy, so they just swept it under the carpet and pretended it didn't happen. After I'd bought mine :/ The TM4C123 has a Quadrature input support, I think. But otherwise pretty much identical.
The '129 is sweet. I *really* want to write a TCP/IP stack for it.
Is there any support yet for older ARM models? Will there ever be?
&gt; The question is whether Rust is better enough to be worth the millions of dollars to switch a company over I think it would be better to consider whether integrating Rust is worth it first. That is, to consider whether on the next iteration of your "stack", when a new component will be added or an old one re-designed/re-written, whether it would make sense to use Rust there. &gt; Again, you're pretending all C++ is crap and all Rust is perfect. That isn't reality. Sorry that it came out that way. If I had more time I would have tried harder to make it come differently. The thing I was trying to say is that currently I think that there are some things at which Rust can get better than what C++ will be able to. I hope I never said that C++ is crap. It isn't. But the more I program in both Rust and C++, the more I get an "I wish had used Rust for this as well" when I hit some rough edges of C++. The same is true about Rust though. When I want to express something and I need integer generics I often think a lot about "Should I have used C++ for this?" or "Am I making my life unnecessarily complicated by using Rust here?". A though I had a long time is that Rust is not a better C++ because of all these things, but it is definetely a better C, so we ended up using it more in things in which C would have been fine (e.g. non-API facing small parts of the stack).
Have you seen this issue https://github.com/tomaka/glutin/issues/860 ?
It is RLS.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programmerhumor] [They aren't angle brackets, they're characters from the Canadian Aboriginal Syllabics block](https://np.reddit.com/r/ProgrammerHumor/comments/688p46/they_arent_angle_brackets_theyre_characters_from/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I recently implemented something generally similar to your `cortex-m-rt` (that currently lives inside firmware I'm working on as a subcrate)- it looks like you're not paying much attention to performance (which is fair). A few thoughts from looking at the startup code: I found it was very difficult to make LLVM generate efficient code for setting up the data section and bss, because the relevant addresses aren't known until link-time. I ended up hand-writing assembly to do that initialization because (with the help of the linker script) I can guarantee alignment and do word-wise initialization. On a chip like the STM32 I'm using that starts up with a 2 MHz CPU clock and has 16 kB of memory, the resulting ~10x speedup reduces a perceptible startup delay to an imperceptible one (in the situation where all of RAM is initialized). YMMV, I was doing this on an -M0 and LLVM might be rather smarter with a bigger core. The way you call `main` ends up wasting a few words of memory at the top of the stack, since it stashes r7 and lr. I ended up marking `reset_handler` `#[naked]` and writing it all in `asm!` blocks (since most of it, the memory initialization, was already handwritten assembly). Knowing that my `#[lang_start]` function never returns and ignores the `argc` and `argv` values provided, calling `main` is simply a jump, without even initializing parameter registers. There's still at least one wasted word of memory when `lang_start` stashes its input LR, but it's an improvement. --- `svd2rust` was a great help for getting register definitions into code, so thanks for that. :)
[Roaring bitmaps](https://crates.io/crates/roaring) are a good default choice for this; they compress well and are fast on creation, modification and lookup.
Oh, [this issue](https://github.com/passcod/cargo-watch/issues/43)? Would be awesome!
&gt; Modern kernels are very fast at context switching. The performance difference between async IO and thread-per-connection sync IO is marginal. No, this is so not true, anyone that wrote high performance network service for thousands/tens of thousands simultaneous connections will tell you that. Look at apache vs nginx, apache is using thread per connection model and nginx is using async io. Run it on "modern kernel" with a lot of connections and see for yourself.
By performance do you not include memory use?
I'll eventually be updating the last chapter of the Discovery book to document the multitasking framework I'll present in the next post. As for the Copper book, I'll probably update it to document the inner workings of the template presented here: like stringing linker scripts using build scripts, etc. But that's low level priority so it might be long before it happens. And yes, I'll be focusing on the blog now; I already got outlines for several post ahead :-).
You mean running linux on ARMv5 (or older) development boards? There's support for that in rustc but, last time I checked, std doesn't compile for those targets because they are marked as not having atomic support. Though it is possible to use atomics on those targets with something like what's proposed [here](https://github.com/rust-lang-nursery/compiler-builtins/pull/115). I can't comment about doing IO for those boards. I don't have much experience with doing embedded IO from Linux. But the [rust-embedded org](https://github.com/rust-embedded) got lots of goodies for that.
There really isn't a good 'loc metric' for unsafe, but more useful than unsafe blocks is what percentage of the code is within the 'privacy boundary' of an unsafe block - that is, it has write access to data that unsafe reads from. Then you need to scope that down to data which the invariants the unsafe cares about cannot be mantained by the type system. But at that point you're halfway to actually analyzing the unsafe code and checking if its safe, when the point of this was to get a LOC figure.
Thanks for your reply! Regarding constructors, as an API writer do you have a preference for forwarding errors in the constructor: `Github::new() -&gt; Result` or making the dependency explicit: `Github::new(core: &amp;Rc&lt;RefCell&lt;Core&gt;&gt;) -&gt; Github`? I notice you use `.chain_err(|| "some string")` a couple of times. Would you change these to typed errors for a 1.0 release? My `Rc` question was actually: Why use `&amp;Rc&lt;..&gt;` instead of just `&amp;..` or just `Rc&lt;..&gt;`? What does the extra indirection add?
Thanks for the comment. Lots of useful info! &gt; it looks like you're not paying much attention to performance Yeah, the focus so far has been making it easy to use and keeping things modular / reusable. &gt; I can guarantee alignment and do word-wise initialization With `cortex-m-rt` the compiler also knows that the .data and .bss are word aligned and that's why the compiler invokes `__aeabi_memcpy4` which is the intrinsic that should do word-wise copying. The problem is that that intrinsic has NOT been optimized in [compiler-builtins](https://github.com/rust-lang-nursery/compiler-builtins) and it's currently [doing byte-wise copying](https://github.com/rust-lang-nursery/compiler-builtins/blob/master/src/arm.rs#L131-L142). That shouldn't be too hard to fix, someone just has to send an assembly optimization to the compiler-builtins repo then *all* the memcpy invocations in the program would get optimized. &gt; The way you call main ends up wasting a few words of memory `main` (almost?) always get inlined into _start / the reset handler so there's no function call. You don't see that in the disassembly shown in the blog post because I have, on purpose, marked `main` as `inline(never)` (I only wanted to show the code related to the application, not the startup). However, it does seems like _start could / should be marked as #[naked] to save some stack space.
That would be interesting. Seconded.. I always wondered what the performance difference nowadays would be. I often read that threading got lots of improvements over the last years, at least in Linux but i've never seen a benchmark. 
Ooh, I really like this cortex-m-quickstart template. It can be tricky for a beginner to piece together all the little bits required to get things working properly on Cortex-M, this does it nicely and it's a lot simpler and easier to understand than some of the other Rust+ARM stuff.
You can still "use `.concat()` for speed" even if this optimization was made. What you're really saying is you'd be too lazy to do it for speed if it worked with `+`
Lol pushing the boundaries of what is effectively possible is a joke? Also read about C10M. But anyways, C10K, while it improves performance for certain domains it isn't solving a "performance issue". It is meant to solve a cost issue for anyone at reasonable scale (i.e. requiring more than 3 hosts for any IO bound application or applications which can only scale vertically). The reality is the only downside to async IO is the code writer/reader's experience. This is why everyone was excited by node.js (although it is far from perfect). It's why people in this thread are excited by what Rust will do in the future.
If I have an event enum, something like this: enum MyEnum { VariantOne(SomeStruct), VariantTwo(SomeOtherStruct), // ... VariantOneHundred(SomeOtherStruct), } of course, one hundred variants is pure hyperbole, but assume I have quite a lot. Also assume that the structs are filled with more than just a `i32`, but perhaps are a few Bytes in size. If I want to pass this enum around, will this cost a lot in performance? Should I perhaps opt to instead store boxes in the variants, to reduce the enum size? Basically, in C I would have an event system with a type and a `void*` to data. Rust's tagged unions make this a bit more ergonomic, but I was wondering about the performance implications.
Obviously if you forget to type in code that is necessary, it will malfunction. Or are you concerned about the lack of static checks?
&gt; actually analyzing the unsafe code and checking if its safe For this stuff I really want the ability to extract Coq code as Rust. Unfortunately it seems all the projects working on this are very inactive.
&gt; I don't mean running Rust binaries on NetBSD Rump. What's the difference?
Is this a dependency tree? It'd help to have the names of packages with a large amount of dependencies and such labeled. Like I really want to know which bubble is piston or serde or servo
I generated this by running Gource on the [Crates.io index](https://github.com/rust-lang/crates.io-index) which means it is simply a hierarchical directory listing. I definitely tried to enable filenames (in this case, it'd be crate names) but there was just way too much to fit on the screen. I'll see what I can do. I'm currently working on creating a dependency tree between all published crates, but it is a _lot_ of data to show visually. Keep an eye out...
In case anyone is curious, I included the command I used to generate this on a [quick blog post](https://medium.com/@daniellockyer/running-gource-on-the-rust-library-index-f939b0067f3a). I aim to improve the visualisation over time. I'm currently processing one for the Rust compiler repo. I would also like to create a dependency graph web page. 
Check out `cargo-expand`.
This is a bit of a meta-Rust question, but please bear with me. I learned programming first with Python, which has the lovely [Python Standard Library Documentation](https://docs.python.org/2/library/index.html). Now, a lot of this is covered via the [Rust Standard Library](https://doc.rust-lang.org/std/), but the extremely long list of modules in Python has no direct equal... that I've found. Am I wrong, and there is some form of collation of Very Useful Modules/Packages/Crates within Rust's community? I'm currently just looking for a simple RNG, but I'd love to see a large list like the Python list.
fyi https://github.com/frewsxcv/rust-crates-index-graph it'd be cool if the visual backend of gource was abstracted out and then one used it show the crates.io dependency graph over time
I...don't get where you're coming from here. First you're telling me I'm wrong to complain, now that I'm wrong to use Python in the first place? If there's a point, then deliver it. I like Python, but my point was that it's not strong (yet) on concurrency, and that the syntax and workflow is clunky. That's all.
Then perhaps https://github.com/kud1ing/awesome-rust is for you?
svd2rust is so cool!! That is a huge step forward.
I also expected this to be an error. The semantics around visibility are subtle and evolving. I guess this is where we are atm.
Not sure if you're not a native English speaker, but 'contrived' definitely has a negative connotation. Its along the lines of artificial, far-fetched, or absurd. They seem to mean its not natural to use, the way that control flow constructs are. I can't disagree, and I look forward to having coroutines, async, and await in the language someday.
This is very cool, great work! How would you approach BLE chips like Nordic's nRF51 or nRF52? On them, the application code needs to link with and interact with their "softdevice" that the actual BLE stack is on.
That would be so cool. I would love to help.
I think GHC's runtime uses a global spinlock for atomics on ARMv5. I don't know how that stacks up against the kernel helpers (probably depends on contention level). Honest question, who's still using ARMv5?
That's strange. Maybe there is a difference in overflow checks based on the compile mode. Can you elaborate on "crash" -- show the exact way you compile/run the program both ways and the output you see?
Cast the pointer to that location to an `&amp;AtomicPtr`.
As someone who frequently works with computer vision and starting to learn Rust, I would love to see more computer vision support! :D
Well, one thing that should definitely be done is teaching Redox NetBSD's hypercall interface so we can pilfer their drivers. As to turning Redox into a unikernel... what would you want to use from it? It's a very bare-bones system as is but in principle it wouldn't be that invasive to get rid of ring and memory protections. Getting rid of preemption OTOH is probably not realistic at all, that would require lots of changes outside of the kernel proper. *Host* for unikernels is yet another issue, that should definitely come with hypervisor support which means running on actual hardware (can't nest virtualisation) and though that works, the driver situation is atrocious, so no matter what anyone's opinion don't expect it soon.
Ty so much for the quick answer! I was worried there may be some hidden fields in the Rust struct (drop flags are gone but ... I don't know Rust internals. Ok, with some further searching I found -z print-types-sizes and a small test program using an AtomicPtr gives me: print-type-size type: `core::sync::atomic::AtomicPtr&lt;u8&gt;`: 8 bytes, alignment: 8 bytes It seems that this may be a useful mechanism for me to be able to validate my Rust-created data structures are mapping perfectly (alignment too). At least wrt the size of the struct. Do I understand things correctly? 
&gt; This is false. String is 3 words (24b on a 64 bit machine, 12 on 32.) in the stack. Oops, failed at simple multiplication. You are correct. My point was that the string's contents are not stored on the stack, and that the actual stack allocation is quite small.
I'd rewrite it Rust. It seems that the NRF SDK kind of imposes its scheduler as the way to do concurrency and I'd like to see how a BLE stack built on top of the concurrency model I'm going to present in the next post would look like. But I suppose most people will just want to use existing SDK. In that case you'd have create bindings and have Cargo build and or link to the SDK libraries. I haven't investigated much in that direction so you are better off looking at [what the teensy folks are doing](https://github.com/jamesmunns/teensy3-rs) or asking them directly.
It's recognizing one character as two because of the way rust handles chars. Something about them being 2 bytes by default. It's been a while since I read the strings and chars section of the rust book. I'd look into that OP. 
The whole "is heap allocating that pointer and length" is misleading and can be interpreted different ways, I read it the wrong way it seems :)
so... any updates? :D
I think we kind of agree that the way to create a HAL is to specify it as traits. Ideally, we'll have: - A crate with only HAL traits: `cortex-m-hal` - Implementations of the HAL for a device family: `stm32f30x-hal-impl`. Built on top of the svd2rust generated crate, `stm32f30x` - Device drivers (e.g. accelerometer) against the HAL traits: `adxl345`. This crate contains only generic device agnostic code. - Applications will pull crates like `stm32f30x-hal-impl` and `adxl345` and be written against the HAL API. What we don't have agreement on is the HAL traits. Should the HAL API have callbacks in their signatures, should it be built on top of futures or should we keep it simple like the IO traits in `std` (Err::WouldBlock for async-ness)? All this will take time to figure out.
[removed]
**Here's a sneak peek of [/r/ConfuciusSay](https://np.reddit.com/r/ConfuciusSay) using the [top posts](https://np.reddit.com/r/ConfuciusSay/top/?sort=top&amp;t=year) of the year!** \#1: [Confucius say shotgun wedding a matter of wife or death](https://np.reddit.com/r/ConfuciusSay/comments/59zkfy/confucius_say_shotgun_wedding_a_matter_of_wife_or/) \#2: [Confusions say drop a brick on foot and foot hurts for days!](https://np.reddit.com/r/ConfuciusSay/comments/5ckedf/confusions_say_drop_a_brick_on_foot_and_foot/) \#3: [Confucius say consider the toilet before you consider the taco.](https://np.reddit.com/r/ConfuciusSay/comments/5x3tj3/confucius_say_consider_the_toilet_before_you/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/5lveo6/blacklist/)
It would make a lot of sense...
&gt; A persistent volume that survives container death would be a good option here. Or just making sure that dependency install/download is its own layer in the docker image, which should only be cache invalidated when the Cargo.toml or Cargo.lock files are changed. Otherwise you'll have devs in your team forgetting to remove their persistent volume when doing their final testing before doing their pull requests, resulting in sometimes having broken builds because they were depending on something in their volume but which wouldn't be installed properly in a clean environment.
Is there some documentation for functions like GPIOE.borrow() etc shown in the code?
The way LLVM does it is with a custom testing tool. You write input code in a textfile, and then have comments inline prefixed with `CHECK:` and the testing tool will check that the generated code contains the string. [Here's](https://github.com/llvm-mirror/llvm/blob/master/test/CodeGen/AVR/and.ll) an example of how the boolean AND operation is tested in the AVR backend.
in case you don't go back to re-read this thread, he did respond: &gt; I was trying wrk -t8 -c10000... 
More power to them. I'm in favor of Rust on as many old platforms as we can handle. 6502? IBM 1401?
I think you can reproduce it too. Just make a new project. Change the main.rs in src/ Come back to the top of the project tree, issue $cargo run The program will run for a while and crash. I've tried tracking what the program doing and it (by adding a statement like println!("Is {} a square number?", i} looks like there is an overflow
Thank.. thats interesting... :)
This seems to fit with the owned/borrowed model of Rust then. It only gets ugly if you need to have two mutable borrows at the same time.
Apart from blinky_main and C startup code, is there any additional code footprint?
Wouldn't using a build container to target x86_64-unknown-linux-musl (like, perhaps, [this one](https://github.com/emk/rust-musl-builder)) and then putting the resulting binary into a `FROM scratch` image result in a smaller image size?
If you never destroy a `VSAPI`, then why do you need either `free` or `Drop`? If you still own a value, you will drop it, yes. At this point, I really have no idea what you're actually trying to accomplish here, or what semantics you're trying to get at.
See [this](https://github.com/vapoursynth/vapoursynth/blob/master/sdk/invert_example.c) example. Everything is performed through a `VSAPI`, which doesn't need to be freed. But things like frames and nodes needs to be freed if anything goes wrong or we don't need it(it's ok to implment `Drop`). `Core` is a special case, when the user is done with it, he may or may not want to free it depending on what he is doing (for a standalone application, yes. But for a plugin ,freeing the core will crash the whole application)
Is it possible to use a peripheral (say GPIOE) outside of the closure representing the critical section? If so, how is it done?
Awesome! I have an STM discovery board and don't know what to use it for :D
In that case, I would do it one of two ways: parameterise `Core` such that you decide whether you own it or not at creation giving you something like `Core&lt;Owned&gt;` or `Core&lt;Borrowed&gt;`, or assume the `Core` is owned and provide a `Core::release_borrowed` or similar method. I'd be inclined to go with the first. If the type parameter is bothersome, you could add a `bool` field to record the difference and check that during `Drop`.
Yes. These peripherals have a `get` method which returns a pointer so you can use `unsafe { (*GPIOE.get().odr.write(|w| ..) }`. This is unsafe because it's unsynchronized so it can result in a data race. In next post I'll introduce a safe way to use peripherals without critical sections while avoiding data races.
Yes, there's a mandatory "vector table" which is effectively an array of pointers (the `INTERRUPTS` variable is a part of that table) that maps exceptions and interrupts to their handlers. Then the code of the handlers (they are vanilla functions) itself is part of the footprint as well. Actually, we got some bloat in that last part because LLVM's mergefunc is not working properly but it seems like that may be fixed soon ([details](https://github.com/japaric/cortex-m/issues/19)). And that's about it. If you want some numbers, running `size` on the blinky program from the post outputs: text data bss dec hex filename 1346 0 0 1346 542 blinky2 That program has about 100 bytes of the bloat I mentioned and about 632 bytes of unnecessary / unused interrupt entries which I didn't bother optimizing away for this particular post. So about 600 bytes would be optimized size of this blinky program. About 400 bytes of vector table (fixed cost of all programs), 100 bytes of startup code (also fixed cost) and 100 bytes for the actual application logic.
Just to be clear: the OP should cast the pointer that is to be changed atomically to `AtomicPtr` (and thus the pointer to this atomic pointer to `&amp;AtomicPtr`).
Eagerly waiting for that post!!
Wrong subreddit. Please, Please, Please pay attention to where you're posting.
I’ve noticed weird things happen when you change the font it uses. You’d think that the font was purely a display matter, but it definitely does have at least some actual impact on functionality.
This could probably be done if all the [three RFC about pi type](https://github.com/rust-lang/rfcs/issues/1930) are completed. But complete all the three RFC would be a huge evolution to Rust. Only the first RFC is being considered [right now](https://internals.rust-lang.org/t/lang-team-minutes-const-generics/5090) and it probably won't be available in stable this year. 
Hard but it has been solved by several languages. One example is the Ada programming language a language commonly used in the aerospace industry for safety critical software (think airliner engine controls, satellite control software, etc.) This link gives some of the flavour... https://www.dwheeler.com/lovelace/s6s3.htm 
And Solo5 is very portable. Just look at the supported "backends". They're even [adding support](https://github.com/Solo5/solo5/pull/190) for the Muen separation microkernel system. You can already target Xen, KVM, POSIX, BHyve. Solo5 also addresses debuggability of the running image (https://github.com/Solo5/solo5#debugging-on-ukvm) straight into OCaml call stack.
Most language implementations that I'm aware of don't stop you from doing things like .... if (my_float &lt;= 0.1) that often don't work the way you'd expect. (0.1 cannot be represented perfectly in binary floating point so depending on the size of the float and the nature of the calculation that produced my_float, you may find that my_float is almost infinitesimally larger than 0.1 or smaller.) Other features of IEEE are not always exposed to the programmer even though they can affect the results of computation.
Rust floats [are](https://is.gd/MzukeD) comparable with `&lt;=`. It's a potential bug, but Rust doesn't try to eliminate every possible bug. If anything, having only one (well, two) float type should make the transition easier, since that's one less `&amp;str`/`String`-style distinction that people need to learn.
Interesting link! The issue though is not just about runtime. For a trivial test case, two integer values of range 1-10, cannot be added together and stored in another integer value of range 1-10 because it may exceed the range limit, and so the compilation should fail. I think catching this kind of problem at compile time fits the spirit of Rust better than runtime only checks. edit: it's a bad example!
[removed]
Were they complaining about the `Eq` trait, specifically? Because Rust separates the concept of total mathematical equality from the `==` operator which uses partial equality (the `PartialEq` trait).
&gt; do you force register access functions to be inline? I have marked everything as `inline(always)` but you really need at least opt-level=2 + LTO to get really lean code with zero function calls for a RMW operation. `modify` (the RMW method) uses closures and those don't get inlined unless you use opt-level=2 or greater. opt-level=0 code looks awful because enums are used internally to forbid invalid bit patterns at the bitfield level. Here are [the disassemblies](https://gist.github.com/japaric/889d87e5b8f24b560d918310b915a9dc) for the following snippets when compiled using different optimization profiles. #[inline(never)] fn access(gpioe: &amp;Gpioe) { gpioe.moder.modify(|_, w| w.moder9().output()); } I think something that would here is being able to compile dependencies with an optimization profile different from the top crate. Then you could get better code even if you compile the top crate with opt-level=0 if the deps are compiled with opt-level=2. But Cargo is missing this kind of feature atm. Language level support for bitfields have been proposed before but there were concerns wrt to portability (endiannes) and I don't remember what else. I don't think they are likely to be added to the language. Also, I don't think you can prevent writing an invalid bit pattern to a bitfield or make a bitfield read only, which are things that the svd2rust API provides, with just language level bitfield support.
Ada inserts run-time tests when dealing with the ranged types, so that system isn't really compatible with Rust's aim of zero-cost abstractions. Rust's strictness is generally about making sure that memory always has a clear owner, and it only ever has exactly one owner, so it can be freed at the right time. The compiler isn't really designed with the aim of preventing calculation mistakes, nice as that would be. Still, I'd love to have what you're suggesting if it were possible - F# and other ML-family langauges have the same problem, where you get wonderful type-safety for "descriptive" types, but unfortunately there's no nice way to constrain numerical ones other than a giant discriminated union/enum, which isn't fun for anyone.
What's a program good for, if it's incorrect? ;)
Thanks. Language level bitfield support can't be used in C or C++ either, it exists, but the order and padding of bit fields are implementation defined. There are some compiler-specific attributes, though. In the above code, bitfield assignment uses a mask generated at compile time (constexpr), and the = operator is overloaded.
One idea I've had for a while is preventing using inexact floating point literals. You'd have to write, say, 0.1000000000000000055511151231257827021181583404541015625 It would stop some of these mistakes, but I'm also pretty sure people would hate it ;).
Not always. `435.75` is exactly representable, for example.
&gt; The point I should have been making is that Rust's memory- and type-safety checks are static They are mostly static, but not always. I think it's fine to have multiple levels of checks: some static, some dynamic, as long as it's clear where the dynamic ones are. For example, while Rust's checks are generally static, `RefCell` and `RwLock` or `Rc` and `Arc` use unsafe code to dynamically guarantee what cannot be statically proven; and it's very useful. I can perfectly see bounded integer types with a mix of both static and dynamic range checking.
I've never used servo as a library, I know it uses mach to manage a lot more than just rush source files. IIRC it also includes spider monkey for JS among other things, and has a lot of environmental variables and commands to juggle when building. [mach](https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/mach) is simply a nice way to manage all that that works on all platforms. https://www.reddit.com/r/rust/comments/38kbe8 seems like a similar question to yours though, maybe it can provide more insight? A bit old but I'm sure most of what was said there still holds true today.
Sure and the point of this thread is to discuss the trade off.
Threads and work pools will get you very far before you have to have call back/async/future spam everywhere.
It's funny to see you say this because I came at it from the same perspective in [my own post](https://www.reddit.com/r/rust/comments/5i7wzv/invalid_value_safety/?st=J24YRCAA&amp;sh=cfa7446d) some time ago! [RFC 0873](https://github.com/nox/rust-rfcs/blob/master/text/0873-type-macros.md) if implemented would make numerical refinement types with runtime assertions as simple as a macro invocation but it hasn't gotten much attention lately.
What if T is contained in the binary like the include_str! Macro does? Read is kinda pointless then. Your stream could simply be a set of bytes in memory and the ogg decoder shouldn't care how it got there.
Read is also implemented on slices, and if you want to seek you can use Cursor. So with that abstraction, its easy to decode ogg from in memory locations.
Paul Rouget which is part of Mozilla and the Servo team (I think) is working on this. Look at https://github.com/paulrouget/servoshell which may interest you.
For me, both running with `cargo run` and manual compile with `rustc` result in: thread 'main' panicked at 'attempt to multiply with overflow', src/main.rs:5 And as Gilnaa says, this is because Rust has overflow checking by default in debug builds and when `j &gt;= 46341`, `j*j &gt;= 2147488281` and the largest number allowed in an i32 is `2147483647`. And even if `j*j != i`, the result of `j*j` is temporarily stored in an i32 because multiplying two i32s result in another i32. If you want to avoid the overflow, you need to cast to i64, like this: total += if ((j as i64) * (j as i64)) == i as i64 {j} else {0i32}; 
Yes, the default cargo hello world app is 3.3M on my system. No need to bother with Alpine. And if you build on Linux there is no reason to bother with build containers IMO. There is also https://github.com/japaric/steed (although it's not ready for prime time yet) which drops the musl dependency and replaces it with rust code.
*Categorically* opposed. That's the least ergonomic and one of the least helpful things I've ever seen. You can't fix people using floats without understanding how they work, and forcing an outrageous level of incomprehensible ceremony certainly won't help. Also, people will write "`f32::from_str("0.1").unwrap()`" every single time instead.
Since `NaN` is a float, "fuck `NaN`" doesn't solve the problem (and tossing the standard semantics is in all likelihood even worse).
I think it mostly removes redundant information (because the name of the variable has to be the same as the name of the field for this to work), so (to me at least) it seems like a minor change.
In that spirit, one should probably also not create a crate with any of [these](http://kizu514.com/blog/forbidden-file-names-on-windows-10/) names.
I think a safe float would have special functionality for properly doing floating point comparisons. This is a pretty accessible discussion of some of the issues that's far better than I could put together for this thread: https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition
Just the registry, cargo does it whenever you `cargo build` or `search`
Hey I've been working with orbital lately for a solitaire game. I settled on just rendering png images to a widget and re rendering when the game state changed. I'd be happy to discuss more tomorrow if you want to get into specifics. 
https://github.com/SSheldon/nul/issues/1 https://github.com/rust-lang/cargo/issues/3982
We're a LONG way off from 2^14! - r/unexpectedfactorial
Has there been any attempts like that for D (or C++), even toy ones, considering that D has fairly capable template system?
Oh my god, I feel so bad for that crate author... Imagine being excited to share the library you worked on and then accidentally breaking the package manager 😭😂😭
Right, so that's why I asked for the output. It tells you exactly what happened: attempt to multiply with overflow at line 5.
What's the difference between the try! macro and the question mark operator?
Actually, I realize that maybe baking interval arithmetic into the language would be a "one size fits most" solution. My main concern would be the extra verbosity this causes -- programmers may decide not to use it because it's noisy. Maybe I should write an interval arithmetic library for Rust to see how it turns out.
I'm surprised it took this long to find this bug since all of the reserved filenames on Windows are very short and many would make decent package names.
I tried, but failed. Here's what I did: 1. Fork Servo and download it 2. Look at src/servo/main.rs, clone it to your repository 3. Throw out the code related to post-crash handling, it causes problems 4. Fiddle with the Cargo.toml until it fits. You should now be able to build your own browser from an outside project. In theory you can send all javascript events directly from Rust, without actual JS. In practice, it is not at all recommended, embedded Servo is not a priority as far as I can see. If you just want the rendering, no, don't do it, it's overkill. Take conrod or piston2d-graphics, which is what I did.
On the positive side, at least it's getting some free advertisement :)
I couldn't help myself. "Jabberwocky" is one of my favorite poems! I felt compelled to make a quick audio recording. https://soundcloud.com/altece/coderwocky
LOL! I am new to rust, did a fresh install and tried to install my first package with cargo and got this error. Spent the last hour thinking it was some configuration issue. Oh well.
Yea package names can be any valid ident, and you can substitute hyphens for underscores.
Same here. Uninstalled Rust completely and re-installed. Even went so far as to uninstall GIT for reasons I can't fathom. Wish I could get the last couple hours of my life back. 
Author here, don't feel bad for me, this is exciting :D Oh also sorry for breaking cargo on windows...
I may have misread and maybe Xen is only supported in the old backend without Solo5. They were using Xen specific features for memory management and security and I don't know if that is missing from the Solo5 backends. Haven't read the paper yet.
I got it to work using bash on Linux subsystem for w10.
Isn't their fault though.
Well, in your defense, what engineer decides... "I don't like files that are called `nul`"? That's plain stupid.
Well that is just great :P.
I was just pleased that such a short and concise name was available!
I'm surprised NUL broke it before AUX or CON.
We are also interested in using Servo instead of Electron for a OpenGL-heavy fullscreen web app (running on big screens in stores on something like the ODROID).
Here's Raymond Chen's explanation: https://blogs.msdn.microsoft.com/oldnewthing/20031022-00/?p=42073 
Precisely so. Also, `CON` (approximately `/dev/stdout`) and `PRN` (approximately `/dev/lp0`) (*edit:* and [a bunch of others](https://msdn.microsoft.com/en-us/library/windows/desktop/aa365247%28v=vs.85%29.aspx#naming_conventions)) suffer from the same problem. It's one of Microsoft's more surrealistic demonstrations of why backwards compatibility is not always a good thing.
Welp, seems someone beat you too it AND broke cargo on Windows for a little while. https://www.reddit.com/r/rust/comments/68hemz/i_think_a_crate_called_nul_is_causing_errors_for/?ref=share&amp;ref_source=link
Hey, funny story, I also contributed to btree ranges this release. I fixed a segfault that was happening. I also wrote the panic documentation for it in the docs, so I know my change definitely made it in, but I also wasn't included in the thanks. I noticed that I'm not on https://thanks.rust-lang.org/rust/1.17.0 But I *am* listed on https://thanks.rust-lang.org/rust/master . So my name isn't lost, but it didn't make it to 1.17.0. Maybe you're in the same boat? I heard you can open up an issue on the thanks project, but I haven't done it yet and I'm not sure if I care that much.
Note that soon the compiler is going to start randomizing the field layout of structs that are not `#[repr(C)]` to discourage unsafe memory tricks that might interfere with optimizations ([#38550](https://github.com/rust-lang/rust/issues/38550)). If you're not depending on the offset value between compilation runs (e.g. storing it in a constant) then you *should* be fine. Otherwise, it's just ordinary pointer arithmetic. You coerce/cast a reference to your struct and a reference to its member to pointers (`*const T`) and then cast them to `usize` and subtract: struct Foo { bar: u16, baz: u64, } fn ptr_diff&lt;T, U&gt;(left: &amp;T, right: &amp;U) { let left = left as *const T as usize; let right = right as *const U as usize; // Always get a positive difference if left &lt; right { right - left } else { left - right } } fn main() { let foo = Foo { bar: 0, baz: 0 }; println!("Offset of `Foo::baz`: {}", ptr_diff(&amp;foo, &amp;foo.baz)); } This prints Offset of `Foo::baz`: 8 The licensing of the Rust and Cargo logos is described [here](https://www.rust-lang.org/en-US/legal.html#art). &gt; The Rust and Cargo logos (bitmap and vector) are owned by Mozilla and distributed under the terms of the Creative Commons Attribution license (CC-BY). This is the most permissive Creative Commons license, and allows reuse and modifications for any purpose. The restrictions are that distributors must “give appropriate credit, provide a link to the license, and indicate if changes were made”. Note that use of these logos, and the Rust and Cargo names, is also governed by trademark; our trademark policy is described below. The trademark section is a bit long-winded but fortunately includes a TL;DR: &gt; Most non-commercial uses of the Rust/Cargo names and logos are allowed and do not require permission; most commercial uses require permission. In either case, the most important rule is that uses of the trademarks cannot appear official or imply any endorsement by the Rust project. IANAL, but you're probably fine to modify the logo for a FOSS Cargo subcommand. If you have any questions you can reach out to trademark@rust-lang.org. Addendum: there is a section which mentions trademark modifications for free related projects: &gt; Using the Rust trademarks in the names of non-commercial products like RustPostgres or Rustymine, or in the name of code repositories in e.g. GitHub, is allowed when referring to use with or suitability for the Rust programming language. Such uses may also include the Rust logo, even in modified form. For commercial products (including crowdfunded or sponsored ones), please check in at trademark@rust-lang.org to ensure your use does not appear official. It doesn't explicitly mention the *Cargo* logo; it's easy to assume that that's implied, but you can't really be sure. 
Thank you. :)
Also even on modern Windows there aren't really "device files", the whole redirection idea is borrowed from the Unix "everything is a file" mentality, but instead of actual files in the filesystem DOS/Windows implements them as some kind of weird shell builtin that behaves as a file rather than a command.
I've gone ahead and opened an issue to address this: https://github.com/rust-lang/rust/issues/41663
They should have been much quicker creating better designed alternatives. If they removed NUK, yeah in 2017, I'm sure thousands of programs would misbehave, because it is still the one and only way to discard a program's output.
Because you're passing `node: &amp;Node` to your function, which means an immutable borrow.
The spirit of the language is to recognize that correct code can be written with raw pointers but the goal is to prevent common classes of mistakes. In that spirit, a "safer float" might do things such as not providing default vanilla behaviours for the comparison operators knowing that it's relatively rare that they will do the right thing and instead would offer several comparison options, each of which having different characteristics, that the programmer could select from explicitly. In my mind, it's analogous to Rust providing Box, Rc and Cell, in recognition that correct use of heap pointers is a common problem.
thanks for the help 
There's a fully implemented embedding crate in servo now (with a C-accessible API), but the rendering part was broken during WR merge last year. See [here](https://github.com/servo/webrender/issues/933) for the ticket.
I think the NT kernel implements an object manager through which all IO operations go. Each object type has a parse method which redirects file operations to different kernel subsystems. It's the equivalent of the Unix single root filesystem hierarchy.
The did so when they introduced UAC in Vista, because almost every program out there assumed to be running on an account with admin privileges in the XP era. People complained because you either got yet another "annoying™" UAC pop up or you had to reopen the application with admin privileges. Heck, even when searching for "uac" in Google, the very first result I get is a guide on how to turn off UAC, followed by the Wikipedia article.
I upgraded to 0.3.14 and am still getting the "No build task defined." message when I press CTRL+SHIFT+B. Edit: VSC version: 1.11.2
"They only said to be cool about langs; clearly the letter of the law and not the spirit is the acceptable standards for tools!"
I think at this point the most efficient solution is just to use a Vec&lt;&gt; w/ `collection.concat()` (built in slice method to turn `Vec&lt;T&gt; where T: Borrow&lt;str&gt;` into String).
r/playrust 
Is Python really that bad? I just took a quick glance and it seems to have nice `async` `await` syntax [https://hackernoon.com/asynchronous-python-45df84b82434](https://hackernoon.com/asynchronous-python-45df84b82434) Recently I wrote a [file watching server](https://github.com/bschwind/file-watcher/blob/master/src/main.rs) with futures and tokio which broadcasts file path names to all connected clients when a file changes. It was fun to write, but I definitely wouldn't call it ergonomic, especially when you need [lines like this](https://github.com/bschwind/file-watcher/blob/master/src/main.rs#L110) when using adapters like `select` on multiple future streams. And the compiler errors were pretty bad, as the OP mentions. I still think something like Tokio is worth it though for lower level servers that don't require a ton of business logic.
Yep! The source for the show, including the script for every (non-interview) episode is on GitHub. [Here's the script for this show.](https://github.com/chriskrycho/newrustacean.com/blob/master/docs/cysk-3.md) Over the summer, I'm going to make that more accessible.
Looks like you've gotten into the wrong subreddit! This is r/rust, the community for the Rust programming language. It's likely that you meant to post this to /r/playrust, the community for the Rust game.
You may be in the wrong subbredit. Looking for /r/playrust ?
Having multiple roots or a single root is really a pretty random design choice. (Meaning, it could legitimately go either way.) I'm not surprised that the basic holistic implemention is the same.
That's really cool. Could make a good security blog post.
Why does one need to write JS to appreciate an alleviation of redundancy?
_Default_ keybindings were removed, but the commands are still there so you can still make custom keybindings. I added the following to my keybindings.json and it works as expected: { "key": "ctrl+shift+b", "command": "rust.cargo.build.default", "when": "editorLangId == 'rust'" }
Nice! I just listened to it while waiting for my flight back home from RustFest.
I'm just getting back from RustFest, and it was absolutely great to meet all that nice rustaceans. Now I'll be flying back home. There will be TWiR stuff, probably some clippy stuff, also a small improvement to an old forgotten crate someone made, more `CONTRIBUTING.md`s for all of my crates and keeping a look out for easy bugs. 
I haven't updated rust_on_msp to the latest nightly yet, and it also full of unsafe and other ugliness. I am working on a svd file generator to replace it all with svd2rust goodness. You can find us on #rust-embedded IRC if you have any questions.
Also https://github.com/robertramey/safe_numerics which was provisionally accepted into Boost last month.
As a Windows user, I am not entirely opposed to being mercy killed... 
no, this is even theoretically impossible to do correctly, as as soon as you spot an error everything after it is just mush. lets for example say you forgot to add a closing " (or } or ] for that matter). this means that all following text is now assumed to be part of that string, until eof is hit. this kind of works with xml, because xml syntax is extremly redundant.
I'm mostly going to work on Gutenberg: just got sorting done and will be doing...pagination ^I ^know ^I ^know ^^for ^^real ^^this ^^time Once this is done and working, I'll probably start making a site for Tera and Gutenberg to test Gutenberg on something more complex than my blog.
You are right, as soon as syntactical errors are involved, it's impossible. I was refering to semantical errors, sorry for not being clear enough. E.g. if we take the json to struct deserilization example from the json serde website and change the json structure from `let data = r#"{ "name": "John Doe", "age": 43, "phones": [ "+44 1234567", "+44 2345678" ] }"#;` to `let data = r#"{ "name": 43, "age": "John Doe" }"#;` then serde reports one error and says "invalid type: integer `43`, expected a string at line...". However, there are three errors (name with wrong type, age with wrong type, phones array missing). 
Don't worry, I won't stab you. I don't have a pitchfork. Seriously, though, I don't think we have any reason to complain to the crate author. We could _possibly_ criticise Windows, for having this odd limitation, or the Rust crate system, for not working around it despite promising to work in Windows, but the crate author hasn't done anything wrong, has he?
Ah, reminds me of the fun it was when someone on a bulletin board posted a picture whose URL was file://c:/con/con…
Wait. Fixed it by removing the crate?
Yes.
&gt;/u/carols10cents has been persuaded to take a moment out of her relaxing weekend to work this out That's really nice of her. Thank you Carol.
Eventually, there should be some kind of workaround for Windows, right? (I don't know, maybe using that newer file system API would work.) We can't really go around excluding a bunch of crate names from every operating system just because they are reserved in the Windows file system, can we?
&gt; Why on Earth is knowing your glibc version important. It's usually not. But knowing that libc is not always glibc might be!
Further up in the post, someone said it's only about 4 files on Windows that are reserved. Seems easier to ban those 4 file names than have to change cargo's behavior.
It's still a work in progress, although you can see the results. Any graphics wizes out there that would like to lend a hand or advice would be greatly appreciated, especially for the issues stated.
What are those other reasons?
I don't doubt that it's easier.
Mainly identifiers that are reserved by the language as keywords or similar. For example if you had a crate named `trait` there would be no way to import/use it in any way. 
Regarding triangle clipping: one of the solutions is to use a clipbuffer - you can create a new vertex buffer with clipped triangles, which may contain *more* triangles after clipping. Alternatively, you could create a clipping iterator which returns more triangles than in the source, if needed. The triangle clipping algorithm works something like this: http://i.imgur.com/NjPuhXl.png Although, there are probably some corner cases I'm not currently aware of.
svg/pdf have layers?
&gt; Everywhere I go "Unix" is the norm. That seems rather unsurprising given that Unix basically _is_ the norm... 
[removed]
Err..what? Don't get me wrong, I run Linux on my laptop and duel boot on my desktop. I've had a MacBook pro before. I like unix/posix, but to say they are the norm is....wrong. Windows desktop market share is over 80 percent[0]. Maybe MacBooks are the norm for people who browse hacker news, but we shouldn't alienate people on false assumptions. (Take it with a grain of salt) [0] https://www.netmarketshare.com/operating-system-market-share.aspx?qprid=10&amp;qpcustomd=0
This sounds like basic matrix transformation bugs. Isolate a single vertex that is getting transformed to the wrong place and follow it from creation to see where it is wrong. 
The problem here is that you then end up shading parts of the triangle that aren't going to make it on screen, and shading is the most expensive part. 
True, but for the time being it's also my problem : / gtk-rs looks pretty promising, though, since I don't actually need hardware accelerated graphics in my case. 
Oh sweet! This looks very promising. It seems to be mostly processor based graphics which means it should be very compatible. 
What is the nature of the fix, out of curiosity? Searching on crates.io shows the create "nul" still exists. (Though I can't find it in the crate index git project.)
Are you planning to add your `softrender` as a backend to `gfx`?
I made good progress on [multiple cursors](https://github.com/google/xi-editor/issues/188) in xi-editor and hope to complete it this week. The main work is multi-insert and delete, and also making the operational transform on cursors work correctly even in the face of complex (non-contiguous) edits. I'll probably get [xi-win](https://github.com/google/xi-win) to the point where it can do basic editing. This will eventually grow into the Windows front-end, but in the meantime I'm going to use it as a testbed for perfecting low latency and smooth scrolling. I did a soft launch of [synthesizer.io](http://synthesizer.io), a music synthesizer with some pretty cool technology. It's probably on the back burner for now though.
When running `cargo test`: error[E0432]: unresolved import `softrender::image_compat::ImageFrameBuffer` --&gt; examples/suzanne.rs:19:5 | 19 | use softrender::image_compat::ImageFrameBuffer; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Could not find `image_compat` in `softrender` error: no method named `copy_to_image` found for type `&amp;softrender::render::FrameBuffer&lt;softrender::pixel::RGBAf32Pixel&gt;` in the current scope --&gt; examples/suzanne.rs:190:40 | 190 | let image = pipeline.framebuffer().copy_to_image().unwrap(); | ^^^^^^^^^^^^^ error: aborting due to previous error error: Could not compile `softrender`. :-(
Would this work for generating projects for other languages than Rust? Can you vary the use of tags to prevent conflicts with other templating languages?
I don't see anywhere you're doing clipping, so it's no surprise that the vertices which cross the screen boundary look "wrong". You need to clip the transformed vertices against the 7 planes of the clip-space frustum. 1. w &gt; 0 2. x = w 3. x = -w 3. y = w 4. y = -w 5. z = w 6. z = -w Clipping is slightly tricky - clipping can both add and remove vertices - but something is inside if `V dot P &gt; 0`. Clipping line AB against plane P to produce vertex C is: `scale = -(A dot P) / ((B dot P) - (A dot P)` `C = lerp(A, B, scale)` Watch out for that w &gt; 0 plane - you need to clip things to be an epsilon inside of it else you'll end up with NaN vertices running around
Is this the biggest rust conference? 
You can use: grid.insert(column, row, &amp;item); [example](https://github.com/redox-os/orbtk/blob/master/examples/widgets.rs) from line 143. Edit: It is grid.insert(column, row, &amp;item), not grid.insert(row, column, &amp;item). Sorry.
**G**nu is **N**ot **U**nix. **nix* would be more accurate.
That... sounds possible, but I don't know enough about low-level computer operations to say one way or the other.
But it has no documentation, how I'm I supposed to understand what the dozens of characters are for?
You can, but I think the catch with `const` is that you'll potentially get a difference reference each time, just as if you'd directly written `&amp;1` or something. [Static](http://play.integer32.com/?gist=47fa4678bbd1f0f668ef623ddaa672d9&amp;version=undefined) vs [const](http://play.integer32.com/?gist=311970b3bd541985f309395c14826dc5&amp;version=undefined).
How should arrange lifetimes in a function which takes two refs and returns one of them. So, which lifetime should I use in this function: https://is.gd/65u0eE fn smallest&lt;'a,'b&gt;(p: &amp;'a i8, q: &amp;'b i8) -&gt; &amp;i8 { if *p &gt; *q { return p; } return q; } I understand that this can theoretically cause issues (such as if the smaller num has a smaller lifetime than the larger), so is there a way to annotate that the return lifetime is the _shorter_ of the two? **EDIT** Oops, I did a larger instead of smaller. Same idea, though
I LOVE this crab logo! It looks so professional and would be good as the official Rust logo 😀
PDF can have layers, they call it "optional content groups" (OCG). It is what Adobe Illustrator uses for their "layers".
I'm working on a [replacement](https://github.com/gilnaa/rusty3bar) to i3-status. Not sure if anything good will come out of it but it's a good learning project.
&gt; We hope to make things easier in the future. Is there a TODO list of things that need to change before running on `stable`? Or is this one of those things that will likely never happen because of compiler intrinsics?
This has recently been improved in Cargo: http://doc.crates.io/manifest.html#the-required-features-field-optional 
Thanks! I'll sign up for the newsletter.
No need to denigrate Windows users. We care a great deal about the Rust experience on Windows, as evidenced by the fact that we escalated this problem immediately rather than waiting for the usual team to come in on a weekday to fix it.
&gt; But most people don't develop on a server. They develop on their PC Citation needed. My intuition is that the vast majority of developers are developing for either web frontend (not Posix, but not really "PC" either), iOS (Posix), Android (Posix), or Linux (Posix) servers.
Why does struct fields need a lifetime: struct q { a: &amp;i8, } In all the examples I've seen (not a lot of them, truthfully), all lifetimes are bound by the structs lifetime. Is there ever a time one _wouldn't_ do something like struct q&lt;'a&gt; { a: &amp;'a i8, } 
No they don't. At least not any of the ones I know. 100% of developers I know are either working on a macOS device, on a Linux device, or SSHed into a remote linux server. I don't know any developers who use Windows and I have never used Windows at work in four years as a professional developer working on a variety of different products. But everyone's experience is different and I'm not claiming to speak for everyone, which is why I said "citation needed", not "you're wrong"...
I don't think the authors of minihttp would describe it as a "complete &amp; sane library" It's understandable why someone would complain about the performance of Rust with regard to HTTP.
Could be beneficial to have more Rust people directly involved in LLVM. What I want from LLVM is to improve their test coverage for lesser platforms, since pretty much every platform LLVM supports Rust supports, and some are quite poorly supported upstream (like mingw...). This position seems like it could have an angle there.
I don't think we necessarily disagree. By PC I meant computer(of any os). Also you help prove me point in some ways. Like to said a lot of rust developers use only Unix(but I'm pretty sure you weren't just talking about rust devs). The overwhelming majority of PCs right now are (unfortunately) windows. Software is being developed for them. Those developers are not cross compiling from linux(I mean technically, its possible but in reality). They have to run windows. Just because you and I run a posix compatible OS doesn't mean every Dev is(I know you weren't saying that but still) On a similar vein, I am willing to bet 99 percent of game developers doing it for money are windows based. Im willing to bet that every AAA is made on windows. Also what industry are you in which I lot of people are coding through ssh haha. I've done it but only because there was basically no other option. Sucks for them :( unless try enjoy vim &gt;:D. FYI I'm on mobile and at the gym now so might not be super thought out, but I *think* my general point gets across :) 
PS I wasn't talking about where they are deploying, but whether or not that develop on a PC(not as an Mac vs PC, just a normal desktop/laptop)
Open source - https://github.com/kryptco. They've got a fork of *ring* exposing some additional APIs that they need, and a library for serde support of SSH protocols (ssh-wire) that uses those new APIs. They they have Go, Swift, and Android repositories that make use of ssh-wire.
Can we see the code that you have thus far?
&gt; custom lint Is that something that could be added to `clippy`? Anyway, glad to hear that it's not too far off! I think Servo landing on stable could have a huge impact on projects using it as a library. I know that *I* am definitely interested in using it. :)
Yeah I'll put it up when I get home.
Thanks, I think it's opt-level that skips the check
Note that the above is not really "systematic", at least not in the way that I'd use it. It's *automated*, but for *systematic* you need something more. The gold standard is a formal specification of the language and a way to verify that the compiler implements such a specification. [This paper](http://people.cse.iitd.ernet.in/~sbansal/csl862-soft/readings/compcert.pdf) gives a good example of one such effort. Other efforts involve code coverage metrics, documentation requirements, and traceability controls, such as those specified in DO-178B or ISO 26262. This stuff is complicated and hard and expensive, so a free open-source project can be forgiven for testing in a somewhat ad-hoc way (and I'm sure there's more rigor behind the scenes that I'm not aware of). That said, there is an ongoing effort to make LLVM more usable in safety-critical systems, and [an interesting talk](http://llvm.org/devmtg/2017-03//2017/02/20/accepted-sessions.html#18) was given at EuroLLVM last month. All that info might have been overkill.. whoops, oh well.
&gt; So name : &amp;str is just pointing to a place in memory that holds the string? and not representative of the string itself? and that memory location can be passed around to other : &amp;str? Right! The upcoming [second edition of the Rust book](http://rust-lang.github.io/book/second-edition/ch04-01-what-is-ownership.html) has a more detailed explanation of `String` and `&amp;str`, which might be helpful.
Thank you for the reply and explaining this. The softdevice is definitely a pain in the ass but works quite well, has a lot of features, and keeps improving.
Thank you so very much. Your few lines of explanation did much more than any google searching I have done, and even though it doesn't relate to my original question, the difference between "String" and "&amp;str" is a bit more clear now. :D
These lints make no sense in anything that's not trying to embed MozJS.
I think at present you simply would not be able to clone the repo and therefore use the library on windows unless you can convince git, rustc, and cargo to use the new `\?\\` namespaced paths. As seen here, I don't think that any of those programs currently do this.
I'm continuing work on my [gzip implementation in Rust](http://github.com/ricbit/rgzip). It can already decode almost all gzip files, I'm working now on making it faster. Currently it's about 3x slower than gnu gzip, but I'm trying to reduce this gap.
Is there a good explanation of lifetimes? While I understand the basic idea, it just seems to be book-keeping which the compiler should be perfectly capable of doing (and it *does* do it, refusing to compile when you make a lifetime error). Are there any clear examples where a "naive" (like the current) compiler would give a reference a different lifetime than the programmer manually?
So one can use the ? instead of a try! ? 
Which part in the readme did you see python is faster? As I read the chart, pi is (Project-init)?
something something backwards compatibility, most likely.
I think things get ambiguous as soon as more than one lifetime is involved. A struct with one reference certainly doesn't have any options, but as soon as you have two references you get "same lifetime", "no relationship", and two directions of "outlives" as possibilities. One thing you might be thinking of is having the compiler infer the answer by looking at how structs are used. Languages like Haskell do that sort of thing a lot. But Rust had almost always avoided it, for anything larger than the scope of a single function. The biggest downside is that functions start leaking lots of implementation details, and it's harder to keep track of what guarantees your library has made for its callers.
We also ban names that are used by certain rust project crates, like `std` or `proc_macro` and some similar unstable crates.
Ok. I think I got it. https://is.gd/TQZ3PJ This should work: fn main() { println!("{}", "ag"); let i = 8; let t: &amp;i8; { let j = 8; let mut p: a; p = a { q: &amp;i, v: &amp;j }; t = p.q; } } struct a&lt;'a&gt; { q: &amp;'a i8, v: &amp;'a i8, } But doesn't because of lifetime 'a, a.v lives only within the block. struct a&lt;'a,'b&gt; { q: &amp;'a i8, v: &amp;'b i8, } Would work.
We can and we have to. Package managers like cargo store the name of every crate in the package repository on their local machine. This is what's called the index, which you'll frequently see get updated when you add a new dependency. The way cargo stores the index is as a git repository which contains a file for every crate (the specific format was chosen for efficiency reasons, based on past experience with other package managers like bundler.) We can't change how git works on windows, because we don't control git, so we can't use these `\\?\` style paths. We can't change the index format, or current versions of cargo will all stop working. The only viable option is to ban these names. Banning these names is a trivial cost. There are 22 names, only 3 of which seem like good crate names to me (`nul`, `con`, and `aux`). There is an enormous number of other valid names users can choose from; its far more important for cargo to continue working on all platforms.
I am not that familiar with compiler, so I can't identify the reason for such memory consumption. Maybe try to split it into several files or use simpler structures like plain arrays? Vectors can not be stored in the .data segment of the binary, so if I am not mistaken, you code will copy data from static constants to the heap, in that case it's better to do conversion from arrays to your struct by some function and reduce compiler work. Also you could create an issue in Rust repo, maybe you found an inefficiency in internals of the compiler.
a few day ago someone recommended [sciter!](https://github.com/sciter-sdk/rust-sciter),it seem very impressed and ideal：under 4-8 mb size, it can implement modern GUI with HTML/CSS.Maybe servo could learn something from it.
Good thing it has easy FFI!
We are close to Windows Linux subsystem support (hopefully next 1 or 2 days), have you played with it at all?
Looking forward!
Small caveat: For embedded applications you'll better check if your target platform has LLVM support. Otherwise you won't be able to compile Rust to it.
I think Rust is better for those things, since it's really good at abstraction and C is awful at it
Another use case is reference testing graphics algorithms. Testing with GL is a pain because when it is available (typically not on that server you are running your tests on), each permutation of hardware and driver combo tends to give slightly different results because quantities get rounded differently in the shaders (or simply just because of buggy drivers). Your crate (certainly better than the [crappy rasterizer](https://github.com/nical/lyon/blob/master/extra/src/triangle_rasterizer.rs) I came up with) looks like it could help me improve the test suite for the [path tessellation](https://github.com/nical/lyon) stuff I am working on.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Crate named NUL broke Rust's package manager](https://np.reddit.com/r/programming/comments/68rn42/crate_named_nul_broke_rusts_package_manager/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Such a type cannot possibly exist, because a zero-sized type contains no information, so how would it know what it owns? Just use a second vector, or `Box::into_raw` / `Box::from_raw`.
Why not? Ownership is statically tracked. The compiler statically knows that `other_v` transitively via the ZST owns `v` and will insert the instructions to drop `v` when `other_v` goes out of scope. Or does it need a point to the datatype itself for those intructions to work at runtime? Box::from_raw when being passed a raw pointer from `slice::as_ptr` does not assume ownership of the vector as far as I know and the box wil just be pointing towards undefined memory.
&gt; Ownership is statically tracked. For values *on the stack*, yes. Not on the heap. &gt; The compiler statically knows that other_v transitively via the ZST owns v and will insert the instructions to drop v when other_v goes out of scope. That's just not how it works. The compiler has nothing to do with a `Vec`'s memory being deallocated; that's down to `Vec` passing the pointer it contains to the allocator when it's `Drop` implementation is called. If it doesn't have that pointer, it has no way of telling the allocator what to deallocate. All the compiler is responsible for is knowing which stack variables need to have `Drop::drop` called on them, *not* what that code is going to do. And `Box::from_raw` *does* assume ownership, because that's the reason it exists. You can't pass it a random pointer from anywhere at random, but if you created the pointer in the first place from `Box::into_raw`, then it's fine; you're just round-tripping ownership through an unsafe pointer.
Unsafe Rust is still Rust, and shouldn't be excluded as such. You still get all the benefits that Rust has over C, such as good support for abstraction (for example using generic programming), ownership/borrowing semantics (as long as you handle your raw pointers correctly). Rust has a big overarching theme of safety by default, but opt-in unsafety if you need it, and that second part should not be disregarded. For example, the `format!`, `print!` and `println!` macros only accept a statically defined string as their format string, which prevents certain kinds of injection attacks that C's `printf` can potentially be vulnerable to, for example. `printf` could very well be defined and used in safe Rust just like it is in C, but the commonly used macros are just a little bit safer.
We don't have a date for it yet, as we are just winding down with the Kyiv edition. We make sure to announce it soon in the usual channels though (here on reddit, on twitter, on the site, etc)
&gt; Such a type cannot possibly exist, because a zero-sized type contains no information, so how would it know what it owns? Can't you track ownership through phantom types?
I hope it will be continued, as I use it and I rely on it already.
\**puts on wellingtons, jumps into weeds*\* Alright, it could own another ZST, but that's not very useful. It's like saying an imaginary friend can own things, they just have to *also* be imaginary. A ZST could also own *one* thing, but that would have to either be shared access or you'd have to somehow prevent more than one ZST existing at once. Beyond that, you could have a type that owns something *not* described in its type (kinda like `Box&lt;Any&gt;` *sort of* does), but that'd be going into unsafe territory, at which point all bets are off anyway. Oh great, now my foot's stuck in the weeds, and I can hear grass snakes.
Basic software floating point operations take 10x the time of hardware floating point in latency and 30x in thoroughput. In contrast, an easily-predicted branch will normally cost somewhere between nothing and very little. You don't even hurt autovectorization much, since Rust's floats are already rarely successfully vectorized.
Why don't I have to dereference a reference for the `println!()` macro to work? Is there some additional magic going on? let i = &amp;1; println!("{}", *i); // works of course. println!("{}", i); // but why does this? 
Thank you, Pierre! It's good to see this out in the open and I'm sure everyone will benefit from it, hopefully in both directions. It also shows that bringing the community together from time to time brings good results. :)
What if every type corresponds to a single value? for example, something like `ZeroBox&lt;I&gt;` which is backed by a `Box&lt;T&gt;` (of some fixed type `T`) stored in a thread-local `Vec` indexed by an offset associated to `I`. So if the indices comes from [typenum](https://github.com/paholg/typenum), you could write `ZeroBox&lt;U0&gt;` for the value stored at position 0, etc. One could also have `ZeroBox&lt;T, I&gt;` for storing values of type `T` with index `I` (and you would have a `Vec` for each `T`)
I noted that elsewhere, but all that really boils down to is having a global variable per type. That's also of no use in this particular case.
Maybe an ignored prefix, so the actual path becomes "DAMMIT-DOS-nul", invisible to the user? Other than that, the restriction either has to disappear (Win10 has added an option to lift path length restrictions, so who knows?), or the file can never exist.
Well, one could write generic code that works on all `ZeroBox`es (similar how each closure has its own type, and you need to write generic code to handle any closure of a given signature).
I remember 20 years ago someone showed me how to use DOS's `debug.com` to rename the reserved device name `AUX` to `BUX` somehow, then creating `C:\AUX` and renaming `BUX` back to `AUX`, creating a secret inaccessible directory.
One issue with that proposal is that `NaN` is not a single value, but [a whole family of them](https://en.wikipedia.org/wiki/NaN). So we would need more than just `Option` to represent them properly.
Clearly there is a miss understanding...IM NOT CLAIMING PEOPLE ONLY TARGET WINDOWS. You and the other poster somehow assumed I said that. By Windows based I mean they develop on windows
It is not good for gaming, just that there isn't any choice in the matter
Yeah, I've used it, but most of my ssh sessions are run from native Windows tools. Would those be able to communicate with the kr ssh agent running in WSL?
Str constants in code like `"foo"` actually in full have type `&amp;'static str`. The `&amp;'static` is important, this means it's a reference that points to a memory location that is guaranteed to exist for the entire duration of the program. Like in C static string constants in rust are baked into the binary itself when you compile You can run `strings` on a Unix system on it to indeed see that they are baked into the binary. They aren't allocated or deallocated at any point. What a "str slice" is is basically a place in memory of octets that are guaranteed to be valid UTF-8. If they are not someone has made an error some-where. This is a slice. A slice is a type of data that is dynamically sized as it's called. The type has no constantly known size at compile time. Any pointer type to such a type like a reference, raw pointer or Box is thus a fat pointer as it's called. It does not just store the memory location but must also store the size. A pointer to a sized type which has a constant size in memory is a flat pointer that only need store the location as the size is known. https://is.gd/EJNfCV You can run that code to see the sizes of the different datatypes on a 64bit machine where a pointer is thus 8 bytes long. - A &amp;'static str is 16 bytes or two pointers long. 8 bytes for the actual address in memory and 8 bytes reserved for the length. - A `String` which is a heap-allocated mutable version is 24 bytes long. Why? Because it's three pointers. One pointer for the location, one for the length and finally another one for the _capacity_. As in how much space it still has to put new data in before it needs to enlage its capacity. Making the string larger beyond its capacity requires that it be realocated which is expensive. - A &amp;string however which is a reference again is a mere 8 bytes long. It's simply a single pointer to those three pointers I spoke of above. - The last one is the actual size of the string data itself. This is a mere 6 bytes because it's a fairly short string. THis is the amount of space the slice takes up. If we make the static string constant longer this size will grow but all the others remain the same. str isn't the only slice. There are many more. A slice is just a region of memory which holds a sequence of identically typed elements. In this case str is a special case of what is commonly written [u8], a slice of unsigned bytes. str adds the constraint that the total slice must be valid UTF-8. Because slices have no known size at compile time you cannot directly pass them around as function stack frames are compiled to have a specific well-known size. The only way to do that is behind a pointer, which is what `&amp;str` is. You cannot pass `str` or `[String]` or any unsized type to a function. Furthermore you can't have `[[u8]]`, only `[&amp;[u8]]` as the elements of a slice itself must be sized again.
[removed]
You need to use Serde 0.9.x with Rocket 0.2.x. The Serde version mismatch is the cause of your errors :) Cargo.toml of the todo example on the 0.2.x branch for reference: https://github.com/SergioBenitez/Rocket/blob/v0.2/examples/todo/Cargo.toml
Best guess: `rocket_contrib` depends on `serde` 0.9 whereas your `Cargo.toml` pulls in 1.0. This results in two versions of `serde` being included in your project, each defining their own strictly separate versions of the `Serialize` trait. `Template::render()` wants something that implements 0.9’s version of `Serialize` while `Context` probably implements `Serialize` from 1.0. Does changing your dependency to `serde = "0.9"` will fix the errors?
Yes! Changing the dependency to 0.9 solved the issue. Thank you!
&gt; The answer is simple, Every major web server has implemented it :D A better reason might be that with CGI, your app is not holding onto any resources when idle. Which is awesome if you want to host a hundred services that are used only a couple times a day, on a single VPS. CGI is the original "serverless" "function-as-a-service" "lambda" cloud! However, you can both release all resources when idle *and* avoid the penalty of loading your app from scratch on every request if you use [my little thing](https://github.com/myfreeweb/soad) that's based on socket activation and *de*activation :)
Hi, I'm a little late but is there a way to disable the rendering on Gecko so you'll only see the items rendered by Webrender? It should be fun to see everything Webrender can do already in Firefox.
Were you the second kid by any chance?
If you set `git config core.longpaths true`, Git will work with these files (and files with paths longer than 260 characters).
Git uses those if you set `git config core.longpaths true`.
Well, they're both Turing complete languages, and Turing complete machines are said to be equivalent in what they can express. That's how it works, right?
I'm sure there's something with the parts of your program that aren't included here, but given this comment in your desired code: // v is now moved into outer_v Which makes me think you *want* `outer_v` to own `v`, why not just have `outer_v` own `v` directly, rather than owning a pointer to `v`? That is, let mut outer_v = Vec::new(); for ... { let v = vec![1, 2, 3]; outer_v.push(v); } ?
Thanks a lot, that was a cool way to do it. Works perfectly :) For future reference, the end business logic now looks like: let data = fs::File::open(tarname)?; let progdata = ProgressReader::new(data)?; let decompressed = GzDecoder::new(progdata)?; let mut archive = Archive::new(decompressed); 
Coincidentally, there are only two illegal unix filenames: &lt;NUL&gt; and '/'. Any other of the 254 bytes is legal.
Yeah, but GN* would be hard to pronounce. 
Yeah, they [reserved the whole list](https://github.com/rust-lang/crates.io/pull/695/commits/35cea412a28106e045c5c6a59c323ca515c9be72).
The first. Stupid off-by-one errors... Well, actually my mom's uncle didn't like his birth name (Dolf) due to its similarity to the first name of some failed painter that decided killing jews was a good idee... He was into sports and liked the phrase Door Oefening Sterk (translated word for word from dutch into english you get By Practice Strong) and started asking people to call him Dos. My parents liked the name.
&gt; We can't really go around excluding a bunch of crate names from every operating system just because they are reserved in the Windows file system Why not?
Since I've released [stdweb](https://github.com/koute/stdweb) I've switched gears to work on an actual React-like Web framework which would make use of it. Currently in the process of writing a procedural macro which will parse [jsx](https://facebook.github.io/react/docs/jsx-in-depth.html) and emit Rust code from it; once I finish that I'll probably start on a DOM diffing algorithm.
[removed]
How so? Doing anything tricky with memory is a pain in Rust and can be very nicely expressed in C. There are a lot of things Rust is better at, but "unsafe" memory manipulation is not one of them. Honestly, if I needed to do that type of work in Rust, I'd just link in some C code that did the memory magic. Rust is nicer to use than C for a lot of things, but very low-level programming is not one of them. If ASM is a significant part of your project, working with C is the least annoying (though all that can be wrapped by Rust to provide a nice, safe interface for higher-level code).
Could you compile to some format that GCC supports and essentially compile twice? It sounds awful, but it may be a way to port an existing Rust codebase to a new platform before it has official support.
NTFS is POSIX compliant in that regard. This is a result of the Win32 subsystem being backwards compatible with DOS.
&gt; what are the performance characteristics of iterators like? Very good. The assembly code generated by LLVM for iterator-heavy code almost always matches (and sometimes even outperforms) the code generated for C-style loops. Also, remember that in Rust, `for` loops are actually just syntax sugar for iterators. &gt; Iterator implementation that knows how to wrap around the end Have you looked at iterator adapters? You can take an iterator that stops at the end of your sequence and pass it to the `cycle()` adapter from the standard library to make it repeat endlessly from the beginning. If you do want to code a low-level solution yourself, you can implement an Iterator that just resets the index to the start of your sequence on overflow.
True. Good point.
I can't load this link, it just spins forever edit: the front page (https://nest.pijul.com/) loads fine (though it seems uBlock is unhappy with some of the graphical elements), but https://nest.pijul.com/pmeunier/ and https://nest.pijul.com/pmeunier/pleingres won't load, even when I disable uBlock.
Well, you can implement a doubly linked list just as easily in Rust as you would in C, you just have to use unsafe and raw pointers. Of course, this only gets you ~the same level of safety as the C version. The hard part in doing data structures and the like in Rust is fitting them into the reference system.
(You can use this to create fake borrows though. Borrows are statically tracked, unlike ownership)
Are you including the effect taking up predictor slots has on the rest of the branches?
I think that's the point. In C, the compiler has no choice but to be paranoid about aliasing. This means the programmer doesn't have to worry about it (except when performance is important.) In Rust, the compiler can assume that aliasing won't happen. The programmer is fine right up until `unsafe` is used and now its up to the programmer to verify correctness in the face of aliasing.
Found it! https://twitter.com/wickerwaka/status/479842553831776257
Xbox One actually just uses the MSVC toolchain so theoretically Rust is ready to go, although you may need to be in #[no_std] if you aren't targeting the UWP framework for your game. Otherwise the full windows kernel is available to you so standard Rust compiled as a cdylib should work!
Nope, there is more that aren't "DO NOT CREATE" type files but more like "THIS SHIT ACTS FUNNY".
At this point, removing NUL would break so many scripts that the world's pitchfork output would be insufficient... It's here to stay forever :(
Hi! I've seen that work, and it seems to be really nice. Some remarks though. First, why so long hashes? They seem much longer than useful in any case. And I'm saying that as someone who isn't annoyed by the length of git hashes. If you dislike SHA-1 (and there is good reason to do so), you could still do SHA-512/160 to get to similar lengths. Second, could you enable github login on nest.pijul.com? I can get you want to build an alternative, but gitlab has it too and it would certainly make it easier for many devs to use your service. I for example have no twitter account and wish to not use any google account I own, nor do I want to create passwords and usernames for yet another service. Third, due to the patch based design, I'm not sure what exactly the hash is hashing. Is it only the patch? Aka, when I reorder two patches, will the two hashes be the same (similar question what happens when I remove one patch, will the first patch have the same hash)? Or does the hash like git also include the order of patches and which patches were applied. One thing I love about git is that everything about history is hashed and knowing the hash all of that is secure and known. I personally have no problems by git having a non patch based design, and believe the issues that seem to outline the advantages of patch based designs to be mostly hypothetical, but I'm always open for new ideas, especially if it can solve other problems git has (partial checkouts of repos: submodules are, sorry to say, a crap to use). I really like the availability of thrussh as well! I hope someday you will be able to run ssh login servers and clients with it. In any case, good luck with your projects!
I'm seeing a common painpoint that rust is difficult or annoying to use at manual memory management and manipulation. Is there any way to fix that or is that not really something rust is targeting?
Thanks for your help. That helps clear up some confusion. I'm still in new territory, I haven't done systems programming or memory management before. I've been looking for a tutorial for rust written from a python perspective to help smooth out the differences in thinking.
My read iterator came together without issue. My attempt at a write iterator, returning `&amp;mut u8` ... has troubles. I imagine the mutable iterator will wind up requiring `Cell`s. Pity Rust's disjoint-mutation analysis is still extremely non-granular. My code cannot mutate the position or capacity of the buffer over which it runs, so a mutable iterator would be altering one cursor and one byte within the buffer, but not performing any potentially invalidating actions. I'll look at `Cell` usage, thanks.
It seems like you went through a lot of effort to try to replicate exceptions in a language without exceptions. What's your opinion on adding exceptions to rust (disregarding the face that it's pretty unlikely that they ever will be added)?
I did? Could you clarify which parts that I did so I can answer your question better? I look at `Result`as monadic error handling that is found inside languages like Haskell. Personally I don't like exceptions because I prefer to handle them with `Result`which I find is pretty explicit, and rather than opting in to error handling like many exception based languages you have to opt out in Rust with things like unwrap or except for instance. 
I'm glad you opened it up! I was hoping to see more of this code after you had talked about it in Kyiv!
Yes, two was enough. Which is why the above path ensued in hilarity.
&gt; First, why so long hashes? They seem much longer than useful in any case. And I'm saying that as someone who isn't annoyed by the length of git hashes. If you dislike SHA-1 (and there is good reason to do so), you could still do SHA-512/160 to get to similar lengths. Pijul is a distributed system. This is different from git, which cannot really be used as a distributed system (more on that below), and is actually used with a central server by most users. As such, we need to verify and sign hashes, and as people who don't do their own crypto, we use standard tools for that. There is an internal patch identifier system though, with super short hashes (64-bit integers, which is optimal because of alignment constraints in our backend). &gt; Second, could you enable github login on nest.pijul.com? I will. There are many things to do on both Pijul and the Nest, and little time to do them. I'm also pretty sure that other users will want other {some-webservice}-login. &gt; Third, due to the patch based design, I'm not sure what exactly the hash is hashing. Is it only the patch? Aka, when I reorder two patches, will the two hashes be the same (similar question what happens when I remove one patch, will the first patch have the same hash)? There is no "reordering of patches" in Pijul. Patches are not manually ordered. There are ordered by a dependencies, which is a partial order relation. A depends on B if A inserts lines in a context introduced by B, or in a file introduced by B. Or, A depends on B if A renames or deletes a file/directory introduced by B. Of course, this does not account for code correctness: you can very well craft patches that cause your code to stop compiling, even though the two branches compile fine. But I guess this is the fate of any text-based VCS used for code. &gt; I personally have no problems by git having a non patch based design First of all, even though pijul can fully simulate all of git (except when git does random shuffling of lines in your files when 3-way merge has several solutions and picks the wrong one), pijul might not be suitable for all cases. We don't have enough experience to tell. &gt; and believe the issues that seem to outline the advantages of patch based designs to be mostly hypothetical Sorry, but this is really plain wrong! There are many ways to explain why, both practical and theoretical. You can find more details at https://nest.pijul.com/help/patches.html - Most problems with commits stem from their lack of understandable, intuitive mathematical properties. Even if you don't care about theory, a saner system is usually easier to use, and in particular easier to script, because it is predictable: you can quickly get an intuition of what it does. This is comparable to the situation in Rust, where you don't have to care about formal semantics and category theory, but still enjoy the speed + correctness + parallelism + explicit, detailed type errors. - Git uses 3-way merge (or derived algorithms), which selects a smallest set of changes that looks consistent with all branches involved. The problem is, the solution is not always unique, which means that if Alice and Bob worked in parallel, added blocks in different (even non-overlapping) parts of a file, Alice's new lines might get inserted into parts of the file she's never seen. This means that in Git, the code you review and test is not the same as the code that will get merged. Even if I hear people repeating "never trust a merge", the situation is actually way worse than what they imagine when saying that: where lines get merged depends on their contents, not on where authors wrote them in the file. I do not know whether this has ever been exploited in a large codebase to trick maintainers into accepting a seemingly benign commit, but it definitely could. - Even if you don't care about correctness In practice (really?), one particular problem is cherry-picking: when you cherry-pick from a remote branch, you sometimes wish you could cherry-pick again from that branch later on. There are several git projects where I wish I could do this, but the very structure of git means you'll have to manually rebase things every time. - Here's a more controversial thought: sometimes, people make mistakes. I don't want to speak for Florent (the other co-author of Pijul) here, as I know this is a matter of political choice, but I think both of us generally agree that society would be better off if mistakes were allowed, and even encouraged in the case that they have little to no consequences. When patches commute, mistakes are allowed: you can keep working, and later on change your earlier edits. It's no big deal. If you prefer a less tolerant system though, I can definitely understand. You might want to teach yourself to avoid mistakes (as a Dvorak keyboard user myself, how could I judge anyone for that?). I know no such version control system that doesn't have the really bad, insecure correctness problems in Git, but we could easily write a "no commutation mode" for Pijul, where each patch would be marked as depending on all previous patches. &gt; but I'm always open for new ideas, especially if it can solve other problems git has (partial checkouts of repos: submodules are, sorry to say, a crap to use). Repositories in Pijul are **sets of patches**, where "set" means the same as in math. In particular, there's no ordering you need to craft manually. A subset of a set is a well-defined operation, as is a superset, an intersection, a union, and many other cool operations. &gt; I really like the availability of thrussh as well! I hope someday you will be able to run ssh login servers and clients with it. What is a "login server" or "login client"? If you're thinking of implementing an equivalent of OpenSSH with Thrussh, this is already possible. You just have to implement the "open session" method in thrussh::server::Handler with fork+exec of whatever shell you want, and pipe all input and output to/from it. Thrussh even supports terminal control characters (another method of thrussh::server::Handler). I suggest reading the docs: https://docs.rs/thrussh/0.10.2/thrussh/server/trait.Handler.html
So, everything not Nest-related that was already in a separate crate is open. The only thing missing is probably the Amazon SES-related stuff, I'll publish it soon. Btw, pleingres is also on crates.io.
https://gist.github.com/myrrlyn/f0df4fff976a4a28f0a919e09741f070
The `Display` trait (used by `{}`) has a recursive impl for `&amp;` and `&amp;mut` references: impl&lt;'a, T&gt; Display for &amp;'a T where T: Display + ?Sized impl&lt;'a, T&gt; Display for &amp;'a mut T where T: Display + ?Sized So you could have a `&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;T` and it'd still accept it.
Nice, have anymore info? I can't seem to find anything.
Please do! I think Rust needs simple generic type constraints.
I see, that's what I was wondering about. I figured manual memory manipulation would be directly at odds with memory safety, so I was wondering why it was a common pain point (ideally you shouldn't have to do any?)
&gt; If you're thinking of implementing an equivalent of OpenSSH with Thrussh, this is already possible. Yes I was. That's wonderful to hear!
I was referencing the part "Hiding failure till the end", where you make it so that the user can call `client.get().repos()...execute()?` instead of `client.get()?.repos()?...execute()?`, tracking errors manually until the final `execute()`. Also, you also say &gt; This hides most of the error handling from the user internally and just passes the errors along until the end! [...] I had to trapeze through quite a few hoops to get it working properly. With exceptions, the code would also look like `client.get().repos()...execute()` but behave like `client.get()?.repos()?...execute()?`. (well, except throwing an error instead of returning an `Err(_)`, but the principle is the same: you don't have to manually propagate the error). Don't get me wrong, I'm not advocating exceptions. I'm just still on the fence about whether or not I like rust, and in particular, whether or not I like the fact that there are no exceptions.
You put a `?` after the `read_to_string` call, so by the time you get to the `match` any error has already been returned. Your `match` is redundant.
I'm working on my code coverage tool [tarpaulin](https://github.com/xd009642/tarpaulin) (because what do we use to cover our cargo), essentially I want to do the job kcov does and more. Last week I: * Identified all coverable lines in a project * Implemented a lightweight breakpoint system * Made sure dead code was linked into the test executables * Struggled with ptrace. This week I'll be struggling with ptrace, it seems when you launch a test executable it may launch each test function as a new process or maybe use a fork to launch them... Either way I get a no child error off waitpid... Once that works I should have line coverage implemented and then it's just testing with more complicated projects, and maybe looking at the coveralls.io API so people can start replacing kcov with tarpaulin. My week is short and rather busy though so I may not have much to show by the end of the week.
Oh my gosh, thank you so much :) 
Speaking as someone who is doing Rust game dev, if you aim to do something so serious you're calling it AAA **Take your business elsewhere.** Rust is not ready for that kind of usage yet. I'm one of many people working on getting Rust game ready but unless you're willing to sink a ton of time and money into using Rust (you'll be reinventing a lot of wheels) you'll be better served by C++ as of this moment.
It can certainly insert instructions to the `drop` implementation, but how will the `drop(&amp;mut self)` implementation know what to drop?
Well if you decide to go forward with it we'd be happy to hear from you on r/rust_gamedev
Ya, maybe that would work, especially since dst_vec only uses RawVec&lt;u8&gt;. And maybe it could export Unsize in a similar way. Good ideas!
We can't change all our Windows users' git configs.
Can it be set per-repository?
That looks cool! I used to play SimCity 2000 when I was a kid. I might try to contribute some time to it later. I especially like the way you named this enum: https://citybound.github.io/citybound/kay/enum.Fate.html
Ok this is pissing me off. I know many devs do that and I've done it. I never said devs never use Linux or ssh. &gt;Many devs develop and run testing on a Linux desktop or laptop, Ok &gt;a few ssh in to develop, Ok &gt;more develop in a Linux vm with or without GUI(sometimes over ssh), You already stated some ssh. Also what is their host OS &gt;and a few even develop on the server unfortunately. As in they ssh? Like you've stated. Look I'm not trying to be a stupid cunt, but you are just bringing up some anecdotel evidence against I point I never made. I'll simplify my original post. Take this with a grain of salt: Many windows users-&gt;many windows devs-&gt;rust needs them to become bigger-&gt;also the game development​ industry uses windows outside of a few indie games. 
Most techniques used in C are implementable in Rust, however, there are a few techniques which are very hard in today's Rust because of missing stable untagged unions and other missing feature that may be stabilized in future versions. An example is the highly efficient bitvector implementation of which a copy can be found [here](https://github.com/stp/stp/blob/master/lib/extlib-constbv/constantbv.h). Note that creating new bitvector instances return a pointer to this structure: |--------|--------|--------|---------|-------|------|-------- | WORD | WORD | WORD | WORD | WORD | WORD | ... |--------|--------|--------|---------|-------|------|---------- | Size | Cap. | Mask | B[0] | B[1] | B[2] | ... |--------|--------|--------|---------|-------|------|---------- ^--- pointer points to B[0] Apparently returning a pointer to the middle of the allocated area has some decent cache effects I guess. This bitvector datastructure is !Sized in terms of Rust. While unsized types are supported in today's Rust it is no pleasure to instantiate them. Something like this is implementable in Rust today but more of a pain experience ...
Not really a Windows issue. Reserved names are invalid only when using DOS compatible APIs. UNC APIs support any names. This is how you can create files and folders, which will be impossible to delete for users using Windows Explorer, lol.
Yeah those are all fair points, I'm not saying it's not a risk, but everything's a risk right? How would you rate the risk of a language like rust vs c++, and doing your own in-house engine vs Unreal? I'm not even sure I would say using rust vs c++ is as big of a risk as writing your own engine vs Unreal for some types of games, but you could probably make the argument that it is. I get what you guys are saying, I really do, please don't think that I don't understand all these risks. Obviously I'm saying this as somebody that has been presented with this choice and decided that it was worth the risks, so take what I say with a grain of salt. I also realize that the company I work for is not a huge AAA developer, so our needs and risks are obviously different. Being different can also be hugely beneficial! Maybe it allows you to do something that is hugely complex without fear, or allows you to do it faster and cheaper? *Somebody* has to do it first right? The video games industry though seems to be, *in my opinion* just a little bit too scared of doing things differently. I dunno that I want to turn the video games industry into silicon valley and javascript frameworks, but I feel like some people would just use c++ until the sun goes supernova. Would you say that rust is suitable for any commercial use right now? If so, why not gaming? Also, compare rust to the risk of using other languages that are not c++, I would make the case that using *any* language with a runtime is more risky than rust simply because porting a runtime is vastly harder than porting something written on top of llvm with no runtime. I can't talk about specifics, but people who do ports of video games have to go to herculean efforts to port certain PC titles using certain languages (c# and monogame, gamemaker, etc), and you can still find people who will do it. Sure, people might have already done the work for, for example monogame, but *everything is hard until somebody does it*. But I get not wanting to be first! Edit: Later, during shower... "I think I said the sun will go supernova... I was wrong on the internet." Obviously the sun is a main sequence star, and would become a red giant, then a white dwarf. "Explodes" would have probably been a better choice of words. More Chucklefish getting basic astronomy facts wrong :P
I think this post is missing the code part.
&gt; What does it do? Dances with high kicks.
Your actor library looks interesting... the only thing is it's covered under the GNU Affero license, which makes it unusable in other projects. Do you think you'd be interested in releasing those crates under MIT + Apache 2?
That is a pretty fantastic source for a name. Does it rhyme with "jaws" or "dose"?
Haha, I'm definitely aware, I can't go into specifics but I mentioned c# and monogame for a reason :P I know there are companies whose entire job is building tools to support these things, and they're very very good at it. I know this because we work with them. I know that the work is already (mostly) done for, for example XNA / monogame, but it's not cheap technology haha, nor should it be. You *will* be able to find somebody that offers the same support for rust, simply because it is easier. It's a weird prisoner's dilemma though, things are cheaper the more you want the same things that other people want, but people don't change what they're doing because if not everyone changes it's more expensive for you. All these game devs ITT dancing around what companies they work for and who they work with :P Edit: After consideration, it was probably not fair for me to say that any language with a runtime would have necessarily *greater* risk, because you're right to say that it is sometimes ground that is is already covered. It's definitely.. at least competitive with that, because the amount of effort it takes to get c# to run on a platform that does not allow JIT compilation is, as I'm sure you know, massive and as you mentioned sometimes it goes pretty wrong :P
I was thinking strategies and FPSes (sorry but fps with gamepad just sucks)
I'm trying to store a compile-time-known number of points (struct with x and y) with different random coords in an iterable structure. // this is too verbose for a large number of points but does what I ultimately want: let points = [Point::rand(), Point::rand(), Point::rand()]; // this will just creates copies of the first point: let points = [Point::rand(); 3]; // this requires a mutable vector: let mut points = Vec::new(); for _ in 0..3 { points.push(Point::rand()); }
Yeah, it feels like at least half the article is missing.
Incidentally, your `match`es are *also* redundant because `Result&lt;T,E&gt;` supports a function to transform one side of the `Result` while leaving the other side alone, so you can turn a `Result&lt;T,E&gt;` into a `Result&lt;U,E&gt;` or a `Result&lt;T,F&gt;`. The map functions look like this: let r1: Result&lt;usize, _&gt; = file.read_to_string(&amp;mut contents); let r2: Result&lt;String, _&gt; = r1.map(|_| contents); let e2: Result&lt;usize, String&gt; = r1.map_err(|_| "We dun messed up".to_owned()); and you can use them to transform the results in place, cutting down on rightward drift. I've found these to be *super* useful in exactly the situation you're showing here. `Option&lt;T&gt;` also supports this type of behavior. It's terrific.
I have to disagree. The ability to compute the same as a Turing machine is the most important one. Having support for syscalls is more a limitation of the toolchain and environment. Theoretically a syscall interface can be implemented as a protocol that only needs the input and output of a program.
And the fact that fewer and fewer processors do branch prediction. People figured out that the enormous number of transistors needed to do that are better spent on parallelism (cores, vectors, whatever). GPUs are all the rage now and they don't even try to predict branches.
Agree. However most of the PL community uses the term "undefined behavior" for what rust calls "unsafe" in order to avoid this confusion (though "undefinedBehavior" is a pretty ugly-looking keyword; not suggesting it as actual syntax!)
Maybe Rust needs an PartialOrdWithBottom trait, which PartialOrd extends, for types in which there is a transitive antisymmetric antireflexive relation on all but one element of the type. I suppose the trait would need to include an "is this value the bottom value" function returning a boolean. IEEE floats could implement this type, and containers can easily use types of this slightly-weaker trait as keys. For just about every other type the "is this value the bottom value" function always returns false, so it gets inlined after monomorphism and the checks get removed by the compiler. Zero cost except when trait objects are used (I think.... MLton refugee here just starting to learn rust, go easy on me).
Yes. Be sure and remind any and all open source projects about this. Open a rewrite ticket today! *Fearless concurrency.*
Thanks to developers using the wrong API, actually. If you use the "\\\\?\\[path]" form in windows, you **can** create files named for DOS special devices (NUL, COM1, LPT, etc...)
PC have plenty of those too, altho I'm missing on JRPG side
This isn't an answer to your actual question, but when I last tried to refactor std, extracting CStr into its own crate was one of the first things I did. It could be reusable.
Known (and really annoying) [issue](https://github.com/rust-lang/rust/issues/24010). Will hopefully be fixed as part of the upcoming implementation of [trait aliases](https://github.com/rust-lang/rfcs/blob/master/text/1733-trait-alias.md).
Yeah that's exactly it, steamworks offers a c API which is fantastic, but basically nobody else. For graphics apis, I actually took the approach that I think glium took where there is a trait implemented by a macro that gives all the offsets and types of fields in custom vertex types, but again, my gfx API requirements are simpler than most.
rust disallows some forms of programs (without using unsafe), these forms of programs are things *you don't want to do anyways*. so *theoretically* without using unsafe you can not map 1 to 1 anything from c to rust, with unsafe you could do a 1 to 1 mapping from anything in c to rust. If you mean can you build system things like you list? 100% yes. this is what it is designed to do well. So...yes. depending on exactly what you mean by 'can everything in C be written in Rust?' and what you limit by 'rust' and include with 'c'. 
I wasn't using stable, I was using nightly; but even in nightly you have to enable features to use them in your crate. If a *dependency* uses a feature, though, then you usually don't have to declare it in your crate. But like what /u/daboross was saying, the macro expansion causes unstable features to be used in the crate invoking the macro, which means you have to declare those features in that crate, too.
The best thing happened in the linux open source world recently.
If/when you do get something like this working, I'd really like to hear about it.
Is there a plan afoot to do some of these refactors in the tree?
It looks interesting, but tbh a WM is a whole different level then, and I'm not sure I have the skill to dive into a complex codebase.
Could we just move CStr into core or no?
You want /r/playrust - This is the subreddit for the Rust programming language.
Ah, I didn't realize that interior null byte could cause incorrect deallocation. You can split slices into ptr and size using .as_ptr method. I'd do what other comment here suggests. Split it into two vectors. Thought no need to store capacity, since that is used only for calling destructors and u8 doesn't have destructor. (You can set it to zero then.)
Oh I overlooked the -status part! :)
I on the other hand was quite happy with the selection: Tech *is* only half the battle (and it appears we're on a good way to win it, too), and the topics presented are central to build a successful community.
I'm also interested in this, given that Microsoft will release their sdk for the x1 this summer if everything goes right. 
I think you should edit this into your question. I was wondering the same thing /u/carols10cents mentioned.
what's your opinion of the mynewt BLE stack nimble?
I'm aware that `NaN` is a family, but the situations where one needs to distinguish between different types of NaNs is few and far between. I think it would be acceptable to treat all NaNs as `None`. Does rust even expose a way to query the NaN's payload currently? I don't think an efficient implementation of `Option&lt;f32&gt;` where multiple NaN encodings map to None could be done easily today since enum discriminants are implemented essentially as tags. But a more elaborate discriminant system (one that discriminates based on the result of calling `std::isnan` on the raw bits, essentially) could have made this possible.
I see that you use the first byte to indicate the hash function used. There is a project trying to standardize a similar future proofed convention - [mulithash](http://multiformats.io/multihash/). It is being used for IPFS, not sure about anywhere else yet. There are a couple rust implementations: - https://github.com/multiformats/rust-multihash - https://github.com/google/rust-multihash
thanks! Might check it out and refactor
&gt; using @nikomatzakis' Referent trait . &gt; use std::nikomatzakis::Referent; Where is this defined or described? I can’t seem to find it.
GObject seems to be equally foreign to both C and Rust, I think.
Pls no
Can you? Probably, if you make a custom `std` that simply removes anything that refuses to link then you might even be able to use the crate ecosystem. I assume if you're willing to go into uncharted territory like this then a custom `std` isn't out of the question (check out how Redox does it). Should you? _No_. I've tried multiple times to get off the ground with Rust gamedev, and although it's 100% plausible if you're willing to go back to the PS1 and GameCube days of everyone writing their own engines and toolchains from scratch, with the added pain of modern game development being orders of magnitude harder now it's definitely not something you can do alone, and it's even a big ask for a team. Amethyst is not ready (I used it for a 48h game jam and it took me until the second day before I had a working prototype and at that point I realised if I let a texture's destructor run it would break the other textures in the game and so I gave up). Piston wasn't ready when I last looked at it a few months ago. It's good for the kind of simple stuff that PyGame or Love do, but it requires a huge number of dependencies to get to that point, and the rest of the ecosystem doesn't support it like it does with PyGame and Love. Piston itself may have improved since then, but that doesn't fix the wider ecosystem issues. There are already world-class OpenGL wrappers for Rust, like Glium, but that's just not enough. Even the most fully-featured Rust loader for the simplest format that I could think of as recently as a couple of months ago is [not ready for integration with game engines](https://github.com/Twinklebear/tobj). As far as I can tell, the only effort made to load an existing level format in Rust is a horribly inefficient Quake 3 BSP loader that I made when I was learning the language. The asyncronous loading ecosystem is resigned to HTTP server usecases plus some other server periphery. If you have a big team and you're willing to explore uncharted territory, Rust may be for you, but you will be writing everything yourself and you will essentially be paying for huge amounts of development that you'd get for free if you just wait 3-5 years. Even the small amount of unsuccessful work I've done in it makes me believe strongly that Rust is perfectly suited for games, but the ecosystem is not just immature, it's nigh-nonexistant.
Are you sure this isn't just a list of all crates? Joking aside, there are quite a few here - even cargo itself. If anyone hasn't used it yet, the `cargo-outdated` can be very helpful for quickly checking on this sort of thing for your project and its dependencies.
I've found [`cargo-outdated`](https://github.com/kbknapp/cargo-outdated) useful for my own similar purposes, but have also toyed with the idea of building a service that will notify crate owners who opt in when dependencies are out of date, possibly combined with [rustsec](https://crates.io/crates/rustsec) to flag updates with security implications. As you demonstrate here it's not particularly hard, but I'm not sure if anybody else would find it useful enough to be worth building.
&gt; // this requires a mutable vector: You could always add let points = points; afterward.
Funnily enough I did a parser combinator for command input for my board gaming system using `impl Trait` too just last week. Nom and Combine are both fantastic libraries, but their APIs are a little too complex for what I want to achieve (which is naturally quite constrained anyway for this use case.) I've been on nightly for some time now and it's incredibly useful, I couldn't move back to stable until it lands.
You misspelled Alex's name in the QotW ;)
It would be useful if it included the crate author, so that one could easily check if any of their crates are in the list.
your code makes no sense to me, at least put some coments about what the functions are supposed to do, and what the parameters signify in. other then that, its super hard to actually get low level data structures right, and most of the frustration with implementing them in rust comes from rust actually enforcing safety rules that you would be violating when implementing it in C/++
Surprise, surprise. Semantic versioning at its best.
This is great, i hope the same happens for Qt too.
Sorted out https://github.com/cristicbz/idcontain.rs, cheers!
` data-encoding ^1.2.0 2.0.0-rc.1` I would rather wait for a full release before upgrading to an RC version.
`cargo-outdated` is in this list…
Not at all. You will get used to it pretty quickly.
&gt; This is exactly the trade off of semantic versioning. This is precisely the kind of situation that semver guarantees will happen because non-breakage is prioritized over stagnation. Okay sure, fair point. &gt; You can't possibly know that all these upgrades are "small" changes. For example, 0.x.y to 1.0.0 or even 0.(x+1).z can contain arbitrary breakages. Sorry, I meant in a more general aspect, not just because of this list. Keeping project dependencies up-to-date with smaller jumps between versions would make them easier to maintain in the long run. &gt; But that's not for you to decide. Of course. I can't _make_ maintainers update their crates but they might be inclined to give them a good polish. I understand the issue though -- I'll refocus the project for greater purposes.
I agree... the tool is quite naive at the minute. I could filter out suggested upgrades to RCs, or move them to the bottom.
camelCase method names are a barrier of entry for people coming from Ruby, Python, C++ and PHP. Syntax, especially as simple as that, is rarely an issue. Pick one, stick with it. I've never seen people stumble over that.
&gt; but they might be inclined to give them a good polish For me personally, a "good polish" is basically scheduled on a timeline of *years*. Polishing is some of the most challenging work in an open source project! There's a reason a lot of them don't have it. :-)
unNatural you mean?
Ok, I think we can just give up with the QotW now. Because no one will *ever* top that one. :)
I've run into this kind of error once or twice before and the first one it happened I also spent a long time trying to figure out what the heck was going on. It would be great if the compiler could detect that the right trait, but from the wrong version of the library, is implemented and mention the version mismatch as it can be an incredibly confusing error for anyone who hasn't seen it before because it's easy to not realize what versions of crates your dependencies depend on.
iKnowItDefinitelyMakesItHarderForMeToRead. theOnlyWayICanReadRustCodeIsToSitThereStaringAtItForLiterallyHoursUntilItMakesSense. howAnyoneCanThinkSnakeCaseIsAGoodIdeaIsBeyondMe. i_mean_look_at_this. its_almost_impossible_to_tell_where_words_begin_and_end. so_much_easier_when_everything_is_glommed_together_into_a_huge_ball_of_text. usingDifferentCasingRulesIsObviouslyAMuchBiggerProblemThanOwnershipLifetimesAndGenericsCombined.
&gt; I would prefer if you did not have to type self.private() to access private data. I would rather if you could just do self.f to get access to a private field f. Couldn't `Counter` implement `Deref&lt;Target=CounterPrivate&gt;` ?
I was doing a parser combinator without any fancy feature. No macros, no impl Trait. I think the api looks and feels very ergonomic. For instance a "Hello world!" parser would look like this: ``` seq(vec![tag("Hello"), skip(1), tag("world!")]); ``` I think there is still room to better our current combinator designs in rust. The current aproachs are too focused on emulating functional programming when I think there is no need to.
It depends. Historically, I've applied whatever force necessary to Python and PHP linters (up to and including piping through `grep -v`) to make them shut up about my using camelCase to squeeze more into an 80-column line. (These days, I've got better things to do with my time than stubbornly fight over every little thing, so I mainly stick to what's not too onerous to attain with a mixture of `rustfmt.toml` tweaks and overruling what I consider readability regressions via "run `rustfmt`, start up `git gui`, selectively commit the hunks I agree with, and then hit Ctrl+J to revert the rest.") Thankfully, `rustfmt.toml` can attain almost everything I want these days. I mainly wind up reverting attempts to put the format parameter on its own line in cases like this: assert!(something(foo), "Lorem ipsum dolor sit amet \"foo\" blah blah blah blah blah blah \"{}\"", foo);
Well, we have the same option and you definitely managed. I don't see that being an at-large effect, though.
&gt; Should we write `API` or `Api`? Note: in Rust types where you have `TypesLikeThis`, the convention is to write `Api` (for example, you would write `HttpConnector` instead of `HTTPConector`) Overall I find Rust types the least readable part of Rust's syntax. Most of trouble is due to `&lt;,&gt;&gt;` noise, but `snake_case` helps make expressions easier to read (IMO).
It says in the FAQ that (somehow?) it works by modifying my ~/.ssh/config file during install? Is that true, and if so, what could explain that this modification isn't happening on my system? I'm running Debian testing. What are the lines that are supposed to be added, so I can do it myself?
How does it work? Is `seq` something that does I/O directly? How do you write high order combinators? (something that receives a parser as a parameter and returns a parser).
How did you feel yourself? Did you like the conference?
Nice to see more people who work with GP / EA using Rust. I've written a crate for EAs: https://github.com/willi-kappler/darwin-rs and will add your repo to the list of similar crates. If I understood it correctly you concentrate on symbolic expressions, you could extract that to a separate crate. Then your GP crate would be independend of the problem. 
Cool, EA writing programms that's what I also wanted to try out. I've written a crate that is independend of the problem: https://github.com/willi-kappler/darwin-rs You have a separate crate for the SBrain interpreter, so I could try to add one of your examples into my project if you don't mind. I'll also add a reference to your project. (BTW: Two posts about GP / EA on the Rust subreddit in a short time!)
Im also completely lost as to why the method is called 'parent'. Rust and Trees ( Graphs ) are tricky. You usually want something along the lines of Adjacent matrix or some other graph structure ( https://www.khanacademy.org/computing/computer-science/algorithms/graph-representation/a/representing-graphs ) ( Rust has the crate Petgraph ) . So you wont store a raw pointer but an index to some list. That being said if you want to use raw pointers you will probably need some unsafe code.
So, sorta yes sorta no. Here's the deal: I use vim, and have commit to it. However, I wanted to integrate things upstream. So I sent in https://github.com/vim/vim/pull/1356/, but as you can see, it took *forever* to actually land. I didn't want what's local to diverge from what was sent there, so I wanted to wait on merging PRs... but it dragged on and on and on, so I did a bad job communicating it. Now, upstream wanted a lot of stuff changed, so my plan was to reintegrate the changes from upstream, then look at PRs. I have been very busy, and haven't quite been able to yet. This is also complicated because some stuff that's in there is stuff I don't personally use, like Syntastic. TL;DR it is but badly. More maintainers would be great.
&gt; First, like I said earlier I work for Chucklefish, it's not a secret or anything in fact I've used this Reddit account for work. So, that being said, Chucklefish is just a little indie studio so I think my personal needs would be vastly different than somebody who was doing complex 3D engine work. I love Stardew Valley; anything I can do to help you all with Rust, please let me know. Gonna read through this thread carefully; I'd love to get the language to be in a great place for games.
Oh, then `seq(...);` (ending with a `;`) wouldn't work, because you need to return the parser (instead of it producing a side effect). In this case, this code looks written in functional style to me. It's just not monadic style (which, funnily, is a syntax invented to emulate imperative code...), but instead in applicative style. It's cool enough! If you could define custom operators in Rust you could even define something like `&lt;|&gt;` so that `seq(vec![a, b, c])` could be written `a &lt;|&gt; b &lt;|&gt; c` (but that's just syntax sugar).
&gt; Im also completely lost as to why the method is called 'parent'. Because it's finding the parent of the node with the given key. The reason the first parameter is called `root` is because you call it with the root node of the entire binary search tree (which you can tell this is by the comparison tests), which it then searches. And you probably *don't* want a graph structure for a tree, because that would be hideously wasteful. This one isn't great, either, but it definitely avoids the pitfalls of cyclic pointers.
The overloaded operator thing would look so cool!
Thanks for the heads-up, also made me start to use `cargo outdated`.
Oh this is fun! It doesn't look like all my cores go above 50%. I tried in = [ [1, 2], [4, 3]] out = [12, 43]. Is there some convenient way to run code on some input after it's generated?
I use Vim, I'm learning Rust, I tend to be a "basic" vim user (sysadmin background, got this old habit that I need to be able to survive with the local tools only, back in the days it made sense, also, more decades as a vi user than a vim users). Anyway, I'm happy to try to help if I can, let me know.
I use rust.vim and would be willing to help with maintenance
A PR that would re-integrate the changes I made in that PR upstream would be amazing; it's mostly formatting changes. From there, it'd be going through the open PRs and seeing if they are still relevant or not...
I just left a sibling comment with some details, that'd be great!
Seq can take any number of parsers as argument. I was about to implement an ```alt````for alternative parsing. The way alt work is trying each parser in sequence, and it stops when one works. There is no problem with the implementation I have in mind, its just a matter of sitting my ass down to write some code. The implementation would be similar to seq. The way the parser data structure is designed allows for all sorts of crazy parsers to work.
Done, I think? https://github.com/rust-lang/rust.vim/pull/152
&gt; For instance a "Hello world!" parser would look like this: `seq(vec![tag("Hello"), skip(1), tag("world!")]);` &gt; I think there is still room to better our current combinator designs in rust. You might like my (WIP) library [munch.rs](https://github.com/utkarshkukreti/munch.rs): $ cargo script -D munch -e 'use munch::*; ("Hello", str::Any, "world!").parse("Helloπworld!", 0)' Ok((13, ("Hello", 'π', "world!"))) $ cargo script -D munch -e 'use munch::*; (P("Hello") &gt;&gt; str::Any &lt;&lt; "world!").parse("Helloπworld!", 0)' Ok((13, 'π')) (There hasn't been any public activity for a few weeks, but I'm working on some major improvements to the byte parsing module which I hope to push this week. There are still no docs though, only some examples and extensive tests.)
There's no way to delete crates from crates.io since that could break someone's build somewhere. You can transfer ownership to someone else and they can publish new versions.
I wish I had more time to do stuff this week but I don't. I think I'll just do a few doc prs to rustc this week.
I was told by crates.io maintainers to change crate description to "this is up for grabs" and if they'll get contacted by someone who wants this name they'll transfer ownership.
but macros are still cool :'(
It would (probably) already implement Deref&lt;Target=ParentType&gt; to allow using any of the parent classes' functions/properties/fields as well.
 is there a way to define authentication check on specific route in rocket.rs? for example all the endpoint that start with /api/*
Yes we add the following to the bottom of your SSH config: https://play.rust-lang.org/?gist=d4a209cae197b04e9ced8bab41be66b8&amp;version=stable&amp;backtrace=0 (reddit formatting wasn't working so I made a playground link) This uses our PKCS11 module, proxies traffic through the krssh binary (so that we can send the signature from the remote server to the phone for verification as well) and offers the kryptonite public key, followed by any other keys you might have. What is the ownership of your ssh config file?
Is it fair to say that most Vim users who are writing Rust are also likely relatively advanced Vim users? The idea of having it directly in the upstream is great, but it's going to be a pain for all the reasons you are experiencing. Why not just maintain it out of tree and push people toward a plugin manager?
One particular problem is that when you update to a new major version of a dependency, if you expose stuff from that dependency in your public api, hence making that dependency a *public* dependency, then you also have to update your own major version causing more churn. It is often quite preferable to stick with the current major versions of public dependencies for a while so you can eventually update them in a single major version, instead of stringing them out over multiple major versions.
Hey geaal, when I started this library my inspiration was: how would nom be without macros! But macros are awesome, main problem for me are the scary error messages!
The Emacs major mode is moving quite slow as well but I'm pretty sure it's just due to the lack of people using Emacs and Rust and who knows how to write Elisp and major modes. I have nearly no experience with Elisp or major modes but would love to help out.
I've come to Rust from F#, where parser/combinators have been written about in depth. Here is a decent series on the concepts: https://fsharpforfunandprofit.com/posts/understanding-parser-combinators/ One quick notes to help you translate if the syntax trips you up:``` type Result&lt;'a&gt; = | Success of 'a | Failure of string ``` is like an enum
&gt; The current aproachs are too focused on emulating functional programming when I think there is no need to. Huh? nom parsers end up being quite fast while preserving much of the ease of use you get from monadic parser combinators. Also I fail to see how a *parser* combinator could fail to be functional, since combinators are by their nature higher-order functions. 
Yes, then it's part of the interface. But now we're constraining the implementation. It's an example of how we sometimes have to fit the design around the borrow checker, although the design becomes better IHMO (sub-structs with their own methods). It is in any case private to a type how it internally handles its mutability issues.
&gt; Is it fair to say that most Vim users who are writing Rust are also likely relatively advanced Vim users? I'm a very basic vim user; only occasionally use it to edit files quickly.
We (I am a crates.io maintainer) do not do the actual transfer of ownership. The current maintainer must do that, but we will try and help people get in touch with maintainers.
Thank you! Will look soon.
Thanks for your answer. May be you or someone know any canonical implementation BST(without recursion) example in Rust even with unsafe raw pointers?
Crates like [array-init](https://docs.rs/array-init/0.0.2/array_init/) can do this.
Nice project. Thanks. PRs to rust-lang crates and brson crates welcome.
I'm forking OrbTk and Orbital so that my solitaire game can build on stable. (It already builds on nightly: https://github.com/gregkatz/cvsolitaire)
Not yet. I am preparing an [hydrodynamics dataset](http://archive.ics.uci.edu/ml/datasets/yacht+hydrodynamics) to be available as a demo to run out of the box. Coming out soon, I think tomorrow. Note that the dataset is transposed before being encapsulated in the `Data` struct. For reasons you can understand just by looking at `utils.rs`. So if you want to try it out, make your variables be a `Vec&lt;f32&gt;`, where each element of this vec is an instance! Then build up your `Individual` as you want and try it out. I don't know much about performance, but I am surprised it ran surprisingly well for an intel atom x5 processor. 
I use vim for everything but I hate configuring it and wouldn't call myself an advanced user in terms of its configuration &amp; plugin systems. I'm always very confused by it.
Rustup should install it by default, then. It would be very helpful!
I know it's not exactly what you are asking for, but the patterns repo is helpful: https://github.com/rust-unofficial/patterns
I'm on mobile, but google "ripgrep code review" for an excellent walkthrough of ripgrep's code. Clippy, as mentioned, is awesome. Rust be Example can help as well. 
I have a related question. Since I must specify the associated types everywhere, how do I do that if they are ambiguous? For example: https://is.gd/eBxHYq I expect the error and this is definitely ambiguous, but I'm not sure how to disambiguate the associated types. The typical "turbofish" syntax doesn't seem to work. Any ideas?
`env_logger` might not actually be what's taking so long. The compiler compiles multiple crates concurrently, and `env_logger` might've started later than some other crate that is actually taking up the majority of the time. I bet you are compiling some compiler tool like racer or rustfmt, and usually `syntex_syntax` is what's actually taking a long time to compile there.
Sorry to hear that! We are working on lowering the latency. It is &lt;1s when I use bluetooth (mac/iOS), but the Bluetooth story on Linux is too complicated so we do not support it yet. What OS/phone are you using? Also what type of network were you running on? If you have the app open, we also use SQS which might improve latency for you.
I am sure you have some kind of environment issue based on those errors. What version of vscode and what version of the rust extension are you using? 
How does this compare to [rust-webplatform](https://github.com/tcr/rust-webplatform)? I suppose you made this as a competitor to rust-webplatform since that one is unmaintained? At any rate, great effort. I'm going to look forward to contributing.
Awesome. Happy coding.
Glad you got this worked out - I'm curious how this has worked out for you up until now. I'm also looking into building Rust programs for this particular architecture. I'm still trying to get this working so if you happen to have documented your wrapping of rustc/cargo I'd love to take a look at it.
Tokei is so much faster than cloc. wow
Hint: ease_of_reading &gt; easeOfTyping, because code will be read much more often than it is typed. 
You might be [interested](https://github.com/vadixidav/mli_mep) [in](https://github.com/vadixidav/gapush) [some](https://github.com/vadixidav/evobots) [of](https://github.com/vadixidav/evomata11) [my](https://github.com/vadixidav/mli) [crates](https://github.com/vadixidav/evomush).
I might be confusing the definition of parser combinators. My understanding is that parser combinators are just that, simpler parsers that can be combined to make more complex ones. I didn't know that there you are forced to combine functions in order to qualify as a parser combinator. The way I do it in my lib is with data structures. A very different approach to functions. Each parser is represented by a simple data structures that can contain other parser data structures. Basically a parsing tree. The functions just serve the purpose of building a parser tree. They don't do any actual parsing. Later, when you execute the parser, the algorithm reads the parsing tree and applies it to the buffer. But from an api point of view, it looks like I'm combining functions that parse.
[I](https://i.stack.imgur.com/phbAr.png) wish memes were allowed
[I did a BVH for my realtime CPU pathtracer](https://github.com/ruuda/convector/blob/master/src/bvh.rs). It has SIMD intersection, and the memory layout is tweaked so siblings are adjacent in memory and on the same cache line. It is optimized for fast traversal at the cost of build time. It uses [Rayon](https://crates.io/crates/rayon) to parallelize the build phase.
Both are equally easy to read for me.
It could probably be made into a context-sensitive keyword (it's only used before closures, right?) Those do add complexity to the parser though.
By ray packets you probably mean the way that most high performance CPU path tracers do this using AVX2 and such. That is not my focus since I really want this to work on the GPU rather which means I get ray packets for free essentially. Hopefully I didn't misunderstand you. Also your stuff looks super cool! Would be cool if we could collaborate to create the ultimate Rust real time path tracer.
Also to run it, it's a compiler plugin
I understand your pain, as I often want to name things `in` and `out`, but I cannot.
Interesting! I considered using Python too, but I felt that it would be too noisy to express coordinate arithmetic like `(0.5w, 0.5h) + (1em, 1em)` without built-in support for units and a + for tuples. Your Elphie example.py actually looks really clean apart from the `MyElement` part. Making small custom graphics like those ergonomic is exactly what I hope to solve with Pris. I’m not sure what you mean by svg fragmentation, but Pris can render svg graphics. I also plan to add an equivalent of Beamer’s `\pause` and `\onslide`. I actually needed those today, so they are next on my to do list.
I was thinking several time that it'd be awesome to write a book similar to "Clean code" that would teach people everything about writing efficient, modular, safe, idiomatic Rust. Something that would be a go-to resource for becoming an expert in Rust. It could be a community ("Open Source") project I guess. One of the resources I find useful is [patterns](https://github.com/rust-unofficial/patterns) repository. It also contains anti-patterns.
Yea exactly, I mostly work on the CPU side so I'm not too familiar with GPU specifics for rendering. For GPUs I guess a warp is kind of like the packet on the CPU, since the scheduling is handled for you, then maybe all that's needed is to keep the rays from diverging too much within a warp? Thanks! It would be really cool to work on a project like that, sort of aiming to a Rust API for photo-realistic rendering in the style of Embree or Optix.
Huh, how would that work?
You can also [do it through WSL](http://i.imgur.com/Q0avBGl.png). You can't delete them through PowerShell or Explorer, though. PowerShell just says it doesn't exist, and when I tried to delete AUX through Explorer it said it was too big.
You can use `cargo build -j1` to build one crate at a time and more easily see how much time each takes.
Fair enough. Thanks!
wait no more, I uploaded the dataset to the repo and it is running out of the box!
I've been fiddling with a trait based on .Net's TimeSpan time, to make it easier to use the Duration type. I'm still trying to figure out how I want to be able to construct a new Duration based on a given length of time. At the moment I'm just using an `f64` like .Net's does, but that feels messy because of having to check for NaN, Infinity, and negative.
Yeah, something like the [Airbnb JavaScript Style Guide](https://github.com/airbnb/javascript) with little code snippets showing examples of (very bad|bad|better|good|best) ways of doing the same thing.
`in_` and `out` are the same length!
You need to manually `impl Copy` for `Phantom`, because `#[derive(Copy)]` cannot be sure that `T` will `impl Copy`. When you manually `impl Copy`, you tell the compiler that it doesn't matter. [Here](https://is.gd/ObSSOm) is a playground where I think I have what you want working.
You're a mutant. :-) Seriously though. With Quxxy's post up on the screen, just flick your eyes from left to right quickly, and see which style allows you to pick out more words. Do it a few times at different speeds. For me, at least, it takes just a little bit more brain/pattern_recognition/ProcessingPower to split the words out in the CamelCase style versus the snake_case. It's subtle, more pronounced the longer the wall-of-text is, but there's a difference. Is there enough of a difference to be meaningful when using *sane* variable names (short, 1, 2, 3 words at most)? I don't know. Probably not. But the difference seems to be there. To add another bit of anecdotal support: why has written language adopted the use of spaces between words? If you assume the current norms that written languages seem to follow the world 'round is the result of centuries of refinement, the use of spaces between words as an optimal representation of written language suggests snake_case is slightly more efficient. Not trying to bikeshed here, I genuinely hadn't really thought about this until today when Quxxy's post set the two styles side-by-side. That said, it does seem to me that conventions that mirror those of modern written language may be more efficient for reading when used in code than conventions that optimize ease of typing. If the code will be read more than typed, the former would seem to trump the latter. Readability &gt; type-ability. The time code spends being maintained is much, much longer than the time spend writing it. Moreso with FLOSS code, I imagine, since many more people have the opportunity to read it as compared to secret proprietary code.
o hai sdroege_
That doesn't work when T is not Clone (which I forgot to mention specifically in my post, but NonCopy is neither Copy nor Clone).
I think something like this is going to be needed in the near future. We have quite a few intro-to books, but I feel like the more intermediate to advanced stuff is lacking. Obviously, Rust still being a young language, so this much is expected.
Did you do a benchmark against the gold standard, embree?
In that case you need to also manually `impl Clone`. `#derive[(...)]` is not that smart ATM, so you need to help it along sometimes, especially with types that are basically hacks to get around things the compiler can't do. [Playground!](https://is.gd/jiQMVR)
Ok, I found out what's the problem. Deriving Copy and Clone implicitly adds these bounds to all type parameters, not to the actual types of the fields in the struct. impl'ing them manually like this works: struct Phantom&lt;T&gt;(PhantomData&lt;T&gt;); impl&lt;T&gt; Clone for Phantom&lt;T&gt; { fn clone(&amp;self) -&gt; Self { Phantom(self.0.clone()) // This is not even necessary in this case, could just pass a new PhantomData. } } impl&lt;T&gt; Copy for Phantom&lt;T&gt; {} I now vaguely remember seeing a conversation about this behavior, but I don't remember why it's actually like this. I don't think this is the "correct" way to derive these impls, as this can overly restrict type parameters in some cases.
Yeah, I just figured this out as well :) Thanks for the idea!
Very cool! I'm had similar ideas [a few months ago](https://www.reddit.com/r/rust/comments/5rrfny/stupid_tricks_with_rust_higherorder_functions_and/?ref=share&amp;ref_source=link) to extend [my parsing library](https://github.com/shepmaster/peresil) to write my [own Rust parser](https://github.com/shepmaster/fuzzy-pickles), which is approaching 100% recognition. It's been pretty fun so far.
Nope not yet. It would definitely be interesting though. I also want to benchmark the implementation against other implementations. 
Do you still have the code for your custom and_then laying around? I'm still learning the language, so I'm not quite sure how to implement it Edit: Ok, after some fails I made a implementation of it that works: trait CustomAndThen&lt;T, E&gt; { fn and_then2&lt;U, E2, F: FnOnce(T) -&gt; Result&lt;U, E2&gt;&gt;(self, op: F) -&gt; Result&lt;U, E&gt; where E: std::convert::From&lt;E2&gt;; } impl&lt;T, E&gt; CustomAndThen&lt;T, E&gt; for Result&lt;T, E&gt; { fn and_then2&lt;U, E2, F: FnOnce(T) -&gt; Result&lt;U, E2&gt;&gt;(self, op: F) -&gt; Result&lt;U, E&gt; where E: std::convert::From&lt;E2&gt; { match self { Ok(t) =&gt; op(t).map_err(From::from), Err(e) =&gt; Err(e), } } } ... Ok(builder) .and_then2(status::ServiceStatusBuilder::spawn) .and_then2(status::create_xml) This works extremely well. Thanks!
Thanks!
Disclaimer: For anyone who has seen my name before: sorry to be a broken record :) Sure its an external plugin. But judging by this question and answer, Clippy is the defacto "canonical". If it is literally THIS important to the community, why are the best parts of Clippy not being merged into rustc? As "advanced lints" or "lints April 2017" or something.
You have a type error `let arraylist = env.new_object(cls_arraylist, "()V", &amp;[]).unwrap();` Is *attempting* to define an `java.util.ArrayList&lt;E&gt;`. The problem is your typing parameter `&amp;[]` holds nothing. This isn't a `java.util.ArrayList&lt;?&gt;`, your abstract type array has no values *period* so instead you're just returning an `java.util.ArrayList`, which doesn't exist. So when its `&lt;init&gt;()` is called to construct this class it has to check the class file for `E` so it knows what `java.util.ArrayList&lt;E&gt;` it is constructing (pointers have to be populated in `java.lang.Class` structures. Except there is no pointer. The data field's length is zero. --- I think. I don't know know that much about JNI.
[It's also the name of the compilation artifact, straight from Cargo](https://github.com/BurntSushi/ripgrep/blob/master/Cargo.toml#L22)
Sorry, I've updated the gist since this Reddit post, and didn't realize that it would change what the original link pointed to. Here's the [original revision that I posted](https://gist.github.com/mikeyhew/635afa3155440b1e2e677070bfe6fed2/9af675960f3a8bd059ca933ee51597514a18c72e). [Here is some context](https://internals.rust-lang.org/t/custom-dst-discussion/4842/3) for the updated gist. I was reading [a post by Niko](https://github.com/rust-lang/rfcs/pull/1524#issuecomment-272020775) on an RFC thread about a trait called `Referent` that every type would implement, providing a function to split up a fat pointer into its two parts, and one to construct one from its parts, and wanted to see what this code would be like if those functions were available in Rust today.
&gt;nd I've failed to find guidance in the docs for the jni crate or in &gt;anything else written about Rust and JNI, or about JNI in general. You can try https://github.com/Dushistov/rust_swig It can automatically convert Vec&lt;X&gt; to Y [], not sure about ArrayList though 
Also, after I refactored the gist to use Niko's hypothetical `Referent` trait, I realized I can create my own `Referent` trait, and just add it as a trait bound. So the next iteration will be `struct DSTVec&lt;T: Referent + ?Sized&gt;`, and I can stop using a macro. It really shows the flexibility of Rust's trait system!
There are a few people where I work interested in it. (Myself included, obviously.) We've used it in some small prototype or utility programs for number crunching. None in the core code, though.
I ran that literally right before `cargo +nightly install clippy`. My `rustc` version is `rustc 1.19.0-nightly (2d4ed8e0c 2017-05-03)`.
Yes, if you work on small packets once you start doing diffuse bounces you lose your coherence very quickly. Recently though, Embree and other systems are moving to tracing streams of rays (like 1k-10k rays at once). If you trace a large enough batch of rays you can find mostly coherent groups within the batch and schedule warps/packets. It does require doing some bookkeeping or shuffling to get the coherent groups together, for example see the [Dynamic Ray Stream Traversal](http://cseweb.ucsd.edu/~ravir/274/15/papers/drst.pdf) paper. This batching is also being looked at for shading, [Disney's Hyperion](https://disney-animation.s3.amazonaws.com/uploads/production/publication_asset/70/asset/Sorted_Deferred_Shading_For_Production_Path_Tracing.pdf) does this and Embree [is looking at it as well](https://embree.github.io/papers/2016-HPG-shading.pdf). This helps a lot as you get to large scenes in an optimized ray tracer, since you end up bound by memory bandwidth and the coherence in intersection and shading amortizes the cost of fetching data.
```` pub enum ParserType&lt;'d, 'a, 't&gt; { Sequence(Vec&lt;Parser&lt;'d, 'a, 't&gt;&gt;), Take(usize), Skip(usize), PWord, Blank, Tag(&amp;'t str) } pub struct Parser&lt;'d, 'c, 't&gt; { pub ptype: ParserType&lt;'d, 'c, 't&gt;, pub chain: Option&lt;Chain&lt;'c&gt;&gt;, parsed: Option&lt;&amp;'d str&gt;, } ``` As you see, there is no closures. Chain is just operations that can be aplied to a parser after it parsed the data (like comparison, conversion and store of data). So in a sense, I did write a little language of parsers and an interpreter. Never thought of that before. Edit: I dont know why the back tick format thing doesn't work
I think if you use 4 spaces you can get a nice code block. I love making little languages an interpreters inside of apps. In python you can use a big nested object with a specific format. In Haskell you can just write the AST. I guess you don't have to think of it as making a little language, but when I do I tend to find that my code is more extensible. Anyway, your work looks cool. Nice job!
Welcome to Reddit. You have posted to the wrong subreddit. In future, you should check what a subreddit is about *before* posting. You probably want /r/playrust.
This is a useful resource, but I don't think it's what OP was asking for. Formatting is just one of the many parts of "clean" code, and I think application structure and conventions for structuring code are really more important parts for idiomatic code. On top of that, the rustfmt configuration guide isn't _really_ idiomatic formats, just simply what `rustfmt` supports at the time - there are several conventions that have been established and still aren't supported by rustfmt, and thus won't be listed in that guide.
Hi! Welcome to /r/rust - a community about the Rust Programming Language. I'm guessing you want /r/playrust, the community for the Rust Game.
It definitely takes a particular mindset and personality to become an expert at *text editors*. Most people just use them, they don't spend hours and hours configuring them for the sake of configuring and fiddling with twiddly bits. Edit: That being said, for a fast moving language like Rust, keeping stuff out of tree is probably a good idea for now.
A very simple solution is to suffix a conflicting variable name with `_`, for example `type_` or `move_`. It's just one extra character, and the intention can be read very clearly that "I added this underscore to distinguish it from a keyword".
Sure, however most of the resources were already posted so I believe this still is good complementary information for the topic.
Yeah, that's a thing I could remember to do. But I'm human, and didn't always. (I prefer to just use a more descriptive variable name, but either way.) It doesn't help that I'm writing code in several different languages right now.
I get this often too. I finally got it to install once and havent touched my compiler or the clippy version since. My main issue with clippy is it all still seems like a bit of a hack... not a stable tool. But that will change over time.
Definitely agreed!
It would be good to get a little script that installs the latest compatible nightly/clippy pair.
Wow, async has a long way to go!
Can we run the rust/playrust neural network on posts as an automod and automatically hide suspect ones until someone intervenes? I don't think that'd help for this one but still.
Its coming. It will be an optional component like rls is at the moment.
High-frequency trading is intrinsically unethical. I wouldn't want anything to do with that.
Pretty sure there wasn't that much thought into what was a keyword and wasn't, more like a rush to implement things and get them to actually work. I mean, closures were a mess in the first iteration. I think not having to say which variable you're closing over and all that extra work overshadowed whether move was a keyword or not. Nobody bikeshed what the keyword for moving closures should be.
Not Niko, but I pronounce `&amp;` as "and", even when it doesn't have that meaning. (I also pronounce `#` as "number". I'm weird.)
If it's a `move`, it's a move. There is no "more descriptive variable name". `chess_move` is NOT more descriptive in a chess program. `move_received_from_controller` is overkill.
Yes, clippy_lints is going to be a rustup module. There already is a Rust PR (sorry, am on mobile, bringing my kids to the doctor for check-up), but we are still working out how to proceed with it. /u/manishearth told me he'll discuss this with the tools team this week. As for the lints not being active by default: This is a choice the user should make, and clippy is developed at a different pace than rustc.
I certainly can relate. 😁
Yeah, we had some breakage recently. That's what we get for using nightly, but this is our only choice until we upstream clippy_lints (the process is underway).
Not only did they add support for Rust and Cargo, but they also use Rust internally. However, my attempt to add my [pathfinding crate](https://github.com/samueltardieu/pathfinding) to VersionEye was met with a 500 internal error.
That's actually a really good idea, at least until we get stable clippy (which we're currently working on).
thanks!
&gt; book 2.0 Can you share a link, please?
Rust is a completely open community project. Why would anything not be allowed to be public knowledge?
Is it possible to cache/memoize some data in an application instead of fetching it from the database/remote api every time ? 
Looks like we need a pathtracer-bench to sit next to ecs-bench :)
&gt; What am I doing wrong? Nothing. Sometimes it happens that a fresh nightly will break the most recent clippy. Since I've been bitten by this before, some time ago I cobbled together a couple of API calls to help me find a working nightly/clippy combination. This thread motivated me to shape that code into something more usable, so here goes: [clippy-releases.sh](https://gist.github.com/inejge/f0a6a70244ff1f7a51e4449105e2136e#file-clippy-releases-sh). Running the script today generates the following output: 0.0.130: 2017-05-03 2017-05-03 2017-05-02 0.0.129: 2017-05-01 2017-05-01 2017-04-30 2017-04-29 0.0.128: 2017-04-28 2017-04-28 0.0.127: 2017-04-27 2017-04-27 2017-04-26 2017-04-25 0.0.126: 2017-04-24 2017-04-24 2017-04-23 2017-04-22 2017-04-21 2017-04-20 For a couple of most recent clippy releases, starting with the latest, the version number and release date for each release is followed by the list of nightly release dates which are equal to or less than the clippy release date. Clippy and rustc are tightly coupled, so a particular version of clippy should be compiled by a contemporary nightly. Let's say you wanted to try clippy 0.0.129 and nightly 2017-04-29. You'd have to run: rustup toolchain install nightly-2017-04-29 cargo +nightly-2017-04-29 install clippy --vers 0.0.129 (Spoiler: it worked.) Of course, the rest of instructions from the clippy repo must be followed to get a working linter.
&gt; This week in Rust 181 &gt; … &gt; Quote of the week: &gt; `"Hold my beer."` &gt; `- llogiq`
I've read some people complaining that they need numeric generics for HFT (Rust doesn't have them yet). However, I can imagine someone trading (pun not intended at first) little bit of performance for lower risk of crash.
I suspect it's less about being "allowed to be public" and more about showing deference to the folks driving the project.
I believe it is unethical. Hear me out. As you said, HFT is far from no. 1 on the list of bad things, but that doesn't make it good. edit: To be clear, most of whats follows is really about investment in general, and thus applies to HFT, being a subset of this. Note that as /u/carrutstick and /u/kmc_v3 pointed out that commodities are being traded through HFT too, I don't really have any objections to that. First of all, HFT is about trading shares, stocks, etc., i.e. a form of value of some production. This means that you get some profit (surplus value) of some firm or company. So why is this bad? You paid for it after all. Well, it means that you own a part of the means of production of a particular work place. You get a share of other people hard-earned money. This share is not something the common man can get, because not only does it require capital, but also technical abilities. This effectively keeps them from owning the working place themself, under the current system. In fact (and this is especially true for automatic trading), you don't really do any 'work', you simply let your capital multiply itself. I doubt any of the leading investors have any idea on what the computer program is doing. Not only is there minimal work in it, there is also no produced value (for example, you can dig holes in the ground all day and fill the up again, that would be hard work for sure, but it would be completely useless and produce no value). All that happens is really that you use your capital, to control the production means, which is both necessates and is necessary others work, and thus block them from getting their fair share. It is completely unnecessary, it is indeed unneeded, but an effect of capitalism. Futhermore, it has expensive implications at society (see: all crashes ever). If you're baker, you bake for people, and this is something that can bring other people joy (as well as simply feeding them), and thus has some value. The same cannot be said about invesments, you don't do anything for other people. ~~HFT also has an ethical issue that manual stock trading doesn't to the same extend: It's really really fast, and did in fact play a huge role in the 2008 crash. The crash was inevitable, and capitalism will have crisis once every few years, but that is partially due to these kind of investments.~~ (see new comment) Now, one could argue that it running a program doesn't make a difference. And in a sense, this is true (this is the classical Kantian critique of consequentialism btw.), but it also kind of misses the point: This is a system (capitalism), and one have to participate in it, but you can do so while minimizing the damage you do to others. Being an investor certainly does not minimize damage. The little difference you do by not running a program like this, albeit small, is still a difference, and does still mean that there is one less player in the game of investment. Lastly, I want to bring up a concrete example. You probably remember the United Airlines case where they violently removed a man from an overbooked plane. Their stock dropped for a few days, and is now back up. Compare to when American Airlines raised the wages a week ago. This caused the stock to drop massively, and it is still falling. Why so? Because bad press is temporary, but improving the conditions of the workers means that the profit margin will get smaller, permanently. Not all of this was about HFT, but whatever. I hope I made my point clear, despite this being somewhat of an mismash of various points. Edit: Also for the point of &gt; Then don't. But there's no way you can stop other people from using Rust for things you consider unethical. I'm curious though to hear more about the reasoning behind this view. I want to say, I tend to dislike the "none of your business" argument. If I think something is unethical, I won't simply ignore it. 
Many Thanks for the feedback :) I just tried the GitHub integration with a toml file and it worked for me. Your toml file from GitHub I pulled in via the URL function and it worked as well: https://www.versioneye.com/user/projects/590b0256e01eee001289856e. Can you post your VersionEye username here? Or just open a ticket here: https://bitbucket.org/versioneye/versioneye/issues?status=new&amp;status=open. Then we will debug your account. I'm sure we will figure it out :) 
Ah yes... I'll fix this.
My VersionEye username is "samueltardieu" (just as on GitHub). I'm connected through my GitHub account. I just went to https://www.versioneye.com/user/projects/github/samueltardieu/pathfinding/show and tried toggling `Cargo.toml` active, and I get the same error.
mov?
Market-socialist working in HFT here: not trying to be rude, but I really don't think you know what you're talking about. &gt; ... and did in fact play a huge role in the 2008 crash. Simply not true. The securities involved in the 2008 crash are not even traded on high frequency exchanges. The most generous way to interpret this statement is that, on realizing that some banks were soon going to be insolvent, people started selling their stock in those banks, but the fact that people could sell quickly did not change the fact that the banks were insolvent. &gt; All that happens is really that you use your capital, to control the production means, which is both necessates and is necessary others work, and thus block them from getting their fair share. This seems to be the core of the rest of your argument, but it seems broad enough to apply to absolutely anyone who engages in trade. The fundamental thesis of trade is that if person A has some commodity that is worth less to them than it is to person B, then someone who can buy the commodity from person A and sell it to person B has created real value: they have made both person A and person B happier, and they have put in work to do so. At the most basic level, HFT is the same thing: if I know that person A wants to sell, and my statistical model tells me that person B is going to want to buy soon, then I will buy from A now and sell to B later. Both A and B are happier with this arrangement than they would be if I wasn't here, because they undertook less risk, got their trades done faster, and statistically both got better prices than they otherwise might have. I have created value for both of them by putting in a lot of work modeling their behavior. I'm not going to say that HFT is always a good thing; there is a long list of unethical strategies one can undertake to try and fool other people about the nature of the market. There is also something of an arms-race scenario that diverts smart people away from more useful activities. That said, if you acknowledge that trade and commerce are good ways of getting people what they want, it's hard to argue that HFT is purely destructive. Looking back at your comment it seems likely that you _don't_ think that trade and commerce are good ways of getting people what they want, which is fair enough. I'd love to think that we'll eventually have an AI-driven utopia where decisions about capital allocation are easy to make, and labor consequently captures more of the value it creates. Until we get there I think that the best system we have for allocating capital is to let people profit from allocating it.
Welcome to Reddit. You have posted to the wrong subreddit. In future, you should check what a subreddit is about *before* posting. You probably want /r/playrust.
Seems like my messages are never clear enough to not need further explanation. :( &gt; So what value do they create? There are two cases: * One person wants X and he is willing to sacrifice Y+Z1 to get it. Another person wants Y and is willing to sacrifice X+Z2 to get it. They are apart or don't know about each-other. A trader spends time to find them, exchanges X, Y and keeps Z1, Z2. The value he provided is that he helped those two people do the exchange. If he didn't do it they'd have to do it themselves or they wouldn't do it. * A trader thinks that today there is a surplus of X and later it will be lacking. The reason he thinks so is irrelevant. He buys X for lower price (supply-demand), he drives demand and price higher motivating people to save up. Then when there is lack of X, he sells for higher price, making it available for people. If he did this right, he will increase stability of X. If he screws up, he will be punished and if he screws up too often, he will go out of business. The stability is valuable because it makes planning future easier. &gt; Capitalism is far from voluntary. The only alternative is starving, essentially. That's unfortunately feature of the nature itself. If you don't work to get resources, you die. I'd love to live in a universe where this is not the case but unfortunately, in this Universe it's work or die. By "voluntary" I mean free of coercion from other people. If nobody is threatening you to kill, steal, etc, your action is voluntary by this definition. It may be "least bad" action (yeah, work is often undesirable, but the other option is to die). I find coercion by other people highly immoral of course... &gt; This is an incredibly simplistic view. The means of production are privately owned, because they're expensive to create, hence under capitalism, the worker is forced more or less rent the means of production, for the price of some of their surplus value. Well, this is nature. If you build by your bare hands, you can either spend your surplus resources to create a hammer, shovel, ... and increase your productivity or continue using your bare hands, while your neighbour can achieve same results as you by working X times less. It may be sad, it may be hard to accept but it's the reality of this world. :( &gt; completely free capitalism would be the best way to solve every problem Maybe it can be viewed as the least bad way to solve problems. The opposite of what I'm suggesting (it's Vluntaryism, BTW) is the idea that someone may initiate violent force against other person. I don't think aggression is better way to solve problems. &gt; What exactly justified capitalism other than property rights, which itself would need justification? Self-ownership. That means you own yourself and I own myself. If I did own you, you'd be my slave. That's not moral or consistent. We are both human beings and none of us is more important than the other. Since you own yourself, you are entitled to products of your work. I'm not allowed to take away stuff you made against your will. The only way I could morally get your stuff is if you will give it to me - no matter if it's a trade or a gift. Even if you invent some clever way to work more efficient, or convince people that your products are worth buying. &gt; What justifies that you are forced to participate in a system, where you only get some small partial of the fruit of your labor, and if you refuse, you end up in jail or starve to death? I don't think there are only these options. If you are dissatisfied with your salary, you may end the contract and do something for someone else. If you can't find someone offering high enough salary, you probably need to improve your skills. Or think and find clever ways to increase your productivity. I would myself do it that way. I'd have hard time taking other people stuff against their will if I wanted more. I don't think it would be moral. Anyway, maybe we should continue via PM, if you want instead of creating quite OT thread...
I've said this before, but: Go open an RFC, if you really want lints moved into rustc. The team generally wants to keep rustc's lint footprint small, but you can try to convince them to import the really good lints. I have no strong opinion on this so I've never pushed for it (but I won't oppose it). Whenever you feel that there is a dissonance in the community like this, where it's a "if X, why not Y?" situation, open an RFC. Best case Y happens. Worst case you find out why Y can't. The clippy team itself has no problem with lints being upstreamed. ---- I suspect the reason is simple, rustc wants to keep itself small, for the same reasons we keep regex out of tree. The fix here is not to move clippy lints into rustc, but instead to make clippy easy enough to install and use that this doesn't matter. As I've already told you before, _the latter is already happening_, it just takes time. Many of your complaints in this space fall down once you realize that almost _all_ these tools are still WIP and there's more important things to be done before we work on making them visible.
 This subreddit is about Rust the programming language, not the game. You want /r/playrust.
[removed]
This makes me wonder: why isn't it? (Could it be?)
[removed]
But that ruins the performance aspect of specialization. The problem with using `FromIterator` instead of `From` on the List&lt;T&gt; is that when you pass a list itself it should be a non-op rather than expensively desconstructing and rebuilding a list piece by piece again. I basically want to write a function that takes `Into&lt;List&lt;T&gt;&gt;` where any iterator can be converted to a list but when it's a list itself it shouldn't needlessly go around deconstructing and rebuilding a list and just be a non-op.
Altough I agree with the general sentiment of your post I do have to point out that you should not generalize investing as it being all bad. It allows people with good ideas but no money to make them come true. People who have money and believe in those ideas can invest in those to make it possible.
[removed]
Anyone using rust for big data?
Should be easy to make a small script `cargo install clippyup` so that `clippyup` will fetch the latest known working version-nightly pair via rustup and cargo install.
Could you host the output of this in a github repo somewhere and make this into a `clippyup` tool? I'd add it to the clippy readme. https://www.reddit.com/r/rust/comments/691zxs/canonical_list_of_idiomatic_rust/dh4hkkh/
I don't think it can (at least not easily), since the following compiles today: let bar = move || { true }; If move was contextual, I don't think there would be a way to distinguish between a closure and a logical or in the line above.
I have heard secondhand of companies using Rust for HFT, more than once. I don't know which. Jane Street did sponsor RustConf so they may be using stuff internally.
It's not just keywords, the built-in symbols are even more annoying sometimes. Python has this problem where a great number of short, common, and often very appropriate words is already reserved. Here's a sample: id len set dict abs min max format input all any bytes dir filter map hash range list str If your linter doesn't point it out, you may end up shadowing one of those and be in for a surprise when you try to use the original later. (I know, static typing and all that). On a related note, C# has an interesting feature where you _can_ use keywords as identifiers: you just have to prefix them with `@`.
At least at the HFT where I work, we usually represent a significant percentage of market turnover (as do our competitors), meaning there's more liquidity with us than there would be without. The thing to note is that every time a retail or institutional investor trades with us, it's because we're providing a more competitive price than whatever the price would be without us (as if there was someone else willing to offer a more competitive price, then they'd be taking the trade instead). Imagine a limit order book, with the ask side (sell orders) looking like: 3@$73 8@$72 7@$71 5@$70 with those 5 orders at $70 all being our orders. The way exchanges work is that whenever someone places a buy order, it will trade with the most competitive offer/ask (which is the 5 orders at $70). Even if someone places an order to buy at $100, they'll still pay only $70 (unless they buy more than 5 lots, then they'll progressively trade with the less competitive orders at higher prices). So our 5@$70 mean that whoever trades with us is getting a cheaper price than they would otherwise.
Could've used the PHP approach and named it `implode` :)
http://rust-lang.github.io/book/second-edition/index.html
[removed]
[removed]
As I understand it: - Use a read-only bind account to establish a connection - Given a username/password, use this connection to search for the user's DN - Attempt to bind with the DN and provided password - If the bind attempt succeeds, the credentials were valid In this crate however, I noticed in `examples/compare.rs` there's password value comparison? We may have to wait for better docs.
&gt; There are two cases: Neither are use value. They exists purely because the means of production are privately owned, and the absence of them would make no virtually difference for the average man. &gt; By "voluntary" I mean free of coercion from other people. If nobody is threatening you to kill, steal, etc, your action is voluntary by this definition. It may be "least bad" action (yeah, work is often undesirable, but the other option is to die). I find coercion by other people highly immoral of course... I don't really care about this limited form of coercion. The end result is the thing I care about. If I said to you "do this or you'll starve to death", that _might_ not be coercion from your limited definition, but the end result is the same: you have one and only one plausible option. &gt; Self-ownership. That means you own yourself and I own myself. If I did own you, you'd be my slave. That's not moral or consistent. We are both human beings and none of us is more important than the other. Since you own yourself, you are entitled to products of your work. I'm not allowed to take away stuff you made against your will. The only way I could morally get your stuff is if you will give it to me - no matter if it's a trade or a gift. Even if you invent some clever way to work more efficient, or convince people that your products are worth buying. Self-ownership makes sense, yeah, but I don't see how private property follows, at all. If anything, self-ownership should mean that you have the right to the full value of your work, i.e. socialism. Also, it seems like a pretty reductionist view on the things. What exactly justifies self-ownership over the rights of well being for all? For example, what justifies you being extremely wealthy, while a billion people are starving? These people would not need to starve if the wealth was collectivized. &gt; I don't think there are only these options. If you are dissatisfied with your salary, you may end the contract and do something for someone else. If you can't find someone offering high enough salary, you probably need to improve your skills. Or think and find clever ways to increase your productivity. I would myself do it that way. I'd have hard time taking other people stuff against their will if I wanted more. I don't think it would be moral. Nah, I cannot. Even with welfare and what not, they would force me to take private jobs if available. Not complying would mean going to jail. As for starving, in the first world, you wouldn't starve, but you'd live a shitty life, e.g. homeless, and nobody deserve this faith. But in the third world (which we tend to forget in the west), there is only starving as an alternative.
&gt; However, I can imagine someone trading (pun not intended at first) little bit of performance for lower risk of crash. In HFT? We're literally scrambling to trim nanoseconds off the reaction time...
The problem of existing companies is that the code bases are already existing; and moving from C++ to Rust is not an easy transition due to the lack of interoperability. *Note: to those considering the C ABI as a middle-ground, I would expect most HFT codebases to be heavily templated to facilitate optimizations, and templates cannot be exported to C.*
I would recommend downgrading the version of postgres (-shared) to a version that uses serde_json 0.9.
Things like `cpu_move` or `generated_move` or `selected_move` seem perfectly viable. But yeah, it's annoying to have to dodge just `move` when you just mean `move`.
Hey, old LISPs had dynamic binding: you would name a parameter `length` and somewhere far away in code you called somebody would try to use the length function... Fun times.
This will have a different solution for library and binary crates. Since `postgres-shared` depends on either serde `1.0` or `0.9`, it can be forced into using serde v0.9 via `cargo update -p serde_json:1.0.1 --precise 0.9.10` - but there is no syntax I'm aware of that can encode this in `Cargo.toml`. The solution best solution here would be to downgrade `postgres-shared` to the version which depends on serde `0.9` rather than 1.0`. However it seems the crate made the change from serde 0.9 to 1.0 _in a point release (0.2.1)_. Unless I'm missing something in how cargo semver works, this shouldn't have happened. In any case, you need to either depend on the earlier version with `postgres-shared = { version = "=0.2.0", optional = true }`, or do a one-time force downgrade (which will be undone next time you run `cargo update`) with `cargo update -p serde_json:1.0.1 --precise 0.9.10`.
So this is an implementation of Wyland **protocol**, not the Wayland itself, right? Very worthwhile project. Perceptia seems even more interesting. :)
Seems like the old "if you think you understand Quantum Mechanics, you don't understand Quantum Mechanics." also applies to VIM. I've never known any veteran VIM user describe themselves as anything approaching expert. This includes chatting to Bram after a talk.
Wayland is only a protocol, so this is a library that can speak this protocol for use by window managers, like their Perceptia project.
I can't wait to see how things have changed from last year till now. It'll be eye opening to say the least.
`input` and `output`?
The standard library probably 
Alas, this is the compromise I must make.
Neither can we! We're super excited to hear from all of you. We got a lot of [great feedback](https://blog.rust-lang.org/2016/06/30/State-of-Rust-Survey-2016.html) last year that really helped to shape what we prioritized this year. We can't wait to do it again.
I know this isn't really the point of this being posted here, but does anybody else wish tiling window managers had (better) mouse controls? The way I can tile the panels on VS/Eclipse/(insert IDE here) is super intuitive, and I'd love to have it applied to a desktop on the whole.
&gt; Ideally this should never happen, but I think either I'm missing something or this was just an honest mistake. The problem is many people don't actually realize updating public dependencies is a breaking change that requires a major version bump. It doesn't help that there isn't really any documentation on this. 
For the "Do you or your company use Rust at work?" question a "Not right now, but we are investigating" would be nice - this is where my company is. edit: lol the very next page sort of covers this... but it's asking for something more definitive.
This doesn't seem at all possible with the built-in type `Into` - even if the core item was marked `default`, this blanket default impl would still conflict with it. I'd suggest just having `FromIterator` implemented, and then `From&lt;Vec&lt;T&gt;&gt;`, etc. implemented manually - people can still choose to use `From` over `FromIterator` when an extra optimization is possible. That's how the standard library does it in many cases - with `From&lt;String&gt;` implemented for `Vec&lt;u8&gt;`, `From&lt;BinaryHeap&gt;` as well, etc.
Is the vector the same actual length? Are you using, e.g., `vec![0u8; 262]` instead of `Vec::new()` or `Vec::with_capacity()`? If you want to read all data from the socket, use `.read_to_end()` (which takes `&amp;mut Vec&lt;u8&gt;`).
Works for me: use std::io::prelude::*; use std::net::TcpStream; fn main() { let mut stream = TcpStream::connect("towel.blinkenlights.nl:666").unwrap(); let mut buffer = Vec::new(); for _ in 0..128 { buffer.push(0); } let read_bytes = stream.read(&amp;mut buffer).unwrap(); println!("{:?}", &amp;buffer[0..read_bytes]); } Can you try creating a working example of the error? Were you perhaps calling [read_to_end](https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_end) on a socket that never EOF'ed?
For whoever is interested, there is actually a reason (other than lazyness) why on my [wayland bindings](https://crates.io/crates/wayland-client) are bindings to the wayland C library, and not a re-implementation of the protocol like skylane: OpenGL support. Mesa links to the wayland C libs and expects the client to give it pointers to C structs from this lib to initialize an OpenGL context. As such, if you want to support OpenGL, both client-side and server-side, you need to use the official C libraries. Which is quite a pain, as re-implementing the protocol is quite easier than binding over a C lib that has really not been designed in a rust-friendly way.
This is amazing, glad to see such a complete implementation. LDAP for corporate authentication opens up a lot of doors! Thank you!!
&gt; I see; thanks for the response, but I'm not sure how it supports the original statement that HFT is unethical. It might comfort you to know, for instance, that a lot of HFT is in markets for true commodities, such as corn, soy, wheat, precious metals, etc. Is it specifically the trading of stocks that you object to? HFT of trading actual commodities also seem to be _less bad_, but I'm still not sure what value it produces. Is trading commodities really that common? Isn't it just the means of product (e.g. stocks) representing them? I might be wrong, but afaik, the other is far more common. &gt; Not sure at all, in fact I think I was using it wrong. I am in the US, and many of my beliefs might qualify as socialism here, but apparently not under the more widely accepted definitions. It seems that to really be a socialist you must believe that all firms should be roughly evenly divided among their workers, or state-owned. Well, the common definition goes something like this: &gt; Socialism means that the workers own (hereunder gets the surplus value) and control (hereunder chooses how it should be run) the means of production. This is very different from socialdemocracy, which seems to align with your view better, since socialism is fundamentally incompatible with capitalism. Market socialism is not capitalists, as markets are not necessarily capitalists. Market socialism usually means something like the workers owning the means of production, but it is organized through markets. There are some issues with this model, but it does classify as socialism. &gt; I used to have thoughts along these lines, but there are a lot of practical difficulties (how do you raise capital for a long-term venture if you can't sell shares in your organization? will short-term thinking amongst your workers lead them to oppose any new hires? will it lead them to try to push out employees they think aren't pulling their weight?). It's a very interesting problem and I don't pretend to have the solution, but I'm not convinced that democratizing the means of production is it. There are certainly problems with socialism, but hopefully those are outnumbered by the problems of capitalism. For your particular problem, it seems that it is mostly a problem with market socialism, but even then I see two reasons why it is not an issue I) There is no "hire" under socialism, there is work, which means that you get to use a particular production means, but the control of it don't have to be direct, it could be through national democracy. II) Futhermore, you won't "hire" to create profit, but expanding your company is probably in your interest anyway (to be clear, we're talking about market socialism), as it makes it more stable.
I see. Thanks for the clarification.
You can use [`chunks`](https://doc.rust-lang.org/std/primitive.slice.html#method.chunks). in.chunks(3).map(|c| (c[0], c[1], c[2])).collect()
&gt; [...] but can't quite grok how to idiomatically do authentication in LDAP There's no one idiomatic way, but there are several customary methods. LDAP is enormously flexible and provides, on paper, a plethora of authentication configurations. The unsurprising outcome is that most implementations, including the one I've just published, support just the lowest common denominator. The universally supported method is authenticating (or _binding_ in LDAP parlance) to the server with what is effectively a username with LDAP syntax (_bind DN_) and a password. Clients which aspire to "enterprise-ready" status usually support Kerberos, by way of two API wrappers (SASL/GSSAPI). Notice that this covers direct authentication to an LDAP server. An application server can use LDAP as a credential store and provide its own authentication mechanisms.
&gt; You just pay a few fractions of a penny more, which gets gobbled up by a HFT firm. And this is basically irrelevant when you are holding stocks for years. Retail traders end up paying less nowadays since HFT brokers can offer slightly better prices than the exchanges to places like etrade and robinhood in exchange for exclusively retail flow. This price improvement happens since market makers can offer really tiny spreads on retail flow since it's basically risk free to make markets in and the price improvement is a way to compete for the business.
It seems I need let mut response: Vec&lt;u8&gt; = Vec::with_capacity(127); for _ in 0..128 { response.push(0); } self.socket.read(&amp;mut response)?; If I skip the pushing of 0s let mut response: Vec&lt;u8&gt; = Vec::with_capacity(127); self.socket.read(&amp;mut response)?; read fails entirely and when I try to access response[0] it is out of bounds. So do vectors need to be initialized like that? They aren't implicitly initialized? 
&gt; As I understand it [...] What you've described is one way that application servers may authenticate _their_ users, with LDAP as a credential store. Actually, Apache's [mod_auth_ldap](https://httpd.apache.org/docs/2.0/mod/mod_auth_ldap.html#authenphase) works just like that. &gt; In this crate however, I noticed in `examples/compare.rs` there's password value comparison? That's, well, just an example of using the Compare operation, not a prescription for authentication. I'll annotate the examples if their intended use is not entirely clear.
/u/Pimpus /u/d3b105b You might be interested in this post from the other day on r/emacs https://www.reddit.com/r/emacs/comments/67o5fp/resources_for_developing_major_modes/
I was the one who posted it ;)
For 1) LDAP is designed for "directory services", which is anything that requires lots of mostly-small, mostly-read lookups over a network. It's most commonly used for authentication because the infrastructure exists for it, but it's also been used for address book/contact manager systems, storing system information about computers (some DNS servers have LDAP backends), and... okay, that's about all I can think of.
Is it feasible to re-create the structs in Rust using `#[repr(C)]` and fill those out for talking to Mesa, or is doing that kind of fakery more trouble than it's worth?
And there goes the No Memes rule
And if you want to avoid initializing the memory… let mut response = Vec::with_capacity(127); response.set_len(127); // obviously unsafe
DependencyCI is very Git &amp; PullRequest driven. VersionEye is more generic and has a lot of native plugins for build tools and dependency managers which work well even without any Git integration. And beside that VersionEye is 100% open source and can be hosted as on premise instance as well. 
It's not really much of a barrier imo. If you want, your functions can have any names, just need to use some of that #![allow()] goodness. As far as standard library goes, I guess you will have to adapt :D
`TcpStream` implements [`Read`](https://doc.rust-lang.org/std/io/trait.Read.html). `Read::read` has signature fn read(&amp;mut self, buf: &amp;mut [u8]) -&gt; Result&lt;usize&gt; so it takes a *fixed-width* buffer. When you call it with `&amp;mut response`, you're giving it a type `&amp;mut Vec&lt;u8&gt;`, which isn't the type you need. Before the compiler gives up, it checks deref-coercions. You will see that there is [an `impl DerefMut for Vec&lt;T&gt;` which resolves to `&amp;mut [u8]`](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.deref_mut), so this will be called. Now, you'd hope that `vec![1, 2, 3].deref_mut()` returns `&amp;mut [1, 2, 3]`, rather than `&amp;mut [1, 2, 3, JUNK, JUNK, JUNK]` up to the internally preallocated capacity, which means that the coercion can't give you the whole underlying allocation, just the parts that have been written to. So you're calling `read` with a 0-length buffer, which means the function doesn't have anywhere to write to! Luckily `Read` has a fn read_to_end(&amp;mut self, buf: &amp;mut Vec&lt;u8&gt;) -&gt; Result&lt;usize&gt; which takes an `&amp;mut Vec&lt;u8&gt;`. This may be appropriate. If you only want to read a fixed amount, however, you should make a fixed-length buffer, such as with let mut buffer = vec[0; size]; socket.read(&amp;mut buffer); as that will `deref` properly. --- On your other question, the most idiomatic way I know of to consume a source is io::copy(socket, io::sink());
I'm surprised that nobody mentioned http://rustbyexample.com which partially respond to your needs. Maybe not enough "real code" but it's: - Community driven - Follow good practices - Well documented - Has small snippets of code - IMO has some things close to "real code" like [this](http://rustbyexample.com/std_misc/process/pipe.html) or [this](http://rustbyexample.com/std_misc/arg/matching.html) You can also find some interesting things in [rust-learning](https://github.com/ctjhoa/rust-learning) too, specially in blogs in "Famous Rustacean Bloggers" section EDIT: I forgot to mention [brson/stdx](https://github.com/brson/stdx) which "contains some of the most important crates in Rust". So you could take a look at all these repositories.
JSON-LD is a serialization of RDF. RDF is a flexible, very abstract format — it defines the concept of a graph of subject-predicate-object triples and that's pretty much it. Anyone can extend any vocabulary (like AS2) with anything they want. So I would *not* recommend trying to coerce an infinitely extensible format into static types. I've done that mistake actually :) Early versions of my [Haskell microformats2 parser](https://github.com/myfreeweb/microformats2-parser) tried to [do exactly that](https://github.com/myfreeweb/microformats2-parser/blob/67eed2ee7cf2c22e1e482cdd93f96feda88934cb/library/Data/Microformats2/Parser.hs#L149-L170) for, well, microformats2 — another arbitrarily extensible format, kind of a competitor to the RDF/linked data/ActivityStreams stuff ;) And I used these types in my [website engine](https://github.com/myfreeweb/sweetroll). It turned out to be a terrible mistake and I had to redo the parser to just [output a JSON tree like other parsers did](http://microformats.org/wiki/microformats2-parsing).
read_to_end hangs probably because the socket doesn't actually close after the bytes are sent in response. So for now I will just use the array rather than a vector, but in the future if I have a vector and receive bytes from a socket to write to it, what is the idiomatic way to do this? Is it let mut response = vec![0u8; 127]; self.socket.read(&amp;mut response)?; Or is there a better way to do it? 
Also, how should I discard the initialization bytes after the buffer is written to? I mean say I initialize a buffer of 127 0s and write 10 read bytes from a socket to it, what about the 117 0s afterwards that were not part of the sockets message? Do I need to keep track of bytes read to know the size of the message received, or what is the idiomatic way to deal with this? Thanks a lot everyone btw, I've been studying Rust for like 100 hours or something coming from C and just trying to get a feel for it. 
&gt; Can clippy be relied on to compile with rustc released on the same day or the next earlier release? If so, the logic should be rather simple. Not entirely reliably. Sometimes there's a nightly that's not yet on travis. But this is rare. But in general yes.
For the "If you summed the size of all Rust projects you work on, how big would it be?" question, if I've submitted a couple of patches to rust-lang/rust but don't do so regularly, should I choose "more than 100,000 lines", or the size of the projects I've been heavily involved in?
Ah, there's no auto-boxing happening so it's trying to use a primitive `int` where an `Integer` is needed. Somehow I thought the runtime would take care of that, but I guess it's the Java compiler. This works with the changes you suggested, so thanks a lot! I have to say that was one of the least helpful error messages I've encountered in a while! Seeing this workflow makes me think a higher-level interface is called for. Something like: let arraylist = env.new("java.util.ArrayList"); let added: bool = arraylist.add(55); And infer the details. Hmm.... 
Technically, yes. (And this is exactly what I asked as well!)
Thanks for taking the time to look over this. Looking at your code it looks like you parse into a less strongly typed structure and work with that. Is that correct?
For the first two, why are there two different forms of syntax then, are there no differences at all between the two forms? Thanks for the explanation on how 3 is different, that's good to know. As for 4, per https://github.com/rust-lang/rfcs/pull/1951 it is not approved yet but likely to be soon, and I'm curious how it would differ.
For the first two, the `where` form is simply there for convenience, as complex trait bounds can get really messy sometimes. The RFC you're linking makes `name: impl Trait` syntax for arguments equivalent to the first two forms as well.
Cool, thanks for the explanations.
So is there really nothing (like valgrind) to show allocations in a Rust program?
You can switch to the system allocator, so the valgrind can know about Rust allocations. Just add this on the top of your crate: #![feature(alloc_system)] extern crate alloc_system;
That cheat sheet actually does show which types use heap allocations, I should have said that. And of course, if you want to know if something uses allocations, you can always look in the source code. For example, for `Rc&lt;T&gt;`, I would go to the [documentation](https://doc.rust-lang.org/std/rc/struct.Rc.html), click on the ["src"](https://doc.rust-lang.org/src/alloc/rc.rs.html#263-265) link, then look at the definition: it contains an `Shared&lt;RcBox&lt;T&gt;&gt;`. `Shared` is just a pointer type (you can look at the documentation for that as well), so it doesn't imply an allocations. `RcBox` sounds like it's going to require an allocation. Looking at the definition of `RcBox`, however, you can see that it doesn't include any types that require an allocation (that part might be confusing). Looking at the `new` function for `Rc`, however, we can see that the `RcBox` value is itself allocated on the heap. So we would know that `Rc` requires one `RcBox` allocation, and the `Rc` type itself just contains a shared pointer to that allocation.
At least for Python it shouldn't be too bad. The Python ecosystem supports distributing pre-compiled packages in a format called "wheels", which the package installer `pip` just unzips in the the right location without having to execute any Python, let alone a C or Rust compiler. That works great for Mac and Windows, but on Linux it's a little trickier; since Linux-based platforms are so disparate, only wheels built for the [manylinux1](https://github.com/pypa/manylinux) platform can be distributed through official channels; there's an official CentOS5-based Docker image, and if you build inside that, you should be fine. Rust still works fine under CentOS 5 ([at least for a little while longer](https://internals.rust-lang.org/t/bumping-glibc-requirements-for-the-rust-toolchain/5111)), so that should work out fine.
If a struct can be ever used from either a public export (if a library) or the main method (if a binary), it will not be warned for. However, if something isn't used, nothing it uses is marked as used from it either. This prevents cyclical usages from making things which aren't used appear as used - but it can also make it confusing to tell the root thing which isn't being used. If you aren't ignoring any unused errors, you can remove all structs and methods it warns against at once and it will continue to compile correctly. If this isn't the case, that's a bug in rustc and should be reported. The only time I've ever had this error when removing all structs/methods wouldn't work is with a module that's accidentally shared between a `lib.rs` and `main.rs` (declared with `mod` in both rather than `mod` in one and `use` in the other) - and some types were only used by lib or main. Besides that all unused errors I have ever gotten have been completely legitimate. If you're alright with sharing your code in a gist or something, I could look through and try and help with your specific case.
Would certainly like to target Redox as a web server to start with. Currently hosting my pure-rust web service on a Linux system. Would like to get the pure Rust to go all the way down to the kernel.
Agreed. It's no different from `Vec` in that regard though.
If you're writing libraries, then things that are exported publicly, and anything they use, is counted as being used. Now, if you're talking about being in the process of writing libraries and not yet having exported anything, then yeah, it could be annoying. But you could just work around that by exporting things from the beginning.
Or "no, but a coworker snuck Scala in the year before last, so I'm just waiting for a good opportunity to pull it in".
It can be tricky knowing exactly what allocates in libraries, but almost nothing in std will do so implicitly. Closures never allocate unless you explicitly `Box` them, iterators avoid allocation whenever possible (the exception being things like `Cycle`, which cycles an iterator indefinitely, and _must_ allocate because it needs somewhere to store the items. Explicit allocations are also usually obvious - `Box` allocates, `Vec`, `HashMap`, `HashSet`, etc. allocate, `Rc`, `Arc` and `Mutex` allocate. In general anything that requires shared ownership will allocate so it isn't on the stack, any collection which has a non-fixed size will allocate. Closures don't have to allocate because they have a known size at compile time - the rust compiler knows what all each closure captures and creates an implicit struct on the stack. Slices are not heap nor stack allocated - they never create data. A slice `&amp;[]` or an `&amp;str` is just a pointer to either heap-allocated or stack-allocated (or program built in) data. A stack allocated `&amp;[u8]` for instance can be created with `let x: [u8; 128] = [0; 128]; let slice: &amp;[u8] = &amp;x;`, a heap allocated one can be created with `let x: Vec&lt;u8&gt; = vec![0; 128]; let slice: &amp;[u8] = &amp;x;`. I've never done any tracking at runtime, but it seems others report valgrind is usable with: #![feature(alloc_system)] extern crate alloc_system; in your crate.
Could you list the changes you would like to see in the cheat sheet? It is CC-BY, meaning free to remix. I'd love to see any needed fixes implemented.
It's possible: EGLImage allows you to set the framebuffer using some externally created thing, like another API (CL, VG, Another GL Context, etc). One of those external images are DRM Buffers. So instead of letting OpenGL manage the buffers you: Do the drm magic dance manually via wl_drm, create an Render to an EGLImage, use eglExportDRMImageMESA to get a GEM handle, create PRIME FD for the gem handle, send to server via wl_drm. (I think you can also create the buffer using gbm, import to EGL, and then send the prime fd to the server). Vulkan is a bit tenative... there's not extension for import/exporting DRM buffers. There is a special Intel function, that's not technically part of an extension but Intel's driver exports it. That can create a VkImage from a PRIME Fd (See VkCube's kms code for a example) Edit: magic vulkan function is `vkCreateDmaBufImageINTEL` in vulkan/vulkan_intel.h Edit: Also not that this won't give you Nvidia support, but probably work with Radeon/AMDGPU (I assume, need to test)
If your monitor can't shut down a system executing bad trades, its dead weight, not a monitor
PhantomData is basically telling the compiler that you have a type in a struct when you actually don't for purposes of static analysis. In this case, you're telling the compiler that Bar, for instance, holds a reference to Foo. The borrow checker will then enforce that Foo must always be alive while Bar is, since Bar is referencing Foo.
&gt; Truly performance critical portions happen in an ASIC or FPGA. Awesome, that is better than I expected.
Here is one. I had to use `unsafe` blocks and raw pointers for the mutating methods, because Rust's borrow checker isn't smart enough yet to realize that the code is safe. Hopefully some day this will work without `unsafe`, and then I can change the gist.
Why would deployment of Rust code be easier than Java?
A tutorial on Rust and Valgrind to track allocations would be pretty cool. Esp with output to flamegraphs [1] [1] http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html 
The problem has been identified and a fix should be integrated in time for tomorrow's nightly.
You answered 'yes' to a 'should I .... or ....' question. Does not compile. 
I've always said I'm pretty goo with vim but not an expert. But then when asked what's an expert, the only answer I can come up with is, anybody who knows vim better than I!
Sure it does! Boolean logic dictates that when the `x` in `z = x or y` is true, the whole `z` will be true regardless of the value of `y`. ;) _English_ on the other hand wants me to specify that I meant you should say you worked on a &gt;100k line project. **Edit:** I say that because I don't think the question is about the amount of code you have actively written, but the size of projects that Rust can scale to. I.e., check the &gt;100k mark to say that you were able to contribute to a project of that size. (Please correct me when this was not the assumption of the author of the question!)
It uses from_elem to implement the vec![value; length] syntax.
&gt; This doesn't seem at all possible with the built-in type Into - even if the core item was marked default, this blanket default impl would still conflict with it. Isn't that what specialization is for? &gt; I'd suggest just having FromIterator implemented, and then From&lt;Vec&lt;T&gt;&gt;, etc. implemented manually - people can still choose to use From over FromIterator when an extra optimization is possible. That's how the standard library does it in many cases - with From&lt;String&gt; implemented for Vec&lt;u8&gt;, From&lt;BinaryHeap&gt; as well, etc. That would require me to produce two functions of each like `List::append` and `List::append_from_iter` or alternatively rely on the consumer to call `list.append(vec.into_iter().collect())` all the time. So right now I just have another trait `IntoList` which is a non-op for lists but for other iterators must consume them and produce a list. So now I can do `list.append(vec)` happily.
Stop breaking my brain ;). Btw my logic professor told us 'or in spoken language is a logical xor' that blew my mind back then. 
They allow you to work on arrays generically. If you see documentation for array today, you'll see a lot of `impl&lt;T&gt; Trait for [T, 1]`, `impl&lt;T&gt; Trait for [T, 2]`... impls for some numbers are missing. Numeric generics would allow us to write something like this: `impl&lt;T, N: usize&gt; Trait for [T, N]`.
I imagine that it is easier to recognize (some subset of) bad trades than to come up with good trades. Worst case you monitor your profits and shut down when they are sufficiently negative. 
That seems like a good solution then. The reason I don't think specialization doesn't work for this is that it's only "two tier" to my understanding. You can have one default impl of a function that matches, and one non-default impl. There's the blanket impl in std, and then you want a blanket impl for IntoIter things, and then on top of that extra specialization, right?
No, you can have as many defaults as you want as you can see here, it always picks the one that has a more specialized type. https://is.gd/eDOKN6 The rule is just that the you cannot make a more specialized one "default" and a least specialized one normal. You can see in that playground that you can remove the "default" from the bottom one and everything wil be fine, but if you remove it from the others it'll complain.
I usually put `#![allow(unused)]` at the top of the file while I'm developing a new crate, and then remove it when things are more fleshed out. I think `#[used]`is meant for telling LLVM not to optimize away certain code.
Is there any kind of version linting tool for Cargo? I can vaguely imagine a tool where i say "i want to release the code in the current working directory as version 1.2.3, is that okay?", and it pulls the previous version of the crate from the repository and validates any changes in things like public dependencies, signatures of public methods, fields of public structs, etc. Is there anything like that? Would it be possible? 
From a memory representation point of view, &amp;str is a &amp;[u8] and String is a Vec&lt;u8&gt;. The difference is in the utf-8 guarantees.
OpenMP is really good for expressing simple parallelization. Compare the parallel Zip example from a recent ndarray release: https://bluss.github.io//rust/2017/04/09/ndarray-0.9/ to what it would be in OpenMP. The C/Openmp code would have more error-prone array-layout-specific indexing, and segfault when you screw it up instead of throwing an exception, but you can probably write it with your eyes closed at this point. And you have tools like gdb, valgrind, intel's toolchain, multiple different compilers to try, etc... that don't exist or integrate smoothly with rust yet. I think if you try implementing a few loops to have some idea what you're getting into, the right choice for you will be obvious. 
AFAIC, you can actually denote more complex bounds using where, like fn foo&lt;T&gt;() where String: From&lt;T&gt; (Example is stupid, but you get the point. Could have just bound T: Into&lt;String&gt;)
Isn't a simpler way to work around it just: #![allow(dead_code, unused_variables)] at the top? You can even put it over a specific item
I am working on a rust inspired VHDL alternative​. Gonna take rust all the way down to the metal
The most straightforward thing you can do is contact the owner of the package, and ask them to transfer ownership to you. There could perhaps be a rule where if the owner of a really outdated/useless package for which the name is in demand has been contacted by the crates.io staff, but they don't reply for a set amount of time, then ownership could be revoked, and made available to others.
&gt; Could you please clarify it for me? If I were to use Rust, I would either have to 1) use unsafe and raw pointers, therefore removing the only argument for using Rust compared to C which is safety No one suggested you write your _whole_ Rust program in unsafe, just the parts that need to be implemented in unsafe to be feasible, such as internals of containers (be it linked list or whichever). You write as much as is feasible in safe and the rest in unsafe, so that the unsafe parts are as minimal as possible and easy to test &amp; verify. This is how Rust works and has worked from the get go. It shouldn't be a surpriste for anybody. Besides, the standard library already provides vector, linked list, deque, etc. 
http://doc.crates.io/policies.html TL;DR, there is no policy.
Those warnings are there for a reason though, they usually mean you forgot to do something. Even in C/C++ similar warnings are often treated as errors. 
That is why you remove that declarative at the end and just leave it there while you're prototyping to avoid having to deal with annoying warnings
Right, you're talking about set union, but the parent's point still holds since that can be defined in terms of a logical *or*: A ∪ B = { x . x ∈ A ∨ x ∈ B }
So what you are saying is that "and" in logics is sort of the opposite operation to "and" in set theory?
I don't know what you are doing at work, but if you are not in embedded or low level programming, Scala is probably a more pragmatic choice.
I know at least one company that stores customer data (and they have millions) in LDAP. Like their contact details and in what contract they are.
`&amp;Foo` where `Foo` is a trait is a so called trait object. It's a type in its own right and it has to be behind a pointer because the type is not sized. How you should see `foo&lt;T&gt; (t : T)` as a function declaration is that it's a static generic. As in the compiler implements a different version for every `T` you call it with. If you call it with `usize` or with `Vec&lt;u8&gt;` the compiler will just automatically generate different versions for all those. How you should see `foo&lt;T : Trait&gt; (t : T)` or the equivalent form with `where` is that the compiler will only be allowed to implement versions for types that satisfy that trait. Because of this you are now free to use methods specific to that trait in the body which you can't if you don't restrict it, if you don't restrict it you can use nothing specific to the type. `&amp;Trait` conversely is an actual type so `foo (t : &amp;Trait)` will mean only _one_ version gets implemented. `Trait` is an unsized type so it must always be behind a pointer to manipulate it as it's a different size depending on the runtime info. Essentially what happens is that the thing you actually care about gets wrapped into an extra structure which contains some extra runtime info about it. It's more expensive time wise because it needs to be unpacked to reason about it and essentially implements dynamic typing but less expensive space wise because the compiler need not make a bunch of extra functions and dump those into the binary. Finally because `&amp;Trait` is an actual type you can use this as well when two arms of a branch need to be the same type. Rust mandates that two arms are always the same type. But say one arm returns a `String` and the other a `&amp;str` as but you really only care about `AsRef&lt;str&gt;` which both implement as a trait? Well luckily you can use trait objects: // this would be illegal let str = (if condition { returns_owned_string() } else { "&amp;'static str fallback" }).as_ref(); // this is legal let str = (if condition { Box::new(returns_owned_string()) as Box&lt;AsRef&lt;str&gt;&gt; } else { Box::new("&amp;'static str fallback") as Box&lt;AsRef&lt;str&gt;&gt; }) let str = str.deref().as_ref(); The first example is illegal because both arms have a different type even though we only care about that they satisfy a certain trait. The second example is legal as both are now the same type. `Box&lt;AsRef&lt;str&gt;&gt;`. Note that we had to use a Box pointer rather than a normal reference for lifetimes. A Box is just a normal pointer except that it takes ownership which is needed here to make it work. Values inside of a certain trait that are behind a pointer coerce to a trait object if the type demands it so you can use `as` or just pass them to a function to coerce them.
`String` is the other big one.
Absolutely, I just gave an alternative interpretation using "for" as a keyword to switch to seeing a set :)
More out of curiosity than anything, why? What is rust missing that Scala has?
A garbage collector and Java compatibility primarily, I'm guessing.