It might be interesting to make it so you read the results with `ron`, which should be pretty close to what they produce anyway...
I like it a lot but still want the option to parse urls from strings, if it doesn't exist still. Returning a Result would be fine.
Yes .url is still there and it returns Result.
Couldn't we `impl&lt;T&gt; Iterator for (T)` and `impl&lt;T&gt; Iterator for (T, T)` and so on?
Doh, indeed, that's a pretty stupid `--du` option.
rsync, FTP, same thing. They're both TCP. This is about limitations in TCP itself.
Whoa, great idea!
This guy has not even researched existing alternatives. I have a hard time believing none of the many projects designed to work around TCP limitations actually work.
Are you trying to make a case for the file forward iterators to seek(0) on construction?
I think you've got the wrong part of the stick. The closure owns `nums`, so what you're trying to do is return a borrow to the interior of the closure itself. This means the lifetime of `&amp;nums` has to be tied to the lifetime *of the borrow of the closure* which is made when you call it. The problem with this is that I can't think of any way of expressing this. If we were talking about a method on a type, it would look something like: fn get_nums&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a Vec&lt;i32&gt; { .. } But a closure looks more like this: type Result = &amp;'x Vec&lt;i32&gt;; fn call&lt;'a&gt;(&amp;'a self) -&gt; Self::Result { .. } Note that there's no relationship between `'a` and `'x`. For this to work, I think you'd need to have Associated Type Constructors (which we don't) *and* redefine the `Fn` trait. So... I don't think you can do this with a closure.
like /u/thiez I would be curious what you are missing from data classes in Kotlin, in Rust structs? 
Oh nice. It's like Data::Dumper in Perl. Super handy.
As a first step, I'd be happy if Rust dropped the mandatory `;`s. It's 2018, they are completely unnecessary, a huge waste of time, aren't even applied consistently, and require an unproportional amount of language lawyering to explain why they are a good idea.
Technically it only proves that the specific version of rustc that Mutabah reproduced (plus all versions of the compiler that used that version directly for bootstrapping) does not contain a trusting-trust attack. If one were extremely concerned about trusting-trust attacks, you'd want to reproduce Mutabah's result every single time that rustc upgrades its bootstrap version (which is once every six weeks), which would also require mrustc to be maintained actively and indefinitely.
Rust programs are native machine code with minimal to no runtime, just like C and C++, so they have the same performance characteristics. I expect the barrier there is organizational rather than technical.
1.25 doesn't use features not provided by stage 0. The build itself will have improvements in optimisations and in the backend in general but won't use new features
Or a struct so that you have the type name: `Vec3(f32, f32, f32)` (there are a ton of options aren't there)
That's a good question. The Rust developers have agreed to allow version (n-1) to build version n, for this very reason. Otherwise, it would indeed be impossible to compile a version of Rust that simultaneously introduced and used a new language feature.
True, more accurately, "Rust has not had a latent trusting trust problem since its outset."
can you point me to the file that does the optimisations?
&gt; which would also require mrustc to be maintained actively and indefinitely Not necessarily, after you make the first rust binary using mrustc (and have verified the code), you can trust that version of rustc, which you can then use to verify the next version, and so on. But it would require keeping your own version of the binary up to date, and verifying that the source code itself doesn't have malicious code for each version.
Yes but there are a lot of target LLVM does not support while nearly every target has a C compiler.
Indeed, but even though needing to audit [every single rustc commit since Rust 1.24] may be better than needing to audit [every single rustc commit since 2010], having the property that your code is free of trusting-trust attacks (IOW that the source code that you're compiling corresponds to the binary that you receive) is a stronger guarantee still, but requires you to continually reverify your bootstrap.
A few that we've started with: - https://github.com/Cretonne/cretonne/blob/master/lib/cretonne/src/preopt.rs - https://github.com/Cretonne/cretonne/blob/master/lib/cretonne/src/licm.rs - https://github.com/Cretonne/cretonne/blob/master/lib/cretonne/src/simple_gvn.rs and of course there's [register allocation](https://github.com/Cretonne/cretonne/tree/master/lib/cretonne/src/regalloc) (docs [here](https://cretonne.readthedocs.io/en/latest/regalloc.html)), which is tasked with performing several optimizations.
I'am porting my gnome 3 extention for totp to i3wm (should works on other wm). I've release the 0.1 version after 3 hours of coding. https://github.com/mardiros/totp_clipboard Working on the configuration windows using relm.
Sorry if I myself sounded hostile to you, it wasn't my intention. I have by far the most experience with C, which is why I used it as a standard of comparison. Seemingly, this is a bad thing to compare other languages to. 
That's true, llvm needs to be available on the target... You're right.
It’s funny but I can’t tell how to use it from the documentation vis-à-vis the setup function. 
&gt; But who knows if general attribute macros will allow replacing the annotated item. That's exactly what they're designed to do. This can be implemented for statements with `proc_macro_attribute` right now using only the `proc_macro` feature which is on the path to stabilization (attributes on expressions are unstable under a separate feature flag because their semantics aren't defined by RFC yet). I've been slowly chipping away at the blockers but there's only a couple other people working on this bit and I've [had trouble building Rust on my machine lately](https://github.com/rust-lang/rust/issues/49869). However, I don't see any reason why proc macros can't be stabilized by the end of the year or even sooner.
But they have an [actual purpose in Rust](http://lucumr.pocoo.org/2012/10/18/such-a-little-thing/), instead of just being there as a line/statement terminator for the compiler.
"low latency" tends to be code for high speed gambling, i am not sure that is a fulfilling or worthwhile job. that said, rust can be and is used for that.
When implementing `Derive` yourself, you should use the `Formatter` helper method like `debug_struct` if possible. This give you this pretty printing for free.
That's a harsh description of high frequency trading, but I won't complain.
Rust can and is used in low-latency environments. Many companies are not very open about that, though, which is why we have no reference customers.
Thank you so much, I did not know about this and spent 30 minutes looking at a (debug) dump of 36 vertices to find the problem yesterday. If I had known about this, I wouldn't have to look so closely. 
Apart from the absence of inheritance in Rust, data classes on the surface appear to be very similar to a struct with derives: #[derive(Debug, Clone, PartialEq, Eq, Hash)] struct MyData { pub field: String, } We have automatic implementations of identity functions, Debug (`toString()`), and destructuring.
Absolutely! I'm currently using rust for a cross-platform, real-time spatial audio server (100+ channels) for an exhibition contract in Melbourne and it has been a great experience. I have had to make some contributions to CPAL upstream, but that is only because I prefer to use pure rust libraries wherever possible rather than C bindings and I'm happy to contribute upstream if it will make this happen.
Ok c++ low latency salaries are like 150k usd. If i do rust will i get close to that?
I have no idea about salaries - I've only worked in software as a contractor. I'm sure if your algorithms, productivity, collaborative skills and ambitions are up to scratch then you could do quite well :)
It's equally suitable as C++. Just remember that not having a GC doesn't mean there can't be pauses when using the heap. I don't believe the default allocator in Rust, jemalloc, provide any guarantees on maximum runtime for a malloc call.
Yeah, sort of like the decision on when to inline, it seems like a profile-guided optimizer could probably do a good job. It's just that some early Rust blog posts would talk about using generics vs trait objects as way for the programmer to pick between static and dynamic dispatch (example: https://blog.rust-lang.org/2015/05/11/traits.html).
I'm not forgetting about it, it's a great project too :) I have some additional ideas to test with wasm, once I get to JIT compilation, to try and run them in a very lightweight virtual machine, without even an OS.
`[&amp;T]` should be enough to convey that all the elements reference a value of the same type, right? For example, the "normal" way to do this: fn f5&lt;T: Trait&gt;(elements: &amp;[&amp;T]); The hypothetical `dynamic` marker isn't intended to change. It just tells Rust to pass an implicit vtable argument instead of compiling a separate copy of `f4` for every instantiation of `T`.
Continuing to work on [lila-tablebase](https://github.com/niklasf/lila-tablebase), a chess endgame tablebase server based on actix-web.
I'm curious about what it takes to support Rust if you already have a working llvm backend that is able to cross compile C programs? At work we have a proprietary core (not ARM) with a working llvm backend (for C). If adding support for Rust is not too difficult, I would be interested in having a go at it.
why not NEON?
I'd think it is because x86 gets the widest use and testing, so the devs are most confident about stabilising it first. Arm will probably be next, after it gets some more testing, but it is good not to rush things. Now that the fundamentals for SIMD support are there, the different architectures should come to Rust fairly quickly in the future.
Has it been considered to add this functionality to the language?
It would be pretty awesome if [Ron](https://github.com/ron-rs/ron) was able to parse this
I believe Rust can be used in place of C++ for any usage. In other words I can't think of a single trait of C++ that makes it really more suited than rust for a given task.
What's the progress on `std::simd`? (can't seem to find the tracking issue)
See the [Y2K issue](https://github.com/rust-lang/rust/issues/44580).
No progress, as far as I know. It's somewhat implemented, but has no RFC yet.
oh nice! By the way, is there a good way to express voltage in uom?
Submitted a [PR for FreeBSD support in u2f-hid-rs](https://github.com/jcjones/u2f-hid-rs/pull/62)! (And for that, released [devd-rs](https://github.com/myfreeweb/devd-rs) 0.2 now without the `nix` dependency.) Received a few nice PRs to [systemstat](https://github.com/myfreeweb/systemstat) for Windows things. To help test them, updated my local buildbot cluster and added a Windows machine to it. And some [weston-rs](https://github.com/myfreeweb/weston-rs) progress: the example compositor now supports resize and brings clicked windows to the front.
How does running wasm not in a browser make it serverless? I don't quite understand.
That's a great moment for a 5 minute pull request or at least opening an issue. ;) (also to the upvoters) https://github.com/yoshuawuyts/human-panic/pull/11
Aww, that's a real shame, `hlua` is really quite an interesting and clever approach on how to make Lua fit into Rust idiomatically. It's a very cool idea to think that it's possible to make an API that aims for actual safety while generating "idiomatic" Lua C API calls, even if that approach leads to certain limitations. I feel like I've been a bit too harsh on `hlua`, so I'm gonna try to both explain why I made a competing library and also explain why I think `hlua` is still cool. First, let me summarize the situation as I understand it. I'm not intimately familiar with `hlua`, so I may have some of this wrong, and if I do feel free to let me know. Because of the way the Lua C API works, it's extremely difficult to come up with a type safe high level interface to Lua, saving the user from having to interact with the Lua stack directly. There are no handle types in the Lua C API of course, only pushing and popping from the stack and manually keeping track of stack indexes. When you try to map Rust variable lifetime to the lifetime of a value on the stack, you immediately run into an obvious problem, which is that stacks are FIFO structures, and this does not match Rust variable lifetimes at all. A simple example: ``` let t1 = lua.create_table(); // Push a table to the stack with lua_newtable let t2 = lua.create_tabe(); // Push a second table with lua_newtable // Lua stack is now [t1], [t2] /* There is no sensible way to match this to the Lua C API, because the stack should be [t2], ["entry"], [t1] before calling lua_settable. You could manage this by pushing copies of t2 and t1 where they need to go at the top of the stack and then popping them back off before returning, but this leads into the bigger problem which is that t1 should be *removed* from the stack on this call. Besides the fact that removing values from the bottom of the stack is costly because it requires shifting values above it, it also would change the stack index of t2, and the Lua bindings system would be forced to keep track of this manually. */ t2.set("entry", t1); ``` This interaction with the Lua stack is sort of the fundamental design problem of any bindings system to the Lua C API. Most bindings systems use the safe, slow approach of keeping handle values inside Lua's registry and doing a LOT of extra stack / registry manipulation. Typically, the Lua instance would not keep values on the stack in between calls at all, but instead when `t2.set` was called it would go find t1 and t2 in the registry and do all necessary stack manipulation at the time of the call. `hlua` takes an entirely different approach and tackles this head on with Rust's type system, limiting what you can do so that you can't run into this problem in the first place! When you create a table value in `hlua`, just like when using the Lua C API, it's simply pushed to the top of the stack. However, what you get back is a `LuaTable&lt;PushGuard&lt;&amp;mut Lua&gt;&gt;`, which locks the parent Lua instance from further manipulation. Becuase of this, inside methods to `LuaTable`, it can freely assume that the correct table is at a known place in the Lua stack, eliminating the need to constantly push values from the registry or store return values into the registry. This solution is also a problem, however, because every new type that needs to manipulate the stack must have its own &amp;mut Lua (actually an instance of `AsMutLua`, but it's the same idea), and this of course must be unique. So `hlua` solves this problem by sort of creating new ones, which is that you are very limited in what you can do (but what you CAN do will generate more or less the Lua C API calls you would expect). The reason that I made `rlua` instead of contributing to `hlua` was more or less directly because of this limitation. I looked at the kind of API that we made for Starbound and sort of decided that it would be either impossible or very very onerous to write an API like that using `hlua`, and that the changes I'd need to make would probably be a little too fundamental to be welcome. `rlua` started out being based on the Lua registry like other bindings systems, and this was of course predictably, depressingly slow. I've since found much better approaches, but it is never going to be as fast as idiomatic C, or `hlua`. Unfortunately (or fortunately, however you look at it), if I were to add the necessary safety measures to `hlua` it would ALSO never be as fast as idiomatic C, so the difference between `rlua` and `hlua` you take safety into account is not actually so huge anymore :( "idiomatic" Lua usage from C is just to live with the fact that you *probably* have enough stack space without calling `lua_checkstack` and Lua *probably* won't longjmp on you at a huge number of places, but you're already in C so you don't mind as much :P. I tried to come up with the quintessential "I need this but `hlua`'s approach makes it impossible" example to further explain my reasoning, but in doing so I think I found a bug in `hlua`: ``` extern crate hlua; fn main() { let one_table = |a: hlua::LuaTable&lt;&amp;mut hlua::InsideCallback&gt;| {}; let two_tables = |a: hlua::LuaTable&lt;&amp;mut hlua::InsideCallback&gt;, b: hlua::LuaTable&lt;&amp;mut hlua::InsideCallback&gt;| { // Here lies unsafety, as `a` and `b` both hold a &amp;mut Lua. }; let f1 = hlua::function1(one_table); let f2 = hlua::function2(two_tables); } ``` I believe this is not supposed to compile, but unfortunately DOES compile so I wasn't exactly able to use that as my example.
the serverless part is more about running very small, self contained applications without caring about how they are launched, how many instances there are, etc
Whoops, you're right, that would have been a good idea! I plead forgetfulness rather than laziness :p
Why do you mention Garbage Collector? Neither C no C\+\+ uses GC \(by default, though you can get libs to add on GC\). Nor does Rust use GC by default. It would be helpful when you are asking questions about something to try to get your facts straight first; otherwise, your question comes off as somewhat meaningless and difficult to parse. I'm not sure what you are even trying to say with your sentence on GC.
&gt; Is the diamond inheritance problem relevant in Rust? it's irrelevant because traits (and hence fat-pointer trait objects) avoid it
Not yet*, but there is an issue to add it: https://github.com/iliekturtles/uom/issues/74 * Technically voltage, or any quantity, can be represented, but it isn't ergonomic until the quantity has been explicitly added.
I actually like this style, I actually use it in the other languages that I program in. The only thing I would do different here is indent the guards and the bodies of the match by one indentation level.
Ok. How do you know all this? Any proof?
Is there a tracking issue with tasks to pick off?
Thanks so much for explaining! I have to get around to finally have a look at rlua. You mentioned rewriting the interpreter. I realize the lua is rather small, but still wonder how much work it would be to make such rewrite in rust. Is the original lua interpreter heavily optimized, or is it more or less a simple beast (modulo the error handling and longjmps)?
Maybe you also meant this, but I'm sure its due to the concerns of lack of Rust programmers and the cost.
Yay for macro support! What I really want to see next though are some serious performance improvements. Compared to VS Code with the RLS plugin, Intellij-Rust can be painfully slow. A few days ago I tried the VS Code route again after using Intellij (and lately CLion) for months and I like it a lot. Currently using VS Code mainly because when I type something up all the error annotations and type inference updates within one or two seconds. In Intellij-Rust it's been very unpredictable for me, sometimes it updates within 2-3 seconds, sometimes it takes 10-20 seconds to update. I do miss a few features in VS Code though, like the automatic Impl generator and a few other Alt+Enter intents and quick fixes.
I guess it's a typo.
No problem. It's amazing how well our brains work in these contexts :D.
Depends. Can you actually do low latency programming? It requires you to be meticulous about the details, which Rust also enforces you do safely as well.
Yeah, it was renamed because people kept mixing it up with the JS UI library.
There are over 5000 neon intrinsics, and it seems that only a couple are implemented on nightly, so... probably because nobody has bothered implementing these yet.
f8 is not an IEEE-754 floating point type so your f8 and my f8 are probably going to be different, and none is objectively better than the other
should this be "When implementing `Debug` yourself"?
Yup, was about to post to say this. [Lots of good stuff there](https://doc.rust-lang.org/stable/std/fmt/struct.Formatter.html#method.debug_struct) that not many folks know about there!
Thanks for the detailed explanation :) &lt;3 The limitation you're talking about can theoretically be bypassed by introducing runtime checks. All my work on hlua was unfortunately restricted by several compiler ICEs (I guess that's what happens when you use rarely-used features such as HRTBs), and I haven't taken the time since then to work on it and fix all its problems. 
To be fair, any job in trading is just gambling. There's just different speeds at which you can do it. 
If the llvm backend is in the mainline, as far as a I understand, most of what is needed is providing a target definition. If not, you probably have to recompile rustc with a different backend. In any case, we have people that can guide you through the process on all levels, so I would recommend you to get in touch with the embedded team, or, alternatively, the community switchboard (commmunty@rust-lang.org). We'll get you in touch.
This is the best thing I could find. https://www.reddit.com/r/rust/comments/5ag60z/how_do_i_bootstrap_rust_to_crosscompile_for_a_new/d9gdjwf/ Otherwise you might want to ask the avr or riscv guys how they are doing it.
Hi, I am in the process of learning Rust, and I published this crate in the hope that it will be useful. The dictionary is a very simple wrapper of std::vec, extended through traits. I also thought about using newtype + Deref but in the end it seemed unnecessary. Efficient insertion would require some work because we are holding an ordered vector. This would be the next thing to improve. Feedback/PRs/opinions are welcome :)
When we beat C++ in the benchmarks?
Hey! I also coded a mix between `du` and `tree` in rust, [check it out](https://ownyourbits.com/2018/03/25/analize-disk-usage-with-dutree/)
This is also a great method for pulling down dependencies in source form so that you can fix issues or add features to the dependency. Cargo makes it so easy to contribute back to upstream projects.
**Multimap** In computer science, a multimap (sometimes also multihash or multidict) is a generalization of a map or associative array abstract data type in which more than one value may be associated with and returned for a given key. Both map and multimap are particular cases of containers (for example, see C++ Standard Template Library containers). Often the multimap is implemented as a map with lists or sets as the map values. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
&gt; the HashMap requires a one-to-one relationship between the key and the value, while a real associative array should allow you to have repeated values for different keys Huh? [play](https://play.rust-lang.org/?gist=cbf92b4cd040518b906bd1c0a43cc110) let mut map = HashMap::new(); map.insert("key1".to_owned(), 1); map.insert("key2".to_owned(), 2); `HashMap&lt;Key, Value&gt;` is not one-to-one; there is no restriction on multiple keys having the same value.
Awesome that looks very useful. The backend is not on the mainline, its just an unmaintained in-house branch, so I'll have to make it up to date first.
I see, I stand corrected! I could swear that's what I saw when I was testing it. Does anybody know what is the efficiency of retrieving values from the HashMap? In my implementation I thought about holding an ordered list, and using binary search by the hash of the key Thanks!
I see, thank you. When I was playing with HM it didn't look like that. In my implementation I thought about holding an ordered list, and using binary search by the hash of the key. Do you know what is the efficiency of the algorithm to retrieve values in a HashMap? 
It's not on the mainline, just an old in-house port. But thanks for the advice, at least I know where to go if I get stuck
Just curious why does someone need to handwrite simd?
HashMaps have O(1) complexity for retrieving items by their key. How expensive that action is in absolute terms depends on what kind of hashing algorithm is used.
Because the compiler might not always be able to to the conversion itself.
I log once every decade here today and have exactly one message :D Shouldn't you be working? :P
The benchmarks game is not accepting new benchmarks because it is being shut down so... tinfoil hat on: conspiracy!
Thank you for the info. 
I would personally be careful about using failure. There were reports about failure slowing down a program up to 30x because it generates backtraces on every return (i.e. every time you use the "?" operator). However I do not know if this was due to a bug or because it is how failure is designed. Just wanted to warn you because it may not be the best choice for a high-performance video game. https://www.reddit.com/r/rust/comments/7te8si/personal_experience_can_cause_hard_to_notice
I don't fully agree with you. Depending on the country (we see a BIG bias on US contracts on r/rust ) your language of choice might be relevant. The higher the pay the more it is true IMHO. When looking for a candidate the language is definitely not the primary driver but having someone at ease with many languages is a plus. rust in particular, proves that the candidate is willing to try new things, to explore beyong what is being thought. If he proves that he understands the core principles between each different language then he has a very good start. Rust is (sadly) notoriously hard to learn and you cannot do it quickly for an interview (if you manage do do it then you're good for the position anyway) so it kind of proves your motivation/spirit. I was just hired in a company that pays (very) well and if I am given the choice of will probably hire for rust developers just so it sets the bar to a minimum level.
I didn't know that, was it announced [here](https://benchmarksgame-team.pages.debian.net/benchmarksgame/sometimes-people-just-make-up-stuff.html)? What does it mean/
Looks like someone read http://0x80.pl/notesen/2018-04-11-simd-is-sorted.html too :)
I read it on reddit :/
&gt; The higher the pay the more it is true IMHO. Maybe it depends on the region. My personal experience and that of my colleges/friends (which is a tiny sample) agrees that the higher the pay, the more requirements the job has on the candidate beyond just the language, and the more qualified the other people interviewing for the job are. In any case, I'm looking for a job, so if you are hiring Rust/C++ devs in central europe maybe we can follow up on pm :P
Something like this? Response::builder() .status(302) .header("Location", "https://www.rust-lang.org/") .body(()) .unwrap();
I live in Colorado, me and my friends are in the mid $100ks for jobs, across several fields, none of which are finance. From tiny startup to megacorp. Reasonable cost of living too.
&gt; 5 minutes into the interview: it seems that you know C++ very well (check). Design, implement, and test an algorithm for scheduling processes in a POSIX-compliant operating system's kernel, you have 30 minutes. [30 minutes later...] Here is this NP-Complete problem, we need to solve it quickly for this particular kind of inputs: design, implement, and test a solution for doing that, you have 30 minutes... [30 minutes later...] You have 30 minutes to design Shazaam from the front-end to the backend... [30 minutes later...] (you get the idea) So they essentially want you to do the work that is the culmination of many years of research/engineering from many top scientists and engineers within an hour an a half?
That would be great! At the moment the text soup is rather obscure :(
&gt; I expect the barrier there is organizational rather than technical. The barrier is technical, not organizational. 1. Rust still lacks a number of features that may not be necessary but are very much appreciated: const generics and CPU access. `std::arch` is coming, but const generics are still a way off. 2. Existing code bases are in C++ for all the companies I know of. In my case, C++17. Heavily templated. Integrating Rust in there is non-trivial. I would expect that Rust *can* be used, and I would expect an uptick in usage once (1) is obsolete. However integration with existing codebases will remain an issue, making Rust more suitable for small stand-alone executables or isolated pieces at the beginning. With time...
It's extremely fulfilling on the technical side ;) As for "morals", well, any company's goal is to make money, and from what I've experienced or seen from "products" company, money is regularly prioritized over customer experience :/
&gt; a lack of mature libraries that are also stable and tested; companies like trading firms really like stuff that's 1.0 and has been heavily used, and C++ has just been around much longer. Depends. For non-latency-sensitive stuff mature libraries are relevant, but then there's not much reason to use Rust or C++ there. For latency-sensitive stuff everything is in-house, as it needs to be tuned, allocation-free, etc...
Which also means you need 25 iterations to compile Rust v1.25?
Auto vectorization is for the most part terrible. I've been working on some code the last few days to get the auto vectorizer to kick in (gcc and ICC), and it is impossible unless some very specific requirements are met and written to. If you know the instruction set, it is often easier done by hand.
There are multiple reasons! **Information** The compiler might not use SIMD because it would produce a different result in edge cases or because the transformation is only safe if some pre-conditions it cannot verify are met. For example, the `__builtin_clz` in GCC can only be used on non-0 inputs otherwise the behavior is undefined. As another example, some instructions require aligned inputs (16 bytes) but your function may only take a `*const u8` which could have an alignment as low as 1 byte. Finally, there are also concerns with aliasing/purity. Some transformations may be blocked because the compiler cannot prove that two arrays do not overlap or that a function is pure (and will not panic/modify the input). **Pattern not encoded** Compilers are gigantic pattern-matching engines. If nobody coded the particular transformation you need in the compiler, then it's not going to pull it out of thin air: you're stuck. **Cost estimation** Compilers have cost models implemented, and may judge that a particular transformation is not worth it. They may be wrong. They may be right in the general case, while the function of interest only deals with one of the edge cases. **It's not just about SIMD** Finally, while SIMD is the catch term of `std::arch`, actually it's not JUST SIMD, it's about exposing CPU instructions as intrinsics, some of which have less to do with efficiency and more with low-level access to previously unexposed CPU functionality. 
I can't imagine what an address-handling library would look like, but someone who is making one should read this: https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/ Not sure what conclusions should be gathered from that information, though. On one hand: &gt; Any attempt at validating an address will be fooled by the real world. You should just give your users a single text box `Address` where they put whatever is necessary to mail them something. But practically speaking: &gt; Some level of address validation is required so that users don't forget to put all their information in. Getting a message two days later from the post office that the address for a package doesn't have a zip code and is being returned is more problematic than rejecting the &lt;1% of (your) customers who have some bizarro address. &gt; Addresses are used to integrate with 3rd party APIs and databases, which assume a specific format. If your payment processor makes poor decisions about address validation, congratulations now so do you. My personal takeaways: - Zip codes are not integers - Don't write software which handles addresses :P
You aren't reading `a` before replacing its value in the loop. Since this could indicate a logic error, Rust warns you about it. In Rust, you can declare variables without having to provide them with a value, provided that they're guaranteed to be provided with a value before they're read. That changes the program to fn f() { // Generate Fibonacci Sequence let mut a; let (mut b, mut c) = (1, 0); for _ in 1..10 { a = b; b = c; c = a + b; println!("{}", c); } } which doesn't generate any errors.
A trading firm isn't going to use more than two languages overall. In fact, I don't think the trading code is anything other than C++, even when it's not latency sensitive. People prefer to use the same language everywhere. 
Hey rustaceans! So I have a struct in which I store a vector of bytes. This struct is called PixelBuffer. I would like to implement a function for it called pixels, which will return an iterator, which will iterate over the bytes, as Pixels (It would jump as many bytes as many components there are in a pixel, and then construct a Pixel from it, or give back a reference to the buffer as a pixel maybe). How can I achieve this? The other thing which would be cool, if the pixels, would only have to implement a trait, called Pixel, so It would handle the ordred and the number of components in the actual implementation (bgr, rgb, rgba stb...). So PixelBuffer should be a trait, and Pixel should be a trait, and implementors of PixelBuffer should specify on which pixel implementation does the PixelBuffer works with. Here is the repository of my work in progress of this concept: https://github.com/AradiPatrik/mini_renderer. Am I trying to make my code too general, or is this the way to go? Any input would be apriciated :)
I went through `vperm2i128 + palignr` first, and then moved on to unaligned loads afterwards. Unaligned loads were not only much simpler and straightforward, but also faster -.-
Looks like a decent comparison to me. Most confusing point is 1.5 for memory consumption.
So rust doesn't know for sure if you are going to edit this value because *it can't see inside the loop*? I'm a little sad its not as clean looking but this solved my problem so thanks very much! :)
libpostal (https://github.com/openvenues/libpostal) is one of the best libraries for that. No rust binding yet that I know of, but it's just a `bindgen` call away :)
Can you say more? They seem like orthogonal things?
https://crates.io is your friend. :) I found the [`emailaddress`](https://crates.io/crates/emailaddress) crate, whose README you should definitely take the time to read in full -- it's in the same spirit as /u/mattico8.
Basically you can emulate SSE `palignr` on AVX2 by doing a `vperm2i128` first: https://software.intel.com/en-us/blogs/2015/01/13/programming-using-avx2-permutations
Let me debunk a few myths, then :) The [trading firm I work at](https://stackoverflow.com/jobs/companies/imc-financial-markets) uses at least 4 languages extensively: - VHDL: for FPGA design, - C++: for highly latency-sensitive parts, - Java: for less latency-sensitive parts, - Python: for offline analysis. From experience talking with developers at other firms, I'd expect at the least the first 3 to be rather common; maybe not those exact 3, JaneStreet is famous for using OCaml for example, but in my experience HFT firms are anything if not pragmatic.
If rust knew I changed the initial value in the loop then I'm not sure what the warning message would be for then. Its not really clear to me why `b` and `c` work just fine but `a` doesn't. (I'm really new to rust so sorry if this is obvious)
You can emulate SSE `palignr` on AVX2 by doing a `vperm2i128` first to produce a modified second operand for `palignr` that has the first opperand appropriately shifted in: https://software.intel.com/en-us/blogs/2015/01/13/programming-using-avx2-permutations (this link is golden). 
The way I was using SSE `palignr` is to shift by `n` bytes a vector that I read from memory, so with unaligned loads I just offset the address of the read by `n` bytes, and directly read from it. The way SSE `palignr` can be emulated on AVX2 is by doing a `vperm2i128` first to produce a modified second operand for `palignr` that has the first operand appropriately shifted in: https://software.intel.com/en-us/blogs/2015/01/13/programming-using-avx2-permutations 
The cause is likely jemalloc, which I think takes a bigger chunk by default, regardless of what your program does. If you use the system allocator, you should notice a reduction in minimum required memory. (With that said, I don't know why 5MB was their cutoff.)
I don't think we're in disagreement here. Where I work (a few blocks away from you, I think!), we also use the exact same ones, but we tend to use C++ for both highly latency sensitive parts and for non latency sensitive parts (I believe we have Java in some places but not everywhere). For us to move to Rust (which would probably never happen at this rate) would require ensuring that anything we do in C++ could be done in Rust, which is almost true but entirely true because we're just very slow and cautious with how we use our dependencies. It's hard enough just to update the compiler everywhere.
`b` is already used in `a = b` and `c` is the same way when `b = c`. You used value of `a` and assigned it to `b`. Same logic for `c`.
&gt; Finally, while SIMD is the catch term of std::arch, actually it's not JUST SIMD, it's about exposing CPU instructions as intrinsics, some of which have less to do with efficiency and more with low-level access to previously unexposed CPU functionality. Just to add a bit to this. Before, if you wanted to check the `EFLAGS` register, query `cpuid`, or, for example, save the contest of all registers to memory (e.g. because you are implementing a coroutine library), you had to write assembly. Now you just call some of the `std::arch` intrinsics that do this for you.
Ah okay, now I get it!
&gt; It's hard enough just to update the compiler everywhere. :( &gt; For us to move to Rust (which would probably never happen at this rate) would require ensuring that anything we do in C++ could be done in Rust, which is almost true but entirely true because we're just very slow and cautious with how we use our dependencies. We regularly hit issues with C++ which would not be issues in Rust (from inscrutable compile-time error messages to mystifying crashes in production), so on this side Rust would be a clear advantage. However, justifying using *two* languages in parallel with the same performance/capabilities is tough, cost-wise. There's an overhead to adding a new language to the mix, overhauling the whole codebase is obviously out of question, ... so it's not clear that Rust technical advantages would be sufficient to tip the balance even if integration with C++ was straightforward (and it's not). I still hope, at some point, to pitch the use of Rust. I am however bidding my time until I estimate that Rust can indeed do enough not to be rejected outright :)
That one bites hard. It happened two months ago for me, a rainy day. I started doubting the pain will ever fully fade away.
Ha! Don't worry, I have an understanding of what I'm getting myself into. A address string can best be thought of as a ordered list of tokens. For example: "1234 W Corbert Street, Townville, Colorado, USA" can be tokenized as follows: street-number: 1234 street-pre-direction: W street-name: Corbert street-post-type: Street location: Townville state: Colorado country: USA Turning a string into an ordered list of tokens would be the responsibility of a parser. My plan for this library would be to define a parser interface, and let other libraries (eg for example bindings to libpostal, or a geocoder that queries an external service) plug in to do the actual parsing. There are other complications as well including address formats, cross-country token aliases, address validation etc. This will not be a small library.
That is an interesting way of avoiding the problem completely. Thanks! I'll look into this.
There is something very different about trading though (and a bunch of other jobs). With trading you are not creating wealth (well, one might argue that you are making the market more liquid). You are literally spending your time having a net impact of zero on the rest of society and earning a lot of money. Since money is just a piece of paper that says : "I received this in exchange of my labor or some natural resource, please give me your time or resource"; you are essentially spending your energy finding smart ways to steal other people time and resource.
Indeed that seems to be exactly what I'm trying to accomplish here. That's an interesting (though feels a little abusive) way of working around it, with slightly less crazy unsafe code than /u/tspiteri's solution. I have a feeling that I'll try to avoid using a `Vec` at all, since for my purposes it may not be strictly necessary instead, but this is really cool! Thanks!
Wow, that's pretty crazy, but does what I want. I think I'll try to avoid this though, it seems like it may not be worth it if I can avoid allocating a `Vec` at all :) But good to see that this is possible. Thanks!
Good point. On gigantic code base, do you think building time would get better or worth than C++ with proper separate compilation ?
Wow that crate looks awesome, you are probably right that I should use this solution instead reinventing the wheel all over again :) Yes I had lots of fun trying to implement an easy to use interface for my own pixels. I will definitely check out how the crate you've linked is implemented :) Thanks for the input :D
PUC-Rio Lua is really amazingly well written, once you accept what its goals are and what environment its written for. It's small and easily embedded, so in that sense it's "as simple as it can be", but I wouldn't exactly call it simple. It's only simple when you compare it to interpreters of a similar caliber, really. It is well optimized and extremely high quality, maybe one of the highest quality C projects I've ever seen. All that being said, as you can probably guess from how much I complain about it, it's not exactly perfect. The API it provides has a lot of very irritating qualities (error handling) and a lot of annoying limitations (no pointers / gc rooting), and performance wise it absolutely can be beaten! This is a bit old now, but if you go [here](http://luajit.org/performance_x86.html) you can see that as of 5.1, LuaJIT *in interpreter mode* is quite a LOT faster than vanilla Lua. As I understand it, some of this is because LuaJIT's interpreter is hand written assembly, but quite a lot of it is because of some fairly simple bytecode format changes that increase memory usage slightly but drastically reduce the amount of bit twiddling in the core interpreter loop. Even the *LuaJIT* interpreter can be beaten as well (though it would be MUCH harder), because LuaJIT accepts garbage collector limitations that come from maintaining complete compatibility with the Lua C API, and (iirc) doesn't do as much as it could to improve table performance. With that out of the way, I've tried for quite a long time to *resist* the urge to just RIIR, and have finally failed at this :P It's a bit ambitious, but I have a project for this that I'm currently working on that has all the above goals in mind. We'll see how far I get with it though, right now it's still extremely early days, and most of the work I've done has just been reading Lua source and researching VM implementation strategies. If it turns into anything I'll let /r/rust know ofc :P
*... of a file path on a Linux system (similar to chroot) Please add what kind of privileges are dropped or a README with an example, if possible. I was confused what you meant with "privileges".
For the /r/programming discussion go to -&gt; https://www.reddit.com/r/programming/comments/8cw2xn/overview_of_the_efficient_programming_languages/
Note that I am not the author of the crate. I did make a couple of pull requests to it but nothing more than that. You can see what it does in the documentation at https://docs.rs/privdrop/0.2.0/privdrop/struct.PrivDrop.html
Cool! That certainly seems the right way to do it.
OK, so I think I can explain the limitations you have encountered. First - the "one-to-one" relationship. I assume you have tried something like this: use std::collections::HashMap; fn main() { let mut hash_map = HashMap::new(); let some_string = "Hello".to_owned(); hash_map.insert(100, some_string); hash_map.insert(200, some_string); } https://play.rust-lang.org/?gist=261f7f157f69a22f1d913683af3e3f4b&amp;version=stable This fails to compile: error[E0382]: use of moved value: `some_string` --&gt; src/main.rs:8:26 | 7 | hash_map.insert(100, some_string); | ----------- value moved here 8 | hash_map.insert(200, some_string); | ^^^^^^^^^^^ value used here after move | = note: move occurs because `some_string` has type `std::string::String`, which does not implement the `Copy` trait The reason it fails to compile has nothing to to with `HashMap` - this will fail to compile too, and for the same reason: let some_string = "Hello".to_owned(); let a = some_string; let b = some_string; Rust's ownership model enforces a single owner for every value. Some values - like numbers - implement `Copy` to allow copy-assignments. `String`s do not implement `Copy` because copying as string would require memory allocation and that's not something Rust is willing to do implicitly - so if you want to put the same string in multiple places you need to `.clone()` it or to take a reference to it. Ownership in Rust is a bit tricky, so I'm going to refer you to the book: https://doc.rust-lang.org/book/second-edition/ch04-01-what-is-ownership.html Moving on. You said you were only able to "establishes a relationship between two strings". So I imagine you have tried something like this: use std::collections::HashMap; struct Foo(u32); fn main() { let mut hash_map = HashMap::new(); hash_map.insert(Foo(100), "Hello"); } https://play.rust-lang.org/?gist=d704d5969ee0a19069a3be1e6d1febaf&amp;version=stable When we run it we get this error: Standard Error Compiling playground v0.0.1 (file:///playground) error[E0277]: the trait bound `Foo: std::cmp::Eq` is not satisfied --&gt; src/main.rs:8:14 | 8 | hash_map.insert(Foo(100), "Hello"); | ^^^^^^ the trait `std::cmp::Eq` is not implemented for `Foo` error[E0277]: the trait bound `Foo: std::hash::Hash` is not satisfied --&gt; src/main.rs:8:14 | 8 | hash_map.insert(Foo(100), "Hello"); | ^^^^^^ the trait `std::hash::Hash` is not implemented for `Foo` error[E0277]: the trait bound `Foo: std::cmp::Eq` is not satisfied --&gt; src/main.rs:6:24 | 6 | let mut hash_map = HashMap::new(); | ^^^^^^^^^^^^ the trait `std::cmp::Eq` is not implemented for `Foo` | = note: required by `&lt;std::collections::HashMap&lt;K, V&gt;&gt;::new` error[E0277]: the trait bound `Foo: std::hash::Hash` is not satisfied --&gt; src/main.rs:6:24 | 6 | let mut hash_map = HashMap::new(); | ^^^^^^^^^^^^ the trait `std::hash::Hash` is not implemented for `Foo` | = note: required by `&lt;std::collections::HashMap&lt;K, V&gt;&gt;::new` The problem is that an hash map's key type need to fulfill two requirements: * They need to be _hashable_ - that is, mappable to a small values that (should) have low chance for collision with each others. * They need to be _equatable_ - that is, given two keys you need to be able to tell if they are the same or different. Many languages provide those automatically for user types - like comparing and hashing the position in memory (if the language objects are always on the heap) or generating comparison and hash functions from the class' fields. Rust's approach is different - types are restrictive by default (support almost nothing) and you need to declare what functionalities you want to give them: #[derive(PartialEq, Eq, Hash)] struct Foo(u32); This will automatically derive the appropriate `trait`s: * [`PartialEq`](https://doc.rust-lang.org/std/cmp/trait.PartialEq.html) - generate `eq` and `ne` methods that will compare the fields (in this case - the single field) * [`Eq`](https://doc.rust-lang.org/std/cmp/trait.Eq.html) - this does not actually implement any method, it'll just promise to Rust that the equality relation on `Foo` follows the rules of reflexivity, symmetry and transitivity. * [`Hash`](https://doc.rust-lang.org/std/hash/trait.Hash.html) - generate the `hash` and `hash_slice` methods. Once `Foo` has all these methods (using these traits - just implementing methods of these names won't do), it can serve as a key type for `HashMap`s. It needs `Hash` to know where to put the entries of that key and from where to retrieve them, and it needs `Eq` to distinguish between different keys with the same hash. 
rust is an expression based language. An expression without `;` has a return value, which allows you to do things like let x = if y { "something" } else { let v = some_computation(); format!("got: {}", v) }; This reduces the need to create temporary variables, etc and makes a lot of code cleaner. Basically, every expression has a return value. An expression ending in `;` has a return value of `()`.
Good point.
No. These jobs do not exist. Don't bother looking for them. Those of us who know they don't exist will keep them for ourselves.
I have no idea. C++ can be quite horrible, especially when using templates heavily to benefit from inlining/type-checking/branch-free code which means lots of code in headers... on the other it's easily parallelizable and the toolchains are mature.
They aren't the same. While TCP has limitations, there are many ways to mitigate those limitations. It's not *that* hard to have file transfers with TCP that get at least close to max capacity. People have even found ways to make transfers over ssh efficient (e.g. https://sourceforge.net/projects/hpnssh/). UDT provides ways to get around TCP's limitations, but you don't see transfers that are multiple times faster beyond pathological cases (that invariably can be addressed with changes to how TCP is employed).
What I'm saying is that the rsync and FTP protocols will both be able to saturate TCP. (At least for large file transfers.) TCP is the only limitation. So they are equivalent as protocols. Of course, an implementation can always slow things down below the max rate of TCP. It just can't speed it up. &gt; People have even found ways to make transfers over ssh efficient Right. Ssh is also the same as FTP and rsync in the sense that, given an efficient implementation, it will be as fast as any TCP protocol can be.
Working on an argument parser. Yes I know of clap but this is more for exercise 
The standard panic messages are already rather useful when developing a program. This crate is something you'd want to use for a published release build of your program for the benefit of end-users, rather than something you'd want to have enabled during the entire development cycle.
Out of curiosity, why do you consider this less clean? IMO, the cleanest variant would be let mut a; let mut b = 1; let mut c = 0;
I considered the point when the recruiter first reached out to me. There are some industries (defense, primarily) in which I would not be comfortable working for example, so I wanted to take my time and evaluate whether I'd feel comfortable working in market making/HFT (the two being separate). --- The first point is about market making: market making is *risky*. Whether the market is liquid, and you have to propose better prices to be first in line, or the market is illiquid and you are the only one proposing prices *at all*, the result is that you are on the front-line: 1. You are holding positions, which may go against you, 2. You are proposing prices, which may shift under your feet. There is reason, after all, that exchanges propose specific deals to attract market makers: it's a financially risky job, which requires quite a good deal of infrastructure *just* to avoid losing money^1 . A typical example is that you are willing to sell shares of company X Inc. Equity markets are typically illiquid, especially for smaller companies. Some days the screens are empty... except for the market makers: - this means that the only indication of how the market values shares of X is given by market makers; nobody else freely shares their opinion, - this means that should you sell, whoever buys may find themselves with stocks that lose (part of) their values with no other buyer in sight. In this vein, I would argue that a market making company is very similar to an insurance company: the value of their service is to take the risk for others. Of course, this comes at a fee, since they need infrastructure to estimate and manage this risk. ^1 *It turns out that this infrastructure can be used to make money, by reacting first, but that's a secondary benefit; it would be necessary anyway.* --- The second point is about HFT: F1 racing is pointless. F1 racing consumes a lot of money (from sponsors and viewers alike), without producing any immediate value. Yet, at the same time, F1 racing contributes to advancing the auto-making industry as a whole. Actually, most of the money invested probably ends up being used to pay the auto-making industry. The same applies to HFT. In the course toward ever lower-latency, the industry is at the edge of FPGA design, PTP synchronization, and... unsurprisingly C++ advances. That is, even if you estimate that the "service" of market making is not worth paying for, you still likely, indirectly, benefit from it in other ways. --- &gt; you are essentially spending your energy finding smart ways to steal other people time and resource. Or, conversely, ensuring that you do not get ripped off. At least here in Europe, brokers have to prove "best execution". Without "best execution", a broker could pass some of their losses onto their clients, or privilege one client over another, etc... With "best execution", a broker has to prove that they made the trade at a fair price: either making the trade on the market (screen) or by contacting a handful of market maker directly and picking the best offer received. "Best execution" is only possible when some parties are willing to set the price, transparently, without even a guarantee of ever trading. Those parties are the market makers. Of course, your broker is likely honest... but "best execution" guarantees it, so you know you're not getting ripped off.
What all these TCP protocols have in common is that, after some various amount of overhead, they simply stream one byte over TCP per byte of the data to transfer, until every byte is transferred. So nothing in the protocol can matter other than the overhead (which is too small to matter for these large files).
&gt; What I'm saying is that the rsync and FTP protocols will both be able to saturate TCP. (At least for large file transfers.) FTP *can* saturate TCP, but compared to rsync &amp; Aspera, it's very unsophisticated and can significantly underperform. This goes double if you are doing sftp. FTP leaves a lot on the table that tools like Aspera take advantage of to achieve higher transfer rates. The rsync protocol has a much more sophisticated approach that closes the gap. &gt; Of course, an implementation can always slow things down below the max rate of TCP. It just can't speed it up. By employing, for example, multiple TCP connections to do a transfer, you can potentially even exceed max rates from TCP. &gt; Ssh is also the same as FTP and rsync in the sense that, given an efficient implementation, it will be as fast as any TCP protocol can be. For starters, ssh &amp; rsync protocols have data compression options, which can allow them to outperform FTP.
You are not alone.
compression isn't something in the protocol (though, I guess, requesting compression is in the protocol). I did think of putting a parenthetical about compression in my post though. Oh well. &gt; FTP can saturate TCP, but compared to rsync &amp; Aspera, it's very unsophisticated and can significantly underperform I'm not comparing it to Aspera, because that's not TCP. Why would it underperform? It doesn't make sense for it to underperform (other than per-file overhead or compression, both irrelevant here)? &gt; For starters, ssh &amp; rsync protocols have data compression options, which can allow them to outperform FTP. Is that just "for starters" or is that literally the only thing you could come up with? I don't think you can come up with another thing than: 1. Per-file overhead (irrelevant here, files are &gt;300MB) 2. Compression (irrelevant hree, files are compressed)
That's not true. UDT doesn't even use TCP, and most of the protocols employ compression, delta analysis, congestion mitigation techniques, etc. The protocol itself imposes almost no overhead, but as the original poster discovered, there are a lot of cases where naive implementations fail to get the best results from TCP (or UDP in UDT's case). There are a lot of tricks to making sure you are doing file transfers as efficiently as possible.
&gt; We can argue semantics, but compression is part of the way Aspera is achieving better results than FTP. Really? Aspera is compressing the .gz files? Shut the fuck up you are talking out of your ass.
I'm not sure exactly what your constraints are. Whats wrong with this ? https://play.rust-lang.org/?gist=bb68624893fd8524014d689e8e5fa978&amp;version=stable 
&gt; What congestion mitigation techniques exist above the TCP level in the ssh and rsync protocols that don't exist in FTP? Vanilla ssh doesn't have much, although there are extensive patches to ssh to help it perform better for large data transfers over WANs. rsync's protocol isn't much better (though the documentation does highlight ways the protocol could be improved), but its internal pipeline process does try to smooth out the transfer and economize on the use of socket buffers to minimize the chance of packets being dropped by congestion control. It has explicit features for identifying links and sparse files, and avoiding sending unnecessary data. The daemon also makes parallel transfers &amp; connection loss recovery easier to manage. It's a lot of little things, but they add up.
Rust's build system sets `--cfg stage0` where appropriate, and you can see where this is handled in the code by grepping for `cfg(stage0)`.
&gt;At least here in Europe, brokers have to prove "best execution". Without "best execution", a broker could pass some of their losses onto their clients, or privilege one client over another, etc... That only came very recently with MIFID II though, right?
Now it is just waiting for a high-level library based on generics that makes writing simd code for all architectures at the same time easier.
I haven't looked into it, but you might like https://github.com/AdamNiederer/faster.
You surely need an `extern "C"` on your `process` declaration.
Thanks, dodheim! I just corrected it. And now the program gave a new error message. It seems that there were more than one issues in my original code. error LNK2019: unresolved external symbol _process referenced in function _main
As /u/_iliekturtles_ said, it can be expressed in terms of other units, but I [just submitted a PR](https://github.com/iliekturtles/uom/pull/77) that will add first-class support for voltage!
What a great project! Despite your best efforts of hiding I did manage to find you on Patreon and gave you money.
The name mapping should be done for you; are you telling the linker about that .lib file? If not, see [.Lib Files as Linker Input](https://docs.microsoft.com/en-us/cpp/build/reference/dot-lib-files-as-linker-input).
This is really cool stuff! Most of this is way out of my skill range but I hope to find some time to look at the audio issues to help out a little (game projects never get finished anyway, haha). Thank you for all your hard work!
Yes, it is a little crazy :) In this case it doesn't worry me much because the only difference between the types of the vectors inside and outside the `for` loop are the lifetimes of the element references, but when the pointer is passed around, the length is always zero such that only the allocation is reused and there are no actual references that will have their lifetime reinterpreted. And since only the lifetimes are different, the conditions in the safety section of [`Vec::from_raw_parts`](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.from_raw_parts) are all satisfied.
I think the lifetime annotations on `specialize` have forced the compiler to extend the borrow `Specialist` takes. I'm not sure exactly what part of it it is, but I *think* having `&amp;'a mut self` means "the borrow on self lasts as long as 'a". In this case, `'a` lasts the entire life of `main`, and thus the `&amp;'a mut self` borrow is extended to that length. The solution is to leave out `&amp;'a mut self`, and replace it with `&amp;'b mut self`. To my understanding, this lets the compiler take out a shorter borrow on `self` so that it will correctly end at the end of the block. Both of these let it compile: fn specialize&lt;'b&gt;(&amp;'a mut self, y:i32) -&gt; Specialist&lt;'b&gt; where 'a:'b { and fn specialize(&amp;mut self, y:i32) -&gt; Specialist { (this is inferred to exactly the previous one).
I'm wondering if once custom allocators gets stabilized (which is also what allows you to opt-out of jemalloc), the default should be switched and the system allocator should be made the default. So many people get some kind of mistaken impression that Rust is bloated almost entirely due to jemalloc (and to a lesser degree the format! machinery and panic! machinery, iirc from all of the "let's make a smaller Rust executable posts"). Since many programs probably don't benefit significantly from jemalloc, making it opt-in might make more sense.
Maybe try this? #[no_mangle] extern "C" fn _process() {} I haven't had Windows running for a long time, but I slightly remember that there is some funniness with prefixing function names with an underscore in certain linking/exporting situations
Yeah I actually think I heard that this was the plan, but you are indeed correct that it would necessarily be blocked on stabilizing custom allocators. And there would need to be a stable way to opt into jemalloc. In the work I do at least, I tend to spend a lot of time amortizing or eliminating allocation, so jemalloc probably doesn't help me much. I believe I've tested ripgrep against the system allocator and I don't think I could detect a difference, which isn't all that surprising!
Later versions of Node support WASM. Even if you can't run Rust directly, you could compile out to WASM and run that.
Yes, I did. Thanks!
Is this u2f-hid-rs working with the native HID APIs or USB APIs, or another abstraction layer?
HID.
[lol](https://github.com/rust-lang/rust/pull/49719#issuecomment-381459484), nope definitely not needed.
\\\_O_/ &gt; however it would make the language less readable (and only marginally easier to write) How? Just let your editor or IDE show the inferred `;`? I did that all the time. Compare the amount of people using `;`-inferred languages asking for making `;` mandatory with people using languages with mandatory `;` that want to have it inferred. I think the situation is exceedingly clear. &gt; That code could be inside a function and would require the parser to do more work. And this explains why `struct Foo {}` doesn't need a `;`, because ...?
&gt;sender &amp; recipient timestamps on chunks Well, that is one. So there you go. You did prove me wrong with that one. The rest of that is nonsense though. I don't even get why. You actually had a real one. 
So this is just a weird wrapper around `setuid` and `chroot`? Why not a structure that takes advantage of RAII and lets you raise privileges to be executed in a closure (thus ensuring that only that code needs to be checked carefully). I was confused reading this as is, especially since it looks like a builder...but it's not because each step actually does something before the `apply()`. 
[removed]
It would be nice to have a cargo setting for it, like `allocator = "system/jemalloc"` and it could probably only be set by binaries, not libraries.
because there is no confusion that it is the members of `Foo`.
Blockchain can be used for more then just cryptocurrency. You're the one jumping to that conclusion. The library looks nice, we'll see what use cases people come up with.
Yes I agree that there is value in liquidity. I even put that in parenthesis. I feel however that the finance industry as a whole has grown way past that : if you were to put on the price tag on this service given to society, I doubt it would be anywhere the money made from speculation.
As others pointed out, on linux the compiled binary _is_ an elf file. Unfortunately, AWS Lambda does not support running a plain binary. It initially supported only dynamic languages. I suspect the reason is the "serverless" model where you don't know what will be the infrastructure running your code. By targeting a dynamic language AWS only needs to provide the interpreter. If you start compiling your native code you will depend on (dynamic) libraries on the compiling host which means you will need to make sure the running instance is running the same system as the compiling system, breaking the "serverless" model. Rust _can_ be compiled to a pure static binary, but that's not the default and it is thus comprehensible from AWS to not support this. Go compiles statically by default; it bypasses the libc linking by talking to the kernel directly instead. So it's probably easier for AWS to support officially. Unofficially, you can use the [crowbar](https://crates.io/crates/crowbar) crate to create a library that the Python runner can load as if it was a python module. This works fine by the way (modulo openssl linking... see https://github.com/ilianaw/rust-crowbar/issues/20 and a discussion here https://users.rust-lang.org/t/statically-linking-parts-of-a-shared-library/16171/30 )
So it's not about Rust being expression-based?
I think he just forgot the "not" in his sentence. Then his post makes sense.
The primary problem is that you've created an infinite recursive loop, so you've blown out the stack. Normally, the compiler would warn you when you've written a function that unconditionally recurses, but in this case it seems to have been successfully confused by the use of `drop`. Presumably, whoever wrote the recursion check never considered the case of a recursive drop. Also, the compiler *did* catch the problem... *at runtime.* That's how you got the error about overflowing the stack. In general, it's not possible to tell if a program will execute in a bounded amount of stack space, nor how much stack space it will need. Finally, I *think* this isn't a safety issue. Assuming you're running on a platform with stack probes (which is not supported on all platforms, but that's LLVM's purview, not Rust's), there shouldn't be any way to exploit a stack overflow to violate memory safety. Still, this should probably be filed as an issue to improve the unconditional recursion check.
That's actually a safe failure mode you've stumbled upon, it just ultimately exits with a segfault. You overflowed the stack by dropping an instance of `ToDrop` inside its destructor. Without protection, a stack overflow will lead to silent data corruption as the processor plows through whatever memory is beyond the current thread's stack. However, Rust uses a stack overflow protection mechanism that aborts immediately with a segfault instead. It's even good enough to print an error message, which is hard during a stack overflow because calling any function at this point will lead to another stack frame being pushed onto the already-overflowed stack, which is bad.
"Safe Rust" means _memory safe_, e.g. no dangling references. It's perfectly safe in this sense to leak memory or to overflow the stack. Nothing is getting corrupted, you don't end up with use-after-free issues, etc.
&gt; https://github.com/rust-lang/rust/pull/49389 Using just `euc` as a suffix seems a bit like Rust's abbreviation gone too far. For a common word like `Vec`, it makes sense in a huffman-encoding sense (length should be inversely proportional to frequency) and "vector" is common enough that it's relatively self-explanatory. But, performing Euclidean division is much less common, and "Euclidean" isn't that common as a word to begin with. At least for `mod`, it could be `mod_positive`. &gt; https://github.com/rust-lang/rust/pull/48945 There's a small argument for `.exhaust()`: it allows types to specialize it to use `drop_in_place` (e.g. `vec::IntoIter`), which is likely to be a very slightly more efficient by not having to memcpy things onto the stack. To compose the best, though, there would need to be something like fn skip_eager_no_yield&lt;F: Fn(&amp;mut T) -&gt; bool&gt;(&amp;mut self, f: F); (i.e. `skip_while` that doesn't return anything, just immediately runs forward and destroys the skipped elements.) so that `.take(n).exhaust()` and `.take_while(f).exhaust()` can benefit from it. Plus, something to make it work with `rev`. All in all, a lot of infrastructure for probably not much gain.
I don't understand. Does *slog* implement a parser for the format produced by `#[derive(Debug)]`and (hopefully) followed by convention for manual implementations? It's already a string by the time it exits `Debug::fmt`.
What do you parse "Street st." as?
&gt;However, justifying using &gt; &gt;two &gt; &gt; languages in parallel with the same performance/capabilities is tough, cost\-wise. There's an overhead to adding a new language to the mix, overhauling the whole codebase is obviously out of question, ... All this means is that the first company to green\-field their development on Rust will outmaneuver less agile companies and win the trading war. After a few months or years, the industry will have switched to Rust.
Someone already did that. It was universally shot\-down by the community \(or at least those that showed up for the discussion\).
I'm in Asia. If you'd consider it then yes let's keep in touch ;). The pay also depends on the industry and the region you work on, probably more so than the actual 'competency' for the job (the difference between 2 person in the same team is not that high). Of course once you start getting higher up the ladder, you tend to do less than what you were hired for and adapt to the particular organization. Of course you're not wrong in what you say, I just wanted to give another perspective.
no, I'm saying the parser doesn't know whether it is defining the members of `Foo` struct Foo { ... } Are the `...` defining members of `Foo` or are they a code block? You need to do look ahead parsing to tell, which is annoying. struct Foo { x: u8 } { ... } In that example `{...}` can _only_ be a code block.
GGEZ is awesome. Keep up the great work! I'll be thrilled if my game can run in a browser (If I ever finish it)
My first ever rust PR made the highlights list, I'm honored.
Thanks! I'll be digging in to see how it works. 
where does Response::builder come from?
&gt; if you were to put on the price tag on this service given to society, I doubt it would be anywhere the money made from speculation. Isn't that reward proportional to the risk? It's quite easy to lose a lot in speculation too.
Happy Cake Day! ^You ^can ^participate ^in ^r/HappyCakeDayClub ^until ^midnight!
Thank you! I feel really awkward [asking for money](https://www.patreon.com/icefox), but it WOULD be nice to be able to devote more of my time to making ggez.
One could also write a Rust interpreter using Truffle that does not depend on rustc at all and gain its JIT performance. Could also help verify the compiler for the Ken Thompson Hack.
The things done before apply relate to getting the uid and gid from the username and group name mostly. Doing so has no side-effects on a normal Unix system but is there any other reason you think it should not be done at that point? I suppose some of it could be moved into `apply` instead if there is any good reason to do so.
/r/playrust. 
I am not sure if your point is that I am unqualified about this subject or if you think that the free market sets what the right price tag should be. For the first part, granted, I'm super unqualified for the subject. I'd love to get the opinion of an unbiased expert, but the figure is so off the chart that I would be surprised if it came close to the reality. (I believe this is between 0.5% to 1% of the GDP in France, UK, US for the money made by financial services in making positive trades...). For the second one... My view is that the presence of these trade opportunities are the result of having a large number of people. Making a profit out of them is ok, but I think it should be treated as a natural resource. So in a nutshell, I just think it should be taxed more heavily.
If a magic genie tells you that you only get three wishes, you wish for more anyway. Because maybe the genie is bullshitting you. Maybe they are obligated, if you'd ask. And they don't want to, so they just tell you not to ask. If Nintendo is going to give a cease and desist, let them be the ones doing it. You aren't helping anyone with anything right now unless you're a Nintendo lawyer.
The best strategy is really to build (micro)-services that are language independent and start using rust for some of those service. The risk is low because you can always rewrite it in x language if needed. This is definitely more risk than not changing anything but it is nicely contained. I believe the reward can be very high. Note that it is in no way specific to rust in particular: a trader can start implementing his service in python ... until the need for a faster solution.
That's not how parsing works.
If you use slog to produce Json formatted logs, then you should easily be able to read them into another app with serde...
Termion only works on POSIX platforms and Redox. That's why I suggested pancurses. It's basically the same kind of thing, but does POSIX and Win32 instead.
If I'm understanding you correctly, then you completely missed the point. The question I've been asking is how you propose to get JSON/TOML/RON/etc. data out of 3rd-party dependencies that only implement `{:#?}`. As I said, it sounds like richhyd's idea is to implement something which parses the syntax used by `#[derive(Debug)]` so that a richer debug dump inspector can be built to explore the data. Such a parser could be used to produce JSON or TOML or what have you.
I often miss points :). So you’re discussing something where you don’t have control of the logger it sounds like. So yes, you’d need a more interesting solution.
I agree, this does seem possible.
I believe that is the case right now for [custom allocators](https://github.com/rust-lang/rfcs/blob/master/text/1974-global-allocators.md); there can only be one global allocator, and only the binary can specify it. It's specified at the top level of the crate, though, not in Cargo. And it looks like it's intended that the system allocator become the default one, and jemalloc move into a crate, so you would just depend on that, import the right thing, and add something like the following to use it: #[global_allocator] static ALLOCATOR: JeMalloc = JE_MALLOC_INIT;
I'm coming from Python were I try to do stuff in one line if possible even if it doesn't really make sense to. I need to get out of this habit.
what is GraalVM
haha, you're probably right. I guess it comes down to: some people prefer semicolons, some don't. I've been a python dev for 5 years and honestly I prefer semicolons -- mainly because multi-line statements in python are painful. Rust has _tons_ of multiline statements (like iterator method chains) so I really appreciate the semicolons. YMMV
Well considering the crater run was all green...
The [home page](https://www.graalvm.org/) does a pretty good job of explaining it. Basically it's a VM meant to run multiple kinds of languages and produce really efficient code. It can do both JIT and AOT compilation.
Sorting out the rules for multi-line statements is a bit fiddly to implement, but coming up with a design that works intuitively is not that hard (at least if your language isn't designed in a week). You basically sort tokens into three groups - multi-line (line ends with `(`, `{`, `&lt;`, `.`, `=`, `-&gt;` ...) - maybe multi-line (line ends with `)` etc. and the next line starts with `.`, `+`, ..., - not multi-line (`;`, `}`, ...) The thing is, if you want good error reporting, you need to implement such logic anyway.
Why would I put a VM between Rust and the OS?
Well, it's really a combination of things: 1. Prior to 1.0, there was a push to simplify things as much as possible to stabilise them. Every unnecessary function, type, or method meant less attention spent on making sure everything else was up to scratch. Between the two, taking the buffer as an argument is strictly more flexible. 2. There's a definite trend toward *not* including things in the standard library unless there's a very significant demand for them, *and* they can't reasonably be provided by an external library. This sort of method can trivially be implemented in an external library, and it's not *necessary*, both of which greatly weaken any argument for including it in `std`. This is both for "we don't want to get stuck with bad APIs" and "we don't want to be stuck forever maintaining things unless we have to" reasons. 3. Rust prioritises good engineering over ergonomics. That's not to say it doesn't care about it, but it's not it's primary concern. I mean, do you have *any idea* of the hoops we have to jump through because we don't have const generics yet? Or `impl Trait`? Or reflection? Having to define a string buffer is potatoes so small you need a magnifying glass to see them in comparison. 4. Introducing new methods to existing standard interfaces is *slightly* dicey, as it can cause existing code to change behaviour. I've actually had a new method change resolution behind my back once, though luckily the new method had *exactly* the same semantics as the one it overrode. Still, it's something to consider, and *not* in adding a new method's favour. 5. Not every "obvious" ergonomic shortcut is going to exist, no matter what. In most cases, there's no great conspiracy, it's just that no one's cared enough about it to add it. Really, Rust could have gotten away with removing `read_to_string` *entirely*, since you can replicate it by reading into a `Vec&lt;u8&gt;` and then doing the UTF-8 check manually, so count yourself lucky. :P Honestly, I don't think anyone would really object too much to a convenience method, it's likely just a matter of convincing people that it's genuinely *worth* it. You probably wouldn't need an RFC for it, either. Toss it in a PR and see what happens. Personally speaking, if I found it was bothering me, I'd probably just make an "easy-io" crate and define it there.
The idea is not to replace the rustc compiler, just to have an alternative implementation of Rust. This VM and set of tools make it really easy to execute a language.
it takes a path instead of a file, but there is a convenience method for this as of 1.26, which will become stable on may 10th. https://doc.rust-lang.org/beta/std/fs/fn.read_to_string.html
Actually, `pub fn read_to_string&lt;P: AsRef&lt;Path&gt;&gt;(path: P) -&gt; Result&lt;String&gt;` was introduced in 1.26.0 just for this: https://doc.rust-lang.org/nightly/std/fs/fn.read_to_string.html You should be able to use this next month on stable.
I actually happened to literally just finish this video. https://www.youtube.com/watch?v=oWX2tpIO4Yc&amp;feature=youtu.be Really cool looking.
How do I calculate number of days between two DateTime&lt;Utc&gt;?
&gt; Why not a structure that takes advantage of RAII and lets you raise privileges to be executed in a closure (thus ensuring that only that code needs to be checked carefully). Starting a daemon as root and doing the things that you need elevated privileges for and then dropping the privileges is the standard way to do things on Unix and it is a well understood way of doing things. I am not familiar with what you are talking about — I mean, I know of RAII, I know of closures, but I don’t understand how you intend to use them together with elevated operations and how it would be any better but I would be interested to know more about it if you could provide some examples or point to some existing resources.
Not exactly what you want, but a convenience function that takes a path and returns `Result&lt;String&gt;` is going to be added in Rust 1.26. https://doc.rust-lang.org/beta/std/fs/fn.read_to_string.html
From the CLI WG [discussions](https://paper.dropbox.com/doc/CLI-WG-Berlin-2v99dJ7g6QVkGoT5VavPY): &gt; document some common guidelines &gt; &gt; * pls don’t bump required rustc version in minor releases I don't think that's necessarily a "common guideline". See for example /u/burntsushi's write-up [here](https://github.com/rust-lang-nursery/api-guidelines/issues/123#issuecomment-342470263). /u/killercup
Btw. the rustc is already verified against the trusting trust attack by the mrustc project (a compiler written in C++ that transpiles Rust to C; it has already successfully bootstrapped rustc). Additional verification doesn’t hurt, though! So exciting.
[removed]
Hi everyone! I'm trying to get into automated trading and was thinking about using rust to build something. I'm not super familiar with Rust but I've heard really good things about it. So just a few questions around this: 1. Is there a way to interact with Rest APIs built into Rust? or is there some cargo package I'm not aware of? Similarly, is there a package for dealing with JSON strings? 2. Is this even a smart idea? Should I just try to write something in C/C++ or even move to using something for an already established automated trading platform using python? 
My point is, the "value to society" from any activity is not self-evident. Are you saying the too much effort is spent on automated trading according to your opinion? That seems pretty arbitrary, especially since you, by your own admission, don't know very much about the subject. 
`(laterDate - earlierDate).num_days()`, assuming you're using Chrono.
[removed]
I admit I do not know much about this area so. But once you're at llvm bitcode aren't you long past rustc compiler? If that is so then this is not an alternative implementation to rustc which is higher level. 
&gt; The "value to society" from any activity is not self-evident. "Any activity" is a bit of a stretch, don't you think? A lot of activities in agriculture, medicine, education, for instance are pretty self-evident. If we soften your sentence, I agree that in modern society, a lot of people do not have a ELI5 story of what is the value of their job for society. Automated trading fall into this category. Some of them are worst, and have a fairly straightforward negative value, while still being technically legal. 
`jemalloc` is a significantly faster allocator in most cases than the system allocator. You say most programs probably don't benefit from it, but I would wager that many more programs benefit from higher allocation speed by default than taking up a bit more space for its metadata; in almost all cases that Rust is used for today, the extra space overhead of jemalloc is *completely* irrelevant.
that is true
is redox not posix-compliant?
Agreed. Or just supply a different parser to Rust that replaces the syntax with something better altogether... I wonder how hard that would be.
Could this perhaps be used to speed up running of unittests?
Been messing with the `failure` crate. The `Fail` trait has bounds `Sync + Send + 'static`. I'd like `MyType: Fail` to somehow store or reference a `Vec&lt;u8&gt;` containing a data dump. Is there any way to do this, or at least pass the raw data in some other form? It seems very limiting for an error handling mechanism to not be able to drag non-`'static` items up the chain. (The limitation on `Sync` and `Send` I can understand a bit better, as one can typically losslessly convert a non-`Sync`/non-`Send` data type to an analogous 'frozen' representation that reflects the original data structure at the moment of error, albeit at some performance/memory cost).
&gt; It seems very limiting [..] On the one hand, yes, it's quite limiting in terms of what errors can contain. On the other hand, it's quite freeing for code that has to deal with errors, since it can assume all errors are going to be `'static + Send + Sync`. That said, you should be able to store a `Vec&lt;u8&gt;` just fine; it doesn't violate any of those requirements.
Are you in middle management or technical roles like programming? I live in Sydney australia i amke the equivalent of mid 150k but not in programming
Very nice writeup! Love it. As for list of game engines running on wasm, I believe Goddot sports that as well. (and it's opensource) It definitely did support it couple months ago.
I don't think this subreddit should be used to advertise ICOs.
FWIW, just being a free function seems like it works fine, and makes how-to-import and the relationship between import and functions clearer, e.g. fn read_string&lt;R: Read&gt;(reader: R) -&gt; io::Result&lt;String&gt; { let mut buf = String::new(); reader.read_to_string(&amp;mut buf)?; buf } // used like toml::from_str(&amp;read_string(file)?) (Also, minor thing, but the `as &amp;mut Read` cast shouldn't be necessary.)
Guido's time machine at work :). It's already usable on beta.
I think it could definitely be an interesting thing to do! Not sure Rust libraries are 100% there yet, especially not compared to Python, but it should be doable. For HTTP, you want [reqwest](http://docs.rs/reqwest). For json, [serde_json](https://docs.serde.rs/serde_json/) (though this is also included in reqwest via [a helper method](https://docs.rs/reqwest/0.8.5/reqwest/struct.Response.html#method.json)). For deserializing json, you'll generally want to create a typed data structure using rust structs and serde_derive, though json can always also be deserialized to `serde_json::Value` for a "generic" system.
You mean **implemented** non-currency uses of blockchain. There are other that are being implemented. There are more that arn't.
Thanks i'll check that out! 
`jemalloc` comes with its [fair share of issues](https://github.com/rust-lang/rust/issues/36963#issuecomment-252029017), and I'm not sure it's a good default. And on Linux, at least, the GLIBC allocator recently got faster, so the performance difference should be lower now.
Is compilation speed really worse than that of "C/C++"?
&gt; Also, the compiler did catch the problem... at runtime What does that mean? C programs don't catch the problem at runtime? If so what happens?
You got an explicit "stack overflow" panic. That's something Rust did, by one mechanism or another. The specifics depend on the target platform. As for C, I'd say that depends entirely on the compiler and OS. I'd be moderately surprised if the major C compilers for modern platforms were doing stack checks by default. That said, on a modern system you're fairly likely to hit a guard page, which would trigger an access violation. On embedded or old hardware without memory-mapping, you could conceivably smash right into the heap or other memory region. So, yeah... it depends. That said, in the interest of fairness, I don't know how thorough Rust is about stack checks on embedded platforms. I'd hope it does checks on any platform where it's possible to perform them.
I'll be honest and say that I have no idea of what you talking about. Isn't the idea that rust is not garbage collected? Shouldn't that check be considered some kind of garbage collecting? does it have any performance implications?
I'm trying out Gotham but I've seem to hit a brick wall. I need to access a variable in a handler but I really don't know how I'm supposed to do this. For example, with the basic gotham template: ``` pub fn say_hello(state: State) -&gt; (State, Response) { let res = create_response( &amp;state, StatusCode::Ok, Some((String::from("Hello World!").into_bytes(), mime::TEXT_PLAIN)), ); (state, res) } /// Start a server and call the `Handler` we've defined above for each `Request` we receive. pub fn main() { let shared_data = Arc::new(Mutex::new(SharedData::new())); let addr = "127.0.0.1:7878"; println!("Listening for requests at http://{}", addr); gotham::start(addr, || Ok(say_hello)) } ```
I'm trying out Gotham but I've seem to hit a brick wall. I need to access a variable in a handler but I really don't know how I'm supposed to do this. For example, with the basic gotham template: pub fn say_hello(state: State) -&gt; (State, Response) { let res = create_response( &amp;state, StatusCode::Ok, Some((String::from("Hello World!").into_bytes(), mime::TEXT_PLAIN)), ); (state, res) } pub fn main() { let shared_data = Arc::new(Mutex::new(SharedData::new())); let addr = "127.0.0.1:7878"; println!("Listening for requests at http://{}", addr); gotham::start(addr, || Ok(say_hello)) } How do I access my shared data variable from my say_hello function? Thanks in advance for any guidance! `
**TLDR**: Garbage collection has nothing to do with stack checks. On major platforms, there is at worst a *very* minimal runtime overhead, but which is necessary to ensure your program doesn't accidentally corrupt memory. The stack is where local variables (and other bits of function book-keeping) are kept in memory. Each time you enter a function, it adds a stack frame; each time you leave a function, it removes the corresponding stack frame. Generally, the OS sets up the stack for a thread with a limited maximum size. There is (to my knowledge) no automated, hardware-backed system for detecting when a program overflows the stack. That's what stack checks are for: to detect if you've overflowed the stack and prevent you from continuing. In the case of systems that support memory-mapping, you can create a "guard page" of memory just next to the stack such that if a program tries to read or write inside that page, they get an access violation/segmentation fault. This has effectively no performance impact, although it does mean you "lose" a small amount of memory for every thread. The problem is that this isn't sufficient. If a function requires a stack frame which is *larger* than the guard page, it's possible for a program to skip over the guard page entirely, never setting off the access violation. This could lead to the program modifying another thread's stack memory, or altering heap data, *etc.* To combat this, Rust inserts stack probes. Any time a function could *conceivably* skip over the guard page, it adds some code to try and read from its stack frame such that *if* there's a guard page anywhere in the stack frame, the probe code will touch it, and set off the access violation. This has a small runtime cost. An issue with this is that stack probes are something LLVM (the backend that Rust uses to actually generate machine code) doesn't support on every platform. LLVM has to be the one to handle them, because only LLVM knows for sure how big a function's stack frame is going to be. If LLVM doesn't support stack probes, then there's not a whole lot Rust can *do* to ensure you don't miss a guard page. If the target platform doesn't support memory-mapping, Rust can't *create* guard pages. In that case, you *might* be entirely on your own, but again, there's not a huge amount Rust can do in that situation. That was quite rambling, but I hope it helped shed some light.
If it's really true, I'm honestly interested. Please give me some examples. Note that I consider only sensible things. In other words they must abide these rules: * It's absolutely necessary by definition of the problem that is being solved for everyone to have exactly same view of the state. (e.g. in case of currency, everyone must agree how much everyone has) * It must resist government regulation, so it absolutely must be decentralized (decentralization is not needed when the project doesn't need to resist governments) * It's impossible to build on top of Bitcoin (e.g. Open Timestamps are built on top of Bitcoin) or other existing blockchain. * Isn't scam
I think that is hard to classify when C and C++ are thrown together. C compiles very fast while C++ compiles very slowly (generally). So ¯\_(ツ)_/¯
I also frequently get bug reports from well meaning folks thinking that they've found a memory corruption bug because they ran valgrind on a Rust program with jemalloc. I think every instance has been a false positive so far. (Switching to the default system allocator and running that under valgrind always reveals no problems.)
Update: I'm looking at walkdir now and I don't think it fits my usecase. With recursion I can say: The current directory uses: space of all files + recursive_call(on each sub_dir) With walkdir I can collect all the directories &amp; files and their sizes. But then I must repeatedly call get_parent_directory() to add my size to the parent directory total size until I get back to the root. That feels uglier. Does that seem reasonable or have I misunderstood something @burntsushi ?
Yes, you'll likely need to do some work to use walkdir. However, you should not be comparing your current implementation with walkdir, but rather, comparing an implementation that *doesn't use recursion* with walkdir. I say this because tying your stack frame to the depth of a file tree is a very bad idea, since it imposes an artificial limit on how deep a file tree your program can look at. If this is just meant as a toy or something to scratch an itch, then sure. Recursion is a simple answer. But if you want people to really use this, then you need to get rid of the recursion. If it were me, I'd probably convert the walkdir iterator to a [stream of events](https://github.com/BurntSushi/ripgrep/blob/1503b3175f2a07dbd405c113948c07f872e4e899/ignore/src/walk.rs#L755-L913) that makes it easier to deal with the tree structure of a file hierarchy. You may also get some use out of enabling [`WalkDir::contents_first`](https://docs.rs/walkdir/2.1.4/walkdir/struct.WalkDir.html#method.contents_first), but I'm not sure.
I'm afraid I can't recommend anything in particular. I started off programming in Visual Basic, and just kept digging into C, assembler, and reading up on how stuff worked at low level until it made sense. It's not exactly an *efficient* method for learning low-level details. Maybe look for explanations on memory handling in C. Or maybe something that examines programs for very small, limited systems like very old computers or embedded systems. It's probably worth pointing out that you don't *have* to understand what I've been talking about to use Rust. That said, I *do* feel that working in Rust is made a lot simpler by understanding what's going on at the instruction level.
Would've loved to see c# there
I'd like to understand Rust and not just use it. From experience, this enables you to actually do and create things vs. just cloning stuff away. Your method of learning is, actually, the most efficient and prolific of all. It just happens that it'll require lots of time. Something which I'm a bit short on right now. But it is what is it. Do you suggest that I learn C?
I must have missed that. Do you have a link?
What you *want* is to understand how code gets executed. You need to learn that in order to really understand C. So it's more that learning C requires you to learn how code gets executed. But that's *also* true of Rust. In fact, a lot of what you learn in C and Rust directly translate between each other. So it's less about learning C specifically, and more about learning the underpinnings. C has the advantage that it's been around *a lot* longer, so there are more explanations of it, which means there's more chance they'll cover the low-level details in a way that makes sense to you. But maybe reading some introductory stuff on assembly might be what you need. Assembly is so low-level that there's no possible way of avoiding the low-level details. But it could also be overwhelming. So... look into introductions to C and *maybe* assembly, until you find one that clicks for you. I don't really know what to suggest beyond that.
&gt; it has already successfully bootstrapped rustc How was this bootstrap compiled? With clang it could still have the attack, since clang also uses LLVM and the attack could be there. With GCC it could also still have the attack, since the attack could have introduced into GCC, and GCC was probably used to compile the first LLVM versions until it became a bootstrapping compiler toolchain.
While Graal looks like amazing technology, I am extremely hesitant to adopt anything by Oracle, given their ideas around copyrightability and patent litigation. I'd rather use a more open effort like WebAssembly to achieve polyglot interoperability than GraalVM. 
That's really useful feedback. Thank you!
git isn't called a blockchain but it's the same basic idea. I think it ticks most of the boxes, especially when used in a decentralised way.
How fast is it? Are there any numbers? 
clearly, and Open Source does not mean free development either. Plus, usually when you donate in Patreon it is because the project you donate to mean a lot to you and that is a way to show the appreciation on a regular basis.
Haven't seen an ICO.
This: https://www.reddit.com/r/programming/comments/8d3ikv/apple_took_down_redditors_app_because_it_contains/
From hyper? ([`hyper::Response`](https://docs.rs/hyper/0.11.25/hyper/struct.Response.html))
TruffleRuby is allegedly 10 times faster than other Ruby runtimes.
Oh wow, I hadn't even seen that, but it's entirely in keeping with the character of Oracle.
Yeah it's true that Oracle is not trustworthy. The project itself is licensed under the GPLv2, but it does not cover patents. Sucks for the developers of Graal/Truffle because this is pretty amazing technology that might not gain traction because of Oracle...
you might also want to take a look at this: https://social.msdn.microsoft.com/Forums/vstudio/en-US/ed9375dd-5b9c-4651-8e8f-22df78a0b2d4/underscore-prefix-on-extern-c-link?forum=vclanguage
I’m curious about its potential to speed up big data processing. For example, you could statically compile your transformation functions, send them to be run by the executors on GraalVM and benefit from runtime optimization 
For a set of benchmarks from last year January, see: https://pragtob.wordpress.com/2017/01/24/benchmarking-a-go-ai-in-ruby-cruby-vs-rubinius-vs-jruby-vs-truffle-a-year-later/ (Tobi has his benchmark game down and was part of the JRuby team and has good contacts to Chris Seaton, so this is not a "random benchmark")
Haha... Rust2018?
Why does Nim reach lower than Rust on that diagram? 
To use Rust code from a JVM language is probably the best reason.
Pretty exciting would be interfacing with other Graal-hosted languages from Rust via LLVM bitcode.
Indeed; before that you had to trust your broker (or shop around).
Its hard to overstate how exciting this is in my opinion. The FFI story here is incredible: I will be able to write a library in Rust, without even a JS runtime, and publish it to npm; you will be able to write an application in JavaScript, without a Rust compiler, and depend on my package from npm. I live in pure Rust land, you live in pure JS land, zero user friction to call Rust from JavaScript.
I wish buffer bloat was nonsense. It'd save me a ton of time.
Possible, but unclear. Latency races are played in FPGA today, and those are programmed neither in C++ nor Rust (though they are piloted by a systems programming language).
I've been working on a type-safe react clone that uses wasm-bindgen over the past week. A basic version works! Some of the things that I haven't done yet, but want to do: * Write my own html! macro, the existing ones suffice for now but obviously don't work with exactly what I need * Write macros that take a Rocket endpoint (of type x =&gt; y) and export a JS function of type x =&gt; Promise&lt;y&gt; * I have a specific way I want to handle promises, timeouts and streams The game of life tutorial at https://github.com/rust-lang-nursery/rust-wasm was extremely helpful.
None. I am a developer, not a trader, and while I have a smackling of options theory, etc..., I have no idea what quantitative trading is to start with ;)
This is really cool. I don't know how hard this would be, but it would be even cooler if this could emit TypeScript declaration files (.d.ts). That would make working with Rust code from TypeScript extremely user-friendly. It would be even cooler in the opposite direction: if TypeScript declaration files could be used to generate Rust interfaces to JavaScript or TypeScript code. That would mean we could use almost all JavaScript libraries out there from Rust very easily, as these definition files exist for nearly all popular npm packages.
if we add the wasm-bindgen typescript flag it can absolutely do this! (https://github.com/rustwasm/wasm-bindgen#cli-reference) if you file an issue, i can work on it or if you'd like to contribute yourself i'm happy to help!
How does one know easily find out that Vec is Send + Sync? The docs at docs.rust-lang.org don't seem to indicate the auto implementation, so do you have to read the Vec source? Or are types in rustdoc assumed to be Send + Sync unless there's a !Send/!Sync marker on them?
I wouldn't say "zero" friction. Simple things like strings even have friction (WASM has no notion of strings, just one big byte array of memory).
Anything, you call a function periodically with a count of something and it will calculate the average throughput within a time window. For example, you could calculate cakes per second or bytes per second over a TCP connection.
gimme
I've just been working through [the excellent game of life wasm tutorial](https://rust-lang-nursery.github.io/rust-wasm/game-of-life/introduction.html) and noted that currently they employ webpack to run everything. Is it possible to use parcel with wasm-bindgen? I've been trying, but to no avail. The best I can get is for parcel to bundle everything and "serve" it, but then the webpage is blank with no errors. Cheers
Sounds like https://fosdem.org/2018/schedule/event/jiting_postgresql_using_llvm/
The shortest way might be to create a static variable using something like [https://crates.io/crates/lazy-static](lazy_static). But I conjured an example where the Arc is put into a custom gotham Handler implementation. This is probably the *right way* to do this with gotham. https://play.rust-lang.org/?gist=6b2153101c40a19fcc978c8f5b480195&amp;version=stable
Ask /u/luavi? 
What I want to see is a JIT that runs the application for a while and does dynamic optimisation, and then outputs a native binary with the optimisations generated during the trial run.
Maybe a kernel written in Java isn't so far off after all.
To be honest, I like pattern matching in arguments. I find `let (mut a, mut b, mut c) = (0, 1, 0);` much more pleasant to read than 3 separate lines of declaration... though then again I'd prefer "real" names.
:-) Would be certainly fun to have some mechanism to plug in more parsers, such that *.rs uses the standard parser, but rust can be made to read e. g. *.rs2 with a plugin.
The variable `a`, declared outside the loop, is not needed: - you do not read `a` in the loop (before assigning it), - you do not read `a` after the loop. Instead, a temporary inside the loop is sufficient. fn main() { let (mut current, mut next) = (0, 1); for _ in 0..10 { let sum = current + next; current = next; next = sum; println!("{}", current); } } I also took the liberty to rename the variables for clarity, as well as rooting the iteration at 0 which is more usual; just because ;)
The borrow checker ate it.
Wouldn't that just optimise the program for one single combination of possible inputs? Next time you run it the 'optimizations' could make it perform slower.. 
You *probably* want /r/playrust. :)
What you are looking for is called "Profile guided optimization". But its tough, because certain hotspots might not be obvious until other hotspots are solved (and similar), and its also just not a commonly used technology so it has less development hours sunk into it.
I 100% agree with arguments (although I don't think Rust actually supports that), but I don't really see the benefit if you're assigning them as three different statements. Your brain has to actually match up each one in order, and it makes it more brittle (if you remove or add one side, you have to remove or add to the other in exactly the same way). I think the reading comprehension is generally worse, but the writing ergonomics is basically ruined. vim example: let mut a = 1; let mut b = 5; let mut c = 10; to remove `a`, we can just navigate to that line and hit `dd`. let (mut a, mut b, mut c) = (1, 5, 10); To remove `a`, we navigate to that line and do the following sequence (assuming we start at the end of the line and we are perfectly efficient vim users): `6bd2w11bd3w`. If you're like me and therefore human though somewhat experienced with vim, this will likely actually look like `bbbbbbd2wbbbbbbbbbbbd3w`. I find vim users get particularly angsty about this kind of experience for this reason.
Added the method; thanks for the feedback!
You can send cakes over TCP? The future is amazing
You've gone too far! Leave my turbofish^turbofish^turbofish alone!
I tend to optimize for *reading* rather than *writing* (although I remain sensitive to a need for good diffs). Part of optimizing for *reading* is to avoid *scrolling*. There is nothing more annoying when trying to understand a piece of code than having to jump back and forth between multiple sections of a file (or different files). Instead, having all the code immediately available on the screen makes it much easier to grok. Avoiding wasting lines unnecessarily is part of this process; it wastes screen real-estate! *Note: I also avoid overly long lines so as to be able to fit two editors side by side on my screen; for the same reason.*
🎂
What did you use to learn about Webassembly?
Yes, that is a benefit of the inline method. I understand the optimization for reading rather than writing, and if I thought the inline method were easier to read, I'd opt for it as well. However, I also optimize for editing. Writing plain code (starting at the beginning of the line, ending when you finish a statement or block) is the easiest form of coding, but I find myself editing significantly more often.
This compiles just fine when I change this line: fn specialize&lt;'b&gt;(&amp;'a mut self, y:i32) -&gt; Specialist&lt;'b&gt; where 'a:'b { to fn specialize(&amp;mut self, y:i32) -&gt; Specialist { Like /u/daboross says, the way you've currently annotated things somehow indicate that your borrow may be used for longer than intended. I wish I understood this better, though, because I sometimes get bitten by this too. :\
Probably a dumb question - can this be used to generate a wasm module which can be [loaded](https://developer.mozilla.org/en-US/docs/WebAssembly/Loading_and_running) directly from a webpage, without having to involve node or npm in any way? I'm excited about wasm but am not a fan of webdev's very npm-centric direction over the past few years.
There's valid uses for when people might want to pass their own instances in. For example to do testing, or to reuse instances from a pool. Either version is valid enough that its worth keeping the method around.
If I know what the length of a vector will be, how can I move the contents out of the vector into an array with that length. The content is `Drop`.
I don’t understand the testing case, you assert that queue is empty. As for reuse of instances, in my opinion it would make more sense to have a `reset()` method on `Speedometer`. My problem with the method is that it leaks implementation details.
wasm-pack is specifically about npm integration, if you want to do that, you use wasm-bindgen directly. It’s not as nice in the end though.
It's nonsense to say that buffer bloat is an example of something that is a congestion mitigation technique thatis in the protocol, etc..
Surely loosing those optimisations would be less of a slowdown than running a massive runtime and profiler everytime you want to run your application. There's a reason very high performance applications are statically compiled.
Oh yeah, I guess that's reasonable. I like the idea of having a `.reset()` method. Might do that when I'm back behind my computer again
I just read a bunch of info about it on http://webassembly.org/ and wikipedia, then read my way through the [spec](https://webassembly.github.io/spec/core/index.html). Had to ask a few questions on the github issue tracker to clarify bits, it's not always easy to figure out how different parts of it should interact just from the spec. The real learning experience was writing nanowasm.
Right now `stdweb` is your best bet for this. It's been the battle-tested solution, and while the newer `wasm-bindgen` / `wasm-pack` crates could work, I'm not sure how to do it with them.
Yes, but "no user friction" still means "performance friction", overhead when calling from one language to another... I'm wondering what the performance gain would be, and what tasks you would need in order for WASM to out-perform said overhead ? Or am I being paranoid with this overhead thing ?
^The linked tweet was tweeted by [@nick_r_cameron](https://twitter.com/nick_r_cameron) on Apr 18, 2018 20:53:43 UTC (2 Retweets | 5 Favorites) ------------------------------------------------- Announcing cargo src (beta): [https://www.ncameron.org/blog/announcing-cargo-src-beta/](https://www.ncameron.org/blog/announcing-cargo-src-beta/) - a code exploration and navigation tool for Rust ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
What I was referring to was the development time. Particularly amount of time spent debugging memory safety issues that are prevented by Rust. Also, cognitive load of trying to ensure you don't have those issues in C/C\+\+. The "hope" of Rust is that it reduces programmer cognitive load and allows more correct software in less time with similar performance characteristics of C/C\+\+. And, in some cases, for example heavy parallelism or concurrency, it is theoretically guaranteed to be less buggy. Now, if Rust actually lives up to that, then, those who adopt it would have a first move advantage \- particularly in development and support costs.
This is fantastic. I recall seeing some comments in /r/rust that said they didn't understand the emphasis on JS/wasm for Rust, given that it's a systems programming language. I didn't respond then, but have been thinking that I should give my reasons why I think it's great even as someone who doesn't work much with the JS ecosystem. - wasm gives Mozilla a reason to fund Rust's development. This provides security for some very smart people to work on Rust rather than advertising pipelines (for example). That benefits all Rust developers. - it provides Mozilla, and by extension Firefox, with developer mindshare, hopefully keeping the web diverse - it encourages developers who would never touch C/C++ in production systems to expand their horizons. It promotes fearless learning.
Thank you so much for taking this on!
This looks amazing! Would it be possible to use this as source code browser for the documentation generated by `cargo doc`?
Yes, hopefully that's the long term plan, but it might take a while
I understand it is nonsense to you, but keeping your socket buffers small (and using the right tcp options), along with some careful work around timing/estimation of throughput are things you can do at layer-7 that can legitimately help to mitigate what is really a problem in the lower layers of the stack.
This looks phenomenal. Odd point -- how much work would it really take to turn this into an IDE?
You're claiming that an implementation of the rsync protocol can "keep socket buffers small" but an implementation of the ftp protocol cannot do so? I don't think you even are claiming that. You're just talking about irrelevant shit and you don't actually understand this conversation enough to know what we're talking about.
&gt; how much work would it really take to turn this into an IDE? Depends on what IDE means to you, I guess. This is based on the RLS which also powers editor plugins like vscode-rust.
What is the difference between "soft real-time" and "low latency"?
Great stuff! Thanks for this. Off topic: This reminds me, when is rustup going to be retired in favor of cargo?
I'm sorry but I don't see the difference to any other µC/embedded system that is connected to you PC. The interesting parts of embedded systems are the **embedded software** not the services they talk to (that run on your PC or so). Do I miss something here?
A custom kernel (that I have made).
Cross JS/wasm boundary calls aren't that expensive anymore these days. Basically an out-of-line function call. So not something you want in the middle of your hottest loop, but definitely not terribly expensive.
[removed]
Awesome thanks so much, I tried to google for it and must have used bad keywords because I just always found the nomicon page. 
We're going to be moving some parts of rustup into Cargo, so most users won't need to use rustup. However, there are no plans to retire rustup. We're not sure when this work will get done, some time this year though.
I came up with this, is it correct? fn vec_to_array9&lt;T&gt;(mut vec: Vec&lt;T&gt;) -&gt; [T; 9] { assert!(vec.len() == 9); unsafe { let mut a = std::mem::uninitialized::&lt;[T; 9]&gt;(); std::ptr::copy_nonoverlapping(vec.as_ptr(), a.as_mut_ptr(), 9); vec.set_len(0); a } }
&gt;(Although this is doing something similar to IDEs, it turns out that the hard part of an IDE is making it all happen quickly, rather than coming up with the info, so this is a much easier case than IDE support) I'm not sure how much it already does this, but I wonder if RLS could take a cue from this: build an index for a new project, and update only relevant parts as they are edited.
We do that at crate granularity right now, we hope to get finer granularity in the future (but it is somewhat challenging - e.g., consider a change which adds a blank line to the start of a file - there are no changes at all as far as the compiler is concerned but every span in the whole file would need to be updated)
Rust's blog [Introducing MIR](https://blog.rust-lang.org/2016/04/19/MIR.html) ;) 
Agreed. This is not a subreddit for evaluating business viability of software. If it's written in Rust, it belongs here.
Is there any very long target plan to be able to debug our rust code in the browser? That would be great!
Looks all right. The only thing I would suggest is to use `assert_eq!(vec.len(), 9);` instead, which automatically adds the differing lengths to the panic message. It may also be preferable to return `Option&lt;[T, 9]&gt;` instead.
This is awesome! Testing it out though, and when I click a trait I see one "reference" to a trait that is implemented in 5 files in my codebase. So still needs some work, but will be super useful to quickly browse things!
If your use case can support a reference to an array instead, you could use `.try_into()` which is stable in beta now: vec.try_into::&lt;[T, 9]&gt;().expect("vec was not length 9")
I doubt you'll find anything capable of console manipulation beyond basic TTY functionality (outputting text, `\n`, and `\r`) which has no std support. Why do you need such an unusual combination of features in the first place? On a desktop OS, it provides no benefit and makes it harder to provide a comfortable API (assuming it's even possible. The platform APIs may expect the caller to take responsibility for allocation in some places.) If you're writing your own OS, you'll need to use platform interfaces that only an OS kernel normally is allowed to access, to ensure proper resource sharing, and I doubt you'll find any ready-made libraries for that since the last major OS that expected you to do that was MS-DOS. If you target a bare metal platform for embedded use, you'll either need to use specialized APIs or work with a framebuffer provided by the platform. The former not only varies from platform to platform, but from display device to display device. (You're essentially implementing your own display drivers.) The latter will require you to implement your own translation from a character like `A` to a grid of pixels to be blitted into the framebuffer, and to do your own movement and drawing of the cursor.
If I understand the gist of this correctly, the board is basically just running a proxy that redirects all board IO from/to the host? If so, doesn't this sort of defeat the point of embedded systems? It requires the board to be tethered to a powerful host permanently, which removes advantages of small size or low power usage. If the host is executing all the logic, that also means the latency advantages of a microcontroller go away, so you can't use it for control tasks such as PIO, motors, etc. If it's intended as a learning platform, it just leads users to a dead end, because they can't use this architecture for practical tasks, and there's by definition no migration path for your existing code and into a self-contained device. So what is the use case this is targeting?
How useful would generating Rust binding be, considering they'll have to be `unsafe` and you'll have to write safe wrappers around them anyway?
Does this produce static files that could be dumped onto GitHub Pages or something?
Hey, maybe they'll Rewrite `gnome-shell` In Rust and make it actually usable!
Very lovely tool! Thank you.
\**wakes up, yawns, checks reddit inbox*\* Well, you seem to have this under control... \**sips coffee*\*
It doesn't, the pages are live. It uses React, so it should be possible to make it work server-side, and thus to make static pages, but I don't have the experience to do that quickly.
Rust is ahead of the competition here. If it gets well-established as the go-to language for WASM, that's good advertising, and it's going to bring a lot of people on board.
"Real-time" computing is about *rigorously-bounded* latency; it means that failing to meet the expected latency constraint is a system failure (which may be more or less tolerable depending on the application), but there's no expectation that the latency be *especially* low. Some systems (due to the need for performing complex data processing, etc.) have measurably high latencies between input and output, but if total latency is consistently bounded and not subject to largely-unpredictable delays, they're very much considered realtime.
&gt; Yes I agree that there is value in liquidity. I even put that in parenthesis. I feel however that the finance industry as a whole has grown way past that : if you were to put on the price tag on this service given to society, I doubt it would be anywhere the money made from speculation. Electronic trading is a tiny portion of the finance industry except in the number of headlines it generates.
I'm pushing to use Rust at the trading firm I'm at, but to be honest the memory access and use patterns in HFT are generally fairly safe. You usually allocate everything upfront and work out of fixed memory regions and try to avoid having complex dynamic object graphs. Lifetimes are rarely unclear as a result. A lot of protocol parsing is just defining the right struct layout and then memcpy'ing, not complex parsing. It's similar with generating outgoing messages or ipc.
&gt; You're claiming that an implementation of the rsync protocol can "keep socket buffers small" but an implementation of the ftp protocol cannot do so? Why would that be true? I'm not claiming that. You asked me about things one can do to improve upon TCP performance. rysnc's contributions addressed the specific points of pain identified in the original article, but while more sophisticated than FTP, it's still a long way from an optimal approach. It's just "good enough' to get you to the point where you aren't talking about Aspera providing 1000x performance improvements. &gt; I don't think you even are claiming that. You're just talking about irrelevant shit and you don't actually understand this conversation enough to know what we're talking about. There's a chance you're right. It is also entirely possible it is the other way around.
&gt; You asked me about things one can do to improve upon TCP performance. No, I didn't. &gt; There's a chance you're right. It is also entirely possible it is the other way around. It's definitely not the other way around.
Just finished a beta of my first ever crate : [mem_file](https://crates.io/crates/mem_file) I decided to implement this when i realised that there was no shared memory libraries for IPC in Rust (despite crates.io having confusingly named crates). As of now, the crate works on Linux/Windows and has basic features that should suite most use cases. Will keep adding features in the next few days...
I am pretty sure that people are not using python and Java in your company for this kind of task. I get your point, what I'm saying is that you'll probably have a harder time to convince people to switch to rust (or any non conventional language) for anything critical at the moment. I bet that showing it on some other areas *first* will prove more successful.
Thanks for the feedback ! Ill definitely have to add that attribute to my linux lock and figure out what the proper type of lock is for Windows :S 
&gt; No, I didn't. Well then, I misunderstood you. I probably misunderstood the needless ad hominems too. &gt; It's definitely not the other way around. Well, that certainly clarifies the matter.
You may find the posts on [Writing an OS in Rust](https://os.phil-opp.com/second-edition/) to be helpful. Without knowing a lot more about your kernel (and its video interface, if any) it's hard to say what would be the most useful resource to help you, but that series has a section on implementing a display buffer for VGA text mode. It should be possible to adapt it to your needs.
https://github.com/rust-lang/rust/issues/46213
/r/playrust
Oh shit... lol thanks 
Ah ok, I could have sworn it was on at least the minimum required version (to use without the flag), but I did not check before posting.
Is your crate different from what [this one](https://crates.io/crates/memmap)(memmap) does?
And lo, my google-fu has failed me. Thanks for the pointer.
I think that mem_file is a wrapper around shm and memmap is a wrapper for mmaping files. shm is a chunk of memory that is shared between processes, mmap is used to map a section of a processes memory to the memory accessable from a file descriptor (such as a file, or shm). mem_file does use mmap to map the shm to the processes memory, but as far as I can tell, memmap doesn't do anything with shm. That's from the context of linux anyway, I don't know how it works for windows.
been hacking together some personal productivity software--making a "new tab page" extension for Chrome that hits a Gotham server running locally which parses all the [todo.txt](http://todotxt.org/) files in my Dropbox, combining them into a big todo list. it also shows the last modified dates of files I'm interested in (project todos, a journal, a blog, etc...) and, given goals like "write here once a week," reminds me to update them when they haven't been written to in awhile. been serving up static pages via [askama](https://github.com/djc/askama) templates, and loving them mostly--but as I add more client-side functionality I'm feeling the pull towards something like [yew](https://github.com/DenisKolodin/yew). this is turning out to be the side project where I really grok rust--and I'm starting to want to write nothing else
I was about to direct you to [rustbud](https://gitlab.com/Screwtapello/rustbud) and the modular crates published alongside it, but then realized who I was replying to 🌚
What about type conversion? JS strings are UCS2, the numbers can be both int32 and f64, the lists and dictionaries can contain mixed types, etc.
I couldn't find it on Google either, I had to use Github search for rust-lang/rust to find it, but I knew it existed already because I saw it when it was first posted.
How about running wasm? That seems like much more of a common use case. 
I ended up using tiny-http which was actually perfect for my use case but thank you very much for your answer! At least I'll know how to handle the problem next time I'm confronted with it. Have a nice day!
There is [priroda](https://github.com/oli-obk/priroda) but it currently doesn't work because of miri. [Here](https://github.com/oli-obk/priroda/pull/3) is an example what it looks like.
What use cases do you see for this? Primarily code exploration for newcomers to a project? How would it fit into a development workflow? This seems something relatively unique to Rust so I wonder how it would work. It looks super cool, so thanks for working on this!
I know that I’ve read this before, but thank you regardless because I didn’t get a chance to try this out before it vanished throught my right ear.
HIR/MIR/LIR are a common pattern in very traditional compilers. Guess that's where OP got LIR from. - HIR: Very close to the source language, typically the AST. - MIR: Reduced version of the HIR, where high level language features are lowered to simpler constructs. For example, a C compiler might transform `switch` to an `else if` tree here. In Rust, lifetimes are gone in MIR, IIRC. - LIR: In Rust's case this is LLVM-IR. The "low-level (L) intermediate representation (IR)" is something very close to machine code, where the constructs of MIR have been reduced even more. Typically this is some SSA-representation of your code in some machine-like language.
Looks great!!! Thank you
Why won't you just use [https://play.rust-lang.org](https://play.rust-lang.org)?
Doesn't Graal already JIT everything? That would mean that using LLVM bitcode gets your pre-optimized code, that can be optimized a little more at runtime. I don't see much use of Graal for Rust purposes. Or for mosts things, really. It mostly seems to be granting a common FFI framework between the things running in the Graal VM, and AOT compiling Java with it is useful, but other than that, it seems like nothing more than a cool but kinda useless project. (Also, Oracle. I wouldn't trust something without a *proper* permission-granting license like Apache 2.0 or GPLv3 from Oracle.)
&gt; It'd be ideal if it worked on Windows without docker Aren't you using WSL? 
Navigating source code is essential while debugging. It’s also useful for understanding code you didn’t write (or wrote 6 months ago). This is not unique to Rust. See for example https://searchfox.org/mozilla-central/source/layout/style/Loader.h for C++ (try clicking around).
&gt; So... even though I wanted to separate my StructOpt related code into it's own file, if I want to call the method it adds ::get_args() to get an instance of my CLI args struct appdata::Params I have to additionally keep use structopt::StructOpt; in main.rs as well?? It's a current fact of Rust that trait methods are scoped with the trait. That is, you can't call a method from a trait unless the trait is in scope. This is to avoid problems with two traits defining methods with the same name; it can definitely be annoying at times, when the methods are "clearly"/deeply tied to the type in question. One hack for avoiding this is to define an inherent method with the same name as the trait one, e.g.: impl Params { fn from_args() -&gt; Params { &lt;Params as StructOpt&gt;::from_args() } } &gt; It's been suggested that I keep StructOpt code in main.rs and hopefully it won't cause any issues passing that struct around to other modules I know friction can add up to be a death-by-thousand-cuts thing, but is adding a `use` line (that the compiler suggests) a large issue?
It sucks for the Graal/Truffle developers but they knew who they signed up with. Not saying they agree with this stuff or feel OK about it, but it's not like Oracle hasn't been doing this kind of thing for decades. When you agree to be employed by Oracle to work on cool projects, you know that they will be tainted in some way.
As thaynem said, memmap looks to be even more generic than mem_file since it maps any file into your memory. mem_file ensure that the files you're mapping are backed by memory and provides safe write/read primitives (although see glandium's comments). Idk how far you've gone into ivshmem but but if you already have code that shares memory properly with qemu (ivshmem server), then using memmap on that shared file might be the way to go (but you'll have to take care of your own locking). Eventually, i'd like to add ivshmem compatibility to mem_file.
GDBGUI?
&gt; This is to avoid problems with two traits defining methods with the same name; it can definitely be annoying at times, when the methods are "clearly"/deeply tied to the type in question. Yeah that bit is a tad confusing for me. Isn't most things scoped already where Rust will point out a problem if there is a conflict. If I had two modules with the same struct or function call and did a glob use for both modules, is that somehow different? I'd have thought that the trait could be scoped to the module that it's defined in, and I could just use the method like normal. If I were to try at some point add another trait for it with the same method name, like in other cases that is when the compiler would stop me and point out I made a mistake. &gt; One hack for avoiding this is to define an inherent method with the same name as the trait one, e.g.: My memory is bad, I've not actually implemented my own traits before then, just added methods like your code snippet with `impl Params`. Probably why I'm experiencing this the first time then. &gt; but is adding a use line (that the compiler suggests) a large issue? No, it's just a bit confusing to go over code and wonder why I have stuff related to my code in another file being declared in main.rs(like the extern crate thing). I already have to do it with the extern crate declarations, so it's fine. It's more of a pain to add pub to each struct and their methods(26 pubs this time around). Asking for a `!#[all_pub]` or something is perhaps unlikely to be approved? :)
&gt; Yeah that bit is a tad confusing for me. Isn't most things scoped already where Rust will point out a problem if there is a conflict. If I had two modules with the same struct or function call and did a glob use for both modules, is that somehow different? Now, importing traits is done to resolve ambiguity. Two traits can define a function of the same name on a type. Now, you might assume that the situation is not ambigious now, so why doesn't Rust just take that? Simple: because of the _now_. Future changes to your code or even a depending library could bring a second method of the same name with them. Suddenly, your _old_ code won't compile, because _suddenly_, you need to explicitly import. This will be far more frustrating then setting it up right in the first place. This is called "action at distance" (changes to other parts of the codebase lead to compilation errors somewhere else, potentially all over the place), which is something Rust explicitly avoids. Now, you could argue that large codebase changes could be made easier by refactoring tools, and this is right, but the same goes for your problem (which is a much simpler one). And indeed, IDEs with quickfixes already have these available for this problem. 
WASM is also being used in the cryptocurrency/blockchain space. We're using it quite heavily at my job: we've altered our Ethereum client to allow WASM smart\-contracts, we've written a framework for building blockchains whose entire state transition is defined in upgradeable WASM, and are subsequently using that to implement that kind of chain. And we wrote a pure\-rust WASM interpreter to make all of that happen. That is pretty heavily\-motivated by JS and its ability to then easily interact with those things, but also by WASM's versatility as a compiler target and strong industry support.
What an awesome "someone should" project. I think I'm going to start hacking on this tonight. With things like https://datafusion.rs/ and all the things at https://arewelearningyet.com/ being worked on. It is just a matter of time until a a Jupyter kernel is desperately wanted. Thanks for the idea!
You might also want to look at http://stevedonovan.github.io/rust-gentle-intro/index.html.
The documentation on docs.rs has the equivalent of a README, but I also generated one in the repo now. You're right it's essentially like `box` with the same caveats, but works on stable rust. It works because the `new_with` method takes a function or closure. The `new_zeroed` method has no direct equivalent in std, stable or nightly. The closest is the optimizations in `vec!` that this crate uses.
I’m trying to collect a stream of data that’s coming in via a (pre-created) FIFO. (I’m teeing off some output from ALSA so I really would prefer to use a FIFO). Opening it for reading, as though it were a regular file, blocks the program. Web searching reveals various things. Is there a current recommended approach for FIFOs? Do I need to get my hands dirty with libc?
Cool. Thanks, looks very useful.
So what exactly is blockchain used for? I don't think identity has some kind of double-spending problem. I can see why it's good for all to have the same view, but I'm not sure why public key cryptography would be insufficient. Does it use it's own blockchain? If yes, what extra feature that is necessary for identity does it have?
My question is whether there should be a line. E.g. if there was a Rust software specifically designed to steal from people, would you like to see it here?
I think this question is not asked enough.
Git is actually perfect example of something that looks similarly but isn't actually blockchain. I argue that you don't need blockchain for as many things as people imagine. You don't need blockchain for git, so git is well-designed. It also doesn't have the same requirements: &gt; It's absolutely necessary by definition of the problem that is being solved for everyone to have exactly same view of the state. Not requirement for git. The result of different state of git repository is two separate projects. The result of different state in currency are two currencies (with half the network effect). Git isn't required to resist governments (but still can if you simply encrypt everything).
🚫
I don't believe anyone has built one yet, no. If it's built in rust and uses rustc/cargo, windows support will hopefully be a given (everything should be cross platform by default, mostly). There's some previous work at https://github.com/pwoolcoc/jupyter-rs and https://github.com/takluyver/calcurust. This idea seems like a good thing to add to https://github.com/not-yet-awesome-rust/not-yet-awesome-rust (I think they accept PRs?).
There's [liner](https://github.com/MovingtoMars/liner) which supports ANSI terminals, but I don't know if it has non-ansi windows support.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/fdehau/tui-rs) - Previous text "tui" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Jupyter is growing in popularity in the security world. I know of an analyst that has written a lot of his assessment toolkit in Jupyter, so that he can execute it on your target system and - poof - out comes your PDF report. Or at least, some initial ones to review and then make targeted efforts after that.
𝕴𝖋 𝖞𝖔𝖚 𝖌𝖔 𝖔𝖛𝖊𝖗 𝖙𝖔 [𝕔𝕣𝕒𝕥𝕖𝕤.𝕚𝕠](https://crates.io/) 𝖆𝖓𝖉 𝖘𝖊𝖆𝖗𝖈𝖍 𝖋𝖔𝖗 "ꜰʀᴀᴋᴛᴜʀ", 𝖞𝖔𝖚'𝖑𝖑 𝖋𝖎𝖓𝖉 𝖙𝖍𝖊 𝖈𝖗𝖆𝖙𝖊 [ｍａｔｈ-ｔｅｘｔ-ｔｒａｎｓｆｏｒｍ](https://crates.io/crates/math-text-transform), 𝖜𝖍𝖎𝖈𝖍 𝖑𝖔𝖔𝖐𝖘 𝖑𝖎𝖐𝖊 𝖜𝖍𝖆𝖙 𝖞𝖔𝖚 𝖜𝖆𝖓𝖙. 
No problem ! I created an issue on the [mem_file github](https://github.com/elast0ny/mem_file/issues/4). I'm only working on this as a side project but I also might see a use case for ivshmem support so i might work on it sooner than later ! My ivshmem C prototype was very rough and from what I remember, trying to figure out how ivshmem actually worked was a pain in the a$$ so we'll see what I can do ! Thanks for the suggestion !
Some details are [here](http://aturon.github.io/2018/04/06/rustup-xargo/)!
The [white paper](https://sovrin.org/wp-content/uploads/2018/03/Sovrin-Protocol-and-Token-White-Paper.pdf) can explain a lot better than I could. I'm very far from an expert in the field lol so I'll let the experts do the talking. I highly recommend you at least glance over it. It uses an open source distributed ledger (I think there is a slight distinction between that and a blockchain but I'm not super clear on the details myself) called [Hyperledger Indy](https://www.hyperledger.org/projects/hyperledger-indy) (under active development) that is backed by the Linux Foundation.
Cool work! Did you blog about rustw previously? I think I saw it while going through TWiR. If you want to take this browser to another useful place, imagine this command: cargo src —open http://github.com/user/project.git#1.0.9
Is there a reason to use your own custom [`Zero`](https://docs.rs/boxext/0.1.0/boxext/trait.Zero.html) trait rather than [`Zeroable`](https://doc.rust-lang.org/core/nonzero/trait.Zeroable.html) from `core`? Is it just that the latter is unstable?
Also worth noting that LLVM has its own MIR which is [Machine IR](https://llvm.org/docs/MIRLangRef.html). &gt;MIR is a human readable serialization format that is used to represent LLVM’s machine specific intermediate representation.
Jupyter Dev here. we (at leas I) would love an R kernel. Keep in mind that the Jupyter execution model is a bit at odd with the Rust (and many) compiled programming language. Jupyter supposes you have partial execution/compilation withe a persistant namespace. Rust tend to need a full crate as a unit of compilation. That is to say cell 9 in rust can influence whether cell 1 can be compiled. This needs come with other languages (and even in Python sometime), so your feedback would be welcome !
Very interesting. I have always wanted an empty box but I guess I can get that with `Box&lt;Option&lt;T&gt;&gt;` or `Option&lt;Box&lt;T&gt;` if I wanted. I didn't know about https://github.com/rust-lang/rust/issues/50047. Makes me concerned.
I know its helpful for debugging, but It feels like the workflow is a little weird. Instead of having an IDE which has the compiler/terminal-messages and editor, you need to switch between the IDE and your browser, which has a copy of your source code. So you have two copies of your code available, one editable, one not. It looks really nice, I am just curious if it has other uses, for when you don't have your editor up already. I guess I should word it like this: Does this have any features that wouldnt be present in an IDE? Navigating via the web is a cool feature that wouldnt be used in an IDE. I am not trying to marginalize this work, I think its a really good step for Rust, especially towards a good IDE. I would love to help work on it :) 
&gt; I bet that showing it on some other areas first will prove more successful. Yes; my "plan of attack" when I judge it ready-to-demonstrate is to showcase it with a utility/prototype. Rust shines for small utilities because of static linking, after all! In the meantime, I am steering people towards ripgrep; it makes my point with little effort.
&gt; A lot of protocol parsing is just defining the right struct layout And then there is FAST Fix \o/ At least it's fun to implement.
Great! Are there plans to give more stats than the "average"? I am wondering if it could be useful for sliding-window based throttling; for example.
The author of that work also wrote a great [blog post] (http://camlorn.net/posts/April%202017/rust-struct-field-reordering.html) about it
No plans right now; but you're welcome to open up an issue if you have a cool idea in mind!
I'm fine with malware, ransomware and whatever else (even Comcast billing and infrastructure software) posted here if it's written in Rust, we can view the source code and talk with authors. And ICOs are not even in the same league. 
Borrow checking is done after conversion to MIR, so lifetimes must still be present.
Great project! I definitely see the use case of using flipper to make it easier for computers to interact with the wider world. Some of my first experiences working with hardware involved doing basic digital I/O over a parallel port. From my perspective, this project is about making the computer you have more powerful (more functionality), rather than making an embedded project smarter / more connected. I couldn't really find an api reference for the project, and the language bindings are... bare (just the led and gpio for python, plus the UART for rust). Digging into the source code it looks like you expose the SAM4S DAC (sweet!), but it would be good to see the peripherals in action - I2C, SPI, UART RX, PWM, ADC, and DAC. The example project in the repo root doesn't really seem to be doing much (at least on master, the dyld branch has a proper example). It would be great to see the language bindings developed more, and to see some examples.
Termion is lower level than a line editing library. Liner is built on top of termion, for example.
I've been using rustyline and it works for me on Window, OSX, and Linux, but I haven't tested on BSD. My code is here: https://github.com/dagit/rust-prolog The parts where I use rustyline are roughly here: * https://github.com/dagit/rust-prolog/blob/master/src/main.rs#L155 * https://github.com/dagit/rust-prolog/blob/master/src/solve.rs#L117 It's worked quite well for me and I don't have any complaints with it, but my uses might be a bit on the simple/straightforward side of things.
https://www.reddit.com/r/programming/comments/8cw2xn/overview_of_the_efficient_programming_languages/dxmxj78/
Actually you can import crates in any file you want. But using declarations must be prefixed with path to the module whare you import extern crate. So if you have module `foo::bar` (in file `src/foo/bar.rs`) and you import crate `blah` there then to bring type `blah::Blah` into scope you need to write `use foo::bar::blah::Blah;`. Or for file `src/foo/bar.rs` `use self::blah::Blah`.
Why the downvotes? It's a well-known fact that `gnome-shell` has severe performance and memory-management issues - I say this is the admittedly unusual case where RIIR is actually a constructive response!
Those are different traits. - `Zeroable` is implemented when a type could be reasonably used without its zero value. - `Zero` is when a type has a valid all-0 representation. Note that `Zero` is implemented for floating point types, arrays and tuples.
You can almost guarantee anything that claims to be a new paradigm isn't.
Bad bot
On large projects, I often spend a long time understanding code before I start writing code, and I find tools like this (or DXR, SearchFox, sourcegraph, LXR, etc.) much easier to do that with, rather than use an IDE
I think that when you are in primarily understanding mode (rather than writing mode) it is easier to navigate in a browser than an IDE. I'm not sure there are other features that an IDE *can't* have, but it might have more sophisticated search than IDEs usually offer (but the real advantage is ease of use, because we don't have to provide editing functionality, it can be much easier to navigate, e.g., by jumping on a single click or showing lots of preview hovers (we don't do this yet)
looks similar, yep
I think I have, although probably quite a while ago
Unfortunately not - we've been thinking about how to offer that in the context of IDEs, but no concrete plans
What am I doing wrong with Lifetimes in this scenario? https://gist.github.com/rust-play/d263703e74a7433d411dc0bc1d8406a4
Currently trying to use webpack + wasm + chrome causes an error since chrome will not allow wasm files to be synchronously compiled when they are larger than 4kb. To get around this wasm-bindgen offers the command wasm2es6js to convert your .wasm file into a .js file that includes the module as a base64 encoded string. This is a great work around, however if I have converted projects using this it would significantly increase the total size, this allows you to get around the webpack implementation by changing the standard `import * as wasm from './wasm_bg';` statement to instead `fetch` the same file and then synchronously compiles it for you.
Why are you storing `&amp;mut usize` in your struct? All you are doing is just dereferencing it to a plain old `usize`. From the current code, I also do not see the need to have `&amp;mut Vec`, the graph could just own the vectors. Works wonders when you remove all that. No need for explicit lifetimes either. https://play.rust-lang.org/?gist=e293ac15d3eeb97649d807a8e10e843b&amp;version=stable
&gt; half-abandonned Well, it's not like a readline clone needs to constantly be updated. There's just not much to change?? I'd definitely expect these things to be just... stable.
Enums also have a lot of tag optimizations aside from the null-pointer optimization these days https://github.com/rust-lang/rust/pull/45225
Yeah, it's basically [firmata](https://github.com/firmata/arduino). 
Thanks for all the good work so far! Not a single mention of auto complete is a bit saddening though.
I actually made the assembly part of the kernel and the VGA bit using that tutorial, if that helps you any.
&gt;it might have more sophisticated search than IDEs usually offer Hm, I think this underestimates the state of the art in IDEs. JetBrains stuff has all kinds of semantic searching, filtering and grouping ) Could we add it to docs.rs though please? :)
Nice! I've been wondering, is there a good and stable way to programatically interact with `rustdoc` yet? Like having it dump JSON, or deserializing data it already produces in the HTML docs? I'm interested because querying docs and APIs from the command line would be a big win for me, but I haven't found a good way to do that in the past. I should probably look into the possibility of making a shell for RLS or something similar.
Sooo `gnome-class` seems to be completely focused on exposing GObject interfaces *from* Rust, and the opposite stays in gtk-rs's `gir`?
There isn't at the moment, no.
Thanks. As you can tell... I'm new to Rust and lifetime handing
Ah, too bad. Would you happen to know if the RLS route would be a possible sane solution?
📅 2018-04-19 ⏰ 19:28:47 [(UTC)](https://www.timeanddate.com/worldclock/converter.html?iso=20180419T192847&amp;p1=1440) &gt;We just released fastmod, a fast, partial replacement for codemod, to assist you with large-scale codebase refactors. https://github.com/facebookincubator/fastmod &gt;— Facebook Open Source ✅ ([@fbOpenSource](https://twitter.com/fbOpenSource)) &gt;🔁️ 5 💟 21 &amp;nbsp; ^(I'm a bot and this action was done automatically)
It's got too many bugs at the moment. Eventually!
The ecosystem is moving really fast now. Big changes to cargo/rustup, rustdoc, RFC for async keyword and futures, NLL, and many, many more changes. Is there a place where we can follow the progress of all these things? Like a list of features/tools and a "in progress/finished (in rust 1.27)" status.
If it's just a question of UI, perhaps you could round up selections to the smallest enclosing expression and pop up the type of that?
Thanks!
I'm a bit confused by the goals for rustdoc vs Doxidize. Is the latter a full replacement for the former?
&gt; Moving variables into structs, I'm reminded that it's either all fields mutable or all immutable, or use some alternative approach with different way to interact with the data(get/set). Reading up a bit more on that now, a little sad migrating related variables to a struct imposes extra friction, I'm sure it's for a good reason though :) This is called interior/exterior mutability, there's many things you can do to modify how these work. You could have a immutable instance of a struct with a Cell inside it, with a mutable value inside the Cell, which would mean it has *interior* mutability and *exterior* immutability.
Good times. But aside from cme, what equities/derivatives exchanges that matter don't have a binary order protocol? Is it more common in Europe?
It's a tough market. Lots of competition.
Everything is progressing exceptionally. But IDE support is still really poor (Autocomplete/Diagnostics). I assume this is because rls is using racer for auto-completions because it's faster than directly using rustc (through the save-analysis?).
About Doxidize: have you thought about its integration into docs.rs? If Doxidize becomes the new standard, then please let it work with docs.rs °_° Looking forward to all of this :)
It’s really sad rustyline is not updated anymore. It’s pulling in some really old crates.
The post says Doxidize is rustdoc's successor, so I'd assume it is meant to replace it fully.
Wow. Consider me blown away
First things first. We gotta get it working before we worry about stuff like that.
Generally, one would use pointers/handles instead of converting/copying types at the boundary. My comment was referencing when you pass values that can cross the ABI boundary directly.
This is a well known issue. Once the non-lexical lifetimes are stable, this code will compile. Until then, you should encompass the mutable borrow in a separate scope: ``` // &lt;...&gt; let y = g.add_node((2, 1)); { let x_read = g.get_node(x); println!("{:?}", x_read.data); } let edge = g.add_edge(x, y, 1); ``` Once the scope ends, the borrow is dropped and you are free to borrow again.
Everyone has their favorite editor/IDE, and mine doesn’t provide code navigation where e.g. clicking on a method call can lead to definition of that method. And debugging can lead to code in dependencies, for example under `~/.cargo/registry/src` which is not really editable anyway.
Correction: Box::new(SomeType { data }) actually fills the allocated memory in place, only arrays are affected. The main use case is with function calls anyways.
The `core::nonzero` module (including the `Zeroable` trait) is deprecated and will be removed / made private soon.
Editions.
I'm currently using CPUIO only to read scancodes sent from the keyboard. My shell program then takes a scancode (it is set in a String) and then uses a match statement to convert the scancode to a letter. The shell then prints the letter onto the screen (WIP, trying to get it to print to one line) and pushes the letter to a another string (this one is for the command that is being ran).
Bad bot
Thanks for this recommendation, is working well for me.
Ah that makes sense. Thanks for the help!
By chance, do you have any idea how it was done in case of the Go kernel linked above? I asked the author, but haven't got a response yet, and couldn't find any technical overview...
GIT is like a variable-size block chain. It exactly fits the first few lines of the wikipedia article for blockchain. Many of the requirements are the same. If I've got the same HEAD hash as you, then I can be fairly sure that no-one (especially governments) has tampered with the source previous that hash on just one of our copies of the repository. This is pretty important for something like the Linux kernel. Yes, if you fork, you'll have a different version, but if you're going to work in a distributed group towards a common goal, then you all need to converge on the same hash again, so that's the same as bitcoin. Staying in sync is very important for a distributed group of programmers (or else merge conflicts get really really bad). The workers on bitcoin that maintain it are miners, the workers that maintain a git project and give it value are coders. Don't get enough coders on your git fork, it becomes useless, just like a cryptocurrency fork that doesn't attract users or miners. So I think there are more similarities than differences.
This looks great. I killed a full hour last week trying to get sed to work, to no avail. Hopefully this (fastmod) will streamline changing the version of a crate across a few dozen Cargo.toml files. 
you should ask the ihaskell guy for tips too 
Not quite, we only have type information available for identifiers, not for expressions.
Some real-time systems require a short latency. For example, a car air-bag device. So they are both real-time and low-latency. How low the latency of a system must be to be considered a low-latency system? For example, is Skype (video and/or voice, not text) considered a low-latency system? Are there low-latency systems that are considered neither hard real-time nor soft real-time systems?
OK, then. My point remains. Please explain what you're doing that makes no std support worth the hassle in a text editor so I can understand what to suggest. If you're intending to target any normal desktop OS, you won't be allowed to use CPUIO to read scancodes from the primary keyboard without root/administrator privileges because it could be used to implement a keylogger that can see passwords being entered. (Even the [evdev](https://crates.io/crates/evdev) API, which is Linux's proper low-level input API, is configured to deny access to keyboards by un-privileged users by default.) Working with a terminal attached to a serial console *is* generally possible, but you have to make your user part of whatever group (usually `dialout`) is granted permission to have unconstrained access to serial lines. On POSIXy platforms (anything but Windows or bare metal), the ncurses library is responsible for abstracting away the complexities of switching the terminal from line-buffered to raw input mode. As for Windows and bare metal, it's probably the same as cursor motion. (You'll need `winapi` for Windows and some raw assembly language for bare metal.) As for output, it doesn't really matter *what* you're using to output, because my point isn't about the use of CPUIO, but the *lack* of use of standard abstraction layers. If you're outputting to a POSIXy terminal, you *can* achieve cursor motion by mixing escape sequences into the text you're printing, but you'll need to either use or reinvent the portability layer that ncurses provides and the forest of terminal definition tables (termcap and/or terminfo) that it relies on. If you're outputting to an x86 screen on bare metal, you'll probably need the aforementioned raw assembly language because I can't find any crates which wrap the x86 BIOS APIs. If you're outputting to a console on Windows, then you'll ultimately need the `winapi` crate because everything that can do what you want is ultimately just a wrapper for `kernel32::SetConsoleCursorPosition`.)
No, no clue. And there are several go kernel. Gophernotes is an interpreter so it's basically re-implementing the GO language (or part of it ?), lgo seem to likely create intermediate .so/.dll object and link/load them dynamically (I would say that because of the weird error message you can get ). I would ask the guys behind Cling as well. There seem to be a good check of logic heck that could/should be shared among compiled languages. Also have a look at https://github.com/QuantStack/xeus which implement most of the Jupyter protocol in Cpp. The Haskell kernel use gchi so haskell already have a lot that allow REPL usage.
Base64 increases the size of your file by 1/3. That's because base64 uses 64 human readable 1-byte chars. That means that for 1byte you express only log2(64)=6bits. Fortunately, if your server supports gzip, it should bring it down to something much closer.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/56rXT2T.jpg** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
Very interesting about gzip, I didn’t even think about that, I was just looking at the pre-network file size. I will have to play around with that some more. 
Interesting. I thought wasm was prezipped (not sure where I got that). In theory, a great compression algorithm should compress base64 wasm to roughly the same size as compressed wasm... But that's theory! In practise, Base64 is not byte aligned, so a repeated chain of bytes in the wasm is likely to be repeated 1/3 times less in Base64. It might actually hurt the compression pretty badly!
I'm part of a team working on C to Rust migration tools. Ours is not the first effort but it improves upon earlier approaches by using a mature C/C++ parser (clang). https://github.com/immunant/c2rust
Twiggy is a code size profiler for wasm: https://github.com/rustwasm/twiggy More info on WebAssembly studio: https://hacks.mozilla.org/2018/04/sneak-peek-at-webassembly-studio/
gtk-rs not only generates bindings from gir files it also contains everything to write GObjects from Rust already, gnome-class simply generates all the boilerplate code from a nicer description of the GObject.
That wasn't what I was addressing. 1. `extern crate` all need seem to be required in my `main.rs` file, not the file that actually uses the crate. That confused me since it's clear what crate I want to use in my `Cargo.toml` dependencies, why require declare that with `extern crate` in my `main.rs` as well? I assume because while Cargo is what most people use for managing crates, you can do so without Cargo? 2. My main frustration with moving code out from `main.rs` into it's own file/module for the purpose of organizing my code better and not having a big single `main.rs` file for my project was that the scope/namespace caused in doing so now requires I make all my struct and the structs fields `pub ` as I just wanted to split into file for organization purpose, private by default added friction. 3. Not having much experience with traits, it turns out that because I use a function call on my struct that moved to another file, the function was added by a crate(StructOpt) via attribute at compile time which is done with a trait apparently. So I have to similar to the `extern crate`, declare a use statement to StructOpt in my `main.rs` along with the use statement for the module/file containing the struct, because I am calling the trait method externally from the module in my main.rs.. The compiler is unable to implicitly understand it shouldn't be an issue according to another response in this thread. Ideally my module would have encapsulated everything related to it so that I'd only need a use statement for the module itself and nothing else in another file like main.rs or another module that uses it. Ideally since this is a binary and not a library project, it'd be possible to declare something like `!#[pub_all]` to make everything in the module pub by default instead of private. What you're describing if I'm not mistaken is bringing a module into scope elsewhere, or re-exporting? That doesn't avoid the issues I pointed out above afaik. 
Hey Steve! I saw you last week at the Web à Québec conference. I asked the question about tooling/IDEs - between your reponse and this post, my question has been more than answered. Thanks !
so the rewritten version of rustdoc won't be developed anymore?
using `gzip --best` from the test project the compressed files are: .wasm: 282kb =&gt; 95kb .js: 378kb =&gt; 128kb
Thanks for the follow up! So : wasm is not compressed at the moment, and base64 is hurting. I think there is some plan to compress the binary directly in the future : https://github.com/WebAssembly/design/blob/master/BinaryEncoding.md
I don't know what this is but I am happy for my WebAssembly friends :)
Does the rust code run as a lambda function? I've been trying to figure out how to do it without going through python or something else. 
Whoa, I didn't know \`codemod\` existed! \(Well, I expected \_something\_ like it to exist, but never really looked for one. I should have, codemod/fastmod seem great!\)
If you are interested in codemod/fastmod, you will probably be interested in rerast too: https://github.com/google/rerast
What is needed to get this to work on MacOS?
Thanks for the link! &gt; Toolchain declarations within Cargo.toml, as with the Xargo integration. This is the sort of thing that confuses me. As I understand it, Cargo is part of the Rust toolchain—perhaps not in the traditional compiler-assembler-linker sense, but often a Cargo feature requires a version of `rustc` that supports a particular flag, for example. Is Cargo going to update itself? Shell out to rustup to do an update which then re-executes the new version of Cargo? My goal is to allow Rust projects to include a some kind of toolchain description that can deterministically be turned into a specific, running toolchain. If it's just "cargo can download and install the `rustc` and `rust-std` versions listed in `Cargo.toml`, that's great. However, if Cargo can quietly update itself, that's terrible for reproducibility. I hope you can see my concern. :)
I suppose we must go in the direction of most excitement but rustdoc is Good Enough. (In fact compared to other ecosystems it's f-king fantastic)
Ooh, I like this, very nice :) Tooling is one of the big problems I have when I talk to other people about trying Rust; The language in general is now pretty approachable (especially due to stuff like ?), and while I personally am kind of used to working with bare-bone tools, a lot of people aren't. Yes, the compiler and related tools like clippy are all awesome, but still. Just a very general question, does this include the IntelliJ plugin stuff? Seeing as they're (afaik) not using RLS but their own implementation for auto-completion etc. It's mentioned, and I presume that they will definitely at least indirectly profit from these efforts, but are there any of the developers in those working groups? I'll gladly admit that I'm too lazy to look them up myself :D
It would be really nice if you could show some examples of input and output. It would also make reproducing your problem way easier.
Isn't there an async import, or am I thinking of Dart?
Gosh I was expecting this comment and thought that I should write about subcommands... i'll do it here and update the article... Subcommands has 0 integration with Cargo. It can't extend cargo as such, can't change it's behaviour, is not receiving any special context etc... it's just convenient way to install and run an executable which will look at your project.
I added in the git repo in examples a sample log. To reproduce you can run something like `grep h examples/sample.log | ./target/debug/rustats -` If i dont grep pipe the output is [https://i.imgur.com/TwunjHM.jpg](https://i.imgur.com/TwunjHM.jpg)
&gt; A project compiling on nightly a year ago is unlikely to compile on nightly today. If you want forward compatibility and stability maybe you should try stable.
Well, I am not necessarily talking about my project, lots of open source project are on nightly. Also when you depend on a nightly, then you have to be on nightly. The point is not about nightly being unstable, it's about the lack of connection between your source code and your toolchain. I just wish I could specify which toolchain my source code is suppose to run on. 
Actually this is only kinda true for goto-definition. "kinda" because it's disabled by default *(ie racer is not used)*. Other than that rls uses racer only, and exclusively, for **completion**.
Hey Nick, is there any further information on that? I'm currently working on https://github.com/rust-lang/cargo/pull/5183 and would love some additional input on how this would relate to the fixes.
&gt; Manual Toolchain management A bandaid solution is to add a `rust-toolchain` file containing something like `nightly-2018-03-18` to your codebase root directory which rustup will automatically pick up to choose the correct toolchain.
`docs.rs` isn't part of the rust-lang organization, so that's kind of up to its maintainers :/ if you want doxidize support there, a good start would be to open an issue and letting them know :)
&gt; This also mean so if you have one dependency working on nightly, then you have to work on nightly too. If you have two dependencies on nightly, hopefully they are both working with the same nightly… That can lead to what I would call the Toolchain dependency hell… Many projects fix a nightly version, for example, in their C. In any case, complaining that unstable dependencies are unstable is a bit tautological. If you want stability, don't do that. That's precisely what the stable channel is there for. 
Well i think a lot of dependencies depends on nightly because of compiler features not yet stabilised but provide fairly well tested and stable output. It is a bit frustrating that you have to be yourself on nightly to use them. I guess it's indeed not really fair to blame it on cargo the fact that there is a fair amount of nightly dependency...
Why is C and C++ one language? How did C/C++ got only "3 (libs)" for cross-platform GUI and Python got "5 (QT, WxWidg)" is beyond comprehension for me. Both, QT and WxWidget are C++ libraries, Python has only wrappers for them.
Having a rust-toolchain file should be considered as good practice, why not even a requirement. That definitely help with figuring out which toolchain you should be on. Just saw that integrating rustup in cargo should happen in 2018, so this issue should be soon part of the past :)
Interesting. Is there any more documentation? Which types can cross the FFI barrier? Where do the compiled binaires get stored?
&gt; GDBGUI Never heard of it. Looks very nice!
term\_painter, term\_size and term\_cursor are my goto crates for this kind of stuff \- they all support Windows as well, which is nice.
FTR: This file should only be necessary for _application_ code bases that require nightly.
Now we see that everything can be accepted, just need a bunch of active people to force it.
Is 3.0 really breaks compatibility with 2.x?
It's always nice to see big players release stuff made with rust without even mentioning rust primarily. It shows that they chose the language for its qualities rather than just making a principle of using the new shiny thing.
GraalVM has experimental support for profile guided AOT compilation with the native-image command. Works roughly like this: 1) You create an image with profiles. 2) You run that image with representative workloads dumping profiles to file. 3) You create another image with the profile dump to guide the compilation. Preliminary results look very promising. Expect to hear more from this in the next months. 
&gt; Some dependencies only work on some architecture or require some external tools (gcc, python, …) Use docker. Its not a problem Cargo can fix and it shouldn't even try.
It's actually getting much better but there was a point where nightly was really hard to avoid. I guess we disagree because you imply that using an unstable dependency makes you unstable. I think if you could force a dependency to use a different toolchain than yours, then you could mitigate the problem. Stability of the compiler and executable stability are two very different things. They are link in some ways and compiling with nightly requires more attention to the output. Not being able to isolate scope is what I am pointing at.
Does that still grant you JIT functionality, or does that just put GraalVM at feature-equivalence with LLVM/GCC/others? If you only get PGO AOT, then Graal isn't really offering anything to AOT languages (apart from maybe a neat-ish FFI layer?). It's still cool for "lesser" languages (javascript, python, ...), of course. (Rust also has PGO available through LLVM, and its useable through cargo-pgo, but it's not currently available in the upstream tools. It's WIP through [issue #1220](https://github.com/rust-lang/rfcs/issues/1220))
I can see where he's coming from. AFAIK there's still no way to specify what minimum version of Rust your code requires.
What I'd like to see is a safe build mode. Which can download dependencies, but only if they're already locked using a cryptographic hash (e.g. SHA-256) in cargo.lock (i.e. external servers cannot influence the build output) and never modifies cargo.lock. I'd also like the default build command to ask for user confirmation whenever it modifies cargo.lock and/or downloads a dependency not locked by a cryptographic hash.
&gt; Dont build from source and problem fixed. Where should they come from in that case?
Can you elaborate a bit more? We already use a checksum here, what difference are you looking for? There’s still stuff to do here, but I’m not sure which part you’re looking for.
Let me try to answer this a little bit broader: There is no JIT left in the image if you just create an image from plain Java bytecodes with native-image (there is a GC though). You can choose to embed Graal as a JIT in such an image, if you want to add the capability to run any of the Graal languages (JavaScript, Ruby, Python, R, LLVM) in your image. LLVM in this case means that the bitcode is interpreted and compiled using Graal dynamically. We have developed the native-image command primary to make it possible to write the whole Virtual Machine in Java and not suffer from warmup issues. But it offers AOT for many other Java applications as well. You can not create native images from LLVM bitcodes (only Java bytecodes) at the moment. When we talk about LLVM support we mean the interpreter with dynamic compilation. It would be a significant effort, but not impossible to add LLVM bitcodes as direct input to Graal to support AOT compilation of LLVM bitcodes in Graal. &gt; If you only get PGO AOT, then Graal isn't really offering anything to AOT languages The use-case we are primarily aiming for is to use the LLVM interpreter/dynamic compilation for interop with dynamic languages. By interpreting LLVM bitcode we can make it safe to run the code sandboxed. That is a requirement for running things like Numpy (or a cool Rust library) in many embedding scenarios like the database. Another advantage is that we can dynamically compile LLVM bitcode together with dynamic languages in one compilation unit (no ffi overhead). We offer less to pure AOT languages in terms of performance at the moment, that is correct.
&gt; The new Rustdoc team is responsible for the Rustdoc software, docs.rs...
Does `--frozen` do what you want?
Honest question: does a Code of Conduct really have a positive impact? I just remember one instance of a project were the promoter of the Code of Conduct basically brought an inane Twitter discussion to GitHub and demanded that contributor to be expelled, despite not being herself a contributor. Maybe I have an unfair bias towards it and it really brings some positive value to a community. Anyone care to share their experiences about this?
Check out [/r/learnprogramming ](https://www.reddit.com/r/learnprogramming/)!
Plus, essentially every single cargo subcommand rebuilds cargo itself.
Fun fact, one of the members of the Rust Community Team was part of the twitter mob that started harassing the project owner on github.
Thank you for the elaboration. I see that my conclusion that AOT-compiled languages would mainly benefit from FFI. However, I was a bit blind to the full potential of this FFI functionality, and did not see the optimization benefit you mention—thank you for bringing that to my attention. While this does not make the AOT code any faster, it is very interesting that the foreign function call can be treated as a local compilation unit, potentially inlining the entire thing. If you don't mind, could you say if Graal is meant to be a LLVM competitor? LLVM's doesn't have a strong JIT game going, but there is definitely a clash as universal compilation targets. If Graal focuses on JIT and LLVM foces on AOT, they will of course live peacefully side by side.
One thing I'm hoping epochs will do is allow for things like that to be gradually corrected, so that Rust can remain streamlined and evolve. Unlike C++, which just seems to get larger and larger.
Any group \- even one of only two people \- has a code of conduct. As long as the groups are small this is usually not written down, but it always exists \(if you start breaking your friends noses they will probably not be your friends anymore \- so, that's part of your informal CoC\). When groups get bigger people usually get more different from each other, so you need more rules to make sure everyone is "on the same page" about what is okay and what is not okay. At some point it just gets easier to write it down and tell people to look at it.
The code deploys the binary that is built from a different file in the examples/ folder. You might be interested in [crowbar](https://github.com/ilianaw/rust-crowbar), it uses the python execution environment but it seems there is no python wrapper involved and call directly into the .so.
&gt; Honest question: does a Code of Conduct really have a positive impact? It certainly seems to have a positive impact on the Rust community. This community is among the most inviting and sincere I've experienced. There was a comment a week or so ago about someone that accidentally subscribed to /r/rust instead of /r/playrust. They don't know programming but stayed subscribed because of how nice everyone is. Is this a product of the code of conduct? It's hard to say, but the attitude the CoC extols certainly permeates the community.
You might be thinking of dart? [The `WebAssembly` object offers a few constructors:](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WebAssembly) ``` //all async compilations WebAssembly.compile(Uint8Array) -&gt; Promise&lt;WebAssembly.Module&gt; WebAssembly.compileStreaming(Promise&lt;Response&gt;) -&gt; Promise&lt;WebAssembly.Module&gt; WebAssembly.instantiate(Uint8Array) -&gt; Promise&lt;{module: WebAssembly.Module, instance WebAssembly.Instance}&gt; WebAssembly.instantiateStreaming(Promise&lt;Response&gt;) -&gt; Promise&lt;{module: WebAssembly.Module, instance WebAssembly.Instance}&gt; //synchronous compilation WebAssembly.Module(Uint8Array) -&gt; WebAssembly.Module ``` Currently webpack uses `WebAssembly.Module` to generate the dependency, and this is discouraged for larger modules, however chrome simply fails to compile any `Uint8Array` that is greater than 4kb in size. It might make sense update the project to use `WebAssembly.InstantiateStreaming` instead of `WebAssembly.Instantiate` but it looks like there is a little less support for the former.
The lgo post seems to have [just hit HN too](https://news.ycombinator.com/item?id=16882421), and some people there say it looks like a separate dll is compiled for each Jupyter "cell" and loaded as a "plugin" (which is not yet supported on Windows, thus apparently yhe Linux-only limitation). No idea however how variables are passed between the kernels; I guess maybe some basic parsing &amp; AST analysis?
The lgo post seems to have [just hit HN too](https://news.ycombinator.com/item?id=16882421), and some people there say it looks like a separate dll is compiled for each Jupyter "cell" and loaded as a "plugin" (which is not yet supported on Windows, thus apparently yhe Linux-only limitation). No idea however how variables are passed between the kernels; I guess maybe some basic parsing &amp; AST analysis?
My personal opinion: CoC is fine, I've seen forums with more draconian rules about communication that that (e.g. heavy filtering and complete ban on anything remotely political - discussing how healthcare works in US) but the mechanism of enforcing it and the stuff it enforces aren't as important in grand scheme of things. For example - is it possible to create a good API for time without Oracle suing the pants off you?
If I were to guess, I'd say /u/Icarium-Lifestealer's "safe build mode" is similar to .Net's [strong names](https://docs.microsoft.com/en-us/dotnet/framework/app-domains/strong-named-assemblies). The cryptographic hash is used to protect against hijacked cargo repositories by signing crates similar to how a strong name signs an assembly.
I really wish the `Try` trait would map from `Result&lt;T, E&gt;` to `Option&lt;Result&lt;T, E&gt;&gt;` etc.
Interesting, why differentiating?
The default should be to work on stable, and unless absolutely impossible, libraries should have a "nightly" feature to opt into nightly features, IMHO. There is no tooling to pick up rust-toolchain files of your dependencies.
Anything which doesn't require the external tools and preferably doesn't require lots of computation on your end. Different scenarios might have different solutions, whether its object file, Llvm bytecode, etc... That's definitely coming with challenges but i don't think it's impossible... This article is exposing pain points. The next articles will be about concrete solutions.
When ghoul day “contributor” do you mean someone who sends pull requests and opens issues or someone on a steering committee or with commit bits?
It is more about learning from each other rather than competing. After all the goal, to "port languages, speed them up and remove barriers between them" is the same. Right now, LLVM bitcode is of great value us, it would not have been realistic to interpret native languages (we tried to interpret C directly, you don't want to go there). So we will be dependent on LLVMs effort for a long time to come. Graal is not just a JIT compiler (as LLVM also aims to be), Graal is a dynamic compiler. This means that it can aggressively specialize the code and deoptimize to an interpreter if a speculation fails. This feature makes it so successful for dynamic languages. I don't know of any plans that LLVM will pick dynamic compilation up. Do you know more? With Graals AOT capabilities it becomes a lot more attractive to write systems software in JVM languages like Java/Kotlin/Scala. I can even envision a comeback for JVM languages in the gaming area. My personal dream :-). 
Yeah, I'm not sure I've ever seen an example of a Code of Conduct used for good. Would love to see one. I'm not necessarily opposed, but I'm skeptical that they do anything. And Coraline Ada, one of the champions of one of the CoC's, rubbed me the wrong way when she [tried to get the Ruby community to adopt hers](https://bugs.ruby-lang.org/issues/12004) and then [floated the idea of demoting Matz](https://mobile.twitter.com/coralineada/status/690334282607378432) (creator and benevolent dictator of the Ruby community whom everyone loves) when he didn't.
When he says the complainant wasn't a contributor he means they hadn't filed any issues, sent any pull request, or even have any indication of being a user of the project to which the complaint was brought.
I've never seen the interpretation of the [marshmallow experiment](https://en.m.wikipedia.org/wiki/Stanford_marshmallow_experiment) as one of trust rather than time preference. Is there more written about that interpretation somewhere? 
Non-Mobile link: https://en.wikipedia.org/wiki/Stanford_marshmallow_experiment *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^172852
**Stanford marshmallow experiment** The Stanford marshmallow experiment was a series of studies on delayed gratification in the late 1960s and early 1970s led by psychologist Walter Mischel, then a professor at Stanford University. In these studies, a child was offered a choice between one small reward provided immediately or two small rewards (i.e., a larger later reward) if they waited for a short period, approximately 15 minutes, during which the tester left the room and then returned. (The reward was sometimes a marshmallow, but often a cookie or a pretzel.) In follow-up studies, the researchers found that children who were able to wait longer for the preferred rewards tended to have better life outcomes, as measured by SAT scores, educational attainment, body mass index (BMI), and other life measures. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
No, I’m talking about the person who *was* contributing.
Doesn't that prevent network access? I'm fine with network access, as long as the data that will be downloaded is fixed by the data which is part of the project.
I personally have no use case for mac and essentially know nothing about the differences between Mac and linux. It might litteraly be the same code as Linux.(Afaik, you also need apple products to develop on apple ?) I'm certainly open for contributions though (I would wait a bit for the stabilisation of the API, I've been changing things around to make it more customizable)
As far as I know, there are currently two modes: 1. A normal build. If cargo.lock does not contain a dependency, it will be added (which implictly trusts the registry) and cargo.lock modified. If cargo.lock contains all dependencies, it already behaves like I want it to. 2. A frozen build, which will prevent all network access. This prevents restoring dependencies which are fixed using hashes. What I'd like is in the middle of the two: * The cargo.lock file does not get modified * If a dependency is in cargo.toml but doesn't have a hash in cargo.lock the build fails (or in the interactive variant, asks the user) * If a dependency has a SHA-256 in cargo.toml it gets downloaded and the checksum verified. Since SHA-256 is collision resistant, this means that the dependency is byte-for-byte identical to what was used when cargo.lock was created. Combined these rules mean that versioned project files will not be modified by the build and the source code of the project and all its dependencies is always the same every time you build. Even if the cargo registry is corrupted/malicious or the author of the crate creates a new signed version with the same version number, they will be rejected because they don't match the hash. So the worst thing a malicious crates.io can achieve is preventing the build (by not supplying the download) but cannot influence the data used in the build at all. A build server should use the non interactive variant, where build fails on non-locked dependencies. A developer should use the interactive version, where adding a new dependency requires user confirmation.
While digital signatures are interesting as well, they're not what I'm interested in here (and key management will be tricky). Digital signatures still allow the author of a crate to sign new versions using existing version numbers. Not sure how HMAC would be useful here, since it requires a shared secret key. I really mean collision resistant cryptographic hashes, like SHA-256 which bind a dependency to what was specified in cargo.lock, not having to trust any outside party, be they the author of the crate or the registry. (Of course you still need to trust the local tooling itself)
At the time of the complaint he was the most active contributor over the previous year, in lines added/removed, at least according to github. He also called himself maintainer for the project on twitter (that's how they found the project in the first place), so presumably he had the right to commit directly.
Do you have a particular example that illustrates this pain point?
You want to talk about *trust*? Fine. Let's look at Ashley Williams, the [lead of Rust Community team](https://internals.rust-lang.org/t/announcement-ashley-williams-joins-the-core-team-and-taking-lead-of-the-community-team/6453). On her previous occupation as a NodeJS board member she [violated CoC multiple times](https://www.reddit.com/r/node/comments/6whs2e/multiple_coc_violations_by_nodejs_board_member/), which lead to her no longer being a NodeJS board member. Now tell me how can I *trust* someone who said sexist crap like "kill all men" or "In fact, if you were a white dude and you wanted to talk at the conference, your chances were basically nil." to be a fair lead of Community Team? One of my main gripes with "SJW"s is not that they want to create "nicer spaces" but that they apply the rules they set in a very selective manner, with many examples. There are many communities ruined by "SJW infiltration", and IMO the right answer is to reject anyone who cries for safe spaces, equality of outcome and applying an ideology to something where it doesn't belong (see: feminist glaciology). I'm yet to see examples of this in Rust community and I hope I won't.
Alexy Kladov works on IntelliJ-Rust and is in this WG
&gt; It is more about learning from each other rather than competing. Ah, I did not mean "competing" in a bad way. GCC and Clang/LLVM competes, which has resulted in both compilers improving much more than they would have otherwise. So Graal will, for native code, be an LLVM backend for a while. I do however read that as a wish for Graal til build its own frontend ecosystem, putting Graal and LLVM as effective competitors sometime in the far future. Interesting. &gt; Graal is not just a JIT compiler (as LLVM also aims to be), Graal is a dynamic compiler. Ah, there's a misunderstanding here. To me (and I think to others' as well), a JIT *is* what you refer to as a dynamic compiler. That is, something that starts on a "fallback", analysis runtime behavior, and executes very aggressive optimizations based on the observed behavior. If assumptions held by the optimizer fails, the code deoptimizes back to the fallback for recompilation. Examples including PyPy's (auto-generated!) tracing JIT, V8's TurboFan, and of course the JVM's JIT compiler. So, to me Graal is is "just" a JIT compiler. :) &gt; I don't know of any plans that LLVM will pick dynamic compilation up. Do you know more? I unfortunately not. A true JIT ("dynamic compiler" to you) would be very interesting for the LLVM ecosystem. &gt; With Graals AOT capabilities it becomes a lot more attractive to write systems software in JVM languages like Java/Kotlin/Scala. I can even envision a comeback for JVM languages in the gaming area. My personal dream :-). I must admit to quite strongly not being a Java man. I don't mind the language that much (although it is inconveniently verbose), but the ecosystem and common Java programming styles/code bases bug me quite a lot... But don't let that ruin your dream! Projects like Graal benefits everyone by bringing new ideas to the table. ----- As a much less fun side note: Your phrasing indicates that you are part of the project by working with Oracle. Assuming this is correct, I'd like to point out that being "only" under GPLv2 is problematic, as it does not include explicit patent grants. Oracle is not a popular company by any measure due to its legal activities, and users (private and cooperate alike, me included) might not feel safe using a project from Oracle that could be followed by patent infringement claim if Oracle feels like doing so. Using GPLv3 or Apache License 2.0 would make users feel safer, potentially increasing reach greatly. Of course, there will still be some that avoid the project altogether because of Oracle's involvement, but that cannot be solved as easily. (The above is *not* intended to extract comments or opinions as to whether Oracle's actions were right or wrong, but are just a suggestion to improve project reach.)
@llogic This topic consistently produces discussions that are all heat and no light on this subreddit. In fact, as far as I can tell it's the only topic where the discussion tends to get really unpleasant here. Is it really necessary that you, as a member of the mod team, start discussions where you know in advance that people who usually get along perfectly well get really angry at one another, mods end up deleting comments etc.?
&gt; I just remember one instance of a project were the promoter of the Code of Conduct basically brought an inane Twitter discussion to GitHub and demanded that contributor to be expelled, despite not being herself a contributor. This is a huge problem. Many times, "Codes of Conduct" have been demanded by people who had nothing to do with the project in the first place, nor did they even intend to make any legitimate contribution to it - but as soon as the CoC was adopted, such people then felt free to tar even long-time contributors to the project with rather dubious claims of "CoC violations", often with recognizable political overtones. (I could of course add references to substantiate the claim, but given the context this would be quite counterproductive.) This of course misses the point of a CoC entirely - it's supposed to be a tool to resolve conflicts and make them less likely, not something that leads to extreme amounts of conflict and bad behavior where none existed before. It's very encouraging in this context that the Rust community as a whole seems to have escaped this failure mode so far - even someone as "controversial" (in the Twitterverse, of course) as Steve Klabnik is in fact readily acknowledged here as one of our most valued contributors, from *both* the strictly technical and the overall, community POV. But talk of "CoC's" *in the abstract* may not really make it clear what the *actual* issues are in this context.
That's hard to believe. I think the Rust community is the most inclusive and patient community that I have ever been a part of.
I have a lot of complex thoughts, but your summary of that situation is not a good one. Also, "I don't like the concept because someone once ran an action I didn't like" should really not be something to jump on. &gt; then floated the idea of demoting Matz (creator and benevolent dictator of the Ruby community whom everyone loves) when he didn't. Matz is lead of MRI. Community management has not been in his hand since years, it is done by groups like Ruby Central, Ruby Berlin, etc. I'm chair member of Ruby Berlin and have had my hands in the projects listed here: http://rubyberlin.org/ All these are fundamentally based on having a code of conduct and enacting it. All these events had minor or larger issues, which we were all able to clarify based on the CoC, which is why you never hear about them.
Heh. You know what they say, "keep your friends close and your enemies closer". After all, even the strictest CoC could not save us from a raging Twittermob.
I think an unfounded assumption is being made that thick skin correlates with negative behavior. Problems start with people who can't discuss technical issues without feeling like their pride is on the line. It's thin-skinned reactions that drive people away. It's thin-skinned people who want to drive others away. It's good to have a code to make sure everyone knows where the red lines are. Some people seem to think a more detailed code makes a stronger code, but it's really the opposite. When people try to address community issues by a legalistic process, collegiality has already failed. A detailed code builds in failure from the start. If I were to write a code of conduct, it would be this: Whoever goes *ad hominem* first is in the wrong. Unfortunately, many codes and enforcement processes actually reward going first. There's a first mover advantage to denouncing someone as "offensive", "unwelcoming", "toxic", etc. That's because people assign great import to these labels whose actual content is vague. It's the opposite of defining bright red lines. Where things really go off the rails is when a code overreaches in its jurisdiction. There are for example some projects that try to hold people accountable for everything they say on social media. That's just inviting people to abuse your processes and derail your project.
&gt; Honest question: does a Code of Conduct really have a positive impact? Yes. I maintain a code of conduct (http://berlincodeofconduct.org/), which has caused a great big number of event to think about the things they want and don't want to have at an event. The CoC itself is frequently debated and evolved (e.g. the "expected behaviour" section will soon go away, because we don't want to rule behaviour). I also run a great many of events. CoCs are not the end, they lead to handling structures, contact points and similar. This has been very beneficial to us. Because, unsurprisingly: problems are regular, but most problems are also in the range where an excuse is possible and can be extended. We (the organisers) moderate that process. This is why you never hear about this: situations get resolved and no one feels the need to make things public. This is, _clearly stated_, both the goal and the reality. It fails sometimes, and then you hear about things. In contrast to many other industries, our events and spaces are run by amateurs and going prepared into situations described in a CoC and having talked about repercussions before is a useful thing to have.
People framing things they don't even mention by name as "harassment" and sticking them on us is a regular thing people try.
&gt; Is this a product of the code of conduct? I'm gonna go out on a limb and say no, definitely not. A CoC won't make people pleasant or unpleasant, it just gives grounds to complain about specific stuff when you feel like it. The rust community is pleasant because it's populated by a core of pleasant people. Although maybe the existence of a CoC is a direct consequence of that as well, I don't know. But I really don't think it's the cause.
Every time that name and story is mentioned here the discussion is automatically cut short by the moderation team, but I wish it was seriously and extensively addressed at some point, because it does concern me, and obviously a lot of other people as well.
Physical spaces and community events of course benefit greatly from a well-defined CoC - no issue with that. But there's actually quite a bit of controversy as to whether CoC's should be adopted by projects that primarily work online, as an across-the-board thing applying to all online interactions. Something that often goes unrecognized is that the issues raised by offline vs. online interactions can actually be very different, and it may not actually make much sense to stick with a single "Code" purportedly addressing both.
What, I had no idea you could do this! Thanks! 🙏
I use "spaces" here to apply to online and offline spaces. I don't agree with your controversy: for the Rust _project_, the CoC is agreed on and we are faring good with that. There might be other projects disagreeing, but this is not a controversy. To be clear: I'm here for the CoC, many others, too.
&gt; Many times, "Codes of Conduct" have been demanded by people who had nothing to do with the project in the first place, nor did they even intend to make any legitimate contribution to it That sucks, but so does having to worry about whether you are a "real" community member. It's been a couple of years since I last contributed code to the Rust project, and I don't have any crates, do I still count? :p If there is no CoC for a particular programming language, a person might legitimately be interested in being part of that community (perhaps they're even already using the language in private or for some closed-source project) but refrain from doing so because there is no CoC. I think it's best to be charitable and assume that people interacting with the Rust community are, or want to be, part of the community (and people who don't want tobe a part of the community still might have valuable insights). I'm willing to be wrong sometimes if that saves us from gatekeeping.
I think it's necessary to address notorious subjects of friction within the community in *some* way. It doesn't have to be all flowers and butterflies, people will get mad and disagree with each other, but so long as we only make sure that no insults are involved, I'm fine with it.
&gt; is it possible to create a good API for time without Oracle suing the pants off you? I'm out of the loop, what is Oracle's claim on such an API? Not that it surprises me, mind you.
Of course, I did not mean to refer to Rust specifically! The Rust CoC has worked very, very well, and there's basically no controversy about it *in practice*, so far. (A few people here and elsewhere seem to hate the idea of Rust having a CoC as a matter of *principle*, but that's something entirely different! Even the Linux kernel has a CoC these days.)
&gt; plus we could've made Iterator just a specialization of Generator Is there no chance to reach that point someday?
&gt; People framing things they don't even mention by name as "harassment" and sticking them on us is a regular thing people try. On /r/rust, mentioning it by name tends to get your comment removed: https://www.reddit.com/r/rust/comments/7nx3cm/announcement_ashley_williams_joins_the_core_team/
&gt; Ah, there's a misunderstanding here. Just to make sure: Dynamic Compiler is just a more specific term for a JIT compiler. I started to use it because JIT can also mean using a static compiler "just in time". Dynamic compiler is not ambiguous. &gt; I must admit to quite strongly not being a Java man. The beauty of working on GraalVM is that I don't need to engage in language wars. We will just run them all ;-). On a personal note: I like safe managed well specified languages, so the code will be useful for a long time. I have no strong opinion on syntax or otherwise. I also like the ideas of Rust, but languages without GC make me think about the wrong things all the time. I cannot engage in license discussions here. But I will forward your opinion. &gt; Projects like Graal benefits everyone by bringing new ideas to the table. I fully agree! Thanks! 
Yes, this is not really the point of course. The actual problem is that "CoC's" as a whole have become associated in some people's minds with a sort of clearly problematic behavior, often with political motivations, and this does not exactly foster the kind of 'trust' that the OP is pointing towards! There's nothing wrong with novices having a say in these sorts of choices *in principle*, but if people start fearing politically-motivated 'entryism' and conflict, the novices are going to lose out.
Yes, because we consider the accusation baseless and the frequent repeat harassment. If you don't agree, move on.
Sure, but it also means that people who are valuable to this discussion (like the community team for example), suddenly have to spend their afternoon with this instead of... well, there's sun outside. I'm a Rust hobbyist. I love spending time outdoors. I'm now spending time indoors with a CoC discussion at hand that has, up to now, not raised _a single point that hasn't been discussed before_. I'd be okay with having such discussions, even at random, but coming from a team member, I'd be happy if I wouldn't have to spend my friday afternoon like this. At least give me a publication date.
&gt; changing the version of a crate across a few dozen Cargo.toml files. You coule also use [cargo-edit](https://github.com/killercup/cargo-edit/blob/master/README.md#cargo-upgrade) 
Ah, OK. So all that's needed is a Small Matter of implementing the rust-side of whichever protocol they're running over that port. Would be interesting if they're re-using something like FastCGI or WSGI. Huh - perhaps lambda is just a bunch of deployment stuff around "running stuff under nginx+uwsgi". Never thought of that possibility before.
I'm just saying, if (a) you shut down discussion so hard on a topic, you can't (b) complain when people don't mention it by name. Your response here is just to justify (a). I'm talking about (b).
Fair enough, I guess it's nothing new.
thanks! I'll look at it.
Sure, but rustyline is abandonned, with lots of pending PRs. Plus, it seems it doesn't work on BSD.
That's right. But when someone fixes a bug and sends a PR, I'd accept a "non-abandonned" project to merge it, which liner and rustyline don't do.
Thanks! But unfortunately, neither liner nor rustyline are actively maintained, both have had all their PRs pending for months on GitHub.
No it was an afternoon hack. Everything is compiled cwd. Only basic types can cross CFFI boundary AFAIR. The code is literally 20 lines. https://github.com/Carreau/cffi_magic/blob/master/cffi_magic/__init__.py#L143-L161
Well, we *could* overhaul the `Iterator` implementation to use `Generator`s instead and it wouldn't impact (I think?) any of the current libraries. Then it would be a matter of making breaking changes on the relevant bits for which the use of `Generators` directly would be better suited. Not sure if this is possible easily with the apparition of editions/epochs, or if we would need to do it in numerous steps, like "introduce a new API with a different, temporary name", "deprecate the old API", "remove the old API", "replace the old API with the new one", and "deprecate the temporary API". I mean maybe it'll take years to reach that point, but it looks reasonably possible to me, which is more than you could say about a lot of languages.
No problem :) The only issue I've found with it thus far is that the VS Code RLS extension can't pick them up yet - which reminds me, I need to raise an issue/PR for that...
I've been writing a number of RPM-related Rust projects lately, including [bindings to rpmlib](https://www.reddit.com/r/rust/comments/8bj1zi/announcing_rpmlib_a_redhat_package_manager/). This is the latest: I wanted to do internal RPM releases of the tools I'm writing, and so I wrote a cargo subcommand to manage that. `cargo rpm` automates a very simple workflow for producing RPMs from precompiled executables. Specifically, it tries to minimally shim rpmbuild into cargo's existing workflow, letting cargo drive the build, and using rpmbuild to package the resulting target files (this is opposed to a traditional rpmbuild workflow where it drives the whole build process). This should hopefully make it relatively simple to produce RPMs from any Rust project with "bin" targets, while still allowing for a high degree of customizability: the `cargo rpm init` command handles generating an RPM spec file for your project from `Cargo.toml`, but once generated allows you to make whatever edits/customizations you'd like. Definitely interested in any feedback!
Well honestly there is room for improvement. Static cross builds tend to have issues (for me) and require some fiddling. With Go for instance, that is much smoother. Actually never had to deal with an issues there at all.
What's really weird about this is that, as a practical matter, the CoC is really only "offensive" to a small minority of people, *and* these folks tend to be the ones who "flirt" the most with discussing the topic! It may be very true that discussing such a topic "too often" risks causing "unnecessary fights, hurt feelings[, ] damaged trust [or even] drive people away from the community entirely", but it's not going to be due to any inherent "offense" or "sensitiveness" of *this* particular issue.
This tries to adhere to the _entire_ spec and carry the documentation from the spec into the crate (so you don't have to check the reference). I wrote this to try and have a cleaner API when dealing with jsonrpc via services like `reqwest`.
Cool, did not know about this. 
I answered based on my understanding of this https://github.com/rust-lang-nursery/rls/blob/master/contributing.md#implementation-overview
Cross-compilation out of the box would be great! We really just need somebody to champion it, I bet.
I looked through the PRs, most of them are either trivial version bumps for dependencies or need some work. There didn't appear to be any bugfix PRs. Yes, the maintainers could be more active, but they are around. I have been watching these two projects over the last year (specifically liner) and I have seen bugs fixed and new features added (vi key bindings were added in both libs last year IIRC). These libraries are basically feature complete, they don't require much maintenance. I see this lack of activity as a sign of relative stability.
One goal of the CLI WG is to document/consolidate packaging of simple (CLI) tools -- so I wanted to say sorry in advance because I think we'll bother you with questions and issues soon :) There is a cargo-deb that has a mechanism to specify custom metadata -- would a generic way to handle this across both cargo-{deb,rpm} make this (with ways to override fields for a specific target of course)?
Do you think it would be possible to share metadata with `cargo-deb` to a certain extent? It would be nice for users that want to be able to distribute on Linux to only write package metadata once, and have both rpm and deb use it. Of course there might be some packaging system specific settings as well.
You beat me to it :) - Can it work without a spec file? - How do you decide what files to include in the rpm and where to install them to? - Can you override where the rpm is written to? - Would you be interested in joining forces and having this managed under the [crate-ci](https://github.com/crate-ci) umbrella? FYI I've been creating [stager](https://github.com/crate-ci/stager) for a generic framework for selecting and laying out files for packaging (tarballs, rpms, debs, etc). My plan was to make a cargo-rpm that would provide a default stager config (that can also be disabled) and allow the user to add their own custom staging for any assets they need installed.
For me, there is Rust Before Tower and Rust After Tower. I'm so into it. I've written 3 services with Tower since it came out and 2 more services that use Prost more directly and I'm very happy with the experience - the examples were also very useful.
TL;DR API is now subject to copyright. Here is the ruling: https://www.wired.com/story/the-case-that-never-ends-oracle-wins-latest-round-vs-google/ Java 8 made pretty great time API. Oracle *owns* Java 8 =&gt; Oracle could potentially sue you for using/copying their API. 
That's wonderful to hear! I'm hoping that the Net WG can get more attention on Tower and help build out its ecosystem as well. I hope you join in!
&gt; There is a cargo-deb that has a mechanism to specify custom metadata -- would a generic way to handle this across both cargo-{deb,rpm} make this (with ways to override fields for a specific target of course)? My thought for this is a config file (either in `Cargo.toml`s `metadata` or a separate file) with a generic packaging section followed by overrides for package-format-specific config files since not all metadata can be shared across formats.
It creates a spec file for you and sets everything up so that it can be edited and rpmbuild just works. This is great because I can't tell you how many rejections are given internally at Red Hat for not having a spec file to reproduce builds.
Metadata about files to be included in the package, such as the owners and permissions/modes of the various files, definitely seems like something that could be shared between `.rpm` and `.deb`-style packages. Feel free to ping me about whatever you'd like via GMail (my username there is the same as my Reddit one)
Awesome! We might want to have a quick meeting with everyone involved in cargo subcommands that do packaging things and I'll be sure to ping you once our plans become more concrete :)
I fancied doing something like this recently, getting n index points within a list of encoded diffs: let index = iter::once(&amp;0) .chain(values.iter()) .zip(values.iter()) .map(|pair| (*pair.1, encode(pair.1 - pair.0)?)) .skip(n) .step_by(n) .collect(); Error handling with a for loop was just that question mark to handle the io::Result - the path of least resistance was also the Right Thing To Do&amp;trade;. Obivously it doesn't work here. 
I see this more like a different tool that does not overlap with IDE. I wouldn't use it with my projects, this I do on IDEs. But this is awesome to get to know someone else's project. Example, it can be extremely useful to explore std/core/rustc. Navigating source code with rust doc or github is unpleasant and this will enable me to easily navigate rustc code before getting it and setting up things. if this will be online, I may be able read rustc while commuting. This works for any project.
Yeah, I saw the part of `cargo rpm init`, I was more asking if alternative / streamlined workflows make sense and are supported. &gt; This is great because I can't tell you how many rejections are given internally at Red Hat for not having a spec file to reproduce builds. If the spec file can be deterministically created from other sources, does it matter? For me, I'd like to avoid duplicating content to avoid it going stale.
&gt; The rust community is pleasant because it's populated by a core of pleasant people. I don't want to look too much like a zealot when discussing other languages/communities, but surely the unique *technical* focus of the Rust community has to be playing a role here. There is a long way from Node.js to Rust, or even from Python/Ruby to Rust - it keeps the casual dudebros at bay and makes the primacy of merit and working code a lot more obvious. You see this in other communities like Haskell, O'Caml and even C/C++, which portray the same sort of "nice and professional" attitude (give or take the occasional mild controversy), whether or not this is also reflected in a formal CoC.
So, that makes sense. If someone's violated the CoC, then you can't *trust* them to not abuse their power over other peoples' commits.
In some cases you can collect into a Result with the right type annotation: `let index: Result&lt;X, _&gt; = ...collect();` and then you can use `index?` at the use site For example: https://stackoverflow.com/a/26370894 
Thanks for the extra background - Are you focusing on packaging for personal distribution or for getting added to official repos? - I ask because the requirements can be different. If I build an RPM to distribute with my app, I can just bundle all the binaries in it and give it out. If the target is for a distribution, you need to worry about whether your cargo deps need to be packaged as well, what versions of the deps are available in the repos, etc btw the discussion for packaging CLIs is at https://github.com/rust-lang-nursery/cli-wg/issues/8
&gt; I find it interesting that you don't mention the incident[...] I didn't do it because the purpose of my post was to start a constructive discussion around whether CoCs have an impact or not (as OPs posts made some unsubstantiated claims). I can link to that particular issue if you want, but I think it would have derailed the discussion from the beginning. &gt; It's funny how you need to be contributor for a complaint, but also fun how you can engage in the outrage if you are not. This particular incident was clearly confrontational, as the complaint was to remove someone from a project based on a conversation on Twitter. If the goal was to generate a debate around the topic, it sucedeed. Direct confrontation and proselitysm are not good allies, though. And bringing these personal discussions to a project and demanding action alienated a lot of people, and I think with good reason. However, that this was handled poorly (in my subjective view) doesn't necessarily demerit the idea of a CoC. What I wanted to questions is this: &gt; a friendly Code of Conduct-bearing project will attract a broader spectrum of people Not sure that can be easily proven. And i was questioning whether CoCs have an impact or not, because... well, my experience with programming communities was always really pleasant, both online and offline. And I cannot imagine that a CoC would really change that. On the other hand, if someone is bothered by this to the point of it being an issue, maybe this is not the kind of person you want in your community. And I was going to write more, but somee others already beat me to it and now it's summer in Germany and I don't want to be in front of the computer.
My immediate goal for personal usage is e internal repos of in-house tooling, although I would be interested in making whatever modifications are necessary to make the tool friendlier to packaging Rust projects for distribution in official repos.
That would be a starting point. However, a great point of a Jupyter notebook (which is challenging for Rust) is that it encourages progressive exploration of data: - make a computation, - check the result, - make another computation based on the result of the first, - rinse and repeat. A local playground would not keep state between invocation, so you'd have to recompute everything from scratch each time, which would significantly impede iteration time.
There was no CoC, so he could hardly have violated it. Any violation of the CoC would also have been outside the project (the only way the people knew about the project was because he listed himself as maintainer on it on twitter), most CoCs try to separate project related activity from everything else, and for a good reason.
Doesn't this almost always require an intermediate allocation though? I remember hitting a case like this once or twice: let tmp = some_strings() .iter() .map(str::parse::&lt;i32&gt;) .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;(); let squared = tmp? .iter() .map(|i| i * i) .collect::&lt;Vec&lt;_&gt;&gt;();
The biggest European exchange for Derivatives (Eurex) still uses FastFix for options. They are investigating migrating to the binary protocol they use for futures/everything else, but are concerned with bandwidth requirements. Apart from that; I don't think CME uses FastFix any longer (I thought MDP3 wasn't FastFix?), and I know that B3 (Sao Paolo) uses FastFix for all its feeds.
I asked more because I didn't want to deal with the official repo complications :)
That's very nice indeed.
Would you be interested in adding functionality for generating `PKGBUILD` files for Arch Linux and MSYS2 also? :)
Ok, let's talk specifically about liner. I'd like to release a new version of Pijul, and it's currently blocked by https://github.com/MovingtoMars/liner/pull/79. That PR fixes a serious bug which happens when using pipes on Unix.
Also, for rustyline: https://github.com/kkawakam/rustyline/issues/123
Mmmm. You have a point, this should be addressed.
Not sure what to make of this. Perhaps you are right. I guess a lot can happen in a year.
Would this help? https://github.com/redox-os/relibc
I have definitely wanted this in the past. Not possible yet, sadly. Might make a nice first PR. [Issues](https://github.com/rust-lang/cargo/issues/3475)
You can implement the trait on `str`: ```rust impl FromValue for str { fn get(v: &amp;Value) -&gt; Option&lt;&amp;Self&gt; { // as_str is optional, depending on how you feel about Deref coercions if let Value::String(ref vv) = *v { Some(vv.as_str()) } else { None } } } ``` 
There's a proposal for an async `import()` in js, but as far as I can tell, no browser has implemented it yet. Webpack *does* support that syntax though I don't think it'll affect chrome's behavior.
Should do! Although the correct way to do it is not via the libc API at all.
This is a great article, and should be very helpful for people coming to Rust from C++ (or vice-versa). I do want to note, though, that it's a bit confusing that your diagram for Rust shows the behavior of a `Copy`-able type, but your code example is not `Copy`-able (since you wanted to implement `Drop`). It might make sense to add another diagram showing Rust's behavior with moved types.
Yes, I think you'll need to call `libc::open` directly and pass in [`O_NONBLOCK`](https://docs.rs/libc/0.2.40/libc/constant.O_NONBLOCK.html). Though that means you'll need to somehow wait for the handle to be readable. (Both until it's opened on the other end, and in between writes, until you get the real EOF.) Do you plan to use `select` for that? Opening it the default way, so that it blocks until it's readable, and also blocks until EOF, might make things significantly simpler. 
The solution here is definitely clunky, but it's not *too* bad imo. You'd just need to do something like: let squared = some_stinrgs() .iter() .map(str::parse&lt;i32&gt;) .map(|r| r.map(|i| i * i)) .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;();
There's quite a few exchanges using Fix for order entry indeed, many who introduced binary formats still support Fix as an alternative. Here however we are talking about FastFix, a binary-compressed form of Fix used for dissemination. It's been obsoleted in many cases: Fix can be used for high-latency access, and binary formats (such as SBE) are much more efficient for low-latency access (decoding is a no-op) at the cost of higher bandwidth utilization.
Should I take a `io::Writer` by value or mut reference? For example: `write_to&lt;W: Writer&gt;(&amp;self, writer: W)`
This comparison is unfair, in my opinion: &gt; Ideally it should be 1. Clone the project, 2. Run this command. &gt; For a Rust project, there many steps : Install rustup, install the right toolchain, install the required components, then run cargo. As with all other language projects (cmake, npm etc.), you need to install the toolchain first. Almost all projects build with either stable or nightly which (I think) are default installed. After that, only the ideal two steps are required for Rust projects: 1. `git clone …` 2. `cargo run` 
It gets real dicey when you have two points of potential failure.
Anytime I use a map or filter_map and there are many operations that can fail. Generally because I want to try to use rayon for the operation. I'll frequently have to insert a collect() to bleed off the errors so I can continue using Iterators. Freeky's example is good, now picture that to include file and database accesses, executing an application, etc. However the real painful part is constantly being forced to structure the code and iterator structure around error handling to make things flow. As I say this, it makes me think I probably want to take a look at rayon's other thread pool primitives. That might solve the issue for threading, but I do still lose the advantage of having a structure that represents a stream of operations.
An automated epoch migration tool would expedite this process as long as the conversion is deterministic. Although if the new API isn't exactly a superset of the old one, I'm not sure how it could work in all situations - it might have to just do what it can and then hand off control to the user ala git merge. But being able to "cargo migrate" a codebase to a new epoch would make a breaking change (eg fiddling with names because people are constantly grabbing the wrong function) a non-issue that could be painful in another language. Especially if the tool understands the code and isn't just doing text substitution, so it can guarantee that the actual code has the same function as the old code. The other major advantage is the crates.io ecosystem. A lot of crates aren't in there, but being able to run all those crates through a migration and test them for regressions is probably a pretty good test of how such a tool will fare in proprietary code that isn't in crates.io.
I think even with iterator-based ecosystem, it should be easy enough to add combinators that use generators. For example: https://play.rust-lang.org/?gist=c0cf72838b46eee5cfb9142f4653e528&amp;version=nightly Combinators that use generators are less specific than regular combinators. My `map_gen`, for example, can replace both `map` and `filter`: https://play.rust-lang.org/?gist=c0cf72838b46eee5cfb9142f4653e528&amp;version=nightly. So, we'll need less such combinators to cover the same functionality as the existing combinators.
Doesn't it? I only see libc references in the todo folder.
I thought about implementing a language server for Oracle PL/SQL. So yeah, I'd be interested!
[removed]
Wrong sub. You want /r/playrust Please read a sub before you post to it.
If you'd like something like `stager` to drive the build, I don't think that should be too hard to accomodate. Perhaps it could generate a spec dynamically and give it to `cargo rpm` via stdin.
Hey, bascule, just a quick heads-up: **accomodate** is actually spelled **accommodate**. You can remember it by **two cs, two ms**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Did you seen [cargo-pkgbuild](https://github.com/kstep/cargo-pkgbuild)? 
I'm sadly on the wrong side of the atlantic. Wil this talk be recorded?
The rule about the spec file isn't about rebuilding the rust binary, it's about rebuilding the rpm.
This is interesting for Rust because of the design they've chosen for compatibility+migration. It's very similar to Rust editions, so it will be a great thing to watch: &gt; * Scala 3 code can use Scala 2 artifacts because the Scala 3 compiler understands the classfile format for sources compiled with Scala 2.12 and upwards. &gt; * Scala 3 and Scala 2 share the same standard library. &gt; * With some small tweaks it is possible to cross-build code for both Scala 2 and 3. We will provide a guide defining the shared language subset that can be compiled under both versions. &gt; * The Scala 3 compiler has a -language:Scala2 option that lets it compile most Scala 2 code and at the same time highlights necessary rewritings as migration warnings. &gt; * The compiler can perform many of the rewritings automatically using a -rewrite option. &gt; * Migration through automatic rewriting will also be offered through the scalafix tool, which can convert sources to the cross-buildable language subset without requiring Scala 3 to be installed. 
I hope to! I recorded the talks at our prior meetup using a cheap clip-on mic/phone tripod combo from Amazon, I've yet to edit them together though so who knows if the quality will be bearable. :P
&gt; extern crate all need seem to be required in my main.rs file, not the file that actually uses the crate. That confused me since it's clear what crate I want to use in my Cargo.toml dependencies, why require declare that with extern crate in my main.rs as well? I assume because while Cargo is what most people use for managing crates, you can do so without Cargo? The mandatory `extern crate` declaration will be going away soon - with the Rust 2018 edition - by the way.
I'm guessing the problem is that you skip a bunch of values that could contain errors, and if you do, you want to throw an error. Honestly I think this is complex enough that it shouldn't be covered by the iterator logic. You want the kind of power that external iteration gives you, which internal does not. For starters the `skip` and `step_by` iterators may choose to entirely skip the `map` as well (and I'd expect this to be normal). Which means that, if you want to run `encode` for every step, the code as you have it, will not do that. It doesn't matter what kind of error management you are given, iterators are free to do whatever they want to give you the same output, but not the same side-effects! We could get very clever to cheat the Iterator system into not working the way it's supposed to. And yes, I do think that's a very very bad idea. It would go like this: let index = iter::once(&amp;0) .chain(values.iter()) .zip(values.iter()) .map(|pair| (*pair.1, encode(pair.1 - pair.0)?)) // Instead of skipping, we convert what we want to skip // into Option&lt;Result&gt;::None unless it's an error in which // case we keep it. .scan(0, |step, res| -&gt; { *step = (*step+1)%n); if(step == 0 &amp;&amp; res.isOk()) { //skip, and yes, that's right we've got nested options! Some(None) } else { Some(res) }) //removes all none-failures that skipped. .filter_map(|id|id) // This will stop the whole chain early when an error is found. // The scan makes sure we never skip an error, so we always // keep it. // If there is no error, then the scan will skip values, and the // filter will remove them from the final iterator. The whole .collect&lt;Result&lt;Vec&lt;(T1, T2)&gt; Err&gt;&gt;()?; // replace with your types This is because Iterators are useful when you don't care in what order (or if at all) certain steps happen. If we really want side-effects and other issues then we should use control-structures.
As in two parts in the map where things can fail? That's what `and_then` is for! And what about when the errors are different types? Then we cast with using `map_err`. let squared = some_stinrgs() .iter() .map(str::parse&lt;i32&gt;) .map(|r| r.map_err(MyErr::from).and_then(|i| may_fail(i))) .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;();
FYI your mention didn't ping me, probably because it was inside a link.
I usually cross compile my gtk apps for Windows. It would be handy to have some settings for icon, theme, and other related things for packaging windows apps as well.
Links? For old and new talks
Since `&amp;mut W where W: Write` implements `Write` it really doesn't matter. I guess it's just the general rule that if you can take a reference, you should. [`std::io::copy`](https://doc.rust-lang.org/nightly/std/io/fn.copy.html) follows this principle.
My code is closed source. I'm going to be using a toy example for my post.
&gt; A rust project is not linked to a toolchain. The only way to know which toolchain it’s supposed to run on, is, if not specified in the project documentation, to try a random one and hope it will compile. This is exactly the problem my [rustbud](https://gitlab.com/Screwtapello/rustbud) project is designed to address, with a spec file inside each project that deterministically reproduces the toolchain that version of the project builds with. Right now, rustbud is written in Python and only handles actual Rust release-channel components like cargo and rustfmt, but I'm currently rewriting it in Rust and I have plans to extend it to `cargo install`ing packages too.
I believe cargo will already compare &amp; reject mismatched hashes, but I don't know what algorithm it uses. Rejecting new entries in Cargo.toml is an interesting idea!
Sure, but in the US as far as I know CME is the only one that still only uses Fix. I know Fix isn't fastfix, but it seemed relevant. FastFix looks like a something I would see in some bizarre nightmare
I think I was just thinking how this could fit into existing technologies. I think this would be super helpful in docs.rs, or even in an application that could take a create URL (like via Github), and then `cargo-src`ify it, so you could browse any crate. That would be great for the situation of when a crate is announced, people can take a look around some of the more hot modules.
/r/playrust ;)
One really interesting thing they're adding is [union types](http://dotty.epfl.ch/docs/reference/union-types.html). Not just in sense of having proper enums, but in the sense that you can have a type `A | B` (the pipe being the symbol for union), and this type will be the same type as `B | A`. So you can write code like: def help(id: UserName | Password) = { val user = id match { case UserName(name) =&gt; lookupName(name) case Password(hash) =&gt; lookupPassword(hash) } // ... }
oh yikes.
What does the error error[E0460]: found possibly newer version of crate `foo` which `bar` depends on mean? When googling for this I only find concrete bug reports, but not a general explanation what this means and how to fix it. `rustc --explain E0460` doesn't help too - it does not have any information on this error code.
Can you take a look at my language. https://github.com/rickyhan/tensorscript-compiler Any suggestions at all is appreciated
Are you getting this when building your own project? Is there anything else printed with it that might be relevant?
I don't think that the main argument for -unknown-unknown over -emscripten is code size. (Still, thumbs up for slimming down those Rust programs; that is an important issue in many applications). To me, it's more that emscripten tries to behave like a POSIX environment in a browser that isn't. That makes it valuable for porting SDL games and that like; having an "Open a TCP socket" API that tunnels traffic through a server via websockets is super useful there. But when developing an application dedicated to the browser environment, those abstractions do not fit well, and I'd rather go for an approach that feels more native.
Yes, I got this is on my own project. I resolved it by removing `target/` and doing a clean rebuild. I think it also printed paths of the compiled crates (similarly to [here](https://github.com/rust-lang/rust/issues/49979)), but I'm not sure now as I have no idea how to replicate this error after resolving it.
It's not, unfortunately. Perhaps because mononoke hasn't been released (AFAIK)?
We have structs, which are a nominal, defined type, and tuples, which are a structural ad hoc type. This is like having a structural ad hoc version of enums. I think union types would be a valuable addition to Rust. They would enhance error handling because they enable declaring the specific set of possible error values per-function basis. It would be easier and more ergonomic to have more precise static guarantees. There will be some design questions though: which traits would the types implement, for example? Automatically the set of the common traits of the members? Or should there be blessed traits in stdlib which the types would implement if the members implement them?
I am not sure how useful union types are when you already have enums; to be honest. I cannot recall a single instance where I found myself wishing for them.
This is rad. I've always preferred KaTeX to every other option, because it's one of those times where asynchronous rendering is far worse than blocking to render for a few milliseconds. Also, static rendering with zero javascript needed!
Do you think that using this library would be good idea? https://github.com/RustDT/RustLSP I think it implements all the server stuff, so one only needs to write the language specific rules.
Yesterday I was trying to build a Rust project for `aarch64-apple-ios`, but got (yet unsolved) sysroot errors in the linking process needing me to add unpleasant linker args to the building process. I read somewhere that the best practice to build an iOS project is to build it as a static library and call the Rust main from a Swift project. Is it really what is best to do? I would have expected to be able to get an IPA from cargo build. If it is, what are the best way to automate it/make it relatively transparent? If it is not, what should I do? Thanks in advance!
Yeah, if you want to build things for stable, all it needs is `packagemanager install cargo/rust`, e.g. `pacman -S rust`
I'm on the opposite side, I miss them badly ! Especially in this case : you have a function that takes several different types (let say 5) but returns a subset of them (3 for instance). And you also have another function that takes the same 5 types as parameter, but returns 2 of them. In Rust you need to define 3 enums, and switch from one to another. With union types, you don't need any of this. Ergonomic Union types is the only thing I miss in Rust coming from JavaScript's FlowType. 
Interestingly, you can model this kind of multi-level enum hierarchies in Scala (which uses sealed class hierarchies to encode enums). Martin Odersky himself said union types appear to really not be that useful, except for code with low-level JVM performance concerns. AFAIK, they are primarily in the type system in order to easily represent least upper bound types. I think Rust could also implement multi-level enum hierarchies, though.
&gt; I cannot recall a single instance where I found myself wishing for them. I wish for them when a function returns a result that is either A or B, but if you represent them as a `bool` it's not obvious which one is `true` and which one is `false`. As a concrete example, [`HashSet::insert`](https://doc.rust-lang.org/nightly/std/collections/struct.HashSet.html#method.insert) returns a `bool`. At a glance, it's not perfectly clear when the method returns `true` and when it returns `false` (see [this thread](https://internals.rust-lang.org/t/hashset-insert-considered-harmful/7257/2) for a discussion on the topic). If you find it confusing, too, the answer is: `true` if the element was inserted and `false` if there was a duplicate. Perhaps returning a `Result&lt;(), ()&gt;` would make the interface clearer? Sure, but that type is apparently so ugly that we went with `bool` instead. Moreover, `Result` is marked with `#[must_use]` so unwrapping it on every insert would be annoying. Maybe introduce a new type `enum Insert { Ok, Duplicate }`? That's the best solution, but introducing new types seems to be such a huge hassle that we still went with `bool`. OCaml has union types (*polymorphic variants* in its own lingo), which solve this problem elegantly. For comparison, take a look at the signature of [`Hashtbl.add`](https://ocaml.janestreet.com/ocaml-core/latest/doc/base/Base/Hashtbl/#val-add) in Jane Street's Base library: val add : ('a, 'b) t ‑&gt; key:'a key ‑&gt; data:'b ‑&gt; [ `Ok | `Duplicate ] Nice and clear! This is one of those situations where it's just easier not to name things and somewhat reminds me of `impl Trait`. The difference is that `impl Trait` lays out the essence of a struct that implements a certain interface, while a union type lays out the essence of an enum without giving it a name.
What is with `github.com-1ecc6299db9ec823`, will this not change in the future?
Personal philosophy: if you're a library, don't use `impl Trait` unless you *need* to. If you would benefit from it, but don't need it, try to make it an optional feature. Switch over entirely when it is unlikely that any of your users are using pre-1.26 compilers, *or* you need to require 1.26 for other reasons. As a rough guide to "what version of Rust might be in use", I have [a script](https://github.com/DanielKeep/rust-script-toolbox/blob/master/decrepit.py) that checks the "in-active-support" package repositories of a few major Linux distributions (though the script is probably a bit out of date now).
I don't know. It hasn't been updated for over a year. I'll take a look at it.
One use case I really want them for is for working with the FHIR spec. It's a common spec for communication between healthcare applications, and there are many places where the spec defines a property to have type `Reference(Condition | Procedure)` or some other union ([example](https://www.hl7.org/fhir/appointment.html)). This kind of type is quite natural to represent in JSON (type safety not withstanding), so it would be really sweet to represent the type in Rust in the same way. Because many of these unions exist and are defined quite arbitrarily, representing them in Rust is quite a pain, because you have to create new enums for every unique union in the spec, and they would just be named something like `ConditionOrProcedure` because their combination has no particular meaning that can be used to name said enum.
Try [actix-web](https://github.com/actix/actix-web) Also check [this](http://www.arewewebyet.org) site
Agreed, but does this imply that there's no `libstd` available with -unknown-unknown?
Nice, but introducing Result by naming a variable result whereas it's not a Result is confusing to me.
Ok, I understand. Would `data` be a better fit for you?
I first read the domain as "rant side ass stuff". 
I think `location` would be even better.
`location` would be even better.
absolutely! thanks for your feedback!
But you'd still have to introduce names for the alternatives, right? And instead of enum alternatives, which are values (or value constructors), they would have to be (unit) types, which is pretty confusing: struct Ok; struct Duplicate; fn insert(...) -&gt; Ok | Duplicate { ... }
Thanks for mentioning the .context method, I'd actually not seen that before (not that I really play with rust much)
Not awesome yet. That's why we have `error-chain`(deprecated) and `failure`. And they must be in the `std`.
I modeled `stager` off of a `stager` we use inside my company that is the foundation for our generating packages for 4+ packaging systems (not all Linux). We've been using it for the last couple of years now and it has been a success so far. I'm assuming it would similarly be a good approach within the rust ecosystem to declaratively specify what files should be installed where across packaging systems.
Will the monomorphization also lead to increased binary sizes with multiple variants, like generic functions do versus trait objects? 
I got really excited because I love AI competitions like this, and this looks like a fun one. But that excitement sadly turned into disappointment when I found out that Codingame compiles all their submissions in debug mode, not release mode. It's not just that the difference in runtime performance between debug mode and release mode is a factor of 10 or more. If everyone suffered the same 10x slowdown that would be fine. The problem is that good code suffers a lot more from this than bad code. Zero-overhead abstractions are not zero-overhead if you don't turn on optimizations... So yeah, a programming competition where you're penalized for writing good code, thanks but no thanks, I'm not going to compete in that. That being said, this video did whet my appetite for participating in an AI competition. Does anyone know any good AI competitions where you can use Rust and where they do compile with optimizations?
This sounds like it would be easier to reason about with enum-variants-as-types, since you could just imagine that any *ad hoc* set of types can form an enum. 
`trap_err` makes for entertainingly straightforward code.
Half a year ago, I was experimenting with running Rust on iOS. I don’t know about the best practices, but what I did was: compile the static library, drag it into Xcode (maybe some extra steps are necessary to use the library), create a wrapper, call functions from the wrapper. For that project I used Objective-C, so creating a wrapper was really easy, but I don’t know about Swift. I used [cargo-lipo](https://github.com/TimNN/cargo-lipo/blob/master/README.md) to build the code, which is really great in my opinion. I don’t know if this is helpful to you, but that is how I had done it.
I made a crate for this: [term\_cursor](https://crates.io/crates/term_cursor)
Something that basic and common must be in the std. PS: Yes, I also like Rust's "checked exceptions"-like error handling.
As much as I love rust, error handling is the point I most disliked about rust. Specially, I don’t know how can one easily compose and propagate errors. I dislike failures way of handling error, because you don’t know the exact error you will be getting without going looking into the source code, though context and stack traces are useful, But I feel there are only useful for the one who write the the code, but not necessarily the one who consume the code (e.g. library user). If I want to handle several error cases differently, I need to do downcasting, but the caller can’t know all the possible Fail variants. failure::Error is a good replacement for Box&lt;Error&gt;. However, I find often time, I want enum Error{} instead. Failure doesn’t seem to offer any help when using enum errors. Using enum errors require a lot of boilerplate code in rust (conversion between different errors). Especially if we need to compose error variants from different enum errors to a single enum error. 
Agree. But even Rust team crates like `bitflags` requires a newer version. At the moment its mostly impossible to support an old compiler version.
&gt; Something that basic and common must be in the std. Sure. **When it's ready.** Remember that anything in `std` is basically supported forever. It's bad enough we're stuck with the not-so-awesome `Error` trait; let's not rush and stabilize yet another way of dealing with errors which would be obsolete in a year or two.
Indeed. The ecosystem has at least slowly but surely been getting better about testing a pinned stable version of Rust in CI. This at least lets you know what they support. Before that, it was a research task to figure out what the minimum supported version of Rust was. :-) Having a pinned stable version of Rust in CI doesn't necessarily imply a versioning policy, but it does at least make sure that bumping the minimum supported version of Rust is a conscious change. But yeah, if you're going to have dependencies on the ecosystem today, then you need to be able to roll with the Rust trains to at least some degree. Supporting very old versions of rustc is probably impossible, although crates with stronger Rust version policies might be possible to use by using older versions of said crates. For example, clap generally only bumps the minimum Rust version in minor releases, which means I can run my own release train a bit more slowly by delaying upgrades.
Every crate I publish uses the `enum Error { ... }` approach, and I have never ever once been bothered by it because it is basically _write once_ code. (I recognize that this is personal preference, and very clearly in sharp contrast to many others.) If I'm in a situation where the boiler plate does bother me (quick CLI apps, for example), then I reach for `Box&lt;Error&gt;` or, nowadays, `failure::Error`. Also, you're somewhat wrong about `failure` not giving any benefit to the `enum Error { ... }` cases. Firstly, it lets you capture backtaces. Secondly, it provides auto-derives for both the `Fail` and `Display` traits, which can eliminate quite a bit of said boiler plate.
With `impl Trait` in the return type, probably not, since a function can only return one type anyway, just you no longer have to name it fully. With `impl Trait` in the argument list (has that been approved?), it acts just like a generic with maybe more ergonomic syntax, so it would increase the binary size.
&gt; At the moment its mostly impossible to support an old compiler version. This is just *not* true. It's entirely doable, it's just a question of effort. All you need is a build script to detect versions and define `cfg` flags as appropriate. The *real* problem is with dependencies, hence why I try to support as old a version of Rust as I can: I don't want someone else's efforts to be stymied by my code.
Yes, in arguments is coming at the same time.
It exists but some stuff just panics. Once the portability stuff works out this will be much nicer, as it’ll be a compile error instead.
I think one of the reasons is that there is still no way to specify a required compiler version in Cargo.toml. That would make other people aware of the versioning requirements, and enable easier automatic testing against that version to ensure nothing breaks.
Can someone give a concrete code example of what such a refactoring would look like? Bonus points if it demonstrates why everyone is excited about impl Trait.
Out of curiosity, when would you choose to use this instead of ‘peak’?
try error_chain
I do not rush anything. Just saying that necessity for an external library for such primary thing isn't "awesome".
&gt;This is just not true It is. I what to use `failure` - 1.18. `bitflags` - 1.20. `log` -&gt; 1.16. And this the basic libraries. Everything else requires "latest stable". PS: Yes, I'm trying to support the lowest version possible.
Not on topic. :P
https://play.rust-lang.org/?gist=ff4f932210f7cc69d5a1c3d9c246946b&amp;version=beta hope this helps
I'd always use `impl Trait` unless you need to return multiple different types which implement the Trait. then you must use `Box&lt;Trait&gt;` or `&amp;Trait` anyway.
One area where I feel that often falls down is when `T` is `U | Null`. I find the fact that `Option&lt;T&gt;` always nests a nice property.
With the way post 1.0 went full conservative in several not-ideal old compromises, i rather doubt it. But yes, i'd love if generators got more love, probably my favorite python feature, if the footguns don't get involved.
Exactly the ResultExt trait adds this
I think you mean `peek()`
What I dislike about pijul is that you cant really view the source code anywhere. Why don't you have a like a mirror of it on github to view?
https://nest.pijul.com/pijul_org/pijul
I want to be able to do something like this: fn read_file(filename: &amp;str) -&gt; Result&lt;FileData, (BadFileName | CantOpenFile | BadFormat)&gt; { if is_bad_file_name(filename) { return Err(BadFileName); } if let Ok(file) = File::open(Path::new(filename)) { match parse(file) { Ok(file_data) =&gt; Ok(file_data), Err(parse_error) =&gt; Err(BadFormat(parse_error)), } } else { Err(CantOpenFile) } } fn get_foo_from_file(filename: &amp;str) -&gt; Result&lt;Foo, (BadFileName | BadFormat | ThereIsNoFoo)&gt; { match read_file(filename) { Ok(file_data) =&gt; { if Some(foo) = file_data.foo { Ok(foo) } else { Err(ThereIsNoFoo) } }, Err(CantOpenFile) =&gt; { Ok(Foo::default()) }, Err(err) =&gt; Err(err), } } Notice the two advantages: 1. I can have each function declare exactly which errors it can throw - without having a different `enum` type for each function. 2. Notice `Err(err) =&gt; Err(err)` - this will pass any error from `read_file`'s `Result::Err` (except `CantOpenFile` - which was already handled in a previous `match` branch) into `get_foo_from_file`'s `Result::Err`. Now, if I wanted to do this with `enum`s, I'd have to do: enum ReadFileError { BadFileName, CantOpenFile, BadFormat(ParseError), } fn read_file(filename: &amp;str) -&gt; Result&lt;FileData, ReadFileError&gt; { if is_bad_file_name(filename) { return Err(ReadFileError::BadFileName); } if let Ok(file) = File::open(Path::new(filename)) { match parse(file) { Ok(file_data) =&gt; Ok(file_data), Err(parse_error) =&gt; Err(ReadFileError::BadFormat(parse_error)), } } else { Err(ReadFileError::CantOpenFile) } } enum GetFooFromFileError { BadFileName, BadFormat(ParseError), ThereIsNoFoo, } fn get_foo_from_file(filename: &amp;str) -&gt; Result&lt;Foo, GetFooFromFileError&gt; { match read_file(filename) { Ok(file_data) =&gt; { if Some(foo) = file_data.foo { Ok(foo) } else { Err(GetFooFromFileError::ThereIsNoFoo) } }, Err(ReadFileError::CantOpenFile) =&gt; { Ok(Foo::default()) }, Err(ReadFileError::BadFileName) =&gt; Err(GetFooFromFileError::BadFileName), Err(ReadFileError::BadFormat(parse_error)) =&gt; Err(GetFooFromFileError::BadFormat(parse_error)), } } 
IMO ability to return early from the outer fn inside a closure would solve a lot of these types of issues.
You might want to take a look at how [Rust Language Server](https://github.com/rust-lang-nursery/rls) is structured. It uses `jsonrpc-core` crate and certainly has more custom bits like using analysis data via `rls-analysis` crate, it has more generic LSP server bits (e.g. [server](https://github.com/rust-lang-nursery/rls/tree/master/src/server) submodule).
I wonder if they are calling `cargo build` and respecting the user's `Cargo.toml`. If so adding the following to your `Cargo.toml` could be a workaround. ``` [profile.dev] opt-level = 3 ```
You are basically reinventing exception specifications; without exceptions. Also, I note that point (2) requires flow-dependent typing. Infuriatingly, it doesn't work today: enum Simple&lt;'a&gt; { String(&amp;'a str), Other(u32), } fn morph(s: Simple) -&gt; Simple&lt;'static&gt; { match s { Simple::String(_) =&gt; Simple::String("Hello, world!"), a =&gt; a, } } Even though `Simple::String` is handled, and therefore `a` is not a case with a lifetime, this fails to compile because `a` still has type `Simple&lt;'a&gt;` and not `Simple&lt;'static&gt;`. Flow-dependent typing would be a nice addition; of course :)
The source is browseable, but attempts to see any of the patches fail. I'm getting the generic "Server not found" page in Firefox, but tracing with tcpdump reveals that one connection to the server completes, while another is forcibly reset by the server.
&gt; Something that basic and common must be in the std. I'm not sure about that. The same could have been said about `Error` and `error-chain` which are not relevant any more.
I admire all the work you've put into this! It's good to see competition in this space, and I also love that seemingly unrelated crates like thrussh have come out of this. The nest being pretty much unusable for me (can't login, can't view patches for starters, ping me if you need help debugging this) makes it pretty hard to contribute though :(
Yeah, Ruby lets you do this: def with_lambda x = -&gt;() { return "bla" }[] puts "Returned in function: #{x}" end def with_proc x = proc { return "bla" }[] puts "I don't actually run since that return bubbles up" end with_lambda # =&gt; prints "Returned in function: foo" with_proc # =&gt; function returns "bla" i.e. an *explicit* return from a proc acts like a return from the function it's being called in, while an implicit one lets you still return values from it normally. Same behaviour blocks have: def foo [1,2].each {|x| return x } puts "I don't run either" end foo # =&gt; returns 1 I don't think this would translate well to Rust, though - what happens if you define the iterator in one function and call it in another, where does the return go? What happens if it's deep in some parallel Rayon par_iter call chain? Ruby's quite happy to say "well, you get a LocalJumpError", but Rust is not Ruby.
Unions are also very useful in TypeScript. I was surprised to find them missing from Rust.
Thank you. That's what I am planning to do indeed, but you'll agree that it is quite tiresome. I'm hoping that there is an easier way now. But maybe not.
I wish these announcements would say what the package actually is. Even the link doesn't.
Ah, so anonymous enums, basically, in Rust parlance.
If it works like OCaml, `` `Foo `` is really a nominal _atom_ or free-standing _symbol_. It's not referencing anything, but has to be distinguished from named references syntactically (the backtick).
It's actually required for `Option` to be a monad (with its useful properties, a.k.a. laws). This is why Scala does not even bother with `null` like Kotlin does; instead everyone uses `Option` and acts like `null` does not exist.
I have not! Looks like a good place to contribute. :)
Yes, but more flexible, in the sense that OCaml uses row polymorphism to make different such "enums" interoperate transparently. As a simple example, `if ... then a else b` where `` a : [`X | `Y] `` and `` b : [`Y | `Z] `` has type `` a : [`X | `Y | `Z] ``.
You're right. It's a git alternative.
In the example I have in mind the blockchain is here to ensure delivery. If a message in written say 6 blocks deep, you can consider the recipient has had the occasion to read it. Now imagine you combine encryption, a blockchain as the ledger of the broker accounts and another one to store the messages. Every N blocks in the message blockchain is a checkpoint block, it will enable the nodes (brokers &amp; readers) to enforce a bandwidth limit for every broker. By bandwidth, I mean writing a number of blocks in a specified duration. Let's say that that no more than three epochs determined by the checkpoint nodes are required for the network to work as intended, then a node can drop the oldest messages in order to save disk space. This is an example of a non-immutable blockchain. The fact that the broker accounts are held in a blockchain helps solving the bandwidth limit. By requiring a cost to issue an account, accounts are limited in number but issued by a neutral, decentralized entity. This cost can be variable and could be a PoW, an Ether payment send to a specific address or something else. Using an Ether payment, you may choose to use a cheaper alternative than PoW to resolve the natural forks of both the broker blockchain and the message one. Then broker accounts would be the only one to be allowed to write, restricted by the blockchain network from exceeding their bandwidth limit. The owner of a broker account could use it for itself or act as a service provider and deliver messages coming from third parties. The reader nodes wouldn't require any cost and would act as additional blockchain nodes, helping propagating the messages and enforcing the rules. Since everyone reads every message, everyone is the recipient, but only the one who can decrypt the message can understand it. As far as I could understand how this project and messaging platform works: * it profits from the resiliency of a decentralized network, * hiding the recipient, it is even more confidential than a mesh network, * it cannot scale as much as a centralized platform * it is more expensive than Telegram, Firechat or Tor IMHO it's an even more extreme alternative. A niche market, but a market that still exists. The concept of broker/reader nodes on a dual blockchain may also be a good alternative to PoW and PoS. Time will probably tell. And if you dislike the idea that a node could keep all the encrypted messages on disk forever just remember two things: * All the data transiting on the internet can be considered written forever. This includes you passwords, your commercial transactions, your private &amp; encrypted conversations, etc. We just rely on cryptography. * If in a foreseeable future our common cryptography tools are revealed to be completely broken the whole world will have bigger problems than the leak of an entire messaging platform or the loss of the Bitcoin network.
They're totally different though. `Box&lt;Trait&gt;` just has a side-effect of solving the issue `impl Trait` solves (at cost). If you can refactor to `impl Trait` without losing any features - I'd go for it. Also depends on a code path it's in. 
You can't submit multiple files, so I don't think you can modify the `cargo.toml` 
What's the point of option nesting, really? `Option[Option[T]]`is not a really useful type.
The link is for a release announcement... Just click the logo (as usual...) .. And you get: Pijul is a free and open source (GPL2) distributed version control system. Its distinctive feature is to be based on a sound theory of patches, which makes it easy to learn and use, and really distributed. Not very hard... Or is it? 
I could see it being useful for iterators that side\-effect external systems.
I could see it being useful for iterators that side\-effect external systems
LoL. I did indeed. :)
Well, uh, sorry: this solution doesn't do static rendering, it uses the KaTeX JavaScript to render after the page has loaded. Though if rustdoc/doxidize end up offering a way to plug in pulldown-cmark transformers on the markdown render pipeline, I've considered making a transformer to use there.
It's hard when I'm browsing my front page
It's fine to give something time to mature. But you should definitely not have to install something third-party to get decent error handling.
It's awesome that we weren't stuck with error-chain, though, even though it's also pretty nice to use. Rust's whole ideology about libraries is that they should be allowed to mature separately from std. We don't have random numbers, logging, error handling extras or many common things other language standard libraries have, and that's OK because we have cargo and crates.io instead.
&gt; Using enum errors require a lot of boilerplate code in rust (conversion between different errors). Especially if we need to compose error variants from different enum errors to a single enum error. I also wouldn't mind if `failure` would add some anotations to get an easy way to convert errors. That said, it's not a big deal to write a `From` implementation by hand. It's certainly no more terrible than writing custom error code in a mainstream OO language.
Because stable rust is guaranteed to be backwards compatible I consider upgrading your compiler to be trivial. Thus the only guarantee I issue for my code is that it will work with the latest stable compiler. 
&gt; You are basically reinventing exception specifications; without exceptions. More like Java's typed exception. &gt; Also, I note that point (2) requires flow-dependent typing. No, not really. In your example, `a =&gt; a` would require `a`'s type to be "_`Simple` without `Simple::String`_" - which is not something that can be sanely supported without flow dependent typing. However, with anonymous sum types: enum Simple&lt;'a&gt; { String(&amp;'a str), Other(u32), } fn morph(s: (&amp;str | u32)) -&gt; (&amp;'static str | u32) { match s { _: &amp;str =&gt; "Hello, world!", a =&gt; a, } } The type of `a` in `a =&gt; a` does not need to be "_`(&amp;str | u32)` without `&amp;str`_" - it can simply be `u32`. So no flow-dependent typing is needed.
Ok, so for you every pijul (or any other product) release announcement must have is the title the complete product explanation of what the product consists etc... For release 0.8, 0.9, 0.10, etc.. Because you find too hard to click in the announcement that takes you to the site and check what it is. Sorry, I don't agree. 
Announcements usually contain a short description and the vision of the project.
You mean like: Pijul is a free and open source (GPL2) distributed version control system. Its distinctive feature is to be based on a sound theory of patches, which makes it easy to learn and use, and really distributed. That are the first words in the home page of the project? Are you sure that you often read that in TITLE of a reddit publication... So you can read that in the front page? Ok. We are losing to much time with this... 
No that is way to much. a single short sentance is usually enough. See for example "this week in rust" and the rust compiler announcement. If you don't have such a line and the project is unknown to me I will probably not even continue to read the announcement.
&gt; I have a script... I've had a *very* quick look at the script, and it seems to assume NixOS is a rolling release, which it's not. It has point releases (every six months, the most recent being 18.03 "Impala", with rustc 1.24) and a more-or-less rolling "unstable" channel (with 1.25). 
Ok. Maybe you are right. I was giving my perspective and just personal opinion.. But maybe not the mainstream opinion. 
Yes, the patches view is broken at the moment, due to the breaking changes described in the blog post.
Do you mean `PrevPeekable`? The `Peekable` `struct` that comes with the standard library only allows you to look foward. I'm using `PrevPeekable` in a parser that I'm writing where I need to access the previous token. This was originally going to be a part of it, but I could easily separate it out into its own crate.
No, as izikbiu said you only submit a single rust source file. I'm using a builder that concatenates all my files together, so at least I can use a sane structure locally. This also means you can't install extra packages -- which isn't entirely unreasonable for their environment, but means I'm cut off from some experimental features.
Yeah, I have to admit, I was *perfectly happy* to write the error 'boilerplate', and always found quick-error and error-chain to be worse experiences. I'll give Failure a try eventually. Right now I Box&lt;Error&gt; happily.
Very nice! And I also appreciate that you chose the GPL for the binary crate! I understand that GPL is problematic for libraries but somehow it seems like it is not very popular for applications either in the Rust ecosystem (totally subjective gut feeling).
Being new to rust, the thing I don't get about errors that this doesn't cover, is why Rust went wacky with Errors and overloaded the return with either an error or the actual value, and then added 40(not actually counted) functions to deal with errors? Why so complicated? Go and most other languages make errors very simple in contrast, and I don't yet see any benefit for all the added complexity.. what am I missing?
Is it possible to change fn get_location(url: &amp;str) -&gt; Result&lt;Location, Error&gt; { let location: Location = reqwest::get(url) .context("error while getting location")? .json() .context("Could not parse JSON")?; return Ok(location); }
You typically get that kind of error message when trying to import a crate built by a different version of the compiler, so a clean build was the right fix anyway.
**Common Public License** In computing, the Common Public License (CPL) is a free software / open-source software license published by IBM. The Free Software Foundation and Open Source Initiative have approved the license terms of the CPL. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Initially, we were using AGPL, but (I'm speaking just for myself here) I don't like its strong political statements about tivoization, I think you don't always choose the hardware you get, and these problems are easily overcome by running things on a server, and writing a trivial interface. I feel that AGPL and GPL3 are ambiguous on that (but I am not a lawyer).
&gt; I am working with the no std library 
That's some serious effort you put into testing...but are you sure your tests catch actual mistakes? It's in early development, but I invite you to try [mutagen](https://github.com/llogiq/mutagen). It will inject actual errors to see if the tests catch them.
I find error handling easier in Rust than in Go, simply because you can (usually) avoid the boilerplate: do_the_thing()?; is more concise, easier to comprehend, and less error prone, than: if x, err := do_the_thing(); err != nil { return nil, err } By "40 functions to deal with errors", do you mean things like `map_err` and `ok_or_else`? They don't get in your way if you don't need them. (They do tend to clutter up the documentation pages, though!) 
Are you going to use a different license for the library at some point, in order to allow more users of it? Or is the idea to discourage alternative clients or integration of libpijul into non-GPL programs?
This is a working group dedicated to build what is essentially just another web framework, concealed as a network services working group. Release async/await. Make it stable. Document the hell out of it. Write tutorials. Teach the world how to use it. Address the shit show that is Rust futures. That is far more urgently needed than Tower or Tower Web. Also, I dislike how close Tower is to core Rust community activities. This "one core async services lib to rule them all" childish nonsense isn't realistic and it's unwelcome marketing.
This post has been [posted on r/rust](https://www.reddit.com/r/rust/comments/8dm5j9/blog_trust) and been subsequently deleted before. I suggest you delete it also.
It's fantastic for writing command line applications. Probably what it's best at. That at all doesn't mean it doesn't do other things well, though. Anything you want/need something be high performance and the nice safety will help you out. Also, having a statically compiled executable makes distribution and installation super easy. 
"The anti-SJW like to overlook this problem when decrying code-of-conducts. No wonder the Rust community is so productive." I am sure that the author has many redeeming values. Attacking a group who opposes social justice warriors was a mistake. The Rust community is still in its infancy. Identity politics has no place here.
The main point of my comment wasn't that folks should all move to failure since it is perfect, but rather, to express an opinion contrary to the accepted wisdom that error handling boiler plate is a significant problem with Rust's error handling story. I very much want to stress the word 'opinion.' :) Also, I have most certainly not figured out failure. :-) See: https://github.com/rust-lang-nursery/failure/issues/189
Well, that guarantee doesn't always hold, and people can't always upgrade so freely even if it does.
 &gt; I **want** to use [..] There've been quite a few times I've had to use older versions of dependencies, or forgo a library entirely because I wanted to maintain a version support promise. A few times, I've had to forcibly limit the maximum version of dependencies (even under semver). It's not fun, but it's doable, though the fun-ness decreases super-linearly with time. :P
Sweet! That definitely helps! I think the main part is gonna be getting the model working and analyzing data. I'll look into those libraries. 
If I remember correctly, the reason I did that was because everyone I've ever brought up the subject of the point releases, the response was more or less "wtf no one uses those, just use the latest". Plus, I couldn't *find* an online source for what version of Rust was supported in each point release.
Can you show a little code to demonstrate your issues? I'm having a hard time figuring what your comment is about. In particular, " you end up with 1 variable that will either be what you want, or an error, and you have to go mess about to figure it out." Generally, in an application, you just print out the error if one occurred in `main`, which is exactly what you do in Go too.
You could write the New York Stock Exchange with it, a real time ad exchange, or ya know-- the best browser in the world
```rust let token_request: TokenRequest = serde_json::from_str(&amp;content); ``` Now, token_request will be a wrapped monster that will either be an error or will be a TokenRequest struct. I *can* match() on it, etc but the point here is token_request is unknown at this point in time. I have no idea if it has what I wanted (a TokenRequest) or an error. so now I have to break out the oodles of functions hanging out to find out. If I match on it, that's fine too, except now all of my code is yet one more level of nesting. My question is, why did Rust overload token_request and make it possibly mean multiple things? in Go, it would be ``` token_request, err = SomeJsonDecodeThing(); ``` (too lazy to write this out as actual Go code) and it's very simple to check err right here, and my "happy path(where no error happened) is not hidden yet another level deeper by a match, or some other function in Option or Result. in C I might have: ``` token_request = decode_json_stuff(); if (token_request &lt; 1) { // handle error here } ``` (I'm too lazy to verify that's proper C, but that's not the point.) I get that match is cool, but again, how you deal with the error is not really my question. I *CAN* deal with the error in any of the languages, but it seems to me in Rust, it's a *LOT* more complicated. I have to go play with one of those 40+ error functions to figure out which one is the right way to handle my error, I have to know if it's a Result, an Option, or some other crated Struct coming back if it's an error, and really all of those don't give me anything more than a string, generally speaking. It's not like Rust's error types somehow give me magically more information, in general, be it rust, Go, Python, etc, all I get is a string value of an error. Does that make sense? In Rust, I have to learn about all these fancy functions to deal with errors. I'm still new to learning all those functions, but all of them seem to force me into yet another level of { }'s whether I handle an error *OR* I get the happy path, and got what I wanted. I feel like I'm playing Russian nesting dolls sometimes, if I want to deal with every possible error in a match. Mostly this is only an issue when you want to try and recover from errors. If all you are doing(and in basically all the rust code I've seen in the wild so far does) is either handle the error by using ? or at most throw the error message out to the user and continue. Or the code is littered with .unwrap()'s. in C, errors are generally returned via a negative number. In Go, it's *always* a separate variable, so you are forced to do *SOMETHING* with it, and it's very easy for your "happy path" to not end up nested even deeper. Granted, I'm new to rust, so I'm probably missing something, but my question is, why did Rust design itself this way? What is the reasoning behind wrapping everything in a Result or an Option? Does that make sense, or did I ramble on incoherently again? If I did I'm sorry! I'm trying to understand WHY Rust decided to handle errors they way they do, it makes little sense to my brain on how it's remotely better than other languages when it comes to errors, mostly it just seems more complicated for no extra gain.
Pretty good for everything, except GUIs atm maybe. High concurrency/parallelism support is a plus for many things as well. Especially good if you're doing something relatively low-level and need to be as fast as C/C++ but safe, like some file encoder/decoder, network stuff.
 * Games: https://github.com/ggez/ggez * Web Apps: https://github.com/actix/actix-web * Big Data: https://github.com/datafusion-rs/datafusion * Web Frontends: https://github.com/DenisKolodin/yew * CLI Apps: https://github.com/BurntSushi/ripgrep * System Libraries: https://github.com/ctz/rustls
How would I create a library with several settings that a user could add to? Like say I initially define colors red and blue. Can I set it up in a way that a user could add green and then use the library as normal? I don't see a good way to do extensible enums, and I don't want this to be string typed. Thanks
In my mind the language it most obviously competes with is C++. I would argue that anything you might write in C++, you could also write in Rust. Not only that, but Rust offers advantages over C++. Particularly, being safe by default, but not just that. Rust has a module system and a clean design. C++ has the advantage when it comes to maturity. To me the clear winner between Rust and C++ is Rust. I made a prolog interpreter using Rust and I'm quite happy with it. I've also written some parsers for old binary formats. I'm also sometimes working on a game in Rust. I think Rust is well suited for writing implementations and run-times for other languages. It seems like a good choice anytime you care a lot about the low-level representation of your data and you need good constant factors. I also value other languages and use them as appropriate but when it comes to tasks where languages like C++ are well suited, I would rather use Rust than C++ (or its other alternatives).
**Resource acquisition is initialization** Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented languages to describe a particular language behavior. In RAII, holding a resource is a class invariant, and is tied to object lifetime: resource allocation (or acquisition) is done during object creation (specifically initialization), by the constructor, while resource deallocation (release) is done during object destruction (specifically finalization), by the destructor. Thus the resource is guaranteed to be held between when initialization finishes and finalization starts (holding the resources is a class invariant), and to be held only when the object is alive. Thus if there are no object leaks, there are no resource leaks. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
There's a cost but there's also a benefit. I think Rust culture is a bit too hard on dynamic dispatch and the associated heap allocation... Reference the `clap` author's write-up where compilation speed and generated code bloat were much improved by switching select parts to dynamic dispatch instead of trait-based generics.
It can be a tad confusing to a user though what crates for those things they should be using. They could do some searches and find the various choices out there. See some old articles touting how great of an improvement crate X is, notice they date, make sure that's still the case, then learn that X actually had some issues but fear not, crate Y is here to save the day. Dev goes on hiatus from Rust for a year or two. Are the crates still relevant with how Rust has progressed? Repeat process, crate Y turns out was replaced with crate Z, not bad, quite a bit of time passed and not too much to catchup on, not like your JS stacks :) I know that we have some repos like awesome Rust which help with this discovery/education of what the common good/popular crates to know of are. Crates.io also helps, especially when you need a more niche crate. I've seen some crates appearing lately, ergo and stdweb that seem to be crates that curate relevant crates into a collection(and possible another layer that you use allowing those crates to be replaced without the user having to re-evaluate and migrate crates in future). I guess discovery of those meta like crates would belong to a repo like awesome rust?
Yeah, I'm going to write one once the dust has settled a bit.
Is `cargo` multithreaded or not?
FYI be careful because that lipo project appears to build 5 targets. Consider that armv7 works fine in place of armv7s, and that you might not need 32-bit support, for the simulator or both
The patch format change wasn't an accident, the version number is still 0.10, and there's a blinking notice on the front page of the Nest saying "beta-quality software". Plus, the Nest's terms of use clearly indicate that everything is still experimental. I believe many software projects have bugs, especially in the beginning.
There's an answer to that in our FAQ. If someone contacts us with a plan to do something where the GPL is a blocker, we are open. Same for the Nest's license: people keep telling they'd contribute loads to the Nest if it were open-source, yet I'm still waiting for their first patch to Pijul itself.
Thanks! I'll try it out.
yeah been kind of struggling with guis. i don’t want to get back to js nor c++
The amount of work that Cargo does itself isn't great enough to benefit from parallelization, but it does run `rustc` in parallel when it has multiple crates that it can build at once (when they don't depend on each other directly).
You could define a trait `Difficulty`, that, say, returns a struct with the gameplay modifications: pub trait Difficulty { fn get_get_gameplay_vars(&amp;self) -&gt; GameplayVars; } struct Normal; impl Difficulty for Normal { fn get_gameplay_vars(&amp;self) -&gt; GameplayVars { GameplayVars { // assuming these are multipliers player_heath: 1.0, enemy_health: 1.0, enemy_damage: 1.0, } } } And then consumers of this library could create their own implementation: impl Difficulty for Easy { fn get_gameplay_vars(&amp;self) -&gt; GameplayVars { GameplayVars { player_heath: 1.25, enemy_health: 0.75, enemy_damage: 0.75, } } } Or if you need more flexibility, you could pass in a mutable reference to your game context or whatever and the difficulty impl can do its modifications there: impl Difficult for Easy { fn mod_gameplay(&amp;self, game: &amp;mut Game) { game.set_player_health(1.25); game.set_enemy_health(0.75); game.set_enemy_damage(0.75); } }
Which would be a case of `impl Trait` actually restricting _possible implementations_. Simple example, something that needs to return a `Read` for a file _or_ `stdin` - that has to be `Box&lt;Read&gt;`. 
I did like the spirit, although unnecessarily polarizing. It gives an argument for why niceness/inclusiveness leads to more productivity - i.e. not just because "it's the right thing to do". (I'm always staggered by the amount of unlocked potential out there, and the cultural obstacles to realizing that potential.)
There're more people experienced with web development than people developing VCS. &gt; And the reviewing job would MUCH harder for me It will. But if you have something to review, you have something to merge too. 
Have you guys tried gtk-rs? 
Curious, is there an overall aim to the Rust + GNOME work, or is it still exploratory for now? Are there plans to R parts of GNOME IR?
Just let me know when you start a repo, and then I can try to pitch in :)
&gt; The phrase "to a degree" seems to indicate that you think GitHub oauth is the basis for everything else. Well, I signed up on the Nest once, but your website decided to not accept my password anymore. So now I prefer to use my Github account. Which is a pretty reasonable thing to do, anyone has a Github account nowadays and the Nest explicitly says you can log in with it.
Both yew and libui-rs seem super promising. Especially excited for a future where we could have the yew API driving libui. - https://github.com/TyOverby/Rust-IUI - https://github.com/DenisKolodin/yew
Well, sorry if I wasn't clear, you're absolutely right that these things should work, and these are pretty bad bugs. This part of the code is about 1% of the total code, and the main reason these still happen is because the Nest is entirely based on a fast-moving ecosystem (Tokio). The rest of the code has two parts: - security/accounts stuff, which I am super scared of opening to contributions. That's about 9% of the code. - the remaining 90% are calls to libpijul, so it doesn't seem super plausible to me that someone who finds it hard to contribute to pijul can find it easy to contribute to this. Also, I'd love to open source it some day, once it is clear that there is a sane funding model for Pijul, so that it doesn't get stalled.
Thanks. I wasn't aware that parts of RLS can be used for other LSP projects too
&gt; "wtf no one uses those, just use the latest". I'm very surprised by this. But regardless, since the script is meant to determine the oldest rustc in use, I think the most recent point release is a better reference than unstable, which will always be bleeding edge. &gt; Plus, I couldn't find an online source for what version of Rust was supported in each point release. That's probably because the google-word for this was "channels", which is not the most intuitive name :-) The solution is actual quite simple: - Download and unpack `format!("https://nixos.org/channels/{}/nixexprs.tar.xz", channel)` where channel is something like `nixos-18.03`. (index of channels [here](https://nixos.org/channels/) - grep ./pkgs/development/compilers/rust/default.nix for something that looks like `version = "a.b.c"; (But tbh, I'm not sure Nix is of any importance in determining the oldest rustc in circulation, it's always going to be ahead of Debian, and even users of very old NixOS releases, if there are any, can create nix shells on-the-fly with any version of any package, so your point release does not limit what you can actually use)
&gt; What is the reasoning behind wrapping everything in a Result or Option? Result lets you use the `?` operator, which gives you an ergonomic way to bubble up errors – this alone is ~80% of error handling. Also the compiler can catch if you mess up. Option is just a way to declare a nullable type. If you don't have it, all your reference types *are implicit Options*. This is bad in a language with value types (e.g. Go, C++), worse in a language without (Python, Java).
Minor things make user experience. The current one is pretty awful. &gt; security/accounts stuff, which I am super scared of opening to contributions You don't have to accept all patches. You can say in CONTRIBUTING.md that patches to some parts of the Nest will not be accepted. Since you don't rely on security through obscurity, openning the code for reading will do no harm.
Sorry, but I had to remove this again. /r/rust may be better than most of reddit, but it's still too troll-baity for this venue, as I found out the hard way when posting it a few days ago.
&gt; The solution is actual quite simple: [..] Not going to lie, that's pretty soundly pushing NixOS into the "I don't care enough" category. :P The other thing I perhaps should have clarified is that I decided to make the cut-off as *supported* releases. The thing with Nix is that, as far as I can tell, if a bug was found and fixed in the version of Rust that shipped with 18.03 (for example), you'd have to... update to the latest version to get the fix. But Nix tends to be so up-to-date, that it probably doesn't make much difference to the overall answer of "what's the oldest still-supported version of `rustc`?".
It should definitely be possible to directly build an executable for iOS, if you're not using Xcode's build system. In principle, it shouldn't require custom linker arguments either, as rustc should [automatically detect the iOS SDK path](https://github.com/rust-lang/rust/blob/master/src/librustc_back/target/apple_ios_base.rs) (although this doesn't seem to support watchOS or tvOS). But you'd need some method to perform the following steps, as Cargo won't do them for you: 1. Copy the binary into your app bundle; 2. Run `codesign` on the app bundle; 3. Zip up the app bundle (an ipa is a zip file); 4. Install it on the device. 5. (optional) Start the debugserver proxy on the device. On a Mac, you should be able to use [ios-deploy](https://github.com/phonegap/ios-deploy) to do steps 3-5 using Apple's MobileDevice framework; alternately, [ideviceinstaller](https://github.com/libimobiledevice/ideviceinstaller) and [idevicedebug](https://github.com/libimobiledevice/libimobiledevice/blob/master/tools/idevicedebug.c), part of libimobiledevice, can do steps 4 and 5 respectively.
It's not very clear. But apparently, GNOME would like to have more Rust (but still providing a C interface so you can use Rust parts in C code).
(Replying in reverse order) &gt; The thing with Nix is that, as far as I can tell, if a bug was found and fixed in the version of Rust that shipped with 18.03 (for example), you'd have to... update to the latest version to get the fix. That is not the case. Stable channels, like Debian releases, provide only "conservative updates for fixing bugs and security vulnerabilities, but do not receive major updates after initial release." In nixpkgs, channels are git *branches*, not tags. &gt; Not going to lie, that's pretty soundly pushing NixOS into the "I don't care enough" category. :P Completely agree here, it is extremely unlikely Nix would change anything to the result, and even if it did, it wouldn't have any actual effect on NixOS users, for reasons cited on my previous message.
Rust is a good alternative to C and C++ when you must manage memory manually. So really your use cases should be narrowed to those. You can write anything but there are better options for most use cases. I use it for critical performance code where garbage collection would be undesired or problematic. It’s great for building libraries to use in higher level languages and virtual machines. Rust’s domain is memory management and your code will look like it’s managing memory.
As /u/cthree87 said, use a key\-value store for plugin data. Alternatively, let the plugin define whole tables, with a FK back to the original table. This FK can even be the plugin table's PK, forming a 1\-1 relationship with the core table. Depending oin the ORM \(I'm not up to speed on rust ORMS\), you might not be able to actually make the "Plugin\&lt;\-\&gt;Core" FK as a database constraint and have to maintain it via app logic. The first way is certainly easier.
I... don't see the difference. What is the difference between `a` being `u32` in your example, and `a` being being `Simple::Other` in mine? In either case you need flow-dependent typing to know which alternatives have been ruled out.
&gt; Do note that heavy use of `impl Trait` will slow down your compiles, as the monomorphization process will take longer. Will it? I was under the impression that when compiling `fn foo() -&gt; impl Trait` the compiler would just figure out what `impl Trait` really was and substitute it... ... and since it already needs to figure out what type is returned today to check that it matches the specified type, the only slow-down I can foresee is that the lack of explicit type might, from time to time, cause a somewhat lengthier type inference. Did I miss something? Did you have a particular slow-down in mind? 
I finished a project in early 2017 end of 2016 with stable. Picked it up last month, several dependencies failed with current stable. So I checked which stable version was current back then to build it before fixing the dependencies. So now I always have a toolchain file and having one in the libraries would have been helpful.
Writing compilers
[removed]
Systems programming; the sort of stuff you'd traditionally do in C/C++/Pascal/D/Ada etc. Rust is somewhat less useful in application domains which may use "managed" memory or highly-dynamic code; thus, it's not a foolproof replacement for, e.g. Haskell, Ocaml, Go, Scala/Kotlin, C#/F# etc. It *can* be made to work in these domains too (arguably unlike C/C++!), and this will generally yield significant improvements in performance and reliability a lot, but it requires quite a bit of rearchitecting (which may not ultimately succeed; some applications really do rely on 'managed' code in a rather fundamental way!) and is not for the faint of heart.
Except, of course, that it's gonna be hell to query it compared to a straight row :(
&gt; Pretty good for everything I would dispute this. If you're currently using, say, LISP, you're probably dealing with a domain for which Rust is not a very good fit. 
That would work and is done for plugin specific settings. But how on adding new features to the already present data (like ratings, playtime, lastPlayed)? Those are basically tied to one of the four models present in the database (artist, album, track and playlist). I would basically want to inject them into the original table if you know what I mean. Your approach would basically add (when using the rating example) n new entries into the database, where n is the number of tracks hold in the tracks table. It seems super inconvenient to be honest. That's what I am currently struggeling with, finding a design that does not duplicate that much stuff.
So, a rating plugin would generate a new table called `ratings` within the database, having the track id as an foreign key and then a field for the actual rating. That sounds reasonable and seems to be possible (I hope it works with diesel though). 
 &gt; For instance, why don't you fight GitHub instead, so that they open their code? Because, unlike the Nest, Github is actually useful? And it's really pleasant to use. You expect contributions and provide a platform that strongly discourages people from making any. Even worse, you don't allow anyone else to improve the situation. 
Well okay, you're very correct. I was using Racket a while ago and the macro system is absolutely far more powerful than Rust's. But I don't have use cases where I would trade the type system for the Racket's macro system so it just escaped me. Out of curiousity, what domains are LISP very good for? I am still figuring out where macro system(and maybe other features in LISP family) are absolutely must.
One option would be to make your `MusicElement` trait a supertrait of `Debug`: `trait MusicElement: Debug { ... }`. This basically means that "to implement `MusicElement`, you need to implement `Debug` as well".
I haven't seen "supertraits" mentioned anywhere, actually (I should probably just read the Rust manual cover to cover). This works great, thanks! 
&gt; Now, token_request will be a wrapped monster that will either be an error or will be a TokenRequest struct. I can match() on it, etc but the point here is token_request is unknown at this point in time. I have no idea if it has what I wanted (a TokenRequest) or an error. so now I have to break out the oodles of functions hanging out to find out. If I match on it, that's fine too, except now all of my code is yet one more level of nesting. I must be missing something. This paragraph sounds like you aren't aware of `?`, which abstracts over all of this for you. But your previous comments clearly indicate you know about `?`. So I'm having a hard time figuring out where the disconnect is. :-/ &gt; My question is, why did Rust overload token_request and make it possibly mean multiple things? Generally speaking, most fallible operations either completely succeed or completely fail. This is true in Go as well, and it's codified by convention. That is, in Go, if you have a function that returns `(T, error)`, then if an error occurred, the error returned should be non-nil and the `T` returned should be its zero value. Typically, the zero value is a nil pointer. In Rust, that convention is lifted up into the type system, which means it's harder for programmers to make mistakes when handling errors. That is, you can't forget to check an error and accidentally use the `T` value even if an error occurred. Maybe you don't care about this failure case, since maybe these types of bugs don't happen too often, and even if they do, they are generally easy to fix. That's not an unreasonable position to make, but keep in mind that you asked _why_ Rust does what it does. It's up to you to make up your own mind about whether it's worth it. There are other aspects to this decision worth mentioning: * In Go, error checking can be quite noisy. I've been writing Go longer than I've been writing Rust, and I do find this mildly annoying. But I can live with it. * In Rust, partial success/failure can be more difficult to codify. In Go, it's possible to return both a valid `T` value and an error pretty easily. A prominent example of this is the `io.Reader`'s `Read` method. But even then, the contract specifically states that implementations can delay the error to the next call. &gt; and it's very simple to check err right here, and my "happy path(where no error happened) is not hidden yet another level deeper by a match, or some other function in Option or Result. I'm not really following you here. If you want to do Go-style error checking in Rust, then that is *very* easy, and the transformation is exceptionally mechanical. Given this Go code: func readTimesTwo() (int, error) { x, err := readNumber(os.Stdin) if err != nil { return 0, err } return 2 * x, nil } You can write the equivalent Rust: fn read_times_two() -&gt; Result&lt;i32, Box&lt;Error&gt;&gt; { let x = match read_number(io::stdin()) { Err(err) =&gt; return Err(err.into()), Ok(x) =&gt; x, }; Ok(2 * x) } See? That's it. You're doing exactly the same case analysis. There's no additional level of nesting. The only slight change here is the call to `into` on the `err` value, which is what converts it from a concrete type to a generic `Box&lt;Error&gt;` type. Go does this sort of conversion for you automatically. Rust won't. (Because there are costs associated with it.) For completeness, idiomatic Rust might be this instead: fn read_times_two() -&gt; Result&lt;i32, Box&lt;Error&gt;&gt; { let x = read_number(io::stdin())?; Ok(2 * x) } This is basically the same as the above code. The only difference is that we've removed the "boiler plate" from the code. &gt; I have to go play with one of those 40+ error functions to figure out which one is the right way to handle my error, I have to know if it's a Result, an Option, or some other crated Struct coming back if it's an error, and really all of those don't give me anything more than a string, generally speaking. It's not like Rust's error types somehow give me magically more information, in general, be it rust, Go, Python, etc, all I get is a string value of an error(at best). If you've found yourself in a place where you need to pick one of "40+" possible error functions to deal with errors in the common case, then respectfully, you have taken a very wrong turn. Could you say more about how you arrived there? It might help others write better documentation (myself included). Have you read the [book's chapter on error handling](https://doc.rust-lang.org/book/second-edition/ch09-00-error-handling.html)? For a longer and more thorough treatment, I also have a [blog post on the topic](https://blog.burntsushi.net/rust-error-handling/). &gt; Mostly this is only an issue when you want to try and recover from errors. Could you show the Go code for this? It really should be no worse than the equivalent Rust code. In Go, if you get an `error` back and you need to recover by inspecting the error, then you'll need to do some amount of type switching or type asserting based on the error. Alternatively, if all you need to do is log the error and continue on, then again, this should be as easy in Rust as it is in Go. &gt; If all you are doing(and in basically all the rust code I've seen in the wild so far does) is either handle the error by using ? or at most throw the error message out to the user and continue. Or the code is littered with .unwrap()'s. Well... yes. This is the common case. This is true in Go as well. &gt; Does that make sense, or did I ramble on incoherently again? If I did I'm sorry! I'm trying to understand WHY Rust decided to handle errors they way they do, it makes little sense to my brain on how it's remotely better than other languages when it comes to errors, mostly it just seems more complicated for no extra gain. Thanks for writing out the comment! I think there's definitely some misconceptions on your part here. I still don't know quite exactly what they are, but I hope my comment here helps clear some things up. I've been writing Go and Rust daily for several years now, so I'm intimately familiar with both systems of error handling. I generally largely prefer Rust's style. One the main benefits I see between my Rust code and my Go code is that I am much more principled about my failure cases in my Rust code, which I generally perceive to be a good thing.
TypedArray implements From&lt;&amp;[T]&gt;. So you can just get a regular old vector from the file, and then convert it with `.into()`
In this case, I was reading about Assembly text editors, looking at the way they move backwards. I saw one that said &gt; Try outputting a backspace, then a regular space to black out the character the cursor is now on top of, then another backspace to move the cursor back once again. Would that work, if I linked it to my Rust code?
I'm trying to learn how to use futures 0.2, are there any examples out there yet that show how Context is used?
Ok now its working. Some weeks ago when I tried the page was just blank.
Thanks! I think your blog post will work out my misconceptions, you just fixed one, for some reason it never occurred to me that Rust errors are shoved into the Type system, and are just types. That helps a lot. I'm not sure how I missed that. Anyways, I'm off to work through your blog post, it seems to cut through all the magic that Rust tries to do for you. All the stuff I've read so far tries to handle the 80% case, i.e. ? and friends, and never covers how all of that magic is implemented, your blog post seems to do that at first glance, so it should help a lot. I'm busy trying to find a new place to live for the next week today, but I'll work through your blog post as I have time, over the next few days. Thanks for your response, and really mostly for the link to that post, it looks like it will get me most of the way to what I need to understand this.
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust.
Thanks. I agree ? is awesome for the common case. As soon as you want to get out of the common case, then you are forced to deal with the complexity of Rust's error handling however. I understand the common case, I'm trying to understand the non-common case. Thanks for the comment!
What is the added value of failure crate? I didn't play with the library yet.
The difference is that `u32` is a legal Rust type and `Simple::Other` isn't - the type of `a` in your example is actually `Simple&lt;'a&gt;`. The pattern matching mechanism is already doing an exhaustion check, so it can know that `a` can not be `Simple::String`. But without flow dependent typing, it can't pass this information to the match arm's block block, so `a`'s type there is `Simple&lt;'a&gt;` - which can not be safely cast to `Simple&lt;'static&gt;`. In my case, the pattern matching mechanism knows that `a` can not be `&amp;str` - but this time it can easily create a type that says "`(&amp;str | u32)` without `&amp;str`". That type is `u32`. You don't need flow dependent typing to represent `u32` - so it can easily make the type of `a` in that match arm's block `u32`, which can be safely cast to `(&amp;'static str | u32)`.
:-) It is a long post, so I wish you luck. But yes, I agree with you about the "magic" aspect of many others' treatment on error handling. That is as true today as it was when I wrote the blog post. The key difference between today and when I wrote the blog post is the rise in prominence of error handling libraries such as `error-chain` and `failure`. The hope is that we will move whole hog to `failure`. But that implies a transition period, which will present hurdles to folks new to the language. Rust's error handling is no doubt more complex than Go's. This is a somewhat controversial statement to make, mostly because of the ambiguity of the word "complex." From my perspective though, it is very concrete. If I wrote a similar blog post on Go's style of error handling, it would _probably_ be around an order of magnitude shorter than the one I wrote for Rust. Rust's error handling is fundamentally built around sum types, and not everyone has been exposed to such things. So in order to grok Rust's error handling, you must also in turn grok sum types. They are simple things, but if you've never seen or used them before, they can be tricky to wrap your mind around initially. (I say this, because I try desperately to always remember my initial exposure to them, and I definitely had a hard time with them until they clicked.)
I must have been thinking about it in the parameter list context. 
I was going to try it next
Thank you very much, this is exactly what I was looking for! I'll try to see if I can get it done.
I honestly don't know how the x86 BIOS's text mode would react to that. By the time I was working at that level of things, I was working on Linux, where even the text console is implemented as a terminal emulator.
It helped me! Thanks :D
Since there are a lot of direct answers already, I'll contribute by stating what it's not good at: * GUI: The highly state-driven nature of graphical UIs make them a bad fit for static languages in general (although that's a debate you probably could hold a whole conference on). * Interfacing with C++ libraries: Rust can interface with C quite easily (as long as you're willing to give up its safeness), not so much for C++. * Prototyping: Rust doesn't allow for quickly implementing concepts for evaluation. It either is shiny and perfect, or it doesn't compile. * C-grade programmers: Rust is hard to understand and write, you can't simply keep a bunch of monkeys hammering at the keyboard to produce something you might be able to use. You need people that know what they do.
I am not gopher9, and want to say I have tremendous respect for anyone competing in a difficult space, and more personally, a special appreciation for someone trying to make DVC simpler by giving it mathematical properties. But there is a sense in which I understand gopher9's point: use of nest to develop pijul makes contributing to pijul harder. Nest being closed source makes this difficulty not of the type that potential contributors can fix, which is frustrating. I d/led pijul right now (see below), and calling cargo build right after cloning, noticed (by trying cargo build, per the instructions) it has lines of &gt;&gt;&gt;&gt; in Cargo.lock. Is this a problem in my clone? is a wrong Cargo.lock checked into nest? is nest software serving up the content wrongly? I can't install nest and debug through it, so one of the pieces of the puzzle is closed off. Just now, I used pijul credit to look at the file, and that seems to be a conflict present in the repo, which jives with occaisonal mentions of conflicts being explicit in pijul's data structures. So, it appears this has nothing to do with nest after all, but everything I said before still holds. Even to contribute a patch to the documentation explaining this, I'd have to go back to working with nest, right? I hope this is not offensive, and that pijul succeeds, and that you obtain a solid source of funding for your important work. [danielv@dvflair ~]$ pijul clone https://nest.pijul.com/pijul_org/pijul Pulling patches: 100% (57/57), done. Applying patches: 100% (57/57), done. [danielv@dvflair ~]$ cd pijul [danielv@dvflair pijul]$ cargo build error: failed to parse lock file at: /home/danielv/pijul/Cargo.lock Caused by: could not parse input as TOML Caused by: unexpected character found: `&gt;` at line 926 [danielv@dvflair pijul]$ head -927 Cargo.lock | tail -5 "pager 0.14.0 (registry+https://github.com/rust-lang/crates.io-index)", "progrs 0.1.1 (registry+https://github.com/rust-lang/crates.io-index)", "rand 0.4.2 (registry+https://github.com/rust-lang/crates.io-index)", &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; "regex 0.2.10 (registry+https://github.com/rust-lang/crates.io-index)", [danielv@dvflair pijul]$ 
Work in progress though: the DAT specs that are floating around the internet (e.g. as sourced in the README) tend to forget to mention stuff (e.g. duplicate entries, incorrect compression flags, filenames don't include the 4 characters at the end, etc.)
It's less about issues with contributing to upstream but using the library when integrating support in dev tools, to give the obvious example.
/u/pmeunier, some time back on reddit there was mention that, since you worked on Pijul and its algorithms at the uni in Finland, some or most of the IP is owned by them. Is this still the case? I really want to see Darcs++ and would hate to see Pijul not get adopted due to licensing and IP problems. I mean, going against git's mindshare is hard as it stands, and any, however minor, roadblock makes it harder if not impossible. To give an example, SRP isn't used (wrongfully afaiu) due to past patent concerns, and now we're dealing with broken and insufficient password authentication schemes in all sorts of network clients. I fully understand why GPL makes sense for pijul the program. It's a balancing act between controlling compatibility/correctness and not hindering adoption. It's tough.
It's actually called "trait bound" I think.
for now at least. I'm not aware of may uses of version=1.0 and who knows what 3.0 would bring.
could you provide a working example of this? I couldn't find any good documentation when digging around earlier
The Rust book actually calls them "supertraits"; see [Chapter 19.3](https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html)
What's the syntax for multiple supertraits? `Foo: Bar, Baz` or `Foo: Bar + Baz`?
The latter one.
I'm trying to cross-compile macos-X to Linux. My current problem is that actix-web depends on flate2 And even when I add flate2 = { version = "1.0", features = ["rust_backend"], default-features = false } It still depends on miniz-sys which I'm trying to avoid. When I add that to my Cargo.toml should only allow any flate2 to be compiled with those options of because some other dependency has a flate2 dependency with default features those will be added back anyways?
Reposting something I wrote a few messages below: So looking at this posts from some "obscure" Rust projects: Last post on reddit from "This week in rust" (EQUAL to all others) was: TITLE: "This Week in Rust 230 (this-week-in-rust.org)" https://www.reddit.com/r/rust/comments/8d0ji1/this_week_in_rust_230/?st=jgb1yarw&amp;sh=3fb47bbd Last Rust compiler announcement on Reddit was: TITLE: "Announcing Rust 1.25" https://www.reddit.com/r/rust/comments/87zdq7/announcing_rust_125/?st=jgb22p0w&amp;sh=4a13ce9f Other rust big projects announcements? like Redox? TITLE: "Redox OS Release 0.4.1 (github.com)" https://www.reddit.com/r/rust/comments/88r810/redox_os_release_041/?st=jgb21ld1&amp;sh=928ba4dc What about Tokio last announcement: TITLE: "New Tokio release: The Tokio runtime." https://www.reddit.com/r/rust/comments/834d55/new_tokio_release_the_tokio_runtime/?st=jgb2fbzj&amp;sh=a9013c94 I see you are really having a hard time! I'm done with this "discussion" ... I've lost already more time that it deserved ... maybe because i'm getting older ... but my patient is getting weeker for the iluminati!! PS: I don't give a damn to the down-votes. 
Excellent rig. Do you miss the volume pedal?
Sure, that was also my assumption. If you have an idea of something where the GPL is a blocker, we'd be happy to discuss it.
Oh, thanks, I guess I'm blind.
Well, I certainly understand his point! I'm not claiming that decisions like that were easy! I'm just saying we have for now decided in favour of this option. Pijul and Libpijul are GPL2, by the way. Calling libpijul in the context of the Nest is much much harder than in the command-line tool itself. If you're interested in the project, why not start on the easy thing, and then maybe we can certainly talk about the harder parts, and whether they should be open or not.
Well, Pijul isn't mature or popular enough yet to give examples, but you can one-up git here by having your upstream library be LGPL, and have a C API to begin with, which will avoid git's libgit2 fiasco. libgit2 is incomplete and always playing catch up in terms of performance and compatibility. What I'm trying to say is that a libpijul C API is available in a liberal or LGPL license, then a lot more programs can link against it. The decision you need to make here is whether you value the FSF ideals more than removing barriers to adoption by the wider software ecosystem. I can't make that decision for you, and it's moot to discuss philosophical aspects, just explaining how pijul the program makes sense as GPL while a C API library can benefit hugely from using a different license.
Do you mind clearing this up in the FAQ? I mean, you say _my work on this_, and we know the work has involved at least another developer. The question to answer in the FAQ is this: Q: Is Pijul patented or otherwise encumbered by IP ownership that would require license/permission for anyone else to implement the algorithms? A: Boolean. No offense intended, it's just that many projects unconditionally dismiss LGPL libraries to be on the safe side, so anything but a boolean answer to patent/ip restrictions is impractical. The fact is that technologies that are restricted in that way are only adopted in commercial or we-dont-care (e.g. piracy as in HEVC movie encodes, etc) fields.
Note: you may be interested in fuzzing technics to shake out bugs/unexplored corner cases :)
Since you have experience with both, could you elaborate a bit on OCaml's C interoperability as compared to Rust's, and why you consider it better?
Spotted this in this week's "This Week In Docs" post. Sounds like a great idea; have enjoyed all the other books so far, and looking forward to one that digs deep on the compiler itself!
Ah yes, to be honest I didn't do that in this case :( there are checks to ensure that obviously invalid data get screened out (the code contains a bunch of data checks before each step) but there might be weird edge-cases (e.g. when the user's low on disk space or when an offset is out of bounds). I probably should've wrote this with TDD, as with my other projects, but this was mostly a rust learning exercise - I usually pick a data/protocol spec and roll with it in order to "bleed myself in" with a new language
DSLs, for one
I consider TDD and fuzzing to be orthogonal: - TDD is for the corner cases you identified, - fuzzing if for the corner cases you missed. They complement each other pretty well.
-&gt; /r/playrust
Good advice - I'll give it a try
Tbqh, with Rust, TDD doesn't always make sense, since the type system is half of your testcase. But fuzzing and TDD are companions! :)
You seem to getting worked up over not much, compared to everyone else in this thread. This is actually a really common complaint, I've heard people ask for short one-liner as part of release announcements about a dozen times across many projects, and many projects do this now as a result. You pointed out a bunch of titles. The title is not the place for a short description for sure. The first paragraph of the announcement is though. Eg: here's what the Rust release announcement's first paragraph says: &gt; The Rust team is happy to announce a new version of Rust, 1.25.0. __Rust is a systems programming language focused on safety, speed, and concurrency.__
Sorry but the argument was that it was hard when browsing the front page... And in the front page you see THE TITLE. That was my point. 
Is it possible to easily turn &amp;T to &amp;[T]? Obviously it should not be possible to do this for more than one &amp;T, but it seems like I should be able to just wrap a reference in a slice with a length of 1. My use case is that there is an API I want to use which accepts a slice, but it would make the most sense for me to use a borrow.
You could use a function such as: fn slice_one&lt;T&gt;(t: &amp;T) -&gt; &amp;[T] { unsafe { std::slice::from_raw_parts(t, 1) } } `std::slice::from_raw_parts` infers the lifetime for the usage, so it's better to have a function like `slice_one` above which ensures the slice has the same lifetime as the element. (In this case the lifetimes are elided in the function definition, with explicit lifetimes it would be `fn slice_one&lt;'a, T&gt;(t: &amp;'a T) -&gt; &amp;'a [T]`.)
Thanks so much for the clarification. I'll try to fix my environment. Probably my case is not so common as of trying to move Actix to support it.
Man steveklabnik is a real mvp in the rust community, hes also really helpfull in the #rust-beginners and #rust irc channels.
That makes sense. Thanks! I think I'm just going to pass a slice around because I don't want to introduce `unsafe`.
I am not a graphics expert, but since it looks like you are on a Linux-esque system, you could try writing your pixels to the framebuffer device directly (/dev/fb0)?
It depends on what drivers are available for the Odroid's GPU. For many SoCs, drivers for Android's graphics stack are the only option, so you're already lucky that X11 is an option. Beyond that, the third possibility that tends to be supported is Qt's direct-to-driver backends (what Kodi uses, if I remember correctly). That said, are you sure you need to do it "without a windowing system"? The X11 stack is fairly modular and it's possible to lock a single window to fill the screen under X11. (Just use a tiling window manager, configure it to display whichever window has focus and nothing else, and disable the keybindings that allow opening additional applications.) According to [this StackOverflow answer](https://stackoverflow.com/a/1516835/435253), professionals in the embedded space tend to use [matchbox](https://www.yoctoproject.org/software-item/matchbox/) in that role.
There used to be a couple of functions in the standard library that did this, but they were not stabilized and were moved to the [ref_slice crate](https://crates.io/crates/ref_slice). So the [`ref_slice`](https://docs.rs/ref_slice/1.1.1/ref_slice/fn.ref_slice.html) and [`ref_slice_mut`](https://docs.rs/ref_slice/1.1.1/ref_slice/fn.ref_slice_mut.html) functions are safe to call.
I'd report the following on the nest... if it didn't alternate between not responding, HTTP 500 and HTTP 404. I wanted to give pijul a try, and see how it scales. So I took the mozilla-central mercurial repository, and started applying the initial changesets from there. The first mercurial changeset only added a .hgignore file, so that went smoothly. The second imported the entire source of Firefox at the time the repository was created. Which, by then, was only 245MB of data. `pijul add` was fast, but `pijul record -a` took a while, and crashed with an IO error... which turned out to be because I created the repository under `/tmp` and pijul filled all the 7.1GB that were free there. After moving the repo to some other place, it turned out to take more than 1 minute to record that change, and 10GB of temporary space, which went down to 1.8GB once done. That's a lot of disk space for 245MB of raw data. Then I went with the third mercurial changeset, and `pijul add` went quickly. Before doing a `pijul record`, I wanted to see how `pijul status` looked like, and it ran for 12 minutes without a single line of output yet before I decided I had waited enough and ctrl-c'ed... Then I went with `pijul record -a` directly, and as of writing, it's been running for 10 minutes and hasn't finished yet. The home page says: &gt; Pijul started as an attempt to fix the performance of darcs, and ended up among the fastest distributed version control systems. Maybe that's true for small repositories, but apparently, it scales really badly.
Just run X without a display or window manager. There's not really anything to be gained and much to be lost from trying to eliminate more.
To get the actual file data, you'll need to first read the file into a `Vec&lt;u8&gt;`, probably using `read_to_end`. Documentation for [this method](https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_end) has an example at the end which should be what you want. --- As for making a `TypedArray`- this is not possible if you're running natively. `stdweb` types like `TypedArray` depend on the JavaScript runtime (they store data in JS arrays for interoperability), I very much doubt it functions outside of that. Instead, I would recommend storing your data as a `Vec&lt;u8&gt;` in all "generic" contexts which are meant to be usable in both JS land and native land. You can read directly from a file into a `Vec&lt;u8&gt;`, and use [`TypedArray::to_vec`](https://docs.rs/stdweb/0.4.4/stdweb/web/struct.TypedArray.html#method.to_vec) to get that from a JavaScript array.
Treat the buffer as an `&amp;str` with `from_utf8()` and whack at it with `str` methods, I think. `split()` should be helpful here.
I would suggest reading through the [rust book](https://doc.rust-lang.org/book/second-edition/ch01-00-introduction.html) to get a bit of an understanding around what rust is. While it is similar to other languages, things like [ownership and lifetimes](https://doc.rust-lang.org/book/second-edition/ch04-00-understanding-ownership.html) will probably be a new concept. Ok, so to answer your questions directly: * `&amp;mut self` means a mutable reference to `self`. This reference type allows you to modify `self` without taking ownership of it. `&amp;self` is a reference to `self` that treats any access as mutable. * If you are implementing a struct, and want to give access to the fields of the struct, you will need to return a reference. If you do `self.blahblah` it sort of means "take the variable blahblah away from self". Depending on how your code is set up you could possibly try `&amp;self.blahblah` 
If `slice_one` was in the standard library I would definitly use it, but I don't think either a new dep or unsafe is worth the slightly better interface that I would get in exchange.
That's some cool history. Thanks!
You'd write something like impl fmt::Debug for MusicElement { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { f.debug_struct("MusicElement") .field("duration", &amp;self.duration()) .finish() } } This will create a debug implementation for any type-erased trait objects of the MusicElement trait. The disadvantage is that you don't have any access to actual fields and this debug implementation does not work for any non-type-erased MusicElements, the advantage is that you can write it without any additional constraints on what a MusicElement needs to provide.
Yes, that's correct.
Rust actually has recently shipped a shorthand that is much more common in error-handling scenarios (and sometimes for Option). Look at this (somewhat old) post on it while it's still new: https://m4rw3r.github.io/rust-questionmark-operator
`==` will work on strings. It's a call to the `PartialEq` trait, which allows for deep comparison.
I gave a talk on ownership that might be useful https://vimeo.com/groups/toidiu/videos/262923423
Almost. You can't use `?` in main yet, but that is being worked on.
Hmm, okay, I'll try that. All my access with be u32 sized, since I'm emulating an ARM processor, so there needs to not be a cost for that. &gt; As for making a TypedArray- this is not possible if you're running natively. Well, that's a bummer. I wonder how you return an area of memory to JS, then. &gt; TypedArray depends on the JavaScript runtime and stores data in a JS array for interoperability. It's just a contiguous area of memory, not a JS Array.
I thought of suggesting that, but, given /u/functime's apparent level of experience with X11, this StackOverflow answer made me change my mind: &gt; Although you don't want to use a window manager, you might need to use a window manager. &gt; &gt; I haven't dug into the X server sources around this, so I can't definitively say X requires a window manager to run properly. But as somebody who writes X client code, and hacks the X server, on minimalist embedded devices with small screens, low CPU power and no GPU... let's just say, all the major players in that space use one, and have good reasons for it. &gt; -- https://stackoverflow.com/a/1516835/435253
Ok, so if I have, pub struct Parser&lt;T, U&gt; where T: TokenProvider&lt;U&gt;, U: ProviderSource{ provider: T, phantom_source: PhantomData&lt;U&gt; } impl&lt;T: TokenProvider&lt;U&gt;, U: ProviderSource&gt; Parser&lt;T, U&gt; { pub fn new(provider: T) -&gt; Self { Self { provider, phantom_source: Default::default() } } } How would I go about getting rid of phantom\_source, or is it necessary? If I just remove it, it complains that U doesn't get used, but the only reason I want U is for T. Both TokenProvider and ProviderSource are traits. I would ideally want something like this: pub struct Parser&lt;T&gt; where T: TokenProvider&lt;ProviderSource&gt;{ provider: T, } impl&lt;T: TokenProvider&lt;ProviderSource&gt;&gt; Parser&lt;T&gt; { pub fn new(provider: T) -&gt; Self { Self { provider, } } } But then it complains that ProviderSource is not sized. 
If you're not returning a `Result` (which you're not, since your program is in main) you can't use the `?` operator. If I were to rewrite your program (but not use real error handling), I'd probably do it something like this: ``` extern crate reqwest; extern crate serde; extern crate serde_json; use std::error::Error; fn main() { let url = "https://www.metaweather.com/api/location/44418/"; if let Some(title) = get_title_from_url(url).unwrap() { println!("{}", title); } else { println!("No title found at {}", url); } } fn get_title_from_url(url: &amp;'static str) -&gt; Result&lt;Option&lt;String&gt;, Box&lt;Error&gt;&gt; { let location: serde_json::Value = reqwest::get(url)?.json()?; let title = location.get("title") .and_then(|t| t.as_str()) .map(|t| t.to_owned()); Ok(title) } ``` 
The `?` operator has been implemented for a long time. You just can't use it in the `main` function yet (something that the page linked doesn't touch on at all). You can only use it in functions that return a `Result` or an `Option`.
No issues writing GUIs with gtk-rs over here.
As others have said, if you're not returning a `Result` (which you're not, since your program is in main) you can't use the `?` operator. If I were to rewrite your program (but not use real error handling), I'd probably do it something like this: extern crate reqwest; extern crate serde; extern crate serde_json; use std::error::Error; fn main() { let url = "https://www.metaweather.com/api/location/44418/"; if let Some(title) = get_title_from_url(url).unwrap() { println!("{}", title); } else { println!("No title found at {}", url); } } fn get_title_from_url(url: &amp;'static str) -&gt; Result&lt;Option&lt;String&gt;, Box&lt;Error&gt;&gt; { let location: serde_json::Value = reqwest::get(url)?.json()?; let title = location.get("title") .and_then(|t| t.as_str()) .map(|t| t.to_owned()); Ok(title) } 
If you're not returning a `Result` (which you're not, since your program is in main) you can't use the `?` operator. If I were to rewrite your program (but not use real error handling), I'd probably do it something like this: extern crate reqwest; extern crate serde; extern crate serde_json; use std::error::Error; fn main() { let url = "https://www.metaweather.com/api/location/44418/"; if let Some(title) = get_title_from_url(url).unwrap() { println!("{}", title); } else { println!("No title found at {}", url); } } fn get_title_from_url(url: &amp;'static str) -&gt; Result&lt;Option&lt;String&gt;, Box&lt;Error&gt;&gt; { let location: serde_json::Value = reqwest::get(url)?.json()?; let title = location.get("title") .and_then(|t| t.as_str()) .map(|t| t.to_owned()); Ok(title) } 
Oh that clears it up. By main I thought the main line of the compiler
Oh, I see what you mean. I though that you mean "adding meta constraint on `a` that it can only be `Simple::Other`", when what you meant is `"setting `a`'s type to `Simple::Other`". In that case, I wouldn't call it "flow dependent typing" - it's just pattern matching. As a side note - pattern matching and flow dependent typing kind of cover the same use cases. You mentioned Ceylon - when I googled "ceylon pattern matching" I got [a blog entry from the official site](https://ceylon-lang.org/blog/2012/09/13/destructuring/) that explains that Ceylon doesn't need pattern matching because it can do the same things with it's flow dependent typing. So, let's say that `Simple::Other` was a valid Rust type. And let's say that my suggested for syntax for types in match branches was valid: bound_name: BoundType =&gt; { /* here bound_name is of type BoundType */ }, So, we could have this: enum Simple&lt;'a&gt; { String(&amp;'a str), Other(u32), } fn morph(s: Simple) -&gt; Simple&lt;'static&gt; { match s { _: Simple::String =&gt; Simple::String("Hello, world!"), a: Simple::Other =&gt; a, } } (let's ignore the implicit cast from `Simple::&lt;'a&gt;::Other` to `Simple::&lt;'static&gt;::Other` - this is not the issue here) Now, imagine we wrote this instead: match s { _: Simple::String =&gt; Simple::String("Hello, world!"), a: Simple::String =&gt; panic!(), } (I used `panic!()` to avoid type inference on the result - we are only interested at the branch patterns here!) Based on `rustc`'s current behavior, it is safe to assume it'll print a warning that `a` can not be reached. Next: match s { _: Simple::String =&gt; Simple::String("Hello, world!"), } Based on `rustc`'s current behavior, it is safe to assume it'll print an error that the match is non-exhaustive - `: Simple::Other` is not covered. (or maybe it'll say that `Simple::Other(_)` is not covered - now it has two styles to represent the same thing. Notice that anonymous sum types don't have this problem) So why wouldn't the compiler be able - if we omit the type - to simply fill it for us? 
&gt; It's just a contiguous area of memory, not a JS Array. Are you sure about that? I'm pretty sure a `stdweb::TypedArray` is a reference to a contiguous area of memory _in JS_. In the source code, it's explicitly a wrapped `Reference` which represents some data which is on the JavaScript side of things. https://github.com/koute/stdweb/blob/ab8a7ce81f57b831979c5c00f29fc8a9f21df819/src/webapi/typed_array.rs#L110 &gt; Well, that's a bummer. I wonder how you return an area of memory to JS, then. `TypedArray` is definitely how you should return an area of memory to JS! It is 100% usable when compiling rust to WASM. If you're making a hybrid application that can compile to either WASM or to some native target, though, you can only use `TypedArray` in the portion of your code which is specific to WASM / the browser.
By the way, just as an alternative, under the Xcode / static library route, you can set up Xcode to invoke Cargo as part of the build process, by adding a “Run Script” build phase. There’s no need for what /u/Yottum seemed to be suggesting where you’d run `make`, then invoke an Xcode build, as two separate manual steps. (Unless they meant having Xcode run `make`, which is also possible.)
I recommend this page for learning gtk-rs: https://mmstick.github.io/gtkrs-tutorials/
Oh yeah, that was kinda my goal for learning Racket in the first place, man how could I miss that. Yep they are incredible for DSLs you're right.
Ha, yes I had a feeling that might be the case.
&gt; &gt; It's just a contiguous area of memory, not a JS Array. &gt; Are you sure about that? Yeah, that's the point of them. Not just typed, but performant, too. Or, rather, they're the typed view of an `ArrayBuffer`, which "is used to represent a generic, fixed-length raw binary data buffer." &gt; If you're making a hybrid application that can compile to either WASM or to some native target, though, you can only use TypedArray in the portion of your code which is specific to WASM / the browser. So to use that data in the common part, I'd have to have some other kind of view of it? Ideally I wouldn't have to copy it. I wonder how that works with canvases, which have a `Uint8ClampedArray` or whatever it's called. &gt; Since you're making an application that is "both native and in the browser", you'll need to write some code which specifically interfaces with the browser / JS, and some code which interfaces with the native OS, right? Yeah, I should probably have two implementation of my ROM memory, one which wraps a `TypedArray` and one which wraps an array or vector, and have a `get_word` method on each. 
Cool. The migration features definitely seem like the killer one - if you don't have a strategy that includes rotation/ handling a break, you don't have a strong enough strategy. Having tooling to get this right is awesome. I look forward to reading more, though I won't be in NYC.
&gt; Yeah, that's the point of them. Not just typed, but performant, too. Or, rather, they're the typed view of an ArrayBuffer, which "is used to represent a generic, fixed-length raw binary data buffer." Sorry, I guess I misunderstood your initial statement. TypedArrays are a typed, performant contiguous area of memory. My distinction is that they are a contiguous area of memory _owned by the JavaScript VM_. They're definitely the best JS gets, and the WASM memory block itself can be accessed via TypedArrays. However, they do not represent a contiguous chunk of memory Rust can own- fundamentally, they are a JavaScript concept. &gt; So to use that data in the common part, I'd have to have some other kind of view of it? Ideally I wouldn't have to copy it. I wonder how that works with canvases, which have a Uint8ClampedArray or whatever it's called. Yeah- I would recommend using a `Vec&lt;u8&gt;` or `&amp;[u8]`. You could make your own wrapper, but it does not seem possible to get data out of a `stdweb::TypedArray` in any way besides converting it to a `Vec` anyways. Vec is what you will need to use on a native platform as well. If `stdweb::TypedArray` gave you access to the bytes without copying all of them to rust memory, your plan would be an excellent idea. I... don't think it does this, though? In any case, after you've copied it, a rust `Vec` will be even faster than `stdweb::TypedArray` if it did provide access, since `TypedArray` is owned by the JavaScript wrapping the WASM module, and you'd need to call into JS to access any bytes from it. I'm not sure about the interactions with JavaScript canvases, someone else probably knows more than I do.
Try: println!("You typed: {:?}", val); And you should see what's going on :)
I dont understand. I expect the printout to be: You typed a You typed ab You typed abc You typed abcd
Yes I do. thank you very much! 
It is not big deal, we can add rust backend to actix. Please create ticket
Qt can render to the framebuffer or via DRM (direct render manager, I think) with the right Qt platform plugin. I recently developed a UI for an embedded system, runs ~60 fps on an Olimex with an A20 cpu, no HW acceleration
I think the article shows a progression from "bad" to "good", in terms of responsible error handling. To the end of the article there are many `?`, and you don't need the `failure` crate to use it, `Result` with any error type that can be converted to will work (but you might want a helper crate like `failure` anyway, just to make some cases more ergonomic).
`TokenProvider&lt;ProviderSource&gt;` is `TokenProvider` implemented over the type of trait objects `ProviderSource` - not what you want. It seems that using the phantom data is the best way to do this.
It shows up this way because `read_line` includes the newline character.
I ran across the FoundationDB repo a few days ago, and that seems to be right when it was open sourced. Could you comment on when someone would pick FoundationDB over Redis or LMDB? I typically just pick Postgres for most projects, and that works great. I can see that FoundationDB might be really good for very large scale stuff, but I'm also wondering if it might have benefits for small projects.
Lmdb is just a storage engine (no server part). Fdb is distributed ordered key value store. What makes it exciting is that it is extremely well tested and reliable. Distributed databases are extremely difficult to test. Cockroachdb or tikv are more comparable and frankly they are likely pretty worried that apple open sourced fdb. There is little reason to use anything else now. 
FoundationDB is mostly interesting for horizontal scaling. If you are *sure* your small project will stay small, I don't think there's much benefit.
CockroachDB provides a full SQL interface and it is compatible with the Postgres wire protocol, so it's almost a drop-in replacement for Postgres. I don't see why they would be concerned about a key-value store?
So I haven't played with it enough to give good details here, but what got me excited were the comments from users and the original founders/engineers on the project: https://news.ycombinator.com/item?id=16877395 Basically, FoundationDB appears to claim ACID compliance (by following certain read/snapshot guidelines). Essentially, this appears to be a building block for any datastore you'd potentially like to build. It would be akin to TiKV, but with stronger consistency guarantees (as desired). From the APIs it looks like abstractions could be built that would match the semantics of pretty much any datastore you'd like, which seems too good to be true and made me want to explore it. I can easily picture HBase, Cassandra, and/or DynamoDB APIs built on top. A full SQL/ACID compliant RDBMS could probably be built too. I'm curious about streaming APIs on top of it as well. It looks like scalability is a factor of replication. It appears to work in both high-latency and low-latency environments, with support for things like low-latency replicas and disaster recovery options for backups. At work we quickly ran some non-scientific load to see how it performed, and it was impressive. Also, it's -super- easy to install and get started, think one click DB... Anyway, I don't know much at this point but what I've read and what I've gleaned from the C API. It's exciting. For me, I immediately started thinking of how this could help with DNS deployments over varying latent distances.
&gt; Cockroachdb or tikv are more comparable and frankly they are likely pretty worried that apple open sourced fdb. There is little reason to use anything else now. The paranoid cynic in me suspects that the growing interest in CockroachDB and TiKV/TiDB is the reason that Apple opened up FoundationDB: kill the upstarts before they become too popular/mature and make FoundationDB "uninteresting".
Nah. Apple is not in the db business and can only gain by open sourcing it. There will be lots of activity and work done to build new layers on top of it. 
Apples to oranges. Server to server redis will obviously be faster. Fdb gives you horizontal scaling and no single point of failure.
glutin did support headless mode (without windowing system). But I don’t know how it will work in your case. 
&gt; What do you mean by no ABI by design? I meant exactly what I said. Many Rust constructs have no specified ABI, and never will. By design. This is what allows Rust code to be fast.
this is really cool but super doesn’t affect me. FoundationDB is great if you are dealing with *actual big data*. To be clear now in 2018 this would likely be in the 100’s of terabyte plus range. At least this gives me another reason to not use Casandra 👍 
this is great, thanks!
It was never open source.
At which point Box&lt;Read&gt; is *probably* better than roll-your-own-dynamic-dispatch.
It's a known issue, already reported in pijul's forum. Moving to the current naive diff (used because it made it easier to debug pijul in its early days) to meyers is expected to close at least most of the issue