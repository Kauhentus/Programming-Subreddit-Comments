Yes, it makes inference harder. (It is conceptually much more complex.) No, it will not require any more annotations. All the burden will be born by compiler implementors.
Lifetimes in function body spanning the entire lexical scope.
Why aren't function arguments evaluated from left to right?
How are we supposed to participate in this discussion when there are already 49 comments five hours after the post has been made? I don't have the time or motivation to read everything. I suppose that many people who comment don't bother reading the previous comments of the discussion, so they just post their own feeling even though it's just a duplicate of a previous comment, or they could have reacted to some other comment instead. This in turn contributes to creating more comments, which makes it a vicious circle. 
When reusing crate names, would it be desirable to make sure the versions never overlap between old and new usage of the crate? That way, people with a dependency could still build.
The standard way is to wrap your type `T` in `Arc&lt;Mutex&lt;_&gt;&gt;`, which is an atomic reference counted mutex, allowing multiple threads to have shared ownership of the mutex which ensures exclusive access when you want to use it. If you would like to share access to a stack-allocated reference, the [crossbeam](https://github.com/crossbeam-rs/crossbeam) crate has a "scoped thread API", which allows this. 
They are. The thing is that the function takes only one argument. The second borrow is for the receiver of the call which is borrowed before the arguments are evaluated and released after the call.
&gt; the program still uses 12+GB of RAM and possibly growing, but it isn't caused by collections not running at all. Exactly - with more threads collections will still happen, but: 1. They will probably kick in more rarely. 2. More garbage will accumulate because more threads are producing it. I did a test doing something similar, and measured the *maximum* amount of allocated memory during program's execution. That was measured using `time -v`. My unscientific observation (on a typical 4-core laptop using Linux) is: if you have more threads than processors, the *maximum* allocated memory grows linearly with the number of threads. This is kinda intuitive: if you go from 100 threads to 200 threads, garbage collection will lag behind garbage production twice as much. &gt; It may well be that each GC doesn't do enough work, but that seems like something crossbeam can push on Here's one idea we'll give a shot. The current epoch-based GC is destroying (`free`ing) tons of garbage within critical sections. But we can take an incremental approach instead: while in a critical section, grab a small chunk of garbage. Then, just after exiting the critical section destroy the whole chunk at once. That would make GC pauses shorter and also shorten the critical sections, giving less chance of threads getting descheduled while pinned. &gt; GC is similarly blocked, and blocked in a way that prevents progress completely on the thread trying to GC Good catch! :) Even though Crossbeam's GC can accumulate unbounded amounts of garbage, it is still lock-free. Ticki's HP-based GC is not - it is blocking, which is in theory even worse. But! - While I haven't tested its performance, I presume threads get descheduled while waiting on hazard pointers rarely enough so that this is a non-issue. It's worth nothing that HP-based GCs don't have to be blocking - it's just how this particular implementation works. But occasional blocking in this case might be totally forgivable. &gt; (I vaguely recall that some allocators optimise for the malloc/free pair being on the same thread?) Perhaps you're thinking of thread-local cache: when you call `free(ptr)`, then `ptr` is not deallocated immediatelly, but added to the current thread's cache. If you then call `malloc` with a similar size in bytes, that pointer might be reused from the cache. If the cache gets very large, then excess pointers actually get freed. We'll employ a somewhat similar strategy in Crossbeam's new GC. &gt; Also, another problem that seems to currently be shared by both approaches is singled-threaded GC: the GC thread needs to be doing as more work than all the other threads Crossbeam's GC is fully multithreaded: any number of threads can be collecting garbage at the same time.
I did specifically mention I didn't want to use a third part library and the one you gave as an example happens to be the exact one I gave as an example of what I don't want to use :P Also, Is it obligatory to wrap it in a mutex ? As I said, the container itself is thread safe in this case. Would it be ok if I returned an Arc&lt;MyContiner&gt; from MyContiner::new() is that was the suitable form for users to use ? Also, is there an example of actually doing this ? I tried sharing state with Arc but all i managed to do was get some esoteric errors about type erasure...
&gt; Also, Is it obligatory to wrap it in a mutex ? As I said, the container itself is thread safe in this case. There's no *need* to wrap it in a mutex, but then you can only access the thing immutably. The mutex is there to let multiple things access the resource and mutate it (but not at exactly the same time).
You asked several questions, and I answered some of them.
&gt; were the PS3/360-targeting C compilers lower quality with regards to optimisation? I was working on 'launch titles' which meant dealing with early compilers, getting software into the first wave, before the market becomes saturated. They did of course improve over time. Of course not every task faces such pressure. Maybe there are analogous situations in 'embedded'. But the main problem with he PS3/360 was they had *in order processors* and deep pipelines for maths; mixing float maths &amp; branches (i.e. most of gameplay code, lol) crippled performance; we needed to workaround with all sorts of tricks. There was no fast way for information to get between the integer/branch and vector-float pipelines. I don't think any modern machines are as insane as that, but a similar issue would resurface if you wanted to leverage generalised SIMD &gt; I reckon Rust will be the language for gamedev in 5 to 10 years, unfortunately **I doubt it** . Only with a big cultural shift in rust. This is a shame because the language engine and hence 95+% of the work done here IS suitable. By then [Swift will have move/borrow](https://github.com/apple/swift/blob/master/docs/OwnershipManifesto.md), and [JAI](https://en.wikipedia.org/w/index.php?title=JAI_(programming_language)) will be available; it's also possible static-analysers ,modules, and concepts will have hit C++. If C++ ever gets [UFCS](https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax) i'll forgive it all its other sins. This is an excellent talk I agree with 95% of. *Rust simply does not target the precise needs of gamedev*. I keep explaining the issues here and it falls on deaf ears. https://www.youtube.com/watch?v=TH9VCN6UkyQ&amp;list=PLmV5I2fxaiCKfxMBrNsU1kgKJXD3PkyxO He considered Rust, Go &amp;D , before embarking on writing his own and explains why here. Custom languages do have a precedent, in his second talk he does mention replies from gamedeveloppers who built their own in-house languages compiling to C or C++, and I recall a PS2 era game where they used a [customised LISP](https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp) (with low level interface for using the PS2 vector-unit ISAs) (edit this [talk from Ubisoft](https://www.youtube.com/watch?v=qYN6eduU06s) mentions this approach, they had an in-house language compiling to c++ sitting on top of their engine). in short, gamedev needs **Performance&gt;Productivity&gt;Safety**. rust gives **Safety&gt;Productivity&gt;Performance**. Productivity and safety are not the same; and games are often in walled gardens and need extensive testing for other reasons. Here's my bigger explanation https://www.reddit.com/r/rust/comments/6p3i0m/what_kinds_of_projects_are_being_written_in_rust/dknrcfd/
to be fair, i'm not sure what C++ compile times would be like if you templated just about everything. I do find wanting to use more generics in rust in situations where in C++ you'd be scared off from doing it ('because it means writing your whole program in headers..') 
I can't think of an alternative, sadly..
Why not borrow it after the arguments have been evaluated?
Problem case #1 does make me a little uneasy, to be honest. The suggestion is to reduce the lifetime of the borrowed `slice`. I'm a little worried about implicitly shortening the lifetimes of local objects if their destructor does things like unlocking a mutex or restore some data structure's invariant too early (if you use some helper type with implemented Drop for panic safety). Don't we sometimes rely in unsafe code on a particular thing to be destroyd right before the closing curly brace instead of earlier?
my requests for Rust to improve it for gamedev:- * between these suggestions you could eliminate a lot of the use cases of embedded scripting languages, by making code friendlier/lighter for simple cases (any module has such code inside, e.g. tests.) * bring back the Sigils. (these melt away, allowing you to write code in the 'productivity case' more easily. the extra nesting levels cost a lot more than you think, they are severely distracting) * allow whole program inference. let people write as many types as they need. rust signatures get quite heavy. * I made this suggestion handling a subset of cases - infer 'impl' types from the 'trait' .. and even this gets a dissapointing negative response here. This is what I mean about 'cultural shift'. *This community seems hostile to the gamedev use case*. https://github.com/rust-lang/rfcs/pull/2063 * allow generics without bounds. (something like a T:Any). its still ok some of the time. figuring out the bounds can again be very distracting during experimentation, * unsafety workarounds - fundamentally we cannot avoid *testing* in gamedev, so 'provable' safety is a lower priority ..and it doesn't even work , a panic is still a crash or severe glitch .. if you rely on bounds checks, you are doing a debug build really. * option for whole program unsafe. e.g. #[unsafe(borrow_checker_warnings_only)] ..makes every function in the module unsafe (no risk of polluting the ecosystem). there are easy patterns that are still hard to mark up. (other suggestions = a 'shortest' .'noescape lifetime perhaps) * this is not the same as falling back to raw pointers; a C++ reference is not 100% safe but still 'safer than *'. the 'rust way' is ruling out this middle ground. * Possibly another pointer type which is a reference of unknown lifetime, covering the middle ground use case of C++ references. (still safer than *) * allow the safeness of operators to be selected per type , e.g. so you can have an unsafe-vec whose [] is unsafe, unchecked * or perhaps the operators all have free functions that they correspond to, and it's a per-module choice *which one* the operator symbols map to.. something like ```use unsafe::index as [];``` etc * unsafe build option , which disables bounds checks altogether (rust release=c++ light debug. c++ release = rust unsafe build) .. naturally if building a library, it flags everything as 'unsafe'. I have another idea for controlling error messages when you're using version control - when you get huge template errors, why not filter them against the lines that you actually *changed*. ("your change in ```foo.cpp:176``` causes an error ending in this ```template vector:1762```, unfold to see details")
Long story short: I don't think so. This is a well know caveat that Rust cannon infer that a certain object is going to be referenced by the children threads until the join() call, so [this](https://play.rust-lang.org/?gist=0856381ce90d70a91b9ceaa4b8c51d99&amp;version=stable) fails to compile. Using a self-reference counted structure [like Arc](https://play.rust-lang.org/?gist=b92947021ebc61764d1f8c98e2f0ec7b&amp;version=stable) "solves" the problem by making sure the shared container isn't deleted until no one is referencing it, but that's overhead for no reason. The std used to have "scoped" threads which give the compiler a hint about how long the references in the child threads are going to live, but since it can be implemented by libraries it was removed. Right now the best option is using Crossbeam [thread spawn methods](https://aturon.github.io/crossbeam-doc/crossbeam/struct.Scope.html#method.spawn) or implementing your own barebones thread scope.
`in` is the `for` loop keyword.
this will be awesome, but it does point to why it would have been useful all along to have an unsafe build option that turns the borrow checker into warnings (and automatically flags every function as unsafe, if you're worried about ecosystem pollution). **there are still cases where writing safe code requires an explicit over-estimate**.. which is where it discomfort and trade-off in using Rust comes from. There's a difference between *safe* and *proveably safe* (with research into 'proof' ongoing.)
I have a vague uneasy feeling when I see the comments like [this](https://github.com/rust-lang/rfcs/pull/2094#issuecomment-319823965) pop up immediately. You don't have to read the entire RFC -- and then realise it's only one of many -- to notice this is a very complex feature. It carries both the semantic complexity of the design itself, as well as many subtle nuances that inform the implementation. Yet its ultimate goal is to make the borrowing &amp; ownership system _simpler_ and more intuitive. So it's the case of complicated implementation that's supposed to expose a simple interface. In software engineering, those cases are _tricky_. It is also why many people opt for implementation simplicity in hope it translates to interface simplicity. Sometimes this produces good results, but sometimes it produces Git. It's not a silver bullet either! What I mean here is that for non-lexical lifetimes to be a successful addition to the language, this complexity has to be managed carefully and cooly. I get it, everybody has been waiting for NLL for what feels like ages (I definitely have!). It's something that has the potential of significantly easing Rust adoption, when "obviously correct" code stops tripping the breakers of the borrow checker. To ensure this happens, however, the actual design &amp; engineering work must be of utmost quality. I have no doubt that the Rust team is capable of delivering it; we should just let them do it in due time rather than trying to rush it.
Looking at the comments on github https://github.com/rust-lang/rfcs/pull/2094#issuecomment-319928151 it looks like it does't change the order of destruction, only of what is legit to compile. So if I understand correctly their destructor would still be run at the end of the block.
If you just want to be able to more concisely refer to "vector of things", then type alias is the way to go. The main difference between type alias and newtype is that aliased type is compatible with new name (`type Foo = Bar&lt;u32&gt;`, I can now use `Foo` wherever `Bar&lt;u32&gt;` is allowed, and vice versa). If you want that - use type alias. If you don't want that - use newtype. For example, in standard library `String` is basically newtype of `Vec&lt;u8&gt;`. You don't want `String` to actually be `Vec&lt;u8&gt;`, because it has to maintain invariants, therefore its a newtype.
Should I wait for this PR to be merged before starting to learn Rust? I suppose Rust programming will be much simpler when it will be merged?
Yeah, Reddit didn't show me the previous comment after I submitted it. Looks like it was a caching problem.
&gt; Is there a way of doing one or both of those things in such a way that a user of said library doesn't need to be a rust expert to use it That's what libraries are for. And in Rust there should not really be a reason not to use them. That is not saying you should blindly use any library out there but after careful selection there should be no reason not to use them. &gt; or include a second third part library (e.g. crossbeam) to use it ? Now you're just making it difficult for yourself. Note that crossbeam is by one of the core developers of Rust. That doesn't necessarily puts in on the same standing as the standard library, but does lead credence to the work coming from a rust expert. But you can always copy/paste the code from another library and then you've met both requirements. I know there are reasons for minimizing third party dependencies, though some of those reasons should be re-evaluated in the light of a modern package manager like cargo. One should realize that the Rust standard library is not intended to be a batteries included one stop shop for all your needs, not even for all basic Rust programming idioms. This is not only because of the sentiment that "stdlib is where libraries go to die", but also is an essential part of keeping your code compiling and working when upgrading Rust. By depending on specific versions of libraries your code is shielded from breaking changes in newer versions. There is work being done to boost the progress on some essential libraries to be of a higher quality in the [lib blitz](https://internals.rust-lang.org/t/rust-libz-blitz/5184). This should make those libraries good enough to be depended upon, whilst still keeping them standalone so that semver protects the users of those libraries against breaking changes. But sharing your thoughts on what would help third party libraries be something you'd be comfortable using would be valuable input for this aspect of Rust development.
Interesting. Is there some intention to merge this with Permabit technologies, which was [*just* acquired by Red Hat](https://www.redhat.com/en/about/press-releases/red-hat-acquires-permabit-assets-eases-barriers-cloud-portability-data-deduplication-technology)?
Sounds good! Thanks for digging this up.
Just found another shortcoming of a type alias. You can't derive for a type alias, and I don't want to manually implement serialize and deserialize.
[removed]
&gt; There's no *need* to wrap it in a mutex, but then you can only access the thing immutably. Wouldn't that depend on how the container is implemented? After all, a threadsafe container might implement its own interior mutability support.
I definitely want more rationale for why `use` being relative by default is allegedly an improvement. When moving from 2.x to 3.x, for example, Python made the _opposite_ change, and even most 2.x ~~holdouts~~ traditionalists prefer to activate the `absolute_import` backport. Relative imports are widely regarded as bad in the Python community due to the potential of name clashes with both standard and third-party modules, as well as lesser clarity as to what exactly is imported. On an unrelated note, one thing this proposal doesn't address is how library crate names can be divorced from package names. For example, there is a line in my `main.rs` right now that reads: extern crate texture; // piston-texture so that I know where the hell this `texture` crate is actually coming from (`piston-texture = "0.x"` in Cargo.toml). If we move to `from $CRATE use $STUFF;`, then the discrepancy will be sprinkled around the codebase and make it that much harder to figure out where the symbols are coming from. _Especially_ if you combine that with the relative import proposal! Granted, this is something that is equally on the crates.io, community, and the module system to address, but it'd be nice if at least that last thing didn't make the situation worse.
To make things worse, Discourse is always trying to hide parts of the discussion and messing with search.
All in all its still a pretty isolated change, it won't change anything fundamentally, just remove a few hurdles you tend to sometimes stumble over with lifetimes in the current implementation. That is to say, if you want to learn Rust, you might as well start now. :)
Its certainly possible to implement a data structure that is threadsafe without wrapping it in a `Arc`, `Mutex`, etc directly - after all, that is exactly what is done for those types themselves. The basic idea is to expose the mutable interface through `&amp;self` rather than `&amp;mut self`, by using internal mutability and a threadsafe implementation on the inside, and making sure the data structure is correctly marked as `Send` and/or `Sync`.
Yes but most of the containers in std don't work that way, so `Arc&lt;Mutex&lt;T&gt;&gt;` or `Arc&lt;RwLock&lt;T&gt;&gt;` becomes a familiar pattern.
If you have `struct ListOfThings(Vec&lt;Thing&gt;)`then you can only derive `Serialize` if `Vec&lt;Thing&gt;: Serialize`. If you have `type ListOfThings = Vec&lt;Thing&gt;`, then requiring `ListOfThings: Serialize` is the same as requiring `Vec&lt;Thing&gt;: Serialize`, therefore you don't need any deriving. Example: https://play.rust-lang.org/?gist=386819d19c7d9b63abc4fdb057bc7523&amp;version=stable I'm not familiar with serde, but I think newtyped and aliased lists will be serialized differently, but as far as I understand serializing and then deserializing will work as expected for both cases. This is actually the same as with iterators: with type alias you don't need to implement `Iterator`, or any other trait, including `Serialize`.
And discourse uses a flat structure, which I hate. Maybe it's because I'm used to reddit but I find it extremely difficult to have a discussion without threaded conversations.
Because that is something that seems simple at first, but is really a narrow special case. Consider the following statements: `Vec::push(&amp;mut x, x.len())` - this is what the call desugars to, this is what needs to be actually supported, with arg evaluation from the left to the right. `Vec::push({x.pop(); &amp;mut x}, x.len())` - however this should not be supported, because making it valid from a lifetime perspective would change the order of evaluation. So what the new system does is essentially "reserving" borrows. The argument evaluation order is still left to right, but when a simple mutable borrow is encountered this will still allow immutable borrows to be used afterwards for arg evaluation, as long as these borrows are finalized before the actual mutable borrow is used. 
If you've got link.exe somewhere, then I am pretty sure that you did. You could maybe re-run the installer and see if that box is checked too, maybe?
I write tests for rust the same way I write them for anything. Ask yourself 'what should my code do?' and then write tests that prove that the code does those things. You can also ask 'what are the properties of my code?' - more on property based testing here: http://propertesting.com/book_foundations_of_property_based_testing.html with rust support here: https://github.com/BurntSushi/quickcheck For more 'component' or 'service' level tests (ie: test the entire service, or large parts of the service, but mock out all external dependencies) I've just mocked out external things - so in particular I've been writing some tests for a library that interacts with AWS SQS, a queuing service. That meant I had to write a 'fake' SQS client and use that in my tests. Then I published to that queue in my test and asserted various aspects about the state of the system. Rust has no mocking support, or the mocking support that exists is really not great. For integration tests where you want to run external dependencies perhaps you could use stainless: https://github.com/reem/stainless Or just write a simple testing harness separately - I use a Python script to run some of my tests.
The issue is The data I'm trying to deserialize has a field called locations, the struct I had previously was: Struct Locations { pub locations: Vec&lt;Location&gt;, } and serde_json was able to figure out how to deserialize just by deriving. But now that there isn't a field in the struct called locations I have to manually implement the deserializer, which I'm having a little trouble figuring out. the type alias looks like: type Locations = Vec&lt;Location&gt;; edit: and you can't make a custom deserializer for the type alias, because Vec already has it implemented. Ended up just going back to regular Struct and implementing IntoIterator
A type alias doesn't create a new type, it just assigns a new name to a type. So, it can be useful if you want to save on typing, but it doesn't typecheck differently or allow you to implement traits you wouldn't be able to implement otherwise. After witing `type V64 = Vec&lt;u64&gt;;`, the compiler sees `V64` and `Vec&lt;u64&gt;` as exactly the same type. That may be useful to you, or it may not.
IIRC, inference is actually explicitly exempt from the strict back-compat guarantees, though I expect changes to it to still be with a light touch.
Linux utility request: a command line tool to accept stdin a data stream, and write to stdout a FEC \([forward error correction](https://en.wikipedia.org/wiki/Forward_error_correction)\) encoded version of the input data. Also a corresponding decoding tool for reconstructing the original data from a potentially corrupted input FEC encoded stream. Should allow multiple types of FEC codes (and block sizes), perhaps even interleaving options; and the decoder should also be able to report on how many errors were corrected, and how many errors were uncorrectable. Such a generic command line tool might have uses for radio enthusiasts, for storing data on archival mediums, for encoding onto printed mediums such as paper or 3D structures. I know compact discs and various radio transmission mechanisms already have FEC built in, even QR codes, but a generic open-source command line tool to do it would be very cool and could be used as a building block for other tools.
could you have a minimum length for crate names such that short handy names don't get taken up, until something has gained a certain level of adoption
To the point where people will loss understanding of what they actually do.
Yes, reading this is what inspired me to start intermezzOS, and older versions had extremely similar bootup code because of it. I really need to find more OS dev time :(
I tried this exact pattern using: let container_sp = Arc::new(MyContiner::new()) and then doing: let first_ref = container_sp.clone() thread::spwan(|| { /*USE HERE */ }) However I got a message about type not being inferable within the context... I will look at it again. If this is the correct pattern I shall try again... maybe I'm using a faulty compiler version or missing something *shrug*. Also, is there no way to bundle the cloning of the arc with the closure scope capturing instead of declaring a 'placeholder' variable every time I want to clone a value into a new scope ?
If your type is already managing thread safety itself, then you could try implementing the `Sync` trait for your type: unsafe { impl Sync for YourTypeHere; } This declares to the compiler that your type is threadsafe (is safe to access from multiple threads concurrently), and will remove the need for a Mutex (I think). See: https://doc.rust-lang.org/book/second-edition/ch16-04-extensible-concurrency-sync-and-send.html
because usually you need it evaluated first. consider `a().foo(b())` you expect `a()` to be evaluated before `b()`
&gt; won't this possibly be a concern for backwards compatability when we get unions that can contain fields with Drop? No, because only a union which contains a field that has `Drop` would need `unsafe` writes, and those can't exist right now, so all unions that currently work will continue to work. In the future, if you need a union with a `Drop` type, you would have to use `unsafe`. &gt; Reading through the rust 1.19 release notes section on unions it appears as though reading and writing to a field of a union should require unsafe. I agree that is confusing, and I'm not sure why it was written that way.
Some common traits can be pass-through derived using the [`newtype_derive` crate](https://docs.rs/newtype_derive/0.1.6/newtype_derive/). For others, if you are doing this a lot, consider implementing a macro like `impl_iterator_for(MyNewType);`.
When you say "refactor", are you speaking of the RFC, or the branch associated with it?
So for me it seems that you want the newtype just to have your model match the data you are getting, and the type alias for convenience. In this case I think you can do this: https://play.rust-lang.org/?gist=a884c29e7e44f2ae9767a9a7b83e907c&amp;version=stable This won't work if `LocationList` is a member of other struct that you are serializing. Serde has field attributes that would allow you to customize deserialization without writing your own deserializer, but I have never used serde so I can't help you with that.
Great article, as always, Ticki. What kind of performance penalty do you expect with a global mutex?
Why would they forget what they do? Do you forget what `Vec&lt;Option&lt;T&gt;&gt;` does? You need to understand what they do to understand why you want to use them, but that is kind of a prerequisite to doing thread-safe programming anyway. `Arc` (**A**tomic **R**eference **C**ounter) allows an immutable object to be shared between threads by providing reference counting (so the object knows when it is no longer needed) . That reference counter is atomic, meaning that one operation (incrementing or decrementing the count) is guaranteed to complete before another begins. This ensures that it maintains a consistent state when two threads try to change it at the same time. `Mutex` and `RwLock` are variations of the same theme that allow threads to acquire locks on objects, which, once locked, can be mutated. A mutex requires a lock to be held to read or write the object, and only allows one thread to hold a lock at a time. A RwLock has separate read-locks and write-locks, and allows many read-locks to be held at once, but a write-lock can only be held if there are no other read-locks or write-locks being held. 
I think you need to `move` your `first_ref` into the closure, otherwise rust won't move ownership into the closure and it sees the your `first_ref` can fall out of scope before the thread is finished. So that would be `thread::spawn(move || {...})`
I mean, Niko's been working on this for... a year? More? This is already the result of serious design and engineering work.
You can turn it off with `unsafe`.
His point doesn't break down in that example. You evaluate left to right, except you evaluate internal arguments before the external call. a() goes first, then b(), then foo().
Ok, sorry for talking about a third party library. But that's the way to use stack variables in scoped threads, there's no way around that, short of writing another library for it yourself.. Let's instead find the best library for it. rayon is good at just sharing &amp; using stack variables across the parallel jobs. If the problem fits rayon, it's very straightforward. let container = Container::new() something.par_iter().for_each(|element| /* job code using the container is here */) The something that is iterated over can be as simple as a range iterator, if you just need a fixed number of jobs. Rayon is quite powerful, even if it gives you one paradigm (iterators) up front. It's intended to be easy to use. Talk link: https://www.youtube.com/watch?v=gof_OEv71Aw
I don't think the example you gave is enough to warrant a really obtuse import syntax. Piston devs almost certainly named piston-texture internally as texture because in the context you would use it - a piston-powered game - you *know* everything related to graphics primitives is coming from piston. If anything, the only confusion is whether you are bringing project-local modules or external crates into scope with a use statement. If extern crate goes away, it looks really weird that you are just "use"ing external crates but need mod foo; use foo::bar; to bring local files into scope. That is why this proposal introduced the from use syntax and dropped mod.
But George3d6 was specifically asking about threadsafe containers, which means that your response can be interpreted as "even for threadsafe structures, it's not possible to have mutability without wrapping them in a mutex". (ie. It can be misinterpreted as saying that there's something special about Rust mutexes which custom containers can't duplicate using `unsafe`.)
Is your container parameterized over the stored type? If so, if you are calling new and not storing anything on it the compiler will fail to infer its type.
&gt; You can turn it off with unsafe .. with a syntax change - raw pointers, and that's too much. Back in C++ a reference *does* carry different connotations to a raw pointer (a raw pointer can be literally anything, a reference narrows it down quite a bit *whilst not needing too much markup*). we could have code that will work, just waiting for tweaks both ways (things in the system, or discovering new helpers) to make it provably safe. there is a middle ground where the borrow checker would still be handy giving warnings. you might have just not figured out the correct labelling yet (that for&lt;&gt; stuff) . there might be future enhancements (like a 'shortest lifetime' ) or new rules in the default assumptions , or an ability to figure out annotations from given examples that would eventually streamline the process of writing safe code. there's a middle ground where you want rusts syntactic tweaks (better lambdas ,tuples etc, no damn header files) but you don't want the whole up-front cost - and **everything i've seen of unsafe code is that it's more verbose than doing it in C++ **, because it's deliberately discouraged e.g there's no unsafe version of operator[], you lose that I don't see why people would be opposed to an option to *disable* something; i'm not asking anyone else who doesn't want it to use it, and it can be clearly marked. it's easy to make a project that doesn't want it ban it. you might have to enable it in the project root, a file which can easily be locked by maintainers
I hear you, believe me :-) This is a problem that Rust's leadership is keenly aware of, and we'd like to figure out some improvements after the impl period (https://www.reddit.com/r/rust/comments/6qrqki/announcing_the_impl_period_sep_18_dec_17/)
I think that would work pretty well. Thanks edit: tried it out, seems to be the best solution. It's for a library to parse google LocationHistory.json files. https://github.com/etrombly/location_history/
See [this comment](http://reddit.com/r/rust/comments/6r6rwb/stratis_redhats_next_gen_linux_storage_framework/dl2zm4h) - Permabit stuff should be just another building block that Stratis can use.
While I would prefer if drop timing wasn't assumed to be the end of a lexical scope, it sadly is and as such, making types drop sooner would be a breaking change. That said, this RFC concerns borrows and will not affect drop times at all. One thing to mention, even if eager drops were implemented, Mutexes would still work as long as you don't take an unsafe pointer to their contents. Other scenarios where Drop is only used to free resources should also work, but cases where Drop is used for more than just destructing would break.
This is really good. I like your workaround for rank 2 types. I haven't worked through the details, but conceptually the way to simulate laziness is to use iterators instead of traversing the children with function calls.
I saw STM and got pretty excited, any more info on where that is going?
there's other potential tweaks like this https://internals.rust-lang.org/t/opposite-of-static/5128/28 which would streamline writing safe code. Until we have all the tweaks (which might take years to discover/refine), don't assume it's a win for everyone.
Started working with doppioslash on an automated solution for arewegameyet.rs with this fork: https://github.com/viperscape/arewegameyet If you're interested in helping, see this issue: https://github.com/doppioslash/arewegameyet/issues/12 I never found a proper crate for parsing crates.io, but it seems to me that sort of meta crate should exist :) So if I cannot find something close, maybe I'll start a new crate based on this concept, for any future arewe(x)yet sites :)
Well, reddit threads are much easier to stomach, for example.
I actually think encouraging discussion on reddit will help fix this problem. It leads to duplication/fragmentation of discussion across internals/reddit but the internals thread is long and that's happening _anyway_ just because nobody is able to even come close to reading all the comments. Basically, for discussions where you're soliciting general community opinion (specifically those where you're likely to get a torrent of Opinions) a threaded model is much better since it lets you deal with clutter a lot more, and similar opinions tend to group. We can experiment with moderating these threads to keep them narrowly on topic. The threaded model lets you more easily skim over discussions and see the important bits. I've never had trouble reading large, noisy, discussions on /r/rust. I've always had trouble on irlo.
Initially, I tried `-&gt; impl Iterator` but it can't be used with traits' methods.
&gt; I'm not sure why it was written that way. I wrote it, and it's because that's what the RFC says: * https://github.com/rust-lang/rfcs/blob/master/text/1444-union.md#reading-fields &gt; Unsafe code may read from union fields, using the same dotted syntax as a struct: * https://github.com/rust-lang/rfcs/blob/master/text/1444-union.md#writing-fields &gt; Unsafe code may write to fields in a mutable union, using the same syntax as a struct: The section about `Drop` doesn't say anything about interaction with unsafe.
I still don't understand it :( Why isn't Vec::push({x.pop(); &amp;mut x}, x.len()) the same as x.pop(); Vec::push(&amp;mut x, x.len()); ?
I think you need a trait somewhere with a function that returns an iterator for child traversal and then derive those iterators. Maybe also a way to reconstruct a value from a child iterator.
Niko's first blog post was almost a year and a half ago http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/ And of course, it takes time thinking about stuff before you can even write the post...
&gt; Piston devs almost certainly named piston-texture internally as texture because in the context you would use it - a piston-powered game - you know everything related to graphics primitives is coming from piston. Except it isn't! Piston is a modular, abstract, and decoupled system where various components can have different implementations. The graphic side, for example, requires you to also depend on something like `opengl_graphics` and its subcrates to actually draw anything. Guess what you can find among those subcrates? That's right, something to handle textures :) I imagine similar situations can easily arise in any of the other "subecosystems" (like Diesel, Tokio, etc.) that Rust seems to encourage the proliferation of. &gt; If extern crate goes away, it looks really weird that you are just "use"ing external crates but need mod foo; use foo::bar; to bring local files into scope. (...) This actually convinces me both `extern crate` and `mod` should stay, due to exactly the symmetry you have highlighted: extern crate foo; // elsewhere mod foo; and: mod foo; // elsewhere use foo;
I guess the problem is that you'll need to store the return value of `a()` somewhere to call foo() on it later, without actually mut-borrowing it. Right? Still looks to me like the compiler should make this work.
then someone is wrong, because it doesn't take unsafe code to write to the union fields on stable... did someone mess up the implementation?
&gt; The threaded model lets you more easily skim over discussions and see the important bits. The mail interface of irlo keeps the threading, which makes it for me a lot easier to read then the web interface.
File a bug report 
Mostly for discussion: There's a button in discourse called "Summarize this topic". It looks like it shows only 20% of the posts, probably selected by like count..
At the very least its a documentation bug
Good point :)
I don't think it could/would be the same iterator type for every `Term`, so I think it would have to be expressed as an associated type. If you iron out the kinks, please send a pull request ;)
As an end user who doesn't know much about filesystems, what could I do to test stratis? Also, can stratis mess up the underlying file system? If not I don't see any reason not to use it on xfs Edit: Yah apparently I can't read. For reference on the stratisd github: &gt; Stratis is currently in early stages of development and is a few months away from being ready for initial testing by users.
&gt; Threads pinned on the latest epoch are not impeding progress, just like in your method. I had indeed completely missed that. I thought that any thread pinned would preclude progress. I am afraid I do not have any clever idea with regard to a thread pinned on the previous/version. When a thread is not making progress while holding a lock, ... I suppose the best solution is for the user to take care about holding locks for as little time as possible; maybe a special debug version which would time how long a thread is pinned and abort when it's held for longer than a configurable value would be useful, to help developers identify which parts of their code is holding the GC back.
Hi there, this is my second day working with Rust and I'm having an issue with storing several pieces of data into a nice structure. I want to have some descriptive text map to an (x, y) coordinate. This is what I'm currently working with, but I've changed it several times. struct Tile { pos_y: i32, pos_x: i32, desc: String, } const beach: Tile = Tile { pos_y: 4, pos_x: 10, desc: String::from("Beach"), }; const jungle: Tile = Tile { pos_y: 5, pos_x: 10, desc: String::from("Jungle"), }; static all_tiles: [Tile; 2] = [beach, jungle]; pub fn get_desc(pos_y: i32, pos_x: i32) { // Print tile description given a (y, x) coordinate for i in 0..all_tiles.len() { if all_tiles[i].pos_y == pos_y &amp;&amp; all_tiles[i].pos_x == pos_x { println!("{}", all_tiles[i].desc); } } } But I'm sure this is horrible way of doing this, and the latest error it produces is pretty confusing. error[E0015]: calls in constants are limited to struct and enum constructors --&gt; src/tiles.rs:12:11 | 12 | desc: String::from("Beach"), | ^^^^^^^^^^^^^^^^^^^^^ | note: a limited form of compile-time function evaluation is available on a nightly compiler via `const fn` --&gt; src/tiles.rs:12:11 | 12 | desc: String::from("Beach"), | ^^^^^^^^^^^^^^^^^^^^^ I'm coming from a python background, and I would normally just use a dictionary for something like this: tiles = { (4, 10): "Beach", (5, 10): "Jungle" } def get_desc(x, y): return tiles[(x, y)] print(get_desc(4, 10)) I hope someone can help, and keep in mind that I might like to store more than just one piece of data to a coordinate. Something like... coordinate: (4, 10) ; description_A: "beachA" ; description_B: "beachB" ; status: 0 Maybe I should look into storing this data in a json file and reading from that? Thanks. 
It was meant to clarify how you couldn't just shift the order of evaluation around to satisfy lifetimes. Consider the `{x.pop(); &amp;mut x}` part as a completely opaque expression that mutably borrows x and does something to it. i.e. `fn foo&lt;'a, T&gt;(&amp;'a mut Vec&lt;T&gt;) -&gt; &amp;'a mut Vec&lt;T&gt;`. Using this, consider the validity of the following equivalents foo(x).push(x.len()) Vec::push(foo(&amp;mut x), len(&amp;x)) considering the order of evaluation, this should obviously not be valid. the `foo` call reserves a mutable borrow of x first and uses this mutable borrow to ostensibly modify x. Then, the `len` call attempts to make an immutable borrow of x. To satisfy the lifetimes, one could re-order the argument evaluation so the `len` call happens before `foo`, but this changes the semantics of the program. So as to detect this kind of situation, while still allowing valid situations, the new system would work as follows. In the time between creating and actually using a mutable borrow, it is still allowed to take immutable borrows of the value, as long as the borrows aren't in use anymore by the time the mutable borrow is actually used. This means that the `Vec::push(&amp;mut x, x.len())`case is valid as the `len` call happens before the mutable borrow is used for the push, while the `Vec::push(foo(&amp;mut x), x.len())` case is not valid as x has been modified by foo() and then reborrowed before the x.len() call. 
Simply put: An individual or organization has published a number of packages on NPM which "typosquat" widely used packages (such as "d3" spoofing "d3.js"). The packages provide the real functionality, but along the way they execute malicious actions, such as in the case reported uploading the environment variables to a remote server... which is concerning seeing as people have been taught to be their secret keys in environment variables to avoid committing them. This is a security issue that is potentially concerning for Cargo as well, so maybe some defensive measures (which?) should be implemented before that happens.
Well, extern crate and mod will always stay. They can't break the established syntax. The lack of a single point of truth on crates is still an issue, though, which is why these proposals exist. All you really want is a delineation between local uses and external uses so the dev knows where to look for whatever you are importing. I don't like the from use syntax personally, because module scopes translate cleanly into a filesystem hierarchy and having from use breaks the path behavior it provides. On the other hand, having to use self:: (or ::) to reference local uses is verbose. I actually like it more typing it out, since it maps very nicely to the model Unix uses - global names are restricted to whats in the $PATH, while trying to run something local to a folder requires an absolute path (./foo) since its not on the $PATH. In Rust, that would mean relative paths are obviously extern, since they come from the environment and not the local directory layout. The alternative would be something like use extern::textures::foo, or some other magic path name for external crates. Again, verbose. It is worth mentioning either is more ergonomic than extern crate and mod declarations now, though. And I'm actually liking that relative crates / absolute local mod use syntax. Edit: It also sounds nicer when you think about how crates are basically floating trees on the branch root of the crate name. They are still kind of really are absolute paths, but only absolute from the crate root. So when you use :: or self:: locally in a crate, you are doing the same kind of addressing you would in referencing an external crate, but you are doing it inside one (so you leave off the crate name). That is explicit, lets everyone use... use only, and sounds coherent. I thought at first I liked the original folder-mod proposal more, but I'm liking the OP the more I think about it as long as it goes with an explicit relative / absolute split in extern / local uses.
So ultimately, writing to a union is always "safe", since at worst it is a `mem::forget`. Of course, it's unsafe if you do it without updating other invariants, but that burden is on the unsafe code relying on those invariants. Given that the RFC says it is always unsafe, this is probably a bug. But we can also leave it this way and it will still be fine, even in the Drop case.
This is really cool! Could someone explain roughly what "2nd-rank types" means? (Also, this kinda makes me wish Rust had some kind of compile-time reflection to make `Term` unnecessary. Would also make `#[derive(Debug)]` unnecessary!)
~~It's also known as higher kinded types (for kinds 2 and up)~~. Actually it isn't, see below. The rest of this comment is about higher kinded types, not higher ranked ones :( Higher kinded types basically means referring, in an abstract/indirect way, to types that themselves have type parameters. It's an extension of "regular" generics where you refer to "regular" (rank 1) types with symbols like `T` in `Option&lt;T&gt;`. With rank 2 types, `Optio`n itself (without the parameter) could be a parameter of a higher kind generic function or struct. Besides Haskell, this concept can be found in Scala and C++ (as "template template parameters"), as well as other less mainstream languages. On your second note, Rust will never have opt-out reflection system because there is an unavoidable runtime overhead to it which runs against the Rust's philosophy of zero-cost abstractions.
&gt; Well, extern crate and mod will always stay. They can't break the established syntax. The current idea is for them to be deprecated, so they might disappear in a future epoch.
&gt; Perhaps you're thinking of thread-local cache: when you call free(ptr), then ptr is not deallocated immediatelly, but added to the current thread's cache. If you then call malloc with a similar size in bytes, that pointer might be reused from the cache. If the cache gets very large, then excess pointers actually get freed. More than just a thread local cache, which will just mean that the freeing thread gets to reuse them and not be particularly different wherever the pointer came from (false sharing aside). I *think* jemalloc will request thread-local large slabs from the OS to batch small allocations, and its ability to return them to the OS may be restricted if pointers end up on other threads. This is all just vague rememberings from a few years ago, so I could be wrong. &gt; Crossbeam's GC is fully multithreaded: any number of threads can be collecting garbage at the same time. I think it is in theory, but not in practice, in these sort of extremely oversubscribed cases; at least, that's the conclusion I draw if my understanding is true that you're meaning that GCs for different epochs can occur in parallel. The GCs will be for different epochs, which means that all threads need to update their epoch (or leave the critical section) between when the first GC starts and ends. This means that approximately there will need to be approximately num_threads time slices before the next GC can start, so that each thread can update to the latest epoch (assuming a significant number of them were descheduled in a critical section). If the time slices are run in parallel on all the cores, this should "only" take approximately num_threads/num_cores*average_time_slice time, but that can easily be on the order of (hundreds of!) milliseconds. This wouldn't be such a problem if threads could latch on to an existing GC to clear their own local garbage bag, because then they wouldn't be having to wait for all other threads to get some CPU time.
You should track that file with git, commit it, and then it's fine. (Don't forget to push the changes after publishing, too).
That doesn't mean you stop getting updates to the language, you just get stuck on the *current* syntax. And if you want extern crate and mod, then you can stay on that syntax. It would be really, really complicated to feature flag individual language features like keyword catch. Also, you probably? cannot (easily?) depreciate extern crate. You only stop using it with Cargo, but you can invoke Rustc outside Cargo and having the notion of external crates in alternative build systems is not only useful, but can easily be required.
&gt; Could someone explain roughly what "2nd-rank types" means? Did you see the Wikipedia link the first time the term was mentioned? https://en.wikipedia.org/wiki/Parametric_polymorphism#Higher-ranked_polymorphism Basically, rank-k is how many `forall`s nest in a type signature: rank-1: forall a. a -&gt; a rank-2: forall a. a -&gt; (forall b. b -&gt; b) -&gt; a // Note that the above _isn't_ the same as this rank-1 type: forall a, b. a -&gt; (b -&gt; b) -&gt; a "Higher ranked" is when k can be arbitrarily large. This is useful for example when you want to use a generic closure parameter with multiple different types within your function: fn rank1_doesnt_work&lt;F, T&gt;(f: F) where F: Fn(T) { // This doesn't work, T must be a number or a str, not both! f(1); f("str"); } // This would work if Rust had `for&lt;T&gt; fn(T)` fn rank2_would_work&lt;F&gt;(f: F) where F: for&lt;T&gt; Fn(T) { f(1); f("str"); } // This actually works today trait GenericF { fn call&lt;T&gt;(t: T); } fn works&lt;F: GenericF&gt;(f: F) { f.call(1); f.call("str"); }
I can assure you that the relevant people working on Rust have not only been aware of this situation generally (as this isn't some kind of new thing, just an instance of it actually happening), but also have been talking closely with npm about stuff.
&gt; as long as the borrows aren't in use anymore by the time the mutable borrow is actually used. But isn't the mutable borrow also not in use *after* foo has finished? It should be okay to call `x.len()` then.
Oh, I see! I wasn't familiar with the notation "2nd rank", but now I am! As for compile-time reflection: what run-time costs does that have? Wouldn't the costs be the same as for generic functions? I'm talking something like: fn&lt;T&gt; debug(t: T&amp;) { if fields!(t).empty() { print!("{}", t); } else { for (name, value) in fields!(t) { print!("{}:", name); debug(value); } } } Where `fields!` would return an iterator over (name, reference to member) pairs. Wouldn't this have the same cost as manually specializing `debug` for all types you'd pass to it?
Sure, but you might be unable to use a new feature until you get rid of those unless it's fine-grained. If the keywords `mod` and `extern` are going to be re-used you might even have to rework things even if it's fine-grained and you need that feature. So in essence they might go away at some point. As for deprecating `extern crate`, there's [an RFC](https://github.com/rust-lang/rfcs/pull/2088) being discussed about exactly that, and the linked module proposal has "Deprecate `extern crate`" as a bullet point.
&gt; It's also known as higher kinded types (for kinds 2 and up). I thought rank vs kind was two different axes. I'm woefully undereducated on the topic though.
&gt; I think jemalloc will request thread-local large slabs from the OS to batch small allocations Ah, right. Well, jemalloc doesn't have truly thread-local slabs. Slabs are shared among threads and require locking/atomic operations, but they do get assigned to threads in a way that minimizes slab sharing. &gt; I think it is in theory, but not in practice, in these sort of extremely oversubscribed cases; at least, that's the conclusion I draw if my understanding is true that you're meaning that GCs for different epochs can occur in parallel. You gave a great explanation as to why EBR needs `num_threads/num_cores*average_time_slice` time between calling `unlinked()` and `free()`. But that is simply the time garbage collection *lags behind* garbage production. In the previous comment you said: &gt; the GC thread needs to be doing as more work than all the other threads, to be able to keep up, which means garbage needs to be cleaned up O(num_threads) times faster than it is created This is what I disagree with. Garbage collection is not single threaded - it's just as fast as garbage production. In other words: GC and GP have equal throughput, it's just that GC lags behind GP. :) The more threads you have, the more it lags. On the other hand, if a thread collecting global garbage is required to hold the global mutex while doing so (that's how `conc` works, AFAICT), then garbage collection is effectively single-threaded. It's bottlenecked by the mutex. That said, things might be a bit more subtle in the implementation...
I think there is a slight misunderstanding. This PR is about the *Request For Comments*. That is, this PR presents the draft of what the final *design* will be. Once the design is settled, other PRs will *implement* it. If you wait until everything is implemented, you'll be waiting for months at least!
Nope, because `foo` borrows it's argument for the lifetime of its return value. As long as that return value is alive. In this case that return value was the same value, but the compiler can't figure that out from the function signature. It might have done something entirely else, stored the mutable borrow in the structure inside its return value etc. Now the aliasing guarantees require that no mutable borrow is alive when the immutable borrow is taken, and the inability to reason about what foo() did means this guarantee isn't possible to give.
Complete newb here I'm on Windows, and no matter what I try rustup fails with a http timeout error similiar to "Failed to connect to static.rust-lang.org port 443: Timed out". More annoyingly I've already installed the msi installer so I have the toolchain at this point, but I can't get rustup to notice that, or care. Do I even keep fighting with rustup since I've got the install anyway? How do I check that this won't cause me grief in the near future?
I'll show you a few solutions, because they're all good to know. First, a `const` isn't just something that doesn't change, it's something that is fixed at compile time. So if you want to call a function to create a `const` value, then you need to have a function that can be run at compile time, i.e. a `const fn`. Right now these are experimental, so you need nightly and a feature flag. You can instead use `&amp;'static str`s which is the type that string literals have: https://play.rust-lang.org/?gist=91ff32fec429016d550a0899df31e96c This works, but you're limited to strings that you know at compile time, no reading them from files or modifying them or whatnot. Another common solution to this problem is to use lazy_static, which automatically initializes the values the first time you use them: https://play.rust-lang.org/?gist=d3333d7962d16426f2a1c117675c647e Which is basically the same as if you had created the Tiles in main(). You could certainly use a dictionary for this, just like in python: https://play.rust-lang.org/?gist=22b60e0be011bbaa1b8e253f0613472b Note that if you want to use a custom struct as the key you need to `#[derive(Hash)]` on it.
&gt; since it can be implemented by libraries it was removed I'm not sure that's quite the right story. What happened is that someone discovered that the standard library's API was [actually fundamentally unsound](https://github.com/rust-lang/rust/issues/24292)! This was just a month or so before the 1.0 release, and I don't think anyone wanted to rush to standardize a new API, so it was removed instead of replaced. But it might come back at some point, since it seems like Crossbeam's approach has been pretty stable?
One tip I'll offer, and this applies to any language, is to think about what will break when that code eventually changes and then write tests for that. For example, if you've written a particularly complicated function and you realize that it'll cause problems if someone forgets to add 1 to some variable you've been very careful about, it'll be prudent to add a test that will fail if someone changes that in an incorrect way. The point of testing is that mistakes will be caught if someone makes a change to some code incorrectly, so try changing different parts of your function and make sure you tests catch what happens. 
Oh woops! You're right. All the stuff I typed in is valid when talking about higher _kinded_ types, but higher _rankedness_ is indeed different. My bad :(
Why am I not even surprised? I really feel I am spoiled by you guys ;)
Rustup is completely separate from the standalone installers, it won't use them. You may have a network problem, can you open https://static.rust-lang.org/ in a browser? If you're behind a proxy you'll need to specify that: https://github.com/rust-lang-nursery/rustup.rs#working-with-network-proxies. Otherwise it may be a bug in rustup, you could file a bug over there https://github.com/rust-lang-nursery/rustup.rs.
Did those talks result in any actions to be taken?
Great! So the first 80% of the work is done, meaning only the second 80% remains :)
Last I glanced at the RFC, it talks about the distinction of value lifetimes and reference lifetimes. For brevity, he then decides to refer to value lifetimes as scope and reference lifetimes as lifetimes. So non-lexical lifetimes is non-lexical reference lifetimes.
Would it be possible to deny network access from a build.rs script? Probably hard to enforce, right?
I can directly open the link, but didn't know that rustup doesn't use the windows internet options. Setting the proxy still fails with a timeout error (a different one), but if it doesn't matter I'll just move on.
Wait, who said that `x.len()` is guaranteed to happen *after* `x.pop()`? Why couldn't it be let a2 = x.len(); // +1 more than your example! let a1 = {x.pop(); &amp;mut x}; Vec::push(a1, a2) Now we could enforce that arguments run in a certain order, but think of the implication of that. Not only do you loose a lot of optimization opportunities, but it suddenly means that people have to be careful in what order they place their arguments. Basically it's a can of worms that makes a lot of things really hard, to make some somewhat hard things easier. We should assume that when I run `(f(), b(), c())` they are all calculated "simultaneously", if order changes the result we should error out and force people to choose an order, that's the whole idea of only allowing 1 `&amp;mut` at a time! TL;DR: your first example has two things happening in any order simultaneously, the second example explicit enforces an order.
It could still put malicious code into a `cargo:rustc-link-lib` output, to inject itself into your target binary. Plus that's only if we're talking about build-deps. Regular dependencies get linked into your target directly.
What are you doing about component libraries in terms of formats? This is generally the biggest stopper for new eCAD tools. I follow KiCAD and they have a good community library they maintain that includes components, footprints, and 3d shapes. Might be worth reusing those formats for your own tool.
If I might ask, what would a `GenericF` implementer look like?
It's on the Cargo subteam's agenda, and they'll be discussing it more, and from there possibly result in actions from there.
&lt;3
Probably using the iterators (in the case at hand `chunk()`-ing the slice and zipping might help the compiler figure out what you want) would lead to good performance, but takes a bit of time to figure out what's the best way to use them.
&gt; It may well be that each GC doesn't do enough work, but that seems like something crossbeam can push on, e.g. each collection only clears the local and the global garbage lists, meaning each thread needs to win the GC race itself to clear its backlog; maybe some sort of wait-free-inspired That's not true, but it took me 15 minutes to figure it out yesterday (I was curious how it works). If the thread „wins“ the race, as you call it, it collects its own local and the global garbage. If a thread does *not* win, it finds its local epoch is different one from the global one and also can collect the garbage: https://github.com/crossbeam-rs/crossbeam/blob/master/src/epoch/participant.rs#L70
&gt; If you have multiple threads contending over a single lock, your performance will drop massively simply because a thread holding the lock might get preempted. Just out of curiosity (given that it seems highly suboptimal for this kind of thing to happen): * Is this solvable in theory on the scheduler's side? That is, could a scheduler reasonably be implemented with some kind of policy like "if any threads are holding locks which other threads are waiting on, those threads will get scheduled before any other threads"? (Or maybe, a bit more sophisticated: the threads which are blocked waiting on other threads' locks still get scheduled "as normal" with the time-slices they would normally get, except those time slices get allocated to the threads they're waiting on instead, as their proxy?) * If it's implementable, would it have some kind of severe negative impact on some other fairness properties that would be desirable? I'm only superficially familiar with how schedulers work so I'm not sure what all of the constraints are. (The question applies to any kind of scheduler, whether in-kernel or in a language's runtime etc.)
You're looking at it backwards. There is no guaranteed-safe, reliable way to convert an OS path to UTF-8 on most systems, because POSIX paths can contain arbitrary strings of bytes and Windows paths can arbitrary sequences of 16-bit values. (In both cases, for legacy reasons. POSIX for 8-bit encodings like iso8859 and Windows because the "UTF-16" APIs were originally designed as UCS-2 APIs three years before before it was realized that Unicode needed to support more than 16 bits per code point.) The purpose of `OsStr`/`OsString` is to be capable of doing three things simultaneously: 1. Round-tripping any "opaque token" (eg. path) the OS APIs might return. 2. Making the `str`-&gt;`OsStr` and `String`-&gt;`OsString` conversions as cheap as possible for a given execution environment. 3. Not complicating the "just use UTF-8 everywhere" representation of `String`. (Hence using either `&amp;[u8]`/`Vec&lt;u8&gt;` or WTF-8 internally. It allows valid UTF-8 to be a subset of valid OsString content so going from internal to OsStr[ing] is a simple cast.)
What if my build script requires network though? Unfortunately, these issues are really hard to deal with. We could say 'minimum string distance between crate names' and that's likely the best solution, but it means if I take gcc someone else cant do acc or some such thing. Historically I think that's the approach websites have taken - google will buy 'gogle.com' to avoid the typosquatting.
See `GenericTransform` in the blog post, which is `for&lt;T&gt; FnMut(T) -&gt; T`. Here is the implementation for `Transformation`, which lifts a `FnMut(U) -&gt; U` into a `GenericTransform`: pub struct Transformation&lt;F, U&gt; where F: FnMut(U) -&gt; U, { f: F, } impl&lt;F, U&gt; GenericTransform for Transformation&lt;F, U&gt; where F: FnMut(U) -&gt; U, { fn transform&lt;T&gt;(&amp;mut self, t: T) -&gt; T { // Try to cast the T into a U. match Cast::&lt;U&gt;::cast(t) { // Call the transformation function and then cast // the resulting U back into a T. Ok(u) =&gt; match Cast::&lt;T&gt;::cast((self.f)(u)) { Ok(t) =&gt; t, Err(_) =&gt; unreachable!("If T=U, then U=T."), }, // Not a U, return unchanged. Err(t) =&gt; t, } } } In general, there isn't much you can do without some trait bounds on the `T` or something like `Cast`.
Yeah, rustup is convenient but not required especially if you're not running nightly. The API for getting the default proxy config from windows doesn't look too hard, I'll see about adding it to rustup.
Just wanted to say I love how quietly cynical your writing is. "One of our companies has had a morale problem lately, and we want to transform it into a new company where everyone is excited to come in every Monday through Friday morning. But we can’t really change the nature of the work, so we figure we can just give the whole company a 10% raise and call it close enough." "...if we wanted to make sure every employee in the company was a good culture fit, we might want to rename them all...". Small but cutting.
lol wrong rust bud
This is the wrong subreddit. Ask r/playrust
Sorry, I was not at my desk and the code example was out of memory... I am specifying the type parameter on the left hand side. And the type inferance problem only happened when i moved... I'll have to see when I get home.
You may want to look into an event loop library which supports channels. I would recommend [amy](https://github.com/andrewjstone/amy), but [mio](https://github.com/carllerche/mio-more) also supports them. Although polling with an event loop still has some delay, it should be reasonably high resolution; even busy waiting, there will always be some amount of delay(waiting for the internal mutex etc.) either way.
Thanks :) Was unsure if the "Juan Offus" &lt;--&gt; "one of us" thing would land or not ;)
This may be a hazard for people that want [reproducible builds](https://reproducible-builds.org/docs/volatile-inputs/). We perhaps should separate the "download phase" from the "compile phase" somehow, so that people can first download what they need, then build it. We could even have a `cargo download` command that downloads everything needed, even additional things you download on `build.rs` -- but just download, not build anything.
Of course! struct Inner { // Your data here } struct MyContainer { data: UnsafeCell&lt;Inner&gt;, } impl MyContainer { // Your implementation here // Take &amp;self even for mutable operations // Use self.data.get() to get pointer to data } // Tell the compiler that your type is thread safe: unsafe impl Sync for MyContainer {} // Tell the compiler it's safe to send it to other threads unsafe impl Send for MyContainer {}
You can create a container or VM and not give it access to the network.
&gt; Would it be ok if I returned an Arc&lt;MyContiner&gt; from MyContiner::new() is that was the suitable form for users to use ? I'd strongly recommend **against* this. Just return `MyContainer`, so the users can choose whether they want to put it behind `Arc` or do something else with it.
I'm not sure how it would impact reproducible builds. While the download / build split phases would solve one problem the overall issue is that a malicious attacker can execute arbitrary code on your system if you mistype a name. We could run everything in containers I guess? idk - what happens when they patch your binary to do the work for them? I feel like if you download malware and it has access to your code/ binary the game is over, and we should just attempt to solve the 'download malware' part as best as we can.
That would be amazing. Thank you for the responses. 
I [wrote a macro](https://github.com/mozilla/sccache/blob/7b658cf1a7b2d6f9c44658b730ce0d65c82a2f90/src/compiler/rust.rs#L490) for basically this exact thing--I had a bunch of `Option&lt;T&gt;` that I wanted to get the value out of, or return an error if they were `None`.
thanks - amy looks much more approachable for me. is busy waiting technically faster? do you have any idea what the scale of the difference is?
We just tagged and are about to release Stratis 0.1. There's still a long way to go before 1.0 (planned for mid/late next year), which is probably when I'd recommend end users start trying it.
[removed]
I've definitely noticed cases where rust should be optimizing out bounds checks but does not. I bet some of those performance come from bounds - like the copy example that comes first. Although I think due to side effects it can't do things like turn for i in 0..arr.len { arr_a[i] = arr_b[i]; } into: arr_a[..].copy_from_slice(arr_b[..]) since when the sizes are different the semantics are not the same. So you have to tell the compiler up front the sizes are the same with an assert. https://github.com/insanitybit/sqs-service-helper/blob/master/src/autoscaling.rs#L401 In my case it's a bit more complex - binary search always returns a value within the bounds of the array, and my indexes are mostly based on constant values. But the speed up moving to unchecked indexing was significant. I don't know if other compilers could really understand that this code can have its bounds checks optimized out, but *I* can understand it... so yay for unsafe. For your request of indicating to the compiler "hey, i promise these bounds are legit" you have two options. I've found that an assert statement early on will eliminate bounds checks later. Or, as I did in my code, just use unsafe.
We'd really appreciate to have this post in our official gtk-rs tutorials. Do you mind adding it there? :)
&gt; I actually think encouraging discussion on reddit will help fix this problem. I agree, but the opposite is happening. In this very thread /u/aturon said: &gt; As before please discuss in the internals thread, not here!
I'm surprised stuff like this hasn't happened more. Quite a few things in the `npm` community are installed with root access (e.g. CLI tools) because the default place for it to go is `/usr/local`. `cargo`, on the other hand, doesn't require root privileges, so there's at least *some* protection there, though this particular thing isn't prevented. Whenever you have arbitrary code running on your machine, especially code that can be updated anytime without a review, there's going to be a significant security risk.
I haven't done any precise benchmarking of amy, but from personal usage it appears to be fairly low latency. Assuming you're using linux, amy will use epoll + eventfd's under the hood (or kqueue for OSX/BSDs) to receive channel events which should be sufficient for most cases. While busy waiting would have the lowest latency, the fraction of time you save would probably be negligible especially given the reduction in CPU usage. That being said if low latency really does matter, your best bet is running some actual benchmarks.
&gt; What kind of performance penalty do you expect with a global mutex? First of all, it should rarely happen that they both try to lock at once. Secondly, there is no contention as it only does try_lock(), i.e. it aborts if another thread has a lock.
&gt; I don't think it could/would be the same iterator type for every `Term` Generate an enum and `impl Iterator` for it?
`Term` is implemented (inside `#[derive(Term)]`) for all types that any downstream crates want to use with `scrapmetal`: there is no finite number of cases to handle so an `enum` won't cut it.
&gt; Also, this kinda makes me wish Rust had some kind of compile-time reflection I was thinking about making a crate that contains traits and types describing Rust types with ability to derive appropriate traits. This should not be hard.
Yes, I know, that's why I'm saying we perhaps should be doing the opposite for such threads.
no problem, do you need me to change the formatting or anything?
Maybe do it by composing multiple enums. enum Either&lt;T, U&gt; { A(T), B(U), } impl&lt;I, T: Iterator&lt;Item=I&gt;, U: Iterator&lt;Item=I&gt;&gt; Iterator for Either&lt;T, U&gt; { Item = I; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { match *self { Either::A(ref mut a) =&gt; a.next(), Either::B(ref mut b) =&gt; b.next(), } } } Then for `struct MyStruct { a: A, b: B, ... z: Z }` generate: impl StructIterator for MyStruct { type Iter = Either&lt;A::Iter, Either&lt;B::Iter, Either&lt;... Z::Iter&gt;&gt;&gt;; fn struct_iter(&amp;mut self) -&gt; Self::Iter { // ... } }
&gt; for _ in 0..h { &gt; for x in 0..w { &gt; dst[didx + x] = src[sidx + x]; &gt; } &gt; sidx += sstride; &gt; didx += dstride; &gt; } &gt; [...] &gt; Conclusion: rustc is too stupid to recognize copies. Is it actually this simple? I think due to out-of-bound panics Rust cannot just optimize this into a copy. Adding an assert about the length of the arrays might fix this.
Tokio 0.2 is on the agenda for later this year: https://internals.rust-lang.org/t/announcing-the-impl-period-sep-18-dec-17/5676
Typos are just one attack vector, it's was issue on the OP but it's far from the worst thing a rogue package can do. Reproducibility can be affected if the download server goes down -- or if your `build.rs` doesn't check the integrity of the downloaded files. A separate download step would mitigate those issues. At the bare minimum, we should be able to inspect the whole input to the compilation process (which includes downloaded files), and vet crates based on that (alongside other things such as the author's reputation). Just *downloading* the malware isn't a problem if you want to review it. Security in the crates ecosystem depends mainly on the reputation of the crate authors and the responsiveness of the crates.io team to remove crates that distribute malware. But it's entirely *possible* that some random crate you depend on becomes compromised in a new minor release. Until the crates.io admins notice the issue, `cargo upgrade` will download malware. From then on, `cargo build` may run malware (`cargo run` will run more malware). For sufficiently underhanded code, this malware might be there for many years, spanning multiple crate versions, until it's found. (perhaps there should be a mechanism for Cargo to warn you when a crate version in your `Cargo.lock` is found to contain malware, even long after you downloaded it; I'm not sure there is)
Ah, ok I misunderstood what you were getting at. I thought you meant *instead* of having an associated type. This approach for iterating enum variants, and `Chain&lt;Once&lt;R&gt;&gt;` for tuples/structs should do the trick. Generating them in `derive(Term)` will be a little bit more involved than the code currently is, however. Are you itching to make a pull request? ;)
It's markdown so no, as is is perfect.
Exactly the type of information I was looking for - thank you!
Sounds like [frunk](https://github.com/lloydmeta/frunk) (check out the `Generic` and `LabeledGeneric` traits).
That doesn't do any processing in case of None/Error though, which is something /u/bluetech wanted. If you don't do any error-processing and just return them directly, yeah macros are trivial.
Mutexes are usually implemented as spinlocks that attempt to lock (by performing a CAS) several times, and finally give up by signaling to the scheduler that the current thread is blocked (`std::thread::yield_now()`). This way the scheduler is already aware of blocked threads and will try to schedule those that are not blocked. If the critical section is very short, then the cost of context switching will be more pronounced, and contention will slow the program a lot. That is because the scheduler can't keep pace with very frequent locking &amp; blocking. However, if the critical section is longer, then the scheduler can react reasonably quickly to blocked threads, and the slowdown will be less noticeable. That's all I know about schedulers. :) If you want to experiment and build some intuition for this stuff, you can play with [this code](https://play.rust-lang.org/?gist=802c0729cc7277623495d80835fb85b0&amp;version=stable) (make sure to use *Release* mode).
pr is submitted
Haha, I thought it was "one office". :)
`cargo vendor` is basically that. Doesn't do the build script stuff, it's up to you to write build scripts that can be told where to find stuff via env vars.
I think I remember also reading that working backwards from the end of the array was another way to get the optimizer to collapse away the checks.
Thanks for the link to a Rust quickcheck implementation -- I didn't know there was one.
Nice! The trouble is that if the build script downloads something, I need to replicate it elsewhere in order to vendor it, even if the build script can be told to not download when an env var is set. This risks having this external download code out of sync with what build.rs does. Having something like a download.rs could solve it -- or another standard way for downloading things on build time.
Any reason you can't just use mpmc queue like https://crates.io/crates/two-lock-queue ?
But didn't pepp_cz say that arguments *are* already evaluated from left to right???
This is from [PR 42083](https://github.com/rust-lang/rust/pull/42083). The [reference](https://doc.rust-lang.org/nightly/reference/items.html#unions) does document this, I'm a little surporised that even the [updated](https://github.com/rust-lang/rfcs/pull/1897) RFC doesn't.
Sorry, I still don't understand it :( Thanks for the explainations so far. &gt; In this case that return value was the same value The same value as what? &gt; but the compiler can't figure that out from the function signature. Why not? Isn't that just the "return type"? &gt; Now the aliasing guarantees require that no mutable borrow is alive when the immutable borrow is taken Which immutable borrow do you mean?
"your internet" TIL I own an "internet".
Thanks!
It's an interesting question. I don't think going backwards will help, because you could have overflowed (imagine `didx` and `sidx` are u8), which I think is defined as wrapping in release. I tried a bit to give hints to Rust to turn it in to a memcpy. Just establishing that the bounds hold didn't seem to work; the following is still a loop: pub fn copy1(dst: &amp;mut[usize], src: &amp;[usize], off: usize, bound: usize) { { let dst1 = &amp;dst[off..][..bound]; } { let src1 = &amp;src[off..][..bound]; } for x in 0 .. bound { dst[off + x] = src[off + x]; } } Changing `x` to go from `off` to `off + bound` didn't improve anything. But actually using the slices was fine; this ends up as a memcpy: pub fn copy2(dst: &amp;mut[usize], src: &amp;[usize], off: usize, bound: usize) { let dst1 = &amp;mut dst[off..][..bound]; let src1 = &amp;src[off..][..bound]; for x in 0 .. bound { dst1[x] = src1[x]; } } I just try and use slices everywhere, as it seems more readable to me, but it would be nice to understand this better to help out the folks who are used to the compiler being a bit more transparent.
Found another problem: the array row_sums_of_c was actually copied for every invocation of rescore.
## Quote of the Week: &gt; No quote was selected for QotW. -- u/StyMaar 
Good suggestion. I'm afraid that using KiCad as my native format could be limiting but I intend to be 100% compatible with both Eagle and KiCad eventually. I also want to deeply integrate with [SnapEDA](https://www.snapeda.com) since they're shaping up to be the world's biggest footprint library.
Thanks for the suggestion. I do have a follow up question. How would you handle a more general case where state being modified is any of the attributes of widget?
Well.. counted loops with indexing aren't considered idiomatic Rust. I know it still feels like we are all trying to find the best primitives for this kind of work together, and it's not finished yet. Yes, the Iterators are “weak” and don't cover everything (no efficient random access, for one). The transformation of the first nested loop is typical of what we can do: The innermost loop was promoted to a method (Or specific purpose iterator - I believe using `zip` with element iterators would have accomplished it as well.)
&gt; I think due to out-of-bound panics Rust cannot just optimize this into a copy The LLVM is *bad* at vectorization. [Here is a simple function](https://godbolt.org/g/5nq42C) I spent about 10minutes trying to make vectorize yesterday. I couldn't get a single permutation that would vectorize. To elid bounds checks you need to do if arr.len() == X { for i in 0..X { //work } } Simple `for i in 0..arr.len()` doesn't always work
Do you think it might be possible to add an opt-in to different behaviour with an `EagerDrop` trait, or similar?
Instead of using pointers with ptr.offset, try to use get_unchecked(_mut). Arithmetic is checked in debug builds only (but in some cases you have to use the wrapping helpers to have the correct semantics in debug builds too). #[inline(always)] is sometimes better replaced by just: #[inline]. The Rust compiler should not rely totally on the magic of LLVM optimizations when slice/array access is involved, and add optimizations, language features, and type system improvements to improve this important use case. Some budget of language features, language complexity, implementation and documentation effort should be spent on this. This is going to both improve the static safety of code (allowing a more intelligent compile-time knowledge of slice lengths and index intervals) and its run-time performance. The point is not to totally remove the need of unsafe slice access, but to reduce its need, and also allow the Rust programmer to be more aware of the tradeoffs (currently a Rust programmer can't even know where the compiler was unable to remove a bound test unless she takes a look at the assembly, this is quite silly).
Just because they are doesn't mean they should be defined to. So instead lets say that the question is: why would allowing this lead us down a dangerous path? Lets change the code again. let a1 = {x.pop(); &amp;mut x}; let a2 = x.len(); // We can't we still have x mutably borrowed! Vec::push(a1, a2); We could break the expression into pieces. But we can't guarantee this, we can't be sure if `a1` mutates `x` in a way that makes `x.len()` unsound. We can analyze the expression, realize that the mutation is valid, and then move things around to make it valid within the strict form. This is an analyzer that is just as complex (and with more unexpected effects of moving things around) as the non-lexical lifetimes.
That's pretty awesome! Glad to see some eCAD stuff coming to Rust. I follow KiCAD development and they've been working on cleaning up a massive legacy codebase and with it being C++ they've had major problems refactoring. Maybe they'll even be able to leverage some of the libraries you'll be developing!
Ah nice; that's along the lines of what I was thinking it could do... I just should've read the code more closely! Thank you.
&gt; Simple for i in 0..arr.len() doesn't always work Yes, there could be side effects preventing optimization. This is the correct thing to do by the compiler! Did you try `assert_eq!(arr.len(), X);`?
Of course. Remember, the internet is the blue "E" icon on your desktop.
I dislike when people discuss the internet/services in a way that implies they own it. The worst is when they say "my cloud," which, while there is a very small chance they really do have a server(s) running something that could be referred to as a "cloud," they almost certainly have no ownership over it.
Other posts on Rust and performance * [What makes Slog so Fast?](https://www.reddit.com/r/rust/comments/577qam/on_writing_fast_rust_code_what_makes_slog_fast/) * [Tricks and tools for writing fast code in rust?](https://www.reddit.com/r/rust/comments/3hvrv1/tricks_and_tools_for_writing_fast_code_in_rust/) * [Profiling Rust Applications on Linux](https://llogiq.github.io/2015/07/15/profiling.html) * [RipGrep](http://blog.burntsushi.net/ripgrep/) * [How High Performance Is Rust?](https://www.reddit.com/r/rust/comments/5queq5/how_high_performance_is_rust/) * [What is Happening With Rust Performance Lately?](https://www.reddit.com/r/rust/comments/5g5vfw/whats_happening_with_rust_performance_lately/) Sounds like we need a HowTo on writing numerical/codec code in Rust. Maybe /u/veedrac can chime in on the subject.
speaking of which, does anyone know how painful 0.2 is going to be for upgrades?
This is strictly tangential, but I don't think contemporary Haskellers would use SYB in this particular scenario, but rather **lenses** and other "optics" like traversals. To sketch it: * The type `Lens&lt;S, A&gt;` is the type of "lenses" that "focus" on **exactly one location** in object structures of type `S`, such that the location holds a value of type `A`. A `Lens&lt;S, A&gt;` provides operations to read exactly one `A` from any `S`, and to modify the `A` at the location denoted by the lens (where "modify" is understood in the pure functional sense—construct a new `S` that minimally differs from the original one by the value at that location). * So for the `Employee` type we'd have a `salary` lens of type `Lens&lt;Employee, Salary&gt;`. * The type `Traversal&lt;S, A&gt;` is similar, except that instead of focusing on *exactly one location*, a traversal focuses on **zero or more locations** of an object. (The number of locations can vary from one object to another). * So for the `Company` and `Department` types, we'd have a `Traversal&lt;Company, Department&gt;` and a `Traversal&lt;Department, Employee&gt;` respectively. * More generally, for any collection type you generally have a generic `Traversal` that traverses its elements. Or alternate elements of the collection, etc. * Lenses and traversals can be freely chained by **composition**: * The composition of two lenses is also a lens; * The composition of a traversal with another traversal *or a lens* is also a traversal. * So when you compose the three example optics I've stipulated here, you get a `Traversal&lt;Company, Employee&gt;`—an optic that denotes zero or more `Employee`-typed locations within a `Company`, and allows you to modify the `Employees`. In Haskell, it'd be something like this (pseudocode!): modify companySalaries (* 1.1) where companySalaries :: Simple Traversal Company Salary companySalaries = departments . traverse . employees . traverse . salary salary :: Simple Lens Employee Salary employees :: Simple Lens Department [Employee] departments :: Simple Lens Company [Department] ...where I've snuck in an extra finesse—list-valued properties like `employees` and `departments` are normally factored not into traversals, but rather into list-valued lenses, because you can generically turn any list-valued lens into a traversal of the lists' elements using `traverse :: Traversable t =&gt; Traversal (t a) (t b) a b`, but not vice-versa.
&gt; Of course, it's unsafe if you do it without updating other invariants, but that burden is on the safe code relying on those invariants. I think you meant that the burden is on the unsafe code relying on the invariants.
[removed]
You've made changes to the file. You can either discard the changes or commit them. After that you should be and to upload it
I think its about panic messages when there is an out of bounds error. Due to the way rust generates code, and the LLVM optimizer works, the optimizer has to keep the panic messages intact. This is one of the sadder parts actually.
And if it's generic over the element type T, the container should only be Sync and/or Send if T is Sync and/or Send, too.
&gt; Also it’s obvious how Rust makes the code that sacrifices checks for speed uglier (compare `a + b` and `a.wrapping_add(b)` or `arr[i]` and `*ptr.offset(i as isize)`). The latter will become `*ptr.add(i)` with [this RFC](https://github.com/rust-lang/rfcs/pull/1966) (in final comment period).
[removed]
Did you not try zipping two iterators together, and comparing `all()` [like this](https://godbolt.org/g/xAGzoq). Though, admittedly, *I* only tried it to see what the compiler spat out.
I played around with vectorization a bit (not to be difficult, just trying to learn what works and doesn't). Rust seemed fine at vectorizing iterators without breaking control flow (e.g. not `all` or `any`, which I think you wanted). I couldn't get it to vectorize anything with early returns or plain iteration, without copy/pasting Rust source. But, if you write your equality test using `sum`, which looks silly, it vectorizes on godbolt: vec1.iter() .zip(vec2.iter()) .map(|(x,y)| if *x == *y { 0 } else { 1 }) .sum::&lt;u32&gt;() I haven't had problems with `for i in 0..arr.len()` not working for eliding bounds checks; what was the problem you had?
Ok... but, how does this help me with getting the same instance of MyContainer shared between two threads without wrapping it ?
Ok, so, I've look over your solution however it does not solve my problem... Arc seems to have this idiot proofing that makes the type inside of it immutable with no option of changing that. Add this code inside your thread closure: //Generally bad if our vec type isn't thread safe //With int is ok since it happens atomically vec_ref[i] = 5; (I can't save an edited version of the playground it seems :/) And it will fail to compile. Assuming I want this to not be the default behavior with my type what do I do ?
Yeah, I did, sorry, fixed.
[removed]
What I was referring to is the fact that the above commenter seems to not have necessarily understood why a mutex is (or is not) needed in certain cases. They rather assume every variable shared between threads that can write to it must always have a mutex guarding access. Thought judging by your comment I am unsure you do, though I will give you the benefit of the doubt and assume you haven't read my post.
I love these posts... This is so much more constructive / more informed than the usual rants we get here. The author put some serious sweat in learning Rust. Sometimes the solution to his problem exists but is non-trivial, some people put it in the comment and everybody gets smarter. Sometimes no rusty solution exist and it is also great to have a mental list of such points.
[removed]
[removed]
To answer a couple of points: &gt; maybe there is/there should be a way to tell compiler “hey, this slice is guaranteed to be this size, drop the unneeded checks”; You can, with an `assert` statement. &gt; non-checking arithmetic is a bit too inconvenient to write (by design, I suppose) but it may help to squeeze some performance; Rust's arithmetic *is* non-checking (twos-complement wrapping) in release mode. This is why you see such small improvements by making it explicit--it's likely noise. You likely didn't have to sacrifice as much in ergonomics as you thought. However, Rust's compiler does still have many optimizations it has not taken advantage of, and some of the simple tricks you can use to coerce optimizations are not necessarily easy to discover.
"your Internet" means you're an owner of the Internet but it doesn't mean you are the only owner or that we each own a distinct Internet. It means that we collectively own it.
"your internet" is a very common phrasing in mozilla-speak, probably because Mozilla wishes to frame the internet as a resource which _should_ give the user control (no DRM, net neutrality, browser freedom, etc).
Gotcha, that makes a lot more sense.
&gt; If you wait until everything is implemented, you'll be waiting for months at least! Only months? That's not too bad :) I've been using Rust only a little bit but ran into a few issues with LL that NLL would have been nice to have. I think a common one was with structs and methods.
Personally, I'd like to see eager drops for all types, but an opt in would be necessary to avoid breakage. Perhaps, it would be a flag to the compiler, file, of crate.
It would be really cool if there was an annotated output of the input source along with decisions the compiler made and why. Something like the nice error text but for optimizations that did or did not fire.
It always freaks me out when screenshots or example outputs use my username. I'm sure (and glad) it's not, but it would be cool if websites could read your username from your system and put them in the examples. Anyways, this looks super cool, and it looks like I'm going to have a new alias in my zshrc!
I think everybody got it except for some Juan Kerr who never does.
1. Will Stratis not have the issues BTRFS does with Databases and VM images?(have to explicitly disable CoW I think, which iirc meant you missed out on some of the nice features BTRFS offered in the first place?) I think ZFS doesn't share these problems, but I've not looked into that well enough as it seemed more complex to grok/manage. 2. Why a new FS with Stratis and not extending XFS? I think they've been focused on adding features that FS like BTRFS has(CoW, snapshots, dedupe, etc). I might be a tad confused as it seems XFS is playing a part in Stratis development?: &gt; Specifically, Stratis initially plans to use device-mapper and the XFS filesystem. But for some reason, the features are separate from XFS instead of becoming a part of XFS? What will happen when XFS has similar features that they have planned to introduce in the future? 3. Will Stratis be a good fit for NAS like ZFS and BTRFS are used today? Both of which also unlike EXT4 or XFS [seem to need more care when used with a hypervisor](http://www.freenas.org/blog/yes-you-can-virtualize-freenas/), any idea if Stratis will also have similar risks to be aware of when not running bare-metal? 4. How well will Stratis work with Docker? Will Stratis need a Docker storage driver like BTRFS, or will overlay2 work fine?(I think BTRFS required it's own due to things like CoW, though I'm not that knowledgeable on filesystem specifics). 5. Is the filesystem more friendly like EXT4 and XFS to use/setup while offering the more advanced features seen in BTRFS/ZFS? Both of which for me personally have gotcha's to be aware of as described above, and a fair amount of reading/understanding upfront for setup to have a good experience avoiding issues and having good performance. openSUSE has a rather detailed BTRFS setup via it's default installer, how will Stratis compare? 6. Will Stratis have similar snapshot utility like openSUSEs Snapper? It integrates with package managers via hooks to do pre and post snapshots and manages history / housekeeping nicely.
How much general interest in Rust is there in Red Hat?
Plenty of posts about Go vs Rust, I don't have any links on my atm but from my research about a year ago into the two there were plenty of good points for favouring Rust or reasons to avoid Go. Rust still has a bit to go before I can say my other dev friends would consider it, but it's been improving a tonne since then, I think by 2018 I can more confidently suggest it. Not really relevant to you I guess, but Rust can do dev on micro-controllers which is a plus for me where far as I know Go is not able to participate.
LLVM doesn't know that `old` is as long as its `len`, so it can't actually use it to justify optimizations where there is early-out. Generally you need to do as /u/frankmcsherry did and make a non-branching version, and if you want early-out you just have to chunk the loop manually at appropriate boundaries. Such is life.
Looks very cool! Installed it and alias'd in my fish shell.
[removed]
[removed]
Been using this since before Rust 1.0 ([proof](https://github.com/ogham/exa/pull/48)). AMA
Can/has this been integrated into https://github.com/uutils/coreutils? The color scheme looks very similar to `ls --color=auto` (probably by design :) )
then you would need to borrow the result of `a()` during the whole time of `b()`
It can be run on real hardware, but your mileage may vary. There is not a functional USB driver; you need a ps2 mouse. The touchpad in one laptop I have worked (using the ps2 driver) another one didn't work because it uses an I2C based protocol, so there is not a driver for it (yet). Networking is only possible through ethernet (not wifi), and only with the right supported chipset; it may work for you. You might as well try the iso on a computer you have, and see if it works.
I had to install libhttp-parser-dev to get the Linux binary to work on my Xubuntu 17.04 box. $ ldd exa-linux-x86_64 linux-vdso.so.1 =&gt; (0x00007ffee1b0c000) libhttp_parser.so.2.1 =&gt; not found ... $ sudo apt install libhttp-parser-dev ... $ ldd exa-linux-x86_64 linux-vdso.so.1 =&gt; (0x00007ffdd1f3b000) libhttp_parser.so.2.1 =&gt; /usr/lib/x86_64-linux-gnu/libhttp_parser.so.2.1 (0x00007fc116708000) ... 
The git support seems like a mis feature. It's not very modular for your file viewer to randomly have support for one particular VCS. Might seem cool now but in a decade there'll be some other new hotness.
As someone who has written a [decoder of his own](https://github.com/RustAudio/lewton), I can confirm that the bounds checks that Rust is doing are some of the major sources of issues with performance I ran into. It would be really good to get better ways to get rid of them in safe code, and to give coders a good way to know which bounds checks were eliminated and which ones the compiler couldn't eliminate. Optimally you could do `#![deny(bounds_check)]` and ensure there is a compile error if a bounds check that previously could be eliminated now reappeared due to a change. With the deny in place, you'll have to place `#[allow(bounds_check)]` to places where the optimizer missed optimizing bounds checks. Iterators are nice, but they only work up to a certain level of complexity of access patterns, and codecs very often have very complicated access patterns. E.g. take implementing huffman codes. Basically what you have is a totally unbalanced (thats its point) binary tree, and when decoding a word, you need to traverse the tree bit by bit and maybe stop somewhere. So generally, a good way of doing this performant is to use tables where you keep 256 entries around, each of them corresponding to a different entry byte, with the entry containing the decoded word and the number of bits the word is long. However, sometimes you have huffman trees with more than 8 bit words. I've tried to use a tree of 256-entry-blocks but this turned out to be not performant, probably due to cache locality. Instead I'm doing the following: the first 256-bytes-table contains either the value, or a pointer to a continuation of the tree. For the pointer I don't want to use a reference to not blow up cache locality, instead I'm using u32 numbers that then can be used as indices to an array. When creating these numbers, I know already that they are indices, but I can't encode it in the type system so what ends up happening is that Rust (probably) still does bounds checks when I'm looking up in the array, even though there is no point to do so. Edit: also I want to point out that decoders are some of the areas where safe and fast systems programming languages could really shine in the future, because decoders often have to parse untrusted stuff, and due to their complexity they also pose an attack surface. Of course, there is only a handful of actually mature decoder projects (ffmpeg, libav, libvlc, &amp; the infamous stagefright), and you can't make that much money from implementing decoders, so there will be certainly less developers and this means its not as big of a market for a language than say web service development, but virtually everyone is using decoders, either through their browsers or through apps on their mobile devices. The large scale usage of these decoders is part of the reason why there is such a strong demand to get them secured.
That's technically true. People own their own LANs, Hosts, Autonomous Systems, etc. The Internet isn't just the routing backbone and service lines. It's as much the edge and endpoints.
If exa is still around when that times comes then it can always be forked or updated.
&gt; From what I gather the proposed 'temp or shortest-idea is the same as saying for&lt;'a&gt; fn foo( &amp;'a ...) ; &gt; 'temp would mean 'the shortest possible lifetime' - when received as a parameter, it may not escape. &gt; What if we could reduce the need to named lifetimes to times when a specific named lifetime can escape the function body (return values or when there's anything mutable). You are literally describing what Rust does.
&gt; Garbage collection is not single threaded - it's just as fast as garbage production. In other words: GC and GP have equal throughput, it's just that GC lags behind GP. :) The more threads you have, the more it lags. As /u/Michal_Vaner helpfully pointed out, I'd missed/not understood a specific line of crossbeam, which means I was incorrect and agree with you!
That graph says 100k packages instead of 10k
In looking at trying to compile this in Windows, I see some unix specific packages. I'm just learning Rust, so I'm curious. Is there a methodology for using libraries based on system capabilities. Posix/Win/etc. ? Is there some place I can read about this?
There are small pockets of interest that are growing. Aside from Stratis, there is also Rust-related activity by the GNOME developers, as well as an active Fedora Rust SIG, working on packaging the latest stable compiler releases, as well as guidelines and tools for packaging independent written-in-Rust things e.g. ripgrep, and more to be sure over time. The fact Firefox is now partially in Rust also undeniably was a big part of getting Rust's toe in the door.
Yes, there is such a mechanism integrated into Cargo: https://github.com/rust-lang/cargo/pull/2328
I aliased `exa -l` to `x` so as not to type more characters and I'm loving it so far!
Isn't this a bit overhyped for a small piece of code? I mean what's next, an own website and logo for a "modern replacement" of cat? Also, the debian bashrc ships with an alias for ls by default to turn on color info. Maybe useful for mac OS with its outdated BSD tools, but not useful for any sane GNU setup.
Why didn't you tell me about this sooner?!
This seems like a great addition to the standard library's Command type. Sort of akin to shlex in Python. Nicely done!
(author of `elastic`) Thanks for the write-up! Both Rust clients for Elasticsearch are steadily maturing, in fundamentally different directions. I look forward to seeing where we all end up in 12 months :)
Perhaps I'm missing something obvious, but I'm not sure how that would solve my problem. If I converted numerous channels into one queue, I would need to consolidate various types and code bases into a single type to put in the queue, right? That's what I'm trying to avoid, while finding some way to efficiently stop my furiously spinning cpu cores. 
As an author of Tokio, that is news to me :) In my opinion, unless there is an obvious need to make breaking changes (and, as far as I am aware, there currently is not), there won't be an 0.2 release. So, I guess it will be exciting to discover what the "major revamp" of Tokio is going to be!
"Small code" can still be useful. Also I don't think this is that small, and even if it is, isn't that a good thing?
To answer your question, the Tokio project is designed to be very modular. Lots of little components that work well on their own such that you can mix &amp; match. Futures, tokio-core, and tokio-io are quite stable already. There aren't really any high priority changes that I am aware of. There is a lot of activity on new repos (that will be available soon hopefully) that add additional functionality. Aka, if you build on futures, tokio-core, or tokio-io, rest assured that there will not be any significant breaking changes in the near future.
How's your week going?
cat doesn't really have optional features, nor does it make sense to give it any. `ls` is already a fairly expressive and powerful tool, but it's constrained by a lot of history (such as its non-human-readable-by-default sizes) and isn't really appropriate for adding things like Git integration.
There is currently no immediate plan for any breaking changes (or an actual 0.2 release). Everything that aturon mentioned can be done in 0.1 w/o breaking backwards compat (as far as I know).
Can colours be reconfigured?
One place that pulled this off really well was [keybase.io](https://keybase.io/docs/kbfs). If you're not logged in the examples say `/keybase/public/yourname`, but when you're actualy logged in it will say `/keybase/public/jerknextdoor`. It was one of the first places I saw this, but now I want it everywhere so I can just copy and paste straight from the docs.
Can you also post something like this for win-api?
What's your favorite kind of goldfish cracker?
That second example beautifully illustrates why we desperately need PowerShell as default in Linux. Parsing that is gonna be a bitch. I personally can't wait for the first distro to ditch bash 😀 
This is really nice. One note: `--tree` option seems to hang quite a while before starting, which makes me thinking it's doing a complete traversal before listing. Compare to `tree` which does a depth-first search _as_ its printing so you can start paging through it immediately. Might be something to think about improving.
So does this work in the linux subsystem on windows? Already switched to ripgrep there. Also I'd love to see some performance and breakdown comparisons to ls like the ripgrep author put out.
I have an incomplete of and experimental implementation of something like that: https://github.com/skade/attr (most combinators don't currently work) It's a special fun, as lifetimes get interesting.
1. We'll have to see. I have some ideas. 2. Turning XFS into a ZFS-alike by adding volume management capabilities and the things you mention seemed like a lot of work, a lot more than reusing device-mapper for some things and just letting XFS be XFS. That said, if XFS learns new tricks, then Stratis, with an opaque approach to pool management, could potentially shift to use less DM and more XFS under the covers. 3. Haven't thought much about this yet. I think multiple CoW layers are probably a bad idea, yeah. 4. I would guess it will need a driver. Hopefully having an API will let this driver be pretty minimal. 5. The current plan is to de-emphasize performance in the data tier in favor of flexibility. For perf, add an SSD cache tier, or use SSDs *for* the data tier, they're so much faster. Emphasizing flexibility means eliminating the setup-time gotchas. ZFS etc still have limitations about how disks need to be added, can't be removed, and so on, that I think are very limiting and that Stratis can potentially avoid. Before Stratis I worked on a proof-of-concept called Froyo, which attempted to do what a Drobo storage appliance does. That's a level of flexibility that I think we can shoot for with Stratis, and that flexibility also results in a more pleasant experience for the user, both at setup, and over the life of the pool. 6. I would hope that Stratis can plug into existing tools like Snapper, or Fedora's DNF, or whatever, in a clean way via its API, to do pre/post update snapshots.
Ripgrep has built-in Git support too. I think that *right now* it's a good feature to have. In 10 years those software will either be abandoned (unlikely) or have newer versions. Anyway, I think Git will still be dominant in one or two decades.
Good Job!!!!! 
Did you do `alias ls=exa`?
Unfortunately, I have some things to do that are more important to me now. I was just suggesting possible solution.
It's apparently not installable with `cargo install`, contrasting with useful things like ripgrep and xsv. Publish a crate, you.
Here are the numbers I have from the last several months. The only thing I can think is something went SEVERELY wrong with their algorithm. year | month | place | perc | Notes --------------------------------- 2017 Autust 94 ~~~~~ WHAT THE FLYING $#@! 2017 July 38 0.458 went down a bit :( 2017 June 37 0.479 mention as moving up! 2017 May 40 0.412 up rank and perc! 2017 April 41 0.375 % down but rank up? 2017 March 43 0.382 % up but rank down? 2017 Feb 40 0.358 2017 Jan 41 0.310 More popular that Bash! 2016 Dec 43 0.316 2016 Nov 43 0.294 2016 Oct 42 0.296 2016 Sept 45 0.258 2016 Aug 42 0.26 2016 July 44 0.25 2016 June 46 0.26 2016 May 47 0.23 2016 April ?? ??? 2016 Feb 49 0.20 2016 Jan 49 0.19 2015 Dec 46 0.22 2015 Nov 52 0.19 2015 Oct 51 0.195 
 let shared = Arc::new(MyContainer::new()); let container = shared.clone(); thread::spawn(move || { // Do something with container here }); // previous container was moved out let container = shared.clone(); thread::spawn(move || { // Do something with container here }); Now you have two threads sharing a container. The type signature is: Arc&lt;MyContainer&gt; If you use scoped threads, you can get rid of Arc.
Of course, this is important thing.
I guess this isn't the same, but it reminds me of [transducers](https://github.com/ruuda/transducers)(Rust crate, links to Clojure talk on Transducers that while long is pretty good): &gt; [Transducers](https://www.youtube.com/watch?v=6mTbuzafcII) are a way to decouple tranformation and reduction operations from the procedure in which the data is provided. They allow the implementation of common functions like map and filter to be reused for any type that represents a succession of data, and they allow your reduction functions to be decoupled from the way in which the data is provided, whether that is a collection, an iterator, a channel, or an observable. And from [this discussion](https://news.ycombinator.com/item?id=10741121): &gt; Rust iterator adapters are closer to the previous Clojure reducers namespace and the Java 8 streams API. All three take a "collection" and return a new "collection" which includes additional behavior/transformations when ultimately iterated over. Transducers separate out the transformation processes into free-standing composable functions. This makes the transformations first-class values, and makes it possible to apply such transformations to less collection-like entities such as async channels. [Another Rust take on transducers](https://github.com/benashford/rs-transducers) describes them as: &gt; Essentially a transducer separates the application of functions on data from the structure of the data. For example the higher-order functions like `map` can be expressed in such a way that could be applied to a vector, but also an iterator, but also a channel containing data passed between threads I think Scrapmetal is similar, but perhaps more useful from what I got going over the blog post. Especially using Everywhere/Term to go through a composited data structure and apply the transformation to only values of the matching type.
Why not abbr? 
That is not exactly what I had in mind. I meant something to allow one to traverse data structures directly in code. Something like this: match MyType::get_type() { Type::Struct(s) =&gt; for f in s.fields { println!("{}", f.name); } }, Type::Enum(e) =&gt; for v in e.variants { println!("{}", v.name); }, } But maybe my idea wouldn't help in this case.
I do.
&gt; but you do that by proving you don't need them as in the functional tradition While I'm happy that some functional programmers are adopting a disciplined -- perhaps even formal -- analysis of code, it is a misleading overstatement to say that it's a "tradition" -- let alone *the* functional tradition -- especially as the use of formal analysis of programs is not only independent of a programming style, but also originated in imperative programming, and is still more prevalent in imperative languages (if only because they are more widespread and have more mature formal tools). But at least Rust has higher-order functions as in the OOP tradition.
~~Probably because abbreviations aren't expanded until you hit space, so `ls&lt;return&gt;` wouldn't trigger it.~~
They expand just fine on enter for me.
Ahh you're right. I wasn't paying close-enough attention and I thought `ls&lt;return&gt;` gave me `ls` output, but it did in fact expand.
&gt; Scene opens with Pascal walking frantically around a restaurant in Kyiv. He stops once he sees some dude sitting in the corner, facing the other way. He walks over there. &gt; &gt; Pascal: Hey Mike, have I told you about this great `ls` replacement I can't stop thinking about since I've installed it years ago? &gt; &gt; Mike, turning around with headphones on and half a slice of bread in his hand while chewing the other half: Wha? &gt; &gt; Pascal: Ah, never mind. 
I really like the ones with sesame on them
What do you imagine a 1.0 version of the futures/tokio stack to be?
Great, thanks for asking!
No, that's boring. I have this in my fish conf instead: alias l 'exa --all --long --modified --group --header --color-scale'
You don't have to have just one queue. With multiple `mpmc` queues, you can build any communication architecture between many threads. You can send `Sender`s and `Receivers` throu the channels too, to create callback channels etc. You can have multiple worker pools, brokers, broadcasters, pubsub, anything... And don't be afraid of spawning many threads. It is very efficient (well, at least on modern Linux). You might be interested in reading how I organized data stream handling in `rdedup`: https://dpc.pw/blog/2017/04/rusts-fearless-concurrency-in-rdedup/ . It is very efficient, and so far beats any other deduplication engine I've seen performance-wise (though some do have better deduplication strategies due to different design, etc. - just to be clear).
&gt; Why would I want Git in my file listing anyway? &gt; &gt; Because you get to see the Git information alongside everything else. Uh huh. And if I don't use git? Are there plans to incorporate every VCS into exa?
Please note that TIOBE does not publish the exact rank for languages at 51st--100th places. It may well be 51st (not hardly imaginable).
This sounds like the fn -&gt; decorator fn pattern from Python. Or some sort of Yo Dawg, I gave you an iterator that returns an iterator so you can iterate while you are iterating? Rust needs delimited continuations!
Thanks for all those answers :) Looking forward to giving Stratis a go in 2018 hopefully. &gt; I think multiple CoW layers are probably a bad idea, yeah. Are you referring to CoW disk image format like `qcow`? This would be avoided with raw image file(assuming CoW FS isn't used by the guest OS) wouldn't it? With providing the VM direct access to a physical disk or partition, no image file is needed, thus there is not an additional FS, the guest OS FS writes straight to physical media avoiding the additional host FS. I think this still needs some care when using a hypervisor(I've not done it myself yet) for BTRFS and ZFS. Perhaps that's out of your scope, but I imagine RedHat has customers whom have VMs setup like that, so maybe someone else would be able to answer that if you're not sure. &gt; I would guess it will need a driver. Hopefully having an API will let this driver be pretty minimal. Will RedHat be contributing a driver or will that be left up to the community to implement? I'd also assume RedHat has customers that use Docker, so if there was enough demand from customers for the support with Stratis perhaps affects the answer? &gt; ZFS etc still have limitations about how disks need to be added, can't be removed, and so on, that I think are very limiting and that Stratis can potentially avoid. Less so with BTRFS I think, as that seems to offer the flexibility of varied drive sizes for a pool as well as software RAID modes it provides. IIRC BTRFS supports hotplugging for drives which is great for adding storage, the process with ZFS from what I've read is more restrictive and extra work before you can utilize the expanded storage. BTRFS flexibility also seems to affect it's performance, yet still has it's setup gotchas for concerns I've raised here, I'm looking forward to seeing Stratis avoid that hassle. &gt; which attempted to do what a Drobo storage appliance does. So in regards to 3, which besides hypervisor mention, inquired about NAS. Stratis could also be a good fit here with similar benefits that BTRFS and ZFS offer over todays EXT4 and XFS? &gt; 1. We'll have to see. I have some ideas. ZFS seems to avoid this issue, I can't recall the specifics, but somehow the way BTRFS managed data differently caused fragmentation for the random I/O for those usecases iirc which it's known to bad for with large files, and ZFS according to their community does not share that issue. That'd be one of my main painpoints with BTRFS for dev machines, while openSUSE provides a rather good default setup to try address common locations, if the system uses a different location or a software that didn't have a location configured to avoid it you needed to be aware of the fact else suffer the consequences. 
``` cargo install exa ``` Please? :)
Really depends on the problem domain I would say. Currently I mainly work in optimization systems, and and for me using a debugger is absolutely essential for understanding what happens in the complex heuristic algorithms we have, and to understand the interaction between heuristics that depend on each other. in addition, we work with geometry, and the ability to get (interactive) plots of the current state that one is interested in is invaluable. Given that I've learned to use a debugger well nowadays, it is a nice tool to have in other cases also. For example, if I'm doing some development in a Django app, I typically fire up the debugger just to investigate the actual types of the values and what can be done with them, as a way to quickly understand the code.
It's actually easier, I just tried with an example. You only need to do the following steps: rustup target add x86_64-pc-windows-gnu ~/.cargo/config [target.x86_64-pc-windows-gnu] linker = "x86_64-w64-mingw32-gcc" ar = "x86_64-w64-mingw32-gcc-ar" then compile export PKG_CONFIG_ALLOW_CROSS=1 export PKG_CONFIG_PATH=/usr/i686-w64-mingw32/lib/pkgconfig cargo build --target=x86_64-pc-windows-gnu --release I was able to run the exe that made without copying over any libraries. It did have a console popup though, I didn't try if the setting windows_subsytem = windows makes it go away. edit: you can test in wine too, it worked there and in a VM fine
there's already a bug open for it, has to do with the way they are formatting the output.
Thank you for sharing!
Is it possible that there is a short delay between first creating a new repository and crates.io actually finding it? as this would explain my problem. 
The probably best way, as /u/meekstadt points out, is to use `&amp;'static str` instead of `String` (you need the `'static` lifetime in the field definition only). If however you want to mix this with dynamic values, this will no longer work. In this case `std::borrow::Cow&lt;'static, str&gt;` offers an easy solution, letting you store both static `&amp;str`s as well as owned `String`s. Otherwise you could introduce some sort of `String` container (e.g. a `Vec`) and bound your lifetime on that of the container, but this approach can get messy fast.
Typo: Autust &gt; The only thing I can think is something went SEVERELY wrong with their algorithm. Is their algorithm open source or secret sauce? 
Pretzel dipped in mustard.
Seriously. Unix is the worst and the best. Programs should be communicating in machine readable structures, not parsing weird ass text! The shell and `ls` should be linked at the hip, at least in how they communicate results.
btw, I found a slight error in the CSE, here is the corrected version: #[inline(always)] pub fn log_likelihood_ratio(k11: u64, k12: u64, k21: u64, k22: u64) -&gt; f64 { let xlx_all = x_log_x(k11 + k12 + k21 + k22); let xlx_row = xlx_all - x_log_x(k11 + k12) - x_log_x(k21 + k22); let xlx_col = xlx_all - x_log_x(k11 + k21) - x_log_x(k12 + k22); let xlx_mat = xlx_all - x_log_x(k11) - x_log_x(k12) - x_log_x(k21) - x_log_x(k22); if xlx_row + xlx_col &lt; xlx_mat { // round off error 0.0 } else { 2.0 * (xlx_row + xlx_col - xlx_mat) } }
Signals are a big 100% unsafe hole in fearless concurrency.
Some interesting points: * Rust reminds me of everything I liked about Perl * Iterating over one field of a struct while modifying another field of a struct, which comes up a lot * Rust is available as Debian packages, so you don't have to do the horrifying curl | bash nonsense
Their [scoring definition](https://www.tiobe.com/tiobe-index/programming-languages-definition/) is described here.
It's good to have JSON as an optional machine readable format. Have a look at the Elvish shell - very cute, genuinely new ideas. As for PowerShell, meh.
How about using namespace for crates ? Something like `/jacobkiesel/nitro` in this case. It would then be possible to have a new crate with the same name, but in a different namespace. Is that even a good/feasible idea ? ¯\\_(ツ)_/¯
What are data races? Never happened to me ;) /s
Welp, I feel soooo threatened by islamo-black-disabled-trans-fascist-women when I write code -_- What is wrong with people disapproving of what is basically “please behave politely”?
I'm not really seeing the benefits of linking this here, especially given there's absolutely no indication that it's a link to KotakuInAction. What conversation did you want to start?
I don't know what was discussed, but one idea I have is sending an email message to the owners of a crate whenever: * A new version is uploaded (to detect a rogue upload by a stolen account of another owner) * New owner is added (again, to detect rogue accounts) * A crate with a very similar name is uploaded. This doesn't prevent it from happening, but might help detecting the problem sooner.
Why do you care about `ls` performance?
Ok so: a) Thank you, this is the only answer in this whole thread that resulted in me being able to share a container mutably with my threads... so at least I have a starting point b) Sadly enough there seem to be two problems with it: 1-&gt; rustc complain about me dereferencing the pointer inside the methods in the MyContainer impl and I had to mark them as unsafe... this is ok for testing but not ok for shipping a library. Is there a way around that ? 2-&gt; This adds a horrible layer of abstraction over the problem just to trick the compiler :/ 
Bought it, looking forward to see the upcoming chapters! 
This is related to zero-copy parsing: I'm getting owned values from a library in a loop and save references to them in a data structure – but I have a lifetime problem: where to store the owned values so that they would live long enough for the references to be valid. Ideally, I'd like to have an append-only store, that I could insert the values into, and then get references to them. A vector doesn't qualify for this: it's not safe to mutate (append stuff) and alias (have references to the contents) it concurrently, because it might reallocate. Does this kind of a data structure exist? I think that it could provide a safe API, provided it was indeed append-only – it could store the data as a linked list of arrays, which wouldn't move in the memory.
Maybe I'm wrong, but isn't wxWidgets cross platform and native? The problem is that, like Qt, it's C++ and so the Rust FFI is non trivial.
[I’m gonna, I’m gonna](https://github.com/ogham/exa/issues/132)
Please don't use tiobe. It's of questionable general value as an indicator, it's surprisingly volatile (as you point out), and there are decent sites that you can use instead (eg Redmonk). No measure is perfect, but some are better than others. Rust has had steady growth and is continuing to grow friends (including adding some big names). This data is corroborated with GitHub stats, crates.io growth, etc. tl;dr - we're doing well, no worries 
Sorry, we’re looking for someone with at least *four* years of exa experience.
[Next release!](https://github.com/ogham/exa/issues/132)
Fantastic to hear. Let me know how you get on. 😀
Not yet, but I want to land that feature soon — it’s a [common request](https://github.com/ogham/exa/issues/160).
[This is a bug](https://github.com/ogham/exa/issues/194) that reared its ugly head at the worst possible time!
Sounds interesting. The advantage with PS is clearly object orientation so it doesn’t break if text output of some command changes. And it is pretty obvious to me that it really shouldn’t. It’s MVC again: the output is the view, the arguments the controller, the actual ”thing” the model. Commands should communicate with models, not views! Views are just for us dumb humans, not for information sharing! Piping raw text with no structure in *nix is an awesome concept as an 80’s and even 90’s concept where many shells didn’t even do sharing of any kind, but come on... But at the same time, complexity is added from a full .NET object model. Often types and whatnot is not the most needed part, but the properties of an object, separate from whatever is going on in a view. So JSON might provide a good middle ground here.
I'm not clear on how the rust code of conduct relates to computational semantics. In any case, the rust code of conduct seems perfectly reasonable.
I suggested slice access methods that don't compile if the compiler isn't able to optimize their bound checks :-) I am not sure what's the best solution. Some alternative solutions should be tried and compared. But this is only a part of the solution. There's a need for an optimization stage in the front-end (not performed by LLVM), improvements to the type system, and probably more. Another disadvantage of Iterators that is often ignored is that they generate lot of code that the back-end has to optimize away. Even when LLVM is able to do this job well, it still takes lot of time and RAM compared to compiling C-like array code. Those abstractions have costs.
To my understanding, /u/sanxiyn takes interest in how the Rust community is perceived in outside circles, and what could be done to change these negative views. This post is perhaps another attempt at provoking discussion on this topic.
I guess one thing I could do is first loop and store the values, and then loop then through again and get the references, and hope the optimiser does it's thing.
Stripe documentation is good for this. All examples have your test api keys in it ready for copy pasting
The point of unsafe is you take responsibility for memory correctness. The compiler isn't some kind of AI, so it can't see that your container is thread safe. There's no way to do it without unsafe. I suggest putting explanation in comment about why the code is correct, despite unsafe. Don't worry about the abstractions. The compiler will optimize them away (at least in release build). Note that the Unsafe Cell is absolutely necessary, because it marks the containing data as mutably aliased.
I'm no longer able to remember Unix command-line incantations as well as I could in my youth - fortunately the rise of StackOverflow has compensated for my cognitive decline! But a flag mess like '-bghHliS' is seriously non-discoverable. It's indeed time to rethink command line tools. For exa, I'd like a 'long form': exa --query inode perm links size blocks user group modified name With the usual modern goodness of misspell matching and word completion. After this, it will tell you that '-bghHliS' is the short equivalent, and suggest creating an alias, which it can manage for you. 
If you treat the signal handler/interrupt context as a separate thread, then it should be mostly safe. This means that you can only send `Send` objects to the signal handler, and only access `Sync` objects that are shared with the underlying thread. This won't save you from things such as deadlocks when you try to acquire a lock that is held by the interrupted thread, but that's not considered a memory safety issue by Rust.
Apparently everyone loves JSON in a way that XML never was ;) It provides enough structure (which is extensible in backward-compatible ways) and everyone and their dog can read it. And yes, we can separate structure from presentation. `exa` is very _pretty_, but that's a bit of a modern curse - eye candy and not much innovation. 
Selective enforcement is a legitimate concern. I'll violate the CoC right now: &gt; Bigots are bad people who deserve to be excluded. I think that does the trick. If it doesn't we're all hypocrites! Anyway, I hope you'll all see that I'm posting in good faith and not ban me or whatever. I've seen what I believe are much more serious violations go unpunished. But that's what makes selective enforcement so dangerous: if I was a disliked personality, I could find my way out the door pretty quick while acting in good faith. But here's a secret: those people aren't worried about bans, they're worried a bunch of petty folks on the internet will publicly condemn them in force for being themselves. And it happens. It's a big problem with the equality movement. Dealing with people under a CoC can be awful in some situations. I censor myself every time I post on this topic because, well, someone could (and I believe someone would) construe what I have to say as an offense. The end result would mean being disenfranchised from a community for the mistake of trying in good faith to improve it for all members. I mean, I'm more worried I'll get lynched over discussing the CoC and the broader movement this way than for the token offense I posted above. So I will probably die of old age before I feel comfortable sharing my best ideas with you or the greater movement. I might have an insane idea that only sounds fine to me because of some prejudice I can't see past, and if I could only convince you of it we could resolve this whole thing. Or I might have a legitimately great idea. Or a good start on one, that needs your help to improve. But you'll never hear it because we can't _really_ discuss these things. Even the most rational people turn their brains off when you challenge them. But if we can't communicate the problem will persist forever. And if you can't communicate with your enemy you'll have war forever. Not because of opposing goals or ideals, but because of the perpetuation of animosity. Obviously it's not the mandate of The Rust Programming Language subreddit forum to solve these issues or even meaningfully further the movement. But as members of the movement I think you all should be aware of the above.
Okay, so you *have* contributed more than I have recently. And you feel strongly that the CoC is bad either in design or implementation. However, I am not following your reasons for referencing KIA. Why is their opinion more relevant than my linking, I dunno, a trans feminist blog about the phallocentrism of if-statiments or whatever? I think we would agree that programming is very inclusive - computers are stubborn and frustrating, debugging is hard for everyone, but machines don't care at all about my sexuality or neuropsych difficulties. KIA *does* care about non-technical politics: &gt; the SJW association is even more annoying, it is a permanent stain on a promising project There are people saying they don't want to use the technology, not because of the technology itself or enforcement of legal restrictions but *because they fear being uninvited from the social platforms associated with it.* You can be whatever you want to be and *use* Rust. Mozilla can't sue you for writing Skynet. The only thing the CoC *can* do is say "we are choosing who we associate with." So here's a question: - Who specifically should be welcomed who currently isn't? The only name dropped so far is Yarvin, and one of Yarvin's big ideas is (if I understand it) 'he who controls scarce resources ought to be most listened to'. Would you like to talk about that? Simply linking a politically charged forum and not saying anything about it yourself is *low effort trolling*. And that's why I've downvoted it for now.
How does the compiler know a Mutex is thread safe and why does it allow me to access a mutex wrapped value mutably if passed to a thread ? It seems a bit retarded for a compiler to err on the side of "If I can't prevent unsafe behavior in all cases, I will just disallow those cases"... "except for these few magical built-ins, they are fine".
It's hard for me to imagine a lens abstraction that isn't in terms of functors, applicatives, and so on. I feel like the lack of higher kinds will hold back porting a lot of interesting Haskell libraries. Not saying it's impossible or anything like that. It's just hard for me to picture porting those libraries.
Because Mutex uses UnsafeCell and appropriate unsafe code in it's implementation. This is the Rust philosophy: use unsafe code to create safe building blocks. Box, Cell, RefCell, Arc, Mutex, Vec, String, RwLock... all use unsafe in implementation but their API is designed so using them is safe. This is the same thing I suggested to you: implement safe interface for MyContainer using some unsafe code, if you are confident that the container is actually thread safe.
The second one is a big one for me, personally. It just seems so natural to do this sometimes, because "Hey, everyone can SEE that this is okay" .. but I'm probably a bit spoiled from GC languages. One gets used to it.
I suspect that the bar has been raised for open source projects. Modern marketing requires nice websites. Which is cool, but personally I'm style challenged ;)
&gt;maybe there is/there should be a way to tell compiler “hey, this slice is guaranteed to be this size, drop the unneeded checks”; You can pass reference to an array which can be created using `arrayref` crate. It's a bit inconvenient to use and I hope it will get better in future. &gt;non-checking arithmetic is a bit too inconvenient to write (by design, I suppose) but it may help to squeeze some performance; I think you can define wrapper types around numeric types which will define arithmetic traits in terms of `wrapping_*` methods, but I am not sure if it will be convenient to use. Idea for crate maybe? Overall I agree with the point that Rust compiler is not smart enough yet and certainly can get better. For example in cases like `foo[a..][..b]` vs `foo[a..a+b]` or with loops (e.g. xoring &amp;mut [u8; 16] and &amp;[u8; 16] results in 16 xor instructions, instead of several movups and one pxor) and many other cases.
I think Rust CoC is good, both in design and implementation. On the other hand, I think there is definite harm of reputation caused by Rust CoC, and since the goal of Rust CoC is in no way related to any social justice movement, I think we should make it absolutely clear Rust is not related to any social justice movement in any way, shape, form, manner, etc., and Rust community is neutral about social justice issues. That is, to make it absolutely clear, for example, Rust community welcomes you, even if you are against gay marriage, as long as you are polite.
Yep. Not runtime cost (usually), but compile-time cost.
Will do! Also I'm writing a Swift book for manning, glad to see a Rust book appear.
alias ls='echo _____ &amp;&amp; exa --oneline' thank me later
switched to Firefox last year, no regrets. if you care about privacy you should ditch chrome too.
Well, you see, you can *exapolate* the missing years.
&gt; You are literally describing what Rust does. not quite: I know the for&lt;'a&gt; ... 'a notation can handle this case but... &gt;What if we could reduce the need to named lifetimes to times when a specific named lifetime can escape the function body **the for &lt;&gt; notation requires creating a label.** my request is to add just enough syntax to allow these simple cases (non-escaping input references) to be handled *entirely at the site of the reference*, without the creation of any names. Yes, it's not so much to type, but nonetheless it's really more like **3 mental steps** , compared to **zero** . those steps being 'what does this 'for' mean, reading/writing the 'a label inside the for&lt;&gt; brackets, and locating the label beside when you see that label inside. The first suggestion is to at least streamline that to one , by making a direct, inplace 'intrinsic lifetime' that immediately means 'the shortest possible lifetime, almost as if we just made a new variation of ```&amp;``` for it. (another way to express this 'cost' is the number of angle-brackets or nesting levels that you have to deal with to do anything. even though ```for&lt;'a&gt; fn foo(... x:&amp;'a``` and ```fn foo(... x:&amp;'shortest``` are the same character count, the latter is fewer to read and write steps, as it's all in one place, consumable inplace as you read, no extra brackets, etc. Also for **teachability**, it's surely much easier to explain '*this keyword word means temporary*' than explaining what that repurposing of 'for' (also used for loops and impl's) actually means.. My own default expectation from getting things working in C++ is you don't have to worry about references input to functions at all, whilst ditto there are 2 return contrasting value cases - temporary accessors who's lifetime is usually clear from context e.g. vector&lt;T&gt;::opertor [] giving an &amp;T, or newly constructed values who will own their own memory.. only RAII controlled pointers. If I was going to retrofit a static analyser to C++ what I'd do is introduce templated ```ref&lt;T&gt;``` and reserve their use for the escaping/ 'inter-mutation' cases. there's another simpler idea which would satisfy me, namely just having a #[] or compiler flag that turns the borrow checker into a warning, flags *everything* as unsafe, and I can get on with enjoying the parts of Rust I *do* actually want, waiting till we meet in the middle with all the tweaks I'm sure will appear over the years that will streamline the use cases. ( eventually, Rust IDEs may be able to figure out the markup from examples.. 'you wrote these implementations, those you must markup the signatures like this to get them to work..' .. but it takes years for this sort of thing to be written/refined, so we need stopgap compromises in the meantime ) It's also possible that more inference would make the markup less objectionable (e.g. what if the trait impls imfered their types from the trait def), but again there's a big philosophical argument there ( I made the RFC and it gets qownvoted) I don't know if it was you specifically (but you're one of the people that occupies a similar space) but I remember 2-3 years ago arguing with someone on the rust team about the need for custom allocators, and being told "no, you're wrong, jemalloc is everything you'll ever need thanks to our profiling and insight.. custom allocators are **bad**".. fast forward to the present day and policy has changed on that. https://github.com/nox/rust-rfcs/blob/master/text/1183-swap-out-jemalloc.md I don't know your position on that but the moral of the story is you should not assume your perspectives on everything are correct *for everyone else* ... I bet you're sat there thinking "you're wrong for wanting this". I know you were there telling me **'you're wrong for wanting a 32bit indexing option on 64bit machines'** (e.g. without considering cases like meshes), which is one of many reasons I usually have a negative reaction to you specifically.
LLVM does have various debug output that can be helpful, though not quite as friendly as that. On nightly rust you can do `rustc -Z debug-llvm` (or alternatively `RUSTFLAGS="-Z debug-llvm" cargo build`) to get *a ton* of information about what llvm does. You might be able to narrow things down a bit using `-C llvm-args=some-llvm-arg` (which should work even on stable). I've used this to look into what prevents vectorization, I'm less familiar with other optimization passes.
&gt;I think you can define wrapper types around numeric types which will define arithmetic traits in terms of wrapping_* methods, The standard library actually has that already, the `Wrapping&lt;T&gt;` type.
Perhaps it's a hint that a crate should exist (maybe it already does?) that abstracts over popular vcs. Libraries like this exist elsewhere, but if we had it here I bet both tools (and other tools that haven't been written yet) could benefit from it.
The key part of an OS *is* the kernel. To be sure, there are other important aspects, but this is what determines what code can run where, really (other than CPU microarchitectural aspects)
Point. The optimizer can collapse away array access bounds checks if the first access passing ensures that the others must pass (ie. If it passes for x=y and all further accesses are in the range 0..y) but it doesn't really do anything for the way you're using `sidx` and `didx` as far as I can remember.
I always wanted cat to give a simple directory listing when given a directory as an argument. I wanted to add that feature once, but after a bit of staring at the gnu cat sources I decided I had better things to do. So maybe exa should inspire me to make a version of cat that groks more than files.
Thanks for the source, I'll definitely check them out to improve my testing.
exa uses libgit2, and puts it behind a Cargo feature flag so you can compile it out. I want it to be an optional dependency, rather than something that’s integrated *everywhere*, for that exact reason. I recently switched back to Git (from Fossil) so I know VCSes won’t be around forever.
I think this is where things get tricky. While I agree with your overall comment. I address things differently. In a case like you mentioned: &gt;if you've written a particularly complicated function and you realize that it'll cause problems if someone forgets to add 1 to some variable you've been very careful about I would go about things differently. I would refactor the code such that that variable can't be added to directly, and the process of adding 1 to it is encapsulated in a function that does this with a descriptive name and proper documentation. In general, I try to be careful with my code like this and keep it as decoupled as possible, which I think makes it even more important for me to be thorough with testing. From my point of view, it's not obvious where my code would break since I've been careful, but I obviously know it will and I want to add proper testing to guard for it. edit: Also, regarding the "proper documentation" I mentioned, the cases you mention is why I think it's very important to address the "whys" in the comments, rather than the whats. Clearly-written code is often self-descriptive on what it does. What others need to know when reading your code is **why** you chose to do it like that, and what might break if done differently.
I just checked out your original code; not a bug in the CSE, a bug in the original code. :D When you originally wrote let row_entropy = entropy2(k11, k12) + entropy2(k21, k22); you meant (I think) let row_entropy = entropy2(k11 + k12, k21 + k22); That in and of itself would cut down on the number of logarithms. It would be interesting to know if Rust still got beat down even with the correct code and fewer logs, or if the CSE is important for performance too.
Yea, there are some [interesting issues](https://github.com/rust-lang/rust/pull/43595) with vectorization of range iterators at the moment. On the positive side, there was a `for_each` function recently added to the iterator trait which should make it possible to simplify the output to llvm of a loop over a range (and probably in other cases too) a fair bit. I did manage to get the example to [partially unroll the loop](https://godbolt.org/g/BqGwiH) using while instead of for, it still didn't vectorize though.
Ok, I may be misunderstanding your idea here than, because it seemed to me that creating any method for MyContainer that affect the Unsafe cell (the actual container) will =&gt; in said methods having to be marked as unsafe. I found an article on the subject though so I will make time to read it tonight and it will probably enlighten me as to where I bumbled. Though the idea of having to fight the compiler to implement a basic data structure seems rather ugly :/... I can't image how horrible this would be when trying to implement something complex like a redux tree or a lock-free map.
Oh, I thought they wanted to provide me with an emetic.
To ensure a reproducible build you would also have to check that what you downloaded is what you expected to get, i.e. you should download a specific git revision or check the SHA256 hash of the downloaded file against the expected value. At that point vendoring is probably a better solution, unless that isn't possible because of file size or licensing issues I guess. 
Now my knowledge of networking and Windows isn't great but on Windows isn't localhost supposed to be port 80? Like localhost:80?
I would really like to build a tutorial/documentation system which prompts you for information along the way so your tutorial is customized. For example right at the start it could ask for your server IP. From then on your server IP is populated in any SSH command. Then half way through it might ask you to generate something and pop the output into a box to be used later.
&gt;But, if you write your equality test using sum, which looks silly, it vectorizes on godbolt: I would think this is due to the fact that doing it like this will always iterate through the whole array, which makes it easier for llvm to reason about.
Why on Earth doesn't [rustup.rs](https://www.rustup.rs/) show how to install it on Linux? It only shows me instruction for Windows. Should I install browser on my server just to view what the command is?
`localhost` and ports are completely separate concepts. Think of them like phone numbers and extension numbers. Ports are used to disambiguate between multiple programs behind the same IP address. Extension numbers are used to disambiguate between multiple offices behind the same phone number. You'd never say "Now my knowledge of phones and &lt;office name&gt; isn't great, but in &lt;office name&gt;, isn't &lt;building's phone number&gt; supposed to be extension 123, like (800)555-6789 ext. 123? `localhost` is just a a conveniently built-in DNS alias for the `127.0.0.1` IP address which means "ourself" no matter which machine you're on. It's like *not* "dial[ling] 9 for an outside line".
Have couple of million files in a directory and even ls perf starts to matter. Its just couple of weeks ago that I encountered ls failing because it ran out of memory...
I try, but Firefox is so slow :(
Oh gods, I used Go in like, one course in college (extreme multiprogramming course) and it gave me cancer of the parametric polymorphism, as well as sever inflammation of all my consistency guarantees.
You mean like [this](https://play.rust-lang.org/?gist=5ebb656347d98b94ba4290f25e8cd044&amp;version=stable)?
ripgrep uses the ignore crate, which I designed with the intention of supporting other vcs's. But that's only for the ignore rules. Abstracting over vcs's seems possible for a particular use case, but seems difficult to create a general purpose abstraction.
Argh, my bad then... Should have learnt how to write unit tests in rust earlier... I wrote a small benchmark for the CSE and non-CSE versions, and there is only a super tiny advantage for the CSE version, so it was definitely not the source of slowness. I really guess it was the combination of the additional logs and the array that was unnecessarily copied... Anyways, seems we shed light onto the mystery, thanks for helping out. Btw, I ran some tests with the scala version on a larger dataset, and while its still superfast, it runs into ugly GC pauses after some time, so I'll go with the rust variant. 
Never change Pascal.
There's a link at the bottom "other installations options"
So, like, `Mutex&lt;Internet&gt;`, then?
Well, the idea was something like this: impl MyContainer { pub fn add_item(&amp;self, item: Item) { unsafe { self.data.get().do_real_insert(); } } } &gt; Though the idea of having to fight the compiler to implement a basic data structure seems rather ugly :/... I can't image how horrible this would be when trying to implement something complex like a redux tree or a lock-free map. Why do you think so? From my experience, compiler blindly trusting programmer is uglier idea. Having clear distinction between safe and unsafe code helps a lot. Unsafe code is usually very simple and easy to verify manually. Safe code is verified by the compiler. Sure, there are additional things the compiler needs to know about your code ("this reference will be shared", "yeas, I really want to do this dangerous thing, it's not a mistake", "this data might be aliased mutably, so take into account when doing optimisations!"), but it saves you debugging time.
Not a Windows guy, but it might be worth checking Windows firewall.
Well, today I've learned something new too. :)
FWIW, if the table size is a nice, constant power of two (which you can normally force it to be), you can avoid the check by doing a mask before access.
I can't see having learning projects as a bad thing.
hmm i haveny had much problems with performance and i use it on laptop. anyway vertical tab tree is a great plugin. 
I even whitelisted the executable that was built, but it was of no use.
Actually that's a great idea. What other VCS s are you using?
Yes and no. As with many things, it depends on libraries. You can create "must-check pointer" in C++, but nobody will use it. It is possible to create a main function that passes zero-sized type called `NonInterruptContext` and make all interrupt handlers take `InterruptContext` and then write all functions that must be called from within interrupt to require `InterruptContext` and all functions that must not be called in interrupt to require `NonInterruptContext`. Similarly you can create `InterruptsEnabled` and `InterruptsDisabled` tokens to require enabling or disabling of interrupts. Then make `fn sei(NonInterruptContext) -&gt; InterruptContext` and `fn cli(InterruptContext) -&gt; NonInterruptContext`. Design it well, build libraries around it and it will work. The most challenging task is to actually write all the code. Also it might be difficult to convince people to use it because it will surely add burden to writing code.
The "flag mess" is annoying, sure. But what I really can't do without anymore is the robust, easy and clean piping and parsing of PowerShell Objects. Let's use "ls"as the example. In PowerShell it's an alias for "Get-ChildItem". It returns a collection of objects, one object for each "childitem" in the directory. You can obviously specify "-Recursive" too. Each of these ChildItem-Objects has 26 Properties, and you can access them all directly and without parsing text. What kind of properties do they have? Well, awesome and useful stuff like "CreationTime", "Extension"(for files) and "LinkType".
As more work on such design changes of Rust type system shows it is usually more complicated then it looks. So they decided to reduce the scope to deliver something useful in reasonable time frame. Niko, one of the authors of this RFC, has shared his idea of solution to these problem not a long ago on internals forum. So is likely that it will be solved in the future. I like the appoach to do simpler steps more often better.
OP, you may need to register the port for listening via a non-administrative account. E.g. if you are using localhost:8000, you can open an elevated powershell session and execute the following command: netsh http add urlacl url=http://localhost:8000/ user=Everyone You can view existing port registrations with this command: netsh http show urlacl [https://msdn.microsoft.com/en-us/library/windows/desktop/cc307223%28v=vs.85%29.aspx?f=255&amp;MSPPError=-2147217396](https://msdn.microsoft.com/en-us/library/windows/desktop/cc307223%28v=vs.85%29.aspx?f=255&amp;MSPPError=-2147217396) Some gotchas: * The URL specified in the command MUST match the URL you bind to in your program exactly. For example, you cannot interchange "localhost" and "127.0.0.1", or "localhost:port" and "*:port". * The URL MUST end with a `/` character else you get the very useful "parameter is incorrect" error * I'm just guessing ;)
Hey, your link is broken because of the exclamation mark at the end
When would you use `transform` instead of `mutate`? I would have expected `transform` to take `&amp;self` instead of `self`, so that you can make a transformed copy while keeping the original. If you don't need the original, then wouldn't `mutate` be more efficient?
It's a bit tied into the whole .NET machinery for my taste, but I think the idea is brilliant. If `exa -j` dumped out the listing as JSON, then we could use tools like `jq` to slice and dice it.
Are you behind a proxy by any chance? If you are, you have to disable it for localhost. (AFAIK there is a setting in the system proxy settings for excluding certain hosts / domains; if you're using Firefox you can also configure an exclude in the browser settings)
Awesome, thanks for the informative response! Very helpful :)
Once I had to resort to Python to list my directory....
Agreed! I think Twilio does something similar. My startup is going to have an API that is similar in programmatic use to these two, and I've been using both sets of APIs for inspiration. 
It's weird that they don't have a published package or mention this in the sure the OP linked, but the README in the repo actually has instructions for installing through `cargo`: &gt; If you’re using a recent version of Cargo (0.5.0 or higher), you can use the cargo install command: &gt; cargo install --git https://github.com/ogham/exa
Can you share a short example of the problem? The compiler *does* understand that `somestruct.x` and `somestruct.y` are distinct things. So, borrowing one field shouldn't stop you from mutating another field if both are accessed from the same local struct or local mutable reference.
Note that it can sometimes be a touch annoying to maintain CLI tools with `cargo install` because there is an [outstanding bug where `cargo install` doesn't respect `Cargo.lock`.](https://github.com/rust-lang/cargo/issues/2263) I think at some point in time, `cargo install ripgrep` didn't actually work because of it. It's fixable with maybe a bit more paranoid `Cargo.toml` if you really care.
Thanks. Time to check what's different between this simple example and my code at home.
&gt; non-masochistic way You can try a different language if you don't like the trade offs &gt;What is the standard way to allowing multiple threads to access this container. [Guarantee Composition](https://doc.rust-lang.org/1.6.0/book/choosing-your-guarantees.html#composition) &gt;Is there any way of allocating the container dynamically and then sharing a pointer to it between multiple threads ? Also, is there a way of stack allocating it and sharing a reference between threads with the guarantee that said threads will be joined before the reference expires ? 'scoped threads' as some have pointed out &gt; Is there a way of doing one or both of those things in such a way that a user of said library doesn't need to be a rust expert to use it or include a second third part library (e.g. crossbeam) to use it ? I.... don't understand the question. When people are required to include your module-A , and your module-A requires some other module-B. They will not be required to _manually_ include module-B . If you fear returning complex composite types is confusing for the end user. You should consider 'newtypes' 
Interestingly, `shlex` has been "ported" for some time, though there's not much fanfare: https://github.com/comex/rust-shlex It seems that this library is more serious about getting used, especially given that it actually has a README. :) Hoping for the best here!
Naah, it's a more complicated structure ;)
So it's based on search engines, which change their algorithms recently and one of which is baidu, which could randomly to decide to start censoring things if the Chinese government wants. 
I'm starting to understand it. Thanks :)
/u/japaric has been working on an RTOS-as-library project called RTFM which aims to make interrupt-safe real time programming feasible. It's very cool how it works: http://blog.japaric.io/rtfm-v2/
This confusion is totally my fault -- I shouldn't've termed this 0.2, since as you say it's not clear yet whether breaking changes will be needed.
Thanks so much for the reply! I was able to use `&amp;'static str` to fix my problems.
Why the echo..?
From a little experimentation it seems rust won't vectorize loops that break early. Also as seen in these 2 examples rust doesn't seem to want to vectorize loops operating on booleans: - uses int, vectorizes: https://godbolt.org/g/jueVXs - logically equivalent, but uses bool, does not vectorize: https://godbolt.org/g/ovwNHo EDIT: I can't get any C/C++ compilers to auto-vectorize a loop with an early return either, although clang will vectorise loops using booleans, so rust does fall slightly short in that regard.
I frequently run it on real hardware (XPS 13 and Lenovo Y510P), but as ids1024 has stated, the driver support is lacking to use it as a daily driver outside of a VM. Supporting more ethernet chipsets and some USB device classes would improve the situation tremendously.
The problem is usually an intermediate function: mutably borrowing different fields at the same time works because the checker can see that they're non-overlapping borrows, however if one or both of the borrows is done through a function it "erases" the disjointedness and the checker only sees a borrow on the struct itself. Here's /u/sellibitze's snippet [converted to use getters](https://play.rust-lang.org/?gist=f9e5875d862d18f7657f98d15e12a13e&amp;version=stable), it makes the borrow checker angry.
&gt; The compiler does understand that somestruct.x and somestruct.y are distinct things. It only understands that on direct access, I expect many people are hiding their attribute accesses behind accessor methods (either by habit or because they need to) at which point it doesn't work anymore.
Sell! Sell! Sell!
That's a quite nice idea in fact. Its not constant (the huffman setup is sent in the second packet) but I might be able to force it to be a power of two by filling it up.
Glad I could help :). It's worth remembering that bounds checks only really hurt when they prevent other optimisations (vectorization especially), since they're easily-predicted branches, so it's only worth swapping them for a data dependency when they do.
Once [this feature request](https://github.com/rust-lang/cargo/issues/1359) (optimize only dependencies) is implemented, splitting a project up into more crates should help as a workaround for this.
It looks like `std::sync::mpsc::Select` (on nightly) is designed to do what you need (i.e. wait on a whole set of channels).
Too early to tell really. There are no plans to make significant changes but we are also waiting to see how a number of Rust language features that are planned will change things. 
This coming tuesday features `elastic` in a similar tutorial! I'll ping you when it's published :)
Also: &gt; It turns out there are certain instances where it’s perfectly safe to have mutability doesn’t only have to happen through unique references to preserve type-safety. There's something a similar shape to "; it" missing after "mutability".
&gt; For example, Tock lets embedded programmers mix their own code and library code from hardware vendors or the open source community without having to completely trust every line of code. And &gt; Rust is the first “mainstream” language to enforce type-safety strictly without relying on runtime memory management [...] This meant that it’s possible to build a kernel that allows extremely fine-grained isolation at almost no cost So what happens if the vendor libraries are written in C?
This looks a lot like `syn`'s output. I feel like you're talking about something different to the output of parsing rust code, though?
I sent an email and received a reply: &gt; From: Paul Jansen &lt;paul.jansen@tiobe.com&gt; &gt; &gt; Hi Vitiral, &gt; &gt; Thanks for your feedback on our TIOBE index. Rust dropped from the 38th place to the 58th place this month (not 94th place). Note that position 51 to 100 are listed in alphabetic order. Rust lost 0.103% market share, which is perfectly possible. I am also a bit surprised that Rust lost its top 50 position, but I can't help it. Let's see what happens next few months. &gt; &gt; Regards, &gt; &gt; Paul
[removed]
did you try using nightly? it's so so so so much faster.
I mean .NET is an open standard and .NET Core which PowerShell 6 is built on is entirely end-to-end open-source under MIT and cross-platform, so PowerShell is through and through MIT-licensed. A heck of a lot better than the GPLv3 that bash and gcc are married to! (I'm assuming that bash is typically compiled with gcc here, I mean they're both GNU projects) What's wrong with the .NET machinery? What's wrong with being powerful ;)
all right all right :D
My work uses SVN
I had issues hosting standalone OWIN (.net) apps where this was the solution. This may be helpful.
I've been using the intellij plugin and it's gotten a *lot* better, even just in the last month (or week). I'm pretty happy with it - the next big thing I'd like is for it to be backed by rustfmt.
does gdb not properly integrate with intellij for rust?
I've never tried it. I rarely use a debugger with rust.
fixed!
1. Perhaps something like an arena or a StringInterner? 2. You could also return a newtype with the index into the Vec and a PhantomType of the ref (to ensure the Vec is still there).
thank you - I didn't realize that's what "Select" refers to. Unfortunately the api it offers is pretty confusing and apparently the implementation is mediocre. But it may be the simplest route. 
Thanks! I just installed it and aliased it to ```ls``` on my system. Seems to work well and the output is really a lot better than ```ls```'s output
interesting read - I definitely have the same amazement when my programs work correctly right off the bat! Also - I'm with you on using threads galore with various design patterns that. However, if you have a thread in a loop checking whether there's new work on two or more `mpmc` queues, won't you need to either 1) continuously spin a core checking whether either of them has something new, or 2) sleep the thread for some period of time and check for new info on wake? 
In this scenario, write access would move, not extend. The original author who was deemed abandoning would no longer be able to `cargo publish`. This sounds uncomfortable and is basically why we don't have abandonment procedures.
Damn macros! :v
https://github.com/intellij-rust/intellij-rust/issues/535
Okay fair that's pretty fucked. .... also, on mac in reddit, ☹️ renders as plain black-lines-white-space, while 🙂 is the colored form. However, in your link, both are colorized. And according to the console, they're identical strings. It'd be a lot more comfortable on my "go beyond ASCII" high horse if the SMP wasn't a wasteland. I still maintain that at least expanding farther into the BMP is worthwhile, though.
So you tried to pipe the output into grep or something and it failed?
Isn't `cat /some/dir` producing a directory listing just `ls`? Personally, what I've always wanted from `cat /some/dir` is for it to cat every file inside it.
Tried IntelliJ Rust today and love it. There are parameter names, and even help me run a specific test easily by clicking the flag besides the code.
Are there (plans to make) a PDF/epub version? Would be sweet to read it on my kindle.
Could you elaborate? Some of your siblings posts indicate that it's feasible to implement this safely, it seems...
But also, don't install system tools with `cargo install`.
Please do not get in the habit of doing this for system tools. If it's not used in your edit-compile-debug cycle, `cargo install` is not the way to get it.
I was actually planning to use `shlex` but, if this doesn't trip over the any of the `bash` constructs in the scripts I need to deal with, this looks like it's more in line with what I need. (The Python code I'll be porting builds on shlex as a hacky way to extract metadata from shell scripts.)
I'll have you know "my cloud" is a box sitting in my closet, so there;)
Yeah it depends on the font. I'm not so sure about the BMP, even. Even allowing all characters from other languages is problematic, because ambiguities are easier in some scripts, and font issues are still present making this stuff worse. If we are to have any chance of this working programmers will have to ditch vim and emacs entirely, for example. With both my native script and Chinese -- a script I've been reading much more regularly -- I need a larger default font size to be comfy reading them on my computer. More so for traditional chinese (which I can't read anyway so this doesn't matter :P). Also these scripts don't interact well (or look good) with monospace anyway. None of the Asian scripts except kana and Cyrillic do. We can't even add Greek/Cyrillic because they have overlaps. We could probably add Hebrew, kana, regular European diacritics, and a couple other scripts. So I think it's something we could do, but it would either be severely restricted or have to wait for all of the programming tools to evolve past that point. 
Great news! JetBrains make amazing IDEs, this is gonna push Rust big time.
It's not a system tool for me. It's just a nicer `ls`. I'm going to `cargo install` it, and have a shell alias for it or something.
Channels are blocking. If you `recv` on a channel, and there's nothing in it, the thread will sleep until there is and wake up as soon as there is. No cycles are wasted, there's no busy looping involved or anything like that. 
&gt; said methods having to be marked as unsafe. Use `unsafe fn () {}` to punt the warning to the user. Use `fn () { unsafe {} }` to hide it.
Github issues are also pretty hard work. This is compounded by the fact that there is sometimes (often?) more than one issue, because of RFCs, tracking issues, etc.
Well, when I read the title I thought: "Ok, nothing special. lt's just written in Rust". But this is actually really cool and has some benefits over ls!
Nope, just plain ls (can't remember if I used -l or not), no pipes or anything involved. Worked around that by doing `find . -print` instead. 
There's the `Reformat file with rustfmt` action that comes with the plugin. Though, the general approach is to leverage the IntelliJ platform's infrastructure to format code the same way as rustfmt does ([issue 431](https://github.com/intellij-rust/intellij-rust/issues/431)).
I kinda like the model the NLL RFC is using, which is to be a separate repo and use github PRs and issues moved from discussions from the RFC github thread.
It's pretty clear to me that the commenter understands why it's necessary, but are just mentioning that typically they get compounded together. There's no need to assume the worst and be snarky about it.
He likes a literal line separation before exa's output, it seems.
Don't f*ck with the guy after which a programming language was named after! – Before he was even born!
Thanks for the help everyone :) . I resolved it by using a `Rocket.toml` file and pointing to 127.0.0.1 instead of localhost. For some reason, Win10 wasn't resolving localhost to 127.0.0.1.
Have you ever noticed all these serialization formats are named for that boring guy at the office? - Ron - Jason - X'Malucant Lukiel It's getting downright predictable.
A few thoughts. The basic idea of directories being modules is great. But then, that's what Java does, and i'm a Java programmer, so it's no surprise that i like it. It's a bit odd that there's no way to express private-to-file explicitly with a `pub(something)` form. This reminds me of the default visibility in Java, which still strikes me as weird twenty years down the line. &gt; A directory with a leading _ gives you a pub(crate) module. Ouch. Is there anywhere else in Rust that we have this kind of lexical sensitivity? I love Python as much as the next person, but i'm uneasy about this. How about defaulting all modules to private, but allowing some kind of module-level attribute to make them public? It's hard to evaluate that without having a story about module-level attributes, which is deferred for now. How about defaulting the top-level module to public, its descendants to private, and then requiring some kind of declaration in a module to make a submodule public? Essentially, the implicit modules are always private, but an explicit "pub mod", of the kind we already have, makes them public. It does mean you can't tell which modules are public from looking at the filesystem; how important is that? 
Websites being able to read system usernames would be neat, until they use it to track you online and every browser disables it. Sadly. 
I'm curious, why would you want to output millions of files to your terminal?
Which mysql package are you using?
I don't believe so.
You've said this at least twice *in this thread,* but you have never said *why.* Notwithstanding the fact that I'm probably going to ignore your advice because approximately half of all my system tools are currently installed this way... **...Why?**
If I made a replacement for `cat`, I'd try to get it made into a Lifetime movie.
tokio-core interacts with futures, and there're certainly a number of breaking changes pending in futures, so surely that update will be breaking whenever it happens, at minimum.
Definitely. And if they allowed you to read system usernames, they'd allow you to read other system information, which would be even worse. Personally, I love being tracked by ads, though. I'd much rather see an ad for a programming job than an ad for a car or something.
Right, but what if you want to wait until one of two channels has a new message. Of you're blocking on the first one the second one could have a message that you don't know about. 
As someone not familiar to JetBrains products, I'm confused by the *Go to Class* feature. Rust doesn't have classes, so... can someone explain what the feature does?
Why does it use SI prefixes by default? That seems like a really bizarre design decision.
**Rust dropped from 38th to 58th**, not 94th. See [vitiral's comment](https://www.reddit.com/r/rust/comments/6rievm/rust_goes_from_38th_july_to_94th_august_place_in/dl5rwx0/) which I cannot sticky, unfortunately...
There is a bunch of pending cleanup, but mostly around deleting deprecated APIs. I don't think there are currently any pending breaking changes that are worth making an 0.2. release for.
...and Tom's Obvious Markup Language
Will it support comments?
It currently does, they're denoted by //
Goes to structure or trait or typedef if I recall correctly. Generally speaking name comes from times where Intellij was Java-only product 
Make it one channel, and send enum MessageToX { X1(X1), X2(X2), } Every receiving thread-type should define one type of messages it can receive. It is also suspicious if a thread-type would be receiving to many types. Instead, have more different thread-types, each receiving their own type.
Cool! And/or in the [specification](https://github.com/ron-rs/ron/wiki/Specification).
(It was already in the readme. Woops.)
oh nice
Now it's in the specification too https://github.com/ron-rs/ron/wiki/Specification#comments
I think if it can *prove* that there will be no panic, then it's fine. Which is why a trick can be backward iteration: if the first access doesn't panic, then the subsequent accesses should not either.
I'm not aware of any; there was some pretty radical changes between when this was created and Rust 1.0 happening. 
I felt that one was too... ^no ^i ^just ^can't ^say ^it
There's a bit of an idea floating around where you can use `_` to let the compiler figure out the name of a type. For that example it would look like `fn point_x(_ { x, .. }: Point) -&gt; f64 { x }`. But I'm not sure this specifically ever made it into an RFC.
Well, in that case I can still be snarky as a result of them not reading the first paragraph of my first post, resulting in this whole discussion about mutexes in the first place... anyway, it doesn't matter *shrug*
There is no excuse for being mean on this subreddit. See the rules. If someone misread something, politely point I out. Besides, that first line isn't clear at all. It could mean one of two things: - You have a threadsafe container implementation and want to know how to best expose it (implement sync, make all methods work on immutable borrows. Something like that, depends on the exact semantics) - You have a non threadsafe container you wish to expose in a thread safe way so that it _becomes_ a threadsafe container (use Arc+Mutex or RWlock or similar) You meant the former, but multiple people (including me, on first read) interpreted it as the latter. Communication is hard. Assume good faith. If folks don't understand what to say, try clarifying, instead of railing on them. 
Hmm...the `_` still feels redundant, though, because I just want to write the struct name, the args, and that's it! :) I'm thinking of proposing something more like a normal `match`, along the lines of: fn point_x(Point { x, .. }) -&gt; f64 { x } I *believe* this to unambiguous at the time a lexer hits the initial `{`token, because even though we've already consumed a word, we know that the word NOW refers to a type, and that we're destructuring a struct, instead of immediately expecting a `:`. I'll have to check the grammar on this, but it doesn't sound too hard to modify it to work this way. For tuples, it seems like a single type ascription (`(a, b): (u32, bool)`) could work, but I feel like it could be better if we could use syntax a la `(a: u32, b: bool)`. I guess I'll save the bikeshedding for the RFC it looks like I'll be writing! I'm actually unfamiliar with what I would need to include in my considerations of proposing this change, though, as I'm not very experienced with writing compilers. I mean, I wrote a simple compiler as part of my capstone, so I have an idea of what could be a concern, but that's nowhere near as complex as what the Rust compiler must do! I'm excited, but nervous.
oh wow thanks for that explanation! I actually sumbled upon that issue yesterday. Two very similar pieces of code, but one with direct acces to an attribute and one using an accessor. I got pretty frustrated and ended up putting each attribute in its own `RefCell` as suggested above.
would love to see hg support :&gt;
Wait a minute. Isn't the author of the vscode-rust extension also an Alexey? I'm sensing a pattern here.
hg
There is a way to generate a mobi easily with kindlegen: - First select the print view of the book (https://rust-lang-nursery.github.io/rust-cookbook/print.html) - mirror it with wget (wget --mirror --convert-links --adjust-extension --page-requisites --no-parent $URL) - inside where index.html is living, call kindlegen: kindlegen index.html
/r/unexpectedfactorial 
You can try https://rustbyexample.com/ and for practice http://exercism.io/languages/rust/about
To be honest, I think that in a little while the distinction will cease to matter. Once implemented, there will be no alternative to distinguish them from. Also, even the term lifetime is dodgy: the lifetime of the variable is still lexical; what's not lexical is for how long it's borrowed!
My first question when seeing this was "What's the difference between this and JSON?". The list seems to be: * Allow unquoted field names. * Optional typing * Comments (`//`) are now allowed. * Trailing commas are now allowed. * Use `()` instead of `{}` to indicate a homogeneous structure, instead of expecting all `{}`s to be the same. Not entirely sure what this means, honestly -- I'm still wrapping my head around this one, since it doesn't match 1-1 with how I think one sees them normally in Rust. ...with the latter seemingly the single *major* syntactical difference from JSON.
Awesome, guess I'd better get started! :)
Yeah, it's very similar. The advantage would be that one wouldn't have to write all the `syn`- related boilerplate.
&gt;When writing in async way, long computations might block the 1 thread that is used. Such computations should be offloaded into another thread (as shown in the async2 benchmark). Deciding what to offload and what not could be difficult and sometimes not too obvious. The only reason to offload in another pool is when your cores are not saturated. However as the number of concurrent requests increases so will your CPU load. At some point your other threads will start make things slower. That's easy to see in Linux: the optimal performance of your app will be when load is equal number of cores. When it goes twice as high you'll see degradation.
Why not?
thanks for the soft-sticky!
Here's [an example](https://gist.github.com/kardeiz/1d0b50dacbeaefe9c37ecf3315134461)! The tricky thing for me was figuring out how to share a core handle between hyper and mysql. I asked about my approach in this example in [https://github.com/tokio-rs/tokio-core/issues/203](https://github.com/tokio-rs/tokio-core/issues/203).
Yeah it's one of these bits where the compiler is a bit too helpful in one case and you get completely lost and confused, because something which looks like a trivial refactoring ("extract method") breaks your code entirely
Thank you. That was the primary issue I was running into too. Sharing the handle.
Will this cost money and the open source one fall out of favor and be deprecated? If so, I'm starting to get a bit scared on how JetBrains are doing things. They did a similar thing with the Go plugin. I absolutely love that they invest in these things, but I am concerned on how it's done. They build a user base on the free version and then make it paid. I'm all for getting paid for your work, but this tactic (if in fact that is what's being done here) feels like bait-and-switch. I find it strange that the blog post doesn't mention whether they are committed to keeping it open source or working in the community IntelliJ editions. Feels opaque :-(
[Have some light background reading](https://www.reddit.com/r/rust/comments/6j0g9o/squatting/djaiszk/?context=10000). So, here's the thing. Cargo is an excellent package manager and I will never ever speak ill about a language providing a first-class path for fetching libraries into your development environment. Then we realized that some tools for Rust dev weren't libraries, but executable utilities. And so `cargo install` was born, to get you those sweet sweet dev tools. Cargo's install command sticks them alongside the Rust distribution, in `~/.cargo/bin` which is a canonical PATH element exactly goddamn nowhere, and if you'd like I can dive down the rabbit hole of why `~/.cargo` was a mistake that we should fix sooner rather than later but I'll withhold for now. So when you update your system, with your system package manager, your `cargo install`ed tools don't update. "But why would Cargo have an install command if not to install things?" You may ask. Well, Cargo has an `update` command that sure doesn't update a thing in `~/.cargo/bin`, so maybe *Cargo isn't a tool for installing general-use programs.* **I mean, it's not even a good tool for installing specific-use, Rust-development programs.** I recently had a discussion where a prominent Rustacean was two, maybe three, major versions behind on `cargo-watch` because it's only installed with Cargo and ***`cargo update` doesn't update your executables because Cargo isn't a system manager***. If Rustup were sane, it would put the shim executables in `/usr/bin` on UNIX and `C:\Program Files` on Windows (or continue the ecosystem trend of wrecking `%PATH%` I guess) and store the real things in `$XDG_DATA_DIR/rust` and `%APPDATA/rust`. If Cargo were sane, `cargo update` when not in a Rust project tree would bow to the (mistaken, but I guess it's too late to do things correctly or something) common convention and update the tools it's responsible for managing. And if authors of general-use tools written in Rust were sane, they'd do what every other package author does and distribute via the standard system channels: Homebrew, PKGBUILD maybe in the AUR, a `.deb` and a `.rpm` either for download or in relevant repositories, so that (a) the executables will go where the system wants them and not have to mangle PATH and add *another* channel for management, and (b) when you update your system with `brew update` or `aura -Auy` or `yum update` or `apt-get update` you update THOSE TOOLS AS WELL. [BurntSushi does "I'm the upstream now" correctly.](https://github.com/burntsushi/ripgrep#installation) We should all follow this excellent example. ## TL; DR Un-wreck your system. For sure don't install system tools with Cargo. I'd avoid it for dev tools except `cargo-watch` isn't upstreamed anywhere. `cargo install --force $thing` is not a cool way to be. I'll grudgingly accept that Rustup has to do magic to manage the Rust distribution(s) you have installed, but you bet I install Rustup correctly and not via `curl | sh` like the website says, because that is [so, so much worse than using a language library manager to install system tools I'm not even going to say any more than this because I'll burst a blood vessel STOP THIS MADNESS.](https://www.idontplaydarts.com/2016/04/detecting-curl-pipe-bash-server-side/) ---- Don't get me wrong I'm mad that installing packages on Linux requires root access; as much as it pains me to say this I firmly believe macOS has the most correct idea (system apps/libs in `/Applications` and `/Library`, user apps/libs in `~/the same` but even that ecosystem doesn't follow the light, either in common `.dmg` "installers" or in Homebrew and it's infuriating, but at least system managers centralize responsibility of maintaining system state. ## In Conclusion But yeah. Cargo is not a system package manager. Don't install software with it. The only things Cargo should download are libraries, which it then builds and sticks into your `./target` folder. You don't install system libraries to `/usr/lib` with Cargo, and so help me god if I get shown otherwise I'm going to throw my laptop out a window. Don't install system executables with it either. Treat your system right. ---- Postscript LOL I just went back and fully reread the thread I linked at the top and *you're in it* We had this same conversation *two months ago*, and as a result I wound up pushing that guy's project into Homebrew. Guess I know what I'm doing this weekend
The nice part about the `_` variant is the symmetry with construction. E.g. the same syntax could be used for passing a point: let x = point_x(_ { x: 23, y: 42 }); Plus that it also works for enums: if let _::Success(val) = something() { println!("val {}", val); } Though your tuple example makes me think more of type ascription.
&gt;just a ... `ls` so what you're saying is, it's a system tool. If you use it anywhere other than within a Rust project directory, it shouldn't be installed with Cargo. [I'm gonna preempt a "why not"; you don't have to click this if you don't want to though.](https://www.reddit.com/r/rust/comments/6rgszy/exa_a_modern_replacement_for_ls_written_in_rust/dl673wa/)
[Because Cargo is not a software installer and while using it as one was understandable for a specific task, it's also mistakenly exploited as a shortcut instead of being a proper upstream to distros](https://www.reddit.com/r/rust/comments/6rgszy/exa_a_modern_replacement_for_ls_written_in_rust/dl673wa/) I'm mad at `npm install -g` and `gem install` too, don't get me wrong; I just don't hang out with those folks enough and also I have higher expectations of Rust.
It's a very popular name in Russia AFAIK (not Russian here) 
I also (as contributor) have similar concerns, but honestly some years will pass yet till this happens :) 
This seems to take a similar approach as other Elasticsearch clients. I haven't gotten back to it in a bit, but I streamed myself working on a Rust port of [Bloodhound](https://github.com/bitemyapp/bloodhound). The key difference is that rather than punting on the meat of the API, it defines the entire Query DSL plus all the other bits and bobs of JSON as a datatype. [Example Bloodhound code](https://github.com/bitemyapp/bloodhound/blob/master/examples/Tweet.hs#L109). IME, this makes working with Elasticsearch dramatically easier. I've known people who barely know Haskell to use Bloodhound in a GHCi REPL to scaffold out the JSON for Elasticsearch queries in other languages. I started on the (suuuuuper early) Rust port [called 'duke' over here](https://github.com/bitemyapp/duke). Since Bloodhound is currently compatible with ES1 and ES5 and the design has worked well with both, I didn't plan to change too much there. I see /u/KodrAus made `elastic`, it might be worth refactoring `duke` in terms of that. Seems a waste to have a nice type system and not solve problems like not having a clean, type-safe way to speak to Elasticsearch, even if the `json!` macro is nice.
I totally think a `_` in the LHS is awesome -- I just don't want to have to rename the type on the RHS if I've already written it. :) To your point, cool! I like how `_` applies there. It almost feels like I'm looking at ES6 Javascript there...which is a good thing for brevity and maintainability in client code, IMO!
my previous reply didn't totally answer your question, I hadn't noticed you asking about a toolbar too. Here's an example glade file with what you were asking for https://ufile.io/1e5uh . Basically you can use a vertically aligned box to hold the menu, toolbar, and scrolled window. Then you put a viewport in the scrolled window and whatever you want to display in that. I used a text area. You can replace the scrolled window with some other layout, like a grid, if you needed more than one thing in the main window.
Depends... You maybe be able to put it in a Tock process (which can be in any language since it's hardware enforced). We do this, for example, for the NRF51 serialization library, for example, which is many thousands of lines of C code. I imagine you could do this for something like the invensense motion drivers, but that's not readily available without some haggling with a big company, so we haven't looked at it. I suspect this covers a majority of the useful cases that involve talking to a peripheral chip over a bus. But that's sub-optimal since there is a performance and memory penalty for putting something in a process and because it kind of breaks the general model for where things should live in Tock (peripheral drivers generally ought to be in the kernel, by design anyway). So yeah, that statement really assumes the "vendor library" is written to be written in Rust. What's worse, it probably has to be written specifically with Tock (or least Tock's general execution model) in mind. So in practice today, this means there are no usable "vendor libraries" you could incorporate into the kernel today. But hey, it's aspiration, and if a better day comes we'll be ready for it.
&gt;Let's assume I have build a library that exposes a thread-safe container. How can this line be assumed to mean: "I have an unsafe container I want to make it thread safe", when the whole assumption I started with is that this stuff is thread safe? Also, rudeness comes in many form, some of it is underhanded some of it is obvious, there's quite a lot of rudeness here but expressed in a more intelligent and subtle manner.
Creating a remote repository doesn't matter. cargo only looks at the local repository / local clone.
Oops.. reworded. Thanks
Thanks! It seems to me like this is an answer to a different question than the one I'd asked? I'm not sure if this is because (1) you understood my question, but I'm missing a connection and can't see that it's an answer, (2) you understood my question but don't know the full answer, and so provided what information you do know, or (3) we miscommunicated. I know the scheduler will avoid scheduling blocked threads. What I'm wondering is if it could also (in theory) avoid *de*scheduling threads that other threads are blocked *on* (or some other policy with a similar effect).
I come from Windows, where they expect you to do your own damn work. :p Edit: Ha. I remembered talking about this with someone, but I didn't realize it was you. Your writeup this time was a lot more substantial, and probably convincing for a lot of people! Impressive work, in that regard. But seriously, though, I think a big part of my prejudice comes from just not having used system package managers for the vast, vast, vast majority of my existence on planet earth, which makes me feel like keeping my crap up to date is more my job than the system's job. This is probably antithetical to all that is good and right, and probably also incongruent with my thoughts on Windows 10's new autoupdate behavior (which I think is fine), but I'm nothing if not self-contradictory.
I really wish I could distinguish another user's comment :( Or edit the damn title...
Is there a single open source plugin they have where this happens? I'm not aware of one.
Thank you for taking the time to include all of this, by the way.
Hmm, that seems to be the exact same snippet as /u/sellibitze's.
I don't think you should be downvoted for this. The problem with .NET is that it's very much an outgrowth of mid-aughts "OOP all the things" thinking, whereas Unix shells (despite their severe warts) feel more like functional programming. I personally lean toward more FP techniques than OOP, but in a broader sense FP is easier to read when doing complex data manipulation, because it puts the data first. Look at PySpark to see what I'm talking about -- it makes logical sense to process data as a series of FP-style combinators. (That said, I think OOP excels in complex stateful interactions, which is why I think Capn Proto RPC is the best RPC library we have today.) IMO a good middle-ground is a statically-typed `struct`-oriented mechanism for piping data between programs, one that puts the data and its shape at the user's fingertips.
Spotted here: https://marco-c.github.io/2017/07/28/code-coverage-architecture.html &gt; With the standard LCOV, parsing the gcno/gcda files takes minutes as opposed to seconds with grcov (and, if you multiply that by the number of test machines we have, it becomes more than 24 hours vs around 5 minutes).
Ok, so, I am terribly sorry... I don't know why I assumed the function must be marked unsafe, a compiler message might have led me that way :? Anyway, the only block I had to mark as unsafe was basically a line of code in this function: fn get_self(&amp;self) -&gt; &amp;mut MyInternalContainer&lt;T&gt; { unsafe { return &amp;mut *self.internal_queue.get();} } However I have some follow up question, if you have time to enlighten a newbi... since you seem to be the one person in this thread with knowledge of the subject and will to share it: The current implementation means that I can allow the user to read and write to my collection from multiple threads (both of which, in this case, are mutable operations due to the nature of the collection). However there are three problems: a) The user may think this structure is immutable (since he's wrapping it in an Arc) and be confused as to how he is able to do it. Is there a way to make this more obvious to a possible user ? (Outside of the usual documentation, a way to make it obvious in the interface itself) b) The structure is actually mutating itself when I call it's read and write, but obfuscating that for the sake of the compiler. However the structure may have methods which are really immutable (e.g. .peek() and .len())... is there a way to allow for two way to refer to my structure, one mutable and one immutable, in such a way that the user could chose to take an "immutable" version onto one thread and mutable one onto another ? I'm asking because, as far as I know, immutability isn't just for thread safety, knowing something is immutable can help ease reasoning about it in many other situations and can even help with compiler optimization... and at this point, by making my data structure usable on multiple threads, I've also inadvertently removed ALL compiler help, I'd probably be getting better warnings and errors with a c compiler at this point. c) Since this structure is meant to be used within an Arc most of the time (otherwise rust will not allow me to reference it in other threads), should I provide an implementation that returns said Arc directly, or is the user responsible for that ? Also, are thread safe object even a thing in rust nowadays ? Or is the language leaning more towards the functional route of just encouraging people to use everything immutably and relay on communication via channels ?... it seems to me that the later is very slow for a system design language but the former seems awfully hard to implement, so i'm slightly confused :S Also, bonus question, Is there a way to make a thing thread safe as long as a certian number of threads access a certain number of methods at any time (e.g. safe with one writer and multiple readers).
I've read through it. Meh. Sure, once `exa` is in on aur / linuxbrew, I'll install it from there. Till then `cargo install -f foo` is perfectly fine with me.
Well, I didn't know at the time that it had millions of files. An user reported that they had difficulties with that directory, so I went in and had a look. `ls` was the literally first thing I did, my reaction to the result was 'oh, I think I found the problem'.
You said you want to _expose_ a thread safe container, which could easily be about having an unsafe container you want to expose with a thread safe API. Your whole assumption of starting with thread safe stuff is not completely conveyed by those sentences. _You_ know it, but readers may not. To be clear, I'm not faulting you for writing it that way, like I said, communication is hard. But please understand that people may misunderstand your words. &gt; there's quite a lot of rudeness here but expressed in a more intelligent and subtle manner. Flag it then.
Why do you say that? 
There was a term, "SEME" (single-entry multiple-exit) but NLLs don't have to be SEME *shrug*.
In the abstract, I agree with you. That is, I share your philosophical point. But I personally will bend to pragmatism pretty easily. &gt; And if authors of general-use tools written in Rust were sane, they'd do what every other package author does and distribute via the standard system channels: Homebrew, PKGBUILD maybe in the AUR, a .deb and a .rpm either for download or in relevant repositories, so that (a) the executables will go where the system wants them and not have to mangle PATH and add another channel for management, and (b) when you update your system with brew update or aura -Auy or yum update or apt-get update you update THOSE TOOLS AS WELL. &gt; BurntSushi does "I'm the upstream now" correctly. We should all follow this excellent example. The problem with my example is that I didn't actually do all of that work. I got it set up on crates.io, in the AUR (Archlinux User Repository) and in Homebrew. (I don't use a Mac, but so many people around me use a Mac that it seemed like a good tactical move.) But I didn't do anything to get ripgrep into the Archlinux repos, Fedora, Nix, RHEL, Gentoo or Chocolatety. Other people did that, and I'm grateful that they did. But it's not something I'd spend my time doing, not because I don't want to or don't think it's valuable, but because I don't have enough time to do it *and* maintain it. It's just not practical. What I'm trying to say here is that you're stumbling into the classic Worse Is Better vs Do The Right Thing trade-off. Making a binary available for installation using Cargo is essentially trivial, in the sense that it really only requires one to run `cargo publish`, but it's not the "right thing." But you suggest doing the right thing. But doing the right thing is damn expensive. And if I can't afford to do the right thing, should I really still take your advice and "not use cargo install"? Really? Is cloning the repo, `cargo build`ing it, and then `cp`ing the executable really what I should do? No, no, I don't think so. :-) At the end of the day, I do what I can to make software I write available to people. But if I spent my time packaging my software in every Linux distro, I'd never get time to actually work on the software. Even as it stands today, I very much dislike doing releases because they're so much goddamn work. And you want to add *more* work to that? What I'm trying to say is that we can't just tell everyone to do the right thing all the time. We need to also consider the costs of doing the right thing, otherwise the choice ends up becoming "do nothing" or "do the right thing." Instead, we should afford the opportunity for people to do more than nothing, even if it isn't the right thing. (N.B. I suppose I wrote this from the perspective of a maintainer. From the perspective of an end user, I'm not sure what the hub-bub is. What does it matter if I want to use `cargo install`? You can tell me how wrong it is all you want, but if it doesn't bother me, then `¯\_(ツ)_/¯` Hell, I still use `go get` to install my window manager on any new machine I setup. Been doing it for years and it ain't never bitten me.)
/u/DebuggingPanda many thanks for the very insightful information!
Damn fucking it, this new gist-based playground thing is a pain in the ass, I probably copied the URL assuming it had been updated, should be fixed now.
One interesting point I think about C vs Rust and where Rust shines IMO is on the possibility to expose the student to a package manager for example, or have access to a friendly and supportive community and eventually to the open source world as well. This can have a good influence on his/her life/career. But probably a high-level language like Python would be better to introduce someone to programming. For beginners: Python &gt; Rust &gt; C
Symmetry with `match` seems like a good thing, but the symmetry breaks down because we can't destructure `enum`s this way. If we could declare multimethods over enums *a la* Haskell *et al*, it might make a bit more sense. 
Maybe there is an easy way to insert some kind of break points in CPU intensive and relatively long-running task to prevent thread blocking, sort of virtual IO operation which will allow to switch to the next task?
Nice. I will take a look at them. 
Locks are a major source of bugs in interrupt handlers when you develop an OS. It can easily happen that one of the called functions wants to hold a lock and causes a deadlock. Preventing them with the type system is far better than with a documentation that can be overlooked. 
This was also one of my early thoughts but it seems to have too much overhead. This would make four categories of function: those who need an interrupt context, those who should never be called within an interrupt context, those who do not care (like math functions) and those who can be called under any context but need to know if they are called with an interrupt context. The big downside is that there is an extra parameter with zero size. I don't know if the compiler will optimise this parameter away or not but if it is not optimised away it can increase the stack usage noticeable. It would be better to embed this implicit parameter some other way, perhaps with lifetimes. 
Our renderer https://github.com/azerupi/mdBook has epub/pdf output on its roadmap (and I'm also part of that project) so eventually yes very much so :) But for now your best bet is to follow /u/apd suggestion.
&gt; They did a similar thing with the Go plugin It went from free to paid. Still open source and accepting contributions, but both JetBrains and the original author abandoned it iirc. Again, no problem getting paid for work, just not as big of a fan of drawing people in then switching. Why doesn't this blog post address the future wrt cost and whether it will remain open source?
This is actually less of a pointer bug and more of a lifetime bug. You've gone and done a use-after-free, and you're just lucky it manifested as something as harmless and obvious as a zero appearing somewhere obvious. The second for loop consumes `layers_cs`, and the each `CString` it holds is dropped at the end of the block, freeing the underlying memory. But the pointer lives on. Apparently, when that memory is freed, the allocator sets its first byte to zero, for reasons known only to whatever allocator the Playground uses. The code gives the correct answer if you just change the line: `for cs in layers_cs {` to `for cs in &amp;layers_cs {` which lets `layers_cs` outlive `layers_ptrs` and thus keep the underlying data allocated.
&gt; Well, Cargo has an update command that sure doesn't update a thing in ~/.cargo/bin, so maybe Cargo isn't a tool for installing general-use programs. I mean, it's not even a good tool for installing specific-use, Rust-development programs. Until this is fixed, one can use [`cargo install-update`](https://github.com/nabijaczleweli/cargo-update).
My point is that if you treat the interrupt context just like a separate thread, then the `Send`/`Sync` traits will work just fine and will prevent you from causing any race conditions. However, Rust's type system only guarantees memory safety, which doesn't cover deadlocks. So the type system won't help you there. But this isn't any different from "standard" Rust: you can lock the same mutex twice using only safe code and it will deadlock. 
Also: still more informative than Opt-In Builtin Traits!
I didn't realize that you are newbie. The method you wrote is incorrect, because one cause data race by calling `std::mem::swap()` on the mutable reference which you returned. The correct way to implement is writing each *synchronized* method of the `MyContainer` taking `&amp;self` and doing mutation internally. Like this: fn add_item(&amp;self, item: Item) { // implement your method here } fn get_item(&amp;self) -&gt; Item { // implement your method here } So the user would write: let container = Arc::new(MyContainer::new()); container.add_item(item); BTW, if by any chance you have also unsynchronized operations, make them take `&amp;mut self`! &gt; The user may think this structure is immutable (since he's wrapping it in an Arc) and be confused as to how he is able to do it. Yes. The thing is `&amp;MyContainer` reference doesn't actually mean immutable, but *shared*. I can see your worry and indeed, it's confusing for people who don't know Rust so deeply. I don't like this much but I'm not sure if there could be a better alternative. &gt; Is there a way to make this more obvious to a possible user ? The only way to make it obvious is giving the method a name that obviously implies mutation. Like `insert()`. &gt; The structure is actually mutating itself when I call it's read and write, but obfuscating that for the sake of the compiler. As I said, the compiler knows whether something is really immutable and when `&amp;T` means only "shared". The way for it to distinguish those cases is `UnsafeCell`. The rules are simple: everything accessed through `&amp;T` reference is considered immutable except for anything wrapped in `UnsafeCell`. The compiler relies on this - this is why I wrote that `UnsafeCell` is absolutely necessary. To be more clear, an example: struct Foo { a: usize, b: UnsafeCell&lt;u32&gt;, } In case of this simple structure, compiler knows that the content of `Foo::b` can be mutably aliased and so even in case of `&amp;Foo` it won't perform optimizations, that would be valid for immutable data but invalid for mutable. In other words, if compiler sees `&amp;Foo`, it knows that `a` can't change and `b` can. Is that more clear now? &gt; However the structure may have methods which are really immutable (e.g. .peek() and .len())... is there a way to allow for two way to refer to my structure, one mutable and one immutable, in such a way that the user could chose to take an "immutable" version onto one thread and mutable one onto another ? I'm not sure what would be the purpose. If you share data you need to use shared reference (`&amp;MyContainer`) or `Arc&lt;MyContainer&gt;`. If you don't, you can use `&amp;mut MyContainer`, but then thread-safety of that thing is not necessary. Also, as I said, if your structure has several fields some of them are always immutable behind shared reference, just don't wrap those fields in `UnsafeCell` (you will allow more optimizations by it). &gt; I'm asking because, as far as I know, immutability isn't just for thread safety, knowing something is immutable can help ease reasoning about it in many other situations and can even help with compiler optimization... Yes, unfortunately, Rust doesn't have "truly immutable references". It'd be an awesome thing if it did (I have an interesting use case for them too!) but I'm not sure how many people would want it. &gt; and at this point, by making my data structure usable on multiple threads, I've also inadvertently removed ALL compiler help, I'd probably be getting better warnings and errors with a c compiler at this point. If you screwed up and your container isn't actually thread safe, you have a problem regardless of the language. Rust is still more helpful than C, because it will disallow doing unsynchronized operations. &gt; Since this structure is meant to be used within an Arc most of the time (otherwise rust will not allow me to reference it in other threads), should I provide an implementation that returns said Arc directly, or is the user responsible for that ? I'd suggest *not* returning `Arc` because there is at least one other way to share the data (scoped threads) and new ways might appear in the future (e.g. `Gc&lt;T&gt;`). Allowing user to choose what he needs is the most flexible approach. &gt; Also, are thread safe object even a thing in rust nowadays ? I'm not sure what do you mean. There are thread safe primitives like `Mutex`, `RwLock`, `AtomicUsize` (that one uses atomic operations instead of locks), channels... &gt; Or is the language leaning more towards the functional route of just encouraging people to use everything immutably and relay on communication via channels ? AFAIK the language isn't opinionated on this. I'd even safe, it prefers flexibility. If you compare several languages: * C(++) allows you anything but without safety checks * Go encourages channels * Functional languages encourage immutability * Rust figured out a way to allow (almost) anything safely - that's the main point of Rust So you really should select between them based on what fits you the best. Unless you need your own container, you don't have to worry about data races - the compiler prevents them. BTW, usually when implementing some type, you shouldn't give it mutex only to make it thread safe. You should make thread unsafe version. Users can do `Mutex&lt;YourType&gt;` to get thread safe version if they even need it. I think this is great strength of Rust. &gt; Also, bonus question, Is there a way to make a thing thread safe as long as a certian number of threads access a certain number of methods at any time (e.g. safe with one writer and multiple readers). Yes, take a look at [`std::sync::mpsc`](https://doc.rust-lang.org/std/sync/mpsc/) (It's the opposite of your example, of course.)
:D Why they are even called "Opt-In"? They feel more like "Opt-Out" to me. They are implemented by default and users opt-out from them by writing `impl !Trait for T`.
Zero-sized types are optimized-away in Rust (they are not 1B big as in case of C). That being said, *references* to ZST are kept unless things are inlined. I've seen many cases where people (ab)use this, so I wouldn't worry about it. I'd agree the code would probably get harder to write.
By the way, have you seen [Vulkano](https://github.com/vulkano-rs/vulkano)? It wraps up the Vulkan API so you don't have to put `unsafe`s everywhere you use it, also making it a bit nicer to use
Fun fact: They build the Turbo version (which could go up to 88mph) first. Well, first from their perspective.
It's a ways away from something sellable.
They aren't opt-in, they aren't built-in. They are traits. one for three. Lots of people are calling them "auto traits" nowadays.
Hmm, Complexly scoped lifetimes? 
So, AFAIK, we can't destructure `enum` values right now anyway, right? At this point, the purpose of this proposal would be to enhance `struct` destructuring in `fn` args, so...that seems orthogonal. Am I missing something?
thx
Thanks. Will try it out first thing in the morning.
Yes. I'm using vk-sys.rs. It's too advanced for my purposes. I'm learning...
Took F# 10 years to get that far.
Oh. I didn't realize that. Thank you.
Localhost could be 127.0.0.1 (IPv4 address) or ::1 (IPv6). I'm guessing Rocket used one and your browser/curl used the other. Not sure.
Sorry... might have been helpful to mentioned, I had worked with Rust a bit in the past (a few months ago) but then life took over and I only really got past the "hello world" and setup part and into coding in it like 1-2 days ago. I'm thinking I might need to get a few books if I want to stick to it... currently it seems to have a lot of pitfalls compared to C and C++, but I assume some may be avoided with best practices. &gt; fn get_self(&amp;self) -&gt; &amp;mut MyInternalContainer&lt;T&gt; { &gt; unsafe { return &amp;mut *self.internal_queue.get();} &gt; } Was the code I intended to write... which is what I used inside "MyContainer" to access the internal object wrapped in an unsafe cell. Does that call 'std::mem::swap()' ? I assumed it just returned a reference to the internal data member. Also, I can't find this on the internet, but is the '.get()' on the unsafe cell atomic :P ? And also, onto your point with mutexed, I agree there are some usecases where you could just wrap container in mutexes. However shared state might require a synchronization mechanism specific to the problem you are solving... at least that's the way I always though about it. A few examples that come to mind would be: -&gt; real-time shared state -&gt; shared state on devices without a fancy kernel (e.g. with a bad scheduler... or without a scheduler at all :P) -&gt; shared state on devices with expensive cas atomic opeartions and expensive seq_cst memory ordering -&gt; shared state in a program that is required to have either low cpu or syscall footprint -&gt; efficient shared (e.g. when you are transferring large amount of data or when based on the state of the program you can change access mechanisms to your container) -&gt; shared state in exception free environments ... you get the point, I'm spoiled with working on x64 and working on things that are concurrent but not rt, so I don't have that much experience with this\ In my specific example I am working on a lock-free queue (or circular buffer, or ring buffer, or fifo container or w/e other aliases are bestowed upon this data structure).
If a non-`Sync` type uses `Rc&lt;RefCell&lt;&gt;&gt;` internally should it be safe to implement `Send` for that type if those `Rc`s are never accesible externally? Or would it depend on something else?
Oh, so if I understood correctly, the question is: Can we signal to the OS that the current thread is in a critical section and the scheduler should avoid descheduling it until we exit the critical section? Well, I couldn't find a satisfying answer to that question on the internet. There most probably *is* an OS-specific system call that signals something like it, but isn't worth the hassle and is not a portable solution. I'm definitely interested if someone knows more about this.
I'm going to link to [an older comment of mine that has numbers on this](https://news.ycombinator.com/item?id=13227907), Firefox supports more CSS than Chrome (at the time of writing of that comment -- Chrome may have more now but the point is that it will be approximately at the same level). It usually also supports approximately the same JS features. A big missing one is custom elements (which is a feature Chrome has had forever because Google wanted it, but an implementation is in the works). The closest thing to the "new IE" in that regard might be Safari, since Safari is very cautious about adding new features.
I'm new to systems programming so pardon the noob question, but what is benefit of declaring and implementing a trait if you have to enumerate the trait's behavior again in the implementation? IE the example in the 2nd edition rust book defines the 'summarizable' trait with this code: &amp;nbsp; pub trait Summarizable { fn summary(&amp;self) -&gt; String; } &amp;nbsp; And then when you declare "impl summarizable for NewsArticle", you still have to include: fn summary(&amp;self) -&gt; String { As the first line of the implementation. I'm curious what the benefit of this is over just declaring the NewsArticle struct and then a method of: &amp;nbsp; impl NewsArticle { fn summarize(&amp;self) -&gt; String { function body 
I'd give it 0.5 -- you don't even do anything to the trait declaration. You just write a weird `impl`: https://doc.rust-lang.org/src/core/marker.rs.html#49
This is news to me since Gogland (a stand alone IDE) appeared on my toolbox and it is now at EAP11. I've used it some. I just hadn't had time to do some serious Go programming. The Go plugin which has the same features as Gogland was updated about a week ago. https://www.jetbrains.com/go/
Let us not speak of my earlier dumbassery (I blame staying up later than I should), but [this](https://godbolt.org/g/5nq42C) code with a bool vectorised, didn't it?
&gt; I don't want Firefox to become Opera Though grabbing some of their features would be welcome.
This actually looks nice. Personally, editing the Cargo.toml to bump a number isn't a big deal, but that tool looks like it'll bump, commit and push for your.
Did you post the wrong link? I don't see any vector ops in the asm for the example you posted?
1) do you know how can I switch to the code in Glade? 2) why won't it launch the window when I click the button "run" in Glade, any idea?
I don't think flow sensitivity is what sets them apart. Liveness based lifetimes (LBL), might be close, but I don't think that is really more helpful to most people.
This crate was written with analyzing scripts in mind, so you should be able to extract as much or as little metadata as you'd like! However, with shell specific features/constructs, YMMV. For example something like a bash local var will probably get parsed as a regular command and you'll have to recognize it as such (e.g. attach meaning to the word `local`). But for something like `[[ foo &amp;&amp; bar]]` it not handled correctly right now. Feel free to open an issue if you run into any problems, though!
My apologies, that should have been [this](https://godbolt.org/g/3sGtLW) link. Not sure what happened there. If *that* failed, I zipped two iterators together, and then did a fold with the initial accumulator being `true`. Each step of the fold does `acc &amp; (a == b)`.
This is a *really* important RFC that has not been getting enough attention. It greatly expands where you can use `impl Trait`, making it possible to use within trait implementations.
JetBrains announcing official support for a this new up-and-coming language is the biggest boost I think Rust could have gotten in the inner circles of tech. The only thing that could surpass it would be Apple, Facebook or Google picking it up for internal use in a public way. 
I agree, while reading that tirade I also was agreeing with the philosophical idea in my head. Cargo is a great tool, but it's being misused quite a bit. With that said I absolutely do **not** have the time to package Way Cooler beyond what I have right now which is (in order of how unlikely I am to forget to update it): 1) through the [website](way-cooler.org/download) (and yes I do the rustup way, and yes it's bad because I don't even use ssl because github pages won't let me and yes I assume you are on a x86_64 system. 2) AUR 3) crates.io These are all bad (either they are insecure or they target only a subset of potential users), but it's the easiest way to get my code on the most amount of people's computers with the least amount of effort from both of us. Maybe I'll look into app images or something, but the point is it's really hard to package your code. 
Can't you just use a shell glob though? Sure it's one more character, but I never complain when my shell exhibits consist behavior with how I think the tool should be used (eg concatenate files) 
Good to hear. The main bash extension I need to handle is `declare -r FOO="bar"`. As for `[[` and `]]`, the closest I come is the occasional script I don't anticipate needing to parse which uses `if [[ -n "$LD_LIBRARY_PATH" ]]; then`
Bloodhound looks nice, I spent some time thinking about providing a Query DSL in terms of data structures instead of a fluent API for an F# client before. I think it would work nicely. I think it's an approach that would work very nicely in Rust too.
https://github.com/tokio-rs/tokio-proto/issues/163 is one I can think of. Literally makes it impossible to create a unix socket program without having a race condition between the check of the existence of the file and creating it. TOCTOU issues aren't fun. 
I want to swap `range[i]`, and `min(range[i+1 .. ])` in place. How would one achieve this? use std::mem::swap; use std::iter; fn main() { let mut arr: [i32; 7] = [33, 93, 28,16 , 832, 8, 12]; print_arr(&amp;arr); sort_arr(&amp;mut arr); print_arr(&amp;arr); } fn print_arr(range: &amp;[i32]) { println!(""); for i in range.iter() { print!("{} ", i); } println!(""); } fn sort_arr(range: &amp;mut [i32]) { for i in 0 .. range.len() - 1 { swap(range[i], (range[i+1 .. ]).min()); //all hell breaks loose } }
Just a question, if I just wanted to use a JetBrains IDE for Rust, which one should I choose? Intellij IDEA? Maybe CLion? I know in the end they are all almost the same IntelliJ IDE with different plugins, but I don't know, couldn't care less about Java. Also, if I have Android Studio, would be reasonable to use this plugin? Would I have to do a lot of things to get a Rust project started?
It's less about systems programming and more about types/OOP. You define the trait as a generic interface, which provides the contract, then you implement its features in each type that implements it. If all you want is for NewsArticle to have the summarize() function, just do that. Creating the trait lets you have multiple types implement it with a common interface.
&gt; I bet you're sat there thinking "you're wrong for wanting this". No, complete opposite actually: you are correct for wanting it, but my point is it isn't a new feature. As far as I can tell, Rust already behaves exactly how you want it, but actually with even less syntax. You say &gt; Imagine if you could just write `fn outer(s:&amp;'temp str , inner: fn(&amp;'temp str)-&gt;Y, other_context:Z) -&gt; X` But Rust currently lets you write: fn outer(s:&amp;str , inner: fn(&amp;str)-&gt;Y, other_context:Z) -&gt; X and both the `&amp;str`s have an anonymous lifetime inserted that is behaves like the "shortest/non-escaping lifetime" you're proposing, equivalent to the `'a`/`for&lt;'b&gt;` version. This all translates into things like &gt; What would be the outcome of making all &amp; function input parameters actually default to a 'temp lifetime &gt; My own default expectation from getting things working in C++ is you don't have to worry about references input to functions at all All being true today, in Rust.
I've already answered this on IRC, but here it is again for posterity: https://play.rust-lang.org/?gist=2a5acad5c5c9b4ba06dfcd4e299ed06b&amp;version=stable
/r/playrust
Shell languages need to be concise, even at the cost of readability. If I want a verbose shell language, I may as well just use Python.
I get that. I say there's little to no factual basis for that. I would be happy to hear more detailed arguments as to why.
What does this mean for the Rust Language Server?
Yes, because it had Visual Studio. Rust does not have an "official" IDE
So basically jetbrains IDEs are all the same just with different preloaded plugins. If you don't want to pay for it, just get IntelliJ CE and install the rust plugin. If you already use another one of their IDEs, just install the rust plugin on that.
It isn't going anywhere. I expect the language server platform to be the dominant way to integrate language support in he future, with so many languages getting support, even the clang project is working on one for C/C++.
why not?
I disagree. First time hearing about non lexical lifetimes I finally figured out why we have to specify lifetimes. The book originally honestly did a poor job of explaining why they are necessary and it was the reason I did not understand them.
&gt; After that you can zip up the contents of the /wherever/release folder and distribute it. Is there some tutorial for generating .msi files? From a Google search I can find that GNOME has [msitools](https://github.com/GNOME/msitools) and it doesn't even run on Windows, so it seems appropriate to use it to package a Windows GTK application on Linux.
My understanding is that current NLL proposal is indeed *not* SEME. Am I right?
While unknown to most programmers, there is established usage of what "flow sensitive" means in academia. According to that usage, Rust lifetime is already flow sensitive, will be path sensitive when NLL is done, and will not be context sensitive (interprocedural).
In general, the plugin works better in IntelliJ IDEA. CLion lacks a couple of minor features (see [this issue](https://github.com/intellij-rust/intellij-rust/issues/1108)). But the debugger is only available in CLion at the moment, because it has the LLDB/GDB infrastructure (a bit of usable information is [here](https://github.com/intellij-rust/intellij-rust/issues/535#issuecomment-278636971)). I can't say about Android Studio, but getting a Rust project started with the plugin is usually quite easy. You might want to have a look at the [Quick Start Guide](https://intellij-rust.github.io/docs/quick-start.html).
Ah. I might have picked the wrong term. I almost went with path but I know that gets used to talk about nested structure. But...I mostly wanted to get people thinking about better terminology not propose anything specific.
1) Glade is just for making the interface, as far as I know you need to edit the code in a separate editor or IDE 2) Not sure if I have a different version of glade, but I don't have a run button. If you right click the GtkWindow on the widget list (the right hand panel), there should be an option "Preview snapshot". That should show you what the window will look like, but it won't have any code associated with it.
Had to dig around a bit, I found [this](https://wiki.gnome.org/msitools/HowTo/CreateMSI). It explains the process ok, but not where files should go or anything like that.
Since we only have to deal with panics which comes with backtrace, and (almost) never a segmentation fault.
Do you foresee an IntelliJ RLS-based plugin, or does this mean that JetBrains is more likely to stay on the bespoke route?
Cool :) I feel almost excited about releasing some GTK program in Windows, even though I have no interest in Windows nor (non-web) GUI. Lol
All my friends and co-workers use windows or mac, so that's why I figured out the process in the first place. Wish we could cross compile to mac too. Need to get OSX in a VM and build there now.
What's the issue with cross-compiling to mac?
Do `exa -TL2` to limit recursion depth for now. (Personally, I use `alias tree='exa -lTL2'`)
You get linking errors https://github.com/rust-lang-nursery/rustup.rs/issues/462 Haven't tried it myself though, maybe it's fixed since then? edit: may be able to hook in this https://github.com/tpoechtrager/osxcross as the linker...if I have spare time I might play around with it. Got the mac VM installing now though, seems easier
It's beautiful 😍
even with stack traces debuggers are super useful. I guess i'm just a wuss
Is it even faster than the current beta (v55)? (Context: I had switched from FF to Chromium a year back or so for faster startup time, but after the recent post about FF's improved startup time, I switched back to FF with 55beta and had great experience with it!! So is it really gonna get even faster by 57?)
No, I was just saying, the first step of debugging -- to figure out the point of crash -- no longer needs a debugger. (And I'm too lazy to learn and do advanced stuff with a debugger like running programs backwards.)
&gt; The Go plugin which has the same features as Gogland was updated about a week ago. Not the open source, forever free version. See the README on https://github.com/go-lang-plugin-org/go-lang-idea-plugin. From your link (emphasis mine): &gt; Gogland is the codename for a new **commercial** IDE It may be free during EAP, but it is not free. They abandoned the free one and sucked it up into the upcoming commercial one (or only as a plugin to another commercial product). Ask yourself: Why doesn't this blog post answer the obvious question of the open source and free future of the existing plugin? You can juxtapose this blog post w/ the one for the Go plugin at https://blog.jetbrains.com/go/2016/12/15/announcing-gogland-brand-new-go-ide-from-jetbrains/. You will see a lot of similar wording, and it foretold the abandonment of that open source one. Why is it so tough to see this has happened before and very well might happen again?
Rust is an amazing language for sure. I can't wait to see what others build with it in the next decade. ;)
I've been having trouble finding recent resources regarding impl Trait. Knowing little to nothing, many of the recent RFC's associated with impl Trait seem quite foreign to me. Right now I'm looking at [RFC #1522](https://github.com/rust-lang/rfcs/pull/1522), and its listed resources [here](http://aturon.github.io/blog/2015/09/28/impl-trait/) and [here](https://github.com/rust-lang/rfcs/pull/1305). These does seem _relatively old_ in regards to the feature and the over all age of the language. Could someone point me to a resource explaining the impl Trait feature? Additionally, my current personal understanding (or lack of understanding) leads me to the following. I don't quite see whether this is syntaxtic sugar for some sort of generic type, or if its allowing `fn() -&gt; Box&lt;MyTrait&gt;` without the box, or something regarding static/dynamic dispatch internally, or if its something entirely different!
YMMV, but broadly speaking: yes it is faster.
lazy capture lifetimes
Can't the original developers just continue developing the last released open source version? If yes, then in what way is this worse than if there was no involvement from JetBrains at all? If you are going to argue that because they offered a superior product and thus the original developer lost interest, then how is that JetBrains fault? If the original developer believes that it is no longer worthwhile to develop the open source version, you can still use the last version that he published. Nothing is "removed" here, except perhaps pressure to develop the free version because most people can afford the paid one.
I'm imagining the models on https://www.redox-os.org/screens/ are worth looking at
One of the major points for me is that Rust is pretty much unique. There are others with similar feature sets, but if you're looking for the same, particular combination of attributes, you're pretty much out of luck. Going to something else entails *some* kind of compromise in one area or another. So, even if it doesn't always scratch the itch I'm having, there's the itches that can only be scratched by Rust.
Tough choice for the playrust classifier.
(Unless it looks at user history.)
[removed]
I'm impressed that your answer is valid regardless of whether OP was talking about the game or the language.
Wrong subreddit. You want /r/playrust. Might want to check before posting next time :)
What about factoring writing style into it? That's the only thing I found out of place.
I'm sure I don't know what you're talking about... [\**whistles*\*](http://i.imgur.com/4xlhjrb.jpg)
Gotcha! ;)
Am I not the only one finding the lack of capitalization jarring then?
Who said anything about crashes, though? Logical bugs are a thing too, and debuggers can be damned useful for those. Plus, I'm a big fan of exploratory debugging as a way to learn how a system works.
Well the whole concept behind language servers is that it is a universal interface. And editor/IDE should only support the protocol, and then the language should only support the server. Now IntelliJ may go a bit beyond the functionality available in the protocol as it currently stands, so either the protocol will have to be further expanded or IntelliJ will have to continue to custom-write their features on top of LSP. I think LSP-only mode in IntelliJ is a few years out yet if it will ever happen.
[Ask and you shall receive](https://github.com/facebookexperimental/mononoke).
AIUI, Jetbrains are quite prone to rolling their own stuff (I'd call it a bad case of NIH syndrome, but it does seem to work quite well for them, so... **shrug**).
I have similar experience. Rust gives me the same feeling of excitement and joy when I make something I had when I fist started programming. 
Why ? What is the benefit of Rust compared to other languages you know/use ?
[removed]
Interestingly my example vectorizes if you use a while loop like so: https://godbolt.org/g/W8PefS (the macro is unnecessary, but may make writing loops like this somewhat less painful). I guess this just goes to show rust's vectorization is somewhat inconsistent/unreliable.
&gt; allowing `fn() -&gt; Box&lt;MyTrait&gt;` without the box That's correct. `impl Foo` means "a type where all you can assume about it is that it implements the `Foo` trait". Generally it's used in function return position, in which case it differs from a generic type in that it is _always_ the same concrete type, the caller just won't know what that concrete type is. In argument position, it's a generic type. If you haven't already read the second RFC in the series, that one is very well written and should help you understand it better: https://github.com/rust-lang/rfcs/pull/1951
&gt; currently it seems to have a lot of pitfalls compared to C and C++, but I assume some may be avoided with best practices. Certainly not. Safe Rust is infinitely better than C. `unsafe` Rust may seem to be similar to C, but it's still safer, because you can't e.g. break borrowck rules. The only additional things you can do with `unsafe` are calling foreign functions, dereference pointers and write to global mutable variables. &gt; which is what I used inside "MyContainer" to access the internal object wrapped in an unsafe cell. If you did it as private method, it should be fine. Although, it might be confusing to those rustceans who would expect `unsafe` block (making the function `unsafe`). &gt; Does that call 'std::mem::swap()' ? I must have been unclear. It doesn't call `swap` but `swap` is an example of function that would break safety if you write `fn get_self(&amp;self) -&gt; &amp;mut MyInternalContainer&lt;T&gt;` without synchronization inside that function. You should write all your APIs in such way that using them incorrectly is impossible. If you can't (don't want to) do that, you should mark your functions `unsafe` Calling `std::mem::swap(container1.get_self(), container2.get_self())` is certainly wrong, because the memory is shared and there is no synchronization inside `get_self`. &gt; Also, I can't find this on the internet, but is the '.get()' on the unsafe cell atomic :P ? That's similar to asking whether `let a = &amp;b;` is atomic. There is no way for it to not be. `.get()` only returns mutable pointer to internal data. &gt; However shared state might require a synchronization mechanism specific to the problem you are solving... Of course. Then the correct approach is to write appropriate synchronization primitives, if they don't exist already. &gt; shared state on devices with expensive cas atomic opeartions and expensive seq_cst memory ordering How would you make operations atomic in this case?
Not the OP, but Rust really gave me a huge motivation boost once I started to become productive. It's a very expressive language that I find fun to work in, and the end result always seems to be incredibly satisfying in terms of quality and performance. The tooling is maturing really well too, ergonomics seem to get better on what seems to be almost a weekly basis. 
How about "non lexical borrows"?
oooooh should have kept it going :D
Not in general, no. The `Rc` being internal to the type doesn't change anything substantial. The code in the type's own `impl` has access to the `Rc`, and that code will potentially run on different threads if the type is `Send`. So if you clone the value and then `Send` it to another thread, both threads will have simultaneous access to clones of the same `Rc`, which is undefined behaviour. For example: if both values `Drop` at the same time, then both threads might see the `Rc`-count go to zero, and both threads might `Drop` the contents of the `RefCell`. And double-`Drop` is segfault territory. It *could* be fine if you never clone the `Rc` (since `RefCell` is `Send`), but then I'd just go with `Box` instead (since `Box` is essentially an uncloneable `Rc`). It could also work if have a `Mutex` in there somewhere, but then I'd just go with `Arc` instead. 
So if it's not `Clone` or `Sync` it's probably okay to be `Send` (or wrapped in a `Send` type)? I can't change the code unfortunately as I'm trying to use existing code (specifically ncollide's `CollisionWorld` with specs).
While Rust is very interesting and fun, the compile speed and lack of resources have made it a little bit less productive. I like Rust very much, but I found it takes a good amount of time to fight with borrow/type checker.
The Rust compiler prevents a huge amount of really annoying and difficult bugs that plague lots of other languages. Thus it makes working with Rust code much nicer compared to other languages. The code comes out nice and readable*, the error handling is very good. * Unless you use Tokio, which I believe is cancer and the Rust community is shooting itself in the foot with.
&gt; Logical bugs are a thing too, and debuggers can be damned useful for those. That may be true, but I always try to make logical bugs into panics by extensively asserting invariants. So pinpointing the location of a crash usually allows me to easily track down the bug.
&gt; It's a very expressive language that I find fun to work in, and the end result always seems to be incredibly studying in terms of quality and performance. I am glad to hear it. I see on myself, as well, that more expressive languages give more joy in practice. I am just wondering what is the advantage of Rust over other languages with high expressiveness (like Python, Haskell, Scala etc.). I've seen opinions like:"first place for most loved programming language on StackOverflow" and I am curious what distinguishes Rust from other languages in term of expressiveness. Finally I will have to try it. 
I disagree. You can use custom aliases to make using your shell easier - but in scripts, it's gotta be verbose. Split it over multiple lines if you have a long pipe going, no problem. I'll even have the `Param ( )` block at the beginning of all my scripts. ValidateSets, optional parameters as well as default states for switches - it's all so easy to do and immediately apparent when you open someones script.
This seems the most logical, but as I said earlier, this only really matters until they are implemented since afterward it will just be "that's how borrow works". I don't see the need for an adjective when there's a single sort.
I'm surprised you don't feel the need to use a debugger more considering the long compile times. Printf debugging is painful when an incremental build is any longer than 10 seconds.
Error handling is a bit iffy in my opinion, errors are very hard to debug (especially if you `?`ed them)
&gt; (like Python, Haskell, Scala etc.) Rust does not have a GC and runs at C speeds.
That it is this way yet runs incredibly fast, and, with the exception of (mostly) Haskell, also prevents entire classes of potential bugs in the process. Even better, it gets you thinking properly about lifetimes of logic and data, and you start applying this thought process to when you're writing in other languages too, so even when you're not actually using it, Rust has your back.
On the plus side, however, you can spend considerably less time in the debugger :) trade-off. If it compiles, it usually works.
Link is dead already.
What's wrong with Tokio?
For one, it makes non-blocking code look completely different from "normal" blocking code. Stackful coroutines + a runtime wouldn't.
I've got property value precedence working, so you can explicitly set values in the RSX markup and have it override the default style for a component [here's another screenshot](http://imgur.com/a/FsXPG) I'm going to implement a text component today hopefully before starting work on feeding input events into the system 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) https://i.imgur.com/3xajNmP.png ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dl77zo3) 
Can I use Rust to program AVR/Arduino yet? I did some searching and saw progress was being made a few months ago, but I'm a little confused as to the current state of things.
It's an overly complicated solution to a difficult problem. The reason I called it cancer is it forces everything to confirm to its structure and restrictions. A tokio project has tokio/futures in practically every file. It's a framework when it should be a library. I find Tokio projects unreadable and from what little I worked with it, ugly as hell to work with. Difficult problems do not have to have complicated solutions if they are fixed at the right abstraction level. Tokio is built by Rust core devs from what I see, they should have spent that time on a language level solution to futures (i.e. await). 
I haven't, but I think I know what's wrong just by looking at the Neon API docs. I've responded on the StackOverflow answer. **TL;DR:** It looks like you're accidentally calling `Handle&lt;JsArray&gt;::set` when you mean to call `JsArray::set`. You need to force a `deref_mut` to occur.
I find also that recently the error messages are very instructive compared to many other languages. Very often the compiler will suggest you how to fix your code with messages such as "consider adding mut here" or "possible candidates are...". Quite often you can debug your code without leaving the command prompt. For example matching on an enum of variants that contain boxed content can tell you (through baby steps) to match on EnumVariant1(box ref mut content ) =&gt;... When you initially tried to mutable use content with ContentType(box content) =&gt;... 
I think it's that I like the way the code looks and reads, and, coming from the world of dynamically typed languages, I've found that I really like statically typed languages because I don't need to go rummaging around to find what the types are for function arguments. And finally, and probably most importantly for me, theres a sense that it can truly be used for anything, whereas in python that isn't quite the case. 
What? I think Rust's error handling is very good. In some cases better debugging support could help tracing them, but very often it is easy to find the cause. What I like most about is how robust it makes my program (as opposed to exceptions, which you can easily forget to handle).
Did you try `cargo check`?
Setting the first byte to zero is actually a [feature of cstring](https://github.com/rust-lang/rust/blob/master/src/libstd/ffi/c_str.rs#L502). 
I use RLS and I already get the error in realtime. However, I'm doing TDD and it's frustrating to get a future-heavy project compiled (it takes 20s, even for debug). BTW, I already have incremental enabled. That doesn't help much.
That's all fine and good, until you start writing code where the type system is of little help (e.g. game logic). Waiting around for 30 seconds each time you make a slight tweak is not fun. You can of course offset some of this by having hotloaded tweak files for all your parameters, but at some point that becomes unviable, because you want to change actual logic rather than just parameters.
I see. One thing you could try is to turn on release mode together with incremental compilation; it is sometimes faster than incremental compilatoin in debug mode.
Really? Wow, that's quite nice.
The point (brought up in a number of Reddit and internals threads) is that the RLS as exists is not a good fit for full-featured IDEs. The developer of KDevelop decided not to use RLS either.
 fn do_some_io_stuff() -&gt; io::Result&lt;()&gt; { io_foo()?; io_bar()?; Ok(()) } The function returns an `Err`. Where did it come from?
How is that question any more difficult to answer in Rust than in another language?
Depends on the error. If it says "foo not found" from `io_foo()`, if it says "no permission to access bar" from `io_bar()`. It is obvious in most cases, in some a debugger or a simple println is necessary. But in case you don't get enough information, your errors are probably poor because errors should allow to actually find out the cause (even without source code).
for me, yup, especially with stylo enabled
You are assuming the error carries data about the action that failed, however that is not always the case.
In python and java for example you have stack traces so you know what line that error was created at.
*Only if you are the sole owner of the `Rc`.* The whole point of `Rc` is to have several owners of an object, and those other owners are going to assume that you never touch the reference counter from another thread. If you *do* touch it from another thread you're violating the contract of the API, which has undefined behaviour. What you probably should do is obtain a `&amp;T` or `&amp;mut T` to the object inside the `Rc&lt;RefCell&lt;T&gt;&gt;`, and then send that across to another thread instead. Or clone the `T` and send that. This way neither the reference counter nor the ref guard are ever accessed from the other thread. But sure, if you're the sole owner, i.e. if `.strong_count() == 1` and `.weak_count() == 0`, and the `T` itself is `Send`, and the internal implementation of `Rc` hasn't changed since I last read the code, and you never clone the `Rc`, then it should be safe. That's a pretty tall order though, so I wouldn't get my hopes up. 
&gt; which I believe is cancer Could we not please
Yeah, something like that. (To be honest I wasn't sure that the scheduler *doesn't already know* which threads are in a critical section, but after thinking about it for a moment (e.g. in `parking_lot` locks/unlocks are just an atomic compare-and-exchange in the basic case, IIRC) it's obvious that it doesn't, or at least, the kernel scheduler doesn't. Maybe in a user space M:N green-threads implementation (e.g. for a language runtime) the scheduler and locking primitives might be implemented cooperatively to know about each other?) The other idea was that the timeslices of blocked threads could be allocated to the threads they are blocked on, in their stead, (conceptually the blocked thread would "donate its slice to the thread it's waiting on, so that thread can finish faster and the blocked thread can get back to work"), though if it's the cost of context switching itself that's problematic, then I'm not sure if this would help. Anyway, if I run into someone with scheduler expertise I might ask them about it :)
I recently converted a JavaScript project from promises to async/await. The difference in readability is staggering. I am not closely familiar with Tokio, though I've read a bunch of code examples and documentation. I don't know if makes the same mistakes as JavaScript with regard to error propagation, for example (which is hard to get right). From what I can tell, while it's very powerful, it's also fairly invasive, and requires a similar kind of chaining you'd do in JavaScript land, which cannot possibly increase readability. From what I can tell from discussions, async/await is actually coming to Rust, though. It would go a long way to solving the readability problem.
Any language's syntactical shortcomings can be solved by aliasing. The main reason to use Bash scripts over Python is portability. Sticking PowerShell on random boxes isn't going to solve that problem any better. And if you're not writing scripts, verbosity is a obstacle, not a comfort. So my point stands: PowerShell offers nothing that the existing combination of Bash + Python doesn't already do. Save for the hassle of installing it and learning it, which I'd rather not bother with for such a utility feature.
In that case you should improve your errors ;)
To be fair, I'd rather them develop a sub-par Tokio and figure out what Rust async code really needs to do rather than prematurely jumping into async/await designs that may not be suitable to their purpose or to Rust's std library .
PowerShell offers an extensive ecosystem of Modules and Snapins, all intercompatible because they produce easily machine-parsable Objects. See for example the [Citrix Snapin](https://support.citrix.com/article/CTX128057). The standardized verb+noun syntax and always available `Get-Help` and `Get-Member` cmdlets mean you'll always know how to use a new module right away. Python is fun but it's not as flexible as having the best of both worlds available right when you press `Ctrl Alt T`. Besides, you still have to install it first - whereas every system will ship with a shell. Windows already defaults all of its users to PS and imo so should BSD/Linux ... even macOS actually, although I don't care much abouut it. bash and python are also under GPLv3+ and PSFL respectively, both of which are more restrictive than MIT. You can also still use PowerShell and Python together. I'm just saying it's time to ditch bash and other string-piping shells already! 
&gt;Of course. Then the correct approach is to write appropriate synchronization primitives, if they don't exist already. &gt;How would you make operations atomic in this case? What I'm referring to is devices (e.g. ARM/Itanium architecture) on which sequential atomic operations are prohibitively more expensive and/or on which some atomic operations (e.g. strong comapre exchange or ce in general) are expensive thus making mutexes more problematic than they would be on x86-64. I'm not talking about not having atomic operation but about sticking to atomic fetch_modify or atomic store/load and using relaxed or non-sequential consistent memory ordering as much as possible. 
This is the [game](https://play.rust-lang.org/) we play here. I think ur looking for /r/playrust/
[removed]
How do you expect regular users to improve their errors when even `std::io`'s errors don't carry the filename that failed the operation? Also, that's not all the information that I need. I also might want to know what line that error occurred which I cannot do with `Result` which is my biggest problem with Rust's errors.
I disagree. Because everything is being written on top of a bad platform. Hyper, Trust-dns, database drivers, etc. is all being commonly written/ported for Tokio. The longer this madness persists the more we are stuck with it.
This doesn't talk about Rust directly, but I thought it is relevant, since Rust features zero-cost abstractions. Also, I recently noticed that some of the featured projects in the Rust community provide "leaky" abstractions (to used the term from the article). We should think about this issue and how to fix it.
To further sanity check this suggestion, with type parameters it looks like this: fn point_x&lt;T&gt;(Point::&lt;T&gt; { x, .. }) -&gt; T { x } This is the syntax that matches what you can type in a `match`, so it's not using type syntax but one of the other path syntaxes.
[removed]
Re-running with `RUST_BACKTRACE=1` does the same.
It starts from the point you panic, not from the point the error was created
Tokio is not simple, that's for sure, but I don't think it should be. Futures and Tokio by extension make extensive use of combinators like those found in Iterator. If you're comfortable with the concepts of Iterator, I generally find the same patterns applicable to the Futures library. I personally love the encapsulation of state machines in Tokio, with minimal overhead in maintaining them. It's a well thought out answer to a complex problem. What it's abstracting away is the complexity around registering for events, and then the method for dealing with those events, I believe the correct tradeoffs were made here. Anyone who's used mio or similar asyncio libraries immediately recognizes the benefits of tracking state of connections with state machines, and that's exactly what Tokio encapsulates. Now it's not perfect. The big problem that I have right now in TRust-DNS is that to be productive, I've started returning boxed objects from nearly all my inner function calls. This is something I've planned on going back and fixing. The problem is similar to that of Result return types, which is that to get a static return type from a function, you need to deal with all the variants that function may return. This generally ends up meaning that you need to return a type specific for each function, almost. The impl return RFC won't really fix this substantially, since you still need to have a constant known type, but it might allow for easier combinators to be used reducing boiler plate. This is a long way of saying as someone who's been consuming Tokio for a little while, and contributed some minor things back to it, that I disagree with your opinion on this. I also believe the language will improve over time to make things like futures and Tokio simpler to use.
If you haven't used error-chain, I highly recommend looking at it. Also, many languages file methods don't return the file name, that's generally the responsibility of the caller to wrap that error with a better message.
Which is exactly my problem, error handling shouldn't be hacked in some library using macros and shadowing the default Result, it should be in the language itself.
Personally I love the safety (in a broad sense) guarantees. Haskell, Scala or Ocaml may offer similar guarantees on this aspect, but while learning Rust was hard, I still found it easier to get my head around how the borrow checker works than the wholly functional/fully immutable stuff.
Do you think the authors of all these libraries have gone mad in all deciding to use Futures and Tokio? Do you think it's possible instead that they all after using lower level async libraries, that they perhaps recognized the value of Tokio and Futures such that they all independently decided to move their software over to this framework? Is it possible that while it looks like madness to you, that's because you have yet to recognize the potential of what the Tokio framework is offering?
I agree with you that tokio poisoning the projects it's used in is a bad thing. Introducing things in core/std does not make those things better. Imagine if tokio (a not-so-bad idea) was created inside std - it would be even harder to get rid of it now, and rewrite into whatever better alternative there is! Making a sane async/await is hard and easy to get wrong. If you know a good easy way - RFCs welcome. Here's some discussion on github: [link](https://github.com/rust-lang/rfcs/issues/1081)
I'm using tokio in my pet project mostly because it's framework *du jour*, and rust just doesn't have anything better for event loops. I don't like the way my code base looks, and I blame tokio for that, but I just don't know a better alternative - tokio is the lesser of evils.
Exa is an official package (on archlinux), and is available in aur.
&gt; Do you think the authors of all these libraries have gone mad in all deciding to use Futures and Tokio? I think the authors are using it because they have no alternative and because it's popular. Because it's popular a lot of people use it when they don't actually need to. Using non-blocking sockets on top of mio is not that difficult. I use mio on practically every project I write. &gt; Is it possible that while it looks like madness to you, that's because you have yet to recognize the potential of what the Tokio framework is offering? Of course, I would love to hear that I'm wrong. 
Well, I'm not impressed. Sounds like PowerShell *still* offers me nothing I want. &gt;Besides, you still have to install it first - whereas every system will ship with a shell. ?? My system ships with Bash and Python. How is this an argument for PowerShell? 
There a number of people who have issues with Tokio. That of course shouldn't be discounted. But I don't think it's madness. I also used mio prior to Tokio. For me, Tokio is all about encapsulation of state. I find it both simpler than my mio code and much more expressive. If you're happy with mio, you should keep using it!
You'd be saying the same thing if they implemented a sub-par async/await feature.
Obviously. Bad solutions always need to be criticized. 
All abstractions are 'leaky' in some sense; that's why they are abstractions and not the things they abstract. So it's important to specify which leaks are admissible and which are not -- something that becomes much more difficult as you take into account more diverse use-cases. For instance, container types are a very clean abstraction -- until you start wanting to deal with allocation failures. Threads are a clean abstraction until you introduce shared mutability and panic recovery. The more you try to account for -- the fewer number of invariants you want to assume -- the more wiley and leaky your abstractions are going to get. It's especially a relevant problem when trying to design "reliable systems", because the state of the *system* is not accurately modelled from *within* the system, so you end up trying to plug some impossible leaks. (It's the same reason cryptography cannot be unbreakable. The cryptographer must make assumptions in advance, and thus they can't access or control arbitrary side-channels which exist outside the crypto algorithm's framework.)
Have been starting to feel this way too, I had to add a bunch of descriptive messaging to each error just to know where it came from, and intercept a lot of other errors and add additional info to them. That said I think it's the best implementation I've come across so far, but should be able to improve further over the lifetime of the language.
Well, the good news is that async/await appears to be under serious consideration, and lots of people are excited to abandon the 'old way' and write some nicer code.
The futures-await crate looks promising, but AFAICS it relies on language features that haven't been accepted yet. * https://github.com/alexcrichton/futures-await * https://github.com/rust-lang/rfcs/blob/master/text/2033-experimental-coroutines.md
&gt; Can't the original developers just continue developing the last released open source version? Sure, unless JetBrains hires them or it's no longer worth having two. &gt; If you are going to argue that because they offered a superior product and thus the original developer lost interest, then how is that JetBrains fault? That's not what I'm arguing. I'm arguing that, in this blog post, they are contributing to the open source version and that may be just to draw an audience before they decide to abandon it and go closed. I'm arguing that they are not transparent with their message; they could easily say"we commit to this remaining open source" or "we're taking this commercial" but they don't. 
I write a lot of Python. Productivity on a Python project always starts high and decays rapidly. Lack of a strict type system means refactors introduce bugs, even when being very careful. You compensate by writing lots of tests for things that should be handled by the language itself and now you have even more code that could be buggy or broken by refactor (tests aren't bug free either!) Rust is a language that watches your back. You forgot to change the arguments to that function, but I gotchu fam. You didn't handle the lifetime of this object correctly, but don't that ain't gunna trip you up! Your thread owns a reference that it shouldn't, but we ain't gunna let that bug slide. Compile-time checks are the most reliable way of proving correctness of the structural requirements of your code before you even ran it. The things the programmer has to worry about are now *just the logic* which frees up so many mental resources once you actually get going.
Nice features! https://intellij-rust.github.io/features/
&gt; I'm a big fan of exploratory debugging as a way to learn how a system works. ```^^^``` THIS putting a breakpoint in, seeing how it got reached, or tracing through.. etc it can also be useful to step through polymorphic code 
The work tokio and futures-rs are doing is a prerequisite to async/await. You simply cannot implement await without it. The vanilla interface without await is ugly, sure. But it's hardly "cancer" or "the Rust community shooting itself in the foot." It's an important part of the transition to have libraries like hyper prove the design of the execution model. Async/await has not been done without pervasive GC before. The closest is C++'s work on coroutines, but that language has extensive experience with unsugared async IO libraries to build on.
I am slowly working through the rust book v2 and getting used to working in rust. I am to chapter 13 and I am really enjoying it so far!
https://crates.io/crates/libloading Spam the dynamic libraries. If I'm only touching the leaves, compiling takes about one second.
Surely you could send an `Rc` where the `strong_count` is &gt; 0 so long as you can ensure all the references are sent at once? e.g. a tree that uses `Rc` internally to reference nodes, so long as the `Rc`s are *only* used internally and can never be stored outside of one root container object. It should in theory be safe to send that root container. Obviously this isn't ideal but it should work right? 
 I literally said, BSDs and Linuxes should drop bash for PowerShell - so that bash no longer comes preinstalled. And just because your particular system ships with python out of the box doesn't mean every system does. You're acting deliberately ignorant here. The concept of a default shell that's not bash isn't exactly hard to grasp. Also, what do you even mean by &gt; Sounds like PowerShell still offers me nothing I want. How is having a cli not something you want? Why would that cli not be cross-platform and free, why should it not speak a standardized syntax with clear defined best practices for scripts and in-built capabilities such as exporting to CSV, sorting and worry-free accessing and parsing of information through Object-Properties. `(Get-ChildItem | Sort-Object Length -Descending | Select-Object -First 1 -ExpandProperty Length) / 1MB` gives me the size of the largest file in the current directory in MB. Is it verbose? Yes. Would I have wanted to (install and) fire up Python just for this little piece of information? No. And neither would I have preferred to wade through the switches of `ls` to see if it can sort by and return just the file size and then grab the first line. Parsing by linebreaks is a hack, my PowerShell 1-liner can be understood by anyone and easily adapter for say showing the oldest item in a directory. Besides, you can still run all the old unix commands and pipe text in Powershell. Except the text now has Properties like "Length" and Methods like "IndexOf", "Trim" and "ToInt32". You can type `(ifconfig).Length` in PowerShell on Linux and it'll tell you how many characters ifconfig returned. You can continue to build hackjobs too: `[int]( (hostname -I).Split(" ") | Select -First 1 | % {$_.Replace(".","") } )` will grab your primary network adapters IP address as a single integer number without any dots or separators. Why? Why not. Sometimes you have to parse text. But it's easier when every piece of text has methods and properties. EDIT: Have the cow scream at you: `(fortune).ToUpper().Replace(".","!") | cowsay`, why not. It's easy to read syntax and anyone can pick it up and play with it.
I've removed this per rule #5. Please feel free to re-post this as a self post with some explanation as to why it's relevant to Rust.
&gt; I like Rust very much, but I found it takes a good amount of time to fight with borrow/type checker. I think that the borrow checker will probably improve, as it is currently sometimes painful. But the type system in Rust has never given me any problems. I love it. &gt;the compile speed and lack of resources have made it a little bit less productive. If you don't use `cargo check` already, I highly recommend it! I used to do `cargo build` every time and that was... not a great way to do things. The other bit of advice I can give you: to achieve what Rust does alone in a language like C, you'll need to run swathes of auxiliary tooling, which will usually take *longer* than just using cargo in the first place, and probably not even catch all the same errors.
Ah, I see. I didn't think of that case, but you're right, that would probably work too.
Whatever crap I decide to write in Rust, it quickly turns out to be a fastest and most reliable one: a top-notch crap, I'd say.
I'm curious what do you think about Scala Futures? In async programming Future is as necessary as Result. Hence it spreads around all sources. But nothing wrong with that. And its absolutely necessary that everyone uses same abstraction, otherwise say goodbye to async libraries ecosystem. Async\await can be implemented later as a sugar on top of futures. But it will never give you all the power of formers.
Compared to Python: nearly everything. The type system stands out the most. Rust is certainly more verbose, but that's about it. Compared to Haskell: speed. I prefer Haskell because it lets me be more expressive, but Rust is just plain faster, and sometimes that matters. Compared to Idris: much more mature. The tooling is a lot smoother, especially `cargo` and crates.io
&gt; theres a sense that it can truly be used for anything, whereas in python that isn't quite the case. Rust is still a systems programming language. I'd never write a compiler in Rust over Haskell. That being said, it definitely expands your horizons. It's probably the only non-garbage collected language out there that's still relatively easy to learn.
Recompiling binaries every time you want a small little update is silly, especially when the [ci](https://github.com/japaric/trust) is good enough that I can provide binaries for [basically any platform you'd develop on](https://github.com/vmchale/tin-summer/releases) fairly easily. Also, `cargo` is a build tool, and using it to distribute a tool that has binaries doesn't make much sense. 
All of the alignment and positioning should be done within Glade. If you need to add widgets to a container, just import that specific container widget into your Rust code as a variable and use the Gtk-rs API to create and attach new widgets to it. Gtk-rs is a difficult beast to work with though, so you might have better luck with using Relm.
Yes indeed, which is why incremental compilation is so heavily anticipated.
Higher precision borrow length estimation using more details from expression tree.
Hey all, I put this together after writing more or less the same boilerplate code over and over in projects for holding some kind of state in a persistent file. It is meant to be used in cases where something like `diesel` might be overkill, e.g. early in a project, for a small tool only run occasionally, or where the number of reads far outweigh the number of writes. It uses `serde_json` to store the contents of a data structure to a persistent file, provides atomic transactions (via closures) for read-only or read-write access, and allows the user to store the data in either compact or pretty-print JSON. So far I've used this for a couple of command line tools that have a persistent (but modifiable) configuration file, as well as with a small web server backed by `rocket`, to provide thread-safe access to data across API calls. Let me know if you have any questions, or suggestions for improvement!
&gt; That being said, references to ZST are kept unless things are inlined. Just a note, there's a RFC to have [zero sized references](https://github.com/rust-lang/rfcs/pull/2040) to ZST types.
Note: Rust's type system doesn't protect against deadlocks in general. However, you can use a lock-free data structure (that use atomics underneath) that will avoid deadlocks.
How does this compare with https://docs.rs/preferences/1.1.0/preferences/?
I'm currently trying to write a BitTorrent client, and I wanted to get opinions on whether or not using/learning the tokio and futures library would be worth it. I've seen a lot of conflicting testimonies regarding those libraries, particularly regarding usability. I'm leaning towards just manually spawning threads and using `std::net` for all of my TCP-connection needs, as this seems like the most straightforward way to do things. At the same time, the reason for this project in the first place is to learn more about and practice with async-io. I'd rather take my time and work through any compiler-related frustrations if it means having a more polished project, and a better understanding of event loops and futures (as a general abstraction, not necessarily Rust-specific implementations). However, I also don't want to feel like I'm banging my head against a all just to learn a new library, only to have the abstractions change later or for there to be very little cross-over with other async-io related libraries in other languages.
You're so ambitious you run away from chairs. I hope you have a nice day!
Why not? What about Rust would make it ill suited to writing a compiler?
Hey! It looks pretty similar in intent, and I hadn't seen `preferences` before. Thanks for sharing. I didn't write `mvdb` with config files as the main focus, but it does a pretty good job at that IMO. I would say that the major differences I can see at first are: * MVDB provides atomic access to data, so one MVDB structure can be shared across threads without explicitly wrapping it in an `Arc&lt;Mutex&lt;&gt;&gt;` (MVDB does this internally) * MVDB only allows you to access data as a Rust data structure, so there is no need for keys/paths. Because of this you can check at compile time that all referenced fields exist in the defined "schema" * MVDB does not re-load from the file on read-only accesses, and only writes the file if the contents changed, even when write access is used.
You mention tokio-core and tokio-io, would you say that tokio-proto also fits in the "not any significant breaking changes"?
&gt; For a term we use so much in our field, there are very few definitions of abstraction. Isn't that a good thing? Also, I don't really see what to get out of this article. My own conclusion is that thinking about what a "good" (and by that, per article "precise") abstraction is is valueable, but that should be one of the core aspects of designing a program anyway.
You should use [RON](https://github.com/ron-rs/ron) instead of JSON, especially given that you are using Serde, which RON is designed around.
cool. using my json utility for same reason. also using csv utility for tables. postgres vanilla library may be also good alternative to full diesel solutions.
Thanks for the heads up about RON. I've added it to my tracking issue for "support more serde backends": https://github.com/jamesmunns/mvdb-rs/issues/2
`postgres` would definitely be an option, but there can be some overhead in setting up tables, etc., which I don't necessarily want to do for every project. Could you link your json and csv utilities? They sound interesting!
yes
Since it's using JSON... is the whole file human-readable, or is there some binary data alongside it? (like a header or something)
I am working through the Rust book and I am near the end of chapter 13.1 for Closures. It mentioned trying to implement the Cacher to hold multiple cached results depending on the argument used and I just wanted to see if there was a better way to write the value function implemented on the Cacher struct: struct Cacher&lt;T&gt; where T: Fn(i32) -&gt; i32 { calculation: T, values: HashMap&lt;i32, Option&lt;i32&gt;&gt;, } impl&lt;T&gt; Cacher&lt;T&gt; where T: Fn(i32) -&gt; i32 { fn new(calculation: T) -&gt; Cacher&lt;T&gt; { Cacher { calculation, values: HashMap::new() } } fn value(&amp;mut self, arg: i32) -&gt; i32 { if let Some(v) = self.values.get(&amp;arg) { return v.unwrap(); } let result = (self.calculation)(arg); self.values.insert(arg, Some(result)); result } }
No header, just plain JSON. The contents of the file will be the same as writing `serde_json::to_string(&amp;your_data);` to the file.
It took F# 10 years _despite_ MSR backing to get Visual Studio integration. The GP comment was a nod to Rust – defensive much..? ;-]
for json i just use "loadjsonfromfile" function which is just a load file and convert to json functions made into one. for csv i use small function to load csv nd insert it into postgres db as table. https://github.com/jaroslaw-weber/learn-korean-tools/blob/master/src/database.rs i did csv to postgres insert here but its not generic. i use csv only to read and have fast access to data but dont update it from postgress. you could make something similar, a wrapper for diesel or postgress :)
I'm not being 'deliberately ignorant', I'm just not seeing the proposed value. You're considering an absurd hypothetical; BSD's and Linuxes *wont* drop Bash for PowerShell because there is no good reason to do so. And every justification you've provided so far is just as much an argument to use Bash and Python, except for the fact that those are already in use in thousands of scripts and don't require re-establishing the whole world. And to do what? "Run programs on a computer?" The whole world isn't going to change just for a utility program. Pretty syntax and discovery features in a shell program is like gold lining the inside of your toilet: it's nice, but nobody is going to do it if it costs too much. And what you are proposing is not cheap at all. It is quite disruptive.
Ah, I was actually unaware of that. I knew it took awhile, but not that long. And was it actually popular for that period - more popular than Rust? If so, I take it back.
Type `git status` to check untracked files and files with uncommitted changes. If the file shouldn't be tracked (perhaps it's an editor backup file), add it to `.gitignore` in the project root, or better yet, to `~/.gitignore`, that way it ignores for all your repositories (generally speaking, I have only Rust-relevant stuff on the project's `.gitignore`.. like `/target/`). For reference, I have this in my `~/.gitignore`: *~ .#* \#*# .*.swp If I recall correctly, `.*.swp` files are temporary files created by Vim when you're editing the file; they are removed after you save. `*~` files are Emacs temp files (and other editors). `.#*` is like Vim's `swp` files for Emacs. It's possible that editing a file created an untracked temp file that prevented `cargo publish`, and saving the file removed it. edit: see [this](https://stackoverflow.com/questions/4824188/git-ignore-vim-temporary-files) and [this](https://vi.stackexchange.com/questions/177/what-is-the-purpose-of-swap-files) (that's for vim, but other editors may have similar things)
The error_chain crate provides a way to get a backtrace for errors without panicking.
This is seriously awesome! Right now I'm toying with some Elm on the Frontend and Rust on the backend. I've been thinking to migrate to Purescript to reduce JSON boilerplate, and Waterslide would reduce it even further (and even detect server/client mismatches). How hard would it be to use this for FFI on Node.js? Writing Rust native modules using [Neon](https://github.com/neon-bindings/neon). edit: consider crossposting to /r/purescript too
Thanks :) I did it for Purescript since it's what I use but if you look at the code it's actually very straightforward with custom derive, and I think it would be easy to do the same thing for Elm or Typescript. I have zero experience with the Node FFI and Neon so take this with a grain of salt, but since it's geared toward JSON, as long as your types are not much more complicated than JSON (and are plain data), it should be straightforward to share the definitions. I have to admit I didn't think about that use case but it would be really cool if it works well and I'd be happy to support it. (I mostly had Rust backends communicating with Purescript browser apps in mind). edit: did the cross-posting
Now that I think about it, you would certainly need to marshal to JSON for it to work with enums and tuple structs currently. I'll open an issue to explore the idea.
Yes but some sort of solution should be in the language itself
&gt; The whole world isn't going to change just for a utility program. Only the Unixes would have to change, one after another. Windows is already on PS. &gt; And what you are proposing is not cheap at all. It is quite disruptive. Correct!
vim-lsp now works in vim8 and neovim. Details at https://www.reddit.com/r/rust/comments/6rx634/async_autocompletion_for_vim8_and_neovim_via_rls/
Off topic: So this is what [yelling bird](http://questionablecontent.wikia.com/wiki/Yelling_Bird) is doing after getting axed by Jeph Jacques.
Use PushItemWidth() to change the width of widgets. Here's a similar use with dear imgui https://github.com/ocornut/imgui/issues/1245#issuecomment-318343825
Someone once said to me "Such change would break so many things that it wouldn't be justifiable even in Rust 3.0."
I'm not sure if my question was clear. Even if those operations are slower, people still need to write reliable code without data races. How is this achieved? (I have no experience with this, so that's why I'm curious.)
I think the point intended was "For a term we use so often, we sure don't spend much time trying to come up with a solid explanation".
Is there any difference between `a || b` and `a | b`?
Yes, the former is short-circuiting and works only on `bool` values, while the latter is a logical (or bitwise) *or* and works on all types that implement the `std::ops::BitOr` trait.
Borrow-extent Lifetimes? Even more confusing though...
That's a nice notation. Very glad it allows trailing commas and comments. We tend to use JSON as our configuration language, but it's of course one of the zillion extended versions: in our case, comments and hex literals.
Very cool. I might fork this and write a typescript version if nobody else beats me to it.
I use [LanguageClient-neovim](https://github.com/autozimu/LanguageClient-neovim). How does `vim-lsp` compare?
Does it have to be the same core handle between hyper and mysql? 
Thanks, an arena was the exact thing I needed. (Using SimonSapin's TypedArena now.) It's funny, I totally knew they existed, but I have never used one so I didn't know the exact semantics. The idea I had was basically re-inventing an arena.
Interested to add this into our tutorials as well? :p
Glad to be of help.
not sure how beneficial it is for gtk-rs, I didn't get gtk to compile yet, and you'd still need to sign it on a mac.
well. it works. apparently I need to remember, what loops can consume collections...
good to know, and a nice feature.
I wouldn't be overly concerned about benchmarks at the moment as both aren't stable, and I believe both are still single threaded.
https://github.com/nrc/r4cppp
wait, what? I never heard of that (not a huge mac developer). I know about that beeing the case on iOS but you need to sign stuff for macOS? What happens if you don't do that? Can you point to some documents? I have some applications that i also distribute to macOS (mostly C++/Qt) so does the toolchain do that automatically? 
Thanks for the historic values table
Its always not a bad decision to also deliver a source of said benchmark diagrams. And as beefsack already mentioned, both projects are not 100% at the stage to put to much concern about such things but rather on design and api/user experience. 
on sierra to run unsigned apps you have to jump through hoops http://www.macworld.com/article/3140183/macs/how-to-install-an-app-in-macos-sierra-thats-not-signed-by-a-developer.html edit: it's not a huge deal, so might still be worth figuring out how to compile gtk second edit: doesn't matter for cli stuff, those run normally in the terminal
I am not sure about Rocket, but Iron can use threadpool.
You can add a flair to the thread, or modify the CSS for the post to add text before/after.
I'd love to see that happen, a typescript version is probably going to have a larger audience than purescript :) I'd like to see if the translation of tuple structs and enums is as straightforward in TS considering the JSON decoding is basically `JSON.parse`.
Is this publicly available?
Really nice, you could consider to add as backend https://gitlab.com/tglman/persy that will allow to have "real" transactions with recover in case of crash, obviously the file won't be human readable/editable but is going to be closer to a database, here is an example I wrote a while ago with serde: https://gitlab.com/tglman/persy/blob/master/examples/serde_config_file.rs, bye
If you post some Rust code samples (or even C++ samples) that you had trouble with, then I'm sure some folks here would be happy to help write the Rust equivalent!
Read the Rust book, then read it again. It took me about four false starts over the course of several months to reach the point where I could write code to a basic level of competency. Read real world Rust code. Matt Brubeck's [robinson](https://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html) project is good. Understand and accept that the learning curve for Rust is steeper than for most languages even for good programmers.
I strongly recommend the CppNow 2017 keynote [Rust: Hack Without Fear!](https://youtu.be/lO1z-7cuRYI?list=PL_AKIMJc4roXJldxjJGtH8PJb4dY6nN1D) by Niko Matsakis.
iron isn't stable?
Sample output is at https://github.com/swagger-api/swagger-codegen/tree/cc848a1c24959c2f6941234b77399fbd58ecd3ca/samples/client/petstore/rust
deleted ^^^^^^^^^^^^^^^^0.1534 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/62826)
How does the functionality of rls compare to racer at the moment? Is now a good time to switch?
&gt; you need to sign stuff for macOS? What happens if you don't do that? Here's the basics: If you distribute an app *outside* the Mac App Store that isn't signed with a Developer ID certificate, and someone **downloads it from the internet** in a way that sets the `com.apple.quarantine` extended attribute on the file (e.g. web browsers set it), then double-clicking the app to run it will display a warning instead. If your local user account has administrative privileges, you can still right click and open it. The quarantine flag isn't always set though, if you copy something manually from a USB drive, or a DVD, or a network file server, the check won't happen unless the file *already* had the quarantine flag set **and** the way it was stored and copied preserved the flag. &gt; does the toolchain do that automatically? Xcode can do it automatically, but building doesn't require it. Some developers use the `codesign` tool manually as well, you can sign things after they're already built and packaged. I'm not aware of any way to sign things using other tools, and in the case of a Developer ID signature, the signature itself is timestamped so that the app will continue to run *after* the certificate used to sign it has expired, which requires the code signing process to interact with Apple's servers over the network. I wouldn't be surprised if someone has written a portable codesign tool that works, but I haven't seen any yet. One (relatively) easy way to do this without having a Mac is to set up CI builds through Travis CI, encrypt the Developer ID certificate using the Travis file encryption system, and let their build server sign the app. That only works if you're OK with the Travis servers having access to your certificate though, in some cases that would be considered a compromised certificate.
Thanks for the explanation. Its i little bit of a relief. I just confused that "this app is from the interwebz – do you really wanna open it" with any "the developer haz no paid the apple tax – app won't open". And all of my "customers" have smart people maintaining their macs and install software on it, so this is [currently] no big of a deal. EDIT: and yes, i would also see a value in building it that way. If there is an easy way to cross compile to win and mac – i would thinking about a rewrite of two of my little C++/Qt apps that i build in a WinVM and on my macbook separately (about once a year when i need to push a new release) 
RLS functionality is a superset of Racer. Assuming the clients can actually make use of the additional RLS features, it's always a good time to switch.
I will go ahead and recommend the soon-to-be-released "Programming Rust" book. Even though I have learned Rust before from online resources (books, blogs, etc), the in-depth explanations there gave me that last bit of detail I needed. It was refreshing how this book expected me to be able to handle complicated things, and did not try to sugar-coat anything. There are plenty of comparisons of Rust and C++, so it would also work nicely as introduction for C++ programmers. It's not released yet though, but is [available as preview on O'Reilly site](http://shop.oreilly.com/product/0636920040385.do). It can be read with free trial option, that's how I did it.
Thanks for the insides! 
I tried this out, and I'm not getting any type information in the completions (except that it shows `class` for fields and `namespace` for methods). Did I set it up wrong or is that feature not ready yet?
Working a little bit on getting gtk to build. I'll see what I can do.
Is there a low friction way to expose a Rust struct and its impl as a C++ class?
How does one integrate Rust into a CMake based C++ app?
There is [semantic-rs](https://github.com/semantic-rs/semantic-rs/blob/master/README.md). To use this tool you need to follow the Angular.js commit message conventions. Another tool is rusty-release. When you call it, you specify what part of the version you want to increase. 
It's possible to drive cargo using ["ExternalProject" feature](https://cmake.org/cmake/help/v3.0/module/ExternalProject.html) and link to produced static libary (more details [here](https://stackoverflow.com/questions/31162438/how-can-i-build-rust-code-with-a-c-qt-cmake-project)). The rust library itself has to be changed to "staticlib" or "cdylib" [as explained here](http://jakegoulding.com/rust-ffi-omnibus/basics/), and has to expose its functions over C-like [FFI interface](http://jakegoulding.com/rust-ffi-omnibus/integers/).
Rocket is definitely still v0.x.
Gdbgui is another option for graphical debugging, and is compatible with rust, c, c++, and golang https://github.com/cs01/gdbgui (Disclaimer: I am the developer)
Vim-lsp is written in pure VimScript so you don’t need to install python. LanguageClient-Neovim works only in Neovim while vim-lsp works on both Neovim and Vim.
Context: trait Add&lt;RHS = Self&gt; { type Output; // associated type fn add(self, rhs: RHS) -&gt; Self::Output; } Quote: &gt; The trait bound for add basically says this, add can be defined for any type, but it can only be added to itself. That's not quite true; if that were the case there would be no need for the separate `RHS` parameter. Instead, it just *defaults* to Self because that is usually what you want, but the stdlib *could* implement `Add&lt;&amp;str&gt; for usize` if it wanted.
For the struct, `#[repr(c)]`. For the implementation, it might be simpler to wrap the methods in plain functions and expose those.
Coffee, and lots of it 
Oh! Thanks. I haven't tried to do that. I'll clarify later when I have a minute. edit: I added a correction and note: https://bluejekyll.github.io/blog/rust/2017/08/06/type-parameters.html?#2 
&gt; in my programs I wanted to use the recursive structure Not sure what you mean by that. Maybe my C++ background is different from yours and/or the kinds of programs I want to write are different from the kinds of programs you want to write. But I found it rather easy to transition from C++ to Rust. To me, Rust feels like a modernized, lean and simplified C++ that encourages a "good style". If you're already familiar with what people call "Modern C++", Rust shouldn't be a big shock to you. Anyhow, there is one very important new rule to keep in mind if you're coming from any other language. Rust imposes a couple restrictions onto the programmer to keep things safe. The important rule is that aliasing (= more than one usable way of accessing the same thing) and mutation are mutually exclusive. And to keep track of whether there is or isn't a reference (or equivalent) "borrowing" something (pointing to it without owning it) and also to keep those references from dangling, the compiler is *aware* of those "borrows" with the help of the type system and the borrow checker. I'm mentioning the type system because the concept of "lifetime" is part of the type system. This is not something you'd find in any other popular language and might seem strange at first. If you want to build your own pointer-heavy data structures (graphs or lists) then, yeah, it's more difficult to work around that rule. There are certain safe escape hatches ("interiour mutability" or preferring indices into a vector over references) and sometimes you might have to get your hands dirty by building your own low-level abstraction using unsafe code. Be sure to package your unsafe code into something with a *safe* interface. That's more of a black art. Due to the restrictions on what you're allowed to do in Rust code, it's rather easy to violate these rules within unsafe code blocks. If you feel the need to go that route, be sure to gather some basic Rust understanding/experiences first and check out the [Rustonomicon](https://doc.rust-lang.org/nomicon/).
`RefCell` of a copyable type (like here) should be just `Cell` - 0 space overhead, and the operations you get are similar to the unsafe code you'd write in C or C++ for this sort of thing. You can't do this without interior mutability because of Rust's guarantees that `&amp;mut T` can't be usable as the same time as *any other reference* (of *any* kind) to the same memory.
I don't really agree. The learning curve isn't that steep. It probably is for object oriented programmers because they need to completely relearn the functional style. If you already know a similar language the biggest problems will be lifetimes and references. And if you know how memory management works they'll be less hard, too.
Honestly, although I think Rust is a great language, one of its biggest problems is terminology and/or labeling. I don't think they're rampant, but they seem to come up in key places. I wish addressing these sorts of things was taken more seriously as a goal. &amp;mut in contrast to mut is another example that's arisen recently. 
In terms of version numbers, Iron hasn't reached 1.0. The 1.0 version often symbolizes API stabilization. This doesn't mean that Iron is crash prone but rather that you might need to change your code as the API evolves.
Your terminology is a bit confused. What you call polymorphism is *runtime polymorphism*. Generics are also polymorphism, but at compile time. Monomorphism is when the compiler takes your generic, polymorphic functions and generates non-generic functions for each use case.
Thanks so much for mentioning this. When I was reading about it, I was thinking something like "path sensitive," or something with "path" in it made more sense but wasn't sure if I was remembering things incorrectly. I think what you're mentioning makes so much more sense and should be adopted. 
gonna try out that error chain lib next time i have to write some rust code :)
Now even with non-copyable types. And since there’s no space overhead, you can have multiple cells for individual fields rather than one large cell for an entire node. I find this is often more convenient.
All comments and feedback are welcome. This is about the second time I ever used tokio and hyper, so the API would definitely need some polishing.
Here you go, two cyclic data structures built without `unsafe` and `RefCell`s: 1. [Doubly-linked list](https://github.com/stjepang/vec-arena/blob/master/examples/linked_list.rs) 2. [Splay tree](https://github.com/stjepang/vec-arena/blob/master/examples/splay_tree.rs) That was built using the [vec-arena](https://github.com/stjepang/vec-arena) crate, but you can achieve the same thing using the more popular (and very similar) [slab](https://github.com/carllerche/slab) crate. Arenas are great. Although they may add another level of indirection and runtime checks, they at the same improve cache locality by storing nodes of the graph close in memory. In fact, they are usually faster than unsafe graphs of heap-allocated objects. And finally, arenas can be much easier to use than unsafe code (in Rust) and `RefCell`s. Notice how much the two examples resemble equivalent code you'd write in C/C++/Java: * `Arena::insert` is like `malloc`. * `Arena::remove` is like `free`. * `Arena::get` (or indexing) is like pointer dereferencing.
OP, you probably have done a nice job with your work, so please excuse my mild rant. There is a question at the end. It makes me sad that there are so many autocompletion plugins for Vim. And all have issues in some sort of way. This, for example is too specific (what about Java, Python and C++ completion?) and will suffer performance issues (What about code bases of a 10e6 lines of code with hundred thousand possible completion candidates?). YouCompleteMe (YCM) is so far beyond anything else in terms of performance and design, scales to massive code bases and is very well maintained. Please stop rewriting the completion engines, add more features to YCM. OP, could you add your functionality as a plugin to YouCompleteMe?
I agree. Though if you are usually using object oriented languages like C++, like I do 99% of the time, you really have to get an entirely "new mindset" to accomplish anything worthwhile in Rust.
How do you do a double level split iterator? Example Data from Color Maze in DailyProgrammer: O G B O R O Y O R B G R B O G O Y Y G B Y G R O R B R I have a Color Enum and made a FromStr. I parse the first line with: let seq = maze_data.lines().take(1).collect::&lt;String&gt;() .split(" ").map(|x| Color::from_str(x).unwrap()) .collect::&lt;Vec&lt;Color&gt;&gt;(); This works fine, as I'm using the collect to work through the lines() iterator. When I try to make the 2D vector, I find I can't split on an iter(): let maze = maze_data.lines().skip(1) .split(" ").map(|x| Color::from_str(x).unwrap()) .collect::&lt;Vec&lt;Color&gt;&gt;() .collect::&lt;Vec&lt;Vec&lt;Color&gt;&gt;&gt;(); I can't do a split on iter for this. But I'm not sure how to make this happen for multiple levels. Best I came up with is: let mut maze: Vec&lt;Vec&lt;Color&gt;&gt; = Vec::new(); for line in maze_data.lines().skip(1) { maze.push(line.split(" ").map(|x| Color::from_str(x).unwrap()) .collect::&lt;Vec&lt;Color&gt;&gt;()); }
Learned two new things today. I've always considered polymorphism to be a dynamic runtime feature. But you do seem to be correct that I have too narrow a view of this. edit: I've updated the post and included a note, https://bluejekyll.github.io/blog/rust/2017/08/06/type-parameters.html?#1 Thanks for the feedback!
&gt; But nobody compiles in debug mode, right? lolsob ;p
RLS supports completions for sure. I use neovim + LanguageClient-neovim + rls + deoplete and get them just fine. I did have to set `RUST_SRC_PATH` for Racer to get completions for the standard library (I thought they put in changes to find it automatically but I guess not), and I had to set both the language client and deoplete to auto-start when I open a Rust file. [Here's a screenshot](http://i.imgur.com/HvJcXA9.png) of it working.
I'm not very familiar with tokio/futures, but I think you would need to share the handle to use futures effectively. You could generate a new core and then `run` the MySQL query on that core, but I think that would effectively just be synchronous. (Plus there may be some overhead of creating a new core--I'm not sure). I think an alternative to using TLS would be to put a Core [remote](https://docs.rs/tokio-core/0.1.9/tokio_core/reactor/struct.Remote.html) into an `Arc` or some kind of static, but I don't have an example of that at the moment.
Rocket is multithreaded, using 2 * num_cpus threads to handle requests.
I agree with beefsack that one shouldn't worry too much about benchmarks at the moment. However, there are some strong claims about performance in the Rocket [README](https://github.com/SergioBenitez/Rocket) that I (and apparently others) haven't been able to confirm. I've written a few small webapps in iron, Rocket, and Hyper (pre-async 0.10, with a thin path router component), and pretty consistently see Rocket at 20-30k requests per second, iron at 55-60, and Hyper at 90-110. (And I've made sure to turn logging off, use the same # of threads for each, etc.) It would be nice to see the code used in the Rocket comparison benchmarks.
It's really amazing. I don't writes a library without it now. No More dealing with errors the hard way.
I couldn't find a good explanation of what generics are, but my understanding is that generics are simply the name Java gave to parts of the language that use type parameters. But it's important to understand that there are at least two forms of polymorphism. First, ad-hoc polymorphism where the definition is specialized to each instance of the polymorphic thing. We see this in C++ with class heirarchy polymorphism. We see it in Rust and Haskell with trait/typeclass polymorphism. Second, there is parametric polymorphism. In parameteric polymorphism the definition is always the same but the parameter can be varied. As such, in parametric polymorphism you can't inspect the parameter and behave differently depending on what it is. This is, to my mind, the big difference between parametric polymorphism and C++ templates. As far as I know, generics are another name for parametric polymorphism and I wouldn't call c++ templates generics. Possibly confusingly, I would be okay with saying that they allow generic programming.
Since it is a nested data structure, nested `map` and `collect` are needed here: let maze: Vec&lt;Vec&lt;_&gt;&gt; = maze_data .lines() .skip(1) .map(|x| x.split_whitespace().map(|y| Color::from_str(y).unwrap()).collect()) .collect();
You can assert all the invariants you can think of and turn everything into a panic. At the end of the day, you'll still run into bugs you don't understand, and you'll still need to debug them. Using one tool doesn't preclude using others.
Could you elaborate? What is the `&amp;mut` vs. `mut` thing?
Ah, that makes sense. Thanks.
/u/paholg had similar feedback. It's been a while since I've actually done C++ in earnest. I was trying to draw comparisons. I know that C++ didn't refer to this as Generics, i.e. Templates, but I guess I have always viewed them as performing the exact same job as Generics in Java. Meaning, I've always viewed them possibly as a superset of Java's Generics system, and thought mostly that this was just a general difference in terminology, as opposed to conceptually different. Of course, I'm no expert on type theory, so I'm happy to be wrong, and your comment is a good one.
It's not even _that much_ slower in debug mode: | v1 | v2 | v3 | |----|-----|----| | 10.438 s | 11.554 s | 11.767 s |
I don't mind the rant. It is always good to question. Since this was in rust I didn't post on how to use other completions. For a complete list you can refer to https://github.com/prabirshrestha/asyncomplete.vim#sources. To get asyncompletion source for python you can use this - https://github.com/palantir/python-language-server. if executable('pyls') " pip install python-language-server au User lsp_setup call lsp#register_server({ \ 'name': 'pyls', \ 'cmd': {server_info-&gt;['pyls']}, \ 'whitelist': ['python'], \ }) endif It is based on the [Language Server Protocol (LSP)](https://github.com/Microsoft/language-server-protocol). You can see other LSP implementations at https://github.com/Microsoft/language-server-protocol/wiki/Protocol-Implementations. It does have Java and C++. Even Eclipse is moving to it - https://github.com/eclipse/eclipse.jdt.ls as well as Clang - https://clang.llvm.org/extra/clangd.html. https://www.redhat.com/en/about/press-releases/red-hat-codenvy-and-microsoft-collaborate-language-server-protocol. LSP in general also scales massively with the code base since it has similar architect as YCM. vim-lsp is responsible for managing the servers. Servers are started using vim jobs in a different process and they communicate with vim using stdin/stdout. This means the performance depends on the server and not vim or vim-lsp. I use asyncomplete with typescript (not LSP) running using vim jobs on large codebase at work and the server uses almost ~1gb ram and I don't feel any sluggishness in vim since the heavy lifting is done by server and not in vimscript. I have also shared the asyncomplete optimizations back to [nvim-completion-manager](https://github.com/roxma/nvim-completion-manager/issues/30#issuecomment-283281158) which I originally forked off from. There are reasons why one would not want to use YCM. Trying to get it working is a pain and setting up python on windows isn't good. There are lighter alternatives like deoplete and nvim-completion-manager (NCM) which take advantage of neovim rpc. There are reasons why these exists. NCM even has a documentation on why https://github.com/roxma/nvim-completion-manager#why. YCM also doesn't support LSP. My goal is to write one vim plugin that works with LSP so devs using all languages can benefit from it. Notice how with just one call `lsp#register_server` I could get it working. I think LSP is the future and not YCM. That could mean either YCM supports LSP in the future or other vim plugins are born. It is always good to have different implementations even in open source world. &gt; OP, could you add your functionality as a plugin to YouCompleteMe? vim-lsp doesn't include autocomplete libarary by default, but you should be able to write YCM source for it. I would prefer YCM to support LSP natively. 
&gt; scales to massive code bases I use YCM for a big C++ project at work and it takes about 2.5GB of RAM. Goto definition reliably takes about 3-5 seconds before it can figure out where to go...
I kinda think this approaches this the wrong way, what C++ has is not generics, really, it's templating. Templating is what it's officially called, and it's really what the feature is like. It _emulates_ generics but not really. Java Generics are close to Rust Generics except that Java generics have runtime polymorphism, and Rust Generics are compile time polymorphic, by default.
&gt; Monomorphism (Small typo: this process is 'monomorphisation', or, in some languages, 'specialization'.)
Rust can be quite idiomatic in a way that is different to C++ code and I think that Rust is less forgiving to unidiomatic code than the majority of mainstream languages. Hence I think the learning curve is steep. Perhaps this is not the case for programmers with lots of functional experience but I think you'd struggle to find anyone for whom the borrow checker didn't at least initially cause some headscratching.
Are you saying that my evolutionary learning of these features over the past 20 years is the wrong way to do it? I agree! 😉 I wish I had only started with Rust. But sadly, I had to learn C++ templates in college and used them my first job out. I transitioned to Java, and was sad templates didn't exist. Then we got the Java Generic system, which was definitely better than C++ templates. Most of these concepts have sunk in through job experience, and less through formal education. And for me, almost all my Rust is self taught through the great tutorials and online docs. I wish I had a mentor, but alas, I am the mentor in my group of coworkers and friends. If you think there are better things to link to and read, I'll happily do that! Honestly, there are still things I'm learning all the time in the language, like my RHS=Self misunderstanding in this blog post. There are some advanced features in the Rust language that I haven't seen a ton of teaching resources for out there... Edit: to be clear there may be those resources, but I've missed them.
Indeed - I call that "deep cellification" and IMO it can correctly model mutable GC models like JS - in a sense, showing that (single-threaded) JS is safe from Rust's perspective!
A cursory glance shows a lot of functions are taking mutable references to the GameState structure. Is there any reason for these to not be methods of GameState?
I’ve sometimes called it "interiorer mutability".
&gt; Are you saying that my evolutionary learning of these features over the past 20 years is the wrong way to do it? I agree! Heh. Yeah, I mean, whichever framing makes it easier for you to learn is great :) But in the past I've had folks learning Rust or Haskell or Java understand things better when told that what C++ does is not exactly generics.
If you want to reference someone on Reddit, you use /u/ So, to reference paholg I would say /u/paholg, now he gets a notification saying hes been mentioned.
Nope, an artifact of originally not using a GameState struct. Thanks! Changed.
Nice, I think that has given the code a lot more obvious structure. If you were looking for an interesting way to restructure and extend the project, I would perhaps look into abstracting away the rendering behind an interface or something and allow switching between a command line view and a graphical one. That might give you reason to play around with some different libraries, if that sort of thing interests you.
Thanks, me and reddit don't go back very far. 
Yes, I've used Haskell much more than C++ and I feel much more comfortable with Rust than C++ even without much experience.
My eperience is very similar. After finishing my degree, I have developed in C# for four years, and since then four years in C++ (mostly C++11) with Qt. Since a few months, I started developing some hobby projects in Rust. We are currently using a lot of tooling and automation in our company to get only part of the safety net which Rust provides. I'm really eager to get some Rust components into our company's software. After trying to rewrite a few components similar to those we have in our company, my experience is that I achieve a lot more in shorter time, and the amount of programming errors is a lot less.
Well... it really depends on the scenario. For example in a single reader &amp; single writer pattern you can fairly easily synchronize a data structure without relaying on mfence (so basically using only relaxed atomic operations and no cas... which on most modern architecture is the same as not having any atomic operations at all, since relaxed =/+/-/== are the same as the non-atomic versions). In the aforementioned example this would simply be achieved by checking where the structure is being read or written to and making sure it's never the same place at once. Obviously in a model with multiple readers and writers it becomes harder, these are some example of "industrial strength" code that uses a lock free (so basically no mutexes and no intentional allocations) approach to data structures: https://github.com/cameron314/concurrentqueue https://github.com/preshing/junction ...that I know of an have used, there are probably many around the internet. But then you add in garbage collection and hazard pointer and it just gets weirder. Alternatively there are designs in which synchronization of certain parts of the code can be obtained by simply reasoning about it. There are designs where holding a spinlock or just failing when the resource is being used in a certain way is the best option (so instead of waiting for the mutex to be free just continue on another branch of your subroutine... in which case there is no need for a mutex, just and atomic bool). I'm not the best when it comes to the subject either. But the jist of it is that, if you are interested in writing code that does not require mutexes in order to operate concurrently without the risk of data races dick into lock-free data structure and routines (not to be confused with wait free).
hi have you heard the good news about nixpkgs
I have been working on this for a few months now, so I'm both pretty excited about this, and very open to comments.
I've forked the RFC so it can be collaboratively iterated on [this branch](https://github.com/elahn/rfcs/tree/delegation). Once we've finished updating the RFC document to address the concerns raised on the thread and summarised the relevant discussion highlighting unresolved concerns, I'll send a PR to the original RFC, so it can receive wide review. More details [in this tracking issue](https://github.com/elahn/rfcs/issues/1#issuecomment-319994894). I've also [posted](https://internals.rust-lang.org/t/collaborative-rfcs/5663) about the general idea on internals.
The same example by works for me. Make sure to setup asyncomplete as it suits you. https://github.com/prabirshrestha/asyncomplete.vim#installing
Depends on how much friction is too much for you. The most straightforward way is to expose your Rust API as a bunch of C functions and just make a C++ wrapper around that as you would for any traditional C API
Very interesting read :) Have you considered tagged pointers for storing some primitives? 
* Switch to using `std::panic` instead of destructor traps. * New `scoped` API * New `take_or_recover` function. * `std::process::abort()` instead of exit. Note that the unit tests aren't really where I want them to be. Also I'm not sure why the cargo page links to 0.1.3 docs. Edit: Forgot to mention abort.
Both following Nightly, eh? When can we expect stable libs and frameworks to lean on?
Thanks! :) To be honest I'd never heard of tagged pointers before. I quickly skimmed the wiki article, but I don't see the connection with implementing primitives. What did you have in mind?
I mean, I'd say it would be easier for a beginner, you won't get stuck on all the fiddly busy-work of dealing with pointers, all the tedious stuff is done for you leaving just the *actual work*. Take a look at [the documentation](https://docs.rs/vulkano) it's quite detailed.
A for loop in Rust like the following: for element in list { // ... } is compiled into the equivalent of: let mut iter = IntoIterator::into_iter(list); while let Some(element) = iter.next() { // ... } So it means if the thing you're looping over is an owning variable, `into_iter` takes that ownership, whereas if it is a reference, that invokes a different implementation of `into_iter` that just iterates over references (ie: the only thing it *can* sensibly do). Once you understand that, it's fairly intuitive I'd say :)
Well... My knowledge is limited, so I can be very wrong about this. When you allocate memory, the value has to be aligned to the size of the data. So, if you allocate memory for a pointer in a 64 bits machine, the last 3 bits of the address are always zero. Some interpreters use this to store primitive values directly in the address. For example, if the LSB is 1, you can read the address as an integer. In pseudo-rust: unsafe fn get_value(address: *const u8) -&gt; Value { let n = address as usize; if n &amp; 1 == 0 { *mem::transmute(address) } else { Value::Integer(n &gt;&gt; 1) } } Thus, you don't need to allocate objects to store integers, as far as the value fits in 63 bits. LuaJIT uses something similar, called [NaN-tagging](http://lua-users.org/lists/lua-l/2009-11/msg00089.html): - NaN-tagging: 64 bit tagged values are used for stack slots and table slots. Unboxed floating-point numbers (doubles) are overlayed with tagged object references. The latter can be distinguished from numbers via the use of special NaNs as tags. It's a remote descendant of pointer-tagging. Anyway, take all this with a grain of salt. I have never written an interpreter by myself. 
I think a really exciting application of this would be doing analysis of deployed ethereum contracts. Ethereum contracts are usually written in a high level language which is then compiled to Ethereum Virtual Machine instructions. The popular language is called Solidity. The compiled binary is then broadcast to the ethereum network and eventually included in a block. Ethereum contracts are small, and thus should be amenable to static analysis. And, since they often move money around, I think static analysis tools would be extremely valuable for improving security. Since there are so many contracts deployed to the blockchain, there's a huge space of interesting programs to explore. Do you think Falcon could be used for something like this? I see that Capstone doesn't support EVM, but they might be open to adding support for it, since it's pretty simple.
I believe you are looking for r/playrust. This subreddit is about the Rust programming language.
As `Tower` doesn't implement any functionality over `Vec&lt;u8&gt;`, you might as well just have it as a type (`type Tower = Vec&lt;u8&gt;`).
Thank you
My experience as well. Once I realized that Vim+YCM was using more memory (like, **a lot** more) than QtCreator, I pretty much gave up on using Vim for C++.
Note: the compile-time polymorphism implemented in Rust is a form of [*parametric polymorphism*](https://en.wikipedia.org/wiki/Parametric_polymorphism) because it depends on a type parameter, but it's also [*bounded polymorphism*](https://en.wikipedia.org/wiki/Parametric_polymorphism#Bounded_parametric_polymorphism) because this parameter can be bounded on a trait (`T: Trait`) or a lifetime (`T: 'a`). When we say that "traits are like typeclasses in Haskell", it's because typeclasses are also a form of bounded polymorphism. See for example the first answer to [this question](https://stackoverflow.com/questions/12430660/creating-polymorphic-functions-in-haskell), and imagine that you could write it in Rust by using traits instead of typeclasses (incidentally you could also write the second answer in Rust by using associated types). Also: parametric polymorphism is a form of generics.
I just want to note that specialization in Rust means [a different thing](https://github.com/nox/rust-rfcs/blob/master/text/1210-impl-specialization.md).
In five words: It depends, but probably no. In more words: The techniques implemented by Falcon are normally applicable to modeling CPUs. These don't always translate well to bytecode interpreters. However, [this](https://github.com/comaeio/porosity) was released at Defcon this year, a decompiler for Ethereum. My interest in ethereum's bytecode interpreter was peaked by this. What is especially interesting to me is there are *multiple officially-supported bytecode interpreters for ethereum* (C++/Go). What this boils down to is a discrepancy in the interpretation of bytecode between interpreters, which if found, could be reduced to a boolean condition. Such a boolean condition could be easily manipulated into interpreting programs differently based on the ethereum bytecode interpreter someone is using. This is an application for formal analysis, if ever there was one. Having had my interest peaked a second time in a week, I will give ethereum's bytecode a better look. The larger answer to your question is, I believe, yes, applying formal techniques, like those implemented by Falcon, to the analysis of Ethereum bytecode will most certainly yield security-related bugs of significance. However, I do not think Falcon will be the tool to apply those techniques.
Check out [reqwest](https://crates.io/crates/reqwest) 
&gt; there are multiple officially-supported bytecode interpreters for ethereum (C++/Go) Is there a C++ interpreter? I'm aware of Rust and Go full node implementations, but not one in C++ &gt; What this boils down to is a discrepancy in the interpretation of bytecode between interpreters, which if found, could be reduced to a boolean condition, could be easily manipulated into interpreting programs differently based on the ethereum bytecode interpreter someone is using. Finding discrepancies like this would be hugely valuable. The effect of a difference in interpretation would likely be to partition the network between implementations. Block S would be mined, implementation A would decide the state was S' and implementation B would decide the state was S''. Block S+1 would be mined, containing a transaction which was only valid if the state is S'. The A side of the network would accept the block, and the B side of the network would reject the block. The network would partition between the two implementations, and likely require manual intervention to fix. Even if it wasn't possible to directly steal funds this way, the attack would be extremely disruptive. You can see the split between the different nodes implementations here: https://www.ethernodes.org/network/1 It looks like geth is around 75% of the network, but parity (the rust implementation) has a large share as well.
Awesome, glad you decided to try out Rust! Your `Tower` struct, being a tuple struct, can be indexed like a tuple, so its methods can be simplified. E.g fn place(&amp;mut self, slab: u8) { self.0.push(slab); } Lines 98-107 can be greatly prettified using an `if let` construct: let n: u8 = if let Some(arg) = args.next() { arg.parse().expect("First argument should be a positive integer number") } else { 5u8 }; let wait: bool = if let Some(arg) = args.next() { arg == "--wait" } else { false }; or some of `Option`'s methods: let n: u8 = args.next() .and_then(|arg| Some(arg.parse().expect("First argument should be a positive integer number"))) .unwrap_or(5u8); let wait: bool = args.next() .and_then(|arg| arg == "--wait") .unwrap_or(false); Otherwise you're off to a really great start. I'd look into running [rustfmt](https://github.com/rust-lang-nursery/rustfmt) and [clippy](https://github.com/rust-lang-nursery/rust-clippy) to fix some minor styling stuff as well as point out places where you can be more idiomatic.
Thanks, I'll give it a shot
Presumably if you remove the docs key from your Cargo.toml, it leaves the previous version's link? Seems like a bug.
Pinging /u/sdroege_ who wrote `take_or_recover` and pushed towards `std::panic`.
Thanks for the reply! I've implemented most of this :)
Definitely an interesting idea, think I'll give it a shot. I'm thinking perhaps adding a `renderer` member to `GameState` that you can assign to that must implement a `Renderer` trait, though to be honest I haven't even gotten to that point in the Rust book yet, so I might be off base :P
Huh, didn't even realize that syntax existed. Thanks. I think I'll leave it like this in this instance because I like the improved readability/meaning that `place` and `remove` give in context, but good to know.
[This article](https://wingolog.org/archives/2011/05/18/value-representation-in-javascript-implementations) contains some details about pointer tagging, nan-boxing, and nun-boxing. Also [this](https://nikic.github.io/2012/02/02/Pointer-magic-for-efficient-dynamic-value-representations.html). You can also read [what SpiderMonkey does](https://developer.mozilla.org/en-US/docs/Mozilla/Projects/SpiderMonkey/Internals) (Jump to "Javascript values").
Interesting. We have a similar framework where I work (but written in Haskell) and it's also named after a type of bird. Small world :)
The LLVM AVR backend was recently merged. AVR support still needs to be added to Rust, though: https://github.com/avr-rust/rust
Installing and running `clippy` on your code is a great way for beginners to improve their code, and I think it's a tool that everyone learning Rust could greatly benefit from using. Congratulations on completing your first Rust project by the way!
If you want the `hyper` API you should probably use [`hyper-rustls`](https://crates.io/crates/hyper-rustls).
Thanks! I've actually already installed and run clippy on it haha :)
/u/nasa42 QOTW nomination for the second paragraph.
Mutable recursive data structures and mutable data reachable from multiple places are a design mistake in a C++. Otherwise, they are natural in Rust as well. &gt; What is the Rust programming paradigm? I'd say: ownership. After I switched to Rust (from C&amp;C++), the biggest difference is, I always know who owns what in my code. I design my code around ownership. It's the first thing I think about. I used to think: "what is the set of steps I need to do to get a result" and then added data structures around that. Now I think "what are the data structures, and their ownerhip relation that I need to get a result" and then add the code around that. In my personal experience everything else was a minor adjustment or a direct consequence of ownership. &gt; How to switch from C++ to Rust the right way? Join IRC channel for newcomers, be a nice person, and don't be afraid to ask for help. Rust is all about a great community. Set your expectations right: give yourself time, and don't stress when code does not compile. Most of lifetime and borrowing problems can be helped by some needless copying/cloning or sub-optimal design. Don't get blocked, do things sub-optimally, and fix it later, after you learn how. People write their code in inherently slow programming languages, and they are doing fine. You will be OK, if you waste some performance here and there in a generally very fast programming langauge.
I personally use a library called `type-safe-json-decoder`which is similar to the Elm JSON decoder system, so I'd probably end up using that. Of course there need to be some decisions made about what TS-side encoding to use for enums... Serde supports a pretty flexible way of doing this with its attributes like `#[serde(tag="foo")]` et al, but I would honestly probably just hack something together for my own needs...
That sounds about right. I think you do need a `Renderer` trait.
That sounds very plausible. I have a similar bug where I removed the "homepage" link (it just linked to the repository anyway) and after publishing an update the old homepage link is still there.
Ah ok, I think I actually *have* heard of this before. But never truly understood it. Now I do though. Thanks for your explanation, and /u/protestor for the links! I will keep this in mind as another optimisation to try, although I imagine there would be a lot of `unsafe` involved to make this work in Rust \^\^ (EDIT: maybe not, there's actually a crate [tagged_ptr](https://crates.io/crates/tagged_ptr) that suggests this would work quite nicely)
Here are a few simple steps to try Swagger Codegen Rust generator: wget https://oss.sonatype.org/content/repositories/snapshots/io/swagger/swagger-codegen-cli/2.3.0-SNAPSHOT/swagger-codegen-cli-2.3.0-20170807.044025-63.jar Linux/Mac: java -jar swagger-codegen-cli-2.2.3-20170703.140356-40.jar generate -i http://generator.swagger.io/api/swagger.json -l rust -o /var/tmp/rust/ Windows: java -jar swagger-codegen-cli-2.2.3-20170703.140356-40.jar generate -i http://generator.swagger.io/api/swagger.json -l rust -o C:\temp\rust\ 
&gt; Mutable recursive data structures and mutable data reachable from multiple places are a design mistake in a C++. What about trees, graphs etc.?
&gt; I've always considered polymorphism to be a dynamic runtime feature The term is actually more general even than this. It's not even an exclusively compsci term: for example, geneticists talk about [single-nucleotide polymorphism](https://isogg.org/wiki/Single-nucleotide_polymorphism), which in our programming terminology, would be when a DNA sequence is quantified over a nucleotide at a particular location.
deleted ^^^^^^^^^^^^^^^^0.9330 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/25349)
Thank you for the link. It exactly has what I mentioned about recursive data structures.
Once you said it, it looks more clear now about "C-like". When I first tried to write the code in Rust I tried to apply patterns that I used for C++. Is there any guide about "rust way of design"?
deleted ^^^^^^^^^^^^^^^^0.5347 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/74268)
[In this bit](https://doc.rust-lang.org/book/second-edition/ch10-01-syntax.html#using-generic-data-types-in-method-definitions) of the v2 book on generics, specifically about methods on structs w/generics, this sentence is hurting the fuck out of my brain: &gt; Note that we have to declare T just after impl, so that we can use it when we specify that we're implementing methods on the type Point&lt;T&gt;. What is *it*? What are we using? Who is specifying what? When would impl&lt;T&gt;'s T not be the same as the Point&lt;T&gt;'s T? What on earth does that sentence actually mean?
deleted ^^^^^^^^^^^^^^^^0.0696 [^^^What ^^^is ^^^this?](https://pastebin.com/FcrFs94k/28468)
Decided to play around with [gfx](https://github.com/gfx-rs/gfx) and port an old quake level viewer I made to rust. https://github.com/Thinkofname/rust-quake Apart from an srgb issue I encountered and a bit of a learning curve it went pretty well. The fact that shaders and command buffers seem tied to the platform still kinda sucks but apart from that it was much easier to work with than opengl directly like I'm used to. I think if the shader situation ever changed I'd like to use it for other projects too.
I've been working on a better [channel](https://github.com/stjepang/channel) for several months now (similar to `std::sync::mpsc` and the [chan](https://github.com/BurntSushi/chan) crate). Still a work-in-progress. What sets it apart from other channels: * MPMC: You can have multiple senders and multiple receivers. * Performance: Both bounded and unbounded variants are lockless. * Convenience: `Sender` and `Receiver` are `Sync`. You can clone them to share among threads, but you don't *have to* - giving out references is fine as well. * Selection: You can select over multiple channel operations - both *recvs* and *sends*. Supports CSP semantics, just like Go channels. * No macros: There is no `select!` macro. Dynamic selection is just as easy as static selection. * Fully-featured: Has the full range of `X/try_X/X_timeout` methods, and provides additional ones like `len` and `capacity`.
Out of curiosity, does `du` use more than one thread in its calculations?
I had the same use-case a year ago and wrote https://github.com/flosse/rust-json-file-store :) Maybe we can share some effort.
The declaration of `impl&lt;T&gt; Vec&lt;T&gt;` means "implementing `Vec&lt;T&gt;` for any type `T`. So, unlike struct declarations, where generic type arguments are declared right after the type name (e.g. `struct Vec&lt;T&gt;`), `impl` blocks declare generic type parameters after the `impl` keyword (e.g. `impl&lt;T&gt; Vec&lt;T&gt;`). This is necessary because there needs to be a way to distinguish concrete types from generic type parameters. Say we changed the syntax so that instead of `impl&lt;T&gt; Vec&lt;T&gt;`, we can just write `impl Vec&lt;T&gt;` to mean "implementing `Vec&lt;T&gt;` for any type `T`". This would suddenly mean something very different when a declaration of `struct T;` was added to the code. The code `impl Vec&lt;T&gt;` now appears to mean "implementing `Vec&lt;T&gt;` for the struct type `T`". As a consequence of changing the syntax, we now lack the ability to distinguish between the two declarations.
This is a convincing rebuttal, thank you for taking the time to provide it. Your reasoning and enthusiasm about the future of LSP is something I can understand and appreciate and I can see that a different approach might be in store. I will give your project a shot now and keep an eye on its development going forward.
As usual, TWiR and some clippy work. I've also been made aware of a possible unsoundness problem in optional, so I may revisit the design.
Continuing work on [tarpaulin](https://github.com/xd009642/tarpaulin) closing issues and hopefully getting onto some new functionality. Have a docker based test environment in the works that should let me test it on multiple distros and find discrepancies and generally improve the debugging process. I might even get round to tackling cobertura.xml support for codecov integration
&gt; Is cloning the repo, cargo building it, and then cping the executable really what I should do? I mean, this particular method is the classic method of installing non-repo software and exactly what we use `/usr/local` and `/opt` for. I'm absolutely down with that; it's the PATH manipulation that Rust and Ruby do, and the injection into system locations that NPM does, that irks me. Re: the distros, I'm of the opinion that once a package is in a distro repository, it becomes their responsibility to maintain the package and keep it in sync with upstream as you issue updates. It should be a one-time cost, either for the author or a volunteer, to get the project into the repositories, and then the distros either follow or drop. Until and unless an actually universal package standard comes along, that's absolutely not a burden that upstream should maintain; after all, isn't that one of the reasons distros *exist*?
I'm glad you received it well. I'm continually working on trying to balance verbosity with acridity, and I've noticed that if I get rolling, I can stray into unpleasantness unintentionally. Not a great habit to have, and I definitely had to prune this one a bit as I went.
I want to write a Wireshark dissector in Rust. If it works out, expect a blog post.
I have and I'm extremely interested to see how that plays out because it sounds like everything I've dreamed of wrt system state
(extremely 1970s voice) "yeah but \* is two keystrokes" I've never tried to cat a directory so honestly I have no expectations or desires about what that would do or mean
Working on my photo tagging program, now that I've got relm figured out I'll add a gui to it. Current features: * Read photo tags * import google location history * figure out geotag based on location history if the photo isn't tagged * group photos based on location or timestamp planned features: * Write kml's for groups of photos
Rust has one of the broadest use case reaches I've seen in a programming language, especially one that has a foot planted firmly in direct machine control. That said, AIUI, compilers often have a different suite of concerns for which more "mathematical" languages are better suited in terms of authoring the thing. A compiler is essentially a large, complex sequence of fold/transform operations and analysis which absolutely can be done in Rust, as evidenced by the fact that we're selfhosting, but ... `rustc`'s code is *not* pretty. I'm not a compiler dev at all; I just hang out with a few and have picked up a few things that may or may not be correct. ---- Personally, I think one of the markers for Rust having really firmly "made it" as a language is when another reasonably used language is implemented in it.
I've skimmed your source code and if I understand it correctly, the image is fetched all 50 ms from the camera and you end up with 20 fps. You may also lose a couple of milliseconds, depending on when Glib decides to call your receive function (though I don't know enough about Glib to say for sure). This may lead to a slow display, but I'm just guessing :) You can also try to remove the extra copy of the frame (`Vec::from(&amp;frame[..]);`). Make sure to compile in release mode and that your camera actually supports 30 fps of 720p in uncompressed RGB3 (mine worked better with YUYV). You can try to fetch the image in a tight loop without the sleep and to just use image.set_from_pixbuf from the receive function (just C&amp;P'd stuff together, don't know if it compiles :) ): thread::spawn(move || { loop { let frame = camera.capture().unwrap(); let (pic_width, pic_height) = frame.resolution; let colorspace = 0; let rowstride = 3 * pic_width; let vec = Vec::from(&amp;frame[..]); let pixbuf = Pixbuf::new_from_vec(vec, colorspace, false, 8, pic_width as i32, pic_height as i32, rowstride as i32); GLOBAL.with(|global| { if let Some((ref camera, ref img)) = *global.borrow() { // assign the pixbuf to the global here... (e.g. use an additional entry for the actual pixbuf) } }); // receive will be run on the main thread glib::idle_add(receive); } }); fn receive() -&gt; glib::Continue { GLOBAL.with(|global| { if let Some((ref camera, ref img)) = *global.borrow() { // get the pixbuf from the additional entry... img.set_from_pixbuf(Some(&amp;pixbuf)); } }) glib::Continue(false) } Because `capture` of the rscam is blocking, you will never end up with duplicated frames. Depending on how fast or slow Glib calls your receive function, you may lose frames. Try it out. You can also start the next loop iteration, when your receive function has been called. Then you have to use something like Condvar or channels to communicate. I've used rscam to display a live feed, too. Instead of using a full-blown GUI framework, I just used gfx to draw using the graphics card. You can also use piston_window or SDL, because gfx is too complicated for this simple use case (I wanted to learn gfx). Of course, it depends on the use case and if you actually need additional GUI elements from GTK or just a simple image live feed display. About my implementation: The basic idea was to upload the picture data rscam is giving you to a texture and draw it using the graphics card. I used another thread for fetching the frames in a tight loop and then using channels to send the frames to the drawing thread. This drawing thread checked for new frames with `try_recv` on the receiving end and reuploaded and redrew the image if this was the case.
Wait what What's the difference between that and `impl&lt;T&gt; Trait for T {}`?
Nice! Is there a Rust server stub generator in the works too?
`&amp;mut` is a reference which allows mutation of the referent. It belongs in the type of a binding. `mut` is a binding which can be directly mutated. It belongs in the pattern describing a binding. So you wind up with combinations like these: - Start with the basics: immutable binding to an immutable item. let a: A = A::new(); - And immutably borrow it somewhere else. let b: &amp;A = &amp;a; - Now let's make a binding which allows modification of its item. let mut c: A = A::new(); The item stored at C can be modified freely. - Now let's get a mutable borrow, as per usual. let d: &amp;mut A = &amp;mut c; Note that `d` cannot be changed to refer to any other instance of an `mut A`; it can only refer to `c`, but it does support modifying the contents of `c` via `*d`. - Time to move `mut` to the left again! This is a mutable binding, to an immutable item. let mut e: &amp;A = &amp;a; We cannot mutate `*e`, but we can swap out the `A` instance to which `e` refers. e = &amp;c; Also, all `&amp;mut` references can be placed in `&amp;` immutable type slots. The reverse is not true. - C-C-C-COMBO TIME: Mutable reference to a mutable referent. let mut f: &amp;mut A = &amp;mut c; We can mutate `*f`, as `f` is a mutable reference (`&amp;mut`). FURTHERMORE, we can swap out the target of `f`. let mut g = A::new(); `c` and `g` are both mutable instances of `A` and are distinct from each other. f = &amp;mut g; We can change where `f` is pointing, in addition to mutating its target. Do note that literally none of what I wrote will compile, as I flagrantly violate both lifetime and borrowck restrictions. Hopefully it does illustrate the difference between `mut name` and `&amp;mut Type` though. ---- If you speak C, Rust's `mut` is basically the inverse of `const`: - Immutable direct instance: const A a = A_new(); - Mutable direct instance: A b = A_new(); - Immutable reference to mutable referent: const A* c = &amp;b; - Immutable reference to immutable referent: const A* const d = &amp;a; - Mutable reference to immutable referent: A* const e = &amp;a; - Mutable reference to mutable referent: A* f = &amp;b; It's possible I swapped which side the `const` go on to modify reference or referent; I can never keep those straight honestly.
&gt; the classic method I hear you. But I really just don't care. If having to run 5 commands instead of 1 is going to prevent people from using my software (and while me or you might find that a bit crazy, it happens), then it doesn't matter whether one method is "classic" or not. &gt; Re: the distros, I'm of the opinion that once a package is in a distro repository, it becomes their responsibility to maintain the package and keep it in sync with upstream as you issue updates So in other words, it's out of my control. Hence why I will bend to more pragmatic endeavors. Just saying "it's their responsibility" doesn't actually do anything to help end users install your software. And I don't think there will ever be a universal package manager (for anything). The problem isn't just technical, it's social, and social problems are really hard to solve.
You don't need to wait. The `ignore` crate has one today.
These work with indices instead of `&amp;T` references. (Both are valid, it’s just different trade-offs.)
I imagine `du` would be IO-bound and more threads wouldn't help. Is this not the case?
Reading through [du.c from GNU coreutils](https://github.com/coreutils/coreutils/blob/master/src/du.c), I don't see anything that points towards the use of multiple threads for reading directories. Looks to me like a simple `while` loop. There may be other implementations that use threading though.
If I understand correctly, this is necessary because there isn't a syntactic difference between a type parameter and a concrete type, unlike say Haskell (`Concrete` vs `param`) or OCaml (`concrete` vs `'param`) so type parameters always have to be declared as such.
I am working on [mini](https://github.com/DevOrc/mini). A version of IRC client for windows. Similar to [tiny](https://github.com/osa1/tiny) 
You might want to use [GStreamer instead](https://github.com/sdroege/gstreamer-rs) for capturing and displaying, it already has optimized code paths for all that and can easily be integrated into [GTK applications](https://github.com/sdroege/gstreamer-rs/blob/master/examples/src/bin/gtksink.rs). If you want to stay with doing things manually, make sure to never copy the frames (gdkpixbuf is also not optimal here IIRC), and to do most processing outside the UI thread (including the actual capturing, any conversions, creation of the gdkpixbuf, etc), and ideally do rendering via e.g. OpenGL with shaders for any needed color format conversion (if there is any).
Why do you want the option in the hashmap generic second type? What's it adding to your logic? Also if you want the code shorter or maybe more efficient, try this api https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.entry .
Why do you want the option in the hashmap generic second type? What's it adding to your logic? Also if you want the code shorter or maybe more efficient, try this api https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.entry .
https://github.com/legolord208/crappy-chess-minimax
An important, ofter overlooked pattern to implement recursive data structure in safe Rust is to use indices into a `Vec`. This is for example what the graph library [`petgraph`](https://docs.rs/petgraph/0.4.5/src/petgraph/graph.rs.html#324-328) is doing.
Also instead of spawning the thread that just sleeps and does a idle_add(), you can use gtk::timeout_add() and return glib::Continue(true) from the closure to have it called forever again after the interval. However you should really do all that outside the main thread instead :)
My main language is Python, and I've never really studied data structures or algorithms (though I have a general idea of what's out there), so I'm going through CLRS and trying to implement bits and pieces in Python and Rust (Python to learn the algorithm, Rust to learn Rust and compare performance).
Yes, according to https://github.com/swagger-api/swagger-codegen/pull/6105#issuecomment-320300513 (the server stub is being worked on, not yet released)
EDIT: I misunderstood the question, so the original answer probably isn't much help. You might be able to use `Option&lt;User&gt;`, or if `FromRequest` isn't implemented for`Option&lt;User&gt;`, implement it yourself. Then in your function, do an #[get("/account")] fn get(user: Option&lt;User&gt;) -&gt; Template { if let Some(user) = user { /* do something with a logged in user */ } else { /* do something with an anonymous user */ } } ~~You could implement `FromRequest` on some kind of a `LoggedInUser` struct, and then include that in the function signature.~~ ~~That way, if the `FromRequest` impl of `LoggedInUser` fails, the route wouldn't match.~~ ~~Something like:~~ #[get("/account")] fn account(user: LoggedInUser) -&gt; Template {} struct LoggedInUser { username: String, } impl FromRequest for LoggedInUser { fn from_request(request: &amp;'a Request&lt;'r&gt;) -&gt; Outcome&lt;Self, Self::Error&gt; { let session_token = /* get token from `request`*/ if let Some(user) = get_user_from_session(session_token) { Outcome::Success(user) } else { Outcome::Forward(()) } } } 
It might be interesting to do something like 'crypto' in the way that hyper has provided 'http' - where cryptographic primitive types are exposed in a single crate. I think one of the really nice parts of this is you can provide safe APIs by default - like Nonce types always being consumed / impossible to reuse without unsafe. There are a bunch of rust crates for crypto right now and it's unclear which to choose - that might help?
Unfortunately I can't help much with your code, but I would like to share some experience: I've wrote a similar app using rscam and vulkano (not yet published) for 5 MP color camera which works on 75 fps. It works good, except relatively big latency ~180-200 ms. Vulkano gives reliable 60 fps and soft captures (in a different thread) 74-75 frames per second from camera. So I think the main source of latency is v4l stack.
I updated my web browser [titanium](https://github.com/antoyo/titanium) to use the newly published [webkit2gtk crate](https://crates.io/crates/webkit2gtk). I also added a command to write a password from the `pass` password manager directly into a text field of a web page. I also tried to update `relm` to the git version of syn to (hopefully) get better error messages within the attribute ([in this branch](https://github.com/antoyo/relm/tree/feature/better-errors)), but I haven't gotten far because updating to a new `syn` version looks as painful as updating a compiler plugin from a very old version of the rust compiler. Is it normal that updating from an old `syn` version requires that much work?
RustCrypto uses a slightly different approach: instead of using one big crate with crypto related types and traits it uses several quite small thematic [crates](https://github.com/RustCrypto/traits), which are in turn used by algorithm implementations. I personally think "crypto" crate (if mahkoh will provide access to it one day) is better used as an umbrella for structured collection of pure Rust crypto crates implemented using same traits and types. Regarding non-reusable nonces or zeroed on drop keys, we are not there yet, but it's certainly worth to experiment around such ideas. Currently we have only one example of such type: MacResult, which ensures constant time equality check.
No, Iron doesn't require nightly at all, while Rocket will probably not work on stable in the foreseeable future, which is why I would always recommend Iron.
Could you provide access to your source code? I want to do some transformations done to the image after capture and I think you approach might suit me well.