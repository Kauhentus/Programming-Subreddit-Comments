Can you open an issue? It is just a question of defining udp specific Async fns 
Probably not for a while
This is the documentation page for that GSL struct: https://www.gnu.org/software/gsl/manual/html_node/Providing-the-function-to-solve.html And this is the macro it refers to: https://github.com/ampl/gsl/blob/d3d2aee48c83d611764ae7a1a2b78df2dc6736af/gsl_math.h#L131 It may not be technically a closure, but it is being used as a crude closure and for the same purpose closures are being used. Now, you say using a vector is "sufficient", which implies that a vector is less powerful but simpler than a closure and since we don't need the full power of closures we should go for the simpler solution. But... vectors are not simpler. This is a translation of the GSL example form the docs to Rust, using a vector: fn my_f (x: f64, params: [f64]) -&gt; f64 { let a = params[0]; let b = params[1]; let c = params[2]; (a * x + b) * x + c } let F = GslFunction { function: my_f, params: vec![3.0, 2.0, 1.0], }; And this is the closure version: let F = { let a = 3.0; let b = 2.0; let c = 1.0; move |x| (a * x + b) * x + c }; I'd say the closure version is already simpler, but consider this as well: * The closure version results in a standard Rust generic type. The vector version results in a custom type. * The type in the vector version can only have `f64`s for its "_variable number of constant parameters_". The closure version can accept any type. Note that the original `glsl_function` could also have constant parameters of any type. * The vector version needs to use indices (which can go out of range if you are not careful!) to access the constant parameters. The closure version uses meaningful(ish - it's `a`, `b` and `c` in the example, but they **can** be meaningful) names all the way. And most importantly - the parameters will not be hard coded numbers (otherwise you can just write these numbers in the function) - and they'll usually have names. So the vector version becomes: fn create_my_f(a: f64, b: f64, c: f64) -&gt; GslFunction { fn my_f (x: f64, params: [f64]) -&gt; f64 { let a = params[0]; let b = params[1]; let c = params[2]; (a * x + b) * x + c } GslFunction { function: my_f, params: vec![3.0, 2.0, 1.0], } } And the closure version becomes: fn create_my_f(a: f64, b: f64, c: f64) -&gt; GslFunction { move |x| (a * x + b) * x + c } The closure version is superior in every way. Why not use it? Just because the OP's example from C doesn't use closures (which C doesn't have)?
What's up with the Go one? Is that a ferret?
The top three languages I consider in Hackathons are Python, JavaScript, and Go. JavaScript is pretty much unavoidable for fast prototyping UI (cross platform at that too), and Python and Go are popular backend languages with fast prototyping in almost anything. They are also very popular, which helps when you need to find teammates who are not necessarily familiar with languages like Rust, Haskell, Scala and the like. On the other hand, if you are working with embedded hardware hacks, go ahead and try Rust.
rustacean, like crustacean
As someone who just spent the whole day hunting for a NaN value caused by an `undefined` somewhere in his measly two pages of JavaScript code, I respectfully disagree.
Reminds me of the time in the mid 80's when i spent all day trying to find a bug in my C code (no debugger available). I wrote `x =- 10` instead of `x -= 10` or something like that. Those were the days.
There is an absence of `impl&lt;U: From&lt;T&gt;&gt; From&lt;Vec&lt;T&gt;&gt; for Vec&lt;U&gt;` and similar in the stdlib, which hints that what you're trying to do probably isn't the best of ideas... More generally, what you're trying to write is (in Haskell code): -- in stdlib, this is the best possible implementation instance {-# OVERLAPPING #-} From t t where from = id -- in Bewilderforce's code instance (From (f a) a, From a (f a), From t u) =&gt; From (f t) (f u) where from = from . from . from As you are encountering, Rust doesn't provide a way to work with overlapping instances, which have their own problems (FWIW, overlapping impls are WIP for marker traits [here](https://github.com/rust-lang/rust/issues/29864)). One solution that has been adopted in Purescript is having [instance chains](https://github.com/purescript/purescript/issues/2315). My 2c would be to write a `map` function for `Wrapper&lt;T&gt;` and call `.map(|x| x.into())` as needed. I understand this isn't what you want, but my hunch is that if you continue writing more complex stuff like this, you'll quickly run into some limitation of the type-checker which cannot be worked around even using a feature flag.
You've cloned the `Vec` out of the `Rc`. If had many items, or the items were individually large, that'd be much more expensive, and likely defeat the purpose for having it in an `Rc` in the first place.
Ah true I should probably have read the solution more closely
&gt; Auxiliary values This seems almost, but not quite, like Σ types in dependently typed languages: you want to return a value having some lifetime, and then another value dependent upon that lifetime.
Non-Mobile link: https://en.wikipedia.org/wiki/Open_Packaging_Conventions *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^210470
&gt; which hints that what you're trying to do probably isn't the best of ideas... Well, it hints something! It might also hint that `From t t` isn't the best of ideas—so my question is also, why is that instance^TWimpl given? It *seems* as if it prevents writing useful instances, and could be replicated by just allowing `#[derive(From)]`, which for non-parameterized types would just be the identity and for parameterized types would often (I suspect?) have only one sensible implementation. There [*is*](http://hackage.haskell.org/package/base-4.11.1.0/docs/Data-Coerce.html#t:Coercible) an instance `Coercible t t` (or rather, `a ~R# b =&gt; Coercible a b`), but GHC *also* creates a `a ~R# a' =&gt; Coercible (F a) (F a')` instance when the `a` type parameter is representational. (But `Coercible` is really not like `From`.)
It's telling you that you have a manifest in the parent directory. This puts `hello` inside a workspace, which you haven't properly configured. You need to either properly configure the nested projects, or delete `.../Learning/Cargo.toml`.
ahh! thanks a lot. Now everything is smooth.
If x is signed int, no type system can help here, but if it's unsigned one, Rust does the job: error[E0600]: cannot apply unary operator `-` to type `u32`
Println does a lot of thing as described by others. Here is a blog that explains a lot: https://matthias-endler.de/2017/yes/ The selected task is much simpler, print 'y' to the screen.
Yeah, I didn't spell out the types but that is the idea. I keep forgetting the places where the functions need to be annotated with the trait name.
Downvotes happen sometimes, even though you had explained things clearly. Some people are just anxious to downvote others, I guess... Your explanation is great though!
I see only few Rust projects incorporating the gear, nowhere near enough. The gear so kool... I now think of actix and wasm logos. 
I sometimes suck at communication so badly, that I have to assume I made a mistake in such cases. Also I'm not a native speaker, although I don't think that's the main issue.
I dig it, it's the heavy metal edition...
In terms of what a better error message would be for the initial example code, I think desugaring the `iter` call as shown later in the post makes it much clearer where the borrow is happening: let iterator = Iterator::new(&amp;data) Maybe something like that could be incorporated into the message.
Why not both? :-)
We're after a logo for [rust-random](https://github.com/rust-random) if you're interested, but nothing so fancy! See [#278](https://github.com/rust-random/rand/issues/278).
Excellent video! Two questions (for anyone): &amp;#x200B; Why do we need \`.iter()\`? Why doesn't whatever \`skip(1)\` returns just respond to \`.for\_each\`? &amp;#x200B; And the second similar question: why do we need \`collect()\`? Why doesn't the result of \`.skip(1)\` respond to \`.iter()\`? &amp;#x200B; I've never seen the need for those two methods in any other language. Is there some restriction on Rust's interfaces that causes the need for this? The \`.iter()\` seems absolutely superfluous, and isn't \`collect\` just a synonym for map? I've also seen it to convert lazy iterators into array iterators.
Given the way `From` is intended to be used, the blanket implementation makes total sense. Take for example: `fn x&lt;TypeLike: Into&lt;Type&gt;&gt;(t: TypeLike)` (where Type is not generic). This should always also accept a `Type`. Also, see similar usage in `?`, which does converts errors into errors using "Into" automatically. It's not wanted in some cases, but in these cases, a custom type can be easily introduces.
A linter looking for weird formatting could, though.
I've run into very similar problems several times. The real problem is the lack of specialization. Or alternatively, the lack of negative trait bounds. This problem, as well as the lack of shared traits for the builtin primitives, make generic programming in rust quite painful still. It sounds like specialization is not too far out, which hopefully will make the situation better. And the traits part can hopefully be covered by crates.io. What I've been doing in the meantime is to use macros. So rather than doing `impl&lt;T, U: From&lt;T&gt;&gt; From&lt;Wrapper&lt;T&gt;&gt; for Wrapper&lt;U&gt; { ... }`, use a macro to implement do `impl From&lt;Wrapper&lt;$type1&gt;&gt; for Wrapper&lt;$type2&gt; { ... }` for all values of $type1 and $type2 that you need. But that obviously doesn't help if you're trying to write a generic library.
Didn't you have a problem in comparision to people who used other languages and had a much wide array of tools to choose and use ?
no, only HTTP over TCP (or directly TCP proxying). I'm interested in what fastCGI would require, could you open an issue for that?
Once you're familiar with Rust, starting a new project and getting it working is usually fast. But for people planning to pick up the language during the hackathon, it will definitely be a bad experience, probably worse than with other languages.
Whilst i don't think that passing distinction is quite right, it is certainly true and not obvious that JavaScript has primitives which are not objects: ``` &gt; typeof(69) &lt; "number" &gt; typeof(new Number(69)) &lt; "object" &gt; 69.valueOf() &lt; VM248:1 Uncaught SyntaxError: Invalid or unexpected token &gt; new Number(69).valueOf() &lt; 69 ```
The services use RDS, Redis, or similar hosted databases as a service for simple CRUD operations. We had a look at streams, Kinesis, SNS, but there were no real need, so we haven't dug deeper.
Python isn't, it's just a language grammar thing. `8.` is a float, so `8. __str__` is invalid syntax. `8 .__str__` or `(8).__str__` works.
Everything here is insightful except for the unfounded shit about python.
&gt; a peculiarity of Java No, it's common to almost all managed languages. Smalltalk did this, Ruby does this, etc.
I've been actually working on a pptx parser crate, since i haven't seen one on crates.io. It's still not public, because it has a long way to go to be usable. Good to see there is actually demand for this. I planned it to be a reader only crate, but i will probably do a writer too. I have a full time job, so i don't have that much time for the project, but this is very motivating! I will let you know if it goes public.
I want to push Clippy a bit further towards 1.0 by starting work on https://github.com/rust-lang-nursery/rust-clippy/issues/3013. In the future the clippy.toml will hopefully/probably be replaced by a `[lints]` section in the Cargo.toml.
As a workaround I use auxiliar argument to store values I calculate in the function and then borrow from it. It wont work with this particular case of iterating ocer references from `Rc&lt;Vec&lt;T&gt;&gt;`. But I can return types that contains references to owned values way. Example struct Foo&lt;'a&gt; { bar: &amp;'a Bar, } fn foo&lt;'a&gt;(path: &amp;Path, aux: &amp;'a mut Vec&lt;Bar&gt;) -&gt; Foo&lt;'a&gt; { let bar: Bar = from_file(path).unwrap(); aux.push(bar); Foo { bar: aux.back().unwrap(), } } 
It is the correct link and works well for me. You can try this: https://www.pingcap.com/weekly/2018-08-27-tidb-weekly/ This week's link is as follows. You can try whether you can open it: https://pingcap.com/weekly/2018-09-03-tidb-weekly/#weekly-update-in-tikv-and-pd
[removed]
No, I mean, the `.map( |x| function(x) )` is an anti-pattern; `function` itself is preferable.
I've been spending some time refining my [checkpwn](https://github.com/brycx/checkpwn) CLI utility. I have had some problems getting tests to work that require input to `StdIn` after runtime arguments, with the `assert_cmd` crate. I've also been struggling with finding a good way to get more user-friendly errors/panics. Been looking at `human-panic`, but can't figure out if I even can, or how to, modify the panic message and wether or not I can make separate panic messages. Haven't found a good alternative approach yet either, so I need to put some time into researching this.
Good work! It would be a nice blog post, I saved it in my Rust articles folder.
Unless you have an *extremely* good reason for using FastCGI, don’t. It’s called fast because it’s fast compared with CGI, not because it’s *fast*. Compared with speaking regular HTTP, it’s generally fairly slow. Instead, use a reverse proxying arrangement.
I am working on a toy jvm and it requires casting to some structs. The obvious way was implementing `From` trait. I was going to implement that by hand but realized most structs has fields like `u8` , `u16` and `u32`. So I did some search to create a macro that implements `From&lt;&amp;[u8]&gt;` itself. I came with something and it passed with some little tests. But I am newbie in that low level stuff and I am not sure I implemented it with right way. Moreover I have never wrote any macro in rust. Here is my macro macro_rules! create_cs_pool_struct { (struct $name:ident { $($field_name:ident: $field_type:ty,)* }) =&gt; { use macros::FromBytes; struct $name { $($field_name: $field_type,)* } impl&lt;'a&gt; From&lt;&amp;'a [u8]&gt; for $name { fn from(bytes: &amp;[u8]) -&gt; Self { let mut buf = 0; $name { $($field_name: { let (val, size) = FromBytes::from_bytes(&amp;bytes[buf..]); buf += size; val },)* } } } } } Where `FromBytes` is a trait that is implemented on unsigned primitive types. Basically macro just defines the struct and implements `From` trait. Is this macro correct for my aim?
&gt; Kind request to those wanting to downvote: could you please explain the reason behind downvoting? I'd love to improve my communication, but I'm unable to see what is the reason I'm being downvoted. :( AFAIK, Reddit randomizes votes a bit, so it might not necessarily be downvoting.
I'm not advocating this particular implementation for standard library, this is just some quick and dirty code. By "generic" I mean I can use it like \`[scanner.next](https://scanner.next)::&lt;String&gt;();\` and \`[scanner.next](https://scanner.next)::&lt;i32&gt;();\` and so on. In C++ u can do \`cin &gt;&gt; x\` for various types of x, and in C you can at least do scanf.
I had a small PR merged - https://github.com/rust-lang/rust/pull/53774 It creates a 'rust-gdbgui' script to invoke GDBGUI (a browser based front-end to GDB) with the Rust pretty printers installed.
There was a proposal to hack `impl&lt;T&gt; From&lt;!&gt; for T` directly in the compiler to avoid problems with ergonomics, but I don't know if it was accepted. Keep an eye on [Promoting `!` to a type tracking issue](https://github.com/rust-lang/rust/issues/35121).
&gt;https://github.com/trustnote/rust-trustnote/blob/master/RaspberryPi.md Thanks for your reply. As we described in the instruction: *You may need to run* *sudo apt install libssl-dev* *if you see error messages like this:* error: failed to run custom build command for `openssl-sys v0.9.35`
I'm writing a small Rust program that uses `structopt` for command line parsing, is there a good tutorial somewhere for how to test it with `assert_cmd`? I looked at `assert_cli` but it seems `assert_cmd` is what I should be using going forward.
Well, is there a better alternative to `php-fpm`?
Yes, and every rust explanation mentions that but I still had the same "aha" realization as antitaoist. It just didn't "click" until it was explicitly pointed out that dropping/scoping and borrow checking are (in this context) separate processes. I had the same frustration "Can't you just infer that it's fine based on context!" 😜.
If I'm not mistaken, printf and println behave the same way with regards to flushing: they flush if there is '\n' written.
They have different semantics though? For example, mapping f over a vector isn't the same as applying f to the vector. Similarly mapping f over a Wrapped value isn't the same as applying f to the wrapped value.
You can also use the `interpolate_idents` crate, it works great on nightly, without buts.
I see, so this is supposed to emulate C++. I'm not very fond of the way it is done there, because it works very poorly for handling errors.
From the [Reddit FAQ](https://www.reddit.com/wiki/faq): &gt; Please note that the vote numbers are not "real" numbers, they have been "fuzzed" to prevent spam bots etc. So taking the above example, if five users upvoted the submission, and three users downvote it, the upvote/downvote numbers may say 23 upvotes and 21 downvotes, or 12 upvotes, and 10 downvotes. The points score is correct, but the vote totals are "fuzzed".
I've been working to improve the documentation and general user-friendliness of [TimeTrack](https://github.com/JoshMcguigan/timetrack), a utility I wrote to track how much time I spend on each of my projects. The next step is to document (and ideally automate) setting up TimeTrack to start tracking automatically when the system starts up.
Finishing up the work required to get this long-lived PR ( https://github.com/bluss/ndarray/pull/461 ) merged in `ndarray`.
Hmm, that doesn't explain negative score though. (It was negative at the time I wrote that.)
I've returned to some Rust code I wrote two years ago that can render a static screenshot of a [MegaZeux](https://www.digitalmzx.net/wiki/index.php?title=MegaZeux) world. I've improved its compatibility with existing world's, and now I'm working on parsing the included Robotic programs into meaningful Rust representations. You can follow along at the [GitHub](https://GitHub.com/jdm/libmzx) [repositories](https://GitHub.com/jdm/mzxview).
Yes this is true if you compile everything on the Pi. If you want to cross compile you might need to set OPENSSL_DIR, OPENSSL_LIB_DIR and OPENSSL_INCLUDE_DIR to Raspbian specific files. Unless pk-config magically works which it never did for me. ... unless the "vendored" feature of rust-openssl is used. But you guys don't seem to use openssl directly so I can't tell if one of your dependencies does. None the less I think it's something worth mentioning. https://github.com/sfackler/rust-openssl#manual-configuration
It seems like what I linked is outdated. There is no other official documentation, but apparently Reddit also [fuzzes the total number of votes](https://www.reddit.com/r/WTF/comments/eaqnf/pardon_me_but_5000_downvotes_wtf_is_worldnews_for/c16r7bv/). [Here](https://www.reddit.com/r/announcements/comments/28hjga/reddit_changes_individual_updown_vote_counts_no/) an admin talks about a "false negativity" effect from faked downvotes.
This is an excellent answer thank you, the lack of sugar around `.iter()` was something I had noticed before but until now I never realised the different iterator commands being the cause for it.
I was not communicating clearly. Compare: let v : Vec&lt;SomeType&gt; let u = v.map( |x| function(x) ) and let v : Vec&lt;SomeType&gt; let u = v.map(function) And remember that `x.someop()` is actually `SomeType::someop(x)`. 
&gt; UFCS Apparently it only applies to Trait functions.
I'll be hacking on my new game, various bits. One is to help make [VST thread-safe](https://github.com/rust-dsp/rust-vst/issues/49), including figuring out a suitable lock-free queue that can be allocation-free on the audio thread. I'll also restart work on xi-win-ui, which I plan to use for the UI of the game. I might also work on visualizations, maybe some code to make spectrogams, which I might use as static images on sigmoid functions suitable as components in digital musical instruments.
LOL
&gt; From a a', From a' a'' =&gt; From (Option a) (Option a'') Is that a thing you can actually express in Haskell? &gt; Consider the case where you have two type parameters Pair l r. What would #[derive(From)] generate in the absence of the blanket impl? An error, hopefully, telling you you have to do this one yourself. In the *presence* of the blanket impl, you can't write *any* of them!
&gt; Why do we need `.iter()`? Why doesn't whatever `skip(1)` returns just respond to `.for_each`? We don't. Starting at `std::env::args()` we already have an iterator. `skip` takes an iterator and gives you another one. You usually use `iter` on a "containy thing" to explicitly get an iterator. &gt; And the second similar question: why do we need `collect()`? Why doesn't the result of `.skip(1)` respond to `.iter()`? The goal is to parallelize over the items being iterated over. So, at some point we need to create a "parallel iterator". I havn't used `rayon` myself but I would guess that the kinds of iterators you can turn into parallel ones are limited. The crate has some specialized `ParallelIterator`s for most (all?) std containers and slices. `collect` would turn an iterator-based sequence into a Vec for which `rayon` provides a parallel iterator implementation. 
I have been playing around with the std::ops Traits to get a handle on programming in Rust. My question is regarding Neg. ``` impl Neg for A { fn neg(self) -&gt; A { } } ``` The body isn't super important. My question is: once you negate something it has moved into the negate and can't be used again afterward. Is there a Rusty way around this. My thought was to do this: ``` impl&lt;'a&gt; Neg for &amp;'a A { fn neg(self) -&gt; A {} } ``` But this makes negating look awkward because I am getting `an implementation of `std::ops::Neg` might be missing for `A`` when I do this: ``` let a = A::new(); let something = -a; let zero = something + a; ``` Is there a way to make it not look so awkward instead of me having to do `-&amp;a`?
Well if you reason like that, I don't think there is on true "pass by reference" language 
TIL, thanks!
\`scanner.next\` can easily return \`Result&lt;...&gt;\`. Currently it doesn't because every \`Option\` and \`Result\` inside of it is unwrapped, because in algorithmic challenges like codeforces input is always well-formed.
Thanks! That clears it up a lot :)
Python is my main language. I've coded directly against the Python C API enough times to have a dim view of Python's hugely special-cased and inconsistent object model. I still love the language!
Wow, its kind of mind blowing this works. Are there any fleshed out examples of how to use this in practice, e.g what types can be passed between Rust and C++? For example, if the full signiture of the function is as follows, could I omit all the arguments because of the default parameters? V8_PLATFORM_EXPORT std::unique_ptr&lt;v8::Platform&gt; NewDefaultPlatform(int thread_pool_size = 0, IdleTaskSupport idle_task_support = IdleTaskSupport::kDisabled, InProcessStackDumping in_process_stack_dumping = InProcessStackDumping::kDisabled, std::unique_ptr&lt;v8::TracingController&gt; tracing_controller = {}); If I were writing it in C++: let platform_ptr = NewDefaultPlatform() InitializePlatform(*platform_ptr) Also, how do I know if a C++ type is relocated in memory?
Why does `Functor` have an associated type? Isn't the `MapObj` always equal to the `Self` trait? ie. something like trait Functor&lt;trait G: Func&gt; over trait&lt;Item=?&gt; { fn map_mor&lt;A, B&gt;( xa: impl Self&lt;Item=A&gt;, f: impl G(A) -&gt; B, ) -&gt; impl Self&lt;Item=B&gt;; } 
Getting XML into the ZIP is the easy part. Generating XML that adheres to the Relax NG schemas of ODF (or OOXML) is error prone. This is a good area to take advantage of the the strong typing in Rust. The sum types in Rust are a good fit. One might generate runtime type,s serialization and deserialization rust code from the Relax NG schemas.
&gt; Is that a thing you can actually express in Haskell? PUNY MORTAL! HOW DARE YOU QUESTION THE POWER OF GHC!!! 😂😂😂 {-# LANGUAGE MultiParamTypeClasses #-} {-# LANGUAGE FlexibleInstances #-} {-# LANGUAGE UndecidableInstances #-} {-# LANGUAGE AllowAmbiguousTypes #-} {-# LANGUAGE TypeApplications #-} {-# LANGUAGE ScopedTypeVariables #-} module Demo where class From a b where from :: a -&gt; b instance (From a a', From a' a'') =&gt; From (Maybe a) (Maybe a'') where -- @ passes a type parameter from = fmap (from @a' . from) Proof that it actually compiles: https://godbolt.org/z/CHH4o2 One point worth noting: at the call site, there should be precisely one `a'` which works, otherwise you'll get an error, since there is no way to specify the `a'` externally (using a `Proxy` or equivalent). &gt; An error, hopefully, telling you you have to do this one yourself. In the presence of the blanket impl, you can't write any of them! You make a fair point, can't argue with that logic. P.S. Please ping me when you submit an RFC for whatever fix you end up aiming for 😉.
What's wrong with the value being moved into the negate method? The method requires returning a value of the same type, so you still end up with something usable afterwards.
Is the a workaround to needing get and set here? i.e. when you do `bitfield.field1` or `bitfield.field2 = ..` it would do the right thing.
It's Labor Day! I'm going to _push_ my alarm clock, right here, today, right now! And nothing is going to stop me!
Well, you need to wrap the C++ code in the cpp! macro, but otherwise it's just C++. Check out the documentation of the cpp crate: [https://docs.rs/cpp/0.4.0/cpp/](https://docs.rs/cpp/0.4.0/cpp/) &gt;Also, how do I know if a C++ type is relocated in memory? Any type that do not reference themself. This is the case of all the type that are trivially copyable. But also if they don't do any fancy thing in their copy or move constructor.
Neat. I didn't dig too closely but if you are using `failure` in your API, I'd recommend against that. It isn't mature enough for being a good base for a stable API and you users could end up needing conflicting incompatible versions of it. Some related crates that might be of interest for people who want something similar. - [privdrop](https://crates.io/crates/privdrop) - [clap-verbosity-flag](https://github.com/rust-clique/clap-verbosity-flag) Interesting crates being used - config - signal-hook - failable-iterator - [version-sync](https://crates.io/crates/version-sync). I never heard of this one before. Now I need to go add it to all of my crates!
Well written post. A bit formal but I think that's because you're not a native speaker. Something that interests me about this is does the use or rust or the LLVM change the results at all (faster, slower, more variances)?
Good thing you mis-typed both "tt" as "nn" in the title; otherwise, that could've ended in disaster!
Does this work for `tokio_uds`? If so, I should consider daemonizing my alarm clock "daemon" (background process) [basically, put it on the todo list].
AFAIU, Rust directly passes the assembly code in `asm!` to LLVM. I see the assembly code verbatim in the disassemble output. Based on this, I would guess that the results shouldn't change.
It does… and does not. There's no helper for autoconfigure uds yet, so you'd have to do quite some amount of manual work. On the other hand, the code could be reasonably similar to the code inside the `spirit-tokio` crate, and reusing the tools in there might give a good starting point to implement the helper.
The results will vary not only based on the architecture, but also: * Based on the processor clock frequency (including second to second changes for power saving, many modern processors will run at something like 800MHz if lightly loaded) * Based on the memory frequency (which is adjustable in BIOS on many desktops) * Based on the memory timings and sub-timings (which are adjustable in BIOS on many desktops) * Based on how many other cores are trying to access memory, your thread might not be first in line at the memory controller * Based on whether the RAM row containing your variable is already precharged from a past access (could dramatically speed up RAM access to nearby locations compared to random locations) * Based on whether a memory refresh has to happen just then and slows you down by several ns * Based on whether the cache clearing instruction followed by a fence could take varying amounts of time based on what's in the cache There's probably other things I'm not thinking of, and some of these probably aren't very significant, but modern processors and memory systems are very complicated. Still, though, congratulations on actually measuring it and not just going based on someone else's data!
[`printf` does not do locking](https://stackoverflow.com/questions/23586682/how-to-use-printf-in-multiple-threads). That's the real reason why this is so much slower.
Unfortunately I don’t believe there is, since rust won’t let you override the assignment operator (unlike C++).
If only bitfield support were in the language where it belongs. This is a nice workaround though
I really wanted to have `field` and `set_field` functions available, but the lack of ability to declare functions with joined identifiers in an `impl` block kept me from doing that. I’d have to mention both functions in the original macro call which was something I didn’t want to do.
It is usually easier to just include assets into binary with `include_bytes!` macro.
Is this game worth buying for a solo player?
If I'm reading that right, `printf` locks the output stream: &gt; Higher-level functions such as printf() conceptually call flockfile() at the start an funlockfile() at the end, which means that the POSIX-defined stream output functions are also thread-safe per call.
Maybe GTK+ is looking for a path relative to the current folder? You can use Process Monitor to see what files your program is reading.
&gt; Notice how the return type is different: for a functor, we want the return type to be over the same family of types as the input, but for B rather than A . However, regardless of what type Iterator::map is called on, it always returns an iter::Map: it’s not as parameteric as the functorial map. I'm sure I'm missing something but I don't really understand this line of reasoning. The real reason `Iterator::map` returns `iter::Map` is because `impl` in return position wasn't a thing in Rust 1.0. If we'd that feature, surely `Iterator::map` would look like: fn map&lt;B, F&gt;(self, f: F) -&gt; impl Iterator&lt;Item = B&gt; where F: FnMut(T) -&gt; B; Which, I think, means your type notation should be equivalent to the desired signature. Of course, this would still return `iter::Map` under the hood, but I don't see why that's relevant. `Iterator` is a trait so when you say `Iterator(A)`, you don't literally mean *an Iterator*, you mean a thing that implements `Iterator&lt;Item = A&gt;`. Which is exactly the same case for `impl Iterator&lt;Item = B&gt;`. Right?
In the mathematical world a functor can map to another category. Having the associated type allows you to express that other category, capturing the general case. The specific case where `MapObj = Self` means the functor is an endofunctor. This happens to be a very common case because monads are what everyone talks about and, loosely speaking, monads are defined in terms of endofunctors (the whole "monad is a monoid in the category of endofunctors" thing). It's just that people tend to use the term "functor" instead of "endofunctor" when talking about monads, possibly because that's how Haskell defined their `Functor` and other languages/frameworks followed suit. Scala, for instance, has ScalaZ and Cats FP libraries that define `Functor` the same way (at least until ScalaZ 8 IIRC). Since we're talking about categories of traits here, I think this `Functor` would be better defined as trait Functor&lt;trait G: Func&gt; { trait MapOb&lt;A&gt;; fn map_mor&lt;A, B&gt;( xa: impl Self&lt;A&gt;, f: impl G(A) -&gt; B, ) -&gt; impl MapOb&lt;B&gt;; } Or maybe a more direct translation like trait Functor&lt;trait F: Func&gt; { trait C&lt;A&gt; = Self&lt;A&gt;; trait D&lt;B&gt; = Self&lt;B&gt;; fn map_mor&lt;A, B&gt;( xa: impl C&lt;A&gt;, f: impl F(A) -&gt; B, ) -&gt; impl D&lt;B&gt;; } So that it allows expressing the general translations but is an endofunctor by default.
Wrong sub, mate. Looks like you meant to post in /r/playrust
This subreddit is about the programming language Rust, you’re probably looking for r/playrust
Nice post! I just want to share some comments from my code where I implemented `rdtsc` as a function: #[allow(unused_mut)] #[inline(always)] pub unsafe fn rdtsc() -&gt; u64 { let mut low: u32; let mut high: u32; // Is mfence really needed? why? and why twice? answer: yes, to // force all pending load/store operations to finish before executing rdtsc // https://stackoverflow.com/questions/41786929/is-mfence-for-rdtsc-necessary-on-x86-64-platform // We could also use rdtscp, which is newer and doesn't need a sequencing // instruction, but rdtsc+mfence is 90 ns and rdtscp is 33 ns //asm!("rdtscp" : "={eax}" (low), "={edx}" (high)); asm!("mfence"); asm!("rdtsc" : "={eax}" (low), "={edx}" (high)); asm!("mfence"); ((high as u64) &lt;&lt; 32) | (low as u64) } I assume you are interested in cache timing attacks, then try to replicate the [Spectre vulnerabilty](https://spectreattack.com/) in Rust. As a starting point, check out [this gist with a C implementation](https://gist.github.com/Badel2/ba8826e6607295e6f26c5ed098d98d27), straight from the paper.
 &gt; And then, I added a little Deref trickery to prevent someone from attempting to Copy or move the Fields type out of the Bf struct, which might put them in serious trouble if they called any function with &amp;self type punning! Unfortunately (for you), the [take_mut](https://crates.io/crates/take_mut) crate can give you `Fields` if you have `&amp;mut Fields`... 
I went with `rdtsc!` because `concat!` would accept only static strings. I couldn't use `format!` because `asm!` accepts only static strings too. I completely forgot about using a function call. Thanks for this. I did this experiment while reading the [Meltdown](https://meltdownattack.com/meltdown.pdf) paper. I was learning Rust too. So I do have plans to implement Meltdown/Spectre, at least in some minimal setting. Thanks for the gist too.
I agree clap-verbosity-flag might not work for your use case. Just wanted to give people options if the all-in-one solution doesn't work for them. &gt; As for failure ‒ I know the authors already avoid introducing breaking changes, because many people use that. I think there'll be some migration strategy eventually, if there's a breaking-version. I got the impression they were trying to minimize breaking changes rather than avoid them completely. They recognize they'll need to break changes but are avoid it because so many people use it. I admit this is my vain attempt at fighting back the tide against greater ecosystem fracture due to `failure`. &gt; I also need something that allows users to return whatever errors they need to from their callbacks ‒ and std::io::Error is not the most useful thing ever for that, while it is quite comfortable with failure::Error. The problem with putting `failure::Error` in your APIs is that it does not implement `Fail` or `Error` traits and so can only easily be consumed by client code that also uses `failure::Error`. In my code, I've been using `Box&lt;Error&gt;` if I want truly generic `cause`. Of course, this means you can't be `no_std` but I'm assuming something like `spirit` already requires `std`. &gt; I'm also a bit afraid failure might stabilize sooner than this crate ‒ it definitely has a head-start. Maybe for your case. For mine, I prototyped with failure and then had to move off of it because I'm trying to work towards 1.0. 
They explain some things I observed. When I ran the program 1000 times, there were some clear outliers. I didn't include them in the plot because they were so off, the actual box was invisible. Probably some event like refresh was happening then.
&gt; Given the way From is intended to be used, the blanket implementation makes total sense. I hate to beat a dead horse on this, but I don't think this claim has been supported, at least without adding the "where `Type` is not generic" clause. Given the way `From` is intended to be used, what makes total sense is that *every type should be able to be "converted" from itself into itself*. For type constructors of kind `*` (except `Void`!) the blanket implementation makes total sense (because there's nothing else for it to be anyway). But that doesn't mean that the blanket implementation makes sense *tout court* and unless there are restrictions on how `From` is intended to be used that aren't AFAICT documented I don't really see how the blanket implementation *does* make sense. I get that it's a done deal and all but it seems overly restrictive. The specific point where this came up was that I was working on a branch in nom where I wanted to replace the default custom error type, currently `u32`, with `Void`, since none of nom's internal parsers ever produce custom errors and it would make using non-`u32` custom errors a lot simpler (currently one has to both employ a wrapper macro and implement `From&lt;u32&gt;` on one's custom type, IIRC, both of which could be obviated). Inside the definition of `add_return_error` one would simply call `.into()` on the error being passed up, if any, from the child parser. But this needs to be done generically&amp;mdash;I know I have an `ErrorKind&lt;E&gt;`, but I don't know that `E` is `Void` in order to call `absurd` on it or that it's some other type for which a meaningful conversion is possible, or what. &gt; It's not wanted in some cases, but in these cases, a custom type can be easily introduces. Well ... how? `Wrapper` is a new type in my example. This `Errors` thing is drawn from something I encountered in Real Life and is a new type.
I don't remember ever running into `-l` for controlling verbosity before, and I've seen various situations where it'd collide with other arguments. On the other hand, `-v` with repeat is such a strong convention that people (myself included) build habits of just assuming it will work without checking. Eric S. Raymond's book, The Art of UNIX Programming tallies up these conventions in [Chapter 10, Section 5: Command-Line Options](http://catb.org/~esr/writings/taoup/html/ch10s05.html), including citing examples of existing commands which implement each flag. [Appendix G: Standard Command-Line Options](http://tldp.org/LDP/abs/html/standard-options.html) of the Advanced Bash-Scripting Guide also provides a less complete and less detailed listing, but mentions the `--long` versions which aren't covered in ESR's book. While `-l` has various meanings, none of them are synonyms for "--verbose". Likewise, pages such as [this Software Engineering StackExchange answer](https://softwareengineering.stackexchange.com/a/307472/35055) explicitly use `-v` as one of their examples when instructing people to follow platform conventions.
For the archives, the solution is the "template" method of App. Took me ~3 weeks to learn how to read Rust lib docs...
Honestly, without those help lines it isn't a nano clone (in my opinion). Those are why I use nano, and recommend nano as a default command line editor. Maybe you could put them in by default, and make them easy to turn off?
Process monitor said it found the file just fine. Copying the exe, app icon, and all the dlls to a separate folder and running it crashes. Doing the same thing but leaving out the dlls works fine. ???
Had I phrased it like that, I couldn't have used _without buts_ ;P
:-(
Maybe I didnt made it clear enough or I should better rename it for this reason - I just started with something like nano and then move on to something for one part shortcut- and one part command-based. 
Started a library for [InkML](https://www.w3.org/TR/InkML/) and published it just yesterday as [`inkml`](https://crates.io/crates/inkml). I was surprised the name wasn't taken yet! There's some *very* basic parsing for the `&lt;trace&gt;` data, along with some tests. Hopefully I get to work on it more this week!
OK! In this case please elaborate because I'm curious. I'm coding python for a living and know quite a bit about the python side (as opposed to the C side). I know how slots are weird and inconsistent, but everything else I encountered makes quite a lot of sense to me.
Tried that, no dice
Update: Seems to be only `libgdk_pixbuf-2.0-0.dll`. Removing that and leaving the rest of the dlls works fine. But the app just crashes trying to read the app icon (not due to the path, it can find it fine) if libgdk_pixbuf-2.0-0.dll is in the same directory
Just released [gutenberg](https://github.com/Keats/gutenberg) 0.4.2 and will have a look at https://github.com/Keats/validator/pull/60 that adds nested validation to [validator](https://github.com/Keats/validator). Still looking for input on renaming gutenberg as well: https://github.com/Keats/gutenberg/issues/377
This is the source of my worries https://plus.google.com/100130971560879475093/posts/PSVHJtJ5PGo and so I came here to be highlighted... Is that wrong? Thanks!
Fortran is the usual example of a true pass by reference language.
This seems like the sort of thing that should go in an IDE/editor, not in the source code.
Also, thank you for that link, the comments are hilarious as well.
Thanks, you reassured me, next time I'll do my homework.
The biggest problem with non-ASCII operators is that "you can't type them" and other people getting really upset about their code being non-ASCII. The non-ASCII idents RFC unfortunately has a lot of this. Ultimately, supporting built-in operators to do this is not really worth it. In a situation where custom operators are allowed, I would be in favor, but for something like Rust where the only operators are defined by the language, it seems unnecessary. That said, have you used ligature coding fonts? I use [Fira Code](https://github.com/tonsky/FiraCode), and these fonts render common multicharacter glyphs like `&gt;=`, `&lt;=`, `!=`, `-&gt;`, and so on as what they're most commonly used for instead of as separate glyphs. (Basically, the exact use case ligatures were designed for.) Fira Code specifically keeps the column count, so the width that aids scanning remains.
Check out [Fira Code](https://github.com/tonsky/FiraCode), one of the more popular code ligature fonts (since JetBrains started bundling it with their IDEs). `==` is still two columns wide, so that serves for at-a-glance recognition, the same way as without the ligatures.
It wouldn't be very difficult on a technical level, but the Rust teams don't seem keen on it. The best way to accomplish it would probably be something like [Haskell's `UnicodeSyntax` extension](https://downloads.haskell.org/~ghc/8.4.3/docs/html/users_guide/glasgow_exts.html#extension-UnicodeSyntax), but including the comparison operators, *etc.*.
Yes, a tricky part about this is where else should it be used? like you point out, == might be hard to find a substitute for given that = is already in use. At the same time, we don't necessarily have to have this for everything, although that does potentially create inconsistency
I've read some other posts in that account and I am unsure of whether the account its from a bot of a person. If its a bot, while its not very good, it can generate "readable" (as readable as this post) content in both english and german, so I guess that's not bad for a bot.
With the alias it can be overridden an an \`impl Functor\` block. Returning \`impl Self\` constrains implementations to always return themselves.
Some more intriguing gibberish from the poster's [front page](https://plus.google.com/100130971560879475093): &gt; Symbols of symbols give words. Words of words give sentences. Sentences of sentences give meaning. Meaning of meanings gives sense
To add to this answer: here's a paper which generalizes monads to relative monads, which need not be endofunctors. http://www.cs.nott.ac.uk/~psztxa/publ/Relative_Monads.pdf I barely understand it, but it was linked to from the [Linear Haskell](https://arxiv.org/pdf/1710.09756.pdf) paper, as an example for the Linear IO "monad" (see footnote on page 5:8).
Use a ligature supporting font. Best of both worlds.
I'm taking the week off and want to do something fun I don't normally do, so I'm attempting to port the `minimp3` MP3 decoder from C to Rust. I was intending to do it by hand, but `corrode` was just sitting there looking cool and shiny and written in Haskell, so I gave it a try. Results are inconclusive so far (which is to say the generated code builds after about 30 min of hand-hacking, then instantly panics), but the project is young. Might have to give `c2rust` a proper try. I also played with updating the `ggez` website. Gutenberg is pretty nice so far; I might complain that writing one's own template is easier than trying to figure out one of the existing ones, but writing one's own template is also really easy so it hasn't been a big deal.
Hi everyone! &amp;#x200B; I really excited to share something that u/nblumhardt and I have been working on this year: building a storage engine for our log server, Seq, in Rust. We're calling this storage engine \_Flare\_. &amp;#x200B; The storage engine work itself isn't open source (yet?). We'd love to open source Flare, but need to work out what it should look like, both from a publicly consumable API point of view and from a community point of view. I'm personally not a big fan of the open for reading, closed for modification/use approach. I'd rather try find a way to share it in a way that's properly free and community-driven. So, watch this space :) &amp;#x200B; I've got a lot more details to share in the near future about some of the ways we use the Rust language itself and libraries in the ecosystem, and how Flare itself works. In the meantime, you can checkout our \[acknowledgements\]([https://docs.getseq.net/v5.0/docs/acknowledgements](https://docs.getseq.net/v5.0/docs/acknowledgements)) page for a list of our direct dependencies and I'm keen to answer any questions you all have.
Interesting use of the word "Intriguing". I guess if you mean, "shit-brained" when you say "intriguing"! :smile:
I've noticed that all the methods use to split strings take a &amp;str and return references. I'm wondering, are there fundamental limitations that make it impossible to write a split string method that consumes a single string and returns a Vec&lt;String&gt;?
Hi, I looked only at the AST definitions, so sorry if I it's something it's taken care of, I also didn't read the Pratt paper. I see that your ASTNode includes expressions and also statements, e.g. operators and `SELECT` statements, at the same level. It looks like statements like `SELECT foo, (SELECT bar FROM ...) FROM ...` can be encoded in the ASTNode but I don't think they are valid in SQ L- I am not sure what is the intended semantics here, looks similar with `LATERAL JOIN`s but it is encoded differenly in SQL. How do you make sure that you don't parse statements like that as valid? Side note: I have implemented SQL-dialect parser/optimizer and I found it easier to have two levels of AST - one for expressions, one for clauses. Statements are composed of clauses, clauses are parameterized by expressions, `SELECT` statement are themselve relations (can appear in the `FROM` clause). I am not at all sure it's the right way though, may be I put too much responsibility at it as the opmimizer was working on the same AST representation. ​
I ran into this problem once, and I just rolled my own iterator that incremented an index.
My bad, you are right. 
If you have `fn split_somehow&lt;'a&gt;(s: &amp;'a str, other_args) -&gt; impl Iterator&lt;Item=&amp;'a str&gt;`, then you can make a very small wrapper around it that gives the `String` =&gt; `Vec&lt;String&gt;` interface you're looking for: fn split_somehow_with_copies(s: String, other_args) -&gt; Vec&lt;String&gt; { split_somehow(&amp;s, other_args).collect() }
In Firefox, you can clear the "Allow pages to choose their own fonts" checkbox (in Advanced font settings), and then choose your own favourite fonts. It's really nice to set the serif, sans and monospaced fonts to the appropriate members of the same family (like Source Serif/Source Sans/Source Code or Lucida Bright/Lucida Grande/Lucida Typewriter); it makes the web look so much tidier and cohesive.
Are you keeping track of the endianness of the values? Depending on the system a computer might store a 4-byte number like 0xaabbccdd as either [0xaa, 0xbb, 0xcc, 0xdd] or [0xdd, 0xcc, 0xbb, 0xaa]. `FromBytes::from_bytes` might be handling that. If you're doing this a lot, you might want to use a generic serialization library like [serde](https://crates.io/crates/serde), [protobuf](https://crates.io/crates/protobuf), or [capnp](https://crates.io/crates/capnp). They let you just put an attribute on the struct definition instead of wrapping the whole thing in a macro.
Best keyboard, Dvorak represent
I've gone back and forth on this a bit. The reason for settling on the current design is the simplification of things like subqueries. It is definitely possible to construct invalid AST structures though. I have also modeled it with a specific ASTSubquery variant wrapping a Select but that results in a cyclic relationship with ASTStatement and ASTExpr. I'll give this some more thought though. I appreciate the feedback.
Correct -- wrapping a subselect in parentheses in an expression context assets that it's a single value.
The problem there is that there's no way to split an owned string into multiple owned strings. If you want owned, you're reallocating. If you don't want to reallocate, you're borrowing.
Most allocators don't support splitting up an allocation into multiple pieces. So if you have a `String` that owns 80 bytes, you can't turn that into eight `String`s that each own 10 of those 80. Those 80 bytes need to be deallocated all at once or not at all.
Even if you are consuming the input string, and are willing to use an unsafe block to create the output strings? 
Could you use from_raw_parts to create the output strings and then somehow "drop" the input string without deallocating that memory? https://doc.rust-lang.org/std/string/struct.String.html#method.from_raw_parts
If you want to make a string that doesn't deallocate its data when it goes out of scope, that's exactly what a `&amp;str` is. You can fake it using `String::from_raw_parts` and `mem::forget` to make a `String` that doesn't actually own its data, but any operation you do with it that you can't do with a `&amp;str` will cause it to try to reallocate. Then you've got corruption of the allocator's internal data structures, and that's just not fun at all.
If this is all a machine-generated article experiment, maybe this is the algorithm!
Congrats! I look forward to see this being opensourced.
I'm not sure, but to clarify what I meant was that there are other compilers such as GCC or Clang with which you can roll ASM. I was wondering if they applied any changes to your code or were more efficient at getting to it somehow? It's not important, just a thought
https://en.m.wikipedia.org/wiki/Rpath I’m not familiar with rust and can’t say quite sure that this is possible. But as far as I remember mingw supports it (totally not sure).
It might be a bit out of scope (I think nano is probably a lot simpler from an implementation point of view), but IMO the `micro` editor [0] (written in Go) is the gold standard terminal editor from a usability perspective. Highlights: - Full mouse support (including selection and scrolling) - Standard GUI keyboard shortcuts (ctrl-s for save, ctrl-q for quit, etc) [0]: https://micro-editor.github.io/
Certainly interesting and I was looking into trying it for a (very) small scale logging system with minimal resources. Will there be standalone Mac and Linux binaries for the server, or remain docker only?
Cool! :-) It's possible that the first release might be Docker-only, but if so, we're fairly certain we'll ship binaries soon afterwards.
Distributing GTK on non-linux is always a nightmare; I'd recommend just finding another way.
Of course you can use `unsafe` to fake up allocations if you really want to. But your program will segfault when it deallocates the fake objects, and it'll be your fault! 
It [appears](https://github.com/arielb1/rust/blob/41578507a616affe87f168dbbc6d11437234bafd/src/librustc_const_eval/diagnostics.rs#L74) that it used to be emitted if you tried to match against a floating point constant which was NaN (not a number). But it's not an error anymore. This area seems to be a bit of a mess. Floating point matching was [phased out](https://github.com/rust-lang/rust/pull/32199), but the patch to phase it out [simply didn't work](https://github.com/rust-lang/rust/issues/41255), so now it's being [phased out again](https://github.com/rust-lang/rust/issues/41620). 
I think there are a lot of ways that Rust's standard library can improve speed, but as far as the speed of the actual core language, I would say it's equivalent to C. Rust gives you the exact same control over memory (if you're willing to use unsafe). I was actually doing everything with no_std, but then I realized I might as well just use C.
Still working on my game. `sdl2` \+ `gl` mostly. Last time I mentioned how useful` notif`y and` serd`e have been for development. I'd like to make a shout-out to the` sla`b package. It has an excellent API and an excellent implementation. It even helped me discover an insidious bug :D
You raise a valid point there. While *repeated* `-v` is not as common and I have seen `-l` in many places already (not with command line utilities, though), it is reasonable to expect `-v` to „just work“. I'll think about some solution there.
Custom-enriched Dvorak, but yes.
I can't wait to see the Dolphin change log on the day that they run on top of gfx!
Oh cool, thanks for posting this /u/varkora! This has been something I've been wondering about for some time now, but only got around to writing [a half-hearted gist about it](https://gist.github.com/brendanzab/4807db11b618070e5e32c8e98dbdc0ad) a couple of months ago. Glad to see folks doing a much better job though! Alas, it feels like we are somewhat hampered by Rust's trait syntax here, which is highly optimised for first-order traits. Seems to make the trait definitions quite hard to understand, but maybe that's just me...
Sorry. It turns out this is a bug in my reddit reader (Apollo). 
Do you really need to expose the whole function as unsafe? Couldn't you hide the asm statement in an internal unsafe block and expose a safe function? Or are there side-effects when using asm! ? I'm not quite clear as to what are the best practises when using unsafe
Awesome! I wonder whether I can frankenstein this on DXVK, to run games through Wine on my machine as I don't have support for Vulkan. 
Are you the author of Remmina? Thanks for that awesome app. It's cool that you're planning on learning Rust. Don't hesitate to ask here or on IRC when you have trouble with something.
Here is my own drunk refactor: https://github.com/Deedasmi/rmonopoly Commits have a brief explanation as to why I would do things that way. 
Maybe, eventually, we’ll get a full 3D board game out of this lol.
Is 42 mb the code size that can be shared among apps? What part of it is runtime, app-specific cost?
What about memory consumption? Electron apps for example are so memory inefficient that I'd rather not use them if it can be helped. Slack support telling me 1500mb for a text chat is ok? Don't think so.
Doesn't gfx-portability have a dx12 backend?
I've read somewhere about plans of bringing the `std::error::Error` and failure together somehow, starting with changes to the trait and then maybe making `failure` just a crate to put a thin layer over it and provide derives for easy to use errors. I hope this will come soon. Anyway, I'll keep the possible problems in mind when going forward and see if I can come up with better solution. The Box&lt;Error&gt; might be a possibility (and no, this can't be `no_std` and makes little sense anyway in this case).
Looks like it: Checking playground v0.0.1 (file:///playground) warning: this looks like you are trying to use `.. -= ..`, but you really are doing `.. = (- ..)` --&gt; src/main.rs:2:7 | 2 | *r =- 1; | ^^^^ | = note: #[warn(clippy::suspicious_assignment_formatting)] on by default = note: to remove this lint, use either `-=` or `= -` 
One of the maintainers, the author was Vic Lee. Shame on me for this posts!!! :-P Thanks for your love, we do our best and we'd really love to migrate it to Rust, but, as you can imagine, we still miss the competencies and the time to do it. Thanks, thanks, thanks!
Is this intended as a complement or alternative to cranelift/cretonne?
I can't, that's the point. If Vulkan is avaiable you may use DXVK for running DirectX games through Wine. I wonder whether gfx-portability will be able to translate Vulkan calls to something that is compatible with my system in the future.
Working on the port of my telegram bot from Kotlin to Rust - using telebot and diesel.
Ah I see. I think there's work being done on getting the OpenGL backend working for the new gfx-rs, not sure about the progress on that.
The Rust version does a bunch of things like locking to make it work with threads. It may also flush differently. It's a tradeoff. If you want a fast printf, write to stdout after locking it once and persisting the guard (or you can bypass the whole lock thing with a different set of APIs). &amp;#x200B; The formatting machinery isn't what's slow, here.
&gt; Relatedly, I'm going to run this red light. I spray-painted it green, so nothing bad can happen, right? "This is my pet lion. What? No, he's perfectly safe; I shaved him just like a poodle and named him 'Snookums'. He wouldn't hurt a \**cacophony of lion roars and human screams*\*"
A very quick look at the code suggests this is an interpreter rather than an (ahead-of-time) compiler. So I assume this is going for simplicity of implementation rather than run-time speed, at least at first. /u/Kimundi, what are your goals for this project?
While the OpenGL backend works fine on macOS, OpenGL is deprecated on Mojave so may not be an option in a few years. At the same time, the Vulkan backend performs really well but Vulkan isn't an option on macOS. So the two Vulkan compatibility layers may be the only options going forward unless someone volunteers to write a metal backend and maintain it.
If you can not ensure that the C API is called correctly through your safe interface, then no, you shouldn't wrap it into a safe interface. To take up your example: Let's say the C function takes a pointer. If the wrapper around it also takes a pointer it should not be safe, since it has no way to enforce the pointer is valid. A safe wrapper however may take a reference those invariant guarantees the object to be valid. Therefore it may expose a safe interface. In a nutshell: Exposing a safe interface to a wrapped C functions means encoding its documentation into the function signature. 
TTYs are evolving/being replaced on systems that are not stone age. In modern distros Wayland and KMS already make that possible (though with major problems sometimes because of not yet replaced tty's not pulling in libinput for its 'tweaks' for defective hardware).
I really doubt Apple will actually retire OpenGL in the future, there are simply too many legacy applications which will never be updated to Metal. Apple stopped seriously supporting OpenGL years ago, they never updated past OpenGL 4.1 in Mavericks (2013), and even that was 3 years late. The depreciation is just signaling the long term status quo of "it works, but don't expect any improvements or bug fixes". Apple wants developers to move on to using Metal rather than sticking with OpenGL and hoping things will improve.
[removed]
That doesn't strike me as machine-generated. It sounds like someone who misunderstood the "fearless concurrency" (parallelism, in this case) mantra that gets thrown around so often.
Doesn't work in most terminals unfortunately.
My language prototype. Need to now start checking how extensions could work.
That's "merde" for you, then.
In this particular case the function could be marked as safe, but you usually mark calls to extern code and x86 intrinsics as unsafe, just to warn the user. For example if I had used the `rdtscp` instruction instead, the program would crash on older CPUs where that instruction doesn't exist.
hm, how about ODBC integration for Diesel?
I'm planning to release a new version of [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) after doing a final review of the changes and writing up release notes!
I'm finishing my first Rust code that will end up in production. It took a lot more time than if I had coded in Pharo/Ruby/Kotlin/Swift but surprinsingly, I'm more confident to push that piece of code in production than any other code I've written. I've dabbled with Rust for a few side projects but I've never stuck with it. Rust has a way to push you to write robust code that I did not expect. The rigor introduced by the language has the nice side effect to increase your confidence. The code is mainly glue between RabbitMQ, Docker, a REST API and Google Cloud Storage. It was not easy and I lost some hairs in the process but I'm quite happy with the result. We'll see in 6 months if I'm still happy with that piece of code :p 
This is great, thank for splitting this out from datafusion.
I compiled on archlinux. May I know what system you are using and the version? I will try to compile on the same environment and see if I get the same issue. thanks. 
For a time now, I'm wondering, how to approach binary protocols in Rust, namely the X11. My main problem is, how to properly and idiomatically handle and represent data, which I want to send/recieve to/from actual server. Starting with connection setup, I am supposed to send to the server: ``` 1 byte: byte-order (value 0x42 or 0x62) -- 1 byte padding -- 2 bytes: protocol major version (11) 2 bytes: protocol minor version (0) 2 bytes: auth-prot name length (n) 2 bytes: auth-prot data name (d) -- 2 byte padding -- n bytes: auth-prot name -- (4 - (n mod 4)) mod 4 bytes of padding -- d bytes: auth-prot data -- (4 - (d mod 4)) mod 4 bytes of padding -- ``` The nicest thing I got, is Connector builder: ``` let conn = Connector .default() .auth(Auth::new(...)) .connect(); ``` Which is big piece of `self.sock.write(&amp;[... as u8, ...])` spaghetti. I cannot see using this in the actual response reading. Every idea/help is appreciated.
I agree with everything but I think [Iosevka](https://be5invis.github.io/Iosevka/) is way cooler than Fira.
I found [animated demonstration](https://youtu.be/rX0ItVEVjHc?t=30m32s) nice.
Very nice. Interesting.
I began work on my second big rust project involving a GUI + some web scraping (Taizen was my first). Still fooling around with the different GUI libraries. I finally hit page 300 of The Book! 
[removed]
This might be interesting as a frontend to https://github.com/CraneStation/cranelift which does not support WebAssembly directly. Nebulet developers might be interested in this - Nebulet is supposed to ingest WASM modules and feed them to Cranelift. There's also https://github.com/paritytech/wasmi as an all-in-one WASM interpreter, it might be worth a look.
Yeah, a tricky problem to consider, not to mention the churn for users. But it seems to be a good path that you're on in spite of the downsides. Really happy to see you helping to keep push graphics in Rust forward :)
Your `unsigned char data[1]` _is not the same_ as an `unsigned char*` pointer. The latter is a pointer to a piece of memory not contiguous to the struct, the former indicates a dynamically sized array contiguous to the struct allocation. It seems you should be able to replace this with the DST syntax for structs, just add a field at the end with type `[u8]` however this is probably not the same as what the C code is doing. In C a pointer to such a struct is a thin pointer and the length of this field is probably stored _inside_ the struct (or can be derived from somewhere else). In Rust such syntax make pointers to this struct become fat pointers, the length of the field is stored _outside_ the struct as part of the fat pointer. Then how to access such structs in Rust? I would declare the field as a zero length array: `[u8; 0]` with explanation how to find the actual length and have the users of this raw C binding use unsafe code to construct a `&amp;mut [u8]` themselves. Perhaps do not derive `Copy` or `Clone` to further drive the point home that this shouldn't be used as such.
Neat, that looks a lot less clunky than iterating by hand! Thank you!
Interesting, I like the use of match - that feels clean to me. =) Thank you!
Thank you for your help! The length is indeed in the C struct as well. The Rust representation is generated by bindgen, how do I override it? Especially without touching the original C code (the code is from another part of the company, I'm not allowed to changed it).
Part 2 of the blog is out now: https://blog.acolyer.org/2018/08/10/bounding-data-races-in-space-and-time-part-ii/
Ah half way throughout my post I forgot this was bindgen output. Honestly? Just keep the bindgen output and write a safe Rust wrapper around it which does the necessary unsafe code around the raw C api: eg. `from_raw_parts((*p).array.as_ptr(), (*p).length)`. The point is that the bindgen output should just expose the raw details and then you write a crate which wraps the raw C API in a nice safe Rust API. Your implementation of the safe Rust API then uses unsafe as necessary, hiding the gory details.
I think it'd be fine to keep it as a `[u8;1]` in the bindgen wrapper, just with a note about correct usage. You're guaranteed the one `UCHAR` allocated thus it's not incorrect and it's not worse than representing it with `[u8;0]`. Somehow I doubt this C is truly standards-to-the-letter-compliant portable though.
This is exactly what I'm trying to achieve :D My struggling right now is to allocate this struct: ``` pub fn send_data(code: u8, data: &amp;[u8]) -&gt; MyResult { let mut cmd: TheStruct = TheStruct { // easy fields data: // how to I stuck my parameter `data` in this data field? }; } ```
An important piece of context for this, I think, is that destructors can do _anything_. In toy programs, they might print a line to stdout. It would be pretty weird if deleting a totally no-op line at the bottom of a function could reorder the lines that that function prints. To make it easier to reason about "interesting" destructors, the rule is they always execute where the curly braces say they should. (Though binding a value to the magical `_` variable doesn't count as a binding at all, and the destructor will execute immediately. That's the only exception I know of.)
But that would require a VNC alternative which support rendering command stream and it needs to work with wayland. &amp;#x200B; Anyway thanks for the reputation - Ill give some more thought on it and see if I either can make something better out of it/use its code base for another project.
Portable was not a thing as the code is targetting Windows only, and it has been written many many years ago :-/
Awesome, I'm going to give this a try. Thanks for your efforts!
&gt; even if Rust had something like it, that patent wouldn't be enforceable because whoever wrote it did it in such a broad way (for better or worse) that many parts of it already have a lot of prior art. You've displayed a lot of confidence in the USPTO that I personally don't have. I hope you're the one who's right.
[removed]
Sorry I should have mentioned that it is an arbitrary dimensional array in the style of numpy with slicing. The code is at https://gitlab.com/half-potato/numox. I've had a lot trouble fighting the borrow checker.
Would it be possible (now or in the future) to run it on Windows? Not all devices have Vulkan, but I suppose all Windows 10 have DX12. On my Surface for example the provided drivers include only OpenGL but not Vulkan.
Fair enough, I'm not familiar with bindgen specifically but I've written some C bind glue myself.
In response to your edit 2: That isn't safe. Various undefined things will happen using that method in practice. Suppose, for example, that one of the substrings goes out of scope. If it's the first substring, it'll deallocate the original memory buffer, so now all the other substrings are referencing freed memory. That's incredibly bad (those sorts of bugs can often be manipulated into a security exploit). If it isn't the first substring, it's going to try to deallocate a memory pointer that isn't part of the allocation table. That will cause undefined behavior, depending on the memory allocator being used. Alternatively, suppose you modify one of the substrings; append to it. In that case the `String` will try to re-allocate (because it needs a bigger buffer). Often times that re-allocation call will invalidate the original memory buffer. Again, this will cause all sorts of havoc. Basically the root of the issue is that when you ask your memory subsystem for an allocation of memory, you can't later chop that piece of memory up yourself and then hand those pieces back to the memory subsystem. It won't know what to do with them; it can only see the original bigger chunk that it gave you. And since `String` owns the memory chunk you give it, it'll misbehave in such an inappropriate usage. That said, there are ways to achieve what you want. The `bytes` crate achieves this magic within the context of arrays of `u8`s. It does so by using internal referencing counting to know when a chunk of memory can be freed, when it has to allocate its own buffers to support your modifications, etc. Something similar could be written for arrays of `char`, but such a crate would have to have its own smart String implementation; you can't re-use `std::string::String`. (I don't know if such a crate already exists, by the way; maybe someone already built that?)
Yeah Rust doesn't help you here, manually calculate the size `mem::size_of::&lt;TheStruct&gt;() - 1 + size_of_data_field` and malloc that. Allocating should go through the new [`std::alloc` module](https://doc.rust-lang.org/std/alloc/index.html).
Why do all the iterator method return concrete types like `Map` or `Filter` rather than the Iterator trait? Seems odd to me, at least coming from java where you wouldn't want to expose the implementation. Is this a performance thing? 
You can insert in the middle in O(1) with `std::collections::LinkedList`.
Just to clarify, it is still undefined behavior to read/write past data\[0\] unless flexible array members are used.
That won't work because in C the [size of a struct is rounded up to its alignment](https://doc.rust-lang.org/std/mem/fn.size_of.html#size-of-structs), so if the struct has a higher alignment than 1 (which it will, if there is anything larger than a byte in there) this will do the wrong thing.
I`ve written a gtk app in rust and made a Windows port. It loads resources without any problems. I`ll try to find the windows port &amp; deployment scripts.
I don't think it's quirky or weird at all. It says it right in the book. Last I checked, there was even a section on universal function call syntax. Maybe if you've been writing java for a long time it seems odd, but there's plenty of languages where you can call methods on primitive types.
It sounds like you're looking for `std::collections::LinkedList`. Could you elaborate why you were hesitant to use `std::collections::LinkedList`?
DX12 and Metal are our primary targets. Metal is just more mature at the moment, but DX12 development [is active](https://github.com/gfx-rs/gfx/pull/2374). Also read the discussion on RPCS3 [issue 5000](https://github.com/RPCS3/rpcs3/issues/5000#issuecomment-414318648). FYI, the [gfx-rs](https://github.com/gfx-rs/gfx#hardware-abstraction-layer) graphics abstraction also targets DX11 and OpenGL, but there is no intention for them to pass Vulkan CTS - that would be too much effort for us.
You're not going to get O(1) delete from a singly-linked list...
Yes, exactly.
Uhm, let me mirror my comment I made [here](https://github.com/rustwasm/team/issues/79#issuecomment-418184473) real quick... --- I wrote an implementation of the Webassembly core spec in pure Rust as a learning exercise: https://crates.io/search?q=greenwasm. It excludes the text format, but includes some basic fuzzer scripts and an easy to use binding to the official Webassembly testsuite. The implementation consists of individual crates for all major sections of the spec: - `greenwasm-structure`: Contains the AST definitions. - `greenwasm-validation`: Contains the validation algorithms. - `greenwasm-binary-format,`: Contains a nom-based parser for the binary format (warning: slow to compile). - `greenwasm-execution`: Contains an execution engine. - `greenwasm`: Exports the above crates under a central crate name (eg, `greenwasm::structure`), and ties them together with testsuite and fuzzer tools. The implementation follows the written spec as closely as possible, at the cost of performance and usability. The idea is that it could act as a building-block, learning exercise or prototype scaffolding for others. :smile: The crates are mainly undocumented, but also directly follow the naming conventions and structures of the spec. --- Of special note is the [`greenwasm-spectest`](https://crates.io/crates/greenwasm-spectest) crate, which contains a mirror of the official webassembly test suite in form of an easy to use Rust library. It could be useful for other Webasembly interpreter implementations, as it is independent from the other `greenwasm` crates.. 
Its not intended as an alternative to anything serious in its current state. :D Right now its just a 1:1 implementation of the spec done as a learning exercise, which means its not really optimized or well designed Rust code. The execution part specifically is just a interpreter, that will probably be also annoying to use because it borrows the AST. (As I've noticed when implementing the testsuite) My plan in the near future is to write a more sane second interpreter, with the goal that is generic enough to simply reconfigure, eg to switch between different backends like a cranelift VM, or an optimized implementation with unsafe code, or alternatively something with extra assertions. As I wrote in the other comment, the main thing in there I think might be immediately usable is the spectest crate.
^The linked tweet was tweeted by [@CurrentlyDeal](https://twitter.com/CurrentlyDeal) on Sep 04, 2018 17:35:47 UTC (0 Retweets | 0 Favorites) ------------------------------------------------- Learning Programming is now 50% OFF on Sale.... Check it OUT!! You Guyz Gonna Love it... [https://www.humblebundle.com/books/machine-learning-books?partner=raalphn](https://www.humblebundle.com/books/machine-learning-books?partner=raalphn) [Attached photo](https://pbs.twimg.com/media/DmRGnPHWsAE-N-A.jpg:orig) | [imgur Mirror](https://i.imgur.com/XCOQmcf.jpg) ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
Are you testing in an optimized build (`cargo run --release`)? When I benchmark these with optimizations enabled, the running time is identical.
Thanks! That fixes it. I oftentimes find myself running into a situation like this where I seem to be unable to find a method in the std. I just had a look at https://doc.rust-lang.org/std/ops/struct.Range.html How would I figure out that a range has a *find* method? Is there a secret but that I'm missing that shows all the methods?
`Range` is one example of an [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html). The Iterator docs list most of the methods that you want. They also appear on the Range page, but in recent versions of rustdoc they are collapsed by default, making them harder to find. I hope rustdoc will be extended in the future to allow "important" impl blocks to be expanded by default.
I think if you use the structopt frontend to clap that you can put these configurations into a shared structure used for the separate subcommands that's flattened into the subcommands. I'm not exactly certain how, but I'm pretty sure that's one of the capabilities.
If your looking for a good terminal with advanced font rendering give kitty a try
IMHO, I think you're too young to be worry about that, my recommendation is that you do what I did, use Rust as much as you can for pet projects in your free time, think about something cool you like or just reinvent the wheel, try to have a strong portfolio of projects in Github and/or something to fill in your resume, you'll see sooner or later you'll land that dream job you want to.
Disclaimer: I'm not super familiar with crossbeam and I may be misreading your code. However, take a look at this bit from the `Arc` docs: &gt; Arc&lt;T&gt; will implement Send and Sync as long as the T implements Send and Sync. Why can't you put a non-thread-safe type T in an Arc&lt;T&gt; to make it thread-safe? This may be a bit counter-intuitive at first: after all, isn't the point of Arc&lt;T&gt; thread safety? The key is this: Arc&lt;T&gt; makes it thread safe to have multiple ownership of the same data, but it doesn't add thread safety to its data. Consider Arc&lt;RefCell&lt;T&gt;&gt;. RefCell&lt;T&gt; isn't Sync, and if Arc&lt;T&gt; was always Send, Arc&lt;RefCell&lt;T&gt;&gt; would be as well. But then we'd have a problem: RefCell&lt;T&gt; is not thread safe; it keeps track of the borrowing count using non-atomic operations. &gt; In the end, this means that you may need to pair Arc&lt;T&gt; with some sort of std::sync type, usually Mutex&lt;T&gt;. So I would suggest changing your RefCell to a Mutex or RwLock and see if that works for you :). 
&gt;I really doubt Apple will actually retire OpenGL in the future, there are simply too many legacy applications which will never be updated to Metal You're giving Apple a lot of credit here that I don't think is due. They have gone so far as to brick customers' hardware with updates, and they simply don't value backwards compatibility as highly as others. There's no reason to suspect they wouldn't break all legacy software, they've done it before. 
I'll give that a shot. What's still puzzling me, though, is if I create two concrete objects, I can spawn() both of them without a problem. If I create two inside a Vec(), it gives me all sorts of headaches about borrowing, mutation, or both.
Rust is available on EC2 in Amazon Linux 2's extras: [https://aws.amazon.com/amazon-linux-2/faqs/](https://aws.amazon.com/amazon-linux-2/faqs/). \&gt; For example, Rust is an extras topic in the curated list provided by Amazon. It provides the toolchain and runtimes for Rust, the systems programming language. This topic includes the cmake build system for Rust, cargo - the rust package manager, and the LLVM based compiler toolchain for Rust. &amp;#x200B; \&gt; *$ sudo amazon-linux-extras install rust1* &amp;#x200B; Though rusto SDK isn't amazon's, but it's still working for a large proportion of aws services (if not all).
If you have any interest in graphics, [gfx-rs](https://github.com/gfx-rs/gfx) is always looking for contributors. We have a [ton of shit](https://github.com/gfx-rs/gfx/issues) we'd need help getting through, if your interested, be sure to stop by at our [gitter](https://gitter.im/gfx-rs/gfx), so we can help.
&gt; I'd need to know more about your use case before I can tell what kind of data structure would be most appropriate. I'm trying to implement a [piece table](https://en.wikipedia.org/wiki/Piece_table), so judging by my own behaviour when editing text, there *will* be frequent insertions and deletions in the middle.
FWIW, rayon should make this easy too. The case with just two planes could be: rayon::join( || plane1.render_set(1000, starter_set_1, set_size), || plane2.render_set(1000, starter_set_1, set_size), ); And with `Vec&lt;Plane&gt;`, something like: planes.par_iter_mut().for_each( |plane| plane.render_set(1000, starter_set_1, set_size) ); 
I am very interested on how they will implement generics. I use Go a lot nowadays and would like to see it improve on that aspect as well as enums (which they don't mention in the draft, but one can hope).
I just realised I did not word that very well with "the node pointer". What I meant was "the pointer to the node behind which the operation is going to happen".
Just when you think you've seen them all... Thank you for the recommendation, will definitely look into it :D
This is a great post. A testament to the wonders of modern compilers. I wonder: since many optimizations rely on proofs of certain conditions to work and much of this proof father is presumably hardcoded, could it be interesting to integrate automated proof generators into compilers? The idea being that we no longer need to hardcode proofs, we can find more proofs of useful statements on our code and ultimately better optimizations.
I am fairly new to rust, but I don't see why you can't just roll your own, return type along the lines of Result&lt; ( T, Option&lt; Warning &gt; ), Error &gt; ... I don't think this will add a lot of verbiage to the code.
Yup! You can already do this in a limited form with assert!, more complex proof tools would let you define more complex invariants, leading to better optimizations.
It doesn't take a lot of effort, in fact that's how we have essentially written it in c/c++/c#/visual basic 6 (yes, 6 is still alive and undying in the manufacturing industry). though it's not 'Option &lt; Warning &gt; ' but something like 'Option &lt; WarningCollection &gt;' where WarningCollection is essentially a list of warnings, since a function can return *lots* of warnings (starting a program could return thousands depending on the industry, the machine setup, the state of the cell, the tools, the tool offsets, etc etc etc).
Epic!
You might want to take a look at the Rope data structure: A rope is a data structure for representing strings, so that many operations (especially editing) are efficient even as the string grows. Xi-rope implements strings, but also generalizes to other structures. [The Xi-rope](https://github.com/google/xi-editor/tree/master/rust/rope) implementation comes from the Xi editor.
Should probably roll your own thing. pub struct Details(Vec&lt;Warnings&gt;); pub struct&lt;T, E&gt; MyResult { Ok(T, Option&lt;details&gt;), Err(E, Option&lt;details&gt;) }
I tried to play around with communicating between TcpStream and TcpListener. Is there a way to communicate without a fixed buffer size?
Thanks for the recommendation! I've read a paper on the rope some time ago, and chose to use a piece table instead because I want to implement as much of the editor as possible myself and a rope seems to be very hard to get right. Maybe I got that wrong, I'll take a look at how xi implements it.
Can't you just take a slog library and log errors with a special marker or something? 
Could you please provide some links to such code? If there exists a (reflexive) equivalence relation between two types and `PartialEq` is implemented, `Eq` should be as well.
I've often considered, for certain types of cli programs, having an in-memory log of application warnings and errors (e.g. warn!(), error!()), and reporting them at program completion.
not really. Sometimes you want to silently eat a warning, sometimes you want to log and report it, sometimes you want to only log it after it has happened with a specific frequency, sometimes a warning is not a warning, it's an error in *this* specific context (customer, plant, division, machine, program, part, or even *just on this specific operation!*), ie it's entirely context dependent and usually handled by some script which is specific to the customer.
You can quite easily do all that with `slog`.
Think about this trivial example: let x = make_expensive_boxed_thing(); let y = TypeWithDrop::new(&amp;*x); If `y` _isn't_ dropped first, it will have a reference to `x` where `x` is already dropped. And that's a pretty big issue. If you need a different order, you can do `drop(x)` to explicitly move a value out of scope (and thus drop it) early.
Bingo! Exactly what I was wondering about! We currently have classes in multiple languages which all do this, but it's entirely roll our own, it's nice to use a standard (ish) system when we can.
I had to do this for the `ignore` crate, which tries to read patterns from `.gitignore` files. We definitely don't want to stop everything if we come across an invalid pattern, so I rolled "partial" errors into the primary error type: https://docs.rs/ignore/0.4.3/ignore/enum.Error.html [Some routines may then return a `Option&lt;Error&gt;`](https://docs.rs/ignore/0.4.3/ignore/gitignore/struct.GitignoreBuilder.html#method.add), but I can imagine other formulations being useful. I'm not entirely happy with this. It has worked so far, but I think there's probably a lot of room for improvement.
That makes sense. Thanks. I was looking at an example in the doc and wondered why it shouldnt work. So declaring before defining is a bad pattern in Rust. let y: &amp;i32; let x = 5; y = &amp;x; println!("{}", y);
I don't have any blog posts I've read readily available, but a [quick search on GitHub](https://github.com/search?utf8=%E2%9C%93&amp;q=derive%28partialeq%29+extension%3Ars&amp;type=Code&amp;ref=advsearch&amp;l=&amp;l=) shows a lot of instances where enums derive `PartialEq` but not `Eq`.
Then you'll just get a bigger allocation than you need, right?
Specifically for references to places defined later. It works fine for owned/'static data: https://play.rust-lang.org/?gist=2d2d911d3f4b2034d8659c5d4fb72059&amp;version=stable&amp;mode=debug&amp;edition=2015 When you say `let y: &amp;_`, the borrow checker assigns an anonymous lifetime to that reference from its declaration to its drop. The reference can be to anything that's guaranteed to exist that long but not anything that doesn't. And because we have to pick _some_ consistent drop order, that also means that things declared later cannot be borrowed over that anonymous lifetime. Drop rules are purely based on scope such that they are predictable and you can rely on them for safety. Borrowck runs _after_ drops have been inserted in that consistent order.
But please do pay attention to the subreddit in the future OP, if only to protect your karma.
[https://imgur.com/2FmRUF1](https://imgur.com/2FmRUF1) &amp;#x200B; &amp;#x200B; Maybe something this !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
It might not. Using `impl Iterator` means there's no way to name the type involved. That makes it difficult to e.g. put such an iterator in a field in your custom struct. Some of those limitations might get lifted over time, but in general with the standard library it's probably good to keep the types nameable, even though naming them explicitly is usually inconvenient.
Something in https://doc.rust-lang.org/nomicon/other-reprs.html might be useful. In particular, if there are C header files out there that represent the layout you need as a C struct, you can use something like `bindgen` to generate Rust struct definitions that'll use `repr(C)`.
Thanks for the detailed response! Your explanation of how the allocator would deallocate in this situation is exactly what I was missing. 
Ooh, yes please! My pet wishes are: - Allow Option&lt;T&gt; fields of structs to be omitted (with attribute to make it required). - Allow trailing Option&lt;T&gt; arguments to be omitted.
It seems you're benchmarking actix-web with logging turned on. Would be fair to comment out these lines: [https://github.com/klausi/rustnish/blob/0b38855de9514b9af203c890993f67ba39463a22/src/lib.rs#L58](https://github.com/klausi/rustnish/blob/0b38855de9514b9af203c890993f67ba39463a22/src/lib.rs#L58) [https://github.com/klausi/rustnish/blob/0b38855de9514b9af203c890993f67ba39463a22/src/main.rs#L17-L18](https://github.com/klausi/rustnish/blob/0b38855de9514b9af203c890993f67ba39463a22/src/main.rs#L17-L18)
For what it's worth, this is the way other languages, like C++ (ctor/dtors) and Go (defer) work too. You could look to Python ('with' blocks) and Java ('try' blocks) too. Those are slightly different, being blocks rather than the "same" scope but work in a similar "first in, last out" order. It might useful to think of "let" as introducing a new "non-lexical" (i.e. one you can't see) scope or block. This is actually how some languages' compilers (maybe even Rust's) structure variable declarations internally, whether or not they provide RAII (I used this in a Scheme compiler). And in this context it doesn't make sense to release things in any other order.
That's a great example of the issue. I can't tell you how many times I've parsed a customers data file and found out the file doesn't match the format specified and the line/data/item is ignored under the current context, or worse 'it just worked...sort of'. This should be a warning to fix things, or a flat out error where execution is halted...but which depends on context and so hard coding things may be the worst option at that specific moment. Another example, a file which uses CRC's internally. It's usually up to the user if they will accept a data file even if it has incorrect CRC's, it's not up to the library, but the user to determine the right behaviour.
Why does it have to use a certain drop order? Can't it use some sort of dependency graph that takes lifetime into account?
Something like this is possible with `rental`. You still need to allocate the `Vec` itself, but it's possible to let it hold shared references into another string, and then pass the two of them around together. Though for safety reasons you can only access the result through a closure: #[macro_use] extern crate rental; rental! { pub mod my_rentals { #[rental] pub struct StringRental { inner: String, vec: Vec&lt;&amp;'inner str&gt;, } } } fn new_split_rental(s: String) -&gt; my_rentals::StringRental { my_rentals::StringRental::new(s, |s| s.split_whitespace().collect()) } fn main() { let my_string = "a b c d e f".to_owned(); let my_split = new_split_rental(my_string); my_split.rent(|vec| { println!("{:?}", vec); }); } 
Unless something changes, `w_result` will likely never become a standard thing that folks use in the Rust ecosystem because it is GPL'd. (It's last update was also two years ago.)
The biggest reason is `unsafe` code; it's sound to rely on drop order to clean up dirty local state. Drop order was initially unspecified but then was added to the guarantees as people started relying on it.
No shortage of multithreading and concurrency challenges in the voxel game Veloren: https://gitlab.com/veloren/game/ There's a starting task that only requires some API massaging: https://gitlab.com/veloren/game/issues/72
Why do people rely on the drop order? I see you said it is a pretty big issue, but when exiting the scope, how can(and why would) you access the local state(like `y` in your first comment)?
Warning-collection? You mean an array?
Check out [contain-rs/linked-list](https://github.com/contain-rs/linked-list).
Targeting to finish my selenium webdriver client, [selenium-rs](https://github.com/saresend/selenium-rs), by the end of this week! 
&gt; "Most of what makes JS suck is the DOM and the horrific security mess of the Browser environment." That's your opinion, but I wouldn't say it's a common one. People generally don't like JS because of the language itself, not how it interacts with the DOM. There are plenty of complaints that people can level against Node.js, and that has nothing to do with the DOM and very little to do with security issues. Aside from that, with regards to WASM, there are plenty of use cases for it where you only really need to interact with a Canvas element, which would sidestep most of the potential DOM manipulation issues.
Then maybe just make it `Result&lt;(T, Vec&lt;Warning&gt;), ErrorType&gt;` ? The `Vec` already includes the possibility of being empty, so there's no need for the `Option`.
Since you seem to know all the possible implementations of FrameType, why not just convert FrameType to be an enum like so: pub enum FrameType { String(String), ISize(isize), Box&lt;FrameType&gt;, } Then you can just use pattern matching...
You might try my Iridium project here: [https://blog.subnetzero.io/](https://blog.subnetzero.io/). I am go through building a virtual machine interpreter in a series of tutorials, 16 so far. I'm happy to answer questions or help mentor anyone who wants to work on it. I would also recommend [http://interpreterbook.com/](http://interpreterbook.com/) and [https://compilerbook.com/](https://compilerbook.com/) by /u/thorstenball. If you want something even more bare-metal-y, you could try out a for-real OS here: [https://www.redox-os.org/](https://www.redox-os.org/). There's also TockOS, a real-time OS for embedded devices in Rust: [https://www.tockos.org/](https://www.tockos.org/). Last one is: [https://os.phil-opp.com/](https://os.phil-opp.com/). He walks you through building an OS in Rust.
Wow, admittedly, its only been my 2nd day of trying to program something real in Rust, but I remember seeing this and I don't know why I reached for Trait instead of using Enum properly. Thank you.
No problem :) I reached a point where I needed a trait with downcasting and was ready to explain what I did until I realized that you can probably use an enum. Enums are great. Languages like Java don't have real sum type support (I use java at work) and so I'm still getting used to reaching for them first too :D
There are just too many ways to handle warnings to come up with a single generic solution. Even within the same code path, runtime context changes can change completely how you want to handle warnings. The best I've come up with is to pass around an error handler callback that can classify anomalies and decide to return an error, add it as a warning or ignore the condition. You possibly want to have an upper bound on the number of warnings that can be generated so your `Vec&lt;Warn&gt;` doesnt ever fill up memory. But ultimately, it's really application dependent.
If you have some time, you can read the fantastic [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/README.html) and then decide which one of the implementations suits you best.
Unsafe internals use pointers which aren't borrow checked. You'd either use borrows or pointers to clean up. But sometimes it's done via a Bomb struct which panics on drop. That requires a defined drop order to be useful.
&gt; Or is that too much to expect from the language and should just be a 'roll your own' expectation? I'm assuming you mean "too much to expect from the stdlib". I'm not sure about how much is too much, but Rust's standard library is definitely on the leaner side (compared to say something like Python or C++). In terms of "roll your own" -- the good thing is that it isn't actually that hard! People here have suggested various designs, some of which are based off `Result`. My approach would be slightly different. The code is very likely not legal Rust, but you can get the idea. (Semigroup is short for [AbstractSemigroup](https://docs.rs/alga/0.7.1/alga/general/trait.AbstractSemigroup.html)) enum Attempt&lt;T, E: Semigroup&gt; { Perfect(T), Trying(T, E), Whoops(E), } impl&lt;T, E: Monoid&gt; Attempt&lt;T, E: Semigroup&gt; { fn map(self, f: impl FnOnce(T) -&gt; U) -&gt; Attempt&lt;U, E&gt; { ... } fn and_then(self, f: impl FnOnce(T) -&gt; Attempt&lt;U, E&gt;) -&gt; Attempt&lt;U, E&gt; { match self { Perfect(t) =&gt; f(t), Trying(t, e) =&gt; match f(t) { Perfect(u) =&gt; Trying(u, e), Trying(u, e') =&gt; Trying(u, e.append(e')), // append is the semigroup operation Whoops(e) =&gt; Whoops(e.append(e')), } Whoops(e) =&gt; Whoops(e) } } } The core idea is that (a) you should be able to define a sensible `and_then` function and (b) you shouldn't have illegal states allowed (e.g. Result&lt;Option&lt;T&gt;, Vec&lt;E&gt;&gt; can have no result and no errors, which is probably not sensible). I'd suggest using `Semigroup` instead of `Vec` as perhaps later you may want to have some other way of combining warnings. For example, it wouldn't be very helpful to keep around duplicate warnings, so you could use Sets. If you want, you could use a separate type `W` for `Trying` (for warning) along with an additional function that lifts warnings into errors, which would make the type more complex.
Also check out Intermezzos it's another OS tutorial that I enjoyed. Afaik it was inspred by Phil Opperman's thing, but not sure which one's more up to date at this point
Those places that use Rust will expect knowledge of computer science fundamentals, which you can learn online but which are mostly taught in university. Also, they chose Rust for a reason, it would be wise to be able to justify your own choice by learning and practicing other languages. 
"Cutning down" is a mouthful but doesn't sound so bad. Maybe sailorish, even.
ok - i am going to start by working on iridium! It looks very interesting and I think I will learn many new things. I will definitely pm you if I need any help!
Don't forget the `must_use`
You might also like https://danielkeep.github.io/itercheat_baked.html
As far as I understand, [Polly](https://polly.llvm.org/) is a LLVM addon which does such a thing: it generates a mathematical model of your program's loops so it can optimize them with [integer polyhedra](http://polyhedral.info/). Shoutout to [@DiamondLovesYou](https://github.com/DiamondLovesYou) who is working to [bring Polly support to Rust](https://github.com/rust-lang/rust/pull/51061).
&gt; "What are your actual objections to JS the language itself that don't apply to every single dynamic, weakly typed language?" We can start here if you like: https://www.destroyallsoftware.com/talks/wat Also, consider that there are few languages that have an equivalent to "JavaScript: The Good Parts", i.e. a popular book solely designed to steer you away from the worst parts of the language. I'm fairly confident you could find equivalent books for C++, maybe PHP too, but I'm not aware of any for Python, Ruby, etc... Regarding your objections to using canvas, what exactly do you see being the problem for games written in Rust that target a canvas element?
&gt; It seems unintuitive to me. It's the most intuitive way of dealing with possible dependencies/ordering effects. If you put on your socks and then your shoes, you have to "drop" them in reverse order, too.
It's a very simple crate, though. Wouldn't take too long to just roll your own.
It's intuitive if you think of stack variables as a stack. Declaration pushes a variable on the stack, and returning pops them all off gain, one at a time.
Lol omg
Note that if `x` is `Copy` then [`drop(x)`](https://doc.rust-lang.org/std/mem/fn.drop.html) does nothing. Which is why I don't really like the idea of using this function.
That looks promising, thank you!
`drop` does the exact same thing for `Copy` types that it does for `!Copy` types, technically; it makes a copy of the data in the stack frame of the new (empty) function. It's just that `!Copy` fields logically move into the function call and `Copy` fields remain usable. The thing to realize it that this drop function is not magic of any kind. (`Drop::drop` is _very_ magic and calling it is never directly possible.) You can literally define it yourself as `fn drop&lt;T&gt;(_:T){}`. There's no way to get rid of `Copy` data from your stack frame, as that's how `Copy` types work; if you want move semantics and being able to drop a variable in the trash, it shouldn't be `Copy` in the first place. If it's about references, manually dropping wouldn't change lifetimes anyway, as that's not how current borrowck or the new edition2018 nll borrowck work; the former's lifetime is from declaration to `}` and the latter's is from declaration to invalidation (which is somewhat of a tautology but I don't have a better quick way to describe it.)
It is possible to implement singly linked delete in constant time with a pointer to the node to be deleted so long as you can accept that any pointer to the next or current node will become invalidated. This can be done by copying the data from the next node into the current node, changing the next pointer, and deleting the next node.
[return change](https://gitlab.com/anire/projects-rs/raw/master/numbers/return_change/src/main.rs) If you ever write more than 3 similar if or while loops , you should take a step back and rethink your approach. In this case it doesn't make sense to declare the denomination and their names as source code. I would start with something like this const DENOMINATIONS : [(f64,&amp;'static str);4] = [ (5.0,"Five Dollar"), (1.0,"Dollar"), (0.05,"Nickle"), (0.01,"Penny"), ]; and build from there. 
There are features like that in literally every language. For example Ruby monkey patching can create absolute horrors. Knowing how and when to use them is **literally** the definition of knowing how to use it properly. You can write solid maintainable code in JavaScript, you can also write unmaintainable shit in it. The same is true of literally every language on the planet. Including Rust. Beyond that, if your killer app for webasm is browser games, then I think you've written it off even before me. 
It's a 'low-level' web framework similar to the ones you mention. With regard to generating HTML, it works just the same as any other: 1. Register a route 2. Have some actions performed (contact a DB, etc) when the route is requested 3. Return a response (could be HTML, could be JSON, etc) This page gives you a breakdown of the lifecycle: [https://rocket.rs/overview/#anatomy-of-a-rocket-application](https://rocket.rs/overview/#anatomy-of-a-rocket-application) In the docs, you can see it has support for templates: [https://rocket.rs/guide/responses/#templates](https://rocket.rs/guide/responses/#templates)
&gt; "Knowing how and when to use them is literally the definition of knowing how to use it properly." Sure, but not all languages are equal when it comes to volume of footguns (https://en.m.wiktionary.org/wiki/footgun) and ease of debugging. In other words, you can write good code in almost any language, what sets them apart is the hurdles that have to be overcome to do so. As for the WASM comment, consider the context of where we're having this discussion, i.e. a subreddit about writing games with Rust, commenting on an article about a company switching to using Rust for games development. Surely it's natural in this context that this is the first WASM use case to explore? There are naturally other use cases for WASM, but with the current implementations that exist for WASM it makes sense to focus on its interaction with canvas, especially as WASM does not currently have direct access to the full DOM (it's necessary to use JS to bridge WASM to the DOM, though this is likely to change over time). Also, bear in mind that work is underway to speed up general DOM operations (such as the parallel DOM work that Mozilla is doing), so it needn't remain a performance bottleneck in the long term.
What do you mean by 'does not support WebAssembly directly'? I think this part https://github.com/CraneStation/cranelift/tree/master/lib/wasm is supporting wasm directly.
Here is the full struct: ```C typedef struct _TheStruct { UCHAR Reserved [8]; UINT a; UCHAR b; UCHAR c; USHORT len; UCHAR data[1]; } TheStruct; ```
This pattern in known as the "struct hack" in C. &gt; So it's obviously a `UCHAR*`. No, it's not. `s-&gt;data` doesn't store an address. It stores the data directly. The data directly follows the other fields in memory which is kind of the purpose of this struct hack. But the expression `s-&gt;data` tends to "decay" to an address depending on the context. C is confusing that way and continuous to confuse people into thinking arrays are pointers. With TheStruct* s = (TheStruct*) malloc(sizeof(TheStruct) + length_of_data); enough memory is allocated in one block to hold the fields followed by the data. C makes the guarantee that struct members are not reordered. So, data is the last thing. And since there has been allocated enough memory it's OK to use `s-&gt;data[i]` as long as `0&lt;=i &amp;&amp; i&lt;=length_of_data` That's `length_of_data+1` bytes, one byte from the `TheStruct` object followed directly by `length_of_data` more bytes. &gt; Unfortunately, bindgen generate a `[UCHAR; 1usize]` as the field type for the Rust struct. As it should. It would be wrong to replace this with a `*mut UCHAR` because the memory is not used to store an address but the data itself. C99 recognizes this pattern and allows the last field in a struct to be an array of indeterminate length: typedef struct TheStruct { // other fields UCHAR data[]; } It's still not a pointer. But the `data` field can be used to address memory directly behind the other fields provided enough memory has been allocated. It's not equivalent to putting a 1 in there, though because now with `[]` there `sizeof(TheStruct)` would be smaller. I agree with `/u/RustMeUp` about leaving it as is and to use `std::slice::from_raw_parts` to access the data if you need it: unsafe fn internal_data_helper(ts: &amp;TheStruct) -&gt; &amp;[UCHAR] { slice::from_raw_parts(ts.data.as_ptr(), ts.length) }
Why do you need this? Does the C API contain a function where a user-allocated `TheStruct` is feed into? And if so, is ownership of this allocated thing transferred to the library? In other words, will the C code eventually call `free` on your pointer? If so, you have to allocate this thing via C's `malloc`.
You `buf` gets destroyed at the end of the function, you should probably `mem::forget` it or whatever. Also, I'm not sure what your strings are. C strings are whatever goes, but are `NUL`-terminated, Rust strings are UTF-8. You take two `NUL`-terminated strings, concatenate them, and return a non-`NUL`-terminated one. That seems pretty inconsistent.
I've done this so far: ```rust let layout = Layout::from_size_align( mem::size_of::&lt;TheStruct&gt;() + data.len(), mem::align_of::&lt;u8&gt;(), )?; unsafe { let myStruct = System.alloc_zeroed(layout) as *mut TheStruct; // other easy fields (*myStruct).dataLen = data.len() as u16; (*myStruct).data = // ??? } ``` I'm still stuck on how to put the parameter `data: &amp;[u8]` in a `[u8; 1]` :(
I'm mostly relying on the README here: &gt; Cranelift currently supports enough functionality to run a wide variety of programs, including all the functionality needed to execute WebAssembly MVP functions, although it needs to be used within an external WebAssembly embedding to be part of a complete WebAssembly implementation.
The article on "Flexible Functors" is quite interesting.
Ya, scope always (or should always) work this way - you can even use geometric interpretations (putting boxes inside boxes) or something as simple as HTML or balanced parentheses. They will all naturally have this same notion of scope.
[Playground](https://play.rust-lang.org/?gist=0b64f2173cf0c36ac89bb842378bcf57&amp;version=stable&amp;mode=debug&amp;edition=2015) use std::{alloc, fmt, mem, slice}; use std::alloc::GlobalAlloc; #[repr(C)] struct TheStruct { reserved: [u8; 8], a: u32, b: u8, c: u8, len: u16, data: [u8; 1], } impl TheStruct { unsafe fn data(&amp;self) -&gt; &amp;[u8] { slice::from_raw_parts(self.data.as_ptr(), self.len as usize) } unsafe fn data_mut(&amp;mut self) -&gt; &amp;mut [u8] { slice::from_raw_parts_mut(self.data.as_mut_ptr(), self.len as usize) } } impl fmt::Debug for TheStruct { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { f.debug_struct("TheStruct") .field("a", &amp;self.a) .field("b", &amp;self.b) .field("c", &amp;self.c) .field("data", &amp;unsafe { self.data() }) // A smidgen of unsafe :) .finish() } } fn main() { let data = [10, 1, 2, 13, 4, 5, 42, 7, 8, 9]; // Actual size and alignment of the struct let size = mem::size_of::&lt;TheStruct&gt;() - 1 + data.len(); let align = mem::align_of::&lt;TheStruct&gt;(); // Align the size to a multiple of the struct's alignment let aligned_size = ((size - 1) &amp; !(align - 1)) + align; println!("size: {} align: {} aligned_size: {}", size, align, aligned_size); // Allocate the memory let ptr = unsafe { alloc::System.alloc(alloc::Layout::from_size_align(aligned_size, align).unwrap()) as *mut TheStruct }; // Initialize the pointer unsafe { (*ptr).a = 42; (*ptr).b = 8; (*ptr).c = 13; (*ptr).len = data.len() as u16; (*ptr).data_mut().copy_from_slice(&amp;data[..]); } println!("{:?}", unsafe { &amp;*ptr }); }
Good point, I hadn't considered this.
Have a look at the \[intrusive collections\]([https://crates.io/crates/intrusive-collections](https://crates.io/crates/intrusive-collections)) crate.
Thank you so much! What's the `- 1` for (int the output of `size_of`)?
Really great and interesting article! I imagine it will help many new Rustaceans in their fight with the borrow-checker. One practical question, however: The article starts with a Lua snippet, and explains how 'lua closures are easy (relatively speaking)' because they use (reference-counting backed) garbage collection. When working with closures in Rust, is it then not an acceptable strategy to start out with a `move`-closure that works on `Rc&lt;T&gt;` and `Arc&lt;T&gt;`'s, only changing over to implementations that enforce stricter ownership when raw speed really is required? (So in other words: Is over-thinking what type of closure you should use maybe a case of _premature optimization_, rather than taking the simple route first, or am I missing something?)
Oh, and a side note /u/stevedonovan : In the first paragraph, you have a closing `)` without a matching `(`. This unresolved tension will now remain with me the rest of the day. ^^'
That's unfortunate IMO :/ I can understand the reasoning, but completely removing the links doesn't seem like the best solution. For example, just rename "Discuss" to "Reddit". *Or* link the main discussion platform (Reddit, URLO, IRLO, ...) instead. Of course, I'm not sure how much work that would be for you. *Or* maybe just openly encourage authors of blog posts to send a PR with a discuss link of their choice. I regularly want to read Reddit discussions about blog posts, so these links already saved me quite a bit of time. 
JavaScript coercion rules are kind of weird, especially if you use null, undefined or an empty array. These are pretty trivial to work with if you know the language and Typescript pretty much eliminates all of them. Lord knows Rust isn't a language you can just pick up and start coding in either. Missing out on one of these will probably just cause your application to crash, which is fine. The context of this conversation is specifically the focus of the Rust team on WASM. The developer in this thread isn't writing games for browsers. If you write Web applications using just canvas you're basically telling a large part of the Web community to go fuck themselves, it's not a viable option. Using the Web of you've got any kind of accessibility issue or you need to scrape data is hard enough, drawing it all on canvas would just make your a jerk. And the issue with the DOM isn't performance, the issue with the DOM is that the DOM sucks. That's not changing because it would destroy the Web. Surfacing it with rust won't make it not suck and the nature of the DOM is do alien to the way Rust actually behaves that it'll be a dog's breakfast under the hood. Rust is an excellent language, but WebASM is explicitly not designed to do what people keep thinking it's for. It's not designed to replace JS. 
Ouch!
Fully acceptable - no need to be always so damn fast! You can then share them easily. Not so ergonomic but can use macro sugar
Okay. So it's a backend server framework? By "generate HTML code", I meant if you could write everything in rust syntax, and have it converted to HTML for you. Is this true? Does rocket do this? If it does, I don't think it's too useful for people who already know web development. If this is not true, and it is a backend server framework, then what advantage does it have over Flask, Django, or Express?
Could you share your source code on GitHub? Without seeing your code I'd say check your fragment shaders, I guess you accidentally multiplied your color data with a zero somewhere. At least I used to make this mistake every time when I was taking my CG course in college.
Point of order, to quote myself: &gt; The problem there is that **there's no way to split an owned string** into multiple owned strings. I switched to "fake" because I assumed explicitly saying you can't split them was sufficiently clear, and because what you said in response made it sound like you were now trying to simply invent allocations: &gt; [...] use an unsafe block to create the output strings?
If you're experienced with C you shouldn't have too much trouble writing Rust. 
Ow Sorry will not do it again &amp;#x200B;
1. It's not a 'server framework', it's a web application framework. Fundamentally, it's Rust code designed to receive HTTP request data from a server application (nginx, apache for example) and return something back out via the server application in the form of a HTTP response (although it doesn't have to return a meaningful response, it could just write to a database, for example). 2. It doesn't 'convert Rust to HTML', it allows you to write Rust code that does something upon receiving an HTTP request. This very often, but not always, comes in the form of an HTTP response containing HTML. It has a templating engine to facilitate this. You write HTML templates with placeholders for your server-side data, and write Rust code that passes the data to the template, and then Rust produces HTML for you to use in your Rust code for whatever you need. It doesn't have to be HTML, either. 3. I don't understand why this wouldn't be useful - it works just like any other web application framework. For instance, Django and Express do similar things using Python and Node respectively, instead of Rust. 4. I can't speak for Rocket's advantages over other WAFs, but I imagine some of the advantages are congruent with the overall advantages of Rust: speed, code safety, etc. If I'm a Rust developer, and I need to write a web application, I'm going to want to write it in Rust rather than a language I don't know, like Python. The same question can be asked of Django or Express - it depends what the developer knows.
\&gt; " The context of this conversation is specifically the focus of the Rust team on WASM. The developer in this thread isn't writing games for browsers. " I didn't say they were writing games for browsers. However, there is clearly a games focus on this subreddit. If you want to complain about WASM in general, a better place to have that discussion is /r/programming . \&gt; " If you write Web applications using just canvas you're basically telling a large part of the Web community to go fuck themselves, it's not a viable option. Using the Web of you've got any kind of accessibility issue or you need to scrape data is hard enough, drawing it all on canvas would just make your a jerk." Fine, but as stated before this subreddit is about games. Semantic HTML exists so that different types of app can parse the HTML, but that's not applicable for games. You aren't going to need a screen reader for games, nor are you likely to scrape visual data from games. For games, canvas is absolutely fine to use. To be clear, the reason I suggest using canvas is because that's what WASM currently supports best. However, this is just for the initial implementation, once WASM can directly access the DOM then it can do everything that JS can do with the DOM. \&gt; " And the issue with the DOM isn't performance, the issue with the DOM is that the DOM sucks." Can you expand on what you're referring to when you suggest that the DOM sucks? \&gt; " Rust is an excellent language, but WebASM is explicitly not designed to do what people keep thinking it's for. It's not designed to replace JS." WASM is designed to replace one particular use case for JS, which is as a transpiler target. JS will still have its place for scripting, and there's too much existing code written in JS for it to die any time soon. Once programming languages reach a certain level of market penetration they basically continue indefinitely, and JS has definitely reached that level. If you're worried your JS skills becoming obsolete you don't need to, they aren't likely to any time soon.
Ow Sorry!
&gt; P.S. If I were persuing your line of thinking, I'd probably avoid special casing the Option class and just have the ability to omit things (in structs, and trailing things in calls) that implement Default, and just use the default there (which in the case of Option, is None). Some kind of generalisation definitely makes sense here, but `Default` has the problem of not working in cases where some fields are required (or don't have a sensible default). I think some mechanism of marking fields as required or not on a field by field basis would be important here.
The caller of the function that need this struct is responsible for the deallocation :) I'm implementing now. I'll keep you posted!
Thanks, will try again when the crate is updated with that MR.
That sounds super awesome. I will study it. Thank you for mentioning this!!
If anyone's interested about the off-shot line about using ML to improve on optimization (which is not expanded upon), I would highly recommend this talk: https://www.youtube.com/watch?v=6GBaH-knNBg Great article overall.
That's great! Thanks a *lot* for explaining so clearly. So it is *exactly* like Flask, Django, Express, etc. Nice. I've worked with Flask (along with Jinja as the template engine), and a little bit of Express (with ejs as the template engine). I'm learning rust now, and I wanted to make apps with it. Then, a week or two ago, I found out about rocket and WebAssembly. I worked with WebAssembly and Rust, along with NodeJS and webpack, but I found webpack uncomfortable to use. Is there anyway I could use Rocket with WebAssembly?
Phil’s is farther along; I haven’t had as much time as I’d like. There used to be more of a divergence but some stuff changed recently that eliminated a lot of the work I had to do previously; you no longer need to go to log mode yourself. 
Alright guys, sorry for not getting it the first time. I appreciate the help.
Yeah, it only comes up in really specific scenarios where the memory cost of that extra pointer/index for a doubly linked list is too much. One use is caching really small values in an LRU cache using the list to string together the ordering of access. There might be some uses for kernels to keep low memory footprints for schedulers, but I can't think of much else I would ever use it for since linked lists are so rare.
You responded to an ancient thread in which I was having a conversation specifically about the areas the rust core team were choosing to focus on. **One** of those areas was webasm, which I commented on. This is a rust subreddit not a gaming subreddit and so discussion of the priorities of the rust core team is completely appropriate. The fact that your comment on JS as a language is that stupid video which doesn't explain **why** any of that happens and that you don't already know why the DOM sucks indicates you know two tenths of stuff all about Web development or the JS language in the first place. The fact that you think this sub has a gaming focus makes me question how much you know about Rust. Webasm is intended to allow for certain performance critical tasks to be possible in the browser. It is absolutely not intended to replace JS in any context. I'm not worried about losing my JS skills, I'm worried about having to download megabytes of webasm code written by people who don't actually understand front end design. I'm also somewhat concerned about resources being spent on webasm support for rust when the language has more urgent requirements. 
I had hoped there was a review platform that has the domain project.rs. It seems to be available!
You can, though the type signatures involved get pretty noisy: https://play.rust-lang.org/?gist=524bd740be8a9cd312a209ea1c60922f&amp;version=stable&amp;mode=debug&amp;edition=2015
I'm using [Command](https://doc.rust-lang.org/std/process/struct.Command.html) struct to execute some process and I want to parse it's stdout. If I use [output](https://doc.rust-lang.org/std/process/struct.Command.html#method.output) method, it will give me Vec&lt;u8&gt; which I then can convert to String. Is there a way to not collect all output, but to parse data line by line discarding unneeded strings after they've been parsed?
By the way, is there a standard no-cost "non-empty vec" data type?
I'd like some ideas on what to name a type. I want an enum that behaves like `Option`, but instead of marking whether something exists, marks whether something is mathematically defined. ``` enum NeedsAName&lt;T&gt; { Defined(T), Undefined } ``` What is a good name? I'm stumped.
Have you considered (or have you already) posting this to the [Rust Internals](https://internals.rust-lang.org/latest) and/or [User Forums](https://users.rust-lang.org/latest)?
Radox os and its side projects
I see what you mean now - using Option to explicitly opt in to optional values for parameters and structs, not just making option nicer to use.
I wonder if it would be possible for `openssl` to release a new `0.9.x` that backports the detection fix. Then, it should be just a `cargo update` for most applications to get the fix too, even if the depending libraries aren't modified 
I think you wrote some Go there lol
More than this, shouldn't he be able to just use `any`?
It is kind of a trick, and its not that advanced, its just type specialization. No, it probably won't go away, as it is fairly fundamental type specialization behavior. 
I'm not sure if the newsletter should be a driver of discussions at all. Blog post authors can provide their own "discuss" links in the post or host their own comment functions.
Oof. Thanks. Lol. Fixed!
Since IPC by definition is outside of the process, you will have to rely on some kind of special OS support. The only kind of IPC that is offered in the same way on most systems are sockets. You might be able to get by with named pipes. Both Windows and UNIX-likes support them (through distinct APIs).
One could consider https://github.com/erickt/rust-zmq
This is more of a style question. Let's say I have a bunch of nested enums. [Example Code](https://play.rust-lang.org/?gist=074e79de12d1f90c161d278c3fe381a0&amp;version=stable&amp;mode=debug&amp;edition=2015) So as you see, the nesting causes steadily greater expansion of type size. With just a little bit functional depth (say, nom parser macros), this leads to a stack overflow. The solution I've struck on is using boxes everywhere for the nesting so the data is stored on the heap. But that is a mass proliferation of boxes and boxing. So here's the question: What amount of boxing is stylistically preferred? As little as possible? 
Or I could wrap up the smart pointer stuff in my enum types to clean up the boxing both in the type declarations and the code itself. Would that be stylistically preferred? 
*Existential* ? But might conflict with the coming existential type feature.
&gt; WebAssembly had only support for two datatypes, integers and floats, and everybody seemed to say you had to use [wasm-bindgen](https://github.com/rustwasm/wasm-bindgen) to use other datatypes like arrays (JS)/vectors (rust), Strings, etc. Which is mostly applicable to the interface between web assembly and JavaScript as the compile abstracts over the WASM when compiling so you only need to worry about data coming into our leaving WASM. This what wasm-bindgen helps you with, creating these bridges by generating bindings for the JavaScript and WASM side for you. You can do it by hand if you want but wasm-bindgen takes away all the boiler plate code. &gt; Is there any other way to use other datatypes (and may be JS objects+functions) with wasm? You can use any data type you want, the only restriction is when you want to talk to and from JavaScript. You need to convert anything you want to send back and forth to the basic types that WASM supports. All wasm-bindgen does is generate these translations for you on both the WASM and JavaScript sides. &gt; And also, I had to use NodeJS and webpack to get wasm-bindgen to work, is there any way I can use it with [rocket](https://rocket.rs)? You can use [wasm-pack](https://github.com/rustwasm/wasm-pack) instead of node.js and webpack to create a js package. But rocket is server side code, and WASM is client side code, in essence you have two applications, one that runs in the browser that gets compiled to WASM and one that runs on the server side and gets compiled to native code. Rocket does not care about WASM and will not help you at all with dealing with it. However, once you have generated your client side application you can use rocket as a fileserver to serve the assets to the browser, but that is as far as rockets involvement goes.
I recently went through the emulator101 tutorial. It's in C/ObjC but I did it in Rust. was great, highly recommend. The author is good about not hand holding too much so you have a chance to learn on your own, but if you get stuck you can refer to their source. http://emulator101.com/ 
I did the interpreterbook in Rust, and it was great. The author provides a lot of tests, so you can basically just duplicate their tests in Rust and then do the rest of the design on your own. 
True, and the fact we use this same idiom in *four* languages means I'm used to doing it. I was just asking if there was some language common thing for this, not necessarily if someone had done my work for me. Result was in the language (well, in the standard library) and so it's use has become ubiquitous. Our code base uses it dang near everywhere and so I was just wondering if there was something like this that I had just missed yet. There was (in an external crate) so it's awesome to know it's a known idiom in rust, just not one so standard as to be included in the library.
Well the type inference needs to consider both all the constraints that `type_with_tag = IntoTypeWithTag::into_type_with_tag(...)` imposes as well as the constraints that `type_with_tag.say_trait()` imposes in order to deduce the type of `type_with_tag`. I'm pretty impressed with that. I'm also still unsure why overlapping implementations for traits aren't allowed if one can seemingly get around that restriction by using these verbose and unintuitive constructions with unnecessary type parameters. Like, why is impl&lt;T&gt; TraitDetector for TypeWithTag&lt;T, ImplsTraitATag&gt; where T: TraitA {} impl&lt;T&gt; TraitDetector for TypeWithTag&lt;T, ImplsTraitBTag&gt; where T: TraitB {} ok while impl&lt;T&gt; TraitDetector for T where T: TraitA {} impl&lt;T&gt; TraitDetector for T where T: TraitB {} is not?
Part of it is inherent limitations of the current type inference engine. There is ongoing work on a replacement called Chalk that will be able to make these kinds of inferences. Are you familiar with type specialization? So say you have this code: struct Value&lt;T&gt; { inner: T } impl Value&lt;i32&gt; { ... } impl Value&lt;u32&gt; { ... } impl&lt;T&gt; Value&lt;T&gt; { ... } The first two impls are *different* types. They are not generic. The last one is. They are equally as specific, but because they cannot overlap (this is something the type inference engine *can* reason about) they're different implementations. When you try to use trait bounds without specialization, the engine cannot currently infer that they don't overlap. Once this is enabled, it will depend on the specifics of the implementation and how the future proofing and orphan rule will be followed for the implementation. 
Because there may be `Foo` that implements both. And hence it will implement `TraitDetector` twice. Type inference trick will fail in such case.
I think community discussions can certainly be newsworthy, and would be appropriate for a community newsletter. It would certainly help with discoverability of related discussions. Maybe a simple comment count threshold could help.
By compiling the rust (which uses wasm-bindgen) to wasm with the wasm-bindgen cli, will I be able to use the result as an ES6 module?
This is what wasm-pack does (which uses wasm-bindgen), even allows you to publish to the result to the npm registry without the need for npm locally.
*Disclaimer: I work on distributed applications; this may color my views.* I actually prefer logging *everything* that is worth logging (all warnings and above) into a central aggregated place. 1. This makes the application lighter, and more focused on its core goal. 2. This allows non-local reasoning: for example, the voltage issue could apply to all machines within a certain rack =&gt; oh, looks like a flailing rack! 3. This allows long-term reasoning: for example, you can compare to 1 month ago. 4. This allows detection fine-tuning: before changing the thresholds, simulate over the last year and check the false-positives/false-negatives; adjust and repeat. This may not always be possible, of course, however I've found it better to separate core logic from logging; and I'd classify warnings as logging as it's not clear there's any error (in isolation).
My biggest problem with cargo is that it only provides the source to be compiled. The binary should be available. Countless times I had to use a tool, like diesel_cli in prod and spent a shitton of time downloading it, compiling to then use. This is a huge waist. The compiled binary/library should be provided
Rust has no stable ABI. The number of builds they'd have to provide for each crate is prohibitive.
As always with these things, the record is on GitHub, not reddit, so please leave feedback there. I'm happy to answer questions here though.
I'd be happy with binaries available for default features, current stable release, tier one platforms only. That should cover the most common case.
Projects that create programs to run rather than libraries can distribute binary releases without it being the role of cargo or crates.io in my opinion, given compiled rust programs are standalone.
We actually do something roughly similar, we just shuffle everything else off into that central aggregate as well. We often use the 'fire and forget' distributed pattern. Logging something? warning? error that doesn't actually stop you since you have an alternative thing you can try? etc etc, all of that gets 'fired' up into some async logging/tracking/event system which gets processed in a different way. I think if you do *anything* distributed you need to do this. heh, this reminds me of my favourite synchronisation primitive. If you need some configuration thing, something which is *read only*, then there is no sense synchronising to check those configurations...just copy it and hand it out to each unit =-P It's dead simple, works perfectly, is easy to understand and code, and most of the time, the extra memory overhead just doesn't matter. It's *staggering* how much simpler this can make things.
I've created an [issue](https://github.com/crate-ci/meta/issues/22) to look into this and integrate relevant documentation into [crate-ci](https://crate-ci.github.io/).
I'm trying to write a function that computes an integer square root: fn sqrt(n: u64) -&gt; Option&lt;u64&gt; { /* ??? */ } assert_eq!(sqrt(16), Some(4)); assert_eq!(sqrt(15), None); Ideally this function doesn't involve a conversion to float, though as long as the final result is reliable it isn't that big a deal. Any ideas?
You likely want something like https://docs.rs/backtrace/0.3.9/backtrace/struct.Backtrace.html which gives you a way to inspecting the native stack, and reading the related debug information. If you just want like a stack trace for relatively begin logging/errors `backtrace` is likely sufficient. --- If you are interested in shadowing stacking techniques (the real name for "*I want an easily serializable stack to track calls sites*") this maybe overkill for what you wish to accomplish. There is a lot of subtle problems with the runtime implementation, it can relatively quick destroy your performance, and be a very discouraging experience. I'd strongly discourage you from purposing this, as the complexity quick spirals (this was literally my day job) from "*yes I can implement an FIFO stack in thread local*" into "*fuzzy callsite matching for asynchronously returning functions from a threadpool with options to unwind the stack*". 
Thank you very much for this extended explanation! I've ended implementing /u/RustMeUp 's solution and it works. I've learned a bunch of unsafe Rust these last 3 days! :D
The usual way is to try to balance the size of the enum variants. I recall some -Z flag to rustc to help with that,but am on mobile right now, and the rustc on my phone fails at the moment.
Thanks for your feedback recycled_ideas, I appreciate it. Following on from your points, I had a few thoughts... 1. I agree that having no fixed schema for the DOM is a mistake. If WHATWG / W3C could agree to start versioning the DOM schema, provide a compliance test suite for each version, and agree to allow specific versions to be specified in the HTML of a website (via a doctype attribute perhaps), would you see that as a good step forward? 2. I agree that deeply nested state can provide problems, though perhaps there are upsides too. Do you see any merit in Web Components? As I'm sure you're already aware the Shadow DOM is a key part of how Web Components work, and whilst on one level they increase the nested state of the DOM they also allow web apps to be more easily broken up into small, reusable components, which seems to me to have merit (once browsers fully support Web Components). 3. If you're not a fan of the Shadow DOM, do you see any merit in the Virtual DOM approach used by React, Vue, Elm, etc... ? Seems like it's the best option we've currently got with regards to performance, and the general approach of modelling the DOM and only applying minimal changes based on a diff seems to be a decent way of patching over some of the real DOM's limitations (they seem quite straightforward to learn too, this article has a simple implementation: https://medium.com/@deathmood/how-to-write-your-own-virtual-dom-ee74acc13060 ). Perhaps we could standardise on a single virtual DOM implementation to make it easier for JS frameworks to interoperate. Do you think that'd help?
Don't have an account there as I find this type of forum difficult to follow. I don't mind if you forward it there, but I think many people who are in a position to do something about it are present on reddit as well.
This is a good point regarding `Cargo.lock`. My wayland-rs project is a set of libraries, as such I don't commit the cargo lockfile. I'm not sure there is a real gain in keeping the registry's index. Given yo will download it anyway, what do you gain from downloading it from your cache rather than from crates.io ?
I think that would be an option, even though I would like to see the projects migrate to the newer crates. But I'm not sure that all of them are still actively under development. I'm by no means familiar with the OpenSSL API, so I can't say whether there are any changes preventing this. /u/sfackler is update for the openssl 0.9.x series a viable option?
IMHO I think you are dismissing the value of a good mentor. I hope OP finds a good opportunity in addition to their own explorations.
&gt; don't remember if the part of LLVM taking the most CPU is acting on target bytecode or not, It is unfortunately, try out `cargo check` vs `cargo build` for an unscientific measurement.
Sure, authors can provide their own discussion-links. But most don't and won't. Apart from that, then the link I'm interested in is different for each blog, at a different position, with different format. That way it's almost faster for me to search on Reddit myself.
Yeah man, this one is for some dev language. r/playrust is what you are looking for.
One is a literal (compiler knows it's value), while the other is a variable (and by definition, may change). Yes, it's immutable by default, but doesn't change anything about the compilation process.
One of our policies is to avoid out parameters. *we* where always checking them and handling them correctly...but many of our customers or third party groups would just skip right over it. &gt;.&lt;
Thanks! Checked the help output, found -Z print-type-sizes. That'll help a lot when I go to clean the type structures up. 
Right, I still find it surprising that the compiler doesn't do some trivial static analysis to catch silly mistakes like this. 
Sure, but TWIR isn't an extension of Reddit and a huge amount of Rust community happens outside of Reddit. If you want to discuss a TWIR entry here, search for it yourself (you probably already read it anyways before it ends up there).
There's [ongoing work](https://github.com/servo/ipc-channel/pull/166) to bring windows support to ipc-channel, other than that you could make a wrapper that would use either ipc-channel or named_pipe (or raw miow) for the particular subset of features you care about.
sorry mate, didn't realise - thanks for help though!
Where do you see the size of your cache? I don't see it in the build log.
I really like the changes being made. It has been discussed to death, but the results are very well thought through because of it.
This is a good clarification -- this isn't entirely clear, since you've posted a Rust users forum link.
When you borrow from something, you're not allowed to move that origin anymore until the borrow is released. You have a borrowing chain from `arc_system` -&gt; `lock_guard`/`system_lock` -&gt; `system`, so in the view of the compiler, only the last is free to move around. In practice, it's actually fine for those origins to move, because the values you borrow from them are indirect. Moving an `Arc` or `MutexGuard` doesn't actually change the addresses of their internal values. The compiler's borrowck doesn't know this concept, but there's a trait for it: [`StableDeref`](https://docs.rs/stable_deref_trait/1.1.1/stable_deref_trait/trait.StableDeref.html). Your `struct GameSystemsAccess` is trying to be a self-referential struct, where `system` borrows from `system_lock`, which borrows from `system_arc`. I think you can probably use the [`rental`](https://crates.io/crates/rental) crate leveraging `StableDeref` to build that in a way the compiler will allow.
I'm not arguing for Reddit in particular, but for links to discussions in general. I would be equally happy about links to URLO or IRLO. 
Yes, though this won't affect the performance.
https://xkcd.com/356/ https://play.rust-lang.org/?gist=a10420ebf122cda92dc49ddffcd07614&amp;version=stable&amp;mode=debug&amp;edition=2015
You're welcome. And if you find that the usual allocation pattern doesn't fit, which often happens e.g. during parsing / tree construction, an Arena works quite well, offering cheap owned pointers in exchange for memory and possible fragmentation.
Yeah exactly, the kind of use case I'm thinking of is something like this struct in Rusoto (AWS sdk), which are the parameters for an API call. Most of them are optional, but "bucket", and "key" don't have reasonable default values so the `Default` trait doesn't work all that well... https://rusoto.github.io/rusoto/rusoto_s3/struct.CreateMultipartUploadRequest.html
Remember that this would have a cost - longer compile times, which are already too long. This \*particular\* case wouldn't take much to catch, but then that would only be a small fraction of possible checks, and you could never catch all of them. So the utility is questionable. &amp;#x200B; Languages have similar limitations for bounds check elision. In C# if you do a for loop over collection.Length it figures out it can elide bounds checks, but if you use an intermediate variable to store collection.Length, it misses it (or used to, it might have gotten smarter since) &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; This *particular* case wouldn't take much to catch, but then that would only be a small fraction of possible checks, and you could never catch all of them. So the utility is questionable. Why is the utility questionable?
You do need npm locally today; the plan is to someday not require it but that’s the plan, not the reality.
How about a simple buildscript replacing these characters with their ASCI-equivalent?
There is a "cache" tab for each project on Travis which shows you the currently stored caches and allows you to delete them. It's in the drop-down menu on the right. 
WHAT THE FUCK. That dude has to be on some good fucking amphetamines. Crazy.
That doesn't mean it doesn't support wasm. The "embedding" is referring to the environment that wasm runs in. The wasm OS effectively. Normally it will be a web browser but it can be other things.
I'm glad anchored paths is winning. Relative paths are a pox :)
Backtrace lets you analyze a running program, but it sounds like /u/dabreegster is looking to write a static call graph analysis (i.e. what functions *might* call other functions) without running the program.
Wikipedia has [an example for computing an integer square root in C](https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Example_3): short isqrt(short num) { short res = 0; short bit = 1 &lt;&lt; 14; // The second-to-top bit is set: 1 &lt;&lt; 30 for 32 bits // "bit" starts at the highest power of four &lt;= the argument. while (bit &gt; num) bit &gt;&gt;= 2; while (bit != 0) { if (num &gt;= res + bit) { num -= res + bit; res = (res &gt;&gt; 1) + bit; } else res &gt;&gt;= 1; bit &gt;&gt;= 2; } return res; } This can trivially be adapted to Rust, though since you're operating on unsigned numbers you set `bit` to the most significant bit for the width of integer you're using. It produces an approximation so you would end it with a check to see if the result number is actually the square root: fn usqrt(num: u64) -&gt; Option&lt;u64&gt; { let mut res = 0; let mut bit = 1 &lt;&lt; 63; while bit &gt; num { bit &gt;&gt;= 2; } while bit != 0 { if (num &gt;= res + bit) { num -= res + bit; res = (res &gt;&gt; 1) + bit; } else { res &gt;&gt;= 1; } bit &gt;&gt;= 2; } if res * res == num { Some(res) } else { None } } 
I suppose it is use under the hood then? But there is no need to manually run it at this point in time - only have it installed?
I can recommend this. The `Cursor` abstraction is what you want.
Absolutely, was more just thinking out loud about how to simplify the code. I realize the context made it seem like a performance suggestion, though.
&gt; This is a huge waist. I use a package manager for that, e.g., `brew install hyperfine` instead of `cargo install hyperfine`. I only use `cargo install` when i actually want to compile the thing for "reasons" (e.g. I am developing it, and want to test it system wide).
Can you use SysV shared memory on windows? if so, that's probably your answer.
Hello! This looks super promising and exciting. I've been trying to run Dolphin with gfx-portability, but I'm getting a "failed to load Vulkan library" error. I have downloaded the latest Dolphin build and added libportability.dylib to Contents/Frameworks. Vulkan shows up in the backend selection but throws the error message upon selection. Could anyone help me? Thanks!
Will try to get my notes up in public shortly, but they're pretty raggy anyhow. We basically just went straight through Blandy and Orendorff and did exercises.
Yeah it is clunky... but somehow this has stopped bothering me. I don't even know why. It's weird.
Ah, so you've already seen it. I hope you don't mind me posting it in the Pikelet gitter.
The issue isn't that these problems are unsolvable. Well structuring the DOM is unsolvable, but the more immediate problems aren't. The issue is that they have to be solved again in every single webasm language and generally by people who aren't experts in this area because they're already in the JS/TS space already. That's the core problem for webasm. It solves the I don't like JS problem which is not a real problem and it solves the performance problem which is sometimes a problem in very specific cases, but it doesn't solve any of the problems JS has already solved. 
Fuck autocorrect
It will only get linked once in the final compiled binary, as long as all the plugins use the same version. There is a better word for it that I can't remember right now, but basically dependencies are de-duplicated. Here is a project I did something similar: https://github.com/George3d6/Inquisitor/tree/master
Why don't you build it and store the binary yourself if it's so much trouble to build every time?
Check out (rouille)[https://crates.io/crates/rouille], or if you want to try something that is built on top of hyper (but not use hyper directly), my new go-to these days is (warp)[https://crates.io/crates/warp]. (actix-web)[https://crates.io/crates/actix-web] may also suit your needs.
Thanks! rouille looks like it's much more my style.
I actually have been working on a [synchronous HTTP client](https://github.com/sbstp/lynx) because I find reqwest too big, it pulls down the whole tokio stack. It works but it hasn't been tested a ton yet. &gt; This project's goal is to provide a lightweight and simple HTTP client for the Rust ecosystem. The intended use is for projects that have HTTP needs where performance is not critical or when HTTP is not the main purpose of the application. Note that the project still tries to perform well and avoid allocation where possible, but stays away from Rust's asynchronous stack to provide a crate that's as small as possible. Features are provided behind feature flags when possible to allow users to get just what they need. At the moment it supports, query parameters, request headers, tls, redirection, streaming the response body, text encoding and gzip/deflate.
Thanks for that! Might it’s worth keeping in mind!
Good oversight. Should I switch to BigRational from the num crate? If I'm using cents (the smallest denomination), then how would I display it as dollars?
Good catch. So I should do something like: ``` let mut amounts = [0;4]; for (i, (&amp;amt, _)) in DENOMINATIONS.iter().enumerate() { while total &gt;= amt { amounts[i] += 1; total -= amt; } } for (i, (_, &amp;name)) in DENOMINATIONS.iter().enumerate() { println!("You have {} of {}", amounts[i], name); } ```
Very excited to see this conversation happening on the record now. IDE experience is key to onboarding new developers, and making headway in that area is going to pay huge dividends.
You may wish to check out `libloading` for this purpose. I used this to link to a `cdylib` and allow runtime loading of plugins. I'm not sure whether `libloading` works with `dylib`s, but given the lack of a stable ABI I decided to go with `cdylib` interfaces.
How do you stream the contents of a file to stdout without storing it as a string?
In case anyone asks how this relates to Rust. the backend is a Diesel + hyper-based server.
You need two lifetimes to describe that line: one lifetime is for the lifetime of the things references in the containing strict (your &amp;’a) and another lifetime parameter for the strict being referenced. So you should add a ‘b. This can get tricky and grow fast. Is there a reason you don’t want to keep these things in an Rc, or use RefCell?
Use [`std::io::copy`](https://doc.rust-lang.org/std/io/fn.copy.html) from the `File` to [stdout](https://doc.rust-lang.org/std/io/fn.stdout.html). 
Inigo 8😒J hurt
What is the problem with pulling in Tokio?
The published Rationale for the Standard notes that one of the purposes of leaving various actions as UB is to allow for implementations to provide semantics beyond those mandated by the Standard, and notes that one of the things which makes C useful is that implementations intended for various purposes often do this. The question of whether to support such features is left as a "quality of implementation" issue. The authors of some compilers seem to believe that "A conforming compiler given program X can do Y [and still be conforming]" implies "A quality compiler given program X can do Y [and still be a quality compiler]", but the Standard says no such thing. It expects that compiler writers will recognize what would be required to make a compiler be a quality implementation that is suitable for its claimed purposes, without the Standard having to order them to do so. A completely-useless-but-conforming implementation would be allowed to check if it's fed a particular hard-coded source text for a useless program that nominally tests all translation limits given in the Standard but doesn't actually do anything, exit silently if so, and otherwise release nasal demons. That would be rather contrived, to be sure, but I think it fits in line with the Rationale's recognition that an implementation to be of such poor quality that--although conforming--it "succeeds at being useless". Since the authors of the Standard haven't regarded that as a defect worth fixing, I think it's safe to say that mere conformance with the Standard is is not intended to imply that something is a quality implementation that is suitable for all purposes. Further, it would suggest that the authors might not have thought it particularly important to distinguish between behaviors which all implementations were required to process in a particular fashion, or those which all quality general-purpose implementations for commonplace were expected to process the same way [whether required to do so or not], but which some unusual implementations might benefit from being able to process differently. A possibly-useful-for-something-but-still-horrible implementation given a function like `void test(void) { struct foo {int x;} foo={0}; foo.x=1; }` could legitimately conclude that the function will never be called, since would attempt to access an object of type `struct foo` using an lvalue of type `int`, which is not one of the allowed types (struct members may be accessed using lvalues of enclosing structure types, but there isn't--nor should there be--blanket reciprocal permission to do the reverse). Any reasonable compiler must be able to recognize at least some cases where an lvalue of one type is derived from another and then used to access that object, but the Standard doesn't mandate such recognition--not even the most patently obvious one [use of an aggregate-member lvalue to access the aggregate]. The only interpretation that makes any sense is that they viewed such recognition as a quality of implementation issue. An implementation that can recognize something like the above, but can't handle something like `doSomething(&amp;unionArray[i].m1);` even in cases where all accesses within `doSomething()` are reads of Common Initial Sequence members done through the passed pointer, might be viewed as slightly better than the above, but should still be recognized as inexcusably bad. If two calls like the above are separated by operations upon members of the Common Initial Sequence via `unionArray[j].m2`, an implementation's decision to cache the values from the first call is not a mark of quality, but rather a demonstration of obtuseness. If the C Standard made any real effort to fully specify a language that is suitable for low-level programming, then it might be reasonable to fault programmers who use behaviors beyond those specified thereby. What it is actually intended to specify, however, is not a complete language that is suitable for any particular purpose, but rather a common core language which quality implementations intended for various purposes are meant to extend in such fashion as to be suitable for those purposes. 
Just to clarify this point: &gt; mod.rs is no longer needed when placing submodules in a subdirectory. Does this mean that if I have a module `foo` then I _must_ have a `foo.rs` file (ignoring module blocks that are in the patent module's file)? I.e. I _can't_ have the following source tree: src/ lib.rs foo/ bar.rs baz.rs
Are people picking gcc because it generates good code, or because it's free? From what I've seen, gcc tends to miss a fair amount of what should be "low hanging fruit". Further, a compiler which applies conservative optimizations that are compatible with code requiring low-level semantics will be able to process such code more efficiently than one whose optimizer is more aggressive and consequently must be disabled when processing such code.
What's your opposition to using `std::sync::mpsc::channel` for your lock-free queues? I've been playing with it for this exact purpose and haven't noticed anything really bad about it, but I haven't dug into the details enough to see if it's deallocating when you pop data off the queue. Sidenote: ime popping data onto the audio thread is much more useful than popping data off it (which frankly, is only useful for metering). Frequency response displays are of course nice, but I've always treated pushing large chunks of audio data off the audio thread as a special case rather than optimizing for it, in terms of API and FIFO complexity. 
There is a difference between saying that an out-of-bounds array access will act upon the storage whose address is computed thereby, with whatever consequences result from that, versus saying that it may behave in totally arbitrary fashion *even in cases where the programmer knows what is at the computed address and actually wants to access it* [as may be the case if code takes the address of the first element of a 2D array and wants to access the whole thing as a "flattened" single-dimensional array]. Specifying that that code which e.g. reads `arr[1][0]`, writes `arr[0][i]`, and reads `arr[1][0]` will always see the effect of the write if it happens to hit `arr[1][0]` would be expensive, but the solution to that should not be to make such operations completely jump the rails, but rather to specify that certain aspects of program behavior (such as the sequence in which various operations are performed) need not be treated as "observable" by the compiler. If code is prepared to deal with the possibility that a compiler given the above code might reorder the second read before the write (e.g. because in all situations where they would access the same storage, the value written would match what was already there, or because the old and new values would be equally acceptable) allowing the program to exploit that fact would allow more efficient code than would be possible if the program had to add extra code (which an optimizer wouldn't be able to remove) specially handle that case. 
First of all is it huge. Secondly if you want a quick dirt cheap http client anything based on tokio is probably way to overkill for the usecase.
Reverse Turing test or idiocy, depending on context
You can rewrite this (and nearly any \`for\` loop) using \`fold\`, but personally I think this actually looks just fine as a for loop. More to the point, I don't think \`for\` loops are unidiomatic at all-- I think that idiomatic Rust is about picking the right language tools that help you get the job done clearly, even when they're not the fanciest FP-monad-transforming-pi-type-hotness. (/me holds out hope someone will find a brilliant, clear way to express this using simpler combinators)
Thanks for the pointers. A `LexItem` sometimes contains `String` so I need to clone to return a `LexItem` over a `&amp;LexItem`. That is the reason I return `&amp;LexItem` in the current implementation. So if I want to use `Cell`, I just return `Cell&lt;LexItem&gt;` from the gettoken and peek_token functions? Since I never mutate the `LexItem` I should be able to only have to use Cell I think. 
A clean `vec.iter` won't work well if you're extracting multiple values at once. That pattern is best suited to doing one thing to one element at a time. I don't see anything in the `Iterator` trait or `std::slice` module that would be helpful for this. You can make your own iterator by moving that logic into the `next` function. [Here](https://play.rust-lang.org/?gist=50d2f7bc68ecfeaaad3993158c41282c&amp;version=stable&amp;mode=debug&amp;edition=2015) is an implementation of that iterator. It gives out slices of the vector of objects, so you can then use the convenient iterator adapters on that stream of slices. struct ExampleIterator&lt;'a, I, V&gt; where I: Ord + 'a, V: 'a { examples: &amp;'a [ExampleObject&lt;I, V&gt;], } impl&lt;'a, I, V&gt; ExampleIterator&lt;'a, I, V&gt; where I: Ord + 'a, V: 'a { fn new(examples: &amp;'a [ExampleObject&lt;I, V&gt;]) -&gt; ExampleIterator&lt;'a, I, V&gt; { Self { examples, } } } impl&lt;'a, I, V&gt; Iterator for ExampleIterator&lt;'a, I, V&gt; where I: Ord + 'a, V: 'a { type Item = &amp;'a [ExampleObject&lt;I, V&gt;]; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { if self.examples.len() == 0 { return None; } for idx in 0..self.examples.len() { if self.examples[idx].idx != self.examples[0].idx { let (head, tail) = self.examples.split_at(idx); self.examples = tail; return Some(head); } } let result = self.examples; self.examples = &amp;[]; return Some(result); } } ... ExampleIterator::new(&amp;example_vec).for_each(process_example);
That problem is somewhat unique to C and C++, largely because the authors of the Standard intended people that writing implementations for various purposes would add whatever combination of additional features and guarantees would best serve those purposes. Consequently, they didn't bother to define all the behaviors necessary to serve anything beyond a tiny fraction of the purposes to which the language might be put. In cases where some (or even the vast majority of) implementations benefited from defining the behavior of certain actions, but other (possibly hypothetical) implementations benefited (or hypothetically might do so) from not doing so, the logical way for the Standard to resolve that was to declare that the action invokes UB *on the grounds that such declaration should not prevent or discourage any quality implementations from defining the action when it would be useful to do so*. If the authors of the C89 had any clue how modern compilers would treat UB, it would look very different.
There's a user with the handle "supercat" on StackOverflow who makes this point pretty often and provides some interesting examples. 
I just took a quick look at your example, but I think what you are looking for is https://doc.rust-lang.org/std/slice/struct.Windows.html
I'm really curious what your resulting stripped binary sizes end up being compared to request.
You probably want to `stdout().lock()` as the target. Basically avoiding a premature pessimization.
In short, the error is detected due to constant evaluation. Anything assigned to a local variable is not considered to be a constant. If you have `array[i]`, then the compiler is like, okay, we have a variable of `[i32; 3]` (note that its size is part of a type) indexed by `usize`. This may work. If you have `array[100]` then the compiler goes, let's see, we have a variable of type `[i32; 3]` and a constant `100`. This will always panic at runtime, so might as well point it out earlier.
Do you know about the rustaudio effort of creating an mp3 decoder? https://github.com/rustaudio/mp3 Shameless plug, but PRs are welcome :).
Option? I mean, it sounds like you want something which either exists (Some) or not (None) then you push responsibility of naming to the users of the code. This has additional benefits of keeping all the Option combinator methods as well as try `?` support.
Does somebody have a minimum working example of this ?
It has nothing to do with it being a lint. The regular lints actually can run both before and after all the passes (we have early and late lint passes). But on top of that the compiler has lots of builtin lints that are basically emitted during other passes in the compiler. This lint is emitted during some const stuff in MIR. We just don't fold as aggressively (and doing so may be nice but also makes compile times worse)
&gt; (Note: itertools' group_by doesn't quite do the right thing.) Could you explain why? It seems perfect for this job: for group in example_vec.iter().group_by(|object| object.idx) { process_example(group); } The only inconvenience is that you'd need to change the `process_example` signature to take `impl Iterator&lt;Item=U&gt;` instead of `&amp;[U]`. Perhaps that's what you've meant?
Well first off, Blazor doesn't actually compile to webasm, it uses a webasm mono runtime, but leaving that aside you still have to be able to call and interact with this code in your application, which won't be webasm aware. If you're using JS libraries, you're losing all the performance, and most of these UI libraries are going to be super hard to do. Second, there have been dozens of transpilation target languages, but they've all failed because language interop sucks. It sucks because you lose a lot of the benefits of your original language while gaining all of its disadvantages. I named Typescript because it's literally JS with types. You can take existing JS and just start adding types. 
my [tiny-nix-ipc](https://github.com/myfreeweb/tiny-nix-ipc) crate: no Windows support, just a convenient unix sockets wrapper with support for fd passing
You can just add `.cargo/config` file to your project.
Oh yea. lol.
I think the choice is between `foo.rs` and `foo/mod.rs`, you need one of those to have a module `foo` (and you can't have submodules of module `foo` without defining `foo`)
To have a module `foo` you must have either `foo.rs` or `foo/mod.rs`. Then, to have sub-modules `foo::bar` and `foo::baz` (in `foo/bar.rs` and `foo/baz.rs`) previously you needed to have `foo/mod.rs`. With this change you can have either that or `foo.rs`. (All of this assuming you don’t use the `#[path = "…"]` attribute.)
You should cross-post this to /r/python, it would interest them, especially given it nicely answers the very question I had namely "why py-spy when pyflame exists?": &gt; While pyflame is a great project, it doesn't support Python 3.7 yet and doesn't work on OSX or Windows. &gt; Py-spy works by directly reading the memory of the python program using the process_vm_readv system call on Linux, the vm_read call on OSX or the ReadProcessMemory call on Windows. &gt; Figuring out the call stack of the Python program is done by looking at the global PyInterpreterState variable to get all the Python threads running in the interpreter, and then iterating over each PyFrameObject in each thread to get the call stack. Since the Python ABI changes between versions, we use rusts' bindgen to generate different rust structures for each Python interperator class we care about and use these generated structs to figure out the memory layout in the Python program.
What's wrong with relative paths?
I linked to [a playground example](https://play.rust-lang.org/?gist=6ca5fc39e17d9581e5fdd2b791e2afb9&amp;version=stable&amp;mode=debug&amp;edition=2015) in my original post, or do you mean something else?
I'm just getting into Rust and the integration with my current IDE (VSCode) leaves a bit to be desired. The one thing I wish was present in `rls-vscode` is the ability to get a feel for the language by exploring the available methods while writing out a variable name. I'm new to the language, I don't know if I want to use `string_stringer.to_vec()`, I don't yet know what that does, but if I've got to write it out and get RLS to run compilation and *then* check what it's doing, I might as well go look up the docs and hop out of the IDE. Basically, go fire up Visual Studio and take a look at the C# Intellisense. That's what spoiled me. 
If all your plugins should have the same API (which they should), then [the `shared_library` crate](https://github.com/tomaka/shared_library/blob/master/demo/src/main.rs) would be more convenient than `libloading` because you don't have to manually assign the function pointers.
I'd love more contributions on my SIMD library, which is another form of parallelism: [https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez) &amp;#x200B; Also I second the suggestion of gfx-rs if you have graphics interest. We have a chance to make a big impact on both Rust and graphics/games with it. &amp;#x200B;
Im using the crate already. The thing is, my plugins are crates themselves. Building will include the framework API too. It is around 2MB compiled. And having each plugin carry that alongside of it is unnecessary as the runtime executable has it already compiled into it.
Yes, exactly.
Thanks to everyone doing hard work on this, it is appreciated very much.
Yes anyone coming from C# is going to feel bad, C# has probably the best intellisense in the world. All of the niche languages I've played with leave you wanting when you are used to this. F#, Nim, Go, even C++. The thing to keep in mind is Microsoft went through a monumentally large project with some of the best talent in the world to make that possible. &amp;#x200B; Rust is working on it, but there is no easy or fast way to create an experience that good. &amp;#x200B;
To me C#'s Intellisense is pretty awesome, but, I personally think that Java's (in both Eclipse especially, but, even in Netbeans) is far superior. Also, much more powerful refactoring tools. To me the "Gold Standard" right now is the Java-world with respect to Intellisense and Refactoring. If Rust can get even 80% of the way there, (which is about where C# is IMHO) it will be truly awesome.
Curious, have any folks here used both VisualStudio + Roslyn and JetBrains' Rider (with it's own code analyzer)? How do they compare?
D doesn't have an official specification for the language but a reference compiler which is conveniently closed sourced. D is a sad attempt at a money shot from its creator IMHO. 
[removed]
dmd is Boost-licensed now. https://forum.dlang.org/post/oc8acc$1ei9$1@digitalmars.com
For me lately it keeps getting into some kind of endless loop and consuming 100% of a cpu core. Somehow it has actually gotten worse.
I would suggest reading the documentation and learning materials to start: * [https://www.rust-lang.org/en-US/documentation.html](https://www.rust-lang.org/en-US/documentation.html) * [https://www.rust-lang.org/en-US/faq.html](https://www.rust-lang.org/en-US/faq.html) In particular, be sure to read [TRPL](https://doc.rust-lang.org/book/). &amp;#x200B; I think that it would be best to immerse in these resources for such a broad, open-ended question.
Rust has captured a larger mindshare and has a brighter future. 
With D you get safety with overhead. Rust brings minimal/zero-overhead safety. 
Hmm... Giving advice here is tough to do without seeing more code, but I'll try. * You might consider checking out [what the book has to say on interior mutability](https://doc.rust-lang.org/book/second-edition/ch15-05-interior-mutability.html), and also look at the [API docs for `Cell` and `RefCell`](https://doc.rust-lang.org/std/cell/index.html). In particular, `Cell` is mostly intended for `Copy` types. So if a `LexItem` has a `String` (which isn't `Copy`), then a `Cell&lt;LexItem&gt;` probably isn't useful to you. * Specifically, my suggestion is about changing the `tokens` and `index` fields in your `Parser` to `RefCell&lt;Vec&lt;LexItem&gt;&gt;` and `Cell&lt;usize&gt;`, respectively. Once you do this, you should be able to update uses of those fields to using `borrow`/`borrow_mut`, and then you can replace `&amp;mut self` with `&amp;self`. Effectively, you're pushing borrow checking to runtime. * I would try and see if you could use a `&amp;str` inside a `LexItem`. This assumes you can 1) borrow from the string you're parsing and 2) you don't need to make any modifications to it. That is, a `&amp;str` is `Copy`, so it simplifies things. * If you do use `RefCell&lt;Vec&lt;LexItem&gt;&gt;`, then implementing a method that returns `&amp;LexItem` is a little tricky, but not too bad. (This is why I suggested making `LexItem` impl `Copy` by using `&amp;str`, then you could feasibly just return `LexItem`.) Basically, you need to use `Ref` instead of `&amp;`. Here's an example that compiles based on your code: https://play.rust-lang.org/?gist=1136d896f0bfa05cddb04ba04c3979d1&amp;version=stable&amp;mode=debug&amp;edition=2015 If you're just learning Rust, this might be a lot to take in. I don't find myself frequently needing to push borrow checking to runtime, but the strategy above has been very useful in writing compositional code in a handful of cases.
I'm working on a blog post about how I wrote an HTTP client using hyper and tokio
Simply its size. It adds a lot of compilation time and binary size.
The main distinguishing feature would be that Rust gets it's safety without using a garbage collector, so there is less runtime overhead. &amp;#x200B; A significant point in D's favor is extremely fast compile times, vs Rust's extremely slow compile times. If you are interested in D you might also be interested in Go, which also has fast compile times and garbage collection. &amp;#x200B; &amp;#x200B; &amp;#x200B;
One doesn't prevent the other but I won't argue from memory for a forum post he would have made years ago... 
Lots of good advice. I got it to parse simple expressions by using `Clone` on the `LexItem`, but that causes extra allocations, so would be nice to avoid that. Next attempt will be converting the `String` usage to `&amp;str`, but then I get into lifetime issues, and I haven't looked at that yet. As you say, pushing the borrow checking to runtime, while doable, seems like it gets rid of one of the best features of rust. The code is [here](https://github.com/nordsoyv/rust-cdl-compiler/tree/master/cdl-core) if you want to take a look. There are some strange things with the AstNodes, I'm trying to implement a polymorphic tree for the expressions, so ended up with an enum Expr that wraps AstNodes. The original compiler is written in javascript so creating a tree of different nodes was not a problem then :) I'm hoping that I can rewrite in rust, compile to wasm, and get some better performance. Its anyway a good way to learn. 
I mean something more minimal that shows exactly how this work without so many types and traits.
As a non-technical reason, I do not have faith in D gaining traction at this point. I have more confidence that Rust will.
&gt; To have a module foo you must have either foo.rs or foo/mod.rs. /u/irishsultan asked a good question above &gt; (Unless you define foo in lib.rs, I guess that's possible as well?) 
Does D provide concurrency that's free from data races? In Rust you can change a `.iter()` to [rayon](https://docs.rs/rayon/)'s `.par_iter()`, and if that change would produce a data race the compiler will tell you. Rust provides much more than safety though. Error handling is done in the return value which leaves all error paths clearly documented, but also provides a very concise tool for the common operation (the ? operator early-returns if a value is an error). Rust also takes a lot of inspiration from functional languages: Pattern matching makes it possible to use Rust's enums which are implemented as tagged unions everywhere with confidence. I've grown to love iterator combinators (map/filter/etc...) and find myself much more comfortable expressing operations with them as opposed to writing out a heavily nested loop in C++. I can't speak highly enough of Rust's package manager + build system cargo. It makes adding dependencies a breeze, along with building a project, running tests, and generating HTML documentation from source code. Everyone uses cargo too, so I know what to expect if I open another person's Rust project.
Wouldn't MIR constant folding make compile time better, not worse? It can be done before monomorphization to reduce duplicate work.
Unfortunately no its not doing anything productive. This happens after a while when I'm working on the code and no deps have changed.
Rust does have language reference, but it is in no way "official". Current [reference](https://doc.rust-lang.org/reference/) has a warning at the top stating lack of normative status.
Ah, I misunderstood. Sorry!
`split` always gives you a list of `&amp;str`s, even if you split an owned string. This way is more efficient - you aren't forced allocating new strings if you want the split results to be short lived. If you do want to allocate fresh strings, you can `map` the iterator to produce a `String` from each `&amp;str` that you get: let v: Vec&lt;String&gt; = can.split("").map(|part| part.to_string()).collect();
As of today D still does not have reliable `@safe` subset (look for relevant bug reports via issues.dlang.org for many ways to escape it) so it is rather bad example. Also even if it is ever finished, it is still opt-in feature. Currently most languages providing reliable safety require GC and/or heavy runtime support. Rust has a solid chance to become first popular one which provides it at systems level with minimal to no overhead.
Strictly speaking that code is not *broken*, the types just don't implement all traits that they could. If a type implements `PartialEq` it says that you can compare two values of that type together, but doesn't guarantee that `x == x`. If the actual implementation just happens to guarantee that, then nothing is broken - such behaviour is definitely allowed by `PartialEq`. However, if something (like a `HashMap`) really wants `x == x` to hold, it will have `Eq` trait bound, and then the type just won't work with the `HashMap`. The code will not compile, but nothing's behaviour will break because of a missing `derive(Eq)`.
Can somebody explain to me why `titles.push(&amp;caps["title"])` doesn't work. ```rust extern crate regex; // 1.0.4 use regex::Regex; fn main() { let re = Regex::new(r"'(?P&lt;title&gt;[^']+)'\s+\((?P&lt;year&gt;\d{4})\)").unwrap(); let text = "'Citizen Kane' (1941), 'The Wizard of Oz' (1939), 'M' (1931)."; let mut titles: Vec&lt;&amp;str&gt; = vec![]; for caps in re.captures_iter(text) { titles.push(caps.name("title").unwrap().as_str()); // titles.push(&amp;caps["title"]); why this go wrong! println!("Movie: {:?}, Released: {:?}", &amp;caps["title"], &amp;caps["year"]); } } ```
It's huge and if you're doing a simple cli program you don't really need to worry about having your IO be async.
&gt; seems like it gets rid of one of the best features of rust That's kinda true I guess, but *only for a specific part of your code*. :-) Everything that doesn't use interior mutability still benefits from compile time checks. Anyway, good luck!
Rust community is much more active
Thanks
I really like D's compile-time and meta-programming capabilities: CTFE, templates, traits or even mixin.
Sorry I meant rls.
Thanks for clarifying. However my original comment has been downvoted quite a bit thanks to my past frustration with the language reflected in the comment itself: not sure a lot of people will see this at this point... 
Right now all of the rust tooling is built around Cargo.toml and cargo metadata, [bazelbuild/rules_rust](https://github.com/bazelbuild/rules_rust) will likely end up generating them to interop with the rest of the ecoysystem.
Yes, the method is inherently racy. On the other hand, you can do sanity checks and drop samples that fail those checks; losing some samples is okay.
There are two different phenomena here that are related but come from different places. One is undefined behavior at the user source code level. It can be tempting to wish that languages and compilers be less ruthless about undefined behavior, especially in cases where programmers believe they know what should really happen. However, this is a discussion for users and programming language designers. The other is undefined behavior at the compiler IR level. When compiling a "safe" langauge, your 2D Array example either works or doesn't depending on the source language, but it's defined behavior, either way. If the compiler thinks it can prove that some of the safety checks aren't needed, under the covers, it might elide them. But if there's a bug in the part of the compiler that makes this decision, it might elide them in a case where they're actually needed, and the consequences might effectively be undefined behavior. This is the question here: could we eliminate even this undefined behavior? And the answer is yes, we could, but it's a tradeoff. 
Not just in module paths, but relative addresses (eg. `source ../../somefile.sh` in bash) have bitten me as a write-only pattern that makes code harder to read.
this is the point where someone tries to say you can use D without a GC. someone always tries to make that point when others negatively point out D's GC.
Conceptually, the notion of parent and child modules; it's only a scoping mechanism. Practically, moving a module shouldn't change its imports.
For a synchronous HTTP client, take a look at [reqwest](https://crates.io/crates/reqwest). It's simple to use straight out of the box, and has several features you'd expect from a more fleshed out client, and uses the tested hyper library underneath, so HTTP edge cases are handled properly.
Huh, that's actually really interesting. I've looked into the chaches for Alacritty since that's the biggest travis repo I have access to and it turns out each build has around 1-2GB of caches. With all branches and PRs this adds up to a total of over 30GB of build caches on travis. I'll have to give your recommendations a shot and see if it changes anything.
This looks like a variance issue. Because you can mutate the values inside `CodeGen`, including setting new values for `cx` and `tycx`, read-write access to a reference means that `'a` must be invariant in order to remain safe. Try removing the `mut` on line 10 and it should stop complaining?
and then the point will come "then it isn't "safe" anymore" 
Careful with assuming HTTP is easy. There are plenty of ways to screw it up. Unless you need to fit in a truly space-constrained environment, it's probably best to use what has seen a lot of production testing.
Thanks, I think I understood there two lifetime here. I appreciate your reply.
Thanks. Well explained.
for parity's sake you should ask the same question in [https://www.reddit.com/r/d\_language/](https://www.reddit.com/r/d_language/) (even better - [https://forum.dlang.org/](https://forum.dlang.org/)). &amp;#x200B; No doubt Rust has a stronger safety story, but that's not the only consideration as a programmer. The amount of mental-lifting you have to get the benefits of Rust may not be necessary for all your programs. D is a fine alternative depending on what you want to do. Educating yourself in an objective way will help you.
Derp, the title should say (emphasis mine): &gt; (At least some) RustConf 2018 ***videos*** are getting uploaded!
Yes, it allocates (and deallocates) a lot. Sending data back is useful for recording and metering, but I also use it to maintain a linear flow of dynamically allocated data through the processing thread - for example, when removing modules from the graph, I send the object back to the UI thread for deallocation, rather than dropping it in the processing thread.
Generally languages are either safe and have GC or unsafe and have no GC. Rust and D are two outliers here. Rust is safe and has no GC. On the contrary, D is unsafe and has GC.
Sorry about the poor wording in the original question. And thanks for taking the time to reply. Your conclusion sounds like the right approach to go with to me.
This is not a technical talk, but it is a very good talk. Thank you.
&gt;Are they going to make the compiler robust to incomplete code then? Yep, that's the plan. &gt;And add heuristics to guess types before automatic type inference can provide a definite answer? You don't need heuristics for that, usual type-inference works just fine. The incomplete bits of code are sort-of substituted with `unimplemented!()`.
async i/O is not just about performance. How do you select a read and recv on a channel w/ blocking I/O?
It is "huge" because it provides many components. You don't have to use them all and can pick and choose.
You have any metrics to back your claim? How much does pulling in tokio-reactor + tokio-current-thread take?
What exactly does D do for safety? Never heard of it having this trait. D was always a "more convenient C++", but it even did away with some safety mechanisms that exist in C++, and reinvented some concepts with more overhead, such as imposing garbage collection in place of deterministic memory safety. 
You could dynamically link the framework into the plugins - if it's not a dynamic lib, create a wrapper crate that exposes it as one. Or you could pass references to the framework functions into the plugins at initialization.
I found that crate but didn't dive into trying to use it because [its last release was in 2015 and the last three releases were yanked](https://crates.io/crates/shared_library). Is it worth using the git version directly?
That was my experience when I started looking around the ecosystem recently. Most of the ecosystem requires a GC, and the parts that don't are not very discoverable.
With Go getting generics soon, I wonder if most people who would have wanted to program in D might be better off moving to Go? &amp;#x200B; &amp;#x200B;
D has some really advanced MetaProgramming and incredibly good C++ FFI. If you have a very large C++ codebase D might be a way to quickly bootstrap additional features.
&gt; Are people picking gcc because it generates good code, or because it's free? I expect free to be an important factor; but not the only one. gcc also supports a broad range of architectures, and comes by default with Linux. Since Clang is equally (if not more) free, has a compatible interface and tends to compile faster... I'd say people stick to gcc because gcc generates faster code in general. I think that on numeric code, Clang tends to have an edge performance-wise; but from personal experience on branch/virtual "regular" code, gcc is still ahead. And yes, I've found some weird cases of abysmal assembly (or outright bugs), like spill followed by reload, etc... but Clang has such cases too :/ 
First of all you’re trying to invent your own crypto system which is usually a bad idea. In your scenario it most definitely is a bad idea since RSA encryption does not stop any tampering whatsoever. You could sign the data using RSA signatures, but even then you should never use raw RSA, but a signature scheme based on RSA. The easiest way to do it though would be to use a higher level library that has primitives for authentication or authenticated encryption. Don’t use the OpenSSL APIs.
Maybe I'm just misunderstanding stuff. The framework is written in rust. Plugins add it as a dependency and then implement the trait Plugin and expose it via a function that I later call to obtain an instance of Plugin. The framework type is set to dylib in my toml config if that is what you mean. 
Helloo, is it true that async/await and generators wont be in Rust 2018?
If you just want "stuff done" and not interested in the algorithms and protocols, then [sodiumoxide](https://sodiumoxide.github.io/sodiumoxide/sodiumoxide/crypto/sealedbox/index.html) will be a good choice. If you don't care about keeping data secret, then you can just sign you data using [`ed25519-dalek`](https://github.com/isislovecruft/ed25519-dalek). If you want RSA (for whatever reason), then [`ring`](https://github.com/briansmith/ring) with enabled `rsa_signing` feature will be a good option (in addition to OpenSSL bindings).
Granted, anchored paths still allow relative paths via `super`. I think this is often overlooked and was highlighted in the guide. Its the reason I don't care too much which solution we go with.
Sure, but contrast with Rust's equivalent: fn add&lt;T&gt;(lhs: T, rhs: T) -&gt; T { lhs + rhs } This results in a compile-time error, you have to add the `Add` bound: fn add&lt;T: Add&lt;T&gt;&gt;(lhs: T, rhs: T) -&gt; T { lhs + rhs } And once you do, anyone trying to use it will get an error *at the call site*, not deep within the implementation.
&gt; D is a fine alternative depending on what you want to do. Educating yourself in an objective way will help you. Indeed. Rust biggest points are the absence of GC and thread-safety. If the GC is not a particular issue for your performance requirements and you're running single-threaded; D may get you there much more easily.
Woah, is that new Rust art on the podium? Will it make it's way into [rust-lang-nursery/rust-artwork](https://github.com/rust-lang-nursery/rust-artwork)?
D also has nice contract programming features.
Hi /u/dtolnay. I have a little implementation question. How does `ParseStream::peek` work? let foo = input.peek(Ident); How the heck are we able to pass `Ident` here? I see that `peek` has a generic param bound `&lt;T: Peek&gt;` and I see that `Peek` is implemented for `FnOnce`s that return some `Token`... and take as a parameter something that is essentially a never-type? I know that we can use tuple-struct names as function-references / lambdas. But `Ident` is a struct with named fields! I would an error message here, asking me if I meant `Ident { /* fields */ }` or something. Are some never-type shenanigans in play here? 
Other talks are available on Rust youtube [channel ](https://www.youtube.com/channel/UCaYhcUwRBNscFNUKTjgPFiA/videos) as well.
&gt; [...] This results in a compile-time error [...] It's also an error in D upon instantiation (which is compile-time). &gt; [...] an error at the call site, not deep within the implementation. So, [same as D?](https://run.dlang.io/is/wvOW38)
This talk was so great, and made me proud to consider myself a part of this community that is always striving to do and be better.
&gt;the absence of generics in Go is just too keenly felt :( they are officially coming, now. 
If you put "http server" into the searchbox of crates.io and order by # of recent downloads, at the top you'll find [tiny_http](https://tiny-http.github.io/tiny-http/tiny_http/index.html) which by the looks of it does exactly what you want.
&gt; &gt; &gt; &gt; &gt; One, I've read several chapters from the D book (which you should also do), and it seems to me that D is more nuanced ie the language is slick but has lots of 'gotchas' you won't encounter with small programs. As a D fan, I can 100% confirm this. Gotchas definitely abound. (Though they're mostly bugs.)
Why do you have so much extra newlines in your comments? Phone?
As far as I can remember, there has been fully open source D compiler (gdc) since 2004.
It's easy to forget to put those on though. Rust it won't compile without them.
The "no gc" parts in D feel a bit like a hack. Sure, you don't need to use the GC, but then you don't need to use the standard library either. Or at least a huge part of it will be inaccessible, and you have to guess which parts will work and which won't. I'd rather have D embrace GC fully, rather than constantly be on the defensive. Does anyone blame Go, Java, C#, Javascript for having a GC? Some people do, but in general they learn to live with it, avoid allocating in loops too much, preallocate as much as possible. Stuff that you'd want to do in C++ anyway sooner or later.
Hey guys, this is a write up I did documenting my experience (and misconceptions) attempting to use Futures and Tokio to perform asynchronous DNS lookups in a project I'm working on.
It's not great that a shared library ships some random symbols. In particular I'm not sure if you can load multiple shared libraries with conflicting symbols on all platforms.
Yeah, I think I need to get into the habit of going to crates.io first. My current process of typing “rust &lt;thing i want to do&gt;“ into Google isn’t working well.
yes
i also did that when i started learning rust
As the error states, this isn't thread safe. You can't mutate external state to the iteration because every iteration needs to do so. Instead, put the data into the iterator. .map(|val| { let extra1 = .. ; let extra2 = .. ; (val, extra1, extra2) }) .find_first(|(val, extra1, extra2)| { computation(extra1, extra2) }) .expect(..) .0;
what is that quote at the end?
Thanks for this writeup! In case you're not aware, we've recently gotten an working group going on async in Rust -- see https://rust-lang-nursery.github.io/wg-net/async-foundations/ -- and the effort involves writing a book about futures and async/await. Would be great to get you involved in that effort as well! You can pop into the WG-net-async channel on [Discord](https://discord.gg/rust-lang) and say hello if you're interested.
Agreed. I've only been in this community for a couple of weeks (and mostly lurking), but while I thoroughly enjoy the language, and fight with it at the same time, it's definitely the community that makes me come back for more every day. There's just so much going on, so much excitement, so many technical discussions to find, and so much focus on this concept of pluralism and positive-sum thinking. I truly haven't seen this in other open-source projects before (especially that last part), and it's awesome!
The pkg directory is an es6 module, [so you can use it like any other es6 module](https://www.sitepoint.com/understanding-es6-modules/).
Yes, I saw the announcement about Error Handling and Generics. Since those are my two big issues with Go, I'm staying tuned :)
On both Rust and Confreaks channels! ow ouch my subscription feed (and their view count)
Yeah, it was a talk with personality, provided useful information, and was very community-minded. The Rust community is really what's kept me interested in the language for the past two years, and has definitely helped me improve my own skills. 
It's basivally one workspace for the framework and the plugins that I ship together with the application. I tried out multiple ways of doing it. The only one that kind of works is having the `crate-type` set to `dylib` for the framework api and the plugins. This way, neither the rust standard library gets packed into the dll nor the framework gets actually linked into the plugins. This setup would require though that each plugin is build with the same rustc version as the main application. And it needs to be re-compiled if the main application changes the rustc version used for development/deployment. I am actually not sure if this even works without having to specify a rustc version. The only way I could imagine having it work is to include the framework and the rustc version in each plugin and make it a `cdylib`, which to my understanding would create a C library. Having one method marked with #[no_mangle] and returning it a boxed Plugin trait implementation and using that one for doing other stuff.
&gt; It's also an error in D upon instantiation (which is compile-time). Sorry, what I meant is that it's an error in *isolation*, without even trying to instantiate it. This means that when I deliver a generic method as part of an API, I can be confident that I have not accidentally forgotten to list a requirement. And when I later modify this generic method, I can be confident I'm not accidentally adding a requirement, and therefore that I'm not accidentally breaking clients. &gt; So, same as D? Although the error messages aren't as good as Rust's. &gt; onlineapp.d(5): Error: incompatible types for (lhs) + (rhs): both operands are of type Foo &gt; onlineapp.d(12): Error: template instance `onlineapp.add!(Foo)` error instantiating Not at all. That's, like in C++, an instantiation stack. [C++](https://godbolt.org/z/KerI0d), **114 lines of errors**, using maximum density and thus unreadable (see at bottom of post): #include &lt;algorithm&gt; #include &lt;vector&gt; struct X {}; int main() { std::vector&lt;X&gt; v; std::sort(v.begin(), v.end()); } [Rust](https://play.rust-lang.org/?gist=4f421510c5f0ab1eab0506187e7fed2f&amp;version=stable&amp;mode=debug&amp;edition=2015), **5 lines of errors**, with deliberately sparser presentation for better readability: struct X; fn main() { let mut v: Vec&lt;X&gt; = vec!(); v.sort(); } Generates: error[E0277]: the trait bound `X: std::cmp::Ord` is not satisfied --&gt; src/main.rs:6:7 | 6 | v.sort(); | ^^^^ the trait `std::cmp::Ord` is not implemented for `X` That is the difference between *structural typing* (aka *duck typing*) and *nominal typing*.
I have had positive experiences with reqwest. What other functionality did you want to add before 1.0?
The only stable ABI Rust has is the C ABI, so if you want to build plugins with a different rustc version than the application, you'll need to make them `cdylib`s.
Some random ideas: * Make a compiler for a simplified version of Rust (this will force you to learn a lot more about how Rust works) * Make a linux kernel module in Rust. It can be something silly/simple. Like maybe it's a character device that spits out ascii art images at random from a database of images. * This probably already exists, but make a [FUSE](https://github.com/libfuse/libfuse) module that exposes a simple database as a file system. * Make your own macro assembler for x86 or arm. * Make a 6502 emulator
&gt; It's easy to forget to put those on though It is not just that. It's easy to write a wrong constraint or incomplete constraint. (E. g. require a hash for a hash map, but not ==, and there will be no error at function declaration and error will be reported during instantiation). Even with template constraints, D templates language is still dynamically typed, and template constraints are similar to type assertions which developers of dynamically-typed language insert at the beginning of functions.
I think the situation is that they won't be in the initial release, but that the 2018 edition will reserve the necessary keywords, and they'll be added in a regular release soon. So you'll have to wait a few months, but not a few years.
I can only address memory safety, which is just one of the safety aspects of a programming ecosystem. One of the things that Rust has going for it compared to a language like D is the lack of a runtime. Rust deals with memory safety through rigorous (and sometimes cumbersome) lifetime checks at compile time, whereas D uses a garbage collector which is part of the runtime that is added to most D programs. You can teel the D compiler to omit the garbage collector (to produce smaller binaries or binaries fire embedded systems, for instance), but that means giving up on automatic memory management and memory safety guarantuees. I'm not sure you can disable the runtime entirely though. In Rust, the language design had zero overhead as an explicit goal. The core library has almost no requirements (only memset, memcpy and memcmp, really) and does not impose any runtime on you at all, while still being able to provide more rigorous safety guarantuees than almost any other language.
Sounds great, I'll check it out! I'm really excited to get async/await in Rust.
No that's my whole point, you can only make it work with this verbose boilerplate of unnecessary type parameters and structs. What I linked is as simplified as I could make it. It's curious that this post got 2 top level replies, one that says "its not that advanced" and, well, yours, asking for if I have a simpler version.
Largest blocker to me is the instability of async/await. Besides that, the second piece is probably typed headers changes.
Rust also tends to have orthogonal features that compose together, whereas D has some overlap that can be confusing. The most obvious example is structs versus classes. In D, classes are references types that are always allocated on the heap, while structs are allocated inline. Rust instead has structs and Box/Rc/Arc/etc. that can be composed together to create the equivalent of D classes with the precise desired behavior.
Why not hack on Redox? If you like lower level middleware, that project could use quite a bit of that. I'd love to be able to compile stuff on Redox instead of cross compiling on the host, and I heard that the author made some good progress there. If that doesn't suit you, there are plenty of other noteworthy projects that could benefit from some attention.
I tried running a benchmark but ran into a [compilation issue](https://github.com/sfackler/rust-openssl/issues/987) of `reqwest`, I'll keep you posted.
I have been following D since early 2000-ish... [proof](https://forum.dlang.org/thread/cfb6go$8nh$1@digitaldaemon.com) and the fact that it's 2018 already and D is still not that popular, is the biggest problem with D. D is a great language, but IMO it doesn't really have a core niche and never gained "enough" momentum. It's like this much better combination of C and Java, that tries to be a better C++. At this point Go stole most of the market in which I would consider using D. Despite, IMO, D is far superior to Go in almost everything. Rust strength is that there are areas in which you can't use a GC, and then Rust is an excellent choice that you're forced to make anyway. Which gives it a foothold and stickiness. On the technical side: I learned to be reluctant to use OOP (inheritance and stuff), exceptions, and love ownership and move semantics, which make me favour Rust. On the D side ... compilation times, macro system/metaprogramming and some minor niceness and flexibility of the DLang is something that I miss sometimes in Rust.
&gt; If the GC is not a particular issue for your performance requirements and you're running single-threaded; D may get you there much more easily. Do these caveats cause any issues when calling D as a shared library from another language over a C FFI?
Just so you know, you can add `https://reddit.com/` before an url to open any existing posts pointing to that url, and if there isn't any, reddit will propose you to submit it. Of course, if the posted link is a redirect, reddit won't be able to link you that post, but it still better that nothing. 
Rust was a ruse to get us talking about Hegelian dialectic the whole time. Who'd a thought?
&gt; Blocking IO makes it harder to know when a connection is dead. 100% this.
Pretty printing is difficult, so I'd just ugly print? and post-process with clang-format.
Namespace under the author's username.
Hey, First of all "researching" probably wasn't the best word to use here. A better way of putting it would've probably been "lightly glancing at various rust DNS clients in order to find the quickest getting started example" :) If I recall correctly, I did find TRust DNS as an initial result when I was looking for a solution, however I didn't immediately see any links to or examples of using the client. Additionally, the initial impression I got from looking at the project page was that this was likely overkill for my use case. I also got a bit confused because the trust-dns.org website lists the project specifically as a server, so I wasn't quite sure if the client was specific to trust-dns or would work with any DNS server. What initially drew me to the Domain DNS library was the fact that I was able to quickly locate a relatively simple example of doing a reverse DNS lookup and I was able to see that it had the ability to perform other queries as well, albeit requiring a lower level approach. Additionally, it mentioned asynchronous lookups using Tokio as a feature, which also piqued my interest since I knew I was already using that via Hyper. Net-lookup (the project that the blog post stemmed from) was actually created as a way to help speed up some logic a friend was doing in node.js and a chance for me to hack around with some Rust code. Admittedly going into the project I knew surprisingly little about DNS, so I was a newbie in that respect, and have learned a lot more or less "on the job". This fact made parsing documentation for DNS clients all the more difficult as well since I was lacking in domain knowledge (pun intended). Now that I'm a bit more seasoned, looking at the documentation the TRust DNS client definitely seems like it would be a better fit for my project and I likely would've avoided many of the problems I addressed in my blog post by using the Tokio runtime vs using the reactor Core. In fact, it would simplify a lot of the lower level logic around the various DNS queries I'm running on each lookup, and I think I'll likely switch over to using it in the near future. I think the biggest problem the "past me" had on initial inspection of the project was that I just wasn't able to find an example quickly enough to get me going with the client. Additionally something I had to learn about Rust in general is that the generated Rust documentation isn't just like javadoc or scaladoc, but can be typically used as a manual as well as a reference. Now that I've looked back at your documentation I'm able to navigate it and I see the examples I'd need to get started rather quickly, but at the time I had trouble finding a client example that was easy to read and I could pick up and use. Sorry for the book response, but I wanted to be rather comprehensive about why I ended up making the choice I did. Hope that helps! PS. Maybe make the names of the libraries on your github page clickable under the "This repo consists of multiple crates" section with a link to the documentation. I sorta gloss over the little status badges including the one labelled 'docs' and really find myself wanting to click on the name 'Client' or 'Resolver' in the list. 
Remember that BetterC mode exists, please. It definitely belongs at least in the minimal overhead category.
**Just to play Devil's advocate** (because I think that all packages should have be name-spaced to usernames or groups from the outtset, seeing clear signs things would have headed this way based on the way NPM is), why does it even matter? That may sound a bit nihilistic, but it doesn't actually affect people's ability to download packages. It only makes discoverability a bit more difficult. Cargo devs obviously thought this would be a problem in the future and "prepared" for it by baking it into the meta for getting a package. Squatting is explicitly allowed under their current rules. A long as you take that into account when looking for a package, it should be obvious that some are more popular than others. So long as its correctly tagged with a good description, it should be searchable, even if the name is \`legitpackage1234\`, if it has 1 million more downloads than the next most popular result, that'll be the package they want to use. TLDR; If namesquatting is "part of the game", what makes it bad at this point, when users would still need to do a bit of research into the package they are planning on downloading?
I'll admit I get a bit nervous whenever there's a new `syn` major version, since rental uses it heavily and there's so many moving parts. Fortunately the upgrade from 0.13 to 0.15 was pretty smooth. I'm looking forward to rust 1.29 so I can use this new parsing API to collapse rental into a single crate and finally get rid of `rental-impl` and the macro-rules shim.
I've not used D, but that sounds a bit like "nostd" Rust. Though I guess that's arguably a bit more niche.
A what? Lol
It is public to procedural macros that want to parse a custom input syntax. For example [this example implementation of lazy\_static as a procedural macro](https://github.com/dtolnay/syn/tree/0.15.0/examples/lazy-static) uses the Syn parsing API to parse the input syntax of lazy\_static which is not an ordinary Rust syntax fragment. Syn uses the same public parsing API to parse all of the Rust syntax tree nodes defined within Syn so you get very easy integration between Rust syntax and custom syntax. A procedural macro can use Syn's parsers as building blocks within a custom syntax. For example in that lazy\_static implementation part of the macro input needs to be parsed as a `syn::Expr`.
but why? a Raspberry Pi 3B+ most likely has more RAM and a more powerful processor, yet it's still painful to use for anything beyond the most basic software development. OpenBSD chooses to make life difficult for any software that needs more than a C or C++ compiler, in my opinion, and C++ is only really supported because there are almost no standalone C compilers. Combining that with an ancient version of the PowerPC architecture... and life is just difficult.
True, it's completely based on my opinion and my impression of the two languages successes, which is biased by my interest in rust and lack of interest in D. &amp;#x200B; But it still seems fair. D has existed for a while and I am unaware of any great successes for it. Rust is much younger and has already gained at least decent traction. Maybe it'll turn out that D has a huge comeback and Rust flounders over time, but that's not what I'd bet on.
I don’t have to worry about hardware security (meltdown. Spector), for the most part. I really like OBSD for security purposes. Plus, it’s the easiest *nix to upgrade from release to release. I’ve never had an OBSD break from an update. Plus, it’s a cool project, imo. Why did a someone setup a Commodore Amiga 500 with modern email? Or why have a Commodore 64 web server? Granted, my project isn’t anywhere near as cool as those.
Thanks so much. Got it sorted :)
Custom registries will fix all the problems with crates.io. It will allow someone to go out and create their own package distribution work their own rules for people to argue about. 
Woah, thats really cool. Thanks for explaining it to me.
[The PowerMac G5 also draws 132W at idle, and 261W under load,](https://www.anandtech.com/show/3843/apple-mac-mini-review-mid-2010/8) which is horrifying to the engineer in me. Rust supports PowerPC on Linux reasonably well, but no one has really put in the effort to support Rust on OpenBSD on x86, so there's no way it's supported on OpenBSD on PowerPC. Even Go doesn't support the old PowerPC stuff on anything but Linux.
Meh, I’ll be using it here and there at my shop, which I don’t pay for electricity there anyway. (Thank god too because I have two dual socket quad core Xeon servers running 24/7 there)
I also want to note that PowerPC (going back as early as 1994) used speculative execution! So, you _absolutely_ do have to worry about hardware security with meltdown-like and spectre-like attacks, unless you're just hoping for security through obscurity. Realistically, I don't think you should be worried about such attacks on personal computers even on x86. See here for an article about it: http://tenfourfox.blogspot.com/2018/01/is-powerpc-susceptible-to-spectre-yep.html
[My favorite of my photos from the conference was taken during this talk.](https://i.imgur.com/AyYwcLf.jpg)
&gt; Iirc, Firefox is pretty up to date. https://support.mozilla.org/en-US/questions/948903 Not really. Even as late as 7 years ago, support had been discontinued probably a year earlier.
🙄 can’t wait for RISC V to come into an affordable consumer package.
&gt; it's mostly for latency-sensitive work that GCs are a plague It's not just latency. If you heap is huge, and the *large portion of it is constantly reallocated*, then GC has a large CPU or memory overhead (or both). The explanation is this: Let `N` be an available memory size on the server. Let `M` be a working set size (memory usage after GC). So GC is needed to be done in intervals proportional to `N / M`. The cost of one full GC iteration is proportional to the working set size, `M` (we need full GC if most objects are short-living). Thus the cost of GC per second is proportional to `M / (1 * (N / M)) = M * M / N`. What does it mean? * GC can be cheap if you have a lot of memory (N is large) * GC can be cheap if your objects are short-lived (M is small) In other words you either: * need a lot of memory * pay for GC with high CPU usage Modern GCs works well only when the working set is small (memory usage is small, or the large portion of memory is consumed by long-living objects (old generation), and full GC is performed only for young generation). So if a system has 100G of memory, and the working set is 99G of short-lived objects, any GC is doomed (it needs to process 99G of objects after allocating each 1G to reclaim 1G of space). `malloc` does not have this problem, unlike GC allocation/free cost (almost) does not depend on working set size and on the amount of memory available. Please correct me if I'm wrong.
You probably want cdylibs to stop exporting this symbol publicly, rather than"getting rid of it".
I think you’re overthinking this, just call it something like `MaybeDefined` :)
Just allow package names to be non-unique. Since minimally we're also providing version strings along with our dependency entries that allows for disambiguation and further disambiguation can be added in the form of a small code, probably a hash of the author name and crate name. If that's not enough then cargo could also ask which variant of the crate you wanted on first build. One, this makes namesquatting irrelevant, even if you are a young dev with plans whose size eclipse the sun staking a claim on the 50+ crates which are going to be cogs in your grand machine you don't adversely effect anyone else's workflow. Two, this would give a pretty good indicator of harmless vs. malicious behaviour. Namesquatting, especially when there's a "contact me if you want this crate name" attached definitely borders on malicious. I can't read anyones minds but I feel like people who squat hundreds of crate names don't have any intention to add code to those packages. That becomes harmless and malicious behaviour (uploading a crate with the same name as another popular crate with the same version information and a payload) becomes really obvious.
If you'd like to make a UI with WebAssembly/Rust, I've heard that yew is really good. It's a React-style backend-rendering framework, I believe. I still haven't gotten around to trying it myself!
&gt; It only makes discoverability a bit more difficult. Easy crate discovery is extremely important in Rust, because Rust takes (correctly imho) the opinion that the stdlib should not be "batteries included" but instead that usage of external dependencies should be as commonplace as Go or Python code's usage of their stdlibs. This allows core functionality to better evolve over time, but risks leaving the impression it is absent by going undiscovered.
On the other hand, Firefox won't stay up to date without Rust port, so I think porting Rust should be pretty high priority.
&gt; no one has really put in the effort to support Rust on OpenBSD on x86 What? OpenBSD/x86 port is upstream and maintained.
You're thinking about the more reasonable NetBSD and FreeBSD platforms, which are Tier 2 and maintained. OpenBSD/x86_64 is on the Tier 3 list, with no support for `cargo` at all. https://forge.rust-lang.org/platform-support.html
No, I was thinking about OpenBSD, and in particular semarie. "no one has put in the effort" is clearly false, because semarie exists. Platform support page is outdated. For example, it does not mention recently merged OpenBSD/ARM64 port.
If the situation is better than the platform support page suggests, then that is good, and I wish the platform support page would get updated.
&gt; How complicated should getting Rust installed be? This requires creating a new Rust target. Since Rust already has OpenBSD targets and PowerPC targets, creating a new OpenBSD/PowerPC target is actually as easy as it can get, but it still needs to be done. It's not automatic. If you want to try, I can help. Feel free to DM my Reddit account. (Once upon a time, I did Android/ARM target, when there was no Android targets and no ARM targets.)
Basically, the only thing missing in OpenBSD is official binary. This is hard to solve, since OpenBSD does not maintain any kind of backward compatibility whatsoever, and in principle and in practice OpenBSD 6.3 (released in 2018) can be binary incompatible with OpenBSD 6.2 (released in 2017).
It's worth pointing out that there's good reasons for the contents of `~/.cargo/config` to *not* be part of your project's source-code. For example, things like "what HTTP proxy to use" or "where to find trusted TLS certificates" are likely to be different on different computers and somebody who sets up `~/.cargo/config` to describe *their* environment won't be happy if your project overrides it. 
I'll name names if you won't. The latest person to be [caught large-scale squatting](https://www.reddit.com/r/rust/comments/9aaanw/cargo_crate_name_reservation_spam/) is [swmon](https://crates.io/users/swmon). /u/swmon_akdf, who is apparently the same person, or someone claiming to be them, later [admitted to it](https://www.reddit.com/r/rust/comments/9aaanw/cargo_crate_name_reservation_spam/e4wutr6/) and pretended to be sorry, but didn't do anything to correct the issue, like adding contact info to the crates. What do we actually **do** in situations like this? They reserved a _huge_ number of potentially real crate names, like "boost", "secure", and "youtube" -- even "rustlang". My suggestions: - Take the crates away. Change ownership to the core team, yank the versions, flag them somehow on crates.io and turn them over to anyone who actually has a crate to upload. - Change the policy so that you can't upload crates without providing contact information. - Prevent future squatting (add an abuse policy and/or namespacing, unless someone has a better idea) 
I think there’s still some C/C++ in rustc. Replace the code with Rust?
Ed25519 signatures are good starting point. Ring has an example of using them: https://briansmith.org/rustdoc/ring/signature/index.html#signing-and-verifying-with-ed25519 Just browsing around crates.io [Signatory](https://crates.io/crates/signatory) seems pretty neat, but I can't give any guarantees on its quality. But it definitely seems to stand upon solid foundations.
Yes, but unless we do a bunch more things like inlining and CSE and stuff, LLVM still has to do this stuff. Optimizations can be made to happen in MIR, but we still have to do them in LLVM since LLVM does all the other optimizations and optimizations like these work best when they can use each others' outputs. &amp;#x200B; (That doesn't mean this is never a win -- preoptimizing in MIR does save LLVM some work -- but it's not a clear win)
My current theory is that it won't let me do this because there would be two mutable references to the map.
Those are just proposals, nothing has been accepted or decided.
I don't say that it is easy but i I just want to get some json data at the start of my program I find it kind of overkill. I don't need any async for this so i would rather pull in curl. But don't get me wrong. For serious server and client stuff there is no way around hyper and tokio. 
If you want your program to work cross-platform, then no, there is no other way. Returning zero bytes is the canonical way of indicating that you've reached the end of the stream. If you have specific information about the nature of your particular stream and platform, then there may obviously be other ways to determine end-of-stream. (For example: if you know that it's a regular file on a typical OS, you can query the file to find its size.) &gt;if a type implementing `Read` returned 0 bytes before EOF, called out in [the documentation for `Read::read`](https://doc.rust-lang.org/std/io/trait.Read.html#tymethod.read) as specifically *not* indicating EOF, it will cease reading and return. I think you've misunderstood what the documentation says. Returning zero bytes is the canonical way of saying end-of-stream, end of story. However; there is no *guarantee* that it won't have more data later. For instance, if you've reached the end of a file, reading will give you zero bytes. If another process appends more data to the file, a subsequent read will probably return that data. If a stream has no data *at the moment*, but is likely to have more data later (for instance, a still-open TCP connection) then read is guaranteed to block until data comes along (at least on all platforms that I know of). It will never return zero bytes unless it has reason to believe the stream has ended.
&gt; on opt_level=3 the optimizer decided that my calculations should be rearranged to yield -Inf on every step So you basically found a compiler bug?
&gt; I feel like val_mut is borrowing from MyMap so it should share it's lifetime... But you didn't tell it to the compiler. This will implement it and compile: impl&lt;'m, T&gt; Slot&lt;&amp;'m mut MyMap&lt;T&gt;&gt; { fn val_mut(&amp;'m mut self) -&gt; &amp;'m mut T { &amp;mut self.map.table[self.index] } } Note that if you simply have `&amp;mut self`, it gets assigned its own lifetime parameter, which is not `m`, so it does not work out. After this, you'll run into problems with temporary values in main, but they're somewhat easy to solve, so I'll leave it for now :)
There's also people taking valuable crate names for weekend projects.
More like it used `unsafe` code and introduced undefined behavior.
If there is both "legit" and "bad" squatting, how do you tell which is which? If I reserve a name for a side-project I sincerely have in mind but never get around to writing any code because life happened, at what point does this become "bad"?
I think /u/Shnatsel meant that you can't use the mentioned library out-of-the-box: is just a framework which can translate most of the wasm, but without concerning how the "environment" is implemented: e.g. how is linear memory implemented, where are globals located, how is imported functions get called, etc. &amp;#x200B; But there is a project called [CraneStation/wasmtime](https://github.com/CraneStation/wasmtime) which is intended to provide an environment implementation, along with other machinery, allowing to use it as embedded library to run wasm. It's in active development though and not ready for use yet.
I'm trying to advocate for Rust in my company, and I know some trouble makers will ask this kind of question, or get bothered because the dll produced by Rust is not the same stuff like that. Just gathering shields against future possible bullets :)
Yes, that will do :D How do I achieve this?
results are in: https://users.rust-lang.org/t/blog-rust-faster-simd-edition/20205/6
But Rust code shouldn't be like Java where you really need an IDE to be productive. A normal text editor should be enough. So I disagree that imports **should** be written by tooling. Of course, if you have a tool that writes imports, it would write absolute paths, but for handwritten imports, relative paths often make more sense and is more in line with modularization &amp; being independent of how the parent module structure is.
Moving a module including its sub-modules wouldn't change it's relative imports of its sub-modules. But with absolute paths, you **WOULD** need to change the imports for its sub-modules!
To me, what you describe is _bad_ squatting. A name is just a name in your case and you shouldn’t prevent someone (with actual code) to use it if you don’t have anything to show. The *legit* use-case is when a user has been proved to be working on something that really needs the name. Having the idea of the name first without the actual code is, to me, a bad reason.
That’s clearly not a solution. We’re talking about crates.io here, not custom mirrors.
Yeah, I was thinking about that guy too… I find it a bit disturbing that someone like them are still up and able to name-squat (especially regarding the CoC…).
&gt; Complementary (and I think this should be added whatever the other solutions): add the possibility to ask the community / administrator to explicitly disable a name. This “future-proof” yanking can be used for binaries. The best example is alacritty. The crate exists and is owned by the real author of alacritty but is squatting (it contains an Hello World). Try to cargo install alacritty &amp;&amp; cargo run alacritty – he does that to prevent a hacker to squat the name and provide a malicious binary, I guess. With this future-proof yanking feature, alacritty’s author could just ask for the removal of the alacritty crate by adding it to a black list. cargo could see that and just provide a nice message to people trying to install that it’s a binary and that it cannot be installed via crates.io. How is that a legitimate use? Alacritty already is cargo-installable with the GitHub URL - shouldn't we encourage, instead of squatting the `alacritty` crate, that `cargo install alacritty` should **actually install** Alacritty?
I've been using it without problems. And its last release (0.1.9) was on July 10, 2018, so 2 months ago. So you can just use the latest crates.io version. The yanked versions happened in 2015, but they are shown higher in the list because the version numbers were higher.
The usual pattern is that someone is working on a project and want to reserve the name so it won't get taken before the 0.1 release. Why not add a crate reservation feature and make this approach official? This is what I suggest: 1. If you `cargo publish` a crate with magic version number `0.0.0`, that crate will be **undownloadable**. It will just have an entry in crates.io. You are encouraged, of course, to add `description` and `keywords` so people will know what will be there in the future. 2. Because this crate is undownloadable, `cargo publish` can be allowed to overwrite it without having to change version. 3. If the crate has not been updated for a reasonable amount of time (two weeks? a month?), the crate reservation will be automatically removed. 4. When you publish a version above `0.0.0`, the crate will finally be downloadable and won't be removed automatically. This, of course, will not stop the illegitimate squatting, but once this usage become common it will allow to easily distinguish between the legitimate and illegitimate ones: * If a crate has a version number greater than `0.0.0` without anything meaningful in it - they're squatting, and can be removed (no one should depend on that crate) * If a crate has a version number `0.0.0` for a long time and all the GitHub commits were junk changes - they are probably squatting and should be removed. This could be a mistake, but since no one depends on that crate the damage is limited. * If a crate has a version number `0.0.0` for a long time but there are actually meaningful commits in it's GitHub - that's a legit create in the making, let it be.
This [codespawn](https://github.com/kondrak/codespawn) crate might be relevant.
[Here's the playlist!](https://www.youtube.com/playlist?list=PL85XCvVPmGQi3tivxDDF1hrT9qr5hdMBZ)
crates.io is a tool for developers, not a release channel.
I know Simon wants to create a crate named X because he mentioned so at a meetup talk. I quickly write a small experimental program called X, publish it under the name. Under your rule, I wouldn't have squatted.
Even though the G5 might look retro on the surface… it's pretty damn modern actually — the CPU runs the same code as POWER8/9 can run (minus the newest extensions and little endian mode), and the latest models actually have PCI Express!
&gt; a Raspberry Pi 3B+ most likely has more RAM and a more powerful processor The late 2005 G5s can have up to 16GB DDR2. And PCI Express, so you can use NVMe for fast storage. RPi's Cortex-A53 cores are an absolute joke, the memory is very slow and single channel, Ethernet is bottlenecked by USB 2.0, SD cards are slow… &gt; an ancient version of the PowerPC architecture Sure it doesn't have any modern extensions, but it runs most of the same code as POWER8/9 in big endian mode.
If you have code, yeah, that’s not squatting.
Why allow `cargo install` binaries from it, then?
And we already found a few further improvements (at least for spectralnorm and fannkuch\_redux, n\_body as presented will be slower on the benchmarksgame server due to lack of AVX)!
Imho, what you describe is still bad behavior, because it prevents a (good) name from being used. It's not evil (intentionally bad) but it's still not nice for the community.
yeah, that is surprising, but at least now we now know this key piece of information for future versions!
I think squatting is fine per-se, e.g. I've reserved a set of names for [RustCrypto](https://github.com/RustCrypto) project, because in my experience it's overly optimistic to rely on cooperation of random people which can register "good" crate name, publish low-quality work and disappear. And even if they are around it's not guaranteed that they will be willing to join initiative to make domain-specific ecosystem better. (see `md5` and `sha1` crates) But I think policy should be updated to address arising issues. Firstly, we need rules for expropriation of crate names. For example: if someone wants to get crate ownership he will fill request (e.g. via simple e-mail), assigned person(s) from crates team will try to contact current owner of the crate and if owner does not object or does not answer for say 6 months, crate gets transferred. If owner says "no" to the transfer, crate continues to be his, even if it's just a placeholder and no new requests for transfer can be filled e.g. for an year. To limit number of requests we can add requirement that transfer requests are accepted only for crates which didn't get updated in say 6 months. We probably will also need a safety feature to disallow publishing of updates to existing major/minor versions, so if version 0.3.1 exists, you will be able to publish only 0.4.0 and later. Secondly we need to hide placeholder crates from search by default. Placeholder crates can be determined by version (i.e. 0.0.0) and/or badge in `Cargo.toml`.
https://www.youtube.com/watch?v=QuGcoOJKXT8&amp;t=3m7s
It will probably be worth it to document which CPU version the benchmarks server has somewhere and to use that via \`RUSTFLAGS=-C target-cpu=core2duo\` when benchmarking.
Such as?
D does have safety features, but mostly achieves it with the `@safe` attribute (https://dlang.org/articles/safed.html#safed-subset) and the garbage collector. D is trying to improve it's safety features with DIP25 (https://wiki.dlang.org/DIP25) and DIP1000 (https://github.com/dlang/DIPs/blob/master/DIPs/DIP1000.md). With those, or something like them, implemented, D's safety story will get even better. I encourage you to view my comment at https://www.reddit.com/r/d_language/comments/9dkx6q/d_vs_rust/ for a little more of my opinions about Rust vs D. If you're exploring new and emerging systems programming languages, you may also be interested in Nim (https://nim-lang.org/) and Zig (https://ziglang.org/).
First, cool project, don't give up! Second, check out the `librustc_target` crate: https://github.com/rust-lang/rust/tree/master/src/librustc_target/spec Depending on whether you want to modify rustc for cross-compiling initially, or use cargo, you might need to "mix" the ppc and openbsd targets from there. There are many _many_ ppc, ppc64, and ppc64le bugs open upstream and in llvm that directly affect code generation. So I cannot really tell you how easy this adventure is going to be. 
Just so you don’t have to click through: no option to remote.
Nice French reference but I’m not sure whether it’s a sarcastic comment or what. :)
Modern GCs like Azul's C4, ZGC and Shenandoah work very well with TB of memory, 100GB is tiny for them. 
Go, C# and to a lesser extent Java (it is improving though), also provide the tools to do manual allocations, or take ownership of how the GC behaves in critical sections. Yes the code might be not so idiomatic, but I rather have a very tiny portion of non-idiomatic code on an otherwise safe codebase, than 100% of code that risks UB or memory corruption issues.
Ada is safe and has no GC as well.
How will that help? People will start squatting namespaces like `web`, `security` and `mem`.
I’m saying that this supposed separation between "good" and "bad" squatting seems very arbitrary. Does literal Hello World count as "actual code"? Does domain-specific Hello World? (Draw a first triangle, blink a first LED, …) Does the result of one evening of work that is not really useful yet on its own? Does a very buggy prototype? Who gets to decide? ----- I think the fact that these questions don’t have a good answer is a sign that this separation between good and bad is not useful in the first place.
Everything you mention are bad reasons for claiming a name. What does the community benefit from an crates.io published hello world implementation?
then you'd need those keywords to be your username
Neither are `ripgrep`, `tokei`, `shell2batch`, `watchexec`, `fd-find`, `exa`, `oxipng`, `parallel` and so on. If you go through the "Most Downloaded" list of command line utilities it's full of non-development applications. When I asked a year ago, it also wasn't stated anywhere that it should only be for developer utilities. I don't think this has changed, or should change at this point.
I mean all `cargo install` does is compile a binary crate and stick it in a folder that's in `PATH`. You could release anything on crates.io. But if you asked me what would most naturally suit being primarily released on crates.io, I would say what I said.
This isn't working. Firstly, pkg is a directory for me, and the includes are supposed to have a .js extension. So, I imported the main file which has a .js extension. Secondly, the main file (generated by wasm-pack, btw) imports the wasm file without the .wasm extension, and if I add it, then I get an error saying the browser recieved a non-javascript type of application/wasm. Then, in the server, I returned the file with a content-type of application/javascript, and then I got an error saying \`Uncaught SyntaxError: Invalid or unexpected token\`, which I think is because the file is not JS - it's wasm. So how do I import it?
&gt; If there is both "legit" and "bad" squatting [...] I'm still waiting for examples of legit squatting.
I didn't mean that `cargo install` was only for development tools. I meant that because Alacritty was not a development tool (or a command line tool even) it might be better suited to a more traditional release mechanism.
Why does the impl compile impl&lt;T, E, F&gt; Stream for PollFn&lt;F&gt; where F: FnMut() -&gt; Poll&lt;Option&lt;T&gt;, E&gt;, { type Item = T; type Error = E; fn poll(&amp;mut self) -&gt; Poll&lt;Option&lt;T&gt;, E&gt; { (self.inner)() } } but this one fails with the following errors impl&lt;A, T, E, F&gt; ActorStream for PollFn&lt;F&gt; where A: Actor, F: FnMut(&amp;mut A, &amp;mut &lt;A as Actor&gt;::Context) -&gt; Poll&lt;Option&lt;T&gt;, E&gt;, { type Item = T; type Error = E; type Actor = A; fn poll(&amp;mut self, srv: &amp;mut A, ctx: &amp;mut &lt;A as Actor&gt;::Context) -&gt; Poll&lt;Option&lt;T&gt;, E&gt; { (self.inner)(srv, ctx) } } errors: error[E0207]: the type parameter `A` is not constrained by the impl trait, self type, or predicates --&gt; webrunner/src/actix_ext.rs:42:6 | 42 | impl&lt;A, T, E, F&gt; ActorStream for PollFn&lt;F&gt; | ^ unconstrained type parameter error[E0207]: the type parameter `T` is not constrained by the impl trait, self type, or predicates --&gt; webrunner/src/actix_ext.rs:42:9 | 42 | impl&lt;A, T, E, F&gt; ActorStream for PollFn&lt;F&gt; | ^ unconstrained type parameter error[E0207]: the type parameter `E` is not constrained by the impl trait, self type, or predicates --&gt; webrunner/src/actix_ext.rs:42:12 | 42 | impl&lt;A, T, E, F&gt; ActorStream for PollFn&lt;F&gt; | ^ unconstrained type parameter 
Maybe try `.clang_arg("-x").clang_arg("c++")`.
And what is the defintion of code? What `cargo new` produces?
Sure, for a general wide audience other release mechanisms are probably better suited.
I'm not sure if the CoC helps here. Unless name-squatting counts as spamming? &gt; - Likewise any spamming, trolling, flaming, baiting or other attention-stealing behavior is not welcome. 
I really like the idea of a time-limited name reservation. I bet it would help kick some projects off the back burner as well! I know deadlines are quite motivating for me. 
&gt; my first ever coding language Well, I can't say I recommend Rust as a first language. It's somewhat like learning to drive in an F1 car, as opposed to a small hatchback. If you haven't already, make sure you read through [The Book](https://doc.rust-lang.org/book/second-edition/). I'd recommend giving it at least a skim through before experimenting much. Rust as a first language is not particularly conducive to experimentation. Anyway, moving on... let base_temp_type = base_temp_type.to_string(); This doesn't do anything beyond copying a `String` that already exists. If all you want to do is make the variable "not `mut`", you can just write `let base_temp_type = base_temp_type;`. can't compare `std::string::String` with `char` This is exactly what it looks like. You can't compare strings and `char`s. The solution is to not do that: compare a string with a string (or in this case, a `String` with a `&amp;str`): `base_temp_type == "c"`. That said, even if you fix this, it still won't work because `read_line` includes the line terminator. So you actually need: base_temp_type.trim() == "c" Moving on... let mut convert_to_type = String::new(); This doesn't appear to be used for anything. let temperature = temperature - 32 / 5 + 32; This won't work because `temperature` is a `String`, not any sort of integer. You need to convert to an appropriate type. One way would be, on the line before: let temperature: i32 = temperature.trim().parse() .expect("temperature wasn't a valid integer"); Though I'm pretty sure the expression you have there is wrong, anyway. Rust isn't a calculator: that gets evaluated as `temperature - (32 / 5) + 32`, and because you're using integers `32 / 5` is 6, not 6.4. So you probably *actually* want to use a floating-point type like `f64`. So all together, [that gives this code](https://play.rust-lang.org/?gist=9fde323281d8b6b3012f351c374420fa&amp;version=stable&amp;mode=debug&amp;edition=2015). Incidentally, the playpen is usually the best place to share code, since it lets people immediately compile it and see any problems. Hope that helps.
Is that difficult to achieve? Does crates.io have better protection against spamming new usernames compared to new crates? Why not turn on the same protections for creating new crates, if so?
There is a *lot* of code in curl, too. Is it that different?
Can I use libraries? Can I use libraries that use unsafe? Basically boils down to making library that safely wraps `write` syscall with nostd, and then calling that. Might need some linker tricks to get the size down, but shouldn't be that bad.
http://mainisusuallyafunction.blogspot.com/2015/01/151-byte-static-linux-binary-in-rust.html
Yeah why not. Most of the core stuff has to anyway. 
Yeah it is definitely unfair and arbitrary. Rust packs in a whole lot that can be just dynamically linked in C. It’s to make it interesting but I guess it’s been done already. 
You could try to omit the space as wo well
Then maybe the different OpenBSD versions should be different targets. Then you could have different binaries.
That and many other options were discussed on the issue, do read it. You aren't really adding anything.
You can't, unfortunately, `collect()` into an array. You can use a `Vec` as the storage, like this: let reconstructedTransmissionList: Vec&lt;_&gt; = EIGENVECTOR_AVERAGE_DATA .into_par_iter() .map(|avg| { avg.powf(glassDiameter).powf(beerSRM / 12.7) }) .collect(); (https://play.rust-lang.org/?gist=837cfbd2978658d5ef7b5a07edc5c713&amp;version=stable&amp;mode=debug&amp;edition=2015) Or alternatively, if you do want an array for performance reasons, look into using `arrayvec` crate.
What's the recommended way to access shared data when using Tower Web?
&lt;3&lt;3&lt;3
Similar to how you access shared data in any multi threaded Rust program, put it in an `Arc`. If a given service/resource/middleware needs access, you can give it a clone in its constructor.
Sorry, I was too fast to answer. I planned to read it when I'm home ;-)
Sounds exciting! I can’t wait to learn the language and contribute to machine learning in Rust. 
Fantastic website! Thank you! 
Thank you!
Nice! I'll probably continue toying around with my code now that I've dug myself in deep enough, but good to know there are other options. :)
Gotcha. It's not a super big deal as the computation is very simple. I'll probably do a benchmark between the vector and array types (with the vector being parallelised) and see how they compare and go from there. Thanks so much
No. Cost of alloc/free in malloc is constant (or maybe logarithmic of memory size). Basic malloc implementation is just a free lists of blocks of `2^N` size. (And better malloc implementations do optimizations above that). Malloc can work efficiently when only a tiny amount of memory available. And GC needs a lot of free memory to work efficiently. And GC works better when you have more memory. Basically, that's because GC can execute less often.
You can request them from Azul.
Would it be possible to include such an example? This is a very common requirement that Hello World apps don't explain how to fulfill. Where that `Arc` should be remains unclear to me.
One had last commit in may the other a day ago. 
You can probably use variations on [this technique] along with the compiler flags from the blog post Steve linked to to make something tiny. It's wildly unsafe but doesn't use the unsafe keyword so it's technically valid :)
I did! But looks like this site is abandoned, I got no reaction there so far.
Oh huh, I guess that makes sense. I never see any job postings anyway
&gt; What about doing an implementation of `FromParallelIterator` for `[f64; 81]` or `[T; N]`? Could that take care of the issue? Rayon could add that itself, although it's annoying without const generics. We'd have to implement it for specific array sizes, like how many `core`/`std` traits are only implemented for `[T; 0]` through `[T; 32]`.
I agree that the cost of alloc/free is constant. I said that malloc’s cost is proportional to the number of objects because each object’s allocation incurs a call to malloc and free. Each call may run in constant time, but the whole will be linear on the number of objects.
Do you have thoughts as to what the example should do to demonstrate? 
Since you already have an initialized target array, you can just iterate that as a mutable slice. You could `enumerate()` for the index, but your example as given can just `zip` the eigenvector data. Something like: let mut reconstructedTransmissionList: [f64; 81] = [0.0; 81]; reconstructedTransmissionList.par_iter_mut() .zip(&amp;EIGENVECTOR_AVERAGE_DATA) .for_each(|(elem, data)| { elem = data.powf(glassDiameter).powf(beerSRM / 12.7); }); This approach may improve your serial code too, by avoiding explicit indexing.
Yup! You have both an immutable reference and a mutable reference to self.values because get() borrows. Here is working example: https://play.rust-lang.org/?gist=80608f03874c44935d3a6f74f4f3711d&amp;version=nightly&amp;mode=debug&amp;edition=2015 All I changed was the value function.
It would depend on what the other language is. Most GCs are designed to *own* the data, and possibly *lend* it to native code. Attempting to have two GCs co-owning the same pieces of data is a recipe for disaster unless they have been specially engineered for the purpose. So, as a rule of thumb, it's just easier to have 2+ GCs in the same process. With care, if you pay attention to avoiding cycles spanning GCs, you can make it work using the lending rules; but that's finicky.
I solved it 2 mins ago but really ugly so I appreciate your answer :) I tried to make it use generics but I failed horribly lol Anyway, thank you.
I think pretty much everyone understands the difference between good faith and bad faith. Just because it's not trivially easy to codify the line doesn't mean we have to give up on any and all oversight. 
&gt; Please correct me if I'm wrong. From experience, you're right. The problem is generally solved by shoving more memory at the process; modern servers can have ~384GB relatively easily. Going further would start costing more though, the cost is not linear, so there's a point of diminishing returns there. Which leads to the second solution: distributing the load. For some problems it's easy, for others... not so :/
A straightforward check on the incoming type (if its a "POST", update the Arc with data from the request body) should do it. If you have a bit of time I could give it a go and post a gist! I have yet to try anything futures based (only really worked with older versions of Iron/Hyper so far) and I'd be eager to give it a shot.
If you’re gonna make a policy based on such a difference, you need a way to deal with the blurry middle. I think that having a group of people making judgment calls (that impacted people might want to appeal) is not a way we want to operate as a community. I do think this means that such a policy is misguided in the first place.
Thanks for the response. I'm not thinking I will need physics at all thankfully so that shouldn't be an issue. 
Amethyst I think is a better option overall right now, development is more active, and its more a integrated experience, documentation is better. &amp;#x200B; Amethyst has a very complex entity system, which should be good for bigger games, and/or games that have strict performance needs, it seems to add a bit of cognitive overhead for games that don't actually need that though. Pong in amethyst is a lot more lines of code than pong in Raw SDL2, in other words. &amp;#x200B; So if you are making a simpler game, something like ggez or just doing things from scratch might be better, or using parts of piston (like, use gfx-rs plus conrod for ui or something) &amp;#x200B;
Huh. I haven't heard about it before. I'll look into it, thanks. I'm pretty sure it's not integrated with amethyst in any way except using the same ECS, though. That's what I meant.
I don't believe Rust 2018 changes anything in this regard. https://play.rust-lang.org/?gist=d7587a869ff6e4b1d9d07c4b5309749a&amp;version=nightly&amp;mode=debug&amp;edition=2015
Macros have to end their identifier with !, right? That's not valid for anything except macro invocations. macro_rules is itself a macro, so it can do what it likes to that identifier.
&gt; Modern GCs like Azul's C4, ZGC and Shenandoah work very well with TB of memory, 100GB is tiny for them. https://en.wikipedia.org/wiki/Russell%27s_teapot
Incidentally, here's another example of the ECS design but not for games. It's for GUIs: https://www.youtube.com/watch?v=4YTfxresvS8
I think you forgot to post include a url in your post :)
Great post! The Tower stack is shaping up really nicely -- looking forward to seeing some of these components factored out and published to crates.io!
This is correct.
Malloc cost is linear of the number of objects, and that's it. But GC cost also depends on the available memory size, that was my point.
Yes; but in Rust 2018 you import macros with `use cratename::macroname` without `!`, which creates the potential for ambiguity.
All of the talks at RustConf were great, but this keynote is especially of interest, so I wanted to submit it too. Catherine talks about game development in Rust, but also shows off how to go from an OO mindset to a design that works well in Rust. It just so happens that these are patterns game developers are already using.
&gt; http://mainisusuallyafunction.blogspot.com/2015/01/151-byte-static-linux-binary-in-rust.html I like that blog: `main` is indeed usually a function.
The components you're talking about don't really have anything to do with ECS's components- the names here are unfortunately rather vague. Your components (database, cache, etc.) are large-scale pieces of the application, containing both data and code, and accessed through abstract interfaces so they can be swapped out. On the other hand, ECS components are small, concrete chunks of data with no associated code. They describe a single aspect of an ECS entity, playing a role similar to a single row in a table of a relational database. That is, they don't *do* anything or even describe a full self-contained object- they're just there for the systems to query, join, update, or otherwise munge. Continuing the database analogy, ECS entities are like database keys. They are nothing more than handles that allow you to locate the components (rows) associated with them. Notably, one entity (key) generally has *many* different types of components attached to it. In a sense, this "reifies" the life cycle of your data- individual components can be created and destroyed without invalidating pointers, fragmenting memory, etc. Finally, an ECS system is a specific, standalone transformation on the components. Systems don't contain any state, and they don't provide any sort of API to other parts of the application, communicating solely through the component store. You can *completely remove* a system and everything else will just keep going (without that system's functionality of course)- so your closest analog might be a request handler, for example. Note that none of what I described above has anything to do with what you call a system-map. That pattern can be useful, for example to manage an open-ended set of component stores, but it's not at all fundamental to the ECS design. So overall, while your design does share a state management technique with ECS--a single shared database--it is really something else. And frankly I'm not sure it makes sense to apply ECS, per se, to anything outside of game-like applications. The lessons in state management are more important and more widely-applicable.
Yes, I would call my approach "data oriented" but not strictly so. I also think it's worth exploring a more rigorous ECS approach to other domains, including GUI. I'll be exploring some of these idea further within the domain of audio synthesis, where there are additional constraints that make the problem very interesting, especially no allocation or other potentially blocking operations on the real-time thread.
You might want to edit your description, because "Rust guy" unfortunately makes it sound like you're looking for a guy
http://go.azul.com/continuously-concurrent-compacting-collector
What do you think about the alacritty case? It's kind of a gray area IMO. 
The paper clearly states that GC is generational. "Generational collectors are based on the Weak generational hypothesis i.e. most objects die young" "current C4 implementations use two generations (young and old)" The paper DOES NOT state that GC works efficiently when all objects are young.
I've been waiting for it as well, and haven't seen it yet. Not sure.
In terms of making this Rust specific, I think there are probably two things worth highlighting here. First is the inclusion of ripgrep's first C dependency (albeit optional). I thought this would be harder to get working across macOS, Windows and Linux, but it turned out to not be that bad. I suspect that while PCRE2 is a quite complicated library (like any regex engine), its dependencies and platform specific knobs are fairly minimal, which perhaps made it easy. I think the other decision here that was important was opting to compile PCRE2 manually, instead of using its build system: https://github.com/BurntSushi/rust-pcre2/blob/319b16b2c66bdccac7052044d8e5ae265f686989/pcre2-sys/build.rs#L83-L100 --- The `cc` crate really saved me here! For folks that want to use PCRE2 in Rust, I wrote a high level binding based on the regex crate's API that anyone can use, completely separate from any of the ripgrep libraries: https://github.com/BurntSushi/rust-pcre2 Secondly, ripgrep core is now smaller (in lines of code) than it was when it was first released. This is because almost all of the interesting code is now in libraries! I am in the middle of writing a guide on how to use the not inconsiderable number of crates that came out of it, but here's a sneak peek: * [grep-matcher](https://docs.rs/grep-matcher) defines the [`Matcher`](https://docs.rs/grep-matcher/*/grep_matcher/trait.Matcher.html) interface for describing common operations provided by regular expressions. This includes finding matches, extracting capture groups and performing replacements. This library permits the use of any regex implementation. * [grep-regex](https://docs.rs/grep-regex) provides an implementation of `grep-matcher`'s interface using [Rust's regex library](https://docs.rs/regex). This is also where a host of optimizations are applied at the regex level to make line oriented searching fast. * [grep-pcre2](https://docs.rs/grep-pcre2) provides an implementation of `grep-matcher`'s interface using the [PCRE2](https://www.pcre.org/) regex engine. Unlike Rust's regex library, PCRE2 provides several fancy features such as look-around and back-references at the cost of slower search speed in the worst case. * [grep-searcher](https://docs.rs/grep-searcher) provides the high level implementation of searching files and reporting their results. This includes features such as counting lines, setting the line terminator, inverting matches, reporting matches across multiple lines, reporting contextual lines, binary data detection, transcoding and even whether or not to use memory maps. This library defines the [`Sink`](https://docs.rs/grep-searcher/*/grep_searcher/trait.Sink.html) interface, which describes how callers must behave to receive search results. * [grep-printer](https://docs.rs/grep-printer) provides a few implementations of the aforementioned `Sink` trait. This includes a JSON output format in addition to the standard grep-like format with support for coloring, multi-line result handling, search &amp; replace and various other formatting tweaks. * [grep-cli](https://docs.rs/grep-cli) provides cross platform convenience routines with user friendly error messages for common operations performed in grep-like command line applications. This includes checking for a tty, inferring a stdout buffering strategy and reading from the output of other processes. All of the above crates are included and re-exported as a facade in the `grep` crate: https://docs.rs/grep And finally, read this before asking me why PCRE2 mode is slower than the default. :-) https://github.com/BurntSushi/ripgrep/blob/master/FAQ.md#pcre2-slow
Are you compiling it with cross-language inlining ?
Only if that's somehow the default in fully static builds. I certainly didn't do anything to specifically enable it. In any case, it's very unlikely to be the issue here, particularly given the analysis I linked to. (Rust's public API functions are very unlikely themselves to get inlined because they are massive. The same goes for PCRE2, whose match function is similarly massive.)
I have a CLI that uniques text files by certain columns. Anyway I initially wrote it to accept either stdin, `fs::File` or `io::Cursor` (for testing). I've done this via static trait dispatch but it means my code needs to have a special API to indicate what kind of handle you want to use, then a match statement to call the run function one of 3 different ways depending on the type. Is it more idiomatic to just accept a `Box&lt;io::Read&gt;`? I've tested and can't see any noticeable difference in peformance, probably there aren't enough read calls to make a difference.
&gt; Only if that's somehow the default in fully static builds. No, it's not the default in any build.
It feels like a well-intentioned attempt at protecting self and others from the problematic decisions to make crates.io and Cargo a release platform and actively forgo establishing a mechanism for establishing authenticity, but ultimately misguided in that "the alacritty crate" is objectively useless software whose sole purpose is to exist such that no other software can exist in its space. It's probably the least bad example I've seen.
I'm sure there is amethyst-physics crate, or something like that, which in is aimed to integrate rhusics.
While amethist has simpler ui than conrod you can just integrate conrod into render, should be pretty simple thing to do since conrod have some glue code for gfx already.
Do you happen to know the rationale for this discrepancy between import and usage? Seems if the "!" was part of the import as well it would be more consistent, more explicit to the reader that a macro is imported and it would avoid the ambiguity.
For readonly access I wrote something that takes a String and keeps a `Vec&lt;*const str&gt;` of pointers to each field in the string. They stay together in the same struct so it's a bit like `owning_ref` I think. You can even implement Clone on such a structure and clone the original String while remapping the pointers.
Thanks /u/jDomantas Answering myself a bit more completely here. It's because the definition of `FnMut` is pub trait FnMut&lt;Args&gt;: FnOnce&lt;Args&gt; { extern "rust-call" fn call_mut(&amp;mut self, args: Args) -&gt; Self::Output; } I.e. `&lt;Args&gt;` is a type parameter while `Self::Output` is an associated type. I think the reason the compiler cares is that in the first example any one `F` can only have implemented `FnMut() -&gt; Poll&lt;Option&lt;T&gt;, E&gt;` once. While in the second instance it would be possible to implemented both `FnMut(&amp;mut Actor1, &amp;mut &lt;Actor1 as Actor&gt;::Context) -&gt; Poll&lt;Option&lt;T1&gt;, E1&gt;` and `FnMut(&amp;mut Actor2, &amp;mut &lt;Actor2 as Actor&gt;::Context) -&gt; Poll&lt;Option&lt;T2&gt;, E2&gt;` on the same type `F`. In that circumstance the compiler would be unable to tell which version of `Actor`, `E` and `T` should be used. This can be fixed by changing the `PollFn` struct in the second instance to contain a field `_actor: PhantomData&lt;A&gt;`.
Most cases where you think you need dependency injection can be solved with \`Reader\` or something similar. I'd probably start by making a struct of resources that I manually passed around, but there are examples of Reader in Rust floating around.
I love you u/burntsushi
This ties the lifetime of of the returned reference to the Slot which is what I wanted to avoid. The returned reference is referencing memory in the map so I wanted the return value to live for as long as the map contained in the slot. I was confused why I could do this: let val = find(&amp;map, 2).val(); But not this: let val = find(&amp;mut map, 2).val_mut(); `val` refers to `map` after all right? Not the Slot returned by `find()`. I think the error message, while technically correct, is not clear. It is forcing the lifetime of the returned mutable reference to be the same as `&amp;mut self` because otherwise there would be multiple mutable references to MyMap.
I don't remember.
If you intend to use this implementation in a pure Go (server) application, then writing it in Go will be probably the most efficient approach, mostly due to sticking to one language. If you (or your users) intend to use this library with other languages (Python, C, C++, etc.), then Rust should be a much-much better option. Not only it does not have Go-sized runtime, thus being easier to use via C FFI, but also provides stricter guarantees, which is important for library which will work with potentially hostile inputs. (also check [cargo-fuzz](https://github.com/rust-fuzz/cargo-fuzz)) Plus Rust implementation probably will have better performance. Well, of course there is too much unknowns to say for sure, but I think it will be much easier to write optimized implementation in Rust.
I...improved the example a bit r/https://play.rust-lang.org/?gist=8a06d706e53e8f10d3d386998db9371f&amp;version=nightly&amp;mode=debug&amp;edition=2015
Looks like it isn't using https://github.com/rustwasm/console_error_panic_hook Really though, this is just a proof of concept :)
It's [apparently needed an update since Rust 1.5](https://github.com/kmcallister/tiny-rust-demo/pull/1). I've [updated it further to to a current nightly](https://github.com/tormol/tiny-rust-executable), A few notes: * While the example itself doesn't use unstable features any more, it still requires nightly because the dependency [sc](https://github.com/japaric/syscall.rs) uses inline assembly. * kubo39 managed to [shave eight more bytes off the ELF header](https://github.com/kmcallister/tiny-rust-demo/pull/1/commits/718e4511687062937437dda69dff22df3c099c3a). * The assembly has grown by two bytes due to an extra `ud2` instruction, which I assume is caused by [unreachable traps](https://github.com/rust-lang/rust/pull/45920).
&gt; Secondly we need to hide placeholder crates from crates.io search by default. Placeholder crates can be determined by version (i.e. 0.0.0) and/or badge in `Cargo.toml`. The only problem with this is when you don't see the "youtube" crate when you search, then try to upload one with that name and get surprised when it conflicts. 
probably benchmark game needs to update to an AVX2 cpu now that AVX-512 is becoming common. They are two gens behind now.
Neat!
Glad to know that this is something you are keeping up with as part of your new adventures. Oddly, this is one of the things I'm most excited about!
Multiline support, I'm so excited! This will finally motivate me to make the jump from grep, I've wanted this feature since way before Rust existed.
I am really not sure so please correct me if I’m wrong, but I’ve read that impl trait in return position (a.k.a. trait objects?) is dynamic dispatch whereas current style Iterators are static dispatch. Therefore although they reduce to the same signature in the end, their performance may be different. 
This is curious. I tried the code from the front page of [rust-lang.org](https://rust-lang.org), and there seems to be something about the string in the match arm 15 that prevents the entire match from being formatted. Removing three characters from it, apparently any three characters - or is it more precisely graphemes - and the code gets fully formatted.
You've been using grep instead of ack, ag, or ripgrep? Man, you're in for a treat. 
Excellent! I've been looking forward to this quite a bit. 
You're probably thinking of this Box&lt;Trait&gt; aka trait objects which in Rust 2018 look like this Box&lt;dyn Trait&gt; `impl Trait` in return position is statically dispatched. It has exactly the same performance characteristics as if you'd written the actual return type there. 
Does it use PCRE2's C library just to parse the regex, or it uses the engine to match regexes instead o ripgrep's own regex engine (when in PCRE2 mode)?
It’s a form of spamming to me.
It uses PCRE2's engine, with JIT enabled. It otherwise wouldn't be possible to support the fancier features without adding them to `regex` itself.
rust has better algebraic type support. match with exhaustion is simple and easy in rust, and it makes me feel warm and fuzzy.
Hence my point 5. to provide a mechanism to do that. Binary crates are still useful for development purposes but shouldn’t be used as a release channel.
The way I think of it, the bang is part of the syntax for calling a macro. So in the same way that `()` calls a function, `!()` calls a macro. In other words, the bang is not part of the identifier.
I’ve also noticed a lot of “low effort” crates that merely wrap a popular C or C++ library using the ‘cc’ crate as a compiler. I’m my humble opinion such C-masquerading-as-Rust crates don’t belong on crates.io. I go there to find Rust crates, not unsafe C code pretending to be Rust. Because of this, Rust is rapidly entering territory where a C++ compiler will also required for any nontrivial program. Check out the first-level dependencies of the ‘cc’ crate, it’s just insane: https://crates.io/crates/cc/reverse_dependencies Anything dependent on any of those crates will also transitively pull in the C++ compiler. Ugh. Now, I get it, in many cases this is the intention, but a closer inspection of the crates shows that many are very quick and dirty wrappers. They often aren’t updated when the underlying C++ library is. I’ve noticed a few contributors just spamming these out, often squatting the short name without any qualification that it’s a wrapper. Now, when someone spends real effort to write a safe native Rust crate they’ll have to use a longer, less discoverable name! 
Maybe you can also build everything (including libstd) with `-C panic=unwind` (maybe also with `-Z no-landing-pads`). Then there would be no catch_unwind support and it should be like C++'s `-fno-exceptions` mode.
The developers of OrbTk GUI are building their own ECS: https://gitlab.com/orbtk/dces-rust When I asked "why not Specs?" they replied: &gt; Yes two reasons. First we want to keep the dependency tree as small as possible. And second we add some features to ECS to define priority to the systems execution. And a feature to easily work with filtered sets of entities and components per system.
Hmmm yes. How about compiling the regex to use PCRE2's engine for fancy stuff but use Ripgrep's engine for regular regex stuff?
I once made a program on the Amiga to clear the console in Assembly, can’t remember if it was ~20 bytes or ~40bytes... first and only program I ever wrote in Assembly!
there are at least a few important additional approaches available, which seem to very interesting for rust developers. &amp;#x200B; [mxnet](https://mxnet.apache.org/), which is a very binding friendly DNN framework supporting a lot of different programming languages out of the box, already got some rust bindings in the meanwhile: [https://github.com/jakelee8/mxnet-rs](https://github.com/jakelee8/mxnet-rs) and two other very promising projects came up in [TVM](https://tvm.ai/about) circles recently: [https://github.com/ehsanmok/tvm-rust](https://github.com/ehsanmok/tvm-rust) [https://github.com/nhynes/tvm-rs](https://github.com/nhynes/tvm-rs) see also: [https://github.com/dmlc/tvm/issues/1601](https://github.com/dmlc/tvm/issues/1601) [https://github.com/dmlc/tvm/pull/1597](https://github.com/dmlc/tvm/pull/1597) 
Grep is generally perfect for me, I don't really want smart ignoring of files. The first thing I'm going to do is tweak ripgrep to disable it. Unless you're referring to other exciting features I'm not aware of!
I did some C64 assembly. My 2k amiga program in opened a file select window and launched a decompression program based on the file extension and info stored in the icon data. I forget what that was called. We had zoo arc Lou tar and who can remember all the file formats. 
I think if you do `alias rg="rg -uu"` then you should be good to go with respect to disabling "smart" filtering.
I promise I'll release it this weekend, I should have released it already but I'm busy fretting over it too much.
Speed, and the ability to filter on file types without awkward find/exec or find/xargs invocations.
Have an endpoint return the total number of hits across all endpoints.
[slides](https://www.dropbox.com/s/yphqy57kwe7nsdj/rustconf-talk.pdf)
You’re an incredible developer /u/burntsushi ! ripgrep has increased my productivity so much in my day to day work and you continue putting out incredible work like this. Thank you!
So what happens if you `use cratename::name` and the crate defines both a function and a macro named `name`? 
I've actually been developing an ECS-based disk management library with specs.
both are imported
Nice! Time to offer rustfmt as a service behind by running rustfmt as a wasm node module behind a REST API!
Discussion of this issue was [here](https://github.com/rust-lang/rfcs/pull/1561#discussion-diff-57859655) in RFC 1561. The benefits you brought up were raised, then the thread veered into a tangent about whether we even need `!` to invoke macros (we do), and the conclusion was "well, you already don't know whether `use foo::Bar;` imports a tuple struct or a normal struct, so making `use foo::bar;` ambiguous as well isn't any worse". I think that's a logical fallacy and it was the wrong decision, but it's in the past now. 
Not just multi-line but full PCRE? `sudo apt remove pcregrep`
I've never used a timeseries db. What sort of stuff would one do with it?
Thanks so much for the input. It's not happy though: error[E0277]: the trait bound `&amp;[f64; 81]: rayon::iter::IndexedParallelIterator` is not satisfied --&gt; src/light/lightFunctions.rs:14:10 | 14 | .zip(&amp;EIGENVECTOR_AVERAGE_DATA) | ^^^ the trait `rayon::iter::IndexedParallelIterator` is not implemented for `&amp;[f64; 81]` error[E0599]: no method named `for_each` found for type `rayon::iter::Zip&lt;rayon::slice::IterMut&lt;'_, f64&gt;, &amp;[f64; 81]&gt;` in the current scope --&gt; src/light/lightFunctions.rs:15:10 | 15 | .for_each(|(elem, data)| { | ^^^^^^^^ | = note: the method `for_each` exists but the following trait bounds were not satisfied: `rayon::iter::Zip&lt;rayon::slice::IterMut&lt;'_, f64&gt;, &amp;[f64; 81]&gt; : rayon::iter::ParallelIterator` `&amp;mut rayon::iter::Zip&lt;rayon::slice::IterMut&lt;'_, f64&gt;, &amp;[f64; 81]&gt; : std::iter::Iterator` &amp;#x200B;
Well, there certainly are some nice features; for instance, recursive directory descent is automatically (and intelligently) multithreaded, you can trivially restrict your search to specific file types, and you can use a config file (e.g. to define your own file types). But are you sure you wouldn't benefit from smart ignoring of files? If you *want* to search in an ignored folder (such as .git), you can just specify it as an explicit search target on the command line, just as you would with grep. Do you have an example of a typical scenario in which you wouldn't want smart filtering? 
Hey rustaceans, This is my first rust project. Help me on improving the code in the more idiomatic way. Thanks to rust community for helping me, when I'm stuck with small issues.
Just wanted to add that I'm also looking forward to reading the post. Thank you for the talk and the upcoming post.
The coolest part about this is probably how little glue code was needed. [This](https://github.com/alexcrichton/rustfmt-wasm/blob/master/src/lib.rs) is all of it. Plus around the same amount of JavaScript [in the html file](https://github.com/alexcrichton/rustfmt-wasm/blob/master/index.html).
We use an ECS-style architecture for a [logistics product](https://withvector.com). Our scenarios are very similar to that of a CRM, where forms and workflows often need to be customizable. In those systems a metadata-driven architecture is a common solution (usually via EAV with data dictionaries). In logistics our market is dominated by on-premise solutions that are directly modified and SaaS solutions have struggled by being too brittle. Taking the ECS / metadata approach seemed like a good fit. We use jsonSchema to define the properties, web/mobile UI, and various metadata. Each schema is namespaced and our data instances (an entity) declares those it implements. The UI interpretes the data to render it, the schemas to determine available filters and actions, etc. The server has generic CRUD routes and uses the type information to execute a workflow. We use triggers to attach logic server-side based on the schema type (e.g. document) or an embedded data definition (e.g. address). Postgres stores the primary data table, metadata tables, and critical models are denormalized (e.g. user_info). We use ElasticSearch for search, filters, analytics, etc. This model does seem hard for some people to wrap their head around. It is really nice to be able to dynamically mix in new capabilities, often without requiring engineers. Usually adding new features is amounts to enriching the platform so multiple come for free. You can probably play within Chrome inspector to see the data &amp; schemas to get a birds eye view of how things work from the client's perspetive.
If you accept an io::Read, why not just use a function that's part of that trait like read_to_string then analyze the string?
Event logging is one general usecase for a timeseries db. You can start doing some really neat things with data when writing/querying when you bake in the concept of time.
Event logging is one general usecase for a timeseries db. You can start doing some really neat things with data when writing/querying when you bake in the concept of time.
Event logging is one general usecase for a timeseries db. You can start doing some really neat things with data when writing/querying when you bake in the concept of time.
My point is that I don't think performance is nearly as significant a motivating factor in most people's compiler selection as the authors of gcc and clang seem to think it is. Are there any other free non-size-limited compilers for the ARM other than gcc and clang? Given the kinds of projects the people in graduate compiler courses were tackling in the early 1990s, it would seem something else useful should have emerged in the 25 years since then, though maybe at the time gcc was good enough to discourage other projects. 
Event logging is one general usecase for a timeseries db. You can start doing some really neat things with data when writing/querying when you bake in the concept of time.
Got it! I usually don't use an underscore between "Batman" and I "AoD", but the non-underscore version was already taken here. I appreciate your comments on SO! 
Got it! I usually don't use an underscore between "Batman" and I "AoD", but the non-underscore version was already taken here. I appreciate your comments on SO! 
Many aspects of C were never really "designed"--they just kinda sorta "happened". Further, contrary to what the authors of clang and gcc seem to think, the Standard makes almost no attempt at balancing the costs and benefits of defining behaviors. Instead, they figured that in cases where it would be useful for compilers to define behaviors beyond those mandated by the Standard, compiler writers would do so whether ordered to or not. The main issue with the 2D array example isn't with safety checks, but aliasing. In the language described by the 1974 C Reference manual, array subscripting was defined as address arithmetic, so given `int arr[5][5]`, the pointer`arr\[0\]+5`would not only compare equal to`arr\[1\]+0`, but it could be dereferenced to access the same element. I think there is significant benefit to letting a compiler assume that an access to`arr\[0\]\[i\]`will not access`arr\[1\]\[j\]\`, when such accesses are written using that syntax. There is also, however, considerable benefit to having a syntax available which would allow flattened access.
Got it! I usually don't use an underscore between "Batman" and I "AoD", but the non-underscore version was already taken here. I appreciate your comments on SO! 
They're commonly used by metrics monitoring systems, where you're tracking performance numbers over time. Ex: graphite, influxdb, prometheus, opentsdb.
They're commonly used by metrics monitoring systems, where you're tracking performance numbers over time. Ex: graphite, influxdb, prometheus, opentsdb.
I'm running this command: ./x.py test --stage=0 src/libcore/ -j12 Does no-doc make a significant difference? I was assuming there's tests in there that I want to run.
/u/kyrenn would you be able to upload the slides to Github Pages? They're reveal.js so it should Just Work.
Have you considered using the `fancy-regex` crate? (it actually uses `regex`, it's a pretty neat design IMO)
oops, fixed.
The traditional task is recording monitoring data... Often CPU/memory/disk usage stats for computer systems, but really any time-based data from heartbeats to jet engine performance uses basically the same structures. It's nice to use special-purpose databases rather than typical SQL ones because there are operations where specialized tools are nice, such as filtering and downsampling.
I'm running this command: ./x.py test --stage=0 src/libcore/ -j12 Does no-doc make a significant difference? I was assuming there's tests in there that I want to run.
This only works when squatter is not that determined. Any sufficiently determined squatter can easily work around any content restrictions you put up. The thing is if the squatter is not that determined, and if the community need that name, we can simply contact the author to give back the name for community use.
They *need* to do nothing. But on the other hand, the entries will at some point no longer be a good way to do things on current hardware. Perhaps some perf-oriented person with access to a more current server comes along to replicate the results, or join forces?
That trick reminds me of the `op` function in Haskell's [`newtype`](https://hackage.haskell.org/package/newtype-0.2/docs/Control-Newtype.html#v:op) library. The parameter to `op` isn't actually evaluated, but acts as a "key" to select the appropriate type.
Yes. I don't think it has quite reached the appropriate maturity level yet, and I don't quite have the bandwidth to get it there. We can certainly consider using it in the future.
Don't worry, you have plenty of company! The issue you're having is one of the [classic examples](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/#problem-case-3-conditional-control-flow-across-functions) that the *non-lexical lifetimes* feature aims to solve. Using the Entry API (as suggested by /u/outroot) is still the best solution in this case, but a later version of Rust may accept your code as-is :)
Not sure. I've been meaning to create an issue for it, since I was definitely holding off until at least libripgrep was done. For the most part, I don't really intend to make significant backward incompatible changes, however, many releases come with typically very minor breaking changes, and having the freedom to make those changes has been useful. I suspect that at this point, "1.0" will mostly be a marketing thing. The amount of use ripgrep has makes it de facto stable.
Yes, this is especially annoying with custom derive attribute macros.
Odd, technically you could build your own system scheduler ontop of specs. In fact there are just 2 provided ones for simplicity, `Dispatcher` and `ParSeq` (which allows you to define the exact sequences that you can parallelize and sequentialize). Maybe I'm misunderstanding "filter" but you can also just make bitsets and filter out entities based on that: for (mut comp1, comp2, _) in (&amp;mut comp1s, &amp;comp2s, &amp;bitset).join() { comp1.0 += comp2.0; }
Hi, any idea how to solve this `cannot infer an appropriate lifetime for lifetime parameter in function call due to conflicting requirements`? `'static` lifetime bound seems to come from `Any`/`Box`. I just don't understand why this is an issue here, since the iterator yields clones. https://play.rust-lang.org/?gist=e0c6808f516dc603286b045826dcfb1f&amp;version=stable&amp;mode=debug&amp;edition=2015
Either - Require a fully-qualified domain name. A namespace can only be registered if it is demonstrated that the person registering is in control of the domain. or - Prevent the obvious ones from being registered. - Introduce rule that the name has to be either your username, your company name, or a product name.
Also on the official Rust Videos Youtube channel: [1](https://www.youtube.com/watch?v=3YCqgwpuFM0), [2](https://www.youtube.com/watch?v=9PIn4suU3jM)
Authors should stop doing this then. Maybe crates.io needs a non-author settable flag whether `cargo install` should be allowed. If some author thinks his crate is a development utility, he can ask cargo admins to review and approve/deny his request.
 error[E0308]: mismatched types --&gt; src/light/lightFunctions.rs:16:20 | 16 | elem = data.powf(glassDiameter).powf(beerSRM / 12.7); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | | | expected &amp;mut f64, found f64 | help: consider mutably borrowing here: `&amp;mut data.powf(glassDiameter).powf(beerSRM / 12.7)` | = note: expected type `&amp;mut f64` found type `f64` If I add the `&amp;mut` as suggested, it gives: warning: value assigned to `elem` is never read --&gt; src/light/lightFunctions.rs:16:13 | 16 | elem = &amp;mut data.powf(glassDiameter).powf(beerSRM / 12.7); | ^^^^ | = note: #[warn(unused_assignments)] on by default warning: variable `elem` is assigned to, but never used --&gt; src/light/lightFunctions.rs:15:21 | 15 | .for_each(|(elem, data)| { | ^^^^ | = note: #[warn(unused_variables)] on by default = note: consider using `_elem` instead error[E0597]: borrowed value does not live long enough --&gt; src/light/lightFunctions.rs:16:25 | 16 | elem = &amp;mut data.powf(glassDiameter).powf(beerSRM / 12.7); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^- temporary value dropped here while still borrowed | | | temporary value does not live long enough 17 | }); | - temporary value needs to live until here | = note: consider using a `let` binding to increase its lifetime error[E0384]: cannot assign twice to immutable variable `elem` --&gt; src/light/lightFunctions.rs:16:13 | 15 | .for_each(|(elem, data)| { | ---- first assignment to `elem` 16 | elem = &amp;mut data.powf(glassDiameter).powf(beerSRM / 12.7); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ cannot assign twice to immutable variable &amp;#x200B;
This would be awesome indeed ! One still has to know this feature though. It needs to be obvious for a first-publisher
Maybe `cargo init` can set `version = "0.0.0"` in the initial `Cargo.toml` and add a comment about it?
&gt; Help me on improving the code in the more idiomatic way. --- &gt; - PR won't be accepted. &gt; - project won't be maintained. I just built it to learn rust and linux kernal. You're kinda' sending mixed messages here :-).
Even though you're cloning the individual items it's still necessary to borrow `self.things` for the entire lifetime of the return value. Trait objects like `Box&lt;Iterator&lt;...&gt;&gt;` always have a lifetime because even though you're erasing the concrete type the compiler still needs to be able to reason about how long the type can live, like the iterator borrowing `self.things` in this case. This lifetime has an implicit default of `'static` which is why you're getting that error. You can fix this with a small tweak to your function header (in the trait and impl; the body can stay the same): fn iterator&lt;'a&gt;(&amp;'a self) -&gt; Box&lt;Iterator&lt;Item=u32&gt; + 'a&gt; Notice that the lifetime is added to the trait like how you define multiple trait bounds on a single generic parameter. You can also add `+ Send` and/or `+ Sync` because they're not implied by default (but those are not typically added unless it's necessary). This does have the caveat of making every implementation of this function borrow `self` for the lifetime of the iterator even if the internal iterator doesn't even borrow. This is because we've erased the type so the only thing the compiler can reason about is the lifetime on the trait object. Typically you would instead define the return type as an associated type which each implementation can fill in, but in this case since we don't have generic associated types there's no way to fill in the borrow information to make it work (that I know of).
You can work around the local type constraint by wrapping [f64; 81] in a local tuple struct and implementing traits on that. 
Makes sense, thank you.
Haven't thought about it this way, thank you.
Good idea
I didn't mean to be rude. If money is an issue I'd be happy to donate! 
PumpkinDB seems pretty dead as well. 
Yeah no commits since last year. I was hoping to portray that in this post: it looks like most projects in this space are essentially relics. Although I understand that they have pretty varying use cases, event sourcing is something I'm interested in seeing a great rust story for.
Me too. I even had an idea to write eventually consistent event store in Rust, but I have no time to do so right now. 
You could save the internet traffic data ( how much bytes per second ) is flowing in to customer data-centers; and devise algorithms based on that data for protecting against ddos attacks. Another use case the value fluctuations of stocks over period of time! ( take an educated guess on what the stocks value might be in a future time; based on past data) Weather variations over time. In fact anything that can graphed with time on x axis
Really good talk. Just the last bit needed expanding a bit, i.e. the idea that once you have your ECS set up, each subsystem will just scan through the components it is concerned with. I think if I posted this link to non-Rust non-game people they would have missed that.
My point is that I don't think performance is nearly as significant a motivating factor in most people's compiler selection as the authors of gcc and clang seem to think it is. Are there any other free non-size-limited compilers for the ARM other than gcc and clang? Given the kinds of projects the people in graduate compiler courses were tackling in the early 1990s, it would seem something else useful should have emerged in the 25 years since then, though maybe at the time gcc was good enough to discourage other projects.
When I read this, the first thing to pop into my head, (in the voice of "Cartman"), was "Lame.".
Also relevant: https://github.com/rust-lang/rfcs/pull/2477
It's a great piece of software! And it's useful for scripting even when you have an alternative installed. But I highly recommend trying something with more opinionated and helpful features. 
Got it! I usually don't use an underscore between "Batman" and I "AoD", but the non-underscore version was already taken here. I appreciate your comments on SO! 
Amethyst will support vulkan and metal soon.
This is not Digg in the 2000s
What if you're searching outside of a fit repo? I search through /etc and downloaded tarballs all the time, and `ripgrep` is usually as fast as `git grep` and has prettier output. I wonder if anyone has made a `git rg` command...
Yea, `--no-doc` is significant. Without it, it needs to rebuild the compiler and rustdoc in order to run doc tests. Unfortunately it looks like a recent change broke things (https://github.com/rust-lang/rust/issues/54061).
Oh, right: `*elem = ...`
[sled](https://github.com/spacejam/sled) is pretty cool. Not event sourced, but it's cool nonetheless, and pretty customizable with its back end.
Really cool talk, thanks for making it and looking forward to the blogpost! :)
Dune reference?
Yes, then it just becomes an arms race, like E-mail spam. But what is the motivation for squatting? Is the squatter hoping to sell the name for cash? If once you get a prefix (like servo-*) you have exclusive use of that prefix, then that would let you have something like a protected identity in order to group all your crates together with names that you could control. If your favoured prefix is already taken then you'd have to choose another one, but still all your crates would be grouped together with consistent naming.
Definitely. I've been tracking Robin's wonderful work there. :-)
You can easily do this on nebulet. WebAssembly binaries can be tiny.
&gt; the operating system of your choice I suppose Nebulet is a perfectly good choice. :P P.S. Awesome work, by the way! Language based systems have their advantages, but always lock you into a certain set of languages, preventing the use of most of the software out there. WASM let's you compile *C*, meaning that once the kernel is ready, you'll be a libc away from supporting most open source software.
I won't name and shame, sorry.
what does ECS stands for? Great talk, I need to watch it again! 
thanks a lot! 
But Rust is just terrible with building. My little game engine here takes about 6 minutes to compile at the first time, it's smaller than my older C++ one that was pretty much instantaneously built.
Event sourcing might be the term you are looking for.
Yes you can and should use sqlite. 
git2-rs? Seems like it has a the features you need.
The only reason why it looks perfectly fine to you, is because pretty much every other package manager realized how bad such an idea would be and refrained from it. Just imagine every random language package manager coming with its own install mechanism, and think about how a) messy your $PATH will start to look like if they all add their own bin dir to it (and the confusion that goes along with it), or b) much this will collide if they all start dumping their binaries into .local/bin (Rust is probably also going this route, hopefully getting rid of `.cargo` altogether). It's not a good idea. You want installs solely done by your system's package manager. Sure, that they all failed until now to support user-local installs is a big problem, but the solution is not to invent a separate install mechanism for every language ever invented.
I don’t know what I was expecting, but I wasn’t definitely not expecting this
/r/rustjerk
I have a problem with my loop in my temperature conversion program. It works as it is, as long as i enter c (for celsius) or f (for Fahrenheit) on the first loop iteration. if i enter one of the correct two entries at any iteration (other than the first), it doesn't seem to accept the correct value. Q) do i need to clear the stdin value each iteration? A) would i be better using match rather than an if statement? r/https://play.rust-lang.org/?gist=d04db2ed5469be4cc08117ee3f4efa59&amp;version=stable&amp;mode=debug&amp;edition=2015 thanks in advance! :)
These are interesting topics for users and programming language designers to discuss. My comment was observing that even with a safe source language, there are sometimes reasons to have unsafe features in a compiler IR.
This is the epitome of human engineering. We might as well quit now.
I found this excellent talk to be complementary to mine ([video](https://www.youtube.com/watch?v=4YTfxresvS8), [slides](https://docs.google.com/presentation/d/1aDTRl5R-icAF38Di-qJ4FzAl3pLlutTKVFcr3mUGgYo/edit?usp=sharing), not to plug my own work too much. I found a lot of common ground: * Trying to write object-oriented code in Rust doesn't work well. Writing data-oriented code does. * "Fighting the borrow checker" is a sign you might be doing it wrong. Try data-oriented approaches instead. * Use a structure-of-arrays rather than an array-of-structures. * Use what I call "state splitting" to borrow mutable references to just the state you need; this works well with the structure-of-arrays approach and is a powerful motivator to use it. * To build graph-like structures, reach for a Vec of components, and indexes into the Vec for relationships, as your first choice. Self-references, arena allocators, and Rc are viable alternatives, but you should have a good reason to use them instead of Vec. * Some form of dynamic typing is useful to keep your system loosely coupled (though we ended up with very different forms of dynamic typing, see below). * Data-oriented approaches have taken root in the C++ gaming community, mostly motivated by performance, but adapt well to Rust, and some of the ideas may be useful in domains beyond gaming. There were some other points that went beyond what I talked about, but could fit in well: * A "generational index" is a good way to avoid use-after-free style errors that result from the use of a stale index. The [slotmap](https://crates.io/crates/slotmap) crate can help. And now for the things that are different. * The exact nature of dynamic typing is different. An ECS usually uses a registry of the different component types ([anymap](https://crates.io/crates/anymap) is a useful crate) and is quite open-ended in adding new types of components. My xi-win-ui, by contrast, has two main component types, Widget and listener, and does dynamic dispatch on a Widget trait. This naturally raises the question, which is better? From my perspective, both are valid. The pure ECS approach definitely makes sense when the components are interacting with each other in diverse ways (collisions, damage, etc). In a GUI, the components are mostly interacting with the framework, and have diverse behaviors within standardized interfaces (input, layout, paint). Thus, one point of my talk is that you don't have to reject all vestiges of object oriented programming, it's perfectly reasonable to hybridize, using data-oriented approaches for state splitting and graph structure, and dynamic dispatch for the behavior variation. My talk also went deeper into the ideas of "data flow rather than control flow" and the use of an event or command data structure rather than method calls. I'm not sure how deeply these ideas apply to games, but wouldn't be surprised if they do. I'm delighted to see so much activity in this space, and get the feeling that we as a community are finding our voice in how to express game-like programs powerfully in Rust, as opposed to early impressions of frustration. I might expand these comments into a blog post, but wanted to add them to the discussion while they're fresh.
I did not know this term previously and it is indeed helpful. Thanks!
...you can click and drag them around. I am in awe. Or something, at least.
Well. Is there a CVE yet?
You can use sqlite. Have a table settings with columns you need for settings and auto increment primary key. On every change of settings just write new row.
I thought that’s done by design?
I was looking into time series databases, like influx or TimescaleDB for PostgreSQL, to store some financial data for a project, and maybe run a network service on some server to update it periodically. I'll look into this, nice work !
Some time ago I had a similar task and wrote the little helper crate `jfs` ([docs](https://docs.rs/jfs/0.5.0/jfs/), [repo](https://github.com/flosse/rust-json-file-store)) maybe that solves your problem?
I am still learning rust, how do I make it work with my project ?
You keep reading more data into the same string and never clear it, so it makes sense that it would only be equal to "c" or "f" on the first iteration. 
It's a rewrite of a python toolset used in CTF hacking competitions, developed by a group at the Copenhagen University. The documentation file uses an exploit known as cross site scripting to showcase that the developers are hackers.
It would be useful to have explicit means of telling a compiler "X can't possibly be false", "X must always be true", and "a program need not *usefully* handle cases where X isn't true", with the semantics that: 1. A compiler given the first may omit any code which would only be meaningful if X were false. 2. A compiler given the second must generate code to ensure that execution does not pass the indicated point when X is false, but may if convenient generate code that forcibly terminates the program *before* execution reaches that directive [e.g. if the directive appears in a loop, and a compiler can determine whether it would trigger before the loop starts, a compiler could do the check before the loop rather than on each iteration]. 3. A compiler given the third would be given the option to do either of the above, at its leisure. For example, if the syntax for the third were `CHECKED_ASSUME(x &lt; 100)` and knowing that `x` is less than 100 would allow a compiler to eliminate 10 checks later in the code, replacing those ten checks with a single test could make things more efficient. In cases where knowing the value of `x` wouldn't help downstream code generation, however, a compiler would not be required to add the check. I see the second and third constructs as more useful than the first, however, and I don't see much to be gained, however, by repurposing constructs for which many implementations had--with the Standard's blessing--defined other useful behaviors, so that they instead mean "a compiler should assume no condition which would rely upon implementations' useful extensions of the Standard will occur". 
Interestingly, llvm exports this as the [llvm.assume](https://llvm.org/docs/LangRef.html#llvm-assume-intrinsic) intrinsic, but as far as I know it's not widely exposed in higher-level languages. I think it actually is worth exposing, for the reasons you describe, and also because it documents the proof obligations for validating the code more rigorously. It definitely ups the difficulty level for programmers, though.
base\_temp\_type.clear(); worked a treat :) thank you!
Awesome! I'm working on a very similar thing; also in rust, but unfortunately commercial software. You mentioned compression; I'd recommend working out how you are going to do that as a priority. I didn't plan on compression from the outset and ended up changing many of my plans when I incorporated it. I found this [blog post](https://fabxc.org/tsdb/) and [this crate](https://github.com/jeromefroe/tsz-rs) helpful (I'm not associated with the author).
Thanks I hate it
One problem with many designs for many things is that they often omit information about various aspects of the design without indicating whether: 1. Those aspects would be complicated to describe, and most users would get by without needing a full description, but those who want to exploit those design aspects could expect that they will remain consistent in future. 2. Those aspects may be subject to change on some particular time scale; whether a user would benefit from exploiting those aspects may depend upon how the lifespan of the project. If a design needs to perform some one-off task and would be useless once the task is complete, the fact that parts meeting the design requirements would be hard to get five years from know shouldn't be a problem. 3. The design aspects aren't likely to change, but aren't published because they encapsulate trade-secret knowledge. Without knowing which category various omissions fall into, it's hard to know what can be safely inferred and what can't.
No, just checked, this is the same version as it's always been.
| It is true, but without noting the motive, it seems to pitch compiler authors as adversaries whose goal is to trip the poor developer and laugh at its expense while taking refuge by the standard to justify their wiles. An implementation's suitability for a particular task may be measured by the cost, in human and machine resources, of performing that task with this implementation (lower is better). In many cases, C implementations intended to be suitable for low-level programming will define behaviors beyond those required by the Standard, in a fashion that will allow various low-level programming tasks to be accomplished more easily than the Standard would require. Implementations that aren't particularly suited for such purposes may make it more difficult or even impossible to perform such tasks. In many cases where programmers complain about gcc, it's because the authors take the attitude that programmers shouldn't expect it to be suitable for most of the purposes that C was designed for, and should regard any such suitability as accidental. 
I was expecting a new release of docs.rs. I was wrong.
it is sad that rust developers are forced by compiler to manage the whole app's memory in indexed arrays to make something work at all. i don't understand how it's good or even "safe" practice.
&gt; You mentioned compression; I'd recommend working out how you are going to do that as a priority. I didn't plan on compression from the outset and ended up changing many of my plans when I incorporated it. I have a very good idea how it will work, but thanks for the advice!
[Changed to use nanoseconds!](https://github.com/njaard/sonnerie/commit/0979008b338cbe61b0d5ffa81fcd447c93dc331c)
For some added context I went to a talk on project Mentat a month ago at the Mozilla head quarters in London. The talk was by a senior engineer at Mozilla. The talk gave the strong impression that it's a done deal that Mentat will become the defacto new storage engine in Firefox. There is still lots of work for portability as it'll be used in iOS, Android, and desktop Firefox. It was very cool, and I'd be pretty shocked if it's suddenly gone.
Well, you can try it out yourself and see. I know once it took 3m22s to build for testing and right after that 1m00s, both debug. And then I created a new project using it as a dependency and it used so much CPU that Firefox stopped working properly (tabs would respond to hovers but not clicks, Ctrl+PgDown/PgUp would change the tab but stay on the same page, just a really weird glitch). Outside of that I don't know the build times for certain, because I just had to restart my computer.
Okay--now I understand what you're saying. Sometimes a source language may need to generate IR in such a way that the source compiler knows that certain conditions will always apply, but the IR compiler wouldn't be able to prove them based only on the IR instructions. While it might sometimes be useful to have an IR express concepts which could jump the rails if used erroneously, that would only seem appropriate for languages which make no effort toward "sandboxing". While having a means of asking the IR processor to trust assumptions it can't statically verify (instead of generating run-time checks) may improve performance, it would also greatly increase the likelihood of a compiler bug turning into an exploitable security weakness.
The rest of the Tower stack stays and warp will be updated to be built on tower. 
In other words, rustdoc is vulnerable to xss?
Right, it gives you `&amp;mut T` referencing the original storage of the slice (on your array). It's not really possible to provide a direct value as mutable or not -- that's up to the consumer whether it's bound like `mut elem`. But without a reference, it couldn't affect the original array.
Perhaps you should describe more what you're trying to accomplish. The simplest way to add a new pokemon type to that file would be to open the pokemons.json file in a text editor and write another entry to it (being sure to preserve the JSON formatting you see with the current entries.)
I'm having a bit of trouble understanding when rust decides a reference is no longer being used. Here's the code I'm playing with ([playground](https://play.rust-lang.org/?gist=001f171f770119c6b6df5a27ac640ad0&amp;version=stable&amp;mode=debug&amp;edition=2015)): use std::collections::HashMap; fn get_or_create_a(hash_map: &amp;mut HashMap&lt;usize, usize&gt;, key: usize) -&gt; usize { if let Some(result) = hash_map.get(&amp;key) { return *result } let new_val: usize = 0; hash_map.insert(key, new_val); new_val } fn get_or_create_b(hash_map: &amp;mut HashMap&lt;usize, usize&gt;, key: usize) -&gt; usize { if let Some(result) = hash_map.get(&amp;key) { *result } else { let new_val: usize = 0; hash_map.insert(key, new_val); new_val } } fn main() { let mut hash_map: HashMap&lt;usize, usize&gt; = HashMap::new(); println!("{}", get_or_create_a(&amp;mut hash_map, 0)); println!("{}", get_or_create_b(&amp;mut hash_map, 0)); } `get_or_create_a` compiles and works no problem, but if I move the code after the `if` into an `else` branch it has an issue with ownership. Why doesn't ownership end before going into the else branch?
&gt; A restart was required after installing the msi to get the bin directory it had added to the path working. Restarting cmd or whatever app you are using for executing command should be enough.
From your code, it looks like your question is: how do I persist a Pokemon (dynamically created during the execution of the program) to that JSON file? 1. I would add **serde\_derive = "1.0"** to your `Cargo.toml` file under the `[dependencies]` section. 2. In addition to deriving `Clone` for your `Pokemon` struct, I would derive `Serialize` and `Deserialize`. (This gives you JSON serialization/deserialization for free, instead of you manually having to do it.) 3. Next, I would create a `PokemonDefinitions` (or anything you want to call it) struct where you store all of the Pokemon definitions. (This could be a simple `Vec&lt;Pokemon&gt;`.) I would \*also\* derive `Serialize`/`Deserialize` for this struct. `PokemonDefinitions` (modulo your choice of name) is what you're going to store and read in `pokemons.json`. 4. You're going to have to modify your `pokemons.json` file to match the structure of `PokemonDefinitions`. (But this is good! You can get rid of that "total\_pokemons" field!) 5. Now in `main.rs`, instead of calling `let json: Value = serde_json::from_str(&amp;contents).unwrap()`, you can simply say `let pokemon_definitions: PokemonDefinitions = serde_json::from_str(&amp;contents).unwrap()`. 6. At this point, you have deserialization logic for free. Now to your question of storing the file contents. ... 7. Well, you were able to open a file, read it, and call serde\_json functions on that file text. You just need to do the opposite: take your `PokemonDefinitions` struct, add new `Pokemon`'s to it, call `let serialized_definitions = erde_json::to_string(&amp;pokemon_definitions).unwrap()`, and write the String `serialized_definitions` to a file.
Not rustdoc, but docs.rs. Basically, whatever crate's documentation you look at can run its own JS. Since it's not the JS that docs.rs explicitly gives, it can be seen as a form of XSS. Given that there's no user session state or actions, it's not really a problem, AFAICT.
Thanks for the explanation. I do have a question about parallelising some other for loops. I understand these methods a great deal more now (thanks so much for your help :)) and I converted one loop already. Now I have two more loops, but they have 3 and 4 arrays, respectively. This is what I need to do: ``` firstArray .par_iter() .zip(secondArray.par_iter()) .zip(thirdArray.par_iter()) .map(|(first, second, third)|{ first * second * third }).sum() ``` But `.zip()` only allows two iterators. I'm aware of the `itertools` crate, but I know the macro doesn't do `IntoParallelIterator`. Is there some nesting of `.unzip()` that I can do in `.map()`? Or do you have some wonderfully insightful solution?
http://panzi.github.io/Browser-Ponies/
It's like how restricting yourself to regular expressions removes an entire class of issues which come with turing completeness. I'm not saying it's worth it in this case, or that the current trade offs demonstrated are the best, it's just important to recognize that sometimes doing with less ends up with \*more\* because of the added constraints.
You could ask and self-answer a question on StackOverflow. That's what I do in situations like this.
the easiest solution I can think of would be serializing bincode structs over tcp.
Well, it lets the compiler do anything it likes assuming the condition is false. "Omit code" is probably not something that has any particular meaning with respect to what llvm actually does. It's _certainly_ not something you would ever want to touch with a 10 foot pole if there was a possibility it actually would be false because of malicious input.
Attention-stealing as well, I'd argue. I think he's clearly violated the CoC, so some sort of action against him would be warranted.
Awesome, thanks!
We don't have a multizip like itertools, but subsequent zips should be fine. You'll just `map(|((first, second), third)| ...)` Another option for all those manual `zip(array.par_iter())` calls is `zip(&amp;*array)`. This dereferences the array into a slice, takes that reference, then lets zip use `IntoParallelIterator` on that.
Could you, roughly, describe what the external API looks like (ideally in C syntax)? Also describe what you want to have the Rust "bindings" look like (using Rust syntax). You want to make a layer from the external C functions to a Rusty API, correct?
I've done this a lot before, abstracting over stdin/file. My pattern is to usually store the variable as a `Box&lt;Read&gt;`. It's inefficient, but it abstracts over anything readable. For abstracting over file/stdin (using clap): ``` let input: Box&lt;Read&gt; = if let Some(filename) = matches.value_of("FILE") { Box::new(File::open(filename)?) } else { Box::new(io::stdin()) // io::stdin().lock() if you are using it immediately after } ```
Use a type alias to effectively "rename" the type, if you would like to expose it differently to users, or if it should only be for a certain type, like `type MaybeDefined = Option&lt;Definition&gt;`.
Try using the [byteorder](https://docs.rs/byteorder) crate. It can encode/decode integers in little &amp; big endian, so that could work for you. It will encode into a `Write`, as far as I've used it.
While technically XSS, does it really count, since you control what content your rustdoc/docs.rs looks at? It's like saying `&lt;script&gt;` tags are vulnerable to XSS since they'll run any JS.
Hi, I'm starting to study rust for game development so this is a great talk , ECS is great for game development but i want to make a observation about OOP, specifically about the Single Responsibility Principle, this principle as his name suggest says that a object must have one specific responsibility. The example showed in the talk with the 200 get() violates this principle and is a really bad example of OOP. Apart from that this is a great talk i'm will be waiting for the Blog Post
It's a little worrying because you can inject basically anything you like if I'm understanding it right. &amp;#x200B; Somebody malicious could for instance pop up a modal encouraging you to register to view the content or "sign in with gmail" or something and then log everything that's typed, including the password. New or unknowing users might be tricked or believe that some change to [docs.rs](https://docs.rs) has taken place. I'm sure there are a hundred other devious things one could do as well.
Thanks ... I have made the changes and now I can add new players [https://github.com/sn99/rust\_sample\_game](https://github.com/sn99/rust_sample_game)
In a way I think that learning Haskell is very helpful, because it forces you even more to change your mindset compared to Rust, because there are less loopholes like `RefCell`. At the end the architecture of good Sorftware in Haskell will be quite similar to the one in Rust. Because the purity/immutability in Haskell guides you in the same direction as the borrow checker in Rust.
Perhaps one of the biggest problems of Rust is that from the outside it looks more similar to languages like C++, C# or Java than to a language like Haskell. All the solutions you're listing are pretty much the same in Haskell.
Not the author. I just read the title, had to chuckle, and thought it's worth sharing.
whoops this is akward sorry
&gt; u64 nanosecond timestamps are good until 2554, which is plenty of future-proofing for me. If you are thinking Unix timestamps, those are by convention signed integers, so it'll "only" last until 2262 in nanoseconds.
I think https://nest.pijul.com/pijul_org/sanakirja offers such features, but it's a KV store.
Oh snap, it compiles down to WASM ? *Rustifying intensifies*
Thanks for the answer! I'll keep an eye out to update my projects when the merge happens ;)
https://docs.rs/slotmap/0.2.0/slotmap/
&gt; I'm quite sure it has to do with dependencies. The engine itself is just around 1300 lines. But it uses like 91 crates (most are included indirectly) last time I checked. Ah! Yes, that would explain it. The first time you build a project, `cargo` will build all your dependencies. In the traditional C++ model, a dependency is either downloaded in binary form or built once upon installation, and never again: - advantage: faster to build! - disadvantage: debugging is a pain (it's built in Release...), the ABI may not match, the standard version may not match, it generally targets the lower bar (goodbye SSE 4.1/AVX), ... Over the last few years, my company has increasingly been migrating to the same model as Rust for our C++ dependencies. Instead of pre-compiling them, the sources are distributed and compiled with the set of flags which suits the client. The one-off increase in build time for each version bump is largely overshadowed by the ease of debugging, performance gain, and general hassle-free experience.
Awesome! 
Don't know what you are talking about. I almost exclusively use Debian-package Python libraries.
I would be very thankful if you would post a link on r/rust when you come around to releasing it.
Hyper v0.10 was pre-async api and is more like what you expected to find. 
Nope, I have [a Rusty API](https://github.com/zottce/samp-sdk) for this external functions. This code shows how should looks this extensions. I want to make an event-based arch using closures for Items, Timers and etc. An extension should store this items which may have optional callbacks. I really don't know how to create something working like [this](https://gist.github.com/ZOTTCE/9fff575a0f9b9c93d2e4bb680fbc3a5f). Seems like I should use `Rc` / `Weak` and `RefCell` / `Cell`. But there are any chances to avoid it?
Alas it can be pretty hard to find time for this stuff as a maintainer. I also was messing around with CQRS+ES as well, but am now working on other things: - https://github.com/brendanzab/chronicle - https://gist.github.com/brendanzab/a6073e73f751a6ca9750f960a92f2afe Hoping that others can figure this stuff out as well, particularly with respect to integrating CRDTs and a [nice story for data migration/versioning](http://files.movereem.nl/2017saner-eventsourcing.pdf) as well.
Part of the problem with SRP as a maxim is that it doesn’t define how large “single” is. You can totally make the argument that that class has a single responsibility: to model a player. You can also make the argument that you did. They both fit, and it’s why I’m personally not an advocate of SRP as a concept.
Author of `domain` here. Sorry for being late, but I thought I write a response, anyway. You are absolutely correct in guessing that the `Resolver` needs a reactor core handle to spawn tasks for network things onto. However, the future that you get from `Resolver::query` (and consequently all the lookup functions) is able to run everywhere. To achieve that, it internally dispatches networking jobs into queues pretty much exactly as you do for your solution. So you didn't actually need to dispatch your lookups to your background thread, you really only needed to `run` the core there. The `Resolver` type is designed to clone cheaply and passed around to wherever you need it after being created once. (That is, it essentially is a handle itself). I think everything actually would have worked out as expected right away, had I moved `domain` to the new Tokio world order already. Sadly, it still lives in `tokio-core` world. Otherwise, it would have just used the reactor you likely created for the hyper parts of your application and everything would have been fine. The reason I haven't done this yet is that I was waiting for the new async/await. A few weeks ago, I implemented the resolver using it and it is so much nicer. But: nightly. So I might bite the bullet and go back to enums-and-stuff and release a new version soon, anyway. 
Sweet. I’ve never used discord. But I will try it out later at home and join your channel/community!
Your work is amazing, thankyou!
Relevant: it's not for the game but seems to actually be about the programming language ;)
&gt;join Thanks:)
Ahhhh this is so cool!
You can also change the type length limit with the `#![type_length_limit="N"]` attribute.
This is fantastic! Eventually, I'd like to get nebulet up to this point. It's slow going :/
that‘s what this subreddit is about...
You probably want /r/playrust
https://github.com/actix/examples/tree/master/r2d2
Masterful?
Currently only the first 64 chars of the type is displayed when a type is too large to be displayed. AFAICT this is hard coded into the compiler, and you can't make the compiler display more without forking it.
Well, if you want to be condescending there's no further need for discussion.
Yes. But that still doesn't stop some people