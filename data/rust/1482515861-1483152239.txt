Looks really nice - going to give it a try!
https://github.com/killercup/trpl-ebook is periodically generated, which can give you the current book. The new book will be published through No Starch, which will have whatever formats your heart desires, I hope, anyway. Eventually we'd like to produce our own official ones, but that isn't very high priority and needs some infrastructure work, but there's much more important infrastructure work to be done at the moment.
Can't wait for asnyc. Great website and docs, keep up the good work!
Heh, my work has been with an ancient rails 3 app we're getting back online, and we ~~wanted~~ needed to severely reduce running costs. Part of that involved rewriting Faye (a push server written in node) in Rust, and now I'm recreating specific endpoints in Rust because our unicorn workers' CPU usage is becoming the bottleneck. Overall though, rewriting the push server and some smart optimizations with database usage brought us from needing $400/mo in hardware to under $40/mo.
One impressive site. Great job!
It's amazing how elegant Rust is while being so low level at the same time. This is super impressive.
This does not yet use asynchronous IO.
Just use hyper with tokio, when it gets reasonable. Edit: And I am really impressed! 😀
Looks a lot like diesel.rs. . .which is the highest of compliments.
I wrote the shell parsing syntax throughout Ion, so if you need help writing a parser for this, let me know.
I think what I'll do is just abstract commands like &amp;&amp; to their own function to take away the need to parse that. The less parsing the better. If I do run into the need to parse then I know who to get in touch with. What library did ion use to parse?
Great, the easiest way to improve my code is to post it to Reddit. :-) The error type is `()` because the user won't care what went wrong. Either he can parse the dates provided by the other side of the HTTP connection, or he can't and will ignore them. (Do you have any ideas what useful information I could provide?) I understand your point about making things more flexible but on the other hand crates provide abstractions and always hide away some information from the user. I don't think I will ever extend this crate to provide more functionality. About the second point: There are [some tests](https://github.com/pyfisch/httpdate/blob/master/src/lib.rs#L35-L83), but I admit they are neither very many nor do they check many cases. I will try out quickcheck maybe it turns up something interesting. :-)
The first thing that jumps out is why is it using `&lt;foo&gt;` instead of `:foo. (But I'm bikeshedding.)
Ah! Sorry, I was at work when I looked and was distracted, so I didn't see those tests. That's good. :-) With respect to error information... I would at least expect an error type to give a nice error message that can be easily propagated by callers. Getting a `()` is just really hard to work with. If I want to wrap an `httpdate` parse call in `try!`/`?`, what does my `From` impl look like? I can't really do `From&lt;()&gt; for MyErrorType` because who knows what `()` actually stands for. Instead, I've got to use `map_err`, which I guess isn't the end of the world, but it'd be nicer to not have to use it. If failing to parse an HTTP datetime is as uninteresting as you say, I still think it'd be useful to be able to log a message in applications when parsing fails to help with debugging. If you provide an error type with a nice message (e.g., "Invalid month", "Invalid year", "missing timezone" ...), then that makes things much nicer for consumers of your crate. I dare say that `()` as the error type is *not* idiomatic, and is probably always worse than an opaque error type. Maybe you can get away with it for internal error handling, but I don't think it should be part of any public API.
Same. I may be weird, but I think JAX-RS does a really good job of defining web requests. This definitely makes me feel right at home.
Oh very nice. I'll get the new features it and if it's still not fast enough for you for parallel want to help with some optimization for parsing or other things if needed?
I agree, even if it was just `struct Error` with display/debug implemented, that would be nice. It also may be a good idea to add some metadata to your `Cargo.toml`, specifically the `repository` and `documentation` fields. Looking at the crates.io page tells me nothing right now.
Glanced over examples looks cute. It doesn't have middlewares? Also no templating? Is this going to be microframework or is it full-stack in early days?
May I request a comparison of all the web frameworks in Rust? Rocket, Ruille, Iron, etc. It's exciting to see the richness and prosperity of this domain in Rust, but becomes a little hard to navigate for an outsider.
By scheduled release date I meant the date on which the current version of the channel becomes stable. For example, the current version of the nightly channel is `1.16`. It will be released on `17 Mar 2017`.
You could have the shell execute these strings directly, with a `Command` like `Command::new("sh").arg("-c").arg(shell_str)`. Here's an example: https://github.com/oconnor663/os_pipe.rs#example If you do that you'll also get magic tokens like `&gt;` and `&lt;&lt;` working for free. For what it's worth you can also do this on Windows! It's just `cmd.exe /C` instead of `sh -c`. A lot of things like `|` and `&gt;` actually work between both shells, though you run into incompatibilities when you try to do really fancy stuff.
Thanks! I have subscribed.
There is templating support (https://rocket.rs/guide/responses/#templates). It's linked as one of the main features on the homepage. You can use request guards (https://rocket.rs/guide/requests/#request-guards) in places where you'd use middleware elsewhere. Further, many of the constructs you'd normally use middleware for are baked into Rocket. Check out the requests guide (https://rocket.rs/guide/requests/) for more detail. That being said, I do plan to add a very restricted form of "middleware": pre-processing and post-processing. Rocket currently uses this internally for a few features, but it'll likely be exposed in the future.
Middleware are components you can write to process requests around each route endpoint. For example you could use them to implement timeouts or cookie parsing (rocket just does the latter for you).
Things to tweak but that's definitely good to know!
&gt; with From impls back to io::Error for ergonomics Which kind of io:Error would my error map to? I guess other and my error description as a message, but my crate is not really related to IO. :/
The problem is the child process sometimes goes silent for awhile which means I can drain the buffer before its done unfortunately. I'll have to check if I only get an EOF at process termination, or if I just run out of stuff on the pipe.
Wow
When you read from a pipe (or socket), and the writer isn't currently writing anything, `read()` will wait for the writer to write something rather than just returning EOF immediately.
A beautiful language. A beautiful Web Framework. I'm so happy right now. =)
What would you want an Apache mod to do? hyper serves HTTP; applications written using it can either be directly browser-facing or behind Apache via `mod_proxy`. IMHO, the `mod_proxy` approach is superior to either running stuff in the Apache process(es) (`mod_perl`, `mod_php`) or using a different protocol for the back leg (`mod_fastcgi`).
yes, sir, thank you!
Note that the `Range&lt;&gt;` type only denotes ranges of the form `x .. y`. `x .. ` is `RangeFrom&lt;&gt;`, `.. y` is `RangeTo&lt;&gt;`, and `..` is `FullRange`. Also note that none of these types are `Copy`, so you can't use it by-value in the slice expression; you have to `.clone()` instead. It's possible to be generic over these, but the solution is not very intuitive. There's the unstable `RangeArgument` trait but if you look at the docs you'll notice that neither slicing a `&amp;str`, nor a `&amp;[T]`, is generic over this trait; instead, they both implement `Index[Mut]&lt;&gt;` for each of the range types individually. It is still possible to be generic over this, it's just not immediately obvious: struct MyStruct&lt;R&gt; { long_string: String, slice: R, } impl&lt;R&gt; MyStruct&lt;R&gt; where str: Index&lt;R, Output = str&gt; { pub fn short_str(&amp;self) -&gt; &amp;str { &amp;self.long_str[self.slice.clone()] } } However, I probably wouldn't use generics like this, but instead use `RangeArgument` and convert the given range to a `Range&lt;usize&gt;` invariably, which makes usage much more convenient: // The struct definition is the same as yours impl MyStruct { pub fn new&lt;R: RangeArgument&lt;usize&gt;&gt;(string: String, range: R) -&gt; Self { let range = range_arg_to_range(range, string.len()); MyStruct { long_string: string, slice: range, } } // This lets you set a new range without changing the final type of the struct pub fn new_range&lt;R: RangeArgument&lt;usize&gt;&gt;(&amp;mut self, new_range: R) { self.slice = range_arg_to_range(new_range, self.long_string.len()); } } fn range_arg_to_range&lt;R: RangeArgument&lt;usize&gt;&gt;(range: R, end: usize) -&gt; Range&lt;usize&gt; { range.start().unwrap_or(0) .. range.end().unwrap_or(end) } Unfortunately, this requires nightly as `RangeArgument` is unstable, even though it's only blocked from stabilization by some trivial changes that, apparently, no one's simply gotten around to making yet: https://github.com/rust-lang/rust/issues/30877
Coming from python webdev, this feels a lot like [Flask](http://flask.pocoo.org/) so far. It's flask with type inference. 
I just have a thing for sites which have simple well highlighted code examples. That and neutral colours!
[This SO answer](http://stackoverflow.com/questions/29789877/can-not-implement-trait-from-another-crate-for-generic-type-from-another-crate-p) describes possible solutions to the problem of not being able to implement traits from other crates. So could you define your own types like this: struct MyInt(i32); struct MyString(String); and then implement the interpreter traits on those? 
back to rust i go!
I started learning Rust some time ago and decided to write a small application to test my knowledge. My skills at Rust are extremely rudimentary. This is a POP3 client that I have tried to write from scratch. I am looking for a review of the codebase. Specifically, about whether I could architect it better and about how it should be written in Rust. Currently, the code has simply been massaged to make sure it compiles and runs, but I'd like to know how to write better Rust. EDIT: One thing I am specifically looking for advice on the code to read from the network socket. Currently, I read from the socket 1 byte at a time. This turns out to be an extremely slow and expensive process since it requires literally hundreds of `read` system calls. Is there any better method?
Yeah, I'm wondering about this too. I think it partially addresses the problem by allowing to explicitly mount the routes but how would one go about mounting multiple "subroutes" under the same namespace? For example, let's say I have an oauth module that defines the handler of two endpoints (authorize, token), how would I mount both endpoints under /oauth. Ideally, I should be able to do `rocket::ignite().mount("/oauth", oauth)` or something like that.
Looks like Flask, neat! Looking forward to seeing the flurry of web framework coming soon (including mine!).
Really impressive. I am very keen to give this a shot. Nice job! Good luck with future development!
I think they were asking about rustc itself running in the browser. While interesting, thinking about how long compilation times are on the metal... &gt;.&lt;
This is a great question/feedback! Thanks for trying out Rocket! At the moment, request guards can't return arbitrary responses, including redirects; they can only return a status code that leads to a catcher being run. The idea is that arbitrary control flow is contained to the request handler. So, at present, you can accomplish what you're attempting by asking for an Option&lt;AuthenticatedUser&gt; instead of an AuthenticatedUser, and then doing something like: #[get("/auth")] fn route(user: Option&lt;AuthenticatedUser&gt;) -&gt; Result&lt;T, Redirect&gt; { let user = user.ok_or(Redirect::to("some_page"))?; } If you need the FromRequest implementation to return a URL, you can ask for a Result&lt;AuthenticatedUser, &amp;str&gt; (or maybe String, or even Redirect!) instead. The benefit to these approaches is that the function declaration directly declares the intent to redirect on some failing condition. By the way, feel free to stop by #rocket on irc.mozilla.org for queries like this!
This looks really nice, I love command line utilities like this! Took a quick look and maybe you can make config settable via either environment vars or a dotfile (like .logrsrc or something) since you hard coded your own machine path there.
Are you talking about the infrastructure stuff brson mentioned on internals? How hard do you think it would be to create an automated process for the book you've been updating to generate the necessary formats like PDF or ebook?
I'm guessing it's for two reasons, ":" is allowed in urls and `flask` uses the same syntax which this is pretty heavily influenced by. 
So many super cool projects built with Rust that are highly applicable to those outside the Rust community. I'll plug [habitat](https://www.habitat.sh), by the Chef team. I got to meet some of the guys behind this project at Rust Belt Rust and they're all great! Not only do they do amazing work, but they truly care about the Rust community and ecosystem. I love seeing Rust at this stage of creeping into the greater IT community!
https://api.rocket.rs/rocket/response/trait.Responder.html#provided-implementations Whether a returned string is owned or not (`&amp;str`/`String`) affecting `Content-Type` is very surprising behavior. They both should be treated as `text/plain` by default and should require to explicitly be wrapped with `HTML`.
The routing annotations are cool and argonomic only when you have one file of code and all of your hnadlers are in one place...
This happens quite often throughout time. There's always more than one person attempting to achieve the exact same goal at the same time. It just means that humanity is ready for Rust to attain some good libraries for this very task. Yours seems a lot further along in construction, but I also don't see methods for achieving `and` and `or` conditionals.
The `then` method is duct's version of "and". I needed to use a different word there because "and" is a keyword in Python, which the [other `duct` implementation](https://github.com/oconnor663/duct.py) is written in. The documentation for that implementation is also much more useful right now, and their APIs are exactly the same by design. I'm not sure if I'm going to add an "or" method, at least not until someone needs one. The main reason you need `then`, rather than just executing two commands in a row as the caller, is that you might want a pipeline like `(a &amp;&amp; b) | c`, where the `c` command only runs once but gets the output of both `a` and `b`. On the other hand, I've only ever seen `||` in Bash used for error handling, and there I do think it makes more sense to have the caller handle it. (I guess I've also seen it used in `if` conditions, but again I think it makes more sense to leave that stuff to the caller.) (Another thing I'm considering adding is some sort of "background" method for when you want `(a &amp; b) | c`, but that's obscure enough that I'm going to wait until someone needs it.)
A good basic rule-of-thumb for programming is DRY: "Don't Repeat Yourself". Look for repetition in your code, and pull it out into a function. For instance, I'd create two functions that each would be used multiple times: fn prompt(p: &amp;str) -&gt; String { ... } and fn prompt_usize(p: &amp;str) -&gt; Option&lt;usize&gt; { ... } (Note that those functions wouldn't directly replicate your existing code, as they wouldn't be able to describe which "read_line()" failed. But I'd consider the simpler code to be worth the loss.) BTW in general code that panics (e.g. expect()) is not a great idea for user-provided input. For good practice, you might want to refactor your functions to return Result&lt;&gt; values instead. You may want to look for examples of the (new) '?' syntax. The logic of range_min/range_max is a little off; in particular in test_rng(), you allocate a Vec of size range_max. But if the range is (1001, 1010), you'll allocate 1,010 elements instead of 10. Consider passing the range_min and the range_size around instead; you may find that the logic is a little cleaner. Your get_largest_num() function is okay, but if you want it to be cleaner (or just want to try a different style), you might figure out how re-implement is as a one-liner using iter::max_by(). (Hint: you'll be using iter(), enumerate(), max_by(), cmp(), and unwrap_or().) That should give you some things to go on.
As far as I can see Rocket implements `hyper::Handler`, and hyper has a branch which is based on `tokio-proto`, so sooner or later it may be possible to use upcoming tokio-based middleware in combination with rocket. That could be nice. * https://github.com/SergioBenitez/Rocket/blob/master/lib/src/rocket.rs#L35 * https://github.com/hyperium/hyper/tree/tokio
is it async?
My perspective is that, if I see a name like `ensure_app_dir` which describes only a side-effect, I want to look extra closely at what it returns... so that may be where our perspectives differ. I will concede that `get_app_dir` is less clear than `get_app_dir_path`, but I have been too busy to sit down and throw some brainpower at coming up with something that meets both your requirement (more clarity). That said, I'd at least suggest `make_app_dir_path` instead of `construct_app_dir_path` since they're synonyms with connotations similar enough to not justify such an awkward-to-type mess as `construct_app_dir_path`. (I'm neither [German](http://en.bab.la/dictionary/german-english/strassenbahnhaltestelle) nor a user of an autocompleting IDE.) (German is infamous for creating new words by gluing existing ones together. The example I gave (Straßenbahnhaltestelle) literally translates to "street road stopping place")
Has it been tested to see if ditching jemalloc makes it faster? Most of my software seems to see a good performance boost from ditching jemalloc, and literally all of my Advent of Code solutions are faster with jemalloc disabled. Usually twice as fast without it.
So, are we web now?
thanks
Well... :D
That's not my experience honestly; we have quite a few end points, and with some good name spacing it works just fine across many files.
Very promising. It reminds me of NancyFx.
Great job on the website, looks fantastic!
If you have lots of static content you'd be better off running `nginx` or `h2o` and reverse-proxying for the dynamic content. That way you can reduce the load on your dynamic server and take better advantage of caching. Unfortunately, there doesn't seem to be a fully-async http framework out there yet (the Tokio community is still small) since the thread-per-connection model is close-to-unusable for reasonable amounts of traffic if you even remotely care about performance, but if you're ok with that then the recently-announced (but in development since March) [rocket.rs](https://rocket.rs/) looks good, or if you don't mind doing some self-motivated learning then there's [iron](http://ironframework.io/), which I've used and am happy enough with, but it doesn't scratch the surface of the developer-friendliness of frameworks found in other languages. Its biggest feature, in my opinion, is that it being written in Rust means that you can use [Diesel](http://diesel.rs/).
I don't get this, is rust targeted towards web development use case ?
Why is a function that is used via the standard path system better than a custom operator that adds complexity to the language? Rust had lots of these constructs in the past, and they were all removed (for good I think). The code presented in the docs page is non obvious without the given explanation. The more you need to know in order to write fast code (without doing too much premature optimisation), the harder it gets. Code should be obvious from the first time you look at it.
I will still have the same problem, it will create N new types which have either nothing in common (so I can't use them as generic parameter), or exact same list of trait requirements (which is exactly what I want to get rid off).
First of all, thanks for the detailed answer, I still cant turn my head from OOP sometimes and answers like this really help me to do so. A bunch of interesting ideas here, I really like the second one, since it does exactly what I've been thinking of, but without some weird casting and stuff. The first idea is good too, but it seems that I've done a poor job explaining trait requirements, since it's more like this: https://is.gd/sLNheq (I've removed Lua code for clarity).
Yeah, that's probably just our differences. It is a tough function to name on general though since we don't have a good expression for the concept. Maybe the right solution is to add another layer of jargon? 😃 I do agree with you on `construct` vs. `make` though. I just read an article the other day about words like make and build being overloaded because of build environment stuff, so I decided to try and use construct instead. But yeah, it does hurt the ergonomy too much. But yeah, it can get too much too, and input and output should also be considered so we don't just repeat a bunch of information already present in the code. Though my favorite example of good German naming is their special forces, named the Division Schnelle Kräfte, or the Rapid Forces Division. Why tiptoe around what they do with words like "special" when we can just say it as it is?
Wasm performance will be far better than regular Javascript, but there will always be a gap with real native.
Thanks! I will try and work on removing the `POP3Result` enum and using the `std::result::Result&lt;() ()&gt;` interface instead. That definitely sounds like a good idea. Also, I did indeed run clippy on the code. It helped me to remove all the `return` statements and also helped fix a couple useless borrows. I guess I could turn most of the POP3 handling code into a library and use it from a different rust binary. Although, my first aim is to have the current application running properly. As part of which I am going to have to write a library for handling the `maildir` format since I couldn't find any
Just a quick glance: range_min can be larger than range_max, not sure what will happen tho. You can use range_min as an offset(generating numbers from 0..range_size and same with your loops), thereby removing it from most of your code, just add it again when you print your output. Try not to mangle input/output between your other code, seperate it so you can support other frontends besides the terminal. function `get_largest_num` could be replaced by something like `v.iter().enumerate().max_by_key(|&amp;x| x.1)`
Feel free to open an issue in the repository, and let's have a discussion about this! Edit: This change will be made for the 0.2 release!
As I understood it, the point of WASM was to be a non-proprietary successor to the Google's PNaCl (Portable Native Client). If you're not familiar with PNaCl, it's Google's idea to make NaCl portable by pushing optimized IR to the client and having the client compile it into machine code before running it. If you're not familiar with NaCl, it was Google's idea to get native performance in the browser by using a modified GCC and static verifier to safely run arbitrary machine code without virtualization. (The idea is that, by disallowing certain opcodes and enforcing certain alignment rules, they can statically confirm that any sandbox escapes will be due to plain ordinary exploits in the C/C++ code behind the APIs the sandbox host exposes... no riskier than what you already get from things like JavaScript JIT Spray exploits.) Sure, native will always be faster... but "compiled specifically for the processor extensions present in each user's processor" will always be faster than compiling one build for all users. Assuming they don't botch their WASM execution environments, it'll be the same kind of difference.
There is a benchmark that compares Rocket with Hyper in the [README](https://github.com/SergioBenitez/rocket#performance). I've also benchmarked Rocket against other frameworks with similar expressiveness including Flask, Bottle, Sinatra, and Rails; Rocket is anywhere from 100 to 1000x faster, depending on your version of the language and framework for each. For a point of comparison with other Rust frameworks, I just ran a benchmark against Iron on the same machine as that used in the README. Here are the numbers: **Iron v0.4.0** (11 LOC) results (best of 3, +/- 1000 req/s, +/- 5us latency): Running 10s test @ http://localhost:80 2 threads and 10 connections Thread Stats Avg Stdev Max +/- Stdev Latency 189.93us 40.05us 2.06ms 67.57% Req/Sec 25.80k 2.26k 34.01k 77.72% 518575 requests in 10.10s, 64.79MB read Requests/sec: 51346.00 Transfer/sec: 6.41MB In comparison, Rocket has 16.6% higher throughput (higher is better) and 15.1% lower latency (lower is better).
I'd assume so too, and the decision was originally made when Rust was much more allocator heavy.
&gt; fn hello(name: &amp;str, age: u8) -&gt; String { &gt; format!("Hello, {} year old named {}!", age, name) &gt; } How does the framework deal with XSS?
It's a beautiful site. Is anyone else getting surprisingly high CPU utilization while on the site? It takes about 15 times the resources that facebook does on 2 of my machines and that really surprises me.
That may be caused by [the clouds](https://github.com/SergioBenitez/Rocket/issues/26).
Can you write some words about `parallel`'s allocation workload? e.g., "for every unit of work done, N small/medium/large allocations are performed."
/r/playrust is what you want also, there must be like billion 'Chis's on steam, so it may be worth it to actually like the profile.
Based on your earlier suggestion, I removed the `POP3Result` and instead replaced it with a `std::result::Result&lt;POP3Data&gt;`. As a bonus, it even reduced the amount of boilerplate code I had by a decent amount! Thanks for that suggestion. 
... please ... read ... the ... description ... 
There's very little allocations being performed in `parallel` and most of my other applications that are affected. I tend to keep pretty much everything on the stack, and avoid allocating as much as possible otherwise. Most of the allocation happens before threads start spinning up. Arguments are written directly to the disk using a custom disk write buffer structure with an 8K byte array. Threads share access to an input iterator structure which contains a custom disk read buffer structure that also uses an 8K byte array, returning a String for each argument to process and only buffering the next ~8K of bytes when required. The command string which tokens are generated from is collected into a String at the beginning of the program, and that String is then coerced into an `&amp;'static str` and leaked. A stack-allocated Token vector is generated from that which contain string slices of the command string, and these tokens are shared among all threads. The `'static` lifetime keeps the compiler happy, because the String existing for the entirety of the application wasn't good enough to tell the compiler that it was safe to borrow it's contents in each thread. Command generation is also mostly allocation-free. The argument string that is built for each command is allocated at the beginning of the thread execution with a decent capacity before the loop begins. It's borrowed and cleared to avoid needing to re-allocate a new string. That said, I'm continually working to make it allocate less and less.
Thanks for writing this. I often find it difficult to wrap my head around some of these crates if I'm unfamiliar with the problem space. Often times if you haven't tried building a server before you won't know why you would use a crate like this. Having a high level overview of what you might use it for and a simple walked through example is really helpful.
I don't see any way to split into messages separated by newlines without.. Searching for new lines. Could maybe speed things up with memchr, though. If your protocol specifies newline separated strings, you don't have a choice. But if you define the protocol, you can use length prefixed strings
I guess the big picture question then is: if your program allocates so little, then why would changing between two battle hardened allocators result in such a large performance difference? Do you have any educated guesses?
Good to know thanks!
Thank you all very much.
Thanks for the series! I've already shown some of these to a couple of people interested, and I hope to continue doing that into the future.
One small nit in your codec implementation, instead of looping over bytes you should use `buf.extend_from_slice(msg.as_bytes());`
sorry my bad first time posting to the subreddit
Seems like attributes could handle this case as well. Agreed, however. At least on first glance there doesn't seem to be any fundamental blockers there (eg requiring some large re-architecting effort), which is always nice.
Yeah, even just a newtype that wraps either &amp;str / String would be better; a `HtmlString&lt;S&gt;` / `HtmlBody&lt;S&gt;` type
*Necessary* ? Probably not, no. But - desirable? Probably. Saves an awful lot of typing (but, then, golang users might not care so much about that)
Templating is available currently (supporting handlebars, tera,..), and HTTP/2 will be available soon from what I understand, via its dependency on Hyper
I can't answer that. I don't know enough to make a guess.
&gt; Stable Rust is dead. Nightly Rust is the only Rust. I **strongly** agree with the next line, and disagree with that quote! ## Say What? In absolutely no way is nightly Rust overtaking stable Rust. Especially with Rust 1.15 being right around the corner with macros 1.1 stabilized, we will have Diesel and Serde on stable Rust. Nightly Rust is **not** the winner. It is **not** overtaking stable. Rocket is the only compelling thing that I am aware of that is going to be relegated to nightly after 1.15. Almost everything else is going to be stabilizing, finally. *Nightly Rust* is about to be dead to most Rustaceans, not the other way around.
Yes. Serde and Diesel will be on stable in 1.15. The RFC for compiler plugins was accepted 10 days ago.
Would it be possible to read an arbitrary number of chars, and then yield to the event loop if none are found, then on the next turn, read another arbitrary large amount of characters? E.g. to make the search O (1)
Thanks!
Templating is nice, but an asset pipeline that handles JS and CSS would be swell as well, i.e. transpiling Babel, JSX to JS and Stylus/Sass/SCSS etc to css. 
I'll gladly accept PRs with updates :)
Even if you accept the premise that you are generally expected to be running a nightly compiler, it doesn't follow that stable rust is dead. While I do use a nightly compiler I almost entirely program in "stable rust", i.e. the subset of the language available in a stable compiler. This means I know that future compiler updates won't break my code. On the rare exceptions where I break that rule, I'm *forced* to annotate my crate with the feature I'm using, so if my code breaks during a compiler update I know exactly what to look for.
The line about plugins being stable is completely incorrect. We literally just accepted an RFC for stable syntax extensions in the past week. Furthermore, stable deriving, which is the single largest reason for using nightly in common code, will be stable in Rust 1.15, coming in six weeks. The article is also entirely incorrect about the attitude of the community wrt nightly Rust, and the.comparison to Python 3 is hyperbolic. Does the author actually remember when Rust *was* unstable, prior to 1.0?
Code: https://github.com/zcash/mpc Peter Todd's write up is just epic. https://petertodd.org/2016/cypherpunk-desert-bus-zcash-trusted-setup-ceremony
You can declare it [this way](https://is.gd/Rdgb1M). let mut hm: HashMap&lt;char, i32&gt; = HashMap::new(); but, most of the time type inference will handle it just fine.
Seem the description of a mystical magical cerimony in a pseudo fantastic futuristic world. I love it! Remaind me of a particular story by Valerio Evangelisti on the Nicolas Eymerich Inquisitor Saga
`futures` is already stable. Using `impl Trait` instead of `Box` can improve performance and ergonomics.
It has nothing to do with the `=` operator. It just has to do with where the additional type information is specified. Any time you declare a binding, like in `let` or in a function argument, you can declare its type with a colon followed by the type. In function arguments, the type is mandatory, while in `let` statements it's optional if it can be inferred. In expression positions, however, the syntax is slightly different to avoid an ambiguity. You can provide the parameters to a generic, you just have to use the turbofish operator `::&lt;&gt;`. For example: let mut hm = HashMap::&lt;char, i32&gt;::new();
Hi, it seems context is missing for this topic. Is it a question? About which code?
There's another point not often mentioned: the Rust stdlib makes use of unstable features, and there is no plan to make the stdlib compile on stable. Essentially, the stdlib being compiled on nightly is an *implementation detail*, hidden from its users. This is an unique position in the Rust ecosystem - every other library that uses nightly features will "infect" the rest of the program. There is no mechanism in Cargo to build just one or a few libraries in nightly Rust and the rest with stable, and if there were such mechanism would probably be unstable (there is no will to make such guarantees about nightly) -- despite it working through the entire 1.0 - 1.14 Rust without any compatibility issue. Just like Cargo is gaining stdlib-awareness to compile bare metal programs for platforms that can't or won't run the stdlib (like kernels), Cargo could gain nightly-awareness to contain the use of nightly to a portion of the program. But there is little compelling case for it: usually we want nightly to use crates that expose compiler plugins to our own application, not because some lib uses internally some unstable features (but I can see this happening for intrinsics, SIMD and other things).
Eh, I think Rust is expressive enough that this won't realistically end up being an issue.
 let a = vec![0u8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]; let b = &amp;a; // b: &amp;Vec&lt;u8&gt; let c: &amp;[u8] = &amp;a; // c: &amp;[u8] This is because `Vec&lt;T&gt;` implements `AsRef&lt;[T]&gt;`, so `&amp;Vec&lt;T&gt;` can be coerced into `&amp;[T]`
It was the only thing on my Christmas list.
I don't think the downvotes are because Rust people don't want to discuss the subject : Rust community is usually very open to fair critisism. The problem is there is multiple wrong assertions in the article.
I wouldn't want my web framework do that personally. You'd need to support webpack/rollup/browserify just for the build tools, babel/TS for the languages and Sass/Less/Stylus/PostCSS for CSS.
I don't think `futures` or `tokio` - the crates - will be 1.0 until `impl Trait` is stable, but they do already compile on the stable version of Rust.
I need a fixed size collection of options to non-copy structs. What collection should I use? Vector could work, but having fixed size would feel nice. I tried using plain array, but I couldn't initialize it: let mut collection: [Option&lt;MyStruct&gt;; MY_CONST_SIZE] = [None; MY_CONST_SIZE]; Because: error[E0277]: the trait bound `MyStruct: std::marker::Copy` is not satisfied ... the trait `std::marker::Copy` is not implemented for `MyStruct` 
XSS protection is a templating level concern (both supported templating libraries appear to properly handle escaping by default)
We should have a note here to help guide you! The issue is that this is being parsed like this: let mut hm = HashMap &lt; char ... That is "HashMap is less than char". Then the comma doesn't make any sense. If you do something like this: let mut v = Vec&lt;i32&gt;::new(); You get this note along with your error: help: use `::&lt;...&gt;` instead of `&lt;...&gt;` if you meant to specify type arguments Sadly it looks like we don't have that note in this case.
I'd think the first thing to quantify would be killercup's hypothesis that the fixed setup costs for jemalloc are non-trivially greater than just using the system allocator. (Which would make it sort of like the old "WARNING: O(1) algorithms tend to have a big 1" problem.)
You are looking for /r/playrust
ahhh thank you
That and Go has RTTI. It can serialize JSON without boilerplate using reflection. Rust has to use macros. Edit: s/JASON/JSON/
are there plans for Rust to introduce "do notation" that would (among others) work with Futures? Maybe something like [Computation Expressions in F#](https://docs.microsoft.com/en-us/dotnet/articles/fsharp/language-reference/computation-expressions). 
Generalized do notation has a ton of technical challenges in Rust, and so it's not clear if we're even going to get the precursors, let alone do notation itself.
Loved this - appreciate your effort! Even though I didn't "follow along at home", it's great to get a feel for what's out there.
And this matters because..? Arguably Rust's method is better being entirely compile-time. ah, whatever
Christmas came early this year!
/r/playrust
Running a high voltage through electronics is likely to just result in the bond wires being destroyed, without actually destroying the chips themselves. To get the data back, just de-encapsulate the chips from the plastic packages and replace the bond wires. Anyway, there's a _lot_ of things that would have been easier, but I wanted the security of what I did to be unquestionable to the maximum extent possible. Source: used to do analog electronics design for a living. Re: Zooko... Frankly, part of my thinking was that if I didn't volunteer to do it, we wouldn't have gotten an accurate look at what the security of the trusted setup actually was; in effect I was somewhat acting as a journalist.
Is there some way that attribute macros are scoped to modules or something? To me it looks like the ability to create arbitrarily named attributes blocks future extensions that add new built in attributes (like this RFC does with proc_macro) without breaking backwards compatibility. Is there some collision avoidance mechanism I don't know of? Is the plan to just have theoretical compatibility issues if adding new attributes but in practice it won't be a big deal? Or just never add any more?
This tbh
Another thank you for this series! Really awesome work and enjoyed reading through all of them.
True, though I'm assuming the English-speakingworld probably chose "special" as a synonym for "expert" that better conveyed that they were experts relative to the rest of the forces, rather than the only experts in the forces.
&gt; You would have no guarantees of stability, so you might as well be on nightly. Exactly. But... &gt; therefore we can't guarantee that they won't be broken by updates to nightly, therefore we cannot allow you to depend on nightly crates on a stable branch. This would be ideal, but unfortunately Cargo doesn't know yet that a crate depends on unstable stuff and will let your stable crate depend on it anyway, happily downloading it and attempting to build, just to give a cryptic error later. We could have`Cargo.toml` fields documenting unstable features or APIs used by the crate, which is something that could avoid this situation. But if some day we get such ergonomics / quality of life feature, then anyone could write a subcommand `cargo build-on-nightly-if-necessary` (with a shorter name I'm sure) that parses `Cargo.toml` for each dependency and build the crate on nightly if necessary. The problem: the semantics of unstable features are, well, unstable, they can change in multiple iterations so giving a name to them probably isn't simple. And there's stuff being stabilized at each Rust version so Cargo would need to track that. Perhaps it should be established that every unstable feature or API should have an unique identifier, and every RFC that proposes changing anything unstable should also deprecate its former identifier and give it a new one (increasing a revision number for example). And finally, each Rust release would come with a list of unstable identifiers that were stabilized. 
Nope! Only the RFC was merged. Now, an implementation needs to land, which may take many release cycles. Then it will stay in "unstable" phase for at least 2 more release cycles. I wouldn't expect it before 1.20.
You can also let c = &amp;a[..]; // c: &amp;[u8]
&gt; Cargo doesn't know yet that a crate depends on unstable stuff and will let your stable crate depend on it anyway, happily downloading it and attempting to build, just to give a cryptic error later. Sure, that could be fixed. But I don't think "build-on-nightly-if-necessary" would fall out from that. Rust doesn't have a stable ABI, I don't think there's a guarantee that `.crate` artefacts built with different versions of the compiler can be linked together. Certainly I doubt the Rust project would endorse a tool that does that, and it would be a bad hack. How would it juggle your different toolchains? cargo and rustup as they exist are built around the assumption that only one toolchain is being used at any given time. What we'd do probably is much more simple - you can declare which versions of rustc you're compatible with, and cargo won't waste your time trying to build a crate that's not compatible with the active rustc.
I wouldn't expect it to be stable in 2017, maybe though.
&gt; How would it juggle your different toolchains? Exactly the same way the Rust team juggle the toolchains for building the stdlib: you need to install a nightly version that matches the given stable (rustup can do that!) and use it. This works today and will for the foreseeable future, what we don't have is a *public commitment* this will always work. But unless the stdlib is modified to only use stable features (doubtful) then this will continue to work. Indeed, with the hacky "build-on-nightly-if-necessary", Cargo might even be able to download the stdlib from source and build it while compiling your project! Cool if you need to patch the stdlib but don't want to juggle the toolchains manually.
You took a lot of precautions that laymen might consider to be in the realm of paranoia. Did you truly feel like you might possibly come under attack or was it more of a trial run for a higher profile ceremony in the future? Is there anything that stood out at you as a highly probable vector of attack that others might not have considered? 
In fact, it appears that a journalist covering the ceremony had her phone hacked during it: http://spectrum.ieee.org/tech-talk/computing/networks/the-crazy-security-behind-the-birth-of-zcash A big flaw that we didn't consider was that DVD-R's are *not* read-only once written - you can keep modifying them after the first time you write them. I hope to write up a blog post outlining that threat in more detail sometime. However, so far it's a moot point, as even the most basic vulnerabilities haven't been addressed yet... for instance, so far only one person (Andrew Miller) has bothered to check the deterministic builds of the software used. So I'm not exactly in a big rush.
I might be blind, but I'm having trouble finding screenshots
Yes, I 100% agree -- It seems like it's straightforward implementation-wise other than figuring out the proper handling of hygiene. 
&gt; A big flaw that we didn't consider was that DVD-R's are not read-only once written I don't think we ever stated this. We *did* state that it was *append-only* which means information won't be lost so that the DVDs can be audited later. Is that something your blog post is contesting? I'm interested nonetheless.
This makes sense, but I would not support doing this for the reasons already cited. We are not going to make it easy for stable users to rely on unstable features.
https://github.com/rust-lang/rfcs/blob/master/text/1210-impl-specialization.md (An unstable feature, but a high priority one.)
Sorry for the delayed reply but I've been traveling. Seeing your code with the `set_arg` signature is helpful (actually it was one piece I wasn't sure if these suggestions would alleviate). This is an interesting problem and I have some ideas for solutions. I will try to write them up in the next day or two depending on how much time I have given the travel. Should you want to try yourself, the outlines for my ideas are: 1. Use an associated type in the interpreter to define what needs to be set, and ensure that the argument passed in is convertible to that type. This will probably only work for the enum-based option. 2. Use a `SetArg` trait and implement that for the various supported argument types rather than have an inherent impl in the interpreter. This will probably work better for the non-enum-based option. In the meantime can you give me any more requirements you have? Like what is `set_arg` supposed to _do_? Update different member variables depending on the argument? Just be converted to, say, `PyObject` and be put in a hash map? What do you expect the behavior in `evaluate` to be? Understanding your larger goal can help guide my thought process.
It does now: https://github.com/alexcrichton/tokio-process/pull/1. I'm the author of that pull request, and am planning on doing similar stuff as OP describes, so I'm quite interested in what OP is up to :-)
Hi everyone! I'm the dev. I'm planning to write some more technically detailed blog posts in the near future talking specifically about my experience with Rust and how I've used it. In the meantime feel free to ask me whatever!
async-readline seems to be aimed at line editing for interactive processes directly connected to the terminal, which is not what's asked for here, IIUC.
Epic is right! The opsec described in that tale is (in a rather literal sense) spectacular.
It's not portable to Windows, but you might be able to glean some inspiration from [libpipeline](http://libpipeline.nongnu.org/), which is a comprehensive C library for pipeline manipulation. This doesn't shell out anywhere, which is faster, but more importantly is more secure against untrusted (or just accidental) input with shell metacharacters.
Performance seems very impressive seeing as how you say you're rendering everything outside the viewport and that it's all still single-threaded, though you do mention that you made some optimizations. What optimizations did you make? And is there anything particularly noteworthy in how you've structured your code to easily add concurrency later?
I used to follow citybound dev, this is cool!
Yes, I will!
Can you check in your Cargo.lock please!
yep. means when I checkout and try to compile, I end up with the exact same dependencies and build as you, so we get nice repeatable builds. It's normally best to include the lockfile in bin projects, and don't include it in lib projects. if your actor system for example is worth splitting out into a separate library in the future then it would .gitignore the lockfile.
I *really* wish people wouldn’t use season names to refer to times. It’s so very culturally insensitive of Southerners. (You’ll note that we *never* do this; only Northerners do it.) But to be serious, it *does* make me have to think a lot harder. Summer… northern hemisphere… OK, so mid-2017.
Couchbase, Aerospike, facebook infrastructure, firefox, majority of concurrent data structure papers using c/c++, and others. These are just from the top of my head.
&gt; while the system allocator is already up and running. This isn't true: the "system" allocator behaves similarly to jemalloc in that each process is started afresh, and the heap needs to be managed just as separately. The main difference with the system allocator is the code is in the platform's libc library rather than in the binary itself (unless the binary is statically linked against the system's libc too).
Oh, cool, my bad
I think the concerns are absolutely legitimate but they're also true of any rust web framework.
&gt; Summer… northern hemisphere… Nah, equator.
`set_arg` puts value into hash-map, `PyDict` (which accepts `T: ToPyObject`). `evaluate` will, well, evaluate something like `foo(a, b, c)`, where `a, b, c` are locals from previously used `PyDict`. I've already implemented the first idea and it's working well. But about the second - can you modify previous code to show what exactly did you mean?
Which of those feature flags is furthest from stable at the moment?
We are moving into the phase of a programming language's life where haters come out without even trivially investigating what the language provides and argue, "Why isn't this like X?"
Opinions seem to have changed on that even for libraries, as the lock file gives information on what was exactly integrated against. If you want to test both the current state and any updates, you should have two cargo runs (cargo test and cargo update + test). (reference: https://twitter.com/wycats/status/804611049894776832)
Clap has a great website.
Macros 1.1 will be in 1.15, this is "macros 2.0".
maybe "using the system allocator rather than overridding whatever it is with jemalloc" would work, but it is a bit long ;)
You just have the native gcc that you use for building Linux executables, you need a cross-compiler that can generate Windows executables.
&gt; higher kinded types That's actually why I've mentioned F#'s Computation Expressions -- just like Rust, F# doesn't have HKT, and the type of the particular monad is specified by the "`builder`" object that is used in the "do notation" ([example](https://fsharpforfunandprofit.com/posts/computation-expressions-intro/)). &gt; memory representation issues yeah, that probably won't be so easy, although that duck-typed project gives hope. but I'm no expert in this. &gt; discussions many times cool, I'll search around a bit, thanks! 
And let c = a.as_slice();
Ah, I thought F# did, thanks for the pointer!
Sorry I'm a little confused. Which method did you implement? The link you sent didn't compile so I thought you still needed help. And which version did you want me to explain further? Edit: Oh I think I understand what you meant now. If the values end up in a hash map anyway then there must be some kind of common super/wrapper type to which you can convert. If you didn't want that common type then you'd have to specify how to handle each argument type separately. I was envisioning something like `impl SetArg&lt;PyString&gt; for PythonInterpreter`, but it occurs to me now that you could probably just add a `set` method to the `Argument` trait to get the same effect. In a sense, each argument would know how to set itself in a particular interpreter. That would let you handle different types in different ways, statically. If you've got things working now, great! I'd be interested to see what you've come up with. If not, I think I'll need to see some more code in order to help fix it.
&gt; Target = [T] I've seen this type a few times now but can't figure out what you call it in Rust. Some docs seem to imply it's a "contiguous sequence", but it can't be an array since the type itself has no size, right? If &amp;[T] is a "slice", what is [T]?
Are you suggesting that some of this gets pulled into tree, or just a general "hey while we're talking about resources this is more of them"?
I already know how to program well in several languages, including C, Python, JavaScript and Java. What resources would be good for me to learn rust?
The Glibc allocator tends to only do well in short lived, low allocation and/or single threaded contexts. From testing some propriety C code, I've seen glib's allocator be 2-3x faster for some trivial tests. But in the large scale, long term tests, jemalloc was ~100x faster. The issue was heavy locking contention in the glibc allocator, and running on a machine with 48 hyper-threaded cores amplified the contention drastically. Due to it's far better worst case behavior in multithreaded contexts, I consider jemalloc the best default for Rust. The one major issue I've run into with jemalloc is that it's fragmentation strategy doesn't work correctly with transparent huge pages (THP). On a system with THP enabled like Ubuntu by default, it can effectively leak memory to fragmentation. I think the fork used by Firefox disables THP for its mmaps, but I'm unsure if Rust modified theirs in a similar fashion.
I'm a little confused by the way you've structured it. You aren't using the `indices_s` value at all. You seem to be just throwing it away, and then trying to mutably borrow the original value and then make the original value the original value??? If that is so then there's no need to take an action. There's also no need to use the return keyword. At least what you've given, it seems [this](https://is.gd/tlRsQT) is what you are trying to do.
The book is a great resource, not sure what the status of the 2.0 version (though the original should be good enough). Rust by example is also a good resource if other resources like "Learn X in Y minutes" work for you 
[removed]
BTW, are there plans to finish Rustonomicon?
The glibc allocator does sound better for your use case. Most of the heavy work should be on the subprocesses instead of parallel itself which mitigates the contention issues I had. Are the consequences with THP on parallel or the subprocesses you're launching? If you want to experiment you could try tuning some of jemallocs settings (http://jemalloc.net/jemalloc.3.html). Setting narenas to 1 or 2, will probably make it slower but might be an interesting test. Though the easiest way to do that is with the MALLOC_CONF environment variable, which may affect sub-processes also using jemalloc depending on how parallel handles environment variables.
Or [this](https://is.gd/sG3Y9n), from the function name. EDIT: Corrected!
One of the things I hope this RFC will accomplish is to bring some fresh contributions to it. 
[T] would be an "array", no? 
Oh nice, I don't think I've *really* seen this, I'll make some PRs to add more of my links for people to find. *Edit:* [Done](https://github.com/ctjhoa/rust-learning/pull/79)
Ah. Do I understand correctly, that trait Statement { fn statement_node(); } Is the problem, and it should simply be `fn statement_node(&amp;self);`?
`[T; N]` is an array. `[T]` and `&amp;[T]` both have reasonable claim to "slice", and so people tend to call both of them slices, and it's obvious from context which you mean.
I'm responding to the claim that Go needs a lot of typing for things that Rust can use macros for. It doesn't, usually, because it can use reflection for this stuff. And reflection isn't subject to the orphan rule, either. Of course, reflection fails at runtime, and it's slower.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/haskell] [Rust is going to have a pre-compiled cache for all packages, is there something similar (in planning) for haskell?](https://np.reddit.com/r/haskell/comments/5k9zyh/rust_is_going_to_have_a_precompiled_cache_for_all/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I don't have time to test it right now, but, on Debian-family distros (eg. Ubuntu, Mint), installing `mingw-w64` and setting something like this in `~/.cargo/config` would probably work: [target.x86_64-pc-windows-gnu] linker = "/usr/bin/x86_64-w64-mingw32-gcc" (I cross-compile for my OpenPandora handheld by doing that with `arm-unknown-linux-gnueabi` and the GCC cross-compiler provided by the community.)
Why exactly do you need gcc to build a rust application in this case? Is it because one of the dependencies relies on gcc or is it something else?
It's used as a linker.
I disagree. Just because the `&amp;*` reborrow is *short* and probably alien to newcomers doesn't make it implicit. OTOH, I heartily agree that it maybe could be taught better, because people will stumble over it on their learning curve.
Well, the more the merrier, but for now it's rather the latter. Because IMHO in-tree we could be doing a better job of making learning resources discoverable. (Sorry if this sounds negative, but there's an opportunity to improve the learning experience with very little effort)
I have made the poor decision to represent nodes in my AST as an enum. Kind of weird. :S I should go back to what you're doing.
Me too. It took multiple attempts over about a decade to learn. Don't think that it's properly bedded in even now
What unnecessary repetition do you want to remove?
Sounds like a great new vector for infecting developers in an enterprise environment.
If I provide a generic implementation of a trait T for every type implementing another trait U, and subsequently specialize that trait for one specific type implementing U, calling that method through a trait object type like &amp;T or Box&lt;T&gt; will resolve to the default implementation on U instead of the specialized implementation that it is resolved to when statically dispatching. Does calling a specialized trait method through a trait object inherently not allow for dynamic dispatch, or is that just not implemented (correctly) yet? EDIT: [Code sample](https://is.gd/ZvHfkZ)
Wait does this replace multirust? And this is the same thing you curl right?
I found some related efforts in rust community. https://github.com/ratel-rust/ratel-core https://github.com/dherman/esprit https://github.com/mitsuhiko/rust-sourcemap 
Don't think you can do much better than what you already have. How would you like it to look, let's say in another language?
Can you produce a code sample? I've tried to recreate what you describe but it behaves as expected (I think): https://is.gd/w32edT This prints Baz::foo() Baz::foo() Meaning that the specialized impl is resolved correctly.
if bool { foo } else { bar } That's as close as you'll get to the ternary. And for a reason - removing anything from there is going to start hurting clarity.
`.wait()` on the `Stream` trait does nothing; it returns an iterator type that needs to be iterated over to produce items: let vals = rx.map(|x| { println!("stream: {}", x); x * x }).wait(); for val in vals { println!("Squared: {}", val); } The return type of `.wait()` has a `#[must_use]` attribute; you should have gotten a warning while building the binary that you needed to iterate here.
Not a "real" solution, but could you store the state as an enum?
This is awesome, thanks! I need to dig into the `slice` vs `Vec` thing. I haven't quite come to terms with when to use either, so I naturally fall into the trap of thinking I always want a `Vec` because I want something I can push stuff to.
A `&amp;Vec` doesn't allow you to mutate the backing `Vec`, though. There's really only *one* thing you can do with a `&amp;Vec` that you can't do with `&amp;[_]`: call `Vec::capacity`. There's rarely any reason to want to do this when reading from one, though. **Edit**: Plus, you can get `&amp;[_]`s from multiple other types; if you ask for `&amp;Vec`, you can *only* pass a `&amp;Vec`.
Right, immutable reference, duh. That makes perfect sense, thanks.
I agree! Just had this same problem, and this was the only hint as to what the problem might be! 
This is a cool trick &amp; definitely has its use cases, but I personally find it more difficult to reason about than the alternatives (even if only by a little).
A bit in college but never did anything as interesting as implementing an actor system. I had seen it for io streams but I didn't even realize rust had operator overloading to be honest.
From the github page for multirust: Note: multirust is not actively maintained. Migrate to rustup.rs So apparently yes. Also yes on the curl, BUT I had silent errors when running it straight from the curl output so I did end up saving it to the drive. 
Is there a way to install rustup as opposed to curling? this &gt;curl https://sh.rustup.rs -sSf | sh component add rust-src didn't seem to do much.
IMHO, you'll probably find that the `enum` approach actually works better in the long run. With `enum`s, you end up with all your logic for a particular task grouped in one place, instead of each `impl` having a little bit of logic to deal with every cross-cutting concern.
Though I've never heard of snap.py, I must commend your effort to port it to Rust and your immensely positive results. That's quite the speed increase! I would die for improvements like that for some of the tools I use myself. Could you provide any insights to some of the difficulties you encountered, or perhaps lessons you learned, while porting the application? I'm doing something similar for a C project and would love to hear your thoughts. 
&gt;That should really be all functions, not just most. No it should not as far as I know. Lets have a look at https://www.khronos.org/registry/vulkan/specs/1.0/man/html/vkGetPhysicalDeviceMemoryProperties.html &gt;Valid Usage (Implicit) &gt;- physicalDevice must be a valid VkPhysicalDevice handle &gt;- pMemoryProperties must be a pointer to a VkPhysicalDeviceMemoryProperties structure You can not construct a PhysicalDevice yourself, only though the API and `pMemoryProperties` is handled by the wrapper. https://www.khronos.org/registry/vulkan/specs/1.0/xhtml/vkspec.html#fundamentals-validusage I don't see why this function should be unsafe. Edit: I just realized, I did not actually wrap the pointers (instance, device etc) so yes that would be unsafe because I can currently pass in a nullptr. But that should be easy to fix. 
Maybe this will help get you started? use std::fmt::Debug; trait Statement: Debug { fn statement_node() where Self: Sized; } #[derive(Debug)] struct Program { statements: Vec&lt;Box&lt;Statement&gt;&gt;, } fn parse_program() -&gt; Program { Program { statements: vec![] } } fn main() { let p = parse_program(); println!("{:?}", p); } 
That's a 90% speed increase between two _very_ different systems. You should totally benchmark on the server and see how it runs. also congrats on your raise because lol that's a wild improvement
The GIL is an implementation detail of CPython. You wouldn't be rewriting CPython if you avoid the GIL, just another implementation of Python. It'd probably be better to follow PyPy's code and rewrite that in Rust. With Rust you might be able to implement better C interop than PyPy, and parsing might be faster, but since PyPy already JITs the code you won't see any real performance boosts.
While the GIL is technically an implementation detail of CPython, the desire for compatibility with existing Python code makes it almost impossible to avoid. Rust would be a great implementation language for something like a language interpreter (though PyPy is some serious competition), but it's not going to be a silver bullet. 
To explain it a bit better from the Python side: the GIL is not some sort of unavoidable consequence of writing CPython in C, it's a conscious design choice made by CPython's developers. It's entirely possible to write a Python implementation that doesn't have a GIL. The problem is that a lot of currently existing Python code implicitly relies on the GIL being there, so if your implementation doesn't have one, you'll run into the thread safety issues again, just on the Python side.
I wanted them to merge if both are Restricted, and to simply take the Full if any is full. 
Actually I didn't know until this post that it did either :) !
By the sounds of it, snap.py is an internal program at their company. 
Well Rust does something similar at least for expressions: The `syntax::last::ExprKind` type (in `src/libsyntax/ast.rs`) has the goods. 
I made a modified version of your code sample that shows the behaviour I'm talking about: https://is.gd/ZvHfkZ. I also just realized I made a small mistake in the description of my problem: the trait object I want to access the object through is &amp;T or Box&lt;T&gt;, not &amp;U or Box&lt;U&gt; as originally specified.
It's not affiliated with Valve in any way, and probably exists to steal your credit card or spread malware. Steam gift cards do exist, but you need to buy them, not get them for free.
I think /u/uuknis called it. Rust isn't doing anything unspecified here; it's the simple fact that `Foo`'s methods aren't added to the vtable for `&amp;Bar` by default, so instead you're hitting that default impl of `Foo` for the type `&amp;Bar` itself (trait objects auto-implement the trait they represent). If you want specializations of `Foo` to carry into trait objects of `Bar`, you need to have the latter extend the former: trait Bar: Foo { // ... } This simple addition leads to the expected result: Baz::foo() Baz::foo() 
The author says in the original article that it is an internal program for their company and that it downloads table data from web pages, not for network analysis and manipulation like the one you linked.
Yep yep, it was an internal tool that was developed before I was hired. It was good at the time, as we didn't have nearly as much data to comb through and it was adequate for the job. Now that we have almost doubled the amount of data, and rely on that tool multiple times on a daily basis, I figure we breathe some new life into it.
You don't need to install Rust at all; one of its incidental benefits over Python is that it produces native executables, so you can just install your own compiled code.
/u/petertodd On the specific topic of section 1.6 (Equihash), are you aware of Alwen, Blocki, Pietrzak, et al.'s recent work on memory-hard functions? They've addressed both the dMHF (where memory access pattern depends on input) and iMHF (where it does not) sub-problems, with fascinating results. To wit: 0. All dMHFs are subject to timing-based information leaks 1. Scrypt is an optimal dMHF 2. _None_ of the current iMHF candidates is optimal (and they characterize the gap) 3. There exists a family of graphs that exactly corresponds to optimal iMHFs (and they describe its construction) EDIT: Relevant papers: http://eprint.iacr.org/2016/783 http://eprint.iacr.org/2016/875 http://eprint.iacr.org/2016/989 EDIT 2: On a somewhat amusing note, the family of graphs was previously described for other purposes, by none other than Paul Erdös. Yet another thing he got to first :P &gt; Paul Erdoes, Ronald L. Graham, and Endre Szemeredi. On sparse graphs with dense long paths. Technical report, Stanford, CA, USA, 1975 EDIT 3: Also relevant is http://eprint.iacr.org/2014/238
Perhaps the release notes could mention the release date of the next version in line.
Cool!
Huh, interesting. Is it a branded medium for tech news?
Wow, thanks! I'm not fully understanding it yet, but this helped me making the thing actually compile :) So next steps are now to find out the implications of `Self: Sized` in my case - or whether it's a better idea to implement the AST using `enum` (as proposed further down in the comments). Thanks!
Thanks for the hint! This probably involves some work, but it sounds like it definitly might be worth it.
&gt; Most functions in Ash are now marked as unsafe. Specifically every function that is marked as extern sync in the Vulkan spec is considered unsafe. Why can't you just not have the `Clone` and `Sync` implemented on those structs and let the compiler thus enforce external synchronization without `unsafe` qualifiers?
While this is the pattern I'm looking for, I believe that in Rust short-circuiting like this is considered poor style, unlike in C, where writing something in shorter form is usually better solution. (x &gt; 0) &amp;&amp; {x-=1; true} Looks quite nice, but I actually prefer if (x &gt; 0) {x-=1; true} else {false} just because I find it easier to read, because I don't have to think how logical operator works, even if it only takes a split second.
Writing condition multiple times.
Sorry, that just brought up more questions :P I'd be very interested to know why you don't consider an "array" a subset (or implementation) of a "slice"? Take this example: `let a1: [usize; 3] = [1, 1, 1];` `let a2: &amp;[usize] = vec![1, 1, 1].as_slice();` `let a3: [usize] = vec![1, 1, 1].as_owned_slice(); // if such a function was exposed` Aren't all versions of `a` just a pointer and length? They happen to be backed by data in different places(heap vs stack), but they are all actually the same struct internally in the compiler, no? and at the least they expose the same interface, no? I would have just guessed: `[T]` is a version of `[T; N]` which is generic across all `N`. And as such only the type system cares about the difference between the two.
You might have misread my comment. `Send` is fine. I was talking about `Sync` and `Clone`.
It has been brought up. My previous post did just that.
Higher-order functions are functions which take other functions/closures as input parameters. It allows you to define a custom function to be performed within that function. - https://is.gd/CulTlv - https://is.gd/kelnQb
Tying up some loose ends here and there. TWiR, my alloca RFC, some patterns entries, etc. Also I just announced another Rust Regulars' table in Darmstadt, Germany on January 20th, hope to meet some of you there.
Recursive enums work when you wrap it in a `Box`.
Carrying on my work on a data visualisation library from last week, I now have an API that can plot 2D interactive bar, line and scatter graphs. [Example](https://gfycat.com/HarmfulUnawareAmmonite) of one of the plots. It needs a bit more work, the main thing holding me back from releasing it apart from better test coverage and docs is trying to convert the graph struct to hold trait objects instead of generics with trait bounds so that anyone can make a type that implements Plottable and add it to the graph instead of requiring built in support for different graph types, and built-in support for a few more plots like histograms and pie charts. If anyone is interested in how it works/contributing the code is [here](https://github.com/Tohie/chartrs).
I would argue that many C++ devs, and virtually all Rust developers, would see that as an anti-pattern.
As others said, the GIL is an implementation detail of CPython, but one that turns out to be pretty important in practice so Rust doesn't fix that. What could be interesting would be to devise a way to expose some of Rusts safety features in python. This could be a special library that goes with the interpreter that exposes immutable data structures or even an extension to the language. One could imagine for example a special context manager (for use in a `with` block) that creates rust-native borrows allowing everything inside that block to release the gil.
coffee-script handles it the same way as rust i think
This is all processing data from HTML tables? Do you control the server side? I expect if you switched from transferring HTML to transferring an encoding tailored to machine processing [1], you could make your system more robust (avoid sensitivity to changes in the HTML formatting or the libraries you're using), have simpler code, require less bandwidth, and require less CPU on both sides. A bunch of questions intended to determine that: * What types of values are in these tables? (Integers, floating point numbers, strings, ...?) * What kind of information do they represent? * How large are they (in terms of total byte size in the current encoding, number of rows, total number of fields, etc)? * What sort of processing are you doing on them? How large is the output? Is the algorithm stable enough that you could just move it to the server side? * How are they generated on the server side—on-the-fly from some online database, or saved from some batch process? [1] JSON, BSON, SQLite database, protobuf/recordio/sstables, cap'n'proto, custom binary format, ...
I just finished putting together [some notes](https://scribbles.pascalhertleif.de/rust-and-ruby.html) on the differences between Ruby and Rust from the perspective of someone who learnt Rust first.
This is not a fully fleshed out article, but some points I noticed recently. I'd love to add more, though :)
So I've implemented a pipelining asynchronous PostgreSQL driver, because I needed one to proper handle the High Availability setups. &gt; If you consider this in a larger rust app you end up with a weird design that does not load balance very well: &gt; You have N threads running to keep all cores you have in your machine happy &gt; Each thread runs an IO loop &gt; Each IO loop keeps multiple postgres connections open I've ended up with this "weird" design because it's easier to run my own event loop than to dive into the labyrinth of https://crates.io/crates/tokio-core and its peers. Nevertheless, it's certainly possible to integrate better with https://crates.io/crates/tokio-core and reuse some central event loop for all the database clusters in an app. &gt; However now that one thread will have quite a busy IO loop which effectively ends up in a cycle of "poll libpq; usleep(1)" since there is not all that much you can do with libpq. Nah, as I've said earlier, with PostgreSQL you just wait on a socket, as usual. There is no need to busy-wait. Here's the point in my driver where I call `poll`: https://github.com/ArtemGr/pg_async.rs/blob/898e50c9337e17da23b9ff61acbb0eae1f86ddd3/src/lib.rs#L462 There is no busy-wait. 100ms timeout is here in case I've screwed up, but I've tested without it and everything works as expected.
My only excuse is that it's something so common in my code that I wanted to have "my own syntax" for it. If you have any equally succinct suggestions, let me know!
&gt; unlike in C, where writing something in shorter form is usually better solution. Is it? I haven't written C professionally, but the rule of thumb is usually writing clear code above all. And dense code is often the exact opposite of clear code. 
Actually, Rust has `null`. It kinda needs it for interfacing with C. However, it's never used outside of FFI, because `Option` is simply easier to work with.
Love the badge!
Let's see if wasting valuable man-hours on my secret project doesn't get me fired first haha
I want to finish up and publish my humanize library. I may also add some extra customization options to [humansize](https://crates.io/crates/humansize) if I get the time.
I thought you block on pg exclusively. If that's not then Disregard what I said. 
Is it using `libpq` as dependency? 
Sure, NP. The event loop blocks. The code of the library user never blocks (unless it explicitly wants to with [Future::wait](https://docs.rs/futures/0.1.7/futures/future/trait.Future.html#method.wait)).
But the same is true with blocking pg in a background thread. 
Of course. And this is true for every asynchronous API out there. You can **always** do in dedicated background threads the things that you can do asynchronously. The difference, when using an asynchronous API, lays in doing **several things at the same time, from the same thread**. When you work with sockets asynchronously, you can wait on **multiple** sockets at the same time. With blocking happening in **one** thread (the event pool thread). When you work with PostgreSQL asynchronously, you can wait on **multiple** connections and **multiple** SQL queries. With blocking happening in **one** thread (the event pool thread). Asynchronous APIs = less threads. In case of an asynchronous PostgreSQL driver (my driver, for example) you can have any number of PostgreSQL connections to any number of PostgreSQL replicas handled, with a multitude of pipelined queries in flight, all by "wasting" no more than a single thread.
In Ruby and Crystal there's [tap](https://crystal-lang.org/api/0.20.3/Object.html#tap%28%26block%29-instance-method). In your case it would be: condition.tap { |cond| do_something if cond } Basically `tap` yields the object to the block, evaluates it, but has the value of the "tapped" object. I guess something similar could be done in Rust.
Fun History Fact: I bitterly opposed concerns in Ruby, but love traits. At the time, concerns were a lot more... concerning. They had an overall performance impact, even on code that didn't use them, and dynamic vs static typing played a big part too. I ended up coming to Rust before they became a real thing, and so don't really have experience with them in Ruby. I bet if I wrote more Ruby I'd use them all the time.
You should perhaps also note that those *pointers* (as in `*T`) are also primarily for FFI (edit: yes, and unsafe low-level code) and are distinct from *references*, the type of `&amp;T` usually employed by idiomatic Rust code, which are guaranteed to always point at valid values. 
900s -&gt; 100s isn't a 90% increase, it's 800%! In the same amount of time, the Rust solution could process 9x the workload.
Even better! My poor math skills continue to make my life better!
Is your humanize library doing more than file size conversions, like general unit conversions? (Showing appropriately in km, m, cm, mm, minutes, seconds, etc?) What is considered a "human-understandable" unit is quite culture specific, so good customization and localization support is a must! For example, in Finland it's considered normal to measure fluids in dl or decilitres when cooking, whereas in Japan cc, cubic centimetres, are used. (1dl = 100cc = 100ml)
I would just return `None` at that point. Booleans should be avoided as much as possible.
Sweet! /u/rabidferret is working on a tokio-based pure-Rust Postgres driver, so I'm interested in hearing what he has to say about the replication support you added here :)
In line with OP's question. Is there a guide to editing VTables in Rust? (I'm aware this is unsafe). But if I have a DLL/SO that is loading in a new type that implements a trait I can *add it* to the exiting VTable right? 
Yep, I enjoyed reading it very much too. :)
You probably want to repost this in /r/playrust – this sub is about the programming language, not the game.
[bip39-rs](https://github.com/infincia/bip39-rs), an implementation of the Bitcoin BIP0039 standard for turning mnemonic phrases in to crypto keys. Needed something similar for a commercial project (the general phrase-&gt;key part) and thought well, BIP0039 kinda does that already and is pretty widely tested, might as well make a library for that rather than rolling something custom.
Homework. I need to write a program that takes in a file with peoples name and information about them, parse it, and have it available to be queried for all information about one specific person. The file is some 1500 lines long, so a lot of what I do will be optimization. About half way done, and it's a great way to learn some more about Rust so it's pretty fun.
You don't have to believe me, ask Rust ;) fn main() { let a1: [usize; 3] = [1, 1, 1]; let a2 = vec![1, 1, 1]; let a2: &amp;[usize] = a2.as_slice(); assert_eq!(std::mem::size_of_val(&amp;a1), 24); assert_eq!(std::mem::size_of_val(&amp;a2), 16); } That is, for a `[T; N]`, the type system knows `N`, but at runtime, it doesn't exist any more. It's just a bunch of `T`s.
 unsafe { let mountp = CString::new(mount_point).unwrap(); let mut stats: libc::statvfs = zeroed(); if libc::statvfs(mountp.as_ptr(), &amp;mut stats) != 0 { return Err(format!("Unable to retrive free space of {}", mount_point)); } Ok(stats.f_frsize * stats.f_bfree as u64) } And for those of you on Windows, you'll want `GetDiskFreeSpace` or `GetDiskFreeSpaceEx`.
Thanks, /u/tikue, there are some solid arguments here. &gt; it hurts the project's credibility While I'm glad to contribute occasionally with some **exceptional** projects (pg_async, vtd_xml, rados.hi), I have other goals in life besides brushing with the open source hall of fame. Using code style that is most convenient to me - saves me time and effort when developing software. My time and comfort are thus important constituents to reaching my goals and worth more to me than the credibility of pg_async. &gt; and discourages contributions I am developing this driver for my own High Availability projects, I'm sure it will provide me with sufficient quality, and I'm not betting it's future and quality on the presence or absence of contributors. So in my case your arguments do not apply. Thanks for being a good sport, anyway. =)
I have low skills in Rust, sorry if something wrong trait DoWhen where Self: Eq { fn do_when(&amp;self, want: &amp;Self, then: &amp;Fn()) -&gt; &amp;Self { if self == want { then(); } self } } impl DoWhen for bool { } fn test(value: &amp;bool) -&gt; &amp;bool { value.do_when(&amp;true, &amp;|| println!("is true" )) .do_when(&amp;false, &amp;|| println!("is false")) } fn main() { println!("main {}", test(&amp;true )); println!("main {}", test(&amp;false)); } 
Why not just merge the two methods -- AFAICT the most common pattern is to do all the required initialization in `new` and return the `Struct` from there (return `Result&lt;Struct, _&gt;` if initialization can fail).
Amazing!! I've been waiting for this for so long; I tried to implement my own async futures-backed thing for my project but really couldn't get it to work the the old library due to the lack of `Send` on the results of queries with the old library. Thanks so much for your work!
Pythonista and newbie Rustacean here. Chiming in with my $0.02. 1) I love the idea of an implementation of Python in Rust just on the face of it. I think it would be a great project for someone to undertake, and Rust might well provide all manner of metaphors for implementing Python all the more efficiently. 2) That said: As other people in this thread have noted, the GIL is not the root of all evil. It's part of the implementation of CPython, it exists for good reasons, it is required and expected by many third-party extensions to CPython, and getting rid of it is tough. Work in this vein hasn't yet yielded the kinds of explosive performance improvements people would like to believe it does, in big part because most of Python's orders-of-magnitude-slower-than-C performance is due more to the boxing and unboxing of object types than the GIL per se. I've talked to some other people about getting rid of the GIL, and I ask them the same question: Why do you want to get rid of the GIL? Because then Python can run really fast, they reply. (EDIT: Or because have CPU-bound operations running on multiple threads. For more on that see below.) My answer to them is: "If you want Python to run fast, start by profiling your Python program and figuring out where its bottlenecks are. Focus on the 10% of the app that gets 90% of the CPU time. Use Cython to push really performance-intensive code out to C. You can get all the benefits you attribute to a GIL-less Python (IMO, mistakenly) right now by doing a little legwork." For fun, and for practice, I wrote a video game that uses a pure-Python graphics framework. When I profiled it, I found that the vast majority of the CPU time was in a) the collision detection system and b) the draw loop. Both I optimized by way of Cython, and the result was a fourfold improvement in performance (going down to 4-6% CPU usage from what was 25-30% on a 4-year-old notebook). C modules created with Cython also have the advantage of being able to sidestep the GIL if they're written properly, so if avoiding the GIL really is your goal -- e.g., for the sake of speeding up operations on multiple CPU-bound threads -- then the tools are already there to make it happen to a great extent. Still, the idea of a "Rusthon" interpreter does tickle the fancy.
I suspect you've already solved this, but... The problem is that you're trying to **move ownership** of something you have **borrowed**: ``` &amp;mut View::Restricted(ref mut indices_t) =&gt; { *target = View::Restricted(*indices_t) } ``` You must instead take an explicit clone of `indices_t`: ``` &amp;mut View::Restricted(ref mut indices_t) =&gt; { *target = View::Restricted(indices_t.clone()) } ``` But, /u/critiqjo points out, I think what you actually want to do is move `indices_s` into `target` and throw away `indices_t`. This requires a couple of small changes to satisfy the borrow checker. [See here](https://is.gd/9hcYN8).
I will be adding a new level to my [hacking game, called hakka](https://github.com/simon-whitehead/hakka). Last week was spent writing an in-game console instead of relying on the native OS one. I had help from two amazing contributors who randomly opened PRs and made improvements to it as I went. I am super grateful to them.
I've been debating whether to include units in the crate, actually. Currently it does Boolean parsing, different representations of numbers, and common string manipulations. If I ever do units, it'll definitely have good customization built-in though.
No, both compile down to the same machine code. However, if you want to group `x` and `y` together in a meaningful way, why not a struct? #[derive(Copy, Clone)] pub struct Point { pub x: usize, pub y: usize, } fn takes_point(point: Point) {}
Second what Quxxy said. In addition, Ruby 1.8 to 1.9 and Python 2 vs Python 3 are _worlds_ different. Ruby 1.8 is long dead. Python 2 vs 3 is still bitterly fought to this day. I'll elaborate more later, if any of you care.
Because it didn't occur to me when I started writing this, as it was a small piece of code that implemented one algorithm with 3 or 4 new types. Given how cheap new types are in Rust compared to all the other languages I usually work in, that might not be a good enough reason.
Could you use [thread_local](https://doc.rust-lang.org/1.5.0/std/macro.thread_local!.html)?
Can you use `Arc` instead of `Rc`? The problem isn't the `'static`, it's that `Rc` isn't thread-safe, and globals are accessible from all threads.
You're looking for /r/playrust
You're looking for /r/playrust I think.
rust is a game, not a nerd language
+1
This is a pretty good solution for now, thanks. pub(crate)'s gonna solve a lot of problems.
It is not as simple as that http://www.grammarphobia.com/blog/2011/04/concerted.html
Rust is a nerd game *and* a nerd language
It's probably inspired by C++'s stdlib "append to file" function `cout &lt;&lt; "Hello, world" &lt;&lt; endl` (and the `cin &gt;&gt; someval` "read from file" equivalent), which is in turn inspired (I can only assume) by Bash. In the C++ world I gather it's essentially considered a historical bad move that's hard to get rid of because of backwards compatability, like the Haskell prelude's partial functions, most of JavaScript, or representative democracy.
[removed]
I think that people are downvoting this based on the assumption that this is a critique of Rust's stability; but the original article doesn't mention Rust, and it does point out some problems in development models in which an attempt to provide a fully stable long term release as well as a long-term development release can cause some problems. I think that Rust's stability model, on the other hand, is fairly reasonable. The stable releases only include features that are committed to stability; the nightly releases allow for development and experimentation with unstable features that haven't yet been committed to, while allowing that development to span multiple release cycles if necessary.
You've caught my intrest ill be waiting!
Usually so i can also call the init function multiple times through out the lifetime of "Struct" without creating a new one. I think init was a bad name for this example. 
This is a very amateur question, but I made a struct like this: struct point { x: f64, y: f64, } And then I need to translate this C code into Rust, but I'm not sure how: static double mag(const struct point point) { const double x = pow(point.x, 2.0); const double y = pow(point.y, 2.0); return sqrt(x + y); }
&gt; EDIT: One thing I am specifically looking for advice on the code to read from the network socket. Currently, I read from the socket 1 byte at a time. This turns out to be an extremely slow and expensive process since it requires literally hundreds of read system calls. Is there any better method? The API you're trying to use properly and the characteristics you're having trouble with aren't rust-specific, so any documentation on socket programming should apply equally well. Link me to the relevant bit of your code and I'll see if there's anything I can say without dedicating too much time to it.
&gt; parsed in it's own thread its*
"One could imagine for example a special context manager (for use in a with block) that creates rust-native borrows allowing everything inside that block to release the gil." Cython has something exactly like this, so there's some precedent for creating what you're talking about.
Very exciting, things really seem to be coming together. Since it feels very in your face here I want to mention: I really wish and_then had been called then, both in futures and on options. Common names should be as short as possible. `then` should be the one with a longer name :\. Not sure if for_each has different semantics than an existing thing named each, but if not, I wish it were called "each". 
Would love to hear about it. I didn't follow Python for a while and I never really adopted 3.x since I had a gut-feeling that it was a huge mistake breaking a dynamically typed language in so many often subtle ways…
It uses type inference to select the appropriate type. It will panic if it can't produce the correct type. There is a `try_get` method that returns a `Result` instead.
I don't think the title of this submission matches the conclusion of the post (putting aside the argument of whether the post itself is correct). Its asserts that small frequent breakage is superior to large infrequent breakage, but I'll argue that if you can get away without breaking anything at all, then you should do that. :P
Oh, very interesting! I'd love to hear more about it!
Sweet! This looks nice overall. Paste.rs seems nice as well, didn't know about it until now. Would be fun to build a personalized frontend around it someday. Good job all around!
\o/ I've got the suggested quote of the week twice in a row. Although this one is older than my first one - but I guess it more fits in with Christmas being in the past week. Also, \o/ \o/ \o/ @ "all std structs are now fmt::Debuggable". We should probably have an RFC that sets in stone that all future std structs be Debuggable too?
no, that's correct. The problem is that with only the HashSet for something like "everything is valid" I'd have to store the id for all items. This way I don't get as much overhead
Actually XP *is* supported for now (it has to be as long as there are Firefox builds for XP), just as a third-tier platform (which means there will be *some* effort to keep it working, though obviously not as much as with, say, Linux on x86_64.
IIRC, there's a `missing_debug_implementation` lint. Now would be a good time to enable it for building Rust.
A wave of future crates from tokio?
What are your go-to fun/learning projects? What was fun to implement? Especially in rust :) When I pickup a language or want to practice and do better than the last time or try a new paradigm, this what I code: - brainf*ck interpreter - chip8 emulator - small raytracer - pong - basic genetic algorithms - hindley milner (well, I still need to finish this one :) Any suggestions? I post here because rust is my current toy and I'm interested in lower level answers than usual (no gui calculator!)
I am not sure I agree with this. Sure, at first blush it seems nice never to have to break anything, but that is how you end up with C++. The programming challenges we face and the hardware we face them on changes over time. This lead to the ways and patterns of how we solve them changing as well. In order to support the new ways of doing things a programming language has to evolve as well. In order to avoid breaking changes the old ways have to stay around in the language. This leads to two compounding problems: 1. Keeping around the old way around permanently adds complexity cost, both for the developer of the language and developers in the language. For the developers of the language the matrix of interactions between things in the language is ever growing. For developers in the language there will be both the ideal and less than ideal way of doing things, and it is up to developer to know and choose the right one. (see C++) 2. Unless we are willing to go all emoij or something, ascii gives us quite a narrow syntactic space to work in. Old features sticking around means they will forevermore squat on prime syntax, leading to new features necessarily being more verbose and involved in their syntax. (see C++) The combined effect of having both the better and worse way to do something in a language and having the worse way having the nicer syntax will add a ever increasing cost to using that language. 
I'm not sure, but perhaps you should declare your functions as `extern fn`, otherwise they'll get mangled (if a symbol is exported at all).
Wow, I never knew about `pg-sys` being called using `links` cargo attribute. Thanks!
The `validate` function returns `Result&lt;(), HashMap&lt;String, Vec&lt;String&gt;&gt;&gt;` for now. Looking at your post, it would be nice to generate the constraints for a HTML form from that struct as well. I *might* publish the crate this week but only started working on it yesterday so it's still very rough
1) While packaging the FFI layer into a separate crate is a good practice, it **does** take certain time to set up. Consider also the rule of three ( https://en.wikipedia.org/wiki/Rule_of_three_(computer_programming) ). 2) Bindgen-based crate would've lacked proper structure and documentation and thus would have been detrimental to the development of the driver. Feel free to refactor the FFI layer into a separate crate, though, if that is your wish.
Everyone is awaiting it!
Can't we just have an implicit Debug implementation if one isn't provided?
I'd expect "then" to execute unconditionally, it'd be the equivalent of the sequencing operator (usually ";") in C like languages. "and_then" better communicates the "if the left was successful, then do the right" nature of the operation on options, results and futures.
You can think of it like `vec[0]` vs `vec.get(0)`. Most of the time you're asserting that the 0th element exists and don't want to deal with the `Option` but the other method's there when you do. The naming here's a bit different since there isn't an `Index` trait that can return things by value.
Cool thanks for your answer. I had experimented with stuff that used ``malloc`` and ``free`` like your main threader^1. Do I understand it correct if I interpret that your use of ``mem::uninitialized`` is basically the same as the ``malloc`` and ``free`` solution but with the ``malloc`` wrapped inside the ``mem::uninitialized`` and the ``free`` put into *Deref*? Btw.: I do love the ``io::Error::last_os_error().description()``. Thats a really cool addition. 1) sad that he deleted his answer because that execution did help me understand how to use the ``malloc`` and ``free`` to create a working prototype.
&gt; Obviously, one might think about a Rust 2.0 which might do breaks in functionality, but I think it would be more productive and refreshing to create an entirely new language instead, from scratch. Or a 2.0 release could simply remove features that have been marked as deprecated for a long time, without being a major change in itself (just a breaking one).
&gt; the desire for compatibility with existing Python code makes it almost impossible to avoid AFAIK neither Jython nor IronPython use a GIL.
&gt; I was wondering, is it possible to get rid of GIL (Global Interpreter Lock) in python by rewriting the CPython using Rust or atleast using the same concepts of concurrency used in Rust, to get rid of global locking ? [You can get a GIL-less CPython without rewriting it](https://www.youtube.com/watch?v=P3AyI_u66Bw). The problem of that is you end up with *tons* of fine-grained locks, and maintaining cache coherency thrashes all the caches all the time, which craters performances. The GIL has remained not because it's not possible to remove it, but because GvR will not accept destroying single-threaded performances to remove it, and that would require very serious engineering efforts… and may run into the other issue of making the CPython implementation significantly more complex. Also you run into C-ext issues as they currently rely on the GIL for their multi-threading safety.
/u/molomull. I did something like this for visual code's debug server protocol which provides a json schema for the protocol. It took a bit longer than I expected to get it working but then again I actually got it bootstrapping itself from the json schema defining json schema. Feel free to steal and borrow from it if you find it useful. https://github.com/Marwes/schemafy/ https://github.com/Marwes/debugserver-types 
Considering how many people are affected by things in std, requiring accurate debug information isn't unreasonable.
OTTOMH: - Game of life: You can keep this simple, or go nuts by implementing Hashlife and patterns and optimizations and all that. - Reimplement common CLI utilities like grep, ls, ... - Simple clients for IRC or FTP - A Reddit/GH/Chat bot that does whatever you deem useful
Thank you for your detailed explaination. I will keep that in mind. It did teach me a great deal.
Reading the article, I was under the impression that the problem was more of maintaining two coexisting yet diverging branches for a long period of time. I don't think Rust currently has this problem (yeah, there is nightly, but AFAIK stable rustc uses the same code as nightly rustc, and is not usually maintained separately – I think 1.12.1 was the only time there was some backporting instead of focusing efforts on nightly development). 
That's the effect, but not the cause. Bias warning: I mostly have worked in Ruby, and lived through the 1.8 -&gt; 1.9 transition. I also worked at a "we'll port our code to Java before porting our code to Python 3" Python shop. The single biggest reason for the split, in my mind, is that Ruby had community buy-in, Python did not. There's two big reasons for this: * the Ruby transition was easier to do. * The Python transition didn't have as compelling of a reason to swtich. So, here's the rough pitch for Ruby 1.9: "Hey, so, Matz wrote Ruby. But he's more of a language person than an implementation person. The Ruby interpreter is written in a very naive manner. So Koichi, who is a very implementation-oriented person, has re-written a brand new Ruby, from the ground up. This will make your Ruby faster and better, and along the way, we're going to take the opportunity to fix some things that aren't great about Ruby. There's also some new features that will only be in Ruby 1.9. We're going to release one last version of Ruby 1.8, 1.8.7, but after that, it's dead. We don't expect everyone to move to 1.9 immediately, 1.9.0 will not be for production use. Please give it a try, and we'll try to fix major issues we find along the way." Furthermore, Ruby never had a super-strong compatibility promise. In those days, every release of Ruby would break _something_, though often not much. In a language as dynamic as Ruby, it's really hard to have total compatibility, and nobody was really paid to work on Ruby. So Rubyists were already okay with fixing little bits of breakage to upgrade, and while this one was bigger, it was also more compelling. Furthermore, it was totally feasible to run a single Ruby program under both interpreters. While there were some changes, there was a clear path towards making them, and you could say "We officially run on 1.8 but are adding in 1.9 compatibility, please give it a try under 1.9 and file bugs". This enabled a more gradual transition that was extremely helpful in making it happen. You can still do this to this day; a project I'm (nominally) a maintainer of still technically supports 1.8.7, 1.9.3 (the last of the 1.9 series), and the newest Ruby releases today. In a single codebase. [It takes some hacks](https://github.com/resque/resque/blob/a3a66389618b830de0e6acf862b0dc9fde05cf49/lib/resque/thread_signal.rb#L2), but it's fine. This wasn't all roses: I cut my teeth in open source on a project that was deeply tied to Ruby 1.8 internals, and never quite was able to port it. It died. I still have feels... As for Python, here's what I've heard from people. Again, I was less involved in this one, so these opinions may be "wrong", or maybe slightly inaccurate. But regardless of their absolute truth, it's how a lot of people felt. "Python 3 has no compelling features for me. Python 2 has some warts, but I'm okay with them. Most of my dependencies don't support Python 3 and have no plans on doing so any time soon. If I have to do the work of a port, I might as well look at other options, and frankly, porting to other languages is more compelling than porting to Python 3, which is effectively another language. I like Python though, so I'm going to stick with it until it's officially EOL'd, and maybe they'll bump back the date again." You had nothing like this sentiment in Ruby world. Or rather, it was clear that if you did, you were in the minority, and you _did_ just port to another version. Twitter, for example, had their own version of Ruby 1.8, "Ruby Enterprise Edition", that backported some of the interpreter improvements from 1.9 back to 1.8. But instead of moving to a new Ruby, they moved to Java/Scala instead. Ruby lost some users, but it gained a lot more too. Anyway, today, Ruby has grown up a little, and now is pretty good at backwards compatibility. The project knew that it couldn't make that kind of change again, and so 1.9 -&gt; 2.0 was a fairly seamless transition, and while Ruby isn't 100% backwards compatible, it mostly is, for most users. And that's what really counts.
Not quite. `mem::uninitialized()` just says to will a variable into existence without making any guarantees about what's stored in it. In this case, `statvfs` clobbers existing contents of the memory pointed to by its second argument, so leaving them uninitialized before calling it should be fine. You could instead use `mem::zeroed()` as retep998 suggested above to write zeroes to all the bytes. Or you could do the same by explicitly writing out `libc::statvfs { f_bsize: 0, f_frsize: 0, ...and so on... }` but this would be verbose and fragile: you'd have to list every field in the `statvfs` field, and that probably varies from platform to platform. `malloc` and `free` create and destroy (respectively) an allocation on the heap. The native Rust equivalent would be to use `Box::new(mem::uninitialized())`, which creates the allocation and arranges for it to automatically be destroyed when the variable goes out of scope. `Box` also uses `jemalloc` rather than the system allocator [by default](https://doc.rust-lang.org/book/custom-allocators.html), under the belief jemalloc is typically better. In general, use `Box::new` instead of `malloc`, unless you have a specific reason you have to use `malloc`. (One valid reason is that you'll be transferring ownership to C code which calls `free`; this will end in tears if the pointer didn't come from `malloc`. But that's not happening here; `libc::statvfs` isn't taking ownership of anything; it's just writing to the memory that you own.) I'm skipping the `Box::new`, just putting the pointee directly on the program stack. This is a bit simpler. It should also be faster (less bookkeeping, better memory layout for the CPU cache), though you'd have to execute this code quite frequently before you noticed the difference.
To elaborate slightly, Windows XP does not have certain features that std relies on, like certain concurrency primitives, and therefore, while newer Windows are tier 1, XP is tier 3. We try to keep as much of it going as possible, but it can't ever be tier 1. You could polyfill it sort of maybe but it wouldn't be the same.
What do you think about [this](https://www.reddit.com/r/rust/comments/5kgk4q/a_reminder_that_emphasizing_stability_too_much/dboaroh/?context=3) comment about how should an hypothetical Rust 2.0 be handled? I think you're right that ease of migration and library compatibility are the biggest blocks a new, incompatible version of a language need to face. Rust 2.0 -- if it ever happens -- can learn from those mistakes and deliver a much smoother transition.
Python was also used publicly by the OS and all manner of scripts. Compiled langages don't have public dependencies like that that they'll suddenly break.
Put all your actual code in a function `fn run() -&gt; Result&lt;(),YourError&gt;`, call that from `main` and handle error formatting &amp; display in main (if any)
&gt; it exists for good reasons Not really. It exists for historical reasons, and is now necessary for backward compatibility reasons :(
I describe a very basic form of the pattern I've been seeing in https://github.com/rust-lang/book/pull/351
Might be slightly more difficult in Rust, due to ownership. You would only be able to pass a reference to the closure, I guess. Though it could be mutable.
[removed]
Here's my main function in an application that uses Clap: fn main() { match Args::parse().map(Arc::new).and_then(run) { Ok(0) =&gt; process::exit(1), Ok(_) =&gt; process::exit(0), Err(err) =&gt; { eprintln!("{}", err); process::exit(1); } } } Where `run` returns a `Result&lt;u64&gt;`, and therefore, the standard error idioms all apply. No other place in the code calls `exit`. Every operation results in graceful termination inside this `main` function. I find it very simple and I think a framework for papering over this small `main` function is probably overkill.
Sadly, wrapping it up in `Mutex` doesn't actually changed anything: = note: `std::rc::Rc&lt;()&gt;` cannot be sent between threads safely = note: required because it appears within the type `std::marker::PhantomData&lt;std::rc::Rc&lt;()&gt;&gt;` = note: required because it appears within the type `api::GILGuard` = note: required because of the requirements on the impl of `std::marker::Send` for `std::sync::Mutex&lt;api::GILGuard&gt;` = note: required because of the requirements on the impl of `std::marker::Sync` for `std::sync::Arc&lt;std::sync::Mutex&lt;api::GILGuard&gt;&gt;` = note: required by `&lt;PYTHON as std::ops::Deref&gt;::deref::require_sync` = note: this error originates in a macro outside of the current crate
~~Ripgrep has the exact same main method.~~ I'm an idiot!
Isn't there a rule against meme responses?
The problem is that we cannot do it implicitly *only for std* without splitting the language into *for std* and *the rest*. And outside of std, we cannot do this even with specialization, because it would introduce ambiguities. With that said, a) is it so hard to write `#[derive(Debug)]`? I even literally just did this from my cellphone. OTOH, some projects (e.g. embedded) cannot pay the cost of additional debug code, so we shouldn't make the implementation mandatory.
Given that you are replying to its author, it might not be a coincidence ;)
The problem is that if I use a non-debug type that I do now own in a struct, I can't derive Debug for my struct. I have to manually implement it. Can be a pain.
Clap provides [`App::get_matches_safe`](https://docs.rs/clap/2.19.2/clap/struct.App.html#method.get_matches_safe) which returns a `Result&lt;ArgMatches, clap::Error&gt;` allowing you to do additional error handling like `ripgrep` does.
I should also say the [`clap::Error`](https://docs.rs/clap/2.19.2/clap/struct.Error.html) provides an `exit` method which does exactly what clap does by default: print an error message and exit gracefully. A full example would be let matches = app.get_matches_safe() .unwrap_or_else(|e| e.exit()); 
Ok, it seems that this is simply not possible in Rust by design https://doc.rust-lang.org/1.4.0/complement-design-faq.html#there-is-no-life-before-or-after-main-(no-static-ctors/dtors) But one might try https://crates.io/crates/lazy_static/
beginner question : I am writing a command line tool taking folder names as parameter. After some research, I came with the code below, is there a simpler way to get the command line arguments ? fn main() { let myargs: Vec&lt;String&gt; = env::args().collect(); if myargs.len() == 1 { println!("usage: picsorter &lt;directory&gt;"); } else { for myarg in myargs.iter().skip(1) { let mypath = Path::new(myarg); if !mypath.is_dir() { println!("'{:?}' is not a directory", mypath); } else { processfolder(mypath); } } } } 
In C, marking a free function as static means it's only visible within the translation unit. In rust, functions are private by default so it's approximately the same. You'll need to add `pub` in front if you want to use the function outside the module where it's declared.
ok, thanks
Yep! And they're both very incompatible with a large amount of Python code that was written for CPython, especially multi-threaded Python code. 
Well, if we only end up half as successful as C++, we'll be cheering and partying. In any event, one of the Rust themes is 'stability without stagnation' – and so far they've made good on that promise. Look at the awesome goodies we got in just the last year! W.r.t. C++, the standards committee has done a stellar job maintain ing the language, considering they'd painted themselves into a corner with being an almost-C-superset.
~~Oh, wow, yeah actually part of the reason I thought it was okay was apparently because [I modified it to support exactly what you describe](https://github.com/quodlibetor/nix-rust/tree/improve-statvfs), but I never PR'd it? I need to clean that up.~~ No, actually I did do it: the StatVFS struct itself [implements `for_path` (and some other convenience methods)](https://docs.rs/nix/0.7.0/nix/sys/statvfs/vfs/struct.Statvfs.html#methods) so you could do: `Statvfs::for_path("/tmp".into())` to get what you expect. 
That doesn't preclude diesel from introducing their own async code.
Sponsorship from Mozilla would certainly be appealing, if it could be made to happen.
My only real question is why? I mean it's great but it's not like Windows and Linux are going run rust horribly. Mozilla would just never allow that to happen I imagine. So what's the long term goal other than a really small usage window. Beyond Mozilla really wanting to support I don't see it happening. I mean even BSD doesn't get a lot of love and has larger goals than this. I just want to say I'm not trying to shut you or your idea down just think you need wider(and specific goals) to see much support beyond fellow tinkerers interested in trying their hand at an OS.
&gt; The problem is that we cannot do it implicitly only for std without splitting the language into for std and the rest. And outside of std, we cannot do this even with specialization, because it would introduce ambiguities. I wasn't suggesting it be done only for std, that would be largely pointless. Having said that, std already is it's own language since we can only derive from the specific std traits. &gt; With that said, a) is it so hard to write No but it starts to become a pain to write: #[deriving(Clone, Copy, Debug, Default, Eq, Hash, Ord, PartialEq, PartialOrd) On a dozen different structs. And this is before I have started in on the [newtypes custom derive crate](https://docs.rs/newtype_derive/0.1.6/newtype_derive/) like From, Into, Deref and MulDeref. This basically guarantees that upstream libraries won't have implemented the trait you want forcing you to wrap them and impl it by hand. It also largely kills the use of strong typing. Meaning people use int's and floats everywhere instead of defining specific units. This leads to things like people adding miles to kilometres which was the cause of that Mars probe crashing. Then there is all the stuff that can't be derived from. For example array's don't implement Index traits. There is a [FixedSizeArray trait](https://doc.rust-lang.org/core/array/trait.FixedSizeArray.html) in unstable, but it's waiting on generic ints. We really don't want Rust heading down the C++'s rule of 3 (now rule of 5) route. Where every basic structure definition is accompanied by a whole heap of crap you have to do. &gt; some projects (e.g. embedded) cannot pay the cost of additional debug code, so we shouldn't make the implementation mandatory. Shouldn't the compiler optimize out unused implementations? Dynlib's I guess would be a problem but that would be less likely on embedded and they are already going to be paying the cost of unused stuff if using a dynlib.
I am not sure how this kind of stuff works, but, would it be possible to get sponsored by a university as a research project? In exchange, you could teach an operating systems course, maybe even have students contribute.
As a outside observer of Redox it's been moving really fast as a project. I don't know if this is jackpot's motivation but "a modern OS written in a language that allows a faster development cycle, more contributors, and better security" sounds like something that should be developed, and a good description of Redox. On the other hand, I don't really see this as part of Mozilla's primary mission. A company like google that is likely to see a lot of benefits from a new OS would make more sense. Unfortunately I don't see Google as being likely to fund a project like this (especially when they already have their own new [OS](https://en.wikipedia.org/wiki/Google_Fuchsia))
Right, but they also have huge teams working on them, along with lots of hardware support. If you want a high level of security with decent hardware support, look into OpenBSD, and there are solutions on both ends of the spectrum. If Redox was at a point where it had software compatibility with something like NetBSD, OpenBSD or (if I may dream) Linux, I'd totally use it, but it's many man-years away from that without letting in less safe code (e.g. pulling in drivers from Linux/BSD). It's definitely an interesting project, but funding will be very hard until it's actually useful for a marketable product.
I agree, it is far away from being used on raw machines. However, in the virtualized world, we could compete with many other OS's in terms of footprint, performance, reliability, and security. It is this market where the earliest success could come - from a small system image that would be deployable on any major hypervisor to run contained tasks with minimal security issues. I would also like to work with other contributors to formalize our ABI, and perform formal verification on our kernel and critical services. Also, if we were to support the hypercall interface NetBSD uses, a number of drivers from NetBSD could be run directly on Redox. I do not believe that a project without sponsorship can compete on the raw hardware front, we would be able to experiment with more real hardware if there was budgeting for it.
I've been fighting the Dickens our of Sublime, VS Code, etc. to get autocomplete working on OSX today. I have racer and related all installed and working fine outside of VS Code or Sublime, but still don't have any autocomplete dialog for methods, or type information when typing the name of a variable. Is there something obvious I'm missing? My settings look as follows: { "rust.rustLangSrcPath": "/Users/jdonaghue/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/src/rust/src" } ..with the Rust VSCode extension installed, and it seems to recognize all of its binaries. But no luck. I'm sure I'm foolishly missing something obvious. 
What's the rust way of accessing `String`s and `str`s by index? When I try `some_string[index]` rustc complains with the E0277 error and `--explain` doesn't help. More specifically, I want to access the last character.
1 and 2 are pretty much, by far, the biggest factors. A quick example right in the README is always ideal for me, and then I can jump into the docs and have a bit more of an idea of what to look for. I wonder how much 1.0 matters for most crates. I have a few random crates I've been meaning to push to 1.0 but just haven't gotten around to it. Coming from Python, I've used so many &lt; 1.0 packages without worry, I wonder how other people think of this. I'd definitely care for something really major like my HTTP library, Json, etc but for 'google safe browsing API client', a ~100 LOC project, not sure I'd really even look at the version number. 
Redox seems like it might be suited for [YC-Research](https://ycr.org/), might be worth contacting them. (I'm in no way whatsoever associated with them, I don't have any information except from reading what YC has posted publicly about whether or not Redox is something that will interest them).
I am asking for sponsorship - the burden of proof of benefit is on me. Don't take what NetSage said too harshly.
There hasn't been news posted on the site since September. When will there be an update?
No. Redox has an ABI mostly designed around capabilities. I want to formalize this ABI. Redox also has a namespace system that allows for the creation of OS-level virtualized zones where individual applications can be executed with filtered access to the rest of the system. It is trivial to use, as demonstrated by the `contain` program: https://github.com/redox-os/redox/blob/master/programs/contain/src/main.rs. Redox namespaces allow for the implementation of `chroot`, `jail`, and `cap_enter` on Redox with a set of generic syscalls - `mkns`, `setrens`, and `getrens`. We could have an app format similar to `snap`, but it does not exist yet. There is an explanation of how Redox namespaces function [here](https://github.com/redox-os/rfcs/pull/4).
i'm trying to do that too! and i have the same problems using byteorder also tokio-core read_to_end blocks infinitely.
Thanks! That sounds interesting. I will have a closer look.
Try this: some_string.chars().next_back() which will get the last `char` in the string, or `None` if the string is empty. Because of UTF-8, you can't simply index into a Rust string and get a character; `.len()` returns the number of *bytes* in the string, but one character can be up to 4 bytes long. Instead, you have to decode the UTF-8 bytes into codepoints (characters), which is exactly what the `.chars()` iterator does. 
Try removing the last two directories from the path. I think it wants the `rustlib/src` path instead. I'm not sure if the path is supposed to have a trailing `/` or not, maybe try that too.
Proper web browser plans? Porting over servo perhaps?
&gt; I wonder how other people think of this. That's part of the point of the blog post: &gt; we ran a survey to find out how Rustaceans evaluate crates This **is** what people who want to use crates look for when deciding which crates to use. A similar dichotomy showed up on the RFC; there's a disconnect between crate *authors* and crate *consumers*. Part of this post is to help share the information we got from the consumers back to the crate authors. If you choose to cherry-pick the aspects of the post that resonate with you, that's fine, but you should be aware that there are other people who use other aspects when deciding on a crate. As a great example, recall [Rocket](https://rocket.rs/). That's an *amazing* website and it makes me want to use it, even with some of the inherent downsides.
You're free to give them your money. I'm not looking for an insanely detailed break down or specific time table just the path of the OS. If it aligns with something I'm willing to support I'll put my money into it too. But if it's going to end up on kiosks or something sorry it does me no good. Remember he's trying to turn this into his full time job and I imagine he wants to eat more than Raman. Not to mention taxes, health care, and any other self employment costs. So the support needs to be pretty big. Also yes of course it's obvious that it's behind which all the more reason people need a reason to back it. Creating an OS and a successful one at that is no easy task. Why do you think there are so few real options for most things.
I'm not exactly an expert here, but my understanding is that Minix has found a bit of a niche in education and research *about* OSes. That's a decent way to get funding from universities, government organs, and the like, perhaps? Even if being stuck in academia isn't the ultimate goal, there may be ways of engaging with some researchers/educators as a way to tap into funding.
Ah. I'm traveling so I went through the post fairly quickly. Is the point of low version crates outside of the "big" ones discussed? I hadn't noticed that. Edit: I just reread it and I don't see that point addressed at all. The reason I'm asking is not to cherry pick. I've developed and used crates so I'm trying to provide feedback and figure out if others have the same view of semver for large crates as they do for small ones.
There's nothing wrong with an internal dependency having whatever version you want. If you aren't exposing any types or functions directly, then you can change out that dependency at any time and your users are none the wiser.
Yes, porting over servo. The only thing I think will be difficult is the graphics functions. Currently, [webrender](https://github.com/servo/webrender/) needs a full featured `OpenGL` implementation - we may be able to do this using [OSMesa](http://www.mesa3d.org/osmesa.html)
I think you could use https://crates.io/crates/futures-cpupool and not write this code yourself. Not 100% sure though.
If a crate wants to ensure that it compiles on a certain rustc version, it'd be prudent to include that in its CI.
cpupool is for offloading blocking work onto a threadpool, I'd say this is overall a good solution, I've done something similar in a tokio-based project I'm working on. It would be nice if something like this was built in ;) (although my solution is a little less fancy, I just have incoming Tcp connections and hand them off to random worker threads) *EDIT:* This post has inspired me to extract my logic for this into its own crate! https://crates.io/crates/tokio-pool The Documentation link should go live once docs.rs is done building the project
Absolutely, but that doesn't stop all the consumers of the crate from experiencing breakage during the period. Also, many CI systems are set to trigger on code changes for just the project in question. In this scenario, an updated dependency causes the problem, outside of the repository.
Ah. What I was trying to get at is that not all crates are the same. So for example my priorities for a large. Rate are different than from a small crate. So 1.0 is very important to me but if I see a random small crate that does what I need I probably won't care. I don't think anyone was lying or anything like that. I was wondering if others felt that the split exists and the priorities are the same. This is something that the post doesn't really cover - maybe because the split only exists in my mind and others don't see it that way. When I say "most crates" I also was meaning "small random crates" which I assume make up the majority. 
Use [duct](https://github.com/oconnor663/duct.rs) or its lower-level backend [os_pipe](https://github.com/oconnor663/os_pipe.rs).
Did you make sure to download a new copy of rust-src and properly configure racer to point to it? (Its probably in a path variable in a plugin config somewhere). All of this should be listed in the setup instructions for whatever plugin you are using. That was my problem when I first set it up, so I hope that helps.
No such luck :/
You seem to be within the very top tier of software developers out there.. how are you not getting job offers for absurd amounts of money? Like I also love my hobby projects but what I am wondering is how you can turn away from the thriving tech market to work on a personal project. Especially considering what I image your market worth is
I haven't used vulkano but I doubt that it is that high level. The choice lies most likely in the matrices that you use. Note that most matrix libraries in Rust where designed for OpenGL, where the (0,0) in image space is the bottom left, in vulkan it is the top left. So you might have to flip the y scale, or use your own stuff. Also the z value can only be between 0 and 1 not -1, 1. Not sure if any matrix libraries out there even support that.
Yes, I do have simple Y flip code that I copied off the example. Do you know any OBJ import librarys that support vertices normals?
Probably https://github.com/PistonDevelopers/wavefront_obj
BTW, RustyCode has not been maintained for a couple of months. [A fork of RustyCode](https://marketplace.visualstudio.com/items?itemName=kalitaalexey.vscode-rust) fixed some bugs, and it automatically finds rust source installed with rustup when you leave `rust.rustLangSrcPath` null.
I'm glad it's free software. I hope you find funding. But you didn't talk about an obvious possibility: proprietary derivatives, because the license is MIT (a permissive/noncopyleft license). OSX came from turning a bunch of noncopyleft free software into proprietary. More recently, many companies that use android release all the noncopyleft bits as proprietary. Some of them have invested in alternate oses, for example https://en.wikipedia.org/wiki/Sailfish_Alliance. I don't want to donate money to help make what ends up as proprietary software in a device made by the next apple or samsung. I think users deserve the freedom to study, modify, and share code on their devices. If it was copyleft, I would donate money and effort to improve it. If I had enough time, I would make a copyleft fork right now, but I don't. Even if you had an option to fund just copyleft parts, like gcc, or cc-by-sa documentation, I'd put some money in. Related: https://www.gnu.org/philosophy/why-copyleft.html, https://www.gnu.org/philosophy/freedom-or-power.en.html
Thank you. I certainly respect the user's freedom - there are some practical reasons to use MIT over GPL. One of them is the ability to link with free software under GPL-incompatible licenses - the issue with ZFS on Linux being an example of incompatibility in the past. Due to the micro-kernel nature of Redox, GPL code is welcome and utilized in many places. The license of one driver, service, or program does not typically affect the license of another. The amount of code licensed under a specific "licensing domain" is typically on the order of thousands of lines of code for our projects. I have a few questions then, open to anybody: - How many people would only donate if the code were GPLv3? - How many people would only donate if the code remains MIT? - And, if willing to specify, how much would your donations be? **EDIT:** To anyone wondering, a change in license would require agreement among all contributors, and would only be done if the current license were negative to the needs of a specific project. There are a few dozen original projects underneath https://github.com/redox-os, all of which are licensed MIT at the moment. Changes would be done on a project by project basis, and would involve public debate. For now, things will remain MIT.
I think there's plenty of room for a very low-level, highly parallelized runtime and browser for mobile phones. And the security aspect is appealing. And neither Swift, nor Java.
Please.
Whenever I work with deserialization (or validation of external data where I may need to retain support for older schemas), the first thing I always look for is a schema versioning and migration strategy so I can dogfood on my rapidly-changing prototypes and so I don't have to worry about getting caught with my pants down when consuming someone else's data structures if they change them. For example, for JSON, I'll use a top-level integer field with a name like `schema_version` which should control which version of the loading/validating code is applied. That tends to mean that I either have to write the top-level handling code manually or put the top level of the actual data inside a key within the real top-level mapping.
Without answering your question directly I will say that I remember SDL having a donation page and having a very specific breakdown of every donation, how the money was used, and whos name it had. It bothers me to see general 'donations' that go into a mystery box where it is unclear how the money is being spent. That being said, I don't think the GPL is always appropriate, but for an OS it might be. One example is WhiteDB, a simple key value store that is GPL. It would be used by linking it in directly, yet GPL makes it useless for non GPL software. Linux as an obvious counter example has shown that since there is a separation between the OS an programs, the infectious nature almost always works in its favor.
That's like asking woz why he quit HP.
I don't know of any projects, but most current non-Rust VM host programs are fairly secure. I don't think it'd be possible to make a VM host at all with 100% safe rust code, but it would be an interesting project to write one in rust. I would think in order to be a fast, full emulator, some unsafe code would definitely be required.
&gt; I don't see people forgoing type safety for want of From impls. I agree. After all the whole point of strong typing is to increase type safety. But other than From, it would be nice for newtypes to be practical. As they are now for most use cases they seem to be more work than they are worth. Currently you have to manually derive Debug, all the common arithmetic operations and things like Clone, Show and Hash. Every single time. And then there are the things that just don't allow a derive. Basically you want all of the default behaviours of a primitive type except it should be treated like a different type, no mixing between them. Having some kind of single derive that groups all the common stuff in together would be handy. Even better if there was a way to optionally relax some of the strong type restrictions to allow some implicit casting to make less syntax overhead. While still increasing type safety above the standard primitive types. For example it would be handy for a newtype based on an float64, to be able to go between a float64 and that newtype without casts. But have it avoid casts between another newtype that happen's to also be based on the float64. Could allow `some.x = 0.0;` instead of `some.x = SpatialUnit(0.0);` But prevent `some.meters = some2.seconds;`. Maybe some of that is already doable via the Into/From trait's, I haven't looked into them too much so I don't know how many levels they convert through. But it would still require them to be implemented. &gt; * typenum has compile-time integer types. Yes, it's a hack, but it works on stable, now. With [generic-array](https:crates.io/crates/generic-array) you can have compile-time sized arrays that index. I think I saw generic-array a little while back although I missed typenum. But I'm not that comfortable with importing core language features from 3rd party crates. &gt; Perhaps we shall hasten the advent of macros 2.0 so that we can auto-derive anything per crate with one attribute. Hopefully ☺
I thought this was a nice summary of how to write good APIs in Rust. There were a few gems I'd not known about, like `Into&lt;Option&lt;T&gt;&gt;`.
This could be really helpful for preventing shell injection attacks, and for writing Rust applications that act as shell scripts. I'll be trying this out in a throwaway project soon, thank you!
There has been some work on storing strings effectively, dictionaries have a fairly efficient implementation but the compiler and interpreter itself are very straightforward. If you want optimizations, you need to look at PyPy which has a lot of them. 
The title has a click bait feel to it, but the article is not a click bait piece. I really think that it deserves a better title than something so formulaic. Titles like these usually announce low quality content. Just removing the number makes it better already.
Thanks for the suggestion, I'll copy that over to the README, and yes I should add some tests ;)
While it's not written in Rust (and thus not "safe"), you may be interested in [VMM](http://man.openbsd.org/vmm.4) from OpenBSD, as they take security and audits *very* seriously.
I had a really old version it seems, 1.2.10, although it doesn't seem like I installed it very long ago. Updated to latest, works perfectly!
Alternatively I would recommend using [docopt.rs](https://github.com/docopt/docopt.rs). It's much lighter weight (and less verbose) than clap.rs and it's very easy to use. You just create a help command and it parses the arguments into a struct for you.
Mostly personal taste. Though, I should have put an asterisk there, because of my *actual* preference: At this stage in my programming life, I generally most prefer one or two returns: Either a single return point, or a successful return and a generic failure return. Note: My actual job is in C++, so I've been favoring `get` functions with a `bool` return (success/failure) and a reference param for actual output values. Recently because of Rust, and because of adaptations of some Rust patterns in C++, I've started to warm up to early returns, as long as it's only for error cases, and before any substantial logic. Mostly, because of, as you said, nesting issues. I'm at a turning point in my life here, so I'm not solid on either side. I really like the former, because it makes debugging easier with only one or two possible return points. I'll admit though, as long as I follow my current standards, if I only return early for error cases, then neither methodology should be more adventageous than the other. So, recently, I've been using the latter case more frequently, so as to reduce nesting; I still feel a little dirty doing that, but the lack of (deep) nesting is definitely more ascetically pleasing. 
 extern crate wavefront_obj; use std::fs::File; use std::io::Read; use wavefront_obj::obj; fn main() { let mut buf = String::new(); File::open("model.obj").unwrap().read_to_string(&amp;mut buf).unwrap(); let objset = obj::parse(buf).unwrap(); } https://github.com/PistonDevelopers/wavefront_obj/blob/master/src/obj.rs#L13-L37
I expected a connection pool library. I guess the API of such a crate would look quiet different, so it might not make much sense in including it, but maybe it would. Having said that, there are some advanced features common to a thread pool and a resource pool. * automatically adapting the pool size (based on demand), * grouping some pool members (for resources on one thread, for threads on one cpu core). And, it might make sense to enable coupling these two.
You can (and probably should) relegate your lower level socket processing to its own thread and not worry about multithreading at that level, since context switching there (without thread affinity) can result in lower IO performance. The goal of non-blocking IO is to maximize timeslice usage on a single thread. For a game server it is unlikely that you will hit a point where you need to process multiple sockets in parallel before game logic becomes the bottleneck. You can use a stock standard library unbounded mpsc to send messages from your tokio event loop to another layer of your application server which itself may be multithreaded. That will probably be easier to handle and ensure separation of concerns. Pass around clones of the `Sender` to your Futures running on the tokio core. https://doc.rust-lang.org/stable/std/sync/mpsc/fn.channel.html
Sensibly enough `Vec` turns into a glorified counter when containing zero sized objects. It the size is zero it sets the capacity to `usize::max_value()` and never allocates anything.
I'd do next = match (sector, mag(sub(e, player)) &lt; mag(sub(s, player))) { (0, true) =&gt; e, (0, false) =&gt; s, (1, true) =&gt; w, (1, false) =&gt; s, (_, true) =&gt; w, (_, false) =&gt; n, };
&gt; People upgrade even slower to avoid having to deal with incessant breakage This is some of my experience with GHC. 
I can't help think the ones expanding a compressed blob are somewhat missing the point (I'm looking at you Python). The C version is also quite obtuse - I stared at `dict[*c - 95]` for quite a while before I figured it out. So whoever has a go at the Rust version, don't do that!
I'm glad you liked my little list! :) If there is anything I missed, or you came across some cool new trick to make your Rust code even nicer, let me know and I'll gladly add it (or open a PR, the site is hosted [on Github](https://github.com/killercup/scribbles)).
Absolutely—it's meant to display idiomatic solutions in each language, and all of the code golfers on there don't seem to get it. From their main page: &gt; The idea is to present solutions to the same task in as many different languages as possible, to demonstrate how languages are similar and different, and to aid a person with a grounding in one approach to a problem in learning another. I had started writing a Rust solution before realizing that since I'm entirely new to languages with functional aspects, it was most certainly better to leave it in the hands of some true Rustaceans.
I just chimed in on your Patreon with a small support, I hope we can make this happen. I think MIT is a good choice, GPL or Apache would be fine as well.
An ethereum contract that pays per-commit? :P
It would have been incredibly inconvenient to recreate all the functionality of `mime` in my own crate. The API design is fine, the mistake was going to 1.0 before the chief dependency had stabilized. 
This was a great comment. I had HN opened to this discussion all day and finally got around to reading through more of the comments only to hit burntsushi's response to lossolo's inflammatory Go vs. Rust "challenge".
You may also want to check out [Learn You a Rust III: Lifetimes 101](http://pro.theta.eu.org/2016/04/16/lyar-lifetimes.html), which details some of the problems I had when learning lifetimes, and how to solve them. :)
I would only donate if it was GPL, don't know yet how much. 
seL4 is only for single-processor systems and does know about IOMMU yet IIRC …
Just my two cents, but I have to say I'm very glad that you are using the MIT license instead of the GPL. Although I understand the philosophy of copyleft, all my experience has taught me that totally free licenses like MIT are more practical and lead to fewer problems (and headaches) in the long run.
Maybe the problem is security - in which case Redox needs to be designed to be trivially updateable from the ground up: stable driver ABIs &amp; APIs, Microsoft-level backwards compatibility, ChromeOS-style A/B booting and so on. Otherwise you'll end up with Android's poor security, where bugs are technically fixed but effectively exploitable for years because no-one can get the fixes.
Here's my iterator attempt [link](https://is.gd/ewOBVd), probably better to use indexes :)
there is nothing much to gain with a Vulcan software renderer. As far as i know there is no software rendering equivalent of Mesa for Vulkan out there.
This is a fantastically detailed and thorough guide. Is there a place we can link this as a permanent resource? Sidebar or wiki or something?
Porting mesa itself over is probably an impossible task, as it's very dependent on linux drm drivers? So in the future you'll probably want to create your own mesa-like drivers?
A rust based OS will also have security flaws
 error: expected one of `(`, `+`, `::`, `&lt;`, `where`, or `{`, found `=` --&gt; src\main.rs:129:53 | 129 | pub fn next_moves&lt;'a&gt;(&amp;'a self) -&gt; impl Iterator='a { | ^ Also, my understanding was that lifetimes didn't apply to objects returned by value, although I might be wrong there.
Small thing: instead of needing to derive `PartialEq` for `Action` in order to compare against `Action::Die` later on, you can do `if let Action::Die = a.1 { ...` (or use a plain match statement, which `if let` is just sugar for iirc).
I cannot speak for him but i see that topic out of scope for a single person to handle **besides** programming an OS. i may be wrong though and porting Mesa is not that hard – creating something like Mesa, i hardly doubt a single person can do that in a time span that would be useful. 
Thank you!
Yes, speaking X11, i only get to send the setup request but when it comes to reading the response it's hard to do because when i use tokio_core::io::read_to_end it blocks forever and i can't do anything
You need to add `#[derive(Copy)]` in front of the definition of your struct for this to work.
Using a CpuPool instead of my own pool was surprisingly easy, I had seen the library but didn't think it was fit for my purposes. Thanks for the sugestion, I also understand futures a little better now 
Can you explain to me why CpuPool is not enough? It seems like it does what my own pool did, except it has no knowledge of Tokio. But I might be missing something, async io is pretty new to me. 
Well, the push for a microkernel should help there.
Yup! I actually really like gitlab's built in CI. I was going for the easiest options, I'll edit the post to mention the alternatives as well.
The question of how has already been answered so I thought I'd chime in with the why. The reason why you can't index strings is quite frankly because text is hard. It all comes down to how we should representing characters. In the days of ASCII, every character was represented by a single byte. This solution yields nice and compact strings and indexing them is done in O(1) time. ASCII only utilizes the last 7 bits of each byte in order to be agnostic between signed and unsigned chars meaning that there are only 128 possible characters. Unfortunately, as computing became more and more global, ASCII became increasingly less optimal due to the sheer number of non-latin alphabets out there. There are a few solutions. One solution is to simply widen the char representation, say, increasing it from 1 byte to 2 or 4. This keeps the O(1) indexing from ASCII but it means that there is lots of wasted space. "Hello" goes from being 5 bytes to 10 or 20 bytes depending on whether we are using 2 or 4 byte chars. UTF-8 (and to a lesser extent UTF-16) allows for a larger character set without wasting unnecessary space by allowing many (sometimes single byte sometimes multibyte) codepoints to be combined into graphemes (a single, logical character). UTF-8 is compact like ASCII and there is an added bonus that valid ASCII text can be read as valid UTF-8 text. The downside however is that the definition of indexing becomes somewhat unclear. Do you want to index by individual bytes, codepoints, or graphemes? If it is the latter, indexing is no longer O(1) but rather O(n) since each grapheme could be of variable width. If you are sure your text is ASCII you can use the `as_bytes` method to convert the string into an `&amp;[u8]` and index that way. Otherwise it is best to use the `chars()` method and manipulate the yielded iterator.
Ditto here! I really want to start helping with redox (day job C programmer with quite a bit of linux kernel experience); have too much on my plate!!!! ARGGGHHHH!
Nah, it just means *those* dependencies should also be at versions greater than 1.0 as well....
I will donate to the project if it starts to be GPLv3+ (I'd be eager to send 15$). If donations would seem important to Redox development, I'd send more from time to time.
this should be in the "rust platform"(RIP)
I smiled. The title case made it pretty clear. Next time: "You Won't Believe These 6 Easy Tricks Billionaires Use to Make Their Crates More Awesome!"
Oh! I guess you got me. Glad you're not a buzzfeed writer.
I'm a friend of KISS, why invent another DSL if you can take advantage of your language/compiler? I mean you would have make sure that the users of your framework get sensible errors in case they get something wrong for example. Its hard to beat the rust compiler here. There would be also an unnecessary learning curve for newcomers to your framework. If you'd rely on pure rust (no macro magic), you can safely assume that your potential users are already familiar with the language (or at least in the process of getting familiar with it). I'm also not sure how well the tooling (racer, RLS and so on) integrates with macros, since I haven't used rust in a while now. Therefore I'd stick with some basic traits and types as building blocks and focus on extensibility. I assume this crate would typically be used to provide direct feedback in some kind of UI or CLI in response to invalid user input, so I'd care to include some support for localization (e.g. through external crates).
A good article, but "PLT" is never defined in the article... I had to google it to find out that it means Programming Language Theory.
May I suggest https://github.com/sector-f/wallst (written in Rust) instead of feh?
Rust makes it easier to write correct and readable code, and getting both at the same time is not a coincidence. The very mechanisms of ownership/borrowing (a tight control over lifetime, aliasing and mutability) enforce a certain simplicity in the data-flow of the resulting software that you *could* get in other programming languages, but generally do not because the language was more lenient and you got away with a more convoluted flow. Have you ever had to debug a `ConcurrentModificationException` in Java? This happens when you modify a container being iterated over. When you have a chain of callbacks/observers, it's incredibly easy to accidentally have a circular reference leading to this exception. In Rust, to get to this situation you have to use `RefCell` or equivalent, and it should make you pause.
Hm, demand is a little harder to track since tokio doesn't provide any kind of metrics for how much time a core is spending idle. If an API like that was provided that's definitely something that could be done!
I apologise for the typo in your nickname. Now, every time i reread the title in my mind, it is in a Sean Connery voice.
As an example, I recently implemented an optimization in a Rust project where I precompute some data upon struct creation, but the function to compute that data calls methods defined on the struct. In other languages, you would just leave a null field in the struct and fill it in later, and rely on programmer discipline to not get NPEs. However, doing so is unidiomatic in Rust. Instead, I split the struct into two seperate structs, the later one containing the first one plus the precomputed data, and implemented Deref from the second to the first and defined only the methods that require the precomputed data on the second struct. Doing this is more work upfront, but it means that the compiler is statically checking that methods which access the precomputed data can only be called after the data has been computed, and the whole thing is immutable. There is no possibility of null pointer exceptions like there would be in lazier designs. In general, programming in Rust is a lot more work because you have to restructure your code to avoid mutability and aliasing and optional values, but the resulting design is much less error prone. You don't technically *have to*, since you could just throw everything into an Option&lt;Rc&lt;RefCell&lt;_&gt;&gt;&gt; or whatever, but doing that brings a lot of syntactic overhead and gives up the benefits of Rust's type checking. Rust's syntax nudges you towards designs that can be statically verified, whereas other languages throw around null pointers willy nilly.
I'm sick today so I may try to knock out another blog post about this. I've been meaning to write about the non-security aspects of rust that I find appealing for ages but it's hard because... there are a lot. The big thing, and I realize this is something that 2017 is supposed to be about, is rust as a tool for productivity. It's hard to really say "I've been x more productive than if I were writing this in C++". I write Java and Python professionally and feel strongly that the problems I run into every day would be far less frequent with rust - but I'm reluctant to post something so closely related to my professional work (especially in a negative light). So I have to talk about why I like the language in isolation when really on a day to day basis I like the language relative to others, because of real problems I feel I could solve with it. That's made it harder to write about. I think if we want to show that rust is productive we need people who use rust in production to talk about it, first and foremost. I use my coworkers as a bit of a litmus test for good rust marketing - they respond far better to posts or content driven by a real company doing real work with rust, as opposed to "rust is x or y" posts. They also responded very well to ripgrep's announcement/ release - a real, productive tool aimed at programmers, showing the strengths of rust. Barring that, especially since it's a very difficult thing to generate, I'm unsure of what a good format would be. I'm planning on writing some posts but I feel they're very "Rust has this cool feature/ pattern" and won't really be swaying many people. Regardless, I strongly agree with the premise that focusing so much on safety / replacing C is not the way to go anymore. tl;dr idk but I'm gonna try to blog edit: ok i did it https://insanitybit.github.io/archive
Totally :)
"I don't write C++ so rust isn't for me". I think many many people have this thought. Some may have even tried to learn rust and walked away with this thought. Perhaps there should be a "Rust for script kiddies" or "Rust for the rest of us" style book that focuses on the benefits other than low level programming. If a scripter is tired of asking their users to also set up their environment and hey want a binary file, they're basically gonna look at golang or rust at this point.
If you wanted to compare notes, I threw my code up at https://github.com/mokomull/x11_client and an example application at https://github.com/mokomull/snake. Blocking forever is what I'd expect from read_to_end: that would read everything until the X server disconnects the socket. I haven't come across any events that are not 32 bytes yet, so I unconditionally read 32 bytes from the socket. I should probably give the protocol spec a closer read before I make this too generic.
There's typo in /u/mutabah's post - should be `Iterator+'a`, not `=`. Regarding your also, you can return an object with lifetime just fine. Here's example: https://is.gd/JKu7hJ
I've been toying with the idea of doing a presentation on Rust at work, and my focus, as I envision it, would be on what kind of code you can write with Rust. Not low level or high level, but that you can write this code where it is so much harder to make many common mistakes. In my day job, we use Java and its performance is basically good enough, so it's really the productivity angle I imagine as the big selling point.
Literally didn't even notice it until I saw this comment. :P You could have gotten away with it!
Here are the reasons it appeals to me as a Python programmer: * Type system massively reduces the amount of unit test code I have to write to satisfy my perfectionism. (Especially gotta love Result, Option, enum, and using ownership to enforce correct state machine use.) * Ability to write fancy abstractions that get optimized out during compilation. (I'm **still** getting used to how freeing it is to not have to worry about this in what would be concerningly hot code in Python.) * Compiled size. (Under 300k for a clap+musl-using "script" with UPX and nightly-available features like `opt-level=z` as opposed to multiple megabytes for a UPXed and AdvanceCOMP'd frozen Python bundle.) * Ease of deployment. (nothing beats a pure-Rust program targeted at `i686-unknown-linux-musl`)
Hey thats awesome im going to start using that personally thanks! As for mookaite i think im going to give the user the ability to pick the 'wallpaper set' command through an arg. 
Damn.
I have a tough time putting into words why I use rust, but here's a try. Rust is a tool for writing high-quality software. When I say high-quality software, I mean software that handles error conditions properly. Software that runs quickly. Software that doesn't crash. Software uses your hardware to its full extent. Software that doesn't leave your system exposed. Software that does what it's supposed to. Can all this be achieved in other languages? Of course. But rust's unique features make it easier, and more likely. Rust is a better tool to write better software. 
Fantastic article, thank you!
Glad you like it :)
I typically explain that Rust's safety has side effects that are beneficial outside the obviousness of merely being safe. Namely, Rust's safety allows for migrating runtime checks into compile-time checks when constructing state machines around the ownership mechanism. Additionally, Rust's safety allows for additional compiler optimizations, because that safety can make more guarantees about the safeness of certain internal compiler flags. These have a speed benefit in addition to the already existing convenience benefits of not having to fight with broken code. I'd much rather fight a borrow checker than to fight through gdb's and lldb's to figure out why everything's totally broken. Then I go on to explain that there's a lot of great features in Rust that make it more convenient than C/C++ in a wide range of general purpose programming tasks. The pattern matching, sum types (Option/Result), error handling strategy, and my favorite, the Iterator trait. For the performance-minded C/C++ software developers, I explain that the safety that Rust provides via lifetimes and ownership allows me to comfortably perform extreme performance optimizations that would otherwise be incredibly nasty and error prone in C/C++ codebases. I can feel safe knowing that if it compiles, it's almost always going to work how I expect. Then there's the whole test-driven development mentality to Rust software development that Rust provides with `cargo test` and `cargo bench`, and data-oriented programming approach that Rust takes versus the inferior object-oriented approach via protocol-oriented programming (traits) to feature ad-hoc polymorphism and generics. It's a bit more complicated to explain that though. Then there's the whole community/tooling/documentation pitch. I think this is one of the more important aspects of Rust as it demonstrates that Rust has a future and is more than just a niche. It has momentum which cannot be destroyed. It's a language invented during the age of the Internet and takes full advantage of that. Rust does not employ guerrilla warfare tactics like other languages have done in the past. You can think of C/C++/Java/etc. as long-running empires. Guerrilla warfare-style tactics simply don't work against them. Emerging languages have always targeted C/C++/Java/etc. through guerrilla warfare tactics -- a loose community that mostly does their own thing. Rust is ambitiously establishing an empire of it's own through it's community -- a plethora of official projects and services: rustup, cargo, crates.io, docs.rs, users forum, internals forum, reddit thread, official documentation, docs team, an official book, GitHub hosting, etc. It's a recipe for success.
I think I love Rust because I'm a bad programmer ^^ I mean, most of the times I started projects in other languages, I ended up not wanting to touch them anymore because either they were sort of working but I felt like if I touched anything it might break everything, or there were some kind of hard to debug runtime bugs that didn't happen every time. I know there are other strongly statically typed languages with smart compilers but Rust is the only one I really used (I looked at Ocaml and Haskell but didn't go into them deeply) and while I confessed I yelled at the compiler a few times when I learned it (and still do it sometimes) it's really good to have most errors detected at compile time. I feel that Rust really helps make me a better programmer: I mean, yeah, I occasionally struggle with the borrow checker, but more than a few times I was like "come on borrowck don't fsck with me this is totally legit" only to realize no it wasn't (and maybe that's why my C projects sometime mysteriously crashed :D). Another thing I love with Rust is its balance between ease of use and fastness. Not only there are lots of high level features that are really cool in the language, but cargo/crates.io makes publishing a package very easy; while dynamically typed languages might seem easier sometimes I feel that if you are not rigorous (and I'm not, see the beginning of this comment :p) it's difficult to buy medium-scaled projects in them; and at the same time Rust is fast, and even when performances aren't critical, well, it's always good, plus in my experience some thing that isn't performance-critical can quickly become it (e.g. it doesn't matter if it takes 10ms or 100 when you run something as a command line, but then you're like "hey I could turn that into a webservice too" and it starts to matter). There are a few languages I am quite familiar with, and some that I really like, but Rust is the one I found the most empowering.The problem with "safety" is that in programming when I read that word I tend to think that it's something for low-level stuff or things that can have security issues and I don't usually need that, but in the end I think that safety also leads to confidence: my code might not be best written, but with the compiler I can be confident that it's relatively correct (obviously it can't catch everything but well), which isn't the case with most other languages.
Yes, it has been turned on in [libcore](https://github.com/rust-lang/rust/blob/master/src/libcore/lib.rs#L67) and [libstd](https://github.com/rust-lang/rust/blob/master/src/libstd/lib.rs#L217).
&gt; Rust for script kiddies Can we please. I (think I) am a pretty good programmer, but many hours into it I'm still confused about why and when, for example, `panic`s are allowed.
I'm currently reading the references and borrowing part of rust official book and i'm a bit lost, i understand the concepts but the code doesn't really makes sense to me some times, examples: fn foo(v: &amp;Vec&lt;i32&gt;) { v.push(5); } let v = vec![]; foo(&amp;v); I know that this code is not valid, but even it it was (by using mut) wouldn't you have to use *v.push(5);? Isn't v some kind of pointer? Or is rust smart and v is already the Vec starting at the address that was passed as argument? Also why does passing a variable as argument to a function considered borrowing it? ex: this code is invalid fn main() { let mut x = 5; let y = &amp;mut x; *y += 1; println!("{}", x); } Shouldn't x only be borrowed if i used &amp;x as parameter? Edit: Yeah rust is smart with this borrowing thing, second question remains
/r/playrust
I thought this was an interesting exercise between two proofs for university. Were you thinking of an interface similar to this? https://is.gd/k7P6X2 Of course, one would have to get rid of the allocation (`Box` inside `ValidationError`) and accept `&amp;str` parameters as well.
&gt; to release a 1.0 version of a crate if any of its dependencies are still in their 0.x versions, which is still a very common case in Rust. Shouldn't this be okay if the dependencies aren't exposed? IIRC cargo treats `0.x` updates as breaking so they won't automatically get bumped with a cargo update.
Speaking of non-programmers, nobody cares what language you use. All they care about is the results. What Rust really needs is a killer feature. Not a language feature. Something Rust does uniquely well, and would require non-trivial work to port to $language_we_know_already. For instance, Ruby had Rails. Without Rails, I've never heard of Ruby. Python latched onto machine learning and is riding that wave. Rust needs its "thing."
Fortunately, this is no longer true! SMP support was recently added to seL4, and I believe it does support IOMMU. x86_64 support is also a recent addition - the [seL4 roadmap](https://sel4.systems/Info/Roadmap/) has more information.
You emphasized the C/C++, completely skipped out on ML. Which I think is a huge part that people miss out when "marketing rust." IMO, one of the biggest strengths of rust is the *abstractions* it provides. The HM type system, the functional semantics, etc. The ML heritage makes Rust one hell of a beast at abstraction -- and that makes it an extremely powerful language. Idegaf about low/no cost abstraction. That's just a cherry on top.
I managed to work out that shortly after posting, but ran into the following: | 128 | iproduct!(0..BOARD_SIZE, 0..BOARD_SIZE, 0..NUM_DIRECTIONS, 0..NUM_MODES).map(|x| self.apply(x)) | ^^^ ---- `self` is borrowed here | | | may outlive borrowed value `self`
It's impossible to get Unicode terminology right from memory alone. I'm guessing codepoints are the actual bytes themselves. 
[Creating a command-line tool](https://github.com/sethlopezme/strez/tree/develop) to take string resources in CSV format and convert them to their Android/iOS equivalents. Not really cool or anything, but it's helping me learn Rust. I'm hoping someone will critique it when I'm done so I can improve.
In my case, the dependency that got upgraded (manually) was exposed, so it broke downstream usage. If I were to upgrade it properly I would have had to bump my crate to 2.0, and then to 3.0 later, and so on. I don't want to see that become commonplace in the ecosystem.
It's useful for debugging! However, if I want to release a library I'd try to avoid it. Like most software development, it depends.
I've been considering the idea of trying out the ruma homeserver. What's the status? Is it usable for playing around?
They have different ranges; unicode scalar values are a subset of all valid codepoints.
As I continue to preach: If C is like playing with knives and C++ is juggling chainsaws, Rust is like parkour suspended from strings&amp;wearing protective gear. It'll look ridiculous at times, but you'll be able to do all sorts of cool moves that would otherwise be damn scary or outright impossible. You'll have so much fun you'll start trying to do it in other languages, too. And many of us never look back. Especially when we hear stories about knife players ending up with a bleeding heart, and that one chainsaw juggler who lost their poodle. At the beginning, you fear the padding will hinder you, but by now you learned that its clever design allows you to move as fast as without it. A bit faster, actually, since you're no longer on the lookout for ledges you might stumble over. Also you get new improved gear every six weeks, and between this and your newly built muscles, you start feeling like a super hero. This feeling is amplified by the community, which simultaneously does awesome feats and is really humble and open about it (you're by now accustomed to people being good at concurrency, and get slightly annoyed that your snake-charming friends insist on doing everything one step at a time). You also met some folks you wouldn't have expected here, from a number of dynamic languages, braving the learning curve to descend into low-level programming, usually singing Rust's praises with unreal sounding benchmark comparisons. You start looking with pity at your knive- and chainsaw-wielding friends. You see both their bruises and denial about said bruises. You'd want to offer them some of that awesome protective gear (by now you no longer feel the strings, because they seldom get taut), but you know the answer already. Poor folks. We are super heroes. We are legion. Join us! 
And I just wrote this on my phone.
Sure thing. Just tell us when you're ready. Also you may grab a nightly Rust and `cargo install clippy` on that, so you can `cargo clippy` your projects. It usually has good suggestions, especially for folks new to Rust.
Here is one approach using [do_parse](http://rust.unhandledexpression.com/nom/macro.do_parse.html): named!(ms_dos&lt;&amp;[u8], MsDosTime&gt;, do_parse!( date: le_u16 &gt;&gt; time: le_u16 &gt;&gt; (MsDosTime::new(date, time)) )); I can't speak to which one is more idiomatic but I use do_parse heavily in [syn](https://github.com/dtolnay/syn).
If it does become commonplace in the ecosystem, it would mean we're actually following the semver spec... https://twitter.com/ag_dubs/status/799022058881613824
Maybe we could have an `¿` operator that returns an err in release mode but panic in debug mode. More seriously, I agree releasing a library containing such bugs should be avoided, I was talking cases that basically amounted to `if !foo.is_none() { foo.unwrap() }`, except by being too enthusiast with the `try!` macro and the will to avoid panicking, when I later introduced a bug by e.g. forgetting a negation in the condition, it made the error much more difficult to find.
I am not aware of it, but skimming the video, it looks like browser.. but faster? Not sure. Browsers are just expected now. If you don't have a browser, don't even start with me. Faster browser is nice, but it's just iteration. The reason I point out rails isn't because it is web, but that it was web when web 2.0 was the new hotness. Ruby captured a lot of that. Following the Web 2.0 hype train was mobile, with Obj-C and Java capturing most of that with iOS and Android respectively. 3D printing kinda had a false start like VR did years ago. It was the next big thing until it wasn't. Right now, the hotness is machine learning. R was well positioned for it, but seems to have snatched defeat from the jaws of victory. Julia tried to gain a beachhead, but was just too new and the community too small to capture it. Python seems to be winning there. Rust wants to be out in front of an emerging trend or get onboard the next one fast. Without legions of developers somewhat familiar with it already (like python), it's hard to move fast enough to capture a clear emerging trend. Rust probably needs to stake out some predicted turf. It stands to reason that robotics is going to be a big field of interest once the machine learning hype dies back and having machine learning is just expected. Robotics, quite conveniently, demands a language close to the metal if you want to get much done. Sound like any language you've heard of? Once we have models trained for speech, vision, driving, etc, we're going to want robots that take full advantage of those models. Right now, the robots are very specialized. The self driving car is the word processor of yesteryear. It's not a PC. It does one thing. It drives. Maybe others have ideas about emerging trends where Rust would be a good fit?
/u/nasa42, quote of the week?
It's really difficult for me to talk about rust without talking about safety. I write C++ for a living on a relatively large stack. It sucks to hunt down a sporadic double delete. So much. One thing I don't think gets touched on enough is how much easier refactoring is because of the borrow checker. I think it's easier to see the lifetime of objects in rust, so it's easier to find blocks of code that can be extracted into a function or structure. It is very nice to be able to bang out some code (that works correctly, thank you borrow checker), and refactor it later on without too much of a hassle.
&gt;braving the learning curve to descend into low-level programming, Not sure why, but my brain initially parsed that as "descend into madness."
What part of my sermon did you have in mind?
Very nice breakdown of the tradeoffs in different implementations =) What causes the extra allocation in Rust do you think? extra input buffering? I wouldn't have expected it to need 6.5MB heap to hold one line
The way I like to think about it is; if an OS or VM could recover from the error, then don't panic. Otherwise, panic. I really like Rust's idiomatic panic system though, particularly stuff like unreachable!(). It lets you know that something absolutely shouldn't happen, and if it did, it's pretty much your fault.
For me, it's not about safety at all. It's what you said - it's having a compiler that looks out for you. The borrow checker is amazing! I hated it at first, but ownership and lifetimes don't just bring sense to multithreaded and concurrent programming, they also make your own data designs so much cleaner! Rust, through ownership, effectively enforces the higher-level single responsibility principle that sometimes is a struggle to be consistent about in other languages. That alone is amazing. But for me, what really gets me is how expressive it can be and yet it seems like we lose nothing in terms of security, reliability, predictability and efficiency. That's just a dream.
&gt; You may mutably borrow multiple slices from the same array simultaneously so long as there is no overlap. Note that safe code cannot convince the compiler that two slices don't overlap. You need to use unsafe code or the function `split_at_mut` (implemented using unsafe code) to actually do that.
I really, really have to agree with this. I don't think Rust has this right now. In fact - having written Rust for close to half a year it's not quite clear to me when I'd reach for it. That's not to say I don't enjoy it - it's just hard to see where it fits. Maybe in the end its niche is democratizing systems programming.
I'm in a similar boat. I'm a decent programmer, but I can get lazy with safety. Rust forces me to be honest and be explicit about my laziness (e.g. I often just do `.unwrap()` to avoid handling errors). I'm past the point now where I'm struggling with the compiler and now looking for idiomatic patterns to make the borrow checker happy. I'm proud to say that I've been able to build significant prototypes without having to mark lifetimes, which means I'm understanding how to structure things in such a way that the compiler can figure it out.
Inflammatory ? I don't see anything inflammatory there. Is every programming challenge inflammatory in your opinion ?
Essentially, cpupool does not perform asynchronous I/O. You have a limited number of threads in a threadpool, and it executes each future sent to it, in order, until completion. Your solution allows multiple futures to interleave execution on each thread.
It all depends on whether you need GUI, and how much of it; that's where Rust is most immature for the time being. (If you do, the bindings to GTK are currently the best way to go.) Aside from that, there's no reason (that I can see) why Rust wouldn't be a good fit for what you describe.
I've used it pretty much exclusively for application development. I've a number of GTK and CLI applications written in Rust.
I don't understand the difference. If your dependencies aren't stable and they affect your public API, then you aren't stable. 
Unfortunately one of the parent comments got flagged, and this isn't visible in the original thread comments anymore.
I've started supporting you on Patreon and I would very much prefer it to stay MIT. I love libre software and I regularly dismiss using/contributing to GPL licensed projects.
One of the issues I brought up but /u/carols10cents never addressed was the relatively small sample size of the survey. I don't think 134 responses merit such wide generalizations.
I never claimed statistical significance, and you're free to ignore the results of the survey. I wanted to publicize this for people who *do* want to know what at least some crate users are looking for.
I'm more of a fan of non-copyleft, though the kernel (only) might be a good place for it. I'd be more willing to donate for MIT than GPL, because I'd be able to get more use out of it. If you decide to go GPL, it might be worth checking out GPLv2, instead of GPLv3. I'm not entirely sure about the details, but there are philisophical reasons (outside of the practical reasons) why linux hasn't gone to GPLv3.
It just set a weird tone when you only ever addressed the comment about semver.
Rust, to me, has a number of things going for it beyond safety: * If it compiles, it works: Rust and Haskell are the only languages I've seen where this has regularly been the case. * Embedding: I think this is a killer feature. If you want to make a native extension for python, ruby, nodejs or erlang to get some additional performance or to integrate with native libraries rust is a great way to do it. The absence of a GC in rust lets it cooperate with other language runtimes without issues. This is an area where the only other competition has been C or C++. * Dependency management: Rust doesn't just provide a better dependency management situation vs C and C++ but other languages too. I like working with cargo more than pip or npm and because it is the official tool it seems rust will be able to avoid the proliferation and fragmentation of tools that other languages have experienced. 
Why does [std::thread::JoinHandle](https://doc.rust-lang.org/std/thread/struct.JoinHandle.html) "detach the child thread when it is dropped" ? This seems like a form of race condition, considering the program will give undefined results. For example, running some [example code](https://is.gd/BhgrR4) which does not join the threads, provides the following results across executions: ./unjoined_threads | wc -c =&gt; 17408 ./unjoined_threads | wc -c =&gt; 39981 ./unjoined_threads | wc -c =&gt; 25600 This may be acceptable behavior, but it seems strange to me that the default behavior is not to attempt to join the thread when the handle is `Drop`-ed.
The real heart-breaking thing about Rust however is how poorly its syntax articulates its semantics. I really do think the syntax is getting in the way of understanding the power of these abstractions. By way of example, it wasnt until we wrote xxxx as x^4 we noticed power-law abstractions: in fact many discoveries in mathematics (, physics, etc.) are in part due to better expression of the underlying "semantics". 
Nice idea. Soany of us re hacking stuff like this together at the moment. 
https://github.com/google/enjarify/commit/f9a22c97a53957102b1208ea7408bbcbbc0eba10
It's just jemalloc being crazy. While I'm not familiar with its internals, from what I've observed, jemalloc will always gobble up around 6MB. If I switch the programs I posted to using the system allocator, then max memory usage drops below 2MB.
I would need a lot more context to tell you why this doesn't work, specific compiler messages and full source file? The spawn function just comes from a regular `tokio_core::reactor::Remote`
As far as I can tell, the counter-claim is basically: "if it doesn't look like C, nobody writing systems stuff will use it." Which is a bit absurd in my opinion -- Rust would be amazing with Haskell-like syntax.
Never mind, solved
It's just `arr[y][x]`.
I take it you've never worked with Scala ;)
I use Results for errors caused by bad inputs, but panics for errors caused by bugs. If for example one of two variables must be `Some(_)`, I can insert an assertion to ensure this, which panics if this condition does not hold. It makes little sense to issue an `Err(_)`, the program is in an indeterminate state anyway. Consider another trivial example with vector indexing. If the user has to input the index, then you should check whether it is in range and issue diagnostics if it is not, but if the index is generated by the program itself, then a panic makes more sense if the index is out of bounds: if it is out of bounds it is a bug in the program.
Rust is a safer low level language which supports high level abstractions with near zero cost. 
Making a [pong clone](https://github.com/sector-f/pong-rs/tree/master) to learn about game dev I'm kinda worried the code is structured terribly, but it works!
I am unfamiliar with rust array syntax, but the following code seems to work: const ARRAY: [[i32; 13]; 11] = [[0; 13]; 11]; assert_eq!(0, ARRAY[4][2]); Seems unfortunate to have to use nested array syntax twice, but seems required since `const` demands type annotations.
Does implementing a generalized, scriptable connection manager and API with pluggable parsers, processors, and encoders also interest you?
The Rust compiler is somewhat of a special case: - a large portion of a from-scratch build is spent building LLVM (written in C++), - bootstrapping means it is forced to build itself multiple times (3 at the moment). Of course, I agree that rustc is slower than desirable (and so does everyone else: lots of work on improving the performance, from micro-optimisations up to massive changes like precisely-tracked incremental builds), but pointing to the compiler itself is misleading.
[removed]
The slogan: "Your software deserves to be in Rust". is what I think about Rust: it's a language that helps me put my ideas into code that is fast, correct and reliable and even if I spent a bit more time upfront writing it, it's much more flexible and (re-) usable saving my time on debugging or having to write my own pieces. The good userstory was Maidsafe that just rewrote their C++ codebase into Rust and was suprised how (relatively) quickly and painless it was. I think we should stop explicitly advertise safety because it's a technical detail and not many people care and understand right. Some even actually interpret it as Rust users being paranoid. I think I'd spin in into: Rust - modern programming language that is fast, reliable and productive. Fast - compiled, typed, explicit, zero-cost abstractions. Reliable - all the safety stuff (just said differently), easy unit testing, compile time magic, etc. Productive - all the shiny features, great abstractions and libraries, lack of segfaults and UB. The biggest point being **reliable** instead of **safe**.
Do you have an example of a case where you don't want a new feature even though it's not a breaking change?
Not quite yet. We're getting pretty close to releasing 0.1.0, but it will still be missing many of the client-server API endpoints. Most notably, it will not include any of the federation system. The initial release will just be for people to experiment with running a temporary private homeserver and for the team to start to get some real world validation that the basic operations work with Matrix clients like Riot.
Dumb question: how do I pronounce "Xargo"? I kind of want to treat the X like a Chi a la LaTeX: "C*phlegm*argo". :)
Personally no, but I'm sure some do because of things like code bloat. But this also bring into question minimum version of Rust and whether bumping that is a breaking change or not. Edited: mobile autocorrect errors
This is amazingly simple, thanks!
It's very unlikely that a small and independent operating system can become a viable alternative for users but there are definitely opportunities in the internet of things / embedded systems space, as a light weight VM to run microservices and as a hypervisor. 
I wrote [my first lint](https://github.com/lfairy/maud/blob/c849d9efdfa40565b4b0710036fa0da75b688f46/maud_macros/src/lints/doctype_html.rs)! It detects when the user writes `"&lt;!DOCTYPE html&gt;"` and suggests using a pre-defined constant instead.
I'm using Rust for a webapp. I'm happy with my choice. One big caveat is that the ecosystem is young—Rust libraries for much of this stuff are expecting to significantly change their API in the near future (hyper), may be buggy, or simply don't exist yet (SOAP). I was debating between Go and Rust. Before I made my decision, I wrote up a Google Doc listing what libraries I was looking for, mentioning best one I'd found in both languages with a bit of information about it. That way I knew what I was getting into.
Personally I think your best bet is going for the same market as an operating system like minoca and forget about a GUI. Whatever you do you're going to struggle to fund it without investors, and unless you find the right investors they are going to ruin the company chasing returns. There is a new wave of angel investors that don't take equity but rather provide a loan that is only paid back when you're profitable, it's a system designed for smaller businesses and not unicorns. The founder retains full ownership and gets access to experienced mentors and their networks, I think it works quite well. However, someone suggested crowd funding and I'd definitely be looking at that if I was you. Quite a few open source products have been funded through kickstarter, indigogo, and the like.
Algebraic datatypes Nice macros Trait system
No, you are probably right. I think it has a lot of different meanings and maybe there might be a better term, but ultimately it might not just be a term, it might be a different way of presenting the Rust compiler. I think a lot of people are used to compilers saying "you can't compile that because that will lead to a very obvious fault", but they are not used to Rust or other languages that have guards within language/compiler to prevent you from making not-so-obvious ones. "Fighting with the borrow checker" at first feels like you are just being lectured to, but once you understand it, you realize it's watching your back. I'm not sure how to express that, safety is certainly something I might feel, but in some ways the compiler feels more like a guide to me. Which is interesting, and as I said, not something I've really experienced before. 
Thanks for the info i'll keep using feh for now. But I'll be github stalking you probably in the near future to see if you ever get to it. ;)
&gt;* Ability to write fancy abstractions that get optimized out during compilation. (I'm **still** getting used to how freeing it is to not have to worry about this in what would be concerningly hot code in Python.) As someone who has dipped their toes into Rust, I'm still not used to this. I'm used to throwing out a lot of useful abstractions in Python in the parts of my code that take the most time. It is much like the sequence in "The Martian" when Matt Damon's character is removing stuff from the rocket to get it into orbit. "Classes? I'll just use a tuple instead. Function call, time to manually inline that. Period? Should probably not use that character." With compiled languages, but Rust in particular, all of these concerns go out the window.
Gotta keep coding, or you run out of insanity and die.
At the same time, Rust's syntax is familiar and comfortable. They've done a great job of giving the power of ML, and making it as easy to use as C-like languages. It's very accessible.
Thankfully, I mostly write I/O-bound stuff, so I generally don't have to go quite that far. For me, it more manifests itself in being wary of going beyond the abstractions included in the standard library.
&gt; This is an area where the only other competition has been C or C++. Or special-case dialects, like Cython, if you don't need to go all the way to native performance.
Why is the Racer autocomplete so inconsistent? Am I maybe doing something wrong? It works with some variables: https://i.imgur.com/gvMo9m7.png But with others suddenly not: https://i.imgur.com/85eRWX8.png (Using Racer 2.0.3 here, I had same results with an old 1.x though.)
I cited Clippy as an inspiration in the article ;)
The shorter version at least.
I've been thinking about this. Obviously the first people to climb the mountain are exceptional, as are the people who find the hardest way; exceptional in ability, yes, but also exceptional in motivation - not everyone thinks that 'Because it's there' is sufficient. Finding the easier ways then becomes important - I say 'ways' because the tour parties you will be leading in the foothills have a range of backgrounds. I think it's important for people to understand the problem before they're ready for the solution, and need practical answers first, then theory. To continue the metaphor, you point out interesting rocks and plants and tell stories about them, and only later do lectures on geology and botany. Climbing the hills and seeing new vistas will set up the motivation for actual mountain climbing later.
You may want to post this in /r/playrust
Nothing. It's work in progress: https://github.com/rust-lang/rfcs/pull/1133
How is it pragmatic to require people to have a giant VM?
Also, I would add the license doesn't matter to me. It's not some magical force that'll change the project into a thriving one either way, the developers have to do that.
&gt; I would like to add that it is generally considered bad form (and against the semver spec, IIRC) to release a 1.0 version of a crate if any of its dependencies are still in their 0.x versions, which is still a very common case in Rust. It is also very common case in Rust that crates have dependency chains that are 5+ crates long. If this rule was universally followed, everything would have to be stabilized in a bottom-up manner. The total number of crates that'd have to reach 1.0 before yours could would be roughly exponential wrt to your longest dependency chain, essentially ensure that higher level crates would basically never stabilize.
My primary point is that we shouldn't be pressuring people to make a 1.0 release just because they think it will make their crate more popular, but everyone seems to be caught up in debating the first sentence. I should have kept it simple.
Agree on the last point (Django/Rails-like). I think we will see way more development on that kind of stuff once Tokio/Hyper gets stable. I know I will be the first one in line to work on something like that (already started [with](https://github.com/Keats/tera) [individual](https://github.com/Keats/rust-jwt) [pieces](https://github.com/Keats/dbmigrate) [actually](https://github.com/Keats/validator))
18 hours ago: https://www.reddit.com/r/rust/comments/5krhr0/rust_is_more_than_safety/ Interesting to see two points of view.
Two remarks regarding your internal design: 1. Only a single type `T`: this is pretty academic. Nearly every data set I've ever worked with has multiple data types (e.g. `f32` and `int32`, but also date-time types, strings and enums [which are more efficient than strings]) 2. The usage of a single matrix per data type corresponds to what pandas calls blocks (see [`BlockManager`](https://github.com/pandas-dev/pandas/blob/master/pandas/core/internals.py#L2691)), and what is pandas biggest problem. Many data processing pipelines heavily add+remove columns and rows to the data set and your (and panda's) design run into to problems here: a) copying the data around every time you alter the data table and b) blowing up memory consumption while doing so. This is exactly the reason why pandas 2.0 (see [design docs](https://github.com/pandas-dev/pandas2)) won't use numpy + a block manager as it's backend. I can see how using a general purpose matrix/array lib as a backend makes it easier to get started, but I personally guess you're going to run into the very same problems that pandas is facing today, and with that rendering your library unable to be used for proper data processing pipelines. Apart from the fast project kickstart I do not see any advantage of using a matrix over single arrays, apart from the very very few cases where you want to do matrix operations on ALL columns (and ALL is pretty uncommon for DataFrames).
I was very uncomfortable reading "Rust is more than safety", and this expressed my sentiment better than anything I could have written.
Hey, awesome! I personally would take a deep look into the phoenix framework (written in Elixir) that takes off currently. It does a few things exceptionally well: - It is based on a tiny core, "Plug". A great take on how middlewares should work and something that should be one of the first building stones for a bigger framework. - the routing is done through clever macro-tricks - Using "Ecto" and "Schemas" instead of Rails-y models, combined with the fact that all non-pure/IO-stuff should live only in controllers. Having all parts of the app as pure functions (speak: functional programming pureness), except one well-defined place where it makes sense, is freaking awesome in practise. - channels as abstraction over (web-)sockets work really well and easy, and scale high. - the way EEx (elixir's template engine) and String-handling works within phoenix makes delivering HTML insanely fast (one piece of template exists exactly one time in memory, leveraging CPU cache if I remember correctly). HelloWorld stuff responds in &lt;&lt;&lt;1ms, people are truly excited about this. just a few things from my head, I'm using phoenix daily. AFAIK Rust's philosophy is not to reinvent wheels but to use true and proven things from the recent past and assimilates the best parts... so, having a look at different popular frameworks and their strengths (to assimilate) and limitations (to overcome) seems the way to go. 
One is a response to the other.
Yes, this is a good way to put it. [Dave's post](https://thefeedbackloop.xyz/safety-is-rusts-fireflower/) is similar, and I'll probably be writing a slightly longer response post. I think the core of it is this: &gt; Safety in the systems space is Rust's raison d'être. Especially safe concurrency (or as Aaron put it, fearless concurrency). I do not know how else to put it. But you just did! That is, I think "fearless concurrency" is a better pitch for Rust than "memory safety." The former is "Hey, you know that thing that's really hard for you? Rust makes it easy." The latter is, as Dave says, "eat your vegetables." I'm not advocating that Rust lose its focus on safety from an implementation perspective. What I am saying is that the abstract notation of "safety" isn't compelling to a lot of people. So, if we want to make the industry more safe by bringing Rust to them, we have to find a way to make Rust compelling to those people.
I might have read something wrong, but I thought point #1 was addressed in the article: http://www.suchin.co/2016/12/28/Introducing-Utah/#the-innertype
Rust's pitch (as pcwalton often states) is "memory safety without garbage collection", often shortened to "memory safety". If you just want memory safety with C-level speed, you could use D or Nim. I don't think "memory safety" is "eat your vegetables". It's more like "get healthy without eating your vegetables", or "get fit without exercising", which is awesome.
So, javascript? It's no wonder that javascript was poorly understood and used for the first decade of its life -- it took people understanding abstractions using the clarity of other languages to bring to javascript "syntax rituals" for understanding *its* abstractions. That's what we have with Rust. We have other languages ritualized in syntax, rather than a syntax which obviously expresses its abstractions. 
Simply stating "memory safety without garbage collection" has the danger of being understood as "oh, that's just as safe as Java, but without GC". The truth is actually "stronger memory safety, and without garbage collection". D and Nim do not have Rust's safety, even though they have a GC!
I am all for focusing on benefits of safety instead of how safety is done. I am very uncomfortable with focusing on algebraic data type, pattern matching, etc., in that if that's what you want, OCaml is more mature. I think lmm is echoing my sentiment on [Lobsters thread](https://lobste.rs/s/chfclw), "is Rust better marketed OCaml (e.g. with C-like syntax)?" If it is, we could work on C-like syntax for OCaml and save lots and lots of efforts.
Genuinely curious: what can Rust do that D or Nim can't (besides being safe without a tracing GC)?
With how often I bring it up on this sub I'm starting to sound like a bit of an evangelist, but have you tried Intellij with the Rust plugin? There's no configuration involved you just download it from the plugin menu of the IDE and it installs by itself, updates are every week or 2 and they make it noticeably better every time. It's not up the same level as Java + Intellij but it's getting there. Biggest con is there's no debugging :-/, not a *huge* issue for me but still annoying.
In your opinion, how does Rust compare to Haskell in the "writing correct and readable code" category?
Great, you don't, but looking at replies to "Rust is more than safety", many people *think* you do. I find misinterpretation very worrying. I mean, I contribute to Rust, and I need answer to myself why I don't contribute to Reason (resyntaxed OCaml, which went as far as replacing "match" with "switch") instead.
Rust statically prevents data races. They simply can't happen within safe Rust. See this fantastic [post](https://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html). Go is considered a safe language (just like e.g. D and Java), but it still doesn't prevent data races, which can lead to hard to trace bugs and even security vulnerabilities: https://research.swtch.com/gorace Just because a language has a GC (or says it's safe) doesn't mean it truly is memory safe in the same sense Rust is.
This is a really good point to me. Talking about the safety is fundamentally not so attractive to many of our potential users -- they're either C/C++ people who have evolved coping strategies to deal with all the pitfalls, or they're dynamic language people who get the safety, too, just at a performance cost. So, I really like the "fearless" part. For me personally, the "concurrency" part isn't as interesting; really, how much of the code you write on a day-to-day basis needs to reckon with concurrency issues? I would think that's a tiny percentage for most developers. One could argue that this is exactly because concurrency is so bothersome/failure-prone in most existing advantages, but then we're back to the "eat your vegetables" argument. So maybe it would be better to talk about "fearless performance", or "fearless zero-cost abstractions", or "low-level control without the hazards". Edit: for those dynamic languages folks especially, I think the attraction of the compiler catching a lot of your bugs for you is also not to be understated.
I'm skeptical. Rightward drift like that is almost always caused by improper error/Option/Result handling. A better solution in the example code is to refactor using match and return if None. 
I am unreasonably excited about this.
I agree with /u/sanxiyn on point 1. &gt; And yet, in my very first Rust program it took me 30 minutes to uninentionally write a deadlock. How'd you do that? I'm interested, I've never had a deadlock in Rust. (Though they are safe.)
Instead of going back and forth with blog posts I think the whole thing should just be settled next month at the Royal Rumble.
Rust makes low-overhead message passing safe, because ownership means that once the message is sent, the sender can no longer access it. Other systems are forced to do things like deep-copying the message or only allow sending permanently immutable data to get this guarantee. It's hard to say much about the dead-lock other than, yes, Rust only guarantees no data races, the most insidious data-corrupting concurrency problems.
Yeah, you'd know, I'd say Rust tried to do what JavaScript did. JavaScript was one of the first languages to take old ideas that aren't getting used elsewhere, and wrap them up in a language that would be familiar to most programmers. And JavaScript made a lot of mistakes in doing that. I think Rust learned from those mistakes (and PLT in general learned from those mistakes).
that's how I'd do it too :) Using map here makes it a bit awkward
I am much more happier with this formulation, because it makes clear this is about how to actually sell Rust's unique selling proposition, and not trying to sell Rust on some points other than safety. Many people misunderstood the original post, exhibit [1](https://news.ycombinator.com/item?id=13272889) [2](https://news.ycombinator.com/item?id=13273112) [3](https://www.reddit.com/r/programming/comments/5krw7r/rust_is_more_than_safety/dbqdi4b/) [4](https://www.reddit.com/r/programming/comments/5krw7r/rust_is_more_than_safety/dbqd18v/) [5](https://lobste.rs/c/pklyuf) [6](https://lobste.rs/c/o3sodh). These are not cherry-picked, I just chose two from numerous examples on each thread. Some especially egregious quotes: "stop hyper-focusing on safety" (from 1), "I'd love to try a "Rust without the borrow-checker" language" (from 3), "I don’t really care at all about memory safety" (from 5). You can check quotes yourself to see whether I am misrepresenting the context. This is not the message I (and I think we) want to send.
The VM is hardly massive; your concern is overblown. It really depends what the OP is trying to learn. If it's learning a language - Rust or Scala. If it's to learn ML techniques - Scala/Python/Spark for the toolchain, as well as R. Basically, optimize your environment to prioritize the one thing you're going to learn and use what "just works" for the rest.
Hardly massive means what exactly these days? How big is hello world with all the dependencies? The question was about application programming, where are all the other languages suddenly coming from?
I quote the OP: " It's basically a bunch of automation for deal evaluation (tons of business logic and calculation) and process automation (emails, reminder, some document processing)." "The application I'm considering is more of a server application rather than client" " I can imagine it involves a lot of web scraping, talking to various web services, and performing a bunch of data transformations, and finally present some type of UIs via web or some endpoint to js client". I offered my opinion on what would be a good fit for the use case he outlined. Moreover, in such an environment (unless you're heavily containerized) the VM size is incidental.
So how big is not giant? I feel like it is an imposition on users to eat up unnecessary resources when the advantage of using scala over rust can't be much. I want single file binaries with no dependencies and I want them to run fluidly. 
FWIW, I didn't feel that any of this was antagonistic. &lt;3 reading this also made me realize that I hadn't expressed what I meant as clearly as I'd wished, it was good! In those days, we didn't have news aggregators either. So the stakes were lower. And I feel like some things need the longer form, but because that culture is gone, I just throw out some tweets without thinking about it instead, whereas blog posts at least had some length.
Just a quick question: what does let* actually do? Also, because string is parsing alphanumerically, it doesn't recognise the * in let*.
I just redid my site completely so that's expected. If you go to mgattozzi.com then go through the archive page it should work.
Curious, what of its original design remains?
Good point. I'm working on adding more characters to the parser since it's only alphanumeric. If that ends up being a bit to hard let me know. Still tweaking the tutorial and this kind of feedback is good. Let is a way to store variables while programming so for example: (let ((a 3) (b 2)) (+ a b) ) Would return 5. Let's say I wanted to do this however: (let ((a 3) (b (+ a 2))) b ) It should just be 5 right since we're saying store a +2 into b. However it doesn't work that way in scheme. I'm going to generalize here and not jump too much into the way environments work but when they're created at roughly the same time they don't exist in the same frame yet. Even if they do it's not until the inner part of the let statement that you can see them. The way let* works acts as a way for the previous example to work. (let ((a 3) (b 2)) (+ a b) ) Would return 5. Let's say I wanted to do this however: (let* ((a 3) (b (+ a 2))) b ) What this is saying is evaluate each value in order. Store 3 into a and now allow that to be accessible to other scopes below me, in this case b and the inner part of the let* statement. Really what these are, are different ways to represent lambdas in an easier to read syntax for people. Eventually we'll be transforming these statements into lambdas for evaluation. Does that make sense at all?
Then I really don't get the sales pitch, because when I've heard it it's as though there are so other safe threading alternatives.
It's all good!
You might be interested in https://www.youtube.com/watch?v=79PSagCD_AY
&gt; deadlock I don't remember. I just tried looking at the git history to see if there was some magical commit where I fixed it but I didn't find anything. My point was that Rust didn't make it magically safe for me to do threading - quite the opposite. I never knew what I did wrong, my solution was to use `Rc` instead of `Arc` and just one thread. IIRC anyway, it was a while ago.
https://github.com/mmstick/parallel
Great post! &gt; his deviates from the stated goal of no allocation. Yeah, we need `impl Trait` to land before this can go away in the general case.
I'm working on an SMTP library / mailserver using nom to parse the messages from clients. It can be found at: https://github.com/awesomefireduck/maillurgy I'm also working on building my own mechanical keyboard and programming the ARM microcontroller in rust &lt;3 https://github.com/awesomefireduck/dactyl-build (mainly documentation at the moment) I would appreciate input on either. (^^,) 
Dear Dave, I can't thank you enough for letting me know about [Kathy Sierra](http://seriouspony.com/)'s website.
Here's the relevant code. For the trait bound error version: const map: [[u32; 13]; 11] = [ [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] ]; let x: u32 = next.x as u32; let y: u32 = next.y as u32; `next` is a struct with just an x and y if next.y == next.y.floor() { if map[y][x] || map[(y - 1)][x] { return next; } } else { if map[y][x] || map[y][(x - 1)] { return next; } } And for the mismatched types error version: const map: [[usize; 13]; 11] = [ [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] ]; let x: usize = next.x as usize; let y: usize = next.y as usize; if next.y == next.y.floor() { if map[y as usize][x as usize] || map[(y - 1) as usize][x as usize] { return next; } } else { if map[y as usize][x as usize] || map[y as usize][(x - 1) as usize] { return next; } }
Also FWIW I didn't feel like there was a ton of daylight between any of our posts. Mostly I felt my post was agreeing with Steve and connecting it to the Mario analogy. And Graydon doesn't want to lose sight of the benefits of safety to software quality, which is also fair. One of the tricky things about blogging is that it's easy to assume "response to X" is the same as "takedown of X." But I think (hope?) when friends engage each other respectfully in public, people can generally see that it's not a fight but a collaborative trip around the hermeneutic circle.
Damn didn't know this language had a built in survival game.
I'd wager you'll have a harder time writing *really safe* Haskell than Rust, at least if the end product should perform in a reasonable time.
If you would be willing, I would be curious to know what puts you off about copyleft, specifically GPLv2 and GPLv3. Thanks
If I may ask - which components do you think are the most important to be GPL instead of MIT?
Understood. Please let me know what you see as problematic with MIT licensing, so we can include it in our debate.
This is a possibility. Especially dual licensing with MIT/Apache 2 as Rust and many Rust projects do already.
Thanks for the feedback. As I have asked others: What reasons do you have for your preference of GPLv3?
nice username
The code example links are broken now. 🙁
Just by trying things out, and giving us feedback on our ideas is plenty of help! My biggest issue now is finding out what is most important to work on next, for the community.
Well, we do sort of have Rocket right now and once the async becomes stablized Rocket may become the de-facto Django/Rails-like framework (or who knows, something else might come out!)
Thanks very much for this. We will maintain scope, I promise! I am working on cross compiling `rustc` for Redox. I want to design a minimal, secure platform for running Rust - I do not want to ruin it by biting off more than can be chewed!
[removed]
A bikeshed question - I have a trait that is not object safe and I want to make a version of that trait that works with trait objects instead. If the "regular" trait is called `Foo`, what should I call the new one? `DynFoo`? `ObjFoo`? `PtrFoo`? `RefFoo`? Is there a convention? Or, in case I can actually make it the same trait like below, what do I call the secondary method: trait Foo { fn bar(self) where self: Sized; fn obj_bar(&amp;self); // or dyn_bar, or ref_bar, or... } 
Rust is my next year's "Learning" goal for work. I will definitely do some redox testing (if not coding) then. I have a lot of experience with networking protocols. I'm sure I'll be able to give you feedback. 
I agree, but it strikes me as sort of strange when people mention that "Rust doesn't provide anything inherently different" from other languages. The thing is Ruby hasn't from Python, nor has C# from Java. Yet they all have been adopted. People are however skeptical of new languages nowadays, and it is just too risky to try to learn new languages when its job prospects aren't yet vibrant. 
I'm sorry to hear that. I really appreciate your technical blog posts; and didn't feel like this one read as antagonistic in the least. I definitely understand the worry that technical debate on the internet can become needlessly antagonistic; but I think that you do a good job of keeping it friendly and focused. In fact, the biggest problems I see with antagonism online is more in the comment threads than the blog posts. Comment threads tend to have a very quick back-and-forth cycle in which it's easy to get lost in the weeds and caught up in the disagreement. Blog posts for a public audience don't quite tickle that the same way, I don't think.
There are other safe threading alternatives, but the alternatives often don't restrict you to a safe subset. For example, you can use channels to pass data in Go, but if you pass a pointer, you can still get concurrent data access. With Rust, you can do message passing *and* the compiler will catch you if you do something sketchy. With other languages, you rely on conventions, but with Rust, the compiler helps keep you honest. All you need is one unsafe assumption and you introduce data races. Rust also protects you from other fun memory safety issues unrelated to threading, such as bounds checks (protects your stack). These issues are solved with conventions and patterns, but that's the selling point of Rust, it makes sure everything is memory safe.
Awesome!
Thanks for your feedback. As mentioned above, point #1 is currently addressed by the InnerType enum. Right now it only supports strings/ints/float, but there's no reason why it can't support other types. I agree the need to copy data around is not ideal, but in this case, I think it is a limitation of the iterator trait, not the use of the matrix as a backend. As I mention at the end of the post, in an ideal scenario, the combinators return elements borrowed from the dataframe itself. Definitely aim to explore that, and there's been a ton of discussion on this lately. Furthermore, the combinators are pretty naive right now, and I think there could be more work in reducing the complexity of operations that don't require iterating over the entire dataframe.
hi! blog post author, here. i'm interested as to why you think that. Rust has been an excellent tool for the backend service work we've been doing at npm, replacing C and Node. side note: why do you characterize your position as "strongly disagree"? it just seems that you have a potentially better language suggestion? which is ... well, tepid, at best.
i gave a very succinct explanation right after that sentence, fwiw.
&gt; I believe that Steve’s original point was "maybe we should try marketing this a different way". I think this is misunderstanding and I would like /u/steveklabnik1 confirm.
I replied to "Fire Mario, not Fire Flowers", "I am much more happier with this formulation, because it makes clear this is about how to actually sell Rust's unique selling proposition, and not trying to sell Rust on some points other than safety." I believe this post *is* trying to sell Rust on some points other than safety, unlike you. Am I misunderstanding?
I quite frequently find that I need to return 2 or 3 different types of futures, which `impl Trait` doesn't allow, so boxing is still necessary. Of course I can make an enum and implement `Future` on it, but that's not very convenient and lots of boilerplate. Are there any plans for anonymous enums, which automatically reimplement traits by dispatching to either variant ? Has this ever been discussed before ? I think it would make a nice extension to `impl Trait`. EDIT: oh wait, OP's crate solves this exact problem. That's what I get for commenting before reading the article :( My point still stands that anonymous enums would be more ergonomic
I believe there was an anonymous enum proposal, not sure though.
Let me quote from the post: &gt; Market the other cool things about Rust! OMG it is so expressive. The standard library is large compared to JavaScript. (snip) Cargo is the friggin best. Large standard library and Cargo are not what safety gives you. In fact, they are completely unrelated to safety.
In your mind, is it unacceptable to _ever_ discuss any positive aspect of Rust other than safety?
No, it's okay, but to repeat what I wrote above, "I don't want to market Rust when Rust isn't the best solution", and I think if your only reason to choose Rust is Cargo, it often is the case Rust isn't the best solution.
This is awesome! I saw this pop up on crates.io recently and was hoping someone would write a blog post about it. :-) I do have one nit though: in your example code, it looks like you're compiling a regex every time your handler is executed. You could avoid this completely by putting the `Regex::new("...").unwrap()` call in `lazy_static!`, which means it will only be compiled once. You can then safely access it from as many threads as you like. There is an [example in the docs](https://doc.rust-lang.org/regex/regex/index.html#example-avoid-compiling-the-same-regex-in-a-loop). (In your example, your regex is really really small, so it should actually compile very fast. But telling whether a regex is small or not isn't always straight-forward. For example `\pL{25}` is over 1000 times bigger than the one in your post!)
You can choose to have array accesses return an `Option`, if you use the [`get` method](https://doc.rust-lang.org/stable/std/primitive.slice.html#method.get) instead of the `[]` indexing. The reason `[]` panics by default, as I understand it, is to indicate to the programmer during development that they have a bug in their program. Many many security problems are buffer overreads or buffer overwrites, which are essentially out of bounds array accesses. EDIT: Thought of another thing. If you *never* expect to have an out-of-bounds array access, you don't have to write extra code to handle `Some` and `None` that would result if `[]` returned `Option`. If your expectations are ever violated, your program will just stop, and this means there's a bug.
[We've thought about adding at least one more](https://github.com/rust-lang/book/issues/344) but don't have any ideas yet-- would you like to share your ideas on that issue?
I totally agree with the section `reputation of software`. We must not tolerate so much failure. Rust is a way to push forward software quality.
&gt; In other languages I take it you're not comparing to OCaml / Haskell / SML / etc. But, yeah... These days I'm programming is Scala, and I'm sad that it allows uninitialized access. :(
I agree that that's definitely a bad example. However the point still stands.
That's a good point, and would be what I'd do 99% of the time. But when writing lints, the interfaces involved are so broad and irregular that wrapping everything in an Option/Result just won't happen.
&gt; not that we would ever have a bugless compiler. [CompCert](http://compcert.inria.fr/) exists. :)
Well, for me it comes down to a bunch of reasons. I'm going to list them first, then go into more detail below: 1. Liberal licenses are simpler 2. I don't understand the GPL 3. Liberal licenses have clear advantages 4. I don't believe in the GPL's purported advantages 5. The attitude of some GPL supporters just rubs me the wrong way --- ### 1. Liberal licenses are simpler I can read and, for the most part, understand MIT, BSD, and friends within a few minutes. The core message is very clear. The parts that aren't clear to me are less relevant. If I make a mistake because of those parts, it can be easily fixed later. I think there are some scenarios where there's a very clear purpose for choosing a copyleft license. For example, if you want to restrict commercial use, so you can sell licenses to business customers (just an example, probably not applicable to your case). In the absence of such a clear purpose, I would always err on the side of simplicity. ### 2. I don't understand the GPL license I mentioned above that parts of the MIT aren't clear to me. Specifically, how I'm supposed to include the license in copies of my software isn't obvious, in my opinion. Is it enough to just leave it in the source code, or do I need to include a README that lists the licenses for all the libraries I ship? I think this isn't relevant, if the library is compiled into my Rust binary (right?), but what if I'm shipping library source code as part of my JavaScript app or whatever? My point is: If a critical reading of the short and poignant MIT license yields that many questions... well, just look at the length of the GPL and extrapolate. Maybe I'm unique, and all those people who use, ship, or write GPL code have consulted with their lawyers and gained a better understanding. Probably not, though. ### 3. Liberal licenses have clear advantages The less hassle a license is, the less likely it is to scare away anyone who wants to use your code. Yes, someone might take your code, build a product on top and make money off of it. But you know what? Worst case, you lose nothing. Better case, that person contributes testing and bug reports. Best case, that person becomes a valuable contributor. As long as an open source project is healthy (i.e. producing a steady stream of improvements), there is distinct pressure to contribute as much back as you can. Anybody who has ever had to merge improvements from a diverging upstream branch knows this. If that pressure results in contributions upstream, how is that bad for anyone, even if the downstream developer is holding back some of the features they added? Yes, it's possible that the GPL will result in those features being contributed, too. I think it's more likely that a copyleft license would have led that developer to base their work on something else in the first place, and that open source project would have missed out on those potential contributions. ### 4. I don't believe in the GPL's purported advantages As mentioned above, I believe that if a developer plans to build a commercial product on open source code, the GPL is more likely to scare away that developer completely, than cause them to contribute back code they otherwise wouldn't have. But even if I'm wrong in that, what good will a legally mandated open source contribution do for the upstream project? Many people seem to think that code is inherently valuable. Sometimes it is, more often it's not. Unless a contribution is of a sufficient quality, it makes no sense for a project to accept it. Or a downstream developer might add features that aren't easily maintained (device drivers for exotic hardware, for example). Unless that downstream developer is willing to maintain their contribution in the long run, it might make sense for a project to reject even a high-quality contribution. What I'm trying to say is, unless a developer really wants their contribution to be accepted, it likely won't be. And if they want that, they won't require a license to force their hand. If the developer has no interest in getting the contribution accepted, they can fulfill their legal obligation by dumping an undocumented code blob that will never be of any use to anyone. ### 5. The attitude of some GPL supporters just rubs me the wrong way This item is the most irrational and subjective on this list, but you asked for my reasons, so here it goes. Many people express rational arguments (often philosophical) in favor of the GPL, and I respect that, even if I don't share their opinions and disagree with their conclusions. However, there is one attitude that particularly irks me. And that is, when people are perfectly happy to share their code without making money from it, unless someone else manages to do so. If I believe that a piece of code I write is too valuable to give away, I will keep it private and try to reap the rewards myself. If I have decided to give it away, then it shouldn't bother me that someone else is using my code to make millions. If that code was so great, it's my own fault for not making those millions myself. After all, I was in the best position to do so. Most likely, the code was the least important factor that lead to that person's succes. Most likely, luck and business chops had so much more to do with that, and that person would have found another way, had my code never existed in the first place. --- Those are the reasons that I, most likely, will never again release any code under a copyleft license, and that I will think twice before basing my work on a project that isn't licensed liberally. And even though I'm not currently in a position to contribute financially, nor do I have an immediate use for Redox, it's still a project that I'm interested in, and that might be useful for me in the future (I'm using Rust for embedded development, with the intent of making money from that). It has been mentioned in other comments that a microkernel architecture alleviates concerns about the GPL's virality. While that is true, it isn't enough to convince me that a GPL'd Redox isn't a bad idea. First, it's bad business practice to trust legal advice from strangers on the internet, so in any case, you're going to incur costs on my side (maybe in the form of money for legal consultation, but at least in the form of time and effort, for reading and understanding the GPL myself). Second, in the past, no-one could really explain to me why certain methods of communication between different pieces of code invoke copyleft mechanics, while others don't. Yes, people mostly seem to agree that linking (static or dynamic) is one thing, while system calls are another, but I've never quite understood how that follows from the license text[1]. Third, the technical details of Redox might very well change. Is it out of the question that at some point, I can statically compile a whole Redox system (kernel, drivers, applications) into a single image for a tiny microcontroller, and use a different method for message passing? If that were to happen, the GPL might suddenly apply to everything within that image, making it illegal to ship a closed-source application as part of it. A final word to those who might be tempted to reply to this comment. Please be aware of this comment's context. I was asked why changing the license to GPL would put me off, and I answered. Please don't misconstrue this comment as me trying to force my beliefs on anyone else. I sincerely believe that everyone is free to do what they wish, as long as they don't harm anyone, and your licensing decisions certainly won't harm me. Mildly annoy me maybe, at most :) [1] Disclaimer: My opinion on the GPL was made up a long time ago. Back in the day I was quite knowledgeable about GPLv2, but GPLv3 came out after that. That argument might no longer apply in the same way. 
I still haven't received my inaugural paycheck yet (apparently I get paid once a month, and I started just *after* last payday), but once I get solvent I will definitely chip in. I strongly prefer the MIT license to the GPL. That said, I feel this way because I believe that the technical work is far more important than the license, and will donate money (and, hopefully, time) regardless of licensing choice. I think the licensing is a complicated question and definitely one worth pursuing. I'm not a lawyer, nor am I well versed in the major players in the licensing arena. Would a simpler solution be to do something similar to how the FSF owns all GNU-project copyright, and have all code merged into the Redox project transfer copyright from the individual author to the umbrella organization, so that the licensing problem can be deferred until later and then only the umbrella organization need acquiesce to a change? On the other hand, I can see that being taken extremely poorly by contributors, so maybe not. I personally would happily sign over ownership of any commits of mine merged into Redox, but that's just me.
Did you have any trouble getting verified on Rosetta Code? It doesn't seem to send me a confirmation code email.
I signed up a long while ago, but I don't recall having any issues (using a gmail account).
Mario picks up a Fire Flower, and becomes Fire Mario. Fire Mario can throw fireballs, which Mario cannot do.
Great stuff. I went through it, and the only problem I found was that the modification to use stderr causes a compile error, because it's missing: use std::io::Write; Also, if you feel like there's space, you might want to follow testing best-practices and show the unit-tests failing before changing the code to make them succeed.
That was the same problem I was running up against, multiple return types. I'm trying to stay away from boxing futures as much as possible. `impl Trait` is going to solve most of the pain points, but I wanted an easy solution that could look fairly elegant.
You might want to check out https://opencollective.com/, which is a bit more focused on open source than Patreon. Probably best to go all-in on one or the other though, so since you've already got a following on Patreon moving could be detrimental. There's also a Patreon plugin for Discourse that could come in handy: https://meta.discourse.org/t/discourse-patreon-login/44366 Also, here's a great list of funding ideas for open source projects: https://github.com/nayafia/lemonade-stand
I say 'zargo'. No clue if that's right.
&gt; people who started it just chose Python for some reason. There was an established scientific computing special interest group at the first PyCon I went to in 2003. There are dedicated Python conferences for scientific computing and I know people who doing Python evangelism to their scientist friends at work. I'm not at all surprised that when people writing numeric code pick Python. I'm a lot more surprised that Lua got traction via Torch.
Gotcha thanks again.
As a developer who mostly works on web dev, "write/deploy native extensions for your &lt;INSERT_DYNAMIC_LANGUAGE_HERE&gt; without fear" is an okay pitch I've used sometimes. Web developers understand there are performance issues in some parts of their favorite frameworks. 
You can nest data types in matches like "if let", which can help get rid of some rightward drift. So your example if let ExprCall(ref path_expr, ref args) = expr.node { if let Some(first_arg) = args.first() { if let ExprLit(ref lit) = first_arg.node { if let LitKind::Str(s, _) = lit.node { if s.as_str().eq_ignore_ascii_case("&lt;!doctype html&gt;") { Can be refactored to something like if let ExprCall(ref path_expr, ref args) = expr.node { if let Some(Args {node: ExprLit(LitKind::Str(s, _), ..}) = args.first() { if s.as_str().eq_ignore_ascii_case("&lt;!doctype html&gt;") { But since I didn't have enough code to check with the compiler, it's probably a bit wrong. Also this may not be be considered an improvement by everyone.
It only gives back error codes for that reason,there are no error messages. Didn't know that Go library, I'll have a look thanks
Someone who took more time to think about this and understands redox might have a better answer. I think the most important reason to use gpl is to avoid proprietarization, so 1. in a core component that can't easily be rewritten. for gplv2, this gets you it's source and build scripts, and even if other components were proprietary, that could help you build a working replacement kernel from free software, and for gplv3, it avoids tivoization. 2. components which are likely to be improved by companies which prefer proprietary licenses. I'm mostly thinking of drivers for hardware which will likely get new hardware versions and result in changing an existing driver to support it.
2017 :) You know how us software developers are about estimating, so I'm not letting /u/steveklabnik1 say anything more specific than that ;)
thought i was on the wrong subreddit there
That won't work in this case &amp;ndash; the intermediate nodes are wrapped in smart pointers (the [`P`](https://manishearth.github.io/rust-internals-docs/syntax/ptr/struct.P.html) type), and current Rust doesn't have a way to deref a smart pointer from within a pattern.
Ah, that explains it! Yes, 2016-12-19 works. Is there a way to fix the dates? I find it counterintuitive that they are off; if I want to install the same nightly on another machine that I already have on another, I'll reach first for `rustup show` or `rustc -V` to show which one it is, and if it's the different one that to specify as the toolchain, that's just... stupid.
Actually, I think Godwadler's Law is that the first person to start bikeshedding the lexical syntax of comments loses the argument.
TIL that Phike Godwadler is a famous computer scientist. [Read it first](https://www.reddit.com/r/rust/comments/5l08o5/rust_is_literally_haskell/dbrycyu/) on /r/rust.
A little of https://en.wikipedia.org/wiki/Godwin%27s_law and a little of https://wiki.haskell.org/Wadler%27s_Law .
Oh noes what have you done?
Less obliquely, I think it's high time for everyone to blow off some steam. I'll be goofing with the CSS for the next day or two, so if you don't want to be annoyed you can either yell at me here in the comments or just take a break from the internet until 2017. The rule on memes is hereby relaxed for the duration of the bacchanalia, but still don't be an asshole and all the rest. Have fun! Or alternatively, type in all caps at me in outrage!
I did too O_O.
How is Rust faster than C?
Star makes music faster but not Mario. But... I get your point.
Hey guys! So I'm currently starting my first Rustkell project! Currently trying to decide between Stack, Cabal, and Cargo.... @_@ Any suggestions? I heard Cabal is a rip-off of Cargo and Stack is like Makefiles but with a better CLI. Somebody recommended that I use Cabal with Knicks, but I'm not from New York and never followed Basketball much, should I?
But wait, /u/kibwen, this custom CSS puts our community in danger! How are we supposed to withstand the onslaught of mernes that are sure to come?
OCaml isn't nearly as user-friendly as Rust. I'll take Rust over OCaml in almost every case, for reasons mostly due to Cargo, rustup, and the Rust Book.
I've been reading ? as "carry" since it's from the Carrier trait.
[I do this because I love you, my child.](http://imgur.com/a/pQv6I)
Why I Love Rustkell, Ep. 1: Higher-Kinded Polyamorphism
 let mut bytes = "Hello".as_bytes().to_vec(); bytes[2] = 45; assert_eq!(::std::str::from_utf8(&amp;bytes), Ok("He-lo"));
I like this layout more than the normal one. It's cleaner and easier on the eye. I also thought we had a "no memes" rule... ;)
dude, it's "its" not "it's".......
I disagree strongly. Comic Sans would greatly improve whimsical readability.
Rust is like a burrito.
So does this mean I *can* bring my "Rust is actually a parasitic fungus that ruins our good crops" post to the table?
I thought it was 'all identifiers must contain an emoji'
Look closer at my mernes^1 ;) ^1 MERN is a scaffolding tool which makes it easy to build universal apps using Mongo, Express, React, NodeJS, Redux and Webpack. Needless to say, this is not the place to discuss this specific combination of web technologies. Why would you even think this?
I'm legitimately impressed that you had that saved somewhere. Alternatively, that you took the time to look it up in the internet archive.
I would like a badge for winapi that says 100% unsafe please.
While I think software reliability is something Rust can greatly improve on, I don't think it's there yet. The current story with panics (basically untyped, unchecked exceptions) is a cause for concern. It is almost impossible for a library to guarantee that it won't panic because there is no compiler support for ensuring this. The depreciation of the (recursive) [#\[no_panic\]](https://internals.rust-lang.org/t/no-panic/1356) idea leads me to believe that Rust won't be doing it any time soon.. So you're left with no way to statically check that code is panic safe, you can't look at a snippet of code and know that it will not panic. And even if you have proven (to yourself) that a set of code won't panic, updating your dependencies can violate that belief. Due to the stigma around panic, it is common for a panic to kill/reset an entire application rather than result in a localised cleanup (where appropriate). Even if that were not the style, something like `panic::catch_unwind` can only match on strings if it needs to determine what actually went wrong. I understand the reasoning behind the current approach, exception safety can be difficult to get right even for experienced developers, but the current approach seems to trade off reliability for security and simplicity.
May I propose 'scythe' operator? The '?' operator reminds me of "short circuiting" and "inline if". Abbreviated, it could read as SCIIF, which sort of sounds like scythe. Scythes sometimes use metal blades (rusty?) which cut and return the harvest (Error in this case). If the scythe did not cut, the harvest continues to grow (like the code continuing on). Plus, it looks sort of like a question mark.
I'm compiling Rust to asm.js and use it with NodeJS, React and Webpack (not the others yet). Do I have to fear that I get banned?
It's not "like", it's just it. Rust is a burrito.
RUSTkell IS WATCHING ALWAYS follow the b̗̜̲̪̮̲ọ̙͇̦̰͖̭̺r͚̱͓ṟ̙̗̝̠̬ͅo͓̘ͅw̘͓̠ ̲̩̘c̩̙̲̙̥̲̝͇̫ẖ̬̪e̯̖̻͙̯̘c̻͖k̯̬e͉̻̖̮r̲͕͓̪̞͚ ͚̭̬͕̘͖&lt;͓̠͙̯i̲͈͚̣̹̘n̗̞̣͕̪͈̪̺͎ṭe̻ͅͅͅr̼̙̱̦͉̥̘̺ͅa̗c̞̠̱̠t̩̘̖̻̲̱̺ͅi̩v̜̱̼̭̦̮͈̟ͅe̖̱̲&gt;̳͕̪͈̖͔:͈̬̥͎̜͙1͕̯̦̠̟͔̻̙:̠̠̹͇̟̩1͔̤:͙̻͔̫̱̮ ͚̮ ̫ͅ ̬̗͇̪̘͎̭ ͉̘͙ ̫̘O̦v̠̺͎e̝̱̪̤r̬̗̺̬̟̖͚l̩̺͔͔a̫̙̜̩̼̹̠̙p̞p̳̯͚̻̳̞ị̫̲n͈͔͚͓̺̞g̲̫̟̯̮ ͔̹̜i̦͚͖n͍s̥̮͓̫t͈̦̹͚a̠̘̙n͇̠̤c̹̙͈̟̫ͅe͕̞̪̠̯̪̲s̞̘̻ͅ ̯̜̞̥̱̤̦ͅf̲͉̭̬̙o͓̯͕r͈̹̙̞͓̤͙ ̦͔̗P̝̤͔̟̱r̤̗̫̞e͕̝̺̫t̰̮̻̩̟͔̣̻ṯ̳̼͙̝͎͍̳ỵ̥̞̺̣̪̖͇S̺̹h͚̱̜̳̘o͇̪̯̺w͓̬ ̖̳̹̪̩̱(̣̠͚̳̹͖̰̙̮C̥͉͓͙͙̟̼o̞̝ͅm͇̯̠ͅp̝͖N̥̣͈̝̥o̝̖͍d̼͈̼̠̙̟̻e͇̻̜̣̣ ̘̲̙̞̱̤I̞̲͚̮͇n̝̩̝t̠̤͔̪͓̤̼)͎ ̹̣̤̬͕̫̝ ͖̫ ̰͇̻̹ ̱̮͚̫̤͕ ͕̦̫̺̩ ̮͉̹͔̹ͅ ͙͎̞̦̰͚̤a͚͎̣̳̺͚̥͔r͈̫̦ͅi̩̰͎͙̣͚s͓̹̱̥̠̹i̹̬̜n̟̟̳͔̤g̩̤̜̻̙̤ ̪̰̯̞f̲̤͎̳͕̦̲̳r̞͉̜̩o̗͙̩͚̙͉ͅm̼̥̖̳ ̳͓̜ͅa͕̼̗͈̣̱̺̯ ̰̺͇̰̘u̗͚͉͔͔̳̳̲̱s͇̰̣̣̤̘e̝͚͍̘͈ ̪̯o̝͎f̞̘̠̩ ͍̺`̭͙̹p̬͕̣̤̹̝̗̖̞s͍̜̬h̹͔̻̩̹̻͈̭̲o̞̘̞͈w͉͓̣̙̙͎͎̭'̩ ̫͖n͔̝̫͇o̹̬̪̗t̙̳͇̩͚̬̘̟̗e̝̻̼:̙̬̹ ̹̫̱͕̖ͅp̣͖̲͙r̗̙̜̮e̯͚̙v̹͍̬̝ͅi̳̖̻̙̹̲̪ͅo̪̬͇͓͔̱͙u̖͓̜͙̺̻̦͈̤s̼̹ ̰̰̹̺̞̻͎̘b̩̜̠̙̘͕̱ͅo̺̭̦͙͙͖̙r̙͕͈̮̖̩͙̥r̼̮̯̻̖̗o̼̟̥w̜̠͙͚̖ ̫̯̠͈͔̹ͅo̱̣̹̰̩f̥̮̱͔͓̫̭̼ ͔̫̮`̮̭̼̬͔̬x̟`͈̮͈͖̪ ̦̭̫ͅo͇͓̺̖͙̼̫̹c̹̪̘c̪̪ṳ͓̫̫̝͙̻͎r̗͈̜̖̟͔̜̬̺s͉̜̠̫̯̻̗̬ ̠͈͓̥̫̪̞h̳̺̤̮̖̭̹e͙͕r͉̱̮͍e͕͔̜͎ͅ;̱̤̹͙̳̱ ͍t̩͕̻͚h͓̜͔̝̭e̺̖͍͚͖͉̠̻ ̻̙̖m̥͔̬͖̤͓̼̹u̼̦̪̰ț̠̖̭͇̤̮ḁ̦̳̬b̳̮l̟̙̗̞̘̘͎͉ͅe̻̞̪̣̪̗͓̲ ̯̪͉̼̟̻͔̭b̩̲̘o̰̤̩͉͚͚̟͈r͕͚͇͇̙̖̼r͉o̬̺w̞̞̙͕ͅ ̫̰̣̺͎̝ prevents s̡̛̲̗͔͙͈͉̖̀̕ͅͅu̬̝̫̯̠̝̩̗̺͓͕̱̯͎͠͝ͅb̯͎̟̱̘͔̱̩͘͜ͅs̡҉̨̻̙̹̬͕̘̫͚̜͉͓̜̞͔͕͟ͅͅḙ͍̤̫͜͞͠q̷̶̧̡̗͕̬̪̺̳̩̦̗͓̖͈͚͍͡u̴̷̡͏̸̻͎̟̬̯̦̻e̢͏̯̠̪̤̤͎͉̬̲̳͚̝̗͎̱n̵̛̗̞̺͍̲̩̣̺̳̮̺̤͝ṯ̢̹͈͔̪͉͕͕̻͞ ̗̼̥̪͈̰̫̫̦̰̟̫̯̀ͅͅm̵̧̝̳̻̣͚̲͔̱̬̳̹͞o͏̴̳̱̥̪͓̗͙̖̣͘v̛҉̡͈̤͖̼̳̰͈͇͝ͅȩ̴̷̖̳̳͕̘͢͠ͅs̛̹̬̗̮̘̥̼̮͎̪̮̗͔̦̹̬̺̤͜͡ͅ,̧̝͈̫̜͞ ̨̮̩͇͓̳͉͍̳̮̩̫͍͓͉̕͢͜͠ͅb̛҉̧͇̞̣̱͠ͅớ̢̻̫̱̠̣̼ͅr͏̸͔̘̖̲̳̦̹͎͎̖͎̝̤̟͟͝ṛ̨̢̣̮̭̳̱̣͜o̡̡̬̳̩̯̼̝̮͠͞͠w̡̖̫͍̙͍͈͍̬͙͍͙̫̪̞͜͜͠s͏̡̞͈̤̺͎͎̞͔̱̺̙̩̹͉͇̯̰͉,̨̛͔̰̱͕̖̘͔̠͈̘̻̫́ ̸̶̧̬̜̺̣͇͚̫̼̣̗̖̫̭̼͝ǫ̕͏̢͈̹̻̼̗͖̕r̷̛̤̝̱̦͚̠͇̹̻̼̫͍̱̪̝̣͟ͅ ̵̨̛̩͖̲̫̭̻͎͍̹̱̙͟͠m͏̫͎͈́͘o̸̸̼̲̹͔̝͍̳͍͖̣d̡҉̗̹̬̩̬̗̭͕̘̬̝̳͉i͘͏̡̜͇̮͎̭̘̀f̛̯͎͈͕̬͎͉͚͇̰̭̞̹͇̙̲̣͟͟͞i͟͝͡҉̴͖̤̟͚͖̖̫c̴̻̟̱̮̞̩̫̹̯̮̤̪̝̘̟͘͟͡ͅạ̜̫͉͓̹̮̜͈̗͈͔̰͎͙͍̳̖͡ͅţ͙̜͍̦̬̳͈͇͎̱͍̮͈͙̥͉̯́͜i̧̢҉̼̲̦̠̖̰̲̳͖̞̳͙̟̤̖̻̬̦̲ò̸̦͖̟̬̙̙̣̕n͈͇̘͍͉̗̥̯̘̯̙͙͜ ̸̨̧͎̬͔͈͟͡ó̵̝̗̬̻̻̮̰͖͍̟̹̥̮̰̖̰̀̕f̴̷̢͞͏͚͇͓̖͔̭̬̝̯̘͕̦̘͎̫̪͇ ̸̟͈̗̭̝̲͎̬̻͔̦͉͚̗̜͢`̴͔̲͕̣̝̯̲͈̬̀͝ͅx͕̗̲̳̤͟`̴̧̢̛͙͇͙͎̥͚̠̲̱̼̦̝̲͉̞̮̭̘͞ ͉̠̪͎͙͠ͅu̡̕͠͏̨̱̯̣̬̻̥̝̼n̴̺̟͈̩̦͉̠̝̬̟̥͚̣͘͞t̢̛̼̦͖̠̰̩͙̯͉̜̬̘̯̼̞̠̲́͡͝i̵͘҉͈̱͉̯̝̘̹̳̪͕ͅͅl͇̘̖̮̺̮͉͚͇̮̣̟̰̜̜̠͚͘͟͜ͅ ͏̞̪̰̼͓̳̤̮͚͕̫͓͖́͞ṱ̷̵̴̸̩̰̣̗͜h̴҉̼͇͔͉̼͍̳e̷̲̟̖͇͉̝̣̜̮̰͕̼̹͉̺͇̘͢ͅ ̸̙͖̦̼̪͚͉̫́͢͝b̶̡̨̭͙̫̤̤̣̣̲͎̗̗́̕o҉́͟͏̴̙͇̯͎̭̗͇͎ͅŗ̗͔̫̰͔̝̩̀r̛͏̶͇͉͉̩̹̘͕̪̥̥̘̯ͅo̙̭̘̬̹̠̞̺̩͖̠̺̥̖͍̝̳̥͟ͅw͏̶̡͚̣̳̥̭͚̣͈̰̲͕̫̥͇͇͕͎͎̥͞ ̶͔͕͚͉̮̜̗̱̭̼̭̹̟̭̼̭̦̟̞͜͡e̴̤̮͍̰̳͝͝͠ṉ̵̴̜͓̲̞̰͍̜̼̞̬̠͟͡d̶̸̛͚͈͔̮̰̠͝ͅs̸̘̳̥͓̳̰̯͍͖͘ ̸̙͕̤͈͓̪͖̣́ ͏̢͕̝̫̪̣̫̤̘̳͇ ̵͙̙͇̻̺̬̘̀ͅ ̶̛͉͕̞͉̤̥͚̻̭̪̬͟ͅ ̴̧̢͎͙̪͕̲̰̹̼͙͍͕̻̮͈̕͡ͅ ̶̡̤̳̗̙̟̞͕̺̲͕̘̖̱̹̖̠́͡͠ͅ ̵̸̢̦̝̻͖̰̥̩̝͚̯͉̭͖̫̯̟̙̻̗͟͟ ̦͎͓̪̘̱͍̮͍̞̕ ͢͏̗̯̖̙̗̟͖̬̰̦̭̭̺̻l̹͇̘̭͕̳̹͉͓̥̦̙̗̲̩̭͖͚̀̕͢͜͟é̛͈͕̘͍̳̮͚̖̹̯̙̜̥̮͍̫͖t̶̡̞̱̳̙̬̲̀͘͝ ̴̨͖̘̣̪̫͓̹̭͚̫̗̭̥͖̀͟͞y̸̧͓̮͇̪͔͝͝ ̸̴̡̧̳̺̟̙͓̲̦ͅ≠̢̼̹̳̣͈̖͖͓̠́ ̤̹͇̖͢͠&amp;̸̢̫̣̲̖̖̙͖͎̰̪̰͔͉͟͡m̸̨̳̭̳̙͚͍̯͕͔̩̖͕̕͞ụ̯͠ͅṱ͙̠̫͇̺̣͖̳͟͜ͅ ͉̭̱̠̣̫̻͖̦̣͇̮̪̮̦̥̝́̕͘x̨̖̜̜̜̤́͞;͏̝̪͈͎̻̹̙̮͞ ̨̟̠͉̗̖̪̮͟͞ ͞҉͝҉͏͖̥̼̼͈ͅ ̢͙̠͚͇̱͙͕̣̗͡ ̢̹̬͔̬̘͠͞ ̞̣͉͙̦͉̼͔̠̕͢ ̡̀҉̗̜̘̤̠̥̜̘̠ ̷͏҉̷̰͎̳͉̰ ̶҉̴̲̯͕̠̫̣̯̰̭̘̮̳ ̶̷̢͙̯̬͉̙̻̰͖̫̼̕ ̴̯̠̖̤͍̜͕̩̥̠͔̹͈͓̥̲̱͘ ̨̕͏̴̫̳̫̬͙̟̹͚͈͎̞͙̠͚͔͝ ̸̧͖͓̝̭͔͇̰ ̢҉̜͚̮̪͉̺̠̦̝̣̻̭̦̙̭̖̝ͅ ͢҉̯͔̺̖̮͔̗̞̮̰͈͍̟̜̰̠̩̙̕ ̸̨̪̪̻̟̟̝̮̱͍̝̮̼̲̜̞̀͜͝ ̵̡͏͓̲̝̙̘͚̣̞̖̼͔̫͍͘ ̧̨̱̱̘̣͉̫̻̙͖ ̖̱̳̫̮̤̮͎̀̕͝ ̶̡̞̯̹̙́͘͟ ̵͏̴͙̣͕͚̭̱́ ̡̹̠̲͉͙̠͓̱͜ ̡͉̻̣̟̥̗̬̝͓̳̹͉͇̤̫͍͜^͖̼̜̭̬͔̻̘̻̪͚̀̀͜ ͡͏̲͓͙̥̠̦͍̜̦̰ ̛̖͖͈̖̩̱̳̲͇͉͎̘̪͇̦̜̞͢ ̵̱͍̫͡ͅ ̨̩̠̬̟͉̕ͅ ̢̝͍̪͍͙͉̱̱̰̦͖̗̯̩͕̬̱̀ͅM̶̵̢̢͉̲̗̜͢á̡͠͏̳̭̘͎̞̮̟̭̞̖͉̙̼̖t̸̶͙̣͖͚̱͕͇̜̲̳͕̥̲̰͉͡c̢̛̪̠̙̱͖͍̹̲̪͎̥̱̯̯̣͍̹̣͔h̯̱̺̬͖̺̫̘̞́͠ͅì͍͉̖̭͈͎̰̳̯̀n̮̥̯͇͖̰̭̯̥̩͈͔͉̫͕͜ģ̡͙̹͖̦͕̜̺̜͈̺̥̝͢ ̧̮̻̥̱̗̖͍̼͉͈̀͞i̧͍͓̤͈̗͇̜̰͞͠ǹ͜͏̞̬̲̯̪͎̖s҉̵̬̭͎̲͚̕t͔͉̘̜̦̣͉̲̰̻͎̞̤̖̬͎̯̀ͅͅą̴̩̬̱͎͔̠̼̱̮̫̙̦̘̗̪ͅǹ́͟҉̠̤̬͙̙c̦̖̳͎̞̲̻͙͈̺̞͚̱̺̀̕ͅe̷͇̣̱̥͍̕͟͝ͅs̸̶̺̟̭̟͉̩͚̀:҉͙̣̳̥͎͍̫͈̠͡ ̴̟͔W͔̹̤̳̜̻͕͝i̱͍̺͖̯͇͝t̟͚̙̘͎͟h̡͕̯ ̙o̶͉u̷̺t͓̫̖͇̙ ̩͚o̬̻̜̟rd̡̫̬e͉͕̤̙̼̻̦r̞͈.̥͈̝͓̙̦̳͢ ̶͉͕̪̥̰̬T̛̠̰͉he͜ ̭̭͕̞̣͙N͓̺͙̫͓͓̗e̲͉̼z͝p̰̥̙͕͖͖̗͡e͍͈̜̠r̩̘̟̲d͔̻̖ͅia͓n̪͓̯̲ͅ ̻̦̠͘ḫ̭i̵̥͎̼̹̙ͅv͕e͓̤̦͠-̛m̦͙͝i̜͖̫n̹d ̸̹̠ǫ̪͙̮̫͈͔̦f͔̦̜̬͙ ̘̯̫̼c̮̰̹h̡̘͇̹a̤o͏͍̠̮̹s͙̮̲.̴͎̘ ̠̘̜̣͡ͅZà̜l̰̞g̹͕̳̮̳ͅo͔͇̘̟͕.͍̭͔̖̪͘ ̧̫̘̰̬̙̱̗H̖̣̰̭̥͙̼e̛͕ ̞̫͍̺͜w̟͖̖̜͎h̥͉̙͔̟͉̤o̪͞ ̺̮̩̫W͕͚̣à̝̞̲i̬̜̬͠t̬͉̫͇͡s̜̺͚̮̥͞ ͍̙̗̗̠͙̺B̗e̹̲ḫ͞ͅi̧n͎͈̬̪d ̳T̨̩̲̣͎̪̞͔h̫̙̹̞̼̮́e ̹̼̫̠͎W͕͙̜͔a̟͙͇̣͎l̝̱l̵̫̩.͜We strive to treat others with r͕̰͇̰͚̀ẹ̀sp̗͡e̵͈͓c̩͎͞t̥̖,̩̦͙̮̖͜ ͓̘̼̻̼͉p͏̲̪̞̞̹͍͈a̶̳͈̫t̖̫͚͖͙ị̭en͘c̵ẹ̷͙̞̠͖,̫͍͖̤̣͝ ̲̘̱k̴͍͖͔i̬͎n͔̗̬̘͍ͅḓ̭̱ńe̸͍̰s̞̰͎̖͉s̨̹̼͙̠͈̯,̛̰͕̰ ̠̥a̼̯̞n̡̥̣̪d̴̖̗̘̲͉ E̻͙̮͔̳̩̤ͬM̮̻̲̖͙͇̼ͨͨͭͬ̂ͪP̲̹̻̯̲̄͒Aͨ̍̒T̳͔ͫ̀̉ͮͅH̥͕̳̺̳̓̑͛Y̭̥̼͉̪̌̊̿ͨ͋̎ͅƯ̹̲̋ͦ ̵̜̻̥̼͚̣̺͉̹̀ ̵̧͡҉̖͖͕̜̘̱͉̟̳̠̪͔͖̦͜ ̴̦̯̟̞̻̀͟ ҉͏̵̯̜̝̖̦̼͖̗̺͚ͅ ̡͉̗̪̬̯̯̫̭͈̲̳́̕ͅͅ ̵̸̵̣̥͓͕̼̭̘̫̟͎́ͅ ̢͎̲̲͕̝̺̭̬̯͙͘͢͝͡ì̵̴͖͖̺̹̥̜͉̝͉͕̲̲͕͓̥̦̟̖̥́ń̛̛̩̣̙̖̮̘͉̹͓̤͎͇̱͢͞ș̴̺̙̦̞͓̥̫̤̠̞͙̬̻̦̜ͅt͏̨̝̬̩̝̬̰͘̕a̵҉̷͔̺̤̻̻͉͉̝͙̪̙̞͢ͅͅǹ̷̢̝͚̰̖̲͎̪̪̱̣͕͡c̵̷͕̝̙̱͎͍̪̩̦̘̮̝̬͠ͅͅe̛̤͈̫̗̩̝̪̣̦͕͇̬̣͚͢ͅ ̸̡̣̟̺̫͓̠̝̘̩͙͇͔͇͇̟͢͡ͅ(̵̧̨̖̙̪͙̖͕̳̭̭͚̥̻͓̲̺̕͝G͏̡̻̬͎̜̟͙̱̘͍͡ͅ.̸̛̙̫̲̭̹̻̻͇̩̼̟̗̲͔G̢̛̣̻̼̫̺͖̲͔̘̲̲̕r̵̴̷̫̺̟̬͚͈̦̱͖͟͟a̷̠̭̩͚̺̜͜͢͡ͅͅp͘͝͠͏̢͎̬̪̰͚̙̯h͓̭̱̻̲̩̫͖̥̭̳̪̯̦̀ ̧̮̗̮̬̤̩̘͎͕̯́g҉̶̠̪͉͉͝͡,̸͝҉͢҉͚͚̼̼̲̣͉̗͙͚̼̞̯̳͖̗͇ ̶̢́҉͇̬̺͕̘͕̟͖̞̪͇̻̙̦̺͉̭ͅP̶̴̨̺͍͔̖̜̦͈̻̥̟̞̀͠r̴͈͔̺̗̤̙̞̘̗̪̫̗̜̥̣̭ͅe͢͏̹̜̙̠̜̮͎̩̦̹̩̣̪̖̕͟t̹͔̥͓͚̱̙̰̹͚̦͘ͅt̨̖̳̳́͠ͅy̶̷̧̨̹̭̭͍̼͈̳̠͕̞̖S҉͔͎͇̮̼͓̻̰͘͠ḩ̹̞̦̫̥̗͔͍̻̞͡ͅọ̶͔̥̩̦́͠ẃ̷̢͚̣̩̜̱̗̣͔͖̮ ̶̦̹͈̲͕̰͚̖͝ͅ(̀͏҉̡̦͕̰͎͚̻̰͍͇̱G̵̡͉̟̠̩̱̩͇̫̻̟͍̞̲̭̘̫͢͢.̸̛͉̼̳͕̼͎͔̩̘̬̱V̷̨͓̤͕͉͙͈͞ͅe̛͏̲̬̯̹̬͍̖̲̜̱̻̖̟͍̱͢r҉̩̰̥̠̺̲̼̻̭̩̗͍̜̘͉͎͔̀͘t̝͙̣̟͉̯̮̝̰͇̘̬̱͉̱̲̀͢͝e̤̬̠̘̬̫̰̻̝̝͘͘͟x͏̡̻͚̰͕̲͖̘̟͙̗̰͈̮͍̀͞ ҉̞͔̰̞̪̘̠̻͚̜̲͚̭̺͙͎ͅg̴̨̰̘̫̯̕͢͞)̷̛̰̲̪͍̖̬͈̫̲̤͙͞ͅ)̸̸̴̨̨̯͎̭̙ ̨̧̹͕̱̖=̥̤̳̜͜&gt;͘͏̧̨̝͉͈͖̦̫̱͈̞̪̠̫̞̰͚͢ͅͅ ̢̯̙͕̭̘̦̩̫̞̭͇̕͡P̷̵̸̧͕̮̳̹̜͍̲ͅr̴̶̢͖͍̝͎̗̣̝̱̖̺͓͔͉̀͜é̖̗̟̰͇͈̰̘̰̮͓͉̻̝̠̟̺͉̕t̴̴̬͕̘͓̮̘͓͈̭͝ͅt̵̢͍̩̻̯͇̫̭̘͠ý̡͖̲͔̲̬͔͚̯͎̬͍̹͎̜̭͈͕̘͠S̷̶̛̺͕̪͖͚̱̩̘̟̕͞ḥ̵̬̝̠̙̦̜̻̙̯̣̀o҉̥̹͓̖͕͓͚w̲͎̭͈̦͎̫͈͕͎̩͈̩̘̻͖͎͖̰͜͝͠͡ ̸̡̱̦̖̤̖̬̟̻̻͙͎͟͜ͅͅǵ̨͡͏̗̰̜̲
Nonono, you're thinking of Swift 4.
The second thing is lazily evaluated. No one has ever made it past the first.
The sessions.end() method seems odd. It would seem more idiomatic for a session to automatically end when it's dropped. 
I heard idris can statically validate your strings for much doge, very cheesburgerz
I view Rocket as an (amazing) experiment. The language will change a lot in 2017 I believe and you will get people from different backgrounds with new ideas (or at least new to me like Rouille 'middlewares'). Maybe Rocket will be the de-facto framework but it's (imo) way too early to say
much borrow such falafel
I wouldn't call a scripting language "developer friendly", though I suppose that depends how you define the phrase. A scripting language is one which focuses on writeability at small scope. This trades off readability (eg. Perl, Bash), maintainability (dynamic typing, type coercion, dynamic scoping, etc), and performance.
To directly access the interior of the pita, you have to use an unsafe block, or else you might drop the falafels on the ground and dirty them.
Don't you just have to seq thunk? Should show up then.
Note that as of yet, there is no formal proof that you will make progress towards the hummus.
...because we clearly don't have enough Mario references this week.
I am in for a copy when it comes out in print. (Mostly as a thank you to both of you for all the work you have put in. The online copy is more convenient than the dead tree.) Is there someone who is gathering info on projected sales who I should be in touch with / give money to? 
I thought this was r/programmingcirclejerk
[removed]
The developers of Haskell have, but they only share the secret through Haskell. 
People mistaking this for /r/playrust is always funny.
Ive long been dying for this clarification: is the "burrito" meme a dig at Douglas Crockford for saying a monad is like a burrito?
When I run this code: extern crate obj; use std::path::Path; use obj::{SimplePolygon}; fn main() { let obj_file = obj::load::&lt;SimplePolygon&gt;(&amp;Path::new("assets/cube.obj")).unwrap(); for object in obj_file.object_iter() { println!("Name: {}", object.name); for group in object.group_iter() { println!("{:?}", group.indices()); } } } I get this: Name: Cube [[(1, None, Some(0)), (2, None, Some(0)), (0, None, Some(0))], [(3, None, Some(1)), (6, None, Some(1)), (2, None, Some(1))], [(7, None, Some(2)), (4, None, Some(2)), (6, None, Some(2))], [(5, None, Some(3)), (0, None, Some(3)), (4, None, Some(3))], [(6, None, Some(4)), (0, None, Some(4)), (2, None, Some(4))], [(3, None, Some(5)), (5, None, Some(5)), (7, None, Some(5))], [(1, None, Some(0)), (3, None, Some(0)), (2, None, Some(0))], [(3, None, Some(1)), (7, None, Some(1)), (6, None, Some(1))], [(7, None, Some(2)), (5, None, Some(2)), (4, None, Some(2))], [(5, None, Some(3)), (1, None, Some(3)), (0, None, Some(3))], [(6, None, Some(4)), (4, None, Some(4)), (0, None, Some(4))], [(3, None, Some(5)), (1, None, Some(5)), (5, None, Some(5))]]
You could try a different library, e.g. obj-rs and tobj have documentation: https://crates.io/search?q=wavefront
Thanks, happy to hear it :D
Okay, I will try obj-rs, as it seems to make more sense.
The Canada operator?
Someone pointed it out already (the deleted comments). I messed up and it's not like I can change the title here. As long as you got my point.
https://www.reddit.com/r/rust/comments/5l08o5/rust_is_literally_haskell/ /u/kibwen (our all-mighty moderator) has decided the next few days will be a time to blow off a little steam and I assume it was partly inspired by the flood of "rust is..." entries we've been getting in the last couple of days, which seem to have been touched off by https://www.reddit.com/r/rust/comments/5krhr0/rust_is_more_than_safety/
The post references Mario but the whistle was originally from Legend of Zelda~
I don't know if Rust is literally Haskell, but it's probably not literate Haskell.
Don't know if it's totally equivalent to the python function, but there is a [zip method on iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.zip)
Sorry, that's just how I visualized it in my head.
I very much wish that I could do something like this: if let Token1 | Token2 = match { // do something } It's allowed in a match but not in an if let.
Forget Ferris, Rusty Cohle is our new unofficial mascot.
Hm... CSS renovations you say? But CSS is not Rust. Rust is CSS. You should rewrite this subreddit's CSS with Rust!
You mean higher minded polyamory.
Why is the comparison with Nim is important? Because Nim code is smaller? Are you making any implications? Looking at some of the Rust code (I don't know nim), the rust code is unnecessarily complicated, and doing things that are not part of each problem's specification.
TIL "and" is a curried function.
FYI, [I've crossposted the article in r/haskell](https://www.reddit.com/r/haskell/comments/5l0zho/the_haskell_community_can_feel_cold_and/).
Rust and Haskell are my favorite languages, so I feel right at home :p Just gotta take a bit of overzealous navel gazing as enthusiasm for the language! Though of course, a heap of skepticism is always smart
&gt; REGERTS Love this spelling. 
That definitely makes sense. Created an [issue](https://github.com/AlexPikalov/cdrs/issues/11). Thank you.
Cool! Nice to know!
I dunno. I prefer stuff on the stack.
About incremental compilation: https://blog.rust-lang.org/2016/09/08/incremental.html
Rust is a *particular* burrito that Graydon ate sometime in 2009.
Rust has abstractions that let you write elegant code which the compiler can optimize, while the same optimizations would be tedious and error prone to apply by hand so C coders are unlikely to bother. Also, the lack of mutable aliasing enables optimizations that are impossible in C.
I really love posts like this, comparing Rust to other languages is a hobby of mine. :) I'm guessing you're not getting much feedback due to being relatively uncontroversial, as there aren't many people who will leap to defend null, in any language. :P &gt; The first and most obvious is that Rust has always had Option. This means that there is no legacy ecosystem where you may run into a null value. This is true, but one thing to keep in mind is that even though we've had Option pretty much forever, we haven't always had Result, and for a very long time we tended to use Option in places that really would have been better served as Result. I'd like to think that all those places were found in the great library purge for 1.0, but I'm not 100% certain. &gt; Because ‘null’ (0) is not a valid address for our String type, we can use that to represent the Absent variant under the hood. I actually don't know if String is eligible for the nonzero optimization in the same way that &amp;T is. Are you sure about this?
On second thought, maybe we're better off without dependencies at all. We can sidestep the whole problem!
It is a good start. Library support for numerical computation is still young in Rust.
This metaphor first appeared on [this article](https://thefeedbackloop.xyz/safety-is-rusts-fireflower/) and then caught on. It can be summarized by [this image](https://thefeedbackloop.xyz/content/images/2016/12/IMG_3232.PNG).
Yeah, Rust has great benefits, but it's hard to get projects started. I'm planning to try prototyping in Python and then rewriting in Rust once the design is settled to see if that works out better. Of course, that does lose some of the benefits.
Nice use of &amp; to mean reference!
In case anyone is wondering, this is happening because the Rust Borrow Checker has become self-aware and started coming up with new and novel UTF-8 characters that your browser might not be able to display properly. https://stackoverflow.com/questions/6579844/how-does-zalgo-text-work 
This is what I felt when they announced the "?" operator... I was like, "why don't just give me a DO block?"
[Rust programmers encounter a `std::option::Option` at a drive-in restaurant](https://www.youtube.com/watch?v=GKNX6dieVcc).
People might think twice before using something called `unwrap_or_panic`. 
No, that list is strict in its first argument.
I have no idea what I've stumbled into and can't decide if I'm disappointed or not...
You cannot reasonably statically rule out stack overflows without severely restricting recursion and stack allocation. And is there really much difference between crashing with a stack overflow and crashing with out of memory? 
If haskell not too lazy i will considerate it
[Cellular automata to the rescue!](https://en.wikipedia.org/wiki/Rule_110)
Rust is a reddish brown mess you sometimes find on iron.
Definitely. While I technically "know" C and C++, there's no way I'm going to trust myself to code in them. On the other hand, as libraries become available, I want to migrate more and more from Python to Rust, simply because of the mindstate it enables (eg. fearless refactoring, no burning out writing bad type system analogues in unit tests, monadic error handling, etc.) in my existing projects. (The "as libraries become available" is the big thing. Right now, I'm mostly focused on several Django projects, a PyQt project, and a Python script I'm actively cursing because it's got a subtle bug that Rust would probably rule out, just as a side-effect of the port, but I don't know of any suitable OpenCV bindings for Rust.) **As far as systems programming goes, I may be able to help shed some light on the mindstate of people coming to it for the first time thanks to Rust:** It generally never even occurs to me to try implementing my own solutions to CPU-bound problems that can't be solved by binding to a library like OpenCV because I'm so used to the limitations of my slow-but-safe languages and so fearful of segfaults (given that code written by "the experts" on my desktop still crashes). My impulse is simply to see domains like real-time simulation as [heavy wizardry](http://www.jargon.net/jargonfile/h/heavywizardry.html)... and I can't justify 7 years of trial-and-error or paying for a second degree to learn them when I've got so many I/O-bound problems that would benefit me. (eg. For several years, I've had an idea for a class of simulation game I've never seen, but I wouldn't know the first thing about the supposed heavy wizardry that goes into making a simulation that can run in real time... and now [citybound](https://github.com/citybound/citybound)'s road-planning demo looks like it might finally be going in that direction. My idea was that nobody has done a game where it's your job to design road networks, right down to choosing where to build an [express/collector](https://en.wikipedia.org/wiki/Local-express_lanes) highway, what kinds of [intersections](https://en.wikipedia.org/wiki/Intersection_(road%29) and [interchanges](https://en.wikipedia.org/wiki/Interchange_(road%29) [[2]](https://midimagic.sgc-hosting.com/ichange.htm) to use, [walkable space](https://raisethehammer.org/article/2833/even_walkable_streets_dedicate_most_space_to_cars), [stroads](https://www.youtube.com/watch?v=F6jFnOnjzrk), [grade separation](https://en.wikipedia.org/wiki/Grade_separation) concerns (eg. weaving lanes), etc.) ...and all that is so demoralizing that I never even end up testing that hypothesis because my bias is so strong that I perceive the probability of it being wasted effort as so high that I can't justify writing the "throwaway" code to myself.
It's a pretty decent analogy. Folks can write what they want in their blogs. We shouldn't pressure people into compartmentalizing what they write about. Folks can care about multiple things at once, and they can also write about multiple things at once.
The mods are responsible for the shitty memes.
Throw the 2017 Road map in the bin and just replace it with that image – on the front page of rust-lang
A strong opinion is one thing, but a strong opinion that wants to be universally held needs to be rather more strongly motivated. There must be room for other positions, because not everyone comes to a language with the same background and needs. I bear the burn marks from mishandling C and C++, so I have a gut need to be more safe (unsafety tends to blow up at a remote site at exactly the wrong time). A person coming from a dynamic-languages background (in which I would include Java) doesn't understand the problem in this visceral way. If purity is more important than pragmatism, then Rust will be doomed to avoid success at all costs, as the Haskell joke goes.
me too thanks
I AM ALSO FILLED WITH REGERTS!!! WHAT ARE REGERTS ANYWAY???
Perhaps you're looking for the [unzip](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.unzip) function. Sample usage: fn main() { let a = [(0, 0), (1, 1)]; let (left, right): (Vec&lt;_&gt;, Vec&lt;_&gt;) = a.iter().cloned().unzip(); assert_eq!(left, [0, 1]); assert_eq!(right, [0, 1]); }
&gt; I actually don't know if String is eligible for the nonzero optimization in the same way that &amp;T is. Are you sure about this? It effectively work, `size_of::&lt;String&gt;()` and `size_of::&lt;Option&lt;String&gt;&gt;()` both yield 24: https://is.gd/vMVXwe But we can go through the source to make sure: * `String` is a newtype of `Vec&lt;u8&gt;` * `Vec` is `usize` and `RawVec&lt;T&gt;` * `RawVec` is `usize` and `Unique&lt;T&gt;` * `Unique` is `NonZero&lt;*const T&gt;` * the null-pointer optimisation [is transitive](https://github.com/rust-lang/rust/blob/master/src/test/run-pass/enum-null-pointer-opt.rs#L70), and the very type used to check for that is in fact `String`
Sadly while it's equivalent in spirit it doesn't allow for the same "hacks" you can perform using `zip(*args)` in Python.
Note: Knuth does not use LaTeX. His macro collection is called "plain TeX".
You also have the izip! macro in the itertools create: https://docs.rs/itertools/0.5.8/itertools/macro.izip.html
The "huh"? As in "So that's a valid result, huh? Well then, let's ..."
Your videos motivated me to start learning rust and to implement an emulator of my own (for the z80). Great to see you doing them again!
The chapter reads really well, great job. There might be some kind of mixup in 12.6, though. (Mind you, I have only read through the chapter and tried to follow the code modifications in my head, so I might have missed something.) It says at the start (and after the change to write to stderr) that the error message when run without arguments is: "Application error: No search string or filename found". I expected this to print a "Problem parsing arguments" error instead. Also the Config parsing error path is not refactored to output to stderr, so (again) unless I missed something, running the program with no arguments would still print to stdout after the refactor.
Box of chocolate**s**
Nice. It's great to see a pure rust implementation of a Cassandra driver. 
Rust is a multiplayer survival game
Jeremy, could you link on the Redox website this reddit post or tell why it is neccessary to donate? Not everybody knows, that you quit your job in order to work as a full time developer on Redox. This information changed everything to me, so that I became a Patreon supporter. Maybe you could format the "Donate" menu better. Maybe in bold and with a dollar sign: **$Donate**
Cool! Now I have a working example if I need to visualize 3D stuff with Conrod - thanks ;-)
In many places you can't do that without `unsafe` behaviour.
Thank you. But it's still too far from perfectness. :)
In `newer_version_1_5.clone().into()`, is this call to `clone()` needed?
Hmm, if there are only bindings i'd be interested in helping out on working on a better wrapper. Let me know.
Download link: https://github.com/user6553591/rust-vulkan-test/releases/latest.
Racer can't autocomplete everything, unfortunately: https://www.reddit.com/r/rust/comments/5kdvkq/hey_rustaceans_got_an_easy_question_ask_here/dbrwuix/
rust is a pretty popular target over at /r/programmingcirclejerk
This is a follow-up to https://www.reddit.com/r/rust/comments/5j63vn/these_weeks_in_planetkit_5_finding_structure/. As before, you can find the code on GitHub here: https://github.com/jeffparsons/planetkit. I'm pushing code as I go, so if you're interested you can also follow along there! 
Here are reasons, why you should prefer Apache 2 over MIT. https://news.ycombinator.com/item?id=3402450
I'll put my money on Fira Sans (or Fira Code) then.
* There is no decent (or even half-decent) option for building OCaml. In the Rust ecosystem, Cargo handles this. * OPAM is as user-unfriendly as any piece of software I've ever tried. * Most OCaml books are either dry and theoretical, critically outdated, or both. * OCaml's IDE situation isn't much better than Rust's, and that's one important criterion for me when assessing a language ecosystem's maturity. I would like to challenge the assertion that OCaml's ecosystem is meaningfully more mature than Rust's. (But then it comes down to your personal definition of maturity.)
&gt; safty guarding In light of [verboten-gate](https://github.com/rust-lang/rust/pull/38628), it is nice to see an increased usage of German loanwords: - "Saft-y" is a Germanism built from the German word "Saft" (juice), and the English adjectival suffix 'y' and means "juicy". - In the same way "guarding" is obviously a misspelling of same-sounding "Gardine", which is German for "curtain". I have no idea what "juicy curtains" have to do with Haskell though.
1v1 me rust m8
That's what we Rustkeleers call manual memory management of a higher kind.
Optimal (safe) C is very very error prone to write, Optimal (safe) rust is much less error prone to write. Even unsafe rust has significantly more guarantees than raw C. On average programmers will be able to fearlessly write code with less copies and allocations with less fear than with C. Also, every pointer in safe rust is already "restrict" in C terms, so there's more scope for optimisation by default. Basically rust has a faster default set of tools than C since you don't have to be defensive.
Nah, I'd rather see Fura Code or Hasklug in their [nerd-fonts](https://github.com/ryanoasis/nerd-fonts) flavor!
\:D/
wooo :D
&gt; &amp;Mario I understood that &amp;
Lets start writing it, i'll accept nearly every pull for the lulz. Glory to Ruskell!
https://github.com/Hammster/rustkell Just make a pull requests, with anything you want. Glory to Ruskell!
What editor are you using? Those errors showing up in between your code looks pretty handy.
I was just searching for a z80 emulator in Rust two nights ago! Glad to see more of this being done. I have some ideas about targeting www.knightos.org. :-)
Thought I was in r/me_irl for a sec jeez
The `if err != nil { return err }` operator.
that's sublime text with the "rust enhanced" package :)
#Be nice. edit: #Bernice.
**Ben ice.**
Carl approves it.
did you mean to be on \r\playrust ? this reddit is for the programming language. 
this is madness i don't even know what bacchanalia means
https://play.rust-lang.org/?code=fn%20main()%20%7B%0Aenum%20Option%3CT%3E%20%7B%0A%20%20%20%20Some(T)%2C%0A%20%20%20%20None%2C%0A%7D%0A%7D
hurrdurr fml
[Verified IO bug, Rust proven unsafe](https://i.imgur.com/ZC4Dpdg.gifv)
How can you miss references, Rust is safe? 
and bro~i am chinese with poor english. i want to say is that the circle arounding in the logo--looks like guarding，metaphor of the safty promise of Rust
you're missing out if you can't use 💩 to indicate deprecation
We iterated on the code a bit, we probably missed some spots. I'll double check these, thank you!! &lt;3
I think that Rust developers focus on lower level development in part because they can. The combination of high performance and type safety is unique in language design space. Application level programming is definitely on the menu - the flagship app for Rust is servo after all. That said, I'd adopt a certain skepticism when your choose libraries for your project. Its early days yet and many are still immature. 
Well he did not `C` this coming.
Has anyone implemented Python in Rust yet?
Mostly this: &gt; I don't want to donate money to help make what ends up as proprietary software in a device made by the next apple or samsung.
[removed]
Great to hear! Feel free to offer feedback.
We should be more concerned about being able to run older versions of Rust in newer versions. Without this it won't be turing complete!
[removed]
Such safety. Much speed. Wow.
[I did it already.](https://framagit.org/antoyo/ion) Look [at](https://framagit.org/antoyo/ion/blob/master/tests/enum.ion) [some](https://framagit.org/antoyo/ion/blob/master/tests/testStructEnum.ion) [code](https://framagit.org/antoyo/ion/blob/master/tests/testSyscall.ion) [examples](https://framagit.org/antoyo/ion/tree/master/tests). But eh, don't even think of using this language: there are bugs even in the memory manager :) .
Wait, what does it have to do with asynchronicity?
It's a tongue in cheek reference to https://learnpythonthehardway.org/book/nopython3.html which stated something like: &gt; Currently you cannot run Python 2 inside the Python 3 virtual machine. Since I cannot, that means Python 3 is not Turing Complete and should not be used by anyone.
No soup for you!
I think that's what we had yesterday.
Would be cool if you could select the dependencies you want to use in the list and it automatically modifies your Cargo.toml accordingly.
What is happening with your keyboard? Why is that comma so big? Why did you only capitalize Rust? What is the meaning of that double dash? It doesn't bother me, I'm just curious to know how did that happen.
💩📧
the sidebar used to contain "no mernes" so I could have easily let this slip, but unfortunately it says "no memes" now. Also where did that weird Australian tea video go?
😅
I would _love_ for this to be a cargo subcommand. $ cargo search tds &gt; tiberius 0.1.0 | A TDS (MSSQL) driver
It's not available for preorder or anything like that yet. And since so many people have worked on the book, we didn't feel like it was right for us to profit off of it, so the profits are going to [OpenHatch](https://openhatch.org/) as [Steve mentioned in the announcement about the book](http://words.steveklabnik.com/the-rust-programming-language-will-be-published-by-no-starch-press). The best way to thank us, imo, is to find someone who's interested in Rust who might not be able to afford the book, buy them a copy, and help them out when they need it :)
why do i watched all of it?
Monads are all abstraction and indirection, so they use similes. Rust is all hardware and efficiency, so we use metaphors.
Thanks for the post! I love following PlanetKit :) Your posts are informative, and I like seeing how you solved some tricky problems.
Yes, but you can't plug that signature into a search engine to find a library that contains the function.
Looks like today is the [Carnival of Rust](https://www.youtube.com/watch?v=MKk1u5RMTn4).
Tomorrow we'll start a beauty pageant and the winner can name themselves 'Miss Reference'.
iOS version does not understand CSS I feel FREEDOM ( ͡° ͜ʖ ͡°) 
I like the trifecta.
well thats more hoogle specific than haskell in general though. Writing something like this for rust should be possible aswell for example searching for functions like this: (Fn(&amp;A) -&gt; bool, Fn(A) -&gt; A, A) -&gt; A difference with haskell is currying though. In Haskell pretty much all functions are curried, while in rust they are not.
It is a cargo subcommand
Oh, Christmas!
&gt; Knowing that your code is correct is not enough, you also have to convince the compiler of the fact. In my case, it's more generally thinking that my code is correct, attempting to convince the compiler, and realize that, uh, actually the code wasn't correct :x
This change should allow it to be detected now https://github.com/alexkehayias/harbor/commit/305e7f8c9b6ea4d59ea357950305c3f2b7797a00
It is. But I like to think of it as iron oxide.
I really like both the Rust and Haskell community. They are both helpful and very open. There is a difference in objectives though, thats certain. Haskell is pretty uncompromising about extensive abstraction. Lenses are "every possible way to access and modify every possible value embedded in any possible context in a composable way". Regexes are defined in terms of a single binary operator `=~`... except the left side is anything "regex-like" from any library, the right is "anything that can be matched by that kind of regex", and there are dozens of possible return types, which dramatically change the behavior from "matches" to "iterator of all matched groups". There is an idea that higher spin up time can be made up for by increased productivity: Haskell libraries are often like an exploration of the far corner of that concept. Rust libraries tend to be a bit more grounded, specific, and transparent in how they do what they do. Depending on what you are looking for, you might have a better time in one or other language, but saying that one community is objectively better seems wrong.
&gt; First, it doesn't mention invalid UTF-8, or UTF-8 at all. We do talk a lot about UTF-8 when discussing strings previously, so we assume people understand these kinds of issues. &gt; it'll panic It shouldn't panic, it will end up aborting with an error message, no? That is, `read_to_string` will return `Err`, which will be propagated up. &gt; something as small as, This is still playing favorites in a way I'm not comfortable with; when mentioning `ripgrep`, I'm thinking of it as an entirely external tool, like as you say, `grep`. Dependencies are a different story. While it is unfortunate (I'd love to say "just use clap" personally), I think it's part of the responsibility of official documentation. If the Rust Platform had been a thing, this could work, but we're not quite there yet.
&gt; My point was that Rust didn't make it magically safe for me to do threading Actually, a deadlock is considered safe in Rust, in much the same way as an infinite loop is considered safe. It's obviously annoying, doubtly useful, but it does not lead to memory corruption or exploits (other than DoS).
I have been looking into Rust as an option of moving forward instead of going back to just C (writing in Java then porting to a C client shell) and was considering to porting to a Rust client shell instead. Your comment makes me question my decision as the primary reason is for speed (hence no C++ if it can be helped). Any one know the C vs Rust vs Java performance ratios? Edit: https://benchmarksgame.alioth.debian.org/u64q/rust.html
Stability without stagnation!
the moderation is pretty spotty tho, seems like the mods switch between being completely absent and full-on nazis. I'm not joking about the nazi bit, have you *seen* their sidebar image?
I read it as japanese
Glad you're satisfied with your solution! I'm not! lol I've been thinking about it for the last few days because I _feel_ like expressing these requirements should somehow be possible. I'd managed to create two windows from the same context using an immutable reference, but I assumed you wanted the context mutable after creating the windows. All I've come with so far to accomplish something similar requires significant restructuring. Actually, hearing that using an immutable reference worked for you made me re-reading your original post and I see that `Context` was zero-sized. Now I think what you've done is actually perfect for binding multiple lifetimes via an immutable reference. There's nothing that could possibly be mutated so it doesn't mean much to have a `&amp;mut` method other than guarantee a single borrower, which is not what you want. If it weren't zero-sized and needed to mutate its members at some point I think it'd be a much less desirable solution.
https://github.com/Daedrus/rustz80emu It's still very much a work in progress but I am glad that I got the ZEXDOC and ZEXALL tests to pass. You'll find a lot of similarities with rustendo (especially when it comes to the overall design) since I was developing right along with your early videos :)
And in the red corner we have /u/graydon2 and /u/steveklabnik1, in the blue corner, /u/dherman and /u/rabidferret await. **LET'S GET READY TO RUMMMMBBBBAAAAALLL!!!!!** 
I prefer "or not?"
 &gt; This is still playing favorites in a way I'm not comfortable with; when mentioning `ripgrep`, I'm thinking of it as an entirely external tool, like as you say, `grep`. Dependencies are a different story. While it is unfortunate (I'd love to say "just use clap" personally), I think it's part of the responsibility of official documentation. If the Rust Platform had been a thing, this could work, but we're not quite there yet. Then I'd just take the names of the crates out entirely. My point is rather making mention that, "you don't have to do this part by hand, and we have some excellent prebuilt crates for this." Not to tell them which crate to use :) &gt; It shouldn't panic, it will end up aborting with an error message, no? That is, `read_to_string` will return `Err`, which will be propagated up. Ah my mistake, I missed the `read_to_string`. But I believe the `std::env::args` will panic if passed in a path with invalid UTF-8. I'm on mobile right now though, so I can't verify. I know UTF-8 is talked about with Strings, but I still think it should be reiterated here even if just briefly mentioned as a relatively common issue, or something to consider.
Is there a good explanation of why can't Rust support dynamically-sized return types? In theory I think it should be possible to write a function like this: trait T {} struct A(u32); impl T for A {} struct B(u64); impl T for B {} fn foo(x: bool) -&gt; T { if x { A(1) } else { B(2) } } The idea is to treat a trait in type position as a dynamically-sized type. Then basically the callers of foo() would get the return value, it's length, and the trait object vtable(s) for the implementation of T, they'd interact with that return value through the trait object vtable(s). It seems like people really wanted to avoid using trait object vtables for performance reasons, and I'm sure in many cases static dispatch and monomorphization unlocks a lot of optimizations, but in many cases it's unlikely to actually matter much in terms of performance to go through the trait object vtables.
Please remember that the benchmarks game is a game, and therefore is not representative. Consider this, for example: https://news.ycombinator.com/item?id=13267312
Hi, I was looking for a way to make the pointers in my code much more raw than in C. I seem to have taken a wrong turn. Can you fine gentlemen assist me?
:) Agree, it's really huge. I was thinking about two options: * to have two methods - simple and advanced one. The same as you suggested; * to have a single method which takes one argument of custom type *Query*. And to provide some kind of query constructor let query = Query::new("SELECT * from users;"); // query with default parameters let query_with_params = query .with_consistency(Consistency::One) // rewrite default consistency .with_page_size(100); // rewrite default page size let res_frame: Frame = try!(session.query(query_with_params)); 
Hmmm, what about "the upside-down ¿ operator"?
What C programmers are too afraid to tell you is that C pointers are a slow/inefficient/marxist abstraction over raw voltage coursing unfettered through your CPU. Rust, however, is renowned for its safety, and so a proper grounding in the language is more than enough to insulate you from the dangerous effects of this most zero-cost of all abstractions.
I love what you're doing here. It makes me want to play something like FreeCiv on a hex-tiled sphere (even if there are 12 pentagons). 
Good point :)
I forgot to mention i generally try to stay away from the ast so this might be a dumb question.
Thanks so much for these. I tried writing a hex-based world game along similar lines about 6 years ago. But I never had time to properly get my head around hex movement rules, so I am really getting a kick out of seeing someone else work it all out!
 There's a place for Rust. Somewhere, a place for Rust. Safe systems programming if you dare, Wait for Rust Somewhere... 
It is actually supposed to be evocative of a bike chainring, yes.
It is all clear now. Rust is the one true way. I will go build a monument to this most glorious of the red blooded, freedom-oriented languages.
I sense hostility!
Any backstory?
https://github.com/rust-lang/book/issues/378 No prob :)
It's just so nice to see someone be so wrong sometimes
I totally know what you mean, I was really kind of unhappy with it first, because as you say, if it wasn't zero-sized, it would be a terrible violation of the borrowing rules! I think if it wasn't zero-sized though, then I might have ended up using it like a container of some kind though...I'm honestly not totally sure though! I think a similar problem might be creating multiple mutable slices into an array, where the slices do not overlap. Once you do `split_at_mut`, or etc, you cannot create another mutable slice from the original array until each of the subslices has gone away. So basically, you have to create all of your slices (or `Window`s, in my case) simultaneously. This would theoretically be undesirable as well though...maybe the `create_window` method would have to consume the context, and create a new one, returning a tuple of `(Context, Window)`? Regardless, thanks for the discussion! This is one of the more interesting problems in Rust that I have only seen mentioned in the [Rustonomicon](https://doc.rust-lang.org/nomicon/borrow-splitting.html)!
Holy shit, that you can do this in one line of code which is so easily readable is blowing my mind. Try that in other languages.
Thank you :)! Christmas is a good time to write some code again, for some reason. Rust is so much fun, and with Tokio and friends, it clearly has the killer-application that is yet another game-changer (right after the borrow-checker).
Does anyone have a screenshot for those of us who missed yesterday?
Wow that's surprisingly bad. &gt; If they're going to require beginners to struggle with the difference between bytes and Unicode the least they could do is tell people what variables are bytes and what variables are strings. That sounds great until you realize that most of the time you're showing the user variable names from inside library functions. Not sure why that part jumped out at me more than the rest, but it did.
&gt; IMO, choosing a programming language is about productivity, nothing more, nothing less. "How quickly can I get this thing done?" (Don't misinterpret this as "how quickly can I write this code?", "this thing" includes testing, release, maintenance, and evolution into some other thing). Rust is the language that can get you that thing done quickest, in other works Rust is about productivity. Well said, my guess is a lot of people think "how quickly can I write this code?"
This is gold!
Here's an idea: parse the AST and count all unsafe branches, divide by all branches. It would probably take a year of work and not add that much value, but it sounds awesome. Great job on this!
"Be nice."
"When you're in Rust You got wonderful traits A compiler you trust Pattern matching is great!"
The first Rust compiler was written in WoahCAML. &lt;mindblown.gif&gt;
 fn main() { println!("Hello, World"); } ---- // TODO use lifetime elision when 1.15 lands static HELLO : &amp;'static str = "Hello, World!"; fn say_hello() { println!(" {}", HELLO); } fn main() { say_hello(); } ---- extern crate hello_world; use std::borrow::Cow; use hello_world::say_hello; fn main() { say_hello(Cow::Borrowed("World")); } ---- to be continued.... 
Thanks for taking a look. I've been thinking of the best metric to measure safety by. I agree that it shouldn't be binary and looking at branches of code that interact with unsafe code could be a good proxy for the extent to which the crate is unsafe. 
T O D O K E T E
Let's all love Rust!
Neither did OP until he encountered a Thesaurus.
now borrowed*
The latest version of futures also provides an Either type now, which is an enum of two variants that impls Future.
No lol that would be r/playrust
The only backstory I know is that early rust programmers liked biking. And not all of them, just some of them. I don't know how accurate that story is.
Can I have some soup?
I think you mean r/playhaskell
What game is this from?
The title ( ͡° ͜ʖ ͡°) 
Right now we're not sure.
why are things like this
I was thoroughly confused at the time
&gt; "Son, I am disappoint" -- Graydon
Haskeller here. This is the first time I've been genuinely jealous of Rust.
Do I have any other Option?
I think the flare gun should be a light source. Would make the map cooler. Remember when the bow did damage?
I thought play was a java and scala framework?
I like my `T: Green`
Yeah, its basically always this awesome here, you should come over more often.
You should be disappoint with reddit not me....seems /u/* isn't on their game.
Cool, thank you.
It's true.
You forgot to `use std::borrow::Cow`, it isn't in the prelude ;)
error: The `Carrier` trait for the `?` operator is not implemented on the `Option` type.
For those of you that didn't notice like me, there are 4 videos here.
So if I understand this right, the main benefit you are getting from tokio right now is just a timeout in the closure?
can confirm
Sure thing *pours soup on plate*
Thanks, fixed. I shouldn't have coded that from my phone. Yet here we are...
Yeah, I'm kind of assuming this is all post-learning cliff. But the point of this is that the stuff you want to get done is usually complex or will become complex sooner or later, and in that case then Rust will be a quick solution (even with the borrow checker slowing you down) once you factor in debugging and maintenance.
mods having fun +++ STOP +++ meme rule relaxed for a short duration +++ STOP +++ see you all in 2017
dude didn't you read the comments? [rust is a hell of an *inverse* drug](https://www.reddit.com/r/rust/comments/5kwxef/fire_mario_not_fire_flowers/dbrgkyj/)
And gold doesn't Rust.
this is rust your code is protected by spikes
That explains all the bikesheds about! 
I just used `unsafe` for the first time today. It feels good. It feels powerful. 
 let this: Gold = unsafe { std::mem::transmute(rust) };
True for me. I've probably spent more time reading about rust than writing it.
&gt; /r/playrust-lang pls make it happen
Agreed but do you expect me to write enterprise_hello_world.rs *on my cellphone*?
As was I.
&gt; Drawbacks &gt; None whatsoever. &gt; Alternatives &gt; None whatsoever. &gt; Unresolved questions &gt; None whatsoever. so it's settled then
Or you could play [this](https://www.youtube.com/watch?v=siwpn14IE7E)
Well I want to keep things very uncontroversial haha. I'm not trying to convince anyone that Rust is better than Java in this post - just that Option is better than Optional, and that null is a burden. I think I'm just curious if people think this approach makes sense. I'll probably get another post out this weekend. &gt; I'd like to think that all those places were found in the great library purge for 1.0, but I'm not 100% certain. Eh, I'm willing to bet that the cases are rare if they exist, whereas in Java there are tons of std functions that return null.
[Also explains NAT.](http://imgur.com/a/GJ6fl)
An enterprise programmer fears no obstacles to creating industrial-strength enterprise quality code!
IIUC it'll be back after new year's.
Your problem is that rust is so advanced that you have to specify the size of your numbers. Try changing Int to Int32.
The Way is long arduous and 'unsafe', 'let' your heart be strong, and 'forget' your past... be prepared to 'drop' all that you hold dear, but fear not pain, as you may safely 'spawn' any help that you need.
Oh yeah also Chromatics made a pretty cool [cover](https://www.youtube.com/watch?v=rSycSBYHitc) of Into the Black that was in Mr. Robot.
What's wrong with SeL4 or the Muen Separation Kernel?
I'm still a little confused as to when to use unwrap and when to use Result vs. Option. Could you clarify a bit for me?
WHAT HAS HAPPENED TO THIS SUBREDDIT? I'M NOT EVEN SURE I DISLIKE IT!
Helo, I was asking my dad who's a real whiz with these kinds of languages. He had a question for you? why
you want TeX in Rust you say? [Ok](https://github.com/cbreeden/ReX)
Google agrees.
For the memes.
You can't let the thread borrow `i` because it might outlive main, and I forgot to put the move keyword in. I just pushed a fix for this. 