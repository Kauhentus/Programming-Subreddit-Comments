What is there to complain about?
To expand on what /u/kostaw said, you still have a couple options. You could have your get function return a `Foobar` like here: http://is.gd/IZ4wuq Or, instead of returning a generic `T: Getter` you could return a `Box&lt;Getter&gt;` which is a pointer to a trait object. Finally, you could do it without using an enum, depending on what you want to accomplish.
Huh. I make use of so many tools to automate tasks or alert me, getting a notice that can improve my project felt like a cool/ natural thing. I guess the best route is PSA? But then you'll reach only the active developers of projects. Either way I appreciated the bot.
Maybe have this thread automagically sort by new?
Really what I'm trying to accomplish is how to return a Generic type like how str::parse does just for academic/curiosity purposes. You can see my response to /u/kostaw to see I just removed enums out of the equation entirely.
That rule was new to me. It makes sense, though I prefer to have a similarly named test/ submodule. Keeps the code and test separate, which might compile faster [citation needed].
Maybe you meant like this? trait Getter { fn get_that_stuff(&amp;Foobar) -&gt; Result&lt;Self,()&gt;; } impl Getter for u8 { fn get_that_stuff(f: &amp;Foobar) -&gt; Result&lt;u8,()&gt; { if let &amp;Foobar::Beta(ref z) = f { Ok(*z) } else { Err(()) } } } impl Foobar { fn get&lt;T&gt;(&amp;self) -&gt; Result&lt;T,()&gt; where T: Getter { T::get_that_stuff(self) } } 
Sounds like you mostly got it. Yes CPU bound. Yes real-time rendering (perspective projection rendering?). If it still doesn't exist I might tackle it for Piston, but there are a lot of architectural problems I'm not sure where to begin finding answers to.
`T` is a concrete, generic type. `String` cannot implement it as it isn't a trait. Because `String` impls `Getter`, it is an example of what `T` could be, but so could a bunch of other types (potentially). If you call `get::&lt;u8&gt;()`, you need to return a `u8`, but your function returns a string. If you want something like `std::parse`, then let's look at what it does. It has the signature fn parse&lt;F&gt;(&amp;self) -&gt; Result&lt;F, F::Err&gt; where F: FromStr And `FromStr`: pub trait FromStr { type Err; fn from_str(s: &amp;str) -&gt; Result&lt;Self, Self::Err&gt;; } So, `FromStr` is a trait that has a function that maps `&amp;str -&gt; Self`, and parse maps `&amp;str -&gt; F`. The function parse could look something like (I'm having trouble finding its actual implementation, as it's evidently a compiler built-in): fn parse&lt;F&gt;(&amp;self) -&gt; Result&lt;F, F::Err&gt; where F: FromStr { F::from_str(self) } So, the magic really happens in `from_str` which is implemented for each type we want to parse. Basically, if you want to have a function generic over its return type, you need to have some function you can call that will give you an object of that generic type, like `FromStr` does.
I was trying to do the same. I cloned rust from github and was grepping for parse so I could just copy what it did, but I could not find it either.
turbo-fish is what they call the ::&lt;&gt; operator. According to the docs &gt; Because parse() is so general, it can cause problems with type inference. As such, parse() is one of the few times you'll see the syntax affectionately known as the 'turbofish': ::&lt;&gt;. This helps the inference algorithm understand specifically which type you're trying to parse into.
For every kind of spam there must be someone who appreciates it. This does not justify making one's bot opt-out rather than opt-in.
I suppose so, but can I just say, in general, that it is a pet peeve of mine for someone to use an acronym without clarifying it. Just over in /r/Games there was a post with ARG. Just ARG, all over the place. Not once did anyone bother to spell the damn thing out. Sorry if I'm not familiar with Alternate Reality Games (which is what I *assume* it means after some quick googling). Even in publications you don't just throw around CNT, CNT, CNT. You start: Carbon Nanotube (CNT), and then use the acronym from there.
What does `as` syntax mean in a type alias/definition? I've seen it several times, e.g. [here](https://github.com/sgrif/diesel/blob/c73dfba0727bbdb3799f328a000b22df06bd0582/diesel/src/lib.rs#L40), but it's not in the language reference (that I could see) and impossible to google for. I'm asking about the syntax in general, not the specific link.
To answer the questions you posed in the comments on exercism: &gt;My initial implementation had the allergens ordered alphabetically in the allergens function - this worked, but failed the test. Is this a problem with my code, or the test? It's a problem with the test. It's not testing that the vector produced by `Allergies(255).allergies()` contains all of the allergens. Instead, it is testing that the vector produced is the same as the vector where they are ordered by value (1, 2, 4, 8, 16, 32, 64, 128). &gt;Can I avoid the clone() calls every time I try and cast an allergen as a usize? So long as `Allergen` has derived `Copy` (which it has), simply dereferencing the borrowed value will work. &gt;Is there an easy way of getting a list of all possible values an Allergen can have? No, because of the case like this: enum Option&lt;T&gt; { None, Some(T), } How would you iterate over this enum's variants? The `Some` variant is a constructor for an `Option&lt;T&gt;` value. So there can be no general solution. But there can be one for static enums of the type `Allergens` is. However, Rust doesn't provide support for that out of the box. You *can* create your own function to handle that. [Here's](https://www.reddit.com/r/rust/comments/29sk5d/iterating_over_static_enum_values/) a discussion. &gt;Am I right in wanting to do something like this? Is an enum even the right data type to be using here? Yes, and yes.
Alright, thanks for clarifying. I'm afraid I can't help with that.
Moving it outside the loop causes the error I posted for me so something is different, possibly because of what I'm doing to get values into the hash map. Do you have to use the values in the inner loop in order to get the error? Maybe it compiles for you because it's dead code. I'll try to create a minimal example that reproduces the problem after work today. How are multiple mutable references taken? I don't see it. Maybe I am remembering incorrectly but I also thought that error was something like "cannot borrow a value that is already mutably borrowed", not the lifetime inference error I am seeing. Edit: I did a quick test and confirmed that I can move the storage out of the loop provided I don't use it in the loop - dead code analysis is doing its thing there.
Looks like you installed the MSVC variant for Windows, which needs Visual C++ installed. I found [this](https://www.reddit.com/r/rust/comments/3sbv3l/compiling_rust_on_msvc_community_2015/) while googling which might be of use to you.
https://github.com/Hoverbear/rust-rosetta
Not as far as I am aware.
&gt; it is not mentioned that you can use it in a type definition Mmm. good point. You may want to look for or open a Rust issue about that. You can also use it in other places besides a type alias, such as in a parameter list: trait Cat { type Food; fn eat(&amp;mut self, food: Self::Food) {} } trait Dog { type Food; fn eat(&amp;mut self, food: Self::Food) {} } struct CatDog; impl Cat for CatDog { type Food = u8; } impl Dog for CatDog { type Food = i32; } fn nom_nom_nom&lt;A&gt;(a: &amp;mut A, cat_fud: &lt;A as Cat&gt;::Food, dog_fud: &lt;A as Dog&gt;::Food) where A: Cat + Dog { Cat::eat(a, cat_fud); Dog::eat(a, dog_fud); } &gt; a sort of bound on the type parameter Yes, but it's doesn't appear to be sufficient. It looks like you have to still include the bound at the usage site: trait Foo { type Output; } type Zeta&lt;A, B = &lt;A as Foo&gt;::Output&gt; = (A, B); fn broken&lt;A&gt;(z: Zeta&lt;A&gt;) {} fn works&lt;A: Foo&gt;(z: Zeta&lt;A&gt;) {} fn main() {} &gt; I would have expected something like Me too, but a `where` clause isn't parsed and an inline bound reports `warning: trait bounds are not (yet) enforced in type definitions`.
It's not an either/or. The autogenerated change log can serve the same purpose as `git log --oneline --no-merges` and still be edited after that. I generally dislike mainly handwritten (= big block of text) changelogs. When I look at a changelog I genereally either want to see if there is a new feature that's worth upgrading for (and see if that upgrade is likely to break parts of my application) or I want to see if the new release fixed a bug I experienced in the past. For those purposes a structured changelog is easy to scan, while I have to read more or less the whole handwritten changelog. Of course it's also not a exclusive question and we will experiment in the future with editing the changelog and writing small summaries for more important releases. This post is just a starting point (we are also new to this) and a call to action to the Rust ecosystem whose changelog-situation is in a sad state.
&gt; Secondly, how can I get a build that has optimizations on (--release), but without stripping the debugging symbols? Use Rustc, and pass both `-o` and `-g`.
It is not over-ridable.
I wouldn't say "trivial" because of sheer amount of bulk and debugging in those kinds of projects (perhaps "tedious" or something would be more appropriate), but I definitely agree with your point; assimilating the right information is totally the bottleneck in these kinds of projects!
[Example 1](https://github.com/ruud-v-a/hound/releases/tag/v0.4.0), [Example 2](https://github.com/ruud-v-a/hound/releases/tag/v1.0.0). I admit that this is a tiny library so there is little need for deep structure in the changelog.
Not the point of this discussion. I've learned many acronyms from this reddit board. (VNC, LLVM-MIR, VOD—just from the front page of posts alone.) Yes, it's an extremely common term for a wide problem domain of people doing scientific work probably coming from Python.
You're right, it's not the point. Hence why I didn't make it a top level comment, and instead replied to the person who also didn't know what MFCC was immediately. I'm also aware people love to do it (use acronyms without clarification). That doesn't make it a good policy.
https://www.reddit.com/r/rust/comments/3fimgp/why_double_colon_rather_that_dot/ctozkd0
Not surprising. The term comes from C++11. In C++ objects are copied by default, it's actually expected that if `operator==(Foo const&amp;, Foo const&amp;)` exists and `Foo` can be copied then: Foo const b(a); assert(b == a); For efficiency, C++11 introduced move semantics which imply **transferring** the resources instead of making a copy. However, copies remain the default in many situations in which case you neeed to work a bit harder to get a move. I expect that rather than coming up with another name (naming is hard, and having different names for common things is not helpful), it was decided to use the term "move semantics" sa in C++11.
This is a really great addition to Rust's ever growing suite of safety/correctness oriented compiler plugins! I'm very excited to see what comes next.
I would argue that a languages ecosystem is significantly more important than than the features of the language itself. Php itself, while not an amazing language by any stretch, has a very strong ecosystem. 
We're working hard on this at https://github.com/Hoverbear/rust-rosetta. One problem is that many of the tasks simply aren't copied over to the wiki! I implemented a crate that will assist with this, but a lot of manual work still has to be done. Check out the `coverage` command in the repo to see what needs to be done. It has options for seeing which tasks need to be copied over, which tasks are different from the versions on the wiki, and which tasks aren't implemented at all.
Have you take a look at [Harvey-OS](http://www.harvey-os.org/news/#things-you-can-do-now-in-harvey)? It is APE (ANSI/POSIX Environment) ready.
I don't think automatically generated changelogs are a good idea. If they are just generated from the commit messages, why not do that on the client side? E. g. `cargo changelog` printing out all the commit messages between a version change (if there's no hand-written CHANGELOG.md).
&gt; In general, If I want to return something involving a generic T should I be calling a function coming from T? Like T::whatever_function()? In general yes, if it's a method that only returns `T` (i e, does not take `&amp;self`/`&amp;mut self`/`self` as parameter). Btw, in the code I wrote above, the third part is just to be able to do the turbofish. You can just as well write `u8::get_that_stuff(&amp;whatever)`, if you prefer it that way. (At least if the trait is brought into scope with a `use` statement.)
Working on a [gettext](https://github.com/justinas/gettext) library for Rust, currently in a very early stage. IMO gettext is a very well thought out tool, with some unfortunate flaws in the official implementation (depending on a global locale, enforcing a file structure, etc.) that I'd like to get rid of in this crate.
Hmm, it's actually documented [here](https://doc.rust-lang.org/std/marker/trait.Copy.html) : the derive strategy will also place a Copy bound on type parameters, which isn't always desired. That could explain the `copy` part of it, but the `clone` error still seems very odd to me.
Made some good progress on Cajal (a neural cellular automata simulation) over the weekend. About 70% done with the basic "growth" phase features. The growth phase allows the "neurons" to grow axons / dendrites across the grid, before transitioning into the "signaling" phase where electrical signals are simulated. Also knocked up a quick visualization tool with Piston, so that I can visually check debug issues easier. Here is a [single page at 0.5% density](http://imgur.com/GkfVH6f.gifv) (~20 neuron bodies), and [here is 3% density](http://i.imgur.com/dIgytfC.gifv) (~120 bodies). And here are [49 pages of cells](http://i.imgur.com/AXTrk6Z.gifv)... you can see the dividing line between each page because I haven't implemented cross-page growth yet. Axons are red, dendrite are teal, cell bodies are brown.
If you definitely have VS installed, and you're getting that "could not exec the linker" error, that means link.exe isn't in your executable path. You can add it manually, but it's easier to run the special command prompt that VS sets up for you. That command prompt has the executable path (and other stuff) correctly set, so you should be able to run rustc from it. How you run the special command prompt depends on your OS and VS version. IIRC, in Win 7 it's one of the Start menu options for VS. It'll be called "Visual Studio Command Prompt", or something like that. Alternatively, look for "vcvars.bat" or "vcvarsall.bat" (sorry, I don't know exactly what it's called) in the VS Program Files directory, and run that from your command prompt.
I'm sure this will help someone else, so if anyone like me vastly prefers powershell over cmd, and wants to be able to load the vcvarsall.bat into their environment from there, you can use a script like this https://gist.github.com/Connorcpu/e96de071cdc43fe7a11a
The years seem to be wrong: November 2016 hasn't happened yet.
That's because it does the exact same thing for Clone
Major refactor of [rusty-cheddar](https://github.com/Sean1708/rusty-cheddar) with the aim of making it easy to generate bindings for arbitrary languages.
create of the week/month
Multithreaded *Bitcoin* blockchain. Or is a general parser and it can parse any blockchains?
It *can* parse any bitcoin based blockchain, but in this state it recognises only bitcoins magic value 0xD9B4BEF9. I will add support for more coins soon
&gt; So basically, the as here is used a sort of bound on the type parameter (like the deprecated DataTypeContext haskell extension, which you can also do with GADTs)? I would have expected something like where or : for that purpose. Other than bugs, there's nothing special about a type definition here: as can appear in a type, and the right hand side of a `type Foo = Bar;` can be any type, and similarly, default type parameters can be defaulted to any type. The basic `&lt;T as Trait&gt;::U` syntax is referring to the `U` associated type of `T`'s impl of `Trait`, that is, somewhere there is: impl Trait for T { type U = X; } and the `as` expression "expands" to type `X`. There's two uses of this syntax in the `type`: - `Type = &lt;Selection as super::Expression&gt;::SqlType`, which is defaulting the `Type` parameter to that associated type. That is, `Select` has three type parameters, but you can write `Select&lt;X, Y&gt;` and the third type parameter is deduced as `&lt;Y as Expression&gt;::SqlType`. - the right hand side `&lt;Source as SelectDsl&lt;Selection, Type&gt;&gt;::Output` says that writing `Select&lt;X, Y, Z&gt;` is the same as writing `&lt;X as SelectDsl&lt;Y, Z&gt;&gt;::Output` (and if `Z` is omitted, then it's the same as writing `&lt;X as SelectDsl&lt;Y, &lt;Y as Expression&gt;::SqlType&gt;&gt;&gt;::Output`). The confusing things is that there is [a bug](https://github.com/rust-lang/rust/issues/21903) that means the compiler isn't enforcing that these type parameters have the appropriate bounds. That is, the compiler should be requiring that the user bounds the type parameters before using them in an `as`, like pub type Select&lt;Source, Selection, Type = &lt;Selection as super::Expression&gt;::SqlType&gt; = &lt;Source as SelectDsl&lt;Selection, Type&gt;&gt;::Output where Source: SelectDsl&lt;Selection, Type&gt;, Selection: Expression; 
Every unstable feature that has any chance of being stabilised has [a tracking issue](https://github.com/rust-lang/rust/issues?q=is%3Aissue+is%3Aopen+label%3AB-unstable). The specific issues for a library feature are linked from the documentation of that feature, and there's also issue numbers in compiler error messages about using any unstable thing. Discussion about what's happening with the specific features happens there, so following the relevant issues is the best way to keep up to date if you've got some particular features of interest. Things that are up for possible stabilisation in the next beta (and hence the next-next stable release) go into a "final comment period" to have a last round of discussion.
ty
- #rust-machine-learning - #rust-audio :)
Working on a async file io abstraction in the vein of seastar. Only as far as having a simple file copy example working with libaio on Linux. The big challenge will be coming up with a good abstraction.
On a benchmark which took normally 30 minutes it could be reduced to ~25 mins, but on this test I also had `-C no-stack-check` enabled. I need to test this further, maybe I integrate some cargo benchmarks 
I've implemented a few algorithms from Rosetta and added tests based on the tasks. I was lazy and didn't add them to the wiki - sorry! I'll try to do it this week. If anyone wants to check it out they are [here](https://github.com/AtheMathmo/rusty-machine/blob/master/rusty-machine/src/linalg/matrix.rs). The algorithms are [LU](https://github.com/AtheMathmo/rusty-machine/blob/master/rusty-machine/src/linalg/matrix.rs#L882), [QR](https://github.com/AtheMathmo/rusty-machine/blob/master/rusty-machine/src/linalg/matrix.rs#L1033) and [Cholesky](https://github.com/AtheMathmo/rusty-machine/blob/master/rusty-machine/src/linalg/matrix.rs#L961) decomposition. The test cases are implemented in the tests folder (I don't think I handled all of the cases). Do you think it would be best to include the `Matrix`/`Vector` structs or just refactor to use only `Vec`s?
I have a feeling you posted this to the wrong subreddit. 
This is the wrong subreddit, you're looking for /r/playrust
Will there be any blog posts about using Rust in Dropbox?
These sort of platform exploits pose the most catastrophic risk to users, although they're rarely used by common viruses due to the difficulty of exploitation (and lack of necessity.) The amortized risk for an average user seems low, but **why isn't the platform firmware memory safe**? Maybe someone\* should re-implement the open source UEFI code in Rust? ... and does anyone fuzz test these things? Where's afl-fuzz for my BIOS? \* With more time than I have.
For anyone else wondering what the hell is SMM: https://en.wikipedia.org/wiki/System_Management_Mode The article is pretty interesting, but it sure could use a glossary.
That upvote.
I saw this general thread on proggit and thought, "Damn, that's awesome. How can we get this into Rust? Especially for a particular project I've had in mind..." and it's already been done! :D But now I'm wondering why I didn't use that luck on the Powerball. Sad face.
Duplicating `clog-cli` into a `cargo-changelog` or `cargo-clog` would be very simple. But personally I'd rather get some buy in from the official `cargo` devs before "taking over" a key subcommand name like that. Especially since there are many different changeling formats, and even though `clog` is extremely configurable, it's still got certain opinions that not everyone shares. I say this as one of the guys that works on `clog`. Perhaps /u/cburgdorf (one of the owners) has an opinion about starting such a project under the `clog-tool` organization. Pragmatically there isn't much gained over using just `clog` as it's already `cargo install`able, but the theoretical mindshare and exposure of being "integrated" with `cargo` is something to be considered. The same can be said of literally any of the third party subcommands.
What's the command to trigger another rebuild in stage3?
Finally! Windows support!
Next thing I tell you is that it is GPL ;-)
Can you elaborate on the `array.iter()` vs `&amp;array` thing for small arrays? There's only a single place in the program where I could directly replace the former with the latter and that makes no difference on runtime.
Noted as submission.
I'm not sure you can just build stage3 by itself. This command will re-build up to stage3, but if you have changed the source it will re-build all the stages before that too, so it's going to take a while. make rustc-stage3 
Anything implementing `Copy`_only_ gets copied by a shallow copy of the structs bytes, and those types also have to implement `Clone`, which _should_ behave the same. Types that only implement `Clone` usually require more efford to copy, turning them from shallow copies into deeper-ish ones, though not neccessarily.
A `for` loop over the same iterator as `.fold` is called on has the same bounds-checking behaviour. In fact, [`fold` is a `for` loop internally](https://github.com/rust-lang/rust/blob/acf4aeeda06b5355060e3dd8316e096465242f94/src/libcore/iter.rs#L1572-L1580).
Right, it _shouldn't_, but according to the article it does make a difference. So I want to know how to reproduce and possibly fix that.
[Relevant clippy issue](https://github.com/Manishearth/rust-clippy/issues/346) that I like to think led to the creation of the lint.
You should check out the water crate: https://crates.io/crates/water/
Thank you, fixed it.
Yep :)
Exactly. It might make sense to put a default database into the crate itself, but I’m not sure if that possible or whether the plugin would know how to find it, currently the database is assumed to be next to your *Cargo.toml*.
Others have said this more delicately.. but for FUCK SAKE put a date on your article. Do you google at all? Then you know how easy it is to get outdated information... You're contributing to the problem. /Rant Thanks for the informative and interesting comparison :-) Cheers.
thanks for the tip, you made me realise i needed to rethink this totally with this in mind. 
One perhaps helpful bit of information is that it probably relates to inlining – the IntoIterator calls on the reference aren't always inlined, depending on the complexity of the contained block. MIR will hopefully allow us to do such optimizations in Rust instead of LLVM.
Does windows support mean moz-js will compile on Windows64(MSVC) or just GNUABI?
`foo` will move `&amp;x` into the for loop whereas will just call its `iter`.
GFX news are missing...
It has nothing to do with 'fuck'.
Huh huh.
Oh if he meant that the C++ template metalanguage itself is dynamically typed then sure, but then he loses any claim that it isn't all that bad and that there isn't anything worse than it. I'm pretty sure we can all agree C++ template metaprogramming is really that bad, and there really isn't all that much worse than it ;P
Still working on my Elm-like GUI framework for Rust. Currently working on porting [stb_truetype](https://github.com/nothings/stb/blob/master/stb_truetype.h) to Rust, to make font rendering easier to support on all platforms. After this the next thing is the layout engine. To this end I've already implemented a quadratic programming solver based on a Matlab solver, in terms of sparse matrices (using [sprs](https://crates.io/crates/sprs/)). This is published as [constrained](https://crates.io/crates/constrained/). No docs yet.
&gt;I don’t mind locking io::stdin, to get faster input, but requiring that the call to lock() be in a separate statement is weird. You sometimes have to unlock io in C++ to get best performance. So you need the following magic incantation or your C++ can run very slowly. `std::ios_base::sync_with_stdio(false);` [Here](https://bitbucket.org/ewanhiggs/csv-game/commits/47028a5938573bd28e6efcc05c6f4584c0233244) is an example from my [csv-game](https://bitbucket.org/ewanhiggs/csv-game/) where adding it improved performance 4x. Thanks to /u/pfo for that sweet snippet.
In a GNU/Linux environment, why RUNPATH is set on ELF binaries leaking information about the build environment, when only system shared libraries are needed?
What is the correct syntax for creating a type alias for a struct with a lifetime? struct Bla&lt;'a&gt; { foo : &amp;'a Foo, // Other fields } // error: wrong number of lifetime parameters: expected 1, found 0 [E0107] type BlaAlias = Bla; // error: use of undeclared lifetime name `'a` [E0261] type BlaAlias = Bla&lt;'a&gt;; // error: expected `=`, found `&lt;` type BlaAlias&lt;'a&gt; = Bla&lt;'a&gt;;
Regarding the nightly docs, someone is actually maintaining them: http://vhbit.net/blog/2014/07/04/rust-docsets-for-dash/ 
Your third try is right, you're just getting parse errors because you left off the semicolons at the end of the `type` declarations.
Looks like this works for me though: http://is.gd/RcPkKG That's pretty weird. The last one should work fine.
`sync_with_stdio` operates via streams, but the C++ code presented bypasses the streams and goes directly to the streambuf.
Thank you, fixed.
Sometimes it's even better to bypass streams, and use streambufs directly, as here.
Thank you, fixed.
That kind of reminds me of rust-encode: For the one-byte codecs (such as the whole ISO codecs) for decoding (`u8`-&gt;`char`) it uses a array with `u16` values as a look-up table which after lookup get widened to `u32` and then transmuted (**unsafe!**) to a char. Not all `u16` are valid `char`s, as some would collide with UTF-16 surrogates. When using a safe match with chars, llvm probably will generate a optimized look-up table. It should even be able to optimize the array when you explicitly place it, though I doubt that this is implemented. If only I wouldn't be so lazy to test it. The ascii-mostly case probably also could be optimized similarly to the utf-8 checking that was recently optimized. Edit: Now I looked it up, llvm doesn't optimize in any of both cases. Also rustc complains that my match is incomplete for u8, when in reality it is complete https://play.rust-lang.org/?gist=2669959d6b976dda33aa&amp;version=nightly
It's only safe if it's a `#[repr(packed)]` thing. `#[repr(C)]` has full alignment requirements (although `#[repr(packed)]` is unsafe all on its own).
The second is better, because you shouldn't use `mem::transmute` (as they say, ants with a nuke). They are both `unsafe` functions, and should only be called with a buffer that is 1) originally from a `T`, or 2) into a `#[repr(C)]` type. The lifetimes will be correct, however.
Developer*
No, expressions on the LHS of = are not meaningfully interpreted differently from normal expressions. They are not reparsed into a different nonterminal than they were parsed as, which is what would be required to approximate pattern matching assignment. The practical consequences, besides making the language more complex, would be that random pattern features wouldn't work for these types of pattern matches. If there were some way to truly unify the pattern and expression grammars without ambiguity, then I'd be OK with the feature. Otherwise, I'm opposed. It's less of a gotcha to say "this feature doesn't work at all" than to say "this feature mostly works, except for these three special cases where the parser can't parse it, so you have to qualify it or do something else". That leads to things like the "when do I have to write typename?" madness in C++.
For Windows users, there's Velocity. Velocity is essentially the Windows version of Dash. Link: http://velocity.silverlakesoftware.com/ Edit: Note that Velocity is free, but it will bug you about purchasing it.
Do you yell 'for FUCK SAKE' at people with whom you have a cordial but impersonal relationship? Maybe you do, but most people would think it is a very rude thing to do.
Oh! And remember your alignment! It's undefined behavior to create a pointer that doesn't have at least `align_of::&lt;T&gt;()`. Edit: not read from, it's actually just creating an unaligned pointer at all that's undefined!
It really depends entirely on what kind of data you're processing. If you're just trying to take the average of 10 gigabytes of integers, that might be a relatively quick operation. If you're trying to apply neural networks to 10 gigabytes worth of books and have it translate them from one language into another, that could take hundreds or thousands of times as long as simply averaging integers. If you're used to working with simple data, terabytes might seem small, but if you're used to working with highly interrelated data, 30GB might be an unreasonable amount of data. BigData is whatever is big to you in your problem domain, in my opinion. In this case, he was processing a benchmark dataset it looks like, so he isn't the one that even named it BigData.
I believe that Spidermonkey has always compiled on MSVC. I could be wrong.
[removed]
The `IntoIterator` for both cases is very simple and is inlined. If you're not sure they are in this case, take a look at the asm from a simple example (e.g. the one I give above).
MSVC mangles C++ differently though, so the current bindings won't work with a MSVC built spidermonkey. It might be possible to generate bindings for MSVC, though x86 wouldn't work without support for thiscall calling convention in rust.
Looks like you defined do_sth() as a static function on SomeOtherTrait, while you try to invoke it as an instance method. [This](https://play.rust-lang.org/?gist=0fec9e0214d72c3d8af5&amp;version=stable) should work.
Cross post on the cpp subreddit : https://www.reddit.com/r/cpp/comments/42uwbc/rust_vs_c_finegrained_performance/
I for one don't really care about keeping the unsafe count low in such low level code but that was really nice.
This is pretty cool. I'd love to see how feasible it is (for me) to try a gameboy emulator. 
binary_search was completely safe, the PR was originally going to make it use some amount of unsafe. This is definitely a safety regression, especially since binary search is infamous for its misimplementations. Of course, it's also quite easy to properly test!
That's brilliant! 
Have you seen [Practical Lock-Freedom](https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-579.pdf)? It, among other interesting things, describes in detail a design for lock-free STM and MCAS from CAS only. Very cool stuff and may be applicable to you if you plan on implementing STM.
http://www.cplusplus.com/reference/ios/ios/operator_not/ The ! operator is implemented as "Returns true if either failbit or badbit is set, and false otherwise.".
thanks. fixed :)
You'll have to rearrange things here and there, but [this article](https://nbaksalyar.github.io/2015/07/10/writing-chat-in-rust.html) does a fantastic job explaining how to work with TCP through the mio crate.
Or just add a smart search keyword (mine is rustdoc) to your browser on the url file:///usr/local/share/doc/rust/html/std/index.html?search=
I should've been a bit more explicit, I guess. `ref` is excluded because it's a binding modifier, just like `mut`, creating a value instead of destructuring one. In an assignment, you wouldn't have binding leaves, but lvalue expression leaves.
simple_parallel is designed to be a drop-in replacement for loops and iterators to make things parallel, much less flexible than `scoped-pool` or `scoped_threadpool` but much simpler for the tasks it is good at. crossbeam is not a thread-pooling library at all; it offers scoped threads, but every call spins up a whole new thread.
I prefer the version with `*byte` because IMHO it shows that byte is dereferenced more clearly. This is not a hard-and-fast rule though.
The difference here is caused by SROA resulting in a different order of loads. One load `y` first, then `z`, the other one does it the other way around. Not sure why exactly that happens. But that ends up costing an extra register for the loop count AFAICT.
We only get to have two stickied posts, and we do already link to playrust from the submissions page.
Well, I guess it's a subjective thing. First off, I personally prefer proven-safe rather than tested-safe (unless exhaustively tested-safe). More importantly though, `unsafe` now permits two things in Rust: - low-level code (such as C libraries, hardware, system calls, etc...) - performance enhancement (eliding bounds checks) I am afraid there is little we can do about the former, however the latter is very much a case of "insufficiently smart optimizer". In this case, fixing the optimizer means reaping the benefits *everywhere* the case occurs: it's a more systemic approach. I also think that it's important to show-case that Rust can reach peak performance without (or with as little as possible) `unsafe`. In order to convince C or C++ programmers that there are benefits in switching over to Rust, we need to allay their fears about performance regressions, and saying "you can always use `unsafe`" is perceived as a cope-out I am afraid (especially since non-practitioners are unlikely to realize that `unsafe` is not a Wild Wild West). In this instance, the standard library is show-casing Rust's code: its portion of `unsafe` is watched and commented upon. It's a bit unfortunate given that it tends to be of lower-level than code built upon it (obviously) and therefore already has a lot of `unsafe` that is necessary, so eliminating instances where it is unnecessary helps a lot in getting Rust to being perceived as useful without having to resort to `unsafe`.
That's very true, thank you for calling me out on this. However, measuring the runtime, memory used or even complexity unfortunately relies on *implementation details* and makes it hard to distinguish between: - a naive implementation, scaled out because of time pressure/laziness/ignorance - a full optimized implementation, scaled out as a last resort :/ In any case, you are right though, a 30 GB dense graph could be a hell of a beast to deal with.
You could use https://crates.io/crates/lazy_static/. There's an example in the readme how to make this more ergonomical.
That sounds a lot like OpenMP, actually.
Thanks, looks like what I was looking for.
How do folks deal with calling `&amp;mut self` methods inside of `&amp;mut self` methods? E.g. I have a `&amp;mut self` method which I tried to refactor into smaller sub-methods. However, those submethods also need `&amp;mut self`, and are called inside of some kind of loop like: fn update (&amp;mut self) { // mutate things on self } fn foo(&amp;mut self) { for i in self.pages.iter() { // do some stuff self.update(); // &lt;-- uh oh, self is already borrowed! } } This usually (always?) fails because self is already borrowed in the iterator. I've gotten around this by refactoring methods like `update` to not use self, and instead pass in the thing that needs to be mutated: fn update(thing_to_update: Foo) { // mutate thing_to_update } fn foo(&amp;mut self) { for i in self.pages.iter() { // do some stuff MyStruct::update(self.foo); } } Which works...but it's kinda gross because it bloats the function signatures (particularly if there is a lot of state in the struct that needs to be used). Any workarounds? Am I structuring it wrong somehow?
I've been working on a mio companion library called ['mai'](https://github.com/zslayton/mai) that does this. It's in a usable (but not polished) state if you'd like to take a look. I'm planning to resume development on it next week. It's similar to rotor but also handles buffer management for you.
It feels a bit dishonest to not mention C++'s "smart pointers" (unique_ptr, shared_ptr, etc).
About 2/5 of the way down: "Idiomatic modern C++ would use a unique_ptr here, which implements the desired behavior. It deletes the object pointed to when the pointer falls out of scope. However, that behavior wasn’t part of the language until C++11." EDIT: Just to clarify, I'm not saying this constitutes sufficient treatment of the subject, but it is *mentioned*. I would say that the part about C++11 is really only relevant for new codebases written with explicit team standards that enforce use of the reference-counting pointers, and I haven't seen very many C++ newbie-friendly materials which emphasize its use.
&gt; registry Steve, thanks. that works. Btw, your talks on rust are most excellent. One small note for your talks, since maybe your reading this again and I happen to be a java guy. Boxing in java does not "really" have the direct intention of influencing stack or heap allocation storage. it has more to do with going from primitive to object wrapper class for various purposes. I say "really" because scoped primitives are in fact stack allocated and object wrappers are heap allocated, but its not the primary motivation in boxing usage I would say.
Thank you! &gt; it has more to do with going from primitive to object wrapper class for various purposes. Yes, that's true as well. I think it's really a question of what aspect do you want to focus on. While it's true that escape analysis can put them back on the stack again, semantically, it's not really that way. In other words, it's an optimization. Does that make sense? Do you still feel that's wrong?
This is very promising! Also the Lovecraft quotes make it appear so solemn. ;-)
&gt; Yes, so I think maybe our disagreement is about the "really". :) Agreed! :)
Yes.
Yes, that was some of my inspiration. Although, I think rayon will be closer in practice as it develops.
Thanks! Watching it right now.
Just wondering... what happened to green threads / coroutines? IIRC early versions of Rust had those as well.
I do miss our runtime and our [Lovecraftian quotes](https://github.com/rust-lang/rust/pull/20944). 
Yeah, those were the days, when `panic` brought itself upon the programmer.
This is ridiculously cool. The post states that Stateful works on stable rust, but its lib.rs has `#![feature(plugin_registrar, rustc_private, quote)]` ? 
Link for the lazy: https://duckduckgo.com/
Quelle Université? C'est Université de Strasbourg? Je suis curieux parce que je suis en Alsace prochaine semaine. Le présentation de Alex Crichton est la foundation perfait pour votre conversation. Bonne chance! 
Here's some: * `&amp;T` * `&amp;mut T` * `Box&lt;T&gt;` * `Arc&lt;T&gt;` (Sorry, I couldn't help myself 😉) If you like Alex's style, look for Niko's talks as well. They're good!
Working on my [port of Handmade Quake](https://github.com/GyrosOfWar/quake-rs) (Quake 1 in Rust), now about on-par with where the videos are. Event handling is now in place and fairly Rust-y. Credit to [Eljay's directx crate](https://github.com/Eljay/directx) because the implementation of event handling is shamelessly stolen from him. 
Consider using [nanomsg](http://nanomsg.org/) or [ZeroMQ](http://zeromq.org/). Both these libraries have Rust bindings: [nanomsg](https://github.com/thehydroimpulse/nanomsg.rs), [ZeroMQ](https://github.com/erickt/rust-zmq). Personally I like nanomsg very much, I'm using it in one of my projects. nanomsg is a library by the original ZeroMQ author, arguably it has nicer API and better architecture. That's why they are really similar.
Non pas du tout, je suis de Belgique. Je vais faire ma présentation à [l'ECAM](https://www.vinci.be/fr-be/ecam/Pages/L'institut.aspx) à Bruxelles mais il n'y à pas encore de date prévue. C'est une haute école enfaite mais je ne suis pas sur qu'on fait la distinction en Anglais. Je suis tout à fait d'accord avec toi, la présentation d'Alex est excellente! Merci pour l'encouragement :) 
As I recall, c_void is a non-empty enum because the LLVM optimizer can potentially break code that uses pointers-to-ZSTs. You could create something like this, though: #[repr(C)] pub struct JsRuntimeHandle(c_void);
[Image](http://imgs.xkcd.com/comics/pointers.png) [Mobile](http://m.xkcd.com/138/) **Title:** Pointers **Title-text:** Every computer, at the unreachable memory address 0x-1, stores a secret. I found it, and it is that all humans ar-- SEGMENTATION FAULT. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/138#Explanation) **Stats:** This comic has been referenced 100 times, representing 0.1026% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_czeh7bd)
One more instance of me thinking "if only this one worked in German too..."
&gt; the purpose of the example is to demonstrate **why people invented a whole bunch of garbage-collected languages** in the late 80s and early 90s, and in those times C++ move semantics were not available The lack of move semantics in C++ was not the motivation behind the creation of garbage collected languages in the 80s and 90s. &gt; It gets cleaned up by the Garbage Collector **sometime after it falls out of that scope** That is [a common memory management myth](http://flyingfrogblog.blogspot.co.uk/2013/10/memory-management-myths-promptness.html). Compilers do not keep dead references in registers and stack slots until the end of scope. They aggressively reuse registers and stack slots. Consequently, tracings GCs see no references, determine that the heap allocated block is unreachable and can collect it before the end of scope, sometimes long before. &gt; In mark-and-sweep systems, at unpredictable intervals all program execution is halted **while the GC cleans up the memory**. That hasn't been true since Dijkstra invented his on-the-fly collector in 1978. Today, no production GCs are stop-the-world. EDIT: Just to clarify, production GCs like .NET and JVM do have stop-the-world phases but they do not stop the world "while the GC cleans up the memory". They are called "mostly concurrent" collectors. What this article describes is called a "stop-the-world" collector. &gt; The Python version takes almost three times as much real time as the C++ version. While not all of that difference can be attributed to garbage collection, it’s still considerable. Sorry but trying to blame GC for the difference in milliseconds between C++ and Python reading a 38-line file is ridiculous. Look at Google's Loop Recognition benchmark, for example. [Idiomatic F# beats idiomatic C++](https://fwaris.wordpress.com/2011/07/11/googles-multi-language-benchmark-in-f/) despite it being garbage collected. &gt; Compare this to reference-counting garbage collection Why RC and not something more efficient or common like generational GC? I don't think the theoretical comparison is worth trying to do because it is just too hairy. How do you account for the improvement in cache locality due to the compaction of survivors, for example? Or the overhead of having to reload references across GC safe points in case object have been moved? &gt; Consequently, there was an explosion of garbage-collected languages in the 90s, designed to make life more pleasant for the programmer even at the expense of performance. All PLs are designed to make life more pleasant for the programmer at the expense of performance. That's why Fortran automated register allocation. 
I've taken a break for a bit, but I'm starting back up on improving a fun little [terminal based conways game of life](https://github.com/Syntaf/GameOfLife). 
Also, !cargo will search crates.io.
You can also use `in &amp;buffer[..read]` instead of `in buffer[..read].iter()`.
I'm also curious about this - I've been under the impression that syntax extensions inherently require using the nightly branch? From what I understand the `syntex` crate allows for side-stepping this using some build.rs magic, though its use and setup seemed a little awkward for my liking (perhaps I should give it another chance?). It's for these reasons, as much as I'd love to, I haven't yet adopted erickt's other amazing crate, `serde`. I wonder what the state of compiler plugins are in terms of stability? Is there currently work going on in this area? Or can we expect to wait another year or two before using these awesome crates on stable (without something like syntex)? Any links or comments from people in-the-know are appreciated :)
I did say "So don’t go and think these code snippets are executable just yet :)". I just haven't wired it up with [syntex](https://github.com/serde-rs/syntex). I suppose I should go do that now... edit: github is down, which has also brought down cargo :( maybe in a bit!
I've nothing too fancy to offer, just wanted to mention that my solution is similar to the refactoring one you mention. However, I normally try to refactor into new types or functions rather than smaller methods, as methods often still retain the problem of borrowing `self` (as you mention). Normally I end up doing the following: - Check to see if I can refactor the fields of my type into sensical groups, so that when I need to mutate those fields, I can de-structure my original type, mutate the necessary "grouped" type and retain access to the other fields. This is rarely useful, but nice when it works out. - If that fails or is impractical, write the body of the mutable method as a private function in the same module which only takes each of the necessary fields as arguments. This way other `&amp;mut self` methods can de-structure self, call the private function (instead of the original method that they wish to call) and still retain access to their other fields. Otherwise, I just try to stay wary while writing methods, i.e "does this method *really* need mutable access to self? Could it be better expressed and more flexible as a function, or perhaps called as a method on one of the fields? These solutions aren't the prettiest and can feel a little verbose, but I find that refactoring into functions can also be surprisingly beneficial and really nice for unlocking a surprising amount of modularity. Anyway, OP is probably aware of these, but just thought I'd get them down in the interest of sharing.
Um... Just use [zeal](https://zealdocs.org/) offline docs for Rust, C++, JS, Python, etc. 
Also, the `!rust` doesn't have to be at the beginning of the search string, for example `String !rust` works just as well. Of course this works the same for `!g`, `!gi`, etc.
I'm just wondering if this is a reasonable idea. Of course, allocating resources to get it done is a different story. :P
I think this would be a good idea.
I don't believe a list of wanted features exists, apart from the [issue tracker] (https://github.com/rust-lang/cargo/issues/). If you wish to contribute to Rust or Cargo, you can browse issues tagged with E-Easy label - most of them aren't too difficult to fix - or you can PM me. I am no expert, but I can help you find something to work on. If you'd like to report a bug or propose a new feature, you can post a new issue on the tracker or, again, message me, so I can help you to do so. Edit: added explanation.
Where have you found newlib to be different from libc as far as rust is concerned?
Just to check if I understand correctly: With `&amp;byte`, the dereference happens at the beginning of each iteration, because the part after `for` is actually a pattern. Right? (I also wonder if it makes a difference for the case where there's more than one use of `*byte` in the body.)
Nice, thanks!
Thanks! TIL
For more clarity, and because a lot of the others are awesome as well: [They're called bangs](https://duckduckgo.com/bang), a looot of them.
I'd also at least skim the concurrency and parallelization support (e.g. show a short crossbeam or simple_parallel example, and how borrowck keeps you from introducing data races).
Yep, especially contrasting to a GC language like golang for example, would give you a good idea of the power (and limitations) of using rust closures.
As you wish: [mandelbrot](https://users.rust-lang.org/t/new-version-of-mandel-rust-uses-rayon-added-benchmark/4403) ;-)
This is great. I am using [qutebrowser](https://github.com/The-Compiler/qutebrowser) for rust docs and now it is much faster to read docs with !rust.
you can also have the ! at the end of the name (g!)
I once gave a [talk about RAII and Ownership](https://github.com/Marthog/presentation-raii/blob/master/presentation/presentation.pdf) at my university. It was a similar audience (computer scientists, at least java and basic C knowledge), although the topic was a bit different, because I did not just talk about rust alone and focused on a single aspect of it. It seemed to be quite understandable, although there was a question about the syntax of the lifetimes example, especially in the combination of lifetimes and generics.
&gt; That's just not true. In fact the vast majority of production GCs stop the world every now and then. They may try to keep most things concurrent, but ultimately they stop. A stop-the-world GC is one that stops the world for the entire duration of the GC cycle or "while the GC cleans up the memory" as the article claims. No production GCs are stop-the-world GCs. They are what is called "mostly concurrent" collectors. They have phases that pause all mutators but they are many orders of magnitude shorter than the entire GC cycle. For example, the .NET workstation GC stops the world to collate global roots. That is a very short pause (microseconds) compared to stopping the world for the entire GC cycles (hundreds of milliseconds). &gt; The alternative (fully concurrent GC) is crazy expensive for the mutator unless you have custom hardware. Fully concurrent GC is crazy expensive, yes. That is the opposite end of the spectrum to stop the world. 
Generally, turning a concrete-type pointer into a trait object pointer is a one-way only transformation, since being able to go back would require additional metadata that is not emitted per default because it would cause too much size overhead. You have several options to approach it though: - If you only need the trait object temporarily, you could turn a `&amp;T` or ``&amp;mut T` into a `&amp;Trait` or `&amp;mut Trait` - that way you still keep ownership and access to the original `T`. - Using https://doc.rust-lang.org/std/any/trait.Any.html , you can explicitly make your trait object generate something with said metadata by adding a method like `as_any(&amp;self) -&gt; &amp;Any` (or one that use `&amp;mut` or `Box`) to it. You can then use the `Any` trait object to cast back to the concrete type. - Just add `as_foo(), as_bar()` methods to the trait that return a `Option&lt;...&gt;` of the actual type - this only works if your set of types is fixed though, and in that case you might just want to use a enum rather than a trait object. 
Thanks, very interesting read! 
If you have control over the `Common` trait, then you can make it inherit from [`std::any::Any`](http://doc.rust-lang.org/std/any/trait.Any.html), which was designed to do exactly what you want. use std::any::Any; trait Common: Any {} struct Foo { foo: u32, } struct Bar; impl Common for Foo {} impl Common for Bar {} fn main() { let mut list: Vec&lt;Box&lt;Common&gt;&gt; = Vec::new(); list.push(Box::new(Foo { foo: 123 })); list.push(Box::new(Bar)); let foo = list[0].downcast_ref::&lt;Foo&gt;().unwrap(); foo.foo; } The best part is that `Any` is automatically implemented for every nameable `'static` type, which means anything that isn't a closure or has a non-`'static` lifetime parameter. You can also do a [moving downcast](http://doc.rust-lang.org/std/boxed/struct.Box.html#method.downcast) if a reference isn't what you want (only if you own the `Box&lt;Any&gt;`, of course): let foo_any: Box&lt;Any&gt; = Box::new(Foo { foo: 123 }); let foo = foo_any.downcast::&lt;Foo&gt;().unwrap(); Note that the `.unwrap()` calls in previous examples will `panic!()` if the downcasts fail, which may or may not be what you want. `Any::downcast_ref::&lt;T&gt;()` returns `Option&lt;&amp;T&gt;` and `Box&lt;Any&gt;::downcast::&lt;T&gt;()` returns `Result&lt;Box&lt;T&gt;, Box&lt;Any&gt;&gt;` (the extra `'static` bound listed in the documentation is, AFAICT, totally redundant). 
You should check if this isn't somehow solvable by introducing an enum that has a case for each type it can be. That's a lot more idiomatic and allows for Pattern Matching.
It simply means that a T object is being allocated on the heap and a pointer to it is stored wherever your Box is located. The only difference to a normal reference is that it drops (destructor call), whenever the box goes out of scope, while a reference doesn't do this, cause it's just a borrow. Overall it simply behaves like just a T object, but introduces an indirection to the heap. Usually you don't want that for cache efficiency reasons, but you also don't want to pollute your stack with objects that are too large, so you should make the trade-off and put those objects on the heap (like super large arrays). Also boxes can store dynamically sized types (types of which the size isn't known at compile time). Like slices, trait objects and "function objects" (trait objects of functions). So if you want to own an object of a dynamic size, you need to use a Box too. Also another use-case is storing an object of your own type inside that type. That obviously means the compiler can't figure out the size of the type due to that infinite recursion. You can break that by using a Box too.
&gt; I think you are neglecting the effects of fragmentation in your analysis there. Just because a certain amount of memory was freed does not mean you can allocate it again. It also says nothing about cache hot/coldness which is a big factor in performance. Not neglecting it at all: there's not going be any fragmentation for a program like that, the allocations come in just two sizes. The `tmp`/`tmp1` vector/shared_pointer allocations will end up alternating between the two addresses. Modern allocators are careful to minimize fragmentation via the use of free lists and size classes and so on. *And* that's not even getting to the part I mentioned where one can just not perform any allocations at all, by leaning on the guarantees of move semantics. The cache locality benefits of a moving GC is a bit of a red herring: languages like C++ and Rust generally allow much more aggressive inline allocation than managed languages, and have better tools for manipulating them (references, etc.). And it's not just a matter of value types existing, but the culture with the language: values types are the completely first class and are the default in C++/Rust. In fact, at least in Rust, there's no other sort of type (even references are just normal value types, that happen to be pointers), and so all libraries will be using them pervasively without even thinking about it (e.g. sum types: `enum` in Rust is always a value type, while Haskell's `data`, F#'s `union` &amp; OCaml's `type` are not in general). The point being: fewer allocations happen, fewer pointer dereferences in general, and things end up closer in memory by default anyway. Furthermore, a modern allocator like jemalloc is quite aggressive in getting things close together, e.g. this prints the addresses of some interleaved allocations of different sizes: const LARGE: [u8; 1024] = [0; 1024]; fn main() { let x = Box::new(1_i64); let a = Box::new(LARGE); let y = Box::new(2_i64); let b = Box::new(LARGE); let z = Box::new(3_i64); let c = Box::new(LARGE); println!("integers:\n{:p}\n{:p}\n{:p}", x, y, z); println!("arrays:\n{:p}\n{:p}\n{:p}", a, b, c); drop(x); let z = Box::new(4_i64); println!("last integer:\n{:p}", z); } [Prints](https://play.rust-lang.org/?gist=2b0c121b186acf9e9caf&amp;version=stable&amp;run=1) something like: integers: 0x7eff1f823010 0x7eff1f823018 0x7eff1f823020 arrays: 0x7eff1f82e000 0x7eff1f82e400 0x7eff1f82e800 last integer: 0x7eff1f823010 Obviously, this is a toy example, but it hints at the tricks jemalloc has up its sleeve: separating allocations of different sizes into separate memory areas, placing things adjacent in memory (the integers are 0x8 bytes each, and the arrays are 0x400 bytes each), aggressively reusing freed memory, etc. The last and especially the first reduces fragmentation, and the latter two are good for cache locality. Of course, there is likely to be pathological cases of these sort of allocation patterns that are handled better with a GC, and, a moving GC gives you many of the benefits of a pervasive-value-types language without having to deal with the consequences of that choice. &gt; The .NET workstation GC stops the world to determine global roots twice per GC cycle. Not to traverse the heap and certainly not to clean up the heap. That typically takes microseconds so the latency contribution is small and the impact on scalability is small (it has been tested on machines with hundreds of cores). However, the article specifically said "while the GC cleans up the memory". No production GCs stop the world while the GC cleans up the memory (i.e. a fully stop-the-world GC). They only ever stop it for a very short phase within the GC cycle or when disaster has struck such as needing to compact the entire heap. I think the disagreement is just that we interpreted the article differently: you seem to have taken "while the GC cleans up memory" to mean the GC stops the world as on entry and restarts it on exit, while I took to just refer to any stops that happen during the GC executions i.e. not necessarily the whole time (the "while" word is a bit ambiguous). I can't read minds, so I don't know which interpretation the author was going for: I agree with you if it was the former.
I had problems with Firefox crashing on me so I switched to Chrome. I've been using it since then because it would be a bigger pain to switch back (that and it's easier in Chrome to open a new window with a different profile and create new profiles, a feature I use quite a bit). This is probably one of the features I miss the most. I still catch myself trying to search with those keywords on Chrome. Edit: I know Chrome has a similar feature but keyword searches in Firefox were a lot more streamlined. I didn't have to stop and confirm the search engine before continuing. I could just type out the whole query and it'd go to exactly what I wanted.
Still there for me.
I had problems with Firefox too (on Linux)... So I went to Nightly... and never came back to stable!
Nope (source: https://duckduckgo.com/bang?q=rust ): But you can [make a suggestion](https://duckduckgo.com/newbang) :)
Hah! You call that lazy? Try this: http://ddg.gg/?q=!rust+Vec
Wouldn't the opposite be an example that's biased the other way? (At best, assuming that the function taking in the buffer has error handling).
The opposite could be biased the other way. However I'm not defending that the opposite should be stated in the article. I'm defending that this example - as is - shows bias and misleads a reader that doesn't know C++. The function taking the buffer doesn't need any additional error handling. Perhaps it's the intention of the caller to add data to a vector that already has data. While, as I stated, I do accept the argument of consistency, consistency was not the argument in the article, and the alternative example that was posted where a vector is created in the heap and it's pointer returned is just an example crafted specifically to make C++ look bad in this situation that has a very nice and clean alternative (passing the buffer as reference).
The idea is that undefined behaviour shows up a lot when you monomorph/inline/const-fold away stuff. For instance, fn main() { // ... *x = 10; process(x); } fn process(x: *mut u32) { if x != null { *x *= 2; } } // inline process into main fn main() { // ... *x = 10; // This check is pointless, because they already derefed `x`. // If the "else" branch is ever taken, it would be UB if x != null { *x *= 2; } } // UB-folded fn main() { // ... // Free to further optimize this code away now *x = 10; *x *= 2; } There isn't some big engine searching for UB and then clobbering your program. It's searching for redundant work, and eliminating it based on the assumption that it's ok, because anything relying on the redundancy is UB. It's also being done by a bunch of narrow analyses that run in pseudo-arbitrary order. They don't get the full source, they just get whatever the output of the last analysis was. The undef stuff is similar. You can assume any branch that reads undefs is never taken, etc, etc.
Is there a way to operate on multi-piece strings? Let's say I have a bunch of String and I want to do a regex search over their concatenation, but without actually concatenating them all into a big string beforehand. For example, matching "bcd" against these two strings chained: "abc" "def".
I feel that since there are so many good intros to Rust already online, I can just link to those and talk about something different.
Do you mean something like that http://is.gd/RGWVFv ?
To be fair I can extract the gist of this and I only speak English, context is a wonderful thing
If the audience is going to consist of students without huge amounts of experience I'd focus on making the presentation a little more, hmm, flashy instead of being very technical. For example: 1. Slide N: show a relatively simple C++ program that looks correct; tell the audience that there is an error in it - ask them if they can pinpoint it. 2. Slide N+1: show the C++ program being run; a wild segmentation fault appears! 3. Slide N+2: show exact same program written in Rust. 4. Slice N+3: show that Rust, unlike C++, refuses to compile the program. 5. Explain. 6. Jump to 1. Basically try to make an impact instead of just throwing technical details at them which are not going to be as convincing nor memorable. Also try to include some interactivity (e.g. the "do you see the error in this program?" mentioned before).
I don't recall having to confirm the search engine before continuing?
Wow! Thanks for the feedback =) Let's tackle them one by one * Yes, I do need to add docs. Procrastinating it :| * Ok, I forgot to remove that line. I was using r' as it was easy than remembering to escape everything. * Hmm, I too thought of this. Your approach is good, I will try implementing it (as soon as I understand how RefCell works) The Iterable for the struct sounds cool! I was reading about Iterators this morning, so I might work on this. Named Capture groups? Done. Pushing soon. Compiler plugin looks complicated stuff o_O. I think Verex (VerbalExpressions for Rust) is a better alternative if you want readability.
That is totally understandable. But the point of the presentation is to introduce Rust to students and profs who have probably never heard about it. Going deeper in one area is probably better for people who have already been exposed to Rust or have enough programming experience to know exactly what the equivalent would be in their language (e.g. c++). At least that's what I think :)
This is accurate, yes. Also, that's Cargo's issue tracker, there's also https://github.com/rust-lang/crates.io/issues
You can add Rust nightly to Firefox search and assign a keyword !rust-nightly. I use it for my office internal documentation pages and custom searches which DDG does not have a bang yet.
Have you seen the article called [What Color Is Your Function?](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)? I hope we can figure out a way to solve this problem that both meets our own criteria and also avoids recapitulating the mistakes that it describes.
I'd like to add that [clippy](https://github.com/Manishearth/rust-clippy) has some lints against shadowing, which nonetheless are `allow` by default, because when I tried them, I found so much matches in the wild that it swamped the compiler output.
It's pretty good as far as I can tell, here are a couple of things I noticed: 1. You can have a lib and one (or more) binaries in the same cargo project, you don't need to nest them. You can find a little bit of information about that [here](http://doc.crates.io/manifest.html#the-project-layout). So you could have a `src/lib.rs` file and have the binary as `src/bin/*.rs`. In my project I even specified it in the `Cargo.toml` [[bin]] doc = false name = "mdbook" path = "src/bin/mdbook.rs" 2. When you implement methods like `fn to_string(&amp;self) -&gt; String` you may want to implement the trait from std: https://doc.rust-lang.org/std/string/trait.ToString.html this will give you trait bounds as a bonus. 3. You seem to copy a lot of the `Vec`s at the beginning of functions instead of using the borrowed version, is that necessary? It seems superfluous to me, but I could be wrong.
Ah, right. I always used [this method](http://lifehacker.com/5476033/how-to-set-keyword-bookmarks-in-google-chrome), which I think is what you describe. Although the other feature was useful too since it didn't require setting up, so I actually miss that in Firefox :) (That said, just setting DDG as the default search engine to enable the bangs replaced my need for my own keywords completely.)
If your only doing a single character look ahead. Then you'll likely want to use the CHAIN operator. So lets say you want to iterate over a list of characters in a single string for c in underlying_string.chars() { //your code here } Now if you want to do this with multiple strings for c in underlying_string_1.chars().chain( underlying_string_2.chars() ) { //your code here } If you get fancy with life times/looping you can easily do N strings. This'll give you an iterator of chars without re-allocating the strings, just copying the characters 1 by 1 for processing. 
Awesome, thanks for this! Helps validate that I'm not crazy :) Good suggestion about refactoring into groups to limit borrowing, I'll see if I can do that in this case. I suppose one nice side-effect of writing `self`-less functions is that it greatly simplifies unit testing, since all the state is intrinsically injected into the function.
When I first started using rust I was running Nightly a lot, but now I'm on stable pretty much always. Do those using clippy just switch branches to perform lints?
Coo! :) &gt; Compiler plugin looks complicated stuff o_O. I think Verex (VerbalExpressions for Rust) is a better alternative if you want readability. Well, the idea here is that you write your regex normally, e.g., `(?P&lt;first&gt;\pL+)\s+(?P&lt;last&gt;\pL+)`, but have the compiler plugin produce a struct for you. For example: regex_capture_struct!(FullName, r"(?P&lt;first&gt;\pL+)\s+(?P&lt;last&gt;\pL+)"); Would then generate this struct: struct FullName { first: String, last: String } This could get *really* fancy by incorporating the struct into the regex matching itself, so that it can completely avoid building a hash map for the named capture groups in the first place. But this idea is just exploratory stuff that might take quite a while to get to! (The `regex!` plugin needs some major love and attention.)
Thank you!
~~https://github.com/brson/multirust-rs~~ https://github.com/Diggsey/multirust-rs
Can Rust be used for PIC programming?
Congratulations! 100 lints is insanely awesome! I'm really impressed by the speed at which you add new lints, too. Every time I look at the repo, the number has increased! What are your plans for linting library code? You could e.g. lint some occurrences of regexes that could've been calls to `split`. (Or just that the `regex!` macro is currently slower than using the run time based constructor.) (Was it my imagination or does the Visual Studio Code plugin show compiler error and warnings inline?)
Likely no. The PIC would need to be supported by the LLVM to start with. If it was then maybe (first you'd need a memory allocator, then you could start porting stdlib). The core issues with smaller PIC/Embedded processors is their only support by 1 compiler, the vendor. 
Actually we're at 101 lints now; I just merged another one from mcarton. As for library lints, feel free to open an [issue](https://github.com/Manishearth/rust-clippy/issues). Regarding inline warnings: At least RustDT does this, so I wouldn't be surprised.
I don't think we'll have stable lints for the foreseeable time. The first things to be stabilized will probably be macros. I'm absolutely OK with the instability though, as I'm quite interested in the future compiler improvements that wouldn't be possible if the interfaces were set in stone.
De rien et désolé parce que je suis inculte mais je connais Stromae! :p J'ai un autre conseil pour toi. Parler de "Pattern Matching" parce que c'est très puissant. (I go back to English to not loose what I want to say in translation) Pattern matching provides a powerful way to express "if you see this kind of node with that kind of node inside it, do this thing". You can do really cool symbolic manipulations like deforestation of a AST, prove theorems (à la Coq), verification of correctness, etc. Here's an [example](https://gist.github.com/anonymous/32357238c0233e348413). You could also make evaluation optimizations to this example using laws of boolean algebra like `Not(Not(x)) =&gt; x` to reduce the number of evaluations. C++ doesn't have algebraic data types so it's quite awkward to write equivalent. We have `boost::variant` but it's not baked into the type system. Another thing is not just the memory safety but writing statically correct code. For example, if I missed a match, say Expr::Not(), then the compiler will complain that I haven't matched it. I am happy to review your presentation to give feedback as it will be good practise to improve my French.
Not just a new Rust User but new to programming in general. Are there any guides to learning to program that use Rust as their language to teach? 
This is another option. Personally I prefer just running `cargo clippy` with a nightly, so I don't even need to change the code.
Thanks, that's a good idea too. I remember that when I first saw the `match` syntax I was amazed! I am not too experienced with algebraic data types though, I don't think I have ever used the more powerful features it offers. Do you have some good reading material about that? &gt;I am happy to review your presentation to give feedback as it will be good practise to improve my French. Sure, that would be great. I will need people to review it to make sure that what I am telling is correct ;) 
Compiler plugins aren't really complicated. You just get a bunch of APIs that you implement and can use a lot of goodies from the compiler code base. Actually I think it's probably easier to build a compiler plugin for rustc than any nontrivial application. ;-)
IMHO, this looks ugly and is less readable than the `try!()` macro.
I really like the idea of zeal, though I'd prefer a commandline client for it, and I cannot find one. Is there one available? Like a curses ui or something? Or even a one-shot CLI program?
Would you recommend switching over to multirust-rs?
https://github.com/sunaku/dasht You can download docs [here](https://kapeli.com/docset_links) and check it's internal content. I'm sure that it's just a html files and you can use lynx, links, w3m and etc. with them. 
Please be more specific, which part is ugly?
The safest way to prevent moves would be to put the structure behind a pointer, eg. a `Box` and export it as opaque type (so the user cannot accidentally unbox it). You may find crate [owning_ref](https://crates.io/crates/owning_ref/) inspiring – I don't know if it satisfies your needs but you may find reading the source helpful.
There is not anything that I'm aware of, no. The Book attempts to work for anyone who knows at least one other language, but teaching programming in general requires a different approach. (That's speaking generally, of course. You could tough it out!)
In the future, multirust-rs, multirust, and rustup.sh are all going to be merged into one thing.
The issue I have with `try`-blocks as they are described in the proposal is mainly that they are so very close to a proper monadic `do`-notation except that it falls apart on details like being able to propagate state, making it useless for anything but short-circuiting control-flow. As for early-return, if the whole function is a `do`-block then it will technically be an early return whenever a statement in the block fails. In the context of `try`-blocks `do`-notation is pretty much the same with the difference that you cannot jump out of nested statements (which might be exactly what you are looking for).
awesome! Going to package it for nixos asap!
The `try... catch` thing seems to introduce some unneeded complexity (e.g. you easily get a `Result&lt;Result&lt;_&gt;&gt;` if you miss a `?` at the end). The `?` itself seems to be helpful in chained expressions but I would prefer the expressiveness of a method level `try` macro.
Too true. However, the people on IRC are really helpful.
&gt; As for early-return, if the whole function is a do-block then it will technically be an early return whenever a statement in the block fails. In the context of try-blocks do-notation is pretty much the same with the difference that you cannot jump out of nested statements (which might be exactly what you are looking for). Not sure I understand what you mean. For instance consider an example like: let mut x; while foo()? { bar(); if quux()? { break; } else if frob()? == fizz()? { continue; } x += baz(); } return x; How would this be converted into a closure based solution?
Yeah, but until then... I mean, multirust "classic" fulfills all my needs but for bugfixes or feature contribution ideas I'm unclear on which to target.
&gt; I disagree. Both JavaScriptCore (WebKit) and Presto (Opera) do, in fact, stop execution entirely while collecting garbage. Sorry I was thinking of high performance ones like JVM and .NET. I am not familiar with JS implementations. **EDIT**: Now that I come to think of it I bet the Dalvik VM running Java code on Android devices uses a stop-the-world collector. I am just reading up on JavaScriptCore and it is just awful. Why are they using such awful GC algorithms in this day and age?! They're all stuck in the 20th century... &gt; but the main execution thread is paused for the entire duration. That's absolutely insane. About 100 lines of code would get them orders of magnitude lower latency. Why oh why?! 
&gt; The point in the article is that garbage collectors have an overhead, which we can all agree on. Well, GCs have lots of overheads but they also improve performance in some respects. That's why the trade-offs are so complicated. &gt; I suppose the author could have added an aside explaining that he was oversimplifying things... The claim that the performance difference between C++ and Python is due to GC is not just "oversimplifying". It is complete nonsense. 
I have had some very basics (made a few simple scripts in Python). I will try to record my learning process, see if anything comes out of it. 
That's fair enough and I'm open to that. It's just not a complete alternative to `try!`/`do` then. Often find myself `try!`-ing in [loops](https://github.com/cristicbz/rust-doom/blob/master/src/wad/image.rs#L52). That last example's got the whole thing---breaks, returns try-s in loops etc. 
&gt; a closure can't 'straddle' a loop boundary. Well, I mean, the monad itself determines the control flow. &gt; it would still require a wealth of additional features (like HKT) so I'd still like some error handling relief in the next couple of years. Yes, this is why, even though I'm in favor of `do`, I'm also in favor of something that will help sooner rather than later.
I don't know much about Javascript but isn't it single threaded? So they only ever need an incremental and not a concurrent collector to get decent latency? Incremental collectors are easier to write than concurrent collectors: marking uses three states and you progress a "wave" through the heap with marked behind it and unmarked in front of it and when the wave disappears you sweep. OCaml uses tricolor marking today. Even mostly concurrent collectors can be quite easy to write. For example, [the VCGC algorithm](http://doc.cat-v.org/inferno/concurrent_gc/concurrent_gc.pdf) is short and sweet. OCaml is supposed to be using VCGC in the future. Concurrent might still be preferable to incremental for Javascript because collection can be done on another core so even single threaded code benefits from dual core. 
I do generally use `for &amp;x in &amp;...`, but not because of &gt; The nice thing about the second one is that it shows that we're dealing with a reference right where the loop variable is defined. In the first one, that only becomes apparent when the variable is used. I find this sort of thing not a big concern when writing Rust: the compiler will tell me when I need to care if something is a reference or value, that sort of thing just fades into the background most of the time.
You actually do not have any `try`-block in there which makes it hard to construct any alternative using `do`-notation, you just have early return from multiple blocks. Neither `do`-notation nor `try`-block + `?` can provide much for the case above since you do not need any "catching" of the error within the function body. The only thing you are using above is the `foo? === try!(foo)` rewrite, not any of the new ways of handling errors that the rest of the RFC details. As for your particular example it looks somewhat odd to me since you seem to lack some state which would be necessary in a normal program (and which would complicate some of the flow, but probably also force some simplifications of the above code). Depending on how the functions are defined above I would probably make some kind of `fold` over an iterator.
&gt; So learning a systems programming language is much wiser in these days. We have many options like JavaScript, Julia, GO, Rust, Swift From this list only Rust is a system programming language. Also it's Go, not GO.
&gt; A stop-the-world GC is one that stops the world for the entire duration of the GC cycle That's not at all what it means. You're moving the goal posts. A stop the world collector is one which stops the world. Mostly concurrent collectors are still stop-the world, they're just *also* stop-the-world. 
Try putting a loop inside the `do` block, and you start needing recursive data structures, which are pretty painful in Rust. Not to mention monad transformers already require either different syntax for `break`/`continue` or even more syntactic sugar.
Yes, you can rewrite your code to use functional styles -- this is always possible since FP style is Turing complete. But Rust does not want to encourage FP over other styles. Rust should fully, and naturally, support imperative programming. Many times I prefer imperative programming to functional programming.
But that privileges FP over imperative programming: if you program imperatively, you wouldn't get nice error handling. That seems excessively opinionated.
After a week off camping (yes, in a tent!) I finally "finished" my Shunting Yard implementation and calculator; its here: https://github.com/simon-whitehead/rust-yard. It parses basic equations and calculates a result. A basic example would be: let yard = rustyard::ShuntingYard::new("2 + 4 * 3"); println!("The result is: {}", yard.calculate().unwrap()); // prints 14 There is some work to do but overall I am happy with how it has turned out.
I think you're looking for /r/playrust
I think the `?` could easily be misleading. It somehow looks like the result of a `&lt;something&gt;?` expression is `bool`. Doesn't ruby use this `?` naming convention for boolean methods? I am pretty happy with the current system and I don't really see the need to imrpove it...
This may help: https://doc.rust-lang.org/book/getting-started.html#tier-1
pcwalton wrote a crate demonstrating intrusive lists with a safe interface: https://github.com/pcwalton/multilist
Yeah I've thought about this and it works in this simple case, but not for any other function that takes an &amp;str (like regex matching fore xample), and so I have to put everything in one memory block. It's a shame because I can do that easily in C++ with iterators.
Wouldn't having both `?` and `do` be bad for our [complexity/strangeness budget](http://words.steveklabnik.com/the-language-strangeness-budget)? I fear that once we get one, we will never get the other, and I prefer `do`...
There is the self-locking trick: struct Intrusive&lt;'a&gt; { field: u32, reference: Option&lt;&amp;'a u32&gt;, } fn main() { let mut a = Intrusive { field: 7, reference: None }; a.reference = Some(&amp;a.field); let b = a; // error: cannot move out of `a` because it is borrowed } ...however, since `a` is now borrowed for life, you can't do much with it, so the usefulness of this trick is somewhat limited. Edit: With cells, it becomes somewhat more useful: use std::cell::Cell; struct Intrusive&lt;'a&gt; { field: Cell&lt;u32&gt;, reference: Cell&lt;Option&lt;&amp;'a Cell&lt;u32&gt;&gt;&gt;, } fn main() { let a = Intrusive { field: Cell::new(7), reference: Cell::new(None) }; a.reference.set(Some(&amp;a.field)); a.reference.get().map(|f| f.set(8)); assert_eq!(a.field.get(), 8); }
Blurgh. ~~But how do you stop `Foo` from moving?~~ ~~This is like doing unsafe types with a wrapper; you fundamentally cannot stop Rust from letting you move stuff, with the exception of things that are borrowed.~~
Especially the tier-3 platforms. That was a nice read, I didn't know rust ran on MIPS.
 `Foo` can move as much as it wants to - `FooInternal` does not move in memory, because all you move is a pointer to `FooInternal`, not the `FooInternal` struct itself. (`FooInternal` should only point to things inside `FooInternal`, not to `Foo`.)
Yes, that is somehting I detailed in the blog-post. Maybe not explicitly, but I did state that it only works on the statement-level inside of the `do`-block so any other nested structure needs its own way of propagating the monad upwards.
The ? operator works fine with functional programming styles too. It just isn't as convenient. Do-notation, however, doesn't work *at all* with imperative programming.
Still does not solve the issue of computation in a context (or error handling in a context) in a nice way by itself, sadly. For that you need something monad-like. But I agree, method-position macros would be pretty awesome.
Then, let's make the try branch not automatically wrap the last expression. An Ok(...) may be needed sometimes but explicitness is good.
It is a very different question to ask what rust *can* support. It almost certainly could support the CPUs you mentioned, but it doesn't because they're very niche and the maker of the chip never implemented an LLVM backend for it. It looks like the real question for you is. Does it run gnu/linux? If it does, then it would fall under the Tier-3 platforms list. Otherwise, the odds are worse. Either way, you should not give up hope until other people have answered.
"Functional programming" in Rust tends to involve many closures. An operator that performs an implicit return isn't very useful in that case, especially when the return type of the closure isn't a `Result` or `Option`. The only case where I imagine it would work is something like some_result.and_then(|x| x.foo()?.bar()) but that could be written like some_result.and_then(|x|.foo()).and_then(|x|x.bar()) Of course this can usually be rewritten to my preferred style some_result .and_then(Foo::foo) .and_then(Bar::bar)
If some as-yet-uninvented version of `do` solves all the issues that `?` does satisfactorily, we can just deprecate `?`---if we remove `?` we get our strangeness money back
When `?` is used for error handling everywhere (and it will be within weeks, because it's four fewer characters than `try!(...)`) you can't realistically deprecate it at that point, especially with the backwards compatibility guarantees. We will be locked into keeping `?` forever if it ever becomes a part of stable rust.
If your passed an &amp;str you can unsafely point to its underlying ram with a String::from_raw_parts() if you ensure the original &amp;str won't be freed during your objects life time. 
Wouldn't it be more suitable to represent the loop as the iterator monad and then `collect` the result? Sure, you get some stacking there but there is no need to do recursive stacking or recursive invocations. Recursive invocations are not that great in Rust since there is no guarantee that tail-call optimization will kick in, much better to use iterators for it. In the iterator monad you can make a conditional which returns the empty iterator whenever you want to use `continue` (see Haskell's `guard`). `break` is more complicated though, since just short-circuiting the current iteration-level is not enough.
You can build loops using the iterator monad in `do`-blocks and use `guard` (to get the functionality of `continue`) without having to do recursive stacking of either datastructures or function-invocations: do { x &lt;- (0..3); y &lt;- (0..3); guard(x != y); iter::once((x, y) }.collect::&lt;Vec&lt;_&gt;&gt;() Expanded version in playground: http://is.gd/7ngx9m This works pretty nicely in rust since Rust's `Iterator` is by default lazy. Getting a `break` to work is not something which is a part of the standard iterator monad, but there are ways to set breakpoints to cancel an iterator: http://erikerlandson.github.io/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions/ In Rust it would most likely require unsafe or some kind of shared state, since the break-flag needs to be set on the iterator (and currently `flat_map` takes `self` by value, which is a problem).
&gt; I'm absolutely OK with the instability though I supect that clippy would see wider adoption if it would be trivial to install and use.
The whole idea of `?` is to have a short postfix syntax (`expression?` instead of `try!(expression)`). The motivation for this readability. I find `try!(try!(try!(this).foo()).bar())` less readable than `this?.foo()?.bar()?`. It's the same argument as `map(filter(sequence.iter(),...),...)` being harder to decipher than `sequence.iter().filter(...).map(...)`. In both cases (postfix ? and Rust's iterator methods) you can read the expression from left to right to know what's going on whereas the other expressions have to be read inside out or understood backwards.
I think making it easier to use multirust (e.g. by pulling it into the standard installer) will allow for easier clippy integration.
The `values` was a typo, should be `data`, it is now fixed. &gt; What's happening here? In this example we have three functions which can fail: `read_values`, `logging_on` and `log_values`. We want to read some data, then check if we are supposed to log the data we just read and if so we want to write the values, and finally we want to return the values we read so we can do something with them. &gt; Why do we need this else branch? The `else` branch is needed because each statement inside of a `do`-block must be an expression evaluating to a monadic type (in this case `Result&lt;T, io::Error&gt;`). So in the specific case of the `if` we need to provide a monadic value in the case that we are not supposed to log anything, and this is just an `Ok` with the empty tuple (which is incidentally compatible with the signature of `log_values`). If we did not do this we would be forced to throw away the result of `log_values` and if we did that we would lose the ability to handle the error or short-circuit the computation. &gt; Does every statement inside do have to be an expression of a Result type? Simplified answer: yes. Though you can lift values into the `Result` type using `Ok`, or additional syntax can be allowed (like allowing plain `let` statements and having specific syntax for chaining without values, in the example above this is implicit just as in Haskell), or specific operators could be used for the monadic chaining. &gt; What does happen to these results? The `do`-notation is desugared to calls to the `and_then` method on the type and closures wrapping the following statements, so they will be flattened into a `Result&lt;SomeData, io::Error&gt;` which is the value the `do`-block will assume. Any error would short-circuit all the following statements within the same `do`-block and jump to the end. &gt; Where are they going to end up? Where and how are they consumed? Most of the results are consumed by `and_then`, ie. values are unwrapped from `Ok` variants and passed to the following statements and errors are propagated upwards in`Err` skipping all following statements. &gt; I find it pretty weird and un-Rusty that even though the if expression is terminated with a semicolon, its result somehow matters (otherwise we wouldn't need the else branch, would we?) The syntax from the example above is taken from Haskell, which has significant whitespace and therefore `do`-notation in haskell does not have any line-terminator (except for the newline itself). Rust does not have significant whitespace so there needs to be a terminator for expressions and statements, I selected `;` for this since that is what people are used to and it also matches the expression grammar. Each statement in the `do`-block is chained with the one below it, so that is why a `Result` needs to be returned by each statement, otherwise there is nothing to actually continue the chaining. I used a Haskell-like syntax to illustrate how it would work, it will not necessarily be how a Rust-version of `do`-notation would look like.
&gt; What does values refer to in the following snippet? I have a feeling that `values` is supposed to be `data` in this example. &gt; I find it pretty weird and un-Rusty that even though the if expression is terminated with a semicolon, its result somehow matters (otherwise we wouldn't need the `else` branch, would we?) Agreed. Makes me wonder if semicolons should be dropped whilst in `do` notation.
Almost everybody discussing do-notation in rust has been borrowing the haskell notation almost exactly, and I think it's not a great syntax for monads in rust, mostly for the reasons everybody's been talking about. Instead of `binding &lt;- expr`, I would instead prefix (or suffix) monadic expressions with an operator. Lets use `?`, since it seems relevant. Then you wouldn't need to worry about expressions having to have certain return values even when they end with a semicolon, and the result (unsurprisingly) looks almost identical to the proposed syntax. do { let data = read_values()?; if logging_on()? { log_values(values) }; data } Basically `?` now 'calls out' to the underlying monad, and the end expression of the do-block is wrapped with `pure`. Also, I would probably use `collect` instead of `do`, but that's not really important.
just `!h` also searches hoogle. The amount of times I've gone for `!g` and missed :/
The ARM Cortex M series works. I assume there's some small MIPS cores that work too, but can't confirm or deny.
&gt; But that privileges FP over imperative programming Every bit of syntax can do this, though. Like, if you squint, our heavy use of iterators "privileges FP over imperative programming" too. Rust has never had "don't have opinions" as a core value. It's "Don't let orthodoxy get in the way of useful stuff."
&gt; I don't really know why the type inference complain Each closure has a unique type. This annotation makes it coerce to a trait object instead.
Have you tried running without the standard library? That was the trick to get anything running on the Cortex M.
OpenWRT devices run linux. So you *want* to use the standard library to get access to libraries like hyper, clap and such. Otherwise you'll have to re-implement all that by yourself.
That's true, and the reasoning behind `?` is that it integrates with more of the language than `do`, and thus solves problems with `try!` that `do` does not. If someone could propose a version of `do` that *did* handle general control flow, it would probably get a lot of traction.
Can you define a data structure in Rust to be immutable? I.e. once the struct is created, it cannot be mutated, and you aren't allowed to `let mut a = a` to cast it into a mutable variable. On a separate note, are there any good immutable data structure crates for Rust? 
&gt; Like, if you squint, our heavy use of iterators "privileges FP over imperative programming" too. I don't see that--could you explain? &gt; It's "Don't let orthodoxy get in the way of useful stuff." Well, I think `do` violates that principle, unless there's a way to solve break/continue/return :) We already have the less-orthodox version of `do`--it's `try!`. `do` is just a more orthodox, less flexible, less verbose version of it. The decreased verbosity in the case of straight-line code is nice, but the loss of orthogonality--we'd be introducing a feature that doesn't interact well with the basic control structures of the language--makes it not worth it in my mind.
You're probably right. I suppose the issue _is_ the fact that said version of `do` is as-yet-uninvented.
Can you instead call `f.make_bar()` every time you need a `Bar&lt;'a&gt;`? You're right that you can't really work with structs that point to themselves.
Ah, yes. Though looking at `collect`, it is pretty close to the Traversal idiom in Haskell (or some combination with Foldable), so the name isn't too far off.
This is fairly standard syntax. Short options that are binary toggles can be joined together. But if a short option has a mandatory argument, you can join together the short option and the argument. A classic example is the compiler: you link libraries by passing "-l" and the library name, but you merge the name together: "-lm" for the "libm" library, "-lcrypto" for the "libcrypto" library, etc. Another example that comes to mind is "cut" - the "-d" and "-f" options for delimiters and fields allow you to join the option and the argument: $ echo "a,b,c" | cut -d, -f1 a $ echo "a,b,c" | cut -d , -f 1 a (I admit I'm using gnu "cut", and I don't have easy access to more historical versions.)
Ah! I see! So indeed for non-binary toggles there is no ambiguity!
Well, Idris !-notation is completely monadic and is not related to early return. So `return (!x + !y)` is basically a sugar for do x' &lt;- x y' &lt;- y return $ x' + y'
Note that untyped templates can still generate code that is statically type-checked. The question here is whether the type errors are caught when defining the template (that is, if you have typed templates), or when using the template (if you have untyped templates).
You can point to dependencies on the same machine with `path = &lt;path&gt;` dependencies.
I looked at this example and failed to see how a `try { } catch { }` construct would have improved the code? I think it looks good the way you have written it.
And while at it, it would be good to think about an alternative lightweight source for crates.io-index. The [git repo](https://github.com/rust-lang/crates.io-index) currently has 21k+ commits. Cargo does a deep clone of the repo, which takes 15.1MiB of data. But the latest snapshot of the repo can fit in a 1.33MiB tar.gz file.
 The icing on the cake: this crate never uses unsafe Yay!
I believe that's how PartialOrd is implemented for tuples, and the #[derive(PartialOrd)] implementations for tuple structs as well.
At least for tuples up to size 12.
Good to know. I'll look at what happens there, but my problem is a bit more general as I need to order by functions of multiple struct members that don't reduce to treating one member at a time.
I guess its an Atmel (now owned by microchip): https://github.com/Sh4rK/avr-rust Q: Does PIC actually run C++ yet or just C?
&gt; That's not at all what it means. You're moving the goal posts. A stop the world collector is one which stops the world. Mostly concurrent collectors are still stop-the world, they're just also stop-the-world. No. I just checked and I am using the correct terminology: "These scenarios, where collection cycles are completed while the mutators are halted, are called *stop-the-world collection*" -- The GC Handbook by Jones, Hosking and Moss p.275 and here: "The tracing collectors considered so far have all been stop-the-world: all mutators threads must be brought to a halt before the collector runs to completion" -- The GC Handbook by Jones, Hosking and Moss p.78 You had me worried for a minute there. :-) 
You should continue reading. Even in mostly concurrent collectors the collection cycles are completed while mutators are halted, it just has some phases that can run concurrently. Edit: Consider this, what if you found a single CPU instruction that's part of the standard mark-sweep GC algorithm that could be moved so it happens before you stop all the mutators, does that magically transform it into not being stop-the-world? How about 10 instructions? Or 100? No, of course not. Stopping the world refers to the fact that the algorithm stops all the threads at some point, and I didn't find that concept confusing at all when I read the GC handbook. The reality is that most production GCs are a mix and match where some parts are concurrent, some are stop-the-world, some might even be reference counted or incremental. And even within each of those there's often mixing and matching (e.g. use different algorithms for different generations, or turn off copying/compaction for the oldest generation etc.). They're never just one thing. Edit2: Oh and btw, .net uses non-concurrent stop-the-world for the first two generations (background collections are only for the gen 2). See "collection on ephemeral generations during background garbage collection is known as foreground garbage collection. When foreground garbage collections occur, all managed threads are suspended. " https://msdn.microsoft.com/en-us/library/ee787088(v=vs.110).aspx#concurrent_garbage_collection
So, when we download this, we can tell others that we have 'the clap?' Seriously, though, excellent work.
Can't a closure take its parameters by mutable reference? For example, `let a = |&amp;mut x: i32| i += 1;` doesn't compile due to ``` expected 'i32', found '&amp;mut _' ``` which I don't really get.
Tried to update https://github.com/Keats/dbmigrate to clap 2.0 but realised the `unstable` feature requires nightly rust since its feature flag includes clippy. Maybe it should be mentioned that the `clap_app` macro is not usable anymore outside of the nightly branch in the breaking changes? What's the reasoning behind it?
You want `x: &amp;mut i32`.
&gt; However, I was wondering if there's any planned or ongoing effort in supporting selfhosted (or even authenticated) package feeds in cargo? I'm not 100% sure what exactly you mean by 'feed' here, but you can run a copy of crates.io and use it instead. That's the only support right now, and the documentation on doing so is, well, kinda nonexistent. Features like this are things we'd love to have eventually, but need community support to develop. There's just not enough hours on the day to fit all of the awesome stuff in.
Oh wow of course, looks like I'm not yet very familiar with the syntax. Thanks.
It's okay! you were close. There are four variations: * `x: &amp;i32` -&gt; all immutable, nothing mutable * `x: &amp;mut i32` -&gt; x is immutable, what `x` points to is mutable * `mut x: &amp;i32` -&gt; `x` is mutable, what `x` points to is immutable * `mut x: &amp;mut i32` -&gt; `x` is mutable, what `x` points to is mutable The first and second are the common cases. You'll sometimes see the third, but usually when it's taking ownership, not a reference. I don't think I've ever seen the fourth in the wild.
So these are the same rules as function parameters, right? And what are the rules for type inference in closure parameters?
Looks like what I need; thanks.
While the lack of `unsafe` is neat, it has a concrete downside: the pool isn't as flexible as it could be. In particular, it seems that one cannot run jobs that don't live as long as the pool itself, and so a new pool needs to be spawned essentially every time one has a job that needs to pass references around. That is, there's no way to do something like let pool = ...; let x = 1; // spawn job that holds a reference to x Pools like rust-scoped-pool and scoped_threadpool do allow this: let mut pool = scoped_threadpool::Pool::new(4); let x = 1; pool.scoped(|scope| { scope.execute(|| { let y = &amp;x; }) })
Why is `?` being tied to `Result`? Couldn't it be generic over `Result` and `Option`, defining a new trait (something like `Optional`)? That way, it would follow the pattern of other elements of Rust syntax, that uses traits like `Index`, `IndexMut` and `Deref` to define the concrete types, instead of tying the syntax to a single type.
Not talking about try-catch, just asking how do-notation would work with such constructs 
Yes, right now, you can only have one. Adding more is a feature I really want, and agree is important. That does mean "behind a firewall" is possible today though. Rust doesn't really _focus_ on OSS: there's a lot of closed-source Rust out there, and we care about making Rust good in those places. You just don't hear about it as much, because it's closed source.
There is lots of value in that commit history. Just having tip doesn't allow for incremental updates. Is cargo using signed commits ? https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work
Not only the high-level. We'd need a good chunk of `typeck`, some parts of lifetime elision, most of `const_eval` and other parts of rustc I probably forgot. Also we'd need to maintain compatibility with current rustc, which is moving *fast*. I'd rather write a bunch of lints in that time.
But diwic _is_ talking about try-catch, so you're asking how do-notation, which he proposes as a generalized try-catch, would work with such constructs which are being suggested to generalize a construct you aren't woking with in your example
As I said, you're forced to create a new pool within the scope. This means, for instance, one is repeatedly having to spawn new threads. You cannot have a single thread pool threaded through an application that has arbitrary jobs assigned to it, unlike the two I mentioned above. This isn't a major problem with my exact example above, since, as you demonstrate, one can simply reverse the order of `let x` and `let pool`. However, it is a problem if one interprets it more literally (i.e. reordering isn't possible), such as if one as functions that want to use a pool. E.g. fn try_to_use_a_pool(pool: &amp;mut Pool&lt;...&gt;) { let x = 1; // no way to push || { let y = &amp;x; } to `pool` }
I cannot comment on "best," but hyper has not QUITE gained async abilities. It's almost there. Until then, the frameworks that exist that I know of are all synchronous. 
&gt; I'd rather write a bunch of lints in that time. Completely understandable. Thanks for the run-down of what all this would entail.
bingo, that's why i couldn't find it. that's exactly what I'm looking for. thanks.
Thank you too, for it appears you uncovered a bug. :-)
/r/playrust
&gt; So these are the same rules as function parameters, right? Yes. They both take an irrefutable pattern and a type (though in closures the type is optional of course). &gt; And what are the rules for type inference in closure parameters? For the most part, the same as any local variable (I have never _had_ to ascribe a type to a closure's parameter that I can remember).
Ah yes, thank you for pointing that out. That is actually a mix up on my part. The unstable feature should *not* include clippy or require nightly to build. I will make that fix and ammend the breaking changes notice. The reasoning behind moving the macro to unstable is the syntax *may* change slightly, as there are certain features not supported by the macro yet.
I am a PHP dev. What I want to tell is, according to the current state of cross platform web applications, starting learn about system programming and going native is a optimistic solution. Even you failed at native application development, you can use this chance to learn about low level languages like Rust which can be helpful for performant back-end development in future . I am not good at handling words :)
The RFC covers this and has a carrier trait for unifying `Result` and `Optional`. Personally, I think the carrier trait is useful but would prefer that the carrier trait get stabilized much later because it may interfere with using `?` and `try` `catch` more generally with higher kinded types if we aren't careful.
What if `-o` declares an argument?
As Steve already wrote, hyper does not yet support mio, so e.g. Iron can not work asynchronously either. Also, I would not go so far and call any of the 'HTTP convenience crates' that currently exist 'frameworks' – they are more like the core pieces of express and nothing like Rails. If you are looking for a nice technical demo how async code can work in rust, you should check out rotor and rotor-http.
Take a look at [rotor-http ](https://crates.io/crates/rotor-http/) 
There is no copy constructor ~~or Copy trait~~ in Rust so the only way to do this I can think of is implementing Clone. This seems to works but I think it's a bad idea to do this http://is.gd/3oE9dg EDIT: There's a good explanation about copy and clone in the stdlib https://doc.rust-lang.org/std/marker/trait.Copy.html
`do` would replace both try-catch and `?`. What I'm saying is that I cannot imagine how one would implement `do` such that (if I wrapped the entire `from_buffer` method in `do`) I could replace all the `try!`-s with `&lt;-` binds.
Lifetimes are not really an issue for monads (well, not more of an issue compared to normal), as long as we do not try to unify all monads under a single trait ([I made a blog post going through a few of the issues in unifying monads under a single trait](http://m4rw3r.github.io/rust-and-monad-trait/)). What you are proposing here with last expression being a non-monadic type (like in the proposed `try`-block) does not unify with monads, since then there is no state available to merge. Instead you have `map`. This means that the inner block cannot contribute to the state of the resulting monad value which is a bad thing since this will greatly limit what is possible to express (eg. you can't even flat-map iterators). If the last expression is a monad-type then it could work out, provided that `?` desugars properly so that state can be carried from `m` to be merged into the result of `f(x)` (and this state is separate from `x`): do { let x = m?; f(x) } As an example I can provide a pretty naive and useless statement-counting monad which would not work if the last expression is only `U` and not `M&lt;U&gt;`: http://is.gd/BhiDRE (note: it does not actually follow the monad laws since the number of calls to `bind` will affect the result, normally the number of calls to `bind` should not affect the result). EDIT: Forgot a `?` in the call to `square(n)` in the equivalent example at the bottom of the link above.
This would work nicely with eg. parser-generators! The fact that it follows the monadic signature and enforces a monadic expression at the last line also helps a lot with generality for different types, if we compare to the proposed `try`-blocks. Not sure how well it would work with eg. loops (since that was a concern which was raised in [one of the comments](https://www.reddit.com/r/rust/comments/435572/blog_the_operator_and_try_vs_do/czfvr25) to my blog post). But since it follows the basic idea of nesting expressions (with or without closures does not matter) it does not really seem like a bind inside of a loop would work out, sadly.
Wait, so implementing `Clone` does allow you to override the assignment operator?
Why does it prints `5 2` in both cases?
See also [this example](https://github.com/gtk-rs/examples/blob/master/src/cairo_threads.rs).
&gt; BoF room ...Bastard operator from Room? Googling just results in more of the acronym, but no expansion as far as I can see. Could you please expand one of them? Also: \*FOSDEM
I recall it having something to do with unlabelled issues, which `E-easy` would counter.
Is there a way of accessing a tuple's contents inside a match? This totally doesn't work... fn to_check(check: &amp;T, bounds: (&amp;T, &amp;T) -&gt; Result&lt;T, T&gt; where T: std::cmp::PartialOrdwhere { match *check { result @ *bounds.0 ... *bounds.1 =&gt; Ok(result), _ =&gt; Err(result) } }
That assumes it already conforms to JSON escaping rules. Not a good assumption to make.
Does something like this look good to you? https://play.rust-lang.org/?gist=efcebc3d53eed58ab066&amp;version=stable
Thanks, great to see how other people handle this.
Indeed, the `?` is much more expressive and cleaner than a `try ... catch`. The `try` looks very hideous and I think will make code more verbose than it already is.
why `=&lt;&lt;` not `&lt;-` as in Haskell?
It works because `field` is heap allocated, so it won't change when you transfer ownership and when it's cloned the `pointer` field is set to the new heap allocated u32.
You can't use return in closures to break iteration. This is a pain point I've experienced with iterators.
Yeah, I played around with this and there's not really a lot you can do in this situation. I tried map\_err and similar methods, but you can't early return anymore once you are within a closure, so you need to either use match or if let, but those are mostly similar, so there's not a lot you can do here. You can get rid of the ::&lt;isize&gt; though, as Rust is intelligent enough to infer that. Also you don't really need owned String objects here. Result&lt;\_, &amp;'static str&gt; should work. If there's potentially a few owned Strings involved, consider using a Result&lt;\_, Cow&lt;'static, str&gt;&gt;.
Well, I'd like to be able to validate that i32 and f32 values are in a certain range, in a function, and return a Result. So it has to be generic, with the PartialOrd trait restriction. But matching and returning a Result using borrowed values has caused the usual "fighting with the borrow-checker" problem…
You can sign up a room at the H building info desk. I'm booked all Sunday so I can't make it. 
Scala also uses `&lt;-`.
Based on [this post](http://stackoverflow.com/questions/16927885/usr-bin-ld-skipping-incompatible-foo-so-when-searching-for-foo) I installed two libraries, which resolved the issue completely: sudo apt-get install gcc-multilib lib32z1-dev 
I think you want /r/playrust
&lt;- is planned for placement box.
A [match clause guard](https://doc.rust-lang.org/book/patterns.html#guards) will work where the range check does not (a regular if statement may be clearer). Possibly making `T` `Copy + std::cmp::PartialOrd` is the solution to the borrow-checker issue.
Sorry for being too concise and for the shameful typo, I blame Belgian beer for that :)
the subreddit for the Rust game is /r/playrust
Nice summary! You've linked the wrong Simon Persson though (I don't mind having my real life identity linked to my reddit account, but to someone else's reddit account? I doubt that's a good idea!) :)
Wow I really had a hard time identifying this one. I was like, "is there something I don't know about numeric bases in rust?".
lol, forgot thanks
That looks like a bug in the error message to me: it seems like it should be more clear about the alternative(s). (I'm not a clippy maintainer, but it seems worth filing an issue about.)
Creating a `String` out of a `&amp;str` with `from_raw_parts` is highly likely to be incorrect: either the `&amp;str` isn't allocated with a `String` (so using `from_raw_parts` is wrong), or it is, in which case it is probably managed by some other `String` object somewhere (so having another pointing to the same memory may lead to double frees and general problems like that).
What does @ do in Rust code? I tried looking it up but I found nothing.
Thanks for writing this up! &gt; It seems very reliant on Mozilla. With the recent closing of Thunderbird and Firefox OS due to the "laser focus" this seems like a reasonable concern. Our guest from the Servo team explained that the core team has diversified so it's not as reliant on Mozilla as people seem to think. This is a valid concern, and I was that guest. I forgot to mention that we’re planning to ship Rust code in Firefox this year: * Announcement: https://www.reddit.com/r/rust/comments/3vxrne/in_2016_we_will_be_shipping_rust_code_and_servo/ * Build system support: https://bugzilla.mozilla.org/show_bug.cgi?id=1135640 * URL parser: https://bugzilla.mozilla.org/show_bug.cgi?id=1151899 * MP4 demuxer: https://bugzilla.mozilla.org/show_bug.cgi?id=1161350 So I’d be very surprised if Mozilla abandons Rust any time soon. That said I agree that Rust would be more healthy if it didn’t rely on Mozilla as much! I’m hopeful that more people/organizations/companies will get involved over time.
There is not any naming convention for owned or borrowed no. There is a naming convention, `str` is a **primitive**, so its lower case, `String`, `Path`, `PathBuf` are **structs** so they are upper case. *Other lower case names include* **functions/methods/modules/lifetimes**, *other upper case names include* **traits/enums/types/trait objects/generic types** and that's about all i can remember now... So really anything you can't point at right now in the code is upper case.. types, enums, traits, structs, are templates for things to be created. While primitives, functions, modules, lifetime, all really exists on paper has they do in the code, abstractly speaking. ---------- For reference you don't want any naming conventions for ownership, you should be able to tell when writing the code if its owned without understanding how the code works. Examples: - `x: &amp;value` borrowed [doc](https://doc.rust-lang.org/stable/book/references-and-borrowing.html#borrowing) - `x: &amp;mut value` is mutably borrowed [doc](https://doc.rust-lang.org/stable/book/references-and-borrowing.html#mut-references) - `x: value` is owned. [doc](https://doc.rust-lang.org/stable/book/ownership.html) Which btw is made much clear by the [method example](https://play.rust-lang.org/?code=fn%20main%28%29%20{%0A%20%20%20%20struct%20Circle%20{%0A%20%20%20%20%20%20%20%20x%3A%20f64%2C%0A%20%20%20%20%20%20%20%20y%3A%20f64%2C%0A%20%20%20%20%20%20%20%20radius%3A%20f64%2C%0A%20%20%20%20}%0A%20%20%20%20%0A%20%20%20%20impl%20Circle%20{%0A%20%20%20%20%20%20%20%20fn%20reference%28%26self%29%20{%0A%20%20%20%20%20%20%20%20%20%20%20println!%28%22taking%20self%20by%20reference!%22%29%3B%0A%20%20%20%20%20%20%20%20}%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20fn%20mutable_reference%28%26mut%20self%29%20{%0A%20%20%20%20%20%20%20%20%20%20%20println!%28%22taking%20self%20by%20mutable%20reference!%22%29%3B%0A%20%20%20%20%20%20%20%20}%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20fn%20takes_ownership%28self%29%20{%0A%20%20%20%20%20%20%20%20%20%20%20println!%28%22taking%20ownership%20of%20self!%22%29%3B%0A%20%20%20%20%20%20%20%20}%0A%20%20%20%20}%0A%20%20%20%20%0A}). [doc](https://doc.rust-lang.org/stable/book/method-syntax.html#method-calls) So if you are declaring a type, you all ready proved the type of that variables ownership when you created/started using it. 
it is built on top of hyper, so not async yet. no?
Like everything though, as far as I understand. Except rotor-http I think? It looks like there's a branch of hyper using rotor based on the discussion on the hyper github issuel
I have two issues related to the borrow checker and boxes that I can't seem to figure out, any help much appreciated! Here: fn main() { struct Data { content: Option&lt;[Box&lt;Data&gt;; 2]&gt; } impl Data { fn do_something(&amp;mut self) { match self.content { Some(ref mut content) =&gt; { self.do_something_2(); content[0].do_something_2(); } None =&gt; { } } } fn do_something_2(&amp;mut self) { } } } doesn't compile because &lt;anon&gt;:10:21: 10:25 error: cannot borrow `*self` as mutable more than once at a time [E0499] I know I can just restructure the code, but is there a way to get a mutable reference from a pattern match against something in self and still call a function mutating self? Second question: I assume that `Option&lt;Box&lt;[Data; 2]&gt;&gt;` is probably faster than `Option&lt;[Box&lt;Data&gt;; 2]&gt;` (less pointers / indirection, more contiguous memory layout), but I can't make the following code work with the former option: fn main() { struct Data { content: Option&lt;Box&lt;[Data; 2]&gt;&gt; } impl Data { fn do_something(&amp;mut self) { match self.content { Some(ref mut content) =&gt; { for c in content { } } None =&gt; { } } } fn do_something_2(&amp;mut self) { } } } fails with &lt;anon&gt;:10:21: 11:22 error: the trait `core::iter::Iterator` is not implemented for the type `[main::Data; 2]` [E0277] Which combination of ref / &amp; / * and mut do I need to sprinkle in there to make it work? Thanks!
You can do `make rustc-stage1` to build the compiler and libraries only once for your cloned version. It won't take nearly as long as building up to stage 3 but it'll still take a while. I could have sworn there was a `make` command to just compile the standard-library but I can't, for the life of me, remember what it was or where I read about it. It's possible that there are already binaries available for your desired target, however. Have you looked through [the Rust distribution directory](http://static.rust-lang.org/dist/)? There's quite a few targets there already, just CTRL-F for `rust-std-[nightly|beta|&lt;release number&gt;]-&lt;target&gt;.tar.gz` or a substring of that. If you get a fresh complete package for your host (`rust-[nightly|beta|&lt;release&gt;]-&lt;target&gt;.tar.gz`) and a `rust-std` package for your target at the same time, they should be compatible. 
That is really nice, would work with every monad which can have a bind signature of `FnOnce(T) -&gt; M&lt;U&gt;`. Going to try to see if it would be possible to create something similar which would allow arbitrary number of invocations (eg. iterator monad or retry). Sadly this will most likely have to involve closures, so short-circuiting on eg. `return`, `continue` or `break` would be hard.
You can now install this plugin via Package Control. Be sure to enable rust in the settings. This requires a working Rust [ycmd](https://github.com/valloric/ycmd) setup. I set up YCM for vim the regular way with Rust support and pointed the Sublime plugin to its internal ycmd instead of creating an independent ycmd install. You may need to copy the generated HMAC secret to your vim settings with a `let g:ycm_hmac_secret = '....'` if you want both to work.
`for c in &amp;content { ..`
&gt; I can't have my rustc work with libs from dist because they are different version. My rustc is automatically compiled and packaged one. Downloaded with rustup/multirust or through a package manager? Both of the former should be getting their packages from this directory, IIRC, so you shouldn't have compatibility issues if you update your installed Rust at the same time that you add the libraries for the target. If you got your Rust with rustup/multirust and it is still relatively new, you can get the day it was built by running `rustc -V` and then go to that date's folder in the dist directory. The only other potential incompatibility is if you're trying to add libraries from, say, the nightly channel, to an installation of Rust 1.6 release. They have to be from the same channel.
I tried that, doesn't work: &lt;anon&gt;:10:21: 11:22 error: the trait `core::iter::Iterator` is not implemented for the type `&amp;&amp;mut Box&lt;[main::Data; 2]&gt;` [E0277]
&gt; In fact I tried to make rustc-stage1 with my local rustc but it failed with In case this meant you're not using a stage0 snapshot - errors like this are an expected consequence.
Is the double "Hello!" a typo in the README? match Msg { Msg::Hello =&gt; println!("Hello!"), Msg::World =&gt; println!("Hello!"), }
Go and use `multirust-rs`. It let's you manage many versions of rust side by side per project. Also it has update/upgrade capabilities. 
Not that I am aware of. Better luck next year, I guess.
Well, it doesn't. The key is that `ParseError` is an enumeration *with no variants*. Because it has no variants, there's not only nothing to match against, the match can't happen *at all*. After all, to match on `*self`, you'd need a `self`. To have a `self`, it'd have to be pointing to a `ParseError`. But `ParseError` cannot exist because it has no constructors; you can't have a pointer to something that cannot exist. Thus, the `match` actually diverges; it's like `panic!` or `abort`. As such, the type system will unify it with any type at all, including `fmt::Result`. If you called this method, Bad Things would happen, but you *can't* call it, so it's all OK.
This is method of `ParseError` that takes `&amp;self` as its first parameter, so `self` is a `&amp;ParserError` reference. The `*self` expression dereferences it and has type `ParserError`. `ParserError` is a bit unusual in that it is an empty enum (one with zero variants): pub enum ParseError {} … which means it’s impossible to get a valid value of that type, since there are none. `match` expressions but be exhaustive: any value of the input type must be matched by one arm or another. `match x {}` is only valid when `x` is an empty enum: all zero values are matched by some of the zero match arms. Each of the arms of a `match` expression must "return" a value of the same type as the `match` expression itself. In this case, each of the zero arms can be considered to return any type you want, since there are none of them. So, what’s the point of any of this? This method can never be called, but having the type implement the trait is still useful in generic contexts. For example, `Result&lt;T, E&gt;` only has an `unwrap()` method when `E` implements the `Debug` trait (which `unwrap` uses in the panic message if the value is `Err`), so when `String::from_str` returns `Result&lt;String, ParseError&gt;`, `ParseError` needs to implement `Debug` so that `unwrap` can be used.
If you don’t mind calling `b` every time (even if `a(x)` and `a(y)` are different) you can compare tuples: `(a(x), b(x)).partial_ord((a(y), b(y))`
Thanks for your answer and thanks to /u/Quxxy too! So, if I understand well both of your answers, the only benefit I see for writing `match *self {}` instead of just panicking is that if someone were to add a variant to the enum later, then the `match` expression would trigger a compilation error (which would be desirable) whereas a call to `panic!()` would not. Is that right?
There's that, and also that `panic!` means unwinding, which can negatively impact optimisations.
I was thinking the same thing. I spent a whole weekend recently trying to compile a tiny rust function that I could call from an existing c project running bare-metal on an ARM cortex-m4. There are some examples out there, but they're almost all incomplete. I suspect because the authors, like myself, barely understand how they managed to get it to work. My company makes and end to end IoT product. In the cloud we use Erlang and Haskell. We strongly value safety and deterministic behavior. If it was easer to do bare-metal Rust development, we'd probably use it for our next embedded project.
&gt;As often happens in web servers world, the only bottleneck is DB &gt;communication - in our API it takes around 98% of every request. Most API calls are I/O bound so rust buys you nothing in these cases. 
Sorry, I overlooked the Box, you'll need `&amp;*` instead of `&amp;`.
You probably meant to post here: https://www.reddit.com/r/playrust/
A punch list that I'm fond of: 1. Publishing is just the beginning. You can keep publishing! 2. Write some tests. Even if it's just one test to make sure basic functionality is working. 3. Setup Travis CI. Most popular Rust repos have it, so it's easy to find examples of how to do it! Basically: sign up with Travis and connect your github account, enable repo in Travis UI and add a `.travis.yml` to your repo. This will help you automatically build and run tests. It happens on all PRs which takes a lot of the overhead off of managing contributions from others. 4. Write documentation. Every public method, function and type should have some kind of comment explaining it. Ideally, some example code that uses doctests is also present. (For example, what the heck is the difference between `lookup` and `lookup2`? :-)) 5. Add a license. Without one, people conscientious of copyright laws will probably not use your code.
Nice write up! Its cool to see people using Rust because it is a high level language which keeps you safe, and not just for low level performance.
 I’m glad to see when crates have no “unsafe” code and when they are trying to avoid usage of “panic”. I think we need some kind of badges to promote such crates. This is the first time I'd thought of this, but it's a cool idea. I feel like most transitive(?) dependencies at some point in a dependency tree would break this, though.
And it produces a single binary. ^Just ^like ^Go!
A few points: 1. You may want to return `io::Result&lt;String&gt;` instead of unwrapping and forcing a panic. 1. I know more or less nothing about the protocol, but isn't the URL validation a bit restrictive? I'm not sure if it's helpful, but could use [url](https://crates.io/crates/url/) to parse it. 2. I'm just going to second the /u/burntsushi's documentation point. It may be a small library, but some people won't even look at the source to try to understand it. Having just some brief explanations is much better than nothing. 3. A small quick start guide in the readme is also nice. At least a small copy-paste example of how to include it in Cargo.toml. It's nice that you have added an example.
I had thought about this. I had imagined something like auto-generated chart showing the ratio of unsafe code to all code in the crate alone, and then a similar chart that includes the crate + all dependencies (not including standard lib). Then there could be stats "This crate uses less unsafe code than 98.3% of crates on crates.io."
It depends on what kind of GUI you really want, but you may want to consider [conrod](https://crates.io/crates/conrod/) as well. It's very different from GTK and Qt, but may be more suitable for games.
I'm not sure about this. While it's true that unsafe can usually be avoided for most use cases, very low-level programming really _requires_ the use of unsafe. The community has too strong of an aversion to unsafe, and I think it stems from the idea that unsafe exists entirely separately from normal, safe Rust -- "here be dragons". Rather, my perspective on unsafe Rust is that you can get right down to the metal, and then use Rust's powerful type system to _enforce your code's invariants_. You write unsafe code, wrapped in a safe API so nobody else has to worry about it. The standard library is a particularly good example of this. Most of those crates that say they use "no unsafe code" are really just wrapping other crates that _do_ use unsafe, even if it's just `std`. So take those words with a grain of salt -- it doesn't mean that there is no unsafe anywhere down the pipeline, just that their specific crate doesn't use it. The goal is to reduce the code surface that needs to be audited, but there still is inherent unsafety. Try not to operate under the premise that Rust is a magic bullet to kill all unsafety. Unsafety is ubiquitous and unavoidable, but Rust lets us work with it much more safely.
This discussion was rather confusing until I actually clicked the link and read the docs on ParseError: /// An error when parsing a `String`. /// /// This `enum` is slightly awkward: it will never actually exist. This error is /// part of the type signature of the implementation of [`FromStr`] on /// [`String`]. The return type of [`from_str()`], requires that an error be /// defined, but, given that a [`String`] can always be made into a new /// [`String`] without error, this type will never actually be returned. As /// such, it is only here to satisfy said signature, and is useless otherwise.
That's great news! I wasn't familiar with the Json integration either—a huge step toward making Rust more easily usable for web development.
Great write up, very informative! I'm very curious about building API back ends in rust, I presently use Python but sometimes the duck typing is frustrating!
Games generally don't use those big general purpose GUI toolkits like Qt or GTK. They usually use immediate mode GUIs ([ImGui](https://github.com/ocornut/imgui) or handmade equivalents) or embed something like [Scaleform](http://www.autodesk.com/products/scaleform/overview) or even an HTML renderer.
I refactored my code so it calls lookup() (sort of) recursively and add some documentation (not sure if its Rust standard), I'll get into writing the tests later on before publishing :P
1. I actually might do that! 2. You mean in the get_server function? I"m sure its not, because it returns other whois urls 3. Hopefully I did it right 4. Will do when I publish it :P
You might be interested in this article I wrote last year: https://pascalhertleif.de/artikel/good-practices-for-writing-rust-libraries/
Ah, yep... &amp; whoops.
&gt; You mean in the get_server function? I meant at line 35 and 36 in `lookup` It looks like a `.` is required and that the top domain should be `com` or `net`, but I may also misunderstand it completely.
The .com and .net queries are different than the other TLD queries so thats why everything else is "" (I believe)
Alright :)
I'm not saying that we should never use unsafe, but if you can do something (properly) with safe code, why shouldn't you prefer to do that in almost every case? Unsafe code is manifestly necessary in many cases, but I think that if the community loses its aversion to unsafe code, many users will resort to unsafe code more frequently than they need to, eventually eroding one of the core benefits of using Rust (trustable external dependencies). I'm well aware that most crates depend somewhere in their code on unsafe code: "I feel like most transitive(?) dependencies at some point in a dependency tree would break this, though." I think that mitigates the usefulness of doing a full-dependency-tree analysis of unsafe uses (for something like a badge), but it might still be useful to look at how much unsafe surface area a crate exposes directly in its API. EDIT: Stupid repeated phrasing.
This is great!! Thank you so much for taking the time! I will play with this later today. I did actually start down this route but the snowball effect had me worried I was going about it the wrong way. Its helpful to see that this sort of borrowing and dereferencing is acceptable. Thanks so much again!
`Fn(&amp;'r Foo)` is invariant over `'r` making the whole struct invariant over `'r`. It's then a contradiction to have `&amp;'r Element&lt;'r&gt;` because the struct will strictly outlive its `'r` borrow but `'r` must live at least as long as the struct. https://doc.rust-lang.org/nightly/nomicon/subtyping.html
That's a YCMD setup issue then. I don't know what the error is here; I'm not familiar with YCMD itself. Do the basic vim setup for Rust that's on the YCM (not YCMD) readme, check that it works, point sublime to it, and add the hmac. 
Sorry I meant validation like you get a SignupData { email, password} and you want to check that email is an email and password length is 8 &lt;= x &lt;= 255. On another note, if you use jwt I also have a crate for that https://crates.io/crates/jsonwebtoken :D 
&gt; I use println and redirect output to file, to create primitive logging, later I’m going to use something more smart and reliable. I've been using [log4rs](https://github.com/sfackler/log4rs) lately and it has been quite nice. Much more convenient than `env_logger`, or println's.
Maybe a helpful bit of information would be the names of transitively depended-on crates containing `unsafe`, so that at least you know who you need to trust (perhaps also the set of authors). For example, the Rust stdlib is probably pretty safe to trust, and /u/frankmcsherry much less so.
oh right. I would still prefer not to use the flipped bind operator `=&lt;&lt;`, it is confusing..
The current solution requires no unsafe code at all, so an unsafe primitive would definitely not be a suitable replacement.
Except for the unwinding issue explained above by /u/SimonSapin why was `unreachable!` not used ?
Try `:=` perhaps?
 [dependencies.iron] version = "0.2.*" [dependencies.bodyparser] git = "https://github.com/iron/body-parser.git" [dependencies.redis] git = "https://github.com/mitsuhiko/redis-rs.git" [dependencies] router = "*" rustc-serialize = "*" plugin = "*" rand = "*" toml = "*" rust-crypto = "^0.2" hyper = "*" r2fa = "*" urlencoded = "*" regex = "*" [dependencies.mysql] default-features = false features = ["socket"] And soon here will be added "rusoto".
Ah, alright. That's pretty odd that the match pattern is a different type than the one produced by a standard range, but I'm guessing that has something to do with optimizations. Thanks for the help!
Unfortunately it is not my choice to use them or not. In some languages named params make sense, but In others don't. In Rust you can always use struct if you want similar construct, so I see no point In adding more complexity to the syntax. 
IIRC the match pattern ranges existed long before the iterator ranges. It's sort of a legacy issue.
Wait wasn't Hyper not using any asynchronous I/O. Idk what they do now but once a month I follow the discussion on the Issue page when It will finally get &lt;sync I/O. However as long they don't have this you are an easy ddos target. Also funny what you say here: 'Compiler is smart and gives very descriptive error messages' -&gt; static typed languages, atleast most of them give good error messages. 'thread::spawn is a very handy thing, and safe in Rust.' Don't do this for web dev unless you know what you do. However coming back to the async thingie. I doubt this api is ready for usage with this bottleneck. As I said someone will just fuck your server from one pc. Even if there are read timeouts(depends how they are implemented) if you slowly send a request you will just block the whole thread. Do that like 8(number of listening threads) times bye bye all Listening threads. Also you say 98%(98% of the time a request is processed could be spend processing more requests....) are your db querys. Are they async??? If not this will also block the thread... I mean rust is an awesome language, but I think It's not ready in terms of librarys for web dev. If I use something I also want It to be well proven for web dev. But I definitly need to say rust offers an intersting oppurnity for this. It has an amazing performance and for example with serde It has probably one of the fastest way to serialize.
I was just typing out [a response](https://www.reddit.com/r/rust/comments/42gh9h/hey_new_rust_users_got_an_easy_question_ask_it/czj94py) when you sent your message that includes what you ask, sans a playground link. I'm stepping out for some food right now but I'll get back to this after dinner.
A quick fix: http://is.gd/DL4a3V
Don't know what happened with those, but there are official [Rust](https://packages.debian.org/sid/main/rustc) and [Cargo](https://packages.debian.org/sid/main/cargo0 packages in Debian unstable, so those should probably be able to make their way into Ubuntu, most likely in 16.10 (I think it may be a little late for them to get into 16.04). Ass /u/NobbZ says, just using `rustup.sh`, `multirust`, or `multirust-rs` is probably your best bet for now.
I may have worded that specific sentence poorly, giving the impression that people shouldn't try to avoid unsafe code. I think we are actually in agreement about Rust enabling users to write safe abstractions around `unsafe`. To address the root of this discussion, badges for crates which use "no unsafe", I think that the suggestion posed by many here to also enumerate unsafe dependencies alleviates my issues with it. My main worry was that if crates were to be tagged with a binary "unsafe" or "safe" tag, the community would likely interpret that to mean "bad" or "good". Such a check can be easily circumvented by punting all unsafety into a micro-crate. Almost every non-trivial Rust program is going to require some degree of unsafety, particularly once performance requirements are thrown into the mix. You see this particularly in implementations of data structures, which can often be sped up significantly with only trivial usages of `unsafe`. LLVM's optimizer is a beast, but it only goes so far. When it comes to unsafety, users can obviously place more trust in `std` than they can in most other crates. Unfortunately, `std` is deliberately minimal. Someone _has_ to write the rest of the libraries that programmers want to have. I would argue that those libraries should use unsafe where necessary to be competitive with implementations written in other languages. Maybe others believe that `unsafe` should be avoided at all costs.
Heh, so long rant, based on false assumption :) No worries, I checked performance before relying on it. All queries are asynchronous.
Thank you, will fix it. 
Thank you and other contributors for making it possible :) You also helped me in irc with REMOTE_ADDR forwarding from nginx.
&gt; I have a bcrypt crate I've been using this for my Rust web server and it's been great. Much needed API around rust-crypto. Thanks :) &gt; Nice writeup otherwise! How do you handle validation of the api request data? Not OP, but I have [something like this](https://gist.github.com/SkylerLipthay/d59f04158376b59f0240). This is a simplification of course — FormError could be recursive, the validations could be DRYed up, and so on. JSON deserialization errors throw a 400, and any non-empty validation error maps throw a 422 (the HTTP response body being the error map as JSON). Using Iron, error handling is very simple here. My previous experience of implementing an Active Record-like pattern in Rust proved to be unergonomic, but you can [do really cool things with compiler macros](https://gist.github.com/SkylerLipthay/668b80a2177955681dc6) (working code, sorry for the mess).
I love it - currently just watching as I don't yet have the Rust skills (Working on it) and the other stuff too. Looking forward though.
And how did you fixxed the problem I basicly said? It's not a false assumption It's based on facts you can read yourself as code.
OK, yeah that's a valid point. :) But depending on how it is implemented you shouldn't have to change function definitions, named arguments would be deduced by the names you gave to the argument bindings in your function definition and with a little bit of hacking you could resolve named arguments at compile time avoiding the runtime cost I think. Making them essentially an alterbnative way of calling functions. So the only thing that could be forced upon you is other people using them and you having to maintain code that calls functions with named arguments. But that argument is valid for all language "features". I don't really understand why you would be firmly against it. The only real downside I can think of is that named arguments would be part of your API and you wouldn't be able to change their name without a breaking change. Which is a big downside I admit!
There are some issues with that solution: - How would you handle trait functions? You should use trait or implementation params names? Should different name in implementation be allowed, warning or should make compilation fail due to definition mismatch? Which one solution will be least surprising to the users. - You should avoid functions with more than 3 (+ 1 for `self`) params and disallow functions with more than 5 (+ 1 for self). If you do so, I don't see the point in named parameters as function name will work for one. - This will make public interface much broader which will force rapid version bumping when refactoring. - Named params without function overloading are no solution.
Although you probably know, I just want to make clear that hardware interrupts don't run concurrently (they do not run in another thread). In interrupt handlers you can only access statics or thread locals. And Rusts rules on ownership and borrowing still work without problems in that case. At least I'm pretty sure of what I just said :P There are a few operating systems written in Rust (most of them small and WIP) with the most famous one being redox. There is a blog series of "This week in Redox" -- maybe you'll find something there. I also found this: http://www.randomhacks.net/2015/11/11/bare-metal-rust-custom-target-kernel-space/
/u/Vikaton, for number 4, add `#![warn(missing_docs)]` to your crate root to see where docs are missing.
Yes of course (it is based on rust-csv)! It is very useful to have a quick view on huge csvs. I use it when I want to *debug* some big csv (e.g. some wrong data on output). I haven't planned to created a similar tool for quick-csv because I think the performance difference doesn't justify the work and it just work fine like this (it is more a developer tool than a production tool in my case)
I think this has been [fixed](https://github.com/tafia/quick-csv/commit/97a09b6d9805e847cfa6dbe84b74e1de13b37fdb) few months ago (I've pushed a message in butbucket long ago :)). There is a [test](https://github.com/tafia/quick-csv/blob/master/src/test.rs#L136) for this. And as for the other tests, maybe it is me, but the behaviour is not mentionned in the spec and it doesn't feel right (to me) (ex: https://github.com/tafia/quick-csv/blob/master/src/test.rs#L119, empty lines ARE valid 1 column csv IMHO) 
Or even better, `#![deny(missing_docs)]` :D
This week I'm going to finish implementing futures in [RobotS](https://github.com/gamazeps/RobotS) with my scheduler and start the serialization for remote message passing between actors. You can follow the progresses on my [blog](https://gamazeps.github.io), even though it might not e extremely structured (but it could be funny to see the struggles).
&gt; My main worry was that if crates were to be tagged with a binary "unsafe" or "safe" tag, the community would likely interpret that to mean "bad" or "good". Yeah, gameifying/publishing a certain piece of info can definitely create false/unintended incentives. &gt; Such a check can be easily circumvented by punting all unsafety into a micro-crate. If the micro-crate is safe, this seems like a win-win. :) (If it isn't, then I agree it is highly suboptimal.) &gt; Almost every non-trivial Rust program is going to require some degree of unsafety, particularly once performance requirements are thrown into the mix. I'm... not sure this is so true, especially as the ecosystem fleshes out. In my experience, unsafety generally gets pushed down into reusable libraries, concentrating the dangerousness into fewer locations. There will of course be a healthy dose of NIH, but I imagine people will be taking the easy route of using code that's already written/tested/in use (I certainly do). Data structures are an example of this: most applications are fine with one of the common data structures (by definition, basically), and hence there's pre-written libs for them typically. Of course, some applications need specialised versions, or need to make a particular trade-off in API/implementation that doesn't make sense elsewhere, so there will be hand-rolled versions, but again, these can be made reusable (generics are a great tool here). &gt; I would argue that those libraries should use unsafe where necessary to be competitive with implementations written in other languages. Maybe others believe that unsafe should be avoided at all costs. I think striving for safe-only crates is very desirable: in other languages, packages written purely in that language are often touted as good for reasons like correctness, ease of modification and ease of distribution. The latter doesn't apply to safe as a subset of `unsafe`, but I definitely think the first two do. Pure packages are valuable even in slower languages like Python and Ruby, and Rust's safe code isn't at nearly as big a disadvantage compared to `unsafe` as those languages are compared to C (the typical language of their extensions). Of course, being able to eke out every drop of performance is important, but having machine-checked correctness is often equally or even more important for some applications.
Finally adding a lazy DFA matching engine to `regex`! I have an initial prototype working that reports the *end* of a match. Now I just need to tweak the compiler to produce backwards regexes to find the *start* of a match. :-)
&gt; if &lt;del&gt;someone were to add a variant to the enum later&lt;/del&gt;&lt;ins&gt;the enum had a variant&lt;/ins&gt;, then the match expression would trigger a compilation error [Edit: Markdown is supposed to support HTML. "slightly-customized" my foot, reddit.] The expression used is less powerful (the least required). A bit like we prefer `&amp;str` to `String` where possible. It's specific to the reason the function body is unreachable; if the programmer was wrong and the condition didn't hold then the compiler would prevent that. So it's the most rustic way to express it. Whether you prefer the expression which is less specific to rust (or at least languages with sum types) is a matter of taste. The implementation of the rust standard library is likely to err on the side of being rustic :). If you're writing a rust module to use inside a ruby project, you might use `unreachable!`, and I think that would be pretty reasonable.
I expect parsing errors to give me the location (line:column) of the error. I also find it convenient to have access to the location of the latest event so I could include it in higher level errors.
Meh, I think taking it to the level of badges encourages fetishism. Better would be to make locations and documentation for unsafe and panic high level documentation elements. Then red flags like unsafe being used everywhere or not being documented are highlighted in a way that invites critical analysis. Plenty of libraries will have a justifiable need for unsafe code. They shouldn't have to explain the resulting badges at the beginning of documentation. 
Also going to chime in and thank you. This is something community has discussed and its pretty cool to see someone do it. More docs is always better :)
Looks very nice :) I've recently been toying around with IPFS, and I think it's great for distributed hosting of static content like documentation. One thing that really appeals to me is that you could just "pin" the IPFS URL of some crates docs and then you have it available on your device even when you go offline. Now with something like your website it would be possible to build a small application (maybe a cargo subcommand) to pin the docs of all dependencies of the project you are currently working on, which would make preparing for offline development a breeze. Have you looked into IPFS before and what are your opinions on integrating with it?
Thanks so much for this! We have wanted this for a while, but hadn't actually built it yet. Some considerations: 1. You've got the core of it here, for sure. The rest of this is all about the "other 80%". 2. There's the question of server vs client side doc generation. You've chosen server. That's a good choice, but there are advantages to doing it the other way as well. 3. One of the hardest parts about a site like this is the platforms. Docs can change based on platform, but rustdoc can only generate docs for the platform you're on. This makes the builds at least 3x more, and more like 15x more if you want to support tier 2 platforms as well. 4. There's no UI yet. This is great in ways, but there's lots of stuff you can do in a UI. 5. ... okay I had more, but it's early and I forget. Maybe /u/acrichto or /u/brson has the list lying around. (And your English is great!)
Also, `rustc` and `cargo` are in debian testing right now, so that means that someday they'll end up in Ubuntu. I think.
This can work, but it can also not work. I am literally the doc guy, so I wrote that in my SemVer crate to make sure I had docs, but then, to get my build going, added a `/// lol`. I forgot to take it out.
https://github.com/brson/multirust#custom-toolchains is helpful, though not as good as it could be, see below
I'd be inclined to say the iterator API is the correct way to do this :-)
&gt; After the devroom I hacked with someone and we came across this function: You ain't seen nothing yet O_O https://github.com/sgrif/diesel/pull/137 I mean https://github.com/sgrif/diesel/pull/137/files#diff-115f8d6a49b2c1f98d1675b5cd003af6L130
See also: https://github.com/rust-lang/cargo/issues/2212
Really. Does nginx really recieve the whole body and then passes it? Idk if nginx reads or or just abit of it before It starts forwarding it. Also for chunked encoding? You basicly leave a gap open and just bypass It. That's how web application are going to suck. Well the problem is the term async is not really right for what I explain but I see we mean the same. However there are coroutines and languages use it already quite efficent. I'm a person who tries to make something in a decent way once. I'm not the person to 'bypass' something. If you are such a person feel free to do so but I think It should be said that you aiming for this instead of making something solid on It's own. I'm not saying don't use it I'm just saying that It's not ready for production. Seeing that guy says ram is cheap and so he can spawn threads makes me cry where we have gone...
That crossed my mind I just didn't want to make 11 regex variable on top of loop. But I believe, it's also possible to make the same thing with only 5 or 6 regexes in this function. Thanks for advice, I will definitely optimize it.
Oh yeah, this isn't as minimal as the examples, but only because I copied it straight from the playground. I thought of the Itertools crate for three vectors, but that doesn't seem in keeping with the spirit of the post, which accomplishes the task using only built-in methods. I know that Rust's standard library is small compared to e.g. Python's, but it's not like he reached for Python's Itertools (not that it would have been any more concise, IMO)
I really like the `where` change, have you considered submitting it upstream?
I'll consider it!
I was curious about this too. It looks like he is using https://github.com/brendangregg/FlameGraph to generate the pictures. Near the top of the readme, there are links for how to collect the profile data on various platforms (OSX included).
What is the best way of turning a string into an enum variant? Let's say I have an `enum Country` containing the names of all the countries in the world, and a `String` which is potentially a country name. How do I turn my `String` into an `Option&lt;Country&gt;`, without having to explicitly write a `match` statement with 100+ branches?
The profiler is Xcode Instruments, on OSX. carol10cents has a nice Howto for flamegraph on OSX: http://carol-nichols.com/2015/12/09/rust-profiling-on-osx-cpu-time/ 
Haha. Yeah, that can happen. It's nice for PRs, and thankfully, I haven't yet resorted to `/// lol`. :P
Personally, I'd use macros for these kinds of situations where data meets code. It's usually something like this: macro_rules! gen_strmapped_enum { ( $name:ident: $($variant:ident =&gt; $value:expr,)+ ) =&gt; { #[derive( Copy, Clone, Eq, PartialEq, Debug )] pub enum $name { $( $variant, )+ } impl $name { pub fn from_str(value: &amp;str) -&gt; Option&lt;$name&gt; { match value { $( $value =&gt; Some($name::$variant), )+ _ =&gt; None, } } } } } That's basically building your enum with the list of your variants, and then iterating again to build the match in the `from_str`. Then you can build an enum like this: gen_strmapped_enum!( Country: Country1 =&gt; "Country 1", Country2 =&gt; "Country 2", ); And the `from_str` method can be used like the following: println!("First: {:?}", Country::from_str("Country 1")); println!("Unknown: {:?}", Country::from_str("Unknown")); I'm not sure there's a library variant of the pattern anywhere yet. I usually end up with a bit more specialized code in the macros.
With Kotlin you have the plus that it is developed by Jet Brains and they are trying hard to have it as a nice experience in Android Studio and other Android tooling, given the current state of Java support on Android.
Awesome! I'm liking the design a lot so far.
Thanks. I am a total noob at Rust, but not at OS and embedded programming. I hadn't seen that link; I'll check it out. So there's some state, and it's shared between background and the ISR. It must be mutable, else the ISR can't affect background computation. That means both the ISR and the background have to access it in unsafe blocks. There also needs to be locking. Usually, that means the background disables interrupts while it accesses the shared state. Or it could be some lockless protocol like [RCU](https://en.wikipedia.org/wiki/Read-copy-update). And in C at least, there needs to be some way to inhibit the compiler optimizing out accesses to the shared state. I've found std::intrinsics::volatile_load and _store, and std::sync::atomic. Does Rust provide higher level objects/operations to encapsulate the low level unsafe stuff? Or do I get to write those? 
I thought they opened up a lot of possible domains lately so that basically any (reasonably short) combination of letters can be a domain name?
Pretty much, yes! I'm using a gapbuffer at the moment, and the performance isn't great. I want to experiment with a Rope and see what the difference is. Found a crate called "strings" which has a Rope implementation, so I'm going to start with that and see how it goes! 
Expand/collapse gets more useful as the number of examples increases. As I go through the docs, I imagine at some point we will want to make collapse the default. See Iterator for example. As for the headings, yes, the sizes and such need tweaking. I haven't gotten to it yet.
collapse is very useful to get an overview and scan for the method you're looking for. I use it often.
`one_input` is indeed implemented with `Some(x).into_iter()`.
&gt; It is using only ~4MB memory like any other rust program haha nice one!
Is this code single threaded? What happens when the decompression runs in a separate thread? SSD bandwidth is still precious and main memory on modern machines has at least 15-40GB/s of bandwidth.
&gt; Really. Does nginx really recieve the whole body and then passes it? By default, yes (edit: it may well start passing it before it finishes reading from the app server, I don't know - but it certainly buffers the whole response, regardless of the client's performance). You can of course turn it off. And really, no matter your feelings on the matter, that's typically the recommendation for a large fraction of application servers out there: hide it behind a battle-tested http server. Exactly how slow do you think an appropriately thread-pooled solution is? The cost of context switches in that scenario is only likely to be at all relevant when you have zero I/O and very little computation going on - if there's I/O it'll be lost in the noise. The cost of maintaining a moderate number of threads (at least on Linux) is extremely low. Async or not is fundamentally an engineering decision - heroes code everything in ASM, the rest of us consider tradeoffs. Asynchronous systems are usually somewhat harder to develop and/or debug. In my view the tradeoff is completely worth it for systems that have to handle very large numbers of connections that each require very little work, and not in situations where each request is a little more complex. That means I'd absolutely code an HTTP server using an asynchronous model, but I quite probably wouldn't bother for an webapp that I expected to be performing I/O or to be doing significant computation. FWIW I struggled with your tone when writing this comment - I would prefer a discussion of technical virtues not to include judgement of my values as an engineer. I care a lot about the quality of what I produce - I just perhaps have different judgements of the technologies involved than you do.
I understand `?` operator side of recent discussions, but I completely miss the point of `do` part. The example in this straw idea tells me nothing. It looks just like simple imperative code. I don't see what is there to be achieved with weird versions of`=`. Are there any explanations available for people who are not coming from Haskell world? 
What kind of GUI are you after? A GUI for tools (like a level editor), an in game player facing UI or in game debugging GUI. For the latter, you could try https://crates.io/crates/imgui/ which is a wrapper for the C++ imgui library https://github.com/ocornut/imgui. The Rust wrapper isn't complete though.
Wrap it in `try!`?
&gt; What do you mean by data driven game engine Not the OP, but "data driven" is a common way to describe certain game architectures/engines. (It'd still be good to spell it out, but the target audience _probably_ knows what this means, is all I'm saying.)
`one_input` was replaced with `std::iter::once`. Its just an error in README. Still, thanks for noting the error :D
&gt; Will result in error unless you put braces around it. You can also use a `;`. `match` is an expression, and so evaluates to a value by default. You can then assign it to something or throw it away by turning it into a statement with `;`, and then it won't require you to have the same type. &gt; Why not matching traits? It's not totally clear to me what you're doing here. &gt; How does unwrap() / unwarp_or() determine if something is an error? These are methods on `Option&lt;T&gt;` and `Result&lt;T, E&gt;`. If it's on an option, than `None` means an error, and if it's a result, then `Err(E)` means an error.
 match 1 { _ =&gt; returnsTrue(), 1 =&gt; returnsError(), } The compiler is unfortunately not smart enough to know that only the `1` case is used. All match arms must return the same type, or diverge (`return`, `break`, or `continue`). `unwrap()` and `unwrap_or()` are both very simple and work as follows for `Option`: impl&lt;T&gt; Option&lt;T&gt; { fn unwrap&lt;T&gt;(self) -&gt; T { match self { Some(x) =&gt; x, None =&gt; panic!() // unwrap_or calls your function here instead } } } For `Result` it works the same except it returns in the `Ok()` case and `panic!`s in the `Err()` case. You cannot match on traits because matches match on each sub-type of an enum. Traits are implemented on the enum not its sub-types. e.g. impl Foo&lt;T, E&gt; for Result&lt;T, E&gt; { /*...*/ } // allowed impl Foo&lt;E&gt; for Result::Error&lt;E&gt; { /*...*/ } // disallowed My understanding is allowing enum subtypes to be first class in the type system would make type inference very complicated and we would lose (or it would be much harder to prove) soundness of some aspects of the type system.
You could use the [spin crate](https://crates.io/crates/spin/) to get a spinlock with [interior mutability](https://doc.rust-lang.org/book/mutability.html#interior-vs-exterior-mutability). You can put it in a `static` (_without_ `mut`) and access and change its contents safely. Of course it prevents wrong compiler optimizations (it uses atomics). This won't work well for interrupts because it causes a deadlock if the thread that holds the lock is interrupted. But you can easily create a wrapper around it that disables interrupts before. Something like: use spin::{Mutex, MutexGuard}; struct Spinlock&lt;T&gt;(Mutex&lt;T&gt;); impl&lt;T&gt; Spinlock&lt;T&gt; { fn lock(&amp;self) -&gt; MutexGuard&lt;T&gt; { // disable interrupts self.0.load() } } impl&lt;T&gt; Drop for Spinlock&lt;T&gt; { fn drop(&amp;mut self) { // enable interrupts again if they were enabled previously } } If you create something like this, please put it on [crates.io](https://crates.io/). (I'll need it for some future blog post :)). --- Of course you can also use lockfree data structures. For example [crossbeam](https://github.com/aturon/crossbeam) and the [rust standard library](https://github.com/rust-lang/rust/blob/master/src/libstd/sync/mpsc/mpsc_queue.rs) itself contain some lockfree queues. Or the [bounded-spsc-queue](https://github.com/polyfractal/bounded-spsc-queue) crate. Or [marble](https://github.com/dzyp/marble). Unfortunately most of these require some modifications to work in `no_std` mode, so please ping me if you find/create something better :). _Edit_: formatting
@steveklabnik1 has it right! The point of this project is to provide a consistent game development SDK for Rust that is both data-driven and data-oriented (see the [Glossary](http://ebkalderon.github.io/amethyst/glossary.html) in the Amethyst book for the definitions), with special emphasis on parallelism and performance. It's good that you're asking this, since I want to make sure the project's goals are clear to everyone.
I can't say unless I see how you are doing the lifting. Please post the code to understand the problem fully. From the error alone I'd expect you are trying to transform one Result into another. I'd guess that your code change to look something like: fn some_func()-&gt;Result&lt;Repository, Box&lt;Error&gt;&gt; { // ... RepoBuilder::new() .branch(PROJECT_BRANCH) .fetch_options(fetch_opts()) .clone(url, Path::new(folder)) .map_err(Box::&lt;std::error::Error&gt;::from::&lt;git2::error::Error&gt;) } (There should be a new method added) You might also be using the `try!` macro, in which case the macro would be doing something like the code above, I wouldn't imagine how it would create the specific error you saw without actually seeing your code.
One nit: could be neat to activate all cargo features before generating the docs, otherwise some parts of the API docs might not be generated. That's the case for example for my wayland-client crate.
Over the week I added a Code128 barcode symbology parser into the [Barcoders](https://github.com/buntine/barcoders) crate. It was harder than I expected as I it's got a few different character-sets that barcodes can switch between during encoding. Good fun, though. :)
Thank you!
Most games do their chat window using their in-game UI in the main window, so an external toolkit like Qt or GTK doesn't seem like the best choice. It might be worth asking on /r/rust_gamedev, although probably most people there also read /r/rust. 
Inner is super cool! Relevant to RFC 1303 and [my macro](https://crates.io/crates/guard/) also. IMO you should publish that one, never too many micro-macro-crates. Splitmut I am... a bit worried about. I see your reasoning for why it is safe, but -- you check for duplicates _after_ you already have both mutable references! Isn't LLVM free to assume that `&amp;mut` references can't alias, and skip the check? I don't know anything about ECSes so I won't comment on that one :)
You don't. You develop a design that does not require inheritance. If you can think of other types that need to crush dreams... interface DreamCrusher { default void crushDreams() {} } class HeartlessManager implements DreamCrusher, Employed { } class SoullessExecutive implements DreamCrusher { }
Sometimes adding a feature might also change a function signature (instead of just adding a new function). Rustdoc should have a mechanism for clearly marking when an API change with features. It looks like the only way to do it with 100% accuracy is to generate the docs for the whole exponential combination, and see what changes.
Wow, this is beautiful! I haven't looked over the rest of the posts, but have you looked at changing the map implementation? Rust defaults to secure hashing, but you can probably use weaker hashing. Or, try out BTreeMap, which is actually really fast at some HashMap-y workloads! http://cglab.ca/~abeinges/blah/hash-rs/ for details
Awesome work, Kevin! I love clap! I think I've tweeted about it being my favorite CLI library in any language I've used so far. Also happy to see 2.0 highlight the flag/delimiter syntax I reported a while back (I'm Jimmy Cuadra from the contributors list.) You also might be pleased by this anecdote: At my day job, we just extended a job offer to an applicant who is also one of the contributors to clap! His familiarity/interest in Rust and the fact that we'd both worked on clap was not an insignificant factor in our decision. :}
The real feature of implementation inheritance is that it "ties the knot". That is, if you have a method definition *A* in Parent which is overridden in Child, and there are other methods in Parent which call self.A, then your Child class will end up calling the Child version of A. This adds a lot of overhead though, since it requires an extra indirection/dispatch step for all self-method calls. But it is the one feature of inheritance which is not easily replicated by simple composition-based design. IIRC, Benjamin Pierce actually explains this quite clearly in his *Types and Programming Languages*.
I would like collapsed to be the default. The first thing I do on most doc pages is click collapse all in the upper-right corner. Then I look through and expand the docs on whichever method I want to read docs for. Ever since I've been looking at Rust's docs, I've always thought that clicking the method name should expand the docs underneath. Isn't it unusual that a method's name links to itself? Other web pages and doc generators don't do that anywhere. Then you wouldn't need the [-] or [+] left of the method. If you wanted to preserve the ability to easily copy a link to the method, there could be a paragraph symbol like Github does. Do you think a pull request that changed this might be accepted?
Thanks! And that is one of the best back stories I've heard! Very cool!
Can you think of any other place you've seen a link that links to itself? It breaks my expectation that a link will do something when I click it, and it took me a lot of misclicks on the method before learning to click the [+]. When Github adds the symbol to headers on hover, they still don't turn the header into a link. That symbol that Cargo uses looks like it would work well, better than a paragraph symbol...
A common thing is blog posts, where the title or date links to the current post.
I might be misunderstanding what you are trying to do, [but something like this?](http://is.gd/Q1pEkV)
I think this happens with low level libraries like the libc (some high level types are defined as aliases to actual types, and this differs between platforms). And I have an impression that in case of diamond dependencies with different features, Cargo just compiles the crate twice..
Really? From what I saw, cargo is supposed to just take the union of the features (but in other cases it can happen that different versions of the same crate get pulled in the dependency graph). Do you have an example? Also, libc does not have any cargo feature... 
Well, that's exactly why cargo feature are documented as additive, and what I said "activating a cargo feature should not be a breaking change". (I'm personnaly struggling quite a lot with my wayland crates due to this, actually)
&gt; I claim it's safe because there is a runtime check; try with equal `k1` and `k2` and it'll panic. Any reason you can't just use `Option` or `Result` for this?
My initial thought was `Option&lt;(Option&lt;&amp;mut V&gt;, Option&lt;&amp;mut V&gt;)&gt;` but I can see how that would be cumbersome. Maybe you could have `get2_mut` which behaves as it does now, and `get2_mut_safe` or `get2_mut_no_panic` or similar which returns with `Option` wrapped. I would just be worried about the case when the keys are generated in some way, rather than being hard-coded.
Hey there, I found it really interesting that you are using OpenCL for your computations, since almost everyone in the ML space is using CUDA. Are you aware of [Leaf](https://github.com/autumnai/leaf)/[Collenchyma](https://github.com/autumnai/collenchyma)? Even though the groundwork in Collenchyma for OpenCL is there, the [-nn plugin](https://github.com/autumnai/collenchyma-nn) is sadly missing OpenCL implementations. It would be great to have someone with a similar interest and some experience in OpenCL contributing ;)
Some random thoughts, not criticisms: 1. Gankro is totally right about HashMap's hasher. It will go lots faster with FNV! :) 2. As you don't actually require random access, you can get much better performance by sorting and aggregating rather than doing multiple random accesses. Something like RadixSort should work great. I know a guy who has [a crate](https://crates.io/crates/timely_sort/)... 3. The SSDs on the current MacBooks are 2GB/s. Holy crap. 4. Unless I misunderstand, your deserializer has a bunch of `Box&lt;Iterator&gt;` stuff in the inner loops. If this were more explicitly typed you'd skip all the virtual function calls. It might be trickier to do, but when I've done similar things it has helped (been worth it, I guess I mean). Edit: Ooo, and philosophizing / moralizing point: you say you don't want to try things that an optimizer couldn't figure out, which is a fine experiment, but one of the real virtues of a laptop/bespoke implementation is that you *can* do whatever you want. If you want to take the ip prefixes to shorter byte arrays, you *can* easily do this and that can be a big deal. Understand how big a deal is a good question.
http://doc.rust-lang.org/std/primitive.str.html#method.parse You can parse to any type implementing [FromStr](http://doc.rust-lang.org/std/str/trait.FromStr.html) which f32 and f64 do: http://is.gd/radcx8
You can also use ``` f32::from_str() ```
Oh thank you for the documentation link! I don't know why, buy I could not for the life of me find this with any amount of searching over the last two days.
So cool :D
I think currently one of the biggest differences between CUDA and OpenCL is that CUDA has a unified address space which allows you to do pointer arethmetic. In contrast to that you always have to create sub-buffers in OpenCL which is uglier to some degree. OpenCL 2.0 also includes unified address space but none of the NVIDIA drivers support it yet (and they understandably aren't pushing it very much). If you are planning to do the OpenCL implementations, feel free to hit us up on Gitter or the Rust-ML IRC :)
&gt;Implement unwinding for i686 MSVC. woo! having to alt+tab to bless the compiler's crash was annoying. It also made me realize compilers close via crashing far more often then cleanly exit.
It looks like you may be switch between 4-spaces and tabs in your code. Try stick with 4-space indentation everywhere! See: https://github.com/rust-lang/rust/blob/master/src/doc/style/style/whitespace.md
Where is the learning part? Also, couldn't you make the indexes type safe? (So that you can't use them in the wrong vector.)
Probably. I would love for this engine to be as Rusty as possible. Unfortunately, it seems like the master branch of nphysics is [failing to build under Travis CI](https://travis-ci.org/sebcrozet/nphysics) and the code hasn't been updated in a while, so I may be forced to look elsewhere unless it gets picked up again by a new maintainer. However, it seems like Bullet is in the process of [expanding and improving their C wrapper](https://github.com/bulletphysics/bullet3/issues/130), meaning it could become easier to bind Bullet to Rust in the future!
I'm also trying to get this into my head. I should just abandon (or reduce in priority) the code reuse goal for now and accept some extra typing to have types that are cleanly separated b/c it will be easier for future changes or for something else? Is that what you're saying? 
OOP is not the only way to share code. I would suggest that instead of thinking of objects with "methods" and "responsibilities", you should think in terms of data. What data do you have as input and what data are you trying to output? Structure your code around the transformations you have to do to the data. 
IANAL &gt; Does anyone know how licenses work with Cargo? There's nothing special or different about Cargo vs any other mechanism for distributing software. &gt; I'm assuming that would imply your application has to be GPL? It Depends. For example, if you're not re-distributing this application, then it's not required, no. As with all legal stuff, ask a lawyer to be sure. &gt; Where does static linking apply in Rust? Things are statically linked by default, but you can choose to dynamically link instead if you prefer.
&gt; I can put a mutable whatsis inside an immutable spin lock? Yes, this is called "interior mutability". It's the second section in the chapter on mutability.
You're moving in the correct direction. Code reuse does not mean 'less typing'. The primary advantage of code reuse is that you do not have to design and test as many lines of code. The lines of code that you need to write in order to fulfill trait requirements are usually very simplistic in nature, and in most cases errors in them will be caught by the compiler. There are many opportunities, in Rust, to do this kind of code re-use using traits and generics.
Ah, a shame that Rust decided to go with spaces as preferred...
Special for those who trust reading the source code: https://github.com/hyperium/hyper/search?utf8=%E2%9C%93&amp;q=thread%3A%3Aspawn&amp;type=Code Maybe you also need to understand what you are reading, before arguing.
Thats because Hyper handles requests in a thread pool and thereby one blocked thread doesn't mean that the whole application is blocked. It's not asynchronous for the server. And nevertheless, please don't accuse other people of having no clue what they are talking about here. Especially if you don't seem to have that much knowledge in that domain and they only want to help and clarify things!
A better explanation of the "buren" format would be nice, as its unclear what that is exactly or why it performs so damn well
1/ I'm already running with FNV. It amounts to about 2.5% of the total CPU. 2/ Ho, good. I thought I would have to do it myself. 4/ Yeah. Once I'm done with playing building bricks, I should probably try to get the best compromise running without dynamic dispatch. And yes, I'm running after two hares. Or more. I'm trying to show the merits of not using a framework, and assessing what kind of performance a native framework could achieve...
buren: * Each field is stored in its separate file. scalar types in their native form, String as size+bytes. * Each field file is compressed. * When reading data, only the wanted fields (ip and ad_revenue) are read and decoded to a tuple. It's not usable yet. I'll work on it, obviously, if this exercice leads to something less academic. At the current time, the fact that I am reading two columns, one a String, the other a f64 is very hardcoded :)
Can Cargo not spit out a list of all platform-specific versions which might be different from the current one? I suspect most crates don't have multiple versions, so doing 3 or 15 times the number of builds of everything is crazy.
Hello, We've just released Pijul, a distributed version control system based on patches, with the goal of being as easy to use as [darcs](http://darcs.net), without the performance issues. There's a detailed explanation on the mathematical theory behind it [on our website](https://pijul.org/documentation/model). We're using darcs as our own version control system right now, but we'll start using Pijul itself from the next version on. And yes, [it's on github](http://github.com/pijul/pijul), although just as a mirror. We also wanted to thank the Rust community for the warm welcome when we started translating our previous version, a few months ago, and for the continuous support since then. We'd love to hear feedback, comments, feature wishes, bug reports... 
I agree with you 100% here, HKTs would open up for a lot of different constructions and also help with error-handling since more generic functions could be made which are indifferent to what kind of wrapping error-handling type is used. Another alternative which I did not think of really when writing this post is to introduce `try`-blocks + `?` as a language extension using the upcoming `libmacro`. That does not actually introduce more complexity at the language level, and then the method-position macros could make the `try!`-macros easier to use.
More progress on Cajal. - Implemented cross-page growth, so axons/dendrites can spread across the entire board if not blocked. In this run, [the upper-left neuron becomes quite adventurous](http://i.imgur.com/w59r7wc.gifv) and grows a monster axon across all four pages - Neurons now grow two dendrites and two axons (was previously one of each). - Implemented signaling! \o/ Dendrites accept input from all neighboring cells and send it back the direction they originally grew. Body's take input from dendrites and pass to the axons. Axons take information from the cell they grew from and attempt to pass to either the next axon cell(s) belonging to the neuron, or any adjacent "foreign" body/dendrites - Implemented arbitrary "external" input to stimulate the cells. Here, [I'm injecting 8 points of signal](https://i.imgur.com/i4CXZ3t.gifv) (one set top left, another set bottom right) to kickstart the signaling. Signal above a cell's threshold is yellow, signal that is below threshold is pale yellow (bad color choice, looks almost white). - Can see some neat patterns already. [Here a feedback loop happens](http://imgur.com/KIK6Fgb.gifv) when the axon synapses with it's own dendrite (known as an "autapse"). Also interesting is that [dense formations kill signal](http://imgur.com/Py1eZKx) pretty quickly Now that the core is mostly working, need to spend some time cleaning up, refactoring and adding tests. And probably do some perf testing.
The decision can be either to accept or to reject. FCP recognizes that either (1) rough consensus has been reached, (2) discussion has died off, or (3) discussion is no longer going in a productive direction and a decision needs to be reached.
At the time that I wrote this, I hadn't actually trained a network yet, just verified that the error backpropagation was working properly by hand. I have since modified the [fuzzy xor example](https://github.com/tedsta/deeplearn-rs/blob/master/examples/xor.rs) to actually include the manual training part. It fails to learn one of the test cases, but learns the rest pretty well. I think it needs more training examples and better weight initializations. When I wrote this I was just so excited that I got error backpropagation working that I wanted to write it all down immediately. I implement `get`/`get_mut` methods on the `*Index` types that take a reference to their containing object, like `Graph` or `VarStore`. Is that what you mean? Internally in `Graph` I sometimes just use the wrapped value in a `NodeIndex` to directly index the node array to get around borrowing issues. The `get` methods borrow the whole `Graph`/`VarStore` when in reality it only needs to borrow the corresponding array. It makes me wish there were a way to do partial borrows. This could be resolved by wrapping nodes in a `RefCell` the same way I wrap variables in the `VarStore`. I'm fairly certain that there's never a reason to borrow a `Node` more than once at a time.
Does that mean `regex!(_)` will catch up with `Regex::new(_)` sooner than anticipated?
I can't try this right now, but I think you just need to make `self` mutable in the function signature: ``` fn comp(mut self, size: usize) -&gt; Integer { ```
Replace `self` with `mut self` in the function signature. Might be nice to have a special compiler error message for this. (This isn't really a borrow check issue; it's more of a const correctness issue.)
There has been some discussion of a 'cargo ianal' but it seems like opening yourself up to legal liability.
Looks like your documentation page still doesn't know about timely_sort, fyi.
I don't know how Rusty it is, but you may be able to use deref coercions here. Implement `Deref` to allow your "child" to automatically deref to your "parent" and then you can get an approximation of the delegation you're after. trait Behavior { fn do_something(&amp;self) -&gt; (); } struct Parent; struct Child { p: Parent } impl Behavior for Parent { fn do_something(&amp;self) -&gt; () { println!("parent behavior"); } } impl std::ops::Deref for Child { type Target = Parent; // maybe Target = Behavior instead? fn deref(&amp;self) -&gt; &amp;Self::Target { &amp;self.p } } fn main() { let p = Parent; let c = Child{ p: p }; c.do_something(); } I'd appreciate any feedback on how good or bad this is. It seems like an easy-to-abuse feature that should be considered any time it's going to be used. When does it make sense to deref in this way?
I know that there are some tools that will check for known problems (of course they will disclaim proving the *absence* of problems) in the Java landscape.
Many people (including myself) feel this is bad style. Deref is for smart pointers, not method overloading.
I did not know these things, thanks for the info!
If I'm reading this right, you declared Spinlock&lt;T&gt; as a tuple struct of one element. Why? Would you do that in real code, or is it just shorthand for a quick example?
Sorry, I think I need to get back to coding in Rust during my free time. The [feature](http://www.scala-lang.org/old/node/115) I was thinking of may be rather specific to Scala. I'm not sure there's an analog in Rust. It may be getting too close to dependent types.
Nope. :( the dfa is for Regex::new. In fact, the gap will widen!
In that case, I'll look into writing that lint...
Yeah it's going to be quite some time before `regex!` gets an overhaul. It's non-trivial and it's hard to re-use code from `Regex::new` because everything has to be static data. It would be nice *in the mean time* if all `regex!` did was verify that the syntax is correct so that it can never fail at runtime and still use the faster "dynamic" engines, but I'm afraid the train has already left the station on that one. (Today, using `regex!` in a loop is totally cool, but if `regex!` just checked syntax but recompiled on every execution, that would be very bad.)
Wow, that looks like a tremendous effort! While I'm not sure this has enough advantages right now to persuade me to stop using git for personal projects (or git just isn't broken enough), it's great to see innovation in the field! I tried reading a bit of the code to get a feeling for the inner workings. The `libpijul/src/lib.rs` file has 2800 lines and is quite intimidating… (You might want to run `rustfmt` on this, too.)
What a week! - Unwinding on i686 MSVC - [Implement the translation item collector](https://github.com/rust-lang/rust/pull/30900) sounds like a big step toward incremental compilation: could a more rustc literate roughly map what remains to be done? - [Stabilization of custom hasher](https://github.com/rust-lang/rust/pull/31081)
It should be noted that these are exactly the orderings exposed by the [C11 memory model](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf), which are also used by C++(11?). These are however known to be inconsistent with some of the optimizations compilers actually do!
You might give blosc.org a go. Zlib is known to be slow. Another technique that greatly simplifies data processing pipelines is to read from stdin driven by pigz
Yeah, I mean, in all of these cases, what you get back is a pointer to the structure. Using Deref to emulate inheritance doesn't do that.
What are the latency and throughput like? Is it reasonable to pitch detect and adjust in realtime?
write your parser or embed some interpreted language, ie. python or lua. You'll find bindings for both for rust.
I like [rust-peg](https://github.com/kevinmehall/rust-peg)! :) Here is [an example](https://github.com/bjz/mia-lang/blob/master/src/grammar.rustpeg) of one of my grammars.
I'm a bit confused, because the source available is pijul 0.1. https://github.com/pijul/pijul/blob/master/pijul/Cargo.toml#L4
Yeah, I tried this one, though it does not compile with rust `1.5.0` as I stated above... will `1.6.0` help?
What about this? `let out = map!(+ a b c d f g h);`: /// Equivalent of: /// ``` /// let out = a.iter() /// .zip(b.iter()) /// .map(|(x, y)| x + y) /// .zip(c.iter()) /// .map(|(x, y)| x + y) /// // ....... /// .collect::&lt;Vec&lt;_&gt;&gt;(); /// ``` macro_rules! map { ( + $a:ident $( $b:ident )+ ) =&gt; { $a.iter() $(.zip($b.iter()) .map(|(x, y)| x + y) )+ .collect::&lt;Vec&lt;_&gt;&gt;() } } 
There three deficiencies with Git that probably can be used to attract users. 1. Git uses SHA1(considered insecure) and barely tries to cryptographically validate the authenticity of a commit history. Consensus in the git dev community is the change from sha1 would be so radical that it probably shouldn't even be called git with a different hash function. There is definitely a market for version control with stronger security properties. 2. Git's unsoundness makes abstracting and automating over git hard. This is a potentially strong use case for a patch theory based vcs 3. Large monolithic repos. Git scales poorly for users of monolithic repos and doesn't give them any convenient escape hatches. Fix 2 or more and there will be adoption.
Fair enough. Although I don't think of what I suggested as emulating inheritance despite the OP's question. I see it as a relatively concise way to implement a trait. It happens to be done by delegating to a contained object that already implements that trait but it doesn't have to be. I'm not yet familiar enough with Rust to know how that would affect things. If I switched from `Deref&lt;Target=Trait&gt;` to a direct `impl Trait for Struct`, what would break? Is the `Deref` option only usable when borrowing, like it's not possible to pass `Struct` to something which accepts `Trait` as opposed to `&amp;Trait`?
Yes, we ignore the glorious `consume`, but that just makes us a subset. :)
No worries, that's a pretty common source of confusion. I seem to remember some debate that "self" being mutable or not is really just an implementation detail, so why expose that? For example, you can just do `let mut s = self` and use `s` from that point onwards. 
Actually SHA1 is still secure in Git context. Collisions does nothing In that case, there must be preimage attack for making SHA1 instructions In Git context. 
Maybe my mental model of git is wrong but I think if I can create a malicious source tree and brute force the same SHA I can insert my malicious history in the place of the real history. So speed ups to second preimage attacks seem like security issue. I dunno maybe Eve wants to change public key on my VPNs DUAL_EC implementation.
Not directly answering your question, but to complement /u/lifthrasiir, you can use the [`get_mut` method](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.get_mut) if you're not sure that the index is valid. The `data[i]` syntax should only used when you're confident that the index will be valid; otherwise, it would be a bug, and Rust therefore panics, preventing a buffer overflow attack. Here's how you might use it: http://is.gd/BuwKQR To get back to your question: the compiler does not prevent compilation when indexes are invalid, in part because `Vec` is dynamically sized, and so such verifications would have a small range of applications anyway. Making this part of the language would also be a breaking change. However, it _will_ remove bound checks whenever it can prove that the indexes will be valid -- making this sort of analysis better isn't a breaking change, it just makes your code run faster.
Very nice!!!
To be honest, I feel like it should. Can't the compiler see its going to crash, given that the values are static? Probably one of those many issues with mutable state making a guarantee impossible.
`a =&lt;&lt; b` will do one of two things: * if `b` is Some/Ok, it will unwrap it, store it in `a`, and go on to the next statement. * if `b` is None/Err, it jumps out of the do block, and the do block evaluates to `b`. At least, that's what it does when `b` is Option-like. You'll notice it's a lot like the try block proposal. It can do completely different stuff with other data types, like if `b` was an Iterator, and if ido was an ideal do block, then it would unwrap into all of the values, running all of the following statements repeatedly for each item the Iterator yields. Or if `b` was a promise, the do block would immediately evaluate to a promise and the statements would be evaluated asynchronously. ido is not an ideal do block, because it cannot run its statements out of order (it only supports skipping them), but it does support data types other than Result.
Thank you. Much appreciated.
You simply can't think that way when it comes to security. A broken hash function is broken and needs to be replaced. Doesn't matter if the problem is pre-images, collisions, or even reduced round collisions (above a reasonable security margin). For security primitives, the time between a marginal theoretical attack and a full attack is your migration window. The time between something like a collision and a pre-image is panic time, when you should be unplugging network cables while you apply the patches to your critical production systems. There's a reason why NIST ran a competition to get a SHA2 alternative starting in *2006* when SHA-1 was already looking weak. They're on the right timeline for security.
Thanks for your enthusiasm! 1. Pijul does not suffer from this. We use SHA-256, but even when that one is broken, changing the hash function, even in only some of the clones of your repository, does not break existing repositories, as long as hashes are of different lengths (see [here](http://pijul.org/documentation/repository/)). 2. Well, that's what we're believe too! 3. I can't be certain we've got this, because there is no monolithic repo running Pijul right now (and even Pijul itself is still controlled by darcs). But the complexity of our algorithms in Pijul, and the description of what causes git to not scale well on these instances, tend to show that we might have a solution.
Peg requires a nightly build, since it uses an unstable library. Not sure if the maintainer wants to chime in here...
I would use [multirust-rs](https://github.com/Diggsey/multirust-rs) to manage your rust installations. Makes it much easier to switch between different versions and stay up to date. You could also try using an older version of `peg` with 1.5.0 compatible dependencies.
Collisions work just fine for exploits in a Git context. I push out a branch for an obscure piece of hardware, that happens to have a binary blob firmware, convince Greg KH to merge it into the staging tree. Little does he know that that binary blob firmware does nothing, it's just there for bits to twiddle, and I have a colliding commit that also turns an `==` into an `=` somewhere critical that allows an exploit. I've pushed my colliding commit to GitHub, so once Greg's tree gets merged into Linus's and that gets pushed to https://github.com/torvalds/linux, it will actually be my version of the commit that is present, not the one that got merged. Now some unsuspecting router vendor grabs the code from GitHub instead of kernel.org since that's what they use for so many other projects, and bam, millions of devices suddenly vulnerable to my exploit.
Looks great! Looking through the theory and docs now. Just wondering though - what was the thinking behind the name, pijul? Looks like it might get a little annoying to type :(
I am using a function that takes a closure as an argument: http://alexcrichton.com/git2-rs/git2/struct.RemoteCallbacks.html#method.credentials The closure had three type arguments, &amp;str, Option&lt;&amp;str&gt; and CredentialType and returns a Result&lt;Cred, Error&gt;. In my case, I don't actually care about any of these arguments. So I can define a closure like: callbacks.credentials(|x, y, z| { return (something that's a Result&lt;Cred, Error&gt;) }); which works fine, but I get unused variable warnings. Any way to deal with this without suppressing the warnings? If I remove the three arguments it won't compile, but I don't actually care about handling them. Should I just fake handling them for the sake of removing the warnings? Is there any preferred way to do this?
Nix has been really useful in the last darcs sprint. Basically, you want a bunch of haskell hackers on four different linux distributions, to start using the same version of rust, and of all the dependencies of Pijul (lmdb and libssh, among others). Apparently, Nix works great in this case: we didn't even have to put the skype call on hold. 
LC_ALL is the name of an environment variable too though. Does Rust happen to already wrap that somewhere in the libc or POSIX code?
I don't see a huge issue there except for the library, which might go viral into the program it is linked into. This can be fixed by a linking exception similar to libgit2, though: https://github.com/libgit2/libgit2/blob/master/COPYING#L8-L21 For a version control system, keeping the implementations aligned and public is of interest and the GPL ensures that.
LC_* are just enums with numerical values at the API level, using setlocale() overrides the corresponding environment variable IIRC You can see how its implemented by gettext-rs [here](https://github.com/Koka/gettext-rs/commit/743094faeb119c1cfc008ee607601ca43ec2302a)
Complaining about the hash function is just silly. Creating a commit with a hash collision that also does something / looks like a real commit is completely impossible in practice.
One question, why SHA256 not BLAKE2? BLAKE2 is AFAIK faster and provide (at least) equivalent security.
/u/lifthrasiir answered the why, but I'd like to make a different point: treat `[i]` as `assert!`. In fact I prefer `foo.get(i).expect("Some assertion message.")` when I _have_ to index. But in general, if you structure your code well, you can do away with a lot of indexing that appears in other languages (by relying on iterators and pattern matching on `get` on non-existence is a valid state). The place where it's tricky to get rid of indexing is in traditional algorithms and data structures, especially due to Rust preventing aliasable mutation (you can use an index as a proxy mutable reference). Implementing quicksort or a graph without indexing is very tricky. Luckily this code is fairly self contained and can be thoroughly tested. TL;DR: While not memory unsafe, it's good practice to treat indexing with a great deal of caution and avoid it when possible. This is the case in _literally_ every other mainstream language which supports indexing too (in C++ it's a security flaw, in Java/Python it's an exception etc.)
Actually it is much harder. Git commit hash isn't just blob hash but tree hash, which is much harder to attack (even when second-preimage attack is available there is [simple fix](https://en.wikipedia.org/wiki/Merkle_tree#Second_preimage_attack)). So even with binary blob, it is hard to control commit hash.
Git tree is [Merkle tree](https://en.wikipedia.org/wiki/Merkle_tree) so it is not that easy to create collision in that case.
This is an argument for Go, if I'm honest.
They say they want to soon, maybe from the next version.
I agree that SHA-3 competition was needed as an replacement for SHA-1. It not just ended with great SHA-3 winner ([Keccak](http://keccak.noekeon.org/)) but also give us other great functions (like [BLAKE](https://131002.net/blake/) and it derivative [BLAKE2](https://blake2.net/)). But as it comes to Merkle tree then even MD5 is still safe enough. Of course there is no reason to use that in new implementations as we have great Tiger and BLAKE2 functions that are fast enough and much safer than MD5 or even SHA1. So SHA1 collisions breakage still leaves Git secure enough. PS SHA-1 wasn't chosen for Git for security reasons. Security is just nice-to-have side effect: http://security.stackexchange.com/questions/67920/how-safe-are-signed-git-tags-only-as-safe-as-sha-1-or-somehow-safer PS2 As changing commit hash function could be hard in Git that changing signing algorithm would not be so hard. EDIT: Even more on topic: http://it.slashdot.org/comments.pl?sid=8147663&amp;cid=50693863
They are currently using Cabal, if I read it correctly.
On their official website: https://blake2.net/#cr
I'm all for it, too, but it may be a deterrent to some.
Okay, cool. So, it's just like __unused in C.
So the security boils down to whether you see the correct or incorrect commit first? That does not sound like security to me.
That sounds plausible! I wonder if it would be acceptable to change `regex!` like that. You're right in that `regex!` was built to avoid allocations, but I didn't specifically have bare-metal in mind when doing so. But that is a good use case... Although, in bare-metal situations, not all of regexes methods can be used. For example, `captures` allocates ([but shouldn't at some hopefully not-too-distant point in the future](https://github.com/rust-lang-nursery/regex/pull/158)) and `replace` allocates.
pijul@pijul.org is our mailing list. We can definitely use the bug reporting tools on github. However, pull requests are tricky at the moment, "darcs send" is definitely easier for us (you can do "darcs get http://pijul.org" to clone the repository).
Commenting publicly on the respective merits of programming languages is tricky and can easily lead to misinterpretation, so I won't do it. Ocaml is a great language, Rust is a great language (in alphabetical order). Rustc and Pijul share this feature of having changed from Ocaml to Rust at some point in their development ;-)
Nix and Debian have different definitions of "reproducible". Debian means bit-by-bit identical. Nix means built-with-the-same-config-and-environment. For example, GCC provides a \_\_TIME\_\_ macro, which compiles the build time into the executable. This breaks Debian-reproducible, but Nix-reproducible does not care.
Lua has sliding scale complexity. I really do recommend embedding it, even if you don't make use of the advanced features, because it would leave you a lot more room for growth. Growing a custom DSL usually sucks, and it eventually turns into a programming language anyway. You don't want to deal with that.
That would result in a derivative licence and make integrating the "work" into another "work" even more difficult (at least, add another restriction).
Wel, it was removed for a reason ;) You can write ugly, complex code in any language. This code is extremely ambitious: an ORM that should be faster than writing literal SQL strings. It can only do that through advanced usage of the type system. 
As a Swift developer experimenting with Rust, these are great for getting a better understanding of the nuances of the language. Reminiscent of using the Swift Playgrounds with markup language to produce interactive tutorials: http://www.andrewcbancroft.com/wp-content/uploads/2014/09/Patterns_playground.png
I know. There's nothing wrong with spawning a thread per connection. It's a perfectly valid approach. I was just clarifying that spawning a thread per connection is typically called "synchronous" or "blocking", because the thread running the connection handler blocks until the connection handler finishes. It's useful when everyone uses the same words to describe the same concept, to prevent confusion like this.
Great stuff, anything to promote darcs concepts is a good thing for developers everywere. Though it's an interesting license choice for a tool and library. Am I allowed to reimplement or do you hold IP/patents?
One tricky thing about hash functions is that while this statement may be true today, it probably will not in the future. People used to think MD5 collisions were impossible in practice too.
&gt; because the thread running the connection handler blocks until the connection handler finishes. it's not how thread::spawn works. really, go test it then will continue.
Scratching my head over how to build a matrix using `nalgebra::DMat`. I have three vectors (`Vec&lt;&amp;f32&gt;`) of (equal, unknown at runtime) length, `n`, and want each of them to become a row in my `3 x n` matrix. I don't really understand how either `from_row_vec` or `from_column_vec` helps me here, due to a dearth of examples…
rofl, I shouldn't have posted before my cofee. of course I meant Darcs, Cabal is not a vcs system!
Thanks! I did not find this information on the website, so it might be a good idea to add it to an easy-to-find place. Assuming you want contributions. ;) I think the biggest questions for potential contributors are: * Which communication channel can I use? * Where can I report issues? * How can I contribute code? They should probably be answered somewhere in the (not yet existing) README and on the website, especially if you are not using Github for development. Is there an archive of the mailing list? Do you mean with "darcs send" that the code review should take place on the mailing list?
It doesn't matter if the whole commit hash is based on a tree hash. The leaves of the tree hashes are the blob hashes, which are just a hash of a small header plus the file contents. If one of those blobs conflicts, the whole tree will as well. True, that doesn't give you the ability to modify another file, you may have to do the attack all in one file. Or, there may be enough bits you can twiddle in the commit object itself, like the timestamps, commit message, and so on that you can achieve a collision that way. One problem with any of this is that it's all speculation, no one has yet published an actual collision. But it keeps on getting closer, and with MD5, it didn't take long between the first actual collision (2004) and a real world forged certificate from researchers (2008), and later a real world black hat forgped certificate (issued 2010, discovered in 2012).
Blocking what? Looks like you're writing "blocking" just to use this word. Other queries are not locked, they are being executed in parallel - it's the main point. All other is out of discussion scope.
Why doesn't pijul use libpijul if I may ask? If you have a library I'd assume you're using it yourself to avoid a situation like libgit2.
What happened to that proposal to make [virtual structs](https://github.com/rust-lang/rfcs/issues/349)? Did anything come out of it? There were also some posts about it here: * http://smallcultfollowing.com/babysteps/blog/2015/05/05/where-rusts-enum-shines/ * http://smallcultfollowing.com/babysteps/blog/2015/05/29/classes-strike-back/ * http://smallcultfollowing.com/babysteps/blog/2015/08/20/virtual-structs-part-3-bringing-enums-and-structs-together/ I agree that this kind of feature feels lacking in Rust currently.
A potential simple scheme: - Define a prefix length (4 characters is sufficient for everyone^(1)) - In `meta.toml` keep a dictionary of all hash functions that have ever been used in the repository, with a different prefix for each - All hashes start by this prefix, guaranteeing collision avoidance (across hash schemes) and allowing immediate identification of the hashing algorithm used for a given change --- ^1 *More seriously, 4 alphanumeric character means 36^4 different prefixes, I am not even sure you would consider implementing so many hashing schemes pijul.*
&gt; to get a uniform repository format everywhere. If you want to penetrate potentially closed-source organizations, then you need to make sure that the license you use allows never publishing the source code. I *think* (but am no lawyer) that BSD, MIT or Apache2 cover this need. At the very least Stallman picks on them for not being copyleft regularly.
Something like [R's swirl](http://swirlstats.com/) would be super cool!
Indeed :)
They have a bit about this in [their FAQ](https://pijul.org/faq.html).
&gt; I'm probably misunderstanding what you mean. I mean nothing more than what's written. This was a genuinely naive question. I've read your arguments for BSD/MIT/ISC, thanks! That's indeed a good point.
Did you know that [David Roundy (creator of darcs) has also been doing some Rust programming](https://crates.io/crates/arrayref/)?
I wonder what a live coding stream would be like. Just a dude writing rust while commentating it on twitch.
Actually the GNU Project recommends licenses without copyleft like Apache2 when you want to establish a new standard: https://www.gnu.org/licenses/license-recommendations.html
I was just seeking to clarify what the parent comment was saying. The benefit is that you can serve multiple requests off a single thread. Whether this is beneficial for your use case is a different question. Like I already said, one-thread-per-connection is perfectly valid for many -- probably most -- use cases.
I'm tired of this kind of comments. Rust is not some kind of magic. Detecting these errors at compile time, carries a number of significant trade-offs. First of all, the majority of out-of-bound cases _cannot even be detected_, since they either have an arbitrary value or a very little constrained one. This means that they have no usable bound, and thus no data to argue about the value, or a potentially OOB (which is actually unreachable). So, this will in the majority of cases force the programmer to make a bound check anyways (through a `if` or `match`), providing no better or worse performance than the implicit one. "Free" manual checks are already possible through the widely-used `get()` method. For statically detecting out of bound conditions, you'll have to introduce a number of otherwise ineffective constructs to the type system: 1. Non-local typestate analysis. Meaning that _you cannot analyze on a function level_. You'll have to _type check the program as a whole_. This has an exponential complexity. For any non-trivial program the compile time will sky-rise (my guess is about 50-70x). Typestates have been proven ineffective over time, due to its many limitations, especially since it is an extremely "pessimistic" form of analysis. Typestate bound checking is a very stupid one compared to, for example, LLVMs bound check elision which is very sophisticated and extensive one, so chances are that you'll not get any advantages of a typestate bound checking over LLVMs optimizations. 2. Structural (non-lexical) subtyping. This is a very complex construct to introduce in a type system with efficient type inference. Type inference will be practically impossible with this kind of structural subtyping. 3. Non-trivial dependent typing. You'll have to argue about the state of the program based on the control path, information about the previous states of the program, non-local type information, and. This construct severely increases the complexity and compile time of the language. There are so many things, you have to trade for a mostly useless mechanism, which will enforce the programmer to do the bound check manually most of the time anyways. A 100 times easier, yet just as efficient, solution is to remove panicable `Index`, but that seems like a bad idea too, since OOB is normally unrecoverable, and using `get()` will make the language very verbose. So while it is possible to create a mechanism which detects OOB, it cannot be perfect (it'll have false positives), since the problem is undecidable. I'm sorry, but Rust cannot solve the halting problem.
Box::new still involves a stack allocation that gets moved. Presumably this is being optimized out in the release build. This probably would work in a nightly build using the `box_syntax` feature and the `box` syntax.
You can find a format called multhash specified [here](https://github.com/jbenet/multihash). There are already implementations in several languages including rust.
Note that deref coercions don't *have* to occur in function arguments, they can happen anywhere you supply a `&amp;T` to a "slot" that expects a`&amp;U` where `T: Deref&lt;Target=U&gt;` (and the equivalent for `&amp;mut`).
Nobody will be able to give you an impartial comparison between the licenses, as it's usually a very heated debate. I will try to give you an overview how I see the differences between the licenses, why I think people prefer which licenses and why I would recommend you a license without copyleft. The basic decision is wether you want a copyleft or not. Copyleft means that people have to give back when they change the code. You should do this when you don't want people to take your code, build something and not give code back (for instance Apple did this with lots of BSD code for OS X. Some of it is actually open-sourced, but not in a license that the BSDs are okay with to include back in their code. Apple also probably is the large anonymous sponsor of FreeBSD). This is essentially what it boils down to. How likely is it to happen (forking and maintaining a project is a high cost to companies) and how bad do you think it is. There are lots of projects which don't have a copyleft license and don't have any problems or at least don't complain about this code "stealing". The BSDs, LLVM, Apache projects like Subversion, SQLite, ... Most importantly though probably is Rust and the Rust ecosystem. The compiler uses MIT and Apache2 dual licensing and lots of crates out there do the same. Most Rust contributors are probably okay with the use of licenses without copyleft. The BSD-like licenses (2-clause BSD, MIT, ISC which are saying almost the same) are relatively short and easy to understand, so you can read them yourself. Apache2 deals with more things like patents, contributors etc. I'm not neither a lawyer nor am I deep enough in this topic so I can't help you further there. Most companies though seem to like licenses without copyleft because there are very few requirements for them that are easily met. The few requirements can also help the propagation for standards. If I heard it correctly, then TCP/IP was first implemented for BSD and this implementation later incorporated into windows and linux, which lead to a fast adoption. Even the GNU project recommends licenses without copyleft for new open standards if you want to dethrone proprietary standards: https://www.gnu.org/licenses/license-recommendations.html When you decide for copyleft, there are several levels how strong it should be. When you redistribute code containing GPL code, the receiver has a right to get the source code to all of the code. This means non-GPL projects can't use your code without putting their code under GPL. If you see that as a problem there's the GPL with classpath exception or with linking exception or the LGPL. There might still be problems with other freedoms the GPL gives its users: for instance the anti-tivoization parts of all GPL versions with the version number 3 doesn't allow distribution in the Apple App Store. With version 2 it's not really clear if it's compatible with the App Store. The Free Software Foundation thinks that it's incompatible. The licenses so far are only about redistribution. The Affero GPL additionally is concerned about when someone builds a service using your code and changes it without redistributing. Github for instance would need to publish their changes and extensions to git if it stood under the AGPL. Github's business model on the other hand maybe bases on their changes and extensions not being published and maybe wouldn't exist in today's form.
This happens because in Debug Mode it doesn't allocate the Array directly on the Heap because for Debug Mode the compiler won't inline (at all?). So it will pretty much do what you wrote in your code and put the array directly on the stack and overflow it before copying it over to the box (standard Stack size is roughly 4 MiB). For Release Mode the compiler will strongly inline everything and notice that it won't make sense to put it on the Stack because you want to move it to the box anyway, so it'll optimize the allocation on the Stack away. There's not really much you can do about it other than maybe using a Vector instead.
Rustc isn't god, unfortunately. Detecting OOB on compile time is practically impossible.
I'd argue against that in the case of a VCS, most developers are actually users. Making sure that source must be shipped makes a lot of sense, especially as it ensures that you can modify your tool if you want. As argued above, I'd relax the license for the library a little, to avoid the unfortunate situation that git has: it can not really be used as a a library.
Looks great, thanks for the pointer! I didn't know this.
If the vec weren't mutable there should be no technical reason why it couldn't be determined. Since its mutable, idk, may be harder. All of the values are statically known though.
If you really want it to work as-is and not use a `Vec`, you can increase the maximum stack size. How you do that will depend on which platform you're on. If you are on Linux or Mac, `ulimit -s &lt;size in kB&gt;` should temporarily do the trick for anything launched from that shell session.
How about changing to `let numbers = vec![0; MAX];`? This allocate on the heap for both debug and release builds. 
&gt; This means a conversion to CString on the parameter(s), but maybe you can return a &amp;str instead of a String on return? Looking at how much copying is involved makes me want to implement a `String/CString` hybrid, that would both be utf-8 and nul-terminated, so it would deref to `str` but also be useable from C via `as_ptr`. Various C bindings could exchange this type without copying and some macro magic for literals. [Proof of concept](https://github.com/gkoz/ctring/blob/master/src/lib.rs). &gt; Does the gettext API say anything about how long the returned string is valid? I believe it's static iff the return value is different from the argument.
Choice quote from your slides: &gt; clippy lints all the things Well, we don't. Yet. Only 109 of them. But we're working on the rest. ;-)
&gt; There are some situation, in which dereferencing happens automatically. One of them is in using the println! macro. Another one is in using function pointers (see Functions). Also missing is any method call. And technically, `println!` doesn't automatically deref its arguments, instead Display and Debug are trivially implemented [on references](http://doc.rust-lang.org/src/core/fmt/mod.rs.html#1311) [and smart pointers](http://doc.rust-lang.org/src/alloc/rc.rs.html#688) by delegating to the pointee (with the requirement that said pointee is Display or Debug of course). &gt; Other kinds of smart pointers in rust are Rc&lt;T&gt; and Arc&lt;T&gt;. These are the smart pointer with reference counter and smart pointers with reference counter and atomic access, respectively. `Arc` is not for atomic access but for atomic reference counting. Rc uses a "regular integer" as refcount (actually an integer in a Cell for interior mutability), so if multiple threads try to increase the refcount at the same time[0], the refcount may not make any sense anymore. Arc [uses an AtomicUsize to store the refcout](http://doc.rust-lang.org/src/alloc/rc.rs.html#176) and the refcouting is thus thread-safe through atomicity. Arc also requires that the object it stores be thread-safe (Send + Sync), but Arc doesn't itself synchronise the value. &gt; One thing that does not work in rust as easily as in C/C++ is dynamically allocating a fixed size array on the heap. Where in C++ you could use new[], in rust you will have to use Vec&lt;T&gt; for that (or to write your own type). In order to allocate space for n elements in a vector, the macro vec![value; n] can be used, where value denotes the initial value for the elements. You can heap-allocate a fixed-size array or a slice e.g. `Box::new([1, 2, 3])` [0] assuming the Rc can be shared between threads, which it can't
"rust for OOP refugees"
A couple of things worth mentioning: 1. The `restrict` keyword is unnecessary in Rust. If you have two mutable borrows of the same type, you can guarantee that these two borrows won't point to the same location. And you can also guarantee that mutable slices will never overlap. 2. An immutable borrow in Rust has stronger semantics than a `const` pointer/reference. `const` in C and C++ means "you can't mutate the object through this pointer/reference". Which means the following code: // Example vector class class MyVec&lt;T&gt; { void operator+=(const MyVec&amp; oth) { for (size_t i = 0; i &lt; oth.size(); i++) { push_back(oth[i]); } } }; Has a bug because something like: MyVec&lt;int&gt; foo(0, 100); // Fill vector with 100 zeroes foo += foo; Will result in an infinite loop. Rust, on the other hand, will catch this, because `foo` cannot be borrowed both mutably and immutably.
&gt; The i-types are (signed) integers of 1, 2, 3 and 4 bytes respectively Should be 1,2,4,8 bytes. Same for u prefixed
&gt; Should be 1,2,4,8 bytes. Same for u prefixed You're completely right, I fixed it …
&gt; You can heap-allocate a fixed-size array or a slice e.g. Box::new([1, 2, 3]) IIRC, with large arrays this may cause stack overflows in debug builds (due to allocating the array on the stack before copying it to the heap allocation).
I've used Nix, worked with it, all of that. I'm still not convinced it's something I need. It's very cool, it does what it does very well, but I just don't have a need to 100% reproducible builds. Put more specifically, it doesn't help me all *that* much when I'm developing for something other than just Linux. I barely even need Linux specifically as it is.
`String::from` for literals and `.to_string()` for not literals. `to_owned` in generic code. IMHO.
/r/playrust
Wouldn't it mean treating Vec as a special type though? I mean, unless you add _some_ dependent typing to the mix, I don't see a way to generalize this to custom structures. It would be great to have, but I would guess a pain to implement, at least as of right now.
Right, I'm just imagining that making possible out-of-bounds a warning would be a solid compromise solution between people wanting backwards compatibility and safety.
Actually standard xgettext utility extracts strings from rust sources using C parser. It can work with "gettext" function name too - not only underscore macro. I've tested simple cases and it creates POT file well.
I think the current workaround for boxed slices is `vec![1, 2, 3].into_boxed_slice()`
Yes, main thing is order of execution. In single thread or in multiple threads - orthogonal to discussion. Requests being executed consequentially, or not. Arguing "it's not async because I like single-thread async" is not constructive.
Why is it "obviously" slow?
GPL permits ["mere aggregation"](https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.en.html#MereAggregation) of separate works in the same media (such explicit permission [is actually needed](https://lwn.net/Articles/417852/)).
Makes sense looking at the code. I asked because what you wrote above made it seem like it wasn't: _We switched to Rust in mid-October 2015, and we haven't touched libpijul much in January 2016 (working on pijul instead)._
I've edited the comment a few times to add new recommendations (or alter existing ones, Option would probably work fine as error reporting here for instance, there aren't that many failure cases that I can see) I tried to apply some of it in a playpen, not really happy with the slice iterator copy things but: http://is.gd/o1Sp7u
They have only one repo among all users. All forks are just branches in that tree.
Yeah, in my actual code I am sending an int back to C to indicate a number of (or no) errors in the rust code. I also ended up adding logging to the rust library because debugging anything in a mex fail is a huge pain in matlab without a lot of setup. the `from_raw_parts` and friends looks useful too, will certainly clean up a lot of my glue code. the c_long probably should be a size_t, I just checked the matlab api docs and mxGetM returns a size_t. According to the libc docs usize and size_t are compatible.
[removed]
Regarding GPL's requirement to share modifications, it only works if you intend to spend your time with judges and lawyers instead of working on the project. There aren't many developers who want that, so that's why they tend to license liberally. You cannot force those who really want to keep their modifications to themselves. And I also argue that it's a bad use of time and resources to try force people to publish modifications. Time better spent on the code.
Developers using a developer tool are developers and users at the same time, so you cannot label them as users in the sense of random joe using his smart phone. Developers modify and contribute to the tool.
I have some example input domain specific language files in the same directory as my rust project (under directory 'examples', when the source code is under 'src', obviously). Whenever I change one of them and do 'cargo run' it triggers a recompile for no reason. My project has more than 40000 lines of code so that hurts my workflow a bit. Is there a way to stop this behavior?
God damn that's really clever and fun. Is there also a reason behind the chainring only having 4 bolt holes?
&gt; you're supposed to spin off a thread Or, eventually, http://doc.rust-lang.org/std/thread/fn.catch_panic.html
See [this comment](https://github.com/rust-lang/cargo/issues/2326#issuecomment-176873338) for the details. It's a very narrow span of using cargo nightlies from a few days in january. A crate published with those versions will not unpack on current rust stable.
I really don't see why you are spamming me, but I am not labeling them as random Joe. To modify a tool, they need source access, to the source of the one they are currently holding as a binary blob. And that is what the GPL ensures: that the user (be developer or random joe) has source access. Many other licenses just ensure that the developer as an integrator has easy going. If you have philosophical beef with the GPL, so be it. If you think licenses are a waste of time, so be it, too. I don't.
It's not about contribution, but about availability.
Sounds right and I argue that forcing release of modifications plus the time it takes to make sense of what is likely to be a sub-par diff that only works for that specific fork are often not worth the effort and time spent.
I'm sure it have problems. For full support someone need to send patch to GNU xgettext utility to support Rust. It's definitely possible but I'm not feeling brave enough for this at this moment. But xgettext C parser is still usable for simple cases.
Likely no. Most examples are compile time errors. I'm not 100% sure how Rust handles NaN poisoning, likely the same as every other language NaN's are hell to deal with it b/c: (this is a generalization haven't tested in rust) assert_eq!( NaN, NaN); //panics So those *may work*, but division by 0 is a runtime panic on debug builds isn't it? 
Two things that have come up that we're _now_ aware of: 1. The Leakapocalypse (relying on destructors running for memory safety) 2. Unsafe code that relies on invariants set by safe code, so it looks fine in and of itself, but safe code messes with it.
&gt; I'm tired of this kind of comments. Sorry, my answer was too much short. &gt; For statically detecting out of bound conditions, you'll have to introduce a number of otherwise ineffective constructs to the type system: You can face the problem with solutions of various complexity. At a basic level you can give errors for accesses bounds that are statically out. The D language compiler does it: immutable N = 5; immutable idx = 7; int foo(in int[N] arr) { return arr[idx]; } void main() {} It gives: test.d(4): Error: array index 7 is out of bounds arr[0 .. 5] Similar code in Rust doesn't give a compilation error: #![allow(dead_code)] const N: usize = 5; const IDX: usize = 7; fn foo(arr: [i32; 5]) -&gt; i32 { arr[IDX] } fn main() {} The Rust compiler needs to catch similar bugs at compile-time. ------- A second level of solution is to catch at compile-time situations like: #[allow(dead_code)] fn foo() -&gt; i32 { let arr = vec![0; 5]; arr[7] } fn main() {} Here the vec is assigned to a constant array, so arr doesn't change length. This gets soon more complex if you want to track slices lengths with some flow analysis. You can face this problem with a flow analisys of slice sizes, similar to the Value Range Analysis D language does on scalar values. ------- A more general solution is to introduce refinement types as in LiquidHaskell and F* (https://www.fstar-lang.org/ ).
Adding variants to the enum will cause the match to fail to compile, not Undefined Behaviour. Using unsafe to construct an instance of a zero-variant enum is UB, but that's true using unsafe to construct an invalid instance of any type.
Pinging /u/Manishearth, who had last time's winning (and only) entry (which we subsequently wrote a lint in [clippy](https://github.com/Manishearth/rust-clippy) against)
Again, I was simply clarifying what others meant. I have no horse in this race.
Hehe, to be fair, you guys asked for input on licensing in this thread at least twice. Just sayin' :). Let's focus on outstanding features of pijul git cannot have, instead.
Overflows... Overflows everywhere...
How does atom-language-rust compare to language-rust?
&gt; I don't know if usize would work correctly for an extern, someone can chime in? _Semantically_ I believe that `usize` maps over to `uintptr_t` rather than `size_t`, _however_ I _think_ that every platform that Rust supports defines `size_t` such that `sizeof(size_t) == sizeof(uintptr_t)` so it will probably still work. **TL;DR** Let the `libc` maintainers deal with it, it's so much easier that way.
It would be as simple as `darcs push` if you had the rights to the repository, but in this case, you need to do `darcs send https://pijul.org`. It generates a file ending in `.dpatch`, which you can then send to pijul@pijul.org. The archives of our mailing list are not yet available (some work is needed to convert smartlist output to jekyll). btw: I really appreciate your attitude towards our (not so popular) VCS.
There would. First of all: immutability isn't a strong enough condition for the bound being known at compile time. You need constant, statically-known length. Second of all: this would require vecs to be lang-items, due to their bound will have to be known by the compiler. 
That's an interesting problem. Here is a demonstration of this: https://github.com/fizyk20-experiments/rust-plugins/tree/static-fail I wonder if there is even a way to fix this. The compiler would have to somehow realize the connection between the lifetime of an object and that of a library.
Looks pretty neat! I tested it with a simple 2 operand calculator that beginners like to implement. #[macro_use] extern crate scan_rules; fn main() { println!("Enter a simple 2 operand arithmetic expression: "); readln!( (let lhs: f64, let op, let rhs: f64) =&gt; { let result = match op { '+' =&gt; lhs + rhs, '-' =&gt; lhs - rhs, '*' =&gt; lhs * rhs, '/' =&gt; lhs / rhs, _ =&gt; panic!("Unsupported operation: {}", op) }; println!("The result is {}", result); } ) } I noticed 2 oddities: It doesn't accept reading an integer-looking number into a floating point variable. Enter a simple 2 operand arithmetic expression: 2 + 2 before: Some((0, 50)) after: Some((1, 32)) thread '&lt;main&gt;' panicked at 'ScanError { at: ScanErrorAt { bytes: 0 }, kind: Syntax("expected floating point number"), _priv: () }', src/main.rs:6 Note that both scanf and Rust's [.parse\(\)](https://play.rust-lang.org/?gist=47a83c736b8fe89a63d2&amp;version=stable) allow this. You might already have noticed the next oddity. It pollutes stdout with what seems to be debugging code. Enter a simple 2 operand arithmetic expression: 191. * 7. before: Some((0, 49)) after: Some((3, 46)) before: Some((0, 55)) after: Some((1, 46)) The result is 1337 
Thanks for the feedback! 4 spaces still looks weird to me, but I can get used to it
Yeah, it was for me too. Eventually I got used to it :)
대박! I love it!
I second nox's comment: &gt; I meant that Cargo itself should include tests that unpack newly-created packages with older versions of Cargo, not a safety check at upload-time of third-party crates. Trying the unpack with a couple of the last stable releases and maybe the current beta/nightly?
Actually, I would argue that any warning should be silenced in the code. What would be interesting is seeing new tweaks that are not yet warned against.
The best underhanded submissions, though, would probably NOT be relying on `unsafe` to give you a sense of safety. Note that the underhand contest is not about crashing the program, it's just about misleading the reader.
I like the idea of automating the crate publication, especially the automatic detection of which version number to bump to avoid silly mistakes.
I found the choice of json... surprising at first. However it appears that these MDA blocks are only used to store the configuration (which disks) and not the actual files metadata. Still, the MDA area are "only" ~0.5 MB, is there a rough idea of how many disks Froyo can handle at most?
Beyond `Box`, even the `PluginTrait` representation could change! I expect that we can rely on the fact that the `Box` boxes a `TraitObject` with two pointers, one for the v-table and one for the data, however these are opaque pointers and I would not be surprised for an ABI change to change the v-table layout. Going forward, and without actually stabilizing the ABI, I believe that the only way to secure this would be to "version" the representation of each exported item: - the exporting library would have a field (or several) in its .rodata or .text section giving the "version" of each exported item - the importing library would, upon importing a symbol, check the version of each of its exported item to see if they match what it expects Oh... and I have absolutely no idea how to compute those hash/version and ensure they are bumped each time a change does occur... (Note: of course the hammer approach is simply to use a single "ABI" version field embedded in each library, however if it is bumped so often that plugins never work... still would be better than nothing).
For now, in a serious project, you would have to go low-level: C-types can be reliably exchanged (use `#[repr(C)]` on structs).
Where's the footgun in treating Option as an iterator?
Ugh. Blame my sleepyness, I read that sentence totally backwards.
Yes, that and the floating point trickery seem the most accessible (and yet devious enough...). Looking for an exploit in Rust is valuable of course, but it's a much higher bar...
Yeah, it would mean that rustc would be able to reason about these things, which is impractical and would be likely ugly, for a bug that isn't unsafe in any way.
That's a pitty and I guess I'll just stick with wildcards then. I don't understand why they are bad (for binaries) when we have Cargo.lock.
Linux/mac support?
I think having a totally innocuous `unsafe` with adequate _explanation_ can be an even better way to hide malicious code in plain site, esp if focus is drawn on validating the `unsafe` block, the brokenness hides in the iteration. And as NSA patches have shown, the malicious code should be explainable as simple mistake anyone would make. Good one would be adding a pad value to hashed password and then only checking the password length by the padding value instead of the length of the password. Possibly using /u/Manishearth 's iterator trick. So really just port the coding style of OpenSSL to Rust. 
The "hole" idea has been explored here a bit and appears to work https://users.rust-lang.org/t/help-with-using-c-plugin-api-from-rust/3249/12
Is there a dog-fooding Rust IDE built in Rust?
Not just crash but unwinding across `extern "C"` is undefined behavior. Unwinding across incompatible ABI wouldn't work either.
Yes, https://github.com/oakes/SolidOak But it works on Linux/OS X only and is still less feature rich than Atom with all the Rust-related plugins IMO.
I just thought it was a heavily stylized capital 'R' 
AFAIK it is just NeoVim with GUI and some built In plugins, so you can adjust it to Your needs. 
Are you guys going to have Rust meetups in Korea?
Could plugins be forced to be the same compiled on the same compiler version as the compiler itself? (Same release, same platform, same ABI, etc)? From looking at the state of things, I don't think a stable ABI isn't likely to happen this year.
&gt; It doesn't accept reading an integer-looking number into a floating point variable. You're right; I think it's because I was trying to duplicate the parsing behaviour of Rust, not the `FromStr` implementations for floats. I'll fix that. &gt; It pollutes stdout with what seems to be debugging code. *Aaaaand* this is what I get for having lots of automated tests that all suppress their output. *Bangs head on desk.* Fix that too... **Edit**: v0.1.1 is up.
I’ve listed the 19 crates that likely need to be re-uploaded: https://github.com/rust-lang/cargo/issues/2326#issuecomment-180145442
I once spotted a bug in some linked list deletion code that 3 other people in the room read over and said was good. Only I caught it because I was the least smart person and had to work through it. They just skimmed it and called it good. So yeah, looking very minimal and _obviously_ correct but not, is a great idea.
I just learned about the leakapocalypse problem and it sounded very scary! Are there any long term solutions for this?
Is there any general advice on how to do this type of profiling in Rust? (I'm just coming from a point of naivete.)
Well for pure Rust code, we have the `#[bench]` system: https://doc.rust-lang.org/book/benchmark-tests.html This will run some code over and over until it gets some statistical significance and outputs average and variance results. My inclination would be to dynamically link in the rust crate and the c code, and run them in `bench`es that fiddle with various parameters (length of key, salt, difficulty params, etc). Should be pretty fair, I think? If you want to do *actual* profiling, then we tend to be able to work with all the usual C tools (e.g. `perf`) because there's thankfully a standard format for most of this stuff. For this specific case, the reference implementation actually comes with [its own benchmark](https://github.com/khovratovich/Argon2/blob/master/Source/C99/Test/argon2-test.c#L61-L125), which might be reasonable to duplicate (there's a seperate one for the C++ impl as well).
Awesome reference. Thanks Gankro!
&gt;&gt; The Rust community gives me a particularly bad feeling. &gt; Did Slashdot became "The Onion"? I actually found this to be a common reaction. I mostly attribute it to unfamiliarity, and general aversion to "moderation" (which is often disparaged as "censorship"). If you didn't encounter it, I suspect that it may be due to filter bubble.
Things I noticed from a quick look: - Your `sys` crate is called `parasail_sys` and not `parasail-sys` which would be the more conventional and suggested naming by the Cargo guide. - I see that you include the MIT license as a header in every file. This is usually only done if the license or project requires it. Of course since you are the maintainer, you decide how to handle it, but personally I'd rather have my code files clean of licenses and only have one central in the root of the crate (as you already do). - A small code example in the README is usually a good thing.
Doesn't this blow up already, even with the same Rust compiling both the plugin and the main program? I mean, won't this lead to the library using one memory allocator and the main program another, and you're allocating an `Box&lt;PluginTrait&gt;` in the plugin and freeing it in the main program?
&gt; I mostly attribute it to unfamiliarity Not only that. Don't underestimate how much of an anti-PR a Contributor Covenant based code of conduct can be. Especially in places not, ahem, touched by political correctness.
Actually there's this (anonymous) person that keeps making variations of that same post on every article about Rust, and sometimes on articles about Firefox/Mozilla when Rust is brought up. They always reword it though, so it's hard to google, but the post usually involves the claim that Rust has many bugs, with the link to the github repo. Just ignore the posts, they're just going to keep doing it. Besides, slashdot hates new things :)
&gt; Besides, slashdot hates new things :) You ain't kidding. That and just about anything Mozilla touches it seems.
Well, Mozilla did accumulate lots of ill will from, in no particular order, Hello and Pocket integration, new tab page ad, killing Persona, killing Firefox OS, etc. I think it is unfortunate but unavoidable that Rust gets hate by association.
I think they hated both Firefox OS *and* that it was killed. They just really like to hate :) In addition, many seem to dislike Mozilla for the situation around Brendan Eich.
I've also been wondering what the Rust version of the [International Obfuscated C Code Contest](http://www.ioccc.org/) would look like. Rust does offer some unique avenues for obfuscation.
Wow. ambitious, good luck!
&gt;&gt; I'm assuming that would imply your application has to be GPL? &gt; &gt; It Depends. For example, if you're not re-distributing this application, then it's not required, no. As with all legal stuff, ask a lawyer to be sure. Well, IANAL as well, but: the application doesn't need to be GPL in any case. It _must be distributed in a fashion expected by the GPL_ (with full source and without any other licenses that restrict the freedom of the recipient to change and reuse the source). 
Thanks! It's been fun so far :)
&gt; LGPL can work reasonably well. Apache License v2 or ISC are more likely to attract users and contributors LGPL has issues with static linking. The LGPL asks you to provide the user with everything needed to relink against a different version of the library. (e.g. on iOS, that isn't feasible) GPL with linking exception is probably a better fit.
The initial poster in that thread looks like an agent provocateur.
Actually looks like they were interested in Rust and just wanted more information regarding the last points, and what better way to do that on the Internet than posting contrasting opinions/answers. (Someone's law)
Like 8-12 max was the initial thought.. The number of disks that physically fit within a single physical jbod disk enclosure, really, give or take. 
/g/ never's really had an issue with Rust on a technical level. Technically its a pretty sound language, and fairly mature for its age. The main issues are political. And have more to do with anonymous imageboard culture meets community code of conduct. For some these two policies are too diametrically apposed.
I too am learning Rust. Would love it if I could contribute to the community somehow =)
Thank you!!
I have an iterator over a bunch of `String` and I would like, in case the value of the iterator is "-", to iterate over all the lines in stdin before continuing with the remaining `String`. Is what I'm trying possible? I thought flat_map() might help me but I'm not seeing it.
True, but some people are more open to contributions and mentoring new contributors
I'd just `map(|arg| if arg == "-" { .. } else { .. })` and read either stdin or the file.
Thanks, that's the plan :D
Cool! I've been using KeePass for ages now, so I'll give this a look. Expect a PR soon. :-)
Does it parse only the 1.x-version databases, only the 2.x-version databases, or both? ...because things like KeepassX use the 1.x format (still catching up), which makes that desirable and I only use Keepass 2.x via Mono, which makes that desirable for me.
All very good points, and I've made some changes: - Didn't even notice the difference in naming -- that's been resolved now. - I still like including some copyright header, but you're right that the full MIT inclusion is unnecessary. Shortened it down to point to the LICENSE file. - Added a code example from one of the doctests -- very good point! Thanks for the advice :).
Currently it only parses the 2.x kdbx format. One of the future goals would be to support both database formats. 
KeePassX 2.x is [was released](https://www.keepassx.org/news/2015/12/533) a few months ago, and uses the .kdbx format.
Sorry about that! I at least want to start doing it a lot more regularly. Perhaps that'll help :)
This is my first major crate I've released. Any and all feedback is welcome. I've tried to outdo myself with the documentation. **Edit**: I've just updated the ASCII art example to make it clearer what exactly is going on on each line.
Really glad to see this, I had someone ask me if this existed the other day! Usually, including "rust" in your crate name is a bit redundant, but since one of the features here is that it's in pure Rust, it's not as strange as it might normally be.
Please keep making these!
I think here is a good place to start looking for some good projects to contribute: https://github.com/kud1ing/awesome-rust
Thanks, that fixed the problem.
Haha yea, it's not really your fault. I really enjoy these videos :)
That's what I mean with 'levels' of purity – for many applications, your heuristic may suffice.
I just couldn't resist, considering all the other names out there like TrueType, OpenType, FreeType. RustType seems like a perfect fit.
Good point!
:D :D &gt; So library crate authors: If you find that your library API can be misused, but lack a zero-overhead way of preventing that misuse Note that we at Servo [already do this to get GC safety](https://github.com/servo/servo/blob/master/components/script/docs/JS-Servos-only-GC.md), since our SpiderMonkey hooks cannot be given a 100% safe wrapper in Rust. (This is an issue with the specific GC design; it is possible to write safe GC libraries in Rust too. The planned GC integration helpers in Rust should fix this issue though). Of course, this case is a matter of safety, not just "API misuse". For the most part since Rust makes it pretty easy to write safe APIs, I expect there to be a lot more scope for API misuse lints over safety lints. So yeah, crate authors: ideas welcome! &gt; Now how would this be done? I figure we’d need to make some crate metadata that we should be able to get accessible to lints (and the rest of the compiler). We're basically looking at an effect system here; annotations like `unsafe`, except for things other than safety. This can be implemented as a lint that enforces annotation, however all crates being fed in must also use this lint (making it impractical for general use). On the other hand, tweaking the compiler to add this metadata seems just as heavyweight. :| &gt; Some have expressed their belief that many lints of clippy belong in rustc. Eventually, I want to do two things (I know you know this, but just putting it here for the benefit of everyone else): - RfC the lint defaults and behavior to get all the bikeshedding worked out - Maybe put it in the nursery I'd be happy to see lints uplifted to rustc itself, but I'm fine with the status quo too.
Huh. I didn't think the last two months were *that* busy for me. I guess I'll have to find time to see if anyone's got a build that could replace my use of the KeePass TrayTOTP plugin.
I'm wondering why the OpenDbError::Io variant doesn't just have a std::io::Error, instead of a String?
I want this project to be idiomatic Rust as much as possible. The dependence on stb_truetype should decrease with time. For example, the analytical rasteriser is entirely my own work, based on an algorithm described in a recent academic paper. stb_truetype is only relied on for parsing font files. **Edit**: Also, I wasn't aware of that truetype library lurking in Piston. That might have saved me some time, but from a first glance it appears to rely a bit too much on `unsafe`. I've tried to minimise that in my version.
awesome. so nice not to have to link in external libraries. congrats!
There are a lot of requests for lints under the `A-lints` tag, do you all look at that when deciding about new lints?
You could call it RusTy for short.
Another thing that I think is important in a package ecosystem is reducing duplicates when possible. I understand different libraries that accomplish the same thing using different methods, but libraries that are for production and not just toys that essentially have the same functionality and only changing the api naming can be annoying. The JavaScript npm world has this problem. Everybody implements their own version of the exact same thing to get "github cred" or something instead of contributing to an existing project that does what they want. The mind share resources would be much better spent on contributing rather than making a new project that is built the same way. note: I'm not saying people should not experiment. Just don't product "production" libraries if they are to a certain degree similar to another....just contribute to the other one. 
Is this using [wavelet rasterization](http://josiahmanson.com/research/wavelet_rasterization/)?
Every time I read something on slashdot, I despair briefly of the state of humanity. Lots of hate, no constructive criticism.
TypeR
I am suddenly wondering if Servo is relying on FreeType or another C library and if they would be interesting in switching to a pure Rust implementation given their goal of eliminating unsafe dependencies. I am not at all knowledgeable about font libraries, but to me, given the apparent complexity of the formats involved and the rendering itself, it seems a potential attack surface much like music/video decoders (could a website trick you into downloading a font?).
Both Chrome and Firefox run web fonts through OTS https://github.com/khaledhosny/ots to sanitize fonts before passing them on to the OS.
Thanks :D
That's the plan!
&gt;I believe that at the end it requires UnsafeCell, so as long as you &gt;can recurse into the definition it does not seem too complicated to &gt;identify them. You can also use unsafe pointers and undefined behaviour might still do what the programmer intended.
Can you clarify the bit about selective cookie policies? I run Aurora channel and subscribe to Planet Mozilla and haven't seen anything to that effect in release notes or blog posts so far.
This is awesome! My terminal project ([notty](https://github.com/withoutboats/notty)) would need this library to ever have a pure Rust terminal implementation.
It's not. From the link: &gt; The next step is to open a tracking issue and begin work on implementation. Further discussion about this feature can be had on the tracking issue. Once we are satisfied with the state of the implementation -- and in particular we feel we have resolved the various unresolved questions -- we will start a second FCP period on the tracking issue itself. This lasts for one release cycle (6 weeks). We will then make a final decision about ungating. In the case of this RFC, there are two distinct feature-gates, one for the ? operator and one for the "try-catch" functionality. Most likely those will be stabilized at different times (and of course we can always refine further, creating new feature-gate for subsets of the functionality if necessary). The closest I can say is "at least 1.10", as it's not in FCP for 1.8, as it's not even implemented yet, and it has to wait a full cycle. So in theory, an implementation could land, it could immediately go into FCP for 1.9, and land in 1.10. That shouldn't happen though; we'd want to let it bake longer than that.
Any time. It's always a tricky balancing act; we'd like new features fast, but at the same time, we want to make sure that they're good. This RFC has a lot of detailed questions that still need hammered out, so I would imagine it will have at least two or three cycles of being unstable. We'll just have to wait and see.
I'm definitely interested for the metadata reading and OTF parsing code. The rasterization is really neat too, but what I'd be even more interested in is GPU rasterization, since the GPU takes up as much die space as the CPU nowadays and it largely goes unused in browsers.
This whole feature is pretty much sugar. It's an ergonomic improvement, not a fundamental ability shift.
Don't get too excited by the parsing code; that's the dirtiest part of the codebase at the moment - not `unsafe`, but not idiomatic Rust either. It's a translation from a C library. It will improve once I get the time. I have ideas for efficient GPU rasterisation based on the same principles in use in the CPU rasteriser, though I take it this would need to be limited to using something like the feature set of OpenGL ES 2.0 for Servo to be interested in it? My current ideas are focussed on efficient use of compute shaders.
Realized I replied to the wrong person. Weird, idk how that happened. Thanks for getting to it. If it's just sugar, I don't really like it. Another symbol and another keyword for something that seems entirely suitable to macros.
I really like `try!`, but. There's three ways to think about this: 1. One purpose of macros is to prototype language features which don't exist yet. So this is a pretty natural outcome. 2. "too much `try!` boilerplate" is a really common pain point for people. I hear it all the time. 3. It does legit make the chaining case a lot nicer. see https://github.com/rust-lang/rfcs/pull/243#issuecomment-169423425 for an example with builders.
Hm. The try! is undoubtedly uglier in that example. However, it only seems to be ugly because the 'goal' of both seems to be to fit as much in one line as possible, which isn't really a goal I'm in favor of. It's more concise, but not really any clearer - in fact, to a beginner, it seems definitively *less* clear, as 'try' should be a bit more understandable than '?'. Still, I think a multiline example would probably still not be great either. My guess is I'll learn to love it, but I'm wary about symbols.
It means you can use `?` in `fn`s that don't return `Result`s, for one thing. It also means if you want to apply the same error handling to multiple potential `Errs` you don't have to `map_err(|e| ...)` after each one; you just put them in a `catch { ... }` and then you can handle them uniformly afterward. I kind of think I might have misunderstood your example, though, because it doesn't look comparable to `catch { ... }`. Could you show the code you're comparing against?
One example where this comes up but _isn't_ about cramming things in one line is the builder pattern, where you naturally want to chain things together and then get the result at the end. Even with newlines between, it's much worse with `try!`.
Ahh, if it's a Linux kernel-style "It's been broken for ages and nobody seems to have noticed" removal, then I don't mind as much.
http://diesel.rs/ was just uploaded about an hour ago.
Which is interesting, but what if I wanted to write a competitor to diesel.rs? I would have to track down and reinvent everything that diesel.rs has invented and I would still only support whatever it is I got around to supporting. An update to the db driver could render my library horribly broken. I'm thinking of the Java world where there is a rich ecosystem of database interaction layers and they are mostly possible because of the JDBC standard.
In particular, I'm thinking about this comment that recently came up in the python community. https://www.reddit.com/r/Python/comments/43vvsn/aiolibs_libraries_for_mysql_redis_elasticsearch/czm9sub Essentially, they have this problem where every time a new framework comes along that wants to do something novel with IO, they end up completely writing their own IO libraries. This means that there are dozens of framework specific Http clients that do things completely differently from each other. I know it is only somewhat loosely related, but I think that having standard interfaces is a good way to foster a more interoperable library situation.
Those languages don't have the same type system features as Rust, and so to blindly copy them would not live up to the full potential of what a truly Rust-like interface could have. Diesel, for instance, makes heavy use of Rust's type system to be _ridiculously_ efficient. For example... &gt; the postgres driver (from my limited knowledge) already pretty much follows the ODBC standard Diesel is about 33% faster than it already. Part of this is because it takes advantage of what Rust has to offer, rather than just being the most obvious binding. To be clear, I want to see more libraries too! I agree that interop is important. But I don't think that it should be done hastily.
Does diesel implement it's own postgres driver? Is it still creating and submitting SQL or is it going down a level from that to interact with postgres? I would be interested to know how it is making the 33% performance gain. I'm not trying to suggest rushing in. But rather what I'm thinking would be something like defining a relatively small interface, implement wrappers for existing libraries to that interface (postgres, sqlite, etc), and seeing what is good/bad about it and refining. I wouldn't want to do the Java thing and sort of dump it down and say "This is the standard, all must follow it" but rather the rust thing of starting small and unstabling and refining to stability and goodness. I wouldn't think that something like this would really be at a "mass adoption" phase until a few years down the road when the interface is stabilized and clean. In other words, I'm not thinking of making a new standard interface today, but just the seed project to see where it might end up.
Good job! Watching every week. Very good idea to not accept large PRs and do all coding while streaming. Hope you not will get tired of doing that :) 
True! I've seen many projects on github that are like 1-2 years old and abandoned. It would be great if these were easy to locate so interested developers could update them and make them compile on newer Rust versions. 
&gt; **Hide state variables in a boxed trait.** While technically correct, that's not the main point of my trick. Returning `Box&lt;Iterator&gt;` only addresses the lack of `-&gt; impl Iterator`. The "over abundance of generic types" and use of a closure for inference of type parameters is the real trick here, and it would still be necessary with `-&gt; impl Iterator`.
Ooh that's even better than what I had. Le sigh. Someday, `impl trait`, you and I will be together, and we shall paint the world with such marvelous return types...
Hah! I came across this post while working on the conrod guide. I'd just written &gt; Unfortunately there aren't many mature options for pure-Rust font rendering at the moment (*if you know of any, please let us know with a github issue or PR!*) In the "Getting Started" chapter. We'll *definitely* be looking into using this and giving support where we can!
Nice!
I think you're right.
Your description says its an alternative to FreeType. If you know what FreeType is, that's an okay description. I'd rather see a description that explains what the project does without relying on knowing what FreeType is.
Would it be too unreasonable for your definition of purity to include "no `unsafe` outside of the standard library"?
I think we're in violent agreement here, then. It's just too early. This is only the second or third ORM project to ever exist. &gt; wouldn't want to do the Java thing and sort of dump it down and say "This is the standard, all must follow it" Gotcha. This seems directly in conflict with "Why don't we have an OBDC port yet".
Sorry for the confusion. I wasn't trying to suggest it be finished right now, I was more wondering if anything was started/planned/finished.
I've thought about this - being very used to be able dynamically load interface implementations in C# and Java. In my experience, about 90% of the time, I only want to load those implementations on startup, based on config. Given rust is a systems language, you could achieve similar results with a 'make based config' system like OpenWRT uses. Whereby you choose the implementations of your traits at build time, instead of them being dynamically loaded at runtime. The build script imports the relevant code and generates the extern crate statements you need. So, you lose the runtime loading, but avoid all the ABI issues discussed in the other comments. I haven't tried it yet, but it would allow you very clearly define interface boundaries in your project, with your own implementation, but make it possible for plugin implementations to replace components in the future.
I believe `and_then()` is a shorter de-sugaring.
My D is a bit rusty^no ^pun ^intended , so I have no clue. [The specification says:](http://dlang.org/spec/function.html#pure-functions) &gt; Pure functions are functions which cannot access global or static, mutable state save through their arguments. This enables optimizations based on the fact that a pure function may at most mutate state reachable through its parameters. So apparently it is possible to also inspect these kinds of things to see how a function will mutate its arguments. I'm somewhat unsure of this, as [std.functional.memoize](https://dlang.org/phobos/std_functional.html#memoize) seems to only key by its arguments, and doesn't mention anything about its out parameters.
I get the feeling my graphics and image processing classes are going to come back and haunt me tonight. Man, I thought I had blocked those out.
:memory: also works if you don't want it to be persistent. :)
 let r = foo().and_then(|val| val.bar()); With that comparison, the `catch` syntax doesn't gain anything. I suppose it might compare favorably if you had multiple infallible calculations in between.
It'd be interesting to compare this to [font-rs](https://github.com/google/font-rs), which is at this point a half-finished prototype. I've been meaning to clean that up and do some serious performance measurements, but just haven't had the time. It's very cool to see foundational libraries like this in pure Rust!
/r/playrust
Well, the `catch/?` version would allow things like loop control and early returns, since it doesn't need to create a function scope. `and_then` becomes a lot more verbose in those scenarios.
Well, thank you very much for the explanation!
It also does From::from conversions, which let you catch even when the errors differ. and_then would require a map_err as well to get that. 
I usually like the (A)GPL licenses, but I don't think it can work here if the goal is to get widespread adoption. It probably completely blocks adoption by cloud providers, e.g. GitHub, BitBucket, and even GitLab^1 , if they wanted to use Pijul they would have to open source practically their entire business. Considering how useful these free hosted repositories are, I suspect that there would be little to no adoption without them. Even just a GPL license (without link clause) would prevent closed source editors from shipping tools integrating with this. While one might view the prevelance of such editors as unfortunate, they are a reality in today's world, and not about to go anywhere. Personally I've been playing around with two somewhat related ideas that might find a VCS like this useful^2 . One is to try and gather a dataset of how I (and others) change the code in reaction to compiler messages, by recording the state of a source tree after every save. Then to attempt to apply machine learning algorithms to create autofix suggestions for simple mistakes like missing semicolons. Long term I'd be interested in how far I could extend such a system and have it output useful code. The other is to take the repository I'm creating for the above, and implementing a "undo N saves" and have that implicity revert the changes in a new branch of the repository. Even better would be to have a system automatically detecting when the state is the same as before and automatically checking out a new branch at the previous commit. While this wouldn't be much use as a shared repository, I think it would bring (me, at least) significant productivity gains by allowing more aggresive editing of code. The second idea would work fine with an AGPL license, I'm not so sure about the first idea though. It seems to me that the repositories, and the models trained from the repositories, would be derivative works covered under the license. And even being totally happy sharing the code, and the trained models^3, I would personally not be willing/able to share all the data I trained the model on. It looks to me that the data would count as source code though, and that I would be required to share it if I shared a trained model. ^1 While mostly open source, they do have a closed source enterprise edition. ^2 I've more or less concluded that in the short term it will be better to go with something more stable like git. In the long term what I want is both different enough from a traditional VCS, and simple enough, that I should just implement it myself. So don't go relicensing just for my sake. ^3 Which isn't really the case. While realistically I am very unlikely to develop this idea to the point where it is worth anything. I do like having the motivation of knowing that if I did, I could at least make some money off of it.
I used it until I found the 'self destructing cookies' extension. It allowed me to stay logged in in sites I trust, while removing cookies for anything else.
Yes, I think so. The wavelet rasterisation method effectively renders every mipmap level on its way to the final result, which can be quite some work to deal with efficiently. Also, because it is effectively rendering mipmaps, you have to worry about non-power-of-2 sizes. No such concerns with this method. I also think scanline rendering lends itself to easier-to-write code than recursive quad-tree rendering.
Oh, that's true.
Thanks for the comment, these are definitely interesting use cases. Why would you not release the data from a trained model under a BSD license?
Have you seen this? [GPU text rendering with vector textures](http://wdobbie.com/post/gpu-text-rendering-with-vector-textures/) &gt; This post presents a new method for high quality text rendering using the GPU. Unlike existing methods it provides antialiased pixel accurate results at all scales with no runtime CPU cost. 
A few points: * Yes, caching is very effective, but on-CPU glyph rasterization pretty much doubles or triples the first paint time on most pages, and that's the most important paint of all, because before then the user is staring at a blank page. Delay due to glyph rasterization could potentially be cut to zero by moving it to the GPU and running it concurrently with layout. * Slow glyph rasterization means that pinch zooming either becomes slow or blurry. Most browsers opt for the latter. But both options are pretty bad for the user experience. We should just be fast enough at rerasterizing text to have sharp, smooth pinch zooming. * Dynamic SVG (used in e.g. New York Times infographics) benefits from fast vector graphics.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming_jp] [Rust に新しいエラー処理構文を導入する提案が受理される](https://np.reddit.com/r/programming_jp/comments/44fmuy/rust_に新しいエラー処理構文を導入する提案が受理される/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Ooooooh... I'm definately going to have a look at using this in my hobby game instead of Freetype... I wasn't looking forward to having to mess with figuring out how to do linking again (I have got it working before).
This sounds really really cool! What i wonder: are there thoughts put in multi-layer fonts (COLR table)? A new library can design its API around such possibilities without having to have backwards compatibility concerns. /e: why `Codepoint` and not simply `char`? Isn't the latter’s whole purpose to be a codepoint?
Well you are calling `stdin.lock()`, which is locking the "`stdin`" variable, what do you think calling `stdin.lock()` again do? More clearly: let stdin = io::stdin(); // locks stdin stdin.lock(); // tries to lock stdin again and tries to use it let out = stdin.lock().lines().collect::&lt;Vec&lt;_&gt;&gt;(); // ..... never finishes because stdin.lock() is waiting for // previous lock to unlock So you are stuck behind whats known has a *[dead lock](https://en.wikipedia.org/wiki/Deadlock)*, you just locked the value, because you locked it the next lock is going to wait until its unlocked to used it, because you never unlock it its never going to be unlocked. So it waits for ever. To unlock a value it needs to leave a scope block `{ }`. Now, i'm not exactly sure if that is whats happening here. I never used `stdin.lock()`, its only my best guess. 
Well actually your example works just fine, since you're not binding the first `stdin.lock()` to anything so the lock is released immediately. However in my case, I expected the stdin to be locked and released lazily as the iterator is consumed, but I guess that's just not how it works
We are going to use this in Redox. This is amazing work!
I've had a look at how the COLR table works, and it looks to me like the current API should be extensible to support multi-layer fonts without having to break backwards compatibility, and without compromises. Since these multi-layer glyphs are defined in terms of a list of other glyphs, I should be able to just add methods for getting this list of layer glyphs for a glyph, and then the user can easily rasterise them on top of each other using the existing API. I picked `Codepoint` for the API to make things more explicit, and also it makes some things easier than dealing with `char`s directly. For example if you want to get a list of glyphs for a range of code points, you can just perform arithmetic on code point IDs. That's not so easy with `char`s. I have however made it so that wherever a `Codepoint` is accepted, `char` (and `GlyphId`) is also accepted, using the `Into` trait.
Not to be too meta but sticking to the wildly supported OpenGL subset that is webgl allows one to target almost all platforms, including embedded and emscripten. It would be nice to run RustType in the browser or mobile.
This is pretty much the exact thing that motivated me to make this (not your hobby game, mine :P). Linking to FreeType (especially on Windows) is a pain.
I think flying-sheep's point is that Rust's `char` type is just a code point, i.e. a disguised `u32`.
You could almost stylize the ㄹ to look like an R without the left vertical bar. It could work for both languages... 
Perhaps using Function Reactive Programming (FRP). There is [this crate](https://crates.io/crates/carboxyl_window/) using this paradigm.
Yes, but by such a minor amount I don't care, and it should be just as fast very soon.
It is still more verbose.
Do notation was discussed a lot in the thread, and having it be based on traits was the original design.
As I learn rust I am making a Sound Que system so that any stage can have one. No matter how small. I think that this is a good project to learn how rust works.
What's the canonical pronunciation?
Ah, that's OK then. Also I'd just like to note that GPU rasterisation isn't high on my priority list at the moment - I want to get a conventional cache working first, then use it in a GUI crate. By the way, how's the recruiting process going for the Servo Research Engineer position? I'm really interested in the position and I submitted an application back in November, but I haven't heard back one way or the other. Is the position still open? I heard a while ago that there were three positions to begin with, but two have been taken so far.
There are some existing columnar data formats in the BigData ecosystem, like [Apache Parquet](https://parquet.apache.org/). It's also a binary format, with each column compressed separately. It also supports complex types like arrays and maps, encoded with the technique described in the Dremel paper. For row-oriented data serialization, there is [Apache Avro](https://avro.apache.org/). Have you considered the write endurance of SSDs when using BigData? I just bought a 500GB TLC SSD that is rated for 84GB of writes/day for 5 years. With BigData, it's easy to write more than that, when you're doing things like external sorts. You can get ~50X more endurance with the more expensive "write intensive" MLC SSDs. But most BigData code accesses the data sequentially, so data distributed on Just a Bunch Of rotating Disks offer good performance. 
I do wonder... ... let's work it out. The original formula is `sqrt(a*a + b*b - 2*a*b*cos(theta))` (oh, looks like some vector product in 2D? Been a long time since I did that sort of maths). In any case, supposing that each and every operation might fail, and we need to unwrap before moving on: fn dot_vector(a, b, theta) -&gt; Result&lt;...&gt; { let a_square = try!(a * a); let b_square = try!(b * b); let a_square_plus_b_square = try!(a + b); let 2_times_a= try!(2 * a); let 2_times_a_times_b = try!(2_times_a * b); let cosine_theta = try!(cos(theta)); let 2_times_a_times_b_times_cosine_theta = try!(2_times_a_times_b * cosine_theta); sqrt(2_times_a_times_b_times_cosine_theta) } To be honest, shadowing seems limited because of the fact that one needs to keep referring to a lot of the symbols. I see a nice improvement replacing the `2_times_...` variables by `r` and using shadowing there, but otherwise it might obscure more than it helps.
I highly recommend keeping a changelog starting right now. It makes it so much easier to upgrade the version of a library.
The convention is `foo()` and `set_foo()`: https://github.com/rust-lang/rfcs/blob/master/text/0344-conventions-galore.md#gettersetter-apis
You probably want to get in touch with /u/larsberg or /u/metajack.
A potential issue with that technique is that there's some on-CPU setup cost: constructing the grid of curves. Usually any sort of CPU-side setup kills you for small text, as by the time you finished that setup you might as well have just have rasterized it on the CPU. :(
I'm not sure actually. I would suspect Japanese kana has high hit rates, as does Hangul. I bet Chinese characters follow a power law distribution, so you'd get high rates on stuff like 的, 不, 了.
&gt; This is truly amazing and very helpful! Thanks! &gt; Regarding the work-flow, do you use something like sshfs to remove the deploy step? So far, I've only cross compiled a few tools and not been doing cross development, so I've just been `scp`ing the binaries. Do you have a workflow that you'd like to recommend? A tool that I'd love to see is some `cargo cross-test` that cross compiles your test and then runs them on the target which could be qemu or real hardware and reports backs the results. That would extremely helpful if you are developing a crate for a slow target like the BeagleBone or the RPi -- `cargo watch cross-test` :D.
I completely subscribe to the idea that automation reduces friction, which in turns increases friendliness. When you have more time for human interaction, you can spend more effort on being friendly and explaining things.
Using an LGPL library doesn't impose any licensing requirements on your code. It only requires that users be able to swap out the LGPLed part. That means that: 1. If you dynamically link to the system copy of GTK+, you're golden 2. If you statically link, you have to provide compiled object files for your code that allow them to swap in a new GTK+ and re-run the linker to produce a new binary. 3. Any modifications to the LGPLed library must be shared under the same type of terms as with the GPL. (Basically, the LGPL says "You don't have to open-source what you link to this, but you do have to enable the user to modify and swap out the LGPLed parts.)
Interesting. I found [some analysis by mapbox](https://github.com/mapbox/node-fontnik/issues/36) that supports a common-wisdom figure of 3000-4000 chars for 99% Chinese coverage. Which isn't great, but not as bad as I'd expected. And it looks from the code like `Glyph.scaled()` doesn't need to rasterize, so I guess you could bung out the cached 99% while rasterizing the other 1% in parallel, rather than having to stop every ~100 chars to get the metrics needed for positioning the following ones.
Minor doc nitpick - in the example code under Glyphs, the comment says `Now glyph is a ScaledGlyph` but `scaled` actually returns a `SizedGlyph`. (Which kind of highlights that the naming mismatch could be a little confusing.)
Rust prefers explicitness and not hiding anything behind the scenes. In particular assignment operator is always just a byte-by-byte memory copy (`memcpy`). If you need to execute some code together with assignment then just declare a function, this is pretty much idiomatic.
Ah, good spot. Looks like I'll rename `SizedGlyph` to `ScaledGlyph` for 0.2, as it does look like a more appropriate name.
For some of the restrictions, adding lints for better diagnostics would surely improve the user experience, right?
I started reading the post and some of the issues seem to be very C/C++ centric such as integer&lt;-&gt;pointer casts. However there is a number of integers casts that I wonder how Rust would fair with given the prevalent use of `as` to cast between sized-integers and `isize`/`usize`.
The philosophy I'm following at the moment is similar to that used by Apple for their font rendering - get as close as possible to the perceptual appearance of printed text. As a bit of context, my rasteriser at the moment uses a simple box filter - equivalent to infinitely sampled typical anti-aliasing. In the future I can extend this to more complex filters as described in the paper I am basing it off (http://josiahmanson.com/research/scanline_rasterization/). With proper tuning these should be able to improve readability through effects like analytical sharpening, whilst maintaining the apparent shapes of the glyphs. Having said all that, traditional hinting is not ruled out, though I am wary of the mountain of complexities in the TrueType hinting specs, and the rabbit hole that would open when trying to implement them.
&gt; If you statically link, you have to provide compiled object files for, your code that allow them to swap in a new GTK+ and re-run the linker to produce a new binary. That sounds troublesome (in the sense of having more work to do) ;-). Thanks for sharing this information about the LGPL. I've learned something new.
I love all the automation and community stuff Rust has going - but one thing I've been wondering about is: How can we get this kind of thing going for smaller communities? As an example, my main project, [libpnet](https://github.com/libpnet/libpnet), is mostly a one-rustacean effort, with occasional (really great!) contributions from others - but my time is pretty limited. Things like Travis, AppVeyor and Homu have been great for build automation, but that's only one part of the story. It seems there is still quite a lot of overhead to doing everything right, so I'm wondering what we can do to minimise that, so it's even easier and less time consuming to get things right. As an additional question: I'd love to have rust-highfive for libpnet - is there a way I can make that happen without setting up my own instance?
It's a spanish name, so the equivalent english would be something like "pee - hool", with a strong "h".
There's been some talk of highfive-as-a-service but I'm not sure it's there yet. I fully agree.
From what I recall, purity in D works as follows: * If all parameters are immutable, then the function is pure as in the Haskell sense - it has no side effects * If there are mutable parameters, the function may mutate global state, but only through those parameters, ie. it could only mutate global state if you passed it into the function. This means that you could mark, say, a `swap()` function as pure. * D has a `debug` statement, which allows you to run code only in debug mode - this works as an escape hatch for purity, so you can still do printf debugging It's quite a nice approach, since you can choose the appropriate "level" of purity depending on what you're doing - it allows you to easily guarantee you aren't launching nukes without having to resort to making everything immutable (note that immutability in D applies to the type rather than the binding). And, of course, if you need to launch nukes to debug it, you can still do that :) In terms of memoization, D has really powerful compile time introspection, so you can define a memoize function which only accepts Haskell-style pure functions as parameters if you desired.
&gt; Is the value of &amp;*&lt;&amp;T&gt; in memory the same as &lt;&amp;T&gt;? Let's take it step by step: `String` == `String` We have a `String`. `*String` == `str` Due to `Deref`, specifically, `impl Deref&lt;Target=str&gt; for String`, http://doc.rust-lang.org/std/string/struct.String.html#deref , we get a `str`. `&amp;*String` == `&amp;str` Adding a reference takes us from `str` to `&amp;str`. Make sense?
Sure. Your understanding is correct. `&amp;str` is `(pointer, length)` and `String` is `(pointer, length, capacity)`. This means creating a new `&amp;str` that points to a `String` is very inexpensive: copying those two bits of data. But... &gt; Is it just prefixed with a usize? `str` by itself is an unsized type, it's only the length. That's why you need it to be `&amp;str` before it's useful: there's no pointer.
So how does a str without a pointer regain the String's pointer? I know of the deref trait, so that * can be mapped, but how is &amp; in &amp;*String defined, and then taking the pointer from the String? (because str doesn't know it?)
Reading comments in that article. I find it quite logical too - you tell objects what to do and don't care what they are. To me, property is just syntax sugar for getText()/setText(text).
That would require chain to drop the first value when it's exhausted, but it does not drop either value until both are exhausted.
What if `??` was used instead? IMHO it's much harder to accidentally skip it while reading code compared to `?`.
Well there are many ways to write your `dot_vector` function without needing the `?` operator. Some examples [here](https://play.rust-lang.org/?gist=79ac3bbdd5ef4a6ebd2a). I'm not sure if all of those options are strictly worse than using the `?` operator. With that operator I imagine the function would like this: fn dot_vector(a, b, theta) -&gt; Result&lt;...&gt; { sqrt((((a * a)? + (b * b)?)? - (((2 * a)? * b)? * cos(theta)?)?)?) } It might be slightly better if we add even more sugar and allow something like this fn dot_vector(a, b, theta) -&gt; Result&lt;...&gt; { sqrt(a*?a +? b*?b -? 2*?a*?b*?cos(theta)?) } ... on second thought, no that doesn't look better at all...
Do you have any refs and/or examples of the kind of results possible with "analytical sharpening"? I'd never heard of it, Google isn't giving me anything and your josiahmanson.com link looks dead. EDIT 20 days later - josiahmanson.com is back up now
&gt;Since the release of Vulkan is near Woah, is there news on this?
 pub struct Board { board_size: Point, robot_location: Point, board_locations: HashMap&lt;Point, GItem&gt;, rng: ThreadRng, message: String, game_over: bool, } fn attempt_move(&amp;mut self, ctx: &amp;mut TextGraphicsContext, d: UsefulInput) { let mut new_robot_location = self.robot_location.clone(); match d { Up =&gt; new_robot_location.y -= 1, Down =&gt; new_robot_location.y += 1, Left =&gt; new_robot_location.x -= 1, Right =&gt; new_robot_location.x += 1, _ =&gt; panic!("Escape/Other should never be passed to this function"), } if self.is_out_of_bounds(new_robot_location) { return; } let entry = self.board_locations.get(&amp;new_robot_location).clone(); match entry { Some(&amp;Kitten(ch, _)) =&gt; { self.message = "Game won".into(); self.game_over = true; self.draw_success(ctx, ch); } Some(&amp;NonKittenItem(ref s, _, _)) =&gt; { self.message = s.clone(); } _ =&gt; self.robot_location = new_robot_location, } } 
The `&amp;` has to do with the magic of how `Deref` works. All Deref implementations return a reference, but the operator calls that method and then dereferences the reference that is returned (actually dereferencing is not defined by the operator overloading). So the implementation of `Deref` for `String` returns an `&amp;str`, which is the fat pointer. `*` calls this method and dereferences the fat pointer, whereas `&amp;` annuls that dereference and you're left with the pointer you wanted. For this to work in the sense of compilation the dereference and address-of operations that `&amp;*` suggests must be being eliminated by the compiler, the details of which I am not familiar with.
This biggest deficit I see in OSS projects is the lack of well described tasks for people to pickup. Really the only way to get a task is to use it in way that breaks it and then work on a patch. This is only drives features that individual devs are specifically interested in. For those less familiar and less skilled, having tasks described and mapped out lowers the activation energy. Rust, *(edit: and Servo)* is one of the few OSS projects that really get this, the https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy are wonderful. More please.
I am trying to write a rust shared library. I'd like to keep some state alive across multiple calls to the library like a thread handle and a handle to a channel into that thread. But apparently that's not possible, since static muts can not be of a type with a Drop implementation. Makes life a bit hard for me. I really wanted to use rust in this case.
I'm often wondering how much of my laptop life expectancy I'm sacrificing on this blog post series. The worst thing being, the PCIe SSD are not replaceable... At least I think I'm done with write heavy operations as I've settled on one input format. I'm not sure what kind of performance characteristics one would get with external drives on modern USB or "semi external" solutions like "jetdrive lite" offers. Finally, to comment on SSD wear, if your cluster is rented, then it is Amazon problem to manage...
Using `static` (not `static mut`) is the go-to type to use for storing global variables, as it allows safe use of thread-safe types. That said, it doesn't solve the `Drop` issue. Fortunately, [`lazy_static!`](https://crates.io/crates/lazy_static) covers this case well, and is the go-to for storing arbitrary global data. (Standard caveat about global data: life may be easier for refactoring/more general use if there's no globals, instead passing a context object around explicitly. Of course, the slot the shared library is fitting into may not allow this.)
I'd suggest `match &amp;args[1][..]` which can be read as "borrow a slice from the first argument", whereas the dereference operator is more obscure.
I didn't know about lazy_static. Will have a look at it, thanks a lot. Passing the context around is a bit hard as I am interfacing with C#. I am very limited in that respect. I tried to transmute my context into a primitive type (Boxed context to IntPtr or an array of ints or something like that) and passing that to C#, as the C# code really doesn't care about the state in rust at all. But yeah, that didn't work either (SIGILL). 
Did you look at nanomsg.rs? https://github.com/thehydroimpulse/nanomsg.rs Nanomsg supports the following transports: * INPROC - transport within a process (between threads, modules etc.) * IPC - transport between processes on a single machine * TCP - network transport via TCP
[combine](https://marwes.github.io/combine/combine/) can do LL(k)
Oh wow, I didn't realise this! I've been doing `get_foo` and `set_foo` for ages now!
&gt; I am very limited in that respect Yeah, definitely a restriction. &gt; I tried to transmute my context into a primitive type (Boxed context to IntPtr or an array of ints or something like that) and passing that to C#, as the C# code really doesn't care about the state in rust at all. But yeah, that didn't work either (SIGILL). Hm, that's surprising to me, I suspect there might be something else going on. The conventional route would be Rust code that looks something like: struct Context { // ... } impl Context { // methods } // FFI functions #[no_mangle] pub extern fn yourlib_create() -&gt; *mut Context { let ctxt = Box::new(Context::new()); Box::into_raw(ctxt) } #[no_mangle] pub extern fn yourlib_do_something(ctxt: *const Context) { unsafe { (*ctxt).something() } } #[no_mangle] pub extern fn yourlib_destroy(ctxt: *mut Context) { unsafe { drop(Box::from_raw(ctxt)) } } One can then glue these together with some combination of `IntPtr`s and `SafeHandle`s ala [the example in The Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/objects/#c-1). (Not sure if any of this is new to you... there may be some other layer of issues totally.)
That makes sense intuitively, but note that it does not match the compiler's error message: if `args[1]` returned an `&amp;String`, the first error would be that the compiler expected an `&amp;String` and found an `&amp;'static str`, and the second error would be that the compiler expected a `String` and found an `&amp;-ptr`. Turns out while `[]` is implemented in terms of `Index` and `Index::index` does return an `&amp;T`, but `[]` "helpfully" derefs that to a `T`, so `c[i]` desugars to `*c.index(i)` rather than `c.index(i)`. 
I just saw this (quite large) pull request by /u/acrichto which adds some very interesting features to cargo: &gt; **Source redirection** &gt; &gt; […] enable replacing one [crates registry] with another […] &gt; &gt; **Adding sha256 checksums to the lock file** &gt; &gt; […] Cargo will now track the sha256 checksum of all crates from registries in the lock file. […] &gt; &gt; **Local Registries** &gt; &gt; […] a new kind of source in Cargo, a "local registry", which is intended to be a subset of the crates.io ecosystem purposed for a local build for any particular project here or there. […] Please note that these features _have not yet landed_ in cargo (and won't be available in stable for quite a while after they did land).
Good timing! I just saw [this cargo PR](https://github.com/rust-lang/cargo/pull/2361) (posted to reddit [here](https://www.reddit.com/r/rust/comments/44kxti/cargo_pull_request_add_support_local_mirrors_of/)) (which has been worked on for at least a week, though, so it's probably not because of recent events regarding Github).
Amazing work! Very necessary to ensure availability of CI builds.
You can actually abuse `Deref` to make getters and setters work "naturally". Sort of.
Yeah, that's the "sort of" :)
UNIX Sockets are pretty robust, have a long legacy (~40 years) of use in production, and are supported by both languages! 
Actually, `++` is quite infamous for working both on the next or previous item depending on circumstances; at least `?` would only work on the previous item, but indeed it's somewhat unique for now.
I read it, but... &gt; Applying and immediately reverting a migration should leave your database schema unchanged. Little known fact: you cannot remove the "default" property of a column in Oracle... (seriously, it's very problematic for testable migrations). Anyway, the crux of the matter: &gt; infer_schema!(dotenv!("DATABASE_URL")); It gives a static view of the schema at the time of compiling and we established that this version of the software would have to work with at least two version (pre/post-migration). What we would need is *multiple* representations of the schema, the ability for the software to determine at each query which version it's executing against and either: - the ability for the library to automatically account for the change (for example, stop inserting/reading/updating a dropped column) - the ability for the user to prepare a different set of queries depending on the schema version Not using an ORM, I do the second. The steps to do a migration are: 1. Write software that will work with either version 2. Load it 3. Apply the patch 4. Cleanup the software, it now works with the new version only 5. Load it Step (1) is obviously the crux here, and is generally managed by catching, at run-time the errors reported by the database ("unknown column 'xxx'" =&gt; we are on the model without xxx =&gt; switch query). Here, it does not seem like diesel handles this; instead it looks like it assumes that you have 1 version of the software for each version of the database schema and shut-down your service while you perform the migration. If I am missing something, please point it out!
We don't make decisions based on BusinessInsider articles, no.
Yes, it has more to do with Firefox's needs, and environments like them.
Unanswered Questions: * Should there be an accompanying `.shrink()` method to reduce the size of the buffer by `n` bytes? * Should it discard data from the start or the end of the buffer? * Should `Unbuffer` implement `BufRead` if the underlying reader implements `BufRead`? The utility is negligible, as it implies the user is already using a double-buffer for some reason. * Should `MOVE_THRESHOLD` be configurable per-instance, per-thread, globally, or left as a constant? * Should the data only be moved if it's less than a certain length, to avoid large copies?
Thanks a lot for your feedback! I really love this Rust community :) I think I'll play around with the mentioned libraries to get a better impression.
&gt; In the Deref trait, the deref method returns a &amp;Self::Target, not Self::Target by value. Ah yes, I always forget this wrinkle. Thanks. :)
The hard part is that you can't have multiple servers, or one that delegates to another. So you can do that easily, but then you don't have access to public crates. After that feature is added, it shouldn't be a big deal.
I always choose metal because of the easy play on words with "rust"! 😄
&gt; After that feature is added, it shouldn't be a big deal. Yay! 
As noted in the presentation, Servo itself is leagues ahead of us in this regard: http://servo.github.io/servo-starters/ (The problematic thing with Rust at this point is it's super easy for an issue to get bogged down in needs-RFC territory -- Servo has no such issue.)
 impl&lt;S: Send&gt; Postage for Box&lt;S&gt; {} 
Sweet. When we can expect next part?
It's been posted.
I think I may have miscommunicated slightly. I also really like using Cargo and think it's great at being a dependency management tool. I don't want to alter it's purpose. I suppose you're saying that you don't want rustfmt or clippy directly installed by the installer, which makes sense. I was thinking more along the lines of automatically running `cargo install rustfmt` and `cargo install cargo-clippy` (though I know the second is unstable) after rustc and cargo have been installed. Finally, I'm really wondering if there is any fundamental reason that clippy couldn't work with a particular stable (given that it ran on the nightly from 12 weeks ago). Is it just that you aren't allowed to opt-in to compiler plugins on stable?
Strange, it wasn't (and isn't) visible in "other discussions". Deleted.
`impl&lt;I&gt; Always&lt;I&gt; for Get where I: Am {}`
That's interesting. I've never seen being batteries included as an undesirable state, just not the one we're in yet. :)
Yes, our code of conduct is very important to us. The values you're expressing here are not our values.
I suggest lurking in the #rust irc channel -- or read some of the r/rust threads -- before concluding that communication is squelched by the CoC. You'll find that it has worked very well in practice. The Rust community doesn't subscribe to the notion that there's a dichotomy between intellectual discourse and kindness.
&gt; Isn't it enough to just be an adult about shit while using and talking about an awesome language? Yes, it should! And if you just want to tell someone they're wrong, rather than insult them or drag in their personal traits, you'll be fine. * Okay: “This is incorrect.” * Not okay: “This is incorrect and you are an idiot.” If you are worried that the code of conduct prevents you from making some technical point, just take out the personal bits and leave in the technical stuff. It’ll be okay.
All generalizations are false, but as a whole, overall, yes, we do.
As Steve is the [head of the community team](https://www.rust-lang.org/team.html#Community), I think he is capable of speaking on behalf of the community, no? He certainly speaks for me.
Which provisions of the CoC do you object to specifically?
Yeah, it's a great channel, but it can be a bit slow.
&gt; But in Rust, you would use a Vec&lt;int&gt;, which will first initialise all elements. (Makes a difference if the number of values becomes large …) You can properly reserve the Vec (with `Vec::with_capacity`) to avoid reallocations. But you won't be able to assign to arbitrary locations no, that'd imply the ability to read uninitialised locations.
No. In any particle's reference frame, it isn't moving, and so has zero momentum. This doesn't apply to massless particles, as you can't really be in their reference frame.
The Rust community is one of the most welcoming, nicest communities that I have come across in open source. That is because of our early work laying the expectation that members of our community engage in respectful, reasonable communication. I would rather turn off someone who doesn't treat the person on the other side of the screen as a fellow human being, than to stoop to the lowest common denominator, and have us remove what makes our community great. If you don't like it, then you don't have to take part. But I assure you, you would be missing out on the great things our community has to offer.
&gt; It encourages being outraged and taking offense I would wager you have no evidence of this. In fact, your post here is the most outrage I can ever remember seeing in a /r/rust post, about anything. It's not even close to the outrage I've seen in other places, though, which don't have a strong code of conduct. &gt; Furthermore, this is just plain nonsense: "it's your responsibility to make your fellow Rustaceans comfortable" &gt; &gt; It's not though, feeling discomfort is a reasonable reaction to being outside your comfort zone, its arguably necessary to learn something new You've misconstrued the meaning of "comfort". If someone finds learning new things stressful, it's probably because they've not been raised in an environment where it's OK to be confused and people act nicely among those who don't understand things. When someone is confused about something, saying "RTFM" makes people uncomfortable and discourages asking questions and learning new things. Giving reasoned answers and constructive dialogue, in contrast, makes people comfortable and encourages learning new things. There are, of course, reasonable complaints about this not being *our* problem, and how we shouldn't be required to suck up to unreasonable levels of "help vampirism". But it's not the case that acting hostile works any better. If you don't want to put the effort into helping a particular person, you're not obligated to. If nobody steps up, for whatever reason, it's perfectly possible to suggest further self-study in respectful and welcoming ways. If you don't understand how to do this, that's fine - other people in the community do, and will do so for you. But why do we care about this at all? It's because we deem this a moral thing to do, because we believe it fosters productive and open debate and because it makes us happy. Any criticisms you have of the policy should be weighed against these. &gt; I don't see how there could be any trust that what someone is telling you is true, or a lie designed to not cause you discomfort. Pathologically lying to people is a good way to cause discomfort, and so is explicitly against our CoC. Ergo, it's not how we expect people to resolve these things.
Me neither. But I also see the appeal of "lean, effective and extensible". In the end, it won't matter much (as long as discoverability is OK).
It's ironic that you're complaining about the existence of a CoC while simultaneously talking about "being an adult" and "hardening the fuck up".
Yes, it would, as far as I know. There was a blog post about doing some of this, but I can't seem to find it now...
Strangely enough I used exactly what you suggest. But it feels like a workaround. It's fine for my use case but I imagine if the inside of the match were more complicated this would be a lot uglier. Shouldn't there be a way to fix this with clone or something?
While that kind of CoC thing has been getting out of hand with _bad_ incarnations in other projects, Rust's one seems quite reasonable. That's basically what a team of adult, responsible community (leaders? communicators? I swear there's an official word for it; people like /u/steveklabnik1) should be doing in their posts anyway, so.
&gt; If someone is objectively wrong about something, telling them they are wrong should not come with the fear that they are going to call you a misogynist or something and that WORSE, some mod is actually going to pay attention to that. CoC aside, telling someone they are wrong is not at all constructive. If you want robust discussion about the merits of some code, talk about the code, not it's author. 
 impl Fn for BirthdayParty impl FnBox for BirthdayPresent :)
Exactly. If you are truly engaging in an honest, technical discussion, then you have nothing to fear from a CoC when telling somebody that they are wrong.
Using Redis would solve both your communication and serialization problems. Depending on the latency you require, polling, [pub sub](http://redis.io/topics/pubsub) or [**BLPOP**](http://redis.io/commands/BLPOP) could all work fine.
I think Rust is great and I hope it will be a successful language. Personally, I don't feel comfortable getting involved in a community where I may get banished by someone making a judgment that I violated a social rule. People have different cultures and find different things offensive. I'm not great at social cues and I don't want to feel like I'm stepping on egg shells and worry about everything I say. I just want to think about the technical stuff because that is what I love!
Thanks for the answer. I'm not arguing that Rust shouldn't have a CoC or that people will be banned left and right. For me it feels like having someone judge over how I express myself and it makes me a bit uncomfortable. I'm not demanding that you should change anything, I just wanted to put my 2 cents in.
Rust &gt; We are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, disability, ethnicity, religion, or similar personal characteristic. Daniweb &gt; Do not post anything with malicious intent against another member, including, but not limited to, racist, sexist or religiously prejudiced remarks I'd say Rust's CoC is broader (though they're both listing examples, so not exhaustive) but I don't think the intent there is all that different. Regarding your hierarchy comment, you'll notice what isn't on the list: code, engineering etc. No one is being given some special right to sneak in bad code.
The moderators of the Subreddit, like any other. It certainly itself violated the code of conduct, though that's hard to see in retrospect. Usually the mod that did responds with an explanation, we'll see if they do here. To be clear: asking about the code of conduct is in no way a violation; the way it was done here was very, very over the line.
 enum AreYouSure&lt;T&gt; { Some(T), }
Yessssss
&gt; keep downvoting this, you're just making my point for me. I think the point being made is that if you think that stating "Don't be an ass or treat people differently based on gender, disability, etc" is somehow a step too far, then you are not the target consumer of the rust community. The 'more neutrally' worded CoC you linked is not any more neutrally worded - it explicitly states that gender, race, etc, should not be a factor in an argument or called out by a member of the community. &gt; Do not post anything with malicious intent against another member, including, but not limited to, racist, sexist or religiously prejudiced remarks &gt; Do not post insults or personal attacks aimed at another member &gt; Do not use offensive or obscene language Let me put it this way. Based on your posts, you're worried you're going to step on someone's toes by saying the wrong thing. Basically, I've never seen this happen. You mentioned not really getting social cues, and I understand that it's even more difficult to do so on the internet when you're not face-to-face and a lot of context is lost. Perhaps as a way to make it easier on yourself, as a general rule of thumb, try to stick to the facts, and try to limit those facts to code/ CS related content. If you find yourself writing about a person, there's a solid chance you're contributing something that's not really important to the discussion.
I don't remember the exact wording of the question, and now I can't go back and re-read it, but at the time it did not strike me as "very over the line". I would have preferred that the moderators posted a statement and, possibly, locked the thread,- though the rest of the discussion was very civil. Simply "disappearing" a post without explanation may be construed as punishment for asking "a wrong question". This kind of thing is, IMO, what fuels a lot of distrust towards forum moderation and codes-of-conduct in general. Surely not what we want here, eh?
It would be good policy to make a comment when a post is deleted, especially one with active discussion, to avoid any perception that enforcing the code of conduct is shameful or underhanded.
Thanks, I will give that a try.
I was there in person - it was a fantastic talk and it only inspired me more to sit down and actually start learning Rust!
Just started learning Rust last week following /u/QEDunham's excellent talk at linux.conf.au. Going to keep doing that this week - I'm currently working through http://cryptopals.com at home, and at work I'm hoping to contribute to a small continuous integration tool that one of my colleagues has started writing to help us test one of our firmware products.
im just starting rust and it's all very much magic and sorcery to me, I'm going through [this guide](http://rustbyexample.com/hello/print/fmt.html) and doing the activity in it. what I have so far is [this](http://pastebin.com/qW5pppYL). but what I want to know is if I have to do it this way. including the variables twice just so I can turn them into hex values seems kind of ugly.
I'm not sure there are much fancy ways you could solve this no, since its just how it seems to work, but you could write a macro for you macro ;) `write_rgb!(f, r, g, b);`: macro_rules! write_rgb { ($f:ident, $r:ident, $g:ident, $b:ident) =&gt; { write!($f, "RBG ({0}, {1}, {2}) {3:#02X}{4:02X}{5:02X}", $r, $g, $b, $r, $g, $b); } } 
Resource clean up should happen during `Drop`, making `finally` unnecessary. There's some weirdness around what happens if a panic happens during a `Drop` while the thread is already unwinding that I have never bothered to learn about, but I don't know if that would justify adding an explicit `finally`.
Finally would be useful for exception-safe unsafe code: https://github.com/rust-lang/rfcs/issues/1010
This is technically under using macros, but if you have other use cases you could do things like have patterns for hex only, patterns for rgb only...: - `($r:ident, $g:ident, $b:ident) =&gt; { ... };` matches to `(r, g, b)` - `(# $r:ident, $g:ident, $b:ident ) =&gt; { ... };` matches to `(# r, g, b)` - `(RGB $r:ident, $g:ident, $b:ident ) =&gt; { ... };` matches to `(RGB r, g, b)` - `($f:ident, $r:ident, $g:ident, $b:ident) =&gt; { ... };` matches to `(f, r, g, b)` All under a single macro rule, because pattern matching is pretty powerful and simple, multitude of options just based on patterns. 
&gt; Personally, I don't feel comfortable getting involved in a community where I may get banished by someone making a judgment that I violated a social rule. I don't like telling this story but I need to. One of my earliest experiences with someone from the Rust community was a small but negative one. I didn't feel comfortable telling them off because I am terrible at social cues too and I bend over backwards to be 'polite' as a rule. But that incident - and my own non-reaction to it - left a sour taste in my mouth and I basically dropped learning Rust for a while as a result. The fact that Rust has a decent CoC and leadership with a history of willingness to enforce it _and not copout CoCs like NCoC_, is a HUGE deal to me. I know that if I had asked the person to stop their shitty behavior, I would have had someone with more clout supporting me. That's not something that is easy to find, in a world where it's normal - to the point that if this wasn't /r/rust but /r/programming or something, I'd expect someone to do this to me now which is why I don't share this story - to call me a liar, ask for proof I can't possibly have about a brief physical encounter, or even tell me that I should enjoy the attention I got (lmao!). Lastly, I will have you know that the incident was nothing like 'stepping on eggshells' or cultural differences. CoCs can and do try to cover real behaviors that are far, far worse than the occasional angry slip-up or ill-chosen word in a second language. I think it would be prudent to remember that the next time you're worried :)
Depends, how do you feel about static typing?
It'd be an interesting experiment for sure!
Well, Rust is a *very* different language to both C# and Go. For one thing, it has a much stricter and more powerful type system, including borrowing and lifetimes. On the other, there's no conventional OO to be had, so you often have to seriously re-think your designs. That said, not having a GC is great. I suppose it's really down to what, specifically you're writing.
I removed it while reviewing the reports in the modqueue. At the time of removal it had been live for several hours and was sitting comfortably in downvote oblivion. I removed because it's obviously not trying to invite civil discourse ("cancer", "tumblr", "hardening the fuck up") and is laden with presuppositions. It's the sort of instant-outrage drama-seeking that we strive to prevent. I chose not to leave a top-level response because of the wealth of outstanding responses in here already.
the lowest setting that I know to run CS:GO is: Intel Core i3 370m 2.40ghz 4gb ram Nvidia 310m 1gb &amp; Intel Hd Graphics 1000 Windows 7 Home Premium 64bit So, yes. Your PC can run rust. goto www.rust-lang.org, download rust 1.6 for windows 64 bit, select gnu version, I don't think you need msvc version yet. Rust is little hard learn but documentation is awesome. Have fun for your rust exploration! 
I sure would like contracts andinvariants in both c# and rust
I was inspired by /u/yupferris' work on a Nintendo 64 emulator to start writing a Game Boy Advance emulator. So far it emulates two different instructions! I'm keeping the source close to my chest right now because I'm ashamed of how little I've documented it, but I took a couple of screenshots to show people stuff ([1](https://i.imgur.com/7HjRvUI.png), [2](https://i.imgur.com/7cjWIm8.png)). There's at least one visible bug, see if you can spot it. ☺
Oh I was confused, thought this was the subreddit for the game.
Hey cool, awesome to see even more emu's in Rust :D Good luck with the project! (and hope to see it open-source sooner rather than later; who cares about documentation for unfinished code anyways? ;) )
Probably, yes. &amp;nbsp; &amp;nbsp; "... yes, ok, but *why?*" Oh, if you wanted to know *that* you should have asked! If the `v` given *is* valid UTF-8, then it's completely wasteful to do an allocation; you can just transmute the `&amp;[u8]` to a `&amp;str` and everyone is happy. On the other hand, if you want to replace one or more codepoints, you *have* to do an allocation. `Cow&lt;'a, str&gt;` lets you have both. At a guess, I'd say it was changed from `String` to `Cow` at some point, but the docs weren't updated. \**pokes /u/steveklabnik1*\*
Perhaps try the #rust-osdev IRC channel (https://chat.mibbit.com/?server=irc.mozilla.org%3A%2B6697&amp;channel=%23rust-osdev), which seems to support embedded questions as well.
If I may ask a question too: I'm currently struggling to figure out the best way to have a struct member which is only available in debug mode. In C I could write: struct Foo { type1_t member1; type2_t member2; type3_t member3; #if DEBUG type4_t member4; #endif } But how do I do the same in Rust? It doesn't seem possible to apply `#[cfg(debug)]` to a single member and I really don't want to write the same _huge_ struct 2 or more times just because some builds will have an additional member... That really wouldn't be DRY at all.
Related - https://github.com/raymontag/rust-keepass
I think the issue is that it returns `Cow&lt;'a, str&gt;` instead of `Cow&lt;'a, String&gt;`. Interestingly, "res" in the implementation itself is of type `String`. http://doc.rust-lang.org/src/collections/string.rs.html#482 Illustration: http://is.gd/diQpNc
&gt; I think the issue is that it returns `Cow&lt;'a, str&gt;` instead of `Cow&lt;'a, String&gt;`. That's *impossible*. `Cow` is defined as: enum Cow&lt;'a, B&gt; where B: 'a + ToOwned + ?Sized { ... } `B` is the **borrowed** type, not the owned one. `ToOwned` is implemented by `str`, `[T]`, `Path`, *etc.*, **not** `String`, `Vec&lt;T&gt;`, `PathBuf`, *etc.* &gt; Interestingly, "res" in the implementation itself is of type `String`. So? Line 464 shows the early return for the case where the entire input is valid UTF-8. &gt; Illustration: I don't understand what this is illustrating.
You need to put the `#[macro_use]` or `#[macro_export]` attribute before your module or your macro [docs](http://doc.rust-lang.org/book/macros.html#scoping-and-macro-importexport).
Where is /u/Quxxy when you need him?
I think the documentation should go more into what Cow is useful for. Cow is supposed to be used for variables that may or may not be owned, but act as if they were owned in case they need to (by calling to_owned on the referenced object). Cow&lt;'static, str&gt; is super useful if you are dealing with lots of string literals, but some dynamically created String objects. With the Cow you can just use the string literals without any .to_owned() calls, while still being able to store the owned String objects. Since you don't see this used a lot, and the documentation doesn't go into a lot of detail on that (unless you specifically go to the documentation of Cow), most people are fairly confused. The first template parameter is the lifetime of potential references the Cow is supposed to store and the second parameter is the borrowed type.
If you `BirthdayPresent.unwrap()` and found `None`, would you panic? :-)
You probably wanted to link to the PR instead: https://github.com/rust-lang/rust/pull/30629 I wanted to try cross-compiling to emscripten myself, then write a quick tutorial and post it on reddit. Unfortunately I couldn't manage to make it work because for some reason [the "TargetMachine" can't be created](https://github.com/rust-lang/rust/blob/8c604dc940c35e4ac36012aa85375250f2e6e07e/src/librustc_trans/back/write.rs#L219-L222) for "asmjs-unknown-emscripten", even if I tweak some build files to force the compilation of the JS backend. The PR says "this is not sufficient for actually compiling to asmjs since it needs additional LLVM patches.", so I'll wait for these. 
/r/playrust
I like your last solution! I whonder if that could be transformed into a wrapper struct... If I understand the `cfg-if` macro correctly it should allow me to define actual compile-time if-else clauses, right? If that would work within methods, I could at least prevent having to define your `debug_assert()` methods above twice and can instead use a regular `if`. In that case this could actually solve almost all of my issues with this!
I'd like to [plug](https://llogiq.github.io/2015/07/09/cow.html) an old blog post of mine here, because it seems apropos.
Ah, oversaw that in the morning. I still assume that that's where the confusion comes from.
Yeah, this was because I was trying really hard for consistency, and then slipped up. /u/mhd-hbd would you open an issue for this, please? EDIT: Nevermind, I found the time to just write the patch today: https://github.com/rust-lang/rust/pull/31500
Oh, yeah I didn't realize that was the bit you needed, I could have told you :(
/u/cmrx64 please take a look at site's server configs, multiple users have reported that the site doesn't work with http:// in some browsers (for me, it redirects to https://). More info: https://twitter.com/ZanLynx/status/695522830763462656 and https://twitter.com/ZanLynx/status/695522583639302146 Here's one screenshot by @ZanLynx https://t.co/GiJrwcHHLp
Your example isn't complete, so I'm wondering... do you perhaps implement `std::ops::Neg` for `Integer`? Because if you do, it's probably because you're calling `Neg::neg` rather than `Integer::neg`.