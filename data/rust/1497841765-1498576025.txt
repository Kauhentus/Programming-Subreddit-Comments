Should probably use the `xcb` crate
Just curious, why are you working on this?
The name is too confusing, given that a major client API framework in Python share the same name. I don't want to search for "tapioca Facebook API" and not be sure what language the answers belong to. I think you should change the name while you can!
I'd sure like to see the numbers behind such a claim. Obviously, learning new stuff should be beneficial on average, but then you have the choice to learn the language you already use deeper, or gather more knowledge of your target domain or learn something else entirely. In this continuum, the choice of learning another language you likely won't use isn't at all a clear winner.
Only if N + 1 + 1 == N + (1 + 1) which isn't fundamental, that requires associative addition. Normally (N + 1) + 1 is the order and unifying those is more complex.
Re 1: There is no difference. In both cases the variable would be of type reference to i32. The ref keyword is useful in more complex binding situations such as let x: Option&lt;i32&gt; = Some(42); if let &amp;Some(ref r) = &amp;x { // ... } to create references which wouldn't be possible otherwise. However, an [RFC](https://github.com/rust-lang/rfcs/blob/master/text/2005-match-ergonomics.md) just got accepted that is intended to improve ergonomics. With this RFC, you could also write if let Some(r) = &amp;x { // ... } and have r still be a reference that points to the i32 inside of x. (This is not yet valid code) 
Re 2: I'd say Rust's references are closer to C++ pointers than C++ references in that there are expressions of that type with some addresses being the values of those expressions. There are only two differences between C++ pointers and Rust references: (1) Rust's referenfes are not nullable and always valid and (2) You don't need an arrow operator to access members of the pointee in Rust. The dot operator already dereferences as many times as necessary. So, there is no need for you to do it explicitly. And no other situation comes to my mind right now where a reference could be explicitly dereferenced but does not have to be. **Edit:** I've seen (and used myself) sometimes `&amp;*foo` to explicitly trigger the `Deref` trait or explicitly "reborrow" something. Due to Deref coercions `&amp;foo` should work in many of the Deref cases. Silly example: fn show(s: &amp;str) { println!("{}", s); } let o = String::from("hello"); show(&amp;*o); // String implements Deref&lt;str&gt;, so &amp;*o is of type &amp;str But I guess you will have a hard time finding real code that does this sort of thing. Instead, you'll see show(&amp;o); where a `&amp;String` is implicitly converted to a `&amp;str`. In *generic contexts* where the target type isn't fixed like above (`s` is declared as `&amp;str` in `show`) an explicit dereferencing still might be useful/necessary.
Most of the underlying complexity of cgo noted in the post above is less matching semantics (most of *that* is under the cover) and more *declaring* them. In Rust, you have to handroll your bindings — possibly via bindgen, in cgo you just use the thing (and there's a big mess underlying it to discover and generate bindings), other languages (based around libffi) take the C/.h source and automatically generate the glue.
This needs some further work on the gstreamer-rs and possibly gtk-rs side first. See my replies here https://www.reddit.com/r/rust/comments/67atdi/gtkrs_gstreamer_how_do_i_get_the_video_and_audio/ and https://www.reddit.com/r/rust/comments/6b3huc/gstreamer_and_rust_a_perfect_match/dhjyq9x/ Actively working on that in any case
Working on my filesystem dumping library. The filesystem is in OCaml, but there's an inspector in Rust. It uses Serde and bincode.
[ircfs](https://github.com/sector-f/ircfs), which is an IRC client that uses FUSE to link IRC channels to files. Basically a FUSE version of [ii](http://tools.suckless.org/ii/). Rust is the first "real" programming language I decided to learn, and this is probably the most complicated thing I've worked on so far. Plenty of multithreading, and `Mutex`/`RwLock` for interior mutability. Honestly, at this point, I really want someone who's more experienced than me to look over my code and tell me what they think of it before I get carried away implementing features. My main concern is how I'm using `Sender` and `Receiver` to get the filesystem and the IRC stuff to communicate with each other. Replies to this comment, issues on GitHub, and messages on IRC (I'm `LambdaComplex` on Mozilla's network) would all be appreciated!
Finishing a blog post about extension traits and looking into finally writing one about testing. Also some small stuff in my [meme library &amp; server](https://github.com/Xion/rofld).
[ramp](https://crates.io/crates/ramp) is the usual recommendation.
Are [associated types](https://doc.rust-lang.org/beta/book/first-edition/associated-types.html) fundamentally different to regular generics? Do they provide any value other than saving some typing on function signatures?
Use [`num::pow::pow`](https://docs.rs/num/0.1.39/num/pow/fn.pow.html) function. extern crate num; use num::BigUint; use num::pow::pow; fn main() { println!("{}", pow(BigUint::from(3u32), 1000)); } 
Going to release 0.0.7 of [Gutenberg](https://github.com/Keats/gutenberg) and try to have Sass built-in. Linux/OSX shouldn't be an issue for that but I didn't manage to have Sass building correctly on appveyor and I don't have a Windows machine available. See https://github.com/Keats/gutenberg/issues/73 for more details
Respect- and beautiful discussion. Love how they acknowledge and encourage each other in their strengths. Gotta love 4chan&lt;/s&gt; IMO, there isn't any fruitful discussion going on there. Except that people seem to be confused about the actual adoption of Rust. I suspect that people actually want to use rust, but fear long term punishments, as Rust might not flourish. A little bit of the chicken-egg problem. Rust could be a little bit more advertising, there are success stories, e.g. the dropbox engineers, they had a talk recently, but such stories have to be written down and "advertised". Seeing other companies actually betting their money on it and not only advertising is extremly powerful. Having Logos on your friends page is nice and all, but it won't convince engineers, which strive for actual improvements. I know that this is a little bit in conflict with the rather humble rust community, but it could create valuable momentum (aside from RIIR). Edit: perfect example of advertising done right is the outstanding talk from /u/nikomatsakis on c++now
There is a somewhat subtle difference between them, consider the following: trait Animal&lt;T&gt; {} struct Bunny {} impl Animal&lt;i32&gt; for Bunny {} impl Animal&lt;f64&gt; for Bunny {} impl Animal&lt;()&gt; for Bunny {} Here, several implementations of `Animal&lt;T&gt;` can exist for the same type `Bunny`, however, when associated types are used: trait Animal { type T; } struct Bunny {} impl Animal for Bunny { type T = i32; } Only one implementation of `Animal` for `Bunny` is allowed, and if you try to implement again for when T = f64: impl Animal for Bunny { type T = f64; } This error appears: error[E0119]: conflicting implementations of trait `Animal` for type `Bunny`: Essentially, associated types are different from generics in that they only allow one implementation of the trait for each type. They are also related to the concept of "type families", and an example of their use case can be found [here](http://cglab.ca/~abeinges/blah/rust-reuse-and-recycle/#associated-types-1).
&gt; It didn't annoy me before but I've done it so many times that it has become a bit irritating You could add a method like [`Option::expect`](https://doc.rust-lang.org/std/option/enum.Option.html#method.expect) to your `Phase` type, so you can write let (a, b, c) = self.phase.expect_something("only works in Something phase"); Altgernatively you might want to create a method like [`Option::ok_or`](https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or) that returns a `Result&lt;T,E&gt;` and use the question mark operator: // assuming PhaseError is a unit struct for the error case let (a, b, c) = self.phase.tuple_or(PhaseError)?; IMHO, the preferred choice depends on which kind of error this is (logic or runtime).
I have a question about Cargo features. The 1000 foot view: As the end result, I want to be able to use the `dotenv` crate without enabling the `backtrace` feature in `error-chain`. This is why I'm preparing a PR to make the `dotenv` to work both the `backtrace` enabled and disabled. The crate `error-chain` has a feature called `backtrace`. Then there's a crate called `derive-error-chain`, which doesn't have features, but a attribute `error_chain(backtrace = "false")` that toggles whether the derived code that supports and requires backtraces is generated or not. In my fork of the crate `dotenv`, I'm trying to parametrise the dependence on `backtrace`. I set the `default-features` of `error-chain` to false to not make `backtrace` enabled by default. In addition, I made the derive code in `dotenv` to depend conditionally on the `backtrace` feature like this: #[derive(Debug, error_chain)] #[cfg_attr(not(feature = "backtrace"), error_chain(backtrace = "false"))] pub enum ErrorKind { Question number one: would it be possible to implement the code generation based on the feature directly inside the crate `derive-error-crate` so the libraries that use it wouldn't have to care about setting the attribute? If it is, and if it is a desirable design, I'm thinking of sending a PR to `derive-error-crate` too. Question number two. Here's an excerpt of my `cargo tree`: mybinary v0.1.0 (file:///Users/USER/repos/mybinary) ├── dotenv v0.10.0 (https://github.com/golddranks/rust-dotenv.git#f87ee2e2) │ ├── derive-error-chain v0.10.1 │ ├── error-chain v0.10.0 │ │ └── backtrace v0.3.2 ... ├── error-chain v0.10.0 (*) ... The `cfg_attr` code in `dotenv` detects that the feature `backtrace` is enabled and it tries to derive the code that depends on `backtrace`. This results to compilation error. It's as if the `error-chain` of `dotenv` doesn't have the `backtrace` enabled after all, since it can't find the APIs enabled by the feature! Is this a bug, or am I missing something about how the features work? 
ohhhhhhh ok yes i see now!
i said: I'm using num_bigint crate
Both "calm" and "slowdown" seem to be free. Combine it with "futures" perhaps and you got yourself a nice name.
num::BigUint and num_bigint::BigUint are the same type.
Question number three: Is it possible to "forward" a feature? Let's say that I introduce a feature `backtrace` to `dotenv`. Is it possible to set `backtrace` of `error-chain` on or off conditionally depending on whether the `backtrace` of `dotenv` is set or not? I couldn't find anything but depending on crate granularity here: http://doc.crates.io/manifest.html#the-features-section
I know. but my question isn't about that.
How to do "pow" using only num_bigint crate.
There is no good way to do this, num_bigint just does not implement pow. You can copy and paste num::pow::pow implementation yourself.
Roger that
posting a 4chan link to Rust again? this one wasn't well received either, because both of these discussions are not productive ones.
Very cool. Since I'm working on a similar/related project ([json_typegen](https://github.com/evestera/json_typegen)) I obviously think this is a good idea. :) One of the current challenges with such code generation tools is the lack of autocomplete, since no tools (AFAIK) expand macros when generating autocomplete info. I'm exploring ways to work around that, like also providing the codegen through alternate interfaces ([website](http://vestera.as/json_typegen/) and [CLI](https://github.com/evestera/json_typegen/tree/master/json_typegen_cli)) which can then be used along with conditional compilation to get both generated code in source control and verification against a remote resource. (Example/further explanation in the project readme). Another approach I'm looking at is to make it possible to expand macros inside the editor. Since I'm currently using Atom I'm throwing together a plugin that expands my own macro inline just to explore the idea. ([The incomplete Atom package](https://github.com/evestera/atom-json-typegen)). Since I'm dealing withe JSON, to get the same macro to accept local, remote and inline samples I'm just using [a simple "starts with"-check](https://github.com/evestera/json_typegen/blob/master/json_typegen_shared/src/lib.rs#L369). I see you are also dealing with YAML though, so might not be as easy?
My passion for Rust knew no bounds, but now that I've read that Mozilla has been "cucked" I'm going to have to do some soul searching. 
Still working on native-windows-gui. The progress is steady and the changelog [slowly adds up](https://github.com/gabdube/native-windows-gui/blob/dev/CHANGELOG.md). I will probably focus on finishing the treeview.
What does this comment mean? People evidently think very well of it, but my brain is too meagre to grasp why.
What you've got seems sensible. Rather than having separate vecs for each log message, i'd be tempted to serialise them all, with type tags, into a big per-thread preallocated byte buffer as they are generated (via std::mem::transmute or similar). At exit, you either transmute the events back into objects to write them out, or dump out the buffer, and reconstitute it offline. If you don't have enough memory to buffer everything, you can have the mutator threads hand buffers to a background thread to be written to disk and reclaimed. You'd need to do double-buffering or similar to do that safely. If the buffers are big, all the background thread is doing is receiving from a queue and kicking off a write system call. All that might well not be any faster, though. You avoid reallocating vecs (although you could do that in your current code by using Vec::with_capacity), and you have a single stream of writes going to memory, rather than several, which might play better with caches, although that's pure speculation, really.
Wrote a README for my command-line libmpv/youtube-dl-based music player: https://github.com/sevagh/surge I haven't published newer versions on Crates.io yet so you'd have to build from source.
I had to take a bit of a hiatus for personal life reasons but have been recently been able to get back to [pvm](https://github.com/amarmaduke/pvm) (Parsing Virtual Machine, a parsing library that takes in grammar files and gives you a virtual machine to recognize text). The biggest issue I was facing last time was left recursion. The machine is based off of PEGs (Parsing Expression Grammars) so left recursion doesn't really come free but I was basing my work off a couple of research articles on the subject. Unfortunately the virtual machine specification in these articles (at least in my opinion) was incorrect, so I had put in more effort than I originally thought to adapt the informal algorithm (which in my opinion is correct) to get left recursion working. Right now on my branch I think things are working pretty well and I feel like I'm well on my way to having a 0.1 release soon! So that's kind of exciting.
That's a rustup thing. It's not well-documented, but if you are running cargo through a rustup shim, you can prepend the arguments with `+version` to run a particular version of the command: https://github.com/rust-lang-nursery/rustup.rs#examples I think perhaps it should be `cargo +nightly install clippy` rather than `cargo install +nightly clippy`, but i'm not sure.
Try wrapping lines 18-30 in braces so they're in a nested block.
Hey, I just wanted to let you know that I used rust-gnuplot all last semester for my modeling projects. It was really a pleasant experience.
Had somehow completely forgotten about expanding with `--pretty=expanded`/cargo-expand. Thanks for the reminder. Sad that it will be removed from stable with no replacement (except for nightly) in 1.19. How did you set up things to get autocomplete from a temporary file though? Did you just replace the original temporarily?
It's referring to the last sentence in my post. Do people prefer the syntax `cell.open_mut(sync_key)` or `sync_key.open_mut(cell)`? Evidently, people like the former. Me too.
Yes.
&gt; Because then I won't be able to add a comma after the last field! $(things),* $(,)* It allows for degenerate cases like `things,,,,`, but you can't win 'em all. &gt; The experimental vis macro type is supposed to solve this: It can't decide between the repetition and the capture. You can get around this by *just* matching the problematic prefix, and forwarding the rest to a common sub-rule. macro_rules! default_new { ( @with_attr [$( #[$attr:meta] )*] $visibility:vis struct $name:ident { $($field:ident : $typ:ty = $value:expr),* $(,)* } ) =&gt; { $( #[$attr] )* $visibility struct $name { $( $field : $typ, )* } impl $name { $visibility fn new() -&gt; Self { Self { $( $field: $value ),* } } } }; ( $(#[$attr:meta])* struct $($tail:tt)* ) =&gt; { default_new! { @with_attr [$(#[$attr])*] struct $($tail)* } }; ( $(#[$attr:meta])* pub $($tail:tt)* ) =&gt; { default_new! { @with_attr [$(#[$attr])*] pub $($tail)* } }; } As an aside, it would make sense to have this macro implement the `Default` trait, perhaps with `new` deferring to that.
That did indeed fix it!?
I am all for collaboration. I actually looked at your hotkey library before making mine, and it lacked two things for me: mouse hotkeys, and having separate hotkeys for Up and Down events. The hotkey register function in your library would need to take an enum of some sort. The mouse has many events: move, scroll, and clicks. I could work on doing this for the Windows part of your library, but I have no experience with Linux in this area. Also, is there really a need for creating multiple hooks (it is just hard for me to understand how some of your code works because of multi-threading).
Speaking of the optional `pub`: Usually, when you want to parse an optional token, you just use the `$( ... )*` (as u/Quxxy showed with a trailing comma). So if you try to use `$( pub )*`, it works, but there's now way of recovering the information about how many `pub`s there were. Fortunately, there's a workaround for that! macro_rules! default_new { ( ... $(pub $( invalid_token $pub_was_parsed:tt )* )* ... ) =&gt; { ... $(pub $( $pub_was_parsed )* )* ... }; } The `pub_was_parsed` is never actually used, because `invalid_token` never occurs in the code. Its only purpose is to help the Rust macro machinery to match the input `pub`s to the output `pub`s. (Note: if we use `( $( $tt:tt )* )` instead of `invalid_token` we can also parse the new visibility rules. I've shown the `invalid_token` as a general approach to handle optional tokens) Unfortunately, this doesn't work for the `pub` in the struct fields, as macro tries to parse `pub` as `ident` which results in ambiguity (is this on purpose? `pub` is not a valid ident in Rust).
Huh. That's a neat trick. `$v:vis` *should* handle optional visibility, though. Without it, I usually just have separate rules for `pub` and no `pub`, expanding to `{pub}`/`{}` for the sub-rule. In the sub rule, you can then match `{$($v:tt)*}`, and expand to `$($v)*`. As for keywords-as-idents; from what I recall, the compiler basically treats *everything* that looks like an ident as an ident, and does checks for "special" idents in various places. So keywords *are* idents, except when they aren't.
For the join efforts part i have implementation for Win, Linux and macOS in my [enigo](https://crates.io/crates/enigo) crate for sending events with some rough [documentation](https://docs.rs/enigo/0.0.10/enigo/), Continuous Integration for [Linux, macOS](https://travis-ci.org/enigo-rs/enigo) and [Windows](https://ci.appveyor.com/project/pythoneer/enigo-85xiy) a [github-organisation](https://github.com/enigo-rs/) and a chat for [gitter](https://gitter.im/enigo-rs/Lobby) or [discord](https://discordapp.com/invite/Eb8CsnN) with discussion about the project, further application etc. i would love to see a discussion and would invite all to join forces.
`pow` works for any type that you can multiply. It is implemented in the `num_traits` crate, because it works for more than just bigints. Note that the `num_bigint` crate already depends on `num_traits`, so you are not saving anything by not using it.
A better solution that does not pull in unrelated crates would be using `num_traits` and `num_bigint` directly.
I've never used Wren but it's so adorable I should change that.
Working on my slides for the Toronto Rust meetup next month... all about the what and why of ggez. Also considering writing something about library API design in Rust. I'm not an expert but I've stubbed my toes on other people's libraries a fair amount by now... would anyone be interested in such a thing?
Just by dumping the output into e.g. `tmp.rs` (so it's recognised as a rust file) within the same project seems to work with vim &amp; rust-lang/rust.vim, I assumed that it's using the contents of the current git directory and that's reasonably common for such tools, but I could be wrong about why it's working - it was a happy accident that I've continued to exploit. Potentially it could also be due to having opened `tmp.rs`, which makes me think that a 'jump to definition' style plugin that ran expand on the macro invocation and opened a buffer (or Atom tab, etc.) with the contents would be pretty great.
pow is implemented in num crate.
I finished implementing all of the floating point operators for [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) and next up I'll probably add a number of common quantities. Also considering using traits from the `num` crate.
I did 1 course a semester for my masters (I was working full time in addition) and it took me ~3 years. General rule is 10 courses for a masters (30credit hours) in the US. Though 5-year undergrad/grad programs are more and more common now. 
OP here: after publishing my [blog post on progress on the AVR front](https://gergo.erdi.hu/blog/2017-05-12-rust_on_avr__beyond_blinking/) last month, several people contacted me asking for detailed build instructions. I've finally gotten around to getting Xargo working (which makes the process at least a little bit easier), and writing it all down.
Thx! There is not much testing going on here for real applications and this is valuable information.
No, it's merely re-exported in the num crate...
I have rustup installed. That's how I have installed nightly before and how I keep rust up to date.
You could also separate out the `Something` like data into an encapsulating type. That basically isolates the `enum` from the data and you can do let Something { a, b, c } = match self.phase { Phase::Something(data) =&gt; data, _ =&gt; bail!(...), }; or let something = match self.phase { Phase::Something(data) =&gt; data, _ =&gt; bail!(...), }; let some_b = something.b; so you only have to work with the fields you actually need. 
Oh, you probably don't have the nightly toolchain installed. Edit: Wait, no, you mentioned that you did. Perhaps it's `cargo +nightly install`
Why don't you use the unicode version of the api (`W`) instead of the ANSI one (`A`) ? 
OK, thanks to your help I now understand how to work around these limitations, and since I'm a Rust newbie, I've decided to complete this macro for practice: * As /r/Quxxy suggested, I'm implementing `Default` instead of adding `::new()`. `::new()` can be added manually, with actual arguments. * Since some types have their own default, I can delegate to that when no default is specified explicitly. With sub-rules it's easy! * I'm also adding visibility control to the individual fields. Here is my complete implementation. Any criticism would be appreciated. #![feature(macro_vis_matcher)] macro_rules! super_default { // Collect all attributes in parenthesis so we can parse them without interfering with $vis ( @collect_attrs ( $( #[$attrs:meta] )* ) #[$attr:meta] $( $tail:tt )* ) =&gt; { super_default! { @collect_attrs ( $( #[$attrs] )* #[$attr] ) $( $tail )* } }; // The actual rule that creates the struct ( @collect_attrs ( $( #[$attr:meta] )* ) $vis:vis struct $name:ident { $( $fvis:vis $field:ident : $typ:ty $( = $value:expr )* ),* $(,)* }) =&gt; { $( #[$attr] )* $vis struct $name { $( $fvis $field : $typ ),* } impl Default for $name { fn default() -&gt; Self { Self { $( $field: super_default! { @decide_field_default $( $value )* } ),* } } } }; // Default value for fields that have their default value set as an expression ( @decide_field_default $value:expr ) =&gt; { $value }; // Default value for fields that don't have default expression - use the type's default ( @decide_field_default ) =&gt; { Default::default() }; // Entry point ( $( $tt:tt )* ) =&gt; { super_default! { @collect_attrs () $( $tt )* } }; } super_default! { #[derive(Debug)] pub struct Foo { pub x: i32 = 10, pub y: i32 = 20, pub z: i32, } } fn main() { let foo = Foo::default(); assert_eq!(foo.x, 10); assert_eq!(foo.y, 20); assert_eq!(foo.z, 0); println!("{:?}", foo); } 
There might be leaks but I don't know how I would fix them. Yes I can wrap the whole thing in an unsafe.
I would not sweat the single heap allocation as I think the author meant he would like to have the buffer as a long-lived object anyway. I tried doing a version using a stack-allocated buffer, but ran into an issue of `write_fmt()` not returning the amount of bytes written, which then prevents you from knowing which of the data in the array is garbage. 
If you wrap the array with `Cursor` I think you can check the position afterwards. Haven't tried it though...
Not a Rust expert, but there’s no reason to check that printing to STDOUT or STDERR was successful.
This isn't a check about whether printing to stdout or stderr was successful or not, but rather a check about whether or not the command was successful or not (aka returned EXIT_SUCCESS) I think. Or you meant that I should simply print both stdout and stderr without checking if the command was executed successfuly? Edit: oh, you were talking about my eprintln and eprint macros… sorry I didn't understood correctly.
I'd use that if it was in a crate :)
Thank you very much for your quick review! I like the `for remaining in (0..repeats).rev()`! But how would I manage the case of the infinite loop? (when --repeat option is not passed) &gt; Printing only stdout or stderr depending on success might not be useful with all commands. So you suggest printing both stdout and stderr? I agree indeed. &gt; Taking the command with arguments in a single argument will make it your job to split the args Do you mean that I can do `Command::new(full_command)` instead of `Command::new(command_name)` and adding arguments separately? I didn't know that! That's much better now. Thanks again! 
&gt; I like the for remaining in (0..repeats).rev()! But how would I manage the case of the infinite loop? (when --repeat option is not passed) Sorry, I've overlooked that. In that case you could either use two different iterators, `(0..repeats).rev()` and `std::iter::repeat(0)` and iterate over a `Box` of it or factor out one repetition and do it like this: match value_of("repeats") { None =&gt; loop { do_one() } Some(v) =&gt; { // parse v for remaining in ... { do_one() if &gt; 0 { print } } } } In the end though, I don't know if it's better than the current solution. By the way, you can assign validators in clap to make it ensure that args are already integers etc. &gt; Do you mean that I can do Command::new(full_command) instead of Command::new(command_name) and adding arguments separately? I didn't know that! That's much better now. No, arguments still have to be passed separately. But instead of using `command.split_whitespace()` I would make clap take any number of additional arguments and use them as args to the `Command`. Then, the user can use their normal shell quoting mechanisms to e.g. pass an argument that contains whitespace.
That would be a good idea. To my knowledge, using the ansi API is slowly getting deprecated (but Windows being windows, they will never truly go away). You can read more here: https://msdn.microsoft.com/en-us/library/windows/desktop/dd374089(v=vs.85).aspx
Thanks. I swapped all of the functions to the Unicode versions.
Most packt books aren't worth the time to read them, with a few exceptions. This isn't one of the exceptions.
Why are you averse to using the `num` crate?
Wow, the Wren source is [really well written](https://github.com/munificent/wren/blob/master/src/vm/wren_vm.c). I barely know C and didn't have any trouble understanding it.
Is there a way to disable (or at least warn) about redefining an immutable variable with let? Example: https://play.rust-lang.org/?gist=80d0e273f358bd42b0ba0fe6960be1fa&amp;version=stable&amp;backtrace=0 I realize an experienced Rust dev probably wouldn't do that... but as an inexperienced one, I've accidentally done that a few times. This effectively hides the fact that we're changing an immutable var!
I for one found it entertaining. There's something glorious about a gang of idiots fighting wildly, as long as you're not involved. Moreover, i wasn't aware of this change to Swift until i saw this, so it was indirectly useful. EDIT: also, i have learned the useful typo "cabbage collected".
I disagree. Rust highly encourages stack allocation, so we can expect rust code to have relatively large stack sizes (iirc: comex did a brief check on some projects and found this to be the case). This isn't a small thing, it's just something no one's really looked at yet. I also don't think that anyone should discredit the statement based on the author, who is easily an expert in this area.
While I can't speak for them, I *highly* doubt it. If I were you, I would rename to `wren`, push a 0.2 version of `wren_rust` to crates.io with the description "Moved to https://crates.io/crates/wren" or something like that, then yank that version to keep users from using `wren_rust`. In a bit of serendipity, `wren` and `wren-rust` are currently at the same version, so the next version you push could go to `wren` without doing any weird semver stuff.
&gt; Properly handling stack overflow in Rust is important primarily because of recursion, right? As I said in my original comment, it should be fixed. Yep. Large stack buffers + recursion. So you would probably start by looking at parsers. I think it's very important to remember that rust has received very little security scrutiny - at least as far as I am aware. So it's hard to say "This isn't that big of a deal in rust, we probably don't ______" because no one's really checking (again, afaik).
Working on my RustConf talk, documenting x.py, and self hosting compiler docs for rust-forge
To be fair, computers do seem to appeal to people who don't mind complexity, but hate nuance and ambiguity. (eg. People are too complicated. I'l going with computers.) I know because, while I'm working to ease my way out of it, I'm one of them.
Well, the kernel does care about rsp when it comes to signal handlers - by default it will subtract 128 bytes (for the ABI-defined red zone) from the current rsp, align down, and use that as the new stack frame. Of course, you can override this using sigaltstack. Looking at the kernel source, I'm pretty sure (but not 100% sure) that the kernel doesn't mess with stacks in other ways, including by freeing memory.
&gt; This isn't a small thing, it's just something no one's really looked at yet. This situation, as the bug will show, has been known for years. We don't have support because LLVM does not have support; nobody has taken the time to fix it upstream. It's a bug, it needs to be fixed. There are also a lot of other bugs that need to be fixed.
I'm not saying otherwise. This isn't me complaining that a team largely comprised of OSS devs isn't working hard enough or anything like that. I don't want to trivialize the work involved in the fix. I just also don't want to trivialize the potential impact.
Can somebody please explain the issue to me? Is there something wrong with red zones? Where does unsafety come from?
Ok, I've added you as an "owner" of both crates, so you should be able to publish to them. You can also remove me as an owner with these commands: cargo owner -r pwoolcoc wren cargo owner -r pwoolcoc wren-sys
You could contribute or become a supporter on Patreon. Both would very much be appreciated :)
&gt; My other goal is to show developers that C++ and Java kinda suck, Disappointing.
The author, Bob Nystrom, is legendary in the language world. I haven't read his book-in-progress "[Crafting Interpreters](http://craftinginterpreters.com/)" yet but have heard it's excellent.
For context, I assume the tweets are related to: https://www.qualys.com/2017/06/19/stack-clash/stack-clash.txt There are multiple links to talks where these sorts of bugs are used to exploit the software. edit: https://access.redhat.com/security/vulnerabilities/stackguard That link is a good intro. edit2: Found a nice write up by geofft https://ldpreload.com/blog/stack-smashes-you
If I understand correctly, the real issue here is not just stack overflow, but the fact that it can grow in such large chunks that it will miss the guard page at the end of a stack. And there should be runtime check for that.
Could you expand on that?
Yeah, I realize that it's actually useful in many scenarios... especially something like let x = some_function(x); I suppose this complicates things... I wonder if there is a linter, at least, that can somehow differentiate between "expected" shadowing, and obviously bad, newb shadowing. 
Oh, and I would recommend just making `serde` an optional dependency, making the feature simply `serde`.
You're right, I changed it.
I'd say a good shadow directly uses the shadowed binding. Oh, another common example for me: let x = x.unwrap_or(y);
Thank you! 
Yes, this is true as well, and you're right, probably more important. Was trying to keep it simple!
thanks! that looks useful, although the dep on nightly kind of sucks. 
Ah! I didn't know that was possible, but since serde reexports everything (given appropriate features), this should indeed work. Thank you!
Yeah, I use rustup and [cargo clippy](https://github.com/Manishearth/rust-clippy#as-a-cargo-subcommand-cargo-clippy) to get around that, though it'll be better in the glorious future when clippy is bundled with rustc itself.
Well, there has has been some discussion about making enum variants types, which is basically what you're looking for. It doesn't necessarily indicate a problem with your code. You can solve the problem pretty easily with some boilerplate though. (Hence the push to integrate this into the language.) What you have to do is declare types for the enum variants you want to use and then use the enum variant as a wrapper for the type. struct Variant1 { /*...*/ } struct Variant2 { /*...*/ } enum MyEnum { Variant1(Variant1), Variant2(Variant2), } // Maybe have some convenience conversions along these lines: impl From&lt;Variant1&gt; for MyEnum {/* ... */} impl From&lt;Variant2&gt; for MyEnum {/* ... */} impl From&lt;MyEnum&gt; for Variant1 {/* ... */} // Panic when wrong variant present... impl From&lt;MyEnum&gt; for Variant2 {/* ... */} // Panic when wrong variant present... // Now we can refer to the variant 'by proxy' using the matching struct: fn process_variant1(v: Variant1) {/* ... */} 
Oh, I've actually bookmarked Crafting Interpreters. I didn't realise it was the same person
I'm not maintaining that crate and the related crates and haven't for a long time. If someone wants to take ownership / maintainership I'd be happy to transfer ownership / make them a maintainer.
is there an `impl` block for the NumberAndRatio trait to implement it for the primitive types? but that is exciting that you found a solution!
&gt; Sure, but the fact is that the checks didn't need to be removed, but they were removed. I think this is part of where the overall disagreement is from; it was decided that the pros outweighed the cons here. It was also a very different time in Rust development; and it's possible it was the wrong call. I'm trying to provide context, not say that what was done was 100% right or suggest what should have been done instead. &gt; I think they all are high-priority bugs. To be clear, so do I. I'm not on the compiler team though.
In release mode, empty functions should be inlined to nothing,so unless LLVM does something stupid, the answer should be 'yes'. You can make sure by checking assembly output (either by rustc flags, playground or perf).
This sub is for the Rust programming language, not iron oxide.
Yes, I had various implementation blocks for 'T:MyFloat' and Vec3&lt;T&gt; etc (e.g. so long as the operators exist the generic impl will roll this) Trying generic impls in a related scenario e.g. f(Vec3&lt;A&gt;,Vec3&lt;B&gt;) -&gt; Vec3&lt;C&gt; I can get it to blow up (some sort of recursion error on evaluating bounds..). This is overkill of course when it's just lerp on a straightforward vector, the version you posted would have done that. I still need to experiment more . Exactly how to clean up what I was doing.. I note that defaults for the associated types are currently unstable. I suspect those would clean things up even further. Maybe I should wait for that to stabilise before going the whole hog.
Probably related: https://github.com/rust-lang/cargo/issues/4189
Possibly related, but different symptoms. In 4189, the builds are actually happening, it's just the console output that's screwed up. On my system, "cargo build" produces no executable. It creates the "target\debug" directory, but no files get created inside that directory.
I'm always happy to see Rust on more platforms. But honestly, at this point you might as well use an ARM Cortex-M. They're just as cheap as AVRs, massively more capable, and Rust development goes a lot smoother. [Here's a **Cortex-M3** board for $1.73 with free shipping](https://www.aliexpress.com/item/mini-Stm32f103c8t6-system-board-stm32-learning-development-board/1568685935.html). I don't know how they do it but god bless China. I'll still use AVR for the simplest hobby projects because the peripherals are easier to configure and I already have a bunch of AVRs in my kit. But those projects are so simple that I don't care what language I use.
Thanks for looking into it!
What do you mean? It seems to work fine for me with GCC. Is it imprecise or something?
I'll consider taking ownership. Do you want to put up a general post on the forums for a call for a new maintainer as well?
[removed]
r/playrust
&gt; FWIW, nightly-2017-06-18 works fine if you just need to get things working. Interesting, because that was the one that didn't work for me. I ended up rolling back to 2017-06-16 (intended to try 06-17, but fat-fingered it), which worked fine.
Add me Tonystackzz
Both of those worked for me.
Yes, Bob is pretty awesome. I miss the Programming Language Games.
Oh, my bad! Totally misread that xD
Awesome, thanks /u/acrichto! 
For context: I write C++ professionally. C++ is the right choice for my organization, though for purely historical reasons. In the long run, I imagine we'd all be better off if Rust or similar languages replaced their predecessors. So my comment came from a place of personal frustration, the same that led me to find Rust in the first place. I only seek to raise awareness of an alternative, hopefully without inciting negative feelings.
The original felt a little too emotionally charged, thank you for explaining why you wrote it though. Awesome work by the way
Thanks, that does the trick! I guess I read the docs too hastily!
&gt; any break ... destroys the claim umm... no? an implementation bug is separate from a language design flaw. Rust the language is designed to be memory safe. `rustc` has bugs. If `gcc` has a bug, that's not a bug in the language of C. Right now there is only one implementation of Rust, so it's easy to conflate the language and the compiler as being the same thing, but there is always talk of people wanting to write a second Rust compiler, like a GCC frontend, or a completely custom compiler. It would have different bugs, just like `clang` and `gcc`. If all of the bugs were fixed tomorrow, it's not like you would expect them to completely change the marketing on the language the next time an issue was discovered until it was fixed? the bugs need to be fixed, but claims that Rust must be perfect are interesting. Rust has struggles, but it's doing really good for how young it is. It seems to be ahead of the curve on quality compared to other similarly aged languages, in my experience.
If it's docs, yes. That way the generated code can be hosted. If it's the README, no - no need.
Yes but some will be completely blind to nuances while being arrogant and insulting. Which is what makes some /r/programming so toxic a lot of the time.
&gt; In practice, Rust code uses Vec instead of stack-based arrays. Remember that not every user of Rust uses libstd, and chances are they care about memory safety.
Off topic: great username :)
I do the same with my crates. Usually you'll want the most up-to-date docs because it makes using the library easier, whereas when was the last time you went into `~/.cargo` and skimmed through a crate's README?
I think that may only work with -C lto 
I'm working with the openapi crate, transforming an openapi document into another format. I have a spec which has paths which has operations which has methods which has params. All these are done in methods which will .iter().map() on the contents of each of these structures, there are lots of hashes and vectors. So by the time I get to params I'm quite deep. And in params I find a text which is a reference to a total different part of the spec. So I either pass the spec around which seems to not be possible as I'm passing also a piece of the spec. Or I put the spec some kind of global place where it can be accessed by the method dealing with parameters which seems also not possible? What's a good approach here?
I could give this and the macro idea a try, thanks!
That's my suspicion, that I can use traits for this, but I haven't had the chance to try it. Basically, I have an enum with many different event types (each with different associated data) and another enum with the possible replies to the events. I guess this could be modeled with traits and associated types. There is still a bit of boilerplate even in this design...
For me, even when writing c-style for loops, I sometimes rewrite it as a while loop because it's unclear exactly when the step and condition are executed relative to each other.
It is true that the C++ standard imposes requirements on the STL data structures that restrict the implementation. I believe that yes, requirements about iterator invalidation specifically are the ones that force the choice you mention for `std::map` and also the use of linked list chaining for `std::unordered_map`. However, this is just a restriction on the STL structures: like Rust, external libraries can implement high performance data structures in C++ with approximately the same ease as doing in the standard library.
Good fucking question. I will say, I question this snipit: let homura = Homura::Madoka { name: "Akemi".to_string(), age: 14, }; I could explain my problem with this, but it's spoilers. [Let's just say...](https://youtu.be/BmisWMv-1bA)
I had a similar thought. It wasn't until I considered the tree example in more detail that it clicked for me, I think. :-) Imagine a large data structure that doesn't have a nice central ownership point, such as a graph that hands out refcounted nodes. There is no central struct that can be borrow checked. But the SyncCell introduces a 'key' struct that *can* be passed around and borrow checked. If there were only one SyncCell for each key, then I think you'd be right: you may as well just pass the data where you'd pass the key. But if I understand correctly (and I'm still not entirely sure I do), then you can have a single key for multiple SyncCells. This allows you to pass the single key around with the main execution thread and access all the refcounted SyncCells that you've scattered throughout your data structures. The key serves as an artificial single point of ownership to lots of scattered, refcounted data. And the correctness is checked at compile time, so the key passing adds no cost.
Coming from a "docs are part of the release artifact" perspective: definitely yes, if they are in a finished state.
Makes sense :) Wait, do you intend to use Rust for a timed contest?
Yeah, that's indeed how it works. Do you think the confusion could be coming from the name `SyncCellKey`? I originally named it like "accessor" or even "singleton" (but it's not really a singleton), then I thought "key" was nice and short, and a key is what you use to open (prison) cells. But I can see how the name "key" can be confusing, because usually there's not one key that opens every lock, but one (or multiple) keys per lock.
I've tested it out on a couple contests :D Example: http://codeforces.com/contest/799/submission/27035271 I believe these competitions are a good setting to introduce a substantial audience to Rust, and a good place for Rust beginners to practice writing short but non-trivial programs.
Heh. I just went back and re-read the original post. All the details are there. I think the issue is that there aren't any simple examples of using a SyncCell. Even the tree example is a large code dump. That's great for people who want the details, but it's missing the one paragraph description of why someone would care. The 'for dummies' version. That's what I tried to give, and I'm glad you could confirm I was right. :-)
I thought it was a good joke though (mentioning the code of conduct), because the compiler is being non-inclusive of alternate styles.
Thank you again! I opted for the match version so it handles the validation of the presence of the "repeats" argument. In the same move, I added errors checking with `Result` to completely remove all panics. I was also able to make clap requires the command to be at the end after a --. I would have preferred it to be optional but it currently is not the case, I will investigate clap more in depth for this matter. I now proceed like [this](https://github.com/CBenoit/autocmd/blob/0929cbca9d905d4679327d2ed8414b020a893e98/src/main.rs#L75) to build the full command string and the Command structure itself. I wasn't sure about how to build the full command string from the list of values and after several tries I decided to convert the clap::Values into a Vec and use the join method on it…
How's that?
because base64 is case sensitive, and this might uppercase the first character, changing the value of the hash not that you should be using this kind of operation on a hash
You should use RegisterHotKey for global hotkeys whenever possible. Using a keyboard hook means that all keyboard input is routed through your application's message loop, which can lead to delays.
[removed]
Perhaps I overlooked it, but I couldn't find anything mentioning that this is for English only, so perhaps that should be added somewhere.
I believe Unicode has a case mapping called titlecase that is actually distinct from the [upper case mapping](https://github.com/wezm/titlecase/blob/788958dd647ad7b2caeea16b2e9017b11a9a5a1d/src/lib.rs#L78). I'm not sure if `std` exposes that though. See [section 5.18 of the Unicode standard](http://www.unicode.org/versions/Unicode9.0.0/ch05.pdf). Note though, that it seems like you're probably fine if you're explicitly sticking to English.
i don't know, but people often put weird things everywhere.
I might very well do this. Does RegisterHotKey have any major downsides?
Note: this is a test, so our audio, prep, flow, timing, etc are all terrible.
Nonetheless, I liked the ~~first~~ zeroth episode and hope for more. 
http://i.imgur.com/s4eamxv.jpg ;)
Some thoughts: ◌ I feel like it needs more scripting. This came across quite a bit as though no one was quite sure why this was being recorded or what you were going to talk about. I gave up counting "um"s, "uh"s, and awkward silences pretty quickly. At least, until Alexis got a full head of steam. ◌ Alexis' explanation was fine, but I felt it suffered quite a bit from being audio-only. If this is going to be about explaining language changes and features, I worry it'll be crippled by an inability to show code. It might work better as a video series with enough explanation in the audio that you can listen to it if you want to and still get ~80% of the information. Otherwise, you're stuck trying to verbally *describe* code in order to explain it. ◌ In future, Manish should avoid recording from the next room over. That or find some way to adjust the relative levels of the participants. ◌ Regarding Manish's comments on magic: *yesss.* Very that. &amp;nbsp; Overall, I'm not sure what this format really adds. For the most part, it was a casual reading of a summary of the RFC, except that the RFC had code examples. That said, there were a few details on the RFC that I hadn't known before, which was good to hear. I think that if there were accompanying visuals (even if it was just a few static shots of code), it could be positioned as a softer explanation of RFCs with more focus on the why and what. Something self-contained that could also function as a "Coming Attractions" teaser for those who don't want to dig through the RFCs themselves. It might also have been that 2005 isn't a particularly obtuse RFC (there is things you have to write, but now you don't). A better candidate might be the specialisation RFC. It hasn't been stabilised yet, and I'm *already* seeing people on Stack Overflow confused as to what's going on. Also, I'm not sure why there were *three* people involved. Most of it was Alexis pontificating by himself. I mean, that's *fine*, it just feels like it was less a three-person podcast, and more The Alexis Show (occasionally featuring some other people, I guess). Maybe Carol could have asked more questions as a listener surrogate. Perhaps Manish could be the snarky one, dropping the odd bit of tangential wisdom. Not sure. Oh, and no pointless theme song. I like that. So overall, not *great*, but not bad. Feels like there's potential for explaining the more conceptually difficult language changes.
"Well, at least nothing caught fire." "... On an unrelated note, we also need to buy a new extinguisher..."
It prevents the hotkey from going to the active application, you need to call it once per hotkey and it can't request already used hotkeys. It's the standard choice for global hotkeys, but there are special scenarios where it's not suitable.
&gt; ... I wonder if just some code samples in the show notes would be sufficient. My concern there would be the infrequent disruption of having to flip back to the page and find the associated example. &gt; Again, we kinda want to be low effort. You could always just do really low-effort 4x3 images of example code and stitch them together as a video track after the fact. There must be a free video editor somewhere that'll let you drop stills into a timeline, crop them, and go from there. Even less effort (but more *time*) would be to play back the audio afterwards, while Carol screen-records herself going through a slide deck roughly in time with the audio. :P &gt; I can ramble infinitely about Rust and it's history ... "Have I ever told you the story of the mutpocalypse? It all began fifty years ago..." "*Moooom!* Grandpa Gankro's telling that story *again!*" "He's old, just humour him."
Oh wow this is exactly what I was looking for. I am currently writing a console for a game and I needed a small scripting language like lua or lisp. I decided to roll my own because I don't need much but wren looks perfect for my usecase. It even has the getters and setters that I want I could do `input.sensitivity = 5` but where sensitivity is actually a method. I'll definitely give it a try, thanks for this.
I’d recommend slinging something simple together with [Popcorn.js](https://github.com/mozilla/popcorn-js) or some equivalent project (apparently it’s not maintained any more). This will be much better than a video with dodgy images inside it, and apart from a bit of initial set up cost it’ll be faster to maintain later and more flexible.
You are right indeed, I got confused by `mspc` (I used the std version a lot when playing with threads, so just assumed there were underlying threads). Even though I knew futures compile down to a state machine. :(
I'd love to have some kind of transcript; it's much easier to make the time to read an article than to listen to a podcast.
Hi! This is not Rust-specific but I think the following would be a nice improvement. I think this should be printed to the standard error, not the standard output: https://github.com/wezm/titlecase/blob/788958dd647ad7b2caeea16b2e9017b11a9a5a1d/src/main.rs#L12 You would not need the "error: " prefix, then. Moreover, if at some point you cannot read from stdin, I think you may want to exit with a non-zero status code. Have fun! Guillaume.
Great job. Regarding wren and lua I find the lack of support for 64bit integers frustrating :( when I was writing DB UDFs I always had to work around that in weird ways. 
The point is not to take away the free speech of the community. I hope that by starting this post members of the Rust community (opposed to other communities as Carol mentions) will be able to continue civil discussion about the RFC.
I'm all for civil discussion, but given that the RFC was locked in order to allow a "cool-down period," I think immediately opening a new thread on a different service is going against the whole reason for the thread locking in the first place.
&gt; I want faster compile times... That is also being worked on and has nothing to do with this thread, whatsoever.
Nope, it's the first episode - at index zero, sure, but zeroth is a different ordinal!
Thank you for reassuring me of this. Because when I see RFCs like this, it gives me pause. 
You should reflect on why that is. There's no reason for any connection to be here, so that's some sort of bias you've got. We all have them!
I can't be sure if you're being sarcastic or not, but I will give you the benefit of the doubt and assume you are responding in good faith. If you are not being sarcastic, then you could just delete the thread yourself. If you are being sarcastic, I think that's unfortunate and would prefer that you give more constructive criticism
I liked the `other_styles` suggestion
I'd like to say the way the thread was handled—moving to FCP, locking it to not allow endless bikeshedding—is fairly encouraging to me that we won't debate these things endlessly when there are larger problems. You'll never avoid these small nits, but keeping them small is key!
I kinda think the point of the podcast format is to work _without_ visuals, folks want to listen to it whilst driving and such. We need to be good at picking stuff that can be communicated in this format.
&gt; We picked an easy RFC on purpose :) I was really briefly worried that it was actually super complex and I'm just some kind of super-genius. I'm relieved to know that's not the case. &gt; I'm really not sure about scripting it. We just want it to be something where we get together and talk about stuff in a way that helps others. I don't mean that the *whole* thing should be scripted. Just *enough* of it to minimise the "um"s, "uh"s, and awkward pauses. Even if it's just more detailed notes to help keep you on track.
We actually already had the notes at https://gist.github.com/Gankro/95390640bac8418661561d0f472f9294 :) It's hard to do that without scripting the whole thing IMO. We had plenty of material, and a rough plan. We wanted it to be a discussion so I'm not sure if a more concrete plan would help.
The thread was locked down, so I'm posting my thoughts here for later reference. I didn't have any preference conerning the RFC until I saw this gem from CodesInChaos: &gt; style is pretty broad. I'd prefer something more specific like naming or case. I'm sure I'm not the only one who, after learning about `bad_style`, was suprised about what it actually meant. I first thought `#![allow(bad_style)]` simply meant turn off _all warnings_ (Yes, I know `#![allow(warnings)]` will do this). It's non-semantic, too far reaching, not specific. I did a quick check of all the lints described in `rustc -W help` and there isn't a single lint there that required to me look at the definition besides `bad_style`. I don't think `nonstandard_style` is _any_ better. I'd recommend we don't use the word "style" _at all_ in this lint, and give it a more descriptive name. For instance, how about `#![allow(nonstandard_casing)]`.
`From` is implemented reflexively for all types. That is, `impl&lt;T&gt; From&lt;T&gt; for T` exists. In your example, `A` could be `B`, so that's the conflict. If you're on nightly, you could enable specialization. Otherwise, I think you're pretty much stuck with the concrete `impl`s.
ahh interesting. 'specialisation' ... would I specialise the T:From&lt;T&gt; case or what do any of the other proposals like negative trait bounds offer intuitive workarounds, (would there be a way to mark 'A!=B' ) maybe I can enable generic conversions to and from f32 at least this way, e.g. i could make some traits 'IsF32', "NotF32' and manually mark those per type to enable this.. &gt;&gt; Otherwise, I think you're pretty much stuck with the concrete impls. That is certainly sufficient for now. the conversions to and from compressed types are the most important. I can roll these things with a macro aswell.
Wren definitely looks interesting and this may be just enough for me to consider switching from Lua. I'm particularly interested in running this in interesting environments, such as WebAssembly, though perhaps porting Wren to rust will be required to make that a reality. Thanks for this, I'll have to play with it!
So do you need to do a major version update when the docs break backwards compatibility? What is the public API of docs?
I like your test case macro. :)
(ok i'll stick with concrete for the timebeing but am still interesting in what it can and can't do) hah. this doesn't work.. trait IsNot&lt;T&gt;{} impl&lt;T,Y&gt; IsNot&lt;T&gt; for Y{} impl&lt;T&gt; !IsNot&lt;T&gt; for T{} 4 | impl&lt;T,Y&gt; IsNot&lt;T&gt; for Y{} | -------------------------- first implementation here 5 | impl&lt;T&gt; !IsNot&lt;T&gt; for T{} | ^^^^^^^^^^^^^^^^^^^^^^^^^ conflicting implementation it would need Y:IsNot&lt;T&gt;..
IIRC for rustfmt folks don't mind so much, and rustfmt is explicitly configurable for this. The reason `bad_style` is something you want to avoid is because it affects APIs, and this has readability considerations for library consumers. rustfmt just affects folks who contribute to your library.
Working on adding open file handling to [my FAT32 library](https://gitlab.com/susurrus/fat-rs). This will ensure that files are only ever opened once. Once this is done I'm going to make the library properly support `no_std` so I can start testing it on actual microcontrollers. edit: Fixed link
Although I think those things all fall under what most programmers consider coding "style", I agree with your point, as some people may not know what "style" is. I think calling it "nonstandard" vs "bad" is mostly irrelevant, though "nonstandard" is probably more correct. However, I do like that "bad" makes people feel that their code needs to be "standard" style.
Yep, we do this plenty of times when interoperating with C (also when doing codegen). So of course you need the ability to opt out, but you should strongly avoid doing that in other cases.
I'd phrase it like "avoid doing it by default." If it turns out to be a hindrance, then consider switching. 
Regarding audio quality, I'd recommend focusing on the [room](https://www.youtube.com/watch?v=r90Xy9eIU8E). Sit in a space full of clothes or so, and hold the microphone rather close to the mouth. That gives a better bang for the buck than buying an expensive microphone. (Also, Carol's audio sounds compressed with a very low bitrate or something.)
What if it gets extended in the future to something else beyond casing?
I'm a little late to the party, but calling it `wren` may cause issues as well, especially if someone decides to port Wren to Rust. However, this shouldn't be the default that people look for, so perhaps `wren-rs` is a better choice. I'm actually considering porting Wren to Rust if it'll make it easier to use on platforms I care about (e.g. WebAssembly). Just food for thought, no real suggestion here.
(I and Alexis were on superfast office wifi, Carol was calling in from home I think) I booked a room with an actual physical mic which I can reposition for the next ones. The rooms themselves are pretty well set up wrt soundproofing.
We operate on pointers all the time in Rust. Passing around `Box&lt;T&gt;` or an `Rc&lt;T&gt;` or an `&amp;T` is passing around a pointer. It's important to maintain a distinction between the pointer and the data it points to, because the data may also be shared with other folks. There's nothing wrong with juggling pointers. Rust has safe smart pointers which you can juggle safely. You also don't have to think of them as pointers in the same sense (e.g. looking at `&amp;T` as a "borrow" is nicer). Rust also implicitly treats smart pointers as the contained data in some cases where it makes sense (e.g. when calling methods), but in some cases you want the distinction and hence the explicit `*`.
For anything more complex than simple counting, I much prefer the second one.
I don't have any constructive criticism to say that hasn't been already said, I just want to say that: please continue making these! I enjoy listening to stuff like this when I'm commuting.
No worse than many first shows, I think the idea is super and really hope the show continues.
You're obviously free to do what you wish, but is it really worth it? Do you really have time to keep trimming your garden all the time? Is it even doable, while continuously changing the code, renaming things, moving blocks of code around, etc.? Do you really care more about perfecting the looks, or do you care more about other aspects like: structure, usability, documentation, interoperability, etc. Because any time that you spent on aligning text to your liking, is a time you could be doing something else. If aesthetics are important to you, you could eg. do some drawing, during the time you saved by just `cargo fmt` everything.
I'm very excited for it too!
Having to tag your code as bad may seem hostile. I don't mind it, but not everyone has the same experience, and don't we want to be inclusive? Given this would be a fairly trivial fix, I don't see any reason not to do it. `bad_style` won't disappear either, for those who prefer it. 
That wasn't the reason. It's for better sculpting the newcomer's learning process. `bad_style` makes you feel forced to fix it, even when just messing around and learning the language. It's an additional bit of friction that we don't need to add in; we already force people to follow the borrow checker (and we should! but we have a limited budget of friction and should spend it wisely). `nonstandard_style` conveys exactly what we want to -- "don't use this, but for code you're just messing around with, do whatever, or if there are other reasons to avoid it". "bad style" just shames you without even saying _why_ it's bad. And yes! It's also about just being nicer. What's wrong with that? Minor change with a bit of bikeshedding happening. It literally wasn't taking people's time away from other, more important things until folks came along and started derailing it for being "too social justice-y" or whatever.
What gets me is when "this works because of automatic dereferencing" and then "this doesn't work because it doesn't automatically dereference all the time" Of course, there are rules, but when given some opaque code you just have to sometimes throw stars at it. Where should you dereference? I don't know, let's try `.cloned()` - welp, that didn't work. Let's dereference inside the function we're calling instead. Works now. Why? I don't really know. I've had it explained before, but it went way over my head.
99% of the time there's a reason why you would want to do this for example, your macros are generating identifiers which might not have the correct case
&gt; looking at `&amp;T` as a "borrow" is nicer I think that's what I mean. Can't we always do that (not counting unsafe code)? I was under the impression that that was the idea.
Yes, but ultimately "a borrow of a `T`" is not the same thing as "a `T`", and the `*` operator lets you distinguish between the two cases in certain situations.
&gt; Rust is being developed with the idea that explicitness is preferable to implicitness. What are the situations (except for unsafe code) that makes it impossible to treat a borrow of a `T` as just a `T` with certain usage restrictions?
Because in some situations when generics are involved, a function could also potentially accept `&amp;T` as well as `T` and the compiler wants you to be explicit. Also, they're quite different -- a borrow ultimately _is_ a pointer and is a tiny thing that can be copied around. Mutating the borrow itself will change what you point to, etc. The distinction is important for by-value vs by-reference, for example.
Just a minor counterpoint: I listen to videos while driving all the time. It sucks when people want to let the images on the screen deliver everything, but most people don't do that, and it's easy to avoid.
&gt; (I and Alexis were on superfast office wifi, Carol was calling in from home I think) This made me think that it would be cool if there were some software that used whatever bandwith was available during recording to let you hear each other, and afterwards took its time to transfer a high-quality version of everyone's recording. :-)
Is there any formal doc for how security issues like this should be prioritized or is it sort of ad hoc? I know a lot of the soundness bugs are just blocked on borrow check on mir, but I wonder if there are others that aren't really blocked, just aren't prioritized. Super kudos to pcwalton for taking this on.
&gt; That's the whole point, isn't it? Otherwise, why even have compiler warn about style in the first place? I laid out the distinction -- we don't actually want to force people to fix it in _all_ situations. When learning the language and writing toy programs? Meh. Disable it while you get used to the new style, if that's the way you prefer to learn. When writing FFI code? Disable it. &gt; It doesn't. It says "your style is awesome, just not what people are typically doing. But it's OK, keep doing it.". I disagree, but I really don't feel like arguing this point. &gt; doesn't mean that style isn't considered bad. But it isn't! There's nothing wrong with alternate styles in Rust code! The problem solely comes from _mixing_ styles, which is why there's a standard style. Why do you think other styles are bad? Plenty of languages have other "standard" styles that work well for them.
&gt; a function could also potentially accept `&amp;T` as well as `T` Hmm, when does one need to do that? &gt; Mutating the borrow itself will change what you point to That's something I didn't know existed in Rust. In fact, that's the kind of thing I thought distinguished Rust from C.
Consider traversing a linked list iteratively: https://play.rust-lang.org/?gist=d05fa9a9919b4e46b1db5328d903f29d&amp;version=stable&amp;backtrace=0 That entire thing is operating on actual pointers, and doesn't care one bit about the data it points to!
Thank you very much. However, it seems that some characters are not allowed to be used like `:` or `{` after `expr`. Why is this?
I could do that as well, not sure. What I want is something that: - can run in the browser - can run on Linux, Windows, Mac, Android and iOS - is reasonably fast (Lua is perfect here) - is easy to learn for someone without too much programming experience and without too many gotchas - is reasonably stable Lua is pretty close, but there are some weird gotchas coming from an OO/data analysis background (metatables instead of classes, bit operations only in 5.3+, etc). I thought about forking Lua to add the changes I want (no global variables, classes instead of metatables, etc), but Wren looks to be a lot closer, and I'd rather use an off-the-shelf language than invent my own. I may not even get to it and figure out the compile process for getting it to run on WebAssembly. Idk.
&gt; There's nothing wrong with alternate styles in Rust code! Oh dear. So that's the root of our disagreement. &gt; Why do you think other styles are bad? Plenty of languages have other "standard" styles that work well for them. It's not about style itself. Every style is quite arbitrary set of rules. It's about deviating from the agreed on style. We have picked a style for practical reasons. So the code can look uniform when using 3rd party libraries, so we can autoformat code easier, so improving other people code feels more familiar, etc. It makes everyone's life easier for the small price of having to get used to it and accept it. Deviating from it is bad, because it ruins that common good. In an esence it's a kind of anti-social behavior.
There is a [policy](https://www.rust-lang.org/en-US/security.html) but I have no idea if it's ever been invoked, or really what it's for specifically. When the policy [was created](https://internals.rust-lang.org/t/proposed-security-disclosure-policy/2024), questions like "is every memory safety bug a security issue or is this for e.g. crates.io login vulnerabilities?" were [not definitively answered](https://internals.rust-lang.org/t/proposed-security-disclosure-policy/2024/7) (as far as I can see the promised RFC never materialized -- /u/steveklabnik?).
Because those characters can be part of an expression, or they are *reserved* for usage in expressions in the future.
Nested method calls and NLBs doesn't seem implicit to me. It's more about "the borrow checker can prove more code as valid"
Thanks very much for the response, all of that makes sense to me and I appreciate the clarification of the process. I'm more familiar with this soundness issue so I'll use this as a way to try to understand the process/ maybe provide some feedback: https://github.com/rust-lang/rust/issues/31287 I see it getting triaged repeatedly as Medium and High. The reason it went from High to Medium is because: &gt; We decided that having this P-high wasn't really proper, since although we're actively working on a fix, it's via MIR borrowck, and not really a "drop everything" sort of situation. I'm fine with this. But it's reprioritized multiple times - I'm assuming based on meetings happening elsewhere. It would be cool to have more insight into the reasoning, especially when a bug is deprioritized. It also seems, in that explanation, that the severity is disjoint from the label - instead being somewhat tied to the work involved. But I may be reading Niko's words incorrectly. It would make more sense to me to have it be P-High, but then assign a difficulty label and state that it's blocked on mir-borrowchk, then have that contribute to the mir-borrowchk. I think it's crazy hard to assign severity labels as a whole so I'm not criticizing the current process - I hope that's clear, I'm personally very happy to see that the unsoundness labels even exist and that Rust's lang/compiler teams aren't in the business of trying to misrepresent vulnerabilities (which I see in other projects I won't name). edit: Skimming other issues I see labels change without much reason why.
There's nothing inherently unsound about changing a reference to point to another valid instance of the type that it refers to, especially since Rust helps keep the mutability of the binding independent from the mutability of the reference itself. See https://is.gd/M4bhBd for an example of what I mean. Notice how you can mutate `x` to point to separate instances of `i32`, but you can't change the value of the `i32`'s themselves through that binding. To enable that you'd need to separately make the references mutable.
The blog post mentions checking out the avr-rust-demo branch of avr-rust/llvm.git. This branch does not exist. Which branch did you intend to check out?
Yeah, we never expanded it; I think it'd be a good thing to spell out more formally. We've had some mail to that list; only one real incident, as published here: https://groups.google.com/forum/#!topic/rustlang-security-announcements/BK_3gbXhSn4 We've gotten some other mail, but it's largely been spam.
oh, it was just git that complained on the checkout as it expected a branch, rather than a tag... I think... weird.. checkout avr-rust-demo works fine though.
Vector of references vs vector of T, for example. Also, the deref coercion magic that fuels this will not attempt to coerce things period if there are generics involved, even if there is a single obvious answer. This could be improved, but it's also about avoiding _too much_ magic happening in a line of code.
Thanks for the pointer. English is my use case so I guess I'll stick with that for now.
That's an interesting point that I did consider... so my use case for the binary is filtering text through it via vim. It seemed that in this situation it would be better to have all output come out in stdout. However I didn't actually test how vim handles stderr. It would also be more correct as you point out so maybe I'll do it anyway.
Whoa! Fancy seeing you in this subreddit. How the Rust rewrite of the LNP going? 😝
&gt; Vector of references vs vector of T, for example. Hm, OK. I guess I have always thought (or hoped) that borrowing should be a concept that was separate from the concept of pointers, but perhaps that's a view I must abandon. I've been telling myself that to the extent that they are connected, it's probably just because using pointers is a natural way to implement borrowing.
&gt; it's also about avoiding _too much_ magic happening in a line of code. Indeed! I feel that all magic makes it difficult for a beginner to understand what's going on.
In general it's both easy and not easy (mostly depending on what your C library looks like). It's easy because you can write C-like unsafe Rust and then link it to C and it will work. Bindgen is really good, somewhat magical. It's not easy when you have to deal with C macros. Some libraries' APIs are mostly macros, operating on data structured that are supposed to be opaque to the library user (this is done for performance, or convenience). In this case you might have to reimplement them all in Rust, which can be annoying and possibly tricky to get right. It's also not always easy to idiomatically Rustify a C lib. Drivers for example might have a driver instance which owns a handle which owns a resource. Each of these have internal pointers to the next layer. So the instance must be freed after the handle which must be freed after the resource, say. On paper, Rust is built to handle this perfectly, using lifetimes. But in practice, you'll wind up with an API where the thing you're using needs to have 3 different lifetimes in it, which is not ergonomic. So you have to find a different way in that case. (If anyone has advice on how to do this and wind up with a usable API at the end..)
How does a typical Rust coding workflow look like? I've spent a lot of time with Clojure which is very REPL oriented, but Rust's Rusti isn't inspiring that much confidence. And I don't want to constantly rewrite the main function to try out code.
Happy to hear any feedback on this post and if there are glaring fault with it then I'll edit the post.
mmap a file and then unsafe cast it to an array of repr C entries, and then just mutate them in order (per thread)? Depending on how much data you generate you may never need to flush to disc during execution. 
Depends on what you write. If it's a library, you can offen write self-contained methods incliding 1-2 doctests and perhaps a few module Tests. Write – cargo check – fix – cargo check – ... – write – cargo test – fix – cargo test – cargo [clippy](https://github.com/Manishearth/rust-clippy) – fix – cargo bench – rejoice – git commit – git push – cargo publish
Should you even need lifetimes in an ownership scenario? If one resource owns another you should be able to express that on the Rust side without too much difficulty.
Why do you mean by that? I thought Rust didn't support overloading.
I think this is really the essence of OP's question.
Now added, thanks for the feedback: https://github.com/wezm/titlecase/commit/b8cfa896e552b6c5d29eae2f51722ff20322815f
&gt; Ideally I believe the implementation should add no overhead at all for functions whose locals can provably not overflow the stack. This is indeed the case, based on what Rust already does for Windows. If the function's stack usage is less than one page, no stack probe is generated. If a stack probe is generated, it just touches each page of memory that the function's stack covers.
I'm not arguing that it shouldn't impl clone im arguing that shouldn't be the canonical way to increment a reference count. 
I am confused about how to handle `'static` lifetimes more specifically when it comes to returning `Box&lt;Trait + 'static&gt;`. I get that the reference will live to the end of the program but for programs that live for long periods of time, I am concerned about the possibility buffer(heap) overflows. Then again maybe I am misunderstanding the actual lifetime of the references and at some point, the memory is released again while the program is still running. However, is it possible to reason the lifetime of the item and bound the lifetime so the memory can be released? My apologies for the wordiness of the question. 
&gt; You can't enforce that nothing in the Rust ecosystem or community can be offensive or upsetting to anyone. Correct. And nobody was saying we should. That comment _also_ insinuated that folks who have a problem with this name are mentally ill. I have often heard criticism of the bad_style lint name from newcomers, it is _very_ out of line to make such an insinuation. There may have been some truth to the comment, but that doesn't excuse the other parts. &gt; unless the thread is summarily locked You're being unfair here. It was made very clear that the lock is temporary.
It means it *can* not that it *will*. The memory will be dealocated when the Box goes out of scope. Does that make sense?
It's not really overloading, but `&lt;Rc&lt;T&gt; as Clone&gt;::clone()` will take precedence over a possible auto-`Deref` to `&lt;T as Clone&gt;::clone()`.
You need to implement [iron_sessionstorage::Value](https://docs.rs/iron-sessionstorage/0.6.6/iron_sessionstorage/trait.Value.html) for your own type. A simple example: extern crate iron; extern crate iron_sessionstorage; use iron::{Iron, Request, Response, Chain}; use iron_sessionstorage::{Value, SessionStorage, SessionRequestExt}; use iron_sessionstorage::backends::SignedCookieBackend; struct Counter(pub i32); impl Value for Counter { fn get_key() -&gt; &amp;'static str { "cookie_name" } fn into_raw(self) -&gt; String { format!("{}", self.0) } fn from_raw(value: String) -&gt; Option&lt;Self&gt; { value.parse().ok().map(Counter) } } fn main() { let mut chain = Chain::new(|req: &amp;mut Request| { let mut counter = req.session().get::&lt;Counter&gt;()?.unwrap_or(Counter(0)); counter.0 += 1; let res = Response::with(format!("Counter is: {}", counter.0)); req.session().set(counter)?; Ok(res) }); let backend = SignedCookieBackend::new(b"secretkey".to_vec()); chain.link_around(SessionStorage::new(backend)); let _ = Iron::new(chain).http("localhost:8000"); } You can also check [examples](https://github.com/iron/iron-sessionstorage/tree/master/examples) in iron-sessionstorage repository.
We'll see if it actually is.
A great way to synchronize everyone is to have each person record their own local audio. And at the start, everyone counts to 10 together (yes it'll sound strange at first, but by 5-7 everyone should be in sync). Then when you edit the final product you simply align all three audio tracks to the last few numbers. This will cut out any latency delays between responses, etc. This also allows you to cut out any "normal human responses" while the primary speaker is talking. I.e. those times when the secondary speaker is listening and wants to respond with, "yeah." Or "uh huh." Or other natural responses we as humans do to provide feedback and show interest... unfortunately for podcasts it's really distracting for listeners. In post processing you can just cut those out, so only the primary speaker makes the final combined audio cut. Also have everyone wear headphones (if they weren't) to keep any audio output from making it into the recorded input. Just some tips :)
Minor fault: the lifetime in your function signatures is undeclared. You need to either make it a generic parameter (`fn new&lt;'a&gt;(name: &amp;'a str)`) or just remove it, since lifetime elision handles it just fine.
/r/playrust
We've basically decided on a policy of "no more than minimal editing", and if folks really want editing we might set up a patreon so that we can pay someone to do editing. (Or if someone wants to help with that) We'll see how the next one goes.
Does this statically store session values (does it keeps them after server's restart)?
This trick is really handy and although I know about use it pretty often I only found out about it due to a nice series of articles by Herman Radtke ( /u/hjr3 ): * http://hermanradtke.com/2015/05/03/string-vs-str-in-rust-functions.html * http://hermanradtke.com/2015/05/06/creating-a-rust-function-that-accepts-string-or-str.html * http://hermanradtke.com/2015/05/29/creating-a-rust-function-that-returns-string-or-str.html These articles/blog posts contain more than just this trick and have proven handy more than once or twice. edit: linked the author's reddit account.
Hmm, I'm on git 1.9.1, and its `-b` flag knows how to supports tags, not just branches. But yeah, if you're on an older version of git, just do a clone followed by `git checkout avr-rust-demo`.
Another similar trick which is also good for ergonomics is to mimic the stdlib's approach with paths and accept anything that implements `AsRef&lt;Path&gt;`. For example, here's how I do that with some code which uses `libc::access` to bail out early if a target directory probably isn't writable: pub fn probably_writable&lt;P: AsRef&lt;Path&gt; + ?Sized&gt;(path: &amp;P) -&gt; bool { wrapped_access(path.as_ref(), W_OK) } (This also demonstrates the "one-line wrapper" trick to minimizing monomorphization bloat.)
Does Alex Crichton sleep? He's almost on every team.
They behave differently with respect to ownership and that's more than enough in my opinion.
&gt; If the function's stack usage is less than one page, no stack probe is generated. I feel like that's unsound. What about [this case](https://godbolt.org/g/HPNNHD)? (I suppose that the guard page is 4KiB.) Since `a` grabs only half a page of stack, then immediately calls `b`, which does the same thing, neither will have a stack probe. But they don't touch the stack memory until *after* `c` has executed, so `c` is free to use memory more than a page after the last memory access, potentially skipping the guard page. Does that make sense? Or am I missing something?
Have you tried mutating the desired CmdView in-place (i.e. via mutable reference to a Vec element), then pushing-in a fresh "add a new command" CmdView afterwards?
I wish I could buy the paper version and get it shipped when ready, and in the meantime have access to electronic versions. Is that possible?
With a **shared** object? That seems unintuitive
Where is this documented?
It's not, so far as I know.
The industry standard embedded MCU is based in ARM, and the manufacturers header files are normally autogenerated from svd files. There is also a tool which autogenerates rust code, that allows you to access each register and bits. Check out the rust embedded guru Jorge's blog Embedded In Rust for excellent tutorials and examples! http://blog.japaric.io/quickstart/
I'm slowly converting my unenlightened co-workers to the way of Rust and there has been talk of trying to get Rust compiling for our very odd embedded platform. Beyond that I would like to get a new release of `dts_viewer` and `device_tree_source` (I should have tried to think of a better name) out before the heat death of the universe.
`data-layout` has to match the LLVM AVR backend, no way around it (so don't change it). The link arguments are whatever you want passed to `avr-gcc`; in my case, I started from the link flags I used for the original C++ version of the firmware that we wrote years ago. I suggest playing around with linking by hand first: `xargo rustc --release -- --emit=obj` followed by manually executing `avr-gcc` on the files that end up in `target/avr-atmega328p/release/deps`, until you get something that works; it should then be easy enough to turn that into `pre-link-args` and `post-link-args`. Another thing you can try is to write your own entry point (i.e. not use AVR-GCC's stubs that set up the interrupt vectors etc). I haven't done that, but I've seen [this demo project](https://github.com/shepmaster/rust-arduino-blink-led-no-core-with-cargo) do it.
Can someone explain what a stack probe is?
This is very timely, considering the recent [stack clash exploit](https://www.qualys.com/2017/06/19/stack-clash/stack-clash.txt).
Congrats, Rust's just saved you from iterator invalidation! I don't know exactly what your code looks like (you should post relevant part of it) but I guess it looks something like this: for view in &amp;cmdviews { // Do things here; attempt to call cmdviews.push(); } Try changing it to this: let mut append_cmd = None; for view in &amp;cmdviews { // Do things here; instead of push()ing use this: append_cmd = Some(new_cmd); } if let Some(new_cmd) = append_cmd.take() { cmdviews.push(new_cmd); }
Fyi, In connection to all the talk about pointers . As is stated in the book: fn test( x: SomeStruct ) Will just pass in the pointer to SomeStruct unless SomeStruct implements clone. So try not to get bogged down on relating C pointer syntax and rust's * and &amp;
The Clone impl in the quote of the week... is just Copy-ing the bytes, right? 
Yes. It does work correctly for Copy types but will segfault on Drop for anything that holds pointers to the heap.
From what I understand, Rust puts "guard page" at the end of stack. The guard page is just memory marked as non-accessible, so if the program attempts to access it, it gets killed by OS before accidentally overwriting the heap (the heap is behind the end of the stack). The guard pages work but they have one possible problem: if the function allocates more than a page on stack and doesn't access it, then it could skip the page and access memory after the page. The stack probes are just single instructions. If the function uses more stack than what fits into a page, compiler can generate instruction that accesses (stack+page_size), (stack + page_size *2 ), ... (stack + page_size * n) where page_size * n &lt; memory_needed &amp;&amp; page_size * (n + 1) &gt;= memory_needed. If someone more knowledgeable sees some mistake in my comment, please point it out.
A lot of things. I keep augmenting my [spectra](https://crates.io/crates/spectra) demoscene crate (already two demos released with it, even though they’re just “state-of-the-art proofs”) by giving it its own shading language. In order to do that the right way, I’m writing a [GLSL450 parser](https://github.com/phaazon/glsl) that will expose an AST as primary interface (and nom parsers as well). Also, I’m finishing [luminance-glutin](https://github.com/phaazon/luminance-glutin) and release it soon.
Wrong subreddit
 fn do_smth(x: usize, y: usize, z: usize, value: i32) { println!("{}, {}, {}", x, y, z); } use ndarray::Array3; let mut arr = Array3::&lt;i32&gt;::zeros((3, 4, 5)); //z y x for ((z, y, x), value) in arr.indexed_iter() { do_smth(x, y, z, *value); } /* 0, 0, 0 1, 0, 0 2, 0, 0 3, 0, 0 4, 0, 0 0, 1, 0 1, 1, 0 2, 1, 0 */
How do I know, if I can trust a crate? E.g. if I want racer, I get a lot of dependencies pulled in and while I can in some way trust the racer developers, I don't know about the dependency of a dependency and so on. This means that cargo pulls a lot of untrusted code which in turn I execute ... and sadly a lot of crates have a huge amount of dependencies. How do you handle this?
This is similar to [an earlier question about game progamming](https://www.reddit.com/r/rust/comments/61n1os/i_spent_the_weekend_playing_around_with_rust_have/), where some objects in the game world need to be able to change the world around them. I'll suggest the same thing here i did there - rather than having the command change the list of commands, have it return some object, an edit instruction if you like, which the top-level loop will then apply to the command list. The edit instruction needs to be able to outlive the borrow of the vector and command it was created in, and that lets you kick the mutation can far enough down the road to be able to do it. Does that make any sense? 
Ah I missed the 50% coupon at some point for that book, hopefully it will come back!
I haven't tested, because it wouldn't be very meaningful. The rctree is not a very efficient or cache-friendly data structure for most workloads, because each node is in a separate location on the heap. If `T` is small, the cache misses are much more expensive than the overhead of `RefCell`, so it will only be a few % faster at best. On the other hand, if the size of `T` plus all the parent/child/sibling pointers is exactly equal to the page size, then the space overhead of `RefCell` will make it slightly larger than a page size and there should be a larger performance difference, but that's not a very realistic scenario either. tl;dr it depends.
I suspect the compiler isn't that smart - yet. But premature anxiety can be a problem ;)
It is because you don't have the ownership of your ladderhatches, you only borrowed them.
It puts you in the file where the function definitely is. You *do* have to search for `fn contains`, but you already know it's definitely in this file. As for `core_str`, just scroll back to the top and find it in the list of `use`s, which tells you which file to open next. My point was that this lets you find what you're looking for without having to either guess or grep through all the base libraries.
Well.. unless `Drop` doesn't free any memory. After all, you can't have user after free if you don't free. Actually I think we could have a `LeakyBox` that is like `Box` but implements `Copy`. The downside is that it leaks memory, but that's not a problem for a short running program. edit: uhm it would also require `T` to not be mutated. So more like a `Rc` without a reference counter.
Wow, that was Simon Peyton Jones congratulating Rust on its type system! That's something! (Here's [exact time](https://www.youtube.com/watch?v=wXoY91w4Agk&amp;feature=youtu.be&amp;t=33m42s) in the video when he talks)
I think I'm missing something, what's the point of the `replace_with` method? Why isn't `replace` enough?
The problem with this specific quest was all the unexpected abstractions. If you expect a simple implementation and find abstractions, that's confusing. The key insight in many of the indirections around the 'str' API (and some others in 'core' as well) is that, in order to be flexible, the functions aren't generic over 'str' at all (as that is locked down inside the 'core' crate, thanks to coherence) but that most are generic over their arguments. This allows you to use these types seamlessly in combination with types from other places. I think most of these abstractions can be made more graspable with comprehensive examples. So not only will you see some of the ways of using that function, but having multiple variants is a telltale sign of some abstractions being present. EDIT: minor corrections
Man, [that stabilise-drop-order RFC](https://github.com/rust-lang/rfcs/pull/1857). I kinda feel bad for @ncm; they clearly care a whole lot about the drop order of items in vecs and (possibly) arrays, but had a hard time communicating the motivation for that passion. I know very little about C++ myself, but if I had to explain their position: - Imagine some kind of multi-step process, and a program that manages that process - The program probably wants to keep track of the steps that have completed, so that it can finalize them in some way, or roll them back if something goes wrong - If there are internal dependencies between step records (like they have pointers to each other) then you'll need to think very carefully and wrestle the borrow-checker, or use a data structure that manages those dependencies (like maybe a graph or something), so it doesn't matter what the naïve drop order is, because you're not using it - If there are *external* dependencies between step records (like they're integer handles that represent an object in some externally-maintained structure), the borrow checker won't be able to stop you from just `.push()`ing them onto a `Vec&lt;T&gt;`, so that's what everybody will do by default - Step records are pushed onto a `Vec` in chronological order: Later records may or may not depend on earlier records, but causality ensures that earlier records cannot depend on later records - Therefore, if `Vec` drops its contents in reverse order, it can't do any harm, and it will very likely Just Work - On the other hand, if `Vec` drops its contents in forward order, it sometimes works and sometimes does Exactly The Wrong Thing If Vec always drops in forwards order, there's various possible workarounds: - Use `Vec::insert()` instead of `Vec::push()`: works, but much less efficient (and likely to get "fixed" by future maintainers) - Use `VecDeque` with `push_front()`: maybe works, what's the drop behaviour of VecDeque? Also, pushing to the front of a `VecDeque` is unidiomatic (according to its docstring), so still might get "fixed" later - Use a custom wrapper around `Vec` that controls drop order: works, and makes it clear exactly what behaviour you require that's different from the standard `Vec`. However, this cuts you off from third-party libraries that understand `Vec` but not your custom wrapper, or require you to un-wrap and re-wrap in various places. You may also need to wrap other Vec variants people have added for type-safety reasons. The example I imagined is an application for managing shipments out of a warehouse: the app knows "packages X, Y and Z need to go on a truck", and when a truck arrives, it directs the warehouse workers (robots?) to load them up. Once all the packages are loaded, the application marks them all as "shipped" and dispatches the truck to its destination. If a particular shipment is supposed to contain 100 different items, but at loading time it turns out that item #35 is damaged, all the items loaded before then need to be unloaded, so the truck can be used for a different shipment. The loaded items need to be unloaded in some particular order, but it's not at all obvious to the application what that order is: a given item might be right near the entrance, or it might be beneath a huge stack of other items, depending on what the warehouse workers thought was best. The only guaranteed unloading order is the reverse loading order, since that way items at the top of the stack will be unloaded first.
I don't think there's too much generalization going on there. Or at least, I don't see a way to reduce the generalization without introducing code duplication. However, I do think this highlights a problem that exists in Rust, and in many other programming languages as well. Say you have a line of code let a = b.foo(); it's pretty difficult in general to go to the implementation of `foo()`. I've actually found it incredibly useful that in Rust you can search for "fn foo" or "struct Foo" and (unless there are macros involved) you will find the definition of foo. Unfortunately, if there are many other places that also define a function "foo" (testcases can be annoying here), you'll find a lot of other stuff as well. Like I said, this is a problem in many other languages as well, but in some of those languages, the problem is sometimes mitigated by an IDE that's good at "jump to definition". The ~~Rust Language Server's~~ *jump to definition/implementation(s) in IntelliJ* works decently, but for `"abcd".contains("bc")`, it unfortunately strands [here](https://github.com/rust-lang/rust/blob/03198da2add75a0bcec792ffd84fcc8d94e8637e/src/libcore/str/mod.rs#L2021). Hopefully, improvements to RLS will make it possible to navigate from `"abcd".contains("bc")` all the way to the implementation in `TwoWaySearcher`. Also, another problem that I've noticed in the Rust compiler's source code is while it's very well-documented and there are lots of detailed comments, those comments mostly describe the details of what's going on. They don't really describe how that bit of code fits into the rest of the system as a whole, instead they assume that you already know that. This makes it pretty hard to "get into" the rustc source code from zero (where do you begin?). I don't really have any good suggestions here though, because comments/documentation describing the system as a whole risk getting outdated, and having wrong documentation is probably worse than having no documentation at all.
The only real way is to read all the code. This is true in many, many ecosystems, and most people just don't even think about this question, honestly. I went to a conference one time. One of the speakers dropped off business cards that said the equivalent of "cargo install $conferencename" on them, and nothing else. His talk title was a secret. The first part of his talk was "A third of the conference installed this gem, and I could have owned you. Don't do that."
So I don't actually try to push while in the search, only after I return from the searching function. But maybe there isn't a difference? Take a look at the playground I linked under coder543's thread.
These are fair points, but I'm not too sure about designing a language and/or writing code and thinking "this is good code" under the assumption that we have great tools to basically undo all the abstraction layers that we ourselves have written. Also, I think the problem of code duplication is widely overrated, but that is a topic for another time :) 
So, the CmdView isn't altered, but fetched. From the fetched CmdView, I try to add a new CmdView to Vec&lt;CmdView&gt;. Did I understand your meaning? Take a look at the playground posted under coder543 above.
Yes, it gives us a way to definitely find what we are looking for. However, I'm not sure if that is supposed to be something we should think is a good thing about our ecosystem, or if it is simply a minimum baseline. My point wasn't "oh no there is literally no way to find this out so we just **have** to guess", but that it isn't straight forward see where things are.
It says "Release Date: March 2016". Is it still unreleased though? While it's not released for real, is it being updated with modern Rust stuff? (like `?` instead of `try!` in Chapter 7: Error Handling)
Following redirects automatically is not part of hyper anymore. But! You can easily check the status code and trigger a new request yourself! Or, the reqwest upgrade should be merged today...
Yeah, LaTeX slides are not for everybody :) I've gotten to like them though. Easy version control, macros for reusable things, fantastic font support with stuff like microtype optimization. And in the end you get simple PDFs that work everywhere.
March 2016 was when it became available for early access, with only a few chapters released. As for `?`, I do believe that Jim has said that he intends to keep this book up-to-date as the language evolves.
They definitely look great. Which editor do you use?
In Rust idiom, `with` implies you're using a closure in order to avoid allocation of the thing you're doing unless it is actually required--similar to `else` on the option/result types. It's the difference between: `foo.unwrap_or(CONSTANT_VALUE)` and `foo.unwrap_or_else(|| unevaluated_function())`. The latter option is cheaper if there is any real work to be done in getting your fallback value. Edit: I'm assuming you're not asking "why" as in "what is this example code *for*," in which case... I'd say it's for an example? oO
&gt; The latter option is cheaper if there is any real work to be done in getting your fallback value. That's what I'm missing, what makes it any cheaper than just evaluating your value before calling the method?
I've had a flip through the ebook - I don't think it offers considerably more than the Second Edition of the official book (https://doc.rust-lang.org/stable/book/second-edition/index.html).
Oh! Ok, so, in this example, I doubt it matters; I think the author was just kind of demonstrating a rustic api. I say that because "replace" doesn't seem optional, you know what I mean? It seems like it's going to happen eventually no matter what. But the reason that kind of an api is offered to begin with (and I hope someone will correct me if I'm wrong on this) is that the *closure* is free (like, doesn't cost you anything in terms of memory or cycles) at runtime, but evaluating something may or may not be. foo.unwrap_or(0); // free foo.unwrap_or(expensive_function_call()); // not free foo.unwrap_or_else(expensive_function_call); // free unless needed The significant point is that you are going to call the method `unwrap_or` or `unwrap_or_else` no matter what, but you may or may not require the fallback value. Edit: found a real life example of `with` being used in this way in the code I'm working on: let foo = *dictionary.entry(u).or_insert_with(|| { count += 1; count }); Here, I'm doing this so that I don't increment the count unless I need to insert a new value. In this case, it's not so much to make the code more efficient as to just succinctly encode my intent, but the point is that I'm saying, "If you need to insert something, do it *with* this function." In contrast, there is also `entry(u).or_insert(foo)` that would insert a given expression if necessary... But, in short, the expression must *always* be evaluated, where the closure may or may not be.
missing an unwrap there, it looks like, on this line: views = (cmd_view.unwrap().cmd.exec)(&amp;mut views); but, this line is interesting anyways. Why does exec need to modify the existing ViewList, and then return a ViewList? it seems like it should just be one or the other.
Isn't impl trait going to help here?
&gt; it's next to impossible to talk about these things and oppose the opinions of people Except, of course, there was plenty of opposition in that thread, with valid reasons ("We prefer bad_style because we like the fact that it is explicit"). This opposition was well-received -- folks disagreed with the opposition, but they didn't snub it or anything. &gt; Do you really want a precedent that basically allows policing of anyone's code, documentation, comments,... basically any form of expression related to Rust for reasons that are basically arbitrary? This wasn't "policing"; it's pretty dishonest to frame it that way. There was no "we must do this" attached to it. There was no "let's scour all codebases and force them to change" attached to this. It was a thing based on community opinion, and the community mostly agreed; so it will probably happen. It's an extremely minor change. Would this mean we go out looking to "fix" language everywhere? Probably not, aside from extreme cases. Again, it was a minor thing. If someone notices something that could be made nicer, we'd probably merge it, but we've always done that. (In this case it needed the FCP thing because introducing a new lint name is something we can never revert). Would this mean that we would force arbitrary rust libs to fix things like this? No. There was no forcing here either, what makes you think there will be forcing in other cases? &gt; are people with a distaste for some expressions who are basically playing the victim card to lend credibility to their opinion Please don't assume stuff like this. She just mentioned it as something that came up when teaching a coworker Rust, to motivate a point she was making (the point was unrelated to the actual lint). And this isn't the first time I've had folks dislike the name of that lint when learning Rust, so I filed the issue. &gt; But the original reason the issue was opened is that @ashleygwilliams likes to actively look for things that are not politically correcrt enough and could be in some ways (even if it's a long shot) considered offsensive or not nice enough. See here and here. Uh. I opened the issue originally. Please don't ascribe my intentions. Ashley didn't even open those issues you speak of, but even if she did, so what? And you shouldn't ascribe her intentions either even if she did open this issue. And there was never anyone saying that people are experiencing trauma because of this. Just "It's somewhat shaming, why not change it?". I find feeling ashamed when you're told "your style is bad" is a pretty normal thing. I wouldn't expect people to be too worked up about it (indeed, whenever folks have mentioned this to me it's just been on the side as a "btw why is the compiler mean about this", not something that stops them from using the language or whatever). There's plenty of space between "experiences trauma because of a thing" and "is totally ok with it". You've painted a very different picture from what actually happened. You seem to have some grudge with Ashley and are viewing all actions through a very skewed light. Please stop.
It could work, in theory, but all of that effort doesn't come from nowhere. Who does that work? Can you trust *them*?
Imho the author contradicts himself! He claims that abstraction is good, as it keeps the uninterested details away. So does the example of ``contains`` 😉 The *implementation* is the detail, that comes with the *cost* of indirection. Often you must spent much effort in pushing a language to its limits in order to provide a damn simple API. Imho that's totally ok and in a way unavoidable, if you wanna keep the API abstraction level high. So what is better? Providing a poor API in order to keep the implementation simple, or deliver an excellent API with the cost of not so simple details? (Which doesn't mean that the building blocks cannot be simple too; often they are, if one grasps the meaning of them - only the picture might be too big that it feels damn complex) I prefer the latter option - PHP's early sorting functions should be a big warning for anybody: implementing n times a quicksort because of n supported base types... arghhh!!! 
Basically execute your commands, gathering up all mutations to the command list. Then when that is done, mutate the command list with any changes.
I suppose, that's true. But that means also a huge inconvenience not only once, but every time you update a dependency for a project or a program.
This is a project I made with the [RTFM] framework and [embedded-hal] (\*), a WIP Hardware Abstraction Layer that I hope will become the base of the embedded crate ecosystem, to test the suitability of both projects for building applications more complex than single task applications. [RTFM]: http://blog.japaric.io/fearless-concurrency [embedded-hal]: https://github.com/japaric/embedded-hal Currently the firmware lets you remotely [control] the robot using a sixaxis controller while the robot [reports] its state (motors speed, CPU) over the same Bluetooth (RFCOMM) interface. [control]: https://mobile.twitter.com/japaricious/status/843971417083432961 [reports]: https://github.com/japaric/2wd/tree/master/logcat The robot has a few, currently, unused sensors on board: an ultrasonic sensor, for measuring distance, and reflection sensors, for a line following mode. I'll eventually write the code to use those. Happy to answer any question about this project. (\*) embedded-hal is still in design phase so I'd appreciate if you would join the [discussion]. [discussion]: https://github.com/japaric/embedded-hal/issues
Oh man, Rustconf is really close to where the eclipse is going to be total. And Rustconf starts on the 19th, while the eclipse is on Monday the 21st. Is anyone going to the conference thinking about sticking around an extra day and driving a little south to see the eclipse?
We are slowly making progress on that. I've recently described our todolist app example (https://github.com/PumpkinDB/pumpkindb-java/blob/master/examples/todolist/src/main/java/org/pumpkindb/examples/todolist/Main.java — this is Java code using a remote PumpkinDB server, but can be rewritten in Rust easily) in another article: https://blog.eventsourcing.com/removing-obscuring-abstractions-392e74284e47 Also, we're looking for "outsiders" help coming up with good examples. I'd encourage to join our chat room at https://gitter.im/PumpkinDB/Lobby if this is of any interest!
Fix is currently deploying. It's always the last "tiny text change" that breaks it :). https://github.com/skade/elixirstatus-web/commit/2ad28d1777500a05d0c57841738e58527b6298ae#diff-c9286564f36b4dc6491d33d908d7a635L1 (see the stray character introduced in line one...)
Haha, know how that goes :) Just wanted to make sure you guys knew about it^^
There's no such thing as a free lunch, sadly. If you want code for free, you pay somehow.
The message was changed because people were confused: how can Rust be memory safe if it segfaults? With a specific message, it's easier to put their mind at ease pre-emptively :)
Really glad to see that proper Semantic Versioning is back.
Neat, I'll give this a read this afternoon, thank you!
Good to know, thank you! Does debcargo also work, if you have dependencies on c libraries? Yes, but python is a bit better in my opinion, because you have at least for the libraries I needed so far much less dependencies than the Rust libraries I used and therefore much less to check. But that might not be the case in general.
That's a cute analogy, except you wouldn't use Drop to unload items from the truck (and mark them as un-Shipped). After all, in the normal case, nothing is damaged and the truck goes off to deliver items, and everything stays Shipped. So since you're not using Drop to deal with this at all, the order of Drop is irrelevant, and instead you'd probably just use something like `items.into_iter().rev()` to unload items.
That's exactly what I had in mind.
Done!
Pcwalton also submitted a patch that optimizes memcpys and should have a big impact on moves in Rust, but apparently it got stalled. Anyone knows what happened to that one?
**UPDATE:** This was caused by using the latest version of xargo, downgrading to 0.3.7 succeeds the build. Humm.. getting into problems after having built according to your documentation: $ rustc --version rustc 1.18.0 (03fc9d622 2017-06-06) $ rustup default avr-toolchain info: default toolchain set to 'avr-toolchain' $ rustc --version rustc 1.18.0-dev (c0a4f0b92 2017-06-18) $ sh build.sh --verbose + "rustc" "--print" "sysroot" + "rustc" "--print" "target-list" + "cargo" "build" "--release" "--manifest-path" "/tmp/xargo.bwR6n525y6sP/Cargo.toml" "--target" "avr-atmega328p" "-v" "-p" "core" Updating git repository `https://github.com/gergoerdi/rust-avr-libcore-mini` error: failed to run `rustc` to learn about target-specific information Caused by: process didn't exit successfully: `rustc - --crate-name ___ --print=file-names --sysroot /home/nano/.xargo -Z force-unstable-if-unmarked --crate-type bin --crate-type rlib --target avr-atmega328p` (exit code: 101) --- stderr error: unknown debugging option: `force-unstable-if-unmarked` error: `"cargo" "build" "--release" "--manifest-path" "/tmp/xargo.bwR6n525y6sP/Cargo.toml" "--target" "avr-atmega328p" "-v" "-p" "core"` failed with exit code: Some(101) note: run with `RUST_BACKTRACE=1` for a backtrace Any idea?
Yeah, as far as Rust is concerned, the type returned only implements that bound, which is good because when it spits errors out it will spit out far nicer ones.
Vim :) With a macro to build (basically just "run make") and preview the slides in a separate window.
Wrong subreddit?
Can you elaborate on how the differences in memory layout between `Arc` and `shared_ptr` require additional copies for promotion? I understand that the promotion isn't possible because the functions aren't provided, but your technical reasons seem off to me. In either case the raw pointer should be reusable.
And I finally have some rust code running on my atmega32u4, thanks a lot for the instructions!
Awesome!
 extern crate serde_json; use std::fs::File; use std::io::BufWriter; use std::io::prelude::*; fn main() { let mut output = Some(BufWriter::new(File::create("tmp.txt").unwrap())); if let Some(ref mut f) = output { serde_json::to_writer(f, &amp;[1, 2, 3, 4]).unwrap(); f.write(b"\n").unwrap(); } } error[E0382]: use of moved value: `*f` --&gt; /home/rgo/src/imoria/icmoria.4.85.22/examples/serde.rs:12:9 | 11 | serde_json::to_writer(f, &amp;[1, 2, 3, 4]).unwrap(); | - value moved here 12 | f.write(b"\n").unwrap(); | ^ value used here after move | = note: move occurs because `f` has type `&amp;mut std::io::BufWriter&lt;std::fs::File&gt;`, which does not implement the `Copy` trait This is expected result. But the two questions arise: 1. If value of f moved into to_writer, how could it be possible to use output after if? If BufWriter moved from main, it should be inaccessible in main, isn't it? 2. What can I do to write \n after serde's output, without second if Some(ref mut) ...? Here demo to (1): fn main() { let mut output = Some(BufWriter::new(File::create("tmp.txt").unwrap())); if let Some(ref mut f) = output { serde_json::to_writer(f, &amp;[1, 2, 3, 4]).unwrap(); } if let Some(ref mut f) = output { f.write(b"\n").unwrap(); } } It works and I can't belive it. upd. Forgot to add declaration of to_writer: pub fn to_writer&lt;W, T: ?Sized&gt;(writer: W, value: &amp;T) -&gt; Result&lt;()&gt; where W: Write, T: Serialize, 
I think you're referring to this? https://reviews.llvm.org/D23470
I haven't seen many vendors do that, which doesn't surprise me too much, as IIRC the C standard doesn't make very strict requirements on how bit-fields get laid out (in reality, compilers *probably* just do what you want though). In any case, a bit-field like structure is what I want (or something like Ada's representation clause where you can specify the exact layout of a type). Having "references" to bits is just a way of simulating that, i.e. I can have a function that returns a reference to a bit so you can either read the bit or write the bit. In C++ "references" to bits are achieved through a proxy type, something like: class ReferenceToSecondBitOfInt { int&amp; ref; ReferenceToSecondBitOfInt(int&amp; ref) : ref(ref) {} operator int() { return (ref&gt;&gt;1)&amp;1; } void operator=(int value) { ref = (value&amp;1)&lt;&lt;1; } }; This type keeps a reference to an int, but overrides the assignment operator and provides an implicit conversion to int that performs the necessary bit shifting. It looks like in rust, I'll probably just end up having a struct to represent a register and a get and set method for each field (probably generated by a macro). I'd be really happy if rust ever gets some kind of bitfield/more advanced representation options though.
Edit: resolved, just had to revert my lock file after a `cargo update`. What happened to 0.3.1? My local crate depended on that because it needed Serde 1.0, but needed 0.3.x to work with Diesel. Now my crate can't compile at all and it seems there's not much I can do about it. What Chrono did with 0.3.1 caused problems, but that could be worked around by rigidly specifying 0.3.0. By yanking 0.3.1 it seems those using Chrono and Diesel are in a bit of trouble. What should have happened is 0.3.1 should have become 0.4.0 and then 0.3.1 could have been yanked, then do today's release as 0.5.0. I don't mean to come off rudely; Chrono is fantastic and I'm indebted to the author for providing a great date and time crate which I use for a number of my projects. This morning I need to build my crate though and I seem to be really stuck for options.
Diesel depends on chrono `^0.3` so I think it should be fine with 0.3.0.
Yes, that's the patch I had in mind.
&gt; Rust intentionally doesn't have overridable `=` operator to make reasoning about performance easier. You could still make `=` overridable by requiring an `unsafe` clause in the declaration, though. Maybe someone should write an RFC for that.
Didn't know about this. A good amount of jobs already!
I don't think it's your fault either, but can you define "working perfectly"? That's the point of a lock file, to keep things working, so if there's a situation where lock files don't get created I think that's a tooling issue. It sounds like both ways can get into this situation where `cargo build`/`cargo update` creates crate combinations that don't work, but I thought it was much harder for that to arise when SemVer is followed. Again diesel doesn't depend on serde so I'm missing context.
The top level binary still builds, but I wanted to do some development on the dependent libraries today (which don't have checked in lock files and I don't have a local lock file.)
`Option::take` was "recently introduced"? #[inline] #[stable(feature = "rust1", since = "1.0.0")] pub fn take(&amp;mut self) -&gt; Option&lt;T&gt; { mem::replace(self, None) } Well, rust *is* a pretty young language...
The main issue for me is actually just that I can't work on the library crates myself (it's just an internal one and I had some work I wanted to knock over today.) BTW, cheers for talking this through with me, it's given me a couple of ideas to see if I can work around it.
&gt; It could also introduce performance problems on certain workloads, due to cache line sharing between the refcounts and the data. Thanks for reminding me to add such a benchmark to [froggy](https://github.com/kvark/froggy), which aims to address this problem ;)
EDIT: The following is not official SemVer, but I thought it was. Not quite. SemVer is basically the same with 0.x, except you can think of all of the digits having been pushed back by one. Which means that, according to SemVer, the following version bumps are similar: 0.1.x -&gt; 0.2.x 1.x.x -&gt; 2.x.x 0.1.1 -&gt; 0.1.2 1.1.x -&gt; 1.2.x ...with the caveat that a version starting with "0.x..." has yet to have a first stable release. :)
If you just want to continue library development with serde 1.0, chrono 0.4, and diesel 0.13 you can use Cargo's `replace` feature with a local (or remote) version of diesel. This will *not* allow you to upload your project to crates.io while you've got replace activated. Something like this should work: $ git clone https://github.com/diesel-rs/diesel ~/src/diesel $ cd diesel $ git checkout v0.13.0 $ vim Cargo.toml &lt;replace chrono version to 0.4.0&gt; $ cd $myproject $ echo ' [replace."diesel:0.13.0"] path = "~/src/diesel"' &gt;&gt; Cargo.toml I'm pretty sure you can change `path` to `git` and use an e.g. github url if you want to share your work (or avoid cloning it and use /u/eijebong 's existing fork). The version in replace must be specified exactly (what I placed there won't work for diesel 0.13.1). 
No it's impossible. Your code "expands" to void take(Self const&amp;&amp;* this) {...} Note that `this` is always a pointer no matter what. And pointers are `Copy` types (in Rust term). **EDIT**: This is just an intuition and is not quite correct. See @dodheim's reply for a proper explanation. More information can be found on [cppreference: member functions](http://en.cppreference.com/w/cpp/language/member_functions).
&gt; The difference is the memory layout of the allocation, not the pointer value (which is just a pointer in both cases), It took me a while to grapple with this, initially I thought that the count was stored with the pointer, but that makes no sense as each instance of the arc would be duplicating counts!
I'm not sure why you are storing them by reference, but: 1) I'm not sure in what version, but soon you are going yo be able to drop the 'static (it will be infered) 2) You can store it by value 3) You **can** use a macro here but that seems like a really bad idea
So, normally if you wanted data in an enum, you'd use something like enum Directions { Up(Point), or enum Directions { Up { x: i32, y: i32 } But in this case, you want each enum to hold one single value, and the variant always holds that data. I would instead do this: enum Directions { Up, Down, Left, Right, } impl Directions { fn as_point(&amp;self) -&gt; Point { match self { Up =&gt; Point { x: 0, y: -1 }, Down =&gt; Point { x: 0, y: 1 }, Left =&gt; Point { x: -1, y: 0 }, Right =&gt; Point { x: 1, y: 0 }, } } } Or maybe even impl Directions { fn as_point(&amp;self) -&gt; Point { let (x, y) = match self { Up =&gt; (0, -1), Down =&gt; (0, 1), Left =&gt; (-1, 0), Right =&gt; (1, 0), } Point { x, y } } } Not sure which one reads better...
&gt; the Rust community We sorta stole this because most major implementations of semver do. I've always wanted to submit it upstream...
doesn't that mean cargo doesn't follow semver? edit: and in that case, what do you buy for yourself (and the community?) by claiming you follow semver-except-for-this-one-bit-we-don't-like when semver was supposed to be the Second Coming to save us all from, like, _this exact situation_...
I didn't downvote but that's not quite correct; there is no free-function equivalent for this because you cannot form a pointer to a reference and you cannot take the address of an rvalue to begin with. The closest kinda-equivalent is `void take(Self const* this) {...}` with the magical, implied, un-directly-fulfillable requirement that the object whose address is passed be an rvalue. Note that `this` is **always** a prvalue that produces an lvalue when dereferenced; i.e. `*this` is never an rvalue, regardless of any reference qualifier on the member function. 
Yeah I agree. As I mentioned in my other comment every community I've seen treats semver more like rust does than like it is specified. Thinking about this thread made me want to write a `semver-rust` or `semver-strongnaught`RFC, too. There's definitely a need.
**edit:** The sibling conversation is more accurate than this. In particular "follows semver" is not a well-specified term :-) Yup, cargo does not follow semver. But it seems like everyone agrees that SemVer is buggy in its 0.x specification. Look at what it [has to say about minor versions](http://semver.org/#how-should-i-deal-with-revisions-in-the-0yz-initial-development-phase): &gt; **How should I deal with revisions in the 0.y.z initial development phase?** &gt; &gt; The simplest thing to do is start your initial development release at 0.1.0 and then increment the minor version for each subsequent release. Interestingly (perhaps) you can perfectly emulate SemVer in cargo by simply releasing *only* minor revisions (no patches!) before you hit 1.0. Since SemVer treats every version pre-1.0 as a breaking change, there is no distinction between these series: 0.1.0 0.1.1 0.1.2 0.2.0 0.2.1 0.2.1 0.2.3 0.0.1 0.0.2 0.0.3 0.0.4 0.0.5 0.0.5 0.0.6 0.1.0 0.2.0 0.3.0 0.4.0 0.5.0 0.5.0 0.6.0 0.0.1 0.1.0 0.1.1 0.5.0 0.5.5 0.9.9 1.0.0 That's... not useful. A good reason to choose SemVer is because it helps you to describe *how much work will be needed to upgrade* in a three-digit number. Throwing that away entirely for the infinite range of numbers in the 0.x.y range doesn't help anybody. In practice, Cargo's rules allow much clearer communication than SemVer allows. I'd be a little surprised if an eventual SemVer 3.0 didn't follow something more like Cargo's rules than the current spec. 
Ah thanks. I thought that since they were at global scope they required the 'static scope specifier which required it to be a reference. TIL that's not the case. static HI: i32 = 0;
&gt; Or use `consts`, which let you get away with all references Is there an advantage to all references? Is there any codegen (or otherwise practical) difference vs. static values?
A simple struct like this should optimize _very_ well, I wouldn't worry about it a ton. It's just two integers, no heap allocation, etc. You could make them constants too, but then you lose the enum-ness. 
This works great, thanks!
So in the case of a `const` reference, each time the `const` is used a new temporary is created and a reference bound to that, with nothing in the data section?
That was a short development downtime while database migrations were running. I'll have to see if Heroku gives me a way to do that automatically :(.
It still won't imply a move in any way...
I don't want to mislead you. I haven't validated this by looking at assembly or anything, but what you said does match with my understanding of how const works, and based on that alone I'd say: yes, modulo LLVM being clever. I fully expect "static =&gt; data, const =&gt; inline" to be more of a rule of thumb than a guarantee. For instance, if you had `static s: &amp;i32 = &amp;1` and `const c: &amp;i32 = &amp;2`, I wouldn't be too surprised if LLVM can see through that and do some constant folding + dead code elimination to ultimately treat them identically. Maybe I should research this more before commenting on it myself :D
Thank you for the explanation! I'd been wondering about this lately and had decided that a `const` reference must create a temporary and bind to that with `'static` lifetime, so I figured it would go in the data section, too, effectively making it the same as `static`. I like it better the way you've explained it, as it at least gives `static` and `const` distinct behavior.
Which directly contradicts your statement "it won't IMPLY a move"
From ETCDEV offer: &gt; Proficient with spoken/written English, excellent communications *stills* (Emphasis mine) Kinda ironic, don't you think? :)
OK, thanks for info!
No, it doesn't — binding to a reference (lvalue _or_ rvalue) does not _actually move_ anything; it merely makes the type _eligible_ to be passed to a move constructor/assignment operator.
Yep! I eventually figured out (and that's why that `Leak` crate simply returns `&amp;T` - it's the same as returning my `LeakyBox&lt;T&gt;`)
That is correct, although the value itself will be dropped when the strong count reaches 0
I'm happy with Iron because I understand its internals, all concepts are really simple and compose well. It also works with stable Rust, while Rocket requires nigtly (that's what its README says).
&gt; I thought it was opened on Ashley's behalf. It was not. I was literally sitting in the audience during the talk and was like "oh this is the nth time someone has mentioned this maybe i should open an issue". &gt; A compiler (ie. not a person or even someone's crush or the like) Felix already mentioned this, the compiler is written by people. Just because something is machine generated does not mean you can abdicate all responsibility for any emotions it may cause. &gt; but then someone comes and markets that as a some kind of a cause nobody did. again with the viewing actions through a skewed light. It was just a "oh hey maybe we should change this to be nicer" issue. Nobody would have minded if it didn't land. Folks supported it, and folks opposed it. The folks opposing it were amicably debated. Like any other normal bikeshed. &gt; Newcomers probably complain because they are used to a coding style from some other language (which is pretty normal too) and simply don't realize code style per se is rather unimportant compared to being consistent about it. no, every time I've seen this complaint it's not because they "simply don't realize code style per se is rather unimportant compared to being consistent about it", it's often experienced programmers making this complaint. They understand all that, they just want to sidestep it when learning (because they're still getting used to it and it's additional friction), and are surprised with the wording of the recommended way to sidestep it. &gt; Hah, not really, no. Yet you: - Imply that you would have a larger issue with it if it were posted by ashley - Seem to be intent on assuming that I was asked by Ashley to post this - Used two examples of _other_ threads which were not opened by her but had her slight involvement deep in the comments as cases "where she has done this before" Your first comment was quite focused on Ashley in particular. This is borderline ad hominem, I suggest you reflect on what assumptions made you make those statements and refrain from assuming such things in the future.
Rust *does* support polymorphic dispatch; they're called [Trait Objects](https://doc.rust-lang.org/book/first-edition/trait-objects.html). Here's something similar to your code which *does* compile: trait Foo { fn foo(&amp;self); } struct Bar; struct Baz; impl Foo for Bar { fn foo(&amp;self) { println!("Bar"); } } impl Foo for Baz { fn foo(&amp;self) { println!("Baz"); } } fn main() { let bar = Bar; let baz = Baz; let mut foo: &amp;Foo = &amp;bar; foo.foo(); foo = &amp;baz; foo.foo(); } However, there are some restrictions on when you're allowed to create trait objects. Run `rustc --explain E0038` for the details. It might be for one of those reasons that you're not able to take a polymorphic reference as you should, or it might actually be that the signature of `opponent()` doesn't work in this context. It would need to be `fn opponent(player: &amp;GameAgent) -&gt; &amp;GameAgent`, rather than using a type parameter, like `fn opponent&lt;T: GameAgent&gt;(player: &amp;T) -&gt; &amp;GameAgent`, since Rust wouldn't be able to tell what type you were calling `opponent()` with in the latter case.
The easiest way to summarize the difference between C++ and Rust move semantics is "Rust move semantics are static, C++ move semantics are dynamic". This is analogous to static vs dynamic types in the way you might expect: if you try to use a moved value in Rust you'll get a compile-time error, and in C++ you'll get a runtime error.^† C++'s `&amp;&amp;` corresponds most closely to a poor man's version of Rust's `&amp;mut` (notably *not* the occasionally-proposed `&amp;move`): an unaliased reference which allows memory owned by the referent (but not the referent itself) to be safely invalidated. This can be seen in how "moving out" in C++ involves setting the source object to some kind of null or empty state, much like `Option::take(&amp;mut self)`; how "move construction" works similarly to `mem::swap(&amp;mut T, &amp;mut T)`; and how C++ restricts implicit formation of `&amp;&amp;` references to temporaries, because temporaries are the only case in C++ where you can be *certain* that something is unaliased, and the initially strange "an `&amp;&amp;` reference with a name is no longer an `&amp;&amp;` reference" rule is explained by the fact that once something has a name, it is possible to form aliases to it (and C++ extremely conservatively just always assumes that one might exist). ^† (Or worse, UB; but I don't think there should ever be a reason to do that in practice, given that you *need* some kind of distinguished state you can check for in the destructor, and if you have that then you might as well check for it on accesses as well, so you can abort cleanly?)
 #include &lt;iostream&gt; struct A { A() { std::cout &lt;&lt; "default constructor" &lt;&lt; std::endl; } A(A&amp;&amp;) { std::cout &lt;&lt; "move constructor" &lt;&lt; std::endl; } void foo() &amp;&amp; { std::cout &lt;&lt; "&amp;&amp;-overload" &lt;&lt; std::endl; } void foo() &amp; { std::cout &lt;&lt; "&amp;-overload" &lt;&lt; std::endl; } void foo() const&amp; { std::cout &lt;&lt; "const&amp;-overload" &lt;&lt; std::endl; } }; int main() { A a{}; // prints "default constructor" static_cast&lt;A&amp;&amp;&gt;(a).foo(); // prints &amp;&amp;-overload // A has not been moved. std::move(a).foo(); // prints &amp;&amp;-overload // A has not been moved. A{}.foo(); // prints "default constructor" + &amp;&amp;-overload // Still, nothing has been moved. } Note that `std::move&lt;T&gt; === static_cast&lt;T&amp;&amp;&gt;`. This code never prints `move constructor` because nothing is moved. Or in other words, `static_cast&lt;T&amp;&amp;&gt;` and `std::move` will cast a reference type to be of type r-value reference `T&amp;&amp;`, this type will then follow normal overloading rules. That is, if you pass an object of that type to a constructor/assignment, it will choose the best function that matches the type. If that function is a move constructor/assignment, the type is moved. But if you pass it to some other type of function, or not pass it to anything, the object is not moved. Independently, function ref-qualifiers allow you to overload functions depending on the type of the reference to the object's type they are called on. But as shown above, having a rvalue-reference to something does not imply that anything was or will be moved. The object might just be a temporary about to be destroyed, or somebody might have performed a cast to trigger that function overload. 
Noticed you implemented [using derive](https://github.com/llogiq/optional/commit/a224019b0741fa51974617603b70ae175be3f402), while it will certainly work to roundtrip serializing and deserializing it will create some unexpected serialized data. // With serde_json Optioned::Some(1.0f64) =&gt; { "value": 1.0 } Optioned::None =&gt; { "value": null } OptionBool::Some(true) =&gt; "SomeTrue" OptionBool::None =&gt; "None" Also when deserializing, `Optioned` will error when a field is missing whereas an `Option` field will become `None` struct Test { x: Option[ed]&lt;i32&gt; } // json {} =&gt; Test { x : None } // Optioned deserialize will give an error So while the derived implementations aren't wrong, I know I would expect the types to serialize to the same thing as for `Option`.
This is all true what you write, but I concur: a rvalue-ref-qualified method implies that something will be moved, probably some member of the class will be moved out of it and returned, such as in: template &lt;typename T&gt; class optional { // ... T&amp;&amp; get() &amp;&amp; { if (empty()) throw something(); return data_; } }; 
Hi! I wanted to chime in and hopefully clear up a few things from your previous comments. I hope that's alright! &gt; The three most important factors to me were longevity, repo activity and documentation. Rocket has been around since late December 2016, Iron has been around since late November 2014. Both are very actively developed, but many more issues can be found and fixed in 2 and a bit years rather than 2 and a bit months. You're absolutely right that Rocket is newer than Iron, but release date is a poor proxy if you're trying to gauge quality. I encourage you to read through Rocket and Iron's code if you're interested. Alternatively, you can read through Rocket and Iron's repository of issues. And, as far as repository activity goes, you'll find that Rocket is quite a bit more active than Iron. Rocket also has an active IRC channel (#rocket) where I and other Rocketeers regularly provide support and suggestions. &gt; As for documentation, last time I looked Iron beat all of the others hands-down on that front. I am very surprised that you feel this way. Rocket was released with both [a complete guide](https://rocket.rs/guide/) and [complete API documentation](https://api.rocket.rs/rocket/). I've tried to make Rocket's documentation as complete and welcoming as possible. I think if you were to take a look, you might just change your mind! &gt; As for limitations, Olivier Jensen’s blog post lists some of Rocket's fairly big ones. I read the blog post you linked. Unfortunately, it appears to be filled with inaccuracies. It would be a shame to base your decision on this one post! For instance, the poster's main qualms, related to form parsing, are answered directly in the [Form type documentation](https://api.rocket.rs/rocket/request/struct.Form.html). The poster's second issue, that Rocket has no concept of middleware, has been addressed since the post was written: a solution is shipping in 0.3. I've also already commented on the poster's third issue related to poor documentation. It may not be the right web framework for you, particularly if you are averse to using nightly, but I encourage you to take a second look at Rocket. And, if you find that you don't like it, I would love your feedback.
Rocket and Diesel are a killer combo.
&gt; I hope that's alright! Sure is! &gt; you'll find that Rocket is significantly more active than Iron Yeah, I have noticed that you've been steaming along with its development since release. &gt; Rocket was released with both a complete guide and complete API documentation. https://api.rocket.rs does indeed look very good. I don't remember it being so comprehensive last time I checked it out (a fairly long time ago) — I stand corrected! &gt; that Rocket has no concept of middleware, has already been addressed: a solution is shipping in 0.3 The lack of middleware was one of my main reasons for not going with Rocket. This is excellent news! &gt; It may not be the right web framework for you, particularly if you are averse to using nightly, but I encourage you to take a second look at Rocket. And, if you find that you don't like it, I would love your feedback. It seems that I need to re-evaluate whether or not it's the right framework for me once 0.3 ships. Either way though, I want to see more Rust on the web and I see developer activity in the space as nothing but a good thing. Healthy competition + different strokes for different folks and all that. Thanks for taking the time to update my understanding of where Rocket's at :)
 optional&lt;foo&gt; opt = ...; auto&amp;&amp; f = std::move(opt).get(); Still no moves here. Rvalue references are still just references, it's what you _do_ with them that matters. EDIT: &gt; a rvalue-ref-qualified method implies that something will be moved, probably some member of the class will be moved out of it and returned Key words: "will be". This is what I've been saying _all along_: ref qualifiers in no way mean that a move _has_ happened, just that one _can_ happen.
I've never been able to use `?`. Every time I try to replace `unwrap()` or `expect()` with `?`, I get a `trait bound Try not implemented for ()` or something. What am I missing? All over the web I see `?` in Rust code.
I think for things like jobs it would be better to have a `jobs.rust-lang.org` that is endorsed and moderated by the community team. Having something "more official" might help/encourage companies to use it. I would also find it useful if TWiR would be accessible through `twir.rust-lang.org` and also reviewed by the community team. 
&gt; a rvalue-ref-qualified method implies that something will be moved A rvalue-ref-qualified method doesn't imply anything, it _overloads_ the method so that it can only be called with rvalue-references. Nothing more, nothing less. T&amp;&amp; get() &amp;&amp; { if (empty()) throw something(); return data_; } Note in particular how `get` doesn't move anything since it just returns an rvalue-reference to data. If `get` really wanted to move data out (when possible) it should have this signature: T get() &amp;&amp; { if (empty()) throw something(); return move(data_); } (But it doesn't because moving data out of an optional is not `get`'s job). IMO the C++ language rules are often easier (and more useful to understand) that all of the pseud-conventions around them. They make using the language easier for those who haven't tried to understand it, but then these people are left in the dark in all the "corner-cases" in which these pseudo-conventions do not work.
Yeah that one had me puzzled for a good while...
The function containing the ? must return a Result
Author here. The official book is quite humbling; Steve and Carol have managed to raise the bar quite high. Still, I hope there's some value to slightly alternative angles. 
do you have a pet project one can have a look at?
Would it be possible to split rustdoc into its own crate (in the nursery) and move it to use something like `syn`, or maybe `libsyntax` (even though its nightly only) ? rustdoc has a lot of quirks, and contributing to it is not really easy :/
There are probably looking for people who have [these](https://www.istockphoto.com/photos/communication) as posters
Images in the RSS feed are broken. If I paste the URL in I get "Server internal error"
https://github.com/steveklabnik/rustdoc Steve is experimenting with exactly what you suggest. It uses the backend of RLS behind the scenes which should make rustdoc a _lot_ easier to hack on in the future.
&gt; then a 2.0 later, when there's potentially thousands of programs depending on the 1.0 APIs, it'll be a nightmare. IIRC something like this happened with the libc crate when it was updated from 0.1 to 0.2. The damage was so bad that I've actually seen people arguing that libc shouldn't be updated to 1.0 unless there are significant changes to 0.2 because of how hard it would be to upgrade the whole ecosystem. This is not true for packages other than `libc`, with extremely few exceptions. `libc` is a special case. When linking to a system library, you can only do that once, which means there can only be one version of a library that links to a system library in your dependency chain. A `libc 0.1` and a `libc 0.2` cannot both be linked to your Rust application at the same time. For crates like `hyper` and `tokio` that are not linking to system libraries, you can link to multiple copies at the same time and it won't cause your application to break. Rust is wonderful like that. So, releasing new versions is *not* something to be afraid of. The only possible or even conceivable problem comes when you have a library that's trying to return a struct from a different version of the library than what your application currently depends on, or requires a trait be implemented from their version of the dependency, etc. Then you have to handle things a little bit more carefully. `libc` is very much a special case, since virtually everything depends on it, which means that if a collision is possible, it will happen there, more so than with any other crate that links to a system library. So all of this talk about "painful churn" is predicated on a problem that does not exist in Rust. Each crate can depend on whatever versions of whatever Rust libraries that they need, as long as there is only one version of any library that links directly to a system library. This is why [the `-sys` naming convention](http://doc.crates.io/build-script.html#-sys-packages) is so popular, since those crates can be a complete, unsafe binding from day one, and then they virtually never need to be revisioned after that, which means linking will never be a problem, even if the safe wrapper library has multiple versions being linked at the same time. Which means `libc` is really the only crate this should ever be a problem for, as long as everyone else properly uses `-sys` conventions.
Definitely, I'm using OpenID Connect and SCIM as the standards I provide as an IDP. I haven't decided whether I'm likely to open-source it yet. Most likely yes, but still deciding.
This mindset is toxic. There is always something better around the corner - once all of this stuff you want is done there will just be another batch of stuff you want right behind. Waiting for 'done' just means you'll always be waiting. The healthier approach is to build change into your process. If you know now that a better api is coming, explicitly document the coming change in your current code. Keep your api surface area small so the changes don't have to be drastic. Make the consumer-facing api higher-level so most of the changes can be internal. Have a parallel nightly track so you can keep a running tally of all the points of conflict. Etc, etc. It's more effort but at least you keep moving.
To elaborate slightly on /u/Gilnaa's answer, which is correct: `?` returns the error from your function if there is one. It also attempts to convert the error to the one in the type signature of your function. `()` is the return type of functions that don't have one listed, that is, `fn foo()` is the same as `fn foo() -&gt; ()`. So `?` is trying to convert the error, but `()` doesn't implement the required trait, which is called `Try`. The only thing that does at the moment is `Result&lt;T, E&gt;`. So, if you use `?`, you have to use that as the return type of your function. This diagnostic is bad and we want to make it better but a fix hasn't landed yet.
While this may be true as a general guideline, I don't think it's realistic to say it applies to the current state of the Rust ecosystem. Certain features are more important than others in terms of how they affect API design. While Rust is young, the features that are most desired are likely to be more important to the way the language is used. There will be a point at which the new features that are on the horizon will be more "nice to haves" and not as fundamental as features like impl Trait, which _will_ be exposed as return types in public APIs. Edit: Another thing I thought of that's worth mentioning as a counterpoint to this: None of the features I listed were things I found just because I was browsing through RFCs idly wondering what was in the works. I learned about all of them because I was working on a real program, couldn't figure out how to express what I wanted, asked for help, and learned that I wasn't just doing it wrong, but that it wasn't possible because a needed feature didn't exist yet. This is very, very rarely something you'd experience with more mature languages.
I updated my comment several times since posting it, and I feel I briefly addressed that concern somewhat. It's definitely possible to encounter a situation where multiple crates are exporting types from different versions of the same library, and that will cause confusion, but how common do you think that problem actually is? `serde`, like `libc`, is an exceptionally popular crate, and it is unusually popular to re-export items from `serde` in crates that use `serde`, just due to the nature of the API. A crate like `app_dirs` could be linked a dozen times to an application, and you would never notice an incompatibility. Even so, upgrading to `serde 1.0` was minimally painful for the community. For a week or two, there was a transitional period where people were encountering the situation you described, but I don't think it was that long lasting. Even more importantly, it was possible to avoid the breakage simply by not upgrading dependencies. If my application worked before `serde 1.0`, it would keep working even after it was released. Once the dust settled and all of my dependencies offered a `serde 1.0` compatible release, I could choose to upgrade all of those dependencies at that time all at once, and update my application code to use the new `serde 1.0` interfaces as well. No pain, no suffering, no confusing struggle. Software is not necessarily easy, so there are always problems to be found. But Rust makes releasing new versions of crates infinitely more manageable than most other programming communities. In `golang`, due to the general lack of versioning, people maintain backwards compatibility at all costs. Because if they update their API, downstream users will have their code broken involuntarily. With Rust, the users generally have to volunteer to have their code broken, as long as the maintainer uses proper SemVer.
That's the kind of RFC that I'd like to comment on, but I feel like I'd need to take a day off just to read all the comments. I don't even know how people manage to follow a conversation with this github interface.
BTW, if anyone has some examples of popular libraries in other languages that released backwards-incompatible updates in response to a new language feature significant enough to change their API, I'd be curious to know about them and see how it was handled and how it affected users. (Python 2 vs. 3 doesn't count.) Edit: /u/apd mentions the introduction of `with` to Python 2 and the impact that had on API design in general in Python. Good example!
This thread is very pro-Rocket, and for good reason! Rocket is very cool. However, for me, I don't like developing on nightly, and Rocket is going to be on nightly for a long time. I would maybe make an exception if I wrote complicated web apps, but these days I mostly make simple, mostly read-only ones. As such, I started my own little framework: https://github.com/steveklabnik/sparkles It basically has enough stuff to power thanks.rust-lang.org, and that's about it. I'm not sure if it's useful to anyone else or not, and I still have to update it to hyper 0.11, it's using a pre-release right now. Hyper finally releasing 0.11 is going to cause a lot of change in the web ecosystem, as stuff will move to async. Rocket is the only major framework that's not built on hyper right now, though, so it's not likely to change in this regard, as far as I know.
We tried this a while back; it wasn't used and so it pretty much died.
What would that RFC contain? Just repeating what we already do?
as per usual, I update my comments way too much, so I would suggest re-reading mine right above yours, but I still strongly suggest not being afraid. These problems are definitely manageable. Serde was painless because of the way Rust handles dependencies, not really because of the size of the community.
&gt; doesn't that mean cargo doesn't follow semver? Cargo follows semver, but also has additional rules for under-specified parts. So it is compatible with semver. That is, semver says "you cannot assume anything about this", and so, us saying "we have these assumptions" isn't truly breaking, as you can still make no assumptions if you want; nothing would go wrong. This is subtle but IMO very important. (I maintain the `semver` package, and care a *lot* about following specs.)
I don't see the benefit of no exhaustive enums matches. Code should break when public enums are added as this is a public API change. Existing code that uses a wild card match still wouldn't break. And code that doesn't will need either decide if the enums are important to match or add a wild card.
Well, hyper is being used by a lot of people even though it's not stable. So, [the 0.11 upgrade to async](http://seanmonstar.com/post/161786147642/hyper-v011) was a breaking change just like an hypothetical 1.0 -&gt; 2.0 upgrade. If a library has a lot of real world users, keeping it in an 0.x version isn't doing it any favors. Eventually some 0.x version will become a de facto stable (an extreme example is the 0.2 libc).
&gt; For a week or two, there was a transitional period where people were encountering the situation you described, but I don't think it was that long lasting. Just noting that I am still in that situation. The dependencies update frequency has a long tale. 
Hi, you should probably post it on /r/playrust. /r/rust is the subreddit of the Rust programming language, not the Rust game.
Your crate hasn't been able to compile for months now? Or you're still using `serde v0.9`? There's nothing wrong with using an old version of a crate, unless there are security problems with it.
Only if you need to match against all variants. Sometimes an enum might only contain a constant and you would never need to ever match against the enum in the first place. Think of it as `Test::A, Test::B` instead of constants like `TEST_A`, `TEST_B`
So I just tried using it on my function which returns `Result&lt;bool, E&gt;`. I cannot use `try!` on a bool, I assume because it's a primitive and it doesn't implement Try?
&gt; But of course, it's pretty hard to argue over that one since it's entirely hypothetical It's not, you would have seen a certain kind of backlash to any opposition when people are that emotionally invested in a thing. People weren't. &gt; it's still miles away from interpersonal contact Yes, and interpersonal contact is not the only way to affect emotions. &gt; Not sure what the point is here The point is that your comments unfairly targeted Ashley here. You may not know her, but your first comment here was borderline ad hominem. &gt; I simply saw her as well as some other people participate in an effort of purifying software of bad words Except there was pretty much no reason to believe that -- she had not posted this issue or the other two issues you linked to yet you painted a very specific picture with very little to go on, and targeted her specifically. Reflect on that. &gt; I confess being aggravated by that, probably sometimes a bit too much than what would be necessary That seems extreme. It's not harming anyone when folks do that. These are like spelling fixes -- minor, low impact, but also don't take up mental space and are. There's no "political correctness" here. "maybe we can be nicer here" is not PC. Perhaps you're still aggravated by such things. That's your prerogative. That doesn't excuse the kind of borderline ad hominem targeting in the first comment.
Non-exhaustive enums are useful from the library author's point of view. It allows them to express the idea of an enum that _must_ handle the wildcard case, so that additional variants can be added without forcing a major SemVer version for the entire library. Right now there's no way to enforce that the consumer of a library matches against an enum in an forward-compatible way.
Ruby adding `:` over `=&gt;` and adding real keyword parameters changed the APIs of Ruby on Rails.
I am using 0.9. As you describe in your second paragraph, largely it is ok to stay behind. I am unable to update my dependencies while I wait for the last few to get with the program, but I can be patient. It is far easier than keeping my installed python packages in sink, but it has not just ban `a week or two`.
This is a very valid criticism. Whenever you add a tool, you can do all of the nice things the tool lets you do, but you pay with complexity. One of the things I like about C and Go is that they are easy to navigate. In C in particular, the only way I can really think of to break the "navigation flow" is function pointers, and usually they are not used when not needed. Here is the same exercise in Go, for example. I will intentionally not use any tools. The function is `strings.Contains`. So we go to [src/strings/](https://github.com/golang/go/tree/ac7f7ecaeb1261262963992496c2562c839fc272/src/strings). Here Rust actually gets a point, since in Rust each module has a single entry point (I think?), while in Go each file in a package can export module functions directly. (But Rust loses a point for * reexports which you sometimes find). So we must guess which file `Contains` is in. The file `strings.go` was my first guess and it's indeed [there](https://github.com/golang/go/blob/ac7f7ecaeb1261262963992496c2562c839fc272/src/strings/strings.go#L92). The definition is: func Contains(s, substr string) bool { return Index(s, substr) &gt;= 0 } OK, what is `Index`? Can't find in the file, so we gotta guess again. My first guess was to look in [`strings.s`](https://github.com/golang/go/blob/ac7f7ecaeb1261262963992496c2562c839fc272/src/strings/strings.s); maybe `Index` is defined in assembly. But that file is empty. Second guess was the `strings_&lt;architecture&gt;.go` files, maybe `Index` is defined differently for each architecture, which I assume is what these files are. Looking at [`strings_amd64.go`](https://github.com/golang/go/blob/ac7f7ecaeb1261262963992496c2562c839fc272/src/strings/strings_amd64.go#L26) it is indeed defined there and has the meat of the algorithm. So I'd say much more straightforward than Rust in this case.
&gt; Even more importantly, it was possible to avoid the breakage simply by not upgrading dependencies. If my application worked before serde 1.0, it would keep working even after it was released. Only with a lock file. Otherwise, if a dependency doesn't nail down it's required version of serde with the same specificity as the others, a new serde release can break your build. We saw this in the wild when a book chapter stopped compiling due to a similar issue with Iron plugins and a reader had to come here for help. IMO cargo treating "shared dependencies" such as serde or libc the same as independent dependencies is probably hostile to reliable builds. I hope the team ruminates about this while they work on futures, which they seem to intend to be another shared dependency.
 Maybe demand for Rust is increasing? (I definitely see an increasing trend in the number of jobs announced in TWiR). 
I meant: ``` fn my_thingy() -&gt; Result&lt;bool, io::Error&gt; { return Ok(true) } fn main() { ... my_thingy()? ... } ``` Wtf reddit formatting?
I was referring to a "week or two" of people starting new projects and running into incompatible dependencies, and then posting around Reddit and in forums. Now things are pretty well documented, so people seems to know what to do, or they've just stopped complaining, I'm not sure which.
Hmm, I think you are right ... the audit would be really great, but would require many people to be dedicated to this (and there might be more important tasks to focus on). But maybe a comment or some kind of bug report function on crates.io would be great (like in the AUR). Or is there a channel where I'd get the news that a package has a vulnerability or malicious code?
_I'm asking for more detail._ "Otherwise, if a dependency doesn't nail down it's required version of serde with the same specificity as the others, a new serde release can break your build" is a "bizarre" statement. What dependency? What "specificity" was it using? What "specificity" were you using to depend on that library? If you had a wildcard dependency on Library A, which depended on Serde, and then Library A made a new release that depended on a new version of Serde, then yes, your build will break, because _you_ don't have a specific enough dependency, and yes, a lock file will somewhat mitigate that problem. If you're saying that the library itself was using a wildcard dependency (i.e. `serde = "*"`), I don't think that's allowed on crates.io, so that doesn't make sense either. If that is allowed on crates.io, that's news to me, and *that* would be the problem I see, nothing else. If you were depending on a library directly on GitHub or somewhere else, and it was using a wildcard dependency, that's a different kind of problem. I need more information before I can even come close to responding to your initial assertions way up in the comment chain.
Rocket [is based on](https://github.com/SergioBenitez/Rocket/blob/3c4cb27d55faa8885421bfedcec0ef3501702793/lib/Cargo.toml#L35) Hyper. Its just not clear if Rocket [will continue to use](https://github.com/SergioBenitez/Rocket/issues/17) Hyper. 
I made an edit while you were typing. In the the book chapter instance indeed there was a library published on crates.io which was itself using a wildcard dependency. That particular issue is probably significantly less likely to happen now that crates.io prevents that.
1) Rocket doesn't have middleware support 2) Rocket isn't async
Yeah, pretty much just a minor amendment to SemVer that accurately describes what already happens. Mostly a matter of rules-lawyering so that some conversations about "but it's 0.x" don't all require having this same conversation.
So you mean an RFC to SemVer, not an RFC to Rust? I think that's where I got hung up.
[Can be done.](http://gnuplot.sourceforge.net/demo/surface1.html)
Tests allow you to refactor with confidence. You should never have to alter tests during a refactor. If you do, you should question what you're testing. 
&gt; Similar to the C++ `override` keyword, Rust requires a `default` keyword to enable trait specialization. Unlike in C++, it's mandatory. Not quite: - `default` is equivalent to `virtual`, it enables *implementers* to override. - `override` is always on in Rust: botching the signature in a trait implementation block always results in an error (a big advantage of `impl` blocks).
Yeah I know but the support is pretty bad. The demos are (almost?) all for plotting functions, but when you try plotting files (in the `x y z` format splot understands directly) the grid function doesn't seem to work properly. Plus one single 3d data set works decently well if you just plot points, but when you then add another one, it gets rendered on top of the other one, regardless of perspective.
Both? I was thinking that an informational RFC to Rust would get through a bit quicker and is something that I care more about. The semver repo seems to be pretty sluggish, typo-correcting changes have been open for over a year.
&gt; Right now there's no way to enforce that the consumer of a library matches against an enum in an forward-compatible way. There's no way to enforce it, sure, but you can create an undocumented variant, and declare that additional variants won't be considered breaking changes. (Having the `#[not_exhaustive]` tag is a 100% improvement, but it's a nice-to-have.)
Aha... so the reason putting `?` into my code never worked is cause I never even checked how to use it! I should read the Rust book.
Two criteria. First, "reasonably sized": if it compiles too fast variance is large, if it compiles too slow benchmarking doesn't finish... As is, it takes an hour to run this. Second, compatibility. Newer rustc continues to compile old libraries, but older rustc often can't compile new libraries. rustc is backward-compatible, not forward-compatible.
&gt; The semver repo seems to be pretty sluggish, typo-correcting changes have been open for over a year. Yeah this is why I haven't done it either. I don't think an RFC to Rust matters much; the semver code is controlled by me, not the project really. I guess you could make a Cargo RFC speccing what semver impl it must use...
Agreed.
What would be an idiomatic Rust way to write something like: if A?.B == C{ doSomething(); } else { doError(); } meaning, that I could do something like https://is.gd/TqUvMo , but the nesting seems fairly ugly (_especially_ if you have several nested optionals).
I feel like the graphs are missing some context. Rather than showing how two passes in isolation have changed in performance, I think the following questions are more important: 1. How fast is `cargo check` (i.e. all passes prior to trans) 2. How fast is `cargo build` 3. How fast is `cargo build --release` As it stands right now, these two graphs don't even tell me the relative importance of improvements to trans vs. improvements to typechecking. Knowing that a given pass is faster or slower isn't especially useful without knowing how much overall time is spent in that pass...
I have run this since 2015, and doing this long term is tricky because nothing stays still. Here are notes if you want to do this yourself: * Before 2015-08-15, type checking pass was named "type checking". Now split to "item-bodies checking", "item-types checking", etc. * Before 2015-12-19, there were two "wf checking" passes, old and new. * Before 2016-03-19, there was no MIR (-Z orbit). * Before 2016-08-02, MIR (-Z orbit) was off by default. * Before 2017-03-03, there was "drop-impl checking" pass. Now not a separate pass.
Both 1 and 2 can be computed from raw log. Visualizing the result will take some thinking. I don't think 3 is that interesting and it also needs separate run. To the first approximation, 1 is just type checking. 2 is type checking + translation + LLVM. Very roughly, if type checking takes 1 second, translation is 3, LLVM is 9.
That only works for private dependencies. If the dependency is public you *want* them to be shared or else you'll get spurious compile-time errors. Cargo doesn't understand this, which makes the situation hard to diagnose. It's not as rare as you might think: it's most likely to affect the "app"-like crates which likely have a huge dependency tree.
I'll freely admit that I'm more pathologically idealistic than perhaps many others are. On the other hand, as I mentioned in another comment, this list wasn't generated from a casual look over interesting RFCs—I found them all by coming up against a wall and learning that the only way to do something I was trying to do required a feature that wasn't there yet. That's literally never happened to me in any other language. Edit: lolz, it was the comment you were replying to.
Nothing in Rust supports MS SQL Server, as far as I can tell. I tried to create bindings for it, but it's full of so many Microsoft-isms that it felt insurmountable. Even with OracleDB, I can auto-generate complete bindings for that on a whim. MS SQL Server is written in a Visual dialect that the Clang compiler can't understand, and even bulk editing the header, I couldn't get it clean enough to use. It would be nice to have a binding to that, but I don't see it happening any time soon. Maybe with MS SQL coming to Linux, they'll make a header file that works with open source compilers.
Have you tried OCaml? All of your highs sound like things we've had for ages. The main advantages I see that Rust has over OCaml are: 1. Performance. (Borrow checker enables safe concurrency and allows avoiding GC.) 2. More modern syntax. I don't know if 2 is something you can live without though. (I know people who care about syntax above all else.) I do agree it's almost painful to go back to languages with weak type systems. I like the type system being my friend rather than something you have to fight with.
Congrats on making the doc team. Thanks for sharing some of your panache as you work through the doc-tools.
&gt; (first I have to port asciidoctor to rust though...) You wouldn't have to; basically, rustdoc will spit out some JSON, so you can process it with whatever you'd like.
Please report that. That'll be helpful to the language developers.
This seems the most similar to your pseudo code: if let Some("d") = res.as_ref().map(|x| x.as_str()) { do_something(); } else { do_error(); } The whole `.as_ref().map()` business would not be necessary if you were matching over Option&lt;&amp;str&gt; though.
As a side note, the point about "The destructor will still run and must take care not to invoke undefined behavior." is kind of wrong. It implies that (prior to Rust 1.12) the destructor would still fire even if the field has been moved-from, with some hand-waving over how the drop flag in the struct is supposed to work. But that's not actually true, your `Drop` impl wouldn't ever fire on a moved-from struct. I guess technically it triggers some implicitly-defined destructor, which then consults the drop flag and calls your `drop()` if the value is still valid, but that's just an implementation detail. The observed behavior is the same as it is now, where the call to the destructor is omitted if the value was moved-from. The except of course being with `#[unsafe_no_drop_flag]` but that should have been used very sparingly.
I was going to post a similar question and I'm also curious on the recommendation around web frameworks at this moment. I am going to prepare a presentation on a local conference soon enough to introduce Rust to people that might not have heard of it, or is already curious with the language. I thought of starting writing a small 'Hello World' and I'm curious to hear experiences using the available frameworks. I really like how Rocket is documented, it has a nice landing page, and a few tutorials to get going. And I've heard great comments about it. But I'm also worried start the presentation with "Rust, the lang, has been stable for a bit more of 2 years", following up with "To start Hello World web server, it is better to run `rustup nightly`". To me, it sounds confusing and a bit contradictory. Also, I worry that it is incidental complexity unnecessary for the first contact with the ecosystem. To resume, my questions are: - How has been the experience while developing on nightly? - Would you introduce new people to Rocket on Nightly? - Is there another recommended web framework running on Rust stable? Nickel seems to be easy to star and have a Hello World and it should run on stable. Any experiences with it?
Here it is: [log.tar.gz](http://s000.tinyupload.com/?file_id=91926561558567410951).
Definitely interesting. Please post some announcement here on the r/rust subreddit if you end up deciding to publish the code. Or do you have a public github profile to follow?
We should still write APIs now, even if the language will be better in 2+ years. If we all took the attitude of, "well, I can't write anything good in this language", then we would have no libraries. I am also not seeing the problem with drastic API changes. That is what semver is for. Its not uncommon for APIs to be completely different in major version updates, even when the language itself is stable - the mongo c driver is an example that comes to mind just because I've recently had to deal with it. Part of this problem isn't an API-author's responsibility anyway. Programmers have to pick a language that meets their tolerance for language and API churn. At this point, choosing rust for $MyAwesomeApp and then complaining about API instability (especially in third party libs) is a bit like buying a house next to an airport and then complaining about noise. 
A qualified vote for Iron here. We use Iron for our core service layer, and Iron remains my favorite for this use case, where Iron's simplicity and flexibility are major assets. On the scale of web frameworks, Iron is barely a framework and provides a very flexible, minimalistic substrate to build on. We have a small internal Finagle-inspired service layer that provides stronger abstractions on top of Iron and provides strongly-typed Request-Response cycles, which has eliminated a lot of boilerplate associated with Iron, instead moving it into a small collection of generics and traits. This works well for us, because our core service layer is an RPC system that communicates via serialized messages, and if we move off of Iron, it would likely be by going down a level to Hyper (and possibly Tokio) directly. While I don't have personal experience with Rocket, it seems like a good choice for more app-like or REST servers, and I'm looking forward to experimenting with it in places where we would currently use Java.
Or for users like docs.rs to invoke rustdoc as a library?
in theory, sure.
Apologize for my sins in creating the current version of rustdoc.
yes &lt;3
Is it possible to filter for jobs that allow working remotely from anywhere in the world?
Was there one thing that dropped the trans times so much? Or was it a series of things that added up? I was wondering what improved the compile times for one of my projects by ~50%.
It more that a 0.x is expected to rapidly iterate into a 1.0. Crates like hyper have been in development for *years* without hitting a 1.0 because they are just waiting for language features or ancillary crates to provide functionality that is missing. If your development is stalled by external dependences, it is probably just time to release 1.0 and break with a 2.0 later. As it is crates like hyper and similarly critical libraries already treat breaking 0.x releases like major version jumps - ie, we will support the old release longer, provide a ton of migration assistance documentation, etc - just with the misappropriated expectation that the current crate is highly unstable. Gstreamer had this problem. The 0.x series persisted for almost a *decade* before 1.0 happened. And then 0.x was supported with bug fixes for years following. Really, they should have had a 1.0 out much earlier and did a 2.0 update with the breaking changes, because *semantics matter*. Dozens of projects used ffmpeg directly over gstreamer because "0.11 is unstable". For Rust, it means the entire ecosystem is frozen waiting for decisions to be made on language features that would dramatically alter the average user experience of the language. It isn't a good position to be in - I personally feel like the enthusiasm and upstarty nature of Rust is dying but there is no legitimacy in the language space succeeding that bright eyed new feeling because everyone still considers the *core language* unstable and incomplete, much less its ecosystem mostly stuck in 0.1x limbo.
Maybe think about switching to a non-MS SQL? As always, choosing anything MS-related always results in vendor lock-in, that's not easily broken.
https://doc.rust-lang.org/std/mem/fn.size_of.html and https://doc.rust-lang.org/std/mem/fn.size_of_val.html
I'm a bit perplexed by your mention of OCaml's type-system given that it's lacking type-classes, associated types, and linear typing. The former allows for greater code-reuse -- in a much easier form than OCaml's functors -- and the latter allows compile-time data-race detection and memory-management, as well as more subtle things like encoding business logic constraints. Consequently impl-trait support is equally missing from OCaml, as too are most of the other things the author is seeking, like async support baked into the language and powerful macro support. A framework like Rocket.rs is impossible in OCaml. It's currently possible in nightly Rust. It will be possible in stable Rust in a couple of years. Frankly if ML is your thing -- and I do like the syntax -- F# is the variant you should be using. It still lacks type-classes, but _does_ have ad-hoc polymorphism via static members, as well as units-of-measure, monads (-ish), and things the author was missing such as native async/await support.
I think we should rewrite it in Rust... ;)
I heard that the check for similar unicode characters (semicolon and greek question mark, for example) took a lot of time in the compiling process. Is this still the case?
I'm trying to use the crate `nalgebra` multiply two matrices with a generic element type: extern crate nalgebra as na; extern crate alga; use na::{Matrix2, Scalar}; use alga::general::{ClosedMul}; fn main() { } fn multiply&lt;T: Scalar + ClosedMul&gt;(a: &amp;Matrix2&lt;T&gt;, b: &amp;Matrix2&lt;T&gt;) { a*b; } However, I get this error: error[E0308]: mismatched types --&gt; src/main.rs:11:7 | 11 | a*b; | ^ expected type parameter, found reference | = note: expected type `T` found type `&amp;na::Matrix&lt;T, na::U2, na::U2, na::MatrixArray&lt;T, na::U2, na::U2&gt;&gt;` = help: here are some functions which might fulfill your needs: - .trace() I don't know in which direction I should be going from here. I thought I satisfied the criteria of the `mul` method of the [`Matrix`](https://docs.rs/nalgebra/0.12.3/nalgebra/core/struct.Matrix.html) type.
Why i64 and not u64?
That's really cool how it integrates with webpack. Makes it a lot easier to add rust to an existing javascript codebase. All you really have to do is add a webpack plugin. Thanks for sharing!
If so, there might be low-hanging fruit in adding a fast path for ASCII.
 fn bit_twiddle(num: usize) -&gt; usize { let bits = [0u8; ???]; // copy num into bits // screw around a bit // copy it back }
This memory diagram is godsend. I ended up doing research about Raph Levien ( /u/raphlinus ) and learned so much!
Algorithms that want to control array sizes to mesh well with cache sizes for performance.
I don't think this is a toxic mindset. Rust is a relatively young language with no baggage. And these "new features" isn't just suboptimal, but also fragment the ecosystem for a long time (even forever, I would argue) - I have several examples of this: - module system (Javascript) - Javascript suffers from this the most. Javascript never had "modules" and Every library has to publish themselves in 2~3 different ways. - package manager (Golang) - Again, similar problem here - lack of common package management system caused the ecosystem to fragment. I think it is starting to converge to `glide` now. - asynchronous programming (Python) - I think Python 3.x is making it better with the new async-await keyword, but Python suffered from multiple event reactors (Tornado, Twisted, and few others) which were incompatible. Asynchronous libraries had to be written for different frameworks. 
Rust used to have a heavy runtime, similar to golang, with its own implementation of green threads. It conflicted with Rust's goal of being a systems programming language. * https://github.com/rust-lang/rust/issues/17325 * https://github.com/rust-lang/rfcs/blob/master/text/0230-remove-runtime.md Now Rust's runtime is super thin. The standard library still contains a lot of code, but it's optional and you can code against the core Rust (https://doc.rust-lang.org/core/) only, which doesn't even have concepts around IO, concurrency, or heap allocation. With this you can use Rust on almost all places where only C can be used.
&gt; I don't understand why you have those question marks. No, there's no way you're going to be able to ask the compiler to insert the size of something into that position right now. The compiler doesn't support const generics yet. Yes, that's what's being asked about. If it's possible to do stuff like `let bits = [0u8; size_of::&lt;usize&gt;()]` at compile time. I've needed stuff like this plenty of times -- not just for bit twiddling too (for usize you can use `cfg` to solve the problem, but not for general types). The current answer is "you can't". Rust has built in operations for _some_ bit twiddling things, but my response to that would be "[I bet that _almost_ works](https://thefeedbackloop.xyz/i-bet-that-almost-works/)". I've certainly been in situations where this wasn't enough. You're probably being downvoted because your comment is way more abrasive than it needed to be.
One of the biggest wins from MIR-level optimization would be in generic code, which then only needs to be optimized once rather than again for every instance. I believe the next-biggest improvement to the LLVM passes would be cleaning up how its IR is generated from MIR- rather than necessarily doing any optimization, just generate less to begin with. I suspect MIR optimizations could also help just by operating at a higher level, but at this point it's unclear.
I'm new to rust and have been working on a project in rust while reading through the Rust Programming Book. One thing the book doesn't help with is "best practices" and I was wondering if anyone knew any good resources for learning the "best practices" of rust.
[removed]
Right, I meant the underlying code which has to, at minimum, check that flag.
thx 
👍 I wish reddit also had a thumbs up in addition to the relevance slider!
Inefficiencies like this might as well mean everything is broken when the examples mentioned are mostly about being more efficient.
`rem` in `fn sub` can be negative, if use u64 I'll need to cast the number to i64, would it cost more?
Yeah I fixed it!
&gt; What is the point of the match? When you try to create a file, what should happen if you aren't allowed to create a file there or maybe the hard drive is *completely* full? Should the program crash? That's what the match statement is allowing you to figure out. In a language like Python, it will just `throw` an exception. If you don't catch the exception, the program crashes. You never know when you need to even think about catching an exception, unless you read all of the documentation very carefully, or you just happen to know that it might throw an exception. In Rust, it returns a value that is *either:* - the file you wanted to create/open - an error telling you what went wrong The compiler then tells you that it doesn't know how to `.write()` on something that is "either a file or an error". &gt; How does having a match statement affect the availability of a method? Simply, the match statement allows you to figure out whether you have a file or an error. You can tell the compiler what to do if you have a file, where you will have a `.write()` method, and you can tell it what to do if you have an error, where you will not have that method. The compiler is okay with this, because it knows what to do now. In Rust, one way that you can just accept crashing if the file doesn't open is to use a method called `unwrap()`. So, let file_maybe = File::create("bar.txt"); let mut file = file_maybe.unwrap(); //will crash if something went wrong file.write("to be written".as_bytes()); Now, it's important to note that I used "create", not "open", because "open" is read-only by default. "create" will make a new file in write mode. It's possible to open an existing file in write mode, but that takes an extra couple of steps. So, what I did above takes three lines. We could condense this to two lines like this: let mut file = File::create("bar.txt").unwrap(); //will crash if something went wrong file.write("to be written".as_bytes()); Now, if you want to handle the error condition somehow other than (safely) crashing the program, that's what the match statement is for, and the link you provided shows an example of that. 
No, it's a `Result&lt;File, io::Error&gt;`; a single enum value that needs to be matched and unpacked. A tuple would be `(File, io::Error)`, which has *very* different semantics.
Thank you for your reply. I now get a compiler warning about. file.write("to be written".as_bytes()); Is this doing the same thing where I have to do error handling? If so is there a quick way like unwrap()?
yes, the warning is because writing to the file might fail, even if you got the file to open, because of things like the disk running out of space. So, `.write()` either returns nothing, or an error message. You can use unwrap there too. file.write("to be written".as_bytes()).unwrap(); As mentioned in another comment around here, you can also use `.expect("some message here")` to provide a more helpful error message if things go wrong. In this case, you might write file.write("to be written".as_bytes()).expect("writing to the file failed"); It works the same way as unwrap, but it lets you write a quick message that will be displayed if the program does end up in a bad situation.
&gt; Is there somewhere that lays out the rules for using mut methods with differing lifetimes? Not that I've seen. Lifetimes and ownership have very few rules, but they can make seemingly simple stuff complicated sometimes. I will say in your specific case that you're building a form of self-referential struct, which is particularly problematic. There are even [entire crates](https://crates.io/crates/rental) dedicated to trying to make self-referential structs more ergonomic, but I don't know if that would work for a Vec. This is not to say that it can't be done, but it's more difficult than the usual stuff in Rust. One easy (but unsafe) workaround would be to just store indices in the `refs` Vec, rather than actual references. It's logically unsafe because if the `inner` Vec changes, then the indices are likely to be rendered incorrect. As it is, you can't even use `make_ref` twice. The first call to `make_ref` accepts a mutable reference that lasts for the lifetime of the Container... thus the only way to release the mutable reference is to destroy the Container. Would you be willing to provide any more specific goals/applications for this Container type? there might be one [in std already](https://doc.rust-lang.org/std/collections/) that could meet your needs. For all I know, the code you provided is something of a red herring, and it's trying to solve a problem that doesn't need to exist. I'm happy to talk at more length about what you're running into, if you want!
 use std::collections::BTreeMap; #[derive(PartialEq, Debug)] enum Node { File, Directory(BTreeMap&lt;&amp;'static str, Node&gt;) } macro_rules! node { ( { $($name:ident $( / {$($contents:tt)*} )* ),* $(,)* } ) =&gt; { { let mut entries = ::std::collections::BTreeMap::new(); drop(&amp;mut entries); // ignore unused_mut $( { let name = stringify!($name); let value = node!($({$($contents)*})*); entries.insert(name, value); } )* Node::Directory(entries) } }; () =&gt; { Node::File }; } fn main() { let node = node!({a, b/{c, d/{}, e}}); let expected = Node::Directory( vec![ ("a", Node::File), ("b", Node::Directory( vec![ ("c", Node::File), ("d", Node::Directory(BTreeMap::new())), ("e", Node::File), ].into_iter().collect()) ) ].into_iter().collect() ); assert_eq!(node, expected); } (I felt `/` as a marker for directories was more apt than `:`, but you can change that back without issue.)
Awesome, thanks! You definitely deserve your flair :) I think in the future I need to remember that one has to use \* (zero or more) for what would be a ? (zero or one) in a regex.
That's why I said "somewhat similar" :)
&gt; Do you think the confusion could be coming from the name SyncCellKey? FWIW, I think `SyncCell` isn't very descriptive, e.g. `RWLock` is closer to `SyncCell` (being the threadsafe version of `RefCell`). Maybe `TokenCell` or something like that is a little more accurate, given the key to this `Cell` is the fact there's an access key/token, rather than it being `Sync`.
&gt;I mean, I'm mocking out all of the functionality I'm supposed to test... to the point that the test becomes tautological. I really don't get the tendency of programmers to fawn over test suites that basically accomplish what a statically-checked language would in a shorter time.
&gt; If you do, you should question what you're testing. Exactly. Since many of the tests are tautological, they end up being useless. Writing good tests is hard. 
I tried using console too. Slider doesnt even move 
&gt; If we all took the attitude of, "well, I can't write anything good in this language", then we would have no libraries. Which is especially silly given the performance of e.g. the regex crate. Is Rust ready for everything under the sun? No. But it's quite good for even very common tasks. &gt;Part of this problem isn't an API-author's responsibility anyway. Programmers have to pick a language that meets their tolerance for language and API churn. Yup. We have the same thing in Haskell and the solution is "patch your libraries," not "stay stagnant and use 10 year-old code" &gt;At this point, choosing rust for $MyAwesomeApp and then complaining about API instability (especially in third party libs) is a bit like buying a house next to an airport and then complaining about noise. Agree completely. If you want the advantages of a young language exploring new paths in design... you have to deal with a young language exploring new paths in design. 
Haskell-style type classes with common extensions are equivalent to SML-style modules. (There's actually a paper on that.) They allow the same amount of code reuse, though the syntactic differences definitely make them awkward to directly translate in practice. It basically comes down to structs are named vs. typeclass instances are not. (So when there's only one implementation for a given type, SML is needlessly verbose, whereas when there are multiple, disambiguating between them via phantom types gets pretty awkward/verbose.) If by "associated types" you mean [this](https://doc.rust-lang.org/1.7.0/book/associated-types.html), why do you say OCaml is lacking them? How is declaring a type inside of a "trait" different from doing the same in a "module type"? Linear types (aka the borrow checker?) are missing, though in Rust they seem much more geared towards performance optimizations ("compile-time data-race detection" aka "safe concurrency", and "memory-management" aka "avoiding GC") than towards encoding business logic constraints. 
Sorry I meant using the base 2^32. That would remove all division and modulos.
I doubt we'll just switch all our databases over anytime soon.
You're getting lots of good help, allow me to link you https://doc.rust-lang.org/book/second-edition/, which is the official book (second edition). It's not exactly bloggy short, but should answer most of you questions in a very helpful way.
**Long tail** In statistics and business, a long tail of some distributions of numbers is the portion of the distribution having a large number of occurrences far from the "head" or central part of the distribution. The distribution could involve popularities, random numbers of occurrences of events with various probabilities, etc. The term is often used loosely, with no definition or arbitrary definition, but precise definitions are possible. In statistics, the term long-tailed distribution has a narrow technical meaning, and is a subtype of heavy-tailed distribution; see that article for details. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot/) ^] ^Downvote ^to ^remove ^| ^v0.22
I’ve sometimes used code like this: struct Foo { … } const SIZE_OF_FOO: usize = 32; fn _static_assert() { std::mem::transmute::&lt;Foo, [u8; SIZE_OF_FOO]&gt;(panic!()) } `transmute` is special, using it only compiles if the argument and return type have the same size. In this approach you need to hard-code the size (here `32`) in your source. Sometimes that requires `#[cfg]` to have a different constant on 32-bit vs 64-bit platforms. This is somewhat unfortunate, but on the other hand it helps ensure you don’t accidentally grow it.
Something like [this](https://github.com/lifthrasiir/unison/tree/gh-pages/src)?
I would reach for a build-script that generates the constants file.
But does it count as "changing functionality" if, for example, I'm moving a bare function like `iter_camelcase(&amp;str)` to `ExtensionTraitForStr::iter_camelcase(&amp;self)`? That's something I'm currently in the middle of, which requires rewriting my unit tests, but doen't change the functionality in any significant way. **NOTE:** The names I gave aren't the actual identifers used... though I *have* been working on that exact API rework for an in-development wordwise CamelCase iterator.
Just wanted to say you're doing good work on the library and keep it up!
That's rather crazy. How did that not happen? It's a pretty assumed thing in most any binary-compiled language.
Not a problem! But you're getting the long answer :p I'm just finished my first year studying comp sci and we've touched on a bunch of languages (pascal, C, javascript, php and c#). Next semester my classes will have c++ and ARM assembly. So i wanted to learn something new. I'm a tech head and follow a bunch of podcasts. I heard Rust mentioned a bunch of times and watched a few presentations on youtube and it piqued my interest. 
&gt;Java 8 introducing lambda syntax (albeit compiled down to anonymous inner classes) [Java lambda's are *not* compiled down to anonymous inner classes.](https://youtu.be/MLksirK9nnE?t=720)
I've thought about that but I don't know how to read the number from decimal to that base efficiently. 
So we should get rid of `as_slice` on `Vec`?
We need a decision on how to deal with things like: struct Thingo&lt;T&gt; { a: [u8; size_of::&lt;Thingo::T&gt;()] } EDit: There might be one already somewhere... but there are more complicated cases.
I think the other issue was that the size of types isn't know by the time const_fn are evaluted. Given that sizes can be determined by const_fn, so you need to handle both at the same time. Restricting recursion is not hard it's already necessary for types in general.
the reddit isn't an official channel, there just happens to be a lot of core members who also reddit
If you want something like Jinja, [Tera](https://github.com/Keats/tera) is what you're looking for. Support for Tera templates is baked into Rocket, by the way. 
The "Sync" in `SyncCell` was intended to mean "synchronized access" (like the opposite of "async"), not the Rust trait `Sync`. And I thought that the fact that `SyncCell` is indeed `Sync` was a nice coincidence. But now I see that most Rust users will indeed look at it like you and think that the "Sync" refers to the Rust trait `Sync`. The name `TokenCell` isn't bad. Then `SyncCellKey` can get the very short name `Token`, which is unfortunately not very descriptive and can cause naming collisions (if for example `use token_cell::*` is used). Naming it `SyncToken` could make it more descriptive and emphasize again that cells are accessed one at a time, but then we're again running into the problem that "sync" sounds more like the Rust trait `Sync` than "synchronized". Reminds me of this quote by Phil Karlton: &gt; There are only two hard things in Computer Science: cache invalidation and naming things.
is not released yet This initial release should be considered to be pre-alpha software--it will have issues. Once Alacritty reaches an alpha level of readiness, precompiled binaries will be provided for supported operating systems.
Why do you think you can install it that way? None of the documentation in the github repo suggests you can - see https://github.com/jwilm/alacritty#manual-installation for instructions.
Hmm while this could work it might be a little bit complex for my timeframe. Thank you though, looks like a very interesting project!
Damn, it is *always* the simplest thing. Thank you!
Cargo is quite specific that `cargo install` is intended for compiler plugins, the odd language tool, and not much else. It's not a general installer or package management tool.
Iron isn't some separate application, it is part of your app. You compile your app and run it, and it will have a webserver. So yes, you will have just one executable to run.
&gt; I've developed session handling tools &gt; I also have some of my own tooling for talking to redis and postgres Yeah, I am using webframework to get all that for free. 
Well thank you. Comments like this really helps to stay motivated!
Mailing lists and flat threads promote a broader range of opinions too which is better in some contexts.
In addition to the already mentioned [Tera](https://github.com/Keats/tera), there's also [Askama](https://github.com/djc/askama), which does more of its work at compile time, including valuable type checks. Both of these are based on Jinja. I am working on [Bart](https://github.com/maghoff/bart), which is compile time like Askama, but based on Mustache instead, so the templating language is more restricted.
We could even make it a `static_assert_eq!` macro, but it’d only work for `usize` values. (In addition to the more obvious it’d only work for const expressions.)
/r/rust was set up way before the internals and users.rust-lang.org sites. (I joined Reddit to follow /r/rust because it was more active than the other channels at that point.) So I guess it is historical.
I've played around a bit with [ructe](https://github.com/kaj/ructe), and I've really liked its approach. Also, for some "roll-your-own" compile-time templating that I've been experimenting with, I 've found it convenient to use [fomat-macros](https://github.com/krdln/fomat-macros) crate. It's not a templating library by any means, but you may find it helpful to know about it as you explore ways to do templating.
Something like `curl ipinfo.io/ip`
Cheers for sharing :). As a web dev who primarily uses node and react, it's cool to see this integration
It looks like https://nvd.nist.gov/vuln/search provides an option to filter by category (buffer errors, double free, ... etc). If you assume that you could rewrite these programs without unsafe, then some set of memory and race conditions would be avoided - maybe you could take the percentage of these CVEs. 
Hi, Checkout these https://github.com/NishanthSpShetty/Stack-VM https://github.com/NishanthSpShetty/Stack-langc https://github.com/NishanthSpShetty/crust First two are quite simple and small programs. It might help you.
Best practices are kind of in flux due to the rapid rate at which new language features are being made. However if you want some additional help writing great code the program `clippy` can help you out there.
I've asked: yes or no.
As a rule, static Huffman tables should be expressed statically; you can improve performance *massively* by doing so, and bypass all of these sorts of borrow checker issues (trading them in for other obstructions, naturally). See https://www.reddit.com/r/rust/comments/54jlxf/huffman_coding_implementation_in_rust/ for commentary on another person’s Huffman coding explorations, including my own anecdote (with code) of improving decoding performance by 20–100× by the right (though slightly absurdly complex) representation. This table here is small enough that it would probably be even fasterer, and you could *possibly* get away with going all SIMD on it if you were enthusiastic enough.
I never got why you'd couple unstable features to nightly builds. I'd rather give the application developer means to allow specific dependencies to use unstable features.
Shameless plug: https://github.com/unpatched/internet-broadcasting-service It's very unfinished, but you can nearly record video. The ffmpeg api needs some more work and not all the fancy options are implemented but I am working on it in my free time. My goal is to make it like OBS. All you'd have to do is push the Vec&lt;u8&gt; of pixels to the encoder frame, so basically use scrap instead of v4l2 in the encoder example. Then you change the output from File to TcpStream if you want a stream, or just leave it at File if you want a recording. I'd also be interested in joining forces with /u/quadrupleslap
You're downvoted but you're right.
You want /r/playrust
&gt; I'd like to know where cargo is specific about this. https://github.com/rust-lang/rfcs/blob/master/text/1200-cargo-install.md#motivation &gt; Fundamentally, however, Cargo is a ubiquitous tool among the Rust community and implementing cargo install would facilitate sharing Rust code among its developers. Simple tasks like installing a new cargo subcommand, installing an editor plugin, etc, would be just a cargo install away. Cargo can manage dependencies and versions itself to make the process as seamless as possible. and https://github.com/rust-lang/rfcs/blob/master/text/1200-cargo-install.md#system-package-managers &gt; The cargo install command provides a cross-platform, easy-to-use, if Rust-specific interface to installing binaries. &gt; &gt; It is expected that all major Rust projects will still invest effort into distribution through standard package managers, and Cargo will certainly have room to help out with this, but it doesn't obsolete the need for cargo install. ---------------------- &gt; That sounds very much like I'm intended to be able to install any binary crate with cargo install. This is a *social*, not technical arrangement. Yes, in theory you can install any binary crate with `cargo install`. The point is, for people who are not Rust developers, making them install Rust first to be able to run `cargo install` is not great UX. Rust is AOT compiled, so unlike Ruby/Python/JS, there's no reason to do so. If you're writing something for Rust developers, sure they have Rust installed, so `cargo install` works fine. But if you're writing something *not* for Rust developers, you should do them the service of giving them a real package. On top of that, it's not literally all crates, that is, Cargo is missing a lot of mechansims that'd be useful in a "real" end-user package management systems. Post-install scripts is the largest single example, but there are more.
&gt; That's rather crazy. How did that not happen? `const fn` is not done yet, so not every function that could be marked `const` is.
That is something I would really like too!
Why is the asm for `bar()` longer than the asm for `foo()`? Rust: use std::mem; #[repr(C)] struct Inner { data: [i64; 4], } extern "C" { fn init(ptr: *mut Inner); } pub struct Outer { inner: Inner, } pub unsafe fn foo() -&gt; Outer { let mut outer = mem::uninitialized::&lt;Outer&gt;(); init(&amp;mut outer.inner); outer } pub unsafe fn bar() -&gt; Outer { let mut inner = mem::uninitialized::&lt;Inner&gt;(); init(&amp;mut inner); Outer { inner } } Asm: example::foo: push rbp mov rbp, rsp push rbx push rax mov rbx, rdi call init@PLT mov rax, rbx add rsp, 8 pop rbx pop rbp ret example::bar: push rbp mov rbp, rsp push rbx sub rsp, 40 mov rbx, rdi lea rdi, [rbp - 40] call init@PLT movups xmm0, xmmword ptr [rbp - 40] movups xmm1, xmmword ptr [rbp - 24] movups xmmword ptr [rbx + 16], xmm1 movups xmmword ptr [rbx], xmm0 mov rax, rbx add rsp, 40 pop rbx pop rbp ret 
Reuse of existing libraries; single code base for online and offline program if it's already native.
And it doesn't even deal particularly well with linear conversations because they decided to NIH everything including scrolling and Ctrl-F grumble mumble.
The [igd crate](https://crates.io/crates/igd) might work, provided you have UPnP enabled on your router (this [example](https://github.com/sbstp/rust-igd/blob/master/examples/external_ip.rs) works for me).
Well that gets kind of tricky. You might be behind a few layers of network equipment. The only 100% reliable way to know your internet accessible IP address on all devices is to query an external server.
This was a pretty easy way to get comfortable with generics after all: https://github.com/steveklabnik/sparkles/pull/12
I personally don't think it buys us that much, but that seems a little different: it is much *rarer* to call `deref` explicitly, than `clone` explicitly, and `as_slice` does result in different syntax (`*my_vec` `my_vec[..]`, or the same with an `&amp;` prefix) that often reads slightly more easily (especially vs. the `&amp;`-prefixed ones). `retain` vs. `clone` has no such distinction.
`cargo update` doesn't update things in `~/.cargo/bin` either. There's not a large pool of vocabulary to use here, but Cargo's terms are very much Cargo-specific jargon and *not* equivalent to those used by system package managers for system package management.
I use it to install Rust tools I use *for Rust*, but I install, for example, `ripgrep` and `alacritty` via the system package manager as appropriate. "Do I use this for Rust development and only Rust development?" &amp;rarr; `cargo install` "Do I use this in everyday life?" &amp;rarr; `aura -[AS]uy`
And yet every binary crate that wants to hit package managers strongly recommends *not* using Cargo to install it, because Cargo can't install to the system. The fact that Cargo injects itself into `PATH` is a convenience for developer work, not the actual course of software installation.
 curl -4 icanhazip.com curl -6 icanhazip.com
if you can run arbitrary code on your router, then you can just check the IP address of the WAN interface. You could then run a small server on the router that you could ping from inside the router to ask for that information, if you wanted it to be available from inside the network, but this is a very limited solution. You're still only going to know the IP address on the WAN of the router. If the router itself is NAT-ed behind an ISP router because there are no more IPv4 addresses (which happens a lot these days), then it will be wrong, or if your network is anything more complicated than super simple, it will also be wrong.
https://www.youtube.com/watch?v=gkojLslXg5M At the end of this video. I wish I knew where they got their info from but that's where I got mine from.
Psh. Package managers. :p
Well, sure, but a) In this context it's about the expectations of a Rust developer (I assume), and b) in the context of &gt; Cargo is quite specific that cargo install is intended for compiler plugins, the odd language tool, and not much else. which you affirmed in another comment. So I'm a bit confused. I've heard "`cargo install` for Rust dev specific things only" a lot, but only from people, I don't think I've read it somewhere explicitly.
Just to elaborate some more on this: * If it were a tuple, you'd get a 'file' _and_ an error (which doesn't make sense, because if you get an error then there's no 'file'). * Since it's an enum, you get a 'file' _or_ an error. One or the other. Hence why you need to `match` and see which one you got. 
Yep, would be interested in a Windows GUI app that's a bit lighter than ShareX. 
Absolutely. Cargo's docs are long overdue for an overhaul, and this will be in them, for sure.
Thanks very much for getting back to me. Yes, that does seem to be the issue. Using a StaticProvider works, though that's not a long term solution. I have env variables for the AWS_DEFAULT_PROFILE, and then that profile exists in the credentials file. Boto seems to tolerate this and connect out but rusoto does not - I'm wondering what the difference is. I attempted to use a profile provider but it complained about the key - possibly because it's quoted in the creds file, I'm unsure.
This is a nice explanation, but I want to add this: If you find yourself writing code like match do_something() { Ok(s) =&gt; do_something_else(s), Err(_) =&gt; return Err("Error doing something") } (in other words, if you fell like you're writing Go), you can use the `?` operator to shorten this to let s = do_something()?; do_something_else(s); which does the same thing. Now, this requires a little setup, as the errors have to be convertable, but the `error-chain` takes care of that easily. 
&gt;no inheritance Because then you can't statically know the type of a given value without trickery. And that means you can't move it or put it into a contiguous array. &gt;composition You should take some time to learn a bit of Lisp or another functional programming language, because then the answer would be clear a day. Rust has a lot of functional features (pattern matching, lambdas, sum types, etc.) so using closures for "composition" might be something you should take a look at.
Because /u/quadrupleslap's GitHub profile picture is that.
&gt; From the Rust project's perspective, having at least one communications mechanism which isn't dependent on a "social" company's free platform is a good thing, hence Discourse existing. I think the project's dependence on GitHub, another "social" company's free platform, is way more relevant than its partial dependence on reddit.
Adding support for `AWS_PROFILE` has been on the wish-list for a while: https://github.com/rusoto/rusoto/issues/429 . I don't know if `AWS_DEFAULT_PROFILE` is in addition to that or an alias for the same thing. Rusoto's credential crate should handle anything the other SDKs do. If you've got a profile in a credentials file that doesn't work, I'd appreciate an issue on Github with a repro so we can fix it. 😄
Looking at the source code, the Quartz implementation seems to be missing `fn frame`.
&gt; Re knowing the type of a value When you have a pointer to an object in a language with inheritance, you don't know whether it really is that object or whether it's a child class. You can of course use RTTI or a "sealing" feature to work around that, but it does add complexity.
Using any database pretty much means vendor lock in, that's the wonderful state of RDBMSes. At least you can run mssql on Linux now.
That wasn't nice
And sometimes runtime overhead.
&gt;But less facetiously: I think Reddit deals better with lower signal-to-noise and fragmented discussions (due to voting and being hierarchical), whereas Discourse deals better with linear conversations. Tree-based comments are a huge plus on a forum IMO. If a bunch of people have already replied to a comment in a linear chain, it derails things if you try to make your own like I'm doing right here.
This definitely feels like the XY problem to me. You already point out that a Rust UI library would be done very differently from Qt, which I think is true. It definitely wouldn't involve large objects that have small pieces overridden. Qt-style OOP with lots of inheritance-based polymorphism leaves a bad taste in my mouth. Traits with lots of delegation isn't much better- you're still doing lots of dynamic dispatch and per-object allocation. Instead, I would split up those large objects so that each piece is only responsible for one thing. That way it doesn't actually matter how your checkbox is constructed, because most places it's touched don't even care that it's a checkbox, or maybe even a widget! I haven't written a UI library, but an example of something similar is an entity/component system for a game engine. Here, components are purely data (i.e. no methods) and grouped by type, rather than by entity. Much like a relational database, components know which entity they are a part of, but entities do not know about their components. Entities may not even exist in memory- if *everything* is in the components, they can just be IDs. This way, components can be processed in bulk, doing just one thing at a time for all applicable entities. For example, a physics system in a game might only touch the Transform and RigidBody components, allowing for more flexibility in how they are stored and better cache usage. An entity that just needs to override one little thing about player interaction doesn't need to accommodate the physics system in any way- no inheritance, no dynamic dispatch, no special cases. I've also seen this sort of design used for compilers. For example, [Cretonne](https://github.com/stoklund/cretonne/) stores its IR as a set of tables, so that extra information can be attached to instructions simply by adding a new table without touching any of the existing code.
Rust does have trait objects though, which are what you describe in the first sentence. You don't know the type at compile-type, and you can't store it in an array, but you can put it in a `Box` or `Arc`. What Rust does not have is exactly what OP is asking about - inheritance. You can have a struct implement a trait, and you can pass instances around as objects of this trait (similar to an abstract superclass). However, a trait only has functions and no data members, and a struct cannot inherit from another struct. In GUI programming, inheriting from a widget and just overriding one method is common. A checkbox that does something on right click, a button that shows a popup when hovered, etc. Of course you can do all that without inheritance, but it's much more complicated, and it doesn't correspond well to the way you think about GUI elements. 
Qt + Rust is definitely a case of trying to fit a square peg into a round hole. It was born and raised in inheritance, molded from birth by it. Inheritance and composition *are* different approaches to solving problems, so asking how to use inheritance in a compositional model is counterintuitive. In composition, you can't override existing methods on an object, but you can implement a variety of behaviors for an object, and there are ways of achieving your goals. I hope [this example](http://play.integer32.com/?gist=1ef04273f205e66727e7aa577ed068ce&amp;version=stable) helps you some. I spent like 30 minutes or an hour writing it, just to make sure it showed some of the concepts. Trying to make educational, hypothetical code is time consuming. It shows how traits can depend on other traits having been implemented, it shows one default impl of a function (size), which could be overridden when the trait is initially being implemented on a concrete type, if there's a more efficient way of implementing that function for that concrete type. It shows off several things. If you wanted to simply extend an existing control, it really depends on what you want to do. If you have an "onclicked" method, the traditional approach with inheritance would be to subclass the Checkbox type and override that onclicked method. In Rust, it would be a lot better to just have an onclicked closure that you assign, rather than dealing with composition or inheritance. There has been talk of adding inheritance to Rust, but that's on the far horizon at this point. I'm not sure if I answered your question at all. I wish you had an example that wasn't Qt, and it would be nice if that example has a Rust Playground link so we could visualize exactly the kind of code problem you're encountering.
/r/playrust
At the moment, Rust has excellent support for OS-level threading via [std::thread](https://doc.rust-lang.org/std/thread/) and libraries like [Rayon](https://github.com/nikomatsakis/rayon) which are built on it (which will give you support for multiple CPU sockets on the same motherboard), but support for parallelism at a layer the OS doesn't abstract is very young. I don't remember hearing any mention of efforts to write high-level MPI abstractions in Rust yet, so bindings to mature C code are most likely all you'll find in any worthwhile state of completion.
Is writing a ground-up implementation of MPI in Rust possible?
Had no idea that was a thing, thank you
Of course... it's just a bit of a time commitment and the people in this community who are so inhumanly productive that they must be robots have already settled on other tasks with broader general appeal or more personal relevance. Heck, given that Rust has a powerful declarative macro system, custom `derive` support, and full support for procedural macros is in development, it won't be too long before integrating a new MPI API into Rust will be easier to do cleanly than for C and C++, where the annotations for things like [OpenMP](https://en.wikipedia.org/wiki/OpenMP) and [OpenACC](https://en.wikipedia.org/wiki/OpenACC) require upstreaming patches to each compiler you want to support.
I think it's reasonable for alacritty to squat that crate name, but I think there's a better message than "hello world" to go here. Perhaps something like "Alacritty is currently not available through Cargo. sorry! &lt;url&gt; has instructions for installation"
pub fn main() -&gt; io::Result&lt;Display&gt;; no. I don't care if it's a trait member. main == bad for a function name. primary screen might be a better choice. Other than my mostly irrational visceral recoil over a nit picky name choice, nice library!
This has been solved a few months ago - not a fundamental limitation, just suboptimal compiler design.
You want [the `--features` option](http://doc.crates.io/manifest.html#usage-in-end-products).
Unfortunately many tools written in Rust are not yet available in package managers: tokei, for example (haven't checked Linux, but it's not in Homebrew). In this case, I prefer using cargo to install it for me, as opposed to manually downloading the package from Github and having to manually check for updates.
&gt; NIH What is that?
I had to go to the `crates.io` documentation page, then click through every page individually because I couldn't work out where it would be documented, and I already knew what I was looking for.
That is exactly how Qt works, reacting to mouse, keyboard, resize, drag, drop, show, hide and some other events is by subclassing and overriding methods. It has another method for responding to user interaction, namely signals and slots, but that only works for those that are defined in advance, not for customizing behavior. And those also don't have a good rust equivalent, callbacks don't work well with lifetimes. Edit: regarding the second part of your post, if you do it in rust from scratch, I think you're right to use some sort of event channel rather than event handlers. The problem I have with that is conceptual, it's easy to understand "when mouse enters, do this", and less intuitive to say "did the user do anything since the last time I asked?". But now that I think about it, it could get well be my professional deformation. 
Well, both of your variables are `&amp;Matrix2`, so I was looking for `impl&lt;'a, 'b&gt; Mul&lt;&amp;'b Matrix&lt;...&gt;&gt; for &amp;'a Matrix&lt;...&gt;`.
["Not-invented-here syndrome"](https://en.wikipedia.org/wiki/Not_invented_here#In_computing)
I live in Utah but am not Mormon, so I'm only 2 for 3 on world's most prevalent evangelists: Rust and [Arch](https://github.com/Aaronepower/tokei#arch-linux) [Linux](https://www.archlinux.org/packages/community/x86_64/tokei/) It's also on Fedora but I don't go for hats, red or otherwise. ---- [It should be in Homebrew soon](https://github.com/Homebrew/homebrew-core/pull/14894) ---- Edit: I got it merged!
I'd still like the warnings if they are never used. Moving them into a lib would disable that.
Great!
1.19.0 will be released on July 20th, to give you a specific timeline. I would also highly recommend Visual Studio Code with the Rust plugin (not RustyCode), or IntelliJ with the Rust plugin.
I'd look into what Mozilla is doing. They use Rust in Firefox and that sort of thing is necessary for their builds. If they don't yet have a proper solution, I'm sure they're currently shepherding plans to create one.
When playing with toy compilers or interpreters, I tend to do loop { let next = env.iter.next() match next { ... None =&gt; return, } } largely for this reason, so I too would like to see a for loop that doesn't hold on to its input.
About the float sorting annoyance at the beginning, why isn't there a standard non-nan type? Rust disallows invalid pointers, but not invalid floats? Division and modulus could be implemented by returning an Option. In practice, I haven't seen NaNs very often, if at all, and they may as well be a runtime exception like dividing integers by 0. The fact that I can represent fractions shouldn't make division by 0 any more valid!
btw, if someone can recommend a Raspberry Pi GPIO crate I would consider switching over. It needs to * work * be documented * use direct register access and not `sysfs`.
I'm not going to have access to a PC until the middle of July, but I will definitely remember this. That was what I was using MPI for: Chunking up a large task and distributing it across a cluster. I'm sure now that I've stated the obvious, someone below is going to crucify me
Not a bad idea. 
Is there any long-form documentation for Crossbeam? I can't pull apart function references and just assume function x does y. (That's something I've never been particularly great at...despite many years of coding). On a side note, if that's not 100% accurate, then why do both books written as "official documentation" tout this phrase...more than once??
I guess I should have specified single element tuple structs in enum variants. I see the appeal of .. when there are multiple members to match against. One example where they are different is that `_` will throw an error after a refactor that changes the number of members, where `..` won't (I think). 
There's a bit of example code [here](https://aturon.github.io/crossbeam-doc/crossbeam/sync/chase_lev/index.html) in one of the sub-modules, though I agree it's not great. I also used some of the example code [here](https://github.com/BurntSushi/ripgrep/blob/master/ignore/examples/walk.rs) to figure out stuff like references that can be accessed in multiple threads. &gt; On a side note, if that's not 100% accurate, then why do both books written as "official documentation" tout this phrase...more than once?? Well, because of the "your code won't explode" thing :) Rust had green threads at one point, but they were removed because it was decided that Rust was a systems programming language and therefore the "raw" OS threads should be exposed to users. I suspect it was just deemed not a priority given that there are only so many developers working on Rust currently. 
Rust: making it safe to code while half asleep. 
If infinities were also disallowed, how many edge cases would still need to be covered? I'm starting to dislike the specification. Infinity is Not a Number, so why is it a number and why is Not a Number a number? [EDIT] Integers have `checked_div(self, other: i8) -&gt; Option&lt;i8&gt;`, but nothing for floats as far as I can tell.
Thanks! The PR is this: https://github.com/compass-rs/sass-rs/pull/11 and the libsass guide is https://github.com/sass/libsass/blob/master/docs/build-on-windows.md Looking at https://ci.appveyor.com/project/Keats/sass-rs-rmnm5/build/1.0.2 it seems I can build sass-sys on Windows but linking fails. I tried both mingw and msbuild but I didn't manage
Yes. It will be changed to `..=` and stabilized. You can use `for i in 0...10` now on nightly with `#![feature(inclusive_range_syntax)]`. [Tracking issue](https://github.com/rust-lang/rust/issues/28237)
Don't worry, none of the native APIs give me raw access to the back buffer, so screen tearing shouldn't be an issue at all. On the other hand, if I ever add Fraps-style injection into Vulkan applications, that *might* be a problem, but that's an entirely separate project.
If I ever need to make a breaking change I'll be sure to change the name to `Display::primary`. ;)
I did not realise until pointed out by /u/TimNN that the people are the same. The 'hello world' message was a bit unexpected.
Thanks for pointing out.
Yeah, VSCode + [vscode-rust](https://marketplace.visualstudio.com/items?itemName=kalitaalexey.vscode-rust) is what I use, personally. For the best experience you'll need to have the nightly compiler installed, but that's only to power the editor, you don't have to actually build your code with it if you don't want to. It's worth noting that the current vscode-rust release (0.4.0) is unfortunately rather buggy; the bugs are fixed and checked in so the extension just needs to be republished, but you'll want to hold off until it is unless you don't mind building it from source in the meantime. (\*poke\* /u/kalita_alexey)
As some comments suggest 'cargo install' should only be used for addition *development* tools, I however didn't/don't see why I can't if I want to. The common problems I encountered with the system installation are: * incompatible libraries (well, this is probably not going to be that big problem for rust executables) * missing package from the distribution (Debian, for example, does not have a package for 'ripgrep') * installation is system wide, so everybody on the machine is affected
While I hadn't envisioned that specific purpose, the general sentiment is actually the whole reason I'm migrating my hobby coding to rust. Python is fast enough for me... I'm just tired of burning out because my perfectionist urges keep driving me to try to reinvent aspects of Rust's type system in Python via unit tests.
Add the new+proper method and deprecate the old, immediately. Leave it for a release cycle. Consider the timeline, and remove it when you think enough time has passed for the majority of the users to have seen the deprecation. Remember, version locking is a thing; breaking changes only matter when they bump their dependency.
Thanks, stack-langc was perfect for my needs!
Again, a little to complex for my needs. But thank you regardless!
That's not completely true. You might be right that the kernel automatically creates a guard page for the main thread. But when new threads are created, userspace controls the stack layout. Rust has [guard page code in libstd/sys/unix/thread.rs](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/unix/thread.rs): // Rellocate the last page of the stack. // This ensures SIGBUS will be raised on // stack overflow. let result = mmap(stackaddr, psize, PROT_NONE, MAP_PRIVATE | MAP_ANON | MAP_FIXED, -1, 0); if result != stackaddr || result == MAP_FAILED { panic!("failed to allocate a guard page"); } glibc also has code for this. It's messier, but you'll see it if you search for guard within [allocatestack.c](https://sourceware.org/git/?p=glibc.git;a=blob;f=nptl/allocatestack.c;h=ec7d42e027ba0ef76cc289d7bf0833c433685193;hb=refs/heads/master).
It's hard to say as unfortunately I'm on quite a tight timeframe and the size of the code means that I'd be spending too much time figuring out why my partitioner doesn't work on it. And after seeing Rayon I realise that I haven't looked into how my model would handle libraries performing parallel processing. Again would probably just take too long for me to get it working.
How would you handle a `RadioButton` type that is also checkable? Would you be able to share the implementation of `CheckBox` between the two implementing `struct`s?
Abstract classes in C++ and Java can also have fields, unlike in Rust. Of course you can simulate this, but as you said it's not as elegant. 
Possible, sure. I really don't think it's a very good use of someone's time though, given that existing MPI implementations (i.e. OpenMPI and MPICH) are designed to support a wide range of hardware. Doing it all over again would be very tedious. (Remember that MPI on supercomputers generally talk to hardware directly, not through TCP/UDP sockets.) I don't really see any reason to avoid the existing MPI bindings, they are quite decent from my experience. It's entirely conceivable to build a high-level Rayon-like library over the MPI layer (although for better usability you'd want serializeable closures, which Rust can't do yet). After all, the threading layer in Rust is *mostly* made of FFI bindings to the operating system!
[Go and Rust - Objects Without Class](https://lwn.net/Articles/548560/) was an eye-opener for me. It predates stable Rust, so not 100% accurate but it does provide a view on some of the downsides of traditional inheritance. Specifically, inheritance ties together many behaviors that you might want to opt into independently. My take is that traditional OOP inheritance has it's place, but it should be used sparingly and not as a general-purpose mechanism for code reuse. I think Rust needs to grow a little bit more here, but it's probably for the best that it started out without full blown inheritance from the start.
Ah hah, I was fooled by the two different `Capturer` structs and didn't look in the common folder.
Isn't this solved by https://github.com/rust-lang/rust/pull/42265 ? Which is basically the compiler generating code for `for` loops like /u/boomshroom wrote manually in his comment
I think the new Scala compiler, dotty, highlights the diffs between the types. It's something I've often wished for!
Nope, because the `for` loop would still be iterating on `&amp;mut self.in_iter`, meaning the iterator itself is borrowing `self`. The change you referenced makes the loop not borrow the iterator while it executes the body of the loop, but the iterator itself still exists for the entire duration of the loop, and since the iterator is borrowing `self`, you still have the problem.
What does IntelliJ offer over a code editor like Sublime? Are the context sensitive hints really that good? Do the unit tests hook in to a test runner? I've found that coding in Sublime tends to be easiest for me, but I'm totally open to change (esp. to IntelliJ). The main thing holding me back is the IDE loading time.
Maybe my prolog interpreter is simple enough? https://github.com/dagit/rust-prolog
I just double-checked with the latest nightly available as of now. (229d0d326 2017-06-23) Same result. "cannot borrow `*self` as mutable more than once at a time"
I can't get used to the UI over at users.rust-lang.org. I made an account. I tried to use it, and I tried to get used to it, but I gave up. At this point I get frustrated whenever that site shows up in search results. Loads of simple things seem way too hard. For instance, I can never tell when a post was made. In a language that moves as fast as rust, it matters a lot. The loading of content on scrolling is never a good UX for me. I don't understand why things turn color and then fade out. Was it important a second ago and now it's not? The linearity is a huge turn off. Following long threads means I basically have to take notes and disassemble the conversation so I can figure out who was talking to whom and about which parts. So, I stick to reddit instead. Plus I'm already here for other reasons instead of it being a special purpose website that I have to remember to check specifically.
I just checked with a simple example. Looks like the dotty compiler just complains about the stuff that is really different and 'ignores' the stuff of the type that is the same: object HelloWorld { def main(args: Array[String]): Unit = { add(1, List("foo")) println("Hello, world!") } def add(a: Int, b: List[Int]): Int = { a + b(0) } } This error message is much more user friendly that Rust's: -- [E007] Type Mismatch Error: /tmp/scastie4459190056588177473/src/main/scala/main.scala:3:12 3 | add(1, List("foo")) | ^^^^^ | found: String("foo") | required: Int | 
Yes, good catch! Thanks!
Sounds interesting, but can you give more info about the company? E.g. it'd be nice if you could answer the following questions :) What is the company's vision/goal? Is it a startup that's burning through investor money or a self sustaining established company? Do you also offer part time jobs for people who are also doing a degree at the same time? 
&gt; it moves data around at line rates This sounds really impressive! Just to clarify, up to what line rate has this been tested? 1Gb/s? 10 Gb/s? Higher?
Doesn't this only work if there is only one NAT between the computer and "outside"?
it's not perfect, but until RLS arrives, it is a nice experience with goto definition, type inference, etc.
The first call to foo() is assigned the **same** lifetime as the bar() function, so *x stays borrowed for the whole function. It might seem like the foo() call should get a smaller lifetime, as it's entirely contained within curly brackets, but the problem is that foo() returns a reference, and then you are returning that reference from bar(). If the first foo() call got a smaller lifetime than bar's 'a lifetime, bar() would end up returning a reference with a smaller lifetime than 'a - obviously unacceptable. If you comment out the 'return f;' line, the code compiles - because now the first foo() call is getting a smaller lifetime, as you expected.
The problem is that in my code I have two different foo() functions and depending on the result of foo1() I want to return either foo1()'s or foo2()'s result.
the compiler uses control-flow to determine borrowed entity scope. So this would work: fn bar&lt;'a&gt;(x: &amp;'a mut i32) -&gt; &amp;'a mut i32 { if unknown() { let f = foo1(x); return f; } return foo2(x); }
Try running `cargo build`. Seriously though, you're looking for /r/playrust.
I've used diesel for its migrations even if I'm not using it as an ORM. It's very nice.
My example was misleading - I want to branch based on foo1()'s result: fn foo1&lt;'a&gt;(x: &amp;'a mut i32) -&gt; &amp;'a mut i32 { x } fn foo2&lt;'a&gt;(x: &amp;'a mut i32) -&gt; &amp;'a mut i32 { x } fn bar&lt;'a&gt;(x: &amp;'a mut i32) -&gt; &amp;'a mut i32 { { let f = foo1(x); if *f &gt; 1 { return f; } } return foo2(x); } playground: https://is.gd/5CCBY9
It has a broadcast mechanism that can be used for collective operations. Someone with better 'unsafe' chops than mine can talk about how to do Rust with hardware RDMA.
Unfortunately, I don't believe this is possible. You have a canonical example for wanting Non-Lexical Lifetimes -- see the example [explained here](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/#problem-case-3-conditional-control-flow-across-functions). There are some ways to work around this, if you provide more detail. Otherwise sometimes you have to resort to using unsafe code. For instance, one solution is to call `foo1` twice, which i'm sure is undesirable fn bar&lt;'a&gt;(x: &amp;'a mut i32) -&gt; &amp;'a mut i32 { if *foo1(x) &gt; 1 { return foo1(x); } return foo2(x); }
Trivial to solve if you can permit calling foo1 multiple times. https://is.gd/eXZGpq You also don't need excplit lifetimes, as the ones you game are the inferred liftetimes by default.
&gt; avoiding unreleased language features would be a problem for anyone The problem is ergonomics. Libraries want to be *consumed*. But if Rust upstream promises dramatic usability feature improvements like async / await as a language feature at some point in the future, that affects how *any* library that does IO and also cares about performance (or even just CPU intensive libraries like a complex math or simulations lib would use) and that kills enthusiasm to write those libraries and APIs in the moment, because we will have to redo our entire user facing API once these language features emerge. A lot of this relates back to how rustc is privileged in what it can do. The core rust compiler implements the language and withholds capabilities from other crates (a common one people run into is how you cannot extend an external type with an external trait implementation - you either have to define your own trait or your own type and have the other be third party) that means you cannot just have an extern crate async-await that implements language primitive keywords like how they behave in other languages. You *have* to wait for Rust itself to adopt them. The unstable / nightly dependencies are more because a lot of features available in nightly, like compiler intrinsics, are never *meant* to become stable. But because no stable API to those features has been adopted yet, if you want to do most of the more complicated language processing or AST manipulation in your library code you *can't* use stable. Rocket is probably the most popular example of this problem - if *needs* nightly to support its routes decorators because it itself has to add arbitrary decorator definitions to the compiler because there is no timetable on stable Rust support for them. A lot of this is about conservatism - we are in 1.0 now, we can't break backwards compatibility until a 2.0 (and there would need to be a lot of accumulated reasons to make that jump) and adopting anything new needs to be taken in the context of that. Which means rfcs, that can just sit for months without moving forward, on all kinds of issues people have with the stable language lacking functionality. Like I said, most of that lacking functionality is ergonomical - the language is absolutely turing complete and you can *do* anything in Rust that you want right now. Worst case is you are using unsafe blocks. The problem is that common workflow optimiations in other langauges aren't present in Rust, and a lot of the advantage of Rust is in the ability to write extremely comprehensive abstractions - even just procedural macros now represent a tremendous amount of potential programmer efficiency over anything C can do, but the Rust devs tread lightly to avoid C++ templating which is a kitchen sink of performance regressions extreme compiler times and undefined behavior, but can do *anything*.
Thanks for your detailed response. I suppose I do belong in the conservative spectrum of Rust users who would advocate waiting for features to be completely baked before being available to normal (non std) libraries and library writers rather than the current situation. 
I am writing an interpreter, and now I want to write tests for it. The tests would be a bunch of small programs that I would check if they are interpreted correctly, or if they produce an error that I expect. My interpreter is a library to allow embedding into other programs. What would be a good way to do those tests? I was thinking of writing it as a single integration test that would load all programs and run interpreter against them, however that feels a bit cumbersome and difficult to inspect when it would be a single test.
What I meant by &gt; available to normal (non std) libraries and library writers is that Nightly is becoming Rusts Python 3 vs Python 2 situation. Incompatibilities in the ecosystem of libraries, by requiring different versions of the language tools. I thinks it's actually even worse since the Python situation was at least two stable versions causing the fragmentation, Rust has one stable and one ever changing Nightly version. I'm currently porting unstable rust from 2015 to work in latest stable, not that fun (but very educational!) and I would probably be done (a wild guess) with this project by now if not for this fragmentation. It's just one story from one user, but it's the story I care most for at the moment. That being said, I find it fairly easy to avoid libraries that depend on Nightly and that seems to be getting even easier when the more advanced build badges arrive on crates.io.
I use ion for most of my scripts, but I'm not sure I'd 100% recommend it as a default for a few reasons: 1. Documentation 2. Shell completions. I don't know if this is actually in there somewhere, but, as I said: documentation. 3. Ctrl-r reverse search. Again, I don't know if there's something I could change here. If you *would* like to change it despite the warnings, there are instructions [here](https://stackoverflow.com/questions/13046192/changing-default-shell-in-linux). The fact that it's written in Rust should be inconsequential. 
All all Rust functions `Re-entrant` by default? I'm trying to expose a generic call back mechanism within concurrent event loop and I'd like the confidence to know its not gonna explode in my face before I start writing it.
Sorry if my question wasn't clear. I do have those tests for small pieces, but I also need to test how my interpreter performs on complete programs. And my question is what would be a convenient way to write integration tests that need to test interpreter behaviour on given list of programs.
Just curious, which tool were people using before diesel_cli (for migrations in PHP etc. projects)?
I'll look into those. Thanks!
Awesome :) I will try to make it this time, as my wednesdays finally became free.
Ha! I've wanted to know what to put in my .cshrc to get it to drop into zsh on our work cluster for ages. Thanks for that! (Can't swap my login shell to zsh because our admins have a lot of global config in tcsh. Tried it already and it doesn't work)
Phinx appears to be the most common for PHP, but based on my little bit of research, PHP does not appear to have a big migrations ecosystem. I did not know about migrations during my peak php personal project years, so I've never used any actual PHP migration tools. I used (lib)ORM for C++ at my last job, but I don't believe it has a CLI for actually running the migration files. 
Haskell's facilities for making compilers are best-in-class. Not that it's not still impressive on the author's part, but it's actually only ~~770~~ 5748 lines for the entire thing. 
&gt; Wait, explain that one to me? The editor needs the nightly build even if I'm not compiling with it? The best experience with VSCode comes from enabling [the RLS](https://github.com/rust-lang-nursery/rls), which requires nightly right now. So the editor will use that for code analysis, but if you want to you can still build your code with stable/beta/whatever. &gt; (And yeah if buggy, I think will be waiting) 0.4.2 is published with all fixes in place.
Always good to see more people drop by. Also please talk to us if dates don't work out. We are open to shift the day around to allow people to attend who otherwise couldn't (obviously for the future, July is now fixed) 
This is a nice little explanation of an important difference between the for and while loop constructs in Rust which is absent in other languages like C. The for loop executes a block of code once for each element it pulls from an iterator (absent additional control flow such as return or break). In order to make this assurance, it holds ownership over the iterator and manages the state of the iterator for you. In contrast, a while loop *just* checks a condition at the beginning of each iteration (in terms of control flow, separate from destructuring and name binding). When the condition check completes, the while loop is no longer involved until the next iteration begins, and it leaves state management *up to the programmer*. Because you're responsible for state management instead of the looping construct, you get back the ability to make borrows, but lose the contract that your code block executes once for each iteration through the loop. This can be clearly demonstrated by calling .next() on the iterator inside of the while loop. As such the blog isn't describing a syntactical quirk of the language, but rather a semantic difference in guarantees made by the different control flow constructs. This contrasts with C-descended languages, where for and while are essentially isomorphic under some rearrangement of code.
Let me rephrase that: I had a tendency to burn myself out trying to reinvent the guarantees provided by Rust's type system in unit test form.
One way to handle DB migrations is to use an external tool - something like [alembic](http://alembic.zzzcomputing.com/en/latest/) or [Flyway](https://flywaydb.org/), for example.
Certainly! Thanks for the compliment, too. :)
**Region-based memory management** In computer science, region-based memory management is a type of memory management in which each allocated object is assigned to a region. A region, also called a zone, arena, area, or memory context, is a collection of allocated objects that can be efficiently deallocated all at once. Like stack allocation, regions facilitate allocation and deallocation of memory with low overhead; but they are more flexible, allowing objects to live longer than the stack frame in which they were allocated. In typical implementations, all objects in a region are allocated in a single contiguous range of memory addresses, similarly to how stack frames are typically allocated. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^] ^Downvote ^to ^remove ^| ^v0.23
Our operatives are everywhere
It's cool that she's talking about Rust, but this title feels like it violates Rule 3 a bit too much.
*Rust Evangelism Strike Force Also, try /r/rustjerk
Maybe, but it's Manning.
too important? literally had to google who she was..
[Apparently she's been learning cryptography too](https://twitter.com/isislovecruft/status/864245830588538880) :)
Unless this changed very recently, you missed the biggest reason: lack of job control.
You might want to try /r/playrust for Rust the *video game*. This subreddit is for Rust the *programming language.*
Oh yeah of course, I forgot wrapping around the ring buffer wouldn't actually be contiguous memory. Stupid me! The documentation was a little baffling to me on this, it seemed that things only got pushed into the other slice in the pair when pushing specifically onto the front, rather than just going all the way around the buffer too. I thought it was using a special 2 buffer system, where items 'on the front' were in one section of memory, and those 'on the back' were in another. My bad, thanks for the clarification!
The ring buffer stores everything in contiguous memory, but there's a gap if the beginning and end don't meet. That gap is at the end if you haven't ever popped an element, but if you have, it will be somewhere in the middle. In the example I gave, it would look something like this: // After the first 6 pushes | "first element" is here v 000000__ // After the 4 pops | v ____00__ // After the next 5 pushes | v 000_0000 Then, when you ask for the slices, it first gives you from the "first element" to the end of storage, then from the beginning of storage to the "last element". The two slices are both part of the same block of memory.
Oh i didnt know i'm sry.... Thank you
I currently only use ion for personal automation, not production, so I didn't notice that. But it would be a big downer. 
...I'll allow it.
This post boils down to someone you find important namedropping Rust on Twitter. Your subjective opinion on their importance is irrelevant to whether this post is off topic. I could care less even if it was Bill Gates namedropping Rust.
But it's mostly unsafe! So what advantage does it have over the C version?
Rust's stdio flushes on newline; since you removed the newline, you removed the flush. You can call [`flush`](https://doc.rust-lang.org/std/io/struct.Stdout.html#method.flush) yourself to the same effect.
Ahh, that makes so much sense. Thanks!
I hadn't really thought about it until right now, but they are formatted so well! Debugging in rust is almost enjoyable (not quite though).
Are you telling me that this: loadfrags.cc (.text._ZN5boost12interprocess20shared_memory_object19priv_open_or_createENS0_9ipcdetail13create_enum_tEPKcNS0_6mode_tERKNS0_11permissionsE[boost::interprocess::shared_memory_object::priv_open_or_create(boost::interprocess::ipcdetail::create_enum_t, char const*, boost::interprocess::mode_t, boost::interprocess::permissions const&amp;)]+0x139): undefined reference to `shm_open' is hard to understand?!?!?!?!?!
Given that paraphrases a quote from [a slide I wrote](http://venge.net/graydon/talks/intro-talk-2.pdf) ("Technology from the past..."), I will answer! (I should qualify this with the fact that rust gained substantially fancier technology in the years of development _after_ that slide was written; but I think the ethos motivating it was maintained, in terms of a [preference for stable and well-understood things rather than the newest-latest tech](http://www.mayofamily.com/RLM/txt_Clarke_Superiority.html). Not to mention my own personal belief that the tech industry reinvents the _same ideas_ it's recently forgotten every few years, like some sort of goldfish that keeps discovering the same 3 shiny rocks over and over, but I digress..) Rust's memory model ("ownership and borrowing") rests on the careful _combination_ of two older ideas: 1. [substructural types](https://en.wikipedia.org/wiki/Substructural_type_system) -- specifically [affine types](https://en.wikipedia.org/wiki/Substructural_type_system#Affine_type_systems), which have appeared in languages going back at least as far as functional programmers trying to avoid GC and/or model IO in lazy languages (see linear lisp, probably the first place I saw it, or clean uniqueness types). To some extent, these are just special cases of plain old "value semantics" implemented more-eagerly than copy-on-write reference counting. 2. Nested "region" pointers (which we eventually called borrows, partly to help disambiguate from region-based memory management). These pointers began in rust as second-class (parameter-only) "safe alias arguments" similar to safe [pass-by-reference arguments](https://en.wikipedia.org/wiki/Pass-by-reference) in (many!) other languages, but with implicit non-aliasing on pairs of mutable same-typed aliases, similar to ["restrict" pointers in C](https://en.wikipedia.org/wiki/Restrict). They only grew into first class types -- that you could store inside other types, say -- after Niko argued us all into believing that the system of lifetime-annotation and lifetime-variable inference / relating at work in other languages would transplant well here without too much annotation burden (jury's still out on that). The best previous example would probably be [Cyclone](https://en.wikipedia.org/wiki/Cyclone_(programming_language)), but I should note that the general idea of "a stack-discipline reference that can't outlive its referent" is inherent in _any_ pass-by-reference regime; it's just not always the case that you can independently reify the pointers _as types_ without immediately opening a hole in memory safety, permitting dangling pointers. The extra machinery in Rust (as in Cyclone) is to let you reify the pointers implicit in a pass-by-reference scheme, but annotate them with a lifetime bound so they never dangle. Again though: when I first started (and published that I was working on Rust) its ideas dated from much earlier: coroutines, copy-on-write reference counting, pass-by-reference, stack-local values. These go back to the 60s and 70s (many of my favourite languages are from around my childhood, late 70s / early 80s). The stuff we picked up later, as the language matured and newer / better language researchers showed up to help, pushes into "90s research"; but it's important to keep impressions of contemporary-relationships in mind. From the arrival of Java in the early 90s until .. well, certainly through the entire 90s and first half of the oughties, there was little interest in native code. Some functional languages (Ocaml, Haskell, some Lisps) had fast native compilers connected to reasonable-GCs, but most people ignored them. The big, influential languages of those decades were either super-unsafe C/C++, or "safe" languages that were bytecode-VMs-with-JITs-and-GCs, in which the argument was mostly about whether they should or should-not have a static type system. The resurgence of interest in (comparably) safe, native languages was a late-2000s / early-2010s thing. Go and Rust went public in 2009 and 2010, respectively. Swift in 2014.
I can’t wait for debugging support in IntelliJ!
Does anyone know what the blockers for packaging `rustup` in homebrew are?
She [leaked US diplomatic cables](https://en.m.wikipedia.org/wiki/United_States_diplomatic_cables_leak) for basically every country in the world. This was covered widely across a range of international papers, led directly to the revolution in Tunisia and indirectly to the Arab Spring, and impacted diplomatic and business relationships throughout the world. Hardly "US politics".
Non-Mobile link: https://en.wikipedia.org/wiki/United_States_diplomatic_cables_leak *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^83765
If anyone was wondering, [here](https://github.com/Baransu/emacs-snazzy) is an Emacs theme based on this color scheme.
.0. Time to get a new Emacs theme!
That is very nice! Which one do you like more?
It's less true than it once was. This notion originated before Rust's borrowing system was created, and while borrowing in Rust is certainly inspired by Cyclone, Rust's system is more completely realized than any similar systems that came before. Rust borrowing is novel. 
Well, as far as error messages go they both do their job extremely well, but they're languages targeted for very different usecases and Elm is a much smaller language than Rust; so it's hard to make a fair comparison. With that said, both of them definitely set the bar for error messages (and most other things, anyway) in their own domain.
Very good point!
It's a starting point. You can convert it to safe rust 1 small part at a time, and ensure the tests don't break while you do so. Doing this can be a lot easier than starting from scratch.
That's what I use in IntelliJ!
I'm fine with this content being posted here, but a title along the lines of "Chelsea Manning endorses Rust" would be less meme-ish.
I haven't done any Rust web development yet but I'm an NFSN user and I seem to remember them being FreeBSD-based, so that's probably your problem. 
OpenSSL is a massive pain in the ass on Windows and Mac, whereas native-tls is easy.
That's Fira Mono.
Depending upon how self-sufficient you are, you may want to consider https://hostus.us/. The last time I compared their pricing it was pretty competitive. There are a lot of options out there and they change pretty frequently.
I sincerely hope that Dracula will one day take over the world of syntax-highlighting.
Does DigitalOcean have a free tier?
I think you're in the wrong sub. The game is over there ==&gt; https://www.reddit.com/r/playrust/
No, but you may receive quite many amount of credit for their promotional campaigns. If you're interested in free VMs, Google Cloud Platform recently started a free tier which has little amount of resources free (and you will be billed for anything beyond it, without the ability to set any limit).
Usually the one provided with the ORM library, for instance Doctrine migrations: https://github.com/doctrine/migrations
It appears to be in there as rustup-init: https://github.com/Homebrew/homebrew-core/blob/master/Formula/rustup-init.rb
rust is amazing ❤️
I guess she has found out that Rust type system doesn't prevent leaking. ... I'll let myself out. 
And our chief weapons are fear, surprise, and ruthlessly efficient code!
I believe there are some ringbuffer implementations that memory map the same memory page containing the ring buffer twice, one after the other, so the second memory range is a copy of the first, which means that you can always find your data in a contiguous block. I don't know if anyone has implemented it in rust though.
Yeah, it was a bit sloppy of me to compare it to Python. I'm not back porting, I'm porting unstable rust features from 2015 that does no longer exist and as such do not have any documentation, so I kind of have to guess what the features were doing. I love Rust, but for me personally Nightly has only brought unproductivity and pain. I hope Nightly goes away.
You could have a look at WebFaction as a "traditional" hosting provider that'll run whatever you want, or one of the PaaS services - Heroku, Openshift, etc.
Then Assange arrives and the party is over.
Comparing an internal compiler error message with a normal error message isn't exactly fair! :)
That did it, thanks!
Why doesnt gnome terminal get any theme love :(. All of the good themes are for iterm
Oh that's really interesting, will be doing some googling on that
Since nobody mentioned it yet, I just want to say I like /u/tomaka's [rouillie](https://github.com/tomaka/rouille). I find its [`router!`](https://docs.rs/rouille/1.0.1/rouille/macro.router.html) macro very pleasant.
True, but… have you used diesel or futures? :D
How about switching to Rust Unitary Strike Team, though? That way the acronym is also RUST.
I was surprised to find Edward Snowden's endorsement in Cory Doctorow's Walkaway. So we know Snowden does make such endorsements... We can only hope.
Posting a code snippet and saying "this fixes the error", without any explanation how it solves the problem is (in this case) not very helpful.
Yeah, that sounds great! But why is it private right now?
I created [locc](https://github.com/mkulke/locc) as my first stab at Rust. At work we have to deal with locations a lot and this is a CLI to help with recurring questions around the topic (geocode/reverse geocode/distance/random locations). The onboarding to Rust was pretty smooth, cargo is a great build-tool &amp; package manager. I did not really struggle too much with the borrow checker, maybe because the code is not typical/idiomatic? (It seems you can write Rust code in a pretty functional way, which makes it look like Scala or even Haskell. The ? macro with -&gt; Result&lt;T, Box&lt;Error&gt;&gt; almost behaves like the "do" notation). I really like that all the libraries seem to leverage Option/Result. I was puzzled a bit by lifetime annotations, sometimes it felt a bit arbitrary when you were required to add those. rust-geo being a young project is a bit lacking, however serde-rs is great, so is clap.
&gt; Not for research or exploring a new type system. (From the slides you linked to) Big respect for keeping open and keeping on top of such a rapid evolution regardless of original plans! The syntax examples in the slides are just reminiscient of current Rust. Thanks for the incredibly detailed answer, and sorry for misquoting!
Are you trying to say Rust can't do REST? I thought Rust was webscale! &amp;nbsp; &amp;nbsp; &amp;nbsp; ^^^Sorry
But Rust Evangelism Strike Force becomes RESF :p
Ah, that's fine then. Couldn't tell if it was just an example or something you were trying to do for real
Fun fact, if you Google Assange you will see that [he was programming in OCaml](https://www.reddit.com/r/programming/comments/eg1m6/10_years_ago_julian_assange_was_doing/) around 2000. Know what else was written in OCaml ten years later? The first version of the Rust compiler. Was that coincidence? Well, it probably was.
Also: Vultr at $2.50! https://www.vultr.com/pricing/ And Scaleway €3 https://www.scaleway.com/pricing/
&gt; So far, I have ported the following to run under Redox: &gt; &gt; - GNU binutils &gt; - GCC &gt; - GNU make &gt; - dash &gt; - curl, with SSL support (used by cargo as a library) &gt; - LLVM and Rustc Okay, now I feel like a slacker oO 
The best thing is it's not debugging: you don't have bug in something you can't compile!
Of course, the minimum memory consumption of such a data structure is 4KiB, or whatever the native page size is.
musl is designed to run on Linux only, while newlib is designed to be portable.
That’s what I use. I switched from iTerm2 Nightly to iTerm2 Beta which doesn’t have that, which is why there aren’t any ligatures in the picture.
Fira Code, not Fira Mona. I’m on the beta for iTerm2, not the nightly, so no ligatures.
afaik, there haven't been any security audits of rust-openssl either
Fair point, but it still shows you what you need before the ()()()()() mess.
Wait wut — I thought I was supposed to use that in IntelliJ, not other JetBrains apps. Do I lose anything significant, and what do I gain from using CLion vs IntelliJ with the same plugin? **EDIT:** I did some research, the debugger is coming to IntelliJ very soon.
I don’t find the wrapping too bad, the nicest part of it is the formatting of the code and the magically underlined code blah.
What? Other langs do flush stdout on read? I find this crazy surprising. Even Python, which says "Explicit is better than implicit"? WTH? To me if something says "read" I certainly wouldn't expect "write". If other langs do that, I'd consider it a bad design in those langs.
Ah, hm, don't try anything with futures/tokio just yet, you might get disappointed.
[removed]
[Tokio](https://tokio.rs) is a Rust library (framework?) for async io. [Futures](https://tokio.rs/docs/getting-started/futures) is an async primitive. Adaptor methods result in highly nested types, similar to deep iterator method chains
Tokio is the newfangled, de-facto library for async I/O. Due to the nature of its types, its error messages look like: ``` error[E0271]: type mismatch resolving `&lt;futures::AndThen&lt;futures::MapErr&lt;futures::AndThen&lt;futures::FutureResult&lt;DBusStream, std::io::Error&gt;, tokio_io::io::WriteAll&lt;DBusStream, &amp;[u8; 1]&gt;, [closure@src/lib.rs:113:23: 115:14]&gt;, [closure@src/lib.rs:116:22: 116:66]&gt;, futures::AndThen&lt;std::boxed::Box&lt;futures::Future&lt;Error=auth::errors::Error, Item=auth::types::ClientReturn&gt;&gt;, futures::future::LoopFn&lt;futures::AndThen&lt;futures::sink::Send&lt;tokio_io::codec::Framed&lt;DBusStream, auth::codec::SaslCodec&lt;auth::types::ClientSaslMessage, auth::types::ServerSaslMessage&gt;&gt;&gt;, futures::AndThen&lt;futures::stream::StreamFuture&lt;tokio_io::codec::Framed&lt;DBusStream, auth::codec::SaslCodec&lt;auth::types::ClientSaslMessage, auth::types::ServerSaslMessage&gt;&gt;&gt;, std::result::Result&lt;futures::future::Loop&lt;DBusStream, (tokio_io::codec::Framed&lt;DBusStream, auth::codec::SaslCodec&lt;auth::types::ClientSaslMessage, auth::types::ServerSaslMessage&gt;&gt;, auth::SaslClientAuth, auth::types::ClientReturn)&gt;, (auth::errors::Error, tokio_io::codec::Framed&lt;DBusStream, auth::codec::SaslCodec&lt;auth::types::ClientSaslMessage, auth::types::ServerSaslMessage&gt;&gt;)&gt;, [closure@src/lib.rs:132:43: 155:34 break_loop:_]&gt;, [closure@src/lib.rs:130:48: 156:26 break_loop:_]&gt;, [closure@src/lib.rs:124:72: 157:22]&gt;, [closure@src/lib.rs:123:27: 157:23 transport:_, auth:_]&gt;, [closure@src/lib.rs:117:23: 159:14 mechanisms:_]&gt; as futures::Future&gt;::Error == auth::errors::Error` --&gt; src/lib.rs:111:9 | 111 | / Box::new( 112 | | result(stream_or_err) 113 | | .and_then(|stream| { 114 | | tokio_io::io::write_all(stream, b"\0") ... | 159 | | }) 160 | | ) | |_________^ expected tuple, found struct `auth::errors::Error` | = note: expected type `(auth::errors::Error, tokio_io::codec::Framed&lt;DBusStream, auth::codec::SaslCodec&lt;auth::types::ClientSaslMessage, auth::types::ServerSaslMessage&gt;&gt;)` found type `auth::errors::Error` = note: required for the cast to the object type `futures::Future&lt;Error=auth::errors::Error, Item=DBusStream&gt;` ``` This should get better once `conservative_impl_trait` makes it to stable, whenever that is.
Actually, I think "value moved here" is slightly ambiguous to beginners. It could mean either "the value moved to this destination" or "this is the place in the code where the move operation occurred". I don't actually know which interpretation is intended. Possibly, both are valid, but a beginner who doesn't know that might get stuck on trying to figure out which one is the right one.
[Rust has **optional** region-based memory management](https://doc.rust-lang.org/1.1.0/arena/)
[This](https://is.gd/6a8acb) error? Since `conf.date` is a `String` and `"latest"` is a `&amp;str`, you need to add some type conversion like [this](https://is.gd/OBxXOE). With the expanded `match`, that type conversion is taken care of by the automatic dereference in the first branch.
i am confusing native-tls with rustls!
Note that the exhaustiveness checking of match arms isn't particularly smart. It can handle booleans and enum variants, but not numeric ranges, like [this](https://is.gd/nzyeue).
In order: 1. This is indeed a label, it is used here so that `break 'running` will break from *two* loops at once. 2. The pipeline means OR, as in bitwise arithmetic. It allows taking the branch of the patch whether the left side or right side pattern is matched. You can pipeline an arbitrary numbers of patterns. 3. The double dots are used for elision: they match any numbers of members of the `enum`/`struct`. 4. `::std` is probably used to ensure that even if the `std` symbol is redefined in the thread, the global `std` is used. I'd hope no one defines a new `std` though. I do recommend reading the Rust book (2nd edition), it may be lengthy but: - nobody said you had to read it in full before starting writing code, - you can skip the sections you either already know OR do not care about at the moment, and come back later. I'd recommend at least getting a passing acquaintance with the topics mentioned in the book, so that if a term pops up that you do not understand, you can have that lighting bulb moment "Oh way, the book was talking about that, let me open it again".
1. Yes, it's a label. 2. "Or". That arm is matching two distinct patterns. 3. In a structure or tuple pattern, they mean "and the rest". This must be explicit so that if you write an exhaustive pattern (*i.e.* match all fields in a structure), and then someone adds a new field to the structure, the compiler can help you track down where you need to update patterns. 4. Because it's an absolute path; `std` only exists in the root module. You don't tend to see them on `use` items, because they get absolute paths by default. Everywhere else, paths are relative to the current module. Just think of `::` in Rust paths as like `/` in filesystem paths (also: `self` = `.`, `super` = `..`). I don't recommend trying to take shortcuts. So many problems people have starting with Rust is thinking "oh, I know how this works!" and then being subtly wrong. I've lost count of the number of times I've seen people trying to use traits like interfaces, or doing insane things with modules. You're probably going to end up either having to read the whole book *anyway*, or otherwise have it explained to you on Reddit/Stack Overflow in a less coherent, less comprehensive fashion. Even if you just *skim* the book, that's probably much better than trying to dodge it entirely.
Yes. This is terrible, and the error message is terrible. It has been slow going making the right improvements to make this better; I regret not persevering through learning enough in order to at least make this be a better error message ([tracking issue](https://github.com/rust-lang/rust/issues/35946)). I only have so many hours in the day, though, and improvements have always seemed just around the bend-- [see this RFC and the issues linked in its description](https://github.com/rust-lang/rfcs/pull/1937). 
In Markdown, a list is four spaces of indentation, regardless of whether that seems necessary or not. So you need *eight* spaces of indentation for code inside a list. So: - This is list item text. This is more normal text inside the list item. But this is code inside the list item. Becomes: &gt; - This is list item text. &gt; This is more normal text inside the list item. &gt; But this is code inside the list item. If you want to have code immediately after the list, an empty comment is supposed to be enough: - This is list item text. &lt;!-- --&gt; This is code outside the list item. … but Reddit’s Markdown-like format doesn’t allow HTML comments for some reason. So you’ll need something else, lest it become like this: &gt; - This is list item text. &gt; &lt;!-- --&gt; &gt; This is code outside the list item. I can’t at present think of anything that will convince it without unpleasant side-effects like an empty paragraph that appears from using ZWSP: &gt; - This is list item text. &gt; ​ &gt; This is code outside the list item.
Haha I just copied it from a StackOverflow page — I don't know anything about boost.
Unless you are doing metaprogramming. Then compilation and link failures are actual debugging since the code is evaluated at build time.
Well I found it made a good bit of sense as I'm following through with the online book you can find on the doc page, which explained the problem very well.
Ah, ok, that's good to know!
You can get the same warnings in Visual Studio (C++) by using the static code analysis feature. Just leaving this here for anyone interested.
Function invocation requires `()` in Rust. The reason to label a loop is to allow `break 'label` to break from multiple loops at once.
1. I want pictures 2. Isn't that GUI? 3. Doesn't CLion do the same thing? 4. I'm wondering if I should try Visual Studio... thoughts?
No, this is definitely always true as long as the array is nonempty and the elements have nonzero size.
1. The warnings is vis studio 2. Isn't the warning it gives in a GUI and not text based? 3. Yea I just checked. CLion is amazing btw. 4. On mac, but they just releases a thing for mac so you know. IMO CLion is the best for C/C++ Also yea I was kinda unclear with that comment. My apologies.
Approximately 6 days ago I my trust-dns project had one test start failing in nightly: https://github.com/bluejekyll/trust-dns/issues/152 Initially I had an overflowing subtraction that the nightly compiler caught for me. After fixing that, it's still failing on nightly. I have yet to track it down. I don't directly rely on any unsafe code, but I'm sure some dependencies do. I still need to isolate where in the code this issue is appearing, right now it's basically an integration test that's failing, which to say the least means it could be anywhere. Oh: and I should add that I reviewed all changes merged into Rust master during that period, and haven't seen anything yet that gave me something to dig into.
Git repositories can easily be moved to other platforms like Gitlab. All the open issues er would be lost, but at least the entire code base would be preserved.
Well, you can use arenas in C too, so I don't see the point in saying that Rust has region-based memory management if it is not by default.
This is a programming language sub-reddit. You are looking for /r/playrust, or possibly an issue reporting forum such as https://steamcommunity.com/app/252490/discussions/4/ or https://support.facepunchstudios.com/
That will still execute println in the first statement. The second line will simply use the result of println!(…), which should be the useless value `()`. If you want to execute some code later as a function, use a lambda: let func= || println!("Hello Friend."); … func();
Incidentally, this thread inspired me to waste some hours on this https://www.reddit.com/r/rustjerk/comments/6jg6tq/what_to_expect_when_youre_not_expecting_the_rust/?st=J4D5C7JB&amp;sh=e8a5cad4
Is it possible to implement a generic `is_even` function? This is what I have: use std::cmp::PartialEq; use std::ops::Rem; fn is_even&lt;T: Rem + PartialEq&gt;(n: T) -&gt; bool { n % 2 == 0 } fn main() { is_even(2); }
Ok, I think we've got something here, so I've filed an issue: https://github.com/rust-lang/rust/issues/42903 Please comment on there /u/fulmicoton or /u/bluejekyll if you discover anything new!
You can do something like this: use std::cmp::PartialEq; fn is_even&lt;T: Into&lt;i64&gt;&gt;(n: T) -&gt; bool { n.into() % 2 == 0 } fn main() { println!("even: {}", is_even(4)); } It converts n into i64 type
+1 for perfect explanation. Explaining these concepts to others can help you further understand the concepts yourself.
Thanks. It's good to know about the `Into` trait. I didn't know about it before. I looked in the `num` crate and it looks like they are implementing their `is_even` method using macros. I'm guessing a macro would be required for an `is_even` without type conversion?
TL;DR yes, bug: https://github.com/rust-lang/rust/issues/42903 please comment there if you have a similar failure :)
FYI, just ported that to Konsole. https://github.com/miedzinski/konsole-snazzy
To be clear, your loop only iterated 232 times, as 1000 overflows converting to u8, and thus in the same as the literal 232.
C++ does by default, but it's 1 line to disable it. &gt; To me if something says "read" I certainly wouldn't expect "write". It flushes what you've _already_ written; if you're prompting the user for input, making sure the user sees that prompt is a no-brainer. How often do you write to stdout then wait for input without wanting the user to see what you wrote?
Looks very similar to the [theme I use](https://github.com/oskarkrawczyk/honukai-iterm-zsh).
Everything in Visual C++ is text-based – it's a commandline app, as with every other compiler I'm aware of... If you see something in Visual _Studio_'s UI, that's because it was parsed from stdout/stderr of the compiler/linker. EDIT: I'd love to know whoever downvoted's justification for downvoting a simple fact.
Forgive me if I'm wrong, as it's been a while since I've used a Mac, but is it more complicated than `brew install openssl`?
You also have to ensure some paths are correct. I don't know the details; it's been awhile since I set it up. It may be that the Brew defaults are correct, but even then it's pretty painful when anything overrides those. (Just thinking back to the last time I installed zsh there. :p)
Do you have example code where these actually perform better than the mutable equivalents from the standard library? I'm betting linked lists and Arc incrementing/decrementing might be slower than you expect. In the meantime, I'll just drop "mut" when I want an immutable. 😜 
yeah, I compiled it on ubuntu with default target, maybe will try it later
https://en.wikipedia.org/wiki/Chelsea_Manning
If you're running fully escalated, there's very little you can't do.
OH. I used `tokei` and it didn't catch the `.lhs`. I'll have to put in a PR I guess :)
Oh yeah I wouldn't use it in production. But it'd be nice to have it as my own shell, plus I could contribute in the form of bug reports.
I trust Apple to handle a security critical crypto library a lot better than some random volunteers. In my (limited) experience with Homebrew they have been lax about security and eager to mess with upstream in arbitrary ways, which can introduce devastating bugs. By using the system SSL you will also get automatic upgrades for security fixes. And, there is the argument that you are already trusting it with so many things, that you might as well not introduce a second library with its own issues.
Processes within a user account are rarely isolated from eachother.
Genuinely curious, how could that be useful?
It's probably necessary of things like debuggers, profilers, etc.
That's how apps like Cheat Engine or ArtMoney work; they attach themselves as "debugger" to another process, and can freely read (and even overwrite) memory.
OSes of _today_ don't. e.g. UWP apps on Windows are sandboxed, or Store apps on OSX, or flatpaks on Linux. Not all apps - especially older ones - are compatible with those sandboxes. The OSes have varying levels of support for restricting those apps. Windows RT or iOS or Android or various SELinux-based secure distros, for example. We just don't see those OSes much outside of phones because we users are picky and expect our old software to keep working. :)
I do not. You could look at the assembly to verify it, I suppose.
Ah cool. I've been wondering which of the various decimal packages is going to be the de-facto standard one. I guess it's [this one](https://crates.io/crates/bigdecimal) then.
Checksums for one, such as CRC32 where you just add stuff together and take the module for whatever bitness you want. I use a simple protocol with an 8 bit checksum and this is the simplest way to do it. There are a few others (perhaps generating a unique ID with a simple counter that's allowed to wrap around), but I think that's the most common.
Awesome work! Are the changes you're making to port things like `cargo` being done upstream, in a "vendored version" of cargo, solely in Redox proper, or something else entirely? I.e. once the port is done, will it be a struggle to keep up with current versions?
Made a ton of progress on my way too ambitious [ReProto Project](https://github.com/reproto/reproto). A DSL for describing and generating protocol objects for various languages. This project grew out of the frustration of the countless number of times I've had to hand-roll these. I'm also unhappy with the alternatives that are available, so I decided to take a stab at my own take on it. Primarily this is inspired by protobuf, but geared towards making it easy to describe idiomatic JSON. Something protobuf unfortunately was never designed to do well. It's the first time I've done something this large in Rust, which makes it a steep learning experience. Initially there was way to much cloning, which has forced me to understand borrowing and lifetimes much better than before. Some highlights: * Protocol objects are strongly typed, the compiler will complain loudly if you try to do something obviously wrong. * The compiler is wicked fast, I don't have any issues with getting fast feedback when working on specifications. Thank you Rust. * I put emphasis on integrating with existing frameworks. I don't want to build an entire server/client stack with custom serialization supported in X languages. There's protobuf and gRPC for that. * I want to be able to generate great documentation. All features are designed with a "documentation first" attitude. For this I'm relying heavily on markdown, similarly to how documentation works for Rust. Last week I've switched from [pest](https://github.com/pest-parser/pest) to [lalrpop](https://github.com/nikomatsakis/lalrpop). This meant having to write a custom lexer, but fortunately this is actually really nice in Rust. I've introduced versioning of specifications using [semver](https://github.com/steveklabnik/semver), multiple versions of a dependency can co-exist in the same package in a conflict free manner. This week I'll be focusing on designing a repository system. This will allow for sharing and downloading specifications similarly to how package managers handle dependencies. Because I want to eventually use this at work it is very important that the workflow is enterprise friendly with internal mirrors, private repositories, and indexes. I'm taking inspiration from cargo.
Windows, OS X and Linux are desktop OSes. It's just that with phones we got to reinvent the model because applications needed to be built from scratch anyway. With desktop it's going to take a while for everyone to move to sandboxing.
In GitHub forks of cargo and several dependencies. Hopefully it will be possible to upstream the needed changes (once some functionality Redox is missing is implemented, and the changes are no longer hacks).
&gt; Checksums for one, such as CRC32 where you just add stuff together and take the module for whatever bitness you want. I use a simple protocol with an 8 bit checksum and this is the simplest way to do it. But that's not overflow on literals, it's on the result of arithmetic operations (which panics in debug builds).
Good point. I'm not sure I can think of cases where you'd want a literal to overflow. It is interesting that compile time overflow is permitted where runtime overflow causes a panic.
Many Linux distributions nowadays set the sys.kernel.yama.ptrace_scope setting which prevents this: https://www.kernel.org/doc/Documentation/security/Yama.txt
This is interesting as a proof-of-concept. But does it serve a practical purpose in the context of Rust? In functional languages immutable collections make sense, as "no side effects" is a big part of functional programming (you could argue that's the single most important part); and it has practical benefits to prevent race conditions, etc., when sharing data across threads. But Rust solves those problems in different ways. Is there anything I'm missing? Something else that immutable collections offer?
Isn't the name of this kind of thing "copy on write" rather than "immutable"? The `Cow` `str`/`String` wrapper works like you described, as I understand it.
Probably because even if it's only a warning, it's hard to miss at compile time.
I would not expect these structures to be used as pervasively as they are in functional (immutable) languages, but I still think they can be of interest. First, if you want to code in a more functional manner in Rust, but also in cases where you need to keep track of all the evolution of a state variable (e.g. if you want to be able to able to revert to a previous state, like the "undo" feature in an app). In the latter case, it will probably cost less memory to have a persistent data structures than e.g. a `Vec` cloned multiple times.
The undo feature is also what I thought of first.
Not the error messages we want, but the ones we deserve.
Imo what would be really useful if there would be a layer on top of these data structures that could perform the diff (generate the edit steps) needed to transform the one structure into the other.
This is the mental model I use when thinking about these scenarios in patterns: `ref v` takes a reference of something that would otherwise be by-value. `ref mut v` takes a mutable reference of something that would otherwise be by-value. `&amp;v` _matches_ references, and binds (or matches) the de-referenced value to `v`. Note that if `v` is no longer a reference, it effectively moves the value (EDIT: as pointed out by /u/sellibitze, this will most likely cause a compiler error). `&amp;mut v` _matches_ mutable references, and binds (or matches) the de-referenced value to `v`. Consequently, `&amp;ref v` matches a reference and de-references it. We might as well just match `v` to get the same effect. I'm not sure if this is applicable for all scenarios, but for the ones I can think of, it would be equivalent. One use I can think of for `&amp;mut ref v` is if you want to match a mutable reference, but use it as an immutable one ([playground link](https://is.gd/jEqX9m)). I hope this helps!
I like sandstorm.io's model which uses capabilities.
I have same nasm code that does 0x100000000 - x. Which is just -x. You can do the same in rust if you want a specific unsigned number rather than (-x as i32) as u32. (Rust also complains if you have a negate a literal with unsigned value)
**I've got a use case for immutable collections** - I'll be rolling something else slightly more specific myself. When you know something is permanently immutable, **there are more whole program assumptions that can be made**. The use case is index and vertex data for meshes, for rendering . Rust uses bounds-checked array indexing, but if you know the data is immutable (as is most of the data held in a game engine - it's created by offline asset conditioning pipelines), you can check *once*, on creation, then use unchecked operations *from then on*. Another example is the 'bounding box' of a vertex array. A program will calculate some bounding shape (AABB, sphere or more) of a set of vertices, and continue to use that. Again, for that to remain valid, there is an assumption that the underlying data has not changed. What I really want is **an vector that maintains the Min and Max values of it's contents**, i.e. on creation this is computed. If the data is ever modified, these values must be re-computed. e.g. then an index buffer can be paired with a vertex buffer, and the index range is compared, and if it's ok, unchecked indexing is used; similarly, the vertex buffer's extents may be assumed. it would look something like this, RangedBuffer&lt;T&gt;{ fn get(&amp;self, int i)-&gt;T; //element access fn set(&amp;mut self, i,&amp;T); // will update internal min/max fn min(&amp;self)-&gt;T; // the min of all T's here fn max(&amp;self)-&gt;T; // the max of all T's here fn generate_from_fn(int size, generate_item_)-&gt;RangedBuffer&lt;T&gt; } it could implement the whole interface for 'Vec&lt;T&gt;' .. but that will require patching some sort of 'update()' calls into the implementation for the entire 'Vec' interface. ... or possibly further generalised for a ```B:Bounds&lt;T&gt;``` which may be default to a simple ```Range&lt;T&gt;```, or a general geometric bounds .. explicit 'bounding box' or 'centre+radius', For maximum elegance I want a version of ```T:PartialOrd``` which can be component wise (see my other requests to generalise the ```gt/lt``` operators, but I'll roll a 'component wise compare' myself for this. As it stands, anything I would have done in C++ in the past has this implicit assumption relied upon informally.. it would be great to have a safe wrapper for this concept. I notice these are different immutable collections , (sets, lists etc) which probably have even more scope for different internal optimizations if you know their content will not change.
You could use a match like in this example: https://docs.rs/mime/0.2.6/mime/struct.Mime.html But with `Mime(TopLevel::Text, SubLevel::Xml, _)` as the pattern for the MIME type.
They do not, because large parts of the old data structure can often be reused. E.g. suppose you implement `ImmutableVec&lt;T&gt;` as a single linked list, prepending a single element means you can reuse the entire tail without copying it, whereas `Cow` would copy everything.
 &gt;&gt; The point of these data structures is not that they are immutable as in "you can't change them", interesting... I've got other use cases in mind for which plain 'really immutable' collections are one solution. Another is 'collections which may be assumed to mutate rarely' .. some data that is setup and optimised for one configuration, then used many times. I am sure there are many special cases that will appear over time as people try to create safe abstractions for *all* the use cases that exist in C++ programs. (one specific use case I have is 'never-NaN floats' - if they're in an immutable collection, you know they were checked once; and 'array indexing that can be assumed correct with no bounds checks' e.g. an immutable index buffer and immutable vertex buffer. The index buffer could hold the min/max indices, then you just check those bounds when pairing an index buffer with a vertex buffer. )
&gt; Last week I've switched from pest to lalrpop. What's the reason behind the change?
I understood what you said. But I was simplifying. Thanks.
FYI, this crate also uses the same function.
Ah, I didn't notice that. For the most recent version (0.3.2) there is this new bit of documentation: https://docs.rs/mime/0.3.2/mime/
If only. 9 out of 10 times the raw output of the MSVC compiler is much more useful than the VS' UI "translation".
I've been using Rust for over a year and somehow completely missed that loops can have labels. Thanks!
We have Rust crates for controlling mouse/keyboard input, taking screenshots and now reading process memory... Rust just became an attractive alternative for writing game bots ;)
What do you mean by open? Are you using hyper? This might help then: https://stackoverflow.com/questions/41619187/hyper-says-invalid-scheme-for-http-for-https-urls
But that's what I mean. All of the desktop OSes in popular use today support that kind of application isolation. They just _also_ support non-isolated applications.
Does anybody have a good tutorial for custom derives they could point me to? Additionally, is it possible for a custom derive to take arguments (compile time constants only of course)?
Wait, are those *immutable* or *persistent*? I expect two very different things from those adjectives!
Why bother with mouse/keyboard, just *write* to the process memory ;)
Good point.
If [lazy_static](https://crates.io/crates/lazy_static) doesn't work for you (which you should try to use if possible) then your only hope is with unsafe. I [wrote about it](https://mgattozzi.com/global-uninitialized) not to long ago actually. If you know it's not a problem since you'll be doing single threaded code then go ahead with it. It's safe that way, but the compiler doesn't think so, which is why you need to use `unsafe`. Using `unsafe` isn't a bad thing.
Seems like something that would quickly become meaningless, and a time sink pushed by non-technical managers.
The two interpretations aren't really that different, since the source location of a move always also specifies the target location. But, an interesting couple of data points- look at the error messages for [function calls](https://is.gd/734fo5) that take their arguments by move, and [closures](https://is.gd/8FKzpy) that capture values by move. The closure message actually tweaks the wording to "value moved (into closure) here," so if I had to pick one I'd go with "this is the place in the code where the move operation occurred."
Kudos on getting that far with pest. When I tried it I did not get absolutely anywhere with the processing section. Nothing I tried worked. I use nom now and very happy with it.
[GIFV link](https://i.imgur.com/JDhk0yj.gifv) --- _^I ^am ^a ^bot. ^[FAQ](https://www.reddit.com/r/livven/wiki/gifv-bot) ^// ^[code](https://github.com/Livven/GifvBot)_
I *think* this is for /r/play_rust but sometimes the type system makes me feel this way, yes.
We would welcome advice from the Rust community with how to improve the code. Even so, this first version has very good performance characteristics, easily hitting 5k msg/sec on an old mac book air. 
/r/playrust
https://github.com/jgallagher/rusqlite 's `Connection::open_in_memory().unwrap();` is not mut
I don't think this is a good idea. Unit tests are great for some things, but [100% coverage is kind of meaningless sometimes](https://labs.ig.com/code-coverage-100-percent-tragedy). Honestly the reason I think TDD/BDD became such a big thing for languages like Ruby/JS is because of the dynamic typing making it easy to mess things up. Rust gets rid of a lot of those problems with a strong type system (granted the if it compiles it works mentality is also not correct). I tend to look at badges like this with skepticism. It's better to test properties using random input rather than with unit tests. For example in Haskell using quickcheck: ``` decode $ encode x == id x ``` I can be fairly certain this will catch more errors than a few unit tests I wrote that might miss some weird edge cases. There's also [cargo-fuzz](https://github.com/rust-fuzz/cargo-fuzz) which has helped catch many a bug. Rust doesn't have goto so the second badge kind of defeats point of having it, and if someone is doing code jumps then they're probably writing it with unsafe rust anyways. What if I need to read and write from something that isn't stdin or out? I would have to for programs doing DB connections or writing to sockets, yet you could write them in a way that was safe. While I get wanting to verify code quality I just don't think these kinds of badges are the best way to go about it unfortunately.
Look at reqwests (think I spelled that right)
That's not the point of 100% control flow coverage. In a safe language like Java which basically guarantees CFI and no memory corruption if you follow every possible control flow path and no control flow path reaches an exception you can prove an absence of exceptions. I do agree that for many projects aiming for 100% control flow coverage could be effort better put on other things though. &gt;I can be fairly certain this will catch more errors than a few unit tests I wrote that might miss some weird edge cases. You want 100% control flow coverage to make sure you catch exactly these kinds of edge cases. &gt;Rust doesn't have goto so the second badge kind of defeats point of having it, and if someone is doing code jumps then they're probably writing it with unsafe rust anyways. You don't understand what CFI is. CFI means that when someone calls a function pointer it is not possible for the function pointer to be overwritten by memory corruption and lead to attacker code (a similar situation applies to the return address on the stack.) This is usually implemented by encrypting function pointers with a secret key. Goto has nothing to do with this. In practise, most of the way to CFI is achievable by turning on a few compiler options. Also, there are complications involving Unix signals and some other quirks. &gt; What if I need to read and write from something that isn't stdin or out? I would have to for programs doing DB connections or writing to sockets, yet you could write them in a way that was safe. Then you don't get the badge. Not all programs can get all badges. Some programs such as OS kernels are too low-level to get most of these badges or it is too expensive to get these badges. Also, I plan on other lower levels of badges but I can't really think of good definitions for them.
&gt; 100% control flow coverage is not meaningless. I didn't say it was meaningless. I said it could be. It means that there aren't panics in the paths I hit, but it doesn't mean I have any assertions around the test to actually state that the values produced are correct. An improper sort function could have all paths tested but if you don't write an assertion that the function actually produces sorted values you're just testing for panics. &gt; Most of the way to CFI is achievable by turning on a few compiler options. Control flow integrity is ensuring certain control flow always follows some 'path' (or set of paths) through a control flow graph, regardless of memory safety errors. One can't prove control flow integrity, it's an enforcement mechanism. So I don't really see why a badge is necessary since rust's default compilation flags are really where you'd want this. And again, we get into specifics - some control flow implementations: a) have performance impact more significant than others b) limit control flow paths at a finer grain level than others c) only limit forward edge calls d) etc etc etc As for least privilege, I don't see any way that it's different from sandboxing, although I guess the word sandboxing has been really mutated and conflated over the last 5 years. But least privilege means that individual components of a system only have the capabilities required to function, this is sandboxing. It's also not something easy to badge. Is a whole program sandbox utilizing DAC as impressive as a muitiprocess seccomp sandbox? I would argue no, but that would be an argument, not an assertion. edit: As I said, I'd like to see a way to encourage these things, but I feel badges lose too much context. I think some people may be underselling code coverage because it's so often abused, but I'd rather have 100% than 0% any day. As for sandboxing, most programmers don't know what it is or how to write sandboxed code, so step 1 is education.
This works great, thank you &lt;3 EDIT: It is called reqwest, without s
&gt; and no memory corruption if you follow every possible control flow path and no control flow path reaches an exception you can prove an absence of exceptions. I think `assert!(double(1) == 2)` would give 100% control flow coverage on the snippet below, but I'm not *quite* convinced there is no way for it to throw an exception. // Doubles the input. public static Integer double(int n) { final int knownInts = new Integer[] { Integer.valueOf(0), Integer.valueOf(2), Integer.valueOf(4) }; return knownInts[n]; }
Java implicit inserts a bounds check. This is why I carefully chose binary control flow instead of writing lines of code coverage.
&gt; That's another good reason to focus on very simple things such as "does the file only read and write to standard input and output?" Instead of specific sandboxing implementations. I think it becomes increasingly difficult to 'rank' a sandbox. I could write every program such that they only read/ write to stdout, but I would maybe only enforce that through DAC. I could enforce it through seccomp, but would my badge change? Certainly the security implications of exploiting my program would. As I said, lots of context is lost in badges. I *do* agree that we should encourage this, but badges just lose too much context - I do kind of like them for code coverage though, I think people knock coverage far too much without really expressing the issues with it, and how those issues can be mitigated. &gt; I should note that these badges would be generic and not only for Rust specifically. A big thing about these badges is that Rust would trivially fulfil many of them and that unsafe languages like C would not. That's a good point, particularly in regards to CFI. Knowing that rust programs are built with safe compiler flags would certainly be nice, relative to C/C++. In particular for shared libraries.
So it is impossible to get 100% binary control flow coverage on the following program, because of the implicitly inserted bounds check? // Doubles the input, or returns `null` if we don't know the answer. public static Integer double(int n) { final int knownInts = new Integer[] { Integer.valueOf(0), Integer.valueOf(2), Integer.valueOf(4) }; return 0 &lt;= n &amp;&amp; n &lt; knownInts.length ? knownInts[n] : null; }
This is honestly a pretty annoying thing about rust, and lazy_static is not great because of checking every time. One workaround I found, if you want to avoid the constant checking of lazy_static, is to create 2 global variables, one static mut and one static, and have the second be a reference to the first. use std::ops::Deref; struct Ref&lt;T&gt; { ptr: *const T } impl&lt;T&gt; Deref for Ref&lt;T&gt; { type Target = T; fn deref(&amp;self) -&gt; &amp;T { unsafe { &amp;*self.ptr } } } unsafe impl&lt;T&gt; Sync for Ref&lt;T&gt; {} static mut GLOBAL: i32 = 0; static GLOBAL_REF: Ref&lt;i32&gt; = Ref { ptr: unsafe { &amp;GLOBAL } }; fn main() { unsafe { GLOBAL = 42; } println!("{}", *GLOBAL_REF); } Bear in mind this solution is unsafe if you don't initialize the variable properly. Lazy_static, on the other hand, is perfectly safe.
This crate can be the base to build event driven microservices. Awesome! :)
Hey, did you take a look at https://github.com/FGRibreau/postgresql-to-amqp ? What are the differences?
Java is a complicated case because in typical implementations it is usually jitted. In a statically compiled language like Ada one would write the code such that the bounds check is optimized out at the binary level and so one wouldn't have to check it in a test case. I'm not as sure how to apply the same concept to a jitted language.
&gt; I could enforce it through seccomp, but would my badge change? Again, this is why only very simple and stupid metrics such as "my program only reads or writes standard input or output" should be used.
If they're simple and stupid I don't think they're really worthwhile, or encourage good behaviors.
Haha, ok.
The answer depends on what you expect from these two words. The data structures are like what is explained on the Wikipedia page, and quoting that page "Such data structures are effectively immutable".
Rust needs some language-level feature to make the "initialize once; then it's immutable" pattern more ergonomic. Not just globals, but a general construct for this. It would also be useful to make `Rc` cycles and so on.
+1 Passing it around would be the idiomatic way. This is good for unit/integration testing later too.
&gt; Not just globals, but... when would you need a special feature when you're not talking about globals? have you seen that you can do this? let x; let y; if z &gt; 3 { x = 4; y = 2; } else { x = 3; y = 3; } obviously this is a contrived example, but you can declare uninitialized variables, then initialize them later, without them being mutable. "deferred initialization" is the term, I think. This only works in local contexts, though. Globals are the exceptional thing that might benefit from some kind of special feature like `const fn`.
Just use hyper 0.10.12. Hyper 0.11.00 was refactored to be async and to not use TLS by default. 
Uhm, I don't recall the specifics, but you need `RefCell` to create an `Rc` cycle in safe Rust, even if the data is immutable after the cycle is created. Unintialized variables won't help here. The fact that you need unsafe code to avoid `RefCell` in the `Rc` case, and to avoid `lazy_static!` in the static global case, made me think that perhaps they are connected.
Unless you have a variant of `Rc` with a cycle collector.
At most once and yes, for now if connection is lost, notification will be dropped. First version ... :) but still, there are a lot of usecases where ppl can afford to lose 1-2 events while the connection is reestablished. 
But can you really trust the compiler? Unless you have a formally verified one like CompCert you'd want to verify the actual binary as is done in SLe4. I deliberately wanted to avoid dragging in details of the high level source language and to stick to more primitive concepts.
Hello /r/rust! I'm back to writing some Rust code after a few months of going back to C++, so I restarted my old project (a Chip-8 interpreter) from scratch. I have a question about code organization and good practices. Let's say that my `src` folder looks like this : ├── assembler.rs ├── cpu.rs ├── instruction │ ├── mod.rs │ └── variant.rs ├── lib.rs ├── main.rs └── memory.rs My main.rs contains all the CLI code and the lib.rs contains an interface for the CLI to work with (and I absolutely love that cargo allows you to do that). However, I feel like my modules (which are declared in the library) are a bit messy. `instruction` and `memory` are pretty much self-contained, so they aren't a big problem, but the `cpu` and `assembler` modules has dependencies on `instruction` and `memory`. So, is this okay to do something like this in, for example, my `cpu.rs` file? use super::{instruction, memory}; And what happens if I start to modularize the CPU itself (or the assembler, for that matter)? Will I have to chain `super` until I get some monstrosity like this? use super::super::super::instruction::{Code, Instruction}; Of course, it won't ever come to that for that little project, but I'm trying as much as possible to do things right, and things like that make me question my structural choices :-) Thanks a lot!
Yup. I think that lacking an easy, low-level way of creating singletons is just Rust's way of teaching us how complex instantiating a global shared object really is. There are multiple ways to do it, and a mechanism that is acceptable for a server app might not good for an embedded system. I'm starting to think about a layered DI framework for Rust that would link instances of service objects (logs, metrics, db) into instances of business objects, while retaining ownership of everyone so that the app can be partially stopped / reloaded on config change or panic. Yes, I was doing lots of Spring not so long ago... And I was liking it.
That's true if you are reading the `GLOBAL_REF` on a different thread than the main thread. On the main thread, the write happens before the read. You are right that you would need to insert a barrier if you read the value on a thread that was spawned before the value was set.
What is your use case for this-- A long running task alerts its completion?
No you're absolutely right. It you're issuing &amp;String you're better off using &amp;str
Why would you come in here and speak this way?
You can't use `Connection` in a global variable because it's not `Sync`: it cannot be shared safely between threads without using a `Mutex`.
I think a `use` statement always resolves from the crate root, no matter where in the module hierarchy it appears; so `use {instruction, memory}` ought to work in `cpu.rs`, and in any other modules.
I'm talking about the Rusqlite data type, not SQLite though.
Right, you create a new connection in each thread. It's a static method, so there's no need to pass a `Connection` around.
Yup. You're right. It seems to have an internal mut.
I suggest using `Rc` or `Arc`.
Maybe `Cell` and `Weak`?
I personally think security bugs are bad design. Multithreading directly leads to lots of bugs and complications unless you have a powerful type system or enforce safety other ways such as through using multiple processes instead of threads.
If the library is hiding global state and doesn't give you any way to attach information to the pointers directly, you might have to resort to a global that maps FFI pointers to their Rust counterparts. That way, any time a pointer crosses the FFI→Rust boundary, you can canonicalise the resulting value.
Porting `multipart` to asynchronous Hyper. I'm still not 100% sure on how to approach this, but I've laid out my tentative plans [here](https://github.com/abonander/multipart/issues/40#issuecomment-310949212) and I'm interested in feedback. (Reposted from last week's thread cause I was a little late and I'm still looking for feedback.)
The simplest solution would probably be to use `std::process::Command` to call the `lp` command from CUPS. (check `man lp` or [this page](https://www.cups.org/doc/options.html) for details on what arguments to use.) It can accept images, text files, PostScript, or PDF as input and, if you don't want to write a temporary file, you can stick `-- -` on the end of your arguments to make it read from stdin. This [Unix &amp; Linux StackExchange answer](https://unix.stackexchange.com/questions/251687/limitations-of-cups-command-line-printing-of-image-files) explains the mechanism by which file formats are supported and how to check support for or add more supported formats.
Thank you! This'll be a great start
[A quick search on crates.io](https://crates.io/search?q=cups) reveals no bindings for libcups. It may be easiest to script something that calls out to [lpr](http://man7.org/linux/man-pages/man1/lpr.1.html)
&gt; I can’t at present think of anything that will convince it without unpleasant side-effects like an empty paragraph that appears from using ZWSP Add `--` on a line before the code: - This is list item text. -- This is code outside the list item. produces - This is list item text. -- This is code outside the list item. vs. with nbsp: - This is list item text. &amp;nbsp; This is code outside the list item.
In this case you may want the std libraries `thread_local!`
&gt; Incidentally, this reads a bit like a homework problem Maybe [this one](http://exercism.io/exercises/rust/nucleotide-count/).
Thanks for the updates!
The whole point is how `catch` interacts with `?`. You could use label-break-with-value to write something operationally equivalent (and indeed, that's how `?` and `catch` are specified in their respective RFCs), but that isn't a substitute for having a dedicated syntax. The dedicated syntax makes the intention more clear, and is ergonomically better suited to fulfilling that intention. Otherwise, we wouldn't have if, match, for/while/loop, continue/break, etc… Instead, we'd just write all our code with branches.
This is the question actually, that describes one non-trivial question on managing lifetimes. Good read imo.
[removed]
What kind of college gives homework assignments in Rust? (yet) :-)
I think this breaks the sidebar rule of No Zealotry. Remove the protoss bindings and resubmit.
I tried to make a more idiomatic version. It would probably be better to validate your input separately from doing any computation. This way, you can validate once, then compute many times (after modifying). This will likely improve any vectorization for your `count` function. #[derive(Eq, PartialEq)] enum Base { A, C, G, T } impl From&lt;char&gt; for Base { fn from(c: char) -&gt; Base { match c { 'A' =&gt; Base::A, 'C' =&gt; Base::C, 'G' =&gt; Base::G, 'T' =&gt; Base::T, _ =&gt; unreachable!() } } } fn count(c: Base, s: Vec&lt;Base&gt;) -&gt; usize { s.iter().filter(|&amp;x| &amp;c == x).count() } fn string_to_base_list(s: &amp;str) -&gt; Vec&lt;Base&gt; { s.chars().map(Base::from).collect() } fn main() { println!("{}", count(Base::A, string_to_base_list("ACGTAAAGTC"))); }
I don't like to repeat myself so I'd do fn valid(c: char) -&gt; bool { c == 'A' || c == 'C' || c == 'T' || c == 'G' } then I like to use guard clauses and early returns to reduce rightward drift of code: pub fn count(c: char, s: &amp;str) -&gt; Result&lt;usize, &amp;'static str&gt; { if !valid(c) { return Err("Invalid nucleotide given as search base"); } if s.chars().all(valid) { Ok(s.chars().filter(|&amp;x| x == c).count()) } else { Err("Invalid character in DNA sequence") } } I would like to simplify the logic further, but I would need something like this: https://internals.rust-lang.org/t/pre-rfc-fold-ok-is-composable-internal-iteration/4434/12
This might be one of the most pointless bots I've ever seen...
Note that the `inline_always` lint is aimed at beginners, who tend to overuse it once they learn of it. If Andrew Gallant uses it, it's probably for a reason.
[removed]
Well, it might help to check what subreddit you're posting to. You probably want /r/playrust.
wrong subreddit, /r/playrust
What bot? Could you please clarify?
&gt; even as I type, I wonder if a single concept of 'verified values' could be created Why not just wrap the float and define the operations on it in a way so that not-NaN always holds (check on creation, multiplication/division/addition returning a Result etc.)? Just like String guarantees valid utf-8.
As u/yuriks said, don't return an owned pointer to T1, return a reference or a custom reference type that implements Deref for T1.
I think a simpler approach would be to just have a table that stores outgoing messages. pg-amqp-bridge can then publish to rabbit and delete the record from the table. On startup pg-amqp-bridge can catch up on any pending messages in the table before listening for new notifications.
What you suggest sounds good at first but the code you wrote may be considered incorrect. First, that `unreachable!()` isn't actually unreachable. The input should be validated. `Base` shouldn't impl `From&lt;char&gt;`. Maybe `TryFrom`. Anyway, the conversion function should return `Result`. Some nits: * suggested derives: `#[derive(Debug, Copy, Clone, Eq, PartialEq, Hash)]` * require iterator instead of vector `fn count&lt;S: IntoIterator&lt;Item=Base&gt;&gt;(c: Base, s: S) -&gt; usize {` * `string_to_base_list` should return `Result`
Can please tell me what kind of script is more useful in server management? https://apkauthority.com
if the amount of events is low (like tens/hundreds per second) that approach might indeed be better, with another custom script doing what you suggested however if the amount of events is nontrivial, that might put additional load on the db and specifically on that table. Probably depends on the use case
Yes, you're right, I was just writing a quick example otherwise I would have handled invalid input. Good suggestions, I mainly wanted to show idiomatic operations on the Base enum, which remove the need for error handling at that stage.
It is literally `panic!` with the prefix "internal error: entered unreachable code". There is a *completely unrelated* (and `unsafe`) `intrinsics::unreachable` function which makes it UB for the program to reach that point, i.e. LLVM optimizes assuming it can't ever be reached, removing anything that would only happen if it *were* to be reached.
Oh damn, I though unreachable! used the intrinsic. But you're right it's just a panic! with a specific message, should have checked the source.
Regardless of your political beliefs about the individual in question, please do not spread medical/scientific misinformation. Chelsea Manning is transgender, *not* 'cross dressing'. It is worth your time to learn the difference. From a quick glance at your comment history, I imagine that you spoke the way you did because you feel that her status as a transgender individual may have gotten her a 'sympathy vote' in the way her case was handled. If that is so, please keep in mind that you only make such effects, be they perceived or actual, worse when you talk like this.
The BWAPI community is a lot of fun. Back in the day I wrote Ruby bindings for BWAPI and made a simple bot that zergling rushed opponents. It had zero intelligence, just make the units and send them to where it expects the enemy to be. Spent 3 weeks on wrapping BWAPI, and then 3 hours building a 30 line bot that defeated some of the super AI heavy players that apparently hadn't faced a zergling rush before. It helped that at the time the Java bindings only worked well with Protoss and Terran I think, so there weren't a lot of Zerg bots around. Just cheesing of course and it took my opponent very little time to improve his bot and defeat me, but it goes to show how much fun a good API around a game can be. If there are going to be decent Rust wrappers I'll take another swing at it!
/r/playrust We're the programming language community here at /r/rust.
Yeah, I tend to nest modules/packages a lot and managing dependencies can get a little bit messy in some languages! I think I need to start worrying about writing reusable code a lot more, and that problem will fix itself. If I'm tempted to nest `alu` and `fpu` in `cpu`, for example, it's because at the time of writing, they are required only by the CPU, so I end up putting them as a non-public sub-module of `cpu`. But now, I can see that becoming a problem if I need to implement another CPU (if I want to add Super Chip-48 support, for example). So I'll keep that in mind, and I already have a (still quite blurry) idea on how I will organize things :-) Thanks a lot!
There are colleges and universities which give homework assignments in ‘any programming language of choice’ – I had a few of those. The lecturer expected just to see a working program, reacting properly for given input and didn’t care for technology used. ;-)
If you're still in love with Ruby you may take another chance with [BWAPI-C](https://github.com/RnDome/bwapi-c) :) We have wrapped alsmost all of the original C++ BWAPI, so today's Ruby bots may be as powerful as C++ ones. Of course, we'll be happy if you'd try Rust API as well!
It seems that [hyper-rustls](https://crates.io/crates/hyper-rustls) can provide HTTPS support for hyper 0.11. But if you just want to make a request, reqwest is the right tool for the job.
If this is from exercism.io, as I thinks it is, since I did exactly this problem too, I encourage you to look at other people solutions.
Ah, I see. Thank you. Just too many bots per page here :)
Are instances of `T2` meant to be able to outlive their parent `T1`? Your pseudo-rust makes its seem like the `t1` and `t2` are disconnected, as if the `t2` could be kept alive beyond the extent of the `t1`. But then, is it really a one-to-many relationship between `T1` and `T2`? Or is it a `zero-or-one-to-many` ?
Nah, much easier to just build a [supply depot](https://www.youtube.com/watch?v=z5OGD5_9cA0).
The usecase is explained here https://github.com/subzerocloud/pg-amqp-bridge#but-why-
If there's an open-source API you recently used (or that you can otherwise access outside of work) you could create a CLI front-end for it. The idea being that you're already familiar with the back-end, and what you did in JS. Of course, a lot of the difference will come down to not using HipFramework.JS or having a DOM to play in, but that's going to be the case most whatever you do in Rust. :)
Good question! I'm guessing logically T2 shouldn't outlive T1 (the underlying pointer, not the new type. In my example I'd expect T2 to outlive the inner scoped T1). Though I haven't (yet) seen any issue in practice. For example, if you remove the inner scope in my example, the drop order of T1 and T2 is ambiguous/unknown, and I haven't seen any problem there. I'm guessing the deconstructors don't care about the relative's data. But now that you mention it, I bet there is a use after free if we forced a drop on T1 and then tried to get the parent pointer from T2. Though I haven't yet seen this come about more naturally (since people don't usually explicitly call drop?)
This is a really interesting idea, thanks! For the global were you thinking something along the lines of a hash table that maps the (integer) pointer value to say, a Rc of the actual pointer? (edit: or would it map to the actual newtype T itself) 
A binary? How do you check plagiarism? The source code too? I wrote it on your office door in Whitespace.
Good point, I'll give it a shot. Isn't manually implementing Deref considered a bad practice? Or would this just be a scenario where it might be okay due to the constraints? 
Last time I checked that intrinsic was unstable. If someone wants stable version, look into "unreachable" crate.
Great thanks for writing this up
I started by porting things I'd normally write in shell script, but wanted to be more robust. It's a good on-ramp because you can produce something useful with only a small amount of code and the simpler language constructs, yet you still get good experience with Rust's approach to error handling, which is one of its most distinctive features. If you have experience with tools like Yeoman and want a project template to pick apart, here's what I use to start such projects: [ssokolow/rust-cli-boilerplate](https://github.com/ssokolow/rust-cli-boilerplate) Just bear in mind that it was written for a prototype templating feature that was backed out of the Rust nightlies for further refinement, so, to "generate a project" you'll have to manually... 1. Make a copy of the folder with the name you want your project to be under 2. Delete the `.git` folder (if you used `git clone` to download it) 3. Edit `Cargo.toml` to set the project and author names 4. Run `git init`
Time for a new crate then i guess ;) https://crates.io/search?q=hipframework.rs
A possible "efficient" solution (error messages by iopqfi): fn count(seq: &amp;[u8], base: u8) -&gt; Result&lt;usize, &amp;'static str&gt; { let mut count = 0; match base { b'A' =&gt; { for &amp;b2 in seq { if b2 == b'A' { count += 1; } else if b2 != b'C' &amp;&amp; b2 != b'G' &amp;&amp; b2 != b'T' { return Err("Invalid character in DNA sequence"); } } }, b'C' =&gt; { for &amp;b2 in seq { if b2 == b'C' { count += 1; } else if b2 != b'A' &amp;&amp; b2 != b'G' &amp;&amp; b2 != b'T' { return Err("Invalid character in DNA sequence"); } } }, b'G' =&gt; { for &amp;b2 in seq { if b2 == b'G' { count += 1; } else if b2 != b'A' &amp;&amp; b2 != b'C' &amp;&amp; b2 != b'T' { return Err("Invalid character in DNA sequence"); } } }, b'T' =&gt; { for &amp;b2 in seq { if b2 == b'T' { count += 1; } else if b2 != b'A' &amp;&amp; b2 != b'C' &amp;&amp; b2 != b'G' { return Err("Invalid character in DNA sequence"); } } }, _ =&gt; return Err("Invalid nucleotide given as search base") } Ok(count) } 
Even better, just add HKTs to the language and we can do this with monads, which are vastly more general
On a related note, (raw) pointer values are unique across different threads, right? T1 isn't threadsafe, but I'm wondering if I could lock the global state structure in a mutex so that multiple T1s could be used in different threads? And have one single structure to manage them all. Does that sounds feasible and safe? 
Threads all share the same address space, so you'd *hope* so.
Even just moving an instance of `T2` to an outer scope will allow people to observe it (easily) in a potentially invalid state: let outer_t2; { let t1 = T1::new(); let t2 = T2::new(); outer_t2 = t2; } // use `outer_t2` here Plus I'm still not clear on how the parent/child relationship between `t1` and `t2` is established, unless `let t2 = T2::new();` is in fact short-hand for `let t2 = T2::new(&amp;t1);` or `let t2 = t1.make_child();`
In any case, if you want to enforce a nesting relationship between `T1` and `T2`, you can probably accomplish it by adding a phantom lifetime to `T2`. That will allow you to encode a relationship that does not allow any `T2` to be moved outside of the scope of the `T1` that is its parent, (However, it will also likely force such a `T1` to be frozen in place while any such `T2`'s are in scope. That may not be what you want for your API.)
would it be possible to have a repo with all of those benchmarks? I would like to reproduce them on a Ryzen machine with 8 cores and 16 threads, to see how they scale to higher core counts.