We're currently using the "binsearch-100" configuration which has more memory usage than binutils, but lower running time.
&gt; 1.x.x is just a number though. Not in SemVer it isn't. SemVer numbers are, as the name says, specifically designed to hold meaning. `0*` is not production-ready. SemVer doesn't consider any `0.*` version number compatible with any other, and the `1.*` turnover signals that the crate is ready to be relied upon without worry for the immediate future, and has the feature set necessary for general use.
I am in the same boat for trying to fly Rust in space. Hoping I can use it to get a toe in the door, and then work my way in from there. Rust's ability to cleanly interface with C is definitely a killer feature, though, otherwise I wouldn't have a chance.
Not everyone who uploads a crate is going to strictly adhere to a set rule.
[Then they're wrong.](http://doc.crates.io/manifest.html#the-version-field) &gt;Cargo bakes in the concept of Semantic Versioning, so make sure you follow some basic rules: &gt; &gt;- Before you reach 1.0.0, anything goes. &gt;- After 1.0.0, only make breaking changes when you increment the major version. In Rust, breaking changes include adding fields to structs or variants to enums. Don’t break the build. &gt;- After 1.0.0, don’t add any new public API (no new pub anything) in tiny versions. Always increment the minor version if you add any new pub structs, traits, fields, types, functions, methods or anything else. &gt;- Use version numbers with three numeric parts such as 1.0.0 rather than 1.0. SemVer is quite literally a core part of how Cargo and crates.io operate. Version numbers aren't just a matter of personal taste; they're important and mean things. Incorrect versioning should be considered a bug just as much as incorrect coding is, because both lead to failures when other people try to depend on them.
Does it mean they will be in next stable?
The language is Turing complete. There are literally an infinite variety ways to approach every problem.
Well played posting that comic! Its great we have a sense of humour!
These days, when I think about my dream language, I start with "like Rust but..." I am charmed. Especially by the attention to detail.
I understand why C is the way it is, but at the same time we're on this subreddit because we're hoping to move past that. I will grant you that Java example is ... pretty atrocious. I can't sugarcoat it. I like C&amp;#9839;'s method, and it *especially* helps that they have a `var` type so you don't have to repeat types like C++ (pre-`auto`) and Java. Rust's method is also pretty great IMO, and I can generally appreciate the naming idioms in place here even if I don't always agree with them. Type inference in general is pretty fantastic, actually. Moral of the story, I prefer non-squashed names, but it's nice being able to have the language help you out with them, such as not having to explicitly state the full symbol all the time, or strip duplication like with `use std::fmt::{many, different, things, in, fmt};`, or infer types where possible. Neither extreme is great, but I have different opinions about Java's vs C's.
Would be awesome if Rust cargo would see compilation failure and try again.
Then it sounds like we're getting at roughly the same opinion from different directions. :)
This is the second time it happened to me in recent memory and the other time is a happy memory of mine because of how [we managed to reach that conclusion](https://users.rust-lang.org/t/pre-implementation-feedback-for-qt-with-rust/7300/52) despite how easily it could have gone pear-shaped.
You have `ipify` module inside your `ipify` crate. So to make your "testing" crate work, you'd need to write: let i = ipify::ipify::get_ip(); The simpler solution would be to just get rid of `ipify.rs` and put all your code just inside `lib.rs`. &gt; I wanted to test that it can be imported and used properly by other crates. You don't need a separate cargo package to do that, the idiomatic way to do integration tests is to put a file in `tests` directory, so for example: `tests/foo.rs`: extern crate ipify; #[test] fn it_works() { let i = ipify::get_ip(); } Also, some feedback on the `ipify` crate itself: Don't use `panic` in *libraries* for situations that definitely can happen, return a `Result` instead and let the caller decide. Also, you should consider returning `std::net::IpAddr` instead of a `String`.
&gt; What is rust's approach to this safety issue? Currently, runtime checks. It's not something we've wholesale rejected as a feature or anything, but there hasn't been a big push towards implementing it yet, and so it needs design work.
Sorry, I thought it was about macros 1.1
That worked, thanks. And thanks for the advice! I'll definitely implement those changes. IpAddr is exactly what I was looking for when I found SocketAddr, too. Weird that I missed it. xD
More generally, you want to look at [refinement types](https://en.wikipedia.org/wiki/Refinement_\(computing\)#Refinement_types). The [LiquidHaskell](http://goto.ucsd.edu/~rjhala/liquid/haskell/blog/about/) project is a good example of this approach in action, but I don’t think anyone's ported it to Rust yet.
Nice! btree did a lot better then I would have thought. Insert is more expensive, which isn't very suprising. When I read the documents it said the btree were more cache friendly which might explain the speed increase. intmaps look up is a multiplication, a bit shift and then a linear search in a vector.
I don't think `Copy` on `State` would help-- the code that /u/adwhit86 showed doesn't even move the `State` instance at all :-/ Can you explain a bit more about why `Enemy` and `Friend` need a reference to each other?
I'm far from an expert on this but being wrong is the best way to get a right answer. From reading about this previously I believe the main thing keeping OTP from being implemented on other platforms is that you need to be able to crash a process remotely without giving that process any chance to recover and not have that break other things about your language. I'm not sure if `panic!` provides the right semantics or not.
Some preliminary benchmark results: https://github.com/gimli-rs/addr2line/pull/21
I'm an Erlang programmer dabbing his toes in Rust. tl;dr: Erlang is great for high level, not too performance critical bits in servers. Rust is great at the low level bits while still being as safe as possible. Rust and Erlang both have the goal of safety, but they come at this problem from entirely different directions. Erlang - unpredictable shit happens, always have a backup plan. You can even work around hardware failures. Rust - strong compiler that prevents unpredictable behavior. Erlang was made for writing servers that must never crash. Rust was made to create low level, fast and safe software. "let it crash" style programming can only be possible by running your code in a VM. Live code updates that are as easy as Erlangs can only be done by a VM. If you're attempting to write a large server style app, Erlang will allow you to get the job done faster and easier than anything else. Nothing comes close. It's hard to convince non-erlang programmers just how amazingly fast and effortless it is to solve your problems in Erlang. But you pay for it in runtime performance. It's not as bad as many other popular languages, but it's still there. It's good enough for the vast majority of server software.
It really was his first PR! Not just his first to Rust. Amazing!
This is not merely a fantastic PR from a new contributor, but a fantastic response from the community to a PR from a new contributor. Everything worked well here. *This* is why people love the Rust community. Keep up the good work everyone!
Great, thanks!
&gt; rust could do this through specialization and a unstable-sort-safe marker trait. I don't think it needs a special trait, Copy will do, right? Knowing there are no other pointers to it + knowing it's safe to do a bitwise copy, should together imply that stable or not doesn't matter.
Sure thing. I'll add this later today. Any suggestions for alt text?
I unfortunately haven't paid as much attention to the details of how Rust has evolved over the last couple of years, but in the beginning Erlang and also the paper [Crash-Only Software](https://www.usenix.org/legacy/events/hotos03/tech/full_papers/candea/candea.pdf) were very strong and explicit influences on Rust's design. Rust programs would have a number of tasks, some of which would be set up with a supervisor task. The supervisor would then be able to observe when one of the tasks it supervises panics and that's where error recovery could happen. Rust message pipes used to (and perhaps still do) give very strong signals about ownership of both ends. For example, if a sender is trying to send a message to a task that has died then the send would fail. Likewise, trying to receive from a pipe where the task that had the sending end had died would also fail. Most often the task would then fail itself, but some task would hopefully be in a position to restart the offending service. I'm even less in touch with the Servo project, but I think they were using some of these ideas to manage clean shutdown of all the various rendering components. Rust's strong notions of memory ownership and avoidance of shared state helps to support this style of programming. If tasks are all isolated from each other, you can pretty safely clean up one task and start a new one without worrying about the impact on others. At least, you don't have to worry about violating type safety or other data structure invariants. This is also why Rust doesn't really have try/catch style exceptions. The boundary of handling failures was always meant to be the task boundary. If you were about to do something that could fail in unexpected ways and you wanted to be able to recover from it, you'd spawn a new task. In a lot of ways, this simplified reasoning about your programs, because you didn't have to worry about recovering from exceptions at a point where some of your program invariants were invalid.
The problem is &amp;T is Copy regardless of what T is. 
The only restriction that the "functional" style places on FizzBuzz is that you have a function `fizzbuzz :: Num -&gt; String` instead of doing it in the `main` function. That way your computation is pure. That's not a very strong restriction in this case.
That's exactly the language I fantasize about designing. I should just buckle down and work on it some day.
Isn't that http://www.ponylang.org/ 
So will this then help Rust in its path towards dominance in terms of speed vs C++?
My issue is that other than bolting Rust's type system (enums, generics, traits), I can't really think how to progress in that direction.
Completely tangential, just because everyone is already thinking about sorting: does anyone know why discriminator based sorting isn't more popular? As I understand it, it could be asymptotically faster, as well as faster in practice on real inputs. But only functional people seem to ever have heard of it, and even then most people don't care...
I think people in general don't know about modern SAT solvers, thus still thinking that NP complete means all hope is lost. In fact, it means that you probably have a perfectly simple problem, just need a bit of a sophisticated solver. But we have those! They work really well! There's almost no chance that you will generate a "hard" instance and it will actually be solved very quickly.
EDIT: I now understand the problem :)
The RFC hasn't been implemented yet, so it would be hard to find a working example 😉
Hvala! And thanks to everyone for being so welcoming! :)
&gt; Currently, runtime checks. If the value's origin is user input, them there must always be runtime checks, isn't it?
No, unless we add `unstable_sort`. Rust's `sort` is stable by default for some reason, while C++ has fast unstable `std::sort` by default and slower `stable_sort` on demand.
`Foo(i32, i32)` can be Copy, but have comparisons only use the first field, you can then tell the difference.
Fair point.
Can you post your cargo.toml files? 
Of course http://hastebin.com/egacoqegon.toml there you go!
Your code is working! But the KEYBOARD_LL hook doesn't work unless you run a message loop. Try this code for your test harness: [Playgound](https://play.rust-lang.org/?gist=4856470ac7e4f7aea4e99e3304489322&amp;version=stable&amp;backtrace=0)
This is the correct answer.
A redis client and driver (learning purposes)
Just my first crate that solves a problem: [lapp](https://crates.io/crates/lapp), It is (yet) another GNU-style command-line parser which is a Rust implementation of the [Lua Lapp](http://stevedonovan.github.io/Penlight/api/manual/08-additional.md.html#Command_line_Programs_with_Lapp) framework. Like docopt, it parses flags based on the usage text, but is easier to use for programs which do not have subcommands. Has an installable program lapp-gen for testing usage-based specifications and generating suitable structs for inclusion.
&gt; is stable by default for some reason Because defaults should be nice and do the safest, most secure and obvious thing even if it is very slightly slower. Otherwise you get bugs. For example I've seen Markdown renderers that have `render_markdown()` and `render_markdown_secure()` instead of `render_markdown()` and `render_markdown_insecure()`. I presume at some point `sort_unstable()` could be added for those people that need every ounce of performance.
This is very nice. &gt; The question whether the default sort should be stable or unstable was pretty controversial, Having the default sort stable is acceptable in Rust, for the same principle of least astonishment used in Python design. I'd probably like a unstable_sort, unstable_sort_by and unstable_sort_by_key in the standard library if they give some performance advantages, but seeing the performance of the new stable sort, there's no urgency. 
LPARAM is a pointer to the KBDLLHOOKSTRUCT struct - you'll need to use unsafe code to cast it to the correct pointer type and then dereference it to get at the fields.
This [RFC](https://github.com/ticki/rfcs/blob/pi-types/text/0000-pi-types.md) proposes similar concepts in addition to type level numerics, but unfortunately it's somewhat stalled.
Just checking what I can expect here. Do these links explain why discrimination-based sorting isn't popular?
About that, we _should_ have an `unstable_sort` as well, shouldn't we?
For simple games, there is rarely any reason to store cross-references in entities. When updating the player, you just pass in the enemies, when you update the enemies, you just pass in the player. In more complex games it's more common having to remember some kind of reference to other objects. One example would be to have one unit remember which other unit it is currently targeting. In situations like these, I prefer to save some kind of ID rather than a pointer (even in C++) and then later look up the unit again by ID. In C++ this prevents you from the use after free bugs you otherwise run into sooner or later, in Rust it keeps you from fighting a losing battle against the borrow checker. ;) Wrapping the units in a Rc&lt;&gt; and using weak references for cross-references is basically equivalent. The lookup is probably slightly faster at the cost of very slightly more memory.
Oh, yes, that was a typo (corrected). But still, the point is still the same: Erlang does have shared storage and hides it through the runtime.
Hm, maybe the fact that all data in erlang is immutable (requires a copy to modify) is what makes killing processes from outside safe? Unless I'm wrong about that too. 
The point of Erlang is to crash your actor. But always have a contingency scenario what happens when that actor crashed. Often its nothing and the rest of the app goes forward unchanged.
&gt; It took me a while to notice that early return `try!(name_port(&amp;buf))` as it kept tripping me up! Oh dear, so the error return of that `try!()` borked type inference for the return type of the whole closure, right? I never noticed. I *did* later see the need for error type conversion, but of course it couldn't counteract that `try!()`... Thanks! Btw, for me the test works if I invoke `curl` with: ``` curl --socks5-hostname localhost:8080 https://www.google.com ``` The setting of `https_proxy` like the README advises generated an error.
Do you mean "threads"? Rust, at least the core language + std, doesn't really have a notion of "tasks" anymore. 
The problem isn't specifically moving the reference in memory, that's okay in almost all situations (e.g. it's fine to push a reference onto a `Vec&lt;&amp;T&gt;`). A reference has information that is not used for the comparisons (the address it stores), which one can use to observe a sort's instability, e.g. sort an array of references (which uses the comparison of the data they point to) and then coerce each one to a `usize`.
Sounds like you want Rust's alternate timeline branching off from version 0.6 or so...
Working on writing my next article for [Schemers](https://github.com/mgattozzi/schemers). It's the beginnings of a parser using nom to do it. The code for part 1 is done, now it's just to write the tutorial.
So it's for January?
It's not about them needinig a reference to eachother in this example, it's that at some point you're going to need some state to reference some other state. Say you have a homing missile struct that needs to know where its target is to define how it moves - that missile will have a reference to the target, unless you want to go the awkward route of storing everything in a list and storing and index instead? 
I notice there's a section that reads &gt; In Rust, a char can’t take an integer value. But this isn't true. You can, for example, convert a char into a `u8` and convert a `u8` into a `char`. Writing something like `let character = 97 as char;` would set `character` to `a`. Writing `let number = 'a' as u8` would set `number` to `97`.
Your problem is that it expected an enum but it found a closure.
Absolutely, yes.
Agreed, I just wanted to verify. OP seems to be interested in how they can write OTP style apps in Rust today and I wanted to call out that this information does not necessarily apply to Rust as of 1.0
I think I understand *what* you're saying, but am less clear on *why* you're saying it. So, if I make a list of objects with unsorted values in monotonic memory placement, and then make a list of references to each of them, the references will not only be already in monotonic sort (when looking at their referent address), but will themselves be stored in monotonic memory order. Then, if I sort the list of references, the sort algorithm will transparently deref to sort by referent-value, not by address-value, yes? And then, if the original objects were non-unique in values stored (i.e. multiple objects stored the same value), the (in)stability of the sort would be apparent by observing that when taking a cluster of references all referring to objects of equal value, the references themselves would not necessarily be in sorted order by stored-memory-address? Next question, why would that matter? Maybe I'm not thinking about this the right way, but I don't see why order matters in a cluster of items that are supposedly equal. Maybe it would reduce cache pressure? That's all I can think of offhand...
Ha! I was specifically referring to "mutable state" as "being able to modify the bits in a piece of memory", which I probably should have called "mutable memory" or something. In that context it seems like Rust's definition of safety is still preserved by the Erlang vm even in the face of kill? It's unclear to me if the first Erlang example there: ``` X = 1. f(X). X = 2. ``` treats `X` as a memory location that is overwritten or if it treats it like a name binding to a boxed value. The former would I think make Erlang kill unsafe (using the Rust definition). I agree that external kill is always "unsane", whether or not it can result type system holes. I mean, external kill allows you to kill a thread in between two network requests, which means that you can put your larger system into any sort of undefined state you would care to.
your 'code' display sections are really small text?
Ah thanks! That was what I was looking for. Well, I'm not too sad, as this made me refactor the code to use `Option&lt;T&gt;`. Edit: I changed the blog post to include your fix.
If you read a title with "RFC merged!" on /r/rust don't get excited. There's a long way to go before you can be potentially using it.
Sweet. I really need to make a full resolver...
How well does this work on windows? How does one set it up to work on windows?
Typography is hard :P Does it look any better now?
Rust's current design was highly guided by the needs of Servo. Though there was a language called "Rust" before then, Rust as it exists now is designed for writing low-level software that's fast and reliable. Servo actually does do some process isolation; it creates a couple of separate operating system processes for each frame (tabs are frames, as are iframes). One of them hosts the DOM and runs JavaScript, one of them does layout, one of them does rendering. If part of the frame goes down, the whole frame is torn down and the user observes an "i tried." Any state that existed in the DOM is gone. Erlang is better at surviving a crash because any long-lived state is stored in a separate database. Storing the DOM in a separate database would introduce noticeable overhead. Besides the IPC overhead, databases perform large amounts of data validation at runtime. Actually, Erlang programs in general do large amounts of data validation to be able to crash early and often. If an Erlang program wants to prevent something from happening, it marks it with a flag at runtime. Rust uses a conservative approximation at compile-time, to avoid that overhead. Full disclosure: I'm in the middle of rewriting a server program from Rust to Elixir, because this impedence mismatch is getting too much to deal with. Yes, I know about Tokio; I still don't want to write a non-performance-critical, yes-reliability-critical program in a low-level language like Rust.
It *should* work just the same, `bindgen` and `libbindgen` support Windows and MSVC mangled symbols. That said, I haven't worked with `bindgen` on Windows yet (but will pretty soon in the future for SpiderMonkey).
Only if shown to be faster ;)
&gt; Rust's current design was highly guided by the needs of Servo. Actually, no, not in this case. Rust used to have userspace tasks much like Erlang, and more of a runtime. Servo did not want this to go. The Servo team opposed the removal of green threads, but it happened anyway (and we learned to adapt to the change). Rather, Servo did help make Rust's overall goals at a high level to be as zero-cost as possible. While removing green threads did not help Servo, it did help this higher level goal which had crystallized out as an independent goal of Rust by the time. 
Why does the missile have to have a reference to the target, rather than owning the target? Also, the list/index approach is a totally valid way of going about it-- see the [petgraph crate](https://crates.io/crates/petgraph).
Thanks! Fixed.
The line `(or in $LD_LIBRARY_PATH on Linux, or in $DYLD_LIBRARY_PATH on MacOS).` made me think this is a non-windows thing. Glad I was wrong. :-) So do I just install `libclang` from http://llvm.org/releases/download.html and it *should* just work?
I haven't heard of CrateDB before, but I'll have to check it out now! For the code review request... no time at the moment for anything super detailed, but reading your example program made one thing jump out at me. Your code for creating a cluster looks like this: // default URL for a local CrateDB instance let nodes = "http://localhost:4200/".to_owned(); // create a cluster let mut c: Cluster = Cluster::from_string(nodes).unwrap(); The ergonomics here could be improved by changing the signature of `Cluster::from_string` to something like fn from_string&lt;S&gt;(address: S) -&gt; Result&lt;Cluster&gt; where S: Into&lt;String&gt; which enables you to skip the `to_owned()` call on the `let nodes` line.
Is it possible to do this in the other direction? I.e., generate C/C++ bindings for a rust library? It seems to me that it would be more beneficial for rust adoption if existing C/C++ projects could painlessly introduce rust dependencies than the other way around.
In the past I've used message passing for this, but another good method is giving everything a unique key and referencing using that. You _might_ get issues if you have a huge number of entities, but for a pong clone you'll have no issues. For going between screens you'll probably want to implement a stack of trait objects with `push`, `pop` and `swap` (pop the current one and push the new one) actions. This is probably best done as a return type of the screen's update method (you can return an `Option&lt;StackAction&gt;`). Rust is actually pretty awesome for game programming, you're kinda forced to do things in the right way, but it makes the right way so easy that you'd never want to do anything else. I'm currently building a simple 3D game with a modified version of Amethyst, and the stack model is what it uses. Previously I passed ownership of the last screen to the current screen and let each screen take responsibility for restoring the last one when it is done, but the stack model is much simpler and more ergonomic. Obviously this is super overkill for a game this simple, but I imagine you're doing this to learn.
https://github.com/rust-lang/cargo/pull/3296/files#diff-07fb9df5b456f9e1ff8719d73a4bc2d0R22 and the three lines that follow. Yes, it's worth making the distinction that while this is a _logical_ move upstream, it's not a literal one: the implementation is very different, specifically to address the shortcomings of the simpler, earlier implementation.
This is my current project, but I'm super slow (and I don't know what I'm doing). I want Erlang, with more familiar syntax for server devs and with strong type safety like rust. That's really my dream language, so I just started to build it.
Thats what monitor's are for
here gose nothing. ``` &gt;git clone git@github.com:fitzgen/libbindgen-tutorial-bzip2-sys.git ... &gt;cd libbindgen-tutorial-bzip2-sys ... &gt;rustup override set nighitly ... &gt;cargo test ... error: failed to run custom build command for `clang-sys v0.11.1` --- stderr thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: "couldn\'t find any of \'libclang.dll\', \'clang.dll\', set the LIBCLANG_PATH environment variable to a path where one of these files can be found"', ../src/libcore\result.rs:837 note: Run with `RUST_BACKTRACE=1` for a backtrace. ``` Not surprising, I need to install clang. Downloading from that link. New shell. ``` &gt;cargo test ... Compiling libbindgen-tutorial-bzip2-sys v0.1.0 error: failed to run custom build command for `libbindgen-tutorial-bzip2-sys v0.1.0` process didn't exit successfully: `C:\Users\...\libbindgen-tutorial-bzip2-sys-1f65f5148c3e7f46\build-script-build` (exit code: 101) --- stdout cargo:rustc-link-lib=bz2 wrapper.h:1:10: fatal error: 'bzlib.h' file not found, err: true --- stderr wrapper.h:1:10: fatal error: 'bzlib.h' file not found thread 'main' panicked at 'Unable to generate bindings: ()', ../src/libcore\result.rs:837 note: Run with `RUST_BACKTRACE=1` for a backtrace. ``` Not surprising, I need to get bzlib. download from http://www.bzip.org/downloads.html New shell. Same thing. Where do I need to put it so libbindgen can find it? I can add it to my path but that seems heavy. 
I think frequentlywrong's point was to note how Erlang works so it is more clear how Rust's model differs from that, which is what the parent is asking about. I think the idea is that Erlang does in fact recover from what in Rust would be `panic!` because its threads are fully independent of each other.
&gt; don't get excited Don't tell me when to get excited :) You're right though. Merging the RFC just means that they've agreed on an initial design. There's still the implementation and potentially more RFCs as issues pop up. However, having the RFC merged means that someone can start working on stabilizing it, so there's a pretty good chance it'll land sometime in 2017. I'm sure you know this, I'm just posting for posterity.
This is lovely, neomake `cargo` checker really needs faster response times, i can't wait to add support for this feature.
Yo Steve, long time fan of your work here. Are there any (official) docs on what macros 1.1 are and how they work? Thanks. And keep doing what you're doing.
I haven't seen a direct benchmark between the two.
Did it stop supporting them suddenly? I used to use `cargo-check` with `--lib` and `--bin NAME` all the time.
Thanks for the shout-out! I really have to do a second pass at removing more of the slow-to-build dependencies. If anyone wants to get stuck into it before me, I reckon the next logical step is [replacing some of the `syntex` stack with `quote`](https://github.com/servo/rust-bindgen/pull/270). Worth double-checking with the maintainers first to make sure it's still a desirable and viable simplification!
Certainly. I wasn't arguing that. (Personally, I find it immensely fun to discover this type of thing, so I'd have left it in.)
As it happens, I did most of the lib/bin split work on Windows, testing against `brotli2-rs` and a few others. Works great with the GNU or MSVC targets. I had to install LLVM/clang and set: ``` $Env:LIBCLANG_PATH = "C:\Program Files\LLVM\bin" ```
Is that `?` part of stable rust? I thought there was still a lot of work being done there.
Those timings look extremely suspicious. Are you looking up a single value repeatedly?
Yeah it made me smile, actually :)
"cargo check" will test if a crate can be compiled without actually compiling it. This is faster than going through with compiling.
Yes. More specifically, it runs the entire compiler up until the point at which it's time to generate the executable, and then doesn't do that. This is much faster than doing all that extra work. So the idea is that your normal workflow is "make changes, call cargo check, make changes, call cargo check. time to try it out, cargo build".
Uh, with nix packaging! That's always nice to see!
Next up: `cargo clippy` 😉
Nice, loved the demo too!
`unwrap` takes its argument by value (`el: &amp;Result&lt;String&gt;`, and since `unwrap` takes `Result&lt;String&gt;`, you'd have to move out of an `&amp;` reference), you can get a reference to the inner value by using `as_ref`, like `group_by(|el| el.as_ref().unwrap())`. `as_ref` can convert `&amp;Result&lt;T&gt;` to `Result&lt;&amp;T&gt;`. The reason that this _must_ only take a reference is because value passed to `group_by`'s argument has to be used again (in the loop).
You shouldn't have to specify the env var. clang-sys, which libbindgen depends on, should be able to find clang installed in the location you mentioned here.
I like to think of Rust's approach as "define your nouns and verbs separately, then indicate valid interactions" as opposed to OOP's muddied "every noun *contains* a set of verbs". It really helps to focus attention on why classical OOP falls short. ...and, at the same time, helps to draw attention to how inheriting default implementations **with** access to default members to implement "is a" is actually orthogonal to the problems a trait-based or ECS-based approach fixes: 1. Nouns and verbs **are** both top-level objects which, on an abstract level, can't be represented properly in a singly-rooted tree (as opposed to a directed acyclic graph). 2. That said, valid "is a" relationships between nouns do exist and requiring people to write tons of boilerplate, just to forward non-pure function calls to parents, is a design bodge. (Though possibly necessary to force stubborn OOP-habituated developers to reconsider their design patterns.)
How does it behave on a crate with both a lib and a bin? In cargo check (the subcommand) you had to choose one or the other with `--lib` or `--bin`, which made it a pain to use with editors on save. That was my single biggest complaint about it. I would be super thrilled to hear this is now a solved problem! :)
Where does this fit in with the language service (RLS)? Is it a stopgap measure before RLS is ready or is it deemed performant enough to make RLS unnecessary?
Yeah, it *is* really arcane in English, but it is *technically* correct -- which is the best kind of correct :). I'm a language lover, so I just love when we see this type of language cross-pollination in... praxis. The Scandiwegians also have "praksis" as a word, are generally *amazing* at speaking English, but every time they use "praksis"[1] when speaking to native English-speakers it just results in puzzled looks (at least in my experience). Language is weird + fun! [1] Accidentally, because it's the natural word to use in their mother tongue.
I still have yet to receive a satisfactory (not "reinvent all this boilerplate") answer as to how to use Serde to read and write JSON with multiple revisions of the schema which follows the best practice of including some kind of`schema_version` field at the top level so the application isn't torn between guessing and locking in old mistakes.
When using the `no_unstable_rust` you get an opaque array of the size of the union (and hopefully with the right alignment as well). When allowing unstable rust, you get an unsafe Rust union: union.h: union MyUnionType { int foo; char baz; char quux[128]; }; Generated bindings with `--no-unstable-rust`: /* automatically generated by rust-bindgen */ #[repr(C)] pub struct __BindgenUnionField&lt;T&gt;(::std::marker::PhantomData&lt;T&gt;); impl &lt;T&gt; __BindgenUnionField&lt;T&gt; { #[inline] pub fn new() -&gt; Self { __BindgenUnionField(::std::marker::PhantomData) } #[inline] pub unsafe fn as_ref(&amp;self) -&gt; &amp;T { ::std::mem::transmute(self) } #[inline] pub unsafe fn as_mut(&amp;mut self) -&gt; &amp;mut T { ::std::mem::transmute(self) } } impl &lt;T&gt; ::std::default::Default for __BindgenUnionField&lt;T&gt; { #[inline] fn default() -&gt; Self { Self::new() } } impl &lt;T&gt; ::std::clone::Clone for __BindgenUnionField&lt;T&gt; { #[inline] fn clone(&amp;self) -&gt; Self { Self::new() } } impl &lt;T&gt; ::std::marker::Copy for __BindgenUnionField&lt;T&gt; { } impl &lt;T&gt; ::std::fmt::Debug for __BindgenUnionField&lt;T&gt; { fn fmt(&amp;self, fmt: &amp;mut ::std::fmt::Formatter) -&gt; ::std::fmt::Result { fmt.write_str("__BindgenUnionField") } } #[repr(C)] #[derive(Debug, Copy)] pub struct MyUnionType { pub foo: __BindgenUnionField&lt;::std::os::raw::c_int&gt;, pub baz: __BindgenUnionField&lt;::std::os::raw::c_char&gt;, pub quux: __BindgenUnionField&lt;[::std::os::raw::c_char; 128usize]&gt;, pub bindgen_union_field: [u32; 32usize], } #[test] fn bindgen_test_layout_MyUnionType() { assert_eq!(::std::mem::size_of::&lt;MyUnionType&gt;() , 128usize); assert_eq!(::std::mem::align_of::&lt;MyUnionType&gt;() , 4usize); } impl Clone for MyUnionType { fn clone(&amp;self) -&gt; Self { *self } } And here is when allowing bindgen to generate unstable Rust: /* automatically generated by rust-bindgen */ #[repr(C)] pub union MyUnionType { pub foo: ::std::os::raw::c_int, pub baz: ::std::os::raw::c_char, pub quux: [::std::os::raw::c_char; 128usize], } #[test] fn bindgen_test_layout_MyUnionType() { assert_eq!(::std::mem::size_of::&lt;MyUnionType&gt;() , 128usize); assert_eq!(::std::mem::align_of::&lt;MyUnionType&gt;() , 4usize); } 
&gt; Erlang - unpredictable shit happens, always have a backup plan. You can even work around hardware failures. Does Erlang have any features, libraries, or best practices that help with having recovery failure that you can trust? With only my surface level knowledge of Erlang, I'd assume that developers on high availability projects would have thought out failure recovery that has been validated but "normal development" would skip on writing failure recovery or if they wrote it, they wouldn't test it which I assume is just as bad as not writing it.
In addition to what /u/upsuper said, the `servo/rust-bindgen` README has more details (for example, if you wanted to build from source instead). As for setting environment variables, you can open a new shell and do $ export LD_LIBRARY_PATH=/path/to/directory/containing/libclang
Some of those `black_box`s don't work, and you probably want to black-box the inputs, too. All in all, `get_btree_set` should look more like b.iter(|| { for s in test::black_box(&amp;data) { test::black_box(map.contains(s)); } }); When you do test::black_box({ map.contains(s); // note trailing semicolon }); you're only black-boxing the resulting `()`, which can only have one value anyway! You want to black-box the actual result from the operation, so drop the semicolon. I might even be tempted to `black_box(&amp;mut map)` after each iteration, since that ensures side-effects are preserved. --- FWIW, `with_capacity` can be counterproductive for hash tables. It means both that you do more random accesses in larger tables when inserting, and have pessimistically bad load factors when retrieving.
Turns out the benchmark for btree (and in fact most, if not all of these), is broken. See sibling thread.
I got bored, so I've just pushed a new version that adds Iterator support to the Roller objects. Now you can do a lot more with this. https://docs.rs/rouler/0.1.3/rouler/struct.Roller.html#method.iter
Interesting. I didn't know there were any pure Rust SAT solvers. Shame it doesn't show up when searching crates.io.
Nice!
That isn't the only reason, sometimes you need the sort to be in-place, and an unstable sort is easier to make performant for that case.
It means exactly what it says. You're only allowed to have named lifetimes in an `impl Trait` return type, but you have an unnamed lifetime. So give it a name: fn keys&lt;'a&gt;(map: &amp;'a HashMap&lt;usize, usize&gt;) -&gt; impl Iterator&lt;Item=usize&gt; + 'a { map.keys().map(|x| *x) }
the description about Erlang is very instructive, but I think those features should be applied to applications or framework, rather than language features. wish the tokio-based ecosystem should be able to implement those features, such as message, state preservation, async, actor,crash surviving,etc. a performance-critical and yes-reliability-critical framework should be very cool.
What I meant was merge all the lints together and make clippy part of the build process.
I wonder whether it would be worth updating some of these errors to make it explicit that there's an implicit lifetime parameter in the `impl Trait` already, and that you need to explicitly give it a name. 
To be clear, making clippy part of the Rust build process is kinda part of the plan. But the lints stay separate.
Ha, always nice to see really simple repositories like this too and people proud about them. :)
I took a quick look, and it seems like a generalization of the idea behind radix sort, which is not as obscure but still pretty underappreciated itself. At minimum, it would definitely be nice if Rust could automatically use radix sort rather than comparison-based sorting on supported types, using trait specialization.
This will definitely have to get a better message, but only if it is stabilized in its current form.
`src/lib.rs` only makes sense if you want your project to be usable as a library. If all you want is an executable, you should get rid of the file. The single entry point to your application will then be `src/main.rs`. Source: http://doc.crates.io/guide.html#creating-a-new-project
Not require it, no. This only impacts cargo check, a new feature, so it's okay to change this. RfC would be helpful, but IMO this behavior was already soft-required, just not specified.
It's okay to change this, but the exact requirements should be documented somewhere, with a stability promise.
indeed, though maybe even better would be a general size increase and a more obvious 'this is a code block' distinction? thanks for the fix :D it's a great post
Nice work. Liked the Rust logo landing pad.
This is one of the big outstanding issues with impl Trait - both what should be captured by default and what the syntax is for explicitly capturing. This is a bit more complicated than other features because type variables can also be captured (in case they're references, for example). More discussion here: https://internals.rust-lang.org/t/lang-team-minutes-stabilization-and-future-of-impl-trait/4171
How does it work if you had already installed the external command and you update cargo ? Will it uninstall/overwrite the existing one ? or shoud you uninstall it first ?
Vulkan natively supports MSAA by creating and rendering to images with more than one sample per pixel (the ` samples` parameter or field of various functions and structs), however the support by vulkano is limited. Techniques like SSAA, FXAA, TXAA, etc. are too high level for vulkano. After all it's not a 3D engine but just a wrapper that allows you to execute commands on the GPU. 
&gt; Is there any overhead associated with that as compared to any other language that returns a direct reference to the value? Option is ofcourse very safe, but just wanted to know if its at the cost of performance? Yes and no. `enum` types in general will add a discriminant value (so the size of an enum value is the size of the associated data + the size of the discriminant), and for trivial matches it'll dispatch on just that value (much like a C `switch`). *However* specifically for the case of enums which have one member with associated data and one with no associated data (which just happens to be the case for `Option`), Rust has a "null variant optimisation": if the associated data is [NonZero](https://doc.rust-lang.org/core/nonzero/struct.NonZero.html), the discriminant will be folded into a zero-valued associated data and there will be no time or space overhead. The actual pointer in a Box or reference is wrapped in NonZero, so `Option&lt;&amp;T&gt;` is compiled to a nullable pointer, and e.g. `size_of::&lt;&amp;u8&gt;() == size_of::&lt;Option&lt;&amp;u8&gt;&gt;()`. There are ideas for extending NVO to e.g. nested enums (allowing folding the various discriminants) but for now that's the only one.
Take the [triangle example](https://github.com/tomaka/vulkano/blob/master/examples/src/bin/triangle.rs): What would I change to add basic AA?
Also in your code you call TranslateMessage() and DispatchMessageW(), what do these do? 
i saw this recently on /r/programming with c/c++ context ... didn't know it exist for Rust too – awesome! :)
See also pencil which I am fond of after having used flask for a while 
Author here. I wanted to wait until version 1.0 is published and write an article explaining the design choices before posting it on reddit. The design of rouille is very different (and IMO much better in all situations) from the design of other frameworks in Rust and in other languages. I sometimes complain here and on IRC about the fact that middlewares are unidiomatic in Rust, so here is my alternative. 
Can someone explain to me why: imul edi, edi seto al test al, 1 jne .LBB0_2 as opposed to: imul edi, edi jo .LBB0_2 I don't see why the above would be superior to the below one...
Note that with optimisation enabled (`-O`), unused functions automatically get compiled out. Make them `pub extern fn` and it'll stop that. You can also add `#[no_mangle]` to them if you want them to keep their names.
My second version does the exact same overflow check as the first version, only in less instructions, less bytes, and without setting al to 1 as a side-effect. (and if al = 1 is desirable, it would be better to do that after the branch, where it would only be executed if desired).
Amusingly, it actually was called "roller" in development, hence the last minute name change. I'm not sure how easy it is to change these things after it's already been published though?
Looking over it again, I think I can figure out what the program does, but I still don't think it's so clear. I'm relying on the output sample which implicitly gives information that should also be explained explicitly. My suggestions: I suggest adding a sentence at the start that elaborates on "counts code" with something like "Tokei measures how much code you have in a directory in different programming languages in terms of file count, line count, ...". At some point, either at the start or in the "How to Use" section, you should explicitly explain what each of the columns mean.
This is neither here nor there, but I always find it strange when people refer to the x86 (or x86_64) assembly language as Assembly. Or any other particular assembly language, for that matter. It just gives off the weird impression that it's supposed to be the one true assembly language.
The issue I have with the above code is not that the check exists, it's that the check is implemented in an unnecessarily expensive way. Is it possible to turn on both the optimization and the check, to see if the LLVM can optimize to to a saner version?
For Rust with Atom, I am using the following packages: * [language-rust](https://atom.io/packages/language-rust) * [linter](https://atom.io/packages/linter) and [linter-rust](https://atom.io/packages/linter-rust) for on-save display of error and warnings * [racer](https://atom.io/packages/racer) for auto-completion * [build](https://atom.io/packages/build) and [build-cargo](https://atom.io/packages/build-cargo) to launch builds/tests with a keybinding. It provides a quite pleasant experience (for very small projects for now at least). 
what does it do if it finds it? panic?
That may not work. You need to specify `LIBCLANG_PATH` before build, and that's all. Cargo should insert the correct path to the library search path if the program is executed via `cargo run`.
If you have the time, you should update your post with a link to this excellent explanation of the weird borrow checker error so that non-reddit user's can understand the rationale behind it.
&gt; Is it possible to turn on both the optimization and the check, to see if the LLVM can optimize to to a saner version? The LLVM isn't the best optimizing compiler I hate to tell ya. This seems like low hanging fruit a patch to their mainline could fix. Side note: In *newer* (read Haswell and after) chips register to register movs are normally translated to 0cycles NOPs/re-names and treated as meta-data hinting for OoO. Skylake has something like 380 registers we can't address because it uses them for re-naming, and speculative execution. Moving the overflow flag, then testing against the post move register I'm fairly certain is something it'll catch. In *older* (read pre-Haswell) you can have read stalls, and cross port read stalls with reg to reg movs. I *kind of* wish Intel would tell us what is happening behind the scenes, but last time they tried we got Itanium... Right around learning about existential register flags I gave up understanding that.
It's actually quite easy for me to transfer ownership of the name roller to you. It won't let you change rouler to roller, but it'll let you publish roller 1.0 with whatever source code you want.
Have you tried using `BufReader` and `BufWriter` ?
Pencil is also pretty great, though it seems the maintainer is a bit checked out.
Can this be called as a library?
&gt; The LLVM isn't the best optimizing compiler I hate to tell ya. &gt; &gt; This seems like low hanging fruit a patch to their mainline could fix. Optimisations are off, so there's no bug here. As others have demonstrated, it handles this code fine when they're on.
For those unfamiliar with what [SAT](https://en.wikipedia.org/wiki/Boolean_satisfiability_problem) is, it's basically finding a solution where the outcome is true based off values given to inputs and the boolean problem is in Conjunctive Normal Form. It's known as the first NP-complete problem. This bit of code solves it based off the inputs!
It was more of a statement in general. In a few platform specific SIMD things the LLVM can fall very hard on it's face. A small loop I wrote to compare IPv6 addresses against a black list the LLVM produces 2.5x instructions of the GCC, and runs 4x slower. Granted the GCC can fall flat on it's face too in some scenarios. I just haven't witnessed this yet :\
Erlang's biggest benefit in having actors baked into the language itself is that the *runtime* can use it. Erlang processes get their own local heaps, each of them gets GC-ed independently, and other resources (ports, for example) are scoped to a process that owns them. Short-lived processes don't get traced at all, and act like arenas. There's no need for Rust-style unwinding, as a language feature, because Erlang has a fixed set of primitive resources that get cleaned up when a process dies. You could actually build OTP-style actors using Linux containers. Docker isn't it, because it doesn't have a supervision tree, but you could probably build that on top. It's been interesting watching containers evolve into a language-agnostic, OS-provided version of OTP. BTW, I do realize that a container is far more heavy-weight than a green thread, and thus more coarse-grained.
I've solved this in the past by making members that refer to the parent as Option, and unpacking/putting them back when done. For example, the following works: trait AI { fn update&lt;T: AI&gt;(&amp;mut self, monster: &amp;mut Monster&lt;T&gt;); } struct CoolAI { var1: i32 } impl AI for CoolAI { fn update&lt;T: AI&gt;(&amp;mut self, monster: &amp;mut Monster&lt;T&gt;) { monster.x += 1; } } struct Monster&lt;T: AI&gt; { x: i32, y: i32, ai: Option&lt;Box&lt;T&gt;&gt; } impl&lt;T: AI&gt; Monster&lt;T&gt; { fn update(&amp;mut self) { let mut ai = self.ai.take(); match ai { Some(ref mut ai) =&gt; { ai.update(self); }, None =&gt; () }; self.ai = ai; } } fn main() { let mut monster1 = Monster{ x: 0, y: 0, ai: Some(Box::new( CoolAI{ var1: 42 })) }; monster1.update(); } I'm not entirely sure that this is the right way to solve it, but it compiles and runs correctly.
An alternative, less janky way of doing it would be to stick the monster's state into a different struct: trait AI { fn update(&amp;mut self, monster: &amp;mut MonsterState); } struct CoolAI { var1: i32 } impl AI for CoolAI { fn update(&amp;mut self, monster: &amp;mut MonsterState) { monster.x += 1; } } struct MonsterState { x: i32, y: i32, } struct Monster&lt;T: AI&gt; { state: MonsterState, ai: Box&lt;T&gt; } impl&lt;T: AI&gt; Monster&lt;T&gt; { fn update(&amp;mut self) { self.ai.update(&amp;mut self.state); } } fn main() { let mut monster1 = Monster{ state: MonsterState{ x: 0, y: 0}, ai: Box::new( CoolAI{ var1: 42 }) }; monster1.update(); }
You could separate monster data to provide a mutable reference to the AI. https://play.rust-lang.org/?gist=7892caca0168a41234c25d395cad04e6&amp;version=stable&amp;backtrace=0 This way you don't break ownership: Monster owns MonsterData and AI, and can mutably borrow it's own data to AI.
&gt; For those who don’t know, Rust essentially has two instances of its language. One instance (or channel) is known as Stable, which contains stable features and functionality. The other is known as Nightly, which contains the edge features and functionality Nit, but (/me pushes up glasses) *technically* there are three release channels: stable, beta,and nightly.
would be cool if it could emit webassembly
Thanks for this solution, using box did feel sort of hackey.
No need for lifetimes, just remove Box: https://play.rust-lang.org/?gist=c02f082c455f077d089c928ac3d8bc5e&amp;version=stable&amp;backtrace=0
For someone that is new to system's programming (I have been using higher level languages for 15+ years), what is the best way to learn assembly? I am mainly interested in understanding Rust optimizations.
I would also eliminate your usage of `regex` and return string slices instead of owned strings. It's very trivial to do so.
I just learned the 16 bit Intel instruction set first, it's pretty minimal. Maybe start there and write some programs in it.
The assembly should appear on the right-hand side as you type.
Exciting! I can't wait.
Good point! Thanks :) This boosted throughput from 3.4MiB/s to 3.8.
Thanks, I had to click the "add a compiler button"
I'm actively working on one called Canteen (it's on crates.io, [code lives here](https://gitlab.com/jeffdn/rust-canteen)) that is also intended to be Flask-like. It's not as far along as some others, but it's pretty fast and damn fun to hack on! I started before I knew about Pencil, and am open to anyone who wants to pitch in. Progress isn't super fast since I'm both busy at work and constantly improving my Rust skills, which leads to frequent refactoring.
Hmm, I'm not entirely sure, but I'd love to find out! It should work exactly the same way as `cargo build` does.
I will check it out!
I can jot a tentative answer to that, as my first Rust project was a library for generic top-down discrimination. (Alas, I never felt it was ready for distribution, so you will not find it on crates.io, although the name now appears to be taken. With luck, this means that interest in the technique is growing.) While this comment only covers discriminator-based sorting, I should like to mention that discrimination is rather more apt to partitioning, and it is thus unsurprising that people are yet to jilt the cherished adaptive sorts offered by most standard libraries. Moreover, the benefits of distributive sorting are most pronounced with large and inclement datasets, which are often better served by specialized data structures as opposed to generic programming techniques. The one-sentence version is that discrimination is a generic technique that can be used to implement sorting, but sorting by discrimination will be slower than radix sorting, and competitive with or slightly faster than a well-implemented comparison-based sort; in either case, it will also be less memory-efficient. The expressive power of discriminators, which are generic over orders (i.e. they can sort according to user-defined orders), is seldom needed in practice. Now, before moving on to a meandering explanation of some of the problems that arise when sorting by discrimination, allow me to give a brief, partial and unabashedly imprecise overview of the fundamental insight behind discrimination as described in the [latest paper](https://www.cs.ox.ac.uk/projects/utgp/school/henglein2012c.pdf) by Fritz Henglein. Given two types: - *a*, which we know how to sort by comparison, one pair at a time, - *b*, which we know how to sort distributely, one set at a time, if we can map an order over *b* to an order over *a*, then we have learned how to sort *a* distributively, and can thus enjoy better asymptotic performance. (More dramatically, such ordering relations are the ladders that allow us to climb over the dreaded omega barrier.) This may appear exotic at first, but the idea that we can find a correspondence between orders is intuitive and widely applied: consider how, since time memorial^(1), `char` has been sorted – conceptually speaking – by mapping it to numeric values in accordance with alphabetical order^(2); or, far more commonly, how lexicographic sorting uses an order over elements to "build" an order over sequences. Expanding on this notion, Henglein proposes to represent ordering relations with a DSL which can express the inverse, contramap, sum, and product of a base order. In simpler Rust parlance, this means that if we have some type that is either: - a distributively sortable type `T`, such as `u32`, - something from which we can get a `T`, such as `char`, - a choice between `T` and some other distributively sortable type, such as `enum`, - made up of many `T`s, such as `Vec&lt;T&gt;`, - any combination of the above, such as tuples or `struct`, then we can use discriminators to sort it in linear time^(3). As /u/comex said, order discrimination effectively behaves like a generic radix sort, and can be implemented as such. (For an outline of how this works in practice, Edward Kmett's [comment on /r/haskell](https://www.reddit.com/r/haskell/comments/3brce1/why_does_sort_in_datadiscrimination_claim_to_be_on/csor54a/) is particularly lucid.) For the purpose of sorting, however, some practical problems arise when developing *generic* discriminators as described in the paper. Specifically, discriminator sorting is decidedly less memory-efficient than conventional sorting strategies, and has poor data locality. To wit: - Discriminators are not in-place. - Discriminators sort by associating the distributively sortable `T`s to the original values from which they were computed, and then sorting by key on `T`; in other words, it's a sort with satellite data. Whether we do it by copy or reference, we pay a price in terms of performance and convenience. - Discriminators effectively "compile" a structure into a tree whose leaves can be sorted distributively and then merged back along the branches. More accurately, discriminators work by structural recursion on ordering relations, and may perform some expensive operations on the way; for example, product orders require a shuffling step where all input pairs `((T1, T2), Value)` are transformed into `(T1, (T2, Value))` before being lexicographically sorted first on `T1`, then on `T2`. Implementing a distributive sort that works well in this scenario is not trivial. Lesser problems, ergonomic in nature, affect the representation of ordering relations, again as described in the paper: - Ordering relations map very elegantly to inductive algebraic data types, but the benefits feel more modest when working with other structures. (This affects "modern" Haskell as well as imperative languages.) - Most languages lack the facilities to express type-safe DSLs with ease. In flamboyant Haskell, Edward Kmett uses the `Divisible` and `Decidable` [contravariant functors](https://hackage.haskell.org/package/contravariant) to implement a generic divide-and-conquer strategy, and then tells GHC to [derive the DSL](https://github.com/ekmett/discrimination/blob/master/src/Data/Discrimination/Sorting.hs#L162) for him. (Such is the way of generic programming.) In coy Haskell, Henglein uses a GADT. Languages without GADTs can adopt a straightforward [final encoding](http://okmij.org/ftp/tagless-final/) with interfaces and HKTs. Languages without HKTs must find an ad-hoc solution their type system can dance to. Happily, Rust can express a marginally clunkier DSL using a final encoding with associated types and manually specified bounds; implementing it is verbose, but simple enough. Ultimately, I am sanguine that these problems are neither unsolvable nor intrinsic to discrimination as a strategy; in particular, I suspect that a better balance between expressivity and performance can be found by bringing the structural recursion over order representations closer to how the underlying sorting routine works. (Which is what I was planning to work on over the holiday season^(4).) Failing that, it would still be feasible to renounce composable orders and implement a simpler radix sort that is generic over many useful types – which, while not quite so sophisticated, would still be useful. --- [1] Computer science is young, after all. [2] It is easy to see how this relation is artificial: after all, there is no meaningful order over symbols from different alphabets or writing systems, yet any standard library will strive to persuade you that `𐂃` (Linear B symbol for "horse") is less than `🝖` (alchemical symbol for "digestion"). [3] The complexity analysis included in the paper is quite daunting. My rough understanding is that discriminators should be linear on the length of distinguishing prefixes, since they work their way "upwards" through an order representation by compounding linear MSD radix sorts in a way that doesn't alter the overall runtime overmuch. [4] Although now that the crate is parked I am probably doomed to spend half the time coming up with an original name.
We had an unofficial underhanded Rust contest last year; IIRC, /u/Manishearth won.
link? Edit [found it](https://www.reddit.com/r/rust/comments/3hb0wm/underhanded_rust_contest/)
I'm not very familiar with streaming protocols, but the body of the response can be as long as you want. If you put an object that implements `Read` as the body of the response, a thread will run in the background and send data to the client as long as the `Read` provides it. 
Awesome, thanks! Any criticism or tips would be much appreciated, but I know you are busy :)
The interesting thing is "constant". With a branch, because of bra'ch prediction, a true result may be faster to computer than a false. Then, timing the algorithm can give you a lot of information on the data. Constant is in the sense "whatever you give, you'll have the result in the same time".
&gt; This would make it easier to use one rustup on glibc and musl distros That rustup would probably work on musl-based distros but there are no *official* rustc releases for musl-based distros (yet) which is, I expect, what most users actually want. Without that, the use of rustup on musl-based distros would be rather limited.
This is slightly besides the point of this article - which is really about how to get a simple http server + database running - but I'm interested in whether Rust might bring some new ideas to the world of backend server architecture. What with the strong typing guarantees and low-level control of data layout, I feel like there must be a better way of designing Rust-based microservices that HTTP + JSON + REST, which becomes a horrid slow brittle mess after a certain point. I'm been having fun with the python library [nameko](https://nameko.readthedocs.io/en/stable/) recently, which uses various tricks to abstract away the interfaces almost completely, hooking everything together with seamless (blocking) RPC calls inside a per-service event loop. My ideal microservice architecture would basically be that but with strongly typed interfaces and much faster IPC (perhaps just using memory-mapped files). I think you could build most of this on top of [capnproto](https://github.com/dwrensha/capnproto-rust), with some macro magic. `[#derive(microservice)]`? I'm keeping a close eye on [fractalide](https://github.com/fractalide/fractalide) as they seem to have the same idea, though I don't fully understand that project yet.
I know, but since there's a musl static target, it's only logical to have rustc that can be hosted in a musl distro (static or dynamic default). This would make it much easier to link static binaries with musl target when it relies on external C libraries.
Does the cpu use the branch prediction with conditional instructions? I thought it can execute the instruction without flushing any pipeline and not get a performance hit no matter if the condition is true or not. According to Agner the throughput and latency is minimal with the SETcc instructions (1 cycle). *edit* oh, the constant time is not referring to O(1) but actually constant computation time no matter what the input is.
Note that `records()` (and `byte_records()`) allocate `Vec` instances. The `reducer` program is spending quite a lot of time allocating memory. You could try the `next_bytes()` interface, but it doesn't go too well with `csv::Writer`. I don't have much experience with the Rust type system. /u/burntsushi, can you say a few words about why `Reader` can't return an `Iterator` or if `Writer` can be somehow made to work with `next_bytes()`?
http://www.zachtronics.com/shenzhen-io/ ?
&gt; I thought that rustc and Cargo (?) were already packaged for alpine linux and for void (?) linux. But perhaps those don't work for you. That must (relatively) new then. I'll go looking for it, but the parent comment was saying it doesn't exist in rustup because there is no official rustc hosted on (dynamic?) musl libc yet. Or I misread the comment.
The performance is ok, one of my higher priority todos is to switch from my BVH over to [Embree](https://embree.github.io/) which will improve performance a lot. It's mostly a "toy" renderer in that it supports features I want to implement, so it's very far from the feature set and usability of what you might expect from a production renderer. For example, I haven't gotten around to adding support for textures yet or exporting materials from Blender which you would expect from a standard tool. It may be able to render what you need though, try it out and let me know! I'm not sure on how its performance compares to other existing renderers, but if they use Embree mine will definitely be slower, and may be slower even if they don't since I haven't done a lot of optimization. I do have a rough plan of what features I'd like to do next (Embree, textures) on Trello but I don't have any sort of feature implementation schedule with dates or something, since it's just a side project. If you do try it out I'd be interested in what parts you liked or didn't like using and what was hard to setup or figure out. I've tried to work on documentation for the scene file format but it's easy for it to get out of sync sometimes. For the object placement and motion you can use the Blender plugin but to set materials and light emission strengths you still need to manually edit the scene file for now.
&gt; Official, dynamically linked rustc for musl needs PR #38075 and more follow up work. Statically linked rustc simply doesn't work; it just segfaults inside LLVM when trying to compile anything (or at least that was the case when I tried 2 months or so ago) Is the problem something that could be solved by avoiding libgcc and libstdc++ and relying solely on llvm's libs (libunwind, libc++, etc.) for all of that?
As a side-note, it's a bad idea to depend on Rust code to be compiled into constant-time assembly, since LLVM is allowed to transform the code in any way it wants (as long as the output is the same). See the example in https://github.com/klutzy/nadeko for a case in which this happens. 
In comparison to equivalent platforms, I think the pricepoint is pretty attractive. The evaluation kit for just the SAM4L is already more expensive (http://www.digikey.com/product-detail/en/atmel/ATSAM4L-EK/ATSAM4L-EK-ND/3719590) and imix includes an NRF51 (which would be another $40 board), RF233 (another $20-40 for a module/dev kit) and three sensors. If you tried to construct like this from an Arduino, you'd end up paying at least as much as well (you'd need at least three shields, I believe). FWIW, the $99 is basically at cost after shipping, fulfillment, etc (we're academics, not making money on this at all). With higher volumes we could probably get the cost down a bit, but just the components cost ~$30 at even 10,000s.
I'm trying to get windowed access to a slice. It is for reading in binary packets. *I'm aware nom exists*, the data is encrypted. So I have a type pub struct Foo&lt;'a&gt; { hello: &amp;'a [u8], world: usize } If I want windowed access like impl&lt;'a&gt; Foo&lt;'a&gt; { pub fn bar(&amp;self) -&gt; &amp;'a [u8] { &amp;self.hello[ self.world ..] } } No problem prefect. But if I used a `Cow&lt;'a,[u8]&gt;` instead of a `&amp;'a [u8]` this fails with a lifetime error. that `pub fn bar(&amp;'a self)` should be annotated I can use `Vec&lt;u8&gt;` in the same fashion. Without the `fn bar(&amp;'a self)`... error... :.:.: Now a `Cow&lt;'a,[u8]&gt;` is just an enum wrapping `Vec&lt;u8&gt;` or `&amp;'a [u8]`. So what is the problem? Is this just a hole in the standard library? Is there a work around? :.:.: Okay I wrote a wrapping crate... literally no issues I'm seeing so far. I guess it just needs to be patched?
I really enjoyed the predecessor [TIS-100](http://www.zachtronics.com/tis-100/) which also fits the bill, but I haven't tried Shenzhen-IO yet; can someone who has tried both compare and contrast them?
Yeah I agree for the components included it seems great, and not accusing you fine folks of trying to make a profit, but it still is a bit of a barrier to entry for Tock contributors.
Believe it or not, what you're trying to do is actually unsafe. In the first case you're ok, because you have the `&amp;'a [u8]` in there, which guarantees that the slice it's referring to is borrowed for the whole lifetime `'a`. So the `bar` method is allowed to return another reference for that lifetime (even though `self`'s borrow is shorter-lived). However when you try to do it with `Cow`, you're running into the problem that you can't pull a reference of lifetime `'a` out of the `Cow`. You're only able to get references with the same lifetime as `&amp;self`. That's because the `Cow` has to consider both of its cases. It _might_ contain a `&amp;'a [u8]`, in which case everything would work just fine. But it might _also_ contain a `Vec&lt;u8&gt;`. That `Vec` is borrowed as part of `&amp;self`, but `bar` has promised that it's going to return a reference with lifetime `'a`. The only way for that to be legal is if you promise that `&amp;self` will stay alive long enough, by calling it `&amp;'a self`. By the way, this was totally non-obvious to me when I first looked at your question. The thing that made it clearer was to try to `match` against the `Cow` and handle both cases explicitly. The `Borrowed` case works just fine, but the compiler will complain about the `Owned` case.
I'd also like to know why it's slower. I'm due to build a new solver in the next 6 months and I'd really like to use Rust but I need some evidence to convince my team.
After falling in love with Twig templates, I will be checking this out. Is this a custom implementation or is it based off another system? (EG Phalcon uses a custom implementation and is a little bit horrible)
Yeh, the colours seem handy. Can't stand the inline error messages though. Anything that moves text around throws off orientation. If they where off to the side, or a simple icon with tooltip on hover it would be better.
&gt; Extend the musl target support with an optional feature to respect the existing metadata to fetch the external C lib archives from alpine. I agree that making things easier would be awesome, but there's some fundamental questions of trust here that'd be important to resolve, as well as a new dependence on stuff that's outside of the rust project proper. Not insurmountable!
I'd personally rather not see it as the default, musl-linked programs don't work properly in Ubuntu on Windows :(
I dunno what the heck that monstrosity is, but this reminds me that there should be infinite points if you can do it with --everybodyloops.
I've generally used Falcon in Python for this sort of thing, but I like the look of Rouille. Feels familiar enough to get going quickly.
Got it. I agree with that. That'll probably come next. One hope is that people with access to both $99 and some expertise/interest in cheaper platforms (like the STM Nuleo boards) will be able to help port Tock more easily given the board the core team is using. But, that's an very valid point.
Like I said, they're not insurmountable issues! I agree with you, all I'm saying is that we'd need buy-in from more than just me :) &gt; there's a real need for offline mode in cargo Cargo should already work just fine offline, both through normal usage and through some extra tooling for specific cases (that already exists.)
Yes, and you could use it, in that sense, in something like "the praxis of the community [is to offer extravagant gifts in the expectation that they will be turned down, e.g.]". In that one, specific, case, you could also say "practice". That is very different from the unqualified claim that "praxis" and "practice" are synonyms, a claim that would legitimate usages such as "he has a lot of praxis playing the violin" or "he has a dental praxis" or whatever.
&gt; I just haven't witnessed this yet :\ Compare the GCC version of [this](https://godbolt.org/g/jvSKCD) with the clang version, as a single data point.
[The Rust Language Server is coming.](https://internals.rust-lang.org/t/introducing-rust-language-server-source-release/4209) It's not here yet. It should solve all of our problems with autocompletion and many other things.
Nice! I'm sure this will help build confidence to get more Rust code into production at Square.
Well, it'll provide the tools necessary to solve the problem. Which is, maybe, even better.
Interestingly, if you switch to `-O2` (which is generally considered safer/more stable on GCC than `-O3` or `-Ofast`), the GCC and clang ASM become very similar in length.
You can use the `?` operator (or the `try!` macro if backwards compatibility is important) if you want something to happen only if all the values are available. So you'll have something like fn do_stuff() -&gt; Result&lt;SomeResultType, SomeErrorEnum&gt; { let params: Params = request.get_ref()?; let name = params.find(&amp;["user", "name"]).ok_or(SomeErrorEnum::NoUserName)?; let email = params.find(&amp;["user", "email"]).ok_or(SomeErrorEnum::NoUserEmail)?; // do stuff with params/name/email }
Yes they should but I don't know how to do that. I tried `if let Some(foo) = ... &amp;&amp; let Some(bar) = ... {` but that doesn't seem to work.
Very good summary! Anyone wanting to check Tera can also try the 0.5 branch that should land soonish and improve error handling/reporting quite a bit. Small correction: the `try_get_value` is exported but not documented in 0.4
 if let (Some(foo), Some(bar)) = (baz, quux) {
Anything like that will throw up red flags in code review, so you would need to provide a plausible-sounding reason for why those things are necessary if you wish not to lose points.
blurgh. I guess I can see why that would deduct points in this case.
A payment system storing currency amounts to fractions of a cent is already a big red flag. I don't know if there's any way this could be done subtly. Both the Stripe and Square API docs clearly state that they return an integer value in cents (or the lowest denomination of the chosen currency), as they should. Floating point is the only way I can think of doing this while maintaining at least plausible deniability, but it's such a poor choice for representing currencies that I can't see how any such code would ever be approved.
Vec-encoded BCD for arbitrary precision decimal numbers, and nicely lossy double or int conversion, maybe?
...ok? That article was posted in November of 2015. 
Fractions of pennies get large when you add em up :) we judges consider it perfectly valid if you are funneling money in aggregate. It doesn't need to be done at a per-transaction level. It's fine if you hide it in some aggregation pass at some other point in time. Like in calculating taxes, or trying to consolidate credit card transactions or something. That make sense?
Yeah we have slightly different goals than Underhanded C. We haven't yet developed a corpus of dangerous coding patterns, so on one level we don't want to constrain our community from being creative. The other aspect is that as part of our [2017](https://github.com/aturon/rfcs/blob/roadmap-2017/text/0000-roadmap-2017.md) is that we want to encourage our community to help productionize our ecosystem. That make sense? We hope this open endedness won't discourage people from playing. 
Many software projects are worked on daily. That doesn't mean they aren't stable. Cargo is a package manager, similar to pip or npm. You shouldn't need to perform incantations. Cargo also builds your programs for you. Set up the simple config file, and then write code. Cargo will find your dependencies, compile the deps, compile your app, and then run your app, all with just you typing "cargo run".
Waiting for 0.5 to come soon. `try_get_value!` may be exported, but it is unusable at the moment because it refers to `::errors` module which is private. The following example doesn't compile: #[macro_use] extern crate tera; extern crate serde_json; use std::collections::HashMap; use tera::{TeraResult, Value}; pub fn dummy_filter(value: Value, _: HashMap&lt;String, Value&gt;) -&gt; TeraResult&lt;Value&gt; { let _ = try_get_value!("dummy", "value", String, value); Ok(value) } fn main() {} I submitted a [Github issue](https://github.com/Keats/tera/issues/94) and a [PR with a possible fix](https://github.com/Keats/tera/pull/95).
itshappening.gif
Rust (the language as well as the standard library) has been stable and without significant backwards-incompatible changes since May 2015. It *was* constantly changing before that, but basically every book/piece of documentation after that should still be valid. Other than that, have you seen that there is an official book bundled with Rust ([here](https://doc.rust-lang.org/doc/stable/book/), with slightly older epub and PDF versions [here](https://killercup.github.io/trpl-ebook/))? Additionally, the second edition of this book is being written as we speak (to be more beginner friendly), and you can follow the progress [over here](http://rust-lang.github.io/book/). As for your other questions, have a look at the chapters on "cargo" in those books :)
&gt; According to the bottom of the LearnXinYminutes tutorial page, this language is apparently constantly changing every day, so won't the stuff I learn in these books be too outdated or something to be useful? The language is still gaining new features and libraries, but what you learn now will continue to apply as new things become available to learn. That's part of what the `1.0` version number meant. &gt; Since this is a (new) language instead of a library on an existing language (as opposed to most Javascript books), doesn't this mean that I will have to build everything I need from the ground up? I'm not sure what you're asking. Build what up? Knowledge? Libraries? Tutorials? &gt; Do I have to deal with makefiles and whatnot as with C and C++ for this language in order to compile what I write... or is this more simple like with Javascript and Python where it will automatically compile and (run for the most part)? Like Python and Node.js, it's got a modern imports system, so you just add your dependencies to the `Cargo.toml` file and `use` them in your code to import them. Like C/C++/etc., it is compiled to machine code, so you have to manually ask for your code to be compiled. (But then, Java also requires manual compilation despite being bytecode-compiled like Python) In Rust's case, "cargo" is both your dependency downloader and your build tool. (ie. Any dependencies not already installed will be automatically set up when you type a command like `cargo build` or `cargo run` which requires a compile.) Like git, it's also extensible and people have written subcommands such as [cargo watch](https://github.com/passcod/cargo-watch) (`cargo install cargo-watch` and add the `cargo install` target directory to your `PATH` if it isn't already) to automatically restart servers or re-run tests as you edit your files. The [rustup](https://rustup.rs/) installer/updater also makes cross-compiling to most common architectures really easy. To target my OpenPandora handheld, all I had to do was type`rustup target add arm-unknown-linux-gnueabi`and then add a couple of lines to `~/.cargo/config` to tell it where to find the C/C++ cross-compiler it needs for the final linking against glibc. In case you're wondering, those lines are: [target.arm-unknown-linux-gnueabi] linker = "/home/ssokolow/opt/pandora-dev/arm-2011.09/bin/pandora-gcc" &gt; Does Rust have some centralized package/library repository to make it simple to find pre-made stuff I can use and build off of? Or is this more like C and C++ where I have to pour the blood of a newt into a cauldron and recite an incantation to Gaben for 30 seconds before I find out that there were 3 unknown compile errors? https://crates.io/ It's what Cargo uses.
Nema na cemu kolega! Jos ovakvih PR-ova molim! :D
Something is weird with the dates. It says 12/12/2016 at the top, but some comments are from 2015.
Maybe an edit. I personally read this article last month lol
Building Gecko now uses Rust by default, but it is still possible to disable it. However: &gt; This is a temporary work-around; we expect to remove that option and require Rust unconditionally early next year as non-optional features start to depend on it.
Yeah, macros are a bastard to parse for any language - Eclipse CDT is pretty good at C/C++ macros, but they are very simple-minded beasts. One approach in Rust is cover some common cases, like `vec!`. Personally I find Geany strikes a nice balance as a Rust editor that has some smarts (like go-to definition) but yes, we'll all waiting for the RLS, which can be integrated with whatever floats our particular boat
areweproductionyet?
One complexity of autocomplete in the context of traits is that the number of methods for an given value very very large if you allow for imports, which I hope they do.
Yes I have a plan for that.
I've actually used Rust in interview a bit and gotten offers every time. It's great for displaying knowledge of systems programming and efficient manual (non-GC'd) memory management. However, many common algorithms and data structures are a huge pain to get right in Rust, especially if you're looking to avoid `Rc`/`RefCell`. For those types of questions, I lean more towards GC-d languages such as Scala, Java, or Python.
Thanks, i will look into that!
So Gecko needs a Python, Rust, and C++ toolchain installed? That's quite a lot, but I expect that's what things will look like for a lot more software moving forward. Luckily dependency management with crates.io and Cargo is way more sane than dealing with the C++ ecosystem, so hopefully it's a relatively small cost.
`Option::and_then` is super useful, I've written a `do_notation!` (you can't just call it `do!` because that's a reserved word) macro before that turns: do_notation! { let first_thing = something_returning_option(); let second_thing = { let intermediate = first_thing * 2; something_returning_result(intermediate).ok() }; something_else(second_thing) } into a chain of nested `and_then` calls. I'll leave the implementation of that as an exercise for the reader (because I can't find my code right now).
Working on an accuracy-focused Gameboy emulator in Rust. It's been a lot of fun. https://github.com/mehcode/wadatsumi
Hm, at some point Jekyll needed Ruby (for Jekyll), Node (for asset building) and Python (for pygments code highlighting) installed to just run the example page. They moved back from that. But currently, I can see sense for Gecko. Before, it was: * C++ as main coding language * A tooling language (Python) Now, it is: * C++ as the original language of the project * a language they transition parts to (Rust) * A tooling language (Python) That doesn't seem excessive.
I just discovered const fns. I'm trying to make a compile-time string constant hasher: const fn hash(name: &amp;str) -&gt; u32 { // Somehow get at characters of `name` here, `.as_bytes()` is good enough. // Must handle different name lenghts, though having a small hardcoded maximum length like 8 is acceptable. } Is there a trick to make this work or am I stumped by the current const fn level of expressibility?
So, tested this now by using the built in trim_right and converting the resulting slice to a String. Even this gave a significant speedup, from 4.9MiB/s to 5.6MiB/s. However, I don't know how I can keep removing linebreaks/quotes in the middle of a text if I don't use regex. Since `String.replace` also returns a String instead of a slice.
Nice! Maybe let the Rusoto folk know -- JMESPath is important in the AWS API platform.
Many traits that were in `std` got removed before stabilization. Most of the reasons are pretty boring. Examples of reasons: "we really need language feature X to make this trait work the right way" or "this trait Y requires a lot more design work before we're comfortable stabilizing it, and we don't _need_ it to ship 1.0." In the case of `from_str_radix`, it seems plausible to me that you could define your own trait and provide the impls yourself using the concrete `from_str_radix` methods.
Hey there, I've been working at AdGear which is now part of Samsung for 3 months now. We started a project in Rust and are very likely to use it for other things. Check out the job posting and let me know if you want to chat. I'll DM you my email. http://jobs.adgear.com/apply/fj3uVz/Backend-Engineer
Do you mean providing completion options from traits from modules not yet imported? That would be sweet.
rustc also requires Python (for tooling), Rust (of course) and C++ (for LLVM) in order to compile. 
I dunno you can still have simple logic errors (e.g. omitting a `!`, or getting brackets in the wrong order), though none of my collection of sneaky C++ bugs that took ages to find would have happened with Rust: a) while (getLine(pc, buffer, sizeof(buffer) &gt; 0)) This wouldn't be possible in Rust because `int`s aren't implicitly converted to `bool` which is required by `while`. b) int n = strlen(foo); for (int i = 0; i &lt; n; n++) { // ... Rust doesn't use C-style loops so this is ok. c) std::string test = "POST /speech?v20160203 HTTP/1.1\r\n"; "Host: api.wit.ai\r\n" "Authorization: Bearer I2WG2UKPDEWMHXSDY5775CYTBANXI3KI\r\n" "Content-Type: audio/raw;encoding=signed-integer;bits=16;rate=48000;endian=little\r\n" "Transfer-Encoding: chunked\r\n" "Accept: application/json\r\n" "Connection: close\r\n" "User-Agent: test/0.0.1\r\n" "\r\n" "8\r\n" "abcdefgh\r\n" "0\r\n" "\r\n"; Rust doesn't allow this type of string literal concatenation.
GCC is still doing a loop, whereas Clang is computing a single value. That said, never read too much into benchmarks without understanding why. It seems fairly unlikely that this optimization will help normal code as much as it does here, since people rarely depend on summations as trivial as this.
Re-coding anything in any language is something not usually worth it. Don`t fix what isn't broken. However sometimes things are broken and need fixing. Even if the code is stable, it might be missing important features, and might make it very hard to add them, do to complex, badly design, or poorly written code. That's when a rewrite makes sense. In this case, rust is an excellent choice. Rust is advantages are that despite being a system language, it offer modern, high-level abstractions. You have stuff like pattern matching, generic types, interfaces, union types (advanced enums) and other stuff that makes your code relatively short, and in my experience, easy to read and maintain. You will also have excellent built-in unit testing as well as module or crate wide (crate is a rust library) tests. You will have those features along side a very safe type system. Rusts type system guarantees that there will be no access of uninitialized variables, no double-free, no null exception, no data-races, along with a few other niceties. The tool-set is also top notch, with a nice packages/built system (cargo), a formatting tool and some ok-ish editor support, and even a linter (clippy relies on unstable rust). But its not all sunshine and rainbows. Rust is a young language, and the library story is still not great. Rust's syntax is also pretty foreign despite having those curly brackets. Rust`s safety also comes at a cost, not a performance cost (no garbage collector or run-time required) but a learning cost. To provide safety rust uses a borrowing/ownership model that most people are uncomfortable with, at least in the first few week. There is also the need to master lifetimes, when doing not trivial code. These concepts, along with the syntax cause people new to the language to struggle as they learn the ways of rust. Also not having a great IDE experience might be a problem for some people. I hope I gave you a glimpse of what rust is and is not about.
Thanks! I'll dig into that :)
I have a request: [please stop using string-based templates](http://m1el.github.io/printf-antipattern/). They're the main source of vulnerabilities on the web, and there are [better ways](https://maud.lambda.xyz/) to do HTML templating. In fact, it's possible to make changes to `tera` templates (without changing the syntax!) so that tera will be HTML-aware.
I'm not 100% sure if this is the best way to handle threaded UDP server requests. Unlike TCP, there is no "accept" stage where I can open a new thread. Please let me know if there is a better way to handle this.
&gt; Tera is not only for HTML though as the article mentions. This doesn't justify using tera as an HTML templating engine. &gt; render a user inputted template using something like maud? Unfortunately, you can't. However, it's possible to change tera to be HTML-aware, and much more safe. I've seen a few templating engines that do that, but they're not widely used, unfortunately.
If its small it would be good learning, and it might run more efficiently. If its big and you have already optimized it with C/C++ then I would not suggest doing the whole thing over. 
Not sure why you got downvoted, but that's an interesting point. If that's the case, then other programs (not using glibc) will also fail to work because all that a musl static binary requires is a 2.6+ kernel ABI. This sounds like NT's Linux personality is incomplete or biased in some way towards supporting glibc.
Great. I was worried that it would not be such a happy surprise. (The whole deal with byte offsets could be off putting when it's far from expectations.)
... is this true?
&gt; Closing the gap requires work but there's no reason why rust should be this much slower. Sure, that's why I said I'd like to know what the reason is. In the other thread about the benchmarks game it became apparent that Rust's DoS resistant hash maps pay a big speed price against less safe ones. What's the reason here? Rust is supposed to be a "language that runs blazingly fast, prevents segfaults, and guarantees thread safety." First thing mentioned is fast. Fast to me (and probably others) means "about as fast as well coded C or C++". We should always ask why when it isn't. One day I'd like "as fast as Rust" to be the baseline, and C++ struggling to stay even.
&gt; I don't know if I totally agree with the idea that people demand terse syntax for common ideas, they just demand abstraction. I think templates in C++ are a good example for unnecessarily verbose syntax. Compare template &lt;typename T&gt; void f(T t); to Rust's fn f&lt;T&gt;(t: T); I think Stroustrup said in one of his talks that he had to opt for the verbose syntax to be able to sell the feature to the committee.
&gt; Unfortunately, you can't. Those are my own usecases though. That and extending templates defined elsewhere like the Django admin. I wouldn't use Maud or Horrorshow myself because it covers none of that and looking at your article, no solutions for any of those is offered. All the strings are automatically escaped in HTML templates in Tera, what would need to change to make it "much more safe"? The escape function from Maud is the same as Tera except Tera escapes a couple more characters so I'm curious
I used Rust in one interview, though the syntax was not verified (just the logic of the solution). You should really try and use what you are most comfortable and proficient with. Though sometimes interviewers will want you to use a specific language.
&gt; All the strings are automatically escaped in HTML templates in Tera 1) You can't "just htmlescape the string". Splicing the result of htmlescape into HTML in random locations is not safe &lt;img src={{ user_controlled }}&gt; can become &lt;img src=boop onerror=alert(1)&gt; In case of maud, it's not possible to do this mistake. tera's templates are not aware of the place where the escaped string goes into. It's not aware of HTML at all. 2) in tera you *have to* manually disable HTML escaping when you use markdown or similar plugins. 3) escaping html selectively leads to double-escaping problems.
You could have a set of "default" lints aka the current rustc lints, and "extended" lints which are those that are now in clippy. They would run in the same part of the build process as today (default lints on every compilation, extended lints on `cargo clippy`/`cargo lint`), but all live in the clippy codebase. Well not sure about the benefits, and it would probably be slower than doing those "default" lints in rustc, but still.
Basically, you need to find the index where you need to split, and then slice the string so you can return an `&amp;str` without allocating any memory at all. You can create your own custom `Iterator` that returns string slices of the original string -- slicing at each index where you need it sliced. You could, for example, create an enum and store a string slice when quotes/linebreaks aren't found, and for the other option you can store the `Iterator` itself. You'd have to create your own custom writer to standard output though.
Never fix a problem that you don't have
Thanks! That's a good idea. I'll let them know.
What is the backtrace that you get when running with RUST_BACKTRACE=1 ?
I totally should have. Thanks for pointing this out. I need to use raw string literals more often.
In your latter case, you'd just shift the decimal: you store an integer value denominated in tenths of cents.
Rewrites in general shouldn't be undertaken lightly-- you should have a goal of improving performance, reducing bugs, or making it easier to change. I did a talk about rewriting a C library to Rust (no video, but I have [slides with speaker notes](https://github.com/carols10cents/rust-out-your-c-talk) and [code](https://github.com/carols10cents/zopfli)) that I approached in an incremental way. I pulled pieces of the C code into Rust and kept the code in such a state that I could call the Rust code in C, thus making sure that the tests passed. I ended up rewriting the whole thing for the purposes of the talk, but I could have stopped at any point and still had working software. In this way, you could even choose only to rewrite the pieces that would help you best meet your goals-- pull over the slowest functions, or the messiest functions, or the functions that most of the crashes come from. Rewrites can be worth it, but there are a lot of tradeoffs to balance for your particular situation.
[Not impposible.](https://www.jobsinnew.tech/langs/rust)
&gt; So, the issue here is that, when wrapping a C library, that's the job of the -sys crate more than cargo itself. So there's no single place to ask for this; you'd be going through the popular -sys crates, asking for support for this. But wouldn't cargo need to know how to associate the metadata with an alpine package in order to get at the archive file for the link stage? I'm thinking that when you select the musl target, which happens to be for static building and fails if you don't have the suitable static code archive for a C library, it makes sense to automatically enable the feature of reusing the alpine archive. It can be opt-in for library version differences and such, but it would certainly make sense as an advancement of enabling the musl target.
It's all up to you on how you want to implement it. For the most part, all you're doing is selecting a format and parsing that format. You can even create your own format.
What are Hack &amp; Learns?
&gt; But wouldn't cargo need to know how to associate the metadata with an alpine package in order to get at the archive file for the link stage? In general, it's the job of the `-sys` package wrapping a system library to set up the correct flags, and possibly, even to build the library if it doesn't exist. It informs cargo of those linker flags through its build script.
If you're planning a re-write anyway, then yes. Or if the project is very small / young.
I think the C++ committee has done a stellar job of growing the language, considering they'd painted themselves into a corner right from the start with being an almost-superset of C. As for Rust, it's a privilege to witness (or even participate in) the language and API design done in the open, full of thoughtful discussion and often surprisingly elegant solutions. 
It's been a while but I finally worked out the beginnings of a parser for this. As always feedback is welcomed, especially if explanations of certain things were unclear or incorrect. Edit: Article is updated based off responses!
50-150MB after compiling, so i guess i`ll just wait for libraries in rust
Sure - but i'd like to save the time for building it myself =)
&gt; nom = "\^2.0.0" This is the same as `nom = "2.0.0"`. That is, `^` is the default. &gt; This is saying, "Use the nom library v2.0.0 but if there is any version between v2.0.0 and v2.1.0 (not including v2.1.0) use that". This is not accurate. This is the semantics of `~`. `^` is about "compatible versions", so it looks like it has two different behaviors: For version `x.y.z`, * if x == 0, then `^0.2.3` means `&gt; 0.2.3, &lt; 0.3.0` * otherwise, `^1.2.3` means `&gt; 1.2.3, &lt; 2.0.0`. This is because `y` versions are considered 'compatible' after `1.0.0`, but not before `1.0.0`.
&gt; The try!() macro knew this though and figured out what to do. Neat huh? I think this is anthromophizing `try!` a bit too much. You _could_ have written both with the same code, which is what the macro actually does. The end effect is the same.
I really like that this series shows how to use some less-talked about Rust libraries to write actual, potentially useful software.
I remember skimming the mailing list a while ago and noticing that you can't actually run Rust apps on Tock at the moment (something to do with LLVM). Is that still the case? Or did I totally misunderstand something? :) Another question, and purely out of curiosity: why the funky shape? I would have guessed that odd shapes are more expensive to manufacture, or is it solely based on surface area?
I would definitely wait until [Tokio](https://github.com/tokio-rs/tokio) is stable.
Personally, I think Java and Python are far more straightforward for use in general-purpose interviews. You'll spend less time explaining memory management approaches and more time explaining how you'd solve the problem.
You forgot the `;` after the `match`
Oh god. No wonder, it's always the semicolon that will get ya.
It look like it's waiting for travis to get the latest rust nightly (see https://github.com/Manishearth/rust-clippy/pull/1373) In the meantime this worked for me: cargo install clippy --git https://github.com/Manishearth/rust-clippy.git --branch rustup
Thanks, I'll wait a little while longer then :) 
If you are (at least slightly) familiar with Haskell, look into "Cloud Haskell".
Will it work with rust installed from Chocolatey? If so, does it need the MSVC or GNU ABI?
It would mean this: a.and_then(|a| a.b).and_then(|b| b.c) Which is the same as match a { Ok(a) =&gt; match a.b { Ok(b) =&gt; b.c, Err(e) =&gt; Err(e), }, Err(e) =&gt; Err(e), }
&gt; It would mean this: &gt; a.and_then(|a| a.b).and_then(|b| b.c) Ahh. Now I see it. ...I still think it's sigil-heavy enough to scare away people not used to functional languages.
The website is updated to [recommend rustup installation now](https://www.rust-lang.org/en-US/install.html). It also has more comprehensive info about [other installation methods](https://www.rust-lang.org/en-US/other-installers.html) than before.
Oh my 
That's interesting, because Java's generic syntax is as terse as Rust's (even if the implementation blows goats), even though naively I'd expect their respective design committees to have similar views
IANAL but I would assume you aren't strictly speaking using code if you just refer to its source in your own and aren't bound by its conditions unless you distribute a binary?
Can rustup cache downloaded tarballs in somewhere now? I want to sync a cache directory among different machines with same architecture to avoid downloading them multiple times.
I prefer the semantics we settled on. :-)
First, 3. &gt; Values of type Ct are usually short-lived is not the same as type Ct is short-lived (i.e. contains a short-lived reference). It may be possible to write fn visit(&amp;self, &amp;Ct) -&gt; (); and only have to use `Ct: 'static` (`+ ?Sized` if you need `Ct` to be `[T]` or `str` for example). Back to 1. But if you know that and need `Ct` to contain references (so it's actually `Ct&lt;'a&gt;`) then there may be hope, but what you want is AFAIK impossible. A long lived collection of `Box&lt;Foo&lt;Ct&lt;'a&gt;&gt;&gt;` would be useless outside of 'a anyway (you can't call `visit` as you are no longer able to have a `Ct&lt;'a&gt;`), so is probably not what you want. One possible way around this is Box&lt;for&lt;'a&gt; Foo&lt;Ct&lt;'a&gt;&gt;&gt; but this requires that `Ct` be a concrete type (we don't have higher kinded types yet). There is Box&lt;for&lt;'a&gt; Foo&lt;&amp;'a Ct&gt;&gt; which avoids this but, now `Ct` is `'static` again. Edit: I guess there is also the possibility that the collection stores the objects directly (perhaps like an AST), in which case using boxes would move ownership and be an allocation, as well as the problems above. The solution to this would be using &amp;Foo&lt;Ct&gt; (with generic lifetimes everywhere).
No, it can not do this yet, nor e.g. resume broken downloads.
Just landed a few minutes ago! ... ... ... ... Successful compile! 
Does it still use the ~/.multirust directory?
This was my biggest gripe recently while trying to download rust on a flaky cell connection in a train. What would it take for this to happen?
This is great! I see a library like this making perfect sense for cases where: - I know what I'm doing - I don't accept any performance overhead, be it required for safety or other stuff - I don't want to learn new APIs, and/or be restricted by them - I want to deal with idiomatic Rust version of the same old Vulkan An example of this case would be `gfx_device_vulkan` implementation.
It uses ~/.rustup now. For a short while though ~/.multirust will continue to exist as a symlink.
Sure, but rounding still exists. If I buy 94 shares of ABC at 514.321 (numbers chosen so as to be reasonable on a stock market) there's 0.6 cents to steal by rounding up instead of down. There's no reason you couldn't do taxes with fixed point either. Taxes are generally only two (maybe sometimes 3) decimal places long.
This has been [asked](https://www.reddit.com/r/rust/comments/4viqen/project_suggestions_cs_senior_project/?) [in](https://www.reddit.com/r/rust/comments/593s4z/can_you_suggest_a_simple_learning_project/?) [other](https://www.reddit.com/r/rust/comments/3bjl53/rust_language_project_ideas/?) [posts](https://www.reddit.com/r/rust/comments/4ryk48/project_ideas_to_get_familiar_with_the_language/?).
That is exactly the point of this library. I am currently writing a rendering engine based on vulkan which means I have to interact a lot with the vulkan api. But it is just painful to write "raw vulkan". I needed to make it a bit more convenient but I also don't want to pay too much for safety features at that level. It is still not quite ready yet and a few big changes are coming soon.
You're looking for /r/playrust, this subreddit is about [the programming language Rust](https://www.rust-lang.org/en-US/).
I did this for a project of mine recently ([moonfire-nvr](https://github.com/scottlamb/moonfire-nvr)). Before: 7,499 non-comment/non-blank lines of C++. After: 5,790 non-comment/non-blank lines of Rust I did it for a few reasons: * to play with Rust. Of course I could have done this with a fresh project, but I want to work on this one, and I don't want to split my limited spare time. And while there's always more to learn, I feel good about how much Rust I picked up in the process. * for the safety/security. I have some `unsafe` blocks, and I still have some dependencies on C code (likely more in the future: in addition to the current openssl, ffmpeg, and sqlite3, probably opencl, opencv, and openmax), but overall I'd say it's a substantial improvement. * to use Rust libraries. I'd say as young as the Rust ecosystem is, it's already a lot more pleasant than open source C/C++ in many ways. Building from source reproducibly is much easier (`Cargo.toml` rather than hoping for the best with whatever's installed with the distro). Using C libraries from C++ works of course but isn't really pleasant; you end up writing your own wrappers. Dealing with ancient, poorly-documented, poorly-tested code is unpleasant. Rust code is by definition recent and from what I've seen better reflects modern documentation and testing practices. Those are some of the positive things, and I'd say they made it worthwhile. But here are some caveats you might be interested in: * It took a lot longer than I thought it would. The hard part was the design, I said. I already know how to implement it, I said. But there are definitely pieces of it that I had to adapt a little to fit the idioms of the new language, which I was still learning. Here's [one example](http://stackoverflow.com/questions/37267201/vecmytrait-without-n-heap-allocations). I started with [FileSlices here](https://github.com/scottlamb/moonfire-nvr/blob/a7bfb00083d3bac2b0315b2fd6a9ffa9876b4e69/src/http.h) and ended up with [Slices here](https://github.com/scottlamb/moonfire-nvr/blob/eb4221851e64e68b8cfdb95ca63091bf1cabac57/src/pieces.rs). The approach of satisfying the borrow checker by requiring the caller to pass in a context pointer and declare an enum class with all the possible types of slice wasn't obvious to me at first. But I'm happy with the result; I think it's understandable and as a bonus each slice uses less memory (now 16 bytes of overhead per slice). * I didn't do it incrementally. I saw a guide to how someone did this in C. But I think it's not as easy to call C++ from Rust or vice versa. * I think even ignoring things where the language forces a change, you never write the same program twice. I refined the design a little in the process of porting it. I tried to keep it pretty similar so I could run side-by-side, compare, and ensure I was happy with the result. Still, there are several little differences where I couldn't force myself to make the same mistake again. So I don't have a totally apples-to-apples comparison. * I'm scared by the current Rust practices for interfacing with C code. For example: not to pick on the author of the nice ffmpeg crate, but I hit segfaults there because I had a different library version / different configure feature flags than the author expected, and it had duplicated some of the structs from the `.h` into Rust code in a way that didn't match my version. I'm looking forward to everything FFI being based on generated bindings (`libbindgen`?) instead; it seems much much safer, as well as less tedious. * General immaturity: libraries are noticeably young/unstable/feature-poor/buggy in some places, `rustc` has had a couple bad bugs on ARM. * Testing-wise, gUnit and gMock are much nicer than `assert_eq!`. You can more easily write tests that give good diagnostics on failure. For one thing, I'd like to have an `expect_eq!` that causes the test to fail but goes on to report other problems. For another, gMock has nice stuff like `EXPECT_THAT(reserved, testing::UnorderedElementsAre(...)`. For yet another, it automates creating mocks for you. * Performance-wise, I could compile with profile-guided optimization before, which was a huge performance improvement. I can't do that in Rust easily [yet](https://github.com/rust-lang/rfcs/issues/1220).
Just when there was talk about needing more `1._._` crates. Good timing. 😁 
BTW, related discussions happen on the discourse forums from time to time. Here's links to some of them: https://users.rust-lang.org/t/pre-rfc-we-need-a-process-for-giving-crates-to-new-maintainers/8033 https://internals.rust-lang.org/t/abandoned-crates/3818 https://internals.rust-lang.org/t/crates-io-discoverability-and-engagement-starting-the-conversation/4053
WOW, you just replaced over 30% of the original C++ code
I think all of these are more or less the consequences of two problems. 1) While the rust compiler is mature and tooling (cargo and rustup) is getting there, the rust ecosystem is not mature. There are few complete and actively maintained libraries. Most are either feature incomplete with no clear path forward or abandoned. Additionally the rust standard library is very small compared to that of languages like go or python (and for good reason). 2) Rust specifically targets systems programming, which often means the dependencies taken for granted in high-level languages are either unnecessary or re-implemented for performance reasons. Rust seems to have taken off for a lot of systems level projects (from [toy compilers](https://github.com/Wilfred/bfc) to [game engines](https://github.com/PistonDevelopers/piston) to [operating systems](https://github.com/redox-os/redox)), and while all this is great, the rust ecosystem doesn't even hold a candle to those of similarly young languages like go and elixir when it comes to feature parity. Disclaimer: I'm not particularly involved in the rust community, these are just my two cents from using the language for a while. (Oh and btw, Iron hasn't had a commit in nearly a month)
Now I'm thinking about how I could write some Rust code to automate my various workflows... Awesome blog 👍
Why not ~/.config/rustup? :(
Perhaps we should add an 'adopt a crate' section to TWiR where authors can put their crates up for adoption... cc /u/nasa42
Funny, I'm creating a language learning tool also :D Specifically, it's a web-based app that we are going to use in our uni (University of Helsinki) to teach some aspects of Japanese pronunciation to our students. It uses spaced repetition combined with input-based quizzes. I'm actually developing it in the direction of a research tool, so that we can collect all kinds of data of the learning process and hopefully advance the state of art in the language acquisition research. For what it's worth, I'm using Diesel+postgres and Hyper+Pencil. I'm quite satisfied with the direction Diesel is going to, although it's not quite there yet. (Having to do all kinds of workarounds.) I was initially very happy with Pencil, since it was simple and had everything I needed. However, as of late, I've become increasingly frustrated with the large amount of clones where references would do in the Pencil codebase, plus the stagnation of the development of the framework. (However, I'm content with having my own fork ATM.) My app serves some HTML pages and static assets, but the most of the functionality is behind a JSON-based REST API.
And the important part: separating config, data and cache. If you stick all that in config, it's worse than not implementing that xdg spec at all.
It sure does! I suspect that attacks like this may be common (which is perfectly fine) so the challenge is to come up with a convincing narrative to hide the fact that the SQL parameters weren't sanitized in order to stand out.
Noooo.... :) Honestly though I can make due stealing the printer out from the compiler, I'm not even really using `-Z unstable-options --pretty ...` unless I want to validate expanded code. I'd be fine if we just had some way of printing unformatted rust and piping it through rustfmt to see what my code did. 
Meh, you can search on github for bugs I introduced. Most of them only ICEs though. You can also look for open soundness bugs in general.
/u/mgattozzi what a coincidence! I started to develop my own scheme just 4 days before you published your first article about yours! And even funnier, I also used the same crates as you do: nom and rustyline. Later I replaced nom with lalrpop and a custom lexer though, because error-handling felt very clumsy with nom. I'm looking forward to your next posts! Maybe I can borrow some of your ideas :) I uploaded my code so you can take a look, if you want! I've implemented some nice things already (there's an incomplete list in the README). Eg. autocomplete in the REPL, define, if and since today also lambda works! Check it out if you feel like it! I'd also love to receive feedback, so if something catches your eye feel free to open a github issue! Repo: https://github.com/flo-l/scheme
Well exactly; they are trying to open that can of worms with 'concepts' and it will be interesting to hear the wails of pain in 2020 or so.
I'm pretty overwhelmed by the feedback of you guys and the Rust community in general! I just implemented a (pretty simple) benchmark. With your help, hints, explanations and pull-requests we've managed to improve the lexers performance: First implementation: `test tests::bench_next_token ... bench: 30,614 ns/iter (+/- 2,177)` Current implementation: `test tests::bench_next_token ... bench: 3,863 ns/iter (+/- 627)` That's almost factor 10! (Disclaimer: I've just put the `next_token()` function into a `#[bench]`, so I'm not sure if that's the best practise). I'll write a follow-up blogpost soon!
You just put the function signature in the return type: fn bool_maker() -&gt; bool { true } fn bool_maker_maker() -&gt; fn() -&gt; bool { bool_maker } fn bool_maker_maker_maker() -&gt; fn() -&gt; fn() -&gt; bool { bool_maker_maker } println!("{}", bool_maker_maker_maker()()());
i've had terrible luck with rust in general trying to use it at work with antiviruses :( no idea why 
You can find documentation installed locally with `rustup doc`, if you have the `rust-src` component installed. It will give you the documentation for your current toolchain, such as `~/.multirust/toolchains/nightly-x86_64-unknown-linux-gnu/share/doc/rust/html/index.html`
Hey congratulations! Sucky is better than no code. Well done.
It's maybe not the problem of the ppl themself but maybe of their surrounding and real life as they might get new workplaces and can't find the time to manage their old free time projects. I'm a newbe in rust but i think about making some libs others could use, but on the other hand i might won't find the time to manage, bugfix and update those next to my normal work. I could think here about using the community to develop, extend and update those libs when i can't. Github has the tools to do so, but not all ppl rely on such things, as you can see on those 6 month not updated libs. Maybe they don't need any updates because they work and ppl don't complain much about them. Who knows. We as a community of developers should work together to create an updated lib database to use in my point of view. And some should start asking those libmakers to get their projects over to other hands so that the community can start upgrading them.
Honestly, i do barely get half of what you are saying in the later part, but moonfire is now compiling on my RPi2, thanks :)
It's bool makers all the way down... 
I don't work in mission critical software, but my understanding is that rustc itself (and by extension, llvm) would have to be certified that they actually produce the intended code, and since it's so large, it would probably never be certified. In addition, there are other classes of bugs than memory safety that rust doesn't address. Most memory safety bugs are already nailed by the very strict way of writing software (use after free + double free are systematically eliminated because most avionics software doesn't use dynamic memory allocation *at all*, for example).
Totally.
Never say never. If there's a will there will be a certification following.
One of the main reason of the success of python was that it was coming "battery included". It's less sensitive for compiled languages, but it's still necessary imho. An alternative would be to have a semi-official extended library, or some kind of "rust official seal of quality™" or at least having curated crates.
No heap allocation is required, and code is monomorphized instead of being dynamically dispatched. 
&gt; crates.io should highlight high quality and maintained libraries. I don't know what sort by "Relevance" currently does but it's not terribly effective. Sorting by downloads favors crates that have been around for longer, even if they're no longer maintained. (Do transitive dependencies count as downloads? If yes, the situation is even worse). /u/shepmaster and I are working on this as we speak. We did a [user research survey](https://www.reddit.com/r/rust/comments/5g5c4x/help_us_understand_how_you_evaluate_crates_so_we/) to understand all the attributes people use when evaluating crates. I'm hoping to have an RFC open on Monday relevant to the default ordering within categories ([which will be added to crates.io soon](https://github.com/rust-lang/crates.io/pull/473)) and we're going to be adding more badges and indicators to all lists of crates. ETA: "Relevance" is relevance to your search query. Transitive dependencies count as downloads, which I don't think makes it worse, since a crate being used by lots of other crates is a good sign of quality/usefulness. I agree that downloads favors older crates, and we're specifically going to address that in our RFC for sorting by weighting recent downloads more than older downloads.
Have you looked at the [ranges library](https://github.com/ericniebler/range-v3)? It uses a form of concepts. Here's a typical example of a method in the library template&lt;typename Rng, typename C = ordered_less, typename P = ident, typename I = range_iterator_t&lt;Rng&gt;, CONCEPT_REQUIRES_(ForwardRange&lt;Rng&gt;() &amp;&amp; IndirectCallableRelation&lt;C, projected&lt;I, P&gt;&gt;())&gt; range_safe_iterator_t&lt;Rng&gt; operator()(Rng &amp;&amp;rng, C pred = C{}, P proj = P{}) const { return (*this)(begin(rng), end(rng), std::move(pred), std::move(proj)); }
[This was proposed and the feedback was pretty negative](https://internals.rust-lang.org/t/proposal-the-rust-platform/3745?u=carols10cents)
&gt; Don`t fix what isn't broken. Given the prevalence of preventable security vulnerabilities, I'd argue that nearly all C++ libraries are "broken".
Maybe I missed it, but are the results of the survey going to be released prior to adding categories to crates.io, or is categories the answer to the survey? I think the OP is in a situation where manual curation is the answer, and the tags already implemented on crates.io serve the same purpose as categories would have (in this case only though...i.e. it's already easy to find crates for `xml` or `sql`, but finding out how those crates rack and stack *isn't*). Looking forward to it either way :)
The results of the survey are influencing our proposal for the default ordering of crates within a category, mainly. Manual curation takes a lot of time. Keywords and categories are different, as I mentioned [in this PR](https://github.com/rust-lang/crates.io/pull/488): &gt; - Anyone can start using any keyword without having to go through a PR &gt; - Since available categories are curated, they should be higher quality than keywords (ex: we won't have categories for both math and mathematics &gt; - Categories' purpose is to aid browsing, while keywords aid searching since they are included in search rankings (categories won't be).
I think Redox's [ralloc](https://github.com/redox-os/ralloc) memory allocator would aid this a lot.
Ada performs dynamic allocation and one version even uses a garbage collector, so I'd say it's perfectly valid.
https://github.com/hansihe/Rustler https://github.com/erszcz/erlang-rust-nif 
As far as I can tell (since the standards are not freely available online), both MISRA and DO-178B prohibit runtime dynamic allocation. Perhaps Ada's dynamic allocation is for non-safety-critical sections of codebases that run alongsize safety-critical parts? It often makes sense to keep the safety-critical and non-safety-critical sections of a codebase in the same language so they can share data structures and libraries. EDIT: I realize I forgot the original reason for this discussion: Yes, I could see ralloc helping in non-safety-critical parts of a Rust codebase.
My problem with "Downloads" is that it favors easy names as opposed to quality: when someone begins developing an application and not a library it's very easy to do the following in your Cargo.toml: sqlite = "*" xml "*" Even if you don't just blindly add them, having a name like `sqlite` suggests to me that this is some kind of semi-official package which is obviously incorrect. As I said in the post that crate lacks some functionality and hasn't seen a meaningful update in more than a year. 
Author of sxd here. &gt; if not for the lack of documentation. This is entirely believable. However, I cannot find any issues reported with what kind of documentation is missing or desired. You may wish to double check your other browser windows; sometimes I forget to hit "submit" on the GitHub issue or pull request. &gt; It also doesn't seem to be maintained (or at least actively developed). This is a catch-22. I don't actively *work* on it because no one reports any issues or submits any pull requests. In my normal day-to-day life, I no longer actively need to work with XML, so there's no outside driving force that pushes me to work on it. It's not **abandoned** by any means, it's just sitting there. &gt; There should be an initiative to provide high quality libraries for basic functionality. Who decides these things that are "basic functionality"? Who **pays** for the work behind it? If you have a source of funding, [Integer 32](http://integer32.com/) has a specific lower rate for open source code. We'd be happy to discuss being paid to work on whatever you'd like. &gt; I know that I could just adopt the orphaned crates and/or contribute. While this is true, it's not really relevant to the point I'm trying to make: most people aren't looking to become open source library maintainers when they start writing an application in a given language. They just expect some libraries to be there for common functionality. I suppose I don't understand: you appear to want something for nothing. You appear to expect that high quality libraries are available, maintained, and free, but don't seem to be offering *anything* to balance it out. You explicitly state you don't want to contribute or maintain a package, and leave out any other methods of contribution. All you get from an Open Source license is "software to be freely used, modified, and shared", everything else is a cherry on top of that. &gt; I apologize for the negative tone I agree heartily; this *does have a negative tone*. That's why my response *also* has a negative tone.
Yep, well, there's no substitute for actually investigating your dependencies before installing them.
Other than some light php usage, I have very little understanding of the backend. Are we web yet looks promising, thank you!
I agree, but the current status quo can be really misleading. At least in the case of `rest` the crate is an obvious land grab that doesn't even work. However, with `sqlite` there are better alternatives out there but `sqlite` does technically work which can give you the wrong impression (large number of downloads, has the "official" name, etc.).
The problem is that there is no "official" that should be inferred on crates.io. Crates.io has not officially endorsed any crates, so I'm not sure how crates.io could stop people from assuming that the name of something magically confers any particular status.
Looking at all these awesome and interesting projects people are working on and I'm just sitting here reading through the first pages to "The Book" writing Hello World. :D
Well, I haven't seen your edit in my inbox which apparently added more things than your reply originally had. Instead of editing my response I'll post a separate one to make the conversation easier: the two issues (your library, everything else) are pretty separate anyway. I apologize for the short quotes, I'm on mobile: &gt; basic functionality The idea here wasn't that I expect a single person to write and maintain all important libraries out there. The point is that in the sea of maybe abandoned, maybe maintained libraries I don't even know which one I should try and contribute to. For `sqlite` people fixed the biggest problem which is proper Windows support and that hasn't been merged for 6 months. My problem is not with open source and community contributions, it's with important crates dying with no real replacements. &gt; libraries for common functionality I mentioned in my previous section that I'd be happy to contribute if I knew which library I can trust to be supported in the long run. While I see your point about open source, it's not terribly useful when it comes to attracting new developers. Let's say I want to develop the same application in some similarly new languages: 1. Go * XML: included in the standard library * SQLite: [go-sqlite3](https://github.com/mattn/go-sqlite3), actively maintained * Web server: pretty much included in the standard library (this is kind of cheating, go was made for applications like this) 2. Swift * XML: [SWXMLHash](https://github.com/drmohundro/SWXMLHash), actively maintained * [SQLite.swift](https://github.com/stephencelis/SQLite.swift), actively maintained * Web server: several options, actively maintained Again, this is from the perspective of someone new who just wants to try Rust for a small project. If you scare everyone off before adopting the language they can't become library maintainers/contributors. &gt; tone While my tone was negative, I tried to avoid making either this or the original post personal. I apologize if I didn't succeed, but your passive aggressive responses made calmly replying to them pretty hard, especially since you misunderstood/misconstrued most of my suggestions.
In the past we'd decided not to, since we had such small usage of Rust and we didn't want to give anyone the wrong idea. But it's been a while, so I'll bring it up again internally and see what folks think.
Also, every new version of the compiler would have to be re-certified (afaik), so the certified version would always be lagging behind the current version.
In Ada, you can allocate freely, but deallocation is an unsafe operation. If an application in Ada uses dynamic memory allocation, it probably only does it at startup and then keeps it for the entire lifespan of the process. Garbage collection is an absolute non-starter in real-time systems, and pretty dubious in safety critical systems in general. The implementation of Ada you're referring to is (I'm fairly certain) the GC patch for GNAT, and as far as I know, GNAT has never been used in a safety critical system to begin with.
Is it possible to precompile (via macro or `build.rs` script) the templates?
That's a feature! And adding `: Trait` is frankly still less overhead. 
This actually occurred to me too, and could be an interesting compromise. It would eliminate the need for splitting intermediate types that clients rarely or never interact with, and would be no less ergonomic than splitting. I may go this route.
Yea in the example you posted I'd definitely go for break. If you do use an extra variable you're essentially double checking your exit condition which is pointless and also slightly slower.
&gt; use after free + double free are systematically eliminated because most avionics software doesn't use dynamic memory allocation at all, for example Yes... and no. I mean, if you use the item at index "i", then decide you no longer need it, but forgot that something else had "i" memorized and access it, it's still a "use after free" class of error. You may using "dead memory" or overwriting an object now used elsewhere in the codebase.
Setting aside the advantages, what do you think is less clear? 
Implementing a memory allocator over a fixed length array in `.data` is still dynamic memory allocation. Also, rust does not prevent this problem.
For a long time, I'd tend to use Ada for proving algromithms, but rewrite them in something else as Ada's ecosystem sucks hard due to AdaCore licensing being difficult to follow, and GPL everywhere; GPL is something of a poison pill if you want to use other open source licenses and such. At this point, if Rust gains something similar to SPARK, I'll likely never install GNAT again.
There's already [a link to docs.rs](https://docs.rs/refraction) in `README.md`, in the form of a badge at the top. I'll try to work on a blurb and example, though; thanks for the feedback!
Right, sorry I missed that. (With the badge overload that some people like to put into their readmes, I'm mostly ignoring those lately.) Now I'm trying to figure out what a "lenticuloid" is :)
It won't be long until macros 1.1 (and thus `serde_derive`) land on stable. From that point on, it won't be an issue at all.
If I do that then I can't use `f` anywhere else in my function after that.
You can take `f` by reference, then you can pass it to `recurse_with_function` without needing an additional closure, see https://is.gd/zW3RxC. Note that the nested functions are only used to avoid having to write `&amp;|x| println!("{}", x)`.
Slightly OT, but thanks for educating me about Geany! I genuinely had never heard of it. I'm trying it out, and loving it so far.
&gt; Garbage collection is an absolute non-starter in real-time systems, and pretty dubious in safety critical systems in general. Even non-GC dynamic allocation is dubious in hard realtime systems, unless it is only used during startup. Even if you are using a hard realtime-capable memory allocator (such as TLSF), it's very difficult to be sure that the worst case is still acceptable to you, because the worst case is potentially much worse than the average case. Further, it is very difficult to handle memory allocation errors at runtime in a hard realtime system.
`impl Trait` is also not really replacing returning `fn() -&gt; bool` but returning `Box&lt;Fn() -&gt; bool&gt;`, which is a boxed trait object of the `Fn` trait. Closures aren't of type `fn`, they are each of a unique anonymous type which implements the `Fn` trait (in part this is because they capture their environment). If you wanted to return a closure before this feature it had to be a trait object. Returning `fn()` types is quite rare because they have to be named functions.
Implementing an AI framework for turn-based games using [Monte Carlo Tree Search](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search) as a teach-myself-Rust project. Big fan of the language!
Not for Serde, and macros 1.1 will also probably fix the problem for a number of other crates, but I still think the OP has a point about crates requiring nightly. I wouldn't advocate banning their publication on crates.io, but it would be nice if there was an automatic process on crates.io to signal in a visible manner that a crate requires nightly (it's sometimes easy to overlook a part in the README).
There is some discussion going on here: https://users.rust-lang.org/t/numerics-math-foundation/7247 https://internals.rust-lang.org/t/roadmap-2017-request-needs-of-hpc/4276 https://www.reddit.com/r/rust/comments/58vje1/when_does_it_make_sense_to_implement_numerical/ https://internals.rust-lang.org/t/getting-explicit-simd-on-stable-rust/4380/299 https://www.reddit.com/r/rust/comments/57axvz/numerical_analysis_crates/ https://www.reddit.com/r/rust/comments/54fq1p/dataplotlib_an_earlystage_hasslefree_plotting/ And there is a nice overview of libraries (crates) here: http://www.arewelearningyet.com/ I'm personally working on these things: https://github.com/willi-kappler/darwin-rs https://github.com/willi-kappler/simple_units https://github.com/willi-kappler/natural_constants https://github.com/willi-kappler/radar-rs So I would say yes, things are starting to develop nicely. You should give it a try and let us know what you're missing ;-) I'm using Rust more and more in my job and will publish more things in the future.
Panicking on invalid inputs is such a bad behavior. &gt; "The server just crashed. Why?" &gt; "Tommy just uploaded an invalid template."
this is great, you explain things well :) A small remark, you can rewrite: named!(op&lt;&amp;[u8], Op&gt;, alt!( ws!(specialform) | ws!(primitive) | ws!(user) ) ); as: named!(op&lt;&amp;[u8], Op&gt;, ws!(alt!( specialform | primitive | user )) ); `ws!` understands combinators like `alt!` and can insert whitespace eating parsers recursively.
For sure more robust tests are always a good thing. Since the tutorial is aimed at newer users I didn't want to dump too much into each article. I'm glad you enjoyed it :D
This was why I asked "Is this new page OS specific?" - I'm on linux and saw http://i.imgur.com/P8BS8hp.png If I saw that as a Windows user I'd find it off-putting. I'm glad to see you get a link to an .exe instead :)
Thanks, I just tried it and it works! Any idea why the compiler hangs?
So... while match some_fn() { Ok(..) =&gt; true, Err(x) =&gt; { // handle error false } { /* wee! */ } Or are you saying the function itself would handle looping, and would just return instead of breaking? 
&gt; that I have to keep my serializable types in seperate files. You don't have to. the build script form of serde_codegen works fine without having to separate out your serializable types.
I suspect that once macros 1.1 happens this will no longer be a major problem. 
Does diesel run on stable rustc now? I know I tried a couple weeks ago and it was telling me to go use unstable.
Why not provide a stable version based on syntex?
Jan 19th at 7pm PST works for me! I'll comment on the GitHub thread :D
&gt; Let us clone the Rust source from github and checkout the version which matches the above commit hash Protip: If you are already using `rustup` you can install the `rust-src` component with the `rustup component add rust-src` command and you'll (always) have the *right* Rust source available in `$(rustc --print sysroot)/lib/rustlib/src/rust/src`. It will also save bandwidth.
I'd say that it's mainly because Rust's ecosystem for web development is still very young and incomplete. (eg. At minimum, I'm waiting for Diesel or Serde to grow schema migration support since all of my projects are data-centric in some way.) You'll be doing a lot of work reinventing things that you get for free in Python or Ruby.
Note on SQLite libs: I've been using Diesel pretty comfortably with a personal rouille project for it.
I thought he was saying something more like ``` match run_loop() { Ok(...) =&gt; println!("Yay!"), Err(e) =&gt; println!("Something went wrong. {:?}", e), } ``` Which means you can just return a Result instead of `break`ing from a loop or using a variable to track state.
The trouble is that you have declared the map with `Foo&lt;Bar&gt;`. So type inference for `insert_foo` deduces `T=Bar`, which causes both errors. It's expecting you to actually pass `Bar`, not something implementing `Bar`, but you pass `Baz`. But then you cannot pass `Bar` as a parameter with `bar: T` because all parameters must be sized and a trait is unsized. There are two possible solutions. One is to change your map's declared type from `Foo&lt;Bar&gt;` to `Foo&lt;Baz&gt;`. Another is to add boxing, [like this](https://is.gd/Jy8Pb2).
&gt; which shouldn't be too much longer, I think. Should be in 1.15.
It has, just like Serde, but it's not as convenient as it is on nightly.
It will be fully on stable in 1.15
Sorry. Didn't check the links and was running Linux. :/ (Have you filled an issue about Windows support?)
As I mentioned in the post the issue has been fixed for around 6 months now (and has an open PR), the maintainer just hasn't merged it (diesel transitively depends on libsqlite3-sys which shares the maintainer of rusqlite).
You need be able to get pan-terminal images working with [Sixels](https://en.wikipedia.org/wiki/Sixel). :)
Thank you for the explanation!
Even in python, I would prefer to use the break version.
There is this modern idea that the absence of commits implies a kind of death. There is no regression of functionality here (except for rare cases of version breaking). In fact, a package could be _finished_. For OSS to work, there has to be a move away from the idea of active developers and passive users. No money is involved, so there must be other things offered in exchange. PRs are great things to get, although even a clear bug report is invaluable. Documentation is an area where active users can participate. Good examples are very important, and come naturally from the development process itself. They just need to be cleaned up and committed. But there again, an active user can share their experience of learning something and contribute an examples PR
Neat. One thing I'm unclear on from the first read through - can you clone the sender or is it a Highlander?
Thanks, I'll try to work on this ( probably in the train haha ). Should I open up a new issue for this; or work off of [this one](https://github.com/rust-lang-nursery/rustup.rs/issues/750)? 
It's really much safer to use different types depending on the circumstances.
Seeing as how `Sender&lt;T&gt;: Clone where T: Serialize + Deserialize`, I assume it means that Senders will just block while they are sending if they have to buffer out to disk.
Is there any breakdown anywhere of what exactly the new macro system is? 
Oh I didn't say Rust did :) It's just that correctness goes far beyond handling memory allocation correctly (or doing without it).
I think it prohibits inlineing, so it can easily affect performance.
&gt; [Wait won't it fill up my disk?](https://github.com/postmates/hopper#wont-this-fill-up-my-disk) I don't quite understand how the mechanism described prevents the disk from filling up. It seems this only works if the Receiver is managing to cope up with the Sender's throughput; if it cannot cope up, then I would expect an unbounded growth of the disk space. --- Regarding the memory structure, you may want to buffer before sending to disk, that is: [-------------------|~~~~~~~~~~~~~~~~~~. . .~~~~~~~~~~~~~~~~~~~~~~~~|-------------------] 0 1024 4096 ... In short, you have either *one* or *two* pages in memory: one when everything is fluid, which grows to two when the queue is backed up a bit. This allows buffered writes to the disk.
Unless you're using it in perf sensitive applications, does it even really matter? If you're trying to maximize request throughput per second on a server I would understand, but I honestly don't think most people are writing code for such scenarios. It's the proverbial prensture optimization problem for most folks I think
Thank you for making me laugh! I enjoy having good mood.
Yes, trawling through processor data sheets is an acquired taste.
The probably most complete description is [the RFC itself](https://github.com/rust-lang/rfcs/blob/master/text/1681-macros-1.1.md)
Yes, `Box` is a special hard-coded exception. AFAIK, it was always (at least since 0.11 or so) the plan to get rid of this exception in favor of `DerefMove` or something similar, but this still didn't happen yet.
Great, finally a new part! But I'm running into problems [solved - see below]. I probably don't understand your explanation: At "Rustacean's first parser" you say to add a block of code, and I assume this should go into parser.rs. But when I try to build, I get the error that "alphanumeric" is an unresolved name. It does find nom, but not that particular function. The actual nom version is 2.0.1. No idea right now what could be wrong. EDIT: Need a "Use nom" at the top. You might want to mention that in the text. Also a little weird that Rust apparently can find and use the Nom macros without it, but not the function. 
Well, your specific error is definitively caused because of too many threads: http://unixwiz.net/techtips/not-enough-codes.html . More in dept information here: https://blogs.technet.microsoft.com/markrussinovich/2009/07/05/pushing-the-limits-of-windows-processes-and-threads/ . You can either change the parameters as per the link above, or change your application architecture to either a thread pool, an event loop, etc. Here's an overview of some i/o processing strategies related to winsock: https://tangentsoft.net/wskfaq/articles/io-strategies.html
The new photo can't have an id, because that will be given to it by the database. I suppose if the main `Photo` struct had an optional id then it could be used for both. This approach gives stronger compile-time guarantees about which photos have ids. 
Dude it's 6th on the list. Nothing to write home about. Language above Rust: swift, elm, ruby
- VSCode plus RustyCode - Eclipse plus RustDT If any of those aren't FLOSS, well, Stallman and my dentist have a common complaint.
- Emacs + evil mode + company + fly check + racer + rustfmt - Vim + rust.vim + racer +rustfmt For larger project I often prefer Emacs since static compilation check doesn't work in my Vim, and that check reduces lots of works.
vim + rust.vim + [tagbar](https://github.com/majutsushi/tagbar) + [vim-tmux](https://github.com/christoomey/vim-tmux-navigator) + rustfmt.
I'm using Emacs with the [spacemacs](http://spacemacs.org/) configuration. 
Vim with rust.vim.
&gt; In Rust, the `Result` enum can neatly separate the two, in similar vein to how ad-hoc tuples in Go do. Rust also has tuples; and `Result` is not a tuple. If we define `#X` as the cardinality of the set of values of type X, we see the difference pretty easily: - `#(A, B) = #A * #B` =&gt; a tuple is a Product Type - `#Result&lt;A, B&gt; = #A + #B` =&gt; an `enum` is a Sum Type where it matters is that if you have an error in a `Result`, you DO NOT have a dummy regular value along side it, and therefore you cannot accidentally use a dummy value because you forgot to check for the presence of error. And that's why it's infinitely better to use Sum Types than Product Types in this situation (unfortunately for gophers).
vim + rust.vim for light editing vscode + RustyCode for bigger projects Tried also the Atom plugin which is also quite good, but settled with vscode for now.
still, these safer extra types could be generated? I see nothing safer in typing those types "myself". 
Honestly, SPARK is the main reason I still consider Ada on new projects. As a language, I know I'm in the rare minority that I actually like Ada, but I can't deal with its dysfunctional ecosystem. The only reason I bothered at all is that Ada's FFI stuff is roughly on par Rust's which allows you to get around the issue if you don't mind binding everything to hell and back. Rust manages to have a lot of what I like about Ada (strong typing, intelligent pointer management) without being excessively annoying about it, and the borrow checker means handling pointers is a lot less of a chore than Ada in terms of sanity. What appealed to me about Rust and made me try it is that it's design paradigm basically allows you to live in a world where you only need to deal with pointers/access types in a very small minority of cases; it's perfectly possible to write a very large and complex program and never once have to touch to heap as a result. Ada had in/out modifiers on functions, and Rust has the borrow checker which goes a long way in migrating two of the most common cases of needing pointers in C world. Avoiding null pointers was what finally made me say "Rust is pretty damn awesome".
What was the problem with DerefMove? Something technical or just a lack of time/interest to discuss/implement it?
Well, if you're motivated to learn about how the system is working, you could use Rust. But if you want to be productive, use python et al. Being productive keeps that positive feedback loop going -- the euphoria when you see your code working.
IntelliJ's Rust plugin is coming along very well. It's on Github and actively being developed. 
Technically `Result` *is* a tuple (at an implementation level, anyway). Consider a `union Value { ok: Ok, error: Error }` (still a sum type). Then `Result&lt;Ok, Error&gt;` really is just a `(u8, Value)` (a product type), where `u8` is something pointing out which interpretation for the `Value` you ought to use.
/u/thejpster, it is possible to clone Senders, yes. The Senders and Receivers at present compete for an exclusive lock to get access. A single Sender is capable of doing writes and there are no reads while a write occurs. Like /u/furyhunter pointed out, Senders don't do asynchronous writes to disk. 
Ahh, so `diesel_codegen` like the `serde_codegen` approach, where one must create a build script and `in.rs` files? See: https://github.com/serde-rs/serde-rs.github.io/blob/master/src/codegen-stable.md
How would that work with a compiled language?
I don't know. Why does this matter whether a language is compiled or not?
&gt; As other people have mentioned, "Macros 1.1" is on its way to replace compiler plugins and will be stable Very Soon. Small nit: 1.1 is used to make custom `Derive` stable; the rest of compiler plugins are "Macros 2.0".
Ah that's my bad. I'll make sure to add it. So the reason you can have macros everywhere was because of the `#[macro_use]` at the root of the program. That's telling rust the macros are available everywhere and it sort of acts like an implicit use statement everywhere because you don't import macros like you do functions.
Mandatory watching to get the ideas _really_ flowing: https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript
This is a nice experiment, however I would strongly advise against using it in real-world code similar to the given example. In this case, compared to the idiomatic solution, the IIFE code is much more complicated, unidiomatic, and requires an external crate (`try_opt`). Is this: fn gist_owner_from_info_iife&lt;'i&gt;(info: &amp;'i Json) -&gt; &amp;'i str { || -&gt; Option&lt;&amp;'i str&gt; { let info = try_opt!(info.as_object()); let owner = try_opt!(info.get("owner").and_then(|o| o.as_object())); owner.get("login").and_then(|l| l.as_string()) }() .unwrap_or("anonymous") } Better than this? fn gist_owner_from_info_composition(info: &amp;Json) -&gt; &amp;str { info.as_object() .and_then(|info| info.get("owner")) .and_then(|o| o.as_object()) .and_then(|owner| owner.get("login")) .and_then(|l| l.as_string()) .unwrap_or("anonymous") } I think not. Unnecessary complexity should be avoided. All else being equal, a standard, idiomatic solution is better than a custom solution, especially when the problem is that simple.
Spacemacs works pretty well too once you've configured racer.
I realize this is beside the point, but this crate provides a method called [`find_path`](https://doc.rust-lang.org/rustc-serialize/rustc_serialize/json/enum.Json.html#method.find_path) that makes this even easier. fn gist_owner_from_info_composition(info: &amp;Json) -&gt; &amp;str { info.find_path(&amp;["owner", "login"]) .and_then(|login| login.as_string()) .unwrap_or("anonymous") }
&gt;Being productive keeps that positive feedback loop going -- the euphoria when you see your code working. Ah. Well put. That is in fact the reason why I believe going with python is the right choice for now (though I do want to learn rust later!). Lack of euphoria has been the cause for many a stagnation I have felt in the past. Thank you!
Well... Hmmm... So... Each time I run a cell is equivalent to fn main() { // lode variables from server. let mut data = deserialize("serialized output for data"); ... same for all variables in scope. // run code from cell println!(data.slow_prosses()); // reserialize a the variables from above. send_to_sever(&amp;data); ... same for all variables in scope. } That may work. 
Full ack. I still think that even with recursion detection, we should place a limit on actual recursion anyway.
VS Code with RustyCode. To be honest I use VSCode for everything, now that I switched away from Sublime Text and Visual Studio.
I have been following the Gnome Builder project. I try it from time to time. I think they even have a Flatpak for it. Does it have builtin support for Rust? I see more and more Rust related posts in Gnome Planet.
As someone who's ramping up in C++, thank you for this. Super helpful.
CSS customization is a bit of a pain, especially because the way they do UI is pretty weird. Atom uses flex, but VSC actually applies pixel widths/heights to views which is hard to get around. Other than that, yeah it's pretty sweet :)
They're quite alike, this article goes through the articles quite well: https://www.codementor.io/mattgoldspink/tutorials/best-text-editor-atom-sublime-vim-visual-studio-code-du10872i7
Great! I'm looking forward to it!
Yeah, all occurences of `var` in a javascript function are hoisted to the top of the function, as if there is only a single scope. E.g. function hello() { for (var i = 0 ; i &lt; 1 ; i++) { var x = "hello"; } console.log(x); // prints "hello" instead of "undefined" } Luckily newer versions of JS bring us `let`, which you can use instead of `var` and which functions as you would expect (obeying scopes), but sadly not all browsers support this (yet).
It's kind of unfortunate that all non-`error_chain` errors need this call to `chain_err()`. Does anyone know if there is any work being done in the standard library or the language proper to make the error handling story better? I think the macro part of this lib is great to reduce the boiler plate for custom error types, but even though I hate exceptions, I think the one thing they still have over Rust's model is context. Stack traces are invaluable to finding bugs. `RUST_BACKTRACE` helps, but not if the program doesn't crash entirely.
I used `let` here, still busted. The problem is that `i` is captured as a reference, rather than as a value. (Meanwhile, passing it to a function captures it as a value. Oh JavaScript.)
/r/playrust is the game, this subreddit is about the programming language.
Replying to my own post, this did half the trick: let deserialized = serde_xml::from_str::&lt;Point&gt;(&amp;buffer); match deserialized { Ok(p) =&gt;{ println!(" P {:?}\n",p); }, Err(e) =&gt; { println!("ERROR {:?}", e);}, } Now I just have to get to a place where multiple XML object types can come in at that point and be processed. 
NeoVim + racer with youcompleteme + neomake (using cargo-check for faster builds).
I'm going to assume you meant to post this in /r/playrust?
For that specific JSON case, this is where I'm glad `serde_json` has a `lookup` method, so you can do `obj.lookup("owner.login")`
It supports code highlightning and auto-completition but nothing more than that. There was an experiment with rust language server to provide more introspection but it was put on hold until RLS matures a bit. EDIT: There is a nightly Flatpak of Gnome Builder, beside the stable one.
Patches gladly accepted!
I just tried your code, and I did get the expected behavior. I don't get what's fundamentally different between my code and yours.
I was thinking about numerical code, not about servers. I think it matters there, maybe it is not what most people are writing though. On the other hand, if you are using Rust, you probably care about performance.
Well, from my perspective, a significant part of the RFC was that we be able to annotate code *before* 1.0 so we didn't end up with a pile of un-annotated code floating around forever. You can't "postpone" *that*, so in a sense, the situation I was worried about has already happened. To put it another way: I wanted to stop the fire from happening in the first place, now we're talking about putting it out after it's already burned some stuff. (**Edit**: for balance, I should point out that this was already *sort of* a problem with pre-1.0 code. To me, this was less of an issue due to the "not ready yet" nature of Rust having likely kept away a lot of people.) But I understand the reasons it was rejected. The core team *does not* have infinite time or resources and things need to be prioritised. *I get that.* I don't blame the team for rejecting it, or think it was *necessarily* the wrong decision on their part. ... but that doesn't change that I feel I was *right* about this becoming a problem, and now we have to deal with in a harder way than if we'd dealt with it earlier. As for my moping, I'd be moping about this even if I *hadn't* written the RFC. Having code break on you isn't fun.
Copy a block of code that's indented three levels, now paste it at a new section where it will only be indented one level. Atom automatically corrects the indentation, VSC does not. Additionally, I've had a much better experience with clippy linting on Atom compared to VSC. Multi-edit in Atom is also cap-specific.
+1 for the team here. Really almost feels like it was designed for Rust.
What did you have on mind for fsts? They are a rather specialized data structure.
/r/rust != /r/playrust/
This series is incredible. ❤ 
Nope, Wind River's VxWorks. Which no longer has SPARCv8 support, except we apply a monkey-patch to it to get there. Though we do ship RTLinux at times, and I assume that goes on SPARC too. Apparently a lot of the rad-hard chips are repurposed SPARCs. I hear certain ARMs are starting to get in play, but I will likely never see anything in the x86 family. Personally I'd like most to be running on a hardened MIPS core, since the support is already there is rustc and LLVM, plus I can reason about MIPS behavior pretty well. Japaric has a PR on my behalf turning on SPARC support. So far it has only taught us about compiler bugs:/ Re: performance; I'm presently working on device drivers. I shouldn't have any room for optimizations; the hardest work I'll be doing is DMA-assisted memcpy of a kilobyte at a time. No dynamic dispatch, no weird behavior, just simple bit banging and a multiplexer.
One of my goals is to have the [same configuration](https://github.com/lilred/dotfiles) on all my machines... :/
How much overhead does use of error_chain add over raw Result? Is error_chain appropriate for all projects?
Sets mainly. IIRC Erlang's sets (and hashmap pre-introduction of maps?) are backed by lists that require linear traversal
Thanks for the continued great work! Eventually I would love to see something like Julia's [http://statsbasejl.readthedocs.io/en/latest/](StatsBase) repository with helpful base utilities like sampling, sample covariance, etc available in Rust. They also have really liberal licensing (MIT) for porting efforts.
Shameless plug: You can use [raster](https://docs.rs/raster/0.0.7/raster/). Its an image processing lib (crate) that I am developing. You can do your Bresenham line by setting pixels individually then save it as a PNG image. Here's how to get going: 1. In rust you start by building a binary using cargo: cargo new bresenham --bin 2. Modify the generated Cargo.toml and add raster as dependency: [dependencies] raster = "0.0.7" 3. Then in your main.rs include the crate: extern crate raster; fn main() { } 4. You can create a blank image and set a pixel and save it as PNG (for best quality, JPEG can have artifacts): extern crate raster; use raster::Image; use raster::Color; fn main(){ let mut canvas = Image::blank(200, 100); // Mutable 200x100 image with black background canvas.set_pixel(10, 10, Color::rgba(255, 0, 0, 255)).unwrap(); // Set pixel at 10, 10 to red raster::save(&amp;canvas, "tests/out/test_tmp.png"); // Save } 5. Then cargo run to run your binary and check your generated image. --- For Bresenham wikipedia has a [good article](https://en.wikipedia.org/wiki/Bresenham's_line_algorithm) with pseudo code. There's also [Xiaolin_Wu's](https://en.wikipedia.org/wiki/Xiaolin_Wu%27s_line_algorithm) algo if you want anti-aliased lines. 
You're right. I think I will give it a slight clean up then release it :)
Still reading through tutorials trying to learn rust and thinking about a starting project like a small game or something like that.
I think this is more readable. fn compare2&lt;A: Ord&gt;(v: &amp;A, l: &amp;A, r: &amp;A) -&gt; Ordering2 { match (v.cmp(&amp;l), v.cmp(&amp;r)) { (Less, _) =&gt; LTLeft, (Equal, _) =&gt; EQLeft, (Greater, Less) =&gt; Between, (Greater, Equal) =&gt; EQRight, (Greater, Greater) =&gt; GTRight } } BTW, as far as I remember, 2-3 trees don't need `Rc`. `Box` should be enough. (I might be mistaken.)
For this kind of experiment, it's fine to put it in `main()`.
You can also use tmux commands or keybindings to send your prefix into the inner tmux session. It just takes more keystrokes, but it's not really difficult or problematic.
GEdit. 
Hm really nice, that looks like exactly what i need! Tbh, the other solutions in SDL/GL like creating a texture/surface and rendering that onto a plane sound like too much overhead and the idea of writing a software renderer for a texture that is then rendered in OpenGL is kind of ridiculous anyway ;) I will try your crate (thanks a lot for the example code) and let you know how it goes!
&gt;After finishing up the most recent of my Scheme interpreter posts I'll be taking it easy this week with finals and the holidays coming up I missed the previous posts of this, but I think I will be reading your previous articles on the matter. Is there also an RSS feed of these (or all your articles) to keep an eye on future Scheme posts? Unsolicited suggestion: the bright blue background for inline code in your articles is kind of distracting and gives more importance to those parts than is warranted.
Compare [Rust thread on GameDev.net two years ago](https://www.reddit.com/r/rust/comments/2q1uew/thoughts_on_rust/). How time changed.
Fine, that makes sense. I don't think it's unsalvageable. If we introduce a compatible version(s) badge, crates without that will be the abandoned ones, really. It's good that they are visible that way; and sort towards the bottom.
What exactly are you trying to accomplish?
Rust Enhanced from http://github.com/rust-lang/sublime-text
Glad to help! I'm a rust newbie myself so I built this crate to learn (and still learning) rust . Feel free to ask me questions about the crate. For rust related questions, you can head over to the [ask questions thread](https://www.reddit.com/r/rust/comments/5j4nlt/hey_rustaceans_got_an_easy_question_ask_here/). The rust folks are always friendly and helpful. 
I'm planning to implement the basics of character movement on my voxel world. The last little while has been on [relatively boring housekeeping](https://www.reddit.com/r/rust/comments/5j63vn/these_weeks_in_planetkit_5_finding_structure/) bits and bobs.
&gt; I have a small wish. Maybe you could create a small release.exe for those who are at work and don't have rust installed to compile the project. Also thanks for getting me some insight how some things work in rust that i didn't got through the tutorials i read.
I added an example in the EDIT. I hope it's clearer. I can show code on how I handle the closures, but my design is not quite good...
Is there any reason you can't put these `FnMut` instances inside a `Box`?
Thank you for your explanation. I added an example of the API in the EDIT.
I'd love to see the [mcmc hammer](http://dan.iel.fm/emcee/current/) implomented for rust. I've bean thinking of how to do it, and I think it is possible, but have not tried yet.
Working on handlebars decorator support: https://github.com/sunng87/handlebars-rust/issues/102
Emacs + evil mode + company + fly check + racer + rustfmt. I highly recommend this setup, Emacs is an amazing editor, especially combined with the power of Vim editing with Evil mode.
&gt; TIL that JavaScript is even more evil than I thought. It's not really javascript here, any language which allows *closing over mutable bindings* may trigger that problem, although semantic details or "best practices" may change how likely it is to hit the issue. You can hit this problem in Python: &gt;&gt;&gt; arr = [] &gt;&gt;&gt; for i in range(10): ... arr.append(lambda: i) ... &gt;&gt;&gt; arr[2]() 9 or ruby: &gt;&gt; arr = [] =&gt; [] &gt;&gt; for i in 0..9 &gt;&gt; arr.push(lambda { i }) &gt;&gt; end =&gt; 0..9 &gt;&gt; arr[2][] =&gt; 9 or in languages like C# or Swift though it's more difficult as their scoping of regular iteration loops is "tighter", so loop-based demos look very artificial: var arr: [() -&gt; Int] = [] var i = 0 while i &lt; 10 { arr.append({i}) i += 1 } print(arr[2]()) =&gt; 10 but you may also have a regular binding which you update for "efficiency purpose" or whatever and if the code is complex enough it might be hard to notice e.g. func thing() -&gt; Int { 42 } var arr : [() -&gt; Int] = [] var i = 0 arr.append({i}) i += 2 arr.append({i}) i = thing() arr.append({i}) print(arr[1]()) =&gt; 42 It is common to hit it in JS due to its scoping details and how common first-class functions are, but it's by no means unique to it. And IIFE are (amongst other things) If you want JS evil, how `this` is handled (in non-scrict code) is no question asked.
That's interesting. All I've ever learned about closures made me believe that pass-by-value types would be captured in their current states, rather than mutably.
Just got off from college, so I've got half-term now. Basically just working on my Rust projects, and rebuilding a lot of my computer systems with Arch, and revamping my development workflow. Fun times ahead. 
It's common for the lexical context itself to be captured, which implicitly captures the references it contains mutably. Incidentally, some languages tack on additional semantics making the whole thing even weirder e.g. in Go i := 0 defer fmt.Println(i) i = 1 defer fmt.Println(i) will print `1` then `0` but i := 0 defer func () { fmt.Println(i) }() i = 1 defer func () { fmt.Println(i) }() will print `1` and `1`, because `defer` only defers the "outer" function call, fully evaluating the rest of the expression so in the former case it evaluates the `i` at defer site, in the latter it only evaluates the anonymous functions but their bodies are evaluated during deferral, and they capture a reference to their context, meaning i := 0 defer func () { fmt.Println(i) }() i = 1 defer func () { i = 42 }() will print `42`.
I've started a jupyter kernel for Rust, but haven't had a lot of time to work on it, and I'm still working on the messaging protocol, haven't gotten to the fun parts yet :) https://github.com/pwoolcoc/jupyter-rs
i did ([ref](https://github.com/mackwic/rspec/blob/master/src/context.rs#L219)), which makes me able to move a unique reference, but I have issues to move it around. Most probably because of its `'static` lifetime (and my poor fluency in borrowck sheningans).
Thank you for posting this! &lt;3 I didn't want to spam the sub by posting every video, we might do a few more, so subscribe to our channel if you want to know for sure when we post new ones :)
Me too. GEdit is a nice lightweight non-vim, non-Emacs editor that works out of the box on Debian Unstable :-)
What exactly changed? In the current thread they seem to be mostly talking about other languages. Some guy even proposed to write a game engine in object-oriented COBOL.
I've been working on writing a layout engine for the Windows portion of a native GUI library, and I'm hoping to get that finished this week. Additionally, I'm going to try to finish a RFC for literal`&amp;'static CStr`s that I started and never got around to finishing.
Not even preallocating the string to right size? Not using iterators? Sheesh. use std::iter; pub fn left_pad(s: &amp;str, pad: usize) -&gt; String { left_pad_char(s, pad, ' ') } pub fn left_pad_char(s: &amp;str, pad: usize, padchar: char) -&gt; String { if s.len() &gt;= pad { String::from(s) } else { iter::repeat(padchar).take(pad - s.len()).chain(s.chars()).collect() } }
Well... format!("{: &gt;20}", "pad me"); but where's the fun in that?
Why does `Context` have a lifetime? I think your program would be easier if `Context` didn't have a lifetime, and only stores `F: 'static + Send + Sync + FnMut() -&gt; T`.
I expect that given the proposed shared distributed compiler cache that this will and should actually happen. Think if we could get an incremental compiler that can check every commit for all time and run that in both directions across a set of compiler versions. Right now I test on 1.3 and 1.9 because that is what Debian and Ubuntu ship with.
The 'lock' file should have the version and commit hash of the compiler and tools that successfully built and tested the code.
It doesn't have all those modern bells and whistles of the modern IDEs but it's enough, if you just know your own code. GEdit is an elegant combination of simplicity and efficiency. 
I don't think it is quite right to say that all APIs that use `Result` should have "rare" `Err`s. In some applications, errors at some layer of the API may be frequent. What I'm hearing is that in those cases it makes sense to use raw `Result`, which hopefully works well in conjunction with `error_chain`.
&gt; Even trivial information like the size of the object is not available. If it isn't, what does [size_of_val](https://doc.rust-lang.org/std/mem/fn.size_of_val.html) do? I thought it did exactly that.
Just learned from /u/neutralinostar in irc that this is indeed a feature named `item_like_imports` that has just stabilized! [RFC](https://github.com/rust-lang/rfcs/blob/1f5d3a9512ba08390a2226aa71a5fe9e277954fb/text/1560-name-resolution.md)
Oops, my mistake. Will fix shortly. Edit: fixed. Thank you for bringing it to my attention.
"General" and "systems" languages are not exclusive! Rust is also a good general-purpose language, and people do all kinds of goofy non-"systems" things with it. Now, the area it's especially good at is things where performance and especially memory handling are important, so you could try to find something like that. But really, anything you write in Rust will get you started thinking "rustfully".
If only Geany had support for multi-cursors like Sublime/Atom/VSC. That's the killer feature that I require from an IDE.
I like the AsRef trick, I haven't seen that one before somehow. I'm not sure using a Cow is worthwhile, since the only case in which it would help is when left_pad doesn't need to pad, which is already almost always going to be considered an error by the user. I guess it doesn't hurt except maybe usability (assuming clever inlining) and shows off a cool feature. `repeat`, `take`, `chain` and `chars` all implement a useful `size_hint`, and so the `collect` should preallocate the buffer correctly. The whole point of my example was to demo how a clean functional version can still be pretty optimal. :D
To help me learn Rust, last week I started writing a BASIC interpreter. I made progress, got it so it could evaluate simple code. See the GIF with [this Tweet](https://twitter.com/travisbhartwell/status/810298331020886017). I've started implementing [Dijkstra's Shunting Yard Algorithm](https://en.wikipedia.org/wiki/Shunting-yard_algorithm) as an evaluation strategy for expressions. But, I've ran into the barrier of not really understanding ownership and borrowing and running into immutable vs mutable borrow issues. Still working through that. If you're interested, my working code is at [my github repo](https://github.com/travisbhartwell/rbasic). I'd appreciate any suggestions for improvements, as this is my first Rust code and I'm sure it's not very idiomatic.
I use Brackets with the Rust for Brackets plug in for syntax highlighting. There's also a Rust IDE plug in, which apparently also has autocompletion, linting, and quick highlighting. I might try it out later, but I like to avoid such things when I'm learning a new language because I find the repetitive typing helps me remember patterns.
Hope you keep doing more of these, they are so great. It was a shame about the one episode with recording issues since it made it rather impossible to watch. As a semi-beginner I feel like I already learnt a lot from these two videos, with a lot of these aha moments "oh nice you can do it like that", "ooh that's so smart" etc. Making me go back to my toy project and fixing things and making it fractionally better with the small improvements. I really love how if I had looked at the problem and your solution with no context, my immediate reaction would probably be like "wow this looks so hard, I would never have thought of doing it like this", but watching you work through it makes it all seems so easy and obvious, and the feeling of "I could totally do that". You show how thinking about a problem is a big part of solving it in a smart manner.
Saw this issue: https://github.com/sfackler/rust-postgres-macros/issues/28 As an exercise to familiarize myself with ffi in rust, I created a barebone wrapper around [libpg_query](https://github.com/lfittl/libpg_query): https://github.com/dashed/pg_query_parser Still a work in progress.
I just played the game without looking at the tutorial, and it was quite fun, although it took me a while to figure out what was going on. Just a couple of ideas: * There are a lot of pages in memory, however only the first couple of bytes of the first page are used. Although it is realistic to have all the pages, I think it would be much less confusing if only memory was smaller. * While I find the idea of running the game inside a terminal emulator interesting, this does have its issues. For example, I kept pressing `^C` to clear what I was typing, causing the game to quit. For a more polished game a proprietary interface would probably be better, and more accessible * I personally think a having multiple sections on screen, making code, memory and registers visible at once, would be more player-friendly, although this might not be what you are aiming for. That being said, great job on this. Im really interested in seeing where you take the project from here.
1. Thinking about memory locations. In Java, everything is effectively pass by reference, and probably somewhere on the heap. In Rust, data can be fully allocated in the stack-frame, or on the heap, or can be a reference to one of the above. Things like passing an existing mutable buffer to a method instead of having the method just create an object can be relevant to squeeze that last bit of performance out. 2. Thinking about lifetimes. In languages like Java, some objects have explicit lifetimes through mechanisms like "try-with-resources", which close and finalize resources. In a non-GC, every piece of memory is like this, and will be cleaned up at the end of scope, unless you move it elsewhere and transfer that responsibility to another scope/function. During the lifetime of the resource, you will pass out references to it, but all these borrows must end before you deallocate. The compiler won't let you mess it up, but until you internalize this idea, you might run into errors. 3. Thinking with Traits. Its like interfaces in Java, so I don't think it will be too hard, and you should pick it up doing other things. A major difference is that the implementation of a trait can be implemented outside the object itself, and can be implemented conditionally ("Optional&lt;T&gt; can be formatted to a string iff T can be formatted to a string"). The biggest improvement is that you can require a parameter implements multiple Traits. 4. Thinking with Enums. Sometimes can replace inheritance, but it definitely makes you think about data different then inheritance. On one hand, you can't easily add new options. On the other hand, you can guarantee that all possible options are handled. 5. Thinking in modules, functions, traits, and data. Classes munge all these things together. Implementation hiding is different, and in many cases, the internals of data should actually be exposed. Pattern matching &gt; getters and setters. 6. Error handling with results instead of exceptions. Looking at this list I made off the top of my head... maybe a project like this: read a file containing a math expression, parse it, and print the result. Write the parser as one module, and the solver as another. Try to use low level file reading interfaces. That should cover most of it? 
&gt; and web applications once Rust 1.14 releases in a few days. You may want to clarify this a bit. I assume you mean something like the Emscripten support will be available in 1.14? As currently written, it looks like you are saying "Once 1.14 is available, you can write OS, games, etc...". If that's the case, you may also want to say "applications that run in the browser / are executed by a JS VM", to avoid confusing it with a microservice or other backend server. &gt; if you set your toolchain to Nightly, cargo install clippy, and set up your IDE to use clippy for linting With rustup, you can compile with stable, and lint using nightly with `rustup use nightly cargo clippy`.
Thanks for replying! Did not read the readme, my bad. Also if there's room for feature requests: the inverse gamma distribution is very useful for Bayesian Inference since it's the conjugate prior for the variance of a Gaussian!
I think impl specialization helps. When will it land stable? 
I feel like I'm missing something. What is the goal - what problem exactly are you solving and why you use blockchain etc to solve it? I've decent understanding of Bitcoin, decentralized system etc but I can't wrap my had around this. Maybe I'm just too tired...
My `tr` doesn't have `-u`. What does it do? Unbuffers?
Yeah. Now that's impressive: A feature in BSD `tr` (via macOS) that is not in GNU `tr`!
I'm glad you think so! Let me know how you go with this first training level :)
This is great - thanks so much for the feedback! I agree that having all 64k of memory available can seem a bit daunting ... especially in this simple proof-of-concept level that, as you said, only uses the first 8 bytes of memory. In future, for more complicated levels, I was planning on having "technical documentation" documents available for the environment the player will be hacking in. As a simple example, I have an idea where the player will be required to hack a digital keypad to open a door. Some "technical documentation" for the model of keypad the player will be hacking will be made available as part of the release (documentation written by me.. the keypad won't be based on a real keypad). The idea being that the documentation can give details on any IO ports, memory regions used, etc, without giving too much away on how to pass the level. RE the terminal: I know, I agree entirely. I work with Windows at work and I use my lunch breaks to hack on side projects like this. I couldn't find a nice cross-platform terminal crate that let me handle things like arrow keys/history navigation, capture ^C, etc. If you're aware of one I would be most grateful and will certainly port this to that :) Otherwise, you're right - I'll need to roll my own or something to give a better experience on the command line. Thanks! RE multiple sections. I also considered this - but my choice RE the terminal above limited my screen space. I think, ideally - and I think this is what you're getting at - the game is full screen, with not only its own in-built terminal but also other debug views around that the player can see. I will take all of this on board. As I said this was a proof of concept. I am so very very happy that you decided to play it from start to finish without the tutorial. Hopefully you got the sense that you did manage to hack the game :) Thanks again!
Ya, there's a game that didn't "sandbox" the environment like you did and it caused overall instability and is the main reason I didn't end up purchasing it. Can't recall the name now though.. 
But you *have* included it in your project if you've included babel. And plenty of people did include left-pad in their project before The Incident; not many people audit the dependencies of their dependencies-- they trust their dependencies' judgment.
Does that mean if I accidentally delete a Cargo.lock referencing a yanked crate with no unyanked usable versions, I can't ever regenerate it and get my code building again?
&gt; not many people audit the dependencies of their dependencies Which is why I think raw download numbers isn't a particularly good metric in the context of deciding which crate to use.
Of course, I'll mark it as a priority for the next version!
Congrats!
Ruru is for MRI, mrusty is for mruby. Unifying them would be Very Hard, unfortunately.
And &gt; they trust their dependencies' judgment. is why i think raw download numbers is a perfectly acceptable metric to use, so I suppose we'll have to agree to disagree here :)
The command `cargo run --example main` will run the example named `examples/main.rs`.
OP will also a way to compose a "child"-struct containing data from a "parent"-struct. The comments in the following reddit thread contains some advice. https://www.reddit.com/r/rust/comments/4kk5ir/composition_vs_inheritance_in_rust_tutorials/ EDIT: This link might be better (The last half is in rust) http://joshldavis.com/2013/06/16/the-rise-of-the-gang-of-four-with-rust/
Maybe we could grant the top 100 or so hard-working rustaceans (top contributors to rust, cargo, servo and popular libraries) and let them vote on top libraries?
And when you run "cargo test", all examples are compiled.
One other thing: if you need a dependency for an example, but not for your crate, you can make it a dev-dependency so that you don't make users download the extra crates.
The very basic advice I think is that if you are writing a library where users need to extend/subclass then you would use traits in rust. If it's an application (where all the subclasses are known) then you use rust enums instead. 
I hadn't even thought about the value of writing custom Iterators. Is that covered in the rustinomicon or elsewhere? Coming from C, I know there are a lot of things to consider about the underlying implementation of language constructs when trying to write performant code. (Cache, data indirections, read vs compute time, etc.) but I still haven't intuited all aspects of rust yet.
I think the problem can be divided even further - let's start with an unsafe intrinsic, re-exported through e g `core::ptr`: #[inline(always)] // having a stack frame here would be very bad! fn stack_reserve&lt;T&gt;(count: usize) -&gt; *mut T { /* ... */ } ...giving uninitialized memory back. That should unblock most people needing alloca. Then, how to make safe abstractions around that function is important, but a separate/followup problem. Does that make sense?
Examples are compiled, but not run.
Thanks for your suggestion. Yeah I think making them the same of indentation is clearer. In this case I wanted to create a persistent 2-3 tree, so older versions of the tree remain available. If we want instead trees that destructively update themselves I think Box should be good too. I'm going to try that variant out soon. 
Your comment here https://www.reddit.com/r/rust/comments/4kk5ir/comment/d3fjpr9 helps out a lot too, thank you! The "Kind" enum makes a lot of sense for different use cases where a lot of functionality is shared.
Many people are fine with just `#[test]` and `cargo test`; see the [Testing chapter of the book](https://doc.rust-lang.org/book/testing.html) for details. They are simple and lightweight, and you can reduce boilerplate simply by factoring out common code into functions. However, if you want an rspec style framework there's [stainless](https://github.com/reem/stainless), which requires a nightly compiler as it relies on a syntax extension, or it looks like there's also a Rust [rspec](https://github.com/mackwic/rspec) which is just a little more cumbersome to use due to using closures and an explicit `ctx` argument that you have to call everything on, but doesn't require using a nightly compiler.
My tr doesn't have -u option. All other tools I tried flushed buffers when they had \n in input stream but not when inserted into output stream.
I'm not sure I agree. If crate X depends on crate Y, seeing lots of people use crate X does not, I think, give much credence to crate Y. If crate Y was so useful, it would have been depended on directly. In fact, it's very possible that Y is low level and very difficult to use and crate X is a nice wrapper that is much easier to use. You want to value those useful higher level abstractions. So, no, just because regex use aho-corasick doesn't mean I should consider it. If lots of people use it directly (i.e. use the API, have trawled through the examples and built something that works), then I should.
Expression `return EXPR` has a type of `!` and therefore behaves like any expression with uninhabited type. You could replace all `return ()` in your examples with `boom()` where `fn boom() -&gt; ! { loop {} }` for the same behaviour. Dead code lint is based on how `!` is handled, not the other way around. If anything, I’d expect `let _: u8 = { return (); "hello" };` to just work. 
That's legacy. When I wrote it, I couldn't predict it would be a 'static. Now, I know, and I want to take the best of it in a refactoring. Thanks for the tip, will do. 
So; I wrote something I *think* is a safe abstraction around the `stack_reserve` function, feel free to poke holes in it: [gist](https://gist.github.com/diwic/42f5eb598389fa4546f0ea857147086e) Edit: As a summary, the safe abstraction does not need additional compiler features but relies only on 1) ~~self-~~borrowing as a method of making something unable to move in memory (and thus, it cannot be returned from a function either) and 2) a macro that hides the variable that is being self-borrowed. Edit 2: Updated the gist a few times; removed playground link in order not to have to update both
Servo has a bluetooth manager? Am I missing something? What is the connection between Servo and bluetooth?
There's a bluetooth web API: https://developer.mozilla.org/en-US/docs/Web/API/Web_Bluetooth_API
Here
&gt; I don't know the Option::take trick, is it equivalent to mem::replace(opt, None) ? [Yes, exactly](https://doc.rust-lang.org/src/core/up/src/libcore/option.rs.html#654). :-)
[removed]
There!
Is there a guide/documentation on how to write macros 1.1 (using syn/quote I guess?)? I'm looking at serde/diesel implementations but would be easier with some docs
Question: aren't all of these constructs safe only on the premise that stack probes work? I'm in impression that LLVM doesn't still support them, although there has been effort to merge a support for them. Can we expect to have stack probes in the near future?
&gt; The biggest improvement is that you can require a parameter implements multiple Traits. For the record, [Java can do this too](http://self-learning-java-tutorial.blogspot.com/2014/03/generics-multiple-bounds.html?m=1) (although only in some places, and wonkily).
I don't think the maintenance category is thought out very well. If I were the peresil developer I'd just do 10 really small releases and that would apparently mean I maintain it really well. Besides some crates might be very stable and not need maintaining as much. I'd remove that category really. It's useful information to know but I can't see a good way to automatically calculate it, especially one that isn't hilariously open to gaming.
&gt; `!` (the *never* type) FTFY. Empty/Unit is `()`.
Unfortunately I don't think termion supports Windows :( Ideally I can include Windows users in whatever solution I come up with. Thanks for the suggestion though! I appreciate it!
Agreed – on the other hand, there's no way we can make a function to create an *array* from an iterator.
Wanted to second this.
Thanks. 
EU here. I think it's more an F has preconceived connotations. An F looks awful, whereas a 50% crate probably wouldn't be awful. Emojis aren't my preferred way either. Crates should just use the raw % and maybe hide scores under 50% to prevent toxicity.
Been work on on a port of the QSerialPort library from Qt. I've used it successfully in the past for various C++ projects and I've found the interface of serial-rs complicated and lacking features. I plan to release it this week but it needs some more testing. You can follow the repo for now until I do: gitlab.com/Susurrus/serialport-rs
No. You just can't publish *new* versions of your crate that depend on a yanked crate.
Aren't they too busy working on Rust code to vote on libraries too? ;) I'm trying not to make the ranking system reliant on people doing work.
I use [kakoune](http://kakoune.org/) text editor . It doesn't have racer support, but does come with Rust syntax highlighting. I just really like the way editing works in it.
If two crates are about equally good, and another, very popular crate arbitrarily chooses to use one of them, the two will misleadingly get ranked very differently.
Could one perhaps subtract the number of regex downloads from the number of aho-corasick downloads to get a better figure for aho-corasick?
Haskell uses exactly the same notation as set-notation that was taught to us in school when I was 12. I found it easy to go from { x^2 | 1 &lt; x &lt; 6, x € L } To [ x*x | x &lt;- lst, 1 &lt; x &amp;&amp; x &lt; 6 ] To [ x**2 for x in lst if 1 &lt; x and x &lt; 6 ] Overall though, if we're talking about syntactic sugar for working on iterables, I think LINQ provides the best fit from lst where 1 &lt; x &amp;&amp; x &lt; 6 select x*x Since such a syntax could be made to work with all iterables and collections. In Microsoft's case compiler plugins extend this to databases (where it builds up SQL queries) and XML documents. In Rust's case, you would have to use macros in the database usecase to be able to convert the where clause code to SQL. 
C/C++ are terrible languages for writing compilers. It's just that C has this magical set of tools that, 99% of the time, is more than enough for writing a compiler: Lex and YACC, or more modern: Flex and Bison. Rust and Haskell are awesome, but there's something magical about a tool that does the heavy lifting for you.
Does this mean that zenity doesn't (never used it before) doesn't deal correctly with `\r` and giving it a new line on each update will result in the desired effect?
Let's hope we can continue to keep divisive and dismissive voices out and maintain a reasonably welcoming and healthy community when it comes to communication. There has been some fallout pre-1.0 with people leaving over disagreements on certain decisions and if we exclude the recent told-you-so by one contributor regarding cargo here on reddit, it's fair to say that the Rust communication channels are pretty much a civilized place by internet standards. This is definitely an achievement, and it's a surprise elitism hasn't happened yet.
More seriously: you say you want to compile *to* Javascript, but from what? If the source language has an existing implementation and is Turing-complete, why not use it? If it doesn't (but is Turing-complete), why not simply write a first throwaway compiler in a language close to the one you're designing, then port this initial compiler to this language? If you're intending this as an exercise, [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(compilers\)) your compiler is an excellent, although ambitious, exercise. If you're intending your compiler to be something beyond an exercise, a self-compiling compiler may be a great proof of concept. Edit: fixing link.
I didn't say we were adding a new named lifetime. You have to add a new named lifetime to the language to design the safe abstraction, which isn't really worth it.
I don't see where you're using self-borrowing there, but yeah, that does seem correct. Not sure how it behaves with optimization.
I've been trying to write a library to plot some basic charts, [here's](http://imgur.com/6pUf7gx) what it looks like so far. Currently it only supports SDL2 but hopefully it should be easy to extend it to some other graphics libraries. I would love any feedback this is the first library I've tried to design in rust, I've kind of been fighting the borrow checker and just getting it to compile instead of thinking the lifetimes through thoroughly it seems like a bit of a mess at the moment as well. Error handling for the Canvas trait is the main thing I'm thinking of changing at the moment. [Github repo](https://github.com/Tohie/chartrs).
You can use `vec![s1, s2]` [like this](https://is.gd/JHXNxO). It will allocate a new vector though.
you can use `for x in &amp;[s1, s2]` to avoid allocating.
Right, just as I suspected. Don't you have to redirect stderr to stdout before piping it to rmcr?
I didn't see this mentioned anywhere else in this thread, but I think [hamcrest](https://github.com/carllerche/hamcrest-rust) should get a mention. It is used pretty extensively in `cargo`'s own test suide, IIRC.
so cool! =)
&gt; Can we expect to have stack probes in the near future? https://news.ycombinator.com/item?id=13179399
How is this different than /u/paulduncanidaho solution of using `&amp;[s1, s2]`? Is this using more memory?
You're right. Implementing it yourself is hard if you've not parallelized data structures before ( I know I haven't and looking at Rayon, sheesh). If you get it into a standard library structure and call `par_iter`it should work fine. 
I've looked into rayon for ndarray recently and I can point out the easy case for implementing the parallel iterator traits at least! Make sure your iterator or iterable is: - Send + Sync as appropriate - ExactSizeIterator - Implements `.split_at(index: usize) -&gt; (Self, Self)` If your iterator or iterable has implemented all of these, adding the parallel iterator traits is pure boilerplate (using the existing facilities). Use a wrapper type around the iterator or view and implement [them like this](https://github.com/bluss/rust-ndarray/blob/ea304e6fec1ffbe520f53b5fe693e87be3c85129/src/iterators/par.rs).
I'm actually not sure if either will allocate memory - LLVM will probably optimize it away. But my option is probably less idiomatic.
Well I'll be. I learned me something new today. Thanks!
`&amp;[s1, s2]` will use a stack-allocated "slice" (array), whereas `vec![s1, s2]` will use a heap-allocated "vector", which is a growable array. It's generally better to use the former if you know you have a constant-size array, because stack-allocated elements are faster to access.
I kind of feel like that's duplicating GitHub (gitlab, etc.) Stars and Developer follows. I'd personally not enjoy having to star *and* like a crate. Plus does that mean all the repos I've already starred I'd then have to go through crates.io and "like" them too?
LLVM generally can't remove allocations, since it's considered a side effect. There might be some kind of magic annotation you can tell LLVM about, but that would require rustc to analyze and make sure the Vec doesn't escape the current stack frame.
Credits go also to Simon Sapins experiments with "Rust forest". :)
It's not covered in any tutorials that I'm aware of. Basically, it looks like this: struct IteratableStruct { data: InputData, index: usize, // if needed } impl Iterator for IterableStruct { type Item = OutputType; fn next(&amp;mut self) -&gt; Option&lt;OutputType&gt; { if has item then return Some(OutputType) None } } Essentially, you create a structure that will hold the data that value(s) will be generated from. It could even be an Iterator type itself. Then you just write the `next()` method that will return either `Some(value)` or `None` to signify that the Iterator has been exhausted. There's also more than one Iterator type so you can choose which one you want to implement. The API documentation shows you which methods are required to be implemented, so all you need to do is implement those methods. For seeing it in practice, I've been solving all the [Advent of Code 2016](https://github.com/mmstick/advent_of_code_2016/tree/master/src) challenges with custom Iterators when possible. I've [also](https://github.com/redox-os/ion/blob/master/src/shell_expand/words.rs) [implemented](https://github.com/redox-os/ion/blob/master/src/shell_expand/variables.rs) it in a [handful](https://github.com/redox-os/ion/blob/master/src/peg.rs#L117) of [applications](https://github.com/mmstick/parallel/blob/master/src/input_iterator/mod.rs).
I think that the feature of having weighted "likes" from users your "trust", makes it completely different that GitHub stars. GitHub stars from the anonymous masses that star everything that's currently hyped mean little to me. On the contrary, I would almost blindly trust the judgment of a few selected developers.
Not trying to be a wise-ass, but prioritizing it over other, standarized and widely used parts of the web is... interesting. Maybe this module is a candidate to become a part of firefox?
I believe that they wrote it.
The result is negative
I know it's not what you asked, but F# and OCaml are fantastic at writing compilers. The first version of the Rust compiler was written in OCaml.
Hey that's cool, I also got lots of inspiration from "Rust forest"! I'd be very interested in your feedback on a (very) similar project of mine called [id_tree](https://github.com/iwburns/id-tree). Just curious about design decisions and your experiences with trees in Rust, that kind of stuff. If you have the time to take a look and give your thoughts, I would very much appreciate it!
Interesting that you chose to use NULL instead of Option in your linked list example.
`into_iter` is probably the best way of doing this, just know that it moves the contents of the vector so you won't be able to use the original vector again. The only other way that I am aware of is to use `.iter().cloned()` which obviously is less preferable because it clones each element.
Lifetime ascription is an interesting one, re the question "why didn't we do this in the first place?". A common beginner question is "how do I tell rust to extend the lifetime of this variable?" and the answer is you don't -- lifetimes are descriptive not prescriptive. If we let the syntax change the lifetimes _sometimes_, this could become harder to explain. For example, if you do this 'a: { { let x = 42; let r: &amp;'a x = 42; } } we don't want rustc to automatically hoist `x` out of the inner scope, right?
I don't see how the fact that people trust their dependencies' judgment translates to the fact that raw download numbers is a good metric. 100 people choosing the crate and 100 people trusting one person who chose the crate are very different things.
&gt; It seems like in reality all you're doing is fooling the borrow checker. Yeah, this is the main problem with it I think. (Not that I think you shouldn't do it, but it's good to be aware that that's what is happening). If you make a `NodeId` type and make it `Clone` but not `Copy`, then you're more safe than just using the raw indices, but that still doesn't prevent you from having invalid indices if you call clone. Of course, you could make it not `Clone` as well, but then what if you need to clone it? EDIT: double negatives are stupid
Because `&amp;` references borrow the whole arena, and `usize` node IDs don't. Even if `&amp;` somehow didn't borrow the arena, what if you pushed a lot of new nodes in the arena so that the underlying `Vec` reallocated the buffer? That would invalidate `&amp;` references.
To be fully validating node one needs to download whole blockchain but not keep it on disk. Pruning is already possible today and I suspect more nodes will prune as blockchain grows. Maybe one day nobody will actually have old data. (That's not too huge problem actually - it's same problem as trusting someone with Genesis block.) So I think it's not forever. Although, it might be more persistent these days. Good luck!
This is all correct; there are a number of issues with the index approach, and a lot of them are analogous to the same issues with a simple pointer approach.
There's another difference though. When you're working with pointers, anybody with the pointer can access the object at that address - without passing by the owner of the object. I rediscovered this arena pattern while working on my too ambitious project. Forcing everything to go past the owner forces you to have a layered architecture which has actually helped me tremendously. 
I'm curious, why would you prefer a String vs an &amp;String? In a case you intend to modify them?
You're looking for /r/playrustlfg (and /r/playrust is the main sub for the Rust game). This sub is for [Rust the programming language](https://www.rust-lang.org/en-US/).
That's an interesting point.
The new book has http://rust-lang.github.io/book/ch10-03-lifetime-syntax.html, and will later have a full dedicated chapter. There's no RFC because they happened before the RFC process. The tricky thing about lifetimes is: they're not that complicated, but they're totally alien to the way many people think. That's why the book chapter is short; that's really all there is to the concept. But the _implications_ are huge. There's not a lot of good explaining of the implications.
Aha that link is *such* a better explanation than the existing ones! I can think of ways to expand it (e.g. give an example illustrating why you can't just do `impl Foo&lt;'a&gt;`, rather than `impl&lt;'a&gt; Foo&lt;'a&gt;`, and maybe an example of a struct with two lifetime parameters), but it is very informative as-is. Thanks!
You could also try mapping `String::from` over the slice of &amp;strs to avoid allocating the vector, but still get owning references.
Everywhere!
Nah, LLVM does it for Vec too if there's a low amount of elements in it (might only work for one element, I can't remember).
Not really (or at least not fully): The compiler is still free to insert drop calls anywhere as long as the given lifetimes are upheld.
Great post! You might even be able to make this faster by changing the hashing function that HashMap uses; it's DDoS protected by default, but that means it's slowed down. If user input won't be going in the hashmap, changing the hashes might dramatically improve the time.
What makes something idiomatic Rust? In, e.g. C, something is idiomatic because it's been done that way for a long time and it's common to see it done that way. 
Thanks for the pointer. I have been reading the various discussions around this but didn't get round to trying it out. I will try a faster hashing algorithm and update the post.
I feel like there should be a more elegant solution, as long as you permit unsafe. Each item has one or more link fields that could be used to encode the info needed to differentiate vacant and occupied slots (make one of the link fields a magic invalid sentinel value for example). Problem is that it's not easy to give the container access to these fields in the item type. Would need something like this: https://github.com/rust-lang/rust/issues/9912
What if none of the top 100 contributors are familiar with certain niche algorithms though? The aho-corasick example from the top comment for example. I doubt many people have actually had to implement it, so few people will be able to recognize the better implementation. 
`match ... { ... }` is an expression, like nearly everything in rust. So it evaluates either to `cache`, or the process exits and it doesn't need to evaluate to anything.
1) `match` block is `switch-case` block on steroids. [read more in the book](https://doc.rust-lang.org/book/match.html) `match` blocks can do pattern-matching on algebraic data types (read as switch on tagged union tag with extracting data from union) 2) `if` blocks and `match` are expressions and have values. let x = if (2 &lt; 1) { println!("dis cannot be!11"); -1 } else { 1 }; let x = match 3 { 0 =&gt; "what?", 3 =&gt; "all is good", _ =&gt; "the rest of ints", }; println!("{}", x); // algebraic data types match Some(3) { None =&gt; { println!("what?") }, Some(value) =&gt; { println!("got: {}", value); } } You can try this around on https://play.rust-lang.org/?gist=3da1183a68e704fdf726fd25edb93910&amp;version=stable&amp;backtrace=0
I haven't read the entire RFC yet, so my suggestion might be worthless, but have you considered tagging? I think it's also something that was being studied for the semantic web. Users label could label crates with how they experienced the crate, with descriptive terms like 'efficient', 'easy to use', 'light', and so on. More tags is better, so it could work with the overall ranking. And I think it could help with comparing different crates' strengths to each other, much more than a scale ranging from bad to good. 
For those of us who don't know Ruby, what's the difference between MRI and mruby?
great! I got it!
&gt; What is the connection between Servo and bluetooth? I guess it's the same for other browsers and Bluetooth (and USB for that matter): Authentication and proximity sensing (think keyfobs, smartphones, ID tags and the like), media sharing and other random gadget pokery. Not that I'm quite comfortable with the security implications, but there.
That's the usual use, yes. You _can_ also do the inverse, with both of them, but their strong points are using them in the way you describe, imho. There's also [Helix](https://github.com/rustbridge/helix), which is like Ruru but with a different angle on how to do the interface, though it seems like it's dead. And finally, I have [ruby-sys](https://crates.io/crates/ruby-sys) that was extracted from Ruru, and frankly, they do more maintenance work on than I do ;) You could use that if you want low-level bindings only.
I think the idea is that, when you wrap it up in an API where deletion is only possible via a `pub fn` that updates references, any mistakes you make that are tripped over by downstream code will result in a runtime panic rather than undefined behaviour.
Yes, there are some production users, and they use TiDB to replace MySQL or MySQL sharding(proxy) solutions. Also there are some users one use TiKV without TiDB when they don't need the MVCC, SQL and transactions.
Work off the existing please and ping me on IRC for questions. Thanks!
I haven't written a lexer from scratch with bison/flex in several years, but part of be suspects it wouldn't be incredibly difficult to intergrate them right into rust via the FFI. Build the parser in a small library, then import the parsing modules via FFI into rust. Best of both worlds.
I just recently blew a foot off trying to understand lifetimes. It actually makes a lot of sense once you get away from the C model that anything on the heap lives forever until you deallocate it. Basically, you need to specify a lifetime when data and initialization live in two different places. In my case, I have a set of implementation that implement a trait that I need to check data against. Because the size of traits are unknown at compile time, they have to be boxed, and loaded into the vector which requires a lifetime, which needs to be specified as the lifetime of the structure, i.e struct SomeStruct&lt;'a&gt;. This allows the entire thing to go "poof" when the struct falls out of scope.
It should, as it relies on Hyper which relies on Rust-Url, which does support ipv6 addresses: https://github.com/servo/rust-url/blob/ae7204f702aeb186876393f0a5f5a91134ba7cf2/tests/unit.rs 
&gt; On the other hand, you now have compile time borrow checking. I think1 this comes at the cost of having a single top level object essentially without interior mutability, ie that you need to have a mutable borrow on this object to modify things inside it. This might present its own set of problems if you want to modify the data structure from multiple places. Yes, the typical way to implement this is with an arena and references into the arena. Doing it this way makes you lose mutable access to interior nodes, unless use use some kind of `Cell`. `RefCell` obviously makes you lose safety guarantees. You can use something like `MoveCell` to build a graph that allows for interior mutability, like [this.](https://github.com/bbatha/movecell_graph/blob/master/src/lib.rs) Unfortunately this means the graph can't be moved (or you need to keep the arena outside the graph). *edit:* you also lose `Send` and `Sync` with these options, barring potentially the existence of something like an `AtomicCell`. Actually looks like you could build a threadsafe [version with this crate](https://github.com/reem/rust-atomic-option). I think there are two paths that state of the art graph libraries can take from here. The more general approach is to have some kind of scoped allocator, like the proposed [defered_ptr](https://github.com/hsutter/gcpp) for C++. For immutable graphs I think that if rust could gain some kind of "construction" phase where you could freely mutate an object then freeze it to pass around. 
I agree that this is quite a significant benefit. I'm using [petgraph](https://crates.io/crates/petgraph) to manage the widget DAG in [conrod](https://github.com/PistonDevelopers/conrod), as well as for the DSP DAG in [dsp-chain](https://github.com/RustAudio/dsp-chain). It is basically a single struct wrapper around two `Vec`s - one for `Node`s and one for `Edge`s. I've found that having the `Graph` as a single type has made it easier to manage ownership of the nodes. Some benefits that come to mind: - Easy to clone, serialize or perform any other operation on the entire graph as it is always entirely contained within a single distinct instance. - Simple to wrap the graph with a concise API that suits your unique use-case as all access must happen via the single owning instance. - Easy to track nodes/edges during update traversals without running into ownership issues (we only need to track indices). - Super efficient traversal as we don't need to jump around the heap. That said, I have come across a use-case with a much smaller DAG where the `Rc&lt;RefCell&lt;&gt;&gt;` approach was the more suitable option. The graph was constructed via chaining iterator adaptors, so the indexing approach would not have made any sense. In most cases the graph was only a tree, though on the rare occasion a node would pull data from two parent nodes, so an intermediary `Rc&lt;RefCell&lt;&gt;&gt;` was used for this case. The whole graph structure was known at compile-time, and the `Rc` cost was *only* paid for nodes with multiple parents, so it differed a lot to some of the other suggestions in this thread. I also didn't need any of the benefits I mentioned above. Anyway, I guess my point is that different situations can better suit different types of graphs. However, for more general graph data structures, I tend to look to petgraph first.
I'm interested, but I find those shenigans of copying such and such dlls confusing 😱 
If I just needed to modify them a `&amp;mut String` via `&amp;mut[s1, s2]` would be sufficient. It would be when I want to move them inside a for loop or iterator, generally into some struct (likely after modification). I should mention I only used the type `String` because you did in the original question. The actually motivating examples would have been mostly the game state struct in a sokoban solver.
[rote](https://github.com/sagebind/rote) looks like it has a lot to offer here in terms of build automation and test scripting. The Lua environment would allow for a lot of power and code reuse for tests. I guess the missing piece of a full blown test framework could come from [busted](http://olivinelabs.com/busted/). It would seem to make sense, since it would leverage Lua's drop-in style to make a powerful systems language program easily scriptable by simply adding some already well-established scripts.
I'm trying not to make the ranking system reliant on people doing work, and by work in this case I mean the work to do the tagging (if no crates in a category are tagged, we have no idea how to rank them and would have to fall back to something) and the work to moderate a tagging system (we would at least need to implement a mechanism to report tags to the moderation team and a way for the moderation team to manage the tags and the users who did the tagging, etc) 
For anyone feeling adventurous, there are a few other ways to solve this. One of my favourite ways is to rewrite the game code via modifying the memory. For example, if you do this: memset 0100 a9 00 85 02 85 03 4c 00 c0 Your'e writing this code into the memory at `0x100`: LDA #$00 STA $02 STA $03 JMP $C000 Then you can hijack the code at `0xC009` which is a `JMP` instruction: memset c009 4c 00 01 This replaces the `JMP` instruction at that address with a `JMP $0100` instruction - placing the Program Counter at your newly injected code. The injected code sets the Y coordinates of the ship to zero then jumps back to the start of the program at `0xC000`. Just a fun little alternative way to solve this level :)
&gt; For example, this little comment from the post about 'clap': &gt; &gt; Agree wholeheartedly. https://github.com/rust-lang/book/pull/351#issuecomment-266808832 :-)
Your pasted request should work. It should also just work if the DNS for a hostname uses ipv6 addresses.
One other advantage is one that use in my current project. Vec indexes act as unique identifiers that can be sent elsewhere. I have a web based fronted that is an editor for a tree structured document, all requests and events sent over websocket need to refer to nodes, and what better way than to use these indexes? Very fast lookup! For this I built my own tree, very similar to ego-tree but using the stash crate for storage.
It's not really important but Heartbleed wasn't actually a buffer overflow, it was a buffer over-read. Your point still stands, though: Rust's memory borrowing model would have likely averted the error.
I've been using Rust since 1.0 and this actually makes more sense then what I vaguely figured out over that time period. I wish this version of the book and the error messages had been around back then.
&gt; Writing tree structures in Rust is no trivial problem. [What?](https://is.gd/zPBKoc) I must be missing something?
You can put an erratum as the first paragraph of the article mentioning correct date.
Perhaps add an idiom to the [patterns](https://github.com/rust-unofficial/patterns) repo?
The tree nodes in the article need to carry a reference to their parent node.
I’ll explain it all, basically at least. Short version: when you produce a dynamically linked library, the Rust compiler and standard library are dynamically linked (`lib{std,rustc,…}-*.{so,dll,dylib,whatever}`) rather than statically, so they need to be accessible when you load your own dynamic library; copying them adjacent to your library is normally the easiest way of doing this.
I hope its ok to ask this here. This question is not code related but still related to rust so... What's the recommended registrar for .rs domain? Similar to docs.rs and rustup.rs The reason I'm asking is that I am exploring the option of using a custom domain for my rust project instead of github's. 
&gt; (For example, using the borrow checker to implement a compile-time-checked state machine, because that kind of compiler-enforced "this member function invalidates all previous references to implement a state change" is something no other mainstream or aspiring-to-be-mainstream language has.) I've implemented similar things in C, C# and python before! i.e. where each state has a separate type and the commands/actions/state-changes on that state return the new state. So therefore you can't call `.login` on `Authenticated`. Infact I did it in Python 2 weeks ago at work, even though Python is dynamic and didn't check that stuff. (It helped me check it though, mentally; with tests; and most importantly with pycharm's fancy type checking). Unless I'm mistaken, there's nothing Rust-specific about that bit of code? 
The Rust-specific part is the way it interacts with the language features so it's truly enforced, so you can trust that misuse is impossible in the context of DailyWTF-level co-workers or downstream users.
&gt; The Rust-specific part is the way it interacts with the language features so it's truly enforced, so you can trust that misuse is impossible in the context of DailyWTF-level co-workers or downstream users. You can't pass a `Foo` to a method expecting a `Bar` in C# either. I don't see how this is Ruse-specific?
Maybe a noob question, but what exactly are stack probes? Thanks.
The problem is that "easy to go from..." is subjective. I learned that in high school too, but I use it so infrequently that I always need to look it up on Wikipedia again to make sense of it. The Python list comprehension notation, while unusual, is built on keywords already present in the language which are, themselves, taken from plain English. (Also, I notice that Rust seems to be torn between two populations of programmers. The ones who are familiar with languages like Haskell and the ones like me who only know more mainstream languages and want Rust as a way to be able to write un-managed code without being driven away by the stresfullness of always being on guard for segfaults.)
Writing the compiler in Rust is pretty easy. There's a plethora of good [parsers/parser generators](https://rust.libhunt.com/categories/1618-parser) that have some advantages over old tools like Flex and Bison. But of course, if finishing it fast is important, any functional high level language will do. If not, I see no reason why you'd pick C/C++ over Rust as of now.
But then you have an arena that can create new `T` elements, but not remove (reclaim) them... Here's my [comment](https://www.reddit.com/r/rust/comments/5czp0j/safe_and_even_more_efficient_bidirectional_trees/da13sqi/) discussing differences between vec-arena and typed-arena.
I do not necessarily agree. nom, for example, has great documentation. It's thoroughly tested. It may not have as many examples or books written about it, but how relevant is that in today's internet age?
The loss in performance is due to another level of indirection (indexing into the vector vs reading pointers directly), bound checking (is the index within bounds?), and "liveness" checking (is the slot occupied or vacant?).
Thank you very much for the feedback. My intention of the blog post was just to clarify one to two common problems and their solution in an article which can be read in under 5 minutes. :)
Correct. This is what characterizes an arena. Since all elements are dropped / deallocated at once, there is no need to spend resources in the meantime to track which of them are still alive. This is also critical to having `&amp;T` reference cycles.
I would definitely recommend choosing a different language. Modern NLP relies heavily on machine learning, which means you are going to want a platform that can compute large matrix operations very quickly. If you really want to use Rust, there are bindings to Tensorflow [here](https://github.com/tensorflow/rust)
I haven't seen anything for NLP, but you might want to take a look [here](http://www.arewelearningyet.com/). You should be able to form an opinion on the current state of the ecosystem. Happy holidays!
Looks great and the example code is so short! The dream would be to be able to use this with Rust and compile into WebAssembly. What can we expect in the future? Is this something that WebGL could evolve into, or an entirely new standard that needs to be established?
The fundamental problem is that with a large enough stack-based structure, you can overflow the stack into an area that is not on the stack, and thus access the memory there. To detect such a stack overflow, there is usually a memory page just next to the stack that is completely protected from all access. Thus, a stack overflow becomes an access violation instead of random reads/writes all over the place. But with a *really* big structure on the stack, you can skip over that guard page. Stack probes are a feature where the compiler inserts code whenever it allocates something big on the stack so that it performs some memory access on each page the allocation covers, which prevents huge structures skipping over the guard page.
Another solution is to use a `Vec&lt;Vec&lt;Node&gt;&gt;` where the inner `Vec` have a fixed capacity: 1, 1, 2, 4, 8, 16, ... If you use indices, you would have 2 layers of indirection, however since it's memory stable you can directly store the pointers.
Is `!` a real type now? I remember there being a big discussion saying it wasn't as well as a crate (`void` IIRC) that had an empty type …
Why do you say large matrices are an issue in Rust? How would it compare to say, Python?
They're not an issue. You can use [ArrayFire's Rust bindings](https://github.com/arrayfire/arrayfire-rust) to do very fast matrix multiplication (even using the GPU). That said, I still wouldn't necessarily choose Rust. Machine learning normally involves a lot of experimentation and REPL-style work which Rust is not at all good at. You really want a scripting language like Matlab, Lua, Python, Julia, etc. that has bindings to a fast library. Maybe I'd rewrite the forward solver in Rust when I had a working system, but I definitely wouldn't use Rust for training and experimentation.
It says this: thread 'main' panicked at 'Failed to send request: Http(Io(Error { repr: Custom(Custom { kind: Other, error: StringError("failed to lookup address information: Name or service not known") }) }))', src/libcore/result.rs:799 EDIT: This does work: curl http://[2601:184:300:500::17ba]/autoupdate/list.txt
I like it, I hope it'll get merged!
I'd like to offer a different opinion. When I rig, for example, Sublime Text with my own build script (cf. http://stackoverflow.com/a/40181091/257568) - it's trivial to make it run some code with every build. My typical worflow is making a unit test, configuring the build system to run it on Ctrl+B, then writing code and seeing how it works with but a single keystroke, without ever leaving the editor. This write-run cycle is, I'd wager, not very different from a REPL. Another point is the borrow checker. A lot of people focus on writing super-fast code in Rust, a code that avoid allocations and *borrows*. But if you shift your focus a bit and allow yourself to use the owned/ref-counted structures more often, the borrow-checker becomes a non-issue. Rust isn't any worse than most other languages when prototyping in that mode, and the result is still faster than most interpreted languages and on par with modern C++ style (which uses ref-counted structs and owned strings too). Prototyping with an interpreted language works for a lot of people, but in my experience Rust can be used for prototyping and exploratory programming as well. It is a matter of approach.
I am not an expert on the subject, but have a look at rs-natural. https://github.com/cjqed/rs-natural
Unless you've added a repr attribute, struct layout is undefined in Rust, so we can be much more aggressive here.
Thanks! I'll have a look
Thanks, it seems a good starting point, I'll check it out
&gt; Though maybe you could just "delete" the element and store a list of "holes" in the vector arena that you can reuse This is similar to how petgraph's [StableGraph](https://docs.rs/petgraph/0.4.1/petgraph/stable_graph/struct.StableGraph.html) works. Removing a node sets the inner element to `None` and its index is added to the front of what is like a "linked list" of free nodes, where the graph tracks the index of the most recently freed node and each free node stores the index of the next free node.
EDIT: I should probably start by saying that your code already looks quite good and idiomatic. The only thing I'd be itching to fix if this was my code is the amount of `clone()`s. main.rs: let conf = match opts::parse_args() { Ok(conf) =&gt; conf, Err(_) =&gt; process::exit(1), }; If you're not going to print a human-readable error message, why not condense it down to: let conf = opts::parse_args().unwrap(); This expression in opts.rs can also be condensed a lot with a Result member functions: let matches = match opts.parse(&amp;args[1..]) { Ok(m) =&gt; m, Err(_) =&gt; { print_usage(opts); return Err(InvalidArgError); } }; Two condensed forms that both do the same thing as the original, though I guess the first is probably more readable: let matches = try!(opts.parse(&amp;args[1..]).or(Err(InvalidArgError))); let matches = try!(opts.parse(&amp;args[1..]).map_err(|_| InvalidArgError)); You could also use a [question mark operator](https://m4rw3r.github.io/rust-questionmark-operator), which was released with the last stable AFAIK. It's a bit weird how you return an InvalidArgError when you encounter the help option, and then because of that exit the program with non-zero exit status. Not sure how I'd change it myself, maybe just exit immediately from that function with `std::process::exit`, though it does seem a little weird. cache.rs: pub fn get(&amp;mut self, key: &amp;str) -&gt; Option&lt;json::Json&gt; { match self.content.get(key) { Some(x) =&gt; Some(x.clone()), None =&gt; None, } } shorter: pub fn get(&amp;mut self, key: &amp;str) -&gt; Option&lt;json::Json&gt; { self.content.get(key).map(|x| x.clone()) } although it might be good to get rid of the `clone()` altogether (not just here). Do you actually need to return a `Json` object here? I'd probably return it as an `Option&lt;&amp;json::Json&gt;` (which might require an explicit lifetime annotation, but I'm not sure). A small thing that probably makes sense but doesn't anymore: slack.rs, line 65 - 67. A continue right before the end of a loop body doesn't do anything. Also, on line 76 you match on a bool. I don't see why would do that instead of just using if-else, which is also an expression in Rust. In `resolve_users` and `existing_user` you could use [ok_or_else](https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or_else) (although you will probably find a few people who would prefer the current version of the code, I just like these kinds of mapping functions more than explicit matching where applicable; do whatever you like). Another small thing is that I've seen a few places where your formatting was a bit off, you might want to check out [rustfmt](https://github.com/rust-lang-nursery/rustfmt) if you don't already know about it. It will format things for you, so you don't have to worry about that anymore (it's best used with an editor plugin that automatically executes it on file save IMHO). Finally, Is there a reason you use rustc_serialize instead of [serde](https://serde.rs/)? It seems to require cloning stuff in a few places when handling json, and also serde has been the quasi-standard for (de)serialization for a while now.
Thanks! It was actually pretty controversial. Some view it as blockchain "spam", while others see the value in allowing rich transaction serialization through the Payment protocol. Actually it looks like they closed the PR Sept. 1st: https://github.com/bitcoin/bitcoin/pull/7376 It still works but you have to burn some value in the process.
What is the best way to find the index of the first or last occurrence of a substring in a &amp;[u8]? Is there anything better than the twoway crate?
Try searching for "rust nom". https://github.com/Geal/nom Also of note is serde.
Wouldn't it make more sense to just check size &lt; max stack size - current stack pointer or whatever, rather than performing O(n) memory accesses?
But if I say "index = 5;", isn't "index" now a reference to whatever is at "x[5]"? Not literally, but logically. It's the equivalent to if I stored a raw pointer to "x[5]" in a special wrapper class that only let me dereference it if I also passed it "x", and it verified that the pointer still pointed to some element of "x". (By checking it's between the address of x[0] and the last element.) Maybe the borrow checker's checking of the access of "x" means this is all fine. I guess I'm hoping someone smarter than me (or at least that knows Rust and the borrow checker better than me) could write a blog posts that details how the index abstraction works with the better checker and all it's guarantees (not just memory safety, but single mutable reference, etc).
Btw. I learnt about stack probes precisely because of Rust. Gotta warn you, Rust is a hell of a gateway drug to the depths of the universe.
It's not about just knowing whether the stack will overflow or not, it's about signalling to the operating system that "we will use these pages". I'm definitely not an expert, but my understanding about the matter is that unless the pages aren't accessed, operating systems are generally not going to map them to point to real memory. By "touching" the guard page, OS knows that the stack space is going to be exhausted, so it allocates the next page. But if the structure is large enough that it touches something beyond the guard page, it's going to lead to undefined behaviour. That's why the stack probes "touch" the guard page, which causes the OS to grow the stack and allocate the next guard page, then the probe touches that, and so on, to gradually grow the stack to the desired length. And yes, that is indeed O(n), but I don't know the technical reasons why there is no algorithmically better allocation mechanism. Maybe it's because the stack is generally not used for large structures, so that has been more like a niche?
But why do c2 has the type u8 and not &amp;u8? Should c2 not have the same type as "a" which is assigned to c2 and has &amp;u8 type? Has it something to do with deref coercions? (https://doc.rust-lang.org/book/deref-coercions.html) Edit: Or maybe because "*a" is a copy type?
Thanks for all this! :D
This is basically the subject of my cospeaker's and my rustconf talk. We had a similar conclusion in regards to exploration - needing a REPL. Python is a solid tool for this, the best we've used probably. However, for doing the actual computation, rust blew it out of the way. Being able to build 'schemas' for our data in the type system, handle unclean data in a typed way, and get ridiculously strong performance made rust really ideal for the actual data processing part of our classifier. The current weak point is needing the machine learning models. Rust is making solid strides here but it's immature at this point. What I think the ideal solution looks like is: 1) Exploration phase in Python 2) Pipeline in Rust 3) Simple Python/ Julia microservice that wraps around a model You can keep your experimental model-related code in the microservice. Your feature engineering code will be maintainable and fast. And you still use Python to poke at the data.
&gt; This is basically the subject of my cospeaker's and my rustconf talk. For those that missed it: http://www.suchin.co/2016/09/13/The-PlayRust-Classifier/
I concur. I am merely asking a question that I've been pondering on lately: is an older, well-tested, well-documented, but more complex system harder or easier to approach than a coarser, rougher-around-the-edges one whose purpose is to be simpler to use? This is hardly quantifiable however, apart from the fact that I've no knowledge about any empirical evidence for either case.
What would be awesome is something like what Erlang (and I assume other languages) have where you can do something like fn foo(Some(0)) {// etc} fn foo(Some(x)) {//etc} but i guess that wouldn't be very rusty
I copied it from the stable docs. Hm. Seems bad that we changed that, though "approximately" isn't a hard guarantee...
In Iron, I want to check the user agent using BeforeMiddleware and if the string does not match what I want, I want to return some HTTP code. How can I do this? The Iron documentation is not really clear on examples with middleware.
Pretty much.
You can also do this: if let e @ 1 ... 5 = x
That does ring a bell, yes. I remember an RFC for typed enum variants, and another for function header matching syntax (or something), which I imagine relies on the former.
&gt; are the two ref (string_ref2,string_ref2) the same? No, they aren't. The type of the expression on the right is indeed the same in both cases (the expression is `&amp;string` and has type `&amp;&amp;str` (`&amp;'some_local &amp;'static str` to be precise (if you've omitted `'static` here, compiler would figure it out anyway))). In case of `string_ref2`, you say that the variable will also have this exact type (`&amp;&amp;str`), so the expression is just assigned to the variable, and `string_ref2` is a reference to a reference (`&amp;&amp;`) to a `str`. In this case case, it's a reference to a variable `string`, which is a (`'static`) reference to `"Hello world"`. In case of `string_ref1`, the type of variable (`&amp;str`) and expression (`&amp;&amp;str`) differ. In this case the compiler performs so-called deref-coercion, which basically strips enough layers of `&amp;` to make this work (by adding appropriate number of `*`. So it work's as if you've written `let string_ref1 = &amp;*string;`. So in the end, `string_ref1` ends up begin exactly the same as `string` - just a reference to `"Hello world"`. Now, printing uses `Display` trait which is defined for `&amp;T` to work exactly as for `T`, so if you try to print `&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;something`, it would work just as if you tried to print just `something`. Now to the comparison. If this compiles (I haven't checked) then it's just because there's a `PartialEq&lt;&amp;&amp;str&gt;` implementation for `&amp;str`. The same logic can be applied to your `u8` example. And if the `assert_eq!(b2, c2)` doesn't work, it's just because `PartialEq&lt;&amp;u8&gt;` is not implemented for `&amp;&amp;u8`.
Cool! 
The `std::thread::spawn` doesn't allow the thread to capture any local variables by reference or use references to locals*. You can put each chunk in separate fully-owned `Vec` and `move` it into the thread. Although I won't recommend this solution. The better way would to use "scoped thread" functionality, which allow the thread to access local variables. It's not in `std` though. I know that there's `Scoped` in the `crossbeam` crate, along with some nice examples. Also, you should try the `rayon` crate! *) The reason why `spawn` doesn't allow that is because the spawned thread may outlive the current function, if that happened if would still have access to already-dead variables, which is definitely a baad thing. But, you may say, "I join the threads at the end, so it should be safe!". 1. Rust doesn't understand what's inside the join function (it's just a function from Rust's perspective). 2. If panic happened somewhere in your function, joins won't actually be called, leading to bad things.
Yes, this is going to be fixed. As I mention elsewhere, clippy isn't a dependency crate (which is what's being talked about), it's a tool. 
This is cool! Neat that you could do a ceiling (unsigned) like let x = if let 0 ... CEILING = x { x } else { CEILING };
&gt; @alexcrichton suggests browsing the relevant LLVM tests, but I'm not sure where to find those. Something like [this](https://github.com/llvm-mirror/llvm/search?l=LLVM&amp;q=asm&amp;utf8=%E2%9C%93)?
Having played with Clojure, I tried it in Rust without second thought (same destructing in let as in function arguments), and it just worked! And this is indeed so handy !
`b2` is `&amp;&amp;u8` and `c2` is `&amp;u8`. They are not `&amp;u8` and `u8`. Proof: https://is.gd/y79ksd The reason for the sort of confusing error is that Rust has this blanket impl: impl&lt;A, B&gt; PartialEq&lt;&amp;B&gt; for &amp;A where A: PartialEq&lt;B&gt; This note suggests that this is what's happening, though it confusingly uses the concrete type: note: required because of the requirements on the impl of `std::cmp::PartialEq&lt;&amp;u8&gt;` for `&amp;&amp;u8` So the compiler has figured out that `IF &amp;u8: PartialEq&lt;u8&gt; THEN &amp;&amp;u8: PartialEq&lt;&amp;u8&gt;`. When it finds that `&amp;u8` does not impl `PartialEq&lt;u8&gt;`, that's when it throws the error. This results in some very confusing errors sometimes. For example, I have a trait in some code (let's call it `Foo`) blanket impl'd for functions. If I forgot the `T: Foo` bound, I get errors about how `T` doesn't implement `Fn`. I'd like to investigate how these errors could be improved, but finite time.
I know there's a lot of work to speed up rust compilation, so it might be interesting to see some of the ways Jonathan Blow optimized his compiler (spoiler: Have a mode that directly outputs x64, bypassing llvm).
Does that have any advantage over `std::cmp::min(x, CEILING)`?
Oh yes I see it now. assert_eq!(**b2, *c2) works. The answer above was a little bit misleading. Thank you. And yes the error messages are sometimes more confusing then the error by itself. 
Awesome post! I started sometime later (0.6 or 0.8, can't remember), gave up for a bit, then came back for 1.0. I remember quite a bit of the weird syntax you mentioned, but not all. It's amazing how far rust has come. Also, thanks so much for the documentation blitz. The Rust Book was a large part of the reason I came back. Btw, minor spelling issue in the post: &gt; so much so that they’re ~~note~~ **not** even shown in the official docs
Thank you so much for these posts they are very simple and very useful! :)
Glad you enjoyed it! That means your return is very close to my four years then; I wrote Rust for Rubyists in the first two weeks.
I managed to put together a [minimal repro](https://gist.github.com/lilred/3868c48004ce344d87002f540d5b21f3). The break surprisingly has nothing to do with LLVM.
At least on Windows, I've found cgo to be abysmal. It requires GCC - but not just any GCC, it has to be the MSYS distro! And it has to be the 64-bit build! And it has to be a particular version (not the latest version, of course)! And this information changes all the time!
I was into C++ and standardization back in spring-summer 2014 when I started learning Rust. So I read about languages similar to C++ in Wikipedia and I noticed that Rust used `fn` as a function keyword. "Damn, that's short!" - I thought - "this must be a good language". I immediately downloaded the Rust reference (it was more up-to-date and available in pdf back then), read it, and liked what I read. Since then I followed Rust development and started contributing occasionally a bit later.
Really? That's interesting. When I was looking for memory safe native languages that could easily interface with C, I gave up on Go (and turned to Rust) because cgo looked like a mess. In Rust, I can link against an ordinary C function in a completely transparent bog-standard way and I was able to understand and predict how to call it from Rust within a couple of hours of picking up Rust, without needing any auto-generated magic between my code and C. I like that there's none of the undercover thunk-spaghetti that Cgo cakes on, but that may be because I have a good deal of experience with C, and an understanding of how C works.
cgo is really really easy to interface with. Just give it a header file and tell Go how to link your C library, and you can use C types/functions in a very straight-forward way. Example here (where I wrote Go bindings to a Rust library!): https://github.com/BurntSushi/rure-go/blob/master/rure.go#L206 The downside of cgo is that calling a C function is much much more expensive than calling a Go function, but this really isn't the fault of cgo, but rather, Go itself.
Still learning! I wrote a little program that queried Pulseaudio if sound was playing and if so signaled an Arduino to light some leds. It was fun!
&gt; blows my mind ;) ... as funny as this is – i must agree! (ot: i try to follow every video but missed the recent ones, has he released anything yet to play with?) 
[Continuation](https://github.com/rust-lang/rust/issues/38524) of this discussion, for anyone interested.
At the risk of alienating the non-game developers here... I think a lot of this stuff comes down to people just having weak expectations of performance. Once you've worked in an industry where you render several million pixels and polygons worth of high fidelity graphics, simulation, physics, fluid dynamics, lighting simulation, shadows, etc. and you do it all at 120Hz in VR on a commodity PC, it's *really* hard to swallow that processing a few thousand lines of text should take tens of seconds... OTOH if your expectation for "fast" comes from web development or something like that, then maybe you think that stuff is "fast enough" much sooner and don't make the performance oriented choices early enough to matter (and paint yourself into a corner where it's hard to make improvements because you figured you'd "optimize it later" when you locked yourself into early decisions). I mean look at this video - he's agonizing about shaving a few tens of milliseconds off of the compilation time on a 33kLOC program. I don't think most compiler writers do that. It's that kind of performance-mindedness that makes all the difference once you're doing 10MLOC.
how big a undertaking would having rust have its own x64 code generator be? I ask as i;ve seen a couple of projects talking about doing it.
None at all I'm sure. Its less clear, more characters, only works if one arg is a const. Its just neat that it falls out of how patterns work.
But the runtime cost isn't a property of cgo. It's a a property of the fact that the calling conventions between C and Go are different. The are other issues too, like the fact that cgo requires pinning threads, because it would otherwise wreak havoc on for example, C libraries that used thread local state. I'm not saying these aren't problems. I'm saying they aren't problems with cgo because they are inherent in how the standard Go implementation works. It's just plain weird to fault cgo for that. You got those problems because of how Go works in the first place. :-) we should evaluate cgo given its constraints. If you need zero cost FFI to C libraries, then Go itself probably isn't a good choice, no matter how good cgo is. And I'm not comparing Rust to Go here. I'm simply saying that cgo has worked really well for me every time I've used it. (To balance out all of the negative comments about it in this thread.)
There are structural types in Rust, like `(x, y)`. This is an example of a type that's not nominal.
This is a wonderful series. Thanks for sharing all of this. I was actually looking for something like `app_dirs`. Looks great. I find the `app_dirs` interface a bit surprising though. The difference between `app_root` and `get_app_root` is not clear without reading the docs. I thought Rust style avoided "get" too (at least for accessors). Maybe these could use clearer names? :)
Ah yeah I see what you're saying. Most of the generated thunks et al have to do with making C libraries play nice with Go's runtime. I guess my question is, if you subtracted out all of that, are we left with something significantly different than rust-bindgen from a user-experience perspective that you think is worth learning from? (I don't think cgo's "parse error messages" approach, while interesting/terrifying, is really all that meaningfully different for the end-user other than imposing some very stringent build environment constraints)
There might be some some concern about portability there. Do we want to build official Rust tools that only target x64 processors?
It's right in the documentation for `BeforeMiddleware`: &gt; Middleware which wishes to send an early response that is not an error cannot be `BeforeMiddleware`, but should instead be `AroundMiddleware`. So given an existing `&amp;mut Chain`, you would do something like this: // `AroundMiddleware` is an `FnOnce(Box&lt;Handler&gt;) -&gt; Box&lt;Handler&gt;` chain.link_around(|hand| Box::new(move |req: &amp;mut Request| if req.headers.get::&lt;iron::headers::UserAgent&gt;().map_or(false, |ua| **ua == REQ_USER_AGENT) { hand.handle(req) } else { // Return your HTTP code response here as IronResult&lt;Response&gt; } )); Addendum: If you consider the missing/incorrect user agent to be an error, you can use `BeforeMiddleware` and return an error there: chain.link_before(|req: &amp;mut Request| if req.headers.get::&lt;iron::headers::UserAgent&gt;().map_or(true, |ua| **ua != REQ_USER_AGENT) { Err(IronError::new("Expected user agent not provided!", /* status code here */)) } else { Ok(()) }) 
The idea AFAICT is to use the direct to x64/fast compilation backend only for Dev builds. Release build would stay the same.
This is especially great when using iterator adapters over iterators of tuples. It means code which would usually take multiple lines can be really concise yet meaningful. For instance this hashmap reversal. ``` let foo = bar.into_iter().map(|(k, v)| (v, k)).collect(); ``` It also allows you to spam smileys in your code. The following is valid syntax ``` let a = |(O,_,o)|(o,O); ```
&gt; Is there anything better than the twoway crate? Is there something wrong with twoway?
Sure, I think we should value their perspective, but -- as of right now -- we're all working with trade-offs and anything that doesn't acknowledge that is just... non-constructive. EDIT: Btw, assuming Haskell wasn't your first language, ... didn't *that* shake you up pretty good?!? That's exactly my point. &gt; There's a whole chunk of domains that deeply care about what the computer is doing at runtime (game dev, embedded, hard real-time, HPC, etc.) that the more progressive side of our industry seems to completely ignore when it comes to the target audience of the latest language or paradigm. I can assure you that they *do* care... it's just that sometimes some goals simply *cannot* be reconciled. (It may just be a mathematically unescapable truth of computing.) EDIT#2: Before I go to bed, I just want to add: I knew about 6 langauges (basically the "imperatives", but also O'Caml) before I learned Haskell. It wasn't before I learned Haskell that I really **appreciated** exactly how much actually goes on, semantically, when you (e. g.) try to catch an exception or even use a "finally"-type construct. It's absolutely ridiculous how much we just rely on intuitition that is (frequently) wrong.
Are you by any chance a fellow Handmade Hero fan? That series has really opened my eyes to this whole other world of programming that I don't think I would have ever even heard about otherwise. With so much bad, slow software around these days it's refreshing to see what guys like that are still capable of. 
Myself and a couple of others have been working on safe bindings to Jack: [rust-jack](https://github.com/wmedrano/rust-jack). We'd be more than happy to work with you if there are additional features you'd like to see added.
Not to mention if `x == -1`
A few points that I either just noticed or just thought up: 1. Your Documentation link on crates.io is 404ing. 2. Your docs would benefit from some simple information on the DOs and DON'Ts of using custom data types in a context where the schema isn't stable. (eg. Rapidly iterating on application, resulting in keys being added and removed without wiping the preferences store and starting over.) 3. Your API is similar to what QSettings offers in Qt, but the biggest advantage I've found for QSettings is that it integrates with Qt to automate the whole "deferred commit on some mixture of a timeout and the 'application exiting' signal" thing to batch up disk writes. Have you put any thought into exposing a "deferred commit made easy" API to minimize how much has to be reinvented to hook `preferences` up to an event loop?
Python is often called a "glue language" because big applications are generally written by using C code (eg. GTK+, libxml2, etc.) for the hot parts and glueing them together with Python.
There's absolutely nothing in jai that hasn't been done elsewhere before. He is rediscovering bits of Lisp and half baked reinventing C++. What in the world makes you think he's ahead?
Some more random obscure syntax tidbits: - You can do `Foo {a: 1, c: 2, ..Default::default()}` in a struct initializer. Basically, it will call the expression you provide, and copy in values from any fields you may have omitted. - This is unstable, but you can also initialize structs like `Foo {fieldname1, fieldname2}` provided you have local variables of the same name - `b"foo"` gets you a bytestring, i.e. a `&amp;'static [u8]` of ascii bytes. Works for byte literals too (`b'a'`) - `r#"foo"#` gets you a "raw string", where you don't need to escape anything. quotation marks, backslashes and newlines get included (In a regular string newlines get trimmed to spaces). If you need to include the pattern `"#` in the string, just up the number of pound symbols on either side. (The pound symbol isn't necessary, but in the zero-pound-symbol version you can't have quotation marks in the string, which is usually what this gets used for) - in `foo.collect::&lt;Vec&lt;_&gt;&gt;()`, the `::&lt;&gt;` is colloquially called the "turbofish operator" - Closure parameter lists also support arbitrary patterns, just that unlike functions you don't have to specify the type. Comes useful in `.iter().enumerate(|(i, x)| ....)` - You can do `self: Box&lt;Self&gt;` in a method and the method will only work on boxed instances. - `let x = HEAP &lt;- 1;` is valid Rust syntax on nightly. You can use it to allocate boxes. https://is.gd/7v3wYP
I said unsigned :-).
Thanks for the heads-up, I'll fix that link as soon as I can! Not sure what you mean by #2? Everything is stored in memory until you write to the file system with the `save` method. 3 is interesting, but it's going to need either an event loop or another thread to work properly, neither of which I'd want to add as dependencies. But, adapter or add-on libraries for different event loops etc. might be a good idea.
I don't remember his exact wording, but I believe his point is that the kind of code that C++ encourages (due to language features, but also books and conferences) is shit. This is true. You can carefully navigate the C++ features to avoid writing shit, but it's a bit of an uphill battle (i.e. it's not a pit of success). 
Do you know of any distinction between structural types and anonymous types?
Yeah, I knew all of those. I think they're less obscure than matching in fn args. I wish `..` didn't have the "same type" constraint, since usually when I'm constructing a subset of fields it's to change exactly one field to a new generic type.
The original Cargo: "hey there, your programming language isn't even 0.1 yet, I wrote a Python script that lets you type `cargo list` to see every Rust project that I know about and then `cargo install foo` to download that repo to your machine via git". Later, rustpkg: "hey, we should probably start thinking about package management, and there's this new Go language and everyone's raving about its package management [it was a different time...], let's take what they do and shoehorn that into Rust's compilation and dependency model". Modern Cargo: "screw it, writing a package manager is hard, we've convinced Mozilla to hire the guys who wrote Bundler to write us one too ¯\\_(ツ)_/¯". Probably not as insightful as you'd hoped, though the lesson really is "if you have money, it's way easier to hire a domain expert than to become a domain expert". :P
&gt; pretty debug printing Do tell!
What other language lets you easily choose between array of structs and struct of arrays memory layouts?
This made me go back and realize that my first rustc contribution was adding [multiline string literals](https://github.com/rust-lang/rust/pull/453) 5.5 years ago. Probably the contribution that I'm most fond of was a month later (after becoming slightly more confident with the code): [adding the `~~~~~` underline to error messages](https://github.com/rust-lang/rust/pull/660). edit: what a world we could have had: `let option::t[@file_lines] maybe_lines = none;`
Looks good! One issue I had was that my keyboard (Scandinavian layout) does not have a way to directly type a `backtick` (I have to use Shift + \\), but I was able to slightly modify the game to accept T as well as `` ` ``. Other then that, it was very pleasant to use, and worked just as I would expect. Edit: I just realized that T is not the best character for toggling the console, as you actually need it to type :/. However, `\` would be an alternative
&gt; There's absolutely nothing in jai that hasn't been done elsewhere before. You can, *and should*, say the same about Rust. But the right set of ideas, combined and composed well, focused on a particular problem space… can be magic.
Ah, so I wasted an afternoon for practically nothing ;P (well, not really). I think that's a good idea - you seem to have a much safer and more ergonomic API than `sqa-jack`, anyhow. I'll send some PRs your way probably soon-ish!
Brilliant! Thank you so much! I did worry about other possible keyboard layouts. I think I will add it to my task list to implement a configuration file where people can change some things that don't affect the general gameplay. Thank you so much once again!
Zbrush. I would love to see the guts of that. Real-time rendering and sculpting of millions of polys and it doesn't use the 3d card at all. Not one iota. And mudbox seems to die all the time depending on if the latest vendor 3d drivers have bugs. But zbrush chugs along. 32 gigs of ram? It will use it. Try and find a cheap video card with that. I don't know how pixologic does it.
Maybe this is a crazy idea, but you could also have a backend that emits webassembly. Of course it's not going to be as fast as emitting x64 directly, but webassembly engines are designed to be fast because they load code from the web, and they probably generate better code than you'd emit by hand.
It's actually a subset of a large reference card I maintain for myself for multiple languages. I've been meaning to clean it up and publish it for ages but I have enough trouble just trying to organize it as-is. (I've been thinking I might try converting it into a TiddlyWiki unto itself so I can view the data in tag-filtered slices, rather than as one big page in the TiddlyWiki I use as a PIM tool.) The master "target to try to retrofit onto all hobby projects" charts are a bit out of date, but here's a [screenshot of one of them](http://imgur.com/WOZhasL). (I found most of those by just spending an afternoon walking my way through the list of registered GitHub commit hooks.) \&lt;infomercial voice&gt;...but what would I call such a web app?\&lt;/infomercial voice&gt; Maybe something like "I want to be awesome at..."
From my perspective, using Rust would be a great benefit. You might be a bit slower at first as you get used to the language, but I expect the gains you get across the whole lifetime of the project will far outweight that. You might also be interested in https://www.perlin-ir.org/.
&gt; A basic 2D layout takes half a second to show up when we can render entire worlds in 8ms? This is one of the many reasons to be excited about Servo. They are trying to do web rendering using the high-performance infrastructure build for video games.
Incremental compilation and improved speed of compilation are high-priority goals at the moment. So I guess you could wait until things improve or try to split your project into different crates, so you don't have to recompile everything when there are only small changes.
I wrote an RFC for this, but it got postponed. https://github.com/rust-lang/rfcs/pull/1564
This seems like a horrible idea when working with the FFI and inline ASM. A few unhandled edge cases would mean many nights of hair pulling frustration for some dev in the not to distant future. 
Thanks for the reference! It's interesting that Perlin exposes the storage module in such a generic way. Might reuse it! How stable (and retro-compatible) has been the Rust language? Will I need to rewrite my code in four years?
Would be great for Clippy to suggest it in suitable cases!
Just a teeny-tiny nit pick: &gt; `&amp;` and `~` pointers may point to objects Rust still has objects. Objects are the result of coupling member variables and member functions. Even Lua has objects. What you meant was this: *`&amp;` and `~` pointers may point to instances of classes* Besides that: Great article. That `fn ident(pattern: type,...)` thing blew my ming as well. The more interesting thing for me though was that 5-letters-keywords thing. Why? Have the Rust devs been tortured with way too verbose Java and Ada? Not that I dislike abbreviations, it's just *"Why 5?"*. I'd guess it would have been due to the keyword `class` and a lack of `struct`s. **Edit:** &gt; Enum variants may be structs Well, err... See ya later. Have to change some API details now.
Interesting how both wasm and asm.js are part of Tier 2. Hoping for some interesting client-side web stuff coming soon!
Having an abstract representation of matrices is indeed really neat :). I prototyped a translation of http://repa.ouroborus.net/ a while back (almost two years ago! How time passes, associated types were still in early stages back then) which uses the same idea for its matrix representation https://github.com/Marwes/repa-rs. Looking at the code now it does not look quite as idiomatic anymore but if you are looking for places to take your library I think repa makes a pretty good model (I probably wouldn't translate it quite as literally as my attempt currently does but I would really like to see a repa-like library in Rust!).
Stability is a major sticking point of Rust; I've been reading many of the posts that come up about how to extend Rust (e.g. specialization, higher kinded types, etc.) and I am continually impressed by the care that is put into finding good solutions that are backwards compatible. The team is also really good at making decisions that don't paint them into a corner later on where you just have to live with some poor decision you made long ago. You can see this dedication to stability in this issue: https://internals.rust-lang.org/t/rolling-out-or-unrolling-struct-field-reorderings/4485 The change is an optimization to how Rust programs use memory, but it also breaks a few things. However, it only breaks very specific unsafe code that has relied on the way structs are laid out in memory, which is not something that was ever stable in the language. So not only does this only affect code where developers have to knowingly give up safety guarantees, but even though the Rust team could easily argue that this should just be merged, after they found out this breaks some code, the consensus is moving to phasing the change in and warning those that rely on this behavior. This change benefits 99.9% of all Rust users, but the few people who are relying on it in their unsafe code (even though they shouldn't) are still getting a nice warning and time to react. So my confidence in the stability of Rust is quite high :)
&gt; `b"foo"` gets you a bytestring, i.e. a `&amp;'static [u8]` of ascii bytes. Bah. I wish. You actually get a `&amp;'static [u8; 3]`. (My annoyance rarely happens in "real" code. It's most annoying in tests.)
C++ is hard to hire for. Lots of people know parts of it, but you generally need a language lawyer on hand to make sure you don't make a mess. Theres plenty of people (myself included) interested in IR in rust. Some have less time available to actually work on it... (Myself included...) But there's already people who want to pitch in wherever theres a good community being built. 
I’m *glad* you get `&amp;'static [u8; 3]`. When it was under discussion I was one of those pleading for it to be changed from `&amp;'static [u8]` to `[u8; N]`. It settled at `&amp;'static [u8; N]`, which is probably generally an acceptable compromise: `*b"foo"` is then of type `[u8; 3]`, and `&amp;[u8; N]` will coerce to `&amp;[u8]` with no trouble (except the occasional bit of syntactic noise).
This is brilliant. Makes me try to think what my first contact with Rust was. I definitely remember reading about it when it still had ~ and @ pointers. I was disappointed when they went away, until I realised they were never needed anyway. I'm now using Rust seriously for the first time (although only for Advent of Code) and convinced this language has huge potential and that once the async IO story is better (soooooon!) we should be using it where I work. This whole thread is also a good reminder what a community exists around Rust. You're so nice and so helpful! So helpful actually that I've never had to ask a question - there was always an answer to someone else already! Keep it up! If I ever get time to sit down for more than a few minutes I'll be looking for ways to contribute, but not sure when that might be!
Hi there! :-) Yeah, it's definitely better to focus on the main goal than to maintain generic code at the cost of not reaching the target. Still, it was worth the try and, even more, the input on the fact that it's not the best approach. I would like to follow your progress, hope you have the time to write about it! I will focus on the indexing strategy with the goal of unifying a higher level of knowledge with a lower level of text. I have a fairly good idea, but I am still in the process of refining it, so I am unable to go into further detail. If I write some code, I will keep your project in mind. Maybe we can integrate some stuff. Still a long way for me though! As for documentation, I have published a paper on CLEF 2016 entitled "Index-Based Semantic Tagging for Efficient Query Interpretation", but it focuses on query processing, which is at a different level than I expect to be working in the future.
&gt; and &amp;[u8; N] will coerce to &amp;[u8] with no trouble That's not true. Which is where my annoyance comes from. It's a strange incongruity. Look at the examples here: https://doc.rust-lang.org/regex/regex/bytes/struct.Regex.html#method.captures --- You need to explicitly turn `&amp;[u8; N]` into `&amp;[u8]` in the presence of generics. This also happens when you have `AsRef&lt;[u8]&gt;` and want to write tests using `b"..."` literals. It's not a big deal or anything. Just a petty annoyance. I've never needed or wanted `b"..."` to be an array or a pointer to an array, so I've never experienced the other side of this decision.
Someone already linked Perlin, but it's not the only IR project happening in Rust. There is also [`tantivy`](https://crates.io/crates/tantivy). You may also be interested in my [`fst`](https://crates.io/crates/fst) crate, which tantivy uses but Perlin doesn't. (FSTs are a core data structure inside of Lucene and fit into your low-level disk-based data structure interest quite nicely.) There is also an IR project in Go: http://www.blevesearch.com/ There is also a "loose port" of Lucene to C called Lucy, which you should consider investigating before writing your own in C: https://lucy.apache.org/ There is also CLucene, which appears to be a C++ port of Lucene, but it looks inactive: https://sourceforge.net/projects/clucene/ One of the things that convinces me that implementing an IR engine in Rust is a good idea is the number of JIRA tickets on the Lucene tracker about the pains of the Java GC. :-) A complete IR engine is a lot of work. Good luck. Some of us hang out in IRC on the `#rust-ir` channel of the Mozilla network.
id imagine many of the libs target demographic would be familiar with these names than using the academic conventions
Great work on useful library and application. However I don't really like that some functions take parameters as strings. For example typos wont be caught at compile time. It would be better to use enums or even separate functions.
I'd say you're right.. if your target demographic is someone like me who just wants an easy to use image manipulation API. I'm confused where you would make the suggested naming changes .. without them completely losing their meaning for someone like me. I haven't tried your crate out yet but my quick glance looks great. I will take it for a spin soon'ish I think :) Welcome to the Rust family! :)
Having had only a quick glance I would agree with this. For example, the API for the blur filter has a `mode: &amp;str` that would expect "box" as a value, where a `BlurMode::Box` would be more idiomatic Rust.
Conrod is an immediate-mode GUI toolkit that is heavily under active development. You might be better off binding to a mature GUI toolkit like GTK through something like [gtk-rs](http://gtk-rs.org/). If you want an immediate-mode GUI, you could use the [imgui-rs bindings](https://github.com/Gekkio/imgui-rs). Just because one library doesn't fit your needs, it doesn't mean that the entire language is unworkable, right? The world's fastest &lt;insert here&gt; always seems to have been written in Rust lately, whether that's the [fastest font renderer](https://medium.com/@raphlinus/inside-the-fastest-font-renderer-in-the-world-75ae5270c445), the [fastest templating engine](https://lambda.xyz/blog/maud-is-fast/), the [fastest ethereum implementation](https://www.reddit.com/r/rust/comments/44yaqj/announcing_parity_the_worlds_fastest_and_lightest/), etc. Rust is not "unworkably slow," since people are by all appearances doing work in it, and the resulting binaries are certainly respectably fast. But, as mentioned in another comment, compile times are a serious concern for the Rust compiler team, and there are some big things coming to speed up compilation.
Hmm thats true. I didnt realize that. Thinking in hindsight, my reasoning on the use of string as params was I like its simplicity (ie. slightly less cognitive load than using enums, no need to: use raster::something::enum, and a wrong param is caught in runtime anyways). And it maps well to raster-cli arguments.
Thanks for your reply, I'll give GTK a go and see if that works better for me. Regarding the slowness, as can be seen from my post I meant that the **development process** with rust feels really slow because of the slow compiles and slow debug build execution speeds. Rust programs can clearly be very fast, there's no doubting that. It's just that I would like the amount of time from the moment I make an edit to the time that I can test it to be lower. On the one hand, my experience with one library doesn't mean a lot. On the other hand, if I'm experiencing this problems already while testing out a very simple demo (the conrod default demo app actually), I can't imagine how bad it would get once my app would grow in size. I wonder what the compile times and debug build execution speeds for [servo](https://github.com/servo/servo) are like?
Here are a several requirements of mine to a good image processing lib: 1. Perform all transformations in linear color space. [Here](http://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/) is a good explanation why that matters. 2. Allow to store intermediate images with higher precision. 8 bit per color is too low and will cause rounding errors after each operation. I think the best option is f32 for each channel component which store linear values and are not automatically clamped to 0-1 range. 3. Correctly handle color space information in image files, do not just assume sRGB. This will become more important in coming years as UHD/HDR/Rec. 2020 become more common.
Wow, thank you so much for all the information! I had tried to inspect Lucene previously to try and understand what data structures they actually use to store data in-disk, but it is all a bit unfamiliar to me (it's also why it peaks my interest). I didn't know about tantivy, but it it looks a bit more mature! The FST implementation is particularly interesting to me, indeed! How did you replicate it in Rust? I mean, is there a paper on FSTs I can read or was it reverse engineering? Let's see if I can convince some people in my team that Rust is viable for this project. If so, I hope to be around a bit more. :-)
The Rust community seems to be well aligned with own interests. To be honest, I didn't expect a particular interest in IR. It's nice to see!
&gt; Now if only someone would take an interest in Rust on SPARC to complete the set of targets on the LLVM support matrix. There's [this PR](https://github.com/rust-lang/rust/pull/38314). With it one can build no_std (bare metal) programs for 32-bit SPARCv8 using a custom ("out of tree") target (.json file). What's missing there is support for Linux on 64-bit SPARCv9; that requires way more work (libc/std/rustc/Cargo support). &gt; ...speaking of targets not yet supported by Rust, I really need to look into whether x32 is still seeing any significant interest. [Someone was working on it](https://github.com/rust-lang/rfcs/issues/1339#issuecomment-262201151).
The function `raster::open` seems to call an internal open function, with unwrap, and then only ever returns Ok. It would be better to just return the error. Either create an Error enum and implement the From trait for all of the sub-errors, or use something like https://docs.rs/error-chain/.
&gt; The FST implementation is particularly interesting to me, indeed! How did you replicate it in Rust? I mean, is there a paper on FSTs I can read or was it reverse engineering? I've left *a lot* of breadcrumbs. :-) You can read my blog post on it, which explains the general idea: http://blog.burntsushi.net/transducers/ --- There's a references section too: http://blog.burntsushi.net/transducers/#references I got the idea of the FST from Lucene, but most of the details of algorithm I got from the papers I linked. Lucene is not an easy code base to navigate. It is quite large!
As somebody who has done image processing in a lot of different contexts over the past decades, either terminology is fine. There's no single accepted standard.
Is there any way to hide automated downloads from crates.io? I wish I could see how popular my crate actually is, not how many times crater has been run.
Another vote for enums. The advantages of enums are significant.
If we fully specify the types in your second example we get: fn main() { let a:&amp;u8 = &amp;1; let b1:&amp;u8 = &amp;a; let c1:&amp;u8 = a; assert_eq!(b1, c1); } fn main() { let a:&amp;u8 = &amp;1; let b2: &amp;&amp;u8 = &amp;a; let c2: &amp;u8 = a; assert_eq!(b2, c2); } With the first `main`, `&amp;a` has type `&amp;&amp;u8` (which is why that is the type the compiler infers in the second example), but `&amp;&amp;u8` can be coerced to `&amp;u8` since `Deref::deref` (see https://doc.rust-lang.org/std/ops/trait.Deref.html) only requires `&amp;self`. I think `&amp;&amp;T` coercing to `&amp;T` is actually a special-case that doesn't go through `Deref::deref`, but it's simpler to think of it that way and it illustrates why it is semantically sound. It's similar to how `let a = &amp;5u8` gives `a` the type `&amp;u8`, but `let a: &amp;Any = &amp;5u8` gives `a` the type `&amp;Any`, without changing the RHS of the code, because of coercions.
I wonder what it'd take for ARM to move from Tier 2 to Tier 1. There have been at least a couple serious ARM compiler bugs recently: [37630](https://github.com/rust-lang/rust/issues/37630) affects Rust 1.13 (the latest stable release). [38177](https://github.com/rust-lang/rust/issues/38177) affected Rust 1.15 nightlies.
On the other hand, you lose all the benefits of deterministic builds.
I can’t remember what the practical reasons were why I wanted it to be `[u8; N]` at present, but the ASM version of FizzBuzz at the bottom of https://chrismorgan.info/blog/rust-fizzbuzz.html was able to use it…
Except that 'normal' doesn't mean anything, 'over' means a premultiplied image composited onto another image.
Huh, you're right. The `Result` type sets a clear expectation of passing the errors upstream, but in fact, any error will cause a _panic_. This is broken to the point of being dangerous. I filed [an issue](https://github.com/kosinix/raster/issues/1).
&gt; I wonder what the compile times and debug build execution speeds for servo are like? Extremely bad. Since Servo is split up into multiple crates, you don't have to recompile the entire browser engine every time you edit a file, but we've still been begging for incremental compilation within a crate because we can't split up `script` (i.e. the DOM).
It's a good idea to pass everything by reference if you can: For most use cases (and you specifically assumed that no strange borrow gymnastics are at play) , there is no downside. This makes 2) less relevant now, but where I would draw the line doesn't actually have much to do with the size of the struct. Copying even a large struct, once, isn't actually a big deal. The question is, how often are you doing it, is it "hot code"? It's good to profile your program to know what you can get away with here. Avoid copies and allocations in hot code and you'll have no problems.
Leaving my comment for posterity, but .. yeah. Next time don't just look at the front page. 1) This uses the 'image' crate 2) This only seems to handle image _files_ (what I am looking for is something that accepts an in-memory representation of an image as well) Previous (stupid) comment: Neat! I recently ran into issues (well, I think it wasn't my fault) with the 'image' crate. Awesome to see a potential alternative for a bloody new rust developer.
[Yay! Badges!](https://github.com/ozkriff/zoc/commit/3216636f1) :-D
Agreed. I answered the question with structs in mind, I wouldn't take a reference to an integer type.
https://crates.io/crates/libc/reverse_dependencies This will show you how many things depend on your crate, which is probably a better metric than downloads anyway.
Unless it was a naked function, possibly? Since you can call `alloca` and just not elect to create a new stack frame. Kinda a horrible abuse of, like, everything though, and massively violates the principle of least surprise.
Not given the same seed.
Never push to runtime an error which can be caught at compile time.
Why? Adding something to an enum isn't a breaking change, is it?
The names of lifetimes are never used when you construct references. Lifetime annotations are descriptive, not prescriptive -- by writing the lifetimes in struct/function declarations you promise to the compiler that the objects will live as long as you've said they do. The way you've written this cannot work because `env` and `db` are deallocated at the end of the `new` function. You can't extend their lifetimes just by writing annotations. The easiest solution is just to take out the references, and have `LmdbController` own `env` and `db`. Edit: looking more closely it seems like the `db` object holds a reference to `env`. This kind of a design (the way lmdb-zero works) is a poor fit for rust because you won't be able to store them in the same struct. If there's a way to get the `env` reference back from the `db` then you can skip storing `env` at all, otherwise you will have to split up the struct.
Definitely, using libclang results in a robust (if heavy, due to clang's size) approach. That's what rust-bindgen does :)
As someone that regularly has to deal with POWER and SPARC in his day job (using C++), this attitude is going to make it even harder for me to ever be able to switch to Rust.
There is no reason to add the overhead of runtime string checking 
This addresses two issues close to my heart: - It cleans up (and hopefully speeds up) CI, keeping our queue chugging along - It makes clippy work on stable rustc! woo! yay! finally! :D
Yep! Just run `rustup component add rust-src` and it will be added to `~/.rustup/toolchains/&lt;your-toolchain&gt;/lib/rustlib/src/rust/src`
If you want extensible enums, you can add a "hidden" variant. This prevents exhaustive matchings and force the use of `_`.
I prefer to not notice that piece of information. Otherwise I'd probably consider it deeply disturbing.
I'd like to note that the `Add` implementation on `Cow&lt;str&gt;` optimizes for the empty-string case, which means it can sometimes reduce allocations, thus improving performance just a small bit.
Great initiative! I've been thinking about "planets" too recently. Their static nature is quite appealing, especially if you don't like to install an RSS reader to aggregate multiple feeds. As for domains it's quite mixed on how it's handled. Since the obvious `planter.rs` is already taken I think hosting on github is a good alternative. If you create the e.g. `planet-rust` github organization you can host under `planet-rust.github.io`.
Nice! Now I can proudly show how many empty lines my projects contain! 😀
Why does rustup require Visual Studio on windows? ELI5
&gt; A basic 2D layout takes half a second to show up when we can render entire worlds in 8ms? I would imagine part of it is that reddit isn't in a binary format that's easily digested by a computer.
Writing a Visitor will be more work to write, but more efficient than deserializing to a Value first. Something like this: match value { Value::Object(object) =&gt; { /* X */ }, value =&gt; Pattern::deserialize(&amp;mut serde_json::value::Deserializer::new(value)), }
Right, but couldn't that also be used to do something approaching the ergonomics of cgo aka extract C symbols from the Rust source and implicitly generating bindings for those, but rather than do that through trial and error round-tripping through the compiler use Clang's parsing stage in order to get the type of each symbol?
The best thing is that racer *knows* about this location and finds sources automatically (but only if you install racer from GitHub, crates.io version is very old).
[Its being discussed](https://github.com/rust-lang/rfcs/issues/1795) right now, and considering that the request came from a gecko dev, its very likely to happen.
&gt; Except that 'normal' doesn't mean anything It does actually: In geometry, a normal is an object such as a line or vector that is perpendicular to a given object. Normals are often used in computer graphics too, though it sounds like OP is using 'normal' to mean something completely different...
Nobody depends on my crate, but it'd be nice to see how many people are downloading it. I know it was downloaded at least a couple times, because there was one day it got 7 downloads and all the other abandoned crates got only 6.
There's a difference between reproducible builds and deterministic builds. Having the seed means that if you want to audit a binary, you can rerun the compiler and see that it produces the same result with that seed. However, you still lose out on most of the other advantages. For example, caching and signatures. Or the ability to provide prebuilt system images. Or for that matter, the ability to avoid recompiling the world all the time.
I've missed that `..` everywhere, so I've got a question - is there any difference between `..` and `_` in match statements? enum Foo { Bar(i32), Lol(i32) } // ... match x { Bar(k) =&gt; println!("its bar {}", k), Lol(_) =&gt; println!("its some lol") } // vs match x { Bar(k) =&gt; println!("its bar {}", k), Lol(..) =&gt; println!("its some lol") } // both are valid, does _ and .. mean exactly the same (in this context ofc)? 
`_` is for one thing, `..` is for all the things. Change it to `Bar(i32, i32)` and you'll see what I mean. (`_` doesn't work any more, you need `_, _`)
The borrow checker is one of the few things lisp never had. Which is impressive considering what the lisp family is.
I know this, but is the same meaning? because `_` means "I don't care about the value, do whatever you want" (though `_` is a valid identificator), while `..` means "skip the rest". Is the generated asm the same? We **need** some official Rust **code style guidelines**, at this point I have no idea what I should write in my code so it is semantically and visually pleasant.
[Stability as a Deliverable](https://blog.rust-lang.org/2014/10/30/Stability.html) on blog.rust-lang.org
NeoVim + rust.vim + YouCompleteMe
awesome, thanks for the issue :)
Specialization would allow this, but I don't think it currently allows specializing associated types
Great! Thanks for pointing it out. That's requesting `armv7-linux-androideabi`, where I'm using `arm-unknown-linux-gnueabi`, but I think it'd take a funny sort of breakage to affect `arm-unknown-linux-gnueabi` but neither `armv7-linux-androideabi` nor the existing `i686-unknown-linux-gnu`, so it's just about as good.
Just for the record - there's also the itertools crate: https://github.com/bluss/rust-itertools It allows you to use more functional programming ideas in Rust without the need to write your own iterators / for loops, since it does have a nice collection of tools ready to use.
I don't know what are the exact plans, but [this issue](https://github.com/phildawes/racer/issues/654) exists.
No, this was just a real quick small project(_that took way longer due to deployment problems_). Tokei does use the `ignore` crate for getting files, so folders ignored in a .gitignore, or .ignore file won't be included.
That would be a lot of work since most of the optimization is done in LLVM at the moment: https://users.rust-lang.org/t/single-pass-languages-and-build-speed/8199/6?u=willi_kappler Just emitting unoptimized x64 code is not that difficult.
In the 0.5 timeframe "object" had come to refer to trait existentials, as it means today. There was an earlier period where there was a `class` system, which is how nominal record types were introduced; but they were merged with earlier structural record `rec` types to form the single nominal-record type `struct` we have today. Classes didn't last long, and they're not what's being described here. There was _also_ an even earlier system based on _structural object types_, complete with ad-hoc method replacement on single instances, symmetric composition, overloading etc. (keyword to search history for is `obj`) and it worked completely differently from either of these two features. We've been through .. a lot.
Ah OK, thanks! I was more thinking of only counting `src/` so as not to inflate the numbers from things in `examples/` or `tests/` which are things I wouldn't want to put in a `.gitignore`
&gt; Sometimes it just doesn't matter. There can be more than one way to do a thing. And then we get perl :)
How much of the webasm target is from rust development, and how much is from LLvm? Or are they separate?
Im planning to remove dependency from piston/image and use plain image decoders/encoders. Currently piston/image is just used for opening and saving file formats (which it does very well). Everything else is done by raster. Can you elaborate on #2? The [Image](https://docs.rs/raster/0.1.0/raster/struct.Image.html) struct is a universal representation of an image (doesnt matter if its PNG, JPEG). Image.bytes contains a vector of RGBA bytes which you can manipulate directly if you want.
What would be a cool metric is how many lines of `unsafe` code there are in a project. I can imagine that, as the ecosystem grows, "zero unsafe code" will start to become a selling point, or at least, maybe it should.
Most of the work is on the LLVM side. For Rust it's mostly a matter of integrating the LLVM work and emscripten, but there is some porting in std.
Id love to do that but I dont know whats the de facto benchmarking tool in rust. Im not sure if SIMD is ready. I am thinking more along the lines of multi-threading for resizing huge images like the one in a GoPro. For example pixel rows 0 - 1000 goes to thread 1 and 1001 - 2000 goes to thread 2 for processing. 
&gt; caching and signatures. If 1000 users download the same precompiled binary it'll be cached fine and have the same signature. Am I thinking of something else? &gt; Or the ability to provide prebuilt system images Same situation - why can't I do this? Compile, distribute. All versions would have the same seed, but: 1) That still protects across versions 2) If it isn't a distributed binary, like a web service, or if users can compile it, then there's no issue.
Thanks for the explanation! It's weird, how my brain just hard-wired an association between the fully written-out `mutable` and C++. And I barely ever needed `mutable` there. What was that `syntax` keyword used for? Some early sort of `macro_rules!`?
I also thought about this, however I decided against it for the following reasons. - That is way too specific. Tokei covers 89 programming languages, and adding an additional column just for Rust wouldn't be a good decision. - unsafe code in rust shouldn't be stigmatized, the programming language already prevents you from writing a lot of unsafe code, when someone writes an unsafe block, or function in their library/app. It is a very deliberate decision, not a mistake.
No worries. It is just a philosophy that I subscribe to. Use the type system to ensure correctness as much as possible. I say this as someone who works on a giant monolithic poorly programmed legacy app. Runtime errors are some of the hardest to track down and diagnose, so reducing the number of possible runtime errors today means reducing the amount of production debugging and fixing tomorrow. The places in our code where people do end arounds the type system are often the most fragile. That being said, not all apps are high availability giant monoliths (few apps should be ;) ).
You might like to know that SPARC support for Rust is being [actively worked on](https://github.com/rust-lang/rust/pull/38314).
I don't think` unsafe` should be stigmatized, but rather we should encourage people to limit their surface area with `unsafe` as much as they can--to create safe abstractions around their unsafe code and encapsulate it properly. A crate that advertises "zero unsafe code" would instead depend on crates that focus on abstracting over an unsafe API.
Use Intellij and the rust addon. Trivial to set up and works brilliantly. Updates every other week and they make it noticeable better every time.
This is a Rust anti-pattern. Instead, you should just store the range and construct the slice on the fly: ([playground link](https://is.gd/KMyK3q)) struct MyStruct { long_string: String, slice_start: usize, slice_end: usize, } impl MyStruct { pub fn get_slice(&amp;self) -&gt; &amp;str { &amp;self.long_string[self.slice_start .. self.slice_end] } } fn main() { let string = "foobarbaz".to_owned(); let my_instance = MyStruct { long_string: string, slice_start: 0, slice_end: 6 }; println!("{}, {}", my_instance.long_string, my_instance.get_slice()); }
thanks!
The source code looks pretty good to me. We can make it a lot faster though. If you're only collecting 12 feeds then you don't need a vector to store feed entries. You could design the catcher as an `Iterator` so you can define how many entries that you want to catch, and then you can store those entries on the stack within an `ArrayVec` from the `arrayvec` crate, or do it efficiently with a standard array. Then you won't attempt to catch more entries than you need. I'm not aware of how to design a `ParallelIterator` though. I do see this in `reader.rs` that could be written better: let mut feeds_list: Vec&lt;FeedInfo&gt; = Vec::new(); for feed in feeds_seq { feeds_list.push(parse_feed(feed)); } feeds_list You could write this as just: feeds_seq.iter().map(parse_feed).collect::&lt;Vec&lt;FeedInfo&gt;&gt;()
This makes some sense, though it seems like a major pain if you need to use that slice in a bunch of places, and even more so if you have several such slices in your struct. I'm sure I can get this to work, but it's certainly not pretty. Is it just an anti-pattern because there's no better way to do it in rust right now, or is there actually something wrong with holding a str slice in the same struct as the String?
YUV, CIE, and XYZ are the minimum ones to implement and the most important to do in that order. (I think CIE and XYZ are pretty closely related IIRC). HSV and HSL are also good ones to have available but I believe their popularity is waning. To answer your original question, it looks like they all use CIE.
I use Visual Studio Code (its awesome) and when on the CLI Emacs. The old way to setup rust was logical (download bin and set some env's) and you're ready to go. The new way is not logical. It does only half the things. When installing rustup the default option should be "install rust &amp; download rust-src". The second option could be "install only rust binary" and than the other current present options. That would help a lot.
I don't see how `my_instance.short_slice` is a "major pain" over `my_instance.get_slice()`. You can trivially abstract over this: https://is.gd/hZlQcB &gt; is there actually something wrong with holding a str slice in the same struct as the String? If the compiler allowed this, you could mutate the `String`, cause it to reallocate or simply truncate it, and suddenly the `&amp;str` that was pointing to it is now pointing, either partially or fully, into garbage memory. Not good. Of course, as long as you made sure to redo the slice every time you mutated the string, or just made sure never to do that, you could make this work with some `unsafe` code. But that's extra cognitive load and just asking for bugs that are difficult to reproducee.
The case is a little different here because `String` is a wrapper around a heap allocation, and `&amp;str` is a pointer into that heap allocation. There's nothing specifically wrong with moving the struct in this case, it's more about mutating the `String` and invalidating the `&amp;str`'s pointer. Invalidation by move and invalidation by mutation are both prevented by borrowing in Rust's ownership rules, and for good reason.
I noted that while you were developing this feature, [in the meantime your son was being born](https://github.com/rust-lang/rust/pull/36430#issuecomment-250372225). Congratulations on both being a parent and an awesome Rust dev. :)
You would have to manually download the `regex` crate, build it, and provide rusti the library paths. See [this header in rusti's README](https://github.com/murarth/rusti#loading-crates).
I'm curious, do you find these crates because you go looking for nifty obscure libraries, or because you happen to use them all yourself? :)
Oh, good point, I didn't look closely enough at the type. 2) still applies, though.
This is cool! I really like planets as a way of keeping up with a language community, and I've missed having one for Rust.
Borrows are only tracked in the compiler, it's not dynamic at runtime, unless you mean `RefCell`, which doesn't apply in this case.
Well I could make the struct use an `Option&lt;&amp;'a str&gt;`, and set that to `None` when I create the struct, and the set it to `Some(&amp;self.long_string[0..6])`. This is obviously unidiomatic (and an anti-pattern), but what I really *want* to do doesn't actually break borrowing rules. Ideally I could do something like [this](https://is.gd/m19ymE), but without using `Option&lt;T&gt;`. One question on (2): out of curiosity, what sort of borrow state is held on stack at runtime? I though borrow checking was all done at compile time.
That actually looks like it would work nicely. Coming from python I was a bit skeptical about adding a new method call, but I guess that doesn't matter since the compiler can inline them (if that's even necessary). Thanks.
A geometry normal has nothing to do with the basics of image compositing.
&gt; Id love to do that but I dont know whats the de facto benchmarking tool in rust. There's a simple-but-good benchmark tool built in: https://doc.rust-lang.org/book/benchmark-tests.html I think you still need a nightly compiler, though. &gt; Im not sure if SIMD is ready Yeah, I'd wait 6 months (or more...) for SIMD. &gt; I am thinking more along the lines of multi-threading for resizing huge images like the one in a GoPro. For example pixel rows 0 - 1000 goes to thread 1 and 1001 - 2000 goes to thread 2 for processing. Rayon [https://github.com/nikomatsakis/rayon] would probably be good for this.
Slow response, but... sorry I stole your thunder posting this here. I found it from searching crates.io for "tokio" and thought it was really cool.
&gt; recursive data structures, in owned trait objects both pretty rare in Rust -- I haven't seen codebases that use them enough so that the syntactic overhead of `Box::new()` starts looking ugly. &gt; Also, the complete box syntax is supposed to construct (and deconstruct!) any smart pointer, be it Box, Rc or anything else. This seems very powerful. That doesn't work yet :) `let x = RC &lt;- foo()` might, eventually (you just need to write a new placer and create a placer singleton). 
Well I concede they are a niche case (at least compared to languages like Haskell that use recursive data structures everywhere). But once I knew what `box` could have been, all uses of `Box::new()` started looking ugly.
An import qualifier for imports that should occur during the compilation phase, introducing new syntax. A bit like today's `#[macro_use]` 
Why can't it update itself?
You should have seen old Rust. `~` _everywhere_. Of course, that was because strings and vecs used the same syntax, and there was a lot more usage of box back then (a lot of it unnecessary).
How do you get cargo doc to generate docs for all platforms? I wrote a serial library (https://gitlab.com/susurrus/serialport-rs) and it has a module for windows and another for POSIX, so depending on what platform the docs are generated on it changes the documentation. This is just for the internal docs, the external interface is generic across platforms and not affected by this, but it's annoying that the `serialport::windows` module doesn't show up in the docs.
The 1.14 is creating considerably bigger release binaries. The binary of a small cl program I wrote has increased from 649K to 991K. Is this expected or am I missing something? I have the lto set to true.
Would you take a reference to an i64? The struct mentioned here is only 64 bits (probably), so I think it makes sense to copy.
&gt; NOOOOOO... what happened to `box(HEAP) foo()`? What I remember from that thread: C++ showed that placement new becomes the de-facto the best way to insert something. `&lt;-` is a reasonable syntax for "insert into collection" and "insert into box", while `box` is awkward for insert duty.
Congrats on the release!
I haven't heard of anything specifically.
There's been plenty of writing on the wall about rustup and the ability to install rust's source code with it though, both in this reddit community and around the community in general.
I'm very new. How do I include libraries? I want to use ncurses but cargo install ncurses said that there are no binaries available.
I listened to the talk and it's really interesting stuff. And for the example in the link, I'd be interested to seeing what would be the correct way of doing it.
Do you get no error message at all and nothing happens? Sounds like a bug to me. Make sure you can reproduce it with the latest version of rustup, then file an issue at https://github.com/rust-lang-nursery/rustup.rs/issues.
I'm really honored that the creator of planet itself endorse this initiative ! Thank you !
I really thank you for the advice. I've played a lot with iterators before, and I find them very powerful and convenient. I can't imagine why I haven't think of them for this project ! Thanks again !
This is probably a result of docs not being installed by default any longer. If you run `rustup component list` you'll probably see that `rust-docs` is not highlighted, and if you `rustup component add rust-docs` then `rustup doc` will work. I'll revisit this issue soon.
Hey. So you're involved in the image crate? I hope I didn't come across as entitled or an asshole. My proficiency in rust is quite limited, I described my last one off thing elsewhere in this thread. What I'm trying to say is, I didn't feel ignored. Unfortunately I also didn't feel able to contribute past creating a minimal test case in a bug report :-/ Will watch for changes, enjoy Christmas/your time off though. ;)
wrong sub. You're supposed to go to r/playrust
Another advantage of enums is that an editor can autocomplete it. If you type foo() then inside the brackets it can show a list of acceptable values.
I would prefer `construct_app_dir_path` still since it best describes what actually happens, but I could go for `get_app_dir_path` instead too. To me the `path` part of the name makes it more obvious that the file system isn't actually being touched when calling this function. But your milage may vary of course 🙂
Would be great if there was a web server, similar to Apache or ngingx, written in rust one day.
Simple web framework: https://github.com/tomaka/rouille Another option is to also to directly use Hyper. Or iron. Though it is kind of complicated..
I recently saw the [tokio-process](https://docs.rs/tokio-process) crate, but don't know if it supports streaming output. If it doesn't, the parts to implement it should be all there, though. (I'd imagine you'd want to have a buffered `futures::Stream` for stdout/stderr which can turn into a stream of lines.)
You specify dependencies for a project in your `Cargo.toml`. I recommend reading [the Cargo guide](http://doc.crates.io/guide.html) for a good primer on how to use Cargo.
You could also check [error_chain](https://github.com/brson/error-chain) crate. The related article on [24 days of rust](https://siciarz.net/24-days-rust-error_chain/) is a really nice intro.
[async-readline](https://github.com/dpc/async-readline) might be what you are looking for. However, it's still a proof of concept.
Many formats like PNG and JPG can have embedded color profiles which describe what color space they are in.
these tasks actually belong to the image decoders/encoders. The biggest hurdle with supporting formats like UHD HDR is that the decoders/encoders for these formats are currently non-existent in rust. 
Awesome resource. Thanks for the link!
Hi, I cannot solve an error saying " cannot assign to immutable field `self.a.a_1' ". I created a minimal example of my error, could you please tell me why it doesn't compile ? struct A { a_1 : u64, a_2 :u64 } impl A { fn new(a_1 : u64, a_2 : u64) -&gt; A { A {a_1 : a_1, a_2 :a_2} } } struct B{ a : A } impl B { fn new() -&gt; B { let mut mutable_a=A::new(0,0); B{a : mutable_a} } fn foo(&amp;self) {self.a.a_1+=1} } fn main() { let b=B::new(); } EDIT : forgot to write a part of the code
I've been using iron too, or extended our NodeJs applications by modules via neon for rust bindings. https://github.com/neon-bindings/neon Depending on the usecase i prefere using NodeJs or Go, till i need performance in certain parts. 
On holidays right now so Im just getting started with rust. I'm a ruby on rails dev so some of the concepts from a low level language like rust are a little confusing but im quite excited. Cargo reminds me of bundler which is wonderful. 
Looking at the docs, it looks like you can: * create a `std::process::Command` * tell it to record the process output with `.stdout(Stdio::piped())` * launch the process with `.spawn()`, giving you a `std::process::Child` * grab the child's `.stdout`, which implements `Read`, and read all the lines you want. * once you hit EOF, call the child's `.wait()` to wait for it to exit and then you can get the exit status. You don't need to wait for lines and wait for the child to exit simultaneously - if the child is still printing output, it's obviously still running. If the child exits while you're still processing the last batch of output, the kernel will keep the exit status around until you call `.wait()` to retrieve it.
Why is .. not automatic when nothing else is referred to? that's how it's done in F#
What's the state on the Vulkan side of things?
 error: cannot assign to immutable field `self.a.a_1` --&gt; &lt;anon&gt;:22:21 | 22 | fn foo(&amp; self) {self.a.a_1+=1} | ^^^^^^^^^^^^^ `B::foo()` takes an *immutable* ref, which means it cannot modify its members. You need to change it to `B::foo(&amp;mut self)`. In `B::new()`, mutable_a does not need to be mutable.
You need to borrow self mutably in the foo method. Like this: fn foo(&amp;mut self) {self.a.a_1+=1} Also, for the line let mut mutable_a=A::new(0,0); That doesn't need to be mutable. Mutability is a property of the let binding in that case. It doesn't continue past the new() method.
I don't think nightlies have a schedule beyond "did we manage to build one today" anymore
Thanks, this is much more idiomatic than just storing the bounds in a tuple.
Can you post an example? 
Excellent! Thanks for your the recommendations. I've bookmarked your site link. It will definitely help me get started out. The common consensus here seems to be that Iron is a solid (if more complex) framework. I might give it a go anyway since in the future my site might probably grow beyond my own estimation. Any suggestions for web servers though, or will Apache work out of the box with some rust mod? I see that you were hosting on Github directly, and this worked because your content is basically static, right?
Link to source: https://github.com/mgattozzi/pipers/blob/master/src/lib.rs
Our [readme](https://github.com/gfx-rs/gfx#features) says 40%, but the number is just a guess. There is quite a bit of [code](https://github.com/gfx-rs/gfx/tree/master/src/backend/vulkan/src) covering a large portion of the core concepts, but certain crucial logic pieces are missing. Mainly, a proper resource state management. And finally - it sure has bugs to be nailed out with testing, since we don't have anything rendered yet.
IMHO, it fits in with Rust's desire to be exhaustive with patterns. Just like you have to use `_` to say "I don't care about the rest of them", same with `..`.
It’s crazy / not crazy enough that it’s already a thing :) * https://github.com/brson/mir2wasm * https://kripken.github.io/talks/binaryen.html
This is pretty useful. Negates a need to run things through a subshell. Only needs support for more platforms, and it'd be nice if it supported `&amp;&amp;`/`and`, `||`/`or` like modes in addition to piping.
Yeah basically it was static so I used github! I wanted to move it over to my own site though for professional reasons and being and to exercise more control over the code. I use nginx as the proxy but you should be able to set it up with Apache I would believe. I don't see why you couldn't.
Still trying to wrap my heqd around Tokio and re-writing my WTFTW winfow manager as it it quite old and not very idiomatic. With XCB &amp; Wayland support. And this time EWMH compatible.
That actually would be kind of fun to do and since it's in point free form I could easily add methods for chaining commands. I whipped this up this morning so in the long run I'd like to get more platforms on it. Really my concern is Windows but it is a tier 1 platform so being able to support it will be a huge benefit.
The build system is more or less continuous. Some days, though, none of the updates work:/
I started learning rust yesterday and was playing around with some examples to best understand how the language works. I wrote something like the following, expecting it to work, but it didn't. fn main() { let mut x = 5; let mut z = 3; { let mut y = &amp;mut x; // `x` borrowed here *y += 1; y = &amp;mut z; // `x` "no longer borrowed" (my interpretation) x = *y; // cannot assign to `x` because it is borrowed. } println!("{}", x); } My question is: code cleanness aside, is there any reason that x shouldn't be allowed to be borrowed after the only variable in the scope referencing it starts referencing something else? 
Coincidentally, I was looking at nginx myself after our previous exchange! Yes, it does look quite nice. Thank you for your help! :-)
We also thought at the time that it was a very high priority thing that was gonna be shipping Soon. Oh, and it's only in the "nightly rust" section of the book, where unstable docs go today. I'm actually writing an rfc for "unstable docs"; I'll make sure to add this to my list of stuff to check out.
I'd have a look at https://rocket.rs
I really like pencil.
I believe that you're running into "nonlexical lifetimes", though I'm not 100% sure in this case. That is, rustc's lifetime analsys only looks at lexical scope (if you know what that is), not actual use. Someday, it will: we're working on it, but it takes time.
To expand on what /u/DroidLogician said, that package contains a program called `link.exe` that we use to link Rust code. It's the way you're supposed to do it on Windows, the default way.
Awesome! Is it async by default? I didnt find it in the docs just yet. Keep up with the good work! It looks really good! Edit: Wow I love the website and the docs. Is a plugin system planned?
I've only recently been watching the nightly output with an eager eye, so I didn't want to speculate on prior behavior lol ___ *reads article* Sweet
I started working on logic need support for and/&amp;&amp; and or/|| so I'll let you know when I complete it. I'll see what I can do about getting Windows support. I've got a Windows machine at home and vacation time now!
I am super impressed by the design and content of the website. Nice work!
As a Djangoist I'm impressed the few seconds I looked at the examples. Will look into this more! 
When I'm home later I'll check it out! From a cursory glance yours has more control I believe while this is meant to be "a just do it for me" solution. I'll definitely take a look!
Do you know why they opted for directX instead of openGL?
~~This deserves some benchmarks~~. Congrats for the awesome crate!
 type Point = { X: float; Y : float; Z : float } let p { X = x; Y = y } = x + y let a = p { X = 1.0; Y = 2.0; Z = 500.0 } Result a == 3.0
Given that it's always six weeks, you can always tell when the next release is, even though that is a bit less convenient than having it written out for you.