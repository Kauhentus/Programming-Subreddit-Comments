Yes, I know how to use the unsafe switch. Can you point me to a way to declare the COUNTER variable as an array?
Ah; in that case, you’ll want `Mutex` rather than `RefCell`.
My function is being repeatedly called. I have no control over what is calling the function. I cannot change the arguments of the function. (I can't change it to pass an array into the arguments.)
Sorry, I am relatively new to rust. How would you use Mutex to create an array like object?
Rust is a large, complicated language though. Even if there was an interpreter built, the size of that interpreter would likely be quite large. My understanding is that dyon is a much smaller language and this makes it better for embedding. There's also the fact that a rust interpreter doesn't exist, and building one would be a much larger feat than making dyon was (and that was still a pretty big thing).
@japaric is away for a few weeks. Normal service will resume soon!
Oh my goodness, yes!!
Thank you! Will give it a try soon.
The usual use-case for `Rc` is to move a stack-value into it: `Rc::new(MyStruct::new())`. Thus having it inline reduces the number of allocations required (which is usually the expensive option). In your case what you could do instead is to call `String::into_boxed_str`, which gives you a `Box&lt;str&gt;` which you can then move into the Rc, giving you an `Rc&lt;Box&lt;str&gt;&gt;`, which auto-derefs into `str`.
Same as `RefCell`. You use the type `Mutex&lt;[u8; 1000]&gt;`.
You probably have to tell bat that you want colour with something like `color=always`, otherwise it will see that you are piping and disable colours. Also `less -R` to interpret escape sequences.
Your initial proposal couldn't work: if a `Rc&lt;T&gt;` directly contains the strong and weak counts, then two or more `Rc&lt;T&gt;`'s owning the same `T` do not share the same `strong_count` and `weak_count`. So an `Rc&lt;T&gt;` _has to_ point to one shared out-of-line-allocated object. At that point, the reason for the current layout is probably obvious: there's no point in adding another indirection, since `T` is known anyway.
 error[E0015]: calls in statics are limited to struct and enum constructors static s: Mutex&lt;[u8; 1000]&gt; = Mutex::new([0; 1000]);
&gt; In practice, I imagine the field ordering is deterministic, is it not? Or are you suggesting that changing the rest of the program may result in a different field ordering? Yeah that wouldn't be great. I was going to say that the order is intentionally random, but it looks like this is not implemented yet, as [this issue](https://github.com/rust-lang/rust/issues/38550) is still open? Maybe someone with more in-depth knowledge of the compiler knows for sure. 
And you can even maintain your own `crates.io` clone with your dependencies frozen as you see fit if you don't trust `crates.io`. Additionally in this specific instance, `num_traits` is one of the more popular libraries and has a decent number of eyes on it.
Arrays are declared using \`array\_name: \[array\_type; array size\] = \[init\_value; size\]\`: Here's a playground which tries to match your question: [https://play.rust-lang.org/?gist=151c7a576e55ebb18936504ef36fa8c3&amp;version=stable&amp;mode=debug](https://play.rust-lang.org/?gist=151c7a576e55ebb18936504ef36fa8c3&amp;version=stable&amp;mode=debug)
Yeah I guess that's a good solution. They originally were just `Rc&lt;Strings&gt;` which is close to the same I guess but I decided to turn them into `Rc&lt;strs&gt;` thinking that would save indirection but it actually added to it.
Yeah that makes sense I guess. A better approach for my use case is probably putting it into `Rc&lt;Box&lt;str&gt;&gt;`
I see you already linked the excellent Scratchapixel series in your Raytracer posts. You might be interested in this series, there's some GPU stuff in there too: http://aras-p.info/blog/2018/03/28/Daily-Pathtracer-Part-1-Initial-C--/
It does save an indirection at the cost of a new allocation
found this one yesterday, not complete but looks interesting: https://aturon.github.io/apr/async-in-rust/chapter.html
Oh my god, thank you.. I thought I tried this earlier.. Here it is, working. Thank you!
Oh, ok thanks for info, I was a little worried. Good to hear everything is alright. Looking forward for more exciting updates from embedded world :)
[Look at the traits in num.](https://docs.rs/num-traits/0.2.4/num_traits/trait.NumRef.html) I believe you have to use the `for&lt;'a&gt;` syntax but I don't exactly understand why. I'm sure someone else can explain better. For example, I don't know if [this is the correct way to use it](https://play.rust-lang.org/?gist=d5b6c939047637328645549bc645d88d&amp;version=stable&amp;mode=debug) but it compiles.
This already exists ;) https://crates.io/crates/query_interface
This crate is not mine, just an example that I know of. The `[lib]` section of `Cargo.toml` is optional: everything in it has a default value. [https://doc.rust-lang.org/cargo/reference/manifest.html#configuring-a-target](https://doc.rust-lang.org/cargo/reference/manifest.html#configuring-a-target) A library is compiled by default if `src/lib.rs` exists. The different values of `crate-type` are documented at [https://doc.rust-lang.org/reference/linkage.html](https://doc.rust-lang.org/reference/linkage.html). When linking Rust code into a C or C++ program, you will most likely need to have a `staticlib` or `cdylib` crate (for static or dynamic linking respectively). I’m not sure if things work if you have more than one (you might end up with multiple copies of the standard library?) so it’s safer to have only one. `encoding_c` is not a staticlib itself because it can be used in a larger staticlib that depends on many bindings crates, for example: * [https://searchfox.org/mozilla-central/source/toolkit/library/rust/Cargo.toml](https://searchfox.org/mozilla-central/source/toolkit/library/rust/Cargo.toml) * [https://searchfox.org/mozilla-central/source/toolkit/library/rust/shared/Cargo.toml#20](https://searchfox.org/mozilla-central/source/toolkit/library/rust/shared/Cargo.toml#20)
Not particularly relevant, but could you not use a [clone-on-write](https://doc.rust-lang.org/std/borrow/enum.Cow.html)?
No it's in this case an issue of references. A CoW still still has a reference to some places it's canonically stored. I have a bunch of structs which each contain like 50 potentially long strings which never need to be changed when initialized but depending on I/O I often need to create a new struct from an older one where only one or two strings are different. Thus an Rc seemed optimal to me in that it doesn't clone the strings then and only rplaces the 2 I need to change.
Rustic.
Why convert String to Rc&lt;str&gt; though? Why not String to Rc&lt;String&gt;? That way there is no linear copy, because you move only the 3 words (size, capacity and the data pointer) from stack to heap, while leaving the original String storage intact.
Cool! Interesting that you did exactly the features I was thinking of (like dynamic registration of interfaces)! What are your thoughts on this technique overalk?
You can hardly blame the author for that when the space is so throughly dominated by cuda.
Yep! You can see my comment deeper in this thread when I found out.
How easy is it to integrate cuda c gpu code with a rust project. In my case there's a small portion of code I'd like to run on the gpu and would like to keep the rest in rust. 
I currently write about 6k points/second to influxdb running on a cloud server with 4 cores and 8gb ram. It's kind of like the roach motel of databases though ("they check in, but they don't check out.") easy to write to, a pain to get all the data back out. Aggregate queries are mostly very fast though. 
I've learned many languages, and c++ was the first I was taught. But I haven't been able to find anything like the rust book to dive back in. 
It's not good practice to jump on this technique to solve every problem, but having it available as a last resort is pretty useful.
I've never been able to read other people's code more easily than with rust, that's one place it's definitely "easier".
i dont think rust would suit interactive/dynamic use .. i think its hard to design a language that can do both extremes well
Maybe you could just use a `thread_local!` instead? It wouldn't be as efficient if you're doing threading but it is otherwise equivalent to `lazy_static` and included in the standard library.
You put it in an Option and allocate if its none. Or if you have nigntly you could try StaticMutex.
Congrats!
Thank you!
I hope to see some Rust scripting environments one day. Dyon is certainly on the extreme opposite end of this spectrum compared to Rust. Wish there was a way to load Rust libraries dynamically. So far, my experiments have failed.
Basically you define the trait for `&amp;Type` instead of `Type` It's purposefully chosen to be `Type` instead of `&amp;Type` because you can promote a call-by-value to a call-by-reference by doing it like that but not in reverse. Remember that `&amp;Type` is a fully fledged type that is `Copy`.
`rustc --explain | mdcat` is what you want, maybe. https://github.com/lunaryorn/mdcat
My first substantive creation in Rust, criticism and advice welcome.
![](https://phaazon.net/media/uploads/rust.jpeg)
Cool project! A few notes: * The benchmarks are not in the repo (while `cargo bench` only works on nightly, adding the `bench` directory to the repo doesn't mean that using the crate itself requires nightly Rust, so feel free to do that) * You can improve the benchmark output by setting the `bytes` field of the [`Bencher`](https://doc.rust-lang.org/test/struct.Bencher.html) - this will output the throughput in MB/s or GB/s, which might be a better metric for these functions than time * The readme says that passing `-Ctarget-cpu=native` is required for SIMD, but it also says that your library is doing runtime detection for SIMD instructions. This is confusing me a bit. If you're saying that you're doing runtime detection, I'd expect that I don't have to explicitly set the target CPU either.
Thanks for the tip! I suppose I should add some notes that this whole crate requires nightly until 1.27 drops! If you compile without a cpu target that supports these instructions, the compiler will turn the intrinsics back into scalar code, and the runtime detection will detect avx2, for example, run it, and it will work, but it will be slow because it didn't get compiled with avx2 instructions. 
I'm afraid I don't know. I'm sure there must be some way to get \`nvcc\` to produce a PTX file, at which point you could look at Accel's source code to figure out how to load and launch it. If you figure it out, maybe write a post of your own and let us all know how you did it!
The `#[target_feature]` attribute can be used for this. You put it on a function like this: #[target_feature(enable = "avx2")] and the function will be compiled with `avx2` enabled. It's still unstable at the moment ([RFC](https://github.com/rust-lang/rfcs/blob/master/text/2045-target-feature.md), [tracking issue](https://github.com/rust-lang/rust/issues/44839), [stabilization discussion](https://internals.rust-lang.org/t/pre-rfc-stabilization-of-target-feature/5176)), but I expect that it will be stabilized along with SIMD support since it's so incredibly useful for it.
Thanks, I'll give that a try. 
&gt; but I expect that it will be stabilized along with SIMD support since it's so incredibly useful for it. It will be! You basically wouldn't be able to write code based on runtime detection without it. (You end up hitting the performance bug described by /u/jackmott2.) 
I also always recommend Criterion over the built-in nightly only benchmarking stuff. Criterion works on stable, and it is a lot better.
Thanks, that did the trick, I've updated it it.
Usually if it can use iterators and combinators, that is preferred as the idiomatic way of doing things compared to the procedural if and else branching pattern way. Also, using patterns to check and extract things is most idiomatic compared to if and else branches. Stringly APIs are not considered idiomatic. I would also say that some crates are idiomatically used, like how serialization and deserialization traits in serde are idiomatic to implement to get integration with things like rocket and anything else that cares about serialization/deserialization. Not many other things define idiomatic Rust that I can think of, but hopefully the comments will bring in some more things.
Oh wait. I realize now this is about the name used for idiomatic code. Whoops.
Thanks, someone else mentioned it, I'll give it a try soon.
[hyper](https://hyper.rs/); HTTP library built on top of tokio. I'm kinda suprised no-one else has mentioned it in this thread.
https://internals.rust-lang.org/t/site-to-vote-express-interest-in-libraries-which-are-most-needed/7742
[removed]
I had a similar problem, it looks like those pages have updated their identifiers, but Cargo hasn't reflected that yet. "GPL-3.0" and "GPL-3.0+" are what you're after.
Thanks that worked!
If you want to view it offline but don't mind it still being in a browser, you can get the error explanations in rustdoc --open.
A usage example would be helpful as well as more than one sentence of description. Take a look at other crate readmes for reference.
+ If OP wants an immutable heap-allocated string, then it will be a `Box&lt;str&gt;` anyway, not an `str`.
Thanks for pointing that out, I relied heavily on doc comments and integrations tests in /tests, I should make it available on the homepage like other crates do I will need to learn how to do that. 
It's actually already existed for 2.5 decades, you've rediscovered the basics of [COM](https://en.wikipedia.org/wiki/Component_Object_Model). 
Yeah, exactly. There's a link to COM Wikipedia page in the article.
Ah, I missed that bit.
Isn't NLL also a borrow-checker (lifetime analysis is borrow-checking, right)? Is Polonius an update on the latest implementation of NLL, or is it another from-scratch implementation of borrow-checker? I'm a bit confused about the terms.
This was really helpful. This blog post is probably really good to those who already know the types of variance that exist (and what the heck they are) but I was lost for half of it.
This is really cool, will certainly try your crate for this one project that's already on my TODO list for some time :P A few nits: - It's always nice when the repository contains a link to the `docs.rs` documentation. You might add a badge or put the URL in the URL field of the repo's description. - The variant `FBM` from the `NoiseType` enum should be called `Fbm`. - I think you could improve the API in a few places: - [`get_3d_noise`](https://docs.rs/simdnoise/1.0.2/simdnoise/fn.get_3d_noise.html) (and the 2D version, too, I guess) takes too many numerical parameters IMO. Look at this call: `get_3d_noise(0.0, 200, 0.0, 200, 0.0, 200, fractal_settings);`. Many magic numbers and from reading the call, you have no idea what which thing means. It might be nice to use a builder pattern instead. Or maybe at least group `offset` and dimensions into two tuples. Like `offset: (f32, f32, f32), dimensions: (u32, u32, u32)`. Or... something else. There are quite a few ways to avoid confusing call-sites. - In the [`FractalSettings`](https://docs.rs/simdnoise/1.0.2/simdnoise/struct.FractalSettings.html) documentation, you say that only the `freq` field is used when using `Normal` noise. That's a bit suboptimal. It's probably best to put those into the `NoiseType` enum. Something like: pub enum NoiseType { Fbm { lacunarity: f32, gain: f32, octaves: u8, } Turbulence { lacunarity: f32, gain: f32, octaves: u8, } Normal, } Or are the parameters on `Fbm` only needed because its an addition to "simplex + turbulence"? Then you might integrate that into the builder pattern? Something like `Noise::from_frequency(3.0).with_turbulence(lacunarity, gain, octaves).with_brownian_motion()` - You might want to consider returning something else than a `Vec&lt;f32&gt;` or indeed replace the whole tuple you return. Maybe just define two types, `NoiseData3d` and `NoiseResult`, where the latter is defined as: struct NoiseResult { min: f32, max: f32, data: NoiseData3d, } And the `NoiseData3d` would then allow easy access via x, y, z coordinates. You can still allow access to the underlying `Vec`, of course. So that's what I noticed for now. Maybe it's useful information for you ;-) And don't forget to take a look into the [Rust API Guidelines](https://rust-lang-nursery.github.io/api-guidelines/). 
The homepage just copies from you `README.md` file in the repository. I'd suggest just copying some simple examples into the README from your test/comments and adding a bit more explanation. ---- I think I would also recommend just a quick sentence about what blind signatures are, and why someone would want them. I'm sure people who are looking for your crate exactly will know, but it's nice for anyone who doesn't have domain knowledge.
&gt; Hmm, I may be misunderstanding the term "memoization", then. I thought it meant exactly what my crate does. Could you elaborate? To me, memoization is a transformation of a function so that it caches its results, thus requiring fewer computations. They key element here is that the function signature doesn't change. A fancy memoization library would allow multiple pluggable caching strategies, such as fixed buffer LRU, or arbitrarily growing buffer. Whereas your library is a transformation of a function and a set of arguments into a nullary function that calculates the underlying result on first call and just returns it on subsequent ones.
I don't know anything about the domain, but a superficial issue is that your formatting doesn't use the standard rust style. If this is a deliberate choice then fair enough, but if not then \[rustfmt\]([https://github.com/rust-lang-nursery/rustfmt](https://github.com/rust-lang-nursery/rustfmt)) can help.
This is wrong on both parts. The first part is dealt with already, so let's look at the second. `'static` doesn't guarantee it'll ever drop. I can take an &amp;'static T and pass it to mem::forget() and it'll never be dropped. Furthermore, statics do not have their destructors run on program termination either.
There are so many similarities there that it's very hard to understand why you decided to go your own way. I hope you'll consider adding some paragraphs on that reasoning, e.g. in what way ggez works fundamentally different from what you're doing with Quicksilver.
So, does this mean, i can create lot of references of that 'static data ?
I never understood how to get that bencher output before, thanks! I don’t suppose you know what other options there are, like frequency instead of period or operations per iter? Thanks!
Here's somewhat different approach just for comparison. It's not as efficient but doesn't use any unsafe magic other than mopa (to work around a flaw in the design of Any). It's based on Simon Marlow's "An Extensible Dynamically-Typed Hierarchy of Exceptions", which describes how the Exception hierarchy works in Haskell. Only tree hierarchies are supported (i.e. single inheritance only). How useful this is in practice, I have no idea :P https://github.com/Rufflewind/_urandom/blob/da71b8b23bc90407c371d651a09d3128654c76d7/rust/dyn_trait_hierarchy.rs
Is there a way I can send a trait bound into a macro? Apparently `$t: ty` does not work due to [this old issue](https://github.com/rust-lang/rust/issues/20272) and `$t: ident` doesn't work for a non-trivial trait bound such as e g `Iterator&lt;Item=u32&gt;`.
&gt; If you compile without a cpu target that supports these instructions, the compiler will turn the intrinsics back into scalar code, and the runtime detection will detect avx2, for example, run it, and it will work, but it will be slow because it didn't get compiled with avx2 instructions. This doesn't make any sense. If I need to compile to a specific target for this to work, why does it do any run time detection at all?
First: remove the dot from &amp;reved.); Second: borrow to_rev The line should look like this: let my_new_str = my_str.replace(&amp;to_rev, &amp;reved);
I'm assuming that the extra dot that is in your linked code should not be there. First non-self argument to `str::replace` is `impl Pattern&lt;'a&gt;`. Currently `Pattern` is implemented for the following types: * `&amp;String` * `&amp;str` * `&amp;&amp;str` * `&amp;[char]` * `char` * `impl FnMut(char) -&gt; bool` You passed a `String` which is not on this list, and therefore you get a compile error. Now the error messages comes from how the compiler tries to find a suitable implementation. First five `impl`s are for concrete types and do not match, but the last one is: impl&lt;'a, F&gt; Pattern&lt;'a&gt; for F where F: FnMut(char) -&gt; bool { ... } `String` can be matched to type parameter `F`, so the compiler proceeds. Now it tries to check the bound `String: FnMut(char) -&gt; bool` which does not hold, and you get that in the error message. To fix this you just need to pass `&amp;String` instead of `String`.
The error message without the borrow is not so great. The compiler should have stuck to `no instance of Pattern for String`, seems like? The `FnMut` is only confusing the issue.
My biggest dream for Rust is to generalize async/await to arbitrary effects. Something like effects in OCaml (that may land by the end of the year). Would make Rust the best language!
It's easiest to use a blind `tt` matcher: ($t:ty, $($bound:tt)*) =&gt; { impl&lt;T: $($bound)*&gt; $t&lt;T&gt; { ... } } If you need to put something *after* the bound, enclose it in a group (`(..)`, `[..]`, `{..}`).
&gt; just in general that putting anything on the heap into an Rc performs a clone This part is not right, in Rust semantics, the value is moved and not cloned, into the Rc. This is whenever you use `Rc::new`. And we can't use `Rc::new` to go from String to `Rc&lt;str&gt;`, it's a separate kind of operation (and separate method) that indeed copies all the string data.
RemindMe! August 12, 2018
I will be messaging you on [**2018-08-12 09:51:21 UTC**](http://www.wolframalpha.com/input/?i=2018-08-12 09:51:21 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/8pdixg/writing_handson_concurrency_with_rust/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/8pdixg/writing_handson_concurrency_with_rust/]%0A%0ARemindMe! August 12, 2018) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
You can use `Vec::&lt;TypeWithCorrectAlignment&gt;::with_capacity()` and then `mem::forget()`
&gt; Not many other things define idiomatic Rust that I can think of There is a whole suite of guidelines for API design: https://rust-lang-nursery.github.io/api-guidelines/ Also, I'm not sure I buy some of what you said. Many folks, including myself, find combinator heavy code difficult to reason about. In general, I've found that striking a balance has been a good path for me. But this means you can't say things like "it's idiomatic to use combinators instead of `if`" because it's too much of a generalization.
The OP didn't know about `#[target_feature]`. Some people may still want to compile with certain target features (or target CPUs) enabled to get those optimizations across the entire program. But yes, this is generally orthogonal to runtime detection.
Any chance of this becoming a no_std crate (with a Feature flag)? 🤔 
You can use [the escaped! combinator](https://docs.rs/nom/4.0.0/nom/macro.escaped.html). First argument is the parser for normal slices in the string (ie, any printable character except `"`and `\`), second argument is the escaping prefix, `\`, third argument is the parser for escaped content (for some format, this might span multiple characters). This version does not replace the escaping character, escaped_transform! does.
It works, thanks! I had the feeling that you could do something with `tt` but couldn't get the syntax right.
rusty
r/titlegore
`bytes` is the only option you can set. However, there's also [Criterion](https://github.com/japaric/criterion.rs/), an alternative benchmark runner that works on stable, which might support what you're looking for. The integrated `#[bench]` support is practically deprecated right now. It works okay, but requires nightly and only has the bare minimum of features.
Thanks, I’ll look into Criterion. :)
You could probably use ‘libc::posix_memalign()’ if you’re on a posix system, when you need to free the memory call ‘libc::free()’. 
Just use `u32::max_value()`.
Thank you!
Well... No. Since the type is static, it cannot contain any reference to any non-static object, and since the object is consumed, it cannot be referenced at all. 
but this would only work on posix systems, I'd like this to work on windows for example as well
I think for now your best bet would be to use config-attributes to switch between ‘posix_memalign’ and ‘_aligned_malloc’ compile time. 
And to make `TypeWithCorrectAlignment` you can use `#[repr(align(16))]` and `#[repr(align(64))]` 
Or just use `u16` or `u64`
You are right. It is fixed now. 
I already thought of this, but the problem is that the memory I'm allocating isnt of a fixed size, so I cant simply have a struct around it can I 
Thanks, some interesting ideas to try. I think most consumers of the crate will be expecting/preferring a Vec&lt;f32&gt; since they will be working with data in that form anyway with most image/rendering apis. I'm definitely going to see how it feels putting the fractal settings in the noisetype enum though. 
The big distinction to me is that Quicksilver is pure-Rust and can compile for web with `wasm32-unknown-unknown` whereas ggez has a dependency on SDL2 and requires emscripten to build for web.
I've always thought dyon looked super cool, and this looks great. Is there a REPL / any plans for one?
was it C or C++ that you learned? C is a simple and beautiful language IMO.
cpp. ;)
No way in hell you're going to learn even the fundamentals of cpp in a week. Hell many people don't even understand pointers after just a week 
I think that's where the `with_capacity(n)` call on the vec can help you. Divide the total number of bytes you need by the size of your alignment struct and use that to size the vec?
The \`std::alloc::alloc\` function will be stable in 1.28 [https://doc.rust-lang.org/nightly/std/alloc/index.html#functions](https://doc.rust-lang.org/nightly/std/alloc/index.html#functions)
Note: I think you were mislead by the 16 and 64 here. `align(16)` is to aligned on a 16-bytes boundary, while `u16` is only guaranteed to be aligned on a 2-bytes boundary (it's 16 bits).
`!0` is yet another way to write this.
There’s [this podcast](https://request-for-explanation.github.io/podcast/ep6-everything-and-the-kitchen-async/index.html) about the original RFC. And this series by withoutboats - [first](https://boats.gitlab.io/blog/post/2018-01-25-async-i-self-referential-structs/) - [second](https://boats.gitlab.io/blog/post/2018-01-30-async-ii-narrowing-the-scope/) - [third](https://boats.gitlab.io/blog/post/2018-01-30-async-iii-moving-forward/) - [fourth](https://boats.gitlab.io/blog/post/2018-02-07-async-iv-an-even-better-proposal/) - [fifth](https://boats.gitlab.io/blog/post/2018-02-08-async-v-getting-back-to-the-futures/) - [sixth](https://boats.gitlab.io/blog/post/2018-03-20-async-vi/) - [seventh](https://boats.gitlab.io/blog/post/2018-04-06-async-await-final/) - [eighth](https://boats.gitlab.io/blog/post/async-methods-i/) - [ninth](https://boats.gitlab.io/blog/post/async-methods-ii/) 
It's not Rust specific, actually: std::cout &lt;&lt; uint32\_t(-1) &lt;&lt; " " &lt;&lt; std::numeric\_limits&lt;uint32\_t&gt;::max() &lt;&lt; std::endl;
Its worse than that though, because compiling the whole thing with AVX2 enabled would mean your regular code has AVX2 instructions in it too, and wouldn't even run on a machine without it! So the target\_feature attribute is necessary.
Fair enough. I do agree that using combinators when its less clear can be bad. For instance, causing side effects should be done in a for or an if. I am a big fan of commenting combinator calls to clarify what happens in each step as well to avoid clarity issues.
Like many Rustaceans, my experience in Rust has surpassed that of "beginner" but is perhaps on the leading edge of "intermediate". I can easily write toy programs in Rust, and Rust's syntax feels comfortable to me. I want to move on to making larger more complex programs in Rust but I'm having trouble on where to begin. I think a good next step would be to watch some live coding videos for small-ish crates. I found a bunch on Youtube, but it is difficult for me to discern the quality of such a video given my inexperience. I am familiar with [Ferris' N64 emulator videos](https://www.youtube.com/watch?v=Fsi9HPcyrU8&amp;list=PL-sXmdrqqYYcL2Pvx9j7dwmdLqY7Mx8VY) and they seem to be very good videos, but I am looking for something smaller scale (and maybe only 3 hours rather than ~100). Does anybody have any suggestions?
Oh! You’re right, I misread OP as saying “bits”
Nobody at my work that uses C++ (including myself) wants to continue to deal with it, but legacy software is written in it and it must be used. We have started using the Conan package manager to achieve easier dependency management in C++, which definitely helps, but there is always another problem with C++ builds doing something weird because there are too many variables. With Rust I have only had an issue with compiler releases breaking nightly packages (and sometimes older stable packages too O.o), but generally things can be solved quickly and you don't have arcane issues like Windows.h including winsock 1 unless you define a special macro, symbols being declspeced when making a static library, or linking to two different VC++ runtimes or having mixed static and dynamic linkage. Those are all windows-specific issues, but builds on Linux also sometimes have weird issues with the order in which libraries are linked, which sometimes on older ld will cause symbols to not get read from the .a files. Lets just say there are lots of insane non-essential tasks that make C++ development slow, and people have been trying to work around this for a long time. Nobody should have to know any of these things; it's like forbidden knowledge. Going cross platform just makes you go ever so slightly more crazy.
Thank you! That's good to know.
Hehe, so C++ is one of the biggest obstacles in our way to rust ;) Thank you for &lt;i32, _&gt; that's really helping me.
As /u/geaal said, you can use the `escaped!` combinator for string literals or the `escaped_transform!` combinator if you need escaped characters. [Here](https://github.com/yodaldevoid/dts_viewer/blob/1e018ea9cc7bafbfc0ef9a432c89690e66ab503a/device_tree_source/src/parser.rs#L435-L448) is an example from one of my projects. It should be noted that this project uses nom 3, but I don't think the `escaped!` combinator has changed since then.
The refcounts need to be behind the pointer so that they’re shared between multiple references. If you always start from a `String`, then using `Rc&lt;String&gt;` or `Rc&lt;Box&lt;str&gt;&gt;` (with `String::into_boxed_str`) might be better for you.
The idea is to wrap into box at every level, so you can use cast to a concrete type of box, right? So in the example above, upcasted "Wolf" is Box&lt;Object&gt;, where Box&lt;Object&gt; is box with Box&lt;Animal&gt;, where Box&lt;Animal&gt; is box with Box&lt;Canine&gt;, where Box&lt;Canine&gt; is box with Wolf? To downcast, you need to "advance" reference to you destination type. If you are casting to "Wolf", you are expecting a chain of concrete types "Box&lt;Animal&gt; -&gt; Box&lt;Canine&gt; -&gt; Wolf"?
Huh. I tried this but my test routine gets stuck in an infinite loop. ``` named!( string_literal&lt;nom::types::CompleteStr, Token&gt;, do_parse!( s: delimited!( tag!("\""), escaped!(take_until_either!("\"\\"), '\\', one_of!("\"\\")), tag!("\"") ) &gt;&gt; (Token::StringLiteral(s.0)) ) ); ``` Here's the test backtrace: https://gist.github.com/thejpster/90989e6ed1208cf819de4d9783a730f4 
Huh. I tried this but my test routine gets stuck in an infinite loop. ``` named!( string_literal&lt;nom::types::CompleteStr, Token&gt;, do_parse!( s: delimited!( tag!("\""), escaped!(take_until_either!("\"\\"), '\\', one_of!("\"\\")), tag!("\"") ) &gt;&gt; (Token::StringLiteral(s.0)) ) ); ``` Here's the test backtrace: https://gist.github.com/thejpster/90989e6ed1208cf819de4d9783a730f4 
I tend to say Rusty for the most part, sometimes Rustic.
I opened an issue: https://github.com/rust-lang/crates.io/issues/1435
Massive hack: If you need to allocate n bytes with alignment a, then maybe you could allocate n + a bytes. In that range, there must be n bytes with alignment a somewhere.
Fun stuff. Thanks for sharing! * Documentation: * The function block comments should all be doc comments (`///`) with properly-formattted Markdown even for the non-public functions. It's really helpful to be able to format the internal documentation when working on the crate. * More examples (`#Examples`) would be good. * As others have noted, the top-level block comment should be greatly expanded to explain the crate thoroughly. An overall example of how to use the crate to do something interesting should be given. * Are there enough tests? It's hard for me to tell, but it seems like inline unit tests for the interesting functions in the crate would be a good idea. If you add examples, they will be treated as doctests. * As others have noted, the style of the `use` declarations is non-standard: I get it, but find it hard to read because it's not what I'm used to from elsewhere. Would suggest a more standard "one-line" use style. * There are "extra" curly braces and parentheses at various places in the code. Minimizing these makes things easier to read. * Too lazy to do the research: are there patents that apply to this code? If so, please note them in the documentation. * Indicate the author and license information for the crate in the `README.md` and in the crate block comment. Put copyright notices there and on all source files. I'm in the middle of grading 22 Rust course projects right now, so apologies if this all seems too nitpicky and not helpful. This looks like a great crate.
Or `u32::MAX` if you need a constant.
Come up with a library idea and make a wire frame, then dive right in
What is the benefit of a non-empty vec over a standard one?
What's the motivation for having a non-empty Vec? For most algorithms I could think of right now, you'd need to check the length separately anyway.
I can't speak for OP, but when dealing with arrays and vectors (and many other data structures), empty is often an edge case that is handled differently. With a non-empty vector you could always sum, get the first element, get the last element, etc.
Exactly. In my case, my first need is the [glsl](https://crates.io/crates/glsl) crate. For instance, [nom](https://crates.io/crates/nom) gives you functions like `many1`, giving you vectors with at least one element. I’d rather like a datastructure that expresses that in its type, like `NonEmpty&lt;_&gt;`. :)
If this is all you need, would a slim wrapper around a `Vec` be enough? It's possible that a constructor guaranteeing at least one element and simple function wrappers could be enough. 
ok, that might be a bug, probably linked to [#787](https://github.com/Geal/nom/issues/787). I'll try to take a look
You can get a sum for empty vec as well. `vec.iter().fold(0, |acc, x| acc + x)` As for "getting the first/last element" - you moved the edge case from one place to another, but instead of processing your actual issue, you now need to process the Error produced by the constructor of `NonEmptyVec`. It's possible to make "non-emptyness" an invariant by abusing the typesystem and types like `(T, Vec&lt;T&gt;)` or `(T, &amp;[T])`, but there's plenty of problems with that.
Yep, exactly. That’s the current implementation I’m writing.
Erm, I already explained why `(T, Vec&lt;T&gt;)` is not wanted. And this is not *abusing the typesystem*, though. :) The idea is to statically prove that a vector cannot be empty, so that you don’t have to test that at runtime when you want to get the first element, or if you need a safe `fold1`.
Ah. Thanks!
We have published the `vec1` crate (https://github.com/1aim/vec1) a while ago, does that help? We use it in our new mail project.
Now this is only tangentially related to Rust, but I've made some benchmarks of a specific rpc scenario, if you're interested you could head over to the blog post about it: https://github.com/KillTheMule/KillTheMule.github.io/blob/master/benchmark_rpc.md I'd be grateful for any comments :)
I'm using [this](https://github.com/sdras/night-owl-vscode-theme) at night and quite like it
This forum is for the "Rust" programming language: [https://www.rust-lang.org/en-US/index.html](https://www.rust-lang.org/en-US/index.html) You are looking for the r/playrust sub-reddit
I think this is a question for /r/playrust rather then the Rust programming language.
Could wasm based modules be a solution here? What would be most excellent is a language agnostic module and abi, something that surpassed the c abi in expressiveness. 
Although the video still contains a lot of mistakes and I could have done a better job at finishing it on time, I still think that property-based testing is an interesting topic and so I shared it. The episode is split into two parts: The first part is writing a parser for the following informal English date format: "15th of May 2015". The second part covers property-based testing using the awesome proptest crate by AltSysrq: https://github.com/AltSysrq/proptest For most people here, the presentation style might be a bit too detailed, in which case I recommend to watch the video on 1.5x. Next time I'll fast-forward some of the typing. Lessons learned: * The video is a bit too long. Next time I should make two parts out of it. * Don't edit videos when you're tired. You WILL make mistakes which are hard to find. I had to re-upload the video because of that. ;-) * Some more: https://github.com/hello-rust/show/blob/master/LESSONS_LEARNED.md If you like to have a specific topic covered, just add a comment here or on Github to get a conversation started: https://github.com/hello-rust/show/issues.
A for or a while has one more branch than a do/while (C lingo), so there are potential performance gains.
Can you not just copy the source for Vec, modify the constructor to require at least one input, and add a check to each function that removes entries that prevents an only entry from being removed (except for drain, which should probably still be able to drain a NonEmptyVec)?
There is also a timestamp, some boolean values and in the future there might be some more types but that's not for sure. Actually writing directly to a binary might be a solution. Do you have some examples how to do that in a proper way?
as far as I can see this can't be embedded easily and it's also a bit oversized, isn't it? 
Moving checks to constructors is a long standing technique for improving the safety of code. Instead of checking some condition every time you use some value, you check it once, and only expose methods on that value that can't invalidate it. We use this technique all over the place when writing modern code. 
That's way overdoing it. It should just be a wrapper for a Vec. 
look like we do need inheritance in rust
That's a good idea! Perhaps it's possible?
No REPL yet. I got an idea of how to do make one. If one thinks of the REPL as one huge expression block, then it might be possible to execute it line by line by using a custom method on `Runtime`. I need to write this up.
I think that's a terrible idea. Let's look what this would be like in Java-like syntax (because Rust has no inheritance): class Vec1&lt;T&gt; extends Vec&lt;T&gt; { /* implementation */ } // Some existing method that takes `Vec&lt;T&gt;`, or, because of // inheritance, also `Vec1&lt;T&gt;`... &lt;T&gt; T someMethod(Vec&lt;T&gt; v) { if (v.len() &gt; 0) { return v.pop(); } return null; } Suddenly the contract of `Vec::pop` is broken, because it can panic when it is nonempty. Why is it that the first thing many people do when you give them inheritance is to break the method contracts of the base class? :p Inheritance: just say 'no'.
I intend to talk to my kids about inheritance before somebody else does. Not even joking.
It seems to be! Great work!
I read your coment as I would eat sushis. (and I love sushis). :)
Whereas - just so I'm clear - with `target_feature` you can e.g. compile in an AVX2 implementation *and* an SSE41 implementation *and* an SSE2 fallback, and decide which one to use at runtime init?
correct
Yes, if you compile with a certain set of target features, then the implication is that you're going to run the resulting binary on a system that you know has support for your specific compilation target features.
Yep, and that's why it's not as efficient :P
I typically don't find myself having vectors passed into my API. Iterator trait bounds work just fine. You can use take combined with a vec.iter() to index it appropriately, or use the Index trait. Returning vectors is completely reasonable. Inheritance is not necessary here, but delegation of implementation could help, and we do have RFCs out there for that.
Seems like you are not the only one :) Here is my [version](https://github.com/thibran/non_empty)
…rusty?
The GPGPU ecosystem makes a rather unhealthy impression to me anyways. I've considered getting into it but GPU prices are still ridiculous, how can 3-4 years old mid-range cards be over $500. And then OpenCL is being killed by some corporations. Maybe Vulkan will change the game, I really hope so.
That's certainly the much simpler and easier to maintain way to do it, but I don't know enough rustc optimization to be confident that the abstraction is zero-cost.
I really like your videos. The flow, the little mistakes in the code, the explanations. Thank you!
Obviously `Vec` should be a subclass of `Vec1` to avoid that, silly as that would be... there are lots of problems with inheritance, but it isn't *that* fundamentally flawed,
Well, `Vec` could be a subclass of `Vec1` to avoid that, impractical as that would be... Of course if you want to also have methods that have contracts that vary the other way, you'd have problems.
Hey everyone ... I'm back again :P I'm now on the 12'th chapter of the Rust Book and am wondering if someone can explain to me why one of the function arguments requires a reference symbol, and the other one doesn't even though they do the same thing: (note that I've gone ahead and made the code more functional so this is not what the function bodies look like, but rest assured that they do the same thing as what's in the book). ``` pub fn search&lt;'a&gt;(query: &amp;str, txt: &amp;'a str) -&gt; Vec&lt;&amp;'a str&gt; { let result = txt.lines() .filter(|line| line.contains(query)) // &lt;-- No &amp; symbol .collect(); result } pub fn search_case_insensitive&lt;'a&gt;(query: &amp;str, txt: &amp;'a str) -&gt; Vec&lt;&amp;'a str&gt; { let query = query.to_lowercase(); let result = txt.lines() .filter(|line| line.to_lowercase().contains(&amp;query)) // &lt;-- has &amp; symbol .collect(); result } ``` Note that for `search`, `line.contains` is passed in `query` with no ampersand. But in `search_case_insensitive`, `line.to_lowercase().contains` is passed `query` with an ampersand (which, to my naive understanding, means that this method is being passed a reference to `query` and not `query` itself). So, to reiterate: Why does one function work without the `&amp;` and why does the other one require the `&amp;`???
In the first, `query` is a `&amp;str` but in the second, `query` is a `String` because that's what `str::to_lowercase` returns. `str::contains` wants a `&amp;str`, not a `String`. Passing a `&amp;String` allows deref coercion to take over and convert the `&amp;String` to a `&amp;str` for you.
What behaviour would you prefer for overflowing operations, i.e. what is in the `else` branch of your function? You don't need to do this yourself. Primitive numeric types have these: [Checked mul](https://doc.rust-lang.org/std/primitive.u32.html#method.checked_mul) [Saturating mul](https://doc.rust-lang.org/std/primitive.u32.html#method.saturating_mul) [Wrapping mul](https://doc.rust-lang.org/std/primitive.u32.html#method.wrapping_mul) [Overflowing mul](https://doc.rust-lang.org/std/primitive.u32.html#method.overflowing_mul) Check these out.
Rust provides the following methods to handle overflows: `checked_mul`, `saturating_mul`, `wrapping_mul`, `overflowing_mul`. (same for `div`, `neg` and `add`) So your example can be rewritten as: let z = match x.checked_mul(y) { Some(val) =&gt; val, None =&gt; { ... }, }; BTW if wrapping is desired behavior Rust provides [`Wrapping`](https://doc.rust-lang.org/std/num/struct.Wrapping.html) wrapper type to reduce the boilerplate.
Ohh Ok that makes sense :) ty! 
&gt; abusing the type system How would one do that anyway? Exploit bugs? The type system is totally great for doing things like [state machines](https://hoverbear.org/2016/10/12/rust-state-machine-pattern/) and [page tables](https://os.phil-opp.com/page-tables/) :p
For just writing individual values one at a time I'd recommend using `byteorder` and standard library `files`. If your data fits, you might be able to do something nicer with `serde` and `bincode`, but I haven't experimented with that much personally.
Rust uses that pattern all the time. `PathBuf` looks like this: pub struct PathBuf { inner: OsString, } `OsString` on Linux looks like this, where pub struct OsString { inner: Buf } pub struct Buf { pub inner: Vec&lt;u8&gt; } On Windows, it looks like this: pub struct Buf { pub inner: Wtf8Buf } pub struct Wtf8Buf { bytes: Vec&lt;u8&gt; } `Path` does the same sort of thing with `OsStr`. Each layer of wrapping enforces new invariants in its constructors and defines new methods. It's efficient because the compiler does two things: 1. The memory representation for a single-member struct is identical to just that member alone. 2. LLVM's optimizers are great at knowing when to inline functions to collapse away the layers of wrapping.
&gt; Is there a better way of doing this? It's my opinion that in all but a few cases you should only use machine integers when you _know_ that the size will never overflow or at the very least be will not be meaningful when they overflow as in you shouldn't use them to simulate actual numbers as a mathematical thing but purely treat them as computer things like locations of pixels on a screen or indexes in a some kind of playlist which can't grow beyond that number anyway or the machine would run out of memory. If you're dealing with actual numbers in the mathematical sense for most use cases something like [Rug](https://crates.io/crates/rug) or another BigNum library which does bignums which can grow arbitrarily within the systems memory limit. In general you will find tht the performance difference is absolutely negilible unless you're doing really heavy number crunching and usually when you're doing that you want machine floats anyway because it tends to be physical simulation. Machine integers _aren't_ "numbers" and don't obey the mathematical properties of numbers and shouldn't be used as a substitute therefore.
very cool! I was confused by the title. "Environment Editor" sounds like it is some sort of GUI to view/edit your environment variables, when in fact it is a replacement for a tool like sed.
Awesome, I will keep that in mind.
Oh right, the MinGW import libraries... If I ever got a solution to https://github.com/rust-lang/rust/issues/30027 then I wouldn't need those massive piles of blobs. Is it possible to just *delete* the vendored MinGW import library crates after doing `cargo vendor`?
awesome, thank you for the detailed reply. I think i have decided to go with rust for now, i am still waiting for couple of things in cpp like modules and networking ts to be in stable. then i think it might make sense to try cpp. 
Shameless plug: you should try catmark ...
How would you remove an element from this vec? 
Sled then maybe!? [https://crates.io/crates/sled](https://crates.io/crates/sled)
Read through and coded along the first three posts in Philipp Oppermann's OS blog. Wow so cool! Highly recommend checking it out if y'all haven't yet: https://os.phil-opp.com/ Also still working through the rust book second edition. Only five chapters left!
What are the practical applications of generating noise at a breakneck speed? (Not meant as irony, I'm genuinely curious)
I'm working on a thing that I'm not sure how to describe. It's essentially a microcontroller emulator (custom instruction set, inspired by RISC-V) and a compiler (custom programming language, inspired by Rust, but without traits, generics, or borrow checker). The goal is to have it simulate an arbitrary number of virtual microcontrollers, each connected to input/output devices and other virtual microcontrollers. I'm pretty familiar with low-level processor concepts, so I'm confident that I can complete the project. But I'm not at all familiar with microcontroller programming, so it will be an exciting adventure into uncharted lands.
Continue porting my Software Renderer from C/C++ Rust. Done: Core Mathematics(Vector(2D, 3D), Matrix(2x2,3x3,4x4), transformation) Algorithm(Fractalsm, Noise) Image Synthesis(Fractals, Noise) including first created ppm for test Renderer parts(Shape, Mesh, MeshBuilder) Todo: Renderer: Continuing Meshbuilder for geometric core primitives. Rendering Algorithm GUI for Analyse Algorithm and Debugging Happy rusting @all :)
I think this will be more readable, if we can use at least a different color and a prefix symbol like ► for points and different color for wrapping back-ticks around code samples
Nice, can you suggest how you approach this kind of porting? I have a big C++ codebase and we face some memory access violations lately. I think rust would be a help in that, but I don't know how to port a small part of the code and use it.
Looks like efforts in this direction are starting: [https://github.com/ry/deno/pull/262](https://github.com/ry/deno/pull/262)
I originally looked into this a while back because I wanted an elite-dangerous type experience - drop into a solar system from a galaxy wide view, with *no* loading time. This can do it! With nice 4k textures on multiple planets. Another demo I have seen does super fast on the fly cave generation as you fly through it. Sometimes having something super fast unlocks no applications nobody thought of! Maybe it could make minecraft use a few gigs less ram! The *real* question is, when does it make sense to do noise as breakneck speed on the CPU, instead of the GPU, since the GPU is pretty good at this kind of work. Game server? when you need many short packets of noise and waiting for the gpu interop each time would be too much overhead? In a game where the gpu is already busy rendering other things? When you want a much simpler solution than interfacing with a GPU to get noise? 
So it is a replacement for envsubst(1)?
I recall Cargo gets upset if you try that - I think there are checksums in Cargo.lock. Judicious editing may be possible, but certainly a naive delete didn't work. 
I am very new to rust but i think you should extract your codebase into a cargo lib project with Cargo.toml Entry: [lib] name = "libname" crate-type = ["staticlib"] The result will be static lib. Sadly i have no experience in this topic, but maybe this Stackoverflow Post or any other more experience Rust developer can help you. [https://stackoverflow.com/questions/43866969/how-do-i-create-a-static-library-in-rust-to-link-with-&amp;#37;D0&amp;#37;A1-code-in-windows](https://stackoverflow.com/questions/43866969/how-do-i-create-a-static-library-in-rust-to-link-with-%D0%A1-code-in-windows) If you will have a working Solution for your Problem it would be nice to share in global rust Channel :). Good Luck :)
With a `Vec1&lt;T&gt;` you can always do `v.into_iter().next().unwrap()`. By having `Vec&lt;T&gt;` inherit from it you break that promise. Inheritance is harder than people think.
Is this open-source and/or will it be? If not, could you maybe do a writeup someday so others (me lol) could try and implement it as an exercise?
Thats a good Question and interesting Idea. Currently i have no plan about open source and publication. But it could be interesting for other developer how may goes through and the main idea behind, because its a very chaotic one :D. Starts with desire of making some gfx in python and confrontation with polygon intersection up to an first implementaion in C and UI in C++ and finally proting to rust. Actually there is no direct plan, but i think its a good Idea. I will add it to my Todo list :).
You may be interested in Frederico Mena Quintero's librsvg rustification. The library is gnome C, but that's probably applicable either way, especially because the intent was to rustify progressively, from within, without changing the API (and possibly ABI?)
I finished (for now 😉) a little application called [journaldriver](https://github.com/aprilabank/journaldriver) which forwards logs directly from `journald` to Stackdriver Logging (the managed log service on Google's cloud platform). Most similar log forwarding applications have generic implementation with pluggable input/output adapters, journaldriver only covers this specific case. For some reason most of them are also written in Ruby. We decided to roll a custom one after I found a machine spending ~20% of CPU utilisation on the old forwarding agent during a high-volume log period. 
Is Crossbeam still a thing? Did Rayon win the parallel iterators race?
I'm porting some rustup features like components and toolchains to gentoo with an esalect and eclass
I think the first matcher for `escaped` should match a single unit of the string, not a series like `take_until_either`. For example [I have a very similar matcher](https://github.com/Nemo157/cbor-diag-rs/blob/master/src/parse/diag.rs#L88-L102) using `none_of!("\\\"")`.
You would have to track offset.
Yes - we rely heavily on logstash and it's a pain to configure, besides hungry for CPU and RAM. Interested in other options! Very flexible input/output configuration, but hard to get right.
 use std::ffi::{OsStr, OsString}; use std::path::PathBuf; fn f(_: &amp;AsRef&lt;OsStr&gt;) { } fn main() { f(&amp;OsString::from("a")); // OK f(&amp;PathBuf::from("b")); // OK // f("c"); // error[E0277]: the trait bound `str: std::marker::Sized` is not satisfied f(&amp;"d"); // OK } * https://play.rust-lang.org/?gist=a7132e4eb99b685df80f82c65514972d&amp;version=stable&amp;mode=debug Is my error with `f("c")` essentially the same with https://github.com/rust-lang/rust/issues/42923 ? I'm a bit confused as to why `f(&amp;"d")` is allowed when `f("c")` isn't.
That just fits my goal. Thanks
This makes it a bit clear. I was thinking that there should be some blog or article explaining this (rustifying your project) part of the process where people have taken advantage of Rust in an already existing/running application.
Most setups require only one or two log sources and a single log sink, which is why I think dynamic runtime configuration is most likely the wrong way to implement this. Out of curiosity - what are your sources and sinks?
That's actually the whole paradigm behind Type-Safe code: All possible modifications on a type should hold up its invariants, and any modifications breaking those invariants should yield a different type (which does not define that invariant) Cannot call `exit()` when `enter()` wasn't called? Great, define `exit()` on an `EnterGuard` and have `enter()` return it. And in cases where two things are nearly identical, but uphold slightly differing invariants, you can use traits to specifiy the common parts!
I recently published [the first release](https://docs.rs/python-parser/0.1.0/python_parser/) of a complete Python parser based on `nom`. This week I will investigate returning meaningful error messages using `nom` and `nom_locate`.
I'm working on adding blurry (similar to transparent) windows to winit. See the [issue](https://github.com/tomaka/winit/issues/538) and [PR](https://github.com/tomaka/winit/pull/568) for details.
Like you do on a `Vec`, but you cannot remove the first one.
The sources are straightforward, but currently we are doing non-trivial things like enriching JSON coming in from our sources before writing everything to ElasticSearch. Would like to move all of that to custom Rust pre-processing, and then logstash itself can be replaced. Which will be a relief...
I think this could also be interesting for Rust since we are concerned with compile time as well. Zapcc is a caching C++ compiler based on LLVM/Clang which promises to significantly speed-up compile times.
Yes, the problem is the same - you can't convert unsized types to trait objects. In first two cases you are giving a reference to `OsString` and `PathBuf`, both of these are `Sized`. In the third case you are giving a reference to `str`, which is not sized, and thus cannot be converted to trait object `AsRef&lt;OsStr&gt;`. In the fourth case you are giving a reference to `&amp;str` (so the actual parameter is double reference `&amp;&amp;str`), which is `Sized`, and the conversion to trait object is valid.
But how do you know its the first / only element?
I'm playing around with rust, new to the language and putting together what I believe is a pretty easy 2 function program. I have it working in one way, however I can't figure out how to make it work in the original way I had intended, just asking if anyone can point me in the right direction. This is how I have it at the moment: `fn main() {` `let x = get_num("first");` `let y = get_num("second");` `println!("The two numbers multiply to: {}", x * y);` `}` `fn get_num(x: &amp;str) -&gt; i32 {` `println!("Enter the {} number:", x);` `let mut y = String::new();` `std::io::stdin().read_line(&amp;mut y)` `.expect("couldn't read line");` `let y :i32 = match y.trim().parse() {` `Ok(num) =&gt; num,` `Err(_) =&gt; get_num(x),` `};` `y` `}` What I would like to do is achieve the second function without using recursion, yet I can't think of a way to do so in a loop. Any advice appreciated.
Because at that moment `len == 1`?
I will to continue to work on a file-sharing webserver to replace USB thumb-drives (mainly because I keep on loosing mine). At the moment you can navigate through a folder and its subdirectorys, and any file in there can be downloaded. This still is a very early stage in development but if you want to check it out: https://github.com/flofriday/thumbcloud
I've never used `envsubst` so compatibility with that was not something I gave thought to, this was designed to replace a common idiom of using sed in Docker and 12 factor applications where you have variables for things that shouldn't be committed to source. With `eve` you can easily treat those things as in source as possible, and not have to remember to add a sed expression to actually perform the substitution. I don't think compatibility with `envsubst` is desirable since there are plenty of programming languages where `$VAR` &amp; `${VAR}` is actual syntax in your code and you wouldn't want the tool that is supposed to reduce your maintenance time to actually cause the opposite by having you refactor around it.
Rust has a construct `if let` and `while let` that might help you here: https://doc.rust-lang.org/stable/rust-by-example/flow_control/if_let.html What might also be helpful are the `Result::is_ok` and `Result::is_err` methods: https://doc.rust-lang.org/std/result/enum.Result.html
I'm sure this is really stupid, but anyway. I'm looking to parse some json using [serde_json and "strongly-typed data structures"](https://docs.rs/serde_json/1.0.19/serde_json/#parsing-json-as-strongly-typed-data-structures). I am looking to parse a json object with a "type" key, but that is a Rust keyword and therefore cannot be used as a struct field. How would you work around this? Just implement a function to return a struct, parsing the json with serde_json::from_str? Many thanks in advance.
yes, sled looks interesting :) Thx. I'll play around with it.
https://github.com/frankmcsherry/timely-dataflow is worth a look.
You could try a different name for the field, and add `#[serde(rename = "type")]` attribute, as [explained here](https://serde.rs/field-attrs.html).
So it's more of a template engine than an editor...
Interesting, thank you. The `Result::is_ok` is definitely something I'm looking for, the main problem I had with the loop was exiting once I'd ascertained that the string input was definitely a number. Something like this was what I had intended, but I couldn't think of a way to make it work: let y: i32 = match y.trim().parse() { Ok(num) =&gt; { num, break; } Err(_) =&gt; continue, }; y I'll definitely take alook at the two links you showed me though, thank you.
The trouble with Python and frameworks like NumPy is that it's rather hard to figure out *why* a certain algorithm is slow, even though you seem to be using optimized NumPy commands. I have an algorithm that works a great deal slower than it's supposed to - it's doing *really* trivial things. I'm probably misusing some API or some such, but I have no idea what the problem actually is; and even if I'm lucky and manage to narrow it down to one faulty function call, I'd still have no clue how to use the API properly.
Ah, I had somehow missed that in the docs. Thanks for pointing that out!! 
I might use a loop and early return: loop { match y.trim().parse() { Ok(num) =&gt; return num, _ =&gt; () } }
Thanks for that. You should probably update [https://hello-rust.show/](https://hello-rust.show/) to add latest episodes.
Thank you very much, that worked wonderfully. Now to continue past chapter 3 of the rust book :)
No, the new borrowck does not disallow something that used to be a valid program. There were several soundness bugs in the old borrowck which caused various corner cases of rust code to compile, even though they were unsafe and should have resulted in an error. The new borrowck fixes these bugs, meaning that any such code will no longer compile. This means that after NLL is merged, a few existing Rust crates (which exploited the compiler bugs, probably unintentionally) would stop to compile. But that is fine, as that code should have never compiled in the first place -- it only compiled due to soundness bugs in the old compiler.
But then you Need to Check for len==1 instead of len==0 so what is gained?
I've been thinking about this for a while... Is there a reliable way to determine whether a piece of memory has been written to swap / other non-volatile memory? And is there a way to prevent an object from being stored on non-volatile memory?
I didn't want to imply that `eve` should be compatible to `envsubst`. Just a matter of stating facts. It is completely fine to have a different syntax. Since you only mention `sed`, I just wanted make you aware of `envsubst` since that is part of gettext and a pretty standard tool (albeit surprisingly unknown) for this use-case.
I don't know how to argue this well but I fell that the language is pilling too many features.
No problem! Just fork Dyon and remove features you don't like...
Which one does `*` correspond to?
If that's your concern, maybe look into Boost. It is a collection of libraries that many C++ devs use.
&gt; BTW if wrapping is a desired behavior for you Rust provides [`Wrapping`](https://doc.rust-lang.org/std/num/struct.Wrapping.html) wrapper type to reduce the boilerplate. Oh, I get it! I thought you, and the documentation, were talking about wrapping the operation in a function of some kind!
 static S: [ // Generate this part via a script 1, 2, 4, 8, ];
Something about putting numbers into identifiers gives me the heebie jeebies XD (referring to `Size0Error`) Nice job releasing it though :)
That's fair ^^
You will no longer need to check on doing operations that may fail without altering the state, such as getting the first element (not removing)
If you want raw bytes with that alignment, you'll want something like: #[repr(C, align(64))] struct Aligned { inner: [u8; 64], } fn alloc_aligned64(size: usize) -&gt; *mut u8 { use std::mem; assert_eq!(size % 64, 0); let mut allocation = Vec::&lt;Aligned&gt;::with_capacity(size / 64); let ptr = allocation.as_mut_ptr(); mem::forget(allocation); ptr as _ } #[test] fn it_works() { assert_eq!(alloc_aligned64(1024) as usize % 64, 0); }
I guess a potential workaround would be: fn f&lt;T: AsRef&lt;OsStr&gt; + ?Sized&gt;(_: &amp;T) { }
„panicking mul“ in debug and wrapping mul in release
It also keeps your code compatible with other Dyon code. Perhaps you even could use Cargo features, so you can add them back in case you make up your mind later? I don't want to do this in Dyon now because the language is still under development. It is relatively easy to add Cargo features later when it's stabilized.
Whoa! It's different in debug and release?!
Yeah, the compiler needing to inzroduce checks for every arithmetic operation results in very slow code, so it‘s not worth it in release, but it makes sense in debug mode to help find bugs.
The reasoning makes sense. What I think is scary about it is that someone might think that the release version has the same asserts that were present in the debug version, and rely upon them to protect something important.
Unless and until CPUs evolve to ameliorate the overhead of checked operations, this is the best compromise that exists. Note that the situation here is different from C: in Rust, overflow is never undefined behavior. Likewise, overflow by itself is never capable of causing memory unsafety; if you don't see an `unsafe` block, then overflow is only ever "just" a logic error, as anything else might be. Finally, note that if someone really wants to enable checked arithmetic in release builds then they can pass `-C debug-assertions=on` to the compiler.
"Abuse" typically refers to things the type system wasn't designed to do, but that are still known to be possible since the type system is turing-complete (such as compile-time computation)
The underlying principle of Zapcc is somewhat similar to that of the RLS: instead of the (somewhat antiquated) model of launching a fresh new process each time a compilation must be made, the process is daemonized and therefore can skip all the "preparatory" work and keep a warm cache. If you make it so that the daemonized process compiles in the background, which RLS should be doing, then you can get even faster feedback.
It is definitely something which should be better documented. Also worth noting that you can cause release builds to include overflow checks by adding this to your `Cargo.toml`: ``` [profile.release] overflow-checks = true ``` This isn't a great long-term solution obviously, but sometimes its better to eat the performance penalty until you're certain you've handled all potential overflows correctly. Similarly, `debug-assertions = true` can be used to keep all invocations of the `debug_assert!` in release builds.
If one of them works for your use case, I really like using `saturating_mul` or `wrapping_mul`
I'm working on [grimoire](https://github.com/jshrake/grimoire)! It's best described as a native shadertoy + vertexshaderart clone. A few notable features include support for multiple render passes, multiple render targets, and streaming texture inputs (video, audio, webcam, microphone, kinect2) via [gstreamer](https://github.com/sdroege/gstreamer-rs).
I like this series! The slowness and the relatively low complexity makes it great for following along when I'm tired/commuting/whatnot. The production values are slowly going up, which is great! Give it a few months and you'll be killer at this :)
Are there architectures that don't wrap natively? Wouldn't it need to do checks in order to wrap on those?
Still working on my [netlink crate](https://github.com/little-dude/netlink). Last week I implemented packet parsing for route packets. Now that I have links, addresses, and route packet parsers, I'll add wrappers for higher level interactions with the kernel, like [the golang crate](https://github.com/vishvananda/netlink) does: `get_links()`, `set_address()`, `get_routes()` etc. etc. I'm slowly realizing how big of a project this is though and it feels a little overwhelming. The good thing is that this is the kind of crate that can be built incrementally, slowly but surely.
Continuing to work on API ergonomics for [ggez](https://github.com/ggez/ggez/). I've been working on the drawing API, which gets quite often and the drawing engine is one of the most complicated parts of the system, so it's one of those areas where arranging things correctly has a big impact.
Hey, I've been playing around with the idea of doing the same. Why don't you open some issues with things that need to be implemented? Would be nice if it had references to the jvm documentation too. 
Neat idea! I've been toying around with implementing the CLR in Rust.
You might consider something like [combine](https://github.com/Marwes/combine) or [nom](https://github.com/Geal/nom) for your classfile reading logic. :) 
Nice! Will you be using Cretonne or LLVM for code generation?
Working on a crate to host the .Net CLR so you can load .Net assemblies and call code from within them. It's a bit tricky because I have to build a C api around the C++ Unmanaged Hosting API, and then write a struct based implementation around that wrapper. Currently at the stage of loading an assembly by its full qualified name. My eventual goal is to use this hosting library to host a C# app we wrote at work and gain insight into its internal behavior (so we can see what's going on on client sites without shipping a new version). 
RLS is a helper tool for IDEs so that they can understand the Rust language. Clang has its own implementation of the microsoft language server protocol, clangd. Zapcc is meant to make compilation faster by caching intermediate results, not meant for IDEs. It is more comparable to incr comp than to RLS. The only commonality with RLS is that there is a daemon in both cases, but in the case of Zapcc it is present solely to store a cache. Rust is two steps ahead of clang on this one as we have incr comp implemented and working on stable, not in a third party fork, and are using an on-disk cache which means that we can have much much larger caches. Zapcc just resets after a memory limit is reached. If you like the speed of ram, you can still use a ramdisk with Rust. But generally, zapcc is good for Rust as llvm development is mostly driven by needs of clang. If Zapcc or a variant of it gets upstreamed to clang, maybe parts of llvm will become incremental. Then rust may profit from it!
No, `Deref`ing into [T] and delegating traits like `IntoIterator` to the composing type is good enough. Would like some macro to auto-delegate certain traits to inner types, though.
&gt; Unless and until CPUs evolve to ameliorate the overhead of checked operations, this is the best compromise that exists. I humbly disagree. There are indeed advances in CPU which could help greatly. The Mill CPU (vaporware still), for example, has multiple ways to handle overflow on arithmetic operations, one of which being "poisoning". A poisoned value is then viral, poisoning any result derived from it, and will lead to a hardware interrupt when written to memory, or used in a branch. This would indeed give zero-overhead overflow checking. Yet, even with current technologies, and despite their dubious use of global flags, it should be possible to dramatically improve the speed at which overflow checking is done. The current implementation uses LLVM built-ins which have been designed not for speed, but for accuracy. The intent of the built-ins is to pinpoint the very operation which causes the overflow. This is nice for the implementation of UBSan, but unfortunately quite at odds with performance. An implementation with performance as a goal, which would trade-off accuracy and simply signal an error without even attempting to report which operation caused it (similar to NaNs) would likely show much better performance. For example, rather than branching on the "overflow" flag after each operation, it could simply "blend" the global flag with a local flag specific to each "stream" of operations, then before using the result of the stream (and only then) check if the stream flag is set. This would reduce the amount of branches drastically, and likely help recovering a lot of potential optimizations. Unfortunately, there is no such implementation available, and designing, implementing and letting one mature would require a tremendous amount of effort and time. In its absence, and since such overflows cannot result in undefined behavior (in Rust), the current compromise was reached, leaving it up to users to turn-on overflow checking in Release mode should they wish to. If the situation were to change, ie overflow-checking was dramatically improved in LLVM and its performance impact could be guaranteed to be minimal in most cases (except maybe, for maths-heavy programs), then I would expect the Rust community to agree to turn on overflow checking by default instead.
This is a decision which was not taken lightly, though I would have preferred checking by default myself. The problem is that Rust is competing with many languages which forego safety for speed, and therefore adding run-time checks is a dangerous proposal as there is a risk of painting Rust as "too slow" and have it disdained out-of-hands. There have, after all, sufficient noises made about the size of Rust executables made by newcomers: they didn't realize that their executable was statically linked and (unlike C programs) did include the `std` library statically as well, and they didn't experiment enough to realize that the initial "bump" was a fixed overhead. Instead, they concluded from their one-off Hello World program that Rust produced fat executables. There are also, regularly, newcomers who are surprised to see Rust being much slower than its C counterpart, not realizing that by default Rust is compiled in Debug mode. The problem is, for all those who complain that Rust produces bloated executables, or slow ones, how many just dismiss it out of hands and don't make a peep, not giving us a chance to correct their flawed assumptions? In light of those issues, it was decided that run-time checks should only be included if strictly necessary for memory and type safety; the most prominent example being bounds-checking. Interestingly, bounds-checking mostly obsoletes the need for overflow checking for memory safety: even if the index computed is completely wrong, it cannot address memory outside the boundaries. Note that there are other instances of overflow-checking causing issues. In the `unsafe` implementation of `Rc`, for example, a bounds-check is made; an earlier version didn't have the check, and someone triggered UB by creating (and forgetting) 4 billions of `Rc`, overflowing the counter (in the 32-bits version), then destroying one `Rc` which released the memory... to which they were still holding other handles. This of course reinforces the fact that `unsafe` code is hard to write correctly.
My thought was that RLS could be taught to incrementally code-gen. After all, it already incrementally recompiles code (to index it, and find errors), so adding a last code-gen step seems feasible. Also, while ramdisks are great, they are still not as good as persistent objects in RAM: a serialization/deserialization step is necessary going to and from disk-format, even if the actual "file" is stored in RAM. I agree with you that more work on incremental recompilation in LLVM is good for everyone!
&gt; The problem is that Rust is competing with many languages which forego safety for speed, and therefore adding run-time checks is a dangerous proposal as there is a risk of painting Rust as "too slow" and have it disdained out-of-hands. One could also have omitted them in debug mode. My worry was that their presence in debug mode would make programmers think that they were always there. Anyway, although it startled me to hear how it works, I don't know what think would have been the best choice. By the way, couldn't one imagine hardware checks that did not incur a performance penalty unless an overflow happened? An overflow could trigger an interrupt and jump to an interrupt handler, I'm thinking.
To read more about the background of this project, see [this github issue](https://github.com/servo/servo/issues/1799). The work that retep007 is doing is uncovering all sorts of interesting corner cases in the current monolithic design that need to be addressed to completely separate the interface and implementation of lots of types into separate crates.
And currently `Vec::first` and `Vec1::first` have different return types, `Option&lt;&amp;T&gt;` and `&amp;T`. Using inheritance that wouldn't be allowed.
&gt; Would like some macro to auto-delegate certain traits to inner types, though. I do find myself wanting that kind of thing sometimes. "Implement all the methods this member implements, by just delegating all the calls." Something like that. Was there some RFC floating around about efficient code reuse, to make this sort of thing easier? I know using `Deref` for that is kind of an anti-pattern.
I enjoy watching your videos a lot -- please keep up the good work! &gt; Although the video still contains a lot of mistakes That is a good thing -- because it is real life of everyone who codes. I like how you go in depth explaining why you do this and that. May be have a follow-up small video where you fix the mistake from the previous one, go a bit into explaining the Rust way and idiomatic approach. &gt; be a bit too detailed - there is fast forward - there are 1.5x++ speeds - you already fast-forwarding a lot of the typing -- it is good to actually see which bits give you have trouble with and how you fix them, especially the borrow checker issues :-) Some suggestions on future topics: - debugging -- how do you do that? I saw a question on stack overflow on how to view the hashmap values in memory with gdb -- the answer is -- you can't :-) (you probably can if you have 12 years of C experience, but you get my point...). - the last video was on TDD. it would be cool to see kcov or some other tool that will show test coverage. Thanks again for your great content!
This is a fun lifetime problem! For some example, see [this code](https://github.com/vks/discrete-log/blob/master/src/main.rs) which implements the discrete logarithm generically for several bigint types. It predates (and somewhat motivated) the integer traits in num you mentioned. Before using such traits, the trait clauses were [extremely verbose](https://github.com/vks/discrete-log/blob/b8f784e6a9aa860757150a8257c7b3be0557447f/src/main.rs). Why do you need `for&lt;'a&gt;` in this case? Imagine you want to implement a function that doubles a generic big integer: fn double(x: T) -&gt; T { x * &amp;TWO } This does not work, because the compiler does not now whether `Mul&lt;&amp;T, Output=T&gt;` is implemented for `T`. Second try: fn double(x: T) -&gt; T where T: Mul&lt;&amp;T, Output=T&gt; { x * &amp;TWO } This also fails, because the compiler cannot infer the lifetime of `&amp;T`. In fact, we cannot name this lifetime manually either, because the is no lifetime in the argument or the return type. You have to use the `for&lt;'a&gt;` syntax to tell the compiler that the trait has to be implemented for all lifetimes `'a`: fn double(x: T) -&gt; T where for&lt;'a&gt; T: Mul&lt;&amp;T, Output=T&gt; { x * &amp;TWO } Of course, you need similar trait bounds for `&amp;T * T`, `&amp;T * &amp;T` and `T * T`, multiplied by the number of arithmetic operations, resulting in the verboseness mentioned above. This is where the num traits come in handy.
I'm personally a fan of this syntax proposed by RFC 1406 struct { some_accessory_data_that_changes_all_the_time_do_not_hash_or_eq: String, #[delegate(Hash, Eq)] name: String, #[delegate(PartialOrd)] position_on_tape: f64, } This would be super useful for GUI libraries. For example in conrod, a widget, say `conrod::widget::slider::Slider` is a struct that contains a `conrod::widget::CommonBuilder`. They have a complicated macro setup where the `Widget` implementation is derived from a proc macro very similar to the syntax above, but it's specific to conrod. I don't see why you couldn't generalize this pattern.
I have toyed with doing this because it's an easy target. It's be especially neat since Rust can easily impl the JVM side of `jni.h` (and `jvmti.h`). However, you'll find once you get an interpreter up, everything's performance from there until you reach JIT needs (and use something like cretonne). So just make sure you separate it out at the method level if you can so one day you can keep counters to determine hotness.
JVM should be easier. It's a less complex VM (at the moment at least)
Thanks for the comment, any ideas on what could be the possible troubles of automatically taking a reference of a reference to a DST object for making `f("c")` work? Because it's against the "zero cost abstraction" principle?
Oh man, I was just starting to write this over the weekend :-) I'll take a look at yours now
Last week I released [tarpaulin](https://github.com/xd009642/tarpaulin) 0.6. Merged a PR for a linker issue that's been a thorn in my side and also a bunch of syntax analysis based tweaks. This week I'll be continuing work tackling some issues and trying to fix an issue I'm have with my embedded project, currently I get a HardFault in the cortex-m Primask::read function so debugging that.
Pretty stupid question, but what's the correct way to use a string that was passed in as an argument from the command line as the parameter to open a file? I.e. ``` use std::env; use std::fs::File; use std::io::prelude::*; fn main() { let args: Vec&lt;_&gt; = env::args().collect(); let mut file = File::open(args[1]).unwrap(); } --&gt; src/main.rs:8:28 | 8 | let _file = File::open(args[1]).unwrap(); | ^^^^^^^ cannot move out of indexed content ``` Do I just use `args[1].clone()`?
I'm wrapping up with my first "useful" Rust project. It's a lightweight wrapper for running Minecraft Server inside a Docker container. https://gitlab.com/markwetter/mc-wrap When Docker wants to stop a running container it will send SIGTERM to the internal process, wait for the timeout and then send SIGKILL. Minecraft was ignoring the SIGTERM, so it would always wait the full timeout before dying. An additional side effect was that when Minecraft is shut down with SIGKILL it will not save its map data before exiting. What mc-wrap does is open a pipe to the input of the Minecraft Server, then it waits for a SIGTERM from the environment. When SIGTERM is received it sends the command "stop" to stdin on the server which causes Minecraft to do a graceful shutdown.
&gt; Note that I have defined `when: manual` which means you need to manual start the Pipeline in the UI instead of having it kicked off as part of the push. I usually set my CI builds to manual since GitLab is giving this compute time away for free, I don’t want to be an abuser of the service, see GitLab issue 23366. Is it really an abuse of service to use it for exactly what it was intended for? Your CI script takes 20 minutes, which is hardly a lot. Mind you, on the free plan, private projects get like 2000 CI minutes monthly, which would be 100 commits.
Looks like several persons are starting it / have already something! We should all focus on a single crate so that efforts are shared and we end up with something cool for everyone! :)
&gt; By the way, couldn't one imagine hardware checks that did not incur a performance penalty unless an overflow happened? An overflow could trigger an interrupt and jump to an interrupt handler, I'm thinking. Eager evaluation of overflows is easier to reason about, however it prevents **speculative execution**. This is why the idea of poisoning and only raising the interrupt at predictable points is so interesting, it leaves the compiler free to schedule speculative executions (which may overflow) and just have the CPU discard their result if it proves unnecessary, without the user ever realizing that overflow happened in the non-taken branch.
Pass the argument string as a borrowed referrence by writing it as \`&amp;args\[1\]\`, like this: \`let mut file = File::open(&amp;args\[1\]).unwrap();\`. 
agh.. right. Thanks!
There are no stupid questions when learning Rust; I've been there, everything feels foreign. use std::env; use std::fs::File; use std::io; fn main() -&gt; io::Result&lt;()&gt; { let args: Vec&lt;_&gt; = env::args().collect(); let mut file = File::open(&amp;args[1])?; // Just need to borrow the argument Ok(()) } `File::open` takes its argument by value, so you need to pass it a reference if you don't want it to take ownership. You don't want it to take ownership because that would require moving `args[1]` out of the vector. *(I can expand on this, I was writing a longer explanation before I realized it was probably more confusing)*
Thanks!
Don't know the answer to the first question. To prevent a memory region from being paged you can use `mlock` on UNIX or `VirtualLock` on Windows. If you're trying to prevent a secure value from being stored in the page file, you should look at libraries like https://github.com/myfreeweb/secstr, which use those functions but also zero the memory when dropped and prevent it from being accidentally printed.
I'm still rather new into my Rustic adventures, but I think there's a [Cargo kcov extension](https://github.com/xd009642/tarpaulin) which ought to provide the same sort of metrics, only in an automated fashion.
`let iter = if foo { bar() } else { baz() }` - `if` is an expression in Rust. 
Is this even legal?
thanks for your correction! I tried to find the limitations to CI as a free user and the linked bug was all that i could find for some reason. I have since found info here: https://about.gitlab.com/2017/04/11/introducing-subscriptions-on-gitlab-dot-com/. It appears to be 2000 CI Pipeline Minutes, and i think that's per user but its not clear. I have added your corrections to the post. thanks! And you're right, your not abusing the service if GitLab imposes their own limits. The spirit of that part of the post is to be a good citizen, also to inform any reader that there is a option to not automatically kick off builds. thanks! 
The implementation of the `Mul` trait at a type level
Generic code coverage tools provide a slightly different kind of information. They can tell you which lines are executed by the whole suite. However, they don’t know which lines are supposed to be executed by each particular test. So, using both of the approaches is useful!
There are already existing parsers. I also created one a while ago and recently handed over ownership to another developer who intends to breathe new life into the project and bring it up to spec with Java 9 or so. It's [classreader-rs](https://github.com/Wright-Language-Developers/classreader-rs).
 for i in 0u16...100000
Hrm, I can see that.
Yup. let iter; if foo { iter = bar(): } else { iter = baz(); } is also a possibility.
This is my first Rust library -- any feedback would be greatly appreciated!
No. All software is illegal unless approved by the Computer Control Council. Without a proper sacrifice it risks awaking the Elder Unix Gods, which only Oracle is licenced to battle
I'm serious, HotSpot looks barely GPL already
I mean, for public projects, there is no limit, and this is intentional, I provided a value for private projects for comparison purposes.
The only legal contention point being made by Oracle is the Java language APIs. The JVM has had a full GPL implementation for nearly a decade now.
`for&lt;'a&gt;` means for *any* lifetime `'a`. However it could also be satisfied by declaring the lifetime with `T` and using it where needed? You can give `a`, `b`, and `c` that same lifetime.
[mutagen](https://github.com/llogiq/mutagen) uses a similar trick to check which tests cover which mutations.
Yes. Reimplementing the JVM is perfectly legal as long as you don't do anything that would be illegal anywhere else, e.g. stealing proprietary code to use in your implementation.
Umm, you might want to consider not using Iron for new projects/crates: &gt; NOTE: Iron is not actively maintained at the moment, please consider using a different framework https://github.com/iron/iron
I would suggest Actix instead
nom4 is a lot stricter on `Incomplete`: if you've got the whole input and it ends with a repetition, you'll need to either use `complete!` or wrap your input in `CompleteStr` to signify that repetitions shouldn't return `Incomplete` if they could continue with more input.
There was [this project](https://github.com/maxmcc/rust-jvm) awhile back as well!
How exciting! How exciting!
Could you give me an example as to how I can migrate my code to use `CompleteStr`? I tried using it in the signatures of the parsers, but ended up with errors like `expected &amp;[u8], found struct `nom::types::CompleteStr`.
Very interesting! The script crate has a rather notorious reputation. Do you have any preliminary benchmarks to determine whether or not this effort has yet succeeded at reducing its compilation times?
Nice to see that the geniuses on pcj are now stooping down to mocking people's toy learning projects.
Just finished up [my first Rust application](https://github.com/crashspringfield/prrr_demo). It's a demo of what I'm calling PrrrStack (mostly a joke) using Postgres, Rust, Rocket, and React.
I understand all that but how can you remove an element while still guaranteeing `len &gt; 0`. It means that prior to the call you had to guarantee `len &gt; 1` which is not a given
I am that new developer, and yes, I am actively working on this. Anyone who wants to contribute is welcome!
Coming from C# where I use NCrunch, this information is definitely available in that tool at least. It shows you all the tests which hit the line and if they pass/fail, and even give a convenient right-click to debug and break on the line. It's one of the tools I miss the most when doing Rust work.
You know what lines are executed, but not which lines are *supposed* to be executed.
Pushing for a first usable and documented release of [graphql-client](https://github.com/tomhoule/graphql-client) (temporary name). I still need to implement the enum deriving for unions and interfaces, and strongly typed query variables. It also needs a lot more documentation and testing, but there's hope it will be done by the end of the week :) The first release is just going to support deriving serde-compatible structs for deserializing the response to a given GraphQL query, and a struct for the variables, so it won't deal with transport and just provide strong types.
Yeah I'm sure there is a more idiomatic way but this is what I'd do in most languages
&gt; generalize async/await to arbitrary effects you lost me
We still need to update the upstream crates to accommodate the changes, but I'm optimistic that we'll soon have preliminary numbers for changes made to the single module that was extracted out of the crate.
Nitpick: &gt; cargo new --bin hello_ci The `--bin` is now redundant since the default for `cargo new` was changed in 1.25.
That link was incredibly helpful. Also annoying as I now need to go rewrite most of a crate, but hey, learning experiences!
Maybe it's just that I don't really understand how that really adds value though. It seems like you're over-constraining your code-under-test by having it work that way. If you're following Red-Green-Refactor TDD, then it should be obvious that it's covering the right code because the test will fail when you write the test, and then succeed after you write the code that makes it work. One of the ideas for writing "good" unit tests is that they only test the *behavior* of your code, not how it is implemented. That idea that this unit test needs to run this other set of code in order to pass seems just completely "wrong" to me.
&gt; because the test will fail when you write the test, and then succeed after you write the code that makes it work. OP addresses this: &gt; The rule of thumb is to verify that the test actually fails if the specific condition which it covers is commented out. The problem with this rule of thumb is that it works in a single point in time. As the code evolves, the test might begin to pass for a trivial reason.
What are your thoughts for using assert_fs / assert_cmd for this? I'm curious if there were any missing features, usability problems, etc.
I'll play. let mut r = 0; let v = (0u64..10).map(|n|{ r += n+n+1; r }).collect::&lt;Vec&lt;_&gt;&gt;();
 let v: Vec&lt;u64&gt; = (0u64..100000).map(|i| i.pow(2)).collect();
..uh, can you rewrite it to do i ^ 2? This doesn't seem to do the same calculation as I did earlier. Unfortunately I don't know enough about *map* to figure out how to get it to do this calculation correctly.
I was just messing with this last week, and there were three additional things I did with my CI definition: * Use the slim Rust docker image * Cache the target and .cargo folders between runs * Strip the binary before uploading it as an artifact https://gitlab.com/markwetter/mc-wrap/blob/master/.gitlab-ci.yml I'm still debating if caching .cargo is abusing the free platform as its over 100MB in size. That being said, the cache is only best effort and they'll expire it if I'm not using it.
You're clever to avoid multiplication -- although even `i * i` is probably faster than `i.pow(2)`.
Excellent man! This ran in 3.3 seconds. Fastest one yet!
You want /r/playrust
The folks at /r/playrust might be better judges of that =P
Sorry, I see I have an off-by-one error. Maybe the following? (0u64..10).map({let mut r = 0; move|n|{ let res = r; r += n+n+1; res }}).collect::&lt;Vec&lt;_&gt;&gt;() Of course /u/CUViper has the correct and obvious `map` solution :-)
I just tested using your earlier code. There is no noticeable difference between i.pow(2) and i*i.
Thank you! Updated to (0u64..100000). This ran in 21.3 seconds!
It's not guaranteed that you can remove something, but there are still other operations that can make use of the `len &gt; 0` invariant.
Thank you!
LLVM will see right through `u64::pow`, of course :)
Huh, then I guess LLVM must do a good job of inlining and const-folding that `pow(2)`.
This is a GitLab CI script I use for my own projects, by the way: https://gitlab.com/KonradBorowski/result_float/blob/master/.gitlab-ci.yml
Agree that a code coverage tool which can breakdown coverage per test shares a lot with a hand-crafted solution. And it definitely has a **huge** benefit of being enabled "by default". But I wouldn't say that it is better across all dimensions: * A single test usually covers quite a bit of integration code as well. With `covers!` mark, you can easier pinpoint the specific bit of functionality which is covered. * Conversely, a single bit of code might be covered by many tests "accidentally", while only some of them target this block of code specifically. Knowing specific tests should help with "where should I place a test" problem. * Having marks spelled out in the code make it possible to discover the tests without running them: you can do it on GitHub, and you don't need an IDE (not that I am against IDEs ;) ) * Red in Red-Green-Refactor works for a particular state of code. When code is refactored, the test might become effectively inflatable.
Hmm... let v = (0..100_000).map(|i| i*i).collect::&lt;Vec&lt;u64&gt;&gt;(); Interested to see how that does.
Care to speculate as to what you think the magnitude might be? Say, an order of magnitude improvement for incremental builds?
You could also run your own ci-runner and cache if you are worried about this. It’s surprisingly easy. If there’s interest, I can do a very short write up. 
Please don't generalize.
It's really hard to say, because we've been warned that simply adding generics everywhere in the script crate will just postpone some of the compile time to the later monomorphization. I'm hopeful that we'll at least get the peak memory usage for compiling the script crate back under 4gb.
Is there any advantage to using Cretonne right now? Is it easier to work with? Is it faster?
Isn't `image: "rustlang/rust:nightly"` official? PS. Since we're posting GitLab ci scripts, here is mine variables: CARGO_HOME: $CI_PROJECT_DIR/cargo before_script: - apt-get update -yqq - apt-get install -yqq --no-install-recommends build-essential cmake test:cargo: script: - rustc --version &amp;&amp; cargo --version # Print version info for debugging - time cargo test --release - du -hs target - du -hs cargo cache: paths: - target/ - cargo/ 
That’s clever. I bet that will be really useful when it’s finished.
 extern crate rayon; use rayon::prelude::*; fn main () { let v: Vec&lt;_&gt; = vec![0;100000].par_iter().map(|i| i*i).collect(); } 
thanks. sometimes old habits die hard. fixed!
I don't have a problem with pcj in general. The fact that this kind of jerking violates their rules and the thread linking here was removed after I reported it (though I think it would have happened without me) attests to this. My problem is with a specific subset of users who have devolved into a mean bunch of trolls, shitposters reposting tired memes and in a couple cases outright aggressive assholes. Now this is getting super off-topic in a thread about something vastly more interesting so I won't derail things further.
The `map()` method on iterators also maps the value while looping to the value returned from the closure (which is different behavior than in a `for` loop). Maybe you're looking for the [`for_each()`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.for_each) method, which loops like `for` but doesn't map, or maybe that's why people are using the `map` method anyhow. I think performance is comparable as the compiler will optimize most things away, but I'm not sure about that. Be sure to take a look at the other [methods available](https://doc.rust-lang.org/std/iter/trait.Iterator.html) for an iterator, they might be of interest for some special use case!
My biggest problem is that the only way I've found to directly load an Assembly is using a deprecated API. (ICorRuntimeHost in the Unmanaged Hosting API). Once I've got stuff working better, and can load and invoke code properly, I'll post more. 
As you said, the usage of `Iterator` transformations often gives cleaner and more readable code. Another big advantage of iterators is that the compiler is (almost always) guaranteed to elide bounds checks when using them, which is not the case with imperative loops.
I unironically thought I posted my intentional comment in /r/pcj, only realizing after a second that it was in /r/rust instead. Also, I thought your comment was also on /r/pcj Anyways, peace
Oh good, I'm not the only one caching target and cargo. Looks like you accomplished it the exact same way that I did as well.
I copied that from somewhere on the internet, just seemed like a good idea.
Can anyone explain why method 4 is so much slower than method 1? Surely push() cant be that expensive, right?
They basically zero cost and faster to write.
Zeros in, zeros out... but you could use a range `into_par_iter()`.
[removed]
&gt; Is that the general reason why people are using higher order functions? Main reason for me is composability. items.iter().filter(|x|x&gt;4).map(|x|x.value) is easier to read and adding one more filter later somewhere is easier than modifying imperative equivalent. 
&gt; So `covers!` increments the corresponding count, and `covered_by!` returns a guard object that checks in `Drop` that the count was incremented. Isn't this reversed? `covers!` is executed at the beginning of the test, then `covered_by!` is executed by the code in question. If `covers!` increments the count immediately there would be little sense in checking if the count was incremented later.
[removed]
&gt;Cretonne Thanks for your idea. I think the most significant and distinctive characteristic of the project is its Readability. I'll consider about *code generation later* : )
Thanks for your link! I will refer to its code and make it more Readable.
[removed]
[removed]
Try `-C target-cpu=native`; Rust should be able to vectorize at least some of these with that.
I got: &gt; expected i32, found u64 Tried let v: Vec&lt;_&gt; = [0;100000].par_iter().map(|i:i32| i*i).collect(); Got back: &gt; type mismatch in closure arguments &gt; expected signature of `fn(&amp;{integer})
3.3 seconds. Same as the /u/CUViper let v: Vec&lt;u64&gt; = (0u64..100000).map(|i| i.pow(2)).collect();
Don't worry too much about it :) The limits we impose on CI are there to deal with exceptional cases, such as people using CI for mining cryptocurrencies. In case CI gets super popular we might have to spin up some additional runners, but that's not a big deal.
Haven't investigated at all, but my first guess would be that repeated resizing of the backing store is to blame.
Picked up a copy of Foundations of Game Engine Development volume 1 (the maths textbook). The code samples included are in C++, so I'm planning to try implementing them in Rust.
oh of course...
What are elide bounds checks? I tried looking online, but it's not obvious.
 extern crate rayon; use rayon::prelude::*; fn main () { let v: Vec&lt;_&gt; = (0..100000u64).into_par_iter().map(|i: u64| i.pow(2)).collect(); }
Gotcha, thanks for the detailed answer! and that artsy QR code is crazy! Are you planning to license your code under something like MIT?
Elide is a technical term for "skip"
Something that isn't here yet is that I've had fewer issues dealing with lifetimes and mutability using H.O.F.'s than regular `for {}` loops. I think it might be that it forces me to think about things a bit more carefully compared to a `for {}` loop where old habits might be a little more prone to cropping up.
Eliding bounds checks just means dropping the bounds checks from the compiled output because those iterator functions are guaranteed to not access out of bounds locations.
I finally fixed the bug in my game engine for mapping cursor positions to a selected isometric tile. I'd spent like 10 hours, comparing it to the original python implementation. It turned out to be an Intel gpu bug. I updated some drivers. 12 hours I've probably spent on this, across several weekends.
Look at [this list of issues](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22). Rust's safety is generally good enough to stop mistakes, but it is not even close to stopping malicious actors. I'd recommend either looking at traditional sandboxing techniques, or a way of running webasm as a secure bytecode. If performance isn't an issue I believe that there are reasonably mature interpreters. In the future cretonne will probably be a high performance JIT.
Also, immutable programming patterns are significantly prettier to express with maps and collects than with for loops and a bunch of `let` expressions for intermediate results. And immutable programming in Rust is generally less problematic than mutable patterns.
Could you please elaborate what are the exact security ramifications of these issues? I can see a lot of issues related to segfaulting, but if that means that it results in a crash, it is not such a big of deal as e.g. gaining access to arbitrary memory. I'm not a security specialist by any stretch of the imagination, but do any of these constitute more severe vulnerabilities such as circumventing Rust's safety rules to gain arbitrary memory access?
Segfaulting means the process dies, so if the remote client tricks your server into segfaulting, the whole server dies. That's a severe enough limit I would think.
The Server would never run Client code, though, only the other way around. The model I'm shooting for is something like Garry's Mod, where the Server sends clientside scripts to the Client for clientside logic, such as UI and whatnot. Crashing a client in this model is generally considered not such a big deal, since you can always avoid a malicious server if you know it's one - so long as the Server cannot infect the Client.
Rust is not designed for this; dynamic linking isn't designed for this. You'll have a much better time using something like lua or wasm. http://play.integer32.com/?gist=6baed32061a94682581351d436f76099&amp;version=stable&amp;mode=debug
If your server is only sending code between clients then your server is safe but your clients are still in potential danger. All the ways to trigger UB will make _the entire program_ (both before and after the UB point) potentially do anything at all, because the optimizer assumes UB never happens. _Probably_ you'll just make the client crash, but you can't say for sure.
Yeah, wasm is what I'm looking at right now. Lua isn't really an option since we already have Garry's Mod for that, and I'm looking to push the boundaries of performant clientside further. I still wonder if a restricted subset of Rust that excludes all unsafe operations (and the example you linked definitely falls under the definition) could be used for that purpose to produce safe, native code.
Totally agree. Was just wondering how much safe Rust is on the UB side.
"Any UB in safe rust is a bug in either rustc or LLVM", but that doesn't actually mean it can't happen :/
&gt; 2 commits &gt; +431,956 −8,072 My goodness.
Isn't it redundant to specify the \`latest\` tag for docker images?
Thanks, I’ll look into it
You can't guarantee that (in Rust at least), you only need to enforce the invariant within the method. You could ignore the operation, you could return an Optional letting the caller branch, you could panic etc.
FYI `print_schema!` was deprecated in 1.3
True, but that's an issue in general with games supporting clientside scripting. Even in Source itself without any kind of clientside language there are plenty of exploits that allow you to infect a client. There's always a way around security...
75 seconds. The longest one yet.
In a way, I've won.
I was trying to understand, what does this do? Does it attempt to do all of the calculations in parallel?
Yep, exactly. It'll do automatic batching of operations as well within a thread to avoid situations like this, but I suspect there is just only so much it can do. That said, there mayyyy be a way to tune it and get not horrible speeds? idk
In general I always assume that a segfault that isn't caused by dereferencing null can be turned into arbitrary code execution. This goes quadruple when the attacker get's as much control over the environoment as you do when you are making the program. [Here is an example of exploiting one of those issues to run code I shouldn't be able to](http://play.rust-lang.org/?gist=d54444f1cb6c7e04600fad86782911dc&amp;version=stable&amp;mode=debug).
For the most part, it should work under many circumstances. Rust dynamically links to live, so assuming both platforms have binary compatible libcs and in the same location, it should work.
Well, yeah, that's one of the methods I was referring to...
How are you doing the time measurement? None of the numbers make sense; it looks to me like you're actually measuring the compilation time.
Do you have the arc publicly available?
One problem is that `Range&lt;u64&gt;` is unindexed to Rayon, because *in theory* it could have more than `usize::MAX` items. So by default, we end up collecting into a bunch of smaller `Vec`, one for each job split, and then try to merge into one big `Vec` result at the end. You can get direct `Vec` collection if you start with a `Range&lt;usize&gt;` or smaller and map that to `u64` instead. We do have a trick up our sleeve when the length is actually known to be small enough for `usize`, and I've just implemented that for ranges in [rayon#578](https://github.com/rayon-rs/rayon/pull/578). Still, I'm not sure how /u/van2z is measuring this, because even in *debug* mode your code only takes a few milliseconds here.
I'm wondering about that too -- none of these should take more than a fraction of a second for only 100,000 items. Compilation time might explain the poor `rayon` results above, since there will be a lot more dependencies to build. (Even then, 75 seconds is really slow...)
&gt; I'm not sure how /u/van2z is measuring this I have also wondered haha
Isn't it way less efficient than doing everything in one iteration or is the compiler smart enough to do that?
Unfortunately, Actix is in the process of sorting [memory safety issues in its current api](https://github.com/actix/actix-web/issues/289).
push is a lot more expensive than just setting the value. but also in method 4 the array is created and filled with zeros first, then filled again with data. In the 3.3 second method it is only filled once. There isn't much work being done to compute the data in the vector, so the little bit of code in push stands out.
Stream fusion is built into Rust's iterators (well, mostly, they're just lazy :D)
I imagine the overhead of having to set up the thread pool, spawn threads, schedule tasks, and tear everything back down is contributing to a good portion of that extra cost.
I'm not so sure. The fastest version of this problem is 3.3 seconds. I expect creating threads for a threadpool to take considerably less time than that.
This is exactly what Java in the browser was and it turned out bad because for everything you think you've sandboxed, there's always someplace you missed.
I would say that so long as you don't try to put it on another architecture you'll fine.
Ohh, is this what collect() does? That's very nice. I think diesel works like that too.
Isn't this true for almost any kind of client-side scripting? I thought the problem with Java was more to do with insecure APIs than Java itself. Please correct me if I'm wrong.
I get 0ns for all. some optimization happening? https://play.rust-lang.org/?gist=3f23861713e0863daf38668ab33ce7d4&amp;version=stable&amp;mode=debug 
Oookay, I see, now. Thanks a lot for this example. This is exactly why I asked this question in the first place.
Should the "third" modules RFC link be https://github.com/rust-lang/rfcs/pull/2126 instead?
A tree-shaped comment section like reddit has might be able to help the velocity issue. Each top level comment has its own tree of replies. I'm a casual community member and I usually don't keep up with RFCs because the amount of comments to read is really time consuming. One of my main concerns is that it's really hard to keep up with the progress of RFCs once they are accepted. Which ones have started implementation? Which ones are in nightly? Which ones are in stable? I see that this week in rust now has a section about the progress of some RFCs, definitely a step in the right direction.
For one, Cretonne only requires Rust and Python to build, and automatically integrates with the Cargo build system, so that would make it much easier to work with (from Rust) than LLVM for sure.
using iterators gets you the benefit of array bounds elision and usually compiles down to code as fast as for loops. But keep in mind that for item in collection { } also uses an iterator, so that is fine to use if it is more natural for the problem, which is common if you want to say, mutate a vec in place or something.
Rust statically links by default so, for the most part, Rust binaries are pretty portable within a target (ie. Linux to Linux or FreeBSD to FreeBSD), but here are the details you have to keep in mind: 1. Rust uses libc for platform abstraction. If you're linking against glibc, you generally need to build against the oldest version of glibc you want to support. (As I remember, people have offered Docker containers for this in the past.) 2. While Rust statically links Rust code, crates you use may dynamically link against C libraries. If you use such crates, you'll have to look into how to request static linking if you want to be protected from the risk of another distro not having compatible library versions. (eg. Certain node-webkit releases had problems because they linked against `libudev.so.0` and expected the distro to provide it, but the distro only had `libudev.so.1`.) If your project and its dependencies are pure Rust (ie. no C dependencies outside of libc), then you can use the musl-libc targets to produce a binary that even bundles libc so that the Linux kernel ABI is the only dependency. (If your code is *not* pure Rust, then you'll need to set up a musl-libc cross-compilation environment to use the musl-libc target. There exists at least one Docker container for this.) While it's overdue for some updating to take advantage of new language features and crates like `failure`, my [rust-cli-boilerplate](https://github.com/ssokolow/rust-cli-boilerplate) demonstrates how to do this in a well-documented and build-automated way. The gist for a pure-Rust project is: rustup target add i686-unknown-linux-musl cargo build --release --target="i686-unknown-linux-musl" 
All of them are taking less than a sec and first version is fastest. please check my comment [down](https://www.reddit.com/r/rust/comments/8s2v0z/benchmarks_filling_up_an_array/e0wtdmt/).
Yeah, you're right. That said, I'm not sure what's going on in the testing since like you and /u/CUViper said, this program runs almost instantly on my computer.
I'm wondering if they've perhaps run `time cargo run --release`, which would take the downloading of the crate, compiling, and execution of cargo into account.
It compiles code faster, but the compiled code is slower.
To be fair, part of the reason Garry's Mod performs so poorly is that it's built on an engine whose core was made close to two decades ago (not even including the fact that afaik it still has a lot of quake). Also, most of the people making mods for it have no idea what they're doing and write absolutely atrocious code. You could easily make a much more performant sandbox game with a more modern core that uses lua as the scripting language.
I'm just learning. I'm making a simple linked list library in C, because I know how to do it - more for revision, then I'll be making one in rust.
There is a project right now that is a direct successor for Garry's Mod that uses C# with UE4. It's called S&amp;box and it's really promising, as far as GMod-alikes go. https://sandbox.facepunch.com/ Lua itself is not very well suited for certain workloads that require performance, although it is perfectly fine for most client-side uses. One other (rather personal, as someone who's worked with it for close to 8 years now) gripe with Lua is it's lack of static typing, proper OOP (yes, I am aware of metatables, but they are far from 'proper OOP'), and lightweight data structures (representing certain types of data using tables can consume much more memory space than it's worth). I'm not really looking to make a better GMod or anything like that, merely to explore the possibilities of using compiled languages in games of these caliber. It's just a curiosity, nothing more.
Fair enough! I've been (very passively) following S&amp;ndbox for a bit now. Just felt I should mention that performance could be far better since you made the comparison to Garry's Mod. Lua is definitely not a perfect language, but it still tends to be one of the nicest dynamically typed languages out there imo. I generally tell people that it's what JavaScript should have been. But as you said, it could definitely benefit from some of the optimizations a proper class/struct system gets you. That being said, something I've been interested in trying for awhile is designing/writing a hybrid static and dynamically typed language that compiles to very optimized Lua, where classes/structs are represented as just arrays (so Foo.Bar would compile to something like Foo[0] rather than having the string lookup) and more c-like syntax. Doesn't do much re: tighter data structures, but it gives you the performance of luajit and the portability of Lua without some of the drawbacks. And like I know moonscript exists, but that syntax really weirds me out lol. Haven't thought about it in too much depth, just something that's been on the mental back burner for awhile.
My understanding is that Javascript's surface area is far lower than Java's. Javascript was designed for the browser and so doesn't include I/O facilities such as networking or storage. However, a Java program has access to a full API. Restricting access to the I/O part meant restricting every path through Java's meta programming facilities as well as the rest of the API that may have allowed access to I/O in various unforeseen ways. The security manager had to check things at runtime. I see this as analogous to allowing null pointers. It's fine as long as you check that it's not null before you do anything else, but what if you forget to do it one time out of a thousand? Why allow null pointers to begin with? Why have I/O in your language at all? For Rust, why allow unsafe code at all? It's a weak point. Passwords are too important to risk it. Use a language with less surface area for things to go wrong.
I have a few gripes with Reddit's tree structure as a way to organize conversations. The first is that it becomes impossible to order messages sequentially. If I want to know what posts have been made in the last 24 hours, there is simply no way to do that. The second is that Reddit's upvote system inevitably turns into an agree/disagree button, which in turn leads to the "top comment chain" always being the most polarized possible version of any given discussion. The third is that I'm only notified about direct replies to my messages, and not to replies to the thread as a whole. An entire conversation could take place in a subtree that you're not related to, and you'd miss the whole thing. Imagine an RFC author completely missing a crucial discussion because they simply weren't alerted that it happened. These problems come together to make it very easy to leave peanut-gallery comments and vote on whatever other comments makes you feel good, but difficult for anything else. The end result is a userbase completely disinvested in anything resembling progress.
&gt; A tree-shaped comment section like reddit has might be able to help the velocity issue. Each top level comment has its own tree of replies. That's pretty much the reason why I'm reading `rust-internals` only by the email notifications. If you've an email reader with thread displaying, then you already get the tree structure. 
They're not really in competition, as they don't do the same thing. Rayon has crossbeam-deque as a dependency.
OMG. I tried and I couldn't do it in a reasonable time. If you solve it, you graduate in Rust borrowck. :)
&gt; If I want to know what posts have been made in the last 24 hours, there is simply no way to do that. Yeah that's pretty annoying. I don't think tree-style comments is incompatible with it though. Reddit should have some kind of 'show new comments' feature to highlight new comments. &gt; The second is that Reddit's upvote system inevitably turns into an agree/disagree button, which in turn leads to the "top comment chain" always being the most polarized, caricaturized possible version of any given discussion. I think that depends on the subreddit. Some subreddits are a mess, but at least on /r/rust I think people often upvote stuff that contribute to the discussion. I know I upvote stuff that I don't always agree with.
really appreciating this blog series, good reading
Second huge commit actually isn't needed. It contains Bindings which are usually generated during compilation. In this repo, they are committed just for simplicity.
I agree with all your gripes, but I think they are specific to reddit, not to tree-style conversations as a whole. E.g. Google Wave didn't have the up/downvote issue, and you could use the rewind/playback feature to see the whole sequence of the conversation, in time order (tough this was not very ergonomic.) I think it's clear that a subreddit would be a terrible place to house RFC discussions, but i don't think it's clear that tree-style conversations are unworkable.
Remember it's easier to do this in Rust using pointers, just like with C version
How are you measuring the time? Filling a 100000 element array cannot possibly take more that a few milliseconds.
The simple answer is, binaries compiled on older Linux systems work on newer ones, provided that you handle any shared libraries except glibc. Or use musl. Of course I mean the same CPU arch. I usually compile one for each system I want to run on but doesn't. I don't have many systems :-)
Collect also has nice complex logic to reserve enough space based on the size hints. which means that while for a loop you need to use 'with_capacity' collect does that for you.
&gt; Does rust support cross-plattform programming? Like can i program something on windows and run it on linux or does it require something? Yes, and the standard library is fully cross-platform. You can e.g. call Windows API functions and make you program Windows only if you want, and even use `#[cfg]` to have platform specific functionality on specific platforms. &gt; Are there any thing that can rust do but c++ can not(or super inconvenient) and vice versa? Depends on what you're asking here. They both compile down to binaries that can do anything on the platform you want them too, so there's no kind of program you can write in C++ that you can't write in Rust. If you're asking about language features, C++ makes it inconvenient to think about lifetimes (Rust forces them onto you) and C++ has various things like constant expressions) &gt; How is GUI development in rust? AFAIK, still complicated. You can interface with GTK relatively well and QT poorly. For Windows stuff, I honestly don't know. &gt; How is Game development is Rust? Is there any library or engine for that? There's an entire *scene* for that. /r/rust_gamedev
Why not just use, built in benchmarking, it's good, and working :)
For start remove unnecessary lifetime bounds from `Coordinator` and `Monitor`. Introduce them only for methods. From there it should be easy to fix your issue
I published [`serde_any`](https://crates.io/crates/serde_any), a crate for serializing and deserializing with a dynamically chosen format. Supported formats are JSON, YAML, TOML and RON. The format can be passed as an argument, inferred from a file name, or guessed by attempting to deserialize with each supported format. 
Better yet, don't use a GPL license, as it (and any other restrictive viral license) will be a major deterrent and likely cause many people to avoid the crate. MIT and Apache dual-licensing is sort of a defacto community standard for Rust projects.
Really good post. &gt; A lack of clarity about the “stage” of any given discussion. A thread brainstorming on a new way to approach Ok-wrapping should not need to recapitulate fundamental disagreements on whether Ok-wrapping is desirable. &gt; Too much emphasis on “the thread”, rather than on standalone artifacts. We don’t have a good process or culture around reflecting the discussion into the RFC itself, and while we do sometimes make “summary comments” to help manage discussion, they tend to get lost in the noise. The RFC thread takes on a primary, high stakes role instead. I wanted to comment on these two items. The RFC process I personally believe needs work. I compare the process to other RFC processes I've observed recently, notably the TLS 1.3 RFC process. In IETF RFCs there's a very clear revision number and stage values for where the RFC is at. See: https://datatracker.ietf.org/doc/draft-ietf-tls-tls13/ Additionally on top of that there's a github page dedicated to the RFC https://github.com/tlswg/tls13-spec where people can bring up issues and pull requests against the RFC. People can do line item comments incredibly easily. Rust has the same situation but most of the discussion happens on the **Pull Request** itself instead of on the RFC current state. IMO this drives more contentions debate to try to "stop" a train that's in motion (the pull request). I think if the initial RFC was simply submitted directly without comment and then people could file issues against the RFC it would better separate discussion and make things cleaner and easier to understand. Then there could be dedicated threads of conversation rather than everyone trying to talk on top of everyone for all the different issues going on.
&gt; A tree-shaped comment section like reddit has might be able to help the velocity issue. Each top level comment has its own tree of replies. &gt; &gt; I don't agree. Trees don't have titles so you don't know what the tree is about until you read some of it. If we had github issues (see my post) instead then we would have titles for the issues brought up.
Gui -&gt; There are some bindings and take a look at https://www.reddit.com/r/rust/comments/6qr11b/are_we_crossplatform_native_gui_yet/ Engine -&gt; Take a look at http://arewegameyet.com/ Cross Platform -&gt; You can add "targets" to rustup. You can run "rustup target list" to get a list of available targets
It's half millisecond at most on my i5, for slowest case of rayon par\_iter, makes sense.
When removing something from a HashSet&lt;i32&gt; with remove(), why do I always need to pass the number to remove as a reference?
Nice post as always. The link to @withoutboats's post "The Rust module system is too confusing" has a stray `.HTML` on the end which keeps it from loading. I'm with others here who think that at least part of the problem is just plain ol' not-so-good communications tools. The giant fast comment thread is essentially a (much more polite and constructive) LKML thread. It engenders confusion and makes reasoned discourse more difficult. I'm not sure tree-structuring the thread is a sufficient answer: it would be nice to have a dedicated tool for this kind of discussion based on sound principles of communication and dialogue. The original [C2 wiki](http://wiki.c2.com) was intended for this sort of thing and did it well, but sadly many folks find a wiki too awkward to use and hard to curate today. Anybody know a bright Communications PhD who could suggest what we might build to help? (Actually, I know one and will ask her.) We're maybe better at building such tools than designing them.
What if it *wasn't* an `i32`? What if it was a large structure that involved heap allocation? Having to pass in and destroy a new value every time you wanted to query a `HashSet` would be absurd.
&gt; I'm a casual community member and I usually don't keep up with RFCs because the amount of comments to read is really time consuming. One of my main concerns is that it's really hard to keep up with the progress of RFCs once they are accepted. Which ones have started implementation? Which ones are in nightly? Which ones are in stable? The implementation of the RFCs also often differs from the text because of practical concerns, are the RFCs updated to match the implementation? &gt; &gt; I agree. If we had a summary page that listed all RFCs currently in progress and the current status of each one, it would be quite helpful.
Interesting. I'd started work on one recently too. I got stalled at the "generate random escaped UTF-8 strings" stage. ASCII is straightforward, but UTF-8 is pretty complicated. It's not exactly clear to me what "random escaped UTF-8 string" should even mean, but any reasonable meaning is a lot of fancy code to get right.
I'm not sure Rust prefers anything, being a programming language and all. A lot of Rust users prefer functional style. I'm guessing it's partly because they come from a functional background, and partly because it is somewhat less error-prone than loops. It's really hard to have an off-by-one in a `map()`.
That's fantastic, thanks :)
Nice writeup :)
I recently sent one of my binaries off to a machine so old that it had a different `ld.so`. I can confirm that the `musl` approach that produces a pure static-linked binary with syscalls only worked for me.
Hm, i've just seen this has been posted here before as https://www.reddit.com/r/rust/comments/8rjn3k/beginner_rust_is_not_so_hairy/
Thanks! I'll add your topic suggestions to the list at https://github.com/hello-rust/show/issues
I would like to see uncover used into cargo codebase, because the usecase is exactly what made me wast a lot of time when I contributed to small bugfix into cargo.
I think this is roughly what OP was looking for… let mut a = [0u64; 100_000]; let _v = a .iter_mut() .enumerate() .map(|(i, v)| { let j = i as u64; *v = j * j; }) .nth(100_000); On my machine: test tests::bench_1 ... bench: 0 ns/iter (+/- 0) test tests::bench_2 ... bench: 53,892 ns/iter (+/- 505) test tests::bench_3 ... bench: 166,373 ns/iter (+/- 12,108) test tests::bench_4 ... bench: 159,566 ns/iter (+/- 2,435) test tests::bench_5 ... bench: 32,429 ns/iter (+/- 1,816) test tests::bench_6 ... bench: 68,702 ns/iter (+/- 2,566) test tests::bench_7 ... bench: 32,435 ns/iter (+/- 1,114) test tests::bench_8 ... bench: 54,551 ns/iter (+/- 2,623) It would be nice to convince `rustc` not to optimize away `bench_1`.
This is interesting. A couple of questions / concerns: how would you scan all PRs related to an RFC? I guess labels? How would you track which RFCs were at a given status? I suppose you could add a directory structure to the project, and promotion through the process would just be a PR to move the RFC to the next level’s directory.
Was 100% sure from the title that this was supposed to go to /r/playrust . :-)
Thanks this is both very interesting and encouraging.
You need a `&amp;mut [bool]`. Good luck!
I am assuming you want something like [this](https://play.rust-lang.org/?gist=63ce28370ec9f2577dc087825209f2af&amp;version=stable&amp;mode=debug). I'm not sure how much of an explanation you're looking for, so I'll just go through all of it. Let's start with the `get_sub_vec` function. You said you want to mutate the slice you get back from it, so you have to return `&amp;mut [bool]` since it needs to be mutable. And because you are mutating a slice of the original vector, the input also needs to be made mutable `&amp;mut Vec&lt;bool&gt;`. But it is recommended to pass a slice as an argument rather than a vector, so use `&amp;mut [bool]` instead (when passing the `Vec`, it will be automatically derefed into a slice). Lastly, since you want the output to be mutable, you need to give a mutable reference, so return `&amp;mut values[1..3]` instead of `&amp;values[1..3]`. Now we have the function we want, so when we call it we'll get a mutable slice. There's no need to make `vec` mutable, since it is a reference. Making it mutable just allows us to reassign it to a different slice. Also, there is no need to first dereference `vec`, you can just do `vec[0] = true;` and it will be automatically dereferenced. So if we stop with what I suggested above, we still have a problem because of the line `println!("{:?}", values);`. We are trying to use a value that is being mutably borrowed and Rust doesn't allow this. If you want to use it, you need to make sure it is no longer mutably borrowed at the point of use. One way of doing this is to wrap the borrow within its own scope as shown in the playground link above. Note that with non-lexical lifetimes, you don't need the inner scope. You can test this by using nightly and `#![feature(nll)]` in the link above.
Hmm I believe something of my understanding of the turbofish thing isn't correct. What is the difference then between: let x: HashSet&lt;&amp;i32&gt; = HashSet::new(); and let x: HashSet&lt;i32&gt; = HashSet::new(); ?
&gt; The TLS example would imply a repo per RFC, but that seems like it wouldn’t scale well for Rust given the volume of RFCs that are generated. It doesn't have to be built using github, though that would probably be simplest. It would require software development but you could wrap a github RFC pull request with an issue tracker and everything else on a dedicated website or automatically create a slim-repo when a pull request is generated against the RFC repo. &gt; How would you scan all PRs related to an RFC in a repo? I guess labels? Yes that's one way of doing it. You don't need to scan if you did 1 repo per RFC however. My personal opinion is that a repo-per-RFC makes the most sense even if it may be heavy-weight. You could segment into two types of RFCs. "trivial" vs "major" for example. "major" RFCs would get a full repo while "trivial" rfcs could just be handled by the pull request process. &gt; I suppose you could add a directory structure to the project, and promotion through the process would just be a PR to move the RFC to the next level’s directory in the project. I wouldn't use a pull request process. I'd probably use something like an attached .yaml (or something else) file in the repository that listed the metadata.
Pretty sure the first one involves passing a `&amp;&amp;i32`, whereas the second is as you've seen just an `&amp;i32`
Firstly, there's no turbofish there. Turbofish is `::&lt;..&gt;`, which is used to specify generic parameters in an expression context. Secondly, the difference is that the first stores references to `i32`s, the second stores `i32`s. The parameter to `HashSet::contains` is *always* a reference; it doesn't matter whether the `HashSet` is storing references or not.
To elide is to skip/remove. Bounds check are checks Rust performs when you index into an array (to make sure you're not performing out-of-bounds access which would be unsafe). So every time you write `foo[x]` Rust first checks that `x` is a valid index (aka `x &lt; foo.len()`), then performs the access. With iterators, values are within bounds more or less by construction (of the iterator), so usually you only get one access at the very start and no bounds check during the iteration itself.
I am still questioning the decision why add new keywords for that? For me language core should be kept as simple as possible as Rust already have a lot of complexity. Instead I would prefer to extend functionalities via macros and annotations as this requires less `language items` and each of such restricts language flexibility. 
&gt;summary page that listed all RFCs currently in progress PHP has that actually. [https://wiki.php.net/rfc](https://wiki.php.net/rfc)
You should still be able to avoid the in-loop bounds check on the second one by doing something like this: let col_slice = &amp;collection[..10]; for i in 0..10 { // do stuff with col_slice[i] } The compiler is usually smart enough to detect that the loop index will never be higher than the slice length, and only do the bounds check once instead of every loop.
&gt; Reddit should have some kind of 'show new comments' feature to highlight new comments. There’s a “highlight new comments” feature that you can enable if you buy a Reddit gold subscription. Other than that the free browser add-on named Reddit Enhancement Suite might have some similar sort of thing but I don’t know. I don’t use RES because I browse Reddit on my phone much more often than I do from my desktop.
I personally think the same thing. I remember some time ago reading that at first the first futures would probably look like that: #[async] fn foo(n: i32) -&gt; impl&lt;Future&lt;Output = i32&gt;&gt; { let r: i32 = await!(other_fn_that_returns_a_future(n)); r + 5 } And now we're all eager with adding the async/await stuff into the langage, but I haven't yet had the chance to right the code above on stable. I know that there are some prerequisites like the `Unpin` stuff that are blocking us from writing this on stable, so shouldn't we focus on being able to write such a code on stable and *then* we can talk about the async/await stuff? Also related, I am confused with the fact that `Future`s will not be started directly when created. Coming from javascript/typescript where `Promise` are started when created, I feel like I'm not going to be the only one confused here. I don't know how other languages solve this issue but I don't think they take the "lazy" approach of "Futures do nothing unless consumed" that we have right now. I feel like we could have some attributes `#[async]` and `#[async(lazy)]` or something, maybe that would solve the issue when you really want some futures to do nothing unless consumed? I'm not really too fond to add that in less that an year as well, I personally find it rushed. Do we really need those keywords to make Rust competitive on web server development side? Personally I don't think so. Disclaimer: It's been so hard to follow where the async/await features are right now that I don't really know if my point of view is still really accurate.
This looks... incredibly useful. I have a little nitpick regarding ergonomics: I would hope that custom test runners would make the `covers!` macro obsolete and just use the name of the test. This would mean that only the `covered_by!` macro would need be used. Otherwise, I find the idea of annotating which test covers what very intriguing. It immediately points out the branches which are not covered at all (no `covered_by!`), making creating the test-suite much easier, while at the same time providing this vital link between tests and code under test. I am unsure how to adapt it to "multiple" branches. That is, there is branch-coverage and there is execution-path coverage. Sometimes, a test wishes to test that a particular branch is taken and then another is also taken but a third one is not... or other such combinations. Maybe this is beyond the intended functionality, though.
You need a black-box or to return the array.
&gt; Do we really need those keywords to make Rust competitive on web server development side For me this is strange reason as I do not see Rust as a suitable language for writing web backend at all. Just there is no point of going through so much trouble in IO bound systems where you need soft real-time system, in that cases I prefer BEAM based languages (Erlang/Elixir) as this was designed from ground up to work in such cases. If you really need to fit Rust somewhere in whole stack then I think that Rustler is what you need, especially as Erlang 21 comes with dirty schedulers enabled by default. Where Rust can be useful as a web server are IoT that are really memory constrained, because if you have more memory then I would still go with [Nerves](https://nerves-project.org). Rust isn’t silver bullet that will magically improve your whole stack. Picking right tools for the job is still the thing. 
The moat important thing I think is missing is something like a badge or number on crates.io showing the number of code lines using unsafe in each crate. Users can decide if the crate type in combination with their use case makes the usage of unsafe code acceptable or not. There are many situations that require unsafe rust code but writing web frameworks is NOT one of them. I was very surprised when I discovered the unsafe usage in actix-web, for me this makes that library 100% unfit for internet exposure.
&gt; Instead I would prefer to extend functionalities via macros and annotations as this requires less `language items` and each of such restricts language flexibility. I disagree, both in general and in this particular case. In general, I disagree that using macros and annotations should be "the way to go". Macros and annotations introduce a very concrete obstacle toward understanding: it is not possible to immediately see the code which is compiled, because it is generated by the macro/annotation. This is also immediately felt when a compilation error occurs within the generated code. Therefore, I would prefer macros and annotations to remain occasional. In this particular case, there is a *semantic difference* between sync and async function: as mentioned, the latter captures *all* input lifetimes and no code is executed by default. This is a very significant change of semantics, and I would argue that semantic changes definitely warrant keywords to unambiguously denote them. (This is in sharp contrast to the `derive` macro, which is additive, not transformative)
Another important point is that we need to specify what trait bound the output of an async functions satisfies. What /u/desiringmachines [suggested here](https://internals.rust-lang.org/t/pre-pre-rfc-async-methods-bounding-async-fns/7656) is ```rust async(Send, Sync) fn foo(&amp;self, &amp;i32) -&gt; i32 {/*..*/} ``` however I think that ```rust async fn foo(&amp;self, &amp;i32) -&gt; impl Future&lt;Ouput = i32&gt; + Send + Sync {/*..*/} ``` is a lot more clear. This way we have the traits on the end of the function signature like al other bounds of the output. This also uses the existing `impl Trait` syntax instead of having to use an entirely new concept just for this one special case. Anothother big factor for me is that `-&gt; impl Future&lt;Output = T&gt;` signals that this function does not just output a `T`. The output is a `Future` and jou have to do something with it (run it on an executor or poll it yourself) before you get a `T` as output. When using just writing `-&gt; T` I think a lot of new people will be confused and will try to use it as a `T`. This will also hide the fact that you can give the return of this function to anything that requires a future.
I honestly hate writing macro identifiers. With IDE autocompletion it's fine but without any assistance pressing `Alt Gr + 8` to get a `[` symbol and then pressing `Shift + 3` to get `#` symbol and so on is really tiresome compared to than just writing a simple word in lowercase. That's the only reason why I think a keyword is nicer from my perspective.
As noted earlier, I run this code a bunch of times. Otherwise this takes less than a second.
The OP opened this Reddit account just to make this controversial post. Don't create trouble where there is none, OP. You're not anonymous.
do you mean x32 &lt;-&gt; x64? I'm on x64 and my server is x64. I'm on Arch and my server can be some other Linux. We're both more or less up to date. Will I have any problem running an executable on my server if I compile an executable on my comp?
I am not that familiar with async development, but can't we do the following thing: // Somewhere in the std or futures crate (name can be shorter) // Note that 'input will automatically catch input lifetimes of the function existential type ImplFuture&lt;T&gt;: Future&lt;Output = T&gt; + 'input; // user crate // if user desires explicit `impl` still can be used instead of shortcut use std::future::ImplFuture; async fn foo(a: &amp;str, b: &amp;str) -&gt; ImplFuture&lt;u32&gt; { .. } This way we'll remove most of `impl` boilerplate, while retaining flexibility of explicit outer style signatures.
rust version of binary file parser for [OpenMoonstone](https://github.com/joetsoi/OpenMoonstone/tree/master/rust/src). The test version I wrote in rust is 60-80 times faster than the python one. Which feels amazing.
I would like to have type safety, performance &amp; low memory footprint, and maintainability for my web server, is that too much to ask? I feel like Rust is the only language that has been able to offer all 3, the only problem is that there is no easy-to-code Future support on stable *yet*, so writing a web server is less efficient. As a result, I've had to resort to start a project with Typescript at my company to still have maintainability at the cost of less performance (which isn't garbage but still is at least 10x slower) and a easier-to-mess-with typesystem. Back then, I would have *loved* to use Rust instead of Typescript, because the server was both CPU and IO heavy. However it wasn't possible back then because you had to use nightly (and it looks like it's still the case right now). Granted, I haven't looked at Elixir yet, and maybe I should. I understand your concerns about the added async/await keywords, however don't underestimate the community that would like to use Rust for web development; as a part of the Rust community, you should know how much we love having a powerful and safe type-system, even if it's slower to code overall. Most of us don't mind spending 50% more time to code something at first if it means easy refactoring and maintainability is a given for later.
Running them a bunch of times, in addition to the 100,000 loops below, in order for the time to be more than a second, for accurate timing.
Running them a bunch of times, in addition to the 100,000 loops below, in order for the time to be more than a second, for accurate timing.
Running them a bunch of times, in addition to the 100,000 loops below, in order for the time to be more than a second, for accurate timing.
Running them a bunch of times, in addition to the 100,000 loops below, in order for the time to be more than a second, for accurate timing.
You could do both. e.g., `async fn foo() -&gt; impl Future&lt;Output = i32&gt;` is legal while `async fn foo() -&gt; i32` is also legal and exactly equivalent. If you favor the inner return type syntax, then permitting the outer return type syntax provides a "normal" way to extend the type signature with things like `Send`. It also seems more congruous with the initialization pattern. The downside is that supporting both kind of stinks because you have multiple ways of doing something, but, it provides a nice path to use more complex type signatures that is consistent with the rest of the language and doesn't require introducing more special cased syntax.
I would rather more in the Rust community to inquire about crates like OP has. If you see controversial statements, you might be projecting. The issue on github has been respectful conversation aimed at writing correct code so far, and it should continue to be in this thread as well.
Eek. That sounds terrible! On a UK keyboard # is it's own key next to the enter key (and shift-# is ~), and [ and ] are also their own keys where shift-[ is {, shift-] is }.
Yup, it's pretty cumbersome to write rust sometimes. They layout is like this (fin/swe) https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/KB_Sweden.svg/2000px-KB_Sweden.svg.png
Couldn't `async fn foo() -&gt; impl Future&lt;Output = i32&gt;` also be interpreted as `async fn foo() -&gt; impl Future&lt;Output=impl Future&lt;Output = i32&gt;&gt;` if you allow both ways?
You don't come from out of left field and impose unsafe audit mandates on a project you've contributed nothing to. No one owes you a second of attention. Be the change you wish to see in the world. If you don't like the "unsafe" code blocks, refactor and submit a PR.
Is it? i can't find a reference to that marco. what is `print_schema!`?
Interesting; on my machine moving the type details to the **collect** seems to get both running slightly faster, with multiplication bearing **pow** by a hair as well. It's consistent, but in the thousandths of a second.
Running them a bunch of times, in addition to the 100,000 loops below, in order for the time to be more than a second, for accurate timing.
why not build it in C if you're going to be using unsafe that much... (well, more exactly, if you're going to expose an unsafe API). thanks for informing us.
&gt; in any case we have to evaluate every use case for unsafe. i used unsafe for the reason, in most cases i couldnt come up with safe solution. Did you however ;)? https://github.com/actix/actix-web/pull/327/files Seriously however, I'm pretty sure most uses of `unsafe` in the codebase either are soundness holes or could be removed.
You need to come up with a set of rules that makes it unambiguous. One such rule is, "if the written return type of an async fn is a not an impl Future, then apply the inner return type scheme by wrapping it in an impl Future. Otherwise, if the written return type is an impl Future, then don't apply any transformation other than lifetime elision." In that sense, `impl Future&lt;Output = i32&gt;` is not ambiguous and neither is `impl Future&lt;Output = impl Future&lt;Output = i32&gt;&gt;`.
I replied to a deleted comment but I'm gonna post it here to avoid retyping it. &gt; You don't come from out of left field and impose unsafe audit mandates on a project you've contributed nothing to. No one owes you a second of attention. Be the change you wish to see in the world. If you don't like the "unsafe" code blocks, refactor and submit a PR. This is a pretty unhelpful thing to comment on a thread from someone asking for a discussion about an issue. And I am glad he brought this to my attention because I was unaware and considering using actix-web in a project, and I didn't think of evaluating which framework to use on the metric of unsafe code. I think it's a worthwhile topic to discuss, and, as someone else commented, something like a badge tracking unsafe code would be a good start.
Looping through container indices is extra boilerplate that doesn't add anything for me. (there are of course other cases but in general...) 1. I'm going to have to look up the thing in the array anyways, probably I'll assign it some meaningful identifier before I use it. This is all done for you with `for item in container` 2. However many operations in the loop have general forms. I think `container.filter(CONDITION)` is more clear than `for item in container { if CONDITION { other_container.push(item); } }` 3. All of this gets lazily evaluated too (eg after `container.collect()`) so that's a nice feature. There's always cases where you'll want to operate within a 'normal' loop but a lot of the time you can express things using the higher order functions and I find it significantly more readable.
I highly encourage you to do so. While Erlang/Elixir doesn’t provide hard type safety like Rust but it has soft type safety via Dialyzer. However for me it is much easier to maintain readability in actor-like stystem like Erlang than it is in Rust, especially in case of unexpected errors which OTP handles perfectly by, not handling them at all. It just kills the process and starts new one hoping that this was one time accident. Also due to fact that most processes are short lived the GC isn’t problem because in most cases you will just throw away whole process stack. So for me if I would be in need to write such IO and CPU bound application then I would use BEAM with Rust via Rustler. And fact that BEAM uses collaborative schedulers (which are hard in Rust) makes it even better for high IO apps as you can write async code that seems sequential from the programmer view. 
&gt; In general, I disagree that using macros and annotations should be "the way to go". Macros and annotations introduce a very concrete obstacle toward understanding: it is not possible to immediately see the code which is compiled, because it is generated by the macro/annotation. Isn't that exactly what happens with async/await, the only difference being that the "macro expansion" has to be embedded in the compiler itself?
I would love to see a write up on this. 
I'm not very fond of reopening _that_ debate here. Much more then `async`, `await` isn't easily possible without some addition to the language. It can't be implemented as a macro, to my understanding. Making those words a pairing makes sense. While I agree that syntax extensions should be weighted against gains, async/await makes a lot of code in concurrent situations much better, _especially_ await.
I can imagine this being confusing, especially when there will be generics and macros involved in.
Do we need the `async fn` at all if we go with outer syntax? Can't we just only have async blocks? fn foo() -&gt; impl Future&lt;...&gt; { async { ... } }
Strictly speaking, that's an option, however often enough such a block would cover the contents of entire function block.
Yikes. Just briefly skimming its source code has eyebrow raising uses of `unsafe`. This one for example: https://github.com/actix/actix-web/blob/5c42b0902f9cc38b1e6e7c8a53637f1ca781a170/src/router.rs#L81 let path = unsafe { &amp;*(&amp;req.path()[self.0.prefix_len..] as *const str) }; `req.path()` returns a `&amp;str`, so `&amp;req.path()[self.0.prefix_len..]` should work just fine. Actually doing that change causes the compile to fail, which reveals why `unsafe` is being used here: to disable the borrow checker because `req` is borrowed mutably at the same time. This can definitely be annoying, but resorting to `unsafe` here seems dramatic. The code likely needs to either be restructured and/or use various _safe_ interior mutability building blocks in the standard library. Here's another one: https://github.com/actix/actix-web/blob/27b6af2800ca368cda314a94ff1936d5142bc782/src/httprequest.rs#L452-L456 /// Get mutable reference to request's Params. #[inline] pub(crate) fn match_info_mut(&amp;mut self) -&gt; &amp;mut Params { unsafe { mem::transmute(&amp;mut self.as_mut().params) } } `Params` itself has a lifetime parameter, and the `transmute` in this case causes the liftetime parameter to be coerced to whatever makes the caller work. This isn't just disabling the borrow checker; this is _begging_ for memory unsafety. I don't usually word criticism this strongly, but these are **serious deficiencies** that need to be addressed. Rust programmers should be pushing back *hard* against this kind of misuse of `unsafe`. Even tests use things like `String::from_utf8_unchecked` to purposely create strings that contain invalid UTF-8: let s = unsafe { str::from_utf8_unchecked(b"some va\xadscc\xacas0xsdasdlue".as_ref()) }; That doesn't inspire confidence. Finally, through my skimming, I didn't see a single comment justifying the use of `unsafe`. These are "nice to haves" and I'm not perfect about it either, but given the scale of `unsafe` used here, I'd expect to see _something_.
Of course it's confusing. But it's a design point. Has anyone thoroughly explored it?
Yes personally I think that would be the best approach at least at first. We could always introduce `async fn` as sugar later.
Is there safe way to test how application handles malformed utf8? First is addressed already
&gt; the only difference being that the "macro expansion" has to be embedded in the compiler itself? It makes all the difference, though. In terms of compilation errors, for example, it means that the compiler will use its knowledge of `async` to craft the most intelligible error message possible, and will anchor the message on code you see. Whereas with async as a macro you get a generic error message anchored to code you don't see which is back-linked to code you see: the decrease in quality is pretty sharp. The trade-off, of course, is that the integration comes at the cost of a larger and more complex compiler.
Wouldn't it be a good idea to provide better error-reporting facilities to procedural macros in the first place?
&gt; Is there safe way to test how application handles malformed utf8? If you accept a `&amp;str`, then the only way for that `&amp;str` to contain invalid UTF-8 is if `unsafe` was abused. Therefore, if an API accepts `&amp;str`, then testing the invalid UTF-8 case for that API doesn't make any sense. If you need to handle invalid UTF-8, then your API should be accepting a `&amp;[u8]`, and that can contain arbitrary bytes. But if you're dealing with potentially invalid UTF-8 in a `&amp;str` somewhere in your code, then something is _seriously_ wrong. &gt; First is addressed already The first was just an example. I see similar things repeated over and over throughout actix-web.
This comment has finally convinced me
If you want something a bit more sophisticated for running benches, I'd recommend checking out criterion: https://japaric.github.io/criterion.rs/book/faq.html#how-should-i-benchmark-small-functions
https://play.rust-lang.org/?gist=4554e55ed2c2b8bbfc86fade0bffa7df&amp;version=stable&amp;mode=debug
&gt; wouldn't it be a good idea to provide better error-reporting facilities to procedural macros in the first place? Yes, but that's unrelated. I am not talking about errors generated by the macro itself (eg. `println!` reporting that an argument is missing) but about errors in the generated code. In the latter case, the macro is already done, it has already informed the compiler of the links between inputs and generated code, and yet an error occurs (type-check for example). I have sometimes toyed with the idea that the "fully expanded" code file should be written off somewhere in the `target` directory, to be used in error messages and for users to get a good view of what Rust code is actually compiled... but having worked on quite a few code generators, I can confirm that this one more layer of indirection is *always* a hurdle. It takes one (at least) more mental hop to map the code written to the code generated. It's unavoidable, really.
What does static linking have to do with exposing the code? You can distribute precompiled rlibs for the compiler to link against if you want to.
Thanks, I'll look into rlibs!
Also took me a third try over 1 to 2 years for it to stick. Wondering if the concepts just need that much time to ruminate to understand.
&gt; The inner return type approach introduces an unnecessary notational split between how the initialization pattern looks and how async function signatures look like. It fails to indicate that these two notations are very closely related. I don't have much experience working with Rust futures yet, but the difference between "work done on the first poll" and "work done by the future constructor" seems like the sort of thing that people will often get confused by. I wouldn't mind a large syntactic difference between those two cases.
\&gt;How can people have confidence in the safety of crates they use? That is kind of the nice thing, if safety is hugely important, grep for unsafe blocks! Avoid things with too much or unsound use of it. 
I think because this fallback is always possible, there's more of a reason to prefer the more ergonomic inner async return type.
\&gt;why not build it in C if you're going to be using unsafe that much Well Rust is a nicer language and ecosystem to work with in many ways, so it isn't totally crazy.
Yeah in a sense (to your question). Compiling on an x32 and moving the binary to a x64 is fine on most linux machines, but the opposite is not true. A more dramatic example would be compiling on a powerpc and trying to run it on an Intel CPU, this will not work because the machine code of the binary won't match the machine code of the CPU. If you do need to do something like this you'll need to do what is called cross compilation. This is where you tell the compiler you want to compile for a different target. You may be familiar with this for any compiling on linux and running on windows, but you also need to do (or it would at least be best) for different architectures. 
:( I recently decided to use `actix-web` due to it seemingly being the most mature out there currently and maybe the long term bet, dismayed to hear this
Unfortunately for OP the compiler was very unhelpful. He did exactly what was suggested to him: help: you must specify a type for this binding, like `i32` | 2 | for i: i32 in 0..100 { | ^^^^^^ The suggested change isn't legal rust. I couldn't find an existing issue for this so I filed a [bug](https://github.com/rust-lang/rust/issues/51634)
I wonder if putting number of `unsafe` usages in cargo would make sense. I also didn't consider checking for it, mostly because I personally make it a point to avoid it and I guess I assume others do as well.
&gt; I don't know how other languages solve this issue but I don't think they take the "lazy" approach of "Futures do nothing unless consumed" that we have right now. .Net languages like C#, F#, and VB take the "lazy" approach. You must call the `Start()` method on `Task` which is their equivalent of `Future`.
Dammit it's to early. Be x32 I mean x86.
Use a US layout for coding, then. Scandinavian layouts are atrocious in that regard.
They're in the process of [removing their SDL2 dependency](https://github.com/ggez/ggez/pull/388). And I'm pretty sure that in turn paves the way for [a better web story further down the line](https://www.reddit.com/r/rust_gamedev/comments/8cwgjq/ggez_on_wasm_perspectives/). I get that you're learning a lot by doing everything from scratch, but ggez and Quicksilver are solving so many of the same problems that the amount of double work that is being done is quite disheartening. The Rust gamedev ecosystem is still in its infancy; framework fragmentation is not what it needs right now. In my 15 years of working in open source, the simplest indicator I know for predicting an OSS project's long term success is that it has at least 2 strongly opinionated core maintainers who are in 80-90&amp;#37; agreement on how to do things. I don't expect you to stop everything you're doing to join forces with ggez, but I hope you'll keep it in the back of your mind. One such convergence event provided a significant driving force for the Amethyst project [when Xaeroxe decided to fold his Nitro engine into Amethyst](https://github.com/amethyst/amethyst/issues/245). I see you've reached out to winit to help out with the wasm backend, which would be an exceptionally important contribution! It's this type of cross-pollination between projects and convergence of key tooling that makes Rust poised to become a leading programming language for games in the decade to come.
You mean like a parser generatir, that produces nom code?
&gt; And fact that BEAM uses collaborative schedulers (which are hard in Rust) Would you mind expanding on that a little bit? I'm really curious about what providing a whole language runtime is able to provide that user-space rust libraries like actix can't do as easily. (I've used BEAM languages a bit, but have not yet had a chance to try out actix).
But in the same vein, can't you say the same about many of the use cases where you declare outer return types the winner? Abstract return types and trait bounds in particular. Yes, for those uses cases, outer return types are preferable or even necessary. But for those use cases, /u/0b_0101_001_1010's solution can be used, while "often enough" there are no abstract return types or advanced trait bounds, and in those cases the inner return type is a simple, compact, and easy to understand bit of syntactic sugar.
Collaborative schedulers require each process to mark where it can be interrupted and go back to scheduler queue. This mean that either such scheduler need to be built in into language where one can automatically insert such instructions or it requires from the developer to remember to add calls to some kind of code that would handle such case. The problem with second one is that it is completely possible for developer to forgot about it (or go awry and intentionally omit such) and take whole time for themselves while starving the rest. That is how multiprocessing worked in early Windows and it isn’t good idea to trust developer. 
&gt; Yes, but that's unrelated. It isn't though. &gt; I am not talking about errors generated by the macro itself (eg. println! reporting that an argument is missing) Neither am I. &gt; In the latter case, the macro is already done, it has already informed the compiler of the links between inputs and generated code, and yet an error occurs (type-check for example). Obviously, and that's my point, if the compiler can have hooks which allow generating quality specific error messages in that exact situation, maybe macros[0] could get that kind of facilities and be able to hook in and provide good, specific error messages. [0] again I'm talking about procedural macros here, compiler plugins if you will, that obviously is not an option for declarative macros but it's not like declarative macros can handle something as complex as async.
So yeah this was the first project I've gotten to use cli testing tools like assert_cli and dir-diff. API wise I had no problems, however there seem to be some platforms that are failing in the CI, specifically [i686-unknown-linux-musl](https://travis-ci.org/Aaronepower/eve/jobs/393467768), and all [windows](https://ci.appveyor.com/project/Aaronepower/eve/build/1.0.11) platforms.
Yeah. I was only thinking that we are pretty sure about what to do with `async { }` blocks and they are an enabler - meaning they let us do something that we couldn't easily do before - while the interaction of `async fn` with life-time inference, abstract types, etc. is a bit less mature. I'd rather get `async {}` blocks quick, and let the `async fn` bits mature in nightly, than block `async {}` on resolving all potential issues of `async fn`.
 match x { Thing { x } Thing { x } } Is this matching `x` to a variable named `Thing` and returning `x` twice, or matching a struct `Thing`, binding a field `x`, and returning `Thing { x }`?
If the function return type is future why label it async? If the function is labeled async why have the return type containing future? Either one or the other not both.
Actix-web... 
It's not that easy to change muscle memory. And I'd rather have the keys written on the keyboard where they actually are just in case I actually need to check where some obscure symbol is (that horrendously expensive OLED keyboard would've been nice in that regard).
&gt; I would like to have type safety, performance &amp; low memory footprint, and maintainability for my web server, is that too much to ask? Given that Rust is the first language that *can* offer those properties, I'm fine with the devs waiting to get it right.
Isn't this exactly how tokio runs futures?
Aren't you missing a coma? How would you write this with fat arrows?
If your feature is short lived then it can be, however if you have long lived feature then not exactly. Tokio is using event pool for handling IO, but if you have CPU bound computation in your handler then it have to use interrupting scheduler to stop one task and give time to another, it isn’t collaborating.
&gt; Aren't you missing a coma? No; the comma after braces is optional. Also, it's poor form to have syntax that requires you to go back an unlimited number of tokens to re-parse what you've already seen: it's hard on both humans *and* compilers. &gt; How would you write this with fat arrows? You wouldn't; it's impossible to write something *that* ambiguous with fat pointers being required. That was my point. The first interpretation would be `Thing =&gt; { x }, Thing =&gt; { x }`, the second would be `Thing { x } =&gt; Thing { x }`.
Thanks, that was exactly the answer I was looking for!
I am extremely disappointed by the dismissive responses from the Actix owner in [#289](https://github.com/actix/actix-web/issues/289) and [#301](https://github.com/actix/actix-web/issues/301). So far I have heard only good things about Actix but these threads make me hesitant to recommend it to anybody. Quite a shame!
Looking at the Linux failure, this is inspiring me to have `assert_cmd` print the exit code when the program unexpectedly fails. I need to also add back in the printing of stdout/stderr in these cases. Those failures on Windows tend to happen when there is a file handle left open. In tests, you should always explicitly `close` temp files and dirs to catch any errors with cleaning them up. These silent failures can lead to those unwraps. Granted, it'd also be nice if we could more easily see what unwrap is failing.
Thanks for the heads up on actix. As others mentioned, a badge would be a great idea, but a compiler flag would be even better (over and on top of the badge). `cargo build --safe`, or something along those lines as the safety level of a library could change w/o notice. A glance at Safe Haskell could be instructive here: https://downloads.haskell.org/~ghc/7.8.4/docs/html/users_guide/safe-haskell.html
How about https://github.com/actix/actix-web/blob/285c73e95ea4a011673bcd4f84a26d2aee84e592/src/server/helpers.rs#L80 
&gt;let path = unsafe { &amp;\*(&amp;req.path()\[self.0.prefix\_len..\] as \*const str) }; Syntax-soup like this inside an unsafe block should be categorically rejected by a code review (without even trying to understand what it does) on the grounds that anything inside an unsafe block should be clear to understand and obvious that the necessary contracts are upheld.
Excellent catch! I really need to come up with better names for these two macros. I always mix them up myself :( If anyone has better suggestions, I am all ears!
No, and I kind of dislike it when someone says on the rust sub: "Rust sucks for that." Or "Don't use Rust for that." I get that it's not the best for everything, but sometimes features/the practice we are engaging in makes it what we want to use. A lot of times these features don't get ironed out until someone is brave enough to have a bad time.
&gt;I have a little nitpick regarding ergonomics: I would hope that custom test runners would make the covers! macro obsolete and just use the name of the test. Yep, that would be useful! `covers!` macro would still be more general though: in a long test, you can have different `covers!` for different blocks, for example.
That would be tricky unfortunately... Cargo tests spawn a separate Cargo process and assert stuff about its stdout/stderr. That is, the test and code are in separate processes, and so `uncover` directly won't work :(
Is there something that `futures-await` is missing that can only be added by making new keywords instead of using a proc macro?
The same for me. I don't think it was because of the borrow checker, that wasn't too hard to understand in concept, but I kept getting tripped up by some of the syntax and had trouble finding the right thing in the standard library. I still get tripped up a bit by `&lt;'a, T&gt;`, usually I first try to write `'a&lt;T&gt;`. But the standard library is fun to work with now, probably the turning point was learning about `rustup doc` for when I'm on a bad connection. NLLs also helped a bunch.
In many Linux distributions it possible to configure switching keyboard layouts with a simple shortcut. I used to code have a Swedish keyboard and always set it to US for coding. If I needed a special character it was simply a matter of "Win + Space" to change the layout. 
Oy. That's straight up UB. *Two separate lints were disabled* in order to write that code. &gt; In general, transmuting an &amp;T type into an &amp;mut T is considered undefined behavior. https://doc.rust-lang.org/std/cell/struct.UnsafeCell.html
That's interesting. I think I need to just try writing some tokoi code to fully get it.
I think identifying the problems about "stage of discussion" and "comment thread velocity" is *spot on*, and also related. The length of the thread is both a barrier to entry (if you see the RFC already has &gt;100 comments, that's a lot to catch up on), and contributes to people dropping out. And, because it's unthreaded/linear and Github will eventually hide swaths of comments in the middle, you can easily feel like your viewpoint was forgotten. This is compounded when the authors decide to close the RFC altogether and open a new one with a revised draft -- though that also shortens the comment thread, reducing the barrier to entry, so there's a tension there. Threaded discussion, or some better idea of "stages" with summary comments that acknowledge previous points of discussion, might help. Another contributing factor to the velocity issue around the ergonomics initiative was the impl period -- whether intended or not, it seemed like there was a rush to get RFCs approved before the impl period (even though relatively few of them actually ended up getting implemented then). 
Give it a shot. You'll adapt in no time. And as the other commenter said, there are shortcuts for switching back and forth between SE/US (but you probably knew that already).
I wonder if it would be practical to have some kind of peer review in the Rust ecosystem. It wouldn't make sense for every version of every crate to be reviewed by experts, but perhaps we could try to review some key things? A bit like the \[libs blitz\]([https://blog.rust-lang.org/2017/05/05/libz-blitz.html](https://blog.rust-lang.org/2017/05/05/libz-blitz.html)) but ongoing.
Sorry I meant `infer_schema!`
Yikes! Just had a discussion with my PM about this and we are _definitely_ avoiding actix-web until these issues are resolved. Elegant API, but this seems too scary and likely to bite us down the road. Fortunately not yet too invested...
Just counting doesn't help - you can have a single `unsafe` block with hundreds of lines. Probably need human auditing, unless someone can come up with a clever way of counting total statements-inside-unsafe
Absolutely. I wouldn't touch actix-web until it's clear that their approach to `unsafe` shifts dramatically.
There's lots of bits of advice from Cliff Click, a very experienced JVM developer: * https://www.youtube.com/watch?v=vzzABBxo44g (Curry-On version, 44min) * https://www.youtube.com/watch?v=Hqw57GJSrac (Longer version from a VM summer school, 1h 15min)
I have tried to make Rust tutorial implementation for Apache Thrift (RPC framework) going, but had no luck with it ([https://www.reddit.com/r/rust/comments/8nq50l/how\_to\_create\_thttpclient\_for\_thrift/dzzhnlq/](https://www.reddit.com/r/rust/comments/8nq50l/how_to_create_thttpclient_for_thrift/dzzhnlq/)), so I started evaluating GraphQL, and Juniper seems to be a very promising GraphQL server framework, so I decided to play around Juniper + Diesel served by Actix-web and had some minimal example working when suddenly discovered a demo which used exactly the same stack [https://www.reddit.com/r/actix/comments/8r6wqv/swipe\_app\_api\_with\_actixweb\_and\_graphql/](https://www.reddit.com/r/actix/comments/8r6wqv/swipe_app_api_with_actixweb_and_graphql/), so I switched to it and will probably continue my contribution there.
First interpretation would be this? match x { Thing =&gt; { x }, Thing =&gt; { x }, } Can you really match twice on the same thing?
Maybe this is obvious, but in an `async` function, the body is what runs when the future is polled. But in a regular function returning the same future type, the body runs immediately to construct the future. So the `async` keyword in the function signature is behaving the same as wrapping the entire function body in an `async { ... }` block.
No, but that's a *semantic* error, not a *syntactic* one. The *parser* has to resolve this ambiguity, so it can't rely on whether the code will eventually prove to be valid or not.
Check out the definition of `HashSet::contains`: impl&lt;T, S&gt; HashSet&lt;T, S&gt; where T: Eq + Hash, S: BuildHasher { // ... pub fn contains&lt;Q: ?Sized&gt;(&amp;self, value: &amp;Q) -&gt; bool where T: Borrow&lt;Q&gt;, Q: Hash + Eq { /* ... */ } // ... } OK, that's a lot of generics, but you can see that if you have a `HashSet&lt;i32&gt;` (`T=i32`), then you can call `contains` with a *reference* to any `Q` where `T: Borrow&lt;Q&gt;` (meaning a `T` can be borrowed as a `&amp;Q`). In particular, there is a "blanket impl" `impl&lt;T&gt; Borrow&lt;T&gt; for T`, meaning if we ignore stuff like `String` turning into `&amp;str` then we can imagine rewriting the above for simple cases: impl&lt;T&gt; HashSet&lt;T&gt; // I also dropped S because it's usually left at the default where T: Eq + Hash { // ... pub fn contains(&amp;self, value: &amp;T) -&gt; bool { /* ... */ } // ... } That's why it wants a `&amp;i32` when you have a `HashSet&lt;i32&gt;`, and it would expect a `&amp;&amp;i32` for `HashSet&lt;&amp;i32&gt;`. 
Well, i've heard great things about rocket, but they are on nightly. They are thinking about stabilizing, but there's still a lot of nightly code left in there.
Maybe a site called, "Are we Safe Yet?" that automatically pulls in all unsafe usages in projects on [Crates.io](https://Crates.io) and displays the context and allows commenting on the usage and a voting systems as to whether the usage is justified and "safe" (upholds the appropriate contracts, etc) and is well documented as to the contract required for safe usage (unsafe fn and traits).
Does rocket do any better in this respect? Or do they also have no issues with (mis)using unsafe blocks all over the place?
As can be read in the Conservativeness &amp; Consistency section it would be used to signal the compiler you want it to a) transform the procedural looking code in the function body to a finite state machine to prevent unnecessary rightward drift that comes with an async block and b) to make it possible to elide the lifetimes and have the compiler infer what they are
In that case, I'd argue that the test should be broken down in multiple tests, though ;)
This is a rather inspiring exposé. The author of Actix used all of the tools available at his disposal to solve problems at breakneck speeds. Have you noticed how far Actix and Actix-web have gone in the last 12 months? One lesson to draw from this is that you *can* be productive with Rust, especially if you're not holding yourself to the highest, unpragmatic standards of code craftsmanship from day 0. It seems, however, a bit too much was pushed under the rug. Time to do clean things up. The good thing is that if anyone can sort this out, it's the author of Actix. I am 100% confident that he can and will. You should be too.
I think there's a big category difference between 1) you're doing the right thing with the wrong syntax and 2) you're doing something Rust fundamentally doesn't want you to do. The second thing can look like "trying to create a self-referential struct" or "trying to build a doubly linked list with `Box`" or "trying to push into a list while iterating over it". Or with beginners, it could even be something simpler like "trying to return an `&amp;str` from a `String` you constructed locally." When you're trying to do those things, the compiler will tell you about the small immediate problem (blah blah this reference outlives this other reference), but not the larger problem (fixing that reference error will inevitable cause other errors, because what you're trying to do is impossible). So I think the biggest factor in whether you start to "get" Rust, is whether you've seen enough working code to make your first guess "close enough" for the compiler errors to be helpful. If your instinct is "hey this function is building a new string, so the return type should probably be `String`", then you're in a good place. Likewise "hey these data structures are going to form a graph, so I should probably start out with `Arc&lt;Mutex&gt;`." I bet a lot of the time, coming back to Rust for the second or third time means you've accumulated enough examples in your head, that your initial guesses for how to structure your code are more likely to land in the "compilable zone".
Counting total statements inside unsafe is pretty easy to do with any Rust parser libraries. I made a little utility does something like that, albeit poorly: https://crates.io/crates/cargo-osha Adding proper counting of expressions inside `unsafe` blocks was easy, here's the results for actix-web: Unsafe functions: 1/352 Unsafe expressions: 1025/37602 Unsafe traits: 0/30 Unsafe methods: 1/1354 Unsafe impls: 2/618 
So you'd basically have to know when seeing fn foo() -&gt; Bar whether Bar impl's Future or not? Nah definitely not something I think is helpful with understanding code. You'd be constantly asking: is this implementing Future itself, or is it using wrapping? Code guides would start recommending `impl Future` syntax because it'd be ambiguous. So no, I don't think this would be a good idea.
What's the reasoning for that?
You could count the length of the contents of each block.
What are the two numbers here? Is that 1 unsafe function out of 352 functions defined in the crate? 1,025 unsafe expressions out of 37,602 expressions defined in the crate overall?
It would be even better if cases of unsafe could be tagged with an identifier that references an "Unsafe.toml" in the project root with an explanation for the use of unsafe. Then on crates.io we could show a list: &gt; Project contains the following uses of `unsafe`: &gt; * Efficient list data structure (12 expressions in 1 module) &gt; * Transmute for data type conversion when parsing label (1 expression in 1 module) &gt; * SIMD optimizations (40 expressions in 3 modules) &gt; * Unspecified uses of unsafe (1 expression in 1 module) &gt; * Project has 12 transitive non-std dependencies that contain use of unsafe 
I think you'll be happy when you read Niko's post about our discussion.
I just did a quick scan, and they are definitely on different planes with respect to `unsafe` use. Rocket does have some. I count ~22 instances outside of non-test code. Most uses are far more restricted in scope than what you see in actix-web. With that said, it feels like there's probably room for improvement, and there isn't much if any documentation *justifying* the use of `unsafe` anywhere. I would say that Rocket could use an audit (hell, any code with `unsafe` could use an audit, especially code that lacks safety arguments), but I'm not terrified after skimming it. :-)
Agreed, I'm a bit uncomfortable with the way some are reacting to this news. Actix is pretty fantastic and if there is some overzealous use of unsafe, well, that can (and should) be fixed. Very few people are experts at Rust at this point and knowing how and when to use/not use `unsafe` is an advanced skill, so we shouldn't be too quick to criticize, even if constructively.
That's nice. I hope they make it to stable soon, but they still seem to be waiting for some features to be included in stable rust, so it will take a while.
Right, I don't think this is the end of the world. The cleanup may take a bit of time but let's not throw the baby out with the bathwater. Actix is a really nice lib, with fast benchmarks, the rust community should want it to succeed.
Right, had forgotten about black-box. Thanks.
&gt; `fn foo() -&gt; Bar` whether Bar impl's Future or not? No. I am suggesting a syntactical transformation.
&gt; it is not possible to immediately see the code which is compiled Macro output can be shown to users. There are compiler features to enable it. For compiler IR's, not everyone is able to read them. So I think the opposite is true. In general I disagree with you, macros should be the way to go if something is too tedious to type for you, or if you need some niche feature from the language. Macros can be developed much easier without affecting *every single user* of Rust, which might have different needs, depending on use case. As an example how macro flexibility helped me in the past, I was shadowing `try!` from the standard library years back well before we got failure or other backtrace supporting crates: I just replaced the return Err() with a panic and immediately got the place the error came from. With the `?` operator, this isn't possible.
&gt; part of the **emotional labor** of the RFC process is to recognizing such feelings as emerging from our personal experience I've noticed a lot of people using this sort of language in the last five years or so, but I don't think I remember much of it from before then. Is there a trend going on? (I got a lot of it from *Nonviolent Communication*, maybe others got it from similar books?) Or is it just a regular getting older thing?
I really don’t get people using unsafe so liberally. I made a basic rule to never write unsafe, with one exception FFI. So far, while annoying in some cases and slows me down to find a safe solution, I’ve not needed to break this rule.
I disagree. (*(*having).to.write).like.this is very annoying compared to -&gt;. That's a cheap example, but [I've complaint about unsafe ergonomics before](http://way-cooler.org/blog/2018/01/09/way-cooler-turns-two.html) 
Yeah, I don't want to downplay this issue at all; security is important. But at the same time I think this thread demonstrates how Rust operates on a whole other level when it comes to safety. Imagine asking &gt;How can people have confidence in the safety of crates they use? in many other programming languages. Having reasonable confidence in a crate after looking for and "auditing" unsafe blocks is a kind of luxury (although correct unsafe code doesn't necessarily protect you from unsafety). (And also please check everything for a real audit.)
\&gt; The output is a Future and jou have to do something with it (run it on an executor or poll it yourself) before you get a T as output. I wonder if some of the split between innies and outies is because they envisage different ways of working with futures. If you think that you're going to take the resulting future and deal with it as a future, by putting in a list of other futures, applying combinators, passing it to an executor, etc, then having the async function clearly return a future makes sense. If you think that you're going to immediately apply `await` to the resulting future, then it matters a lot less that it's a future at all. Rather, you are thinking in terms of '[colours](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)' of functions: you just want to make sure that you always put an await on a call to an async function, and never put one on a call to a non-async function. I wonder if it's also related to how much you anticipate using, or seeing, async/await. If it's something that will exist in corners of your codebase that you will come across occasionally, then you're willing to tolerate some verbosity in order to be able to quickly see exactly what it does, and so the outer return type is right for you. If you think your codebase will be shot through with async/await like veining in a Valdeón, you're willing to expend the mental effort to see implied futures in order to have less code to type and scan. 
I acknowledge the flexibility, however I'd note it's a double-edged sword. I've worked in a code-base (C) where `new` and `delete` were prohibited and special macros had to be used instead for allocating/deallocating memory (*sigh*). Newcomers had to unlearn the standard way, and learn the codebase specific way (and its quirks). And then C++11 came out and the macros were not compatible with Modern C++ practices and had to go. Flexibility has a cost: it encourages custom practices. In the end, I like it for experimentation... but I don't think it scales well.
This isn’t how abstract types work. Writing that code would imply that all future have the *exact same* (unnamed) type, which is necessarily untrue.
Ahh, Do you have a reference for that being deprecated? I was trying to figure that out myself since i had the same feeling. In my post I linked to a [github issue which asks to deprecate it](https://github.com/diesel-rs/diesel/issues/1431#issuecomment-353724484). 
He doesn’t sound dismissive to me. It sounds like he’s trying to fully grok the implications of some of his choices. People make mistakes...
 A purely parser based / syntactical transformation would mean that `impl core::Future` would wrap the thing twice. Similarly things would go wrong if some item `Future` shadows the core future. You'd need to make that transformation at least after name resolution for it to make sense... otherwise `Future` effectively becomes a contextual keyword.
How about `sync fn foo() -&gt; async i32`? Where `async T` is basically shorthand for `Future&lt;Output = T&gt;`. It's more verbose than the proposed inner syntax, but less verbose than the proposed outer syntax.
I'm not sure about this. JavaScript has 'inner return type' async/await, and this works quite nicely with using the return value of a function as a promise. I think it's a tradeoff between code being clearer because it's more explicit, or clearer because it's more concise / less noisy.
Just replace second `Thing` with `Anything`. Nothing chages. Without fat arrow the syntax is ambiguous.
&gt; Very few people are experts at Rust at this point and knowing how and when to use/not use unsafe is an advanced skill, so we shouldn't be too quick to criticize, even if constructively. I very strongly disagree with this. If you told me I was only allowed to criticize (constructively of course) one thing in Rust code, the *one thing* I would pick is misuse of `unsafe`. `unsafe` makes up at least part of Rust's core value proposition, and if we bungle that up in a widely used and widely praised crate, then that doesn't just reflect poorly on the crate itself, but it reflects poorly on all of us and diminishes Rust's value itself. I cannot stress how important it is that we do not let this kind of misuse of `unsafe` propagate through the ecosystem.
Well, maybe not abstract types exactly then, but some kind of return signature alias, which will allow us to use `AFuture&lt;u32&gt;` instead of `impl Future&lt;Output = u32&gt; + 'input` without giving up optional explicitness and without introducing two separate behaviors for `async fn`.
To be fair Rust's syntax for working with raw pointers is not great. I get that its nice to have safe code be the more ergonomic choice, but it does make unsafe code harder to read.
Sure, but that is just one factor out of thousands. Maybe in your code that is coming up a lot, in the code I am working on it is a very small portion, and instead I am enjoying tuples and ifs as expressions, short for loops, useful attributes, easy packaging and easy doc comments and so on. But you are right there is room for improvement. I am using "get_unchecked" and "get_unchecked_mut" a bit and its naaaastay. 
&gt; Flexibility has a cost: it encourages custom practices. Yeah but if your language is on the other extreme, being overly generous with features, like e.g. C++, you end up with dialects as well, where everyone writes in their own dialect of language features they know.
If you're re-starting *the whole program* a bunch of times, then your timing includes boring process startup overhead, but in the case of `rayon` you will also pay for thread startup every time. This is a worst case -- in more typical use, you'd have the threadpool waiting around for multiple uses throughout the life of a process.
Hmm... interesting points. What about a short macro to syntactically wrap the return type for the simple case? Would that be possible? async fn foo() -&gt; Fut!(i32) { ... }
Yes I completely agree, async blocks is the most important feature and the rest can be seen as syntactic sugar. It is always better to start with the verbose option and to wait for a bit to see how it's used in practice. After that you can always add on more suger if its needed.
The raw pointer methods stabilized in 1.26 will help going forward https://github.com/rust-lang/rust/blob/stable/RELEASES.md#stabilized-apis-1
I'm wrapping a complicated C library (wlroots) so yes my use case is a little different. But there is a lot of C wrappers and we should be making it easier to write IMHO. 
Transmuting an &amp; to &amp;mut is UB - Transmuting an &amp; to &amp;mut is always UB - No you can't do it - No you're not special from https://doc.rust-lang.org/nomicon/transmutes.html
&gt; [do you think I don’t understand impl Send? :)](https://github.com/actix/actix-web/issues/301#issuecomment-396426085) ^ This is not an acceptable response to someone pointing out a memory safety vulnerability in your unsafe use of Send.
Most importantly Rocket is not asynchronous.
Transmuting an &amp; to &amp;mut is UB - Transmuting an &amp; to &amp;mut is always UB - No you can't do it - No you're not special from https://doc.rust-lang.org/nomicon/transmutes.html
&gt; Yeah but if your language is on the other extreme, being overly generous with features True. I think the key is to provide generic/orthogonal features which let the user create the necessary abstractions. At the same time, there are features that I cannot see easily emulated by libraries. `match` (and pattern-matching) is such an example; matching on `std::variant` is not as ergonomic because it requires lambdas, meaning that you cannot use `continue`/`break`/`return` to affect the control flow of the enclosing function. (I think one of the issues of C++ is that its development by committee encourages solving paper-cuts and symptoms with short-term fixes rather than addressing the root causes with long-term ones; this results in a plethora of niche features which are only interesting in a handful of edge-cases and greatly contributes to inflating the language)
It's a term that I've seen in psychology and sociology circles for quite a while. I think it's mostly an academic term about social dynamics that people have found useful.
I have to say, I'm really impressed with aturon's ability to think about hese issues and then write coherent blog posts about them. I think a lot of software developers are like me, in that they find the writing process really frustrating and often end up giving up before something's finished.
The raw pointer methods stabilized in 1.26 will help going forward https://github.com/rust-lang/rust/blob/stable/RELEASES.md#stabilized-apis-1
Agreed. The first rule of unsafe is "Don't use unsafe".
The library is getting a lot of attention lately. It’s hard not to become defensive when your code is being combed through by a very safety focused community. I agree that was a poor choice, but let’s try and be supportive is all I’m suggesting.
Disclaimer: I'm still working on this, but this looks pretty promising. The shared runners on gitlab.com are kind of flaky in terms of consistency in the benchmarks, but I only seem to get very few false positives!
I haven't followed things close enough to provide an explicit example, but maybe this will prompt someone else: What if I want to return a Trait impl that inherits from `Future`? I.e., `trait DifferentFuture : Future { ... } async fn myfunc() -&gt; impl DifferentFuture&lt;Output=i32&gt; { ... }`
The second rule should be if you do, explain why in a docstring. The compiler should warn that there is no docstring and you should explain why.
I switched from German to English layout a few years ago. The first couple of days, my backspace saw some heavy use. The next couple of days, it took about an hour of "warming up" everyday until I actually typed what I wanted. After that, I never looked back. I actually have some trouble finding the right key on a German layout now. Unexpected bonus: I get to chuckle at my coworkers when they try to type something at my workstation.
Yes the compiler should warn that a unsafe block has no docstring and that you should explain why unsafe is needed. Then in the docs have a unsafe section why all the explanations (and put that in cargo.io)
If I understand the situation, macros might be a solution, as they work in types. This compiles today: macro_rules! myret { () =&gt; { impl Clone } } fn foo() -&gt; myret!() { 23 }
The term was [coined in 1983](https://en.wikipedia.org/wiki/Emotional_labor#Definition:_emotional_labor_versus_emotion_work), and usage [has been growing steadily](https://books.google.com/ngrams/graph?content=emotional+labor&amp;year_start=1980&amp;year_end=2018&amp;corpus=15&amp;smoothing=1). However, it blew up in 2017, and in escaping the academic literature, [has been used much more sloppily](http://www.slate.com/blogs/better_life_lab/2017/10/20/please_stop_calling_everything_that_frustrates_you_emotional_labor_instead.html). Originally, it specifically meant the effort involved in presenting particular emotions, that you might not actually feel naturally, as part of your job - imagine a teacher being enthusiastic, a shop worker being friendly, or an emergency dispatcher being calm. Nowadays, it means something like any kind of emotional effort you expend on behalf of someone other than yourself. 
But there are cases apart from FFI when there is no safe solution. E.g. self-referential structs that Rust doesn't support out of the box. I think there is always exception to a rule. Though I agree that you should try keep these exceptions to a minimum.
.libs don't need to expose internal source code - in fact with Visual Studio, they by default don't expose anything Rust can link with. As far as I know, I have to manually maintain a .def file for a static library I'm writing in C++ with extern C blocks for Rust to link against in Visual Studio. This means that like 99% of everything loaded into the lib is hidden from linkage. 
Yes, looks like this will work: macro_rules! future { ($tp:ty) =&gt; { impl Future&lt;Output = $tp&gt; + 'input } } async fn foo() -&gt; future!(u32) { .. } Though, signature now looks a bit peculiar. I think `type` with `impl Trait` would be better, though I am not sure about implications.
there have been several articles about switching away from Rocket because of how often their web apps were breaking as nightly versions change. I definitely don't recommend them. Rouille is nice for projects that aren't hugely concerned about performance.
I think they are/were waiting for async support in rust, and a pull request for that was just opened a few days ago: https://github.com/rust-lang/rust/pull/51580
Reference counting isn't free (especially atomic reference counting) and grabbing an Rc when you weren't expecting to can even sometimes cause memory leaks; so where I use Rc, I usually try to avoid cloning it in favor of taking references into its interior. I actually consider the ability to know when you are touching the refcount to be a major *advantage* of refcounting in Rust. Of course, in today's Rust someone could already make a refcount be implicitly bumped by doing it inside a Deref or something, so I'm not *totally* opposed to the existence of some sort of "autoclone" trait on the basis that you can already do things like that implicitly in other places in Rust, but I wouldn't want it applied to pretty much any types that I worked with. Actually I'm not sure if there are any types I'd want to auto clone. It would be interesting to see whether attribute macros could automatically insert the clones on a function by function basis instead, since I think usually the cases where people want something like this are ones where they have a module or a function that uses Rc pervasively and it just becomes noise.
Yes. Self-referential struct are something I wish the language supported directly. Pins might make this easier, but I haven’t played with them yet to understand their limitations. Also, I haven’t built many data structures in Rust, yet?, and I know that they may need unsafe. But maybe not? I like the arena and approach as a workaround to some of the common data structure issues.
I don't really see how the inner return type approach is "more ergonomic" except in that it's less typing. The way I parse `async fn foo() -&gt; T`, it overloads the function arrow `-&gt;`, in that I have to remember that `foo()` does *not* return a `T` in this case, though with just `fn foo() -&gt; T` it *does* — which is to say that the "`async` as modifier" reading in the post is not one that comes naturally to me; I parse "async fn" as a unit, and would like to be able to look to the right of the arrow to see what it returns. The inexplicitness is a loss to ergonomics just as much as the reduction in typing is a gain. 
I don't think any sort of counting can help. Think about that: it can be a primitive unsafe one-liner, but it may be widely used throughout a whole application. E.g. transmuting lifetime - you just can't tell automatically if it is correct thing to do, you need to analyze it manually.
sorry to open this again, but I am also a Rust noob and I am wondering what would apply in my case. I implemented a vec3 struct, which should do basic vector math. Now i want to create a method .unit() that returns the unit vector. What is the difference between these 2 possible implementations? fn unit(self){self/self.length()} vs. fn unit(&amp;self){\*self/self.length()} Does the first one consume the original vector?
Fair enough. I do somewhat live in dread of the time when a serious memory error in a widely-used Rust crate leads to some kind of exploit - it is inevitable at some point. But, looking at the comments on the issue, it seems that the maintainer has not internalized your point-of-view (which I share) that memory safety is more important that speed, elegance and everything else. Or possibly, is just not aware that some of the uses of unsafe, such as those which you identified above, are essentially straight-up forbidden by Rust's semantics. And I can't really blame him for that, because the community has not settled on a strong set of norms surrounding `unsafe`. Often the guideline just seems to be "never use unsafe", but if you can't get Rust to do want you want without it, then what? It's easy to fall back to transmuting `&amp;` to `&amp;mut` and it mostly works, until it doesn't. So I'm really just saying go easy, this stuff is pretty hard and not widely understood. But yeah. Needs fixing.
The tracking issue for Rocket on stable is here: https://github.com/SergioBenitez/Rocket/issues/19 It's not so much that they're "thinking about stabilizing," but that Rocket prioritizes ergonomics. The developers believe that the language features in that list allow for beautiful code. Eventually those features or something like them will move to stable, and then Rocket too will work on stable. Same story with async.
Looks like a neat little language! I just installed the repl and I'm gonna play around with it.
I think it's a very good idea to wait a little to be able to provide a more ergonomic api. With rust being such a new language, some libraries are a little rushed, but i really think, that in the future, rocket will become a fantastic web server.
I've already written at length about why I disagree with this argument: https://internals.rust-lang.org/t/pre-pre-rfc-async-methods-bounding-async-fns/7656/94?u=withoutboats
If you use the `Iterator` methods, it's also a lot easier to transition to rayon `ParallelIterator` instead, as the API is mostly mirrored.
Why compare them? One is async HTTP library with performance focus. Another is more like a framework, that most likely will use some sort of HTTP backend in the end, they all do. I'm pretty sure I saw there people suggesting to use hyper or actix-web as one.
Yes, actix has huge promise. If he or someone else can tighten up all the unsafe usage, then everyone will be happy. Otherwise there's a gap in the ecosystem for a new actor crate with tighter safety guarantees.
Still hacking away at a data sketches library. I worked on probabilistic counting on the train and got PCSA (Flajolet-Martin) working. I'm hoping to tackle LogLog and HyperLogLog this weekend. I'm also getting more familiar with Rust modules so I can partition the project appropriately.
\+1 There are multiple important components to a successful library: performance, usability and safety (maybe more?). If there is a problem with just one of them: fix it. That may be much easier than fixing a safe library that has problems in multiple areas.
He is actively making commits for these issues and taking PRs.
There's also always [trait aliases](https://github.com/rust-lang/rfcs/blob/master/text/1733-trait-alias.md) but they aren't implemented yet.
Right after that he said: "Thanks. I will check again if I can implement it without unsafty. I am not sure it can be fixed though". After that he fixed the issue. Keep reading.
I can’t disagree with this perspective enough. I don’t understand it at all. Rust is an amazing language, and we should not limit the domains it works in at all. It’s fair for you to say that you don’t foresee using it for web backends because you prefer something else, but I think Rocket is showing the potential power of Rust (when it stabilizes) in this space. I want to replace all my java backends with Rust, I just need to convince the people on my teams of this as well.
I've dabbled with extending lua myself in the past, too. It's a cool idea, and coupled with LuaJIT could deliver excellent performance while retaining some of the ergonomics of statically typed languages. Alas, not what I'm looking for. Being a beta tester for S&amp;box is enough for me anyway :)
This comment leaves a really bad taste. Must be horrible to have strangers pick over comments you have made, devoid of context, possibly offhand, possibly in jest, possibly just when you were in a grumpy mood, in a setting which feels sort-of private but actually is open to the entire world.
JavaScript doesn't have types in its function signatures, so it has neither the inner nor the outer return type approach! Are you thinking of the syntax within the function body? 
Thanks, it's made me more courageous to try write larger systems with Rust
The point was, he closed the issue, despite there being a huge number of other `unsafe` issues mentioned in this Reddit thread. At this point, I think the only sensible thing is to do full audit of each `unsafe` block in `actix` and either: A) Replacing such `unsafe` block with safe block B) Adding a comment that proves why `unsafe` needed to be used.
The author of the [rustonomicon](https://doc.rust-lang.org/nightly/nomicon/) also wrote [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/README.html), which leaves an unsafe implementation only to the end. An example of collections on crates.io explaining unsafe features it exposes: intrusive-collections, which targets no-std and has a dedicated [safety section in its docs](https://docs.rs/intrusive-collections/0.7.2/intrusive_collections/).
I see. Definitely a valid point. I understand that restricting access to APIs in Java was very hard architecturally and removing them entirely was either impossible or undesired. The code was still there, just 'hidden', and the reflection facilities provided ample opportunity to use them. However, I feel like this isn't a wholly fair comparison. Rust, by design, just like JavaScript, Java or C#, is memory safe, and any insecurities (without unsafe) arise as a result of rustc or llvm bugs. Conceptually, this isn't much different than having an insecurity or a bug in your JIT-compiler for any kind of language. If your JIT compiler somehow produces a violation of the language contract and through a bug allows random memory access, this is no different from the situation in Rust. The only difference, of course, that JIT compilers produce native code while loading the program, and rustc does it before. As I mentioned in the other posts, I'm not looking for a new fancy scripting languages, there are plenty of choices for that and that isn't my goal. I'm doing research into how Rust would fare in this use case. At any rate, thank you very much for your insight.
My point is slightly different, do not use Rust because “it is awesome and I love it”, use Rust when it solves problems you have. For me, in most cases, Rust will be great overkill, because it will introduce more problems (building application, deployment, error reporting) than solutions. However there are situations when using Rust is ok or even desirable, ex. writing load balancers (because there you need raw speed and as little overhead as possible) or log dispatchers/metric gatherers(because you want them to use as little resources as possible to leave rest for your application). In other words: use technology you need, not one you want. Otherwise there will be problems and pains. It is not about limiting domains it is used in, it is about picking right tool for the right job.
In my head, the async function kind of "returns" a `T` in the sense that async fn foo() -&gt; T means that in the example let x = await foo(); // did I get the proposed await syntax right? `x` is of type `T`. Since that's helpfully going to be the most common way `foo` shows up in practice, the relationship feels good to me.
I very much like this idea. I'd really like to see the RFC broken up into async blocks, which are important functionality, and the inner return type sugar, which is... sugar. I think I'm still in favour of the sugar, but I'm against the idea of including it as part of the same RFC as the functionality since it's completely orthogonal
It's a quick metric for doing a preliminary overview, not a replacement for doing proper auditing. Taking a look at the output of cargo-osha posted elsewhere in the thread, there are 1025 unsafe expressions in actix-web, out of a total of 37602. That tells me that there's a pretty large auditing job to do, just to determine what invariants need to apply for those 1025 unsafe expressions to be valid, let alone auditing any of the code within privacy boundaries that the unsafe code relies on to uphold those invariants. If a crate has two or three unsafe expressions, that tells me that it could be relatively quick to audit those expressions, figure out the invariants they rely on, and then audit everything in the code base that could impact those invariants; for instance, if it relies on invariants about length and capacity, then from there you just have to audit things that touch length and capacity. Or in some cases, the unsafe code doesn't really depend on any other invariants, and can be audited in isolation. On the other hand, if you have 1025 unsafe expressions, that's a huge job to audit all of those plus everything that could impact whether those are actually valid or not.
I sort of want to agree, but `unsafe` exists for good reason, and we can come up with some less facetious rules that are more useful, such as: 1. Unsafe code is any code in a module that contains an `unsafe` block. Keep modules that contain `unsafe` blocks as small as feasible in order to reduce the scope of unsafety. 2. Functions that are not marked with `unsafe` but that use `unsafe` blocks internally must, for every possible value of every possible combination of input parameters, be 100% incapable of causing memory unsafety. If there exist any inputs to a safe function that cause memory unsafety, that function is not valid Rust. 3. Don't modify any unsafe code (see the first rule) if you haven't read the Rustonomicon. 4. Don't add any new unsafe code without first making a reasonable effort to achieve your result safely. Unsafe code isn't magical pixie dust that will make your program faster, and it can even make your program slower; profile first. 5. Document every unsafe block with a comment describing the invariants that the surrounding module needs to uphold in order to maintain the validity of the unsafe code.
I think that actix web and rocket can be used in similar roles.
Number of lines of code inside the unsafe blocks themselves isn't a useful estimate. An unsafe block represents an invariant that the type system cannot enforce. The way to contain the scope of the aforementioned invariant is via the module system, i.e. privacy. If there's any useful metric of unsafety that can be had by counting lines of code, it would be "number of lines of code in modules that contain unsafe blocks".
Agreed. The notion that a core value proposition of Rust (speed *without* sacrificing safety) can be cast aside out of convenience is exactly what is so troubling. There are strictures in the compiler that can make things very difficult (or impossible) without `unsafe`; that is not the point of this critique. The sacrifice of safety for the sake of expediency at all costs is very concerning, especially without demonstrating the appropriate care in these choices. 
If I recall correctly, all of the missing features are high-priority, with the intent on making the 2018 epoch. 
Nifty idea, thanks for working on this. One suggestion: implement the cargo/semver version resolution. E.g., if I have `walkdir = "2.1"`, don't suggest `2.1.4` (or say I'm not using the latest version), as they're the same.
:) [Let me know](https://gitter.im/gluon-lang/gluon) if you run into trouble!
&gt; The point was, he closed the issue, despite there being a huge number of other unsafe issues mentioned in this Reddit thread. He's the maintainer and can do whatever he wants. He's tracking `unsafe` stuff with other issues. People are free to open issues for other uses of `unsafe` and send PRs. He is actively pursuing option A. If people want to help with A or B then they can submit PRs. As he says here: https://github.com/actix/actix-web/issues/289#issuecomment-397897695 "fixed most of the problems. let's open new ticket for each new case."
Hi there, it looks like this post got caught in the spam filter, likely because of how new your account is. Would you mind submitting this once more and then messaging me to make sure that it doesn't get caught in the spam filter again?
Hi there, it looks like this post got caught in the spam filter, likely because of how new your account is. Would you mind submitting this once more and then messaging me to make sure that it doesn't get caught in the spam filter again?
Oh, I agree. It must feel bad, however it's bad for a reason. People trusted that whoever wrote `actix` was a capable Rust programmer (his library was excellent at latest web benchmarks), not someone that does some hack job and writes [`transmute &amp; to &amp;mut`](https://github.com/actix/actix-web/blob/285c73e95ea4a011673bcd4f84a26d2aee84e592/src/server/helpers.rs#L82)
"Are We Reasonably Safe Yet?". Sounds like the idea is quantifying the community belief in the safety of a given library. 
[CHANGELOG entry](https://github.com/diesel-rs/diesel/blob/3d18dcb2edadc1bb1e9a93ad6b12930c3afeed20/CHANGELOG.md#deprecated) [Deprecation message you should receive if you try to use it](https://github.com/diesel-rs/diesel/blob/1.3.x/diesel_infer_schema/src/lib.rs#L17)
Sure. Note that I've specifically avoided speculating on the maintainer's state of mind. These things aren't knowable. I hate it when people do it to me, so I do my best not to do it to others, because I realize how much it sucks. What I am trying to do is confront reality. The reality is that we have a very popular project that has completely flouted one of Rust's core value propositions. We can't abide that.
How do guards work without `=&gt;`? Sorry, am on mobile so can’t do a pretty example right now. 
There is no option a, both are part of same thing - Audit your usage of unsafe. Say I want to use actix but want to wait until all `unsafe`s are fixed -how do I track it?
&gt; until these issues are resolved I would be more concerned about the author's attitude towards unsafe. Resolving any specific issue is not going to fix the systematic problem unless the author adopts a new policy towards usage of `unsafe`.
At least it's not just me. It's also possible there's some subtle unsafety I'm being protected from. I've been trying to get good at lifetimes and this was an educational challenge even though I can't find a solution. I think I can work around it at a acceptably small cost to ergonomics and performance, but this seems like it should be doable. Alternately I could unsafe in a new lifetime, but I don't want to do that unless I can fully understand what's going on.
Yes, and yes.
Looking forward to it then!
[removed]
It's not harder to do it correctly than in C/C++, and when you've done it, you can generalize it and publish it as a crate so that others can use it easily.
I think all the lifetime bounds are needed. HasAccessor needs a lifetime for the accessor method to allow Accessor to borrow. Coordinator needs to name that same lifetime since it owns a HasAccessor. Monitor own's a Coordinator and needs that same lifetime, which it looks like I mislabeled 'c instead of 'a
Why don't the whole lot of you get off your soap boxes and help clear up the unsafe blocks?
You’re looking for /r/playrust
You might find [this article](https://bheisler.github.io/post/benchmarking-in-the-cloud/) interesting.
The application should handle malformed UTF-8 before the stuff gets converted to &amp;str (untrusted data, eg. from the network, usually to you as &amp;\[u8\]). After you have a &amp;str, you're already in the code path that checked the string isn't malformed.
It's number of expressions, not number of lines of code. But yes, it's still a shitty metric. But it's better than no metric. The purpose of `unsafe` in general is to say "this thing is hard to programmatically reason about", so getting more specific than that is, well, hard. I'm not going try to write a program that can go deeper than that right now. :-) The idea of counting `unsafe` code that escapes the current module, one way or another, is an interesting one. That would take rather fancier parsing and analysis though.
a little redundancy in syntax is useful, e.g. catching typos/double checking intent, both to read and write, but in this case in the single-expression case it really clarifies things IMO. it's like a table of mappings - it seperates the cases and values more strongly in a world where everything is curly braces
As for an example why you shouldn't casually use `unsafe`. I once made a crate called `array-macro` which allows you to write code like `array![String::from("Hello, world!"); 4]`, which is sorta like `vec!`, except it creates an array. The code looks like this: https://gitlab.com/KonradBorowski/array-macro/blob/master/src/lib.rs Very complex, right? Well, here is a thing, if it was any simpler, than it would have not-so-obvious memory unsafety. Like, it would work most of the time, but then panic, and things would go bad real fast. It's very easy to write unsafe code that appears to work most of the time, but causes very confusing to debug undefined behaviour sometimes. I would love to have this without `unsafe`, but unfortunately I don't think there is a way. In fact, this used to not use `unsafe` at some point, but [it was abusing a bug in a compiler which is now fixed](https://github.com/rust-lang/rust/issues/46478).
Yes, that's cool! I indeed notice a lot of noise; if you look in that screenshot, those 26 fails are pure noise... because it runs the exact same code and I only have like 30 benchmarks. The plan is though to have a "dedicated" benchmark server at some point, or at least a static VM with a few dedicated cores and RAM.
&gt; The idea of counting unsafe code that escapes the current module, one way or another, is an interesting one. That would take rather fancier parsing and analysis though. Not sure what you're proposing to measure here, to me it seems like measuring "unsafe code that escapes the current module" should be as easy as seeing how many items are marked `pub unsafe`.
I agree, but you also need a leader who admits that the cleanup is necessary and is willing to shepherd it, instead of continuing to push it under the rug. I also don't see how using `unsafe` makes the process of coding faster.
Interestingly, TypeScript requires you to use the outer type, with the outer type being some type with a Promise compatible constructor defined for it. Coming from having done a lot of async/await in both C# and TypeScript, I can see how returning the inner type, but having to specify the outer type as the return type can be confusing at first, but after a while it starts to make sense. Especially when you frame it in the context of other features, like generators. The real advantage for me is I can quickly glance at a function signature, regardless of it being an async function or a function that just returns a future and know that I can await the result of that function based on the fact it returns a future. I don't have to look at the async in the function signature to infer this information, I can just look at the same part of the function signature in both cases. To me the async portion of the function signature is more of an indicator of what I can expect to be able to do inside the code for the function, that being the ability to await other futures and to return the inner type, knowing it'll be wrapped in a future.
Yeah, it can be a valid indicator of course. 
I was thinking that you would also have to look at how often those items are actually called. A `pub unsafe` function called once obviously has fewer places it can go wrong than one called a thousand times in different places across the codebase. Of course, those invocations also have to be `unsafe` by nature, so you'd want to count things without double-counting them... idk. I like the way /u/annodomini thinks of it actually: not a metric of quality, but as a tool to guide auditing.
Not sure if I didn't fuck something up, but now it compiles. http://play.integer32.com/?gist=d4fdd024c985ff6b8536d442cd1bc727&amp;version=stable&amp;mode=debug
There was an RFC for adding an attribute, together with special lints for rejecting not attributed `unsafe`. That attribute would've been `#[reason = "doc..."] unsafe { ... }`, used to explain *why* the unsafe code might be fine.
They can. Doesn't mean they should. You may ignore me, I have a prejustice for web frameworks that didn't take async path.
&gt; If there exist any inputs to a safe function that cause memory unsafety, that function is not valid Rust. Adding to that, you should handle intentionally malicious input. The `Ord` implementation may be inconsistent or panic, `ExactSizeIterator` may return invalid iterator length, `FusedIterator` may not be actually fused, `Clone` may return a completely different object and so on. Only unsafe traits, `Copy` (as long you don't call `clone` method from supertrait `Clone`) and `Sized` can be trusted to be correct. If you call anything user defined, make sure to prepare every possibility, including panicking. It's fine to abort, leak memory or return wrong result when an input is malicious like that, but undefined behaviour is not allowed.
The most important metric is how many modules has unsafe blocks and how many lines those modules have (including safe rust lines). If a module has an unsafe block with a single line, then the whole module needs to be audited (because this unsafe line might be relying on safe code from the module). Module boundary privacy is the only thing that limits the scope of auditing. [https://doc.rust-lang.org/nomicon/working-with-unsafe.html](https://doc.rust-lang.org/nomicon/working-with-unsafe.html)
How should I think about the semantics of \`expect("Not a number!")\` in something like the following? let guess: u32 = "42".parse().expect("Not a number!"); That is, as a beginner, I'm having a hard time remembering that \`expect("Not a number!")\` returns a \`Result\` that either wraps the value in \`Ok()\` or wraps the error message in \`Err()\`. But where does the name \`expect()\` come from?
Wait so are back to being Rocket the best choice?
How exciting! How exciting!
Agreed +1
I mean, it isn't single threaded either. Does the difference between multi-threaded and asynchronous request handling matter much for most use cases of an HTTP webserver?
&gt; (*(*having).to.write) how much C have you written? cuz it would have been like (*(*having)-&gt;to-&gt;write) lol
Or "remove"
But they are planning to take the async path, they are just waiting for async/await syntax in rust. Which is coming to nightly.
Note: I’m not the author, just posting it here because I think it’s a cool project! 👍
I know a guy who is special!
FYI the actix main core has bad unsafe as well. https://github.com/actix/actix/search?q=unsafe&amp;unscoped_q=unsafe &gt; let ctx: &amp;mut Context&lt;A&gt; = unsafe { &amp;mut *(self as *mut _) }; 
Time for some hooking and shared memory shenanigans! :D
&gt; 1) I wanna write a function that takes a trait fn something&lt;F: Foo&gt;(writable: F) There you go. These days you can also do fn something(writable: impl Foo) But I personally think that this particular syntactic sugar will rot the teeth. Your other two examples, fn Something(writable: &amp;Foo) fn Something(writable: &amp;mut Foo) should just work. So I wonder where your complaints come from because it looks like the situation is almost exactly as you request. &gt; 2) let me borrow stuff, its very unintuitive that some code works but when you move it to a new method to make it better it does not compile. func get_y(&amp;mut self) -&gt; &amp;mut f32 { &amp;mut self.y } I have no idea what you're talking about. When you replace 'func' with 'fn' that function compiles and does exactly what you want. &gt; 3) make self ref structs work, think of something thats safe but limiting(like you can only mutate the reference inside the tree and not to outside the tree references), I just wanna write a tree like structure not fight Zeus. &gt; &gt; do some compiler in the back checks, add some stuff to the language or something just make it work without unsafe and without runtime checks, I know its a hard problem but I'm sure there is a reasonable solution. Self references don't work when you move things around. They don't play nice with mutability. There are very good reasons why self referencing structs are hard. If you want easy trees, either use indices instead of pointers, or use a garbage collected language. You claim to know it's a hard problem, but your solution is "just do something in the compiler". To me that indicates that you do not understand it. &gt; let me impl Display on trait, not a trait Foo : Display or other voodoo, I just want a default display method on my trait, agree on something and let the users learn the default behaviour instead of writing stuff like Rust wants to avoid duplicate trait implementations, so you can't implement traits for other traits, just not traits that are defined in another trait. &gt; make generators easy, I just wanna write (I'm not yet sure how this is going to unroll) fn foo() -&gt; i32 { yield 1; yield 2; yield 3; } for i in foo() { println!("hey {}", i) } I think there are RFCs floating around for this kind of stuff.
This not transmuting right? I uses `as *const T as *mut T` which should not introduce undefined behavior.
`func get_y(&amp;mut self) -&gt; &amp;mut f32 {` `&amp;mut self.y` `}` NOTE: Allowing this would violate the no mutable aliasing rule. It would be unsound and would break fundamental underpinnings of Rust. What you are saying here is that you are going to return a mutable reference to the memory location pointed to by self.y. But, the caller has a mutable reference to self itself. Therefore, you now have 2 mutable references (aliases) to y. This has to be forbidden; otherwise, all the guarantees of Rust "Safety" break down like a house of cards. I think of the Rust way as, "Safety First, Ease of use Always".
The language specifies a syntax for translating text into a well-defined program. Are you asking for changes to the meaning of the program, or to the syntax for the text of programs written in the language? It's not enough for you to say "make this code work". You have to specify the *meaning* of your code, and then specify the syntax that you want to write code in, so that it translates to the meaning that you have specified. Let's look at your first example: trait Foo { } fn Something(writable: Foo) { } What does this code *mean*? What do you want it to mean? Foo is *trait*. It is not a sized object. You cannot pass an object to a method when the size of the object is unknown. This is a *semantic* error, not a syntax error. You need to specify what *meaning* this code has, because right now, it is meaningless. This is why the compiler objects to it. The compiler isn't just a nitpicker, where it accepts some programs but rejects other programs whose meaning should be obvious. In this case, your code is *meaningless*. &gt; And thats all, I dont care about all the other things You have to care, to write a meaningful program. Now your second example: func get_y(&amp;mut self) -&gt; &amp;mut f32 { &amp;mut self.y } I've rewritten it to specify the parts that you omitted: struct Foo { y: f32, } impl Foo { fn get_y(&amp;mut self) -&gt; &amp;mut f32 { &amp;mut self.y } } This code compilers and does exactly what is expected. What is the problem you're experiencing? &gt; 3.make self ref structs work, think of something thats safe but limiting Specify the semantics you want, and at least make a suggestion about the syntax you want. As it stands, this request is too vague. &gt; let me impl Display on trait, not a trait Foo : Display or other voodoo, I just want a default display method on my trait, agree on something and let the users learn the default behaviour What would the "default" Display impl be for an arbitrary trait? Specify the behavior you want. &gt; I think the sentence 'writing stuff the Rust way' is bad, I wanna write stuff the intuitive/readable way. "Intuition" is just another word for "experience". Your "intuition" comes from existing languages. Rust is not the same as existing languages. Learning idiomatic Rust seems not just necessary, but desirable. After all, if you don't want to learn how to do things in a new (and possibly better) way, then what's the point of learning a new language? &gt; Its the compiler job to make our life easier not the other way around. Then tell us what is difficult, and how you would like it to be better. I'm not dismissing your objections, but asking for *concrete* details on what your objections are. Saying "this should just work" is not sufficient. &gt; make generators easy, I just wanna write (I'm not yet sure how this is going to unroll) fn foo() -&gt; i32 { yield 1; yield 2; yield 3; } for i in foo() { println!("hey {}", i) } Good, that's a concrete suggestion. There's plenty of evidence from other languages that this is a desirable feature to have. Maybe someone who understands the language much better than I do could offer some perspective here. However, for my own perspective, I don't think this is a higher priority than the other things going on in development of the language. You could write this using threads, send/recv queues, etc., so that the "yield x;" call becomes "channel.Send(x)". 
The `parse` function returns the `Result`, `expect` takes the Result and either returns the value in the `Ok` variant or panics with the given message.
What if only the `async` version of the fn did the return-type transform? So you could write either `fn foo() -&gt; impl Future&lt;Output = i32&gt;` or `async fn foo() -&gt; i32` 
&gt; results in very slow code You might be surprised how small the penalty is for fully-checked arithmetic. The checks can be turned on in release code, and I've measured the impact. For many substantial programs, the cost is negligible. There's always the possibility of the cost showing up in some hot loop, but I always rely on the profiler to point me in the right direction, and then I can change the loop if necessary to reduce or eliminate the cost of checked arithmetic. 
Ok, yes, `expect()` does not return a `Result`, but why is it called `expect()`?
That's not what that says. If you try this on the [playground](http://play.rust-lang.org/?gist=44e5f6e3f8c8a68943859171e56a2f29&amp;version=stable&amp;mode=debug), you'll see that it actually compiles fine and does what it should: struct Test { y: f32 } impl Test { fn get_y(&amp;mut self) -&gt; &amp;mut f32 { &amp;mut self.y } } fn main() { let mut test = Test { y: 100.0 }; let y = test.get_y(); println!("y: {:?}", y); } //output: y: 100.0 If you try to use `test` while `y` is in scope, you'll see that you can't. Which means that this part of your explanation &gt; ou now have 2 mutable references (aliases) to y is incorrect.
You might enjoy F# or OCaml, which have similar ML syntax and features but with garbage collection, so you can do your self referential structs whenever you want.
You can use actix-web just fine with synchronous code as well (I just ported a medium-sized web application from Rocket to actix-web). You just return `Result` from your handlers instead of `Future`. 
&gt;return wrong result (although wrong still means a valid value for a given type) Is that right? Shouldn't it panic? Is it OK to return an incorrect result as opposed to Result&lt;Error&gt;, Option&lt;None&gt;, or Panic?
Still churning away at my [point process simulation library](https://crates.io/crates/point_process). Haven't committed any major changes lately, however :/
Sure, that's why Iike async approach - you can use both with it.
Because it expects the `Ok` value.
I think the RFC you're referring to is [#1910](https://github.com/rust-lang/rfcs/pull/1910), which was postponed.
&gt; `as *const T as *mut T` That's not the part that's UB. You need to show the full snippet: let r: &amp;HttpInnerMessage = self.0.as_ref().unwrap().as_ref(); unsafe { &amp;mut *(r as *const _ as *mut _) } This is taking a `&amp;T` and turning it into an `&amp;mut T`. _That's_ the part that's UB. It doesn't matter whether you do this via a literal `transmute` or a pointer cast. It's still UB. I would strongly encourage you to read https://doc.rust-lang.org/std/cell/struct.UnsafeCell.html very carefully. e.g., &gt; The `UnsafeCell&lt;T&gt;` type is the only legal way to obtain aliasable data that is considered mutable.
Scandalous! First I'd like to say I love you /u/fafhrd91 for all the work you contributed. Also I admit I'm a novice Rust user (and long time lurker since beta days). I think there's an aspect of unsafe programming that isn't well communicated - some people will claim that they can write safe programs in unsafe languages by being super careful and having years of experience (hello /.). While that's up for debate - maybe there are such experts, there however isn't any quick way for users to verify expertise of these programmers. Maybe you were very careful while writing the core of your program. No way for me to check that without tedious audit. But after a few years maybe your interests will shift and because you wouldn't want the project to die you will accept patches without diligently studying what impact they might bring in relation unsafe code littered in your project. With large projects often nobody has complete mental picture and after a while patches will be accepted if the code builds and don't break that much. In that world users can't trust unsafe code to be safe. And this is why I like and plan to switch to Rust, I can grep my libraries and if I see too much dubious unsafe code I would rather avoid it. Probably majority of Rust users are here for that - it's a language cross between C and Erlang that in addition to features advertised on front page also makes you sleep better at night. People expect code that can be made without unsafe constructs to no contain it, most would probably accept 20% performance hit, otherwise we'd be in C land. In short, only without unnecessary unsafe constructs can people rely that the code they now depend on will stay dependable in the future. 
Yes. You can have a 1000 connections serviced asynchronously by several threads, you can't realistically have 1000 threads do the same.
&gt; I know dynamic linking is going to require us to stabilize some things we'd rather not, such as internal memory layout We should just allow people to use specifically-standardized types, ABIs and binary representations (ala `#repr(C)`) when doing things across a potential shared-object boundary, with a guarantee that this will preserve compatability - and leave things as they are otherwise. This is the only solution that doesn't have people "paying for what they don't use". 
I figured it had to be something like that, but the name doesn't indicate that it expects `Ok`. Under that reasoning, it would make just as much sense if it expected `Err`, perhaps even more given that the only explicit argument is the panic message. If I read it in my head as `ok_or_panic()` instead of `expect()` will I run into any major problems?
&gt; If I read it in my head as `ok_or_panic()` instead of `expect()` will I run into any major problems? `ok_or_panic()` is how i read it too
&gt;knowing how and when to use/not use `unsafe` is an advanced skill Knowing how and when to use `unsafe` is an advanced skill, but knowing when *not to* absolutely shouldn't be; there's a simple rule: you don't type `unsafe` unless you know what you're doing. &gt;we shouldn't be too quick to criticize, even if constructively. Any current users should assume their web services have security vulnerabilities until this is resolved. It would be irresponsible not to talk about this.
I feel like people forget that actix is a library that has been basically developed and open-sourced for free. People are very welcome to fork, make PR to change, or to criticize *nicely*. Some of them just went full retard mode too far as if they were chasing heretics.
The problem I personally have with this is that `foo()` is not returning a `T`, instead `await foo()` is returning a `T`. If `foo` returns a `T` directly, why even have the `await` keyword?
\&gt; which should be absolutely unacceptable. Have you read the MIT licence agreement lately? [https://github.com/actix/actix-web/blob/master/LICENSE-MIT#L17-L25](https://github.com/actix/actix-web/blob/master/LICENSE-MIT#L17-L25)
I feel like I'm missing something really obvious, but the name `expect` just doesn't click for me. Glad I'm not the only one!
What I find interesting, as a meta-observation, is that this is helping establish a community norm and guidelines around `unsafe
[removed]
[removed]
&gt; "trying to return an `&amp;amp;str` from a `String` you constructed locally." Ugh, very much this. It took a while for it to click why this doesn't and can't work, no matter how many lifetimes you specify :P
Looks like the thing.
I realize now that this would be a weird thing because the interior of `myfunc` is still returning `i32` and can't really inform the compiler any details about making the `DifferentFuture` instance (maybe it must be `into()`able?). This bothers me and makes me like the explicit nature of the initialization pattern. Even then, the same thing as above applies to the `async` block in the initialization pattern. You'd have to either require a trivial transformation between `impl Future` and your subtrait or construct your subtrait yourself. `await` has a pretty clear contract - await on awaitable things, which are things which impl `Future` - but `async` declarations have a less clear contract in that it's purpose it to construct an awaitable, of which there are an infinite number. This is just covariance/contravariance, I suppose.
I wrote a reply here almost the same points [https://www.reddit.com/r/rust/comments/8sar4g/lets\_talk\_about\_rust/e0y6skz](https://www.reddit.com/r/rust/comments/8sar4g/lets_talk_about_rust/e0y6skz) about avoid duplicate trait implementations, it makes things kind of dirty, look at my example I prefer Rust to run the trait impl if nothing else specified, if type impl display it will use the type display, nothing fancy.
2. I thought I wont have to give full code but here is the issue, [https://github.com/rust-lang/rfcs/issues/1215](https://github.com/rust-lang/rfcs/issues/1215) I dont think that it should matter if you put your code in method or outside of it, if one of them complies the other should too. maybe kind of mark this function as code block and dont allow some actions on this method like taking reference to it or something, I don't really know all the problems as to why it shouldn't work as function so I cannot really propose something
Yes. It's supposed to protect you from legal liability, not responsibility in general.
Yes, sorry. In JavaScript if you return (for example) a string, the caller recieves a Promise of a string.
Maybe this is what Rust does too, but C# is also eager in the sense that when you call an async function it immediately starts executing until it hits its first "await" keyword, then it suspends and returns the Task representing the rest of the function. You could imagine it being fully lazy where it would suspend immediately. 
With any remotely complicated software I spend so much more time planning and debugging than I do writing that it doesn't matter very much.
+1 for outer return type. Also, rusts`async`/`await` syntax is very similar to c#, which also use outer return type (`async` functions must return `Task`, `Task&lt;T&gt;` or `void`)
Win+Space is also the built-in keyboard combination to change layouts on Windows.
I have my mac set to a PC layout, and it confuses the hell out of my workers too!
With that sort of syntax, I'd tweak it to `fn foo() -&gt; async i32`. No use having the `sync` keyword if the existence of `async` in the return type lets you know.
Someone can damage your computer without using unsafe, if this is an issue for you you should pin a specific version in cargo.toml.
These could even be generated from comments above the unsafe.
To rephrase this: You should handle intentionally malicious input from generic parameters, or anything else provided by your API's *consumers*. It is safe to rely on your *dependencies*, particularly the standard library, behaving as advertised. As a pragmatic choice, though, your unsafe code should probably have as little dependencies as possible.
I think this thread is evidence of the system working. - someone makes a cool lib that innovates by providing a compelling all that people want to use - because the lib is gaining popularity, people start looking at the code and notice that there are soundness holes - the community shares this information with the author and within itself Now I know that if I want to use actix-web I need to either go through and fix any soundness holes or accept possible security vulns. The interface is still innovative. The problems will get fixed, or someone else will make a lib using the innovations in the interface. The system works!
1025 unsafe expression? Holy crapoli. What the hell. That's a serious case of "do you even Rust, bro?" `actix` is now dead to me, and I regret having ever mentioned it in a conversation. That's not a potentially broken framework, that's a totally broken process.
https://rfcbot.rs/
Ok, here goes: The official documentation for the runner is [here](https://docs.gitlab.com/runner/), including the install instruction. In short, you generally want the Docker executor, as it offers the most flexibility. If you can run it on something like Kubernetes, that's even more powerful, but not needed. I personally run it on K8s, but if you're running it on a single server, I prefer installing it as a [docker service](https://docs.gitlab.com/runner/install/docker.html). You will need to create the config file: 1. Grab a token following [this](https://docs.gitlab.com/ce/ci/runners/). If you have a private gitlab instance, you can do this on the admin settings. Otherwise under project settings =&gt; CI, copy the url and token under 'Setup a specific Runner manually'. 2. Register the runner (creating a config file, etc), using the gitlab url and token from 1 and choosing the docker executor: docker run -it --rm --name gitlab-runner \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ gitlab/gitlab-runner:latest register 3. Optionally edit the config file generated in /srv/gitlab-runner/config (or whatever path you mounted). 4. Create a network to share with minio: docker network create gitlab 5. Start the runner: docker run -d --name gitlab-runner --restart always --net=gitlab \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest Note that the docker socket is mounted, so that the runner can start other containers. For more configuration options, see [here](https://docs.gitlab.com/runner/configuration/advanced-configuration.html). We'll refer to a section of this for the cache. Next, if you want to have caching, you want to run minio. This is, again, easiest to run as a docker, and since it's just a cache, we don't need persistent storage in this case, so no external volumes. 1. Launch minio: docker run -d --restart always --name minio --net=gitlab minio/minio server /data 2. Get the access key and secret from the logs: docker logs minio 3. Stop the gitlab-runner. Copy access key and secret into the [runners.cache](https://docs.gitlab.com/runner/configuration/advanced-configuration.html#the-runners-cache-section) configuration of gitlab-runner: [runners.cache] Type = "s3" ServerAddress = "minio:9000" AccessKey = &lt;access key&gt; SecretKey = &lt;secret key&gt; BucketName = "runners" #BucketLocation = "eu-west-1" Insecure = true #Path = "path/to/prefix" Shared = true 4. Restart gitlab-runner. That should do it.
Well dangit. For some reason it's not recognizing the code blocks.
Garbage in, garbage out :)
Maybe it would be better to word it as "`foo()` is asynchronically returning a `T`"?
Yeah that's exactly what I wasnt seeing, thanks!
Thanks for that, I think I just got stuck in my (wrong) expectations, I never bothered to check the docs.
How does one configure the IntelliJ Rust plugin to use a standalone network directory mounted Rust installation? I have a Rust install on a network mounted directory /mnt/shared/rust, also .cargo due to its size in /mnt/workdata/.cargo. In IntelliJ configuration I point "Toolchain location" to rustc - ok. I point "standard library" to stdlib sources - ok. But how should the plugin know where .cargo resides? There is no local CARGO_HOME set and I there is no further option in the Rust plugin project configuration :-/ Hints where to set this in a IntelliJ Rust project appreciated... 
There is no responsibility "in general", it is always within a certain context, be it a legal system or a moral stance. And the license defines the context of the agreement: &gt;**IN NO EVENT** SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE **LIABLE FOR ANY CLAIM, ...** So, it is really unclear what is it that you are proposing by saying "*his current behavior seems like ... , which should be absolutely unacceptable*". If it's unacceptable for yourself, you should not use this library, which is exactly the point made by the license agreement - "whatever your claim, it is not something that we **will have to** treat as our responsibility, neither in legal terms, nor in any other term".
There's an interesting rust/c mashup using rust-brotli and c-lzma to generate a more tuned compressed file at the end of this post about DivANS [https://blogs.dropbox.com/tech/2018/06/building-better-compression-together-with-divans/](https://blogs.dropbox.com/tech/2018/06/building-better-compression-together-with-divans/) 
The numbers seems unlikely to be correct. ``` rg --no-heading unsafe | wc -l 21 ``` 1025 expressions in 21 unsafe blocks?
Without lots of expert knowledge, I can say this: For public generic functions, the rlib must contain more than just the binary code, probably some sort of bitcode. Since any user of an external crate can substitute arbitrary type parameters into a generic function, and that function is then monomorphized, much of the original code must be present. With dynamic linking, it would be impossible to expose any generics. All that said, according to https://doc.rust-lang.org/reference/linkage.html, shouldn't the `dylib` crate type already allow using Rust dependencies dynamically?
This seems questionable to me. https://github.com/actix/actix-web/blob/master/src/with.rs#L104 &gt; Note that while mutating or mutably aliasing the contents of an &amp; UnsafeCell&lt;T&gt; is okay (provided you enforce the invariants some other way), it is still undefined behavior to have multiple &amp;mut UnsafeCell&lt;T&gt; aliases. From the documentation of UnsafeCell. This seems to violate that bit of documentation. 
I don't think I see what you're seeing here. In this case, `deref_mut` gives you a `&amp;mut self`, so you're guaranteed exclusive access there, and its lifetime (via elision) should be tied to the return type `&amp;mut T::Config`. In order to figure out safety here, you need to audit the rest of the module to make sure there isn't some other way to get a `&amp;mut T::Config`.
Thanks, that looks useful indeed. This seems the kind of information which would be helpful to have when glancing at a project README; did you think about exposing it as simple web endpoint for badges, like tokei does? [https://tokei.rs/b1/github/BurntSushi/ripgrep](https://tokei.rs/b1/github/BurntSushi/ripgrep)
The point is that they look extremely pretty.
Really awesome work!
What are your feelings about LALRPOP at this point? I think gluon is one of the more mature projects using it so would be great to hear how it has served you
Thanks for the response. And that seems the issue to me - there's no checking of the invariants when interacting with UnsafeCell and raw pointers. Rc should be used at least, if I understand this correctly? 
&gt; This leads to a bigger question about how the unsafeness of important Rust libraries can impact the library users. There has been a proposal about enforcing unsafe restrictions [across a crate hierarchy](https://internals.rust-lang.org/t/pre-rfc-cargo-safety-rails/5535). The responses were sadly mostly negative.
This has really soured my enthusiasm for actix-web too. What are the alternatives? - Rocket =&gt; Requires nightly, which rules it out for me - Gotham =&gt; No longer being updated - Iron =&gt; No longer actively maintained There's the raw Hyper option but that feels like a very low-level place to start.
For (2), I believe he is talking about the following [situation](https://play.rust-lang.org/?gist=7cb67d9b016241d1d2580f2a1f12dc7e&amp;version=stable&amp;mode=debug). Although a contrived example, I'll admit I've run into this probably quite a bit recently in a similar context with `Option`s. Usually it starts with you keeping the code for `test` inline, but it does some preprocessing step and/or is used more than once. Once you move it into a new function though, it stops working even though it worked when copied in the local scope. I understand why it fails to work, but it can be a bit annoying to refactor sometimes.
I believe it is counting each sub-expression separately. So if you do `unsafe{ foo(a, b+c) }` it would count `foo()`, `a`, `b`, `c` and `b+c` as separate expressions. I never really intended `cargo-osha` to be anything more than a proof of concept.
I'm working on refactoring the first project I ever wrote in Rust. Crazy how many things I've learned in about a year! It's an API client for Tumblr. https://github.com/piedoom/rumblr Previously, I would have a bunch of duplicate code for every request. Now, I'm refactoring so the client has one `get` and `post` method with a generic deserializable type parameter. For instance, before I might have something like: ``` pub fn get_user(..) -&gt; User{ ..user requests.. ..deserialize.. } ``` Whereas now it'll be a single private fn. ``` fn get&lt;T&gt;(..) -&gt; T where T: Deserialize{ ..network.. ..Deserialize to T and return.. } pub fn get_user&lt;User&gt;("/user/endpoint"){ .. return user.. } ``|`
What the hell is going on with the module system, it is beyond confusing and I've read all of the documentation and a bunch of stack overflow posts. Say I have a file structure like so: src | -&gt; main.rs | -&gt; particle_system.rs | -&gt; mod.rs | -&gt; particle.rs | -&gt; emitter.rs | -&gt; movement_strategy.rs Lets say I want to include a movement_strategy in my particle. As far as I can tell I need to add "mod movement_strategy" to my mod.rs file, and then I can import it into my particle.rs file by using "use movement_strategy". However this doesn't work and it asks me to give the full path "use module::particle_system::movement_strategy::...;" Why is this? What am I doing wrong? Also if I have an external crate type that I need access to across multiple levels (in this case I am passing a display type down to the particle to display), how/where do I correctly import it to avoid the compiler complaining? 
I'm writing a safe wrapped around a c library that has a thread safe type. Functions using it take it as a mutable pointer then block on a mutex. I've generated bindings to this with bindgen which use &amp;mut (sensibly). How can I wrap these bindings to create &amp;self methods without introducing the overhead of another mutex? My first thought was to use unsafe cell but because it's ub to have multiple &amp;mut references that won't work.
I'm writing a safe wrapper around a c library that has a thread safe type. Functions using it take it as a mutable pointer then block on a mutex. I've generated bindings to this with bindgen which use &amp;mut (sensibly). How can I wrap these bindings to create &amp;self methods without introducing the overhead of another mutex? My first thought was to use unsafe cell but because it's ub to have multiple &amp;mut references that won't work.
I published my first crate - a super fast gradient noise library that uses the new SIMD intrinsics: [https://github.com/jackmott/rust-simd-noise](https://github.com/jackmott/rust-simd-noise)
Yes, read the Nomicon. That persuaded me that unsafe is a headache I'd rather avoid where-ever possible. There's a reason why we're using a safe language instead of C or C++, right? To let the compiler worry about all that UB stuff.
Aha that makes more sense. I (probably) stand corrected!
Ah, yes, that makes sense.
I knew that the original lacks some good old `for &lt;'a&gt;` somewhere. :D
Gotham looks like it has been [picked up](https://github.com/gotham-rs/gotham/commits/master). I was considering testing actix out, but having UB in the library is a write off.
I only have to use unsafe in my current project because of FFI. But that's reasonable - the compiler can't reason about C code. (Yet.)
&gt; The reality is that we have a very popular project that has completely flouted one of Rust's core value propositions. We can't abide that. We need to make it clear that these things must be fixed, or people shouldn't use the project. Potentially but here is the thing: without actix-web I would not have a working project right now. From where I stand it's the only actually usable framework and I tried a bunch of them. It's effectively just one developer right now so if the goal here is shame the project to the point because of unsafe usage then I don't think anyone is being helped here. Getting rid of unsafes in actix-web is not an easy undertaking.
Thanks, That's gotten me a lot closer, still working around issues with another lifetime in the original code. Hopefully I can make this work. Lifetime's should only stop it from compiling, not cause bugs. 
We all take shortcuts. Sometimes I don't come to a complete stop at 4-way stop-signs in the neighborhood if I can see nobody on the cross-street. Sometimes I'll bracket a piece of code with 'unsafe { ... }' if I'm having a tough time with the compiler. Sometimes I'll give my toddler a bottle of cough syrup so he'll sleep in the car for a few hours and I can spend time in the strip club. We all do it. Am I rite?
&gt; Even tests use things like String::from_utf8_unchecked to purposely create strings that contain invalid UTF-8: That's... horrible... I'll expect that to break once we ship debug versions of std that get automatically chosen by cargo debug builds because I expect all `_unchecked` methods to contain `debug_assert!`s.
The more I skim through the source code the more I am sure I wouldn't touch actix-web with a 20 foot pole. The problem isn't the many uses of unsound `unsafe`code, but rather the attitude of the main developers towards Rust. Even if they would fix all the unsoundness in their code, I wouldn't be able to bump the version of `actix-web` and sleep well unless I were to manually re-inspect all uses of `unsafe` in the version I would be upgrading too because the `actix-web` developers are just not to be trusted. `actix-web` is the fastest most dangerous Rust web framework. 
It has worked out great so far! Only issues I have had is some ambiguities when setting up error recovery which is annoying but they haven't been showstoppers. I may need to deal with that eventually though.
+1. Even if they fix all the unsound `unsafe` code I wouldn't be able to sleep well knowing that each minor update of `actix-web` can break the world. I don't trust the project, and regaining any trust is going to require dramatic attitude changes.
Why does nightly rule Rocket out for you? Nightly rust is pretty much safe.
You're experiencing it, right here. This is as good as feedback will get.
Oh nice, I'll compare compression ratios right away with the flate2 crate. Just as a question: is the target compresison ratio to be more compressed than deflate, or to be like brotli, to live in the "less compressed but quickly" camp?
These kinds of messages go a long way &lt;3
Especially in something like Fira Code
Nightly may be safe but it not a stable release. Rocket gets broken by nightly changes. I want to use stable rust with its commitment to stability and backwards compatibility so that code I write now has a good chance of continuing to compile 1,2,3 years from now on the stable release of the time without the need to rework it. 
I've always needed unsafe to implement data structures. Even if it's possible without unsafe, it will tend to be much less efficient, and with data structures, you should know your invariants well enough to favor efficiency.
That’s good news. I’d still want give it a few months before committing though, given the frequency of releases and updates since the 0.1 release. 
The goal isn't to shame. The goal is to remove and prevent flagrant misuse of unsafe in the Rust ecosystem. IMO, this is deserving of strong critical feedback.
Your goal might not be to shame but it feels like shaming in this thread here. I tried to fix some of the unsafe usage but it's incredible heard to get rid of. Quite a few run into language implementations. I think actix would need some expert knowledge to remove some of those unsafes.
&gt; Why is this? What am I doing wrong? It is important to get the paths right. They work exactly like Unix paths. Assuming you put a `mod particle;` in your `mod.rs`, the correct path to access `movement_strategy` from `particle.rs` is `use super::movement_strategy`. `use movement_strategy` only works in the file where you put `mod movement_strategy;`. The most confusing thing is IMHO that paths in `use` statements are absolute and paths in code are relative: use crate::function; assert_eq!(function(), ::crate::function()); &gt; Also if I have an external crate type that I need access to across multiple levels (in this case I am passing a display type down to the particle to display), how/where do I correctly import it to avoid the compiler complaining? The idiomatic way is to have `extern crate ...` in your top-level source file (`main.rs` or `lib.rs`). You can just access it from anywhere, see the example above.
I'm gonna say something possibly unpopular but I feel like Rust already has too much verboseness sometimes that can't just be solved by macros. I don't want to have to edit Rust in a proper IDE with snippets and such just to save my fingers. If I'm writing a lot of async code I want it to be concise to do so. But I understand that it does seem a bit magical to have the function signature transformed so much.
There are certainly some comments in this thread that are crossing that boundary, but I tried to keep my criticism to the code itself. I also obviously have strong opinions on the ecosystem wide impact of this kind of misuse. I don't think there is any problem expressing that.
How about `fn foo() -&gt; async i32`? Then it's more clear that the return type is being modified, but we can still specify bounds in a mostly clear way. And we don't have to type async related stuff twice (both async and Future).
Nobody has claimed it's an easy undertaking. As to your other point, is your argument here really "The end justifies the means"? Because while the safety and stability of *your* service is your business, and something that you're well able to assess, that's not the case for other people, and perhaps not for the community generally. There's been a lot of positive noise about actix-web, and a lot of people trust your opinion – that's not your fault, or directly your responsibility, of course, but that positivity feels misplaced at the moment. If the author wants to address these concerns, there's no shortage of potential contributors (in the context of Rust's small community), but a bunker mentality isn't going to help anyone here – if this isn't addressed, there's going to be a high-profile exploit of a server running actix-web sooner rather than later because of these choices, and that's going to damage trust in the language more generally, and fuel more "Rust isn't safe, actually" comments on HN.
You of all people could help to address these unsafe blocks.
It would take me weeks. I don't have that kind of time. I wish I did, but I don't.
So do just one, but make sure it's a beast
&gt; As to your other point, is your argument here really "The end justifies the means"? Because while the safety and stability of your service is your business, and something that you're well able to assess, that's not the case for other people, and perhaps not for the community generally. I'm a realist and while Rust still has massive usability issues around certain types of borrowing it does not surprise me that we will see unsafes from time to time. actix-web is not the worst offender here. The `owning_ref` crate for instance's most useful type `OwningHandle` is a massive unsafe API violation but the community has been largely okay with this from what I can tell. &gt; If the author wants to address these concerns I don't think the issue here is not wanting to address the concerns but that it's very hard to provide the same API without some fairly complex changes.
I agree to you. That was my first thought, too.
I suppose I'm one of those people who think of using combinators on returned futures, rather than awaiting them right away. Even if you don't use the combinators, though, I'd imagine that there would be plenty of cases where you fire off several async functions with no dependencies between them and then await a collection of them only when necessary.
As a networking guy I get a little excited than disappointed each time I read a "Rust Networking" post and it's just about handling TCP/UDP sockets (or worse: HTTP).
That code isn't even doing anything normal with raw pointers. It's just using it to get rid of the lifetime associated with the reference, which is suspicious of an invalidation issue.
&gt; What you are saying here is that you are going to return a mutable reference to the memory location pointed to by self.y. [...] Therefore, you now have 2 mutable references (aliases) to y. No. When you call `get_y()`, the "self" that it targets goes out of scope, until the `&amp;mut f32` goes out of scope. This is exactly similar to how many, many methods in `std` and other Rust libraries work. Consider how `&amp;mut v[i]` works, where `v` is an instance of `Vec&lt;T&gt;`. As long as the value returned (the reference to an element within the vector) is live, then you *lose* direct access to `v`. You have narrowed the scope of your access. You do *not* retain access to `v`, as long as that reference is live. 
If you provide a variable to a function then the function takes ownership of that variable. So `fn unit(self)...` will basically steal `self` and then drop it from memory when it goes out of scope (i.e, the function ends). In the second way, `fn unit(&amp;self)`, you are providing a reference to `self`, which is basically another variable: `&amp;self`. When the function leaves, the reference itself is dropped, but `self` itself remains. The first way doesn't explicitly "consume" the vector, but it does take ownership of the value, dropping it when the function ends. The ownership model is probably the biggest learning curve for rust, but once you get a mental model of how it works it gets a bit easier. Every variable is owned by something. Functions and other methods take ownership of the variable by default unless its passed by reference. References can only stay alive as long as the thing they refer to. [I would check out this portion to understand a bit more.](https://doc.rust-lang.org/book/second-edition/ch04-02-references-and-borrowing.html)
I just skimmed through the last part, but I’m still pro inner return type approach. One big disadvantage of the outer return type approach is, that you specify to return an `impl Future&lt;Output = i32&gt;` in the signature, but then you just `return 5` within the body. That is inconsistent and confusing.
&gt; I also obviously have strong opinions on the ecosystem wide impact of this kind of misuse. FWIW so do I generally. At the same time though I have done enough Rust now to know that the language still has lots of limitations that make programming with it really hard when it comes to efficient borrowing. I have at least two uses of `OwningHandle` in our codebase I can't get rid of and I know what a massive soundness issue it is. So it's hard for me to fault this.
My advice would be to systematically remove all or most unsafe, even if it means regressing performance. Then setup benchmarks. Profile and optimize. If optimizing leads you to unsafe, then so be it, but justify it and provide a safety argument. From my quick glance, this probably requires some serious refactoring. Fixing actix-web isn't how I want to spend my time, sorry. My goal here to impress upon others how important this is for the ecosystem.
&gt; cargo-osha is a proof-of-concept tool that is counting each sub-expression separately. So if you do `unsafe{ foo(a, b+c) }` it would count `foo()`, `a`, `b`, `c` and `b+c` as separate expressions. This is why the number is so high. 
Rouille seems nice, but rocket seems so easy to use, when looking at it's hello world example, it's much shorter than hello world examples in other web servers.
Have you figured out how one would execute wasm in a Rust application? I suppose you could embed a JavaScript engine that supports wasm, but that seems like a waste if you don't want JavaScript. I've been Googling around and I can't find anything.
I'd say that the difference with `owning_ref` is that attempts to abstract over its unsafety, and it properly informs you of which parts of the API require you to take safety into your own hands.
Rouille's hello world is barely a couple of lines longer, once you remove the thorough comments explaining things, and that's a fixed cost. Each new endpoint you add doesn't require a bunch of boilerplate, so Rocket just saves you from having to write an additional like three lines of code. On a real project, I don't think it makes a difference, but Rocket is certainly flashier.
There are nontrivial "setup costs" associated with studying a codebase well enough to be able to intelligently make the kind of sweeping architectural changes that are needed to transition from a non-borrow-checkable design to a borrow-checkable design. No matter whether a given person addresses a single `unsafe` block or an entire module, they still need wide-scope knowledge of the project.
At work we have a security review process for this purpose. Actix may not be approved, given what I've read. The nice thing about rust is that the auditing process becomes a *lot* simpler - just grep for 'unsafe' and there'll be lots of low hanging fruit.
The core unsafety issues in actix-web are that self referential type borrows exist within the `HttpRequest`. Right now there is no way to resolve this nicely in Rust other than to introduce a ton of wrapper types with many lifetimes. The same type of unsafety that exists in actix-web (for instance that the `Params` contained within the `HttpRequest` is 'static which is a lie because it borrows non static data) is exactly the same issue with `owning_ref::OwningHandle`. Both APIs are marked as safe.
&gt; Rocket is certainly flashier Yes, that's probably why it seems more attractive to me, because I lack the knowledge of what a good web framework needs, that's really all I have to go on. But i do also like that rocket doesn't want to rush to 1.0 or stable, so that they can improve ergonomics of the api, and i really like that. Granted, rouillle is also waiting on proper async in rust, rouille is quite small, while rocket is one of the biggest frameworks in rust in terms of contributors.
I agree with the overall sentiment expressed here, but: &gt; 2 (...) unsafe blocks internally must (...) 100% incapable of causing memory unsafety (...) function is not valid Rust. and &gt; 5 (...) invariants that the surrounding module needs to uphold (...). I'm probably misunderstanding what you meant there, but aren't these arguments contradicting each other? The statements seem a little bit too "_preachy_", I would rather go for a "encourage safe Rust" approach than a "discourage unsafe Rust" one. There is no "Safe vs Unsafe" in my eyes, `unsafe` is just another tool in the Rust language toolbox.
I believe it. I've had similar issues in the past. Hell, I still do. I am still uneasy, for example, about how to encapsulate the safety of memory maps. But this goes beyond a couple of instances. This is a very popular and highly visible crate, which means a lot of people are going to look to it as an example of how to write Rust code. Normalizing this kind of use of `unsafe` would be very bad for the ecosystem. I've said in the past that I believe the success of Rust will, in part, depend on whether folks can have confidence in their dependencies' correct use of `unsafe`, because it's such a fundamental part of what Rust claims to provide. If we just say "well the language has too many limitations so I'm just going to abuse it" at the kind of scale present in actix-web, then we have a serious problem, and I think it needs to be addressed. If the language is in fact too limited to build something like actix-web safely, then I agree that is also a problem. But I think we are far from being able to conclude that until more people have tried.
(just letting you know that I edited my comment while you were writing yours, but indeed.)
Is there documentation stating that somewhere? Or in general the difference between debug and release?
Sometimes unsafe is legitimate - FFI. I think this would provide some bad signal.
&gt; It's a quick metric for doing a preliminary overview, not a replacement for doing proper auditing. I worry that it would not be good for the former and would be dangerously considered useful for the latter.
Yes, the fact that non-security-expert developers can grep for unsafe and go "wow, I can reason about this code locally being incorrect" is a massive selling point for rust.
&gt; edit: The last time I can remember any discussion about appropriate use of unsafe was when a CVE was found in the base64 crate. It doesn't come up very often - that's probably a good thing! I was going to mention this one but you already did :) I just love/hate/love it because it's such a *perfect* example of unsafe abuse to me. Consider: * How many situations call for a ultra-optimized base64? * How many situations use base64 on untrusted input? It's like buying a golf kart and finding out its engine is an unshielded nuclear reactor.
How about calm down a bit and read [this](https://www.reddit.com/r/rust/comments/8s7gei/unsafe_rust_in_actixweb_other_libraries/e0ycdit/) 
I have a high interest of removing uses of unsafe that make an unsound API. I just do not know how with the current state of the language without making actix-web impossible to use. When /u/seanmonstar filed his first unsafety issue against actix-web I tried to see what workarounds I can find for the core design and not the individual cases and I could not come up with anything. I really think a fundamental fix to the issue requires language features that are not there yet.
Rust suspends immediately, and does not run any of the async code even before the first `await`.
Yes, i do think there is an argument to be made for keeping code concise and beautiful. Haskell might be a little hard to read sometimes if you don't know the language, but it's short and clean, which is why i really appreciate it.
In this case I think its pretty strongly connected Hochschild's work. Trying to manage the emotional tenor of an issue tracker thread is a major, often unrecognized, component of doing open source work, or at least of doing my open source work.
Pre-1.0, Rust had more sugar. It lost a lot of it in order to make the language simpler, which I think was a good idea. We've gotten more of it back - for example, the `?` is a somewhat recent addition that was just added to make things less verbose, and I love it. I would like to see things that make Rust code less cumbersome to write, particularly things that macros can't already solve adequately.
Makes me think ... What if we had an "allow_unsafe" in `Cargo.toml` that contains list of crates for which we allow `unsafe` blocks. It could be purely optional, but it would bring attention to at least some users...
Sure. I feel like I can tell when unsafe is expected, such as anything with `-sys`. It would be interesting to see a ratio of unsafe to safe code. If an FFI heavy lib has a lot of safe code, then that library is doing a lot of fancy work, which may also warrant a review (e.g. I think Vulkano has some custom logic to ensure correct usage of the library).
I like this a lot! Also have crates.io put links to the instances of unsafe so that people can audit easily!
Perhaps something more along the lines of 'unsafe code test coverage' would provide signal that I would accept.
While as others have said source does not need to be exposed for dynamic linking I share some of your concerns but more so for Unix than Windows; the Unix ecosystem in general _heavily_ favours dynamic linking probably for the opposite of what you say in that dynamic linking is often more convenient when the source code is available and there is a system of software-distribution middle man like a lot of Unix flavours have where they take the source and compile it according to the specifications they think their target user base is interested in like size, security, or performance. This has been a particular problem with Haskell—despite ostensibly being more adapted towards Unix than Windows it actually runs into a lot of problems on many distributions because the fundamental design of non-strict languages makes dynamic linking to be very problematic with any recent performance because you have to inline in different ways as the compiler really needs to take functions apart and re-organize them to be efficient so the current situation on many many distributions is that if a single Haskell library is updated every package that uses it has to be updated with it because you can't just normally link to a dynamic library and call it good in Haskell. Thus far it's not really clear on how Rust is going to get packaged on Unix—at least on portage the `cargo ebuild` cargo subcommand that generates ebuilds seems to just use static linking which does go against the general philosophy. At least the Gentoo system there are frequent bugs in the subslotting of the `dev-lang/rust`package and the subslot isn't properly updated when the binary interface of the libstd changes so even though an ebuild correctly specifies that a package links against the ABI of rustc often when rustc is updated a rebuild is not appropriately triggered resulting into linker errors that in my case once made my machine unbootable because I use a rust binary in my boot sequence.
I think that should maybe more so be a compilation setting than a thing in the source code though. As in dynamic libraries and whatever links to it can be compiled in a stabilized ABI or in an ABI that permits the compiler to optimize and change more as its sees fit with the added guarantee that as long as you don't make changes to a public type that the ABI won't change in the stable ABI unless a new stable ABI is selected.
Yeah you've pretty succinctly summarized the remainder of my concerns. Side note I love your username.
What needs to be audited depends on what code can change invariants that the unsafe code relies on. Sometimes, that's nothing outside of the unsafe block itself; it's possible to write an unsafe expression that can be validated as sound without referencing any code outside of it. Other times, you only need to audit the code in the surrounding function; the invariants might be upheld in a way that could only be violated by changes to code within that function. If you depend on any invariants upheld by types, then they can potentially be violated by anything which has public access to the appropriate parts of that type, which could be module scope, crate scope, or in the worst case, exported publicly from the crate. As we see with actix-web, the scope of code which could violate constraints is any code in the application which uses actix-web. So lines in the module is not really particularly a better metric than lines (or expressions) inside unsafe blocks. For each unsafe block, you have to start reasoning from it, then find the scope of what could affect it, and work iteratively out from there until you are able to demonstrate that all of the invariants relied on are upheld. Number of unsafe blocks, lines in unsafe blocks, or expressions in unsafe blocks basically gives you a lower bound on how big your auditing job is. The upper bound is always going to be all code in the application, if someone doesn't encapsulate invariants properly.
Not yet :( Being too busy with work. Someone else mentioned Cretonne, and it sounds like it could be a cool alternative down the line. Check it out. https://github.com/cretonne/cretonne
"succinctly"... one of the many talents I lack.
I think this all points that new tooling is needed in the crates ecosystem for auditing unsafe blocks of code. I'm just spitballing here, but I think a tool like the following might be useful: 1. An tool (let's call it `unsafe-audit` for the time being) that can be cargo install'ed. 2. This tool would hook into GPG's code signing abilities (similarly to how git allows you to sign commits using GPG) to sign unsafe blocks of code. 3. Auditors could use this tool to audit unsafe blocks of code, and if satisfied, sign them and push these signatures to a central repository (let's call it `unsafe-audit.rs
I wouldn't mind if `if COND =&gt; ELSE_CLAUSE` was also the name of the game. In fact I wouldn't. Having said that this `-&gt;` in function return types is absurd and should be a `:`; that annoys me so.
GUI stuff isn't great yet (though GTK works reasonably well as I understand). There is a library that works as a wrapper for the Win32 libraries, but all it does is let you call the C functions directly. Pretty much everything Rust can do with its standard library, so can C++ (at the very least with boost; probably with the STL in most cases), but Rust does it nicer. For example, the STL has tuple types, but they're kind of ugly in the code, and they can be a pain in the arse to work with - there's a reason many C/C++ libraries use output pointers. Rust, meanwhile, has tuples that work reasonably similarly to the ones in C#. It also has many zero cost abstractions - working with iterators, for example, feels like working with linq much of the time, and when you compile for release, your compiled code will look basically identical to how it would if you'd just used for loops. I think the only thing Rust can do that few (if any) languages have is built in unit testing. It also has documentation comments that work similar to Javadoc, but use markdown to produce well formatted html documentation. If you look at the [Piston documentation](http://docs.piston.rs/piston/piston/) and the [Stand Library documentation](https://doc.rust-lang.org/std/index.html), for example, you'll note that they look practically identical. This makes learning a new library so much easier - especially since if any code examples shown don't help you to understand how the code should be used, there's often a link directly to where it's defined in the source code. Also, Rust prevents data races at compile time - if your code is able to generate a data race, a dangling pointer, a use after free or any of those other common sources of security threats, your code simply won't compile (usually). Now, of course, it does this by preventing you from doing certain things that you may actually need to do, which is where unsafe comes in (which works basically the same as it does in C#). The other thing is, there isn't an IDE as yet (though last I checked VS has a decent plug-in). This doesn't particularly bother me, because I have emacs set up with autocompletion for the languages I code in anyway, and gdb is particularly easy to use with emacs, but I know this is a pain point for some.
About two years ago we (GitLab) experimented with adding a benchmark suite to GitLab's test suite, based on RSpec. We ended up not going with that, primarily for two reasons: 1. Test environments rarely have even close to enough data to make benchmarks reliable. 2. CI performs too inconsistent. Sometimes a benchmark would pass, other times it would take 3x longer than expected. If you want to run periodic benchmarks, I would suggest using a dedicated (and physical) host that _only_ runs those benchmarks.
In python you actually don't _have to_ put the expression in an if-clause on a next line. `if true: print("Hello, world!")` is actually completely fine. Likewise in Rust you don't _have to_ put braces around it either and it's actually quite common to not do so with single-statement things in match clauses. I would definitely in your case just write: match x { some(num) =&gt; println!("{}", num), None =&gt; println!("Nothing :("), }
People take shortcuts in evaluating crates all the time. Up until now, based on the excitement over benchmarks and blog posts on porting apps to actix-web, I had assumed that it was a reasonably high quality library (haven't had a reason to use it myself, so haven't evaluated it in depth). That number from cargo-osha instantly changes that impression. Unless you're doing bindings to a C library, you shouldn't have nearly that number of unsafe expressions; you should be able to abstract over whatever unsafe code you need to write in a smaller helper module providing a sound interface. Whether or not you're binding to a C library, that number indicates huge amount of code that needs to be audited for soundness. There are basically three useful ranges for evaluating the output of something like cargo-osha; 0, which indicates that you don't need to audit that code for unsoundness directly (unless you suspect bad faith and use of soundness holes in the compiler and standard library). Low, which means you need to audit or trust the evaluation of someone you find reliable, but that auditing is doable. High, which means you need to treat it like C code; invest a lot of time and effort into auditing it, accept that it's unsound and sandbox it away as much as possible, and/or accept that you will continue to deal with undefined behavior. Where that threshold between low and high is is subjective, as is who you trust to write and audit unsafe code, and what audit methods you accept. Ideally, we'd have formal verification of soundness of all unsafe code, and of the compiler, but that's a long way off if it will ever happen at all. This kind of metric definitely gives you some quicker access to information than trying to manually grep through every one of your dependencies to start the auditing process.
Thank you. This is what I wanted but never looked into bench before.
Great to see more progress on Gluon! Congratulations on the release /u/Marwes!
It's a problem but yall are being a bunch of assholes. First that Nikolay is great, seriously he is awesome, he did so much in so little time, he gives support to everything needed, I can't express how much praises he deserves. He is always there for the community and he uses what he develops. There are problems, which are Rust problems, not only Actix, we hadn't had **the talk**, about unsafe code and we need to, this is the perfect opportunity for it. Creating guidelines and creating a way to be aware of those issues more easily, besides learning quirks to avoid unsafe code. Anyway, actix is reaaaally fast, it's used in production in azure and in many other organizations and mostly it's the only framework "ready". It works greatly, and is as trustable as a C lib, but it's easy to use, it's fast and it's there. Because the others aren't there. - Iron is not maintained - Gotham is 0.3, really I can't overstate how not ready gotham is (I tried and ended-up rewritting everything in actix) - Rocket breaks on nightly updates, and nope, not going to prod for some years - Actix is fast, easy to use, has every feature needed and it's there I will keep picking actix, but I will be aware of the problems, try to test for it and help the community how I can. Seriously STOP BEING A BUNCH OF ASSHOLES, Nikolay is awesome and deserve praises and help, not non-constructive criticism.
We, as a community, have let this thread drift into some concern-trolling territory.
Ok, I think I'm getting it. My issue is that I've only been using options, results and simple expression with match lately, and I somehow had not pictured that you can use any expression, hence the use of brackets on the LHS of the fat arrow. Thanks for your comments.
Yeah -- though rocket has a little more than I want inside it I also considered it but didn't choose it because of the nightly requirement. Unfortunately, [Gotham.rs's torch is getting passed](https://gotham.rs/blog/2018/05/31/the-state-of-gotham.html), so now I'm doubly confused. I guess one viable option is to just use Hyper directly, but surely there's a tool that's a little bit higher level to use? I also use the [rust web framework comparison](https://github.com/flosse/rust-web-framework-comparison) repo, so I guess maybe next I'll try [nickel.rs](https://nickel-org.github.io/)
As someone else commented above, you need to scan outwards from that unsafe block to make sure that the invariants are maintained. Maybe they are maintained by the surrounding function, in which case you can stop there, but maybe they reach right out into the rest of the module or further. So the unit that needs auditing would vary depending on the situation.
The [indexmap](https://crates.io/crates/indexmap) is really neat example of building a map with no unsafe code that is extremely competitive with the std hashmap. In Conduit, we've found it's many times been a better choice.
I didn't mean to claim that all instances of the keyword `unsafe` needed to be abolished. However, I do think that all instances should have things in place to prevent triggering memory bugs. If for some reason they cannot, then the function should be labeled `unsafe`. I may be wrong, but so far I haven't seen anything that I think couldn't be fixed. For the `HttpRequest` issue of having multiple mutable aliases, since a `RefCell` can't be used (internal references are returned, which couldn't be done with the guards of refcell), then at the very least, assertions should be placed in `get_mut` that there are no other clones.
I tried using serde back when it required nightly. I would update something in my dependencies, and it would break. I'd then have to update my nightly but sometimes the latest nightly wouldn't work with serde, so I'd have to sit around searching for a set of versions that worked with each other. Eventually, as serde itself was also releasing 0.x versions at the time with breaking changes, I'd have to update all of my code that interacted with it to get it to work with new nightlies; and I was implementing a serializer, so it was reasonably complex code. That sort of soured me on the idea of any use of nightly for production code. For experimentation, sure, but not for something where the updating treadmill will become a burden.
&gt; I'm probably misunderstanding what you meant there, but aren't these arguments contradicting each other? Not contradicting, I'd say it implies that "if your function has `unsafe` blocks within it and those unsafe blocks depend on things that the function cannot enforce, then that function must be marked `unsafe`". However, some might argue that bullet point #2 could alternatively start with "Public functions exported by a library that are not marked with `unsafe`...", because the intended value could be to protect library consumers by showing that there aren't landmine function inputs that an unsuspecting user of your API will use to violate your module's invariants. For the purposes of this specific conversation, limiting the scope in this way would suffice.
It's a bit of an odd one, but I find it works at least a bit better if the error message is always in the "expected ..." format. Like I would write: "42".parse().expect("expected string to be a number"); This works well with the general Rest convention to have error messages be in the format "expected an X, but found Y".
Maybe someone to summarise all the major points and arguments made to date at regular intervals, in a neutral manner.
As a heads up, the Jun 28 San Francisco meet-up title and link are out of date.
It's not "being an asshole" here, but the library developers just straight up *ignored* Rust's measures (which prevent people from producing unsafe code) by *incorrectly* working around it. This is not a problem of Rust.
&gt; 1. Unsafe code is any code in a module that contains an unsafe block. Keep modules that contain unsafe blocks as small as feasible in order to reduce the scope of unsafety. &gt; 2. Functions that are not marked with unsafe but that use unsafe blocks internally must, for every possible value of every possible combination of input parameters, be 100% incapable of causing memory unsafety. If there exist any inputs to a safe function that cause memory unsafety, that function is not valid Rust. These two rules are contradictory. The whole reason that unsafety can "infect" a module is that it can rely on invariants that are enforced outside the boundary of the function in question. The natural way of ensuring that those invariants are enforced is making sure that any state which could impact those invariants is private to the module, and that all functions in the module that manipulate that state uphold those invariants. We do need a set of unsafe code guidelines, but that work has been intermittent. There's the [nomicon](https://doc.rust-lang.org/nomicon/), which is quite informative but more of a tutorial than a set of formal guidelines. There has been [some discussion on internals](https://internals.rust-lang.org/c/language-design/unsafe-code-guidelines), [some attempts at defining a memory model](https://github.com/nikomatsakis/rust-memory-model) (with [some more discussion in the issues](https://github.com/nikomatsakis/rust-memory-model/issues?utf8=%E2%9C%93&amp;q=is%3Aissue)), and some promising [research](https://homes.cs.washington.edu/~spernste/pubs/crust-2015.pdf) [results](https://plv.mpi-sws.org/rustbelt/popl18/paper.pdf). So while there's a start, I think there's more work to do. Perhaps some guidelines on using unsafe code while maintaining a sound interface could be added to the [API Guidelines project](https://rust-lang-nursery.github.io/api-guidelines/checklist.html). Of course, some issues with unsafe will be purely internal, but a lot of the issues come up with trying to provide a sound interface over code that uses unsafe. We also have [formatting style guides](https://github.com/rust-lang-nursery/fmt-rfcs/blob/master/guide/guide.md), and the [list of Clippy lints](https://rust-lang-nursery.github.io/rust-clippy/master/index.html), but I don't know of a general purpose best-practices document that this would be appropriate for. Of course, as we have seen earlier in this thread, there are instances of [one builtin and one clippy lints being disabled for a single line of `unsafe` code](https://github.com/actix/actix-web/blob/285c73e95ea4a011673bcd4f84a26d2aee84e592/src/server/helpers.rs#L77), which allows extracting an `&amp;mut` reference from an `Rc` without any kind of cell; and later that was [just rewritten in a way that wouldn't trigger the warning](https://github.com/actix/actix-web/commit/de49796fd191d755b63c1818524ca2e762b62399#diff-9302ebfc746e6097e970f99d795282acL82) without actually changing the safety. So while we could come up with and publicize some better guidelines, there are people who are going to ignore them even with you have the compiler, Clippy, and people filing bugs warning them about the issues.
The thing about FFI is that all of the code behind the FFI layer is unsafe (unless they are thin wrappers around a safe language), so while the use may be "legitimate" in the sense that it's requires to use unsafe to provide such an FFI library, you still have the burden of needing to audit all of the code in the binding, and in the code backing it if it's in an unsafe language, if you want to avoid the possibility of UB. It's not a bad signal, it's just an expected signal for FFI; there is a lot of unsafe code here, buyer beware.
Being critical of a developer's work when they're contributing to open source is a really difficult thing to do properly. What we have here is a situation where people wanted to trust and use a library, but are finding out that that would be a serious mistake - undermining some of the primary reasons why anyone chooses rust. &gt; There are problems, which are Rust problems, not only Actix, we hadn't had the talk, about unsafe code and we need to, this is the perfect opportunity for it. I tried to make this argument in my head earlier and couldn't really justify it. The developer disabled lints, disabled warnings, clearly didn't look into what those lints or warnings meant (they clearly state that some things are UB), etc. It's hard for me to say "Well, Rust just needs to better document these things" - they were documented, in one case *two* separate lints had to be disabled *and* unsafe had to be used. How could rust do better there? How much more signal would we need? I don't see a lot of insults at Nikolay, or people saying that they are bad or whatever - but that they have lost trust in the project. Is this unfair criticism? I don't believe so. The standard for a rust library *must* be higher than "at least as safe as C". If that standard is not being met because it is not a goal... please publicize that in your crate. As an example, I have seen at least one crate explicitly state it is *not* for safe usage - a fine attitude so long as it's made very, very clear.
Let's say I have a Rust project, called `project_x`, with the following structure: ``` project_x * src * bin * smol.rs * lib.rs cargo.toml ``` `cargo.toml` specifies that `project_x` depends on the external crate `rand`. `lib.rs` looks like this: ``` extern crate rand; use rand::prelude::*; pub fn random_f32() -&gt; f32 { random::&lt;f32&gt;() } ``` And `smol.rs` looks like this: ``` fn main() { let x = rand_f32() + 1; } ``` I want to: * use `random_f32` from `lib.rs` * not have to re-import `rand` in `smol.rs` How do?
That seems fair, yes. In extremes, counting could indicate a serious problem. I just would not want to 'badge' based on it, or rely on it - it could easily give a false sense of safety or unsafety.
That's a fair point.
This whole "it's open source therefor they can do whatever they want" thing is really silly. Of course they can publish what they want. They could backdoor the whole thing too. Would we call that responsible? No shit they aren't legally required to fix these things, no one is arguing that.
As far as I know, the only efficiency win is in situations where you expect to reuse the same array over and over. Even then, it's going to take a combination of strange factors for it to really matter. I'd recommend the much more usable style of returning a new array over the slightly more efficient style of reusing one in most cases.
Benchmark it! It will probably depend on the size of the array, and whether the method gets inlined. But you can't be sure without measuring.
That's pretty much the nail on the ehad; people wouldn't mind the use of unsafe code if it was well communicated that there was a lot of it.
Note that using `kebab-case` is common for packages (though the debate between using `-` and `_` will simmer eternal until they're made actually equivalent). The crate name will then, if unspecified, be transformed to be the package name with `-` replaced with `_`. A crate name is restricted to be a valid Rust identifier. As far as I know, there are no restrictions on a package name (other than reserved names, which I can't enumerate at the moment).
I would prefer to do this now and postpone further sugar for 2019.
Do you think this outward scanning is something that might be accomplished programatically? 
So this? fn foo() -&gt; async T
Thank you for taking the time to clarify things for me :) . I kinda like that there are no hard rules for how `unsafe` should be used beyond its' scope, just the early stages of a community guideline.
oh yeah, vague bells ring in my head: i think i read you can use '_' instead of '-' when writing the crate name...thanks!
It's on the list, #455
I do hope to release it later this year. I think the code is now stable enough to do a release, so I'm in the process of polishing some more and adding some documentation (which is about as fun as you imagine ;) ). After that a holiday, so it'll probably be Q4 when I put it on crates.io.
In order to bind to the DOM, wasm-bindgen is going to use WebIDL definitions to auto generate them. Unfortunately it seems that approach isn't viable for JS global functions and objects, so the project needs help to get to full coverage. Each PR submitted will bring us one step closer to making browsers a first class platform for Rust!
May be it checks the lock file and you had 2.1.1 there, for example? Just a guess.
It's an issue for everyone. It would be nice not to have to do a security audit with every library upgrade, don't you think? Those are the kinds of tedious things we ideally have computers do for us.
Answer: add `use project_x::*` to `smol.rs`.
Don't. There's no guarantee that `fs::File` uses libc at all, so even if it's possible on some platforms, it won't work on others. If you want a Rust wrapper around `FILE`, write a (or [find](https://crates.io/search?q=FILE%20wrapper) an [already](https://crates.io/crates/fd) [written](https://crates.io/crates/cfile-rs)) Rust wrapper around `FILE`.
&gt; The real advantage for me is I can quickly glance at a function signature, regardless of it being an async function or a function that just returns a future and know that I can await the result of that function based on the fact it returns a future. I don't have to look at the async in the function signature to infer this information, I can just look at the same part of the function signature in both cases. This hints to me that maybe `async` shouldn't even be present in the function signature (and we should rely on ` -&gt; impl Future&lt;...&gt;` to denote asynchronous functions). The post notes that with the outer return type, the mechanics of `async` as a keyword has a bit in common with `unsafe` as a keyword. But there's a difference. When I write: ``` unsafe fn foo(x: i32) { // do stuff } ``` It tells me that 1) the body of the function may use unsafe code and 2) the function _itself_ is unsafe. It's _kind of_ shorthand for ``` pub(unsafe) fn foo(x: i32) { unsafe { // do stuff } } ``` Here, `pub(unsafe)` means "only unsafe code can call this". This isn't actually valid syntax, though. The _only_ way to indicate to a caller that a function ought not to be called from safe code is to use the `unsafe` keyword as it exists now. With the outer return type: ``` async fn foo() -&gt; impl Future&lt;Output = i32&gt; { // do stuff } ``` is sugar for ``` fn foo() -&gt; impl Future&lt;Output = i32&gt; { async { // do stuff } } ``` Notably, after the desugaring, `async` or a similar keyword doesn't appear anywhere in the signature. So now we've got two different, valid ways to open an asynchronous function: ``` async fn foo() -&gt; impl Future&lt;Output = i32&gt; ``` and ``` fn foo() -&gt; impl Future&lt;Output = i32&gt; ``` Yet a caller cannot distinguish between the two. Usually, we put the stuff that the caller cares about first, and the details that are being abstracted away second. e.g. we put the function signature before the body, under the guidance that the caller cares less about the body. If the caller can't distinguish between these two scenarios, it's reasonable to claim that the caller doesn't _care_ that one of them has an entirely `async` body. So it doesn't make sense to put the `async` keyword first. I think a sane syntax would amount to attaching `async` to the actual body, rather than the signature: ``` fn foo() -&gt; impl Future&lt;Output = i32&gt; async { // do stuff } ``` This is a pretty minimal language change. Arguably, it amounts to changing the interpretation of existing syntax: `async &lt;block&gt;` no longer defines an expression: `async &lt;block&gt;` takes an existing block and annotates it, such that `fn(&lt;args&gt;) [-&gt; &lt;return type&gt;] &lt;block&gt;` still matches the above input as well as un-annocated blocks.
Rust keywords and the word "test" are all disallowed (see https://github.com/rust-lang/cargo/blob/af3f1cd29bc872b932a13083e531255aab233a7e/src/cargo/ops/cargo_new.rs#L131) I believe "test" was also included since it is an existing crate which is used when executing tests, and introducing a new crate with the same name breaks stuff. See https://github.com/rust-lang/cargo/issues/2432. --- With `kebab-case` / hyphens, this is actually greatly encouraged! Hyphens look and feel much nicer than underscores in crate names, and `rustc` will automatically let you use `extern crate krate_name;` if the name is `krate-name`.
If you're writing a lot of data and the user will likely be able to erase it and keep the `Vec`'s capacity, I'd recommend using a mutable reference. This is good for methods like [`fs::read_to_string`](https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_string). If you aren't dealing with potentially huge amounts of data, though, I'd recommend just returning. You might have to allocate more data, but if the user won't be running your function in a loop anyways, it's not likely to matter too much? If you're really concerned with performance, as /u/thiez said, benchmark it. Create a benchmark of your anticipated use case, and see how much better `&amp;mut Vec&lt;T&gt;` is than returning one. --- &gt; Should passing arrays around be avoided Like the title question, this depends on exactly where you are. If you mean in function parameters, you should always prefer to take `&amp;[u8]` over `Vec&lt;u8&gt;` if you don't need to consume the data. If, however, taking `&amp;[u8]` would mean you clone it and create your own `Vec&lt;u8&gt;` anyways, you should take `Vec&lt;u8&gt;` by value so the user can avoid that extra allocation if they wouldn't have used it after giving it to you.
`use project_x::random_f32;`?
Published the first release of an [asynchronous PushBullet client](https://crates.io/crates/pb-async). I needed this as part of a webapp I'm rewriting to use `actix-web` (rather than Python/Flask). `PushBullet` is nice for sending messages directly to my phone, so it's nice to have support for it in Rust too. I'll either be working on more asynchronous libraries or building the webapp itself for the rest of the week depending on how things go.
[Playground](https://play.rust-lang.org/?gist=836c0309af9dd051eeb7d0177c6903a5&amp;version=stable&amp;mode=debug)
Sounds fun! Reminds me of [LRWETMLL (Learning Rust With Entirely Too Many Linked Lists)](http://cglab.ca/~abeinges/blah/too-many-lists/book/). Might be a fun read if you're interested in seeing many different ways to do this with associated advantages and disadvantages.
I mentioned this in a reply below but copying it here: `expect()` makes the most sense to me with messages which are in the same format, like `.expect("expected string to be a number");`. It's _ok_ to use it in other ways, but it does make it seem strange as you mention. This matches what the Rust compiler reports errors as. The general community convention is to say `"expected there to be an int, but found &lt;other value&gt;"`. `.expect()` generates error messages which match this as well: Err::&lt;(), _&gt;("hello").expect("expected goodbye"); writes thread 'main' panicked at 'expected goodbye: "hello"' As for expecting `Ok`, not sure if there's a good way to think about it other than just "I expect success". If you do need the other way, [`expect_err`](https://doc.rust-lang.org/std/result/enum.Result.html#method.expect_err) does exist! I think it's `expect` not `expect_ok` just because expecting success is a much more common thing to do than expecting failure.
Stop calling folks names. It's not in line with the CoC and it hurts your argument. Calling out nonconstructive criticism is OK though, which is why I'll let this stand. I still note that much of the criticism is constructive.
To expose `FILE *` to Rust, your best option might be to implement the `Read` and `Write` traits for `*mut libc::FILE` and expose the value as a trait object, possibly boxed. You cannot create a `std::fs::File` out of a `FILE *` because Rust's `File` only contains a file descriptor (on Unix) and would effectively ignore `FILE`'s buffer. On Unix you can expose `std::fs::File` to C by extracting the file descriptor from `File` and calling `libc::fdopen` to convert it to `FILE *`. This won't work on Windows because there `File` is a handle under the hood, so you will need to find a way to convert that handle to a file descriptor/file pointer (on Windows both are implemented in C runtime rather than being kernel objects).
I updated `smol.rs` so that my question makes sense :)
The OP mentions an array, so I assumed it has a size that is known at compile-time. I strongly agree with you if they meant a `Vec` instead :)
Pretty much. Usually binaries wouldn't do much more than setup cli args or other config and call into the lib so you usually don't have to import much twice.
Consider the following functions: fn my_panic(x: intsize) -&gt; ! { panic!("Panic: x &lt; 5!") } fn main() { let x = 3; if x &lt; 5 { my_panic(x); } x + 1 } The compiler will complain as `x` was moved to `my_panic`, but then still used later within `main`. However, the program should not be able to continue if `x` does end up getting moved. How should I handle this?
Cool! Thanks.
I probably should have come up with a more descriptive title. This post is mostly about the target feature support that is coming in 1.27.
You won't get any complaints here because `isize` is a copyable type, meaning it can still be used after a move. If `x` were a non-`Copy` type then you would get an error, which you'd want to resolve either by explicit cloning or changing the parameter type to avoid the move. 
Apart from the obvious having-multiple-mutable-references unsafety, *why* is it undefined behavior? Isn't this what UnsafeCell uses behind the scenes anyway?
You're right, there won't be any issues with the example as I stated it, so I have updated it. There's no way to let the compiler know that everything after is dead code if the branch is taken?
I have started writing a series about the subject of my [RustFest Paris talk](https://paris.rustfest.eu/sessions/lyon-vector-graphics-rendering-in-rust). It's more in-depth than the talk itself since I can go into details without fear of going over half an hour. So if you already saw the talk there may still be something for you in there. I published [Part 1](https://nical.github.io/posts/rustfest-paris-01.html) and [part 2](https://nical.github.io/posts/rustfest-paris-02.html) at the same time because I felt that the introduction was not very useful on its own and I am a very slow writer. I'm around, so don't hesitate to ask anything. Link to the project: https://github.com/nical/lyon Link to the video: https://app.media.ccc.de/v/rustfest18-7-vector_graphics_rendering_on_the_gpu_in_rust_with_lyon
Nice! One approach to reducing the dynamic overhead would be to do the check just once to work out which function to call and store that somewhere, and then later calls just load and call a function pointer. This is somewhat similar to GCC's [function multi-versioning](https://gcc.gnu.org/wiki/FunctionMultiVersioning) (except I believe that uses "ifuncs" + the dynamic linker to truly minimize the overhead). An example would be something like: type FnType = unsafe fn(&amp;[f32], &amp;[f32], &amp;mut [f32]); static FN: AtomicUsize = AtomicUsize::new(0); let mut val = FN.load(Ordering::Relaxed); if val == 0 { let fn = if is_x86_feature_detected!("avx2") { add_avx2 } else if is_x86_feature_detected!("sse2") { add_sse2 } else { add_scalar }; val = unsafe { mem::transmute::&lt;FnType, usize&gt;(fn) }; FN.store(val, Ordering::Relaxed); } let fn = mem::transmute::&lt;usize, FnType&gt;(fn); fn(a, b, c); After the first call, this consists of a (cheap) atomic load, a well-predicted branch, and a virtual call, which should be cheaper than the full `std::stdsimd::arch::detect::os::check_for` call each time.
To be honest, this attitude toward the use of `unsafe` now has me wary of ever moving from rust-cpython to PyO3 (originally primarily developed by fafhrd91 after being formed from rust-cpython). ...and cementing my existing decision that, if I extend [goblin](https://github.com/m4b/goblin/) for identifying and extracting resources from various types of `.exe` files in one of my projects rather than reinventing the specific bits I need, It'll only be after I've ensured the [somewhat `unsafe`-eager](https://github.com/m4b/goblin/search?p=1&amp;q=unsafe&amp;type=&amp;utf8=%E2%9C%93) ELF support can be `feature`'d off at compile time and patched away the two uses in the PE implementation and the two in some common code. (Failing that, I'd have to add `MZ`, `NE`, and `LE` support anyway, so it might be quicker and easier to NIH the parts for the various `PE` variants rather than getting comfortable with someone else's codebase that I'll need to audit and patch to satisfy my paranoia.)
And OS Keywords are banned on crates.io IIRC, there was a crate called `NUL` that affected Windows Users
I believe it has to do with what rustc emits to LLVM. Without UnsafeCell, rustc emits a `noalias` marker on the memory which guarantees to LLVM no one else will be writing to that data, which is not true in the transmute. 
Awesome, thanks for the helpful links. I think that `fd-rs` might do just the trick for my use case.
The use of unsafe was not really necessary too. IIRC, the more general data-encoding crate did not use any unsafe code and was faster at the time.
have you seen [dyon](https://github.com/PistonDevelopers/dyon)? not exactly what you're looking for, but possibly interesting.
It's not "ignored"; it's active violation which literally requires you to type out the characters `unsafe`. &gt; This is not a problem of Rust. Sort of. Unsoundness in the presence of `unsafe` isn't, but there is still some room for reflection. Even if you have a coherent rule set, if the rule set is too awkward for people to design real stuff in, it's still a major problem, no matter how sound the rule set is. Unfortunately, this happens a lot when you start to get into fancier type systems: for example, you'll often see newbies to dependent types completely confused as to why the compiler can't figure out that `Vec t (m + n)` is equal to `Vec t (n + m)`, and truly understanding the answer to that dirt simple issue basically requires you to know the entire language and type theory - from the evaluation model, to the distinction between propositional and definitional equality, etc. etc. Is the rule set *sound*? Actually, yes, as far as we know. But "talking" in this language is so arcane and tedious that nobody wants to do it. To paraphrase Edward Kmett on the language he designed for his own thesis: "I threw everything I could into my type system, and what I ended up with was a language I wasn't smart enough to program in." Rust is faced with a similar issue with its borrowing and concurrency model: even if the rules are *sound*, if working with them is so obtuse that library designers just avoid the rules rather than follow them, then what was the point in the rules in the first place? Rule coherence is important, yes, but equally important is the ability for real humans to actually be able to think and operate inside the ruleset.
Thanks for your help! : )
Absolutely. The "of course you don't understand the \`void\*\` machinations of my custom mutex" attitude is replaced with real accountability and a standard of transparency in hairy code.
Rust's closest equivalent to C++'s abstract classes are traits. You'd do something like `trait PlatformSpecific { ... }` and then use `impl PlatformSpecific for ... { ... }` that trait for anything you want . Beyond that, there are two ways you can do it: 1. The way that's most directly equivalent to a virtual (polymorphic dispatch) is to use [trait objects](https://doc.rust-lang.org/book/trait-objects.html). However, they're not idiomatic in this situation because they're more intended for things like mixing types with a common interface in a `Vec`. 2. The more idiomatic solution when you need to abstract for different build targets is to use conditional compilation attributes like `#[cfg(windows)]`. See, for example, how Rust's standard library [handles it](https://github.com/rust-lang/rust/blob/d52c44ea8df9f9045e6059cb2d37df743be50bb1/src/libstd/sys/mod.rs). (This avoids the overhead of dynamic dispatch.)
Nothing too exciting here, but good to see WebRender moving closer to a final shape. With the amazing work being done on Webrender (rendering and hit testing), basic text layout libraries (shout out to Patrick Walton), and winit (shout out to Francesca Frangipane) there's a foundation being laid for some amazing Rust UI applications in the future. Really excited about this! And mad props to Mozilla for taking on the challenge of making a modern renderer despite rampant graphic driver bugs, that shit is hard work.
&gt; rustc will automatically let you use extern crate krate_name; if the name is krate-name Not a confusing design decision at all.
I wouldn't used inheritance in C++ here. I would use conditional compilation, just as in Rust. // platform.hpp #if defined(PLATFORM_LINUX) # include "platform_linux.hpp" #elsif ... ... #endif // platform_linux.hpp struct PlatformSpecific { std::vector&lt;linux_struct_t&gt; someLinuxCache; } There's no advantage to using inheritance. It requires ugly casts as the usage site, and you need conditional compilation around the definition of the derived classes *anyway*, because otherwise you suddenly need a definition for `HANDLE` while compiling the Linux and MacOS versions of the code. The Rust way of doing this is with `cfg`, like /u/ssokolow points out in his link to the standard library source.
Nickel also seems nice to use.
&gt; I've generated bindings to this with bindgen which use &amp;mut (sensibly). If the functions use a mutex internally then the bindings don't need to use `&amp;mut`. However, I thought bindgen only generated the Rust equivalents of the C function calls which wouldn't use Rust safe references. Do you mean `*mut` instead? It's perfectly fine to have multiple of those pointing to the same thing because it's unsafe to access them anyway.