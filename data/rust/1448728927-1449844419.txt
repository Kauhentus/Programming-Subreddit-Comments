thanks, I'll have a look at that. 
Is RUST_SRC_PATH set in your environment variables? I had that problem on Linux until I set that in /etc/environment and restarted. IIRC, you'd do the same through the advanced system settings GUI on Windows. I would think that setting the source path in the VSCode settings should allow the extension to provide racer with the path info it needs, but it wasn't working for me until I set the envvar globally.
I guess for large-ish functions, you want to have a generic wrapper that uses `into()` around a non-generic function like this: fn foo&lt;T: Into&lt;Bar&gt;&gt;(barable: T) { foo_impl(barable.into()) fn foo_impl(bar: Bar) { // Actual implementation } } Any experience with that?
Helping improve the language itself to better suit the needs of OS developers in general is something that falls under the purview of Mozilla's Rust team (like the one that this position is advertising), yes. If instead you were talking about Mozilla sponsoring someone to work on Redox full-time, then you would probably need to present a compelling business case for them to do so. (Note that I don't work for Mozilla, so I can't speak for them.)
I get the same issue. How do you start in debug mode?
The rustic way to do this is to disambiguate on the function, e.g. `a.into::&lt;String&gt;()`. Yeah, it looks weird.
You don't need to do any special pre-allocation stuff - just print a static string - "aborting due to an allocation failure" or whatever.
Just a couple of quick changes. You don't actually need to transmute, you just need to cast the raw pointer type when creating the new slice. `self.as_mut_ptr() as *mut u8`. As for the alignment issue, you should *start* with a `Vec&lt;u64&gt;` and if you need `[u8]`, *then* transmute *down* to the `[u8]` from the `[u64]`. I also recommend aligning your RC constants. https://gist.github.com/james-darkfox/6e936f902eb555977783
I just finished my first small project in rust. It's an implementation of murmur3. Right now it is just the 32bit hash. I've already started on the 128bit variant, but I wanted to get some feedback on my code before I go any farther. I'm very much a C and Java programming, but I'd like to keep my rust idiomatic so any feedback I can get would be appreciated. Thanks!
The standard library has generally tried to maintain a convention that `unsafe` is only for things that can lead to memory safety violations (whether they *really* can is an implementation detail). We haven't been big fans of exposing it for any other purpose, but of course we can't *stop* you. Historically we've actually had bugs result from things being marked `unsafe` as a lint for other dubious behaviour, because people come to assume that the functionality can't be achieved by safe code otherwise. There have been proposals in the past to provide a "generic" unsafe, which allows one to specify something like `unsafe&lt;NoTLS&gt;` or something. These proposals have not achieved serious traction.
There's also a crate that packages an r2d2 connection pool as Iron middleware. https://github.com/martinsp/iron-postgres-middleware Usage is very simple, you just call `db_conn` on the Request struct.
You could also wrap your dangerous code behind special types that enforce awareness, so that your calls look more like this: do_the_task().yes_really(); Similar to how you have to call `expect` on a result.
Now I really wish Rust had higher kinded types and do notation!
Well, `unsafe` is IMO just making an API uglier. You have to add this extra `unsafe` block.
Yep, certainly. It's not a good solution either.
I would say it looks pretty good! I'd declare the consts outside the function itself, probably, but that's more habit than anything else. I'm never sure how often people do things like this, or use "use", either...
Awesome post! Good to see some numbers, too. It was interesting to read about your implementation of linear types. I would hope that this becomes an idiomatic pattern in safe Rust code.
Did you read the question? The question is about compiling Rust to shared library, not about compiling C. The question is mistitled, but that is no excuse not to read the question itself.
What problems did you have with hyper?
Would [Humpty Dumpty](https://github.com/Manishearth/humpty_dumpty) be useful in such settings? Does chomp use it?
Generally names (like variables, constants, type definitions and so on) should be defined in the smallest scope possible. If those constants are used only inside that function, then they need to be defined inside the function, to be invisible outside.
The instructions can be found the github page.
rustfmt allows you to either format a single file (piping the file from stdin) or formatting the whole project. I'm not sure which is used by the Atom integration. For formatting single files, however, there's this similar problem: https://github.com/rust-lang-nursery/rustfmt/issues/562 Unfortunately, fixing it properly will be difficult, because rustmft uses syntex_syntax, which is just a crate mirror of the "official" rust libsyntax. I'm not sure if patching libsyntax to optionally not follow mod paths is an option. I've fixed it in my local build of rustmft by ignoring all parsing errors but I'm hesitant to submit it to upstream, since it introduces more problems.
I have not heard of Humpty Dumpty before, looks like an interesting plugin. Sadly I am writing Chomp for stable rust (works on rustc &gt;= 1.2, since `bitflags` requires 1.2), and cannot include plugins by default. If I was making it for nightly I would write the `parse!` macro as a plugin since that would enable much better parse errors (`error: unexpected token: `@` &lt;chomp macros&gt;:8 __parse_internal ! { @ ACTION_NONTERM ( $ i , $ v ) ; $ ( $ t ) * } } ; (` is not so good whenever someone accidentally writes a bind-statement at the end of a `parse!` block). Thank you for the link, I am going to take a look and see if I can use it to at least validate the chomp crate.
A custom lint with what, clippy?
Just a comment: with macros in method position, one might perhaps be able to write this: i.parse! { let method = take_while1(is_token); take_while1(is_space); let uri = take_while1(is_not_space); take_while1(is_space); let version = http_version(); ret Request { method: method, uri: uri, version: version, } } The other thing I wanted was to be able to use keywords inside macro blocks as if they were identifiers (so `return` instead of `ret`)
I recommend you use a trait that is unsafe to implement, something like UnsafeFrom&lt;T&gt; and implement it for the integer types. I don't know if there is some way to get an invalid state for a float (I don't think there is) but if it isn't then you'd do the same for them, and have UnsafeFrom&lt;[u8; n]&gt; for each (with n the size of the type, obviously). You could even do the actual implementation using macros. If you're doing this I recommend you make an UnsafeInto&lt;T&gt; implementation that is automatically implemented for any types with a matching UnsafeFrom, just like the regular From/Into. Actually, now I'm thinking of it, I might do a pull request/RFC to implement From/Into for these types in the stdlib, as I don't think it's actually unsafe. EDIT: After talking it over with some IRC folks I was directed to the [byteorder](https://github.com/BurntSushi/byteorder) crate, which I recommend you check out. It has implementations of these functions with the added bonus of not assuming the order of bytes on the consumer is the same as the order of bytes on the producer.
&gt; The other thing I wanted was to be able to use keywords inside macro blocks as if they were identifiers (so `return` instead of `ret`) I must admit I am wondering about `ret`; I mean, there is a `let` already so why not a `return`? I suppose there is a specific issue somewhere... 
And it's also really easy to grep for!
Oh, it looks like you already can use keywords. In this specific example, I think that writing the return value without `ret` (and disallowing a `;` after it) would be more Rusty, but I'm not sure whether the grammar would become impossible to parse with macros.
I don't believe it's possible to do it generically without constfn and possibly type-level integers (or more generally dependent types), and even that might not be sufficient (e.g. you'd probably want to statically assert that `size_of::&lt;T&gt;() == size_of::&lt;Self&gt;()`, I'm reasonably sure there's no support for that currently) All you can do is define an `UnsafeFrom&lt;T&gt;` similar to From except without any semantic guarantees, and then implement e.g. `UnsafeFrom&lt;[u8; 4]&gt; for u32`, I think the trait would need to be unsafe because nothing stops you from implementing inane stuff like `UnsafeFrom&lt;f64&gt; for String`
Python has them too. But they are not enforced.
Yeah, I don't think it's going to work as `transmute` does not allow you to use generics, so I just gave up this dream and resorted to using enums.
It's called the "newtype pattern", using tuple structs: struct EventID(i32); struct WindowID(i32); http://doc.rust-lang.org/book/structs.html#tuple-structs
The `#[deprecated]` annotation will have a `note` field that you can use to voice your concerns. This will be written out in the rustdoc and the deprecation warning.
After asking, I just saw that (unstable) compiler plugins can define not only macros, but also lints. What are the differences between rustc lints and clippy lints? Do writing a lint for either share the same API?
thanks for your answer already, but I can't even understand how that would work with serde. Unfortunately, that enum type I'm dealing with is part of a large type hierarchy, so I have to make the decision what kind of thing to deserialize to inside the deserialize() function. Can you show how you did it? edit: aha. There's a serde_json::from_value that can help. I guess that's the route I'll take, then...
You might as well use the [byteorder](https://crates.io/crates/byteorder) crate.
There was some talk along these lines in rust crypto about marking the low level prone to foot gun, really you shouldn't be using primitives as unsafe functions, forgot how it turned out and why. 
Looks great, thank you!
This is the resource you are looking for: [Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/)
You're welcome :)
While tuple structs are the current approach, I've always really liked F#'s approach to this, with their "Units of Measure" feature: http://fsharpforfunandprofit.com/posts/units-of-measure/ I'd love to see something like this approach pop up in more languages.
They work the same way - clippy is a collection of generally useful rustc lints.
Ok, glad you found it. Like I said...not elegant.
`str.split_whitespace().next().unwrap()` will never fail, even though its a runtime value.
So, to use clippy, one needs to run unstable Rust? Is there a way to run lints (using an external program maybe) in stable Rust? (just like there is syntex to run procedural macros in a build script)
Cargo source doesn't exit, that's a link to the issue on cargo requesting it. :-) I would expect cargo source to fetch the source of a specific crate if its an arg (e.g. `cargo source serde`) or to fetch all of the dependencies if there's no such arg and you're in a crate directory.
I really want to get into F# just for that. There is a library for Python I use called [Pint](https://pint.readthedocs.org/en/0.6/) - unfortunatly it can be quite verbose unless you `import *` or something. I'd love Rust to have it since it's a compile time validation of types - Rust is all about that. I'm not sure how you'd go about it - I guess you could use macros everywhere to check operations but I don't know if there is a general way of defining the interaction between types without generating the code for every possible unit. EDIT: OK a preliminary google shows [someone managed to do this](https://github.com/Boddlnagg/units) and the unit arithmetic is handled in the types. A bit above my head as to how it works but it looks fantastic.
Thanks for doing that, I wanted to make sure I wasn't making a mistake first!
I don't see what's so special about all this. This is just a special case of generic code with a little bit of syntax sugar. it's possible to implement in any language with generics/templates. The only difference to the current rust approach would be the syntax for literals which isn't hugely important anyway since good code should avoid "magic numbers" anyway and instead define named constants. 
For completeness' sake, in C++ you would: 1. Use [`BOOST_STRONG_TYPEDEF`](http://www.boost.org/doc/libs/1_59_0/libs/serialization/doc/strong_typedef.html), although it has the potentially undesired effect of allowing implicit conversion from "original" type to "new" type 2. Just create a generic wrapper type `struct Wrapper&lt;T, V&gt;` where `V` is a *validator* (a functor `bool(T const&amp;)`) and then `typedef Wrapper&lt;int, WindowsIdValidator&gt; WindowsId`; the `Wrapper` is constructible, copyable if the base type is, and provides a `T const&amp; get() const` method. I personally prefer the second way in general, as I usually have invariants to maintain.
No. The API is completely unstable, and we need more than an AST.
The idea is to not modify the dependency in any way (that is, not clone into a separate directory, etc), just to run a quick &amp; dirty test on it while building. Cargo clippy? Is that a command?
Would a similar "dangerous" annotation make sense?
There is lots of nice dimensional analysis that goes on with F#'s UoM. This is simply not possible in Rust right now.
Yeah if you put it that way, then racer should use that API as well.
You're very welcome. Perhaps adding the lint as an optional feature (which will of course require nightly) would given you the best of both worlds?
Or use the `RUSTC` trick!
I didn't expect that it's so complicated. I'd rather think it should be build in rust... something like `#[warn(unwrap)]` since one of the main features shown on the rustlang page is "threads without data races". Why to invest so much effort in "safety" if a `unwrap` of a tiny bad dependency can kill your whole thread?
Same problem here, also on Windows (10) 64-bit. I'll try digging into it more sometime later, though hearing that it doesn't reproduce in debug mode doesn't sound great for my prospects of success.
`.unwrap()`/`.expect()` are assertions. Would you also lint against `assert` calls and indexing? I'd rather my dependencies were written defensively and used asserts rather than blindly going horribly wrong. Yes `.unwrap()` can be used wrongly as a lazy alternative to error handling, but so can asserts and indexing (imagine indexing using an index read from a socket). There's no way any lint/compiler could distinguish between correct uses of `assert` versus wrong ones. **Edit:** There's loads of discussion in [this similar thread](https://www.reddit.com/r/rust/comments/3pn25i/should_unwrap_be_banned_or_discouraged) if you feel like going down that rabbit hole.
I was looking at that, but the `ReadByteExt` trait from byteorder wasn't defined for `std::io::File`. I would have just ended up implementing all of these same functions over again.
Worth noting: Sean maintains Rails's ORM, ActiveRecord. This is very much NOT a port of it, but he's got a lot of experience in this area, and this is a project I'm really excited about.
I like to think of it as where I can fix all the problems that I can't fix in Active Record. \^_^
Yeah, I've been thinking about it too. But it doesn't implement operators and stuff, I think. Maybe doing some magic with macros and generics would work.
Just to note that there's [contenders](https://crates.io/keywords/orm) - perhaps the most developed is [rustorm](https://github.com/ivanceras/rustorm).
Yeah, that's what you need to do. serde_json is stream oriented and tries really hard to minimize copies, so it's not currently able to do backtracking like this without going through the Value type. I've been waiting to see if/when specialization lands before doing a rewrite to make it more friendly for parsing things multiple times like this. Would (and /u/tiny_fishbowl) mind going into some more detail about why you want to parse the type multiple times. Is the only distinguishing factor for you the type and number of items in your variants? Do you have a particular reason why this is the case?
You should be able to do: let num_s = num.to_string(); [..., num_s.as_bytes(), ...] I.e. separate creating the `String` from taking a reference into it (and taking a reference is essentially what `as_bytes` does). This means that the thing the reference points to lasts for longer, instead of just being deallocated at the end of the statement.
Rust definitely has a learning curve, but after you'll learn how ownership and borrowing works this kind of "fighting the typesystem" goes away. (There may be a little problems when trying to directly translate code from another language, eg. C++, but you should be able to notice that when designing, not when trying to compile that). Speaking of your particular case, it's really weird that `&amp;num.to_string().to_bytes()[..]` had work for you in place where `num.to_string().as_bytes()` didn't. This is basically the same operation. (And instead of `[..]` after you should be usually able to just write `&amp;` before). In general, if `[]` is an argument of function call, or some other expression, ie.: foo(&amp;[slice1, num.to_string().as_bytes(), slice2]); you should be able to allocate a string here. Objects created inside of expression do live till the end of the expression (usually to the next `;`). The next thing, is that when you want to put something up front, you should store the fully-owned version, so: let num = num.to_string(); // put the string here [ ..., num.as_bytes(), ...] // and borrow it afterwards The last thing is that peryou should be able to use `format!` or `write!` macro in your code: let string_to_send = format!("{}{}{}", string1, num, string2); // or even write!(stream, "{}{}{}", string1, num, string2).expect("failed to write"); These macros are not only convenient, but also performant. The `write!` doesn't even make any temporary allocations (neither for full string nor for the temporary stringified `num`).
Is there any reason this wouldn't work? let num_string = 1.to_string(); let slices: [&amp;[u8];1] = [num_string.as_bytes()]; The combination of lifetimes and things like slices can be confusing at first. When you tried to call num.to_string().as_bytes() the thing that doesn't live long enough is (num.to_string()) since as_bytes tries to take the a slice of the string data but since the string doesn't actually exist once that statement finishes, the result of as_bytes wouldn't point to the data anymore. If you had instead called ```into_bytes``` which actually takes ownership of the string from https://doc.rust-lang.org/std/string/struct.String.html fn into_bytes(self) -&gt; Vec&lt;u8&gt; // note the function takes self [&amp;1.to_string().into_bytes()] Then you wouldn't have any lifetime issue. Note that the &amp; won't actually be allocating anything, it's just coercing the Vec&lt;u8&gt; into a slice
thanks for the link to the thread, it's really interesting :)
The `[...; 1]` isn't the number having one digit; it is a fixed sized array of length one. That is, `[&amp;[u8]; 1]` is storing one byte slice, and that stored byte slice can have any length. It could also be written: let num_string = 1.to_string(); let slices: &amp;[&amp;[u8]] = &amp;[num_string.as_bytes()]; Or, if there's more than one slice: let num_string = 1.to_string(); let slices: [&amp;[u8]; 3] = [slice_a, num_string.as_bytes(), slice_b]; (Or the type annotation could be left off entirely.)
exactly! There are parts of an application where this is not so critical but at least the parts that are should be aware of these panics. IMHO
Actual valid Rust: #[derive(Eq, PartialEq)] struct WindowsId(i32);
Exactly. You implement what makes sense, and don't implement what doesn't There's a good CPPCon 2015 talk about it... edit: https://youtu.be/jLdSjh8oqmE Kyle Markley's "Extreme Type Safety with Opaque Typedefs"
for sure. mine is actual valid c++ too.. was just replying to the "how we'd solve this in c++" comments
Oh, I just saw it as [u8;1]. I understand borrowing and ownership, its more of having to look everything in the standard library up to see what returns a slice, or a vector, or if the contents are mutable or not or whatever to make it work. In the name of simplicity why doesnt STD, when it has to return a pointer, use something like std::borrow::Cow? It doesnt use anything if it doesnt have to. 
Awesome thanks, this looks like it will make life easier then
Even if you do "naked sql", you should never build query strings with string concatenation. You should always bind parameters like the example in the [READMe of rust-postgresql](https://github.com/sfackler/rust-postgres) does: &gt; conn.execute("INSERT INTO person (name, data) VALUES ($1, $2)", &gt; &amp;[&amp;me.name, &amp;me.data]).unwrap(); (here the library is using `$1` and `$2` - but more common is to use `?` to bind variables). Note it doesn't have trouble with SQL injection. Unlike, say, the following example: &gt; conn.execute(format!("INSERT INTO person (name, data) VALUES ({}, {})", me.name, me.data)).unwrap() By using `format!`, we're essentially building a string that's the concatenation of `""INSERT INTO person (name, data) VALUES ("` with `me.name`, then `", "`, then `me.data`, then `")"`. But that's insecure. So we never do this.
&gt; (here the library is using $1 and $2 - but more common is to use ? to bind variables). This is not possible with Postgres, is it?
Will you use database-specific features on each database? What about using optional dependencies for specific databases, like [rust-postgres](https://github.com/sfackler/rust-postgres) or [rusqlite](https://github.com/jgallagher/rusqlite)?
Yeah that binding stuff is generally what I do, save for one awful php db project I did for school before I had a clue..... 
I totally dig this project, but I have to say, I *wish* `unwrap()` was not a thing. let connection = Connection::establish(env!("DATABASE_URL")).unwrap(); let users: Vec&lt;User&gt; = users::table.load(&amp;connection).unwrap().collect(); I get it, it's showing how to use it, but... unwrap() causes panics, which are the single most common cause of rust application failure. Don't unwrap things! *Certainly* don't unwrap things without checking them first. Using `match`, even in examples... it's not that bad. 
What would the example do in the `Err` case? Example code uses unwrap so that it can focus on the thing it's showing off and not on error handling code.
Good, one less thing to worry about then... Of course xss still exists
&gt; Yes... but people copy and paste the example, complete with the total absence of error checking. Are there any examples of this actually happening? I think we talk a lot more about whether or not examples should unwrap than people copy paste unwrapping examples into their Rust projects. 
Playing with word game solvers, notably including a really fast and small trie implementation with bit vectors. I plan to put it up as a crate after some polishing.
It happened all last week with people using Piston on #rust, that's why it springs to mind today. /shrug Well, anyhow. Write whatever examples you want, but I can say, *categorically* that yes, people copy code examples with `unwrap()` in them, and then complain when panics happen.
And even if they do: it's not the best, but it still doesn't give you memory unsafety, it's fairly easy to debug. Unwraps are much more problematic in library code, because they restrict your choice in how to handle errors, you can't really. But in application code, it just affects you.
But then they learn not to do that, and the problem is solved. Its the best kind of problem: it appears fast, its easy to resolve, it does not recur, and it doesn't spread beyond its source. People are going to learn about unwrap one way or another.
Ah, right, query parameters use `?` while user defined variables use `@foo`.
MySQL absolutely accepts `?`
I will be supporting database-specific features as best I can. If you aren't coupled to your database, you aren't doing anything with your database (which can do very interesting things!). At the moment we're tightly coupled to Postgres. In the future, I might pull database specific features into a separate crate. I've designed it to make that possible, as best I can.
I completely agree with you. It basically came down to the amount of time I had for docs. Pull requests are totally welcome!
&gt; Diesel gets rid of the boilerplate for database interaction I kind of feel like there's still a lot of boiler plate. A lot of the DB stuff I end up doing is in PHP (unfortunately). A lot of the APIs there simply take and return PHP arrays (which are really ordered maps, like hash's in many languages except order of keys is preserved) and arrays of arrays (PHP arrays can also be numerically indexed like, well, arrays). From a type-safety standpoint, this is terrible. But from a lack of boilerplate standpoint, it's great. I don't have to create a struct for every query that I run. I do appreciate that you seem to know what you're doing. You allow separate structs from inserts and updates compared to selects. You're aware of not just the "what do I do about the serial id column" issue when doing selects, but you also realize/acknowledge that other columns have default values that you want to use. And you're aware of "RETURNING". (Though you didn't implement it for DELETE for some reason?) Ideally, I should have to type column names when I write my query (unless I'm selecting *), and then I go to use a particular table cell, and that's it. So I guess one of the ways I judge any SQL library is how many additional times I have to repeat my schema. You don't do great in that category, IMHO, but I've seen much, much worse. Type inference has solved one of the huge annoyances of statically type languages. It makes them look more like dynamic languages, but they still prevent errors at compile time and not runtime. I don't know how, but I'd love to see the same thing done for SQL in statically typed languages. 
&gt; If you aren't coupled to your database, you aren't doing anything with your database (which can do very interesting things!). I completely agree with that, and I'm pleased to see someone writing an ORM saying it.
&gt; I kind of feel like there's still a lot of boiler plate. Can you elaborate? I'd like to fix this. &gt; (Though you didn't implement it for DELETE for some reason?) Mostly because it wasn't super important for 0.1. I definitely will. &gt; You don't do great in that category, IMHO, but I've seen much, much worse. I think the best I can do is twice. Once for the model, and once for the struct you use for insert (potentially three times if you have a separate struct for updates). I do intend to replace the `table!` macro with something automatic at compile time eventually. I would love to get that number down, as I agree it's annoying as hell. It's a hard problem to solve though, and I think creating entire structs through codegen would be more confusing than not. Anyway your points are all valid, and I'm definitely open to discussion. 
https://github.com/sgrif/diesel/issues/34
Lovely! As the author, are you planning on using it for any of your personal projects?
Yes I just spent I fair amount of time eradicating unwraps() in my project this week. My project started as a frankenstein's monster of example code, complete with a ton of unwraps. I still haven't gotten rid of all of them. If you have unwraps in example code, expect noobs to use unwraps in their projects.
Unwrap is very useful, and trivial to write yourself. What you actually are asking is to eliminate panicking from the language, which I made a comment about actually [an hour ago](https://www.reddit.com/r/rust/comments/3uqeau/cargo_how_to_warn_on_unwrap_usage_within/cxhn4ge). (I thought this was a reply to that comment at first!)
Very cool, I've been waiting for something like this for a very long time. Hopefully MySQL support comes soon, as that's my db of choice. &gt; We make extensive use of unit structs to make this happen, meaning many queries have a size of zero. Since a zero-sized type can contain no useful runtime information, this means that the construction of the query is guaranteed to get eliminated by the compiler, resulting in code as fast as if you’d hand rolled it. Can you elaborate on this? It sounds interesting, and others might find this technique useful in their own code. It might even be worth a blog post about `diesel` internals.
&gt; fn users_with_name(connection: &amp;Connection, target_name: &amp;str) &gt; -&gt; Option&lt;Vec&lt;(i32, String, Option&lt;String&gt;)&gt;&gt; &gt; { &gt; use self::users::dsl::*; &gt; match users.filter(name.eq(target_name)).load(connection) { &gt; Ok(x) =&gt; Some(x.collect()), &gt; Err(_) =&gt; None &gt; } &gt; } Wouldn't something along the lines of `result.ok().map(|x| x.collect())` (or `result.map(|x| x.collect()).ok()`) work?
I wish, but it does not work. [This code](http://is.gd/vNTcl7) fails with: &lt;anon&gt;:10:22: 10:38 error: does not take type parameters [E0035] &lt;anon&gt;:10 println!("{}", a.into::&lt;String&gt;()); Edit: You can do `String::from(a)`, but I was wondering if anything else is more Rustic/elegant. 
Please, provide some context :) What os do your use?
One more helpful rule (I guess you know it, but I'll explain for the others): Method named `as_foo()` borrow and return references (and are really cheap), while methods named `to_foo()` build and return new, owned value. `into_foo()` also returns standalone value (such as `to_*`), but consume the caller. To give examples: * `string.as_bytes()` -- zero cost conversions, return borrowed value. * `foo.to_string()` -- allocates new string with the representation of foo. * `string.into_bytes()` -- "transmutes" the string into vector, with no allocation. You can't use `string` afterwards.
We should be able to do that using macros – this would probably look a bit like: #[measure] struct M; This could also implement Mul and Div, so that you could write: let distance = 1.0 * M; let time = 2.0 * S; let speed = 2.0 * M / S; let acceleration = 2.0 * M / S / S; let force = 5.0 * KG * M / S / S; Actually this wouldn't be a lint but a procedural macro. Btw. The only thing that keeps dimensioned from working with arbitrary units is the lack of a type-level map from unit to number, but this is certainly feasible within the type system.
[Like this?](https://play.rust-lang.org/?gist=5ab765feb11c6ec2479b&amp;version=stable) If you're not using references you'll have to dereference to get at the inner value (if you are using references you can just use [deref coercions](http://doc.rust-lang.org/nightly/book/deref-coercions.html)) but I would say that that's a small price to pay. Edit: [Now with more macros and generics!](https://play.rust-lang.org/?gist=9a1ddd6426c9925159ee&amp;version=stable) Edit2: [You can even add Trait constraints!](https://play.rust-lang.org/?gist=330c7f054d8c20046566&amp;version=stable)
Currently the way to allow a multitude of type numerals (so we can express something like *m*/*s*², which means we need an exponent of 1 for *m* and an exponent of -2 for *s*) is to have a tuple of type-level numbers where each position within the tuple corresponds to a unit However, this is not the only way to express a multitude of units. We can already create type-level lists (which typenum uses for arranging bits), so it would certainly be possible to do a type-level linear search for a unit in a type-level list of `(unit, exponent)` tuples (which would be the basis of a very naive map implementation). Doing this would only require to define a unit struct and `impl Unit for _;`. The macro would only be there to define constants for the units and implement unit level arithmetic.
Zero-sized types are described [here](https://doc.rust-lang.org/stable/nomicon/exotic-sizes.html#zero-sized-types-%28zsts%29) if you are asking about them.
Removing `unwrap` from the `Option`/`Result` types doesn't really solve the fundamental problem at all, programmers will always find ways to be lazy, e.g. `operation().unwrap_or(|| panic!())`, or `match operation() { Some(a) =&gt; a, None =&gt; panic!() }`, or, worse, for code that doesn't need the value in the `Ok` variant, `let _ = operation();` which will silently continue even when an error occurs (the `unwrap` form at least flags that there's something weird happening). Both of those don't-silent-ignore options are harder to track down than just grepping for `.unwrap(` and `.expect(`, and are thus much less good for e.g. quickly sketching out : there's a lot to be said for having a "standard" and structured way to handle errors by crashing. (Languages with exceptions have this, by just not catching the exception: `unwrap` is at least explicit.) (NB. this is true even if panicking wasn't a thing, e.g. `operation().unwrap_or(|| process::exit(10))`.)
&gt; In the name of simplicity why doesnt STD, when it has to return a pointer, use something like std::borrow::Cow? It doesnt use anything if it doesnt have to. Another reason to not do this, beyond the semantic impacts, is that `Cow` isn't free: a reference is just a machine pointer (or a machine pointer and a pointer-sized piece of extra information, for references like `&amp;[T]` that point to dynamically sized types ) that doesn't have a destructor/any clean-up code, and so is super-cheap and optimises well. On the other hand, a `Cow` type like `Cow&lt;str&gt;` is the size of 4 pointers, even for the borrowed case (it needs to have enough space to store a `String` (3 words), and the enum discriminant (1 byte plus padding)), and has clean-up code that may or may not be eliminated. Hence, code using `Cow` is likely to run slower and be larger (once compiled).
I'm seeing people panic and destroy the current thread (which could be the main thread) when invalid parameters are passed to functions. An example from a Rust [de]serialization library: impl &lt;'a, T : PrimitiveElement&gt; Reader&lt;'a, T&gt; { pub fn get(&amp;self, index : u32) -&gt; T { assert!(index &lt; self.len()); 
Continuing to work on [imap-rs](https://github.com/insanitybit/imap-rs) for a type safe IMAP client. I'm using Regex right now as a crutch to help me continue to develop the API but the bulk of the work will be building the parser. I'm still trying to figure out some of the details of the RFC that may mean annoying API changes, but nothing too bad (error handling may change). I've also got to make a few API changes to my Google Safebrowsing Lookup client [here](https://github.com/insanitybit/gsblookup-rs) to have a more generic interface.
Perhaps if panicking is less convenient than properly handling the error, people will properly handle errors more often. IMO the compiler ought to verify the presence or absence of panics and warn you accordingly, so you don't have to rely on grep. For instance, if library code has the potential to crash my program because someone left an unwrap in there, I'd like to know. Even better, designate code capable of panicking as unsafe.
I just discovered this morning that the problems with hyper I mentioned last week also happened with tiny-http, except that they are much rarer. Maybe I'm hitting an issue with the stdlib itself. I'm going to wireshark what happens the next time the data written to the socket don't make it to the browser. 
Thank you my bad
Thank you sir! PS. It will be so sweet to have this built into Cargo.
Sure, but that's not actually my question. Are you saying it can't be expressed inside the &lt;Thingy&gt;?
I had similar problems a while back with hyper that turned out to be caused by https://github.com/hyperium/hyper/issues/368 . The default number of threads in the threadpool is 5 and a single chrome connection will happily eat all of those with aggressive parallel connections and keepalive. Putting nginx in front of it solved the problem - nginx can handle keeping all the connections alive and just forward individual requests to hyper.
ORMs eliminate an awful lot of drudgery for basic CRUD work, and if they're well constructed they also prevent you from making common concurrency mistakes (for example: a good ORM will version objects, and perform optimistic locking to ensure that you can detect if concurrent modifications are made). My experience is that concurrency-correctness is actually the biggest advantage for (good) ORMs: it's something that developers who aren't well educated in database systems (and their varying locking strategies) typically get wrong a *lot*. Obviously they can also encourage lack of thinking about performance aspects, and blindness to the capabilities of raw SQL - but I think a good ORM is useful in the toolbox of a well educated developer.
Man, I have been thinking for months now that `Copy` was the expensive one. Glad you pointed that out.
Well, if attributes can be attached to blocks, something like this could work: #[line 10 "grammar.y"] // line 51 generated.rs { // line 52 generated.rs foo(); // line 10 grammar.y bar(); // line 11 grammar.y baz(); // line 12 grammar.y } // line 56 generated.rs EDIT: formatting
Author here, as of right now most of the groundwork for Collenchyma has been done and the first BLAS operations are working. While our primary goal is to use Collenchyma for machine learning, it aims to also be usable in other domains that benefit from accelerated hardware. Any feedback or question is highly appreciated :)
The query builder is also a thing to mention here. SQL strings aren't safe, and aren't checked by the compiler. Using a query builder is basically the same reasoning as why you would use Rust over evaling a string in JS
I don't know anything about this library you're quoting from, but there are identical boundschecks in the standard library, in the implementation of Index on vecs and slices. This is sometimes idiomatic, just like unwrapping is sometimes idiomatic.
Yes! I've also been porting crates.io over to it to help explore the APIs in a real world scenario.
Also FWIW, I like SQL too. Databases are good at things, and I'm trying to make sure we take advantage of them.
Was going to work on my newbie Rust skills, but had an hard drive failure on the laptop. No data lost, but I get to upgrade to SSD and will probably go 100% Linux instead of running a VM. Was wondering what editor is a good fit for Rust on Linux?
Another approach to solving this is labeled arguments, e.g. in OCaml: let do_window_thing ~event_id ~window_id = ... do_window_thing ~event_id:my_event_id ~window_id
One of the key elements of relational algebra is the ability to alias tables and columns, and to be able to refer to those aliases. This makes stuff like self referential joins or other complex join scenarios possible. You can see this in the wiki article: https://en.wikipedia.org/wiki/Relational_algebra I only took a cursory look at this, but it looks like it does not (yet?) support aliasing. This is a hugely important feature IMO, and one I often find is an afterthought in other ORMs, yet it's absolutely critical to writing complex queries. I really, really like the API in general, and I hope this can become one of the missing pieces in the Rust ecosystem.
&gt; for types that are Clone but not Copy you probably don't want to be doing a Clone for every iteration of the loop. This is not how rust works, though, it's actually borderline Clone-FUD! :-) Clone is simply user-defined copying, Copy is for primitive type-style copying. Sure, the latter is *often* cheap, but the former is often that as well. Also, there is no clone per iteration in the code.
Which `cargo clippy` should already be doing, no? Also it should be noted, and be somewhat obvious but `clippy` requires a nightly `rustc`. 
Also if you have cycles to spare, [RustDT](https://github.com/RustDT/RustDT) is quite a good IDE for Rust.
We don't support doing anything interesting with aliasing yet, but the ground work is there: http://sgrif.github.io/diesel/diesel/expression/expression_methods/global_expression_methods/trait.ExpressionMethods.html#method.aliased For now it's only really used for `WITH` statements.
Unwrap is not a marker for come back and fix me later, unwrap means either: * Though the type system doesn't know this call can never fail, I know it will never fail. A trivial example of this that I like because it uses only std and no other logic is `str::split_whitespace().next().unwrap` * There is no better solution to this error than panicking. Usually you want `expect` for this because then at least you get a nicer error message. And this case is unlikely to come up in a production program, in which you'd want some sort of logging/exit screen logic when you fail. But sometimes, this is what you want; examples are a good case of this. `try!` is not the only alternative to unwrap. You can use `unwrap_or` and provide a default value. You can use monadic composition methods like `or_else`. You can use `match` to implement some other logic. Maybe you want to return it directly, not through try!. And if you are returning a Result from this method, the type of the error case is not always obvious. If your calls return multiple kind of errors, what do you want to do? Do you want to return a Box&lt;Error&gt;, do you want to create your own error enum, or do you want to handle all but one type locally? There's a long section of the book about all the ways errors can be handled. So examples tend to make the decision whose wrongness will become most immediately apparent, instead of one whose wrongness will only become apparent when it has pushed you into creating code that isn't factored correctly for your use case.
Whoops, sorry for missing your question over there. I stopped checking it when it seemed to get no traction. XD I did an episode of [The Bikeshed](http://bikeshed.fm) recently where I talked about our various `update` APIs, and how I wish I could get rid of all of them and just have `attributes=` and `save`. I don't know if I've ever come up with a list. There's definitely a lot of things I'd remove. I think a biggest benefit is just being able to recognize some of the things that commonly cause issues. 
Were "experimenting with rust" and "language of the month: rust" posted on reddit? I didn't see them previously.
Thank you so much for the detailed feedback. I did clean up based on your feedback. On the mutable reference, here is how I understand what is happening. It accepts a mutable reference to Read, which is a reference to something else that may or may not be mutable itself. In my case in the unit tests it is a cursor wrapping an immutable string, but it could be a file, socket or some other source of data. The cursor needs to be mutable since it is tracking its place in the data, but that doesn't mean the data it references is mutable. Is this correct? I wanted to use this function for strings or for large files, that's why I accept a Read instead of passing the data itself.
I'll set both up this week. Thank you.
Those are all good options! IMO if example code picks an error strategy and follows it, that will sometimes be a valid thing to do, versus unwrap which is always wrong. Its just as easy for me to change try! to match as it is for me to change unwrap to match, if that's what needs doing. And if try! is what I need, I don't have to change anything. Re split_whitespace(), that's interesting... if for some reason I know I have a string containing non-whitespace then yeah I guess it won't crash. However with whitespace it crashes. Am I being obtuse here? Why would I not check this? fn main() { let blah = " \t\t".to_string(); let wha = blah.split_whitespace().next().unwrap(); println!("wha: {:?}", wha); println!("Hello, world!"); } and the result: C:\Users\bzzt\rusttest\meh&gt;.\target\debug\meh thread '&lt;main&gt;' panicked at 'called `Option::unwrap()` on a `None` value', ../sr c/libcore\option.rs:367 
Would be interesting to compare doing a request with diesel vs writing one in rust-postgres as benchmarks
Have you considered just using a debugger? That aren't that difficult and are surprisingly useful. 
OK, then that's the best solution. Maybe we should have a clippy lint for instances where a trait method and an inherent method have the same name, because that one's a footgun (Edit: Note we do have a lint, but only for standard traits, not all traits in scope).
I don't believe they were. You're free to post them if you'd like. :)
Debuggers are nice, I should probably use them more. But a pretty common workflow for me is to only know what I'm looking for once I have a log file of what happened.
Interesting! I'll have to take a look at the source sometime. 
Now that this is done, I plan to start working on my two next steps: - glutin integration, so that it works out of the box as much as possible - server bindings, to allow the creation of wayland servers in Rust
So cool, but the link to the doc is broken :'(
Protip: instead of writing `Copy + Send + Sync + 'static + Any` everywhere, use trait Message: Copy + Send + Sync + 'static + Any {} and then receive&lt;Args: Copy + Send + Sync + 'static&gt;(&amp;self, message: M, context: ActorCell&lt;Args, M, Self&gt;) Becomes receive&lt;Args: Message&gt;(&amp;self, message: M, context: ActorCell&lt;Args, M, Self&gt;) 
If you're on a supported platform, you be [interested](http://huonw.github.io/blog/2015/10/rreverse-debugging/) in [rr](http://rr-project.org/). The debugger becomes the log file.
I guess /u/Wolenber is assuming you're already using a custom trait as a constraint, so adding a bound to that trait will not require making changes elsewhere.
&gt; Is there something like that in std? Takes a reference, and if you use it past its lifetime, it will copy it to the stack and then return a refernce to the stack? Not automatically; but something like `.to_owned()` will do the copy if you need to. &gt; Sorry about picking you brain, but is there anything that is like Box for the stack, where it uses the stack of its parent, and then passes itself as as a reference? I'm sorry, but I don't really understand it. Your example can look like this, right now: fn foo() -&gt; i32 { 8 } fn main() { let mut integer = foo(); loop { integer += 5 } } 
&gt; num is converted to a reference string, which is then converted to a vector (so you have ownership) its not a reference, so you get the lifetime of whatever the brackets are and the new reference is still valid No; `to_string` returns a `String`, which doesn't contain any references. Firstly, that code doesn't compile, unless you're using something other than the standard library. Maybe you mean `.into_bytes()`? Assuming that, the difference is a difference in how borrows are treated between method calls and the `[]` syntax. The latter is a little more flexible, the compiler is a little more eager to connect the dots and push things into longer-lived temporaries with `[]` than with plain methods. Basically, using `[]` will mean the compiler rewrites the code as let temporary = num.to_string().into_bytes(); let array = [..., &amp;temporary[..], ...]; // use array... while the `as_bytes()` version is like let array = { let temporary = num.to_string(); [..., temporary.as_bytes(), ... ] }; // temporary is deallocated here // use array... and so requires manually promoting the temporary outside of the array. I filed [#30127](https://github.com/rust-lang/rust/issues/30127).
Also this will probably need: impl&lt;T&gt; Message for T where T: Copy + Send + Sync + 'static + Any {}
I'd recommend turning `actors.rs` into `actor/mod.rs` and then changing `actor_cell.rs`, `actor_ref.rs` and `actor_system.rs` to be submodules of the `actor` module, i.e. `actor/cell.rs`, `actor/ref.rs` and `actor/system.rs`. Looking forward to how this lib turns out :) I've never used an actor lib myself, but i've always been curious.
&gt; You can’t have size of type at compile-time. What about http://doc.rust-lang.org/stable/std/mem/fn.size_of.html ?
How would you combine traits that have associated types? Specifically, if I want to enforce that implementers of a trait `Thing` also implement something like `Add`, how would I go about this; such that I can use the trait anywhere I could some other trait, like `x: Box&lt;Thing&gt;`?
I've released new version with fixed alignment. There is just one thing which bothers me. Benchmark performance drastically dropped. `[u8; 200]` - 1,221 ns/tier `[u64; 25]` - 2,159 ns/iter is there any reason for that?
Ah, I see.
Just to repeat, because this was somewhat buried in the article: Servo is now a multiprocess browser, using the [gaol](https://github.com/pcwalton/gaol) crate for sandboxing. This adds (a) an extra layer of defense against remote code execution vulnerabilities beyond that which the Rust safety features provide; (b) a safety net in case Servo code is tricked into performing insecure actions. There are still plenty of bugs to shake out, but this is a major milestone in the project.
That's a ultra hard combination to pronounce :)
Have you tried lrs yet? https://github.com/lrs-lang/lib
Not at compile time.
We have E-easy and E-less easy. I'm not sure if jdm has any plans to add E-mentor, but it might be a good idea!
Hmm, but `mem::transmute` should be a no-op, it reinterprets the parameter but doesn't change anything about it. It doesn't give a static guarantee that the conversion is safe (since raw pointers are inherently unsafe..) but it also doesn't have any overhead.
If I understood what was said when lrs was originally released, it would take a lot of work to get it into a usable state for OS-Dev, because it relies on a lot of linux things (i.e. is programmed based off of linux syscalls). Glancing at the issues open on the repo, it sounds like this is still the case (though work is being done to mitigate it).
This isn't a case of that. /u/leopoldj wants to call the default implementation of a trait method from inside a specialized implementation of that same trait method for the same type. There's no way for this to work (without a helper method) because only one implementation of a given trait method can exist for a particular type. Once the specialized implementation exists for a type, the default ceases to apply.
Cool. Is it enabled by default? 
Ah I see. Implementing a custom trait might make sense if I have a common set of constraints I tend to be using for a given type.
Is this expected to improve multi-threaded performance? (or is Servo just replacing threads with processes?)
The Rusty Code extension for Visual Studio Code (now open sourced) is also coming along quite nicely. Been playing with it tonight. Rough around the edges, but fairly young yet and both the extension and editor are showing promise.
How is this compared to arrayfire-rust. It can also offload the processing to the GPU using CUDA or OpenCL
Hmm....*grabs his wtftw source*....let's get this baby running on wayland
If only SemVer had a "logical" version as well I think it'd see far more proper use. Like it or not, versions are dual purpose, political as well as practical. I'd venture to say we'd see far more post 1.0 crates if people were allowed to say "this is logically version 1" but the second number denotes breaking changes. I think many stay at pre 1.0 solely to avoid having to follow SemVer properly, because &lt;1.0 is somewhat free for all. Although long term, having so many pre 1.0 crates could be detrimental and counter-productive. I don't really like depending on pre 1.0 crates unless there is no choice. Just my opinion though. 
That's a really interesting combination of trait based generics and move invalidation.
That's really something which ought be automated. elm-package does exactly that, `elm package bump` will diff the API changes and update the version number based on API changes since the last release: &gt; Versions are incremented based on how the API changes: &gt; PATCH - the API is the same, no risk of breaking code &gt; MINOR - values have been added, existing values are unchanged &gt; MAJOR - existing values have been changed or removed It only looks at structure/types though, so it does not "see" non-structural major changes (behaviour change without API difference).
I think that rust-lang.org should link to this-week-in-rust.org edit: actually it does, under "community". It probably should be more prominent (eg: embed the latest release of this week in rust in the rust-lang.org frontpage)
Maybe we need a `trait_alias!` macro for this kind of thing :)
I think you're talking about RVO, or "Return value optimisation". I e, if you do fn make_big_struct() -&gt; BigStruct { /* ... */ } fn main { let z = make_big_struct(); } ...Rust tries to avoid copying, and instead use the parent's stack frame (where `z` is stored) directly. I don't know the compiler internals enough to tell exactly when this works and when it does not, though.
&gt; Hmm, but mem::transmute should be a no-op, it reinterprets the parameter but doesn't change anything about it. No but calling functions at compile-time is unsupported right now so constant calls and expressions can't be expressed. The post refers to [const fn](https://github.com/rust-lang/rust/issues/24111) which is about exactly that. Other lack-of-const-fn PITA, `ptr::null()` and `ptr::null_mut()` are functions, but since there's no const_fn you can't statically create a null pointer, so you can't statically create structures containing null pointers. I hit that trying to make a CPython extension in Rust (using the low-level C API), a number of structs are generally allocated statically (e.g. Python types created in C) and full of null pointers, had to allocate them dynamically.
I got it now, thanks.
const fn has landed; it's unstable. Its capabilities are gradually being expanded.
I don't think it's related to my problem. In my situation the request is processed and the response is properly written to the socket and flushed, but the browser keeps waiting. EDIT: Also, I know that the browser receives the response at least partially because the content of `&lt;title&gt;` is shown. But the actual content remains blank while the browser waits for more data. 
Again with(out) the images? ;-)
Keep in mind that below version 1.0 the API isn't considered stable yet, so a minor upgrade can contain breaking changes. To quote the specification: &gt; Major version zero (0.y.z) is for initial development. Anything may change at any time. The public API should not be considered stable. So many crates aren't 1.0 yet because they don't have a stable API yet.
I've got some ideas how to do that (similar to what [semantic-release](https://github.com/semantic-release/semantic-release) does). I should really get started.
ZFS mentioned in the document is OpenZFS? As in, you'll be able to leverage all (large part) of the work that went into it? That seems huge.
Thanks! Will fix when get home.
I looks like you want Rust to have inheritance and code patterns associated to it (such as calling the method of the "superclass" when implementing a child class), but Rust programs generally aren't structured this way.. A more common way to reuse code and state in Rust is to isolate the common part in another type (a struct, for example), implementing methods for it as needed, and include it as a field of structs that reuse it in some way. This is called [composition over inheritance](https://www.reddit.com/r/rust/comments/372mqw/how_do_i_composition_over_inheritance/).
Oh that's awesome
&gt; Shouldn't those kinds of warnings be moved to clippy? The `bad_style` lints have been around for a long time, even longer than clippy. Once the entire world uses `rustfmt`, it'll make sense to remove them, but unti lthen...
I guess I'm not the only one missing QotW, should I do it in future TWiRs?
https://github.com/Munksgaard/session-types
Are u have plan for support Gnome?
Nice work! I'm also working on a similar project [1] and I see you are using opt.level 3 and I'm wondering if you've encountered any issue with wrong optimizations? I tend to get some when optimizing too much but that could be due to the mix of asm with rust, not sure yet and didn't take the time to investigate. [1] https://github.com/tytouf/roulios
&gt; server bindings, to allow the creation of wayland servers in Rust Does that mean Wayland compositors or something else?
I haven't encountered any issue with opt.level 3 so far. Though, I use little assembly now.
Is this being done with a cross compiler or a horde of compiler options that make stuff work. If a cross compiler then any instructions on how I can build one?
I'm not Russian, so it's all Greek to me, but I'm excited anyways. Keep it up!
[oscpad](https://github.com/bburdette/oscpad) is basically working. This week I'm going to use it to actually control some things and see what issues come up. On the list is making an interface to control some programmable LEDs, and also making a web interface to simulate the cyclophone, a which is a physical synthesizer controller. 
I was thinking of compiling Rust for a R-Pi kernel. Will have a look at this later. Thanks.
Check out my Makefile and thumbv7em-none-eabi files. /u/steveklabnik1 already provided a guide, but this one is arm-specific: http://spin.atomicobject.com/2015/02/20/rust-language-c-embedded/. This should help.
Erlang is latency optimized, not throughput optimized. Go's scheduler is throughput optimized, not latency optimized (and even that was not considered fast enough for Rust's core). There's really quite a bit of freedom in the design space that is going to dictate what tradeoffs you will make, so going forward, you should try to decide what kind of scheduler you want and move toward that. And that will dictate the use cases for your library as well. For instance, is this meant to orchestrate high level concurrent services that mostly operate sequentially? Or can people use this for more fine grained concurrency and expect it to work as well as a fork join pool? As an example of something that might be useful for Rust users to know: at the moment, how many indirections are there between the scheduler and code that's run? Are you just calling a closure trait object, or is there more machinery involved?
Can you elaborate more about your GUI problem? Are you using an existing toolkit or creating a new toolkit? All discussions I'm finding on Google about composition over inheritance and GUI points out that inheritance is more adequate to build GUIs. I saw a question [here](https://stackoverflow.com/questions/14406373/inheritance-or-composition-on-gui-objects) that may be interesting, but there isn't much discussion. Anyway, you might look into how the [gtk bindings](https://github.com/gtk-rs/gtk) are mapped in Rust: since GTK use inheritance, inherited classes are mapped to traits, not to classes (example, [ButtonTrait: WidgetTrait + ContainerTrait](http://gtk-rs.org/docs/gtk/traits/button/trait.ButtonTrait.html)). Might not be Rusty, but it works. The only GUI library I know that is written in pure Rust is [Conrod](https://github.com/PistonDevelopers/conrod), and it doesn't have a concept of inheritance ([those](http://docs.piston.rs/conrod/conrod/#traits) are its traits). But it's an immediate mode GUI library, or imgui, in which the GUI toolkit doesn't retain state or callbacks on the widgets. The opposite is "retained mode", and it's much more common. I can point to other links about imgui such as [this](https://gamedev.stackexchange.com/questions/24103/immediate-gui-yae-or-nay) and and [this article](http://www.johno.se/book/imgui.html) (and of course [the c++ library](https://github.com/ocornut/imgui)). The article I linked is very interesting because it says that with immediate mode, the classes that represent a widget are turned into methods: &gt; Widgets as methods instead of objects &gt; Each "widget method" in the Gui class encapsulates both the existence, interaction, and display of each logical "widget". Once again, note that from the perspective of the client that widgets can only be said to "exist" in the form of a method invocation; widgets change from being objects to being method calls. &gt; One of the main gains here is the complete centralization of control to the calling code. Both the "widgets" and the code that reacts to user interaction with these widgets are all in the same place.
&gt; `get_display()` Where does this fetch the display from? I would expect a global (singleton), and this gets me slightly worried :x
I hope the atomontage engine guy will be interested in porting his amazing engine to rust.
Actually, the logo represents a spherical fungi spore. :-)
[Ride](https://github.com/madeso/ride) is actually a thing. Too bad it isn't written in Rust...
/u/graydon2 has said several times that there's not one single inspiration for the name.
This doesn't deserve downvotes guys, come on.
removed for accuracy.
Thank you for your detailed post. I will list only some of the problems here. I am creating a brand new GUI toolkit in Rust. It is a very thin veneer over the Win32 API at the same time super easy to use. I need to dispatch GUI events using dynamic dispatch. So I have a trait like this: pub trait EvtHandler { fn on_left_mouse_click(x: i32, y: 32); //And so on ... } Firstly, dynamic dispatch from C to Rust is a tricky subject. I solved the problem by transmuting a Rust trait object into its two parts - data and vtable - and storing them separately in C. This is working fine now. Now, let's say I have a simple drawing app. It needs two windows - the main frame and a canvas within it. So I model it like this: struct DrawingApp { frame: Frame, canvas: Canvas } I can implement ``EvtHandler`` from ``DrawingApp`` and listen for all events in both ``frame`` and ``canvas``. But now an event handler method like ``on_left_mouse_click()`` will be called for both windows. That's not very clean. Where do I go from here? In C++ I will inherit from ``Canvas`` and ``Frame`` to isolate their own event handling code. In Rust I try to employ composition and create two new structs like this: struct DrawingApp { frame: Frame, canvas: Canvas, frame_evt_handler : FrameEventHandler, canvas_evt_handler : CanvasEventHandler } This looks OK on paper. But soon I run into a problem. I need the ``FrameEventHandler`` and ``CanvasEventHandler`` to be able to communicate with the ``DrawingApp``. But if they hold references to ``DrawingApp`` then the ``DrawingApp`` effectively becomes immutable. This is probably where my Rust newbness is becoming all too obvious. But I hope this gives you some idea. 
But please just stylise it as “Oxide” then, not “oxIDE”.
Will do.
What about 0x1DE
Probably won't work effectively with current rust - it was last updated in 2012, sadly.
I think rust is leaning a lot towards just providing generic support for a lot of common multi-linguage IDEs, but if someone does build an IDE for rust that could be a good name! Might get confused with [Sodium Oxide (library)](https://github.com/dnaq/sodiumoxide) though.
I'm more likely to rename "E-less easy" to "E-mentored" than add another label. The goal of the "E-easy" and "E-less easy" labels in Servo is that the person who adds enough information for someone else to tackle it is the mentor.
It raises the question of how they actually managed to build libcore for 1.4?
Ironoxide
They being the rust team. Seems weird that you can't bootstrap the compiler.
Rust is named after a fungus.
&gt; Is it expected that the entire rust environment bootstraps? You need to use the unstable compiler to compile.
OK. I'm going to put my fingers in my ears and LALALALA CAN'T HEAR YOU.
not enough leet speak. &gt; 0&gt;&lt;1D3
Assertions exist to model invariants that must be upheld at runtime, and determining that an invariant has been violated is one of those sky-is-falling situations where you absolutely do want to terminate the program.
Nah, then it's not hex anymore.
That's exactly what I meant! It looks like most compilers do it automatically, whch brings up another question. Compilers will (sometimes) optimize things to use poiners/references rather than copying the actual data, so when should you use pointers? For example, If you think that you have a large struct which would benefit by using a pointer rather than copying, should you just pass it, and then let the compiler figure out if it would be faster to use a pointer or not, and not waste time trying to deal with pointers and optimizing it? So I guess what I'm saying is, Is there any point in passing by reference unnecessarily? If the compiler optimizes it to the best case anyway, it seems like you should'nt use (the heap) unless it wont compile without it, or you want to "choose your guarantees"
Jetbrains already has [0xDBE](https://www.jetbrains.com/dbe/).
ah, touché
It's a seperate implementation not copy pasting. Tedsta has written Redox's ZFS implementation from scratch.
naaah. I don't wanna see Gnome on Redox neither, but the question itself is legit. 
Could you link those examples? It's otherwise hard to explain without context. My guess is that `build` is doing some sort of construction that could fail, and the example code is using `unwrap` as a quick 'n' dirty way to get the constructed value (if `build()` failed and one called `unwrap`, the current thread would panic).
Hey /u/Hauleth and /u/ticki_ , sorry to hijack your thread, but I've been soliciting OS-level programmers for feedback on the libcore/no_std stabilization RFC: https://github.com/rust-lang/rust/issues/27701. The final comment period will likely end soon, so if you (or anyone you know) have any suggestions for improvements to our freestanding support before we stabilize it, now is the time to comment. :)
So far everything public has been from scratch. I guess I'll have to change my methods.
I have quite recently written [a script](https://github.com/Ogeon/rustful/blob/master/scripts/changelog.sh) to generate [a changelog for Rustful](https://github.com/Ogeon/rustful/blob/master/CHANGELOG.md) from Homu commits, that may be interesting. It's not super robust or generic or anything, but it works well for this case and may be tweaked to work for other projects and styles as well. My Bash skills are limited, at best, so watch out for dragons.
You murderer.
See other comments. There's not one single myth for the reason of the naming. i.e. the author is in for the long con. Hopefully in another year another origin story will emerge. I'm banking on an inventive acronym (there's always a [literal origin](https://en.wikipedia.org/wiki/Rust,_Baden-W%C3%BCrttemberg) story).
In order to get autoderef you would need to implement the `Deref` trait (as seen here for `Rc`: https://github.com/rust-lang/rust/blob/master/src/liballoc/rc.rs#L424). You'd need an `unsafe` block within the `deref` function in order to do the actual dereference, but the `deref` function itself wouldn't require an unsafe block to use because it's not marked `unsafe`, and hence you'd trivially be able to get memory unsafety even with no `unsafe` blocks. And as shown here, you can't mark a method implementation as `unsafe` if it's not also `unsafe` in the original trait definition: http://is.gd/MybCGc . There are of course various ways that this could be made to work properly, but all of them would require changes to the language. I also doubt that there's a consensus on whether or not raw pointers *should* have autoderef, since I imagine there are plenty of people who are happy that raw pointers require such explicit operations.
Using my patented algorithm to calculate the amount of breaking changes in Rust, `(2015 - 2012) * 365`, I can say with almost 100% probability that it does not work with current Rust.
Not the author, but as someone who write huge blocks of docs, if I didn't have an editor that supported folding, it would be annoying to scroll past all the docs and see just the code.
Oh sorry, I missed the embedded aspect. In that case, have you seen [Ivory](http://ivorylang.org/)? It's a DSL (embedded in Haskell) for doing memory safe programming on embedded systems. Rust is way more polished for the end user, but I figured you might at least want to be aware of it.
In my experience, an entry in a changelog mostly corresponds with a pull request, just with the exception that some pull requests aren't noteworthy in a changelog. So if a PR is called "Add /version endpoint to server" or "Rewrite parser", you could simply transfer these lines to the `CHANGELOG.md`. Ideally, you always have an `unreleased` section on top of the changelog, where each contributor is requested to add his contributions (if it makes sense). A release then means bumping the version in Cargo.toml, updating the changelog, tagging the commit that does these things and then publishing the crate. Doesn't sound like something very difficult to me :) &gt; For me personally, the quality of commit messages in a nascent project is abysmal. Absolutely. That's why a changelog helps, to be able to filter through the noise easily.
When I wrote that list, I also looked at the README and sometimes at the documentation itself. I think it's fine to keep it in there initially, but a separate file makes it easier to find and link to :)
Очень хорошо!
Eh. Changelogs are supposed to be human readable, you can't exactly autogenerate them.
It's still better than nothing in my opinion, but yes, handwritten changelogs are surely easier to read :)
If the website is publishes via github pages, you can just check in the images to say, an `/img` directory in the repo and they will be available via `redox-os.org/img/...`, rather than trying to link to something in some distant github repo.
Agreed. I also need to improve my changelogs too - they could be more high-level.
I didn't know the logo is ment to represent snakes... TIL
I've been trying to become more disciplined, both with semver and changelogs and stuff. Will take time to propagate out to all my projects, but it might be another case of 'broken window syndrome'. It's much easier to keep up if you stay on top of it.
No, no singleton here. `get_display()` tries to connect to the unix socket the wayland compositor is listening on (which must be provided as an environment variable). The `WlDisplay` object it returns wraps the connexion, which is closed when it is dropped. I admit `connect()` would have been a better name for example, but I decided to stick with the names of the reference C library.
&gt; To address your concern about breaking changes, I've mostly adopted the convention that Rust itself follows, which is to include the literal string [breaking-change] somewhere in the commit message, along with an explanation of how to fix things. One issue with this for library users is that they have to mentally merge a diff of those breaking changes between versions. If you are super disciplined and do `[breaking-change]` for each commit that changes the public API, then that could cause unnecessary noise for a user to wade through.
Interesting. I never really ran into that problem tracking breaking changes in Rust before 1.0, but I guess I could see it becoming a pain if I waited a few months between every rustup. But I think that's because of the volume of breaking changes, which probably isn't comparable to your average Rust library... I mean, a CHANGELOG still needs to list each breaking change and how to fix it too, although I guess a CHANGELOG has the opportunity to be holistic if there are related breaking changes scattered across multiple commits. To be clear, I do think a CHANGELOG is clearer. No argument here about that. For me, it's more a question of: how much value can I suck out of commit messages? If I can get X% of the way there without spending the time to curate a CHANGELOG, maybe that's OK for most libraries.
Do you mind describing your development environment? ~~Virtualbox? Dedicated hardware?~~ ~~I see someone using Virtualbox with fbdev~~ ~~https://forums.virtualbox.org/viewtopic.php?f=3&amp;t=63416#p337905~~ edit - I was making it way too hard. basically sudo apt-get install weston &amp;&amp; weston
vim [supports folding](http://vim.wikia.com/wiki/Folding), Steve! You should consider tolerating a .vimrc with more than 7 LOC :P
&gt; In my experience, an entry in a changelog mostly corresponds with a pull request, just with the exception that some pull requests aren't noteworthy in a changelog. I would consider that a change log that doesn't add much value on top of a commit log personally (with tagged releases). (Unless there is a high signal to noise ratio, which is probably only true for very active projects.) I just don't see the point. If I'm going to maintain a change log, then it should give more bang for your buck than appropriate use of `git log`. &gt; Doesn't sound like something very difficult to me :) It is. I'm not just pontificating here. :-) I've tried it. I failed. I can show you: https://github.com/BurntSushi/nflgame/blob/master/CHANGELOG --- That log is effectively useless IMO in the presence of a commit log. [EDIT] That example change log is pretty cute. I started it back in 2012 and the commit message reads: "Starting a CHANGELOG since changes from now on should hopefully be smaller." Which still seems sensible to me. Take a look at the first change log entry. I had high ambitions: https://github.com/BurntSushi/nflgame/commit/046725b9d3e2fee41878ea856be18202a2976a1f#diff-d3bb3391c79904494c60ee2ac2f33070 --- If every entry were like that, then that change log would be extremely valuable today. Alas, like I said, I failed. :-( &gt; where each contributor is requested to add his contributions (if it makes sense) I always try to be extra judicious in what I ask of folks who submit PRs. I would prefer to spend a volunteer's good will on tests and docs. :-) But yeah, I agree that this would be mostly reasonable. &gt; Absolutely. That's why a changelog helps, to be able to filter through the noise easily. I was talking about nascent projects, where a change log would be bad for the same reasons that commit messages would be bad. For me personally, it doesn't make sense to keep a detailed log of progress for a project that one is just starting. (For one, there are no real releases...)
You see, Graydon Hoare was a huge fan of True Detective...
Thanks. You've convinced me to add a CHANGELOG onto my crate, [Barcoders](https://github.com/buntine/barcoders). This is something I should have been doing. Even though I probably currently have zero users, I have been making changes that I'd like to document somewhere. This makes sense.
&gt; although I guess a CHANGELOG has the opportunity to be holistic if there are related breaking changes scattered across multiple commits This is the main thing, I think :) A changelog can be much more high level.
&gt; Regarding the panic handlers bloating your code, would the custom panic RFC be a feature that would help here? https://github.com/rust-lang/rfcs/pull/1328[1] That RFC is currently in its final comment period, so if you have some feedback you should leave it very soon. :) No, it's not going to help much here, since it is designed for `std` and is dynamic.
Visual Studio Code doesn't, unfortunately.
You should be able to leverage the [Nullable Pointer Optimization](https://doc.rust-lang.org/book/ffi.html#the-"nullable-pointer-optimization") and use `None` instead of `ptr::null()`.
Define "human readable". Isn't a list of headlines "human readable"? I do admit that the layout isn't great, yet, but this isn't much worse than Conventional Changelog, which is also autogenerated but with categories, and it does link to each PR where more details can be found. Anyway, it's either this or no changelog at all, in my case, since I don't want to delay a release just because I don't feel like I have the time to properly summarize the past changes in a "human readable" way. I would gladly take my time and write another blog post with examples, documentation links, etc., but life tends to get in the way these days, so I'm currently quite happy with a changelog for robots. I just thought that someone else (maybe even in a similar situation) could be interested in the same approach and I wanted to spare them some of the effort.
Yes, that's one of the potential language changes that I was alluding to.
Nice writeup!
This is one place where the Rust tooling and conventions really do leave something to be desired. Almost everywhere else Rust has a pretty good story for best practices in development and deployment; integrated tests, a package manager to let you easily depend on third-party code, doc comments and module level docs with doctests, it integrates reasonably well with existing coverage tools, it has some good lint packages available, `rustfmt` is coming along, and it has a pretty good code review and CI culture. Obviously nothings ever perfect, I can think of things that could be improved in each area, but on the whole I think there's fairly good tooling and a fairly good culture for all of these. However, [crates.io](http://crates.io) has no way of displaying a changelog by default. There isn't really an established convention for where to put a changelog or how to format it. The Rust project itself does a reasonable job of putting together a changelog for each point release, which is a considerable manual process helped out by a few project-specific conventions. But the ecosystem as a whole doesn't have any established convention or tooling for it. I'm not really sure if [clog](http://blog.thoughtram.io/announcements/tools/2014/09/18/announcing-clog-a-conventional-changelog-generator-for-the-rest-of-us.html)/[conventional-changelog](https://github.com/ajoslin/conventional-changelog) is the solution. I really don't like the metadata junking up the subject line of Git commit messages; perhaps if were a normal RFC-822-header-style trailing annotation to Git commit messages it could work better. Git commit messages should generally be worded to address developers of the code, while changelog message should address users, who can be fairly different audiences. Another option is just having a changelog file in some conventional format, and having people update it when changes are made. This can become a frequent source of merge/rebase conflicts if working on a project with a number of developers, but could work for smaller projects. The final option (which can also be mixed with the above) is to have someone manually collate a changelog at the point of release. This will frequently take a good amount of work, and it's all pushed off to the end of the release process (unless you mix it with the incremental version above), but it usually provides the best results if the release manager is careful about it.
This helped immensely. It seems ridiculous that any beginner guide would have build() and unwrap() without explaining what they do.
Thanks, this really helped a lot!
Rust support in kdev is all I want. The compiler is in LLVM, maybe it can support Clang Analyzer for syntax support.
&gt; I'd love to get your feedback on that experience, considering that crates.io represents the Rust ecosystem's state as of six months before 1.0 even came out. It's a bit messy, but nothing I wouldn't expect. I haven't really dug quite deeply enough to really start to consider deeper refactorings. It takes significant advantage of native database features, which has made it perfect for my needs, and has driven great features like the [`sql_function!` macro](http://sgrif.github.io/diesel/diesel/macro.sql_function!.html). I'm not sure if I'll get around to doing a full port that's clean enough for a PR, but it's been a great sandbox to explore the API in. It's a solid, decent sized, real world app. Warts and all. &gt; And if you want to write a totally new web framework to port it to Yehuda and I are working on it. ;)
Similar to this (stores up to 8 bytes inline), I've been using Tendril (https://github.com/servo/tendril) with great success lately.
Oh, I see that `InlinableString` is exactly what I want. The only thing that disturbs me is the size of this structure: 48 bytes for each instance is exactly 2x more than the usual string (24 bytes). I think there is an opportunity to save much by sacrificing only two bytes of inline capacity: enum InlinableString { Inline { length: u8, // We use u8 instead of usize for store length bytes: [u8; 30], // Inline capacity is 30, not 32 (it's important for the final size) }, Heap(String) } The size of this structure is 32 bytes. This is only 8 bytes more than usual String and 16 bytes less than the current implementation of InlinableString.
I'm a big fan of [clog](https://github.com/clog-tool/clog-cli) but not everyone likes using git Metadata to autogenerate changelogs. But it's far better than me saying I'll hand craft changelog and either not doing it, or leaving off all the nice features which clog does automatically (like links to commits where the changes were made, links to issues, etc) See [clap's changelog](https://github.com/kbknapp/clap-rs/blob/master/CHANGELOG.md) for an example. Also the nice thing is being customizable about what sections are displayed and how much Metadata to use. See [cargo-extras changelog](https://github.com/kbknapp/cargo-extras/blob/master/CHANGELOG.md) for an example. But you could also change the default sections too, don't like "feat(SomeFile.rs):" cluttering up your commit messages for new features? No problem, add an alias for "f" and omit the file, a la "f:" instead. Now it's only 2 extra characters per subject line and you still get all the niceties of clog autogeneration!
&gt; working on it Eeeeee! :)
When will Wayland be a real replacement for X? When will there be distros that come with Wayland by default and no X at all?
Wayland is currently the default in Fedora Rawhide. Gnome and KDE both have Wayland compositors, and both GTK and Qt apps can run directly on Wayland. For anything written directly to X11, there's XWayland. I can currently run Wayland for everything I do (Gnome on Arch) except Qemu.
Heads up, that gaol lib has no LICENSE file in the repo and no license info in the README. A lot of people will immediately stop looking after noticing that, both for legal reasons and others.
Much simpler than expected! I'll see if I can get this working on Windows.
Thanks for the PR! Merged :) https://github.com/fitzgen/inlinable_string/pull/1
I plan to name my scheme implementation "Radon", that is RnRs, "Rn" for "Radon", "Rs" for "Rust" And if I could implement an editor in Radon and Rust, I would like to name it "Neon", "Ne" for short which means New Editor or New Emacs. These are my most ambitious dreams. And I'm currently learning Rust and working on Radon. Hope I can write a usable Radon before 2016
One nitpick: `posix_memalign` itself allocates memory, so I think that the allocations from `malloc` just get leaked. Pretty nifty overall though. 
When the field in question is `mut char` or `*mut PyObject`?
What's so bad about GNOME on Redox?
One question and one comment: Question: Why not mmap() the memory? You're already working at the page granularity, and you can mark the memory as executable as you request it and avoid the memalign/mprotect() call. Additionally, if you want to be slightly more portable, sysconf() would the appropriate way to get the page size. Comment: For debugging you might consider memsetting to 0xcc (int3) instead of 0xc3. This will cause an immediate SIGTRAP which should be easier to debug than your code returning from an unknown point. Additionally, if you run it inside a debugger it will trap directly to the debugger... Either way, thanks. These are the sorts of things I'm interesting in being able to do in rust, and seeing how straight forward they are is interesting.
Nitpick: programs that run on OpenBSD are pretty heavily encouraged to follow [W\^X](https://en.wikipedia.org/wiki/W%5EX) (although this is not enforced), if OpenBSD support is intended.
It's all function pointers as long as you keep that "f" lowercase.
Fixed, thank you.
Using John Cleese's head as a logo for Python is an entertaining thought, but I think they made the right decision. 
&gt; One step that I add is to also fill the memory block with the RET instruction, which will let us return from our function even if we happen to accidentally run other memory in the block. I found this to be super clever.
I was told before I couldn't compile it on x64. Compiling with 32 bit Rust gets a bit further but the compiler eventually panics. the output is [here](http://imgur.com/kSIyHTn)
Even still, this is less efficient than a typical C++ implementation of the pattern, right? In particular, the tag to distinguish `Inline` from `Heap` is redundant with the `length` as any length &gt; 30 implies `Heap`.
It's great, keep it up! Хорошее начинание! :)
Just a heads-up, on all other architectures you will most likely need a cache flush after emitting your instructions. x86 is the only architecture that I know of where cache flushing for self modifying code is redundant.
I think I'm going to, I figured I'd post here first.
[**@steveklabnik**](https://twitter.com/steveklabnik/) &gt; [2015-11-30 21:31 UTC](https://twitter.com/steveklabnik/status/671441532751380480) &gt; We say programming is hard, and we hate bad code. So we practice writing code. &gt; &gt; We say writing docs is hard, and hate bad docs... ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Doesn't Gnome rely on Linux-specific facilities now (ie, it's not even portable betwen unices)?
Ah, cool, will have to check that episode out. Laila worked with us (CoachUp) for a while and was great. I didn't realize she was a host of that podcast!
Atom does, currently having to use it while rustycode is broken :( Edit: Fixed it, if anyone else needs to, install from git! On arch that's in AUR as rust-racer-git
Maybe an issue in the bug tracker of one of Piston’s repositories is more likely to be seen by people who can answer?
I think the answer to your questions is "yes." `serde` is the *presumptive* standard serialization library. It was developed by /u/erickt as a replacement to `rustc-serialize` (then called `serialize`) to not only be faster but to also support a wider variety of use cases. A key component to both `rustc-serialize` and `serde` is how easy they make it to serialize data from custom types. For example, if you have a struct with 20 fields in it, you really don't want to be writing the code that serializes each field individually. Indeed, both `rustc-serialize` and `serde` have macros that will write that code for you. Unfortunately, these macros are implemented as compiler plugins, which don't work on Rust stable (and won't for quite a while). As Rust 1.0 approached, `serde` was still nascent (I think?), but most everyone knew that the `serialize` library wasn't the way forward. So it was moved out of the standard Rust distribution and currently resides in the nursery. It [is still maintained](https://github.com/rust-lang-nursery/rustc-serialize), but it is marked for death. However, as a compromise, it retained its ability to automatically serialize custom types by hard-coding it into the language as a special case. Therefore, the `rustc-serialize` crate enjoys a special advantage over all other serialization libraries, including `serde`. `serde` has made really really impressive strides to improve the situation. /u/erickt [made plugins workable on stable Rust](https://github.com/serde-rs/syntex), which means `serde` can do the automatic code generation for serializing custom types. Unfortunately, it still isn't as ergonomic as `rustc-serialize`, since it requires fiddling with `build.rs`. If you're running on Rust nightly exclusively, then this workaround isn't needed, and `serde` should be your crate of choice.
I guess it tends to happen when the crates are very closely related. For example, for some libraries I write, it's useful to have a command line tool to play with them. I usually put that tool into its own separate crate, e.g., `{libname}-bin`, and it makes sense to keep that in the same repo as `{libname}`. Others, like `regex`, have two sub-crates called `regex_macros` (which is so tightly coupled that it uses undocumented APIs of `regex`) and `regex-syntax` (which is also tightly coupled, since it defines the concrete syntax of a regular expression). It's just plain ergonomic to keep all of this together in one repo.
Beautifully summarized. If you want even more gory details, check out my [blog](http://erickt.github.io/blog/categories/serde/) where I wrote about its development over a number of posts.
Ah, didn't see that one that may do the trick. 
Would it be possible to add a shim to `serde` that lets `serde` work with applications that implement the `Encodable` and `Decodable` traits from `rustc-serialize`? E.g., something in the spirit of: impl From&lt;::rustc_serialize::Encodable&gt; for Serialize { /* ... */ } impl From&lt;::rustc_serialize::Decodable&gt; for Deserialize { /* ... */ } Currently, (as far as I can tell) there's no simple, ergonomic way for a library to support both `serde` and `rustc_serialize`. (Yesterday I asked [about this](https://www.reddit.com/r/rust/comments/3v2k37/can_a_library_support_both_rustcserialize_and/?ref=share&amp;ref_source=link)). It would be helpful if, as a library author, I could merely support `serde` and let `serde` support `rustc-serialize`.
Hey buddy I think you are in the wrong sub-reddit. This is for the Rust programming language. You probably want /r/playrust. 
doh. thanks man
That's great to hear. I'll see about using it, perhaps if I use C++ for a future external, or maybe as a performance test for some simpler algorithms like autocorrelation. One of the major reasons I used Rust was because I don't know the STL (or, really, C++) very well at all. I found the actual text from the [SC help docs](http://doc.sccode.org/Guides/WritingUGens.html): &gt; STL Containers &gt; It is generally not recommended to use STL containers, since they internally allocate memory. The only way the STL containers can be used is by providing an Allocator, which maps to the allocating functions of the server. 
We're just running a nom benchmark :c
Right! It's not the trait.
It will mask callvirtfn-after-free bug
Specifically, it means that you'll do &gt; use std::[whatever] instead of &gt; use redox::[whatever] This might seem like a small change, but it's has implications beyond that. It gives us access to the internal features and attributes that only libstd has the authority to use (for example, prelude).
Redox is completely open source. What I meant was that I had uncommitted work that was ported from code that I copy+pasted from ZoL. But I am redoing it now.
&gt; which must be provided as an environment variable :( Well, that'll make unit-testing fun, I guess. I would favor providing other options, if possible (like simply letting the user provide the unix socket), but I agree that when writing a wrapper having the "low-level" interface match the wrapped language makes it much easier to adapt.
You'll need to make sure your GCC compiler includes 64-bit support. [Slightly more details here.](https://www.reddit.com/r/rust_gamedev/comments/3v5vpq/piston_projects_wont_compile_on_x64_windows/cxkk68i).
The build failure in this case is in the miniz-sys crate, which is part of [this repo](https://github.com/alexcrichton/flate2-rs).
Awesome! Just out of curiosity, is the Rust calling convention documented somewhere?
`impl&lt;'a&gt; IntoIterator for &amp;'a Foobar` is what you want. Then add an appropriate `iter()` method to `Foobar` that calls to that impl's `into_iter()` For `iter_mut()`, do the same with `impl&lt;'a&gt; IntoIterator for &amp;'a mut Foobar` EDIT: Reading your question more closely, the solution to your specific problem then is not to take `it` as an `&amp;I` but as an `I`. You pass in an `&amp;Vec` and call IntoIterator on that reference, rather than on the vec it points to, and it does what you want.
There was a "competition" on r/cpp once about making the smallest string possible started by looking at Howard Hinnant's implementation of `std::string` in libc++. The base idea of the winning entry was that you would start from a 24 bytes strings: length, capacity and pointer, and try to reuse as much as possible. I seem to remember it ended up being able to store 23 bytes + the (mandatory for C compatibility) `'\0'` character inline... though I now wonder where the size was stored (ugh memory...). In any cases, the string can certainly be packed more efficiently, however that will come at the cost of forgetting safety and re-implementing `String`. It could also be an opportunity to drop the size of `String` to 16 bytes (storing capacity as the first N bytes of allocated buffer), though it comes at the cost of having "large" strings more often. An "easy" implementation is to keep the 3 fields; omitting support for 32-bits code: #[repr(C)] struct InlinableString { capacity: usize, // Actually a 1-bit tag + capacity length: usize, ptr: *mut u8 } If the tag bit is set, then your `capacity` is `mem::sizeof::&lt;InlinableString&gt;() - 1`, and the size is stored in the first byte of `capacity` (beware byte order) with the rest of the content inline. If the tag bit is not set, then depending on byte order you can either read capacity directly or require some masking/shifting first.
Yes, both kernelspace and userspace. Currently, libstd does not run on Redox. But we have a temporary replacement, namely libredox. Libredox tries to to be as even with libstd as possible. So, libredox contains big parts of the functionality that libstd provides (much of which is just reexported from libcore), such as methods, types, memory allocation, collections, IO, macros, helper functions, and so on. Libstd has a special authority which makes it able access certain features that other libraries cannot use. Such as a prelude. Now, libredox also has a prelude, because it's now spoofed as libstd.
Make your function accept an iterator. See http://is.gd/jhDynP
We *do* plan to have POSIX-compatibility (we already supports many of the Linux syscalls), so in the long-term future, it'll be possible to port Unix programs (such as Gnome, Firefox, VLC, Libreoffice).
It is not, because it is in no way considered stable.
As potential inspiration, take a look at [nalgebra](https://github.com/sebcrozet/nalgebra)
Aha! This is completely surprising. Thanks a lot! And IIUC the implementation used for &amp;Vec is that for &amp;slice, through the magic of Deref.
So, basically: "It's complicated" Anyway, thanks for sparing the time to explain/give examples. :)
It keeps appearing every time I re-run.
I figured that out. I could've sworn I had a 64 bit compiler, but I guess not. Thanks for the help.
Nice job executing the contents of memory, but you left off the JIT part!
Should be 0xcc instead. I usually put this in my linker scripts :)
&gt; Aha! This is completely surprising. Thanks a lot! Its one of the very few cases in the standard library where a trait is implemented for a reference. Because of deref coercion, in most cases this is avoided because it can make it hard to figure out what method is being called. &gt; And IIUC the implementation used for &amp;Vec is that for &amp;slice, through the magic of Deref. That sounds right.
You should know that PITA is no longer officially in Microsoft's hands and is just as much an ISO standard as POSIX is.
I'm building a simple, in memory, versioned, key value database to accompany my [posts](http://rustyrazorblade.com/2015/11/ramp-made-easy/) on RAMP, an algorithm intended to provide atomic reads in a distributed environment. It's really, really simple, and could probably be done a million times better if I just started it from scratch again. I opted to use capn' proto for the server. Not sure if I'd use it over zeromq + a custom PEG parser if I started over. [PunisherDB](https://github.com/rustyrazorblade/PunisherDB)
TIL, thanks!
One way I've seen 'build' style work for example is anywhere that you have collections of operations where the final operation may want to go back and optimize the previous operations in order to improve the performance, or where multiple 'passes' may be optionally applied. example: sql queries. one way to make this work is to have a command object where you apply some function to it to 'filter' and 'select' and 'order' etc etc (think linq in c# for example), where the final 'build' or 'execute' then creates the final sql command and processes it. 
I think this is a good idea as well. If the convention is to use `CHANGELOG.md`, then rust already breaks it because it uses `RELEASES.md`.
Did you compile with debug enabled?
Haven't seen any floating around, good to see you finally make your way here jarx :). If I had the time I'd be down but currently up to my armpits in another project! LMK if you decide to get the ball rolling on this one.
Thanks. I'm currently viewing as much (stress testing firefox) source on it (official i2p, i2pd, python i2cp) as I can find while planning out the project. I'll let you know what's happening...when I know. ;P Good luck with your project.
&gt; Does one write a JIT function into memory, then remove the write permissions and add execution permissions? Yes. Maybe advanced JITs use some more sophisticated mechanism, but that's the basic idea.
I'd never said GNOME is an OS. Despite that GNOME intrusive and is dependent on systemd. I don't think redox is going that way.
Thanks for the link. If anything, reviewing their source will probably improve my rust code.
Isn't this covered by a `Mutex&lt;RefCell&lt;T&gt;&gt;`?
The two threads approach seems reasonable. I can't imagine how the event should be handled otherwise. If you have only one thread, and it's executing your main program, where should the event run? Unless your main thread also is entirely event based, like Javascript, in which case you could probably get rid of the Mutex.
There isn't one. But there is a decentralized software that runs on rust. It's called maidsafe/safenet. 
Atomics don't acquire locks, so they're generally faster. Also, `Mutex` provides interior mutability all by itself, so you don't actually need the `RefCell`.
Okay, that makes sense, thank you.
I might be entirely wrong about this, but it looks like `inotify-rs` has a function called `wait_for_events` which is telling the kernel to wait until there are notification events before returning. Which I believe means the kernel will know not to schedule the thread at all until it's ready to wake up.
`&amp;Vec` has its own IntoIterator implementation, the for loop calls `IntoIterator::into_iter(iterable)` and in that context, deref is not used.
Just to be clear, I should still be using the two thread approach right?
It would essentially be a more efficient/lock-free form of `Mutex&lt;&amp;T&gt;`.
Yes. What shadow meant is that the kernel wont waste CPU time with the thread that's blocking after the syscall.
Your use case is probably best addressed by AtomicOption, provided in the atomic-option crate (https://github.com/reem/rust-atomic-option). It provides atomic actions on the semantic equivalent of `Option&lt;Box&lt;T&gt;&gt;`.
Thanks, I'll definitely try that!
What are the most important points that are blocking stabilization of Serde? Is there a roadmap for inclusion in stable Rust 1.x? edit: actually, to think about it, rustc needs to separate its internal AST from the plugin-facing AST, to stabilize compiler plugins, and only then stabilize serde. Or does stabilization of compiler plugins need something else?
&gt; Who the heck took ownership in that for loop expansion? The `for` loop did. By removing the `&amp;`, instead of giving the loop a borrow of `philosophers`, you gave it `philosophers` itself. &gt; And why can't it figure out that once the for loop is done, ownership should be up for grabs again? Ownership doesn't magically teleport around the code like a mage casting Blink with the hiccups; it goes where you tell it to go and nowhere else. If you want ownership back, you have to explicitly transfer it back, but `for` loops have no construct for doing this.
`for p in philosophers` is a syntax sugar for `p in philosophers.into_iter()`. [`IntoIterator::into_iter` consumes the vector](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html#tymethod.into_iter) (it takes the parameter `self` by value). This means that after you call it, you can't use the value at all. On the other hand, `for p in &amp;philosophers` means `for p in (&amp;*philosophers).iter()` that [ends up](https://stackoverflow.com/questions/29166437/how-does-vect-implement-iter) calling [`std::slice::iter`](https://doc.rust-lang.org/beta/std/primitive.slice.html#method.iter), that takes `self` by reference and therefore only borrows the vector.
Is there a way to have something like this, but without `Option`? (that is, non-nullable)
So `for` loops are constructs that actually have ownership. Wild. I can envision a situation: let x = Thing::new(); let y = x; y.do_something_that_internally_changes_ownership(); `x` can never make assumptions and reclaim ownership from `y`, and there's no reason a `for` would be any different. Makes sense. Thanks for your answer. Very helpful :)
Ah, the notion of *consuming* is really what I was missing here. Thank you!
Will check tomorrow, thanks for the idea!
`for` loops are syntax sugar. `for foo in bar { ... }` compiles to the same code as this: { let mut _bar_iter = IntoIterator::into_iter(bar); loop { match _bar_iter.next() { Some(foo) =&gt; { ... } None =&gt; break } } (Ultimately, all control flow constructs in Rust can be constructed with `loop` and `match`).
You could use `as` to cast raw pointers instead of a `mem::transmute`.
Loop, match, break, and continue.
Well, I'll still have to write a dummy wayland compositor, which I expect to be quite some work too (and will require me to finish my libwayland-server bindings first). But it's definitely on my todo-list !
Thanks for the thorough investigation! The `Ordering::Relaxed` problem seems rather scary, though. I've never heard of it before, and while not technically unsafe for AtomicBool/isize/usize/ptr, it seems like maybe this is something one should be aware of when using `Ordering::Relaxed` in the existing Atomic structs.
About the question of "who owns" the vector after the for loop: AFAIK, after the for loop that consumes it, the vector is dropped (its destructor is called, and its memory is deallocated). So, there is no vector after the for loop. I suppose you know that variables are dropped when they go out of scope (which is usually at the end of the function), unless something consumes it (consuming means transferring ownership - you can't use the value because whatever consumed it now owns it). The thing is, whatever took ownership of the vector may do something with it then immediately drop it. Or store it somewhere (and thus not drop it). Etc. Rust has an idiom of "early drop", that is, you can call [`drop(variable)`](https://doc.rust-lang.org/std/mem/fn.drop.html) to drop the variable before it goes out of scope. Now, how is `drop` implemented? It's [simply](https://doc.rust-lang.org/src/core/mem.rs.html#491): pub fn drop&lt;T&gt;(_x: T) { } `drop` is a function that consumes a value of any type, does nothing with it, then lets it go out of scope (which calls its destructor).
&gt; it seems like maybe this is something one should be aware of when using Ordering::Relaxed in the existing Atomic structs. It's definitely something one should be aware of (although that particular example is more theoretically than practical, with current compilers/hardware, [see also](http://www.cl.cam.ac.uk/~pes20/cpp/notes42.html)), but it's not like it's the only weird aspect of weak memory models. They're quite complicated, and using anything other than sequentially consistent (`Ordering::SeqCst`) needs a *lot* of care; by the reports I've heard, even the state of the art in formalising concurrent code with Acquire/Release is relatively limited, and doesn't model Relaxed at all. (Even using SC takes thought, although there is a much deeper understanding of it.)
Sure, but the example still probably wouldn't work because the references wouldn't live long enough. ;)
I doubt performance would be a problem - the problem is availability, i e your code wouldn't run on certain older processors. Not sure how well other architectures can handle exchanging (and loading and storing) twice the pointer size either.
Then how about: const PREPARING: &amp; 'static &amp; 'static str = &amp;"Preparing"; /* ... */ status.store(PREPARING); ...that should work, but is slightly less convenient. Is there a more elegant way to write it? 
I may be an outlier here, but I think most of the "ergnomic" parts of both `serialize` and `serde` are neglectible. Good serialization should still be written by hand mostly, possibly with macro support for many standard patterns. I really dislike the "ergonomic" parts of `serde` and avoid them as much as possible.
[removed]
You might have the wrong subreddit.
I would go crazy without `derive(RustcDecodable, RustcEncodable)`. :-) It's exactly what I need 95% of the time.
Ah yes, I do use `gq` for wrapping long lines, but I thought that that's all it did. `formatprg` takes an external program and gets piped the lines on stdin, which could be a problem... It would need to trust that the first line is correctly indented and format relative to that I supposel I suppose you could use `formatexr` to change the format sent to `rustfmt`, but the plugin uses neither right now. https://github.com/rust-lang/rust.vim/search?utf8=%E2%9C%93&amp;q=formatexr
I've a similar situation with my wayland crates, basically `wayland-client` depends on two 'internal' crates that are `wayland-sys` and `wayland-scanner`. A breaking-change on `-sys` is not necessarily a breaking change of the API of `-client`, but a breaking change of `-scanner` is most likely one for `-client`, unless maybe it is the consequence of a breaking change of `-sys`... So yeah, complicated. And that's partly because I'm considering unifying the versionning of these 3 crates, even if it could sometimes imply a release of a new version of them without any changes.
If Rust does not make JSON and other data formats ergonomic then Rust will never gain broad adoption in the corporate space. A lot of programming that programmers get paid to do is mundane data shuttling—i.e., the moving around of data from one machine to another, from one format into another, into and out of a database, and finally to a computer screen or report somewhere. In my experience, this is true even of C++ corporate programming. A lot of C++ shops do “systems programming”—drivers, embedded, low-level and performance critical code—only in isolated spots, with the lion's share of the code base instead merely shuttling data around. C++ makes data shuttling verbose and error prone, and, so far, Rust isn't a whole lot better. But Rust has a beautiful trait system that could make data shuttling fun and easy—it just needs to _standardize_ on one trait for encoding and one trait for decoding. Currently the field is fragmented—i.e., `serde::Serialize` and `rustc_serialize::Encodable`—and libraries must either (1) choose to support either `serde` or `rustc-serialize` or else (2) use compile-time features or some other hack to clumsily support both traits. Whereas, if, say, `serde` supported both traits, then the fragmentation wouldn't exist, and the Rust ecosystem go move forward with only the `serde::Serialize` (and `Deserialize`) trait. This is a big opportunity for Rust. C++ doesn't make data shuttling easy, but it's moving in that direction. Projects like [Casablanca](https://github.com/Microsoft/cpprestsdk) are inching towards production quality, foreshadowing C++'s embrace of the Web, and the C++ language standard is moving towards features such as stackless coroutines and reflection that will, among other benefits, make data shuttling a lot easier. But C++ moves at glacial speeds, encumbered by legacy baggage, and this means Rust has an opportunity to leap ahead and be the first language to unify sexy systems programming with mundane data shuttling.
Curious to see what the adoption outside Apple eco-systems will look like.
Do they have a license?
No, but Swift inspired itself by Rust in some ways and we did steal `if let` from them :-)
Yeah, it's a pretty close competitor.
Seems like someone found the link to the page before they were ready to officially announce.
It is! There's an implementation for that: https://github.com/rust-lang/rust/blob/master/src/libcore/iter.rs#L2614 &gt; or perhaps it's inserted by the compiler, but then optimized out? Yes, all of this is subject to optimization. LLVM does a good job here.
Looks like it's up now, for me at least.
It's apache and some of the writing is CC-4.0 licensed. https://github.com/apple/swift/blob/master/LICENSE.txt
Wouldn't it be more accurate to say that the current Swift implementation can interoperate with the Objective-C runtime? There doesn't seem to be anything about the language itself that requires a runtime, unless I'm missing something.
Maybe I'm not clear on the definition of "runtime" as a noun, then. I think the Swift compiler emits the reference counting code when it's creating the executable.
&gt; FBString apparently manages 23 bytes by storing the remaining capacity of the short string in the final byte, so it doubles up as NULL if the short string is full. Ah! So that was the trick. Clever indeed. 
I don't see myself switching to Swift, if I was thinking about adding to another language to my toolset it'd be D or asm. This is sort of like comparing apples to oranges, how do you compare a language with a runtime GC with one that doesn't inherently need it? Not to mention Cargo is unbelievably useful in that I can mix and match basically any crate from the ecosystem and expect specific behavior. Maybe someday I will find a usage for swift but currently Rust is the end all be all for me and I don't see that changing. Swift has a place but it's not in the same place as rust.
Here is a really great explanation: https://github.com/elliotgoodrich/SSO-23
It's not that similar to Rust. Swift has a large runtime—the Objective-C runtime—and is automatically memory-managed.
In the same sense that the current Java implementation can interoperate with Oracle's Java runtime, sure. As it stands, the language requires a pretty large runtime.
Sure, and I'm happy that Rust and Swift have influenced each other so much—I have a huge amount of respect for Chris and his team. But Kotlin (for example) has most of Rust's features too. :)
Some of the methods in this crate like `.take()` need to leave behind an "empty" value.
&gt; Swift is intended for systems programming, and performance matters at every level (inefficiencies multiply their factors in large systems). Swift does "spend" performance, but only when we get something for it. This is C++'s "only pay for what you use" concept. &gt; Safety is something that we're willing to spend performance on. It implies: &gt; * array bounds checks &gt; * no undefined behavior &gt; * automatic memory management &gt;However, you can disable these and can use completely unsafe facilities if you want (including malloc and free!).
Well, for one, I've submitted two PRs already ;) Just small things. But, as I've said before, Swift is a really great language. But it's not really in the same space as Rust. It's still significantly higher-level. And that's great, for accomplishing its goals. Oh, one other thing: Swift is gonna teach a lot of programmers about things that we use in Rust, that some people consider exotic, like Option. Excited for those ideas to become more mainstream.
Reference counting is technically a form of garbage collection.
* 2010-06-16: [Rust’s first git commit](https://github.com/rust-lang/rust/commit/c01efc669f09508b55eced32d3c88702578a7c3e) * 2010-07-08: Rust first announced at the Mozilla Summit and published on GitHub * 2010-07-17: [Swift’s first git commit](https://github.com/apple/swift/commit/afc81c1855bf711315b8e5de02db138d3d487eeb) These dates aren’t super meaningful (in particular, Graydon notes that he had four years of Rust history in private Mercurial and Monotone repos before switching to git); just noting them for fun. Exciting times!
I think the effect there will depend on Swift's tools/library handling. My simpler Rust projects tend to involve grabbing some crates and duct taping them together. It's actually possible to get quite a lot done that way.
IMO it's a welcome addition to the language landscape, and a serious (good) implementation; I'm a language pluralist and believe different languages with different strengths are a sign of health. You could go feature-by-feature to try to figure out which one is bigger or clunkier but I think on balance they're of similar size and complexity. Rust makes you think more about ownership and aliasing; but it gives you some pretty great threadsafety guarantees in return. Swift spends a little more runtime speed on a few things (more indirect dispatch, CoW types, ARC); but it compiles a lot faster and has a slick REPL. Swift's type system has more kinds of things (protocols, structs, classes, extensions), but each one is a bit simpler; Rust concentrates its type complexity in a fewer number of more subtle and powerful concepts (traits). Rust has built-in support for fixed-size, interior arrays; Swift has built-in support for reflection. Rust has a macro system, Swift has some nicer built in syntactic sugar for dictionaries and optional types. Between them I am sure you could find reasons to prefer one or another for a given project, but I also suspect most programs you could write comfortably in one you could write comfortably in the other. It's tempting to be a bit cliquish or tribal and view Swift's gain as Rust's loss anytime someone chooses to use it when they "could have chosen" Rust. Please don't. Think in terms of technology and progress. Swift is good technology. It's open source and it sets the bar higher than it was set for C++: it has bounds checking, automatic memory management, non-null by default, sum types, type inference, and type-constrained generics. That's the new normal in terms of safety and expressivity, in a space formerly dominated by C++. That's _great_. It means (along with Go, D, Nim and a few others) that the stranglehold C++ has had is beginning to loosen. You no longer have to argue your company into adopting Ocaml or Haskell in order to get these sorts of things. As someone who was initially excited by the possibility of Java being a "better C++" (or better M3) 20 years ago, and was sadly disappointed by its tight coupling to a closed-world virtual machine, I can only say it's about time there was more action in this space. More better native languages, yay!
I'll accept that categorization. I guess the crux of my question is: if I write a C program that uses malloc and free, and uses structs containing integers to decide when to call free, do we say that C requires a runtime, or that my program requires a runtime? Edit: I would like to thank all who answered here. You're part of why I love this community. 
"Automatic memory management" is the big one there, and the reason why Swift and Rust are not necessarily competitors (though I'd say Swift is closer to being a Rust competitor than Go is).
 &gt; do we say that C requires a runtime, or that my program requires a runtime? Well, all non-assembly programs require a runtime, the question is, how large. And the runtime is a red herring here, the key distinction is "automatic" vs "manual", historically. Reference counting and tracing garbage collection have both been around for a long time, what Rust does is newer, and so less well-categorized. Rust programs which use Rc/Arc kind of have a very basic GC built-into them. This definitional issue is sticky, and why I like to stay away from the question entirely. I think describing it as "pervasive reference counting" gets to the crux of the issue, much more than "has a GC" does, personally.
Yes, that's enough for a one dimensional view except you need a pointer or slice to the elements too. You can represent it by just two fields: a slice and a stepsize.
Hah! That's some quality entertainment. 
I haven't had the chance to use Swift yet due to not owning an Apple device, but from what I've seen it looks like a very well-designed language. In general, we should be happy that there are more viable native languages around today that take memory safety seriously. Because that's why we're here, right? It isn't about which programming language you use, it's about using tools to create products that keep your users safe in an increasingly hostile digital environment. And remember that language popularity is not a zero-sum game: if you were not already worried about C++ "killing off" Rust, then you should be no more worried about Swift doing the same. :)
Screenshots in the Readme please
That's a fuzz on stories, not comments, and they were at -2 at the time they wrote that. The fuzz doesn't work that way.
TIL git grep :-)
It's great! I use it all the time.
This release contains Linux compatibility, so no more Apple device needed. &gt; And remember that language popularity is not a zero-sum game: if you were not already worried about C++ "killing off" Rust, then you should be no more worried about Swift doing the same. :) Well stated.
Don't tempt fate. :P
Pretty sure comments used to be fuzzed as well (not sure if they still do), but AFAIK it never actually sent comment scores into the negative as a result of fuzzing.
Well I've been on nothing but a phone since seeing the announcement, and I doubt that they have the compiler running yet on Android. :P
&gt; you're going to have a hard time finding compatible libraries. And this was, in fact, the fear of some people on the libcore stabilization thread.
This project reminded me of [This talk](https://www.destroyallsoftware.com/talks/a-whole-new-world) by Gary Bernhardt.
Which is linked in the README :)
What exactly are you sending is it just text or is there images and things in the file?
I don't care ;) But what bothers me is that some people in the Rust subreddit take it too seriously even if it is nothing against Rust. They read some comments from Steve, Patrick or Huon (sorry guys, to take you as an example. I love you! You have done an amazing job so far :-*) and think that is the last word.
Iirc the editor in Redox OS is also called Sodium.
It is pre-alpha. It is possible to do real work with the server it still lacks many features to handle HTTP. The dependencies are more mature but they also lack functions and trait implementations. The rotor crate which provides the state machines is labeled proof-of-concept.
Unlike RFC 1303, this does not handle types that are not options.
Does Swift have a runtime GC? I thought it was only reference counted (and immediately freed upon reaching zero).
There's too much legacy around the tty to just drop it entirely. sshd, for example, opens a tty to the controlling process. Programs running in this terminal will only use the tty for signal generation, though, otherwise it will behave like a socket. Believe me, I also hate the tty. This is not a shell at all, actually. But as I think I alluded to in the readme, I'm writing this because I want to write a shell.
Currently the unicode support in general is incomplete and buggy as hell, but in the long-term any failure to support any part of unicode will be a high priority bug!
&gt; Don't take the fun out of Swift for other people. I'm not trying to! I love higher level languages. I literally have a Ruby and a Perl camel tattood on my body. I think Swift is a great language. I hope it catches on. It's just not as low level. That's super, super okay. But for some applications, the distinction matters a lot. Not like "it'd be worse to use X rather than Y", but "You cannot do this with X." That's why you see some of this reaction out of Rust users; for us, this distinction matters a lot. I don't think Servo would be doable in Swift.
I have read it, and for most "usage samples" that occurs are either `Option` or `Result`. In other cases either: 1. There will be more option than one, so IMHO there should be explicitly marked that we want to ignore all other results. `let … else …` would IMHO quickly became anti-pattern, especially if `let … else let …` pattern became thing. 2. It will be some kind of variation over `Result` or `Option` and if it will be used a lot - there should be macro like `try!` which would simplify chaining. 3. The other option will never be valid and there should be used [`enum Void {}`](https://github.com/reem/rust-void) which IMHO should land in `std` and should be marked in compiler as irrefutable pattern so `let Ok(val) = foo();` should be possible (as we know that `Err(…)` cannot happen).
Hey all, wow the comments on proggit are :-(, but as I said there this project doesn't even have a working prototype that I can post pics of yet. I was planning to just update my progress in the "what are you working on" threads, I guess I should have imagined that it might blow up the first time I did that. If anyone wants to work on this, please get in touch! I actually know very little about graphics programming, so especially if you know things about that.
Like in other comment I stated: non-option types either will have more than one pattern to match against and IMHO then we should explicitly state that we want to ignore all other patterns, or it will be variation over `Option` or `Result` and if it will be use often then you should create macro that is analogous to `try!`.
I've been thinking of the same problem, actually. One of my pet peeves that I didn't see you mention yet are client queries, and terminal events. Especially in a world with windowing systems and the like, the ability to query the size of the terminal and be notified when the terminal size changes is a must. If I thought for a while, I could probably figure out half a dozen other use cases. Are you looking to support that?
Well, never thought those dropdown menus will get to me in my terminal...
You're right, swifts automatic memory management is basically Rc&lt;_&gt;. And also "class" besides "struct", which automatically wraps instances in Rc&lt;_&gt; s and gives some nice syntax on top
&gt; But for some applications, the distinction matters a lot. Not like "it'd be worse to use X rather than Y", but "You cannot do this with X." That's why you see some of this reaction out of Rust users; for us, this distinction matters a lot. I don't think Servo would be doable in Swift. Steve, this is absolutely understandable and you should definitely use Rust for this kind of software. &gt; But for some applications, the distinction matters a lot. Yep, but every time I read about low level there is someone who says that only Rust is the right tool and everything except Rust/C++/C is not low level enough. &gt; Not like "it'd be worse to use X rather than Y", but "You cannot do this with X." I never read that someone asks what the user wants to achieve and then said that language X is not the right tool for the job. &gt; for us, this distinction matters a lot. As it should be :) I understand that you want to promote Rust and to bring as many users as possible into the Rust camp. But some users need first a higher level language for lower level things to get an impression. Some users should drive first in the F3 before they can drive in the F1. #tl;dr Please, ask the user what he/she wants to achieve and then say "No, Swift is not low level/system language enough for your kind of problem. Use Rust".
I see. Unicode specifies that some chars (mainly cjk chars) are double wide, but not these characters I don't think. I'll look into how to properly support fonts like this, because it definitely makes sense as a feature.
I don't disagree with anything you've said here. If I do something else, please let me know. I love programming languages, and trying out tons of them and generally advocate others do the same, [even when it's Swift and Rust](https://www.reddit.com/r/programming/comments/3vadny/swift_is_open_source/cxlwpwn).
I came across this paper today. This is a really neat type system—kind of a fancier, more complex version of Rust boxes and references—that allows you to build most practical graphs and linked lists safely. Obviously, the complexity is pretty high, and I can't say I regret avoiding this kind of thing in Rust: the learning curve of Rust is high as it is. But it would be really neat to see an extension of Rust in this direction (perhaps as a compiler plugin of some sort?)
Yes, it would be possible, but the signatures of some methods would need to change. `take` would need to go away (leaving only `replace`), and methods like `spinlock` would require a replacement value.
I was just thinking the other day about how to design a terminal that basically renders a subset of HTML...
&gt; Please, ask the user what he/she wants to achieve and then say "No, Swift is not low level/system language enough for your kind of problem. Use Rust". He never told anyone to use Rust over Swift here. You just quoted "Swift is a systems language", and he replied highlighting one major difference. Systems means different things to different people, and the Swift definition is different from the Rust one. He highlighted that difference. Not to say that Rust and Swift don't have overlap -- given that Swift seems to be trying to be much more than an iOS/OSX thing, there's probably a lot of stuff that both langs can do well. I don't think anyone refutes that. But it doesn't fit the definition of systems used by the Rust community (and this is the Rust subreddit, so of course that's the definition we'll use) Outside of the sub I've seen Rust community members being much more careful with that term. &gt; only Rust is the right tool and everything except Rust/C++/C is not low level enough. I haven't seen that often, really. I have seen it used when something is touted as a C++-killer (frankly, I hate that term, but you get what I mean), but never when someone says "I want to build something". And it is partially justified when simply talking about low level since for many people who work on low level things, it _does_ require good performance. In these cases nobody wants to build something (so asking "what do you want to build" doesn't make sense); they're just discussing what low level is. And once again, the different definitions of systems and low level come into play, and really it's just a discussion on that. Meh. (Aside: I don't think pervasive ARC fits the C++ "Only pay for what you use" concept, but I guess with good escape analysis it can. Not sure how Swift does it now. If it doesn't, adding simple escape analysis sounds like a fun project!)
The level of discourse might drop swiftly, and that would be apple-ing!
I'd be down to mess around with it. I've been meaning to get better at graphics programming, tbh, and it couldn't hurt to learn about the details of terminal emulation. Also, I'm on OS X, so I could probably start out working to get something that'll build on both Linux and Mac.
I'm thinking of a type to represent the result -- a column or row vector. [See this code for an example](https://play.rust-lang.org/?gist=4e5f7123302b355a7218&amp;version=stable)
Thank you so much for taking the time to do that! I understand now what you mean and I think this will indeed solve my problem :)
I can't wait to see what comes out of this. Awesome job.
Awesome project, I have been thinking about something like this for along time. I have tried pretty much every terminal emulator under the sun, and every one is held back by all the things you outlined in the readme. It's also awesome that is is being devolved as a library. When it gets more mature, I hope someone hooks it up to a server and makes a real browser based terminal. If you want to give updates on the project(which I would very much appreciate), you should start a blog. RSS FTW!
Reference counting has more predictable runtime behavior than other forms of GC, but that doesn't imply that it's cheaper.
&gt; I know about every terminal project with any traction Does that include TempleOS? I don't know that it has much in the way of "traction", but I'm curious if some of the ideas he built into his terminal/editor/language/dream will ever make it out into the real world.
It took me a while to figure out what you were going for. So if I understand correctly, you're trying to produce a Python interface which is used like: x = Ok(42) y = x.match( ok=lambda val: "Things are alright!", err=lambda val: "Error!", ) print(y) Pattern matching and custom syntax sugar definitely aren't Python's strong suites, but within the context of the language, I think you've gotten as close to looking like Rust as you'll get. I'm not sure what we're accomplishing here, though, because Python already has exceptions, which are a common, well-supported error handling mechanism (that aren't possible to mistake as valid return types). If you're writing FFI bindings you probably want to translate your `Result`s directly into exceptions.
&gt; As someone who was initially excited by the possibility of Java being a "better C++" (or better M3) 20 years ago, and was sadly disappointed by its tight coupling to a closed-world virtual machine I had a similar feeling back then. Unfortunately AOT compilation was tabu at Sun and only commercial JVM vendors offer it. Mark Reinhold also explained that JNI was made as it is, as a way to discourage writing native bindings. Now Java 10 might eventually become what Java 1.0 should have been for many of us. The language competition in this space is certainly a factor that made them improve the language in this area. 
Yes, this is correct for now. I've recently made it buildable on OSX, but it only collects coverage for Python and Bash scripts there. (And to be honest, I haven't actually tested it yet! :-) ) I'm not familiar with how OSX binaries work, but I'm pretty sure they use the DWARF debugging format just like Linux, so most of the binary parsing code should be reusable. ptrace() support is, from what I've heard, quite different on OSX, so that needs a complete rewrite in kcov.
I'm excited what the future will bring in this regard to Swift. Maybe there will be a cross platform library from the community? But when reading the swift 3 guidelines, Apple quite stresses the fact that New swift 3 stuff should be cross platform, so I guess more and more of Foundation will flow into the Swift repository 
Sorry Steve, it was not directed against you. You are doing an amazing job and I would love to see more people like you in the open source world.
I've met similar difficulties when writing my wayland lib : by default the events handling provided by the C library is callback-based, which was a huge pain to deal with in Rust... (`Arc`s and `Mutex`es everywhere ! ) In the end I decided to completely flip the handling model, and I collect all events generated by the lib into a buffering iterator, which can then just be iterated over to get the requests and handle them. I don't know if such an approach can be adapted to you case though, wayland is overall rather friendly about this, but all situations cannot be handled like that.
So pretty much an event queue? Or could it be classed as an event loop?
Cool, let's get in touch.
Note that they have now more stars that [any other programming language on github](https://github.com/showcases/programming-languages). Is the tooling support really awesome in swift? Anyone has some experience?
It's fine. That many stars means lots of light. Lots of light, very suddenly, means they're going to be blinded. Them being blinded gives *us* a chance to sneak up behind them and tie their shoelaces together, borrow mutable access to the laces, then run off giggling.
I'm not sure that tooling is the only thing that matters here. I just think a lot of people are excited about the launch. More people know about swift than about rust. I mean, it was discussed in an apple keynote! Finally, it's not like (the most widly used implementations of) Java, C++, C, or many other popular languages are (primarily developed) on github.
It is worth noting that file operations are stated as a non-goal on the github page.
Yeah you are probably right. I kinda forgot about this keynote announcement for a moment. It was just a bit crazy to see a project receiving 13000 stars in less than one day. I thought I was missing something.
Which kind-of makes sense. But IIRC the Linux async io system calls employ an epoll-able file descriptor where completed io operations can be read from. This could work nicely with a common interface for polling together with network io. But I have no idea how this works in e.g. Windows or OSX. If it isn't feasible to implement it in a cross-platform manner, it's probably not worth doing.
&gt;To achieve these ends, notty will implement a new and more consistent escape protocol than ANSI escape codes. Postscript, or [Display Postscript](https://en.wikipedia.org/wiki/Display_PostScript) (or another modernization)? [DSP PDF](http://partners.adobe.com/public/developer/en/ps/sdk/DPS.refmanuals.INTRO.pdf)
You could make Ok and Err share an abstract superclass that would implement most of the behaviours in terms of a single abstract method (match). At least that's the way I went when trying to imlement it. However I didn't bother with the type hints (at least for now).
You're welcome. My experiences with Ruby are also why I feel strongly about this...
The multi-threaded event loop is a non-goal as well.
Out of curiosity, is it then possible to implement on top of mio ? (and if so, how would it be done ?)
&gt; You could make Ok and Err share an abstract superclass that would implement most of the behaviours in terms of a single abstract method (match). At least that's the way I went when trying to imlement it. However I didn't bother with the type hints (at least for now). This is the approach that PyMonad takes, I believe. The problem is how to do type hinting for that. I should probably just try writing it that way but I foresaw some issues with type hinting.
Gtk+ Bindings would be neat as GObject ist very similar to the ObjC model. 
Getting pretty far off topic, but since I have studied linguistics, I'll bite. What is your basis for disagreeing? Do you have research to cite, or are you just going based on your gut feel? As it turns out, bkkgirl is correct. Comparing languages that seem completely different, like Chinese and Esperanto, is like comparing Ruby and Python or comparing Java and C#. All natural languages live in the same "space." They're all operating at a roughly equal level of abstraction and verbosity, and are used for the same things. Natural language has no concept of "high level" vs "low level" languages, or "system" languages vs "application" languages. To say it another way: there's no concept of suitability to purpose for natural languages--they are all roughly equally suitable to every situation, provided the people around you also speak the language. Not many people would claim the same for programming languages: most would say that choices like C or Rust are clearly more suitable to embedded programming than C#, no matter how many of your friends and coworkers love C#.
I am not a Linux async IO expert, but I believe that when you use those APIs, you lose a *lot* that is provided in the sync apis, like caching...
I started on something but don't really have time to finish it right now, you are welcome to use it, or ignore it :) I had some problems with the metaclasses I imported, so I had to stub out type defs for `EnumMeta` and `GenericMeta`. I had to make a new metaclass because `class Result(Generic[T, E], Enum)` gave me a metaclass conflict. It uses the new `enum` module, I so believe it is python 3-only (unless there is a backport of the enum lib?) from enum import Enum, EnumMeta from typing import TypeVar, Generic, GenericMeta T = TypeVar('T') E = TypeVar('E') class ResultMeta(EnumMeta, GenericMeta): pass class Err(Generic[E]): # ... Err methods like you already have class Ok(Generic[T]): # ... Ok methods like you already have class Result(Generic[T, E], Enum, metaclass=ResultMeta): Ok = Ok Err = Err # example def returns_result() -&gt; Result[int, str]: return Result.Ok(4) 
Oh, wow, I didn't know that. It seems like Ocaml does not have those utility functions generated, so I just assumed SML didn't either.
Also, only the most basic things are available in the async interface. It's pretty much impossible to avoid using the sync apis entirely.
I'm not sure about OCaml, but in SML, tuple access is a special case of record access, where the field labels are consecutive integers. Where some languages (like Haskell) desugar records into tuples, SML desugars tuples into records.
Congratulation to the mio team. ------ What about the API mismatch between windows and unixes, can you explain , in high level, how it was solved? Does mio provide the same performence characteristics in both unixes and windows?
I'm not sure how you would ever be able to get well-typed scripting in a shell. Unfortunately, Unix relies entirely on serializing to and from raw text, with no type guarantees. You can try being well typed in your own space, but the second you call out to `cut` or pipe data from one program to another, everything is lost. In order for a fully typed shell to work, it would require an entire new user space where all programs have strongly typed input and output. Urbit actually is trying to go that way, but has to be radically different and incompatible with Linux for it (more than it would be otherwise, at least)
I think file IO would need to be provided by another library (that probably would work with a thread pool), and some third library would provide both under a common abstraction.
&gt; I see this sentiment so often that I have a fear of Rust turning towards Haskell, where every file begins with a list of "non-standard" pragmas, which are actually de-facto-standard, but for those across a certain threshold. Rust doesn't have a spec. So there's no such thing as "standard" to begin with. &gt; Compiler plugins of that kind also turn Rust into a language that can never be practically ported, as all plugins or the plugin API would have to be ported as well. The plugin API is part of the compiler. So porting the compiler automatically results in a port of the plugin API.
Probably the way this hypothetical plugin would work is that you'd only turn it on for the modules where you actually define the graph data structures, so performance would be less of an issue since those modules would be so small. The nice thing about the Rust type system is that once you've proven those specific modules to be memory-safe *in isolation*, the basic rules suffice to automatically prove the rest of your program memory-safe.
I think mio doesn't want to have anything to do with file I/O. Perhaps this third library would be forced to re-implement mio+file i/o on Windows and use mio on other platforms. Yeah doesn't seem optimal.
I would be happy to reopen the discussion post Mio 1.0. In general, I am not familiar with use cases where it is beneficial to mix network &amp; file operations in the same event loop.
Nice, thank you. I may take some of the work here and apply it to what I have.
You can even simplify `same_object` down to: fn same_object&lt;T&gt;(a: *const T, b: *const T) -&gt; bool { a == b } There might be cases where it can't automatically cast, but in the basic case it seems fine: http://is.gd/m9d90m
You can re-implement the coreutils, or have a file that defines what "types" the tools return, but that doesn't work for any 3rd party binary. Parsing the output of a tool that prints a log would still operate on strings, unless you build a community around describing the output of tools and have it easily distributable (and checkable, since if you don't cover all corner cases you have an unsound type system - but since you are converting arbitrary text from an arbitrary binary, you can't automate it without fun halting problem things) The way I see it, you either try and implement a strongly typed shell scripting language that is purely opt-in and useless for 3rd party tools, which fall back to unix "everything is a string", or you drop 3rd party support entirely :/ Sorry about being a downer, btw! I'd still love to see your take on it, just me musing about the idea.
The type system would be implemented using a serialization library that would serialize types native to the language of the application into the serialization format, which is isomorphic to the shell's type system. Obviously, tools would need to use this library to gain the advantages of it. That's kind of tautological. Insofar as type declarations are necessary, I would definitely want it to be performed through xattrs or something like it on the individual files, rather than some sort of centralized truth store about the types of all applications. And as I said, this would need to be a gradual type system, with dynamic type guards around any IPC to fail correctly when it violates the type contract it has declared (and to do something sane when it hasn't declared a type at all). So if you pipe cat into grep, it works as expected. But if you pipe something that outputs Set&lt;Integer&gt; to something that takes Set&lt;Integer&gt;, the data is properly deserialized into the analogous type in the language the receiver is written in, and it TypeErrors if it gets something that isn't a Set&lt;Integer&gt;, and so on. EDIT: haha whoever downvoted this comment: chill thanks for your input
How is replacing `T` with `_` an improvement? It's exactly the same character count, and it forces the reader to do more type inference.
And I thought I had seen the most nightmarish signatures toying with C++ meta-template programming... ... now I doubt!
Hmm... if [this](https://www.reddit.com/r/rust/comments/2u53le/this_is_a_doubly_linked_list_in_safe_rust/) (which Google turned up now) is what I'm remembering, then it was actually *cwzwarich* who mentioned it in a discussion you were also a participant of. In that case it's my memory that's unreliable, which it always has been :P
I think that a lot of this noise is simply due to Rust syntax. Namely, lexical syntax (&lt;&gt;::&lt;&lt;&gt;&lt;&gt;&gt; everywhere) and the way things are namespaced. Another is that you can't abstract things that happen in the type level as easily as abstracting things at value level. There are no type-level functions, etc. There are dependently typed languages (that in theory have a more complex semantics) that nonetheless are easier to read, at least in this use case.
[This](https://www.reddit.com/r/rust/comments/2u53le/this_is_a_doubly_linked_list_in_safe_rust/co5dxc3) comment is gold, I really really want Rust (at least Rust 2.0, 3.0, I dunno) expand its reach on "things that can be proven correct at compile time"
But isn't `F&lt;a&gt;` applying a type constructor (function!) `F` to an argument `a` of type Type? I always that that was deliberate from the beginning -- for `F&lt;a&gt;` to mirror the syntax of `f(a)`.
True. There is a lot of repetition in this code, so it could be made a lot more readable just by binding some types to names, if it was possible inside `where` clauses. Since it isn't, the code looks as it looks. But it isn't too surprising, since this can easily count as abusing the type system ;)
I think the current `try!` could be extended with your `=&gt;` syntax (in a backwards compatible way, since it would be a syntax error anyway)
Yes, and that "for each" is what we call a function! `F : forall . (a : Type) -&gt; Type`. `Some(a)` is also a function -- `Some : forall . (x : a) -&gt; Result a`.
If you view it as a function, `Some` is injective: if `Some(a)` is equal to `Some(b)` then `a` is equal to `b`. It also always create a new value (for any `a`, `Some(a)` isn't equal to any value created by other constructors) Rust standalone functions, methods and lambdas are more general, and can indeed perform arbitrary computation.
Rust reserves the right to reorder fields as necessary for alignment purposes. It doesn't currently do that but it's recommended to not rely on the ordering of fields in non-`#[repr(C)]` structs. I don't know if Rust initializes fields in memory order (which would silently break this if Rust decided to reorder these fields in a later release) or in declaration order. Either way, it's probably a good idea to do the order-dependent stuff in separate statements. It's also much clearer to the person reading the code that the initialization has to be done in a certain order.
Or pushing it to its limit? :)
Well, yeah. But that's why we encourage use of stable! The entire point of ensuring that `#[feature]` doesn't work on stable is to avoid the Haskell situation described upthread, after all!
Build it as a compiler plugin! There's no reason why this stuff has to be developed as an official up-front-designed-and-specified feature. In fact, I would argue against doing that for this kind of huge work. If the plugin gets lots of traction, then it could be upstreamed. But the design has to prove itself viable and popular first. I've found Reddit upvotes to be an especially poor proxy for whether stuff is actually going to get used.
The code is purely generated from a custom #[derive], so nobody will see it, but you're right that it couldn't hurt to do the method that will definitely always work!
Doesn't Swift use green threads? Scheduling them is a form of runtime. In any case, [this comment](https://github.com/apple/swift/pull/17#issuecomment-161847725) in that joke states Swift requires a runtime (but I dunno if it just means "a standard library")
Swift is not adequate to write kernels, or to write programs that require precise control of memory management. Rust is competing in a different niche (but they overlap in some areas)
Naive noob question: I need to use a lot of byte sequences that are up to 64 bytes, or up to 256 bytes. The up to 256 byte sequences will be used in other structs which if inlined, the largest of which would end up around the 520 byte mark. Up to a dozen or so of these structs will end up in a Vec. Are these sizes small enough that inlining them as arrays rather than Vecs would be worthwhile?
Awesome to hear that you want to improve the docs! Thank you so much for clap!
I was pretty sure that tuples, structs, and arrays are always initialized in order you write initializers (which could differ from field declaration order). But I tried to find some documentation to that behaviour, and I can't. So now I'm confused. I'm often writing code that relies on that behaviours! (But please note, that it's only for tuples and struct literals, **not** function calls and expressions). I've found some tests in `rust/src/test/run-pass`: [struct-order-of-eval-2.rs](https://github.com/rust-lang/rust/blob/master/src/test/run-pass/struct-order-of-eval-1.rs). Also 1,3 and 4. --- Edited, because I've found some kind of proof.
Not in that case, but If you are doing the comparisons inside other code _ is the better option. 
The worst part is, this is still pretty understandable to a third party (that knows Rust). The signatures will only get worse.
&gt; However, one thing we discovered was that it was impossible (as far as we know) to implement a zero cost rust safe abstraction on top of IOCP. Why is that? Wouldn't the same techniques as used with threads apply here as well?
I personally have a huge amount of respect for Rust, as well as for the team of folks who have been designing and building it. I think that it is fair to say that Rust is better than Swift at certain kinds of system programming at this point in time. That said, the grammar and design of Swift specifically anticipates the notion of single ownership and borrowing to avoid the costs of reference counting. The major philosophic difference between Rust today and Swift-as-I-envision-it is that Rust forces you to think about ownership everywhere, but Swift-as-I-envision-it should only force you to think about single ownership &amp; borrowing if you want to optimize performance or guarantee that you have no encounters with the runtime. If it helps, think of the extant Swift "inout" parameter modifier as being equivalent to "&amp;mut", and imagine the logical swift extensions to support the rest of the Rust model. This is a really important area for us to develop, but it also isn't the highest priority of the team. That means that Rust will maintain a lead in this area of applicability... unless someone motivated and capable from the open source community decides that it is really important to them, and makes it happen sooner. -Chris
Yes. Follow along in the 'mio' branch. 
Yes left to right initializer order is the semantics and will remain so AFAICT. The thing that might change is the order of *destruction* for the elements of tuples / structs / arrays. See also https://github.com/rust-lang/rfcs/issues/744
Multiple threads on one epoll is how e.g. nginx achieves high throughput. Yes, you have to deal with synchronization (but epoll itself is thread safe) but there's no free lunch.
Yes, async io doesn't go through filesystem cache (that's the whole point, you get zero copy dma from disk). If you want async io with caching, using mmap with madvise/fadvise achieves that. Both have their uses. Async io without caching would be useful e.g. when reading or writing large buffers (megabytes at once) that are used only once.
&gt; What do you have in mind when say a multi-threaded variant of EventLoop? Something like nginx where you have a low number of high throughput sockets and requires significant cpu (e.g. crypto) per read. Many threads use one epoll and then proceed to read/write the socket and process the data. In particular this is important with udp where there is only one (or a few) socket for many clients. &gt; one EventLoop per thread and shard sockets between them This leads to non-optimal load balancing. And doesn't cover the udp use case.
Actually, my purpose for this lib is doing things with GTR, so metric tensors and Christoffel symbols will definitely be included, but everything will be calculated numerically, not symbolically. But making it possible to also use symbolic calculations... That is definitely an idea worth investigating in the future ;)
&gt; even easier than Python scripts :P ...hardly a high bar to pass. Pypi's unreliability and the distribute/setuptools/easy_install mess is a real pain point in python, and trying to distribute bundled binaries is still a massive problem. ...but yes, but go has an excellent cross compile story, and is easy to get into, it's a great choice for web apps.
Just a question, do you know either C or C++?
I have absolutely not first hand experience with Swift, but I have heard from friends that it's quite good. The error messages are apparently a bit odd, but that can be dealt with. My impression is that it already has some momentum in the industries, so it may be the better choice if your goal is job opportunities. What I _can_ say is that Rust is alright for web development. It's not the same as using the usual PHP, NodeJs, etc., since those are either specifically designed for web servers or has a very forgiving type system that lets you skip some steps (sometimes at a cost). Rust server libraries will, on the other hand, do their best to use the type system to make sure that there are fewer invalid states, and thereby fewer cases of "where did that come from?!". Rust programs are usually not very surprising. In the end, I would actually recommend you to try both and see which one feels like the best language for you. My negligible Swift knowledge tells me that they are similar enough to be about equally good for web servers, so I suspect that there is no real right or wrong. It's all about what you like in a language.
I would go with Java or Scala. In web programming you can assume that you will be on equipment that is powerful and you will have memory. This negates the downside of the JVM. Rust is a great language, but I don't think web support is near Java or Scala Play levels yet. They are also (like Rust) very good multi-threaded languages, and you can scale well that way if needed.
That sucks. I got lucky, where I work we use Haskell. It's not as hard as everyone thinks
That is true. This is what I told my coworkers as well. They also scared that they lose the ability to read/write the imperative style :(
Noooo!! The more you answer, the more it asks, it's impossible, no one can pass it.
Web programming is a very broad definition and that makes it kinda hard to give a proper advice here. Let's start with Swift. I don't think that it has any potential for becoming next goto language for web development. It's not only because it's primary focus is Apple platform making it a new language with baggage of an old one, but it also provides no actual value comparing to existing languages. All its features look more like random syntactic sugar than well thought tools. As far as know there are no major frameworks/libs yet. From educational point of view it might be worth looking at, but won't make you a better developer. One the other hand there is Rust, which I believe has a great potential for becoming an awesome language for any kind of web development. With powerful type system, macro system and compiler plugins you can write very complex libraries that are easy to use. Rust will teach you a lot and will help you to become a better developer. Unfortunately Rust's ecosystem for webdev is not there yet. There are, of course, great existing libraries like mio or hyper and some new promising developments like diesel, but they are yet to become building blocks for something bigger. I think that a library like finagle/wangle will emerge at some point, but it will take some time. I've made a half baked prototype of such framework and I'm pretty sure that it will be quite an undertaking to write a production grade lib of this kind. Other languages mentioned here so far: I'm not very familiar with JVM based languages (Java/Scala) because they are usually no go from ops perspective, but there are a some interesting and production grade libraries (finagle) that are worth looking at. (Scala has a very interesting type system, worth looking at) Go. It's hard to write about this one, because at the first glance it is awesome for web dev, especially for different kinds of messaging passing, routing or queuing stuff. It's very easy to write network services in Go in general. But if you'll try to write a REST API with a lot of repetitive CRUDs then you'll have a lot of pain dealing with. Stuff that took you 1-2 lines of code with ruby/js will take 15-20 lines and you'll have to write it again and again and again. It's nearly impossible to do complex abstraction in Go. Lack of generics and proper type system in general is to blame for this. Nevertheless given that Go is a very simple language I think it's worth looking at, at least for the purpose of learning about coroutine style concurrency. 
It just takes 15 min max!
Elixir :)
Or Scala. :P
You can use `.split_at_mut()` to create a wrapper function which returns two separate mutable references into a vector. Edit: example because I was on mobile before: http://is.gd/FhqqRp
&gt; If that makes sense in English :) Just a note (with apologies): it does make sense, but its 'too easy' not 'to easy' and most commonly people write 'Go is too easy for my taste' instead of the order you chose. I hate commenting on peoples' grammar, but since you mentioned it I was confused at first and thought you had just skipped typing a word or two between "Go is" and "for my taste" (which I do all the time).
I think the short answer is that while nothing stops either language from being a good language for web development, currently neither language has the kind of library and framework support that a lot of people want when they start a web project. I think Rust is further ahead here, and you can check out http://arewewebyet.com/ for links to a couple of different relevant crates. Since you want a functional language that is not as exotic as Haskell, I would recommend considering Scala as a language that has more support for web development right now.
Could you point me to where this behaviour is documented (if it is)?
But I can't do that and still have VecHolder be the owner, can I?
I don't understand. It only borrows a mutable reference to the slice/vector, VecHolder still stays the owner. It doesn't modify the vector itself at all, it's just a safe way to get two references into it.
Yes. It makes a lot of sense to use one epoll with many threads. This lets the kernel take care of load balancing.
You need to expose the functionality some way, such as by having vecholder implement a method that calls split_at_mut, by making the vec a public field, or by implementing this logic inside a method on vec holder. Can't really say which of these is best.
This type level programming is really interesting! Could you suggest good learning materials about the topic? Thanks.
It took me too long to realize this is about networking (like TCP/UDP) and not like increasing social connections "networking".
This is a great response, thank you! I think I'll implement a simple standard iterative algorithm with transposing for now. Then I'll try adding some divide and conquer logic for larger matrices after. Thanks also for your sample structs. Right now I'm using Vec's instead of Box's. Is there any notable performance difference?
&gt;In my experience things that are only reluctantly open, like Swift, rarely thrive in an open way. They tend to continue closed, sometimes small-minded development and issue releases in one direction only. Sometimes, they stop bothering and become closed again. &gt;Apple is one of the most obsessively closed companies in the world. They have sometimes banned apps from iOS simply for being open source. Uh, you know Apple is also the main company behind LLVM, the extremely successful open source project that powers rustc? And that the LLVM creator, who stills works at Apple, also created Swift? I'm disappointed to see this FUD about Apple here.
You're welcome! &gt; Thanks also for your sample structs. Right now I'm using Vec's instead of Box's. Is there any notable performance difference? Just one additional `usize` field for capacity in `Vec`, and no additional runtime cost, so it shouldn't really matter. I've written `Box` instead of `Vec`, because in original it was: struct Matrix { width: uint, height: uint, data: ~[f32] } But now I realize that while `~T` had changed to `Box&lt;T&gt;`, the `~[T]` was actually a vector (with capacity) hardcoded into language, so I've should written `Vec` in the first place.
&gt; Unfortunately, quite a lot of projects that encode operations into the type system end up pretty hairy to read So worth it though.
It doesn't really. I've been waiting until they stabilize.
I heard Elixir has optional type checking but I didn't get to that point in learning it yet. Scala does have your beloved TypeSafe™ properties, Haskell typeclasses and BEAM's Actor concurrency model implemented in Akka. It may be your best bet. I don't like JVM though, but it's my personal thing.
&gt; and has a slick REPL. Swift's type system has more kinds of things (protocols, structs, classes, extensions), but each one is a bit simpler; Rust concentrates its type complexity in a fewer number of more subtle and powerful concepts (traits). Rust has built-in support for fixed-size, interior arrays; Swift has built-in support for reflection. I think a good enough REPL and a sizeable amount of compile-time reflection could be good for Rust.
It would, but. We are publishing the book through No Starch, so once that comes out, it'll have an ISBN and all that. The authorship there is "The Rust Project Developers". Oh, and OP: as part of this work, a bunch of stuff may shift, so sorry in advance :(
It *could* look a bit better. The whole `&lt;A as Op&lt;B&gt;&gt;::Output` syntax could be a lot nicer. I really wish something other than `&lt;` and `&gt;` were used so my text editor would highlight matching parentheses. The `as` also seems out of place. I get that it's a type-casting operation, it just doesn't feel like one. Something like `A.Op(B)::Output` would clean up a lot of it. I don't know if it's a good idea, but another possibility would be to have a flag to tell the compiler "insert necessary where clauses so it'll compile".
Any ideas for how specifically I might amend it? When I was initially writing it I felt like I was writing a flyer you might put up on a notice board on student halls, so I see where you're coming from...
I know its out of date, its just the only good list I know of Rust web libraries.
&gt; have sometimes banned apps from iOS simply for being open source. Nonsense. I suspect you're referring to VLC being pulled over what was publicised as a GPL dispute. Apple only took the project down because VLC's own developers petitioned Apple to pull the project down (essentially an ownership dispute). The dispute was settled and VLC is now back on the App Store and it is still a GPL project.
Fair!
I'd like to hear more about how the dispute was "settled", because it wasn't an ownership dispute. [This article gives a good rundown on the issue](http://www.zdnet.com/article/no-gpl-apps-for-apples-app-store/) and it boils down to "App Store policies restrict freedom in ways that the GPL (and other licenses) explicitly forbid". Unless anything has changed about the App Store since then, it would seem that broad strokes of the Free Libre / Open Source software community are locked out unless they agree to sublicense their code according to Apple's demands, which requires in turn that all contributors who've ever licensed code under a rigorous license agree to water-down also. This is not a design flaw of the GPL and other licenses requiring freedom. It's the very point, and Apple stands out as a rare example of a vendor that has made a point of forbidding license terms that guarantee freedom. Has that changed?
I don't think there's a way to do this at compile time, since the number of borrows depends on whether the indices requested are the same. You could definitely do this with unsafe code and runtime checks. `unsafe` really is there for "listen, compiler, I know it's hard for you to understand, but just trust me".
That's awesome.
I think it would help if there were even just one word that's specific to the networking you're talking about, for context.
When I read the headline, I/O networking is what I assumed it was. Then I read the google groups post and assumed I was mistaken. " whether you're looking for support, announcing a new project, or looking for input on an existing one." -- that made me assume it was the social-oriented use of the word "networking." Now revisiting this thread I see I had it right originally.
Even though this is an evil hack, I'm curious to understand what is going on. I'm not familiar with some of the type constraints syntax here. Could you help illuminate or annotate what is going on in that link?
&gt; From crypto flaws, side-channel attacks, unvalidated user input, bad file permissions, misconfigurations of software, XSS flaws, sql injection... these extend way beyond the programmign language. While I agree that a language is not necessarily the place to 'solve' every security problem, I think it's interesting to note just how much beyond memory errors a type system can protect you from. For example, you can encode information into the type system, providing safety that can go beyond memory safety - you can ensure that invalid state is handled, or that data of a certain type can only be treated in a certain way, etc. I've been using it to ensure that connections to an IMAP server are valid, and you can't make commands from an invalid state. That insane tensor thing up there provides a more semantic security than memory safety. Naturally it's not a perfect solution but I'm excited to see the type system used more to ensure semantic / non-memory-safety errors.
Apple have never had a policy either for or against GPL on the App Store – that's the inherent falsehood. Apple only ever removed apps after VLC's own developer community objected (or more specifically: Rémi Denis-Courmont objected). Similar objections by apps own developers have affected GNU Go and a few other apps. In no case have Apple removed apps of their own accord; it's always been in response to community raised licensing disputes. Yes, members of the VLC community asserted that it was against GPL to have VLC on the store due to the GPL requirement that you must be able to recompile and reinstall the code without restriction. Specifically, Apple's App Store and developer account terms and conditions were held to violate section 6 of the GPLv2: &gt; You may not impose any further restrictions on the recipients' exercise of the rights granted herein. Which is a very broad statement. Any click-wrap license probably violates this. In any case, to avoid any dispute a scaled down version of VLC was briefly released under Mozilla Public License v2. Since iOS9, Apple have allowed anyone to install apps for free using Xcode (you no longer need a paid developer account). This distribution method has no restrictions provided you are only using to install directly onto your own device from source code not binaries (F.Lux got into trouble for distributing Apple signed binaries this way). Following this, full VLC under GPL is available again and most people agree that the store is in compliance with GPL 2 since you can recompile and install from Xcode at any time with no restrictions. Although many still feel that *any* terms – including Apple ID terms and conditions which apply to running iOS in the first place – violate section 6 and so there remain objections. The point remains though: at no point did Apple have a policy of rejecting apps based on the GPL. VLC and GNU Go never violated any of Apple's terms and conditions. Apple have only followed the wishes of the apps own developers.
http://pastebin.com/RFKLPKet How's this look? I wouldn't necessarily implement those new functions taht way, I'm just trying to demonstrate that you can write the impl for the enum or for the objects.
I understand this is a bad idea and that Rust is not the right language to do this in, which is why I wanted an alternative to this. I looked into enums and I think they will work for what I am doing. The important thing is they are fixed size and they can store varying amounts and sizes of data.. Thanks for the idea, but I don't really know what I am doing here anyways so I will likely run into more problems.
Do you require being able to add new animals after the definition of AnimalVariant? (eg: in another crate).
No, all of the variants are defined already and new ones are never added.
Seems like nobody pointed out `RefCell`s yet? If you don't mind the (likely insignificant) overhead of using a refcell, you can do: struct VecHolder { vec: Vec&lt;Vec&lt;RefCell&lt;String&gt;&gt;&gt; } impl VecHolder { fn get(&amp;self, index1: usize, index2: usize) -&gt; &amp;RefCell&lt;String&gt; { &amp;self.vec[index1][index2] } } /* ... */ let s1 = v.get(i, 0).borrow_mut(); let s2 = v.get(i, 1).borrow_mut();
To be fair, I've never heard of anybody ever using Darwin for anything besides Apple building OS X on top of it, or people browsing through the source trying to diagnose OS X bugs. It's not a good example of Apple's open source projects "thriving in an open way"
I dont know if your real case allows this, but perhaps you can change the data type from `Vec&lt;Vec&lt;String&gt;&gt;` to `Vec&lt;(String, String)&gt;` (or even `Vec&lt;MyRowStruct&gt;` ) and use destructuring http://rustbyexample.com/flow_control/match/destructuring/destructure_tuple.html This requires all rows in the matrix to have the same length.
Neither. Rust's sweet spot is systems programming, Swift's is iOS GUIs. You'd be far more productive in Java or C#, which is now truly cross-platform. If you want a more fashionable language, try Go.
I think I can, once I find the time. I may be giving a talk about it at the Rhein-Main Rust Meetup in Frankfurt next Friday, and perhaps blog about it, too.
Neat, looking forward to reading more. (Won't be in Frankfurt though!)
The F# community is in the middle of things here. The vision is to get F# ported over to the CoreCLR. The [CoreCLR](https://github.com/dotnet/coreclr/tree/master/Documentation#get-net-core) is a subset/refinement of the full .NET Framework runs on Windows, Mac, and Linux (it's in a Release Candidate state at the moment). Here's a [tracking issue](https://github.com/Microsoft/visualfsharp/wiki/F%23-for-CoreCLR---Status) for F# being ported to the CoreCLR. The general intent from there is to get [Open Web Interface for .NET](http://owin.org/) (OWIN) compatible web stacks, in which F# is somewhat behind. There's an effort for making a functional web stack called [Freya](https://github.com/freya-fs/freya) that's underway. If you're looking at making F# web applications right now on Mac/Linux, I think you'll be limited to using Mono, which involves writing F# in a C# framework. 
I will answer as someone that made similar question some time ago here. I write Node.js and Go too. Do not use Rust if you do not need it's performance for web development. I am building huge project atm, i will use node, Go and Rust for it. Rust will be used for the high performance part in which i have a lot non-human clients communicating with web api. Using Rust for all is just overkill and counterproductive. If you do not need it's performance then use node.js which you use normally, you will be a lot more productive in it than in Rust, like n times. Another thing is your team good enough to write Rust? Writing good javascript in node.js is VERY EASY compared to writing efficient good Rust code. I know a lot of people writing in node that will not handle Rust. So to sum that up. Every language has it's use. You don't do web development in assembler for a reason, but you could if you wanted. Analyze constraints for your project then pick the right tool for the job.
Oh, right. I was sort of talking about web development where these components already exist as a black box to be used. But yeah, these things would benefit a lot from Rust. Would love to hear more about your experiments when you try them!
Unfortunately those aliases would make `impl` coherence undecidable.
Sidenote about Go example. In Go, you are more likely write http://play.golang.org/p/-mcVm7zzT1; I cannot imagine a real-world example where you would want to return an error. Also, keep a generate comment to rewrite all Int8 + Int8. Embedding value in a struct with NaN flag would also be another option (`struct { V int8; IsNaN bool }`). Of course, I would love that addition would panic on overflow and there would be separate operators for saturating and wrapping addition.
&gt; although it's quite a lot of work to set up and leads to fun code like [this](https://github.com/fizyk20/differential-geometry/blob/master/src/tensors/variance.rs#l205-l218). If you are going to write type safe generic code, you will have to accept that the amount of declarations needed follows the complexity of what you're trying to generalise :) The pay off is compile-time errors instead of runtime errors.
It's OK, I'll have the slides up on my github at least.
&gt; I'm not very familiar with JVM based languages (Java/Scala) because they are usually no go from ops perspective I wonder what all those devops at Amazon, Google, Twitter and similar size companies are using....
Hopefully this is stable soon because it's a very necessary tool for writing good FFI. Right now people wanting to interface with C code that wants to call back into Rust have a very difficult decision to make: risk unwinding across the language boundary, or use nightlies and risk alienating a good chunk of potential users?
Different allocators will only cause an issue if you will try to allocate in Rust and free in C or vice-versa but you shouldn't do this. It also increases size of the binary but it is usually not a big issue.
It seemed from the syntax that you would be allowing people to define type-level λ-abstractions, which would mean that `impl` coherence has to perform unification modulo β/η-reduction. Would you have some syntactic restriction to avoid this?
Heh, the post link already broke. Thanks for the canonical link.
I genuinely had no idea this was going to be such a problem! At least I now know for future reference that *networking* is not such a clear-cut term outside of my little bubble :)
As I said, as far as I know, the alias I defined is *literally* the same as `&lt;A as Add&lt;B&gt;&gt;::Output`, i.e. they are fully interchangeable, i.e. `type` could be implemented as a syntactic preprocessor (replacing `Plus&lt;A, B&gt;` with `&lt;A as Add&lt;B&gt;&gt;::Output`), and hence `impl` coherence already has to do (or make conservative assumptions about) whatever beta-reductions/eta-conversions you are thinking of. However, I'm not an expert on the type theory terminology, so an example of something that you think may be problematic would be great? e.g. are you thinking of `impl&lt;A: Add&lt;B&gt;, B&gt; Trait for Plus&lt;A, B&gt; {}` (which is illegal)?
Did you mean [clippy](https://github.com/Manishearth/rust-clippy)? It doesn't have a lint to detect this...yet...
I'm not familiar enough with your terminology, but I thought that aliases were only useful for us, the programmers. As far as I've observed, the compiler performs the substitution before trying to do anything else. At least, if you do something like type A = u32; let x: A = 7.0; you get an error about `u32` and not `A`.
Except that the system allocator might not match the allocator that the C code is using. In particular I'm looking at Windows where the Rust system allocator uses `HeapAlloc` which isn't the same as the `malloc` used in C code.
I am coming from Java/C# background and fairly new to Rust and C. Let's say I am providing a function which is called from a program written in C. When the function is called I might do some memory allocations, and return allocated structures back to C program. From this moment isn't the C program responsible for freeing the memory?
Why does Rust uses `HeapAlloc`? (that is, in which ways it's better than simply calling `malloc`)
Is there a place where I can read about this?
As I understand it, `&lt;A as Op&gt;::Output` does a type cast from `A` to the type corresponding to its implementation of the trait `Op`, and then gives the associated type `Output`. Essentially, it lets you use the trait `Op` as a unary operator on types. You can define the trait `Op` to be a binary operator as well, with the syntax `&lt;A as Op&lt;B&gt;&gt;::Output` or `&lt;(A, B) as Op&gt;::Output` depending on how you define it. For convenience, [here](https://github.com/fizyk20/differential-geometry/blob/71c87a907417e6d782330e5e09e7ea0ba9e8fa81/src/tensors/variance.rs#L205-L218) is a fixed link that highlights the right code. Basically, the only line that does anything is type Output = &lt;&lt;V as RemoveIndex&lt;Ul&gt;&gt;::Output as RemoveIndex&lt;&lt;Uh as Sub&lt;U1&gt;&gt;::Output&gt;&gt;::Output; which does a sequence of type operations as discussed above (only now they're nested), and sets the associated type `Output` to the result. All the gobbly-gook in the `where` clause just says "hey, only define this `impl` when I'm able to do the operations that I want to do". For example, one such operation is `&lt;Uh as Sub&lt;U1&gt;&gt;::Output` so we need to be sure there's an `impl Sub&lt;U1&gt; for Uh` in existence in some form somewhere, which is done with `Uh: Sub&lt;U1&gt;` in the where clause. Now that I've typed all that, I'm not sure it's actually helpful. I wrote the peano numbers in Rust's type system, and that provides a much simpler version of all this hackery. It may be easier to grok. You can find it [here](https://github.com/paholg/peano) if you're interested.
Putting aside the question of undefined behavior, I think all DWARF unwinders will abort on an unhandled exception. They do differ on whether they will call destructors on the way down; some of them specifically do not invoke cleanups for unhandled exceptions.
Just pointing here that a flat memory **is** the way to go. A simple `array[i * len + j]` is way greater than doing that fragmented and unnecessary `Vec&lt;Vec&lt;_&gt;&gt;`.
That seems a legitimate case for it still be UB, but I'd like to have this more defined (the notion of "undefined behavior" of Rust is very limited compared with C, defining some aspects of unwinding to another language would be a step in this direction)
FYI: [RFC #560 "Integer Overflow"](https://github.com/rust-lang/rfcs/blob/55d1032776bc5fac167a0044eaeab81c6a44fc14/text/0560-integer-overflow.md)
But you don't have a `Box&lt;[i32; 1_000_000]&gt;`, you have a `Box&lt;[i32]&gt;` which is fat, so you can't transmute, right?
The thing function wouldn't compile, because it's undefined how operator + should work.
Then I'm afraid this idea is so burdensome that it stands no hope of ever being adopted. Lifetime annotations are already pushing the limits of what many people are willing to put up with; I think having to qualify every function that ever *transitively* uses any form of arithmetic would be utterly intractable.
I completely agree, thanks for emphasizing :)
You could annotate whole module with Silent or Panic (but probably couldn't with Return). If you have some hashing functions, you would wrap all the functions in Silent. And other functions in Panic.
I'm sorry, I wasn't clear. What I meant by VecHolder being the owner, is that your example function would be part of VecHolder. Besides, unlike the example, I need to return an arbitrary number of mutable elements to the vector, not just two. But I'm beggining to realize that I probably don't need that, the number of cases where I'll have to modify more than one element is really small and I can afford to copy the data or solve it in another way.
I was hoping to solve this within rust's borrow checker power. It feels like I'm cheating whenever I use RefCells. But it's a good solution, I'll keep it in mind if I can't find an alternative.
Yeah :D
No, `unsafe` is not to enable people to do things 'The Wrong Way', it's to enable doing things that the compiler cannot (currently) understand. Sometimes people will use it wrong, in ways that breaks the invariants that Rust assumes, but that is not what it is for, that is merely an unfortunate consequence. Using `Box` where it is not needed is also clearly 'the wrong way', but nobody would suggest to make `Box::new` unsafe.
In addition to what others have said, there's a new syntax being worked on (isn't stable yet AFAIK) that should be able to allow this: let arr = box [[0; 1000]; 1000]; The suggestion to use boxed slices is indeed a working solution today that I honestly dislike. This is a result of the evolution of Rust from an ancient time when dynamic arrays where builtin magical creatures of the language. slices are semantically *views* into some contiguous block of memory provided by some container. As such these types ([T], str) should be associate items of their respective containers in the same manner that concrete iterator types in C++ are associated items. e.g. ```vector&lt;int&gt;::iterator```. This would prevent nonsense things such as ```Box&lt;[T]&gt;``` which doesn't make sense to me semantically. Unfortunately, I think that changing this is not backwards compatible. 
Thanks Steve for your list of pros and cons. &gt; But my side projects have been mostly Node as of late, because I'm not the only ones working on them. No Ruby development anymore? &gt; Such is life. I can tell you a thing or two about it :)
It's moving ahead. Thanks for the links!
Thank you, I follow F# and Don Syme on Github. &gt; which involves writing F# in a C# framework There is [Suave](http://suave.io/) for F#. It's a nice web framework but for everything else (mostly) you must use .NET.
"stack overflow" is a just special case of segmentation fault. If you overflow far enough you miss the guard page completely and just trample on whatever happens to lie behind it.
&gt;This would prevent nonsense things such as ```Box&lt;[T]&gt;``` which doesn't make sense to me semantically. &gt;Unfortunately, I think that changing this is not backwards compatible. I disagree that `Box&lt;[T]&gt;` doesn't make sense semantically, it's just the terminology that is inaccurate. [T] isn't necessarily a view. It's just a contiguous sequence of elements. `&amp;[T]` is only a "slice" because it's borrowed from somewhere. I'd prefer you called [T] an array personally, but that ship has sailed unfortunately. 
I'm curious about Rust's cross compile story. From a quick search, it doesn't look like it's extensively documented, but it could be really interesting. What steps would I need to take to compile a binary targeting, say, an old 32-bit Debian 6 server from my recent Mac, linking to openssl and other shared libraries properly? What about a new x86_64 server?
[clippy](http://www.doingitlocal.com/wp-content/uploads/2014/09/microsoft-paperclip.jpe)
Yeah, my comment was also pretty tongue-in-cheek. Rust is somewhere in between Haskell and C(++).
Interesting experiment. A question. Why can't you simply implement the arithmetic operators for different types? I don't see why you need different names or traits for that. If there is a + operator for Int and a different for Float then the compiler can select the correct one or simply raise an error if no operator found for the given type. I don't see where the complexity is hidden here. 
Thanks! I didn't finish with all of it but this concept is much cleaner now :) Your inline comments were also very helpful.
That would be possible and is one way I considered. I am assuming you mean that + is a just a function which takes two arguments and returns something of the same type (a -&gt; a -&gt; a) and then when compiling we just select (Int -&gt; Int -&gt; Int) or (Double -&gt; Double -&gt; Double) depending on what 'a' is inferred to (failing with an error if 'a' is not Int or Double). This is certainly simple to implement but it only works for builtin functions and types. Pursuing this direction more generically means you eventually end up with traits which are a good solution and one I might go with but I have not yet had time to explore all solutions to this.
&gt; Wold it be reasonable to support for this format to rust? One thing that must be said is that IFC is an implementation detail of MSVC and not part of the C++ standard. Wether Clang/GCC/Intel/IBM/... will follow or invent their own formats remains to be seen.
Similarly it is important to realize that for now MSVC and Clang's implementations differ for now... and neither is "more" standard. So any work on supporting modules seem premature to say the best.
I am doing a little bit of Ruby, but not a ton. Mostly for lack of time.
If you run into more issues just keep asking questions. 
You could do what Elm is doing in the interim, which is to have a special cased type parameter called `number`. So: (+) : number -&gt; number -&gt; number The operator would be a builtin that would insert the correct prim_op for the specific type that was inferred.
Exactly what I needed! Thanks! :)
Oh, whoops; you are correct.
 _ if =&gt; Is an anti-pattern, in my opinion. You're not taking advantage of matching, and you're using `if` already anyway. I'd write your first example.
While (as /u/steveklabnik1 comments) the official style guide probably says that `_ if =&gt;` is an antipattern, I would still recommend using `match` for such a long chains. I find it more readable (conditions are nicely grouped in the single column), but also the other big advantage is refactorability -- if you started from if-else and decided later to add some matching, you would have to change the whole if-else chain to the match. Yuk. Match also helps when `mv` is generated by some function call and later reused in all conditions. When using if-else, you'd have create separate let-binding (and if you don't want to pollute the scope -- additional block).
Modules vs header files isn't a terribly integral part of what makes C++ what it is.
Why does it only work for the built in types? The user could implement the + operator for type Foo. You could also allow this kind of overload for every function. I agree that it is more complicated if you want to implement it generically but that's not necessary.
You can't, because you can't shadow a unit struct or variant that's in scope, and `None` is always in scope. But this check occurs at a later stage of compilation, and so it isn't an error during macro expansion.
For OSes where the OS ABI == C ABI, you are kind of right. But for those cases extern "C" and tooling to generate header files from module public symbols will be enough. Plus major consumer OSes are moving away from C ABI, so the OS ABI plays a bigger role. For example on Android in spite of the NDK, Java rules the platform. On Windows the way forward is COM and .NET, which although possible to use from C, it is a big pain to do so. On MacOS X and iOS, compatibility with the Objective-C runtime plays a big role, hence why Objective-C++ also exists. In any case Swift ABI will be the way forward. On IBM mainframes, the OS bytecode ABI is more relevant. Unikernels have also their own ABIs. There are still an endless list of use cases where the C ABI matters, but meanwhile OS vendors are reaching the conclusion that it is time to reach to other richer ABIs. Meanwhile all major C compilers are actually written in C++. Who knows how relevant C ABI will be in a few decades. 
/r/playrust
Does the Rust site offers the book for specific stable versions?
I'm preparing my talk on Type-Level Shenanigans for this month's Rhein-Main Rust Meetup next Friday. I'll probably blog about the topic, too.
I've got a busy normal work-week ahead of me, but hopefully I'll be able to make some contributions to liquid-rust. It'll take a while to be feature complete, but a more efficient liquid engine would be fantastic for work. Plus, edunham mentioned at the Portland Rust meetup last week that it was something needed for the cobalt project so if it helps that get along then all the better!
I thought it should be impossible to create segmentation faults in safe Rust.
Actually, ~[T] was, just before ~ disappeared, identical to Box&lt;[T]&gt;. 
TBH I think I'd prefer reddit as well. It'd be a lot more convenient having /r/Rust, /r/rust_gamedev/ and, I duno, /r/Rust_networking all in the same place.
If I understand correctly the problem here is that you cannot be certain that the operator will have 2 parameters and a return value. Otherwise you would know which tree things have to match. Can't you enforce that all binary operators will actually be a function with two parameters? User defined operators must have additional metadata anyway. You probably need precedence, associativity, stuff like that. I don't see the point in allowing a random value/function to be assigned to an operator.
if using match, I'd rather write let see = match mv { x if x == best =&gt; 10_000_000, x if x == killer.0 =&gt; 2, x if x == killer.1 =&gt; 1, x =&gt; self.see_move(&amp;x) }; But I can't really explain why. Looks better than `_ if mv =...` in my opinion.
That "option" construct looks like it could be turned into a macro or syntax extension perhaps, if the burden of writing special methods is too much. fn foo(a: u8, b: u8, c: u8) -&gt; u8 { let d = poo!(a + b + c); let e = poo!(a + b); // ... many arithmetic operations } Alternatively, you could use a [newtype wrapper](https://aturon.github.io/features/types/newtype.html) around the types themselves, and have picking the correct implementation of arithmetic baked into the type itself. fn foo(a: PoO_u8, b: PoO_u8, c: PoO_u8) -&gt; PoO_u8 { let d = a + b + c; let e = a + b; // ... many arithmetic operations } Then you have to call `PoO_u8(x)` before calling the function and `y.unwrap()` afterwards.
Enforcing that operators always have 2 parameters solves part of the problem but for + you also want both arguments and the result to be the same (== require both arguments to be the same and the result to be Bool, etc). Thus only operators which has a known "shape" will be possible to overload which may be enough since it is simple to implement it this way. Fixity and associativity is also a problem which I need to solve, not sure how exactly yet. And yes, there is no real point in allowing operators to be assigned any random value, I just wanted to illustrate what would happen when that version of overloading is taken to its limit.
The recommendation I've heard is use nightly, but don't use unstable features... on the theory that more bugs are being fixed then introduced these days.
Dammit, you're right - in ASP.NET 5 they do seem to have removed the things I did hate the most. v. 5 does look really good. Cross-platform, and IIS no longer being mandatory but optional, refactoring into nuget packages so we only pick the things we need for your projects etc... now I'm wondering, with all these amazing changes and their new direction, will there still be a place for Rust (&amp; node, go etc) in web development? What might the advantages of using Rust over say.. ASP.NET 5 for developing medium-large web applications, with the improvements in version 5?
[Apple's docmentation says](http://clang.llvm.org/docs/AutomaticReferenceCounting.html#optimization) &gt; This specification describes ARC as performing specific retain and release operations on retainable object pointers at specific points during the execution of a program ... under certain circumstances, ARC is permitted to re-order and eliminate operations in a manner which may alter the overall computation history beyond what is permitted by the general “as if” rule of C/C++ and the restrictions on the implementation of retain and release. [Mike Ash's explanation is a little easier to understand](https://www.mikeash.com/pyblog/friday-qa-2011-09-30-automatic-reference-counting.html) &gt; ...we're still doing a retain/autorelease sequence in the getter, and a retain/release combination in the calling code. This is considerably less efficient! &gt; Not to worry. As I mentioned above, ARC emits these special calls instead of plain message sends for the purposes of optimization. In addition to simply making retain and release faster, these calls are able to eliminate certain operations altogether. &gt; But wait, this doesn't solve the problem of excessive temporary objects at all! We're still doing a retain/autorelease sequence in the getter, and a retain/release combination in the calling code. This is considerably less efficient! &gt; When objc_retainAutoreleaseReturnValue runs, it looks on the stack and grabs the return address from its caller. This allows it to see exactly what will happen after it finishes. When compiler optimizations are turned on, the call to objc_retainAutoreleaseReturnValue will be subject to tail-call optimization, and the return address will point to the call to objc_retainAutoreleasedReturnValue. &gt; With this crazy return-address examination, the runtime is able to see that it's about to perform some redundant work. It therefore eliminates the autorelease, and sets a flag that tells the caller to eliminate its retain. The whole sequence ends up doing a single retain in the getter and a single release in the calling code, which is both completely safe and efficient. 
Where have you heard this recommendation? Unless you need nightly features, you should use stable.
I'm sure some people on here would be happy to give you some optimisation pointers but we'll need to see the code first.
Have you compiled it in release mode? Rust in debug mode is slow, very slow.
&gt; Using Nighly used to be recommended before 1.0, because releases were not backward compatible and not tested anyway. 0.x release were just like snapshots. It should be noted that nightly followed an accelerated "implement-validate-deprectate-remove" cycle back than, making that rather feasable. 
For the curious, a [Lakh](https://en.wikipedia.org/wiki/Lakh) is 100,000.
Indeed it does! Change the version in the URL, for example: * https://doc.rust-lang.org/1.0.0/book/ * https://doc.rust-lang.org/1.4.0/book/ Less useful for citation, but you can also replace the version with release channel names to get the latest on that channel: * https://doc.rust-lang.org/stable/book/ * https://doc.rust-lang.org/beta/book/ * https://doc.rust-lang.org/nightly/book/
I'm trying to finish the next post for the _Writing an OS in Rust_ series, which is about accessing and modifying page tables. It has become quite long, so it certainly contains many mistakes. I'm trying to fix as many of them as possible before I publish it, but I'm sure that there will be a lot of work after publishing, too.
Now I have provided link into it. 
Yeah, Actually i have ran against 14 lakh(1.4Million) number. 
I'm working on a port of [marisa-trie](http://marisa-trie.googlecode.com/svn/trunk/docs/readme.en.html) from C++ to Rust. Marisa implements succinct tries as described in [this paper](http://www.computer.org/csdl/proceedings/focs/1989/1982/00/063533.pdf). If I'm not mistaken, this is a more compact representation of string sets than the one used in the [fst](http://blog.burntsushi.net/transducers/) crate. I'll be trying to make this compatible with the Automaton trait from fst so that fuzzy queries can be done efficiently as well (marisa only supports exact and prefix queries out of the box).
General tips: - When you create a `Vec`, use `Vec::with_capacity()` to make sure it allocates enough room from the start, instead of gradually growing. - Instead of allocating new vectors in each step, allocate one that is large enough for all steps and pass a mut reference to it - You don't actually need to copy out both the left and the right half. You only need to put the left half in a temporary location, the right can stay where it is. - Use slices and iterators when you can. The vector and slice iterators are very efficient - If you must use a loop counter (an index) instead, use the length of the thing you index as a loop bound. For example: `while i &lt; L.len()`. This should make sure the bound check for `L[i]` is elided. - If you need an efficient stable sort, there is `.sort()` on vectors and slices in the libstd already. But it's more fun to write it yourself.. - `i += 1` is a nice way to write the increments.
Good question, I should perhaps have elaborated more on that part. First there is the basic things such as an API for marshaling values between host and embedded language. This is quite easy to use already (see for instance the definition of the string module https://github.com/Marwes/embed_lang/blob/master/vm/src/primitives.rs#L264-L273). With some trait magic the marshaling is done automatically whenever these functions are called. In addition to making it easy to interact with the VM the language itself should make host types feel like first class citizens inside the language. Currently it is only possible to call functions on host types which gets you pretty far given its a functional language but I would also like for it to be possible to pattern match on host types as well as accessing fields directly on them.
So, all these other ABIs you mention... How many languages support them? Very few. How many support the C ABI? Pretty much everything. The C ABI is not going away any time soon. As you've pointed out, there are plenty of libraries/frameworks not written natively in C any more, but there is still no clear successor. &gt; Meanwhile all major C compilers are actually written in C++. That's not even wrong, but it's completely irrelevant. The language a compiler is written in has nothing to do with what ABIs it supports. &gt; Who knows how relevant C ABI will be in a few decades. Who knows how relevant any current technology will be in a few decades?
I created a /r/rust_networking, I don't have time to set it up properly right now though. Hopefully I can get to it later in the week!
There's already a branch, so hopefully not long.
https://github.com/arcnmx/cargo-clippy
Yes, I apologize for being brief, I'm traveling. I was part thinking about that RFC in the "what if I want to add an allocator parameter but the library didn't before, is that now a breaking change" and "I want to give the option of an allocator but not wreck ergonomics for those that don't care" cases.
In this recent podcast: http://cppcast.com/2015/12/robert-ocallahan/ they mentioned this implementation of modules which like others said is not standard. According to the podcast, C++ modules are more like C++ 20 or C++ 23.
No plans for that as of now as there is no event loop. It is something that should be possible to add on top of API that the VM provides by defining the async and await functions. // Stores the function in somewhere async : (() -&gt; a) -&gt; Async a // Retrieve the value or run the function if it is not yet run await : Async a -&gt; a And then there is some event loop which tries to run each function that has yet to be run. As a comparison here is the module for [lazy values](https://github.com/Marwes/embed_lang/blob/master/vm/src/lazy.rs) (Lazy is a bit more integrated in the VM than it needs to be but you might still get the idea). Lazy values are easier to implement but still follow much of the same idea I alluded to above.
Can you explain what debug mode provides in terms of debugging? Obviously release mode will be more optimized. Is debug mode just compiled without optimizations?
&gt; The latter is mostly done in the React community, though I expect it to spread as the vdom approach spreads. I really like Ember's plans here, FastBoot. Basically, you drop in Node and it Just Works.
Who else things `cargo run` should be renamed to `cargo run --debug`? Or possibly `cargo walk`?
&gt; Dienstag, 15. Dezember 2015 That looks great. Will it be recorded?
If you need any early review, let me know. Seriously, anything to read the next entries sooner. ;)
I think I still don't get you (or you don't get me) :D C++ has both `constexpr` and type-level values, and one can call `constexpr` functions to perform computations on type-level values. So the idiomatic solution is to use the type-system (type-level values) but perform the computations with the idiomatic imperative run-time code (`constexpr`) instead of with template instantiations. One has always been able to use template instantiations but doing so in C++&gt;03 for this particular problem is technically worse since the compile-time will be larger (so it is not only a matter of masochism). Rust only has `const fn` (which is currently not that powerful but anyways). It does not have type-level values or dependent types, so there is no way to use the result of a `const fn` within the type-system [*]. [*] that is a lie since one can/will be able to use `const fn` to set the size of a `[T; N]`, but that is the only place within the type system where AFAIK `const fn` can be used, which I don't think is enough to implement a similar solution to idiomatic c++.
I had some trouble constructing this search, but if I did it right it looks like [there weren't any](https://github.com/issues?utf8=%E2%9C%93&amp;q=is%3Apr+repo%3Arust-lang%2Frfcs+is%3Aclosed+is%3Aunmerged+label%3Afinal-comment-period+closed%3A%3E2015-11-30+).
If we are talking about steps after the initial render then yes you are right, you need to write application with that in mind. 
Oh, neat. I didn't know that existed. Thanks :-)
No problem, it's great!
Is it possible to sacrifice compile time to get optimizations but keep some debugging stuff?
One of the biggest things I wish for in rust syntactically is flagMap sugar like Scala's for comprehension...
Sure, you can set opt-level 0, 1, 2, 3 and turn on/off debug assertions, debug symbols all individually. Cargo's profile feature makes it easier.
This is my first Rust utility - comments about code style, being idiomatic, etc. are all most welcome. * it's not on crates.io yet (I think it is missing features still) * I will put up the bindings e.g. [libcryptsetup-sys](https://github.com/solidninja/peroxide-cryptsetup/tree/master/lib/cryptsetup-rs/libcryptsetup-sys) soon * rustdoc and better integration tests are the biggest missing things So briefly about my experience writing this. I was lurking in the Rust community for a number of years now but actually getting programs past the 40-line stage was difficult for some reason. I am very used to Scala's way of structuring programs (implicits + typeclasses) and the excellent IDE support. Using Sublime Text without racer was probably not the best choice for learning the APIs quickly and I will be switching to vim. After initially struggling with borrow checking errors everything was reasonably smooth, though I stumbled upon a few unstable APIs I could not use there and then (path handling was a major example, especially relative path creation). For-comprehension sugar would also be nice (I tried using flat_map before realising and_then is what I really wanted).
Have you tried https://github.com/TeXitoi/rust-mdo
Ah this looks pretty good, thanks
Of course we would need to understand the code more, but I think this is likely the best solution. This is basically a switch statement on a variety of mutually exclusive things - screams enum to me.
Now with added [website](http://www.rust-networking.org/), and subreddit: /r/rust_networking!
Swift is for IOS/Mac dev. If anyone do not have mac os, he/she can not learn. It is swift biggest drawbacks. 
Seriously, I figure it's time to output a message like "Compiling in debug mode" by default.
Probably here on reddit, also awhile ago (definitely after 1.0 was released though).
Google used go for heavy processing or deployment. Download from youtube or any google site is being processed by golang. Amazon are using various languages depending on the functionalities. Twitter using scala after ruby on rails.
I can't really comment on Rust vs ASP 5 as I've barely touched Rust bar a few simple examples, but I've been working full time with ASP 5 since the first beta. Can't really stop myself from a little fangasm. I'm absolutely loving it and honestly would currently pick it over any other stack I'm familiar with(Ruby, Node, Go, ASP 4). It's extremely easy to set up, on par with Node, it's also already catching up to it in benchmarks and the ASP team only recently started working on optimizations. There is no magic like in Rails and the http pipeline you can build up by yourself. Extending it with your own middleware and services is wonderful too, they did a great job on the abstractions. It has also proven very popular with my team, it's nice to introduce a new tech and have no one complain for once. :) I would assume a Rust implementation could compete in scenarios requiring high performance or low memory overhead, though I'm talking out of my arse here. One comment about IIS, it's not really optional yet, at least on Windows. Kestrel knows only how to serve HTTP requests, for security and all other bells and whistles, you'll need to serve your requests through a reverse proxy. IIS serves that purpose on Windows and Nginx on linux.
Or, to be more explicit, "Compiling without optimizations..."
As someone who also comes from a "scripting" language background, I am very interested in this and your future posts about your Rust experience. Thanks for sharing!
[removed]
UFCS does help make the reason these syntaxes are different clearer. Rust is not object oriented, so it doesn't really have instance methods and class methods and things like that. `foo.bar()` is just syntactic sugar for `Foo::bar(&amp;foo)`.
&gt;Type declarations are required for functions, but for variable assignments they are inferred. This is actually incorrect. Local variables are inferred, but anything non-local such as a function, const or static, need types. I know your not OP but i felt like replying.
Thanks! This is different to [this](https://doc.rust-lang.org/std/num/)? I see it is by the Rust Developers, why is it a separate crate?
Fixed, thanks! And double thanks for the [pull request to improve the Bitmessage POW library](https://github.com/imrehg/bmpow-rust/pull/1)! Reading it all makes sense, much clearer in flow and purpose! I think I wanted to shy away from "unsafe" parts until I know how do they work, as the threads should be really independent from each other. :) Will review it (so I understand how things work) and merge it in a bit!
WebKit has a lot of value and they open sourced that as well. It was a pretty rocky start, but it was their first major release. Since then, WebKit has become the default web rendering engine for desktop and mobile, and they've continued contributing towards it since then.
Awesome, I was thinking of doing the exact same thing but as a standalone tool. It's still somewhere in my project_ideas list. Have you considered making it a standalone tool? What benefits does designing it as a compiler plugin have?
Great, my only gripe is: Is it not possible create struct equivalent to rust enums using one simple tag, and union ? 
The way I like to work is to have the header produced at compilation, you can't do this with a standalone tool without adding complexity to the build system. However you can get a compiler plugin to act as a standalone tool (as I've described in the readme), so it's really a case of being flexible. 
Possibly, but I'm not sure how Rust's `#[repr(C)]` enums are stored internally yet. The other thing I noticed was that Rust allows generic types to be `#[repr(C)]` but I currently have no idea how that would map to C. 
Good idea with using other types.
C++ solves diamond problem using virtual inheritance. Maybe that would work. But it's quite complicated for compiler to do and also execution speed will slow down a little.
Also if you do want to do more work on making it a standalone tool I had it set up as a [compiler drop-in](https://github.com/nrc/stupid-stats) at [this commit](https://github.com/Sean1708/rusty-cheddar/tree/152a004b621b004b53200589fd5d0befd3f3550f), so feel free to look there for inspiration (or just fork it there). If you do decide to go down that route it shouldn't be horrendously difficult to get it working with [syntex](https://github.com/serde-rs/syntex).
cargo crawl?
I've just looked it up and (from [here](https://doc.rust-lang.org/nomicon/repr-rust.html)) it seems that the data layout of non-unit enums has deliberately been left unspecified, so I don't think I can do anything like that.
Following the advice given by /u/annodomini and /u/paholg I've posted an issue on GitHub ([here](https://github.com/rust-lang/rust/issues/30262)). I hope the devs will find some time to help me find a way of debugging this issue further :)
A big step for ffi, thanks! Well done
This is not the case anymore since apple open-sourced swift and apparently provided a linux compiler https://github.com/apple/swift/blob/master/README.md
~~[image](https://crates.io/crates/image) is quite nice for that, but it may be too low level if you want to do more than just manipulating pixels.~~ Edit: no, `image` isn't made for 2D rendering.
You should look for a 2D drawing lib that can render to an off screen buffer, if you want to do more operations. I don't know of any, off the top of my head, though.
Possibly. You would want to look at [`RenderTexture`](http://www.rust-sfml.org/doc/rsfml/graphics/struct.RenderTexture.html) in that case.
Even 3-6 months is still regular for me. This is not strong criticism by the way, I just think the issue should be mentioned because people voice that aggravation from time to time.
This is fantastic :D I really like the proposed syntax.
[removed]
This week is a Mozilla "work week". Twice a year, the company plus some volunteers meet up in real life and get work done together, instead of over the Internet. This morning was (is, actually, it's still going) the opening keynote, and this is a quote from it.
I personally like [this answer](https://www.reddit.com/r/rust/comments/2tdsev/compilers_with_backdoors/cp91cep?context=10000). :)
I would rather have `macro foo { ... }`, `macro bar($x:expr) { ... }` and `macro baz[$x:expr] { ... }` rather than allowing all the possible delimiter combinations, such as `macro foo ( ... )`.
Trying to avoid complicated runtime bureaucracy. If the system starts becoming that complicated, you should probably just move to composition. You could also just enforce once-only inheritance, perhaps. Then you could preserve offset semantics and make people more likely to write simpler base-structs. The result is that every struct's inheritance data becomes an inverted tree, which is actually quite appealing in an odd way. 
Thank you, now I can use rust at work :D 
Wait, *Servo* components?
*regular*, agreed, but *very*? I fear that people will be dissuaded from trying clippy when reading that statement, which is probably not your intention either.
This is too much magic to be Rustic. Also I don't see the need for *multiple* inheritance (on the data side). For behavior we have traits.
Servo is a HTML rendering engine being written in Rust https://github.com/servo/servo/
Yeah. The url crate is the first.
That's why inheritance by auto-deref is considered an antipattern.
Is the performance of image comparable to (R)SFML? Any copy operations in image seem to go through a few layers of indirection, eventually pixel by pixel, with bounds checking, into a `Vec&lt;Pixel&gt;`. In SFML (C++), images are similarly backed by `std::vec&lt;Uint8&gt;`, but region copies are done with only preliminary bounds checking, and then by incrementing both source and destination pointers to copy each pixel. For images without alpha values, SFML copies whole rows at a time with `memcpy`. I'm not sure how image can compete with that. And now a bit off-topic, but what techniques might someone use to get similar performance in Rust without relying on `unsafe` code? Something to do with slices?
What about using [Piston](https://github.com/PistonDevelopers/piston-examples/blob/master/src/image.rs) to draw it to the screen? Test that example by executing: $ git clone https://github.com/PistonDevelopers/piston-examples $ cd piston-examples $ cargo run --bin image More details [here](http://www.piston.rs/). edit: actually, uh, it pulls so many unrelated dependencies that the build of xml-rs ended up failing here (perhaps because I'm not running the latest stable?). It fails with: &gt; 136:60 error: no method named `join` found for type `collections::vec::Vec&lt;collections::string::String&gt;` in the current scope
They are not the same thing. There weren't enough info when I wrote the answer, so my first assumption was that it could be enough. Image is primarily an image IO library and not a 2D rendering library, as far as I know. As for achieving similar performance, your best bet if you want to stay with the safe stuff from `libstd` is probably to (ab)use the `Write` trait and/or do something clever with iterators.
Servo will almost certainly be a different product. XUL is a big barrier here.
I find it interesting that someone else has come up with a similar bootstrapping stack design to mine. Might not be just a pipe dream after all! "My" stack (which I haven't worked on [much](https://github.com/eddyb/rs0)): * rs-3: Dual stack single-threaded [virtual machine](https://github.com/eddyb/rs0/blob/master/src/rs-3/x64-linux/vm.s) (FORTH-like) * FPGA-friendly design * 32-bit memory space, statically partitioned into pools * 32-bit integer operations + byte memory access * rs-2: Assembly dialect tailored to the stack machine * can [be done](https://github.com/eddyb/rs0/blob/master/src/rs-2/examples/fib.rs-2) with a [macro assembler](https://github.com/eddyb/rs0/blob/master/src/rs-2/std.rs-2#L232) * could be a FORTH instead (which I have not tried) * used to write a one-pass compiler for rs-1 * rs-1: B-like imperative unityped language * optional type annotations for potential separate formal verification * indexing static arrays instead of typed pointers * no pointers at all required, simplifying the formal model * in-array "word"/byte-level pattern-matching * used to write a multi-pass compiler for rs-2 * rs-0: High-level Rust-like imperative+functional language * single-threaded + no dynamic memory allocation =&gt; no unsafe * "deep cellification", i.e. every leaf field behaves like Rust's `Cell` * no optimizations, no dtors, no UB semantics around aliasing+mutability * references with Rust's lifetime elision rules (similar to the proposed annotation-less regions in C++) * trait system with less special cases (i.e. more like a subset of Prolog) * polymorphism with monomorphization only used for functions manipulating values of their type parameters directly (i.e. codegen depends on `sizeof(T)`), everything else is virtual * used to write a multi-pass Rust 1.x compiler A Rust compiler written in rs-0 compiler may be very slow, but it should be able to *describe* Rust's semantics through its implementation. Something that may not be immediately obvious, but with /u/nick29581's proposed changes to macros, *it may be possible* to also compile arbitrary plugins and use them (by running them as black boxes that take tokens and output tokens).
coincidentally rust is after all a slow combustion (fire), so that is cool.
Isn't Mozilla moving away from XUL though? (no source, just something I heard through the grapevine)
Yes, but one way of looking at Firefox is "Gecko driving a XUL interface", so once you remove the Gecko, and replace it with Servo, and remove the XUL and replace it with, say, browser.html... is it even Firefox anymore? See also "The Ship of Theseus Puzzle" http://plato.stanford.edu/entries/material-constitution/#Puz
Ah, actually you mean don't allow braces around the pattern, which would solve the ambiguity problem here. The problem is that would prohibit macro uses which look like items (since I propose forcing the brackets around the pattern to match the use).
I think the fact that Rust is definitely going to get inheritance means that multiple inheritance should be reconsidered or redesigned, while of course avoiding the problems C++ has (and you're right; that we have traits should factor very heavily into the design). I suppose what's missing here is motivation for multiple inheritance, anyway. 
Also the Firefox brand is still huge with many.
Is there any chance for macro-methods? I'd love to be able to write something like this: impl Foo { pub macro write($self, $dst:expr, $($arg:tt)*) { $self.push(format!($dst, $(arg),*)) } } foo.write!("{}, {}", a, b); Note the multiple arguments. I think it's much more idiomatic than global macro.
While this attack isn't out of the realm of possibility, there are so many other attack vectors right now. Stuff like simple vector overruns. Trying to fix the bootstrap compiler issue reminds me of trying to put an ultra high security lock, steel bomb proof door with blast proof steel jam and hinges on a house with glass windows. The work is wasted, the thief will just go in the window. Likewise we have a lot of other problems to solve before this one.
Yeah I know, but &gt;fungalfox sounds a tad nasty..... I was thinking about what to call firefox if it got rusty, but because rust is also a combustion we should be good..... Besides rust's presumably have cellular respiration going on which should still be combustion so firefox still works in that sense. 
I don't see any benefit to the single-pattern convenience form, as (in addition to the parsing complexity) it just makes things less uniform and makes it more involved to add new cases. Other than that, this looks good.
&gt; The ability to add constraints and invariants to Rust code thanks to algebraic data types and traits without falling back on a heavy runtime like Haskell is great for security, **although it's quite a lot of work to set up and leads to fun code like [this](https://github.com/fizyk20/differential-geometry/blob/master/src/tensors/variance.rs#l205-l218).** This is where Haskell and I disagree. Expressing arbitrary facts in the type system is cool and all, but ultimately excessive. You don't *need* to express arbitrary facts in the type system and you don't *need* arbitrary proofs of anything. The _only_ thing you need is case analysis, good names and a sensible choice of defaults. I've commented elsewhere that Rust is basically the only language I can write IO code in and have a modicum of confidence that it works. But does Rust's IO have any complicated type-system fanciness? Nope; the secret is to have a few different string types, to have *every* error visible in the program, to have well-structured conversions between them and to have a good set of defaults. That's it. Same for most things in Rust, in fact, which is one of the reasons I like it so much. glium is a good example of a slightly larger API taking this approach. As far as I know, there's no type-system fanciness there. *Most* constraints that one actually cares about are of this form. Those that aren't tend to be *really* hard to express in a type system anyway, which is exactly why nobody uses super-fancy type systems. The article in fact makes two very pertinent points of things which are exactly like this - integer overflow and string concatenation. You don't need fancy things for the proposed solutions.
Why not go all the way and split multiple macro patterns: pub macro m($x: expr) { ... } pub macro m($x: expr, $y: expr) { ... } It would be ugly if they were split over multiple files, though.
Why add the restriction that brackets match use?
Brilliant! What are you doing in development, /u/steveklabnik1, you belong in marketing!
There's generally only one use that makes 'sense' and we have other options for no reason really. It means multiple ways to do something with the same semantics and thus makes code harder to read for new users - "does `vec![...]` mean something different to `vec!(...)`?"
I don't think the macro syntax needs convenience forms. Macros are a powerful tool of last resort (to say nothing of their poor interaction with tooling, which you should be sympathetic to :P ), and I don't see a problem with them having syntax that makes people think twice about what they're actually doing. Making macros too easy to reach for is precisely one of my objections to Lisp. I also don't view `if let` as a convenient `match`, I view it as a refutable `let` binding, and in any case it's also something that should be used with caution (it's possibly one of the strangest things on the surface to Rust newcomers).
I hope they use something like Apache Thrift for the plug-in interface. I really don't like writing JavaScript.
Is there a story, /u/Gankro and /u/steveklabnik1?
Came here to say the same thing. I'm not a fan of having 2 ways of expressing the same macro, but I do think that splitting them out is a lot more readable.
I don't have a strong opinion, but there are definitely people who hate "typedef struct Foo { /* .. */ } Foo;" and who like to type 'struct' everywhere. 
Thanks &lt;3. It's nearly done, but I would appreciate any feedback (especially regarding code correctness). For anyone interested: https://github.com/phil-opp/blog_os/pull/61
I just tried this out and I'm shocked that that's the case. That's so unintuitive it almost feels like a bug--especially because it's not mentioned anywhere in the [documentation](https://doc.rust-lang.org/nightly/core/option/enum.Option.html#method.unwrap_or).
I still think Servo with lightweight cross platform UL (like google`s flutter based blink render engine and dart) has more brilliant future than Servo just as render core of browser. Servo as app platform do not need to care about too many HTML,DOM,CSS standards,and browser plugins,extentions.It should grow faster than Servo as component of some browser. It maybe could build a real product ecosystem for rust and Servo. 
Built and displayed the Rust logo on Mac OSX 10.9.5 using rustc 1.6.0-nightly (abfadfeee 2015-12-02) cargo 0.7.0-nightly (2a07807 2015-12-02) Yay [multirust](https://github.com/brson/multirust) ! 
I have designed a board game and am interested in implementing Monte Carlo tree search to see whether a good AI opponent can alert me to balance issues in the game. I have what I think is an okay heuristic for evaluating board positions, but what I don't understand is- how do you integrate the information you get from playouts with what your heuristic says about a given position's strength?
So that you can use compiler plugins to compile the compiler.
I have to disagree with the ideas of both 1. Bundling desktop app support or custom lang stuff unnecessarily and 2. Treating servo as a marketing vector. Bundling a custom lang library was presumptuous and an imposition when google suggested they might start doing it with dart and this is no different. If the users want A, is there a very important, absolutely critical reason we are making them run B in this case? Even if the custom lang was great, webassembly (a standard being planned by multiple orgs collaborating, rather than foisted onto everyone by one stakeholder, meaning there will be more probability for buy in and common usage) will be out by the time it could get any popularity. I think people have more willingness to consider projects that the developers believe can stand on their own in terms of getting popular. And that goes for Servo as well. If people see the pitch for servo and it seems to be including a lot of stuff extraneous to core web browser basics in its promotional materials, people are going to think one couldnt sell on its basics as a web browser like speed. 
I have a compromise solution: `pub macro fn m(...) { ... }`. We cannot use `macro_rules! fn { ... }` today so there is no compatibility problem.
I like the huge progress made in this proposal. IMHO, a better alternative to the ugly $var notation would be quasi quoting such as in Nemerle. I also agree with others about simplifying macros by example to only allow the single case syntax. 
You would not _believe_ the trolling burden you've put on me in your absence, I've had to work overtime to come up with puns and jokes to fill in your shoes.
Nothing here is backwards compatible anyway and conversion will be required. How about providing a conversion tool to help with the syntax changes instead of trying to minimize change and settle on something mediocre with ugly bits? 
In general, I have a ton of issues open for each section of the API docs, so dropping comments in them about things like this is really helpful. Here's the one for Option: https://github.com/rust-lang/rust/issues/29366
Sorry for the pretty ridiculous time lag between these posts. It's taking a lot longer to get these out than I would've liked. Too many irons in the fire. :( Hopefully this one starts to get a little more interesting for folks here. There's a lot of Swift-specific stuff, but almost everything on the Rust side is potentially useful for any embedding-Rust-in-another-language task.
I made one &amp;mut joke today when I told Alex to stay where he is while we came to find them, if that helps? :P 
Someone mentions in the comments that you need to specify `const` in all the parameters because of the parser. To me this seems unnecessarily verbose--`Matrix&lt;const nrows: usize, const ncols: usize&gt;` has a lot more line noise than `Matrix&lt;nrows: usize, ncols: usize&gt;`. Does anyone know why the parser needs that? As for my input: it would be nice to have templating for all the basic types--`uNN`, `iNN`, `char`, `bool`, etc. This would open up the doors to many interesting things (similar to template metaprogramming), and it seems like if we are already going to add integer templating we might as well go all the way and add templating for all the base types. This would also answer the Pre-RFC's question of whether we want to have templating for just `usize` or all integral types. I know the Pre-RFC says it doesn't want to take these into scope, but I think it should!
&gt;I made one &amp;mut joke today Can you share the &amp;mut joke or would that anger the borrow checker. :)
Good to know! I went ahead and left a comment. In the future, would it be better to leave a comment, or just submit a pull request with the change? Or both?
Oh fine. Also: that code creates a texture with the contents of the file at [`assets/rust.png`](https://github.com/PistonDevelopers/piston-examples/blob/master/assets/rust.png) and draws it each frame, but can just as easily draw something else. Now, I think that the OP won't be able to read the contents of the texture with Rust code (the texture is stored in the GPU and I guess it's slow to retrieve it), but he can store it in a matrix.
Dereferencing is unsafe, but testing raw pointers for equality is safe? Makes sense actually. That's for `*mut` pointers too?
I think there can even be a macro that converts macro_rules! to almost any new format.
What would be the size of compile-time integers? I think they should be bignums, or at very least `u64` - and please don't make them depend on the word size of the machine that is compiling the program. Compile-time `usize` would frustrate cross-compiling for no benefit.
Wow thx, this was a great read. I'll guess it goes a little bit out of hand judged by the size. but i can't imagine to wrap this up without loosing the point. Some topics needs space for elaborating and i enjoyed the time reading. The "lag" between the posts pretty much corresponds to the length :) ... looking forward to the rust view models :D
Oh it wasn't my example. Yeah, it can't be declared in an impl, it should be a macro that is expanded in a "dumb" way. edit: I'm trying to wrap my head about the idea of type-directed macro expansion. It seems very hard (you need to perform partial type checking even before having the complete AST). I'm not sure whether there is a language that does this.
Too bad that nobody questions whether `!` needs to be present at all. If you need to mark macro usages with `!` to warn users (only one of the reasons often given), YOUR MACRO SUCKS and you should feel bad.
Isn't Firefox OS abandoned? 
&gt; I'm trying to wrap my head about the idea of type-directed macro expansion. Do you mean something like [generated functions](http://docs.julialang.org/en/release-0.4/manual/metaprogramming/#generated-functions)? They're basically just macros which are dispatched on the types of their arguments.
the const keywords add A LOT of noise, otherwise it's a great addition.
Yeah, that's a good shout.
Pull requests are even better!
Amazing effort! There is so much work put into this series.
Holy shit I cannot wait for this to hit the language.
&gt; However, if there is demand later, we will be able to expand this system to full dependent types. This seems non-obvious to me. Given "full dependent types" I would expect to be able to write the following function: fn safe_copy_without_bounds_check&lt;T&gt;(n: usize, src: &amp;[T; n], dst: &amp;mut [T; n]); where the value of `n` is runtime-dynamic.
I am really excited and grateful you're writing this series. It's great! Keep it up. :)
They could be arbitrary precision like Go's numeric constants. Might not be worth the complication though...
This is one of the very expected library in rust. Along with glium, rust is now GPU ready !
We're actively working with Gecko engineers to integrate Servo's CSS style calculation code into Gecko, and we are also starting to look at the possibility of integrating [WebRender](https://github.com/glennw/webrender/) into Gecko. All this is still in very early, experimental stages.
I don't know enough about these projects to write such a post myself, but I'll see if I can nag the team about it this week. :)
As someone who is trying to learn Rust: this is really nice. Thanks!
Sure you can, with variadic generics (just like C++11 has variadic templates). Either that or a trait which is implemented by the compiler for all tuples and allows "iterating" the element types with type/trait/impl recursion.
Firefox OS _phones_ are abandoned.
Good point, maybe it is possible then. 
I have never seen tuple bigger than 16 elements and even then it was when dealing with `u8x16` SIMD vector. If you would need bigger one you could create own type and derive all needed traits.
http://doc.rust-lang.org/std/io/struct.Cursor.html#examples is an example. There isn't a lot of standard practices or libraries or anything yet.
Quality stuff again. Any news/hint about the (long term) future plans?
That's what I was afraid of… In the example instead of a nice types (`std::fs::File`) they use generics with a specific traits (`W: Write + Seek`). It makes code a bit noisy.
NO it was named after Pittsburgh Penguin [Bryan Rust](https://en.wikipedia.org/wiki/Bryan_Rust). Graydon, being Canadian, could tell when Bryan was young that he was going to be an incredible NHL player and that the language would become popular at the same time he started in the NHL.
number 1 wanted feature for me. I don't think it's so important to support integers of all sizes, but a signed isize could be needed in some mathematical use cases, or to represent an offset.
Well, unfortunately `typenum` still has great days to live as there is no mention of integral generic parameters yet ^^
&gt; Remember that this is bare metal kernel code. We just used type system magic to make low-level page table manipulations safer. Rust is just awesome! This is so wonderful. &gt; So to fix our unmap function, we need to remove the cached translation from the TLB. We can use Gerd Zellweger's x86 crate to do this easily. Seriously. So good.
Thanks for the link. As a complete novice can I ask you a question? In the link provided, a solution to the problem is presented, under "alternative solutions". If Clang can why can't Rust? *Something about non reference lexical/defer until semantic analysis phase...*
My first intuition would be that `MyGeneric&lt;ActualType&gt;` is automatically made `#[repr(C)]`? However, it seems like rustc doesn't mind that `ActualType` is not itself `#[repr(C)]`, so I'm a bit confused about this myself.
That makes a lot of sense. Thanks for the explanation.
The latter. Now that I think of it, it should at least have triggered an "unreachable code" or "dead code" warning, so I filed [issue 30289](https://github.com/rust-lang/rust/issues/30289).
Because in C, type names and variable names have the same lexical class (i.e. they look the same, both are just a series of alphanumeric characters). Rust's types can be alphanumeric characters followed by `&lt;` and a list of types or lifetimes (which have another lexical class altogether) and then `&gt;`, and changing the lexer to treat that as 'variable-or-type' would be ridiculous when you could just prefix it with a keyword and keep the parser clean(ish).
Indeed, `sprites.clone()` is automatically called in the standard definition of `animated_sprite.clone()`! I actually forgot to add `#[derive(Clone)]` at the top of `AnimatedSprite`'s definition. It is now fixed.
In my total novice armchair opinion, I do not believe anything servo should be in Firefox. Why? I feel as if people will complain and feel as if it's forced. Like switching from Windows 7 to Windows 8 Maybe not that dramatic, but people are used to Firefox's features. Developers will complain if everything is not 100% compatible You could make servo 100% compatible with Firefox, but then that would limit the design of servo, and innovation would be held back. If Mozilla released "thunderfox", it would get press, everyone would call them innovative. No one would be scared of the upgrade, because it's not forced, "legacy" Firefox would always be there for them. When chrome was released, a lot of people left Firefox for it. I have a feeling that if all of those people's Firefox was "upgraded" to chrome, they would all be in outrage, but since they chose to go to chrome, they were okay with fewer and worse add ons and it being buggy and taking up loads of ram. Because they chose it. Remember when Firefox removed the file menu, and went to the orange bar?
The key is that &gt; I do not believe anything servo should be in Firefox. and &gt; You could make servo 100% compatible with Firefox, but then that would limit the design of servo, and innovation would be held back. Are not incompatible. A great example of this is what is actually happening; Servo's URL parsing is landing in Firefox. This doesn't limit Servo as a product, but does help Firefox out.
The line `const NO_EXECUTE = 1 &lt;&lt; 6` should be `const NO_EXECUTE = 1 &lt;&lt; 9`.
All platforms use the same Gecko engine. https://www.reddit.com/r/rust/comments/3vxrne/in_2016_we_will_be_shipping_rust_code_and_servo/cxsrt4i is about non-platform-specific components.
Yep, I was more of talking about things like plugin compatibility, or "the servo based browser will use xml for the gui, since Firefox already uses xml" so "intra-program" compatibility rather than web standards. But like I said, in my professional arm-chair opinion. I know nothing about browser design, haha. Just kidna through it out there. From the responses, it sounds like it's a non concern.
I have nothing long-form at hand, but bugs include: * https://bugzilla.mozilla.org/show_bug.cgi?id=oxidation * https://bugzilla.mozilla.org/show_bug.cgi?id=1151899 * https://bugzilla.mozilla.org/show_bug.cgi?id=1175322
&gt; I feel as if people will complain and feel as if it's forced. We’re talking about implementation details of the engine, invisible to users.
I think there were some attempts at defining them, but none was implemented so far.
&gt; We could have a full Rust compiler formalized in Coq Would you even need the full compiler or would it be enough to compile a subset which could then be used to compile the full compiler?
I disagree about the latter part, macros conceptually *are* exactly functions. They are functions being called by the compiler itself which operate on the compiler's data structures (ASTs). It's one implementation strategy that helps Rust be parsed easily and not be context sensitive (which is a good thing) but it is a trade-off nonetheless since Rust pays for it by losing uniformity of syntax. I don't think the "warn users about macros" is really a substantial reason, nor should it be communicated to users as such. Macros should not be feared or treated as last resort doomsday weapon of sorts. They are one of the tools that Rust provides. And I do think that a context sensitive grammar like in C++ is a huge burden for tools and so I believe Rust made the right choice here. 
We could call them `uint` and `int`, have them be u64/i64 in the compiler and have them automatically cast to whatever size is needed. This way, we can change it in the future. It would also be nice for the compiler to check for overflows at compile-time, that is, when the cast happens. EDIT: cas -&gt; cast EDIT2: now that I think about it, if we indeed check that the value is in bounds, we could simply have an `int` type and check whether it is positive on cast. I also like the idea of lower case type parameters being a hard error. Then, we would have T:Trait = type subset of a trait and x:T = value element of a type.
&gt; macros conceptually are exactly functions. They are functions being called by the compiler itself which operate on the compiler's data structures (ASTs). That's fair, but they're not functions on variables, and that was my point. &gt; Macros should not be feared or treated as last resort doomsday weapon of sorts. I agree, but I still want to know when I'm using one. There are certain guarantees that you get with functions that simply aren't present for macros, even with Rust's hygienic macros.
I think the ultimate goal would be for this to be generic over any type and instantiable with any const expression.
Your README looks like it could use a little updating. You might not get many users with a statement like &gt; This library is still very much a work in progress but does work (even though I would not recommend using it now as it will most likely have many breaking changes for a month or two (2015/10/27)). Also, your link to Akka doesn't work. As for where to go next with the project, you could include a short walkthrough of functionality from the library in the README, or write a series of blog posts exploring how to solve real-world problems with this actor system. Any library can be improved by documentation. Most actor frameworks also seem to be able to act across machine boundaries (over networks), so that could also be a good place to start exploring.
The downside is of course is that you could probably write a macro that lets you swap the position of the name and the method name and get general UFCS, allowing you to call functions as methods which is intentionally disallowed in current rust, e.g. `fn bar(foo: Foo) {}` could be called as `foo.bar!()`.
That wasn't a rigorous description of what I wanted. And really I'll take less than what I wanted as long as I don't have to implement everything from scratch. But what I mean is that I can imagine just having to implement a struct and maybe provide some methods for creating new individuals or a random population, or something like that.
Just noticed this is a whole series of blog posts on writing an OS in Rust! And you even show how to test it with qemu. This is pretty amazing stuff. I'm going to have to take the time to go through these. Do you have any long term plans, toy Rust OS or anything?
It can survive machine shutdowns, and can be revived on other machines.
Honestly, the amount of really low level stuff you need in an OS kernel is pretty low. Once you've gotten past booting and few wrappers for syscalls and talking to devices and the like, most of the rest of the things you do can be written in fairly idiomatic, high level languages. One issue is that some things are highly performance sensitive, so you need a high level language that has low or controllable cost abstractions, but luckily Rust fits that bill.
This seems to be good style to me; in the same way that in C++ your methods would take an interface that you could implement for both a real server and your mock in Rust you explicitly name the traits your function uses. You're not going to have the same ease of mocking as in a dynamic language. That usually relies heavily on monkeypatching which is unavailable¹ in a static language like Rust. ¹: Not *technically* impossible, but would be a huge amount of effort to implement, and would be so brittle you couldn't usefully use it for testing.
First, great! I have only a little familiarity with Akka, and only browsed your documentation quickly, but I couldn't see support for an actor supervision hierarchy yet. Is that planned? I do not have enough experience with large actor systems to make the case that a supervision hierarchy is needed, but if Akka and Erlang/OTP are doing it... I also thought http://spray.io/ was a very nice way of writing client/server code (including HTTP client/server), but I have not followed its integration into Akka. It would be interesting to see how to do client/server code with Robots (perhaps with mio?).
I see. Yes, so standard Monte Carlo would be to just play as many random games as possible and pick the move that has the highest win percentage. But that's without a tree and not that efficient. If you want to be more efficient you would have to implement the [UCT](http://senseis.xmp.net/?UCT) algorithm. That's the one that keeps track of visits and wins in the tree. And that is where the virtual visits and wins would come in. And as far as finding the correct values ... well that's a really difficult problem and the correct values are probably different for each implementation. I've just copied the values from another Go engine for now but parameter tuning is something I will have to do at some point myself. The preferred tool for this in Go seems to be [CLOP](http://www.remi-coulom.fr/CLOP/).
It depends on what you mean by scoring of course. ;) Right now the only ruleset we support is [Tromp/Taylor](http://senseis.xmp.net/?TrompTaylorRules) (which essentially means that all stones on the board are considered alive, so you play until the bitter end), but if all goes well I'll support Chinese rules in 0.3.1.
Avoid making unconstructive comments, please.
&gt; The graphics stack was fully rewritten a few years ago (replacing Cairo with Moz2D/Azure) Oh, if only that were true. I've spent a significant chunk of the past couple of months continuing the conversion but there's still a *long* way to go.
It's a 63, isn't it? 
This change is not a very difficult. It should not be a big pain for people to update their code since they usually don't have hundreds of macro definition. Compatibility with previous syntax is better, but it should not a so huge concern IMO. Since the old syntax will remain, and the new macro is not backward compatible anyway, It's now or never to make all the necessary changes.
It really is the best resource on Operating Systems, whether you're a beginner or familiar with the topic. Even if it wasn't and the book was only *good enough*, I still think professors should use it so students can save money and spend it on their remaining expensive textbooks. The author's rationale in making it a free book is a [fascinating read](http://from-a-to-remzi.blogspot.in/2014/01/the-case-for-free-online-books-fobs.html).
If I need a function which I need parameters to be named, I see it as a sign that I could use a struct. 
Not for benchmarking purposes, though that should just require calling `day4lib::mine_coin_with_conf(secret, CoinMiningConfig::default().cpus(1))`. [edit] You're very right! I've just experimented with that, and updated the gist; the short of it is that it was a slowdown caused by hyperthreading.
And also try 4 threads. Virtual threads steal CPU time and reduce performance for CPU saturating operations such as this brute force task. (Virtual threads are only useful for general purpose computing with many programs that don't saturate the CPU) Tools like `make` are often run with `-j` `real_cores * 1.5` or `real_cores + 1`, this higher value is used because the CPU is only really saturated with compiling, while make doesn't only compile. Additionally other threading overheads may be present.
That's probably it; I was referring to this message in gogui: 'Please mark dead groups manually. Iomrascalai does not support scoring'
You could also use the functional options pattern the way it's used in Go-land. See http://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html and http://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis EDIT: I forgot I don't know if Rust has variadic functions...
that and the builder pattern kinda sorta serve as a bulkier variant of named parameters if you squint very hard. i think we all will appreciate the real deal though :D my only gripe here is that many APIs arose due to the absence of named parameters when they were designed, and would have been designed better if named parameters were there at the time of their inception. and they’ll have to stay there due to backwards compat and the builder pattern will haunt rust forever some inappropriate relative spurting tirades at family gatherings
I think that's more true for default parameters rather than just named parameters. (I can't keep track of whether everyone thinks that "named parameters" imply default parameters. :P) I work in languages with named/default parameters all the time, and I'm not exactly excited when I come across a function with 20 parameters and all or most are optional. It's a lot to stuff into one function. It happens a lot.
In my ideal world, Rust would support currying instead (the Builder Pattern is just a poor way to implement currying anyway).
I am not, however, convinced that this is the right decision. It's taking away useful functionality for the sake of lint. It also doesn't actually give any safety guarantees for the collection itself, which must assume interior mutability is a thing. Alas, such is life.
Two thoughts: --- Making macro declarations build-in syntax might make it hard to write custom macro generator-extensions, _but_ there is a weay to level that difference a bit: Make the new syntax a desugaring step into the general macro form, and allow custom macro generators to use it as well, say by putting a attribute on it. Example: pub macro foo { ($x:ty; foo bar) =&gt; { ... } } #[custom_macro_syntax_extension] pub macro bar { parse ty x; parse ident foo; parse ident bar; expand to { ... } } Could desugar to: new_macro_rules! { pub macro foo { ($x:ty; foo bar) =&gt; { ... } } } custom_macro_rules! { visibility pub; name bar; parse ty x; parse ident foo; parse ident bar; expand to { ... } } Here, the default expansion would just replicate the macro syntax inside a regular macro invocation, and any syntax extension like that attribute could just override that with a different expansion to get different behavior. --- As the second point, I'm a bit confused about the desire to get rid of the `$x` syntax. I was under the assumption that it serves the important purpose of acting as a explicit syntactic escape sequence, not just for macro arguments but for syntax extensions in general. Like for example the `quote!()` extensions, where you can do stuff like let x: ast::Expr = ...; let y: ast::Expr = quote_expr!(1 + $x)
Ah, then no it doesn't support that yet. Even for Tromp/Taylor rules. Hopefully soon I'll support the required command for both Tromp/Taylor and Chinese rules.
**Rust** does not have varadic (with the exception for `extern c` as C has varadic), although, macros and builders solve this easily.
Updated my comment: I think it's a timing variation issue. Your note about it being correct because it always produces the same output threw me off; I assumed there was a canonical "correct" answer.
Yes, but wrapping almost every argument in a newtype, then unwrapping (with .0) them in the function isn't exactly ergonomic, is it?
You don't need builder pattern to emulate named *and* default parameters, you can just use the `Default` trait and a struct to make some cool stuff: - Define a `FooParameters` struct containing all the args you need and impl `Default` for it with the appropriate default values - If you just need to change `foo` and `bar` values: my_awesome_func(FooParameters { foo: 42, bar: "cake", .. Default::default() });
Interestingly, Rust "doesn't need" named parameters.. except `format!` (and friends) [implements named parameters](https://doc.rust-lang.org/beta/std/fmt/#named-parameters). This feature shouldn't require a macro.
Well i had a threaded solution for Rust mind you i have no clue to how actually multi thread, this took me about ~5 hours and i am very new to Rust, used it for about 2 weeks and i am a beginner in programming (learned Python a year ago). I actually finished a single threaded solution in 30 minutes but decided i wanted to try threading it. Now my results with the challenge string `yzbqklnj` and 6 leading zeroes (you can't compare this by calculating different keys, some keys might not even exists or be all the way at the end of the search), cpu: 6 core AMD, no SMT/HT: - Your Python solution on my system runs in 25 seconds. - My [Rust threaded](https://www.reddit.com/r/adventofcode/comments/3vdn8a/day_4_solutions/cxmt9ag) solution (using locks) running it in 0.8 seconds, - My [Python "threaded"](https://www.reddit.com/r/adventofcode/comments/3vdn8a/day_4_solutions/cxn40x2) solution (splitting a range) does it in 4 seconds. (took me about 30 minutes to make it). (Mind you not that python solution is very much half baked) Now I calculated against other single threaded rust solution, they mostly all ran at 4 seconds on my PC, so this again points towards about 5x faster, not 3x. But this is all bound not by your code, but by the hashing library. So away from numbers, this doesn't say much if Pythons hashing algorithm (which does 90% of the work) is written in C *(which i am unsure of)*. So we're not comparing Python but libraries. Because Python is a very good high performance language when you use the right libraries at the right places. 
About the cited [poly-collections](http://bannalia.blogspot.com/2014/05/fast-polymorphic-collections.html) &gt; In C++, instances of classes derived from an abstract class are typically heap-allocated and managed through (smart) pointers because their exact types (and hence their sizes) are not known until run time —strictly speaking, the type of each object is known at the point of creation but then abstracted away or erased when passed along to the location of the program where it is stored and used. For this very reason, such objects can't be stored in STL collections directly but rather through an indirection. This seems to describe objects analogous to Rust's trait objects. Is this kind of structure (grouping together each possible variant of a trait object) possible in Rust? That is, [this](http://2.bp.blogspot.com/-Lv6UAlC4odg/U2LROnC6CCI/AAAAAAAABGI/kXBnlQSjjUo/s1600/poly_collection.png) instead of [this](http://2.bp.blogspot.com/-7PrKhjz_y3E/U2KfmXMHklI/AAAAAAAABFs/fcQOdNYzLzA/s1600/vec_unique_ptr.png). The problem is that by the time you created a trait object, the compiler already erased its size. I don't really understand the C++ code to know whether the technique on it can be applied to Rust.
&gt; seriously, the builder pattern simply is a workaround for the nonexistence of that feature. it is exclusively used in languages that don’t have named parameters, in places where other languages would utilize named parameters.. It is a matter of taste, I guess. I have been writing code in Scala and Python for years (both have named/default parameters), and I find the builder pattern a better solution for most cases. 
It wouldn't be trivial, since Rust can't use type parameters as traits, but I would imagine that it would end up similar to [`AnyMap`](https://crates.io/crates/anymap).
I mean, named parameters could be part of Rust's syntax.
I was going to chime in here with my solution and suggest single-threading, but that's already been suggested and tried, with the article updated. Instead, I'd like to point out that the advent of code challenges have been pretty cool so far, and I've been really enjoying implementing them in Rust. I would definitely recommend it for anyone who wants to get their feet wet with the language but doesn't have a modestly-sized project in mind.
u/coriolinus You should have used pypy (pypy3 in this case) if you're trying to get some performance out of python. No idea how many times faster it would run though.
Awesome. Thanks a lot. I'll give it a try.
The announcement emphasized cargo extras multirust update cargo install cargo-extras gives me .multirust/toolchains/stable/cargo/registry/src/github.com-0a35038f75765ae4/clippy-0.0.30/src/lib.rs:1:1: 1:42 error: #[feature] may not be used on the stable release channel Looks like clippy and script are included in cargo extras, but won't build on stable.
Yes, it calls those two out specifically: https://github.com/kbknapp/cargo-extras#included-subcommands
&gt; The biggest news with Rust 1.5 is the introduction of `cargo install` Is there also a `cargo uninstall`, or is it a one-way function like `cabal install`?
Basically, you want to pass a struct having the definition of an individual and then have the library run a number of iterations and give you the results?
Thank you, bors, for your hard work! (PS: For those who don't know: [this](https://github.com/graydon/bors) is bors and [this](http://buildbot.rust-lang.org/homu/queue/rust) is what it's doing :))
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/botsrights] [User thanks bors for its work](https://np.reddit.com/r/botsrights/comments/3w8lig/user_thanks_bors_for_its_work/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
That might be a good idea, yeah.
&gt; Enforcing parameters be included can be done at runtime with a Builder.finalize() function It can be done at compile time too with sufficient [application](http://is.gd/gvUpyb) of PhantomData.
&gt; cargo check To me this is probably the most useful/most frequently used cargo command; would it be possible to get this merged in the cargo itself?
It is a very likely candidate, yes. Getting `install` going so we can get broader adoption of custom commands is the first step towards getting more commands in Cargo itself. That way, we can see which ones are popular, and also, get them a bit more battle-tested before we pull them in. I expect `cargo check` to be the main command you'll be running most of the time in a few months.
I recently had to start writing a bit of low-ish level code, and started with C++ (of course), but coming from a high-productivity/low-performance background (mostly Python, a little Clojure) I really hated it. And then I found Rust which I think offers a spectacular alternative to C++ for many tasks. The ecosystem is much younger right now, but it's much easier to use third-party dependencies than C++ (one of my principal gripes with a recent project). I'm very much still a newbie, but here are some great talks from those more experienced that address some of the things Rust offers: - https://www.youtube.com/watch?v=_-fweBvtifA - https://www.youtube.com/watch?v=O5vzLKg7y- Here are a whole bunch of talks from RustCamp (some pretty good ones in there, IIRC): - https://www.youtube.com/playlist?list=PLE7tQUdRKcybdIw61JpCoo89i4pWU5f_t And here are some others I have bookmarked to watch later: - https://www.youtube.com/watch?v=agzf6ftEsLU - https://www.youtube.com/watch?v=3CwJ0MH-4MA - https://www.youtube.com/watch?v=BBbv1ej0fFo - https://www.youtube.com/watch?v=ySW6Yk_DerY
I haven't had a chance to use cargo check yet. What is the run time like? Can it be run on a single project file?
Isn't there a page somewhere where someone is graphing rust compilation times? I can't find the link, but I'd be curious to see how much 1.5 has improved.
https://github.com/sanxiyn/sandbox/blob/master/rust/time-2.png is the closest thing I know.
[Off topic] May I know how the code in https://github.com/rust-lang/blog.rust-lang.org is preprocessed before hitting the blog site? What package i need to install beforehand?
In my experience, Rust is a "hard" language to learn. Coming from an extensive programming background in a wide variety of languages, Rust has characteristics that make it quite unique which were a bit of trouble to wrap my head around. Of course, it's possible that to someone without a background in programming, these characteristics will come easily, as you might not be encumbered with old ways of thinking.
It's been stable since 1.0.0 &gt;How well does it interface with c? https://doc.rust-lang.org/book/ffi.html
I considered that, but my preference would be to jump into Rust itself. To be honest, part of it is practical like memory safety, data race checks, etc. The other part is a related to a reply I saw from /u/steveklabnik1 on the "Why learn Rust?" question which (I can't remember his comment word for word but it got me thinking about this) touched on the reason why I want get back into programming, which for me is the excitement that one gets from the activity of programming regardless of the technicalities of the language itself, and it is this very excitement that I get from Rust that pushed me to come back and ask this very question and start to be curious again. It may sound dumb to someone that doesn't know me that a language which could be considered "just a tool" could be this inspiring(?) but somehow, it has been. Yes, I know it is still maturing and the documentation is lacking, and the libraries aren't quite there yet, but I want to make the effort for this language rather than putting it off for later, even if it would simpler to just learn python. I don't know, maybe it is dumb, but I thought if anyone would have any ideas, it wouldn't hurt to try.
I find Build patterns and structs much more solid approach. IMO, it's just another feature that saves some keystrokes initially that introduces bugs and makes it harder to do re-factoring later. 
&gt; As for where to go next with the project, you could include a short walkthrough of functionality from the library in the README, Hmmm, I didn't realize that the README was so bad, since it's the first impression of the library that's kinda bad for me. I'll work on that tonight. &gt; or write a series of blog posts exploring how to solve real-world problems with this actor system And to think that I managed not to have a blog until now... More seriously that's indeed a great idea, I'll try to do that during the holidays (plus if i make a toy project, I'll have to use my library much more than now, so I might find features myself :) ) &gt; Most actor frameworks also seem to be able to act across machine boundaries (over networks), so that could also be a good place to start exploring. Thanks, I was thinking of doing that but affraid that it would not actually be that useful :)
The second part of your comment was actually one of my bigger considerations here. I'm not really intimidated by difficulty, I managed to teach myself a second (human) language pretty well, so... ¯\\\_(ツ)\_/¯
See: https://help.github.com/articles/using-jekyll-with-pages/
While mozilla employs a number of core developers, Rust is a community effort.
We have a strong commitment to SemVer, and we have zero-cost C interop.
It's Jekyll.
Could a cargo command at least indicate which files were installed (and therefore could be removed)? Perhaps doing this is basically what `cargo uninstall` would entail.
The Samsung Open Source Group [is contributing to Servo](http://blogs.s-osg.org/servo-continues-pushing-forward/), the most high profile Rust project. Rust itself is looking more and more like a community project, even though many key contributors are Mozilla employees. Rust has a lot of [nice projects](https://github.com/kud1ing/awesome-rust). Many of them are libraries and development tools. You can check the [game engine Piston](http://piston.rs) (see also /r/rust_gamedev), the [web framework Iron](http://ironframework.io/) (see also [Nickel](http://nickel.rs/)), the operating system [Redox](https://github.com/redox-os/redox), among others. I'm specially excited about [Diesel](https://www.reddit.com/r/rust/comments/3ur9co/announcing_diesel_a_safe_extensible_orm_and_query/), announced last week, and [RustAudio](https://www.reddit.com/r/rust/comments/2vn0xx/rustaudio_a_collection_of_crates_for_audio_and/). [Here](https://www.youtube.com/watch?v=_ZXLCVibI8c) is a demo with RustAudio and [Conrod](https://github.com/PistonDevelopers/conrod). edit: another project using Rust is [MaidSafe](http://maidsafe.net/).
The hyperthreading issue here also affects build times for crates with a lot of dependencies. By default, `cargo build` runs one parallel job per logical core, rather than one per physical core. On my laptop with 4 threads on 2 physical cores, I get a speedup by running `cargo build -j2` instead of `cargo build` (which defaults to `-j4`). You can change the default locally in [`~/.cargo/config`](http://doc.crates.io/config.html) but it would be great if Cargo could choose a better default itself.
One of the areas of my prior knowledge that was hugely helpful to me while beginning to learn Rust was understanding assembly language, allowing me to think about the translation of Rust thereinto. Doing so gave me a better understanding of *how* Rust accomplishes its features, and thus the costs associated with one technique versus another. All of that might be too low-level for you at this moment; focus on learning the high-level aspects of Rust first. But then, don't deprive yourself of an understanding of what's actually going on *underneath* Rust. I believe it's impossible to be a good user of a language that compiles to assembly without (at least some of) an understanding of assembly.
You can also say `MyType::default()` if you think the redundancy is ugly.
&gt; When asking questions like this, it's generally a good idea to try to trim your sample code down to something that can run without dependencies. For the first problem the DBVTBroadPhase can be substituted with a `Vec`: https://ideone.com/WPDq1E I'll have to look into the ncollide source code to get a substitute for the second problem... &gt; When the vector goes out of scope, there is no longer an owner, so it will be deallocated. I might be mistaken, but in line 51 (or line 33 of the smaller example just linked) I am moving the memory from the `Vec` into the `Box`. In fact, although I might just be lucky, it works like it should in the "real" program where I'm using that hack. &gt; What you probably want is something that returns the `Vec`, as that transfers ownership out to the caller. I want to ensure that the references into the array stay valid once the `World` is created. Thus I have chosen the `Box&lt;[]&gt;` in favor of the `Vec`. Perhaps there's a type that's better suited? &gt; This signature is essentially impossible to implement. What you're saying is that for any lifetime 'a, this function will return a World object in which all borrowed references do not outlive the lifetime `'a`. But since you're not passing in any objects which have that lifetime, there is nowhere for you to borrow those references from. This signature guarantees that you're going to have to lie to the compiler by writing an unsafe block. Darn. I thought the `'a` would refer to the lifetime of the `World` in that case. Is there a way of referencing the lifetime of the returned object? And can I specify that the elements of the `Vec` created locally will be moved somewhere with the same lifetime (thusly their references staying valid)? &gt; I think that the `World` should only contain owned objects, and the `DBVTBroadPhase` should likely be constructed later, and can contain borrowed references to the objects owned by the `World`. The `DBVTBroadPhase` is intended to be updated, not created for each frame. Which brings me to the next point: &gt; Just write something that implements very basic circle collision on your own I have thought about that, especially because checking for collision between circles is the simplest one can think of (apart from collision between a point and a circle - or between two points :P), but the ncollide library maintains a data-structure that makes it easy to retrieve nearby objects, or at least I hope it does. This should make for a lower algorithmic complexity than the O(n²) of the naive approach of checking for collision between all objects. &gt; By the way, it would also be good if you could describe your current level of experience with programming in other languages. I have a couple of years of experience, mainly with C++. I've dabbled with various other languages, ranging from x86 Assembly, over stuff like Java, Python and sh to languages like Scheme, OCaml and Haskell. Many languages I've only worked with a couple of months though, most of my experience is with procedural programming languages. I think I have a grasp on ownership and borrowing - that's what drew me to Rust even though C++ got smart pointers. I have just started learning Rust about a month ago though, so I know the idea behind encoding these concepts in the type system, but I'll have to learn to express my intentions in Rust.
Hmm, seems promising. I'm mainly worried about using rust to develop programs and then my coworkers finding that the language has languished and needing to port to something else later. This eases my fears a good bit.
Download the new installer and run it, everything will just get upgraded.
That's a design decision, not a bug.
Design decisions can be bugs.
I disagree that this is common. 
The problem with builders is manyfold: * The syntax is *much* heavier on the eyes. You're switching from what is, using a kwargs-style construct, to what is likely a multiline chain of methods which also require the import of the builder itself. * For functions which have trivial logic checks, writing so many methods for a builder objects gets tedious and doesn't give anything back. * Default structs are good... until you can have different combinations of default structs that work. * I don't see the reason for having to define the arguments structure *plus* the underlying finalized struct when they are both so similar yet different enough to not be recycled. It's an eye-sore.
If you're using a lot of arguments in a Python function the pattern is to just use the underlying **kwargs objects. Rust can easily and trivially use structs for the argument passing. But having to define them for every situation, plus accompanying builders, does not provide any benefits whatsoever from an ergonomics or safety point of view.
format! to me is the biggest justification as to why named parameters are needed; we're using them already, they would look better everywhere builders are used already, and the sugar does not have any downsides.
On Slide 6: &gt; Une reference ne peut survive a ce vers quoi elle pointe *. &gt; C'est ce que l'on appelle un system de type affine. I am not sure whether "reference" here is meant as (a) variable or (b) pointer. From the text I would suspect the latter, however then the note about Affine Type Systems does not make sense. An Affine Type System is a Type System where a value can only be used *at most once* (exactly once is a Linear Type System), and while it is useful for memory safety, it just is not sufficient for the borrow checker.
Well, strictly speaking, there's supposed to be one: though it's searching for md5 hashes with *N* leading `0`s, it's supposed to return the smallest integer which produces that hash. That said, I honestly don't know what's causing the behavior you're seeing. Units of work are assigned sequentially from 0, so it should be impossible for every thread to bypass the block containing the lowest potential solution. Even though multiple threads might return potential solutions out of sequence, there's [code in place](https://github.com/coriolinus/adventofcode-2015/blob/master/day4/src/lib.rs#L96-L104) specifically designed such that whenever any thread reports success, it should wrap up the last results from every running thread, and only return the minimum. That you're getting different results suggests my code there isn't working, but I can't see why it wouldn't or how I'd solve that issue.
Hmmm, I am not a Windows person, but it _should_ just work..
I hope so too, but let's start small :)
I am not sure it is better; I can see cases where you would want the compile-time computations to match the run-time ones.
That's what I was thinking too.
Indeed, and from what I've seen of languages with dependent types they seem much more experimental right now too...
I'm starting to learn rust and seriously considering migrating back to Arch from Debian.
Hmm. Is branching twice faster? Gosh darn micro-benchmarks, there's no end. Joking aside; it might be faster, I didn't check that to be honest. Someone should make a third post on this topic doing it like you described, it's not like this subreddit can have too much MD5 right? :P
You found a bug! That code is supposed to look like [this](https://github.com/coriolinus/adventofcode-2015/blob/master/day4/src/lib.rs#L135-L155): let begin_at = next_work_rx.recv().unwrap(); let mut this_work_result = None; for current in begin_at..(begin_at + WORK_SIZE) { md5.input_str(secret); md5.input_str(&amp;current.to_string()); let digest = md5.result_str(); md5.reset(); if digest.chars().take(leading_zeros).all(|c| c == '0') { this_work_result = Some(current); break; } } if result.send((next_work_tx.clone(), this_work_result)).is_err() { break; } Quite right that they were sending those `None`s for no reason; they're supposed to report back in and request a new unit only after having either found a match, or exhausted their current unit of 1024 items to check. Most likely, that's also what was causing the numeric instability reported by /u/Quxxy. Thanks for taking the time to look this over and help me improve my code!
People love to abuse the word "ergonomic" in rust discussions... why is that? I don't see more syntactic noise from the caller's point of view between foo(Miles(23), Days(42)) and foo(miles = 23, days = 42)
It's too late for me now and a busy day tomorrow; maybe someone will beat me to it before the weekend.
I've moved to using [multirust-rs](https://github.com/Diggsey/multirust-rs-binaries/raw/master/x86_64-pc-windows-msvc/multirust-rs.exe) on Windows. Works perfectly fine.
&gt; This way, ... , update my rust musl in the appropriate .multirust directory, ... I think the OP is using MUSL, but they still have `libLinkMemory.so` linking dynamically to provide the implementations for `shmget` and `shmat` and want to get those implementations into the `libc` crate. (OP please tell me if I am off-base here)
There's a few things: first, the ABI and some constants are slightly different, but with Rust specifically, you have to make sure that all of the C code was previously properly compiled with that right libc, beforehand. You'd be doing that, but yourself, if you were using gcc/clang directly.
How actually fast is it? My naive implementation: https://github.com/dikaiosune/adventofcode2015/blob/master/src/day_four.rs 0 ✓ adam@icemachine ~/rust_projects/adventofcode2015 $ time target/release/adventofcode2015 -d 4 -p 1 Running solution for day 4, part 1... Reading challenge input from input/4 Solving challenge for day four, part one... Santa can use 282749 as the integer input for his AdventCoin function. real 0m0.090s user 0m0.087s sys 0m0.000s
To nitpick your example: `format!` implements _variably_ named parameters, aka python kwargs. It makes sense for that to require a macro in Rust. (Edit: It also requires that you write it as a compiler plugin or pre-processer, because normal macro rules can't parse the format string).
What are your pain points? I use Debian every day.
Or `|` all of them together rather than add (either shifting or masking the last one)
A similar use case I can think of is SQL parameters ([oblig](http://bobby-tables.com/python.html)).
That's not good. /u/a-t-k 's suggestion is probably better in that case. Changing the i32's to u32's might work too.
Also, could't you just mem::transmute the loop variable i to a &amp;[u8] instead of doing .to_string().as_bytes()? That would save you a heap allocation per loop iteration.
This is really neat. How does it scale though? For instance, what if there were two required parameters?
&gt; default parameters yes, i always think of named and default parameters when hearing “named parameters” i know that theoretically, you can have only named parameters (for reordering and making it more explicit), but i think it’s rather pointless &gt; I'm not exactly excited when I come across a function with 20 parameters and all or most are optional true, but the same is true now with the builder pattern and param structs with dozens of fields
How could that happen? output is an array of u8, where would they cancel each other?
112u64 would transmute to `[112]`, whereas it converts to `[49, 49, 50]`
Oh yeah, of course. Nevermind that then.
Does not compile: main.rs:6:24: 6:50 error: the trait `rustc_serialize::serialize::Encodable` cannot be made into an object [E0372] main.rs:6 impl JsonEncodable for rustc_serialize::Encodable {} ^~~~~~~~~~~~~~~~~~~~~~~~~~ main.rs:6:24: 6:50 help: run `rustc --explain E0372` to see a detailed explanation main.rs:8:24: 8:40 error: the trait `serde::ser::Serialize` cannot be made into an object [E0372] main.rs:8 impl JsonEncodable for serde::Serialize {} ^~~~~~~~~~~~~~~~ main.rs:8:24: 8:40 help: run `rustc --explain E0372` to see a detailed explanation error: aborting due to 2 previous errors Here's the explanation: $ rustc --explain E0372 Trying to implement a trait for a trait object (as in `impl Trait1 for Trait2 { ... }`) does not work if the trait is not object-safe. Please see the [RFC 255] for more details on object safety rules. [RFC 255]: https://github.com/rust-lang/rfcs/pull/255 I believe the problem here is the traits have generic methods and thus cannot be coerced into trait objects.
When output[0] == x, output[1] == -x and output[2] == 0. The adding operator is not how you check for 0s, use bitwise OR.
I can't quite say. Every so often I like to switch distros and I'm in the mood for Arch again.
Design decisions can be suboptimal decisions that should change, but it would be more productive to explain why you think this decision is wrong than to just call it a bug, which can come off as dismissive of the designers.
is it just me or did you not actually provide any bench marks in your gist?
This is really what it should be. output[0] | output[1] | (output[2] &amp; 0xF0) != 0
This battle was settled explicitly long ago. https://github.com/rust-lang/rfcs/blob/master/text/0430-finalizing-naming-conventions.md &gt; In CamelCase, acronyms count as one word: use Uuid rather than UUID. 
You can always disable the warnings.
You can use `write!` to avoid allocation: ... let mut buf = Vec::with_capacity(8); for i in 0..std::u64::MAX { buf.clear(); write!(buf, "{}", i).unwrap(); ... hasher.input(&amp;buf); This decreases the running time by ~25% on my MacBook...
You should feel more than welcome to add API definitions to libc! There are [instructions in the README](https://github.com/rust-lang-nursery/libc#adding-an-api) for how to do so, and so long as it's green it's good to merge. Let me know if you have any trouble! (@alexcrichton on github and acrichto on IRC)
You need to install the command line tools separately in MSVC Community 2015. This is done by opening a new project and selecting C++ as the type. This will open a dialog where you click on an option to install the command line desktop tools -- which includes the linker.
http://ncameron.org/perf-rustc/
It's likely faster to just do branching on the first byte, and checking the rest inside the if-statement. Think about it, the first byte is only zero 1/256 of the time, so the branch predictor will just skip over that whole thing and only pay the branch penalty (a dozen cycles or so?) every 256 times (and even then the next branch, for the second byte, is equally easy to predict).
Thank you for your time. That makes sense.
For finding the key `yzbqklnj` with 6 (because i had the numbers) leading zeroes (on my system: AMD 6 cores): - It finishes in 2.8 seconds. - [The Python](https://github.com/coriolinus/adventofcode-2015/blob/master/day4/py/day4.py) one did about, 25 seconds. - My [multi threaded Python](https://www.reddit.com/r/adventofcode/comments/3vdn8a/day_4_solutions/cxn40x2), 4 seconds. - Most Rusts ones using strings, 4 seconds. - My [multi threaded Rust](https://www.reddit.com/r/adventofcode/comments/3vdn8a/day_4_solutions/cxmt9ag) using strings, 0.8 seconds. - edit[0]: My [multi threaded Rust](https://gist.github.com/SimonWoodburyForget/075db6ceb2d283b0ad5f) implementation of his optimization, 0.56 seconds. The correct output `key : hash` should be: `yzbqklnj9962624 : 0000004b347bf4b398b3f62ace7cd301` Mind you, i had no clue what i was doing in that Rust code at all, i programmed and played with threads, mutexs, arcs, up to the point Rust let me compile and then kept playing with the control flow until the timing looked nice enough to get me bored. edit[0]: it's a bit more "advanced" so that it can stretch it's number of leading zeroes without changing the code. 
Thank you for the tutorials, I will put them on my todo list to watch. I do know the eco system is young, and that is why I would like to contribute to rust. Hopefully I can get used to the syntax, there are a few oddities in rust I haven't experienced in any language(such as the =&gt; operator), but I will get there.
Ohh, I hadn't realised `rustc_serialize::Encodable` and `serde::Serialize` were traits. I get it now, the serialization struct is implemented on the user end (manually or derived), thus there isn't a serializer struct which you can abstract upon. Given that, I think it's not possible to do that using the type system alone (it's fine using `cfg`s and features, like on toml-rs). What makes it impossible is that a given type may have both rustc-serialize and serde's traits implemented and if there were a trait which would work with either it wouldn't be able to chose one over the other.
I actually added that part after reading "Linear types can change the world", in which Wadler writes: &gt; Pure linearity is, in fact, a stronger constraint than necessary. It is ok to have more than one reference to a value, so long as the value is being "read"; only when the value is "written" (e.g., destructively updated) is it necessary to guarantee that a single reference exists. Because affine types have weaker constraints than linear ones, I felt as though this was sufficiently accurate. EDIT: Also, I indeed meant "pointer" (which is called a _reference_ in Rust AFAIK, since it also has raw pointers, even though they are only useful in Unsafe code).
Although I must admit that it is lacking some information. I didn't really want to put big blocks of text either, since we cannot directly read from our slides during the presentation. The most obvious case is when I had asterisks* to remember to add important details which I omitted from the slides.
I think you shouldn't use that syntax in Ruby. It has only an awkward way to check the exit status of the called process that is removed from the actual invocation (`$?`) and passing arguments to processes called like that is inherently error prone (`ls #{foo}`). Also I'm not even sure how portable it's syntax is. After all, Windows doesn't use Unix shell syntax. As /u/zenflux suggested, use `std::process::Command`.
That is the answer but I am looking for a day when it will be possible. It would IMHO simplify things. 
I don't know of any, but you could help out by writing one. In fact, if you did write such a library, I'd be glad to help with the Windows implementation. `WlanQueryInterface` to query the handle obtained by `WlanOpenHandle` in order to get a `WLAN_CONNECTION_ATTRIBUTES` which has a field `wlanAssociationAttributes` which in turn has a field `wlanSignalQuality` which is what you want. https://msdn.microsoft.com/en-us/library/windows/desktop/ms706556%28v=vs.85%29.aspx
If you were really hell-bent, you might save some time by iterating through integers of the form 0x3?3?3?3?... where ? is 0 through 9, instead of using to_string, and maybe having a specialized MD5 implementation since it's a relatively simple algorithm.
Knowing what is being copied or moved, how for loops work, operator traits, when `Deref` is used, etc..
Try to look beyond the syntax, and look at the semantics. For example, Rust's `match`: let x; match 1 { 1 =&gt; x = "ho", 2 =&gt; x = "ho", 3 =&gt; x = "ho", 10 =&gt; x = "blargh", _ =&gt; x = "huh?", } ..is like C++'s `switch`: char * x; switch (1) { case 1: case 2: case 3: x = "ho"; break; case 10: x = "hi"; break; default: x = "huh?" } Only it has more pattern matching semantics on top, for example with the range pattern syntax: let x; match 1 { 1..4 =&gt; x = "ho", 10 =&gt; x = "blargh", _ =&gt; x = "huh?", } And it is an expression, ie. it returns a value: let x = match 1 { 1..4 =&gt; "ho", 10 =&gt; "blargh", _ =&gt; "huh?", }; And for compound datatypes, you can pull stuff out, and use wildcards: let x = match (true, 1) { (true, 1..4) =&gt; "ho".to_string(), (false, 1..4) =&gt; "yo".to_string(), (_, 10) =&gt; "blargh".to_string(), (true, n) =&gt; format!("huh? {}", n), (false, n) =&gt; format!("yuh? {}", n), }; Dunno if that helps, or is just more confusing! 
The problem is that acronyms like to bundle themselves next to each-other. You get stuff like `WTFOMGBBQHTMLMD5`, which reads much better as `WtfOmgBbqHtmlMd5`.
What do you mean? script has built on stable for a while now and... wait... the latest version is 0.1.3? But that would mean I completely forgot to... ... oh. Uhh... hang on, I'll be right back \**scurries off*\*
Oh output is [u8], ya in that case it works. I missed that reading the code.
The other responses are good, but for completion I want to add that this syntax is just a small variation of ML's match statement, so it has at least 40+ years of precedent. Example: match x with | 0 -&gt; "none" | 1 -&gt; "one" | _ -&gt; "many"
I guess I need to reach office to read them. If using HTML instead of PDF, please don't constrain zooming. 
[And a link to the repository itself.](https://github.com/Diggsey/multirust-rs)
Hooray! The fact that someone is using this makes the time I put into those d2d1 winapi bindings worth it :D
&gt; The biggest news with Rust 1.5 is the introduction of cargo install, a new subcommand that installs Cargo application packages on the local system What about `rust uninstall` `rust upgrade`?
There *is* a REPL for rust, called rusti. Am on mobile, so please somebody link.
It's not a real REPL though, is it?
Multirust is the way to go. It enables you to switch to Nightly on a per-project basis, and then switch back to stable when the feature you want is available, with minor friction. This is seriously awesome.
Link: https://github.com/murarth/rusti
As powerful as Scala is, which I don't doubt for a second, I can't get over how noisy its syntax is. Sigils and keywords everywhere! It's so much cognitive overhead.
Now the question is: is it possible without marking the entire code as `unsafe`? :D
Not a true REPL, no. It essentially adds each expression to one big source file and recompiles it each time. It's probably all right for testing a handful of expressions but the execution time for each new expression is going to be slower than the last. A serious REPL should only compile new input. I think there's some aspects of Rust which make this difficult to implement without a lot of complexity and/or restricting the semantics of the language to a more manageable subset.
You can upgrade by running install again, and uninstall also exists. 
Me too. I even prefer Firefox's scratchpad to the REPL.
For me foo( miles = 23, days = 42) is definitely easier to read than braces ridden complement ` foo(Miles(23), Days (42))) `. Each brace in my mind creates a cognitive load of "did I match it properly?", because successive braces meld into a single brace for me. 
Actually, it's more of a read-compile-run-loop.
Thanks.
I think this is unfair and unreasonable. You know, people continually complain how noisy Rust's syntax is, and it's unfair and unreasonable. Same for Scala.
Use Self. For example, this is roughly how Clone trait is defined: pub trait Clone { fn clone(&amp;self) -&gt; Self; }
I knew it had to be possible in a simpler way. There is always a simpler way. Thank you!
In my experience that only comes up when you're doing something complicated with types. Typical business code needs very little of that (in my experience)
I personally think, the problem in Scala is way worse, because anything can be a function name . I might be mistaken, but even `+-~` is a valid operator/function name. In Rust, you 'limit' the non-standard syntax to `macro!{}` declaration or `#[magic]` procedural macro. Some choices made in name of compatibility with Java were... dubious. E.g. when you compare you return an `Int`instead of an `enum { EQ, GT, LT }`. **Order of traits AFFECTS behavior.** So if you have `new Ball with Red with Shiny` is not same as `new Ball with Shiny with Red`. To me the fact that this can happen is frankly frightening. How do you test for such complexity?! Just imagine if implementing `#[derive(Hash, Eq)]` would yield different behavior to `#[derive(Eq, Hash)]`or that `impl X for Struct {}; impl Y for Struct {}; ` was subtly different than `impl Y for Struct {}; impl X for Struct {}; `. ------------- These are just quick experiences, that made me turn down Scala. The only thing in that approaches this level of weridness is `Deref`functionality (and Scala has similar feature AFAIU called `implicit`). I know why its there, but boy does it complicates things (especially reading the docs).
Type inference makes it tricky. Your REPL would have to be lazy (for cases when it did not yet get sufficient type information yet). What is the use case for a REPL in Rust anyway?
TIL (from slide 10) that you can actually do this: let x; { // new scope for borrows ... // prepare some stuff x = ...; // assign x from previously computed stuff ... // clean up } ... // use x instead of let x = { // new scope for borrows ... // prepare some stuff let tmp = ...; // assign x from previously computed stuff ... // clean up tmp }; ... // use x That's awesome. Thanks!
`cargo uninstall` is there, `cargo upgrade` is not.
Yup! `{}` is an expression, like everything else :)
The real benefit of a REPL isn't a plain REPL on its own. It's being able to work on top of a partial program (even one that blows up somewhere on startup), akin to a powerful debugger (but not for debugging per se). If I run `python -i myscript.py` I can immediately start running and introspecting my values, yet the basic script is still very much inside my editor. In fact, I've moved the REPL into my editor to get something akin to [Light Table](http://lighttable.com/#features).
Thanks! But I ended up finding this: https://adjivas.github.io/shm/shm/ And I'm currently working on trying to get this going instead before I jump into editing rust's libc exposures. Thanks for the pointer on the instructions in the readme! :D I appreciate you being so kind.