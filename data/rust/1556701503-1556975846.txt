While it is trivially obvious if you just tell a user that to treat it like a macro, this abstraction will inevitably break down, and at that point the user has a more complex situation to deal with - something that looks like a macro, but will not work as a macro in certain rare cases. I don't think that's a hugely helpful situation to be in, currently. That said, this does give me an alternative idea: a prefix keyword (e.g. `await`) can trivially be turned into a postfix macro, if that macro definition is something like `expr =&gt; await $expr`. So implementing a prefix keyword does not preclude the possibility of postfix userland abstractions being implemented later, as soon as postfix macros are enabled. Which would imply that the best strategy now is to implement a more traditional `await` syntax, recognising that this produces some non-ideal code in situations involving a lot of chains, and then implement postfix macros as a next priority. Has this been discussed yet as a possibility?
At this point every possible syntax has been discussed thoroughly, and the people on the lang team have been spending great efforts to weight the tradeoffs! The \`?\`-operator was a bikeshed of similar volume, but in the end the error handling in Rust turned out to be my personal favourite error handling in any language I know. It's because it's so readable: You understand quickly what someone else's code is doing because the success path is not obfuscated AND error handling is explicit. &amp;#x200B; I'd like to give the people on the lang team at least some reward for their work by saying thank you. Thank you for making Rust even more amazing!
The problem with that is the tilde doesn't really express "oh yeah of course that's an await" in any intuitive way. ? Seems to get the job done ok for results since you're basically querying if it was ok, but ~ has no similar meaning in any other language and Is small enough to gloss over while skimming code
Just give us method call syntax macros already. üêº
At this point every possible syntax has been discussed thoroughly and the people on the lang team have been spending great efforts to weight the tradeoffs. The \`?\`-operator was a bikeshed of similar volume, but in the end the error handling in Rust turned out to be my personal favourite error handling in any language I know. It's because it's so readable: You understand quickly what someone else's code is doing because the success path is not obfuscated AND error handling is explicit. &amp;#x200B; I'd like to give the people on the lang team at least some reward for their work by saying thank you. Thank you for making Rust even more amazing!
The output from above is actually with \`cargo test -j 1\`. Didn't fix it üòû
I always wondered why...
Hi, i need a little help with cannot infer an appropriate lifetime due to conflicting requirements from a closure: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a96c409196f151a2fd82322c3dc5aba9](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=a96c409196f151a2fd82322c3dc5aba9) The problem is probably that the closure holds a reference to \`self\`. I think a solution would be to add a lifetime, but the return time does not included a reference. Any idea?
Haha I didn't even realize it was 4 years until I read your comment. I thought it was a joke about govt projects taking twice as long as expected. I blame 24 hour days :P
The most disturbing part is all the gentle touching of the cow porcelain statue in the video.
aand it's an ASMR video, they always creep me out.
Really sweet! I'd love to try it but got a bit lost trying to clone and duplicate. There seem to be `../gltf` and `./rendy/rendy/` reference things going on. If you've modified other libraries, it would be easier on us to test or pitch in if you publish those separately and refer to them as dependencies with something like `portaudio = {git = "https://github.com/RustAudio/rust-portaudio.git", branch = "master"}`
Otoh this discussion is likely gains 50x more traffic than any other past discussions.
I am pretty sure that in most jurisdictions it would, but given how many different jurisdictions there are you can probably find one where such an implicit agreement does not hold any water.
So to be clear, whatever the await syntax ends up being, it cannot *be* a macro, postfix or otherwise. The team have ruled this out due to error ergonomics, and also because it has some unwanted side-effects (I believe it can be used to create a `yield`-like macro, which would be undesirable at this point). Any version of await that looks like a macro (again, postfix or otherwise) would therefore have to be special-cased in the compiler. It could still look like macro syntax, but it would not be a macro in its own right. For me, this is the number one reason why I'm not convinced by any of the macro or macro-like proposals - this is new syntax, and it should look like new syntax, not something that could be implemented in userland code. That said, if postfix macros were also implemented (this would probably take some time, but isn't impossible), then any prefix `await` syntax could be converted into a postfix macro of some description. Something along the lines of: macro_rules! do_await { ($expression:expr) =&gt; ( await $expression ) } The problem here is with naming - I think it's to be expected that the postfix macro would usually be more popular than the prefix syntax, so it should probably be possible to call it with just the name `await`, but then if that's a reserved word, this becomes complex.
I'm sorry, but I don't get why you want AI in your parser. Could you explain the usecase for this?
I've been working on [Bake](https://github.com/stepchowfun/bake), a containerized build system inspired by a tool we use at Airbnb. For a crude explanation, it's like Make meets Docker. You define tasks (like installing dependencies, building the project, running tests, deploying, etc.) and it runs them in Docker containers. I use it for all my side projects now.
The mods regularly put some cool videos in the sidebar, and they never disappoint.
Thank you very much, the +1-1 thinking makes sense. I also found out the playground has a show assembly feature, both those two lines yield exactly same assembly code for those who are interested to try it out.
Because it's a great video.
Unless there is some kind of "automatic unwrap" special casing, I think it's fairly straightforward: you can only call `await` on a type `Future`
This is a natural language parser.
Not sure if anything except *Postfix macro* and *Method call* will work, because of method chaining.
Yes I read it, but that doesn‚Äôt mean that I agree with them. Using `@` would also be very weird, because there is no existing semantic connection between that character and what await does.
I'm not sure what you did exactly. Did you implement a WebDAV library that could be used to build clients or server, or did you only write a WebDAV server? It sounds like you could have made two separate crates.
Reverse engineering and game hacking for windows, I also dabble in driver development. I'm a huge fan of wasm because it allows me to showcase my Rust to a much larger audience! I made [pekit](https://casualhacks.net/pekit) as a simple online PE viewer backed by [pelite](https://github.com/CasualX/pelite) which is more of an reverse engineering automation library. Its primary purpose is being _fast_ because the industry standard tools (IDA, Ghidra, others) are super slow for game binaries (typically 40-50MB and can be 500MB in memory). I have some many ideas for these projects but so little time, I work in 3D printing in my day job. Which is a mix of C++, C#, python.
Can you share some code snippet
Companies working in a brand new space aren't afraid to push the boundaries and use new technology perhaps?
Oh! This suddenly makes much more sense!
It is weirdly but profoundly fascinating.
Or the `...` proposal: `let response = http::get(url)...?;`, although that looks weird when chaining methods, but it does force there to be a visual gap which indicates that some time passes before the processing continues. But really so long as it is not excessively verbose that's fine with me and I'll work with whatever the lang team chooses. Rust already has some verbose parts, e.g. having to use `if expr { expr } else { expr }` instead of the ternary operator from C. My longish term plan is to remap this in the editor, if I get around to that.
Now this could be a *very* useful lib..
It's visible in the official Reddit mobile app as well in the "Community Info" section for the subreddit.
if you're going to go that route, I don't see the problem with a postfix macro. you'd see the same error ergonomics as the existing await macro; unless that's not good enough for whatever reason. and re the difference in behavior across compiler special case vs actual postfix macro. is there any reason a theoretical real macro couldn't emulate the compiler specific behavior (preventing `yield`)? If it could (with worse error ergonomics) then I'm not sure i see why it would matter whether the compiler special cased it.
I like the bismuth one best
Don't run your services as root and the attacker will have very low chances of getting root access.
The first. It's a library that can be used to build servers, or to incorporate in servers. There's an example right on the crates.io / github.com page. I have also built an entire server using this crate, but I haven't published that on crates.io yet. In fact I'm not sure if publishing applications as a crate is a good idea, perhaps it should just be available from a github repo.
In the end, no: eventually the user has to wait for the results of their operations. The goal of async programming is to push that \`wait()\` as high up into the top level of the application as possible, so that the underlying futures can get as much done asynchronously as possible. If you're \`wait()\`ing within one of your functions which isn't \`main()\`, consider having that function return a future constructed via combinators.
Sure, but if a hacker takes over a programm he might get access to a shell and can use exploits in other programms to gain root access.
&gt;this one (CodeLLDB) Worked great, thank you for this link.
There has been an effort to port/move (at least part of) rusty-machine into the rustsim group: https://github.com/AtheMathmo/rusty-machine/issues/199
Did you even do any research yet? What have you found so far?
If that happens, you have other concerns than your keys. If they get root access, it's game over.
I'd pose a different question: Is there any legitimate reason to use `wait` on futures?
At least for linux, you may want to look into setuid and related API's ( not sure if/how they are implemented in rust). You should be able to have both processes running as different users, and protect the crypto process storage by using regular filesystem permissions.
This would be wonderful to have. At least all the non-gpu non-deep-learning, for example the algos in [Mlpack](https://www.mlpack.org/) would be really great to have in Rust
That cucumber snake at the end made my day.
what's the state of crates.io mirrors and (private) alternative registries with http API? What I was looking for: * local, updateable crates.io clone with web api and all local storage * authentication from local authority (not GitHub) * must not access Internet except to sync crates.io mirror * perhaps with some subset of crates to save on storage * setup and maintain local private registry with web api for publishing/downloading proprietary crates. I found the following on mirroring crates.io: * [https://gmjosack.github.io/posts/dissecting-cratesio-minimum-mirror/](https://gmjosack.github.io/posts/dissecting-cratesio-minimum-mirror/) * [https://www.integer32.com/2016/10/08/bare-minimum-crates-io-mirror-plus-one.html](https://www.integer32.com/2016/10/08/bare-minimum-crates-io-mirror-plus-one.html) * [https://github.com/rust-lang/crates.io/blob/master/docs/MIRROR.md](https://github.com/rust-lang/crates.io/blob/master/docs/MIRROR.md) * [https://crates.io/crates/crates-mirror](https://crates.io/crates/crates-mirror) and for alternative registries: * [https://blog.rust-lang.org/2019/04/11/Rust-1.34.0.html#alternative-cargo-registries](https://blog.rust-lang.org/2019/04/11/Rust-1.34.0.html#alternative-cargo-registries) * [https://doc.rust-lang.org/cargo/reference/registries.html](https://doc.rust-lang.org/cargo/reference/registries.html) * [https://github.com/alexcrichton/cargo-vendor](https://github.com/alexcrichton/cargo-vendor) * [https://github.com/alexcrichton/cargo-local-registry](https://github.com/alexcrichton/cargo-local-registry) but I didn't find the one-stop, all-singing, all-dancing solution I was hoping for. are there other projects/blogs/docs that I should be looking at?
Some other questions worth asking to flesh out your (or your crate users') threat model: \- If I can run code as the parent process user, can I use the same api to interact with the crypto process? If so, what is the danger in that? (will probably depend on the use case) \- Do the performance characteristics you want to provide prevent you from running the crypto process in a different host? That would give you another layer of security if the parent process gets compromised
If you already have programmed in other languages and you are concerned about memory security, well, rust is for you. However, many people use Rust because they are tired of using old languages like C or C++ with all their limitations. They are doing their best to create a new ecosystem where you can you can make software using an efficient workflow. Take for example the inclusion of external libraries in a project. With C++, for example, you have to manually download all the dependency and link them to your project. There are some tools that help you in this process, but those tools are not native to the language, and if a library you want to link to your project does not use such a tool, you have to do everything manually. In the Rust ecosystem there is no problem, since everybody uses a package manager called Cargo,that downloads and links all the necessary dependencies for you. You can use Rust in every area of programming, like operating systems, game development, web development, and so on. The ecosystem is not 100% ready, but it is continuously growing, so in the future it will be easier and easier to make stuff in Rust. If you want to learn more about Rust, go to https://www.rust-lang.org/learn
I think this should go to r/webassembly. Rust is not only for WASM.
There is a create called [archery](https://crates.io/crates/archery) that allows you to statically pick the type of rc pointer through a type parameter. (I'm the author btw :)
No, I prefer @ since it looks like the first letter of ‚Äúawait.‚Äù
I got it to compile like so https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=65bccb5d295a1b7fedd9af94e7e78e15 The added `+ '_` indicates the Boxed thing shares a lifetime with self (I believe the underscore in this case matches the anonymous lifetime on `&amp;self`), and the added `move` keyword makes sure the `&amp;self` isn't used agree it's put in the closure.
The extension is written in Rust, I though it could interest some people.
I am currently attempting to build the first scalable decentralized [blockchain protocol](https://github.com/purpleprotocol/purple) and I chose Rust specifically for this because it provides the perfect balance between safety, speed and ease of development. It also has functional programming idioms which for me, being mainly a functional programmer, is sometimes like an oasis in a desert of imperative code.
Despite it already being used as a unary operator in other languages, using tilde as a unary operator has always felt wrong for me. The resemblance of its shape to `-` and `=` just feels too strongly like it should be an infix binary operator.
Personal favorite would be a generic version of the named postfix sigil style `http::get(url)@await`, where you could just put any in-scope callable thing after the sigil: `http::get(url)@await!` -&gt; `await!(http::get(url))`, `foo.bar@baz?` -&gt; `baz(foo.bar)?`. This doesn't seem to be a popular alternative though.
For people coming from garbage collected languages, a winning point about Rust is rewriting performance-critical parts without fear of memory errors, which can often bring great speedups.
I asked about this (specifically related to circle-ci) a while ago, here's the thread: https://old.reddit.com/r/rust/comments/azte2g/migrating_to_circleci_any_tips_for_keeping/ TLDR; most people just advised me to switch away from circle-ci. I ended up changing my build script to run `cargo test -j1 --doc` and `cargo test -j1 --lib` to separate out my two test runs into different processes, and it seemed to help a bit, but that's not really a solution
Oops, I was on mobile, I couldn't see the language bar on the repository.
Link to cast-rs under Crate OTW is dead.
Do you like programming languages with types? Rust might be interesting to you. Do you like fast code? Rust is very fast. Do you like secure code? Rust can help with that. Do you like deploying raw binaries without managing a vm or runtime? Rust can do that.
old question. A rust ML ecosystem should provide different levels of abstraction with simple to use interfaces under one umbrella project. From a very low level lib that would contain, Matrices and Activation functions a user could combine as desired. This could be a subset of bigger ndarray and the huge math libs available. But also, tools like bag of words, strides, roi/lattices on a matrix level. easy converion utilities from vec to matrix (ie filling a 1024x768 matrix from a Vec&lt;u8&gt;) by line, including pre-processing for text and other sources that are usually non in byte form by default. ie database table, files etc. The next level lib would allow the building of network layers with n-input and n-output (for linear classification) or similar for regression, genetic althorithms, lstm, networks and whatnot, that consists of easily connectable layers (fully, manual, random, whatever is needed).Functionality like drop layers, for If possible maybe even a combination of different ML techniques could be achieved. ie. an ANN layer that reflects one Genetic Althorithm. The highest ai/ml application layer would provide simple but extensible interfaces, to search, predictions, gan Each abstraction layer should be as simple as possible, so it allows new and old to dig deeper into the topic. The higher level libs should rely on generics from the lower libs to allow some sort of pluggable exentions.
Rust is for applications where memory and performance is a factor, but long compile times are not an issue
That's what I have thought so. But for some reason \`stm32f1x.cfg\` doesn't connect. \`stm32f3x\` connects and flashes. \`stm32f4x\` does connect but fails to flash. I didn't spend a whole lot of time investigating why that is happening. Might be the version of openocd that I am using or maybe the board I have is just a weird clone.
Rust is great for... * Writing "scripts" which don't require you to install the language runtime first. (If you don't depend on any C code and your Linux builds use the `*-unknown-linux-musl` targets, you can easily produce programs for Windows, MacOS, and Linux (see [cross](https://lib.rs/crates/cross)) where each version is just one file that'll run on a fresh install of the OS without installing anything else. * Rewriting the slow or memory-hungry bits of your existing programs as Rust extensions to make them more efficient. (See things like [Neon](https://www.neon-bindings.com/) and [Helix](https://usehelix.com/) for making this safe and easy.) * Writing programs where the compiler can catch lots of mistakes before you even *start* testing your program. (eg. The Hyper HTTP library takes advantage of how Rust's features work together to let you write state machines that are checked for validity at compile time. PHP's infamous "Can't set header. Request body has already begun." is a compile-time error when you use Hyper.)
happy cake day!
I know a good use case! Classifying /r/rust posts as either legitimate or intended for r/playrust
Is it deployable to real AWS Lambda?
Thanks, I think.
It's so incredibly mesmerising
Wut? It was in no way ASMR, just a guy making a phenomenal milk knife
 pub fn handle_command(matches: &amp;ArgMatches) { let (name, args) = matches.subcommand(); if let None() = args { println!("Please provide input file"); return; } // .. safe to unwrap here? } In a lot of examples I see IF LET being used with Option::Some() However, it strikes me as weird, because to leads to very hard to follow code. Naturally what you want to have is branching off / exceptional behavior as early as possible and having your main body code not nested. However unwrap is ment only for prototyping / development and not production. How does one correctly achieve linear branching off return early control flow of code?
These guidelines are pretty well followed by the teams _now_. A lot of these APIs predate such guidelines, and some are from when rust was pretty different as a language. So things got missed.
&gt; It's a library that can be used to build servers, or to incorporate in servers What is the difference with building client? Shouldn't there be a common part for encoding/decoding WebDAV requests? I was thinking of writing a WebDAV client recently, that's why I'm asking
Awesome. I will integrate this in the next iteration of the code I am working on.
Thanks for the broken link report, I've just done some housecleaning on the sidebar (I'm sure others have reported this in the past, but I'm just so horrible). Someday I'll find a place to surreptitiously hide video links in the redesign. Someday...
A `Waker` (and `RawWaker` and `RawWakerVTable` as internal implementation details) is basically a hand-implemented `std::function` (from C++). It's merely a type-erased callable (for the `wake` method) that also knows how to clone and drop itself. Why this can't be abstracted out is mostly beyond me.
The link from [https://crates.io/crates/cast](https://crates.io/crates/cast) is correct [https://github.com/japaric/cast.rs](https://github.com/japaric/cast.rs)
np
Thank you.
In general everywhere C++ is used but is boring because of his unsafe type system. Rust is awesome for many things : - JavaScript engine programming üòÅ it was created on that purpose - system programing (take a look at redox) - embedded / iot programming (take a look at rust-embedded) - nodejs add-ons programming (take a look at neon bindings) - webassembly programming (take a look at rust-wasm) - safe libs programming in general that can be used by any app with a shared object or dll But it's not a general purpose lang IMHO : - GUI programming is painful - Async programming is not mature and should have breaking change this year - API programming is not a good choice (you have more mature and pleasant solutions in OCaml or Haskell if you like ML type system)
 let args = if let Some(a) = args { a } else { println!("Please provide input file"); return; };
I'm glad you stumbled on this post. I did take a look at archery but wondered if you have another example? I got a bit confused with the HashMap. Probably due to the mental model I already had in mind.
That's very exciting to hear. If you don't mind me asking; Are you using the RUSTFLAGS override or something in the Cargo manifest or .cargo/config?
In the long run I think it's going to be the regular macro and eventually postfix `@`, the same fate as `try!()` and `?`.
There were previously ML attempts a while ago such as [AutumnAI](https://github.com/autumnai) in Rust. Could be good to start from there. In a similar vein, the Clojure community has recently been bootstrapping numerics/ML support, there are some useful learnings from that community as well. Personally, I think Rust could shine in the implementation of ml infrastructure such as BLAS, GPGPU, etc. The interactive stuff should still be done in higher-level languages such as Python.
Ok, for those like me who try and fail at first; I installed llvm to C:\\LLVM, then in my &lt;repo&gt;/.cargo/config I added the following lines: &amp;#x200B; \`\`\` \[target.x86\_64-pc-windows-msvc\] linker="c:/llvm/bin/lld-link.exe" \`\`\` It was truly much faster, but I do see some new warnings: \`warning: not embedding natvis: lld-link may not support the flag\`
It can be abstracted away, and higher level abstractions like Wake are implemented in the futures crate. Even then, creating a new Waker is normally reserved for executor implementations. It's not something many users are expected to do.
Awesome! I used to mess around in Powdertoy for hours, falling sand games are so much fun.
For something like your example, I tend to use [.ok_or_else()](https://doc.rust-lang.org/std/option/enum.Option.html#method.ok_or_else) to convert to a result, and then `?`. In order to use this, your `handle_command` fn would also need to return a Result, perhaps something like `Result&lt;(), Box&lt;dyn Error&gt;&gt;`.
participation and compatibility to existing solutions is often much more useful then reinventing the wheel just once again, because very well working existing solutions aren't written from ground up in rust... the less known [TVM](tvm.ai) project and its support for rust (beside a few other languages and hardware acceleration approaches) is a very well example for this kind of ignorance.
Because a knife made of milk will never rust.
This [comment](https://github.com/rust-lang/rust/issues/59725#issuecomment-480594110) talks about what a possible abstraction might look like, and some of the current blockers.
Another way that hasn't been mentioned, which I tend to use is `let thing = match some_opt { Some(thing) =&gt; thing, None =&gt; return }`
It no NaN Gates and Flip FLOPS but it's something.
[https://www.youtube.com/watch?v=lY10kTcM8ek](https://www.youtube.com/watch?v=lY10kTcM8ek)
The whole channel is great, to be honest. The videos are relaxing but also intriguing. Surprisingly well made, and the ingenuity of the creator in making some of these knives using cobbled together household items and what looks to be an incredibly small working space is inspiring. Along a somewhat similar vein I also enjoy this channel: https://www.youtube.com/channel/UCoC47do520os_4DBMEFGg4A It doesn't have the same "ingenuity" and creativity of kiwami's channel, but it's similarly relaxing, quiet, and interesting. A bit like the Primitive Technology channel that gained a lot of popularity awhile back. There's tons of channels like these, with content that tickles a curious mind but are otherwise relaxing. Good for winding down a long day of staring at 10-line-long rustc error messages brought about by 30 nested layers of Future combinators. (Or, in other words, giving up on understanding the error message and simply trying random tweaks on the code until the compiler is happy again.)
Heh, yea sorry. I forgot to switch those back to git deps when I pushed this time. Should be fixed now.
Thanks :)
Places where I use rust at work: 1. Embedded camera devices for remote maintenance in industrial environments. 2. Plugins for Unity3D (C#). Mainly to interact with our other systems or to do some "number crunching".
And Bob Ross is just a guy teaching others how to paint.
I'm pretty sure you don't want to do this , what are you trying to achieve?
Is glorifying the production of weapons really appropriate content for the rust community?
I will indeed. I' think I'll wait until tomorrow. I'd like to let people some time to answer the survey, but at the same time, I'd also like to publish some results soon, because I'd like to do so before the final decision has been made by the Rust Core team. Not because I want to influence them, but because otherwise this poll would have been completely pointless :).
Yes. Integrating them in synchronous code. Or for gradually asyncifying an application (Start on lower layers, then work upwards).
Was writing an ebook reader but thought it to be a better idea to start with something I know something of first, so I started writing an IRC library. Nothing fancy, just to learn. For anybody interested or if you have any advice on what not to do or what I could've done better: [nth-ird (github)](https://github.com/teslaNova/nth-irc)
you *do* realize knives have other purposes than as weapons, right? ...Like cutting? Yknow, food n stuff? The knife in the video looks more like a kitchen/chefs knife than a weapon.
If you feel like contributing to Rust itself (the compiler or standard library), you can check out the [issues labeled `E-Easy`](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy) for a good way to explore the codebase. There's also [Not-Yet-Awesome Rust](https://github.com/not-yet-awesome-rust/not-yet-awesome-rust), a list collecting ideas for useful crates that don't currently exist. The same kind of list also [exists for the embedded ecosystem](https://github.com/rust-embedded/not-yet-awesome-embedded-rust), in case you're interested in embedded. [This Week in Rust](https://this-week-in-rust.org) often lists a few items in the "Call for Participation" section, you can check those out as well.
Most fun I‚Äôve ever had while taking a shit. Seriously. Are seeds and fungus meant to make a lichen like growth, or was that just a secondary effect from a lower level rule?
\&gt; Stabilize futures\_api &amp;#x200B; :tada:
The cast crate seems simple, obvious, and widely useful. It almost feels like it would make sense to be in core?
Well this is first example I encountered, I need to reinterpret (not convert) u32 into f32 as part of fast function approximation, but also generally it should be possible to somehow limit type parameters to same-sized types as is done with `transmute`
Applying advanced analytical techniques and extensive research, I was in fact able to uncover a astonishing fact: the Youtube video does indeed have "kitchen knife" in the title.
Odd, yet the craftsmanship and care given while he works is fascinating.
You want r/PlayRust
Here the right link [https://github.com/japaric/cast.rs](https://github.com/japaric/cast.rs)
He just strokes it so gently...
transmute is magic, you can't duplicate it yourself. the best you could maybe do is have an unsafe trait for the size of a thing and then require that both types implement the same size measurement trait.
Seems like `TryFrom` should handle this nowadays, unless there's something I'm missing?
`macro_rules! foo { () =&gt; { $crate::bar!(); }; }`
I‚Äôm not a fan of `?` anyway because more often than not, I don‚Äôt see it when I‚Äôm reading other people‚Äôs code than uses it. I would rather use `map`, `and_then`, or `if let`
Semver maintainer here! I actually have a private fork of semver-parser that passes the full test suite of node-semver. I haven't had time to make it public yet, though. I look forward to checking out your crate!
I'm hoping for more adoption, but there are probably still things that we'd need guaranteed from Rust before people will even start using it (potential example would be stabilizing the ABI). The biggest hurdle I see is adoption due to the high learning curve, especially with global engineers where English is not their first language (it makes it that much more difficult to have knowledge transfer).
Thanks!! Works like a charm...
I wish it was public, might have saved me some time haha. In any case diversity isn't bad, so no harm done.
You should check out the "Edition Guide"s chapter on macros. It explains this issue pretty well
Can‚Äôt you use the ‚Äúas‚Äù keyword for this?
Can you elaborate how TryFrom can be used?
This touches on a larger conversation about Rust, LLVM, and constant-time code generation. Constant-time code generation in LLVM is a mess. As you rightly point out, LLVM backends can and will completely ruin your day by turning constant-time LLVM IR into variable-time machine-code. Even worse, is that (AFAIK) there doesn't seem to be any movement within the LLVM project to fix this issue. Currently, making rock-solid constant-time code means hand writing assembly for each of the target architectures you want to support. Obviously this isn't going to cut it. There's been some effort within the Rust community to solve this project. There was an [abandoned effort](https://github.com/klutzy/nadeko) to implement a `#[const_time]`macro that would compile the marked rust code directly to x86_64 assembly, bypassing LLVM and allowing constant-time code generation. Given that was abandoned, what now? It seems to me that we have an opportunity to solve this issue via similar approach, but instead of compiling directly from Rust to assembly, we go Rust -&gt; WASM -&gt; assembly. I've been thinking about what it would take to have CraneLift generate constant-time machine-code from constant-time wasm code. It seems possible, and would allow us to have a real, workable, `#[const_time]` macro that would compile constant-time rust to constant-time machine-code via a WASM intermediary. So back to what this means for SideFuzz. SideFuzz currently checks that the Rust Code and LLVM-IR is constant-time (modulo LLVM's wasm32 backend constant-timing variable-time code), but obviously can't account for LLVM backends that mangle constant-time LLVM-IR into variable-time machine code. I'll update the README to make this really clear - thank you for the suggestion. This means that it's still super useful, even for code that gets compiled via a non-wasm LLVM-backend. You can be sure that your *Rust* code is constant-time, even if the LLVM backend might mangle it. I'll be sure to update the readme to clarify this. Long term though, I hope that SideFuzz has a role to play in a larger solution of constant-time code generation in Rust.
Yes, actually you are right.
Good point and great idea with the other host!
Thanks, I'll look into setuid and friends!
I think that depends on the solution chosen. I suspect that most of them (sans maybe the "magic" one) would work that way if they are prefix, since they are expressing a way that isn't how you wrote it to mean "await, and then try". Arguably, that's seems like a bad way to design an API so you shouldn't be doing that in the first place.
I had real troubles following the book a couple of months ago. Has it been updated to recommend the stable Rust yet? If not, try it, because it worked for me, where nightly wasn't! I hadn't seen the target needing a reset thing though!
How is "it cannot be a macro" a problem? It is no problem that ".await!()" Is not a real macro but a special case in the compiler. Even if we never get postfix macros in rust, this is as good as any other random postfix syntax with the exception that it can be a general feature in the future.
... What?
Thanks for the response, what you say makes a lot of sense! There are plans for using CraneLift inside rustc, which would make the additional WASM step unnecessary (the generated code would be slower, though) - really, the ideal solution would be proper constant-time-op support in LLVM, since that would benefit all targets immediately. It really is a mess...
The final part of this series about building a plugin system using rust, web assembly and wasmer. - [part 1](https://wiredforge.com/blog/wasmer-plugin-pt-1/index.html) - [part 2](https://wiredforge.com/blog/wasmer-plugin-pt-2/index.html) - [part 3](https://wiredforge.com/blog/wasmer-plugin-pt-3/index.html) - [examples repo](https://github.com/FreeMasen/wiredforge-wasmer-plugin-code) - [wasmer-plugin repo](https://github.com/FreeMasen/wasmer-plugin) As always feedback, comments and questions welcome!
Hm, I dunno, they don't really say if one should use nightly version or not except for 1 paragraph: "#![no_main] indicates that this program won't use the standard main interface that most Rust programs use. The main (no pun intended) reason to go with no_main is that using the main interface in no_std context requires nightly". Right now I am using latest stable version of rust, which is 1.34.1, so I might want to try other versions, thanks for the tip.
He specifically asked for reinterpreting. `as` would perform a conversion.
Sure, here's a playground link: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b59644efe0048caa5b74c4fa70673390 Code: ``` use std::convert::TryFrom; fn main() { // Infallible conversions assert_eq!(u16::from(0u8), 0u16); // Fallible conversions assert_eq!(u8::try_from(0u16), Ok(0u8)); assert!(u8::try_from(256u16).is_err()); assert!(u8::try_from(-1i8).is_err()); } ``` Unlike the `cast` crate, we don't have `TryFrom` implemented for float -&gt; integer conversions, but I don't see why we couldn't add them. The only other difference is that the `cast` crate gives more descriptive errors as to why a conversion errors.
&gt; It then generates a new keypair and offers encryption and decryption public-key operations to the parent process. &gt; If you want to use a secret key that was previously generated, how do you load the secret key into the child and prevent the parent process from just accessing the file where the secret key was stored From what I understand you're doing it upside down. The trusted app (dealing with keys) should be the parent, and you IO should be a child, running with previously stripped privileges, in own namespace/container/sandbox/VM/yada yada. :)
no, "as" does explicit type conversion, which might change actual data stored. I need to say to compiler, to interpret these 32bits as `f32` instead of current `u32`. Simply said, I do not want to change data only it's meaning, what is usually done on "fast" approximation on some mathematical functions, like approximating value 2\^n in constant time instead of whole computation, which takes linear time. This is method based on Newton's Method of Approximation which is "good enough" for some applications, and coincidentally, it can be easily implemented by applying `u32` operations on `f32` type, for which, such reinterpretation is required.
But isn't that antithetical to this subreddit?
I've heard of the library during my vacation and forgot the name and was looking for 'approval testing rust' - I haven't heard 'snapshot testing' definition before. I also would recommend looking at [http://approvaltests.com](http://approvaltests.com) \- I think this is the first implementation of such approach, with some extra features like image comparison.
I am blown away by the cleanliness of his work space.
Ah. Another helpless redditor sucked in. You have my empathy.
I think you're looking for r/playrust
Might add this as a keyword but I have to admit I never heard of approval testing before.
Also checkout https://rust-lang.github.io/rustc-guide/ if one is interested in rustc itself.
Thank you! It is better than Python ;)
This app is just a thin wrapper (that provides interactive mode, file processing, and variable management) for my library [https://crates.io/crates/rcalc\_lib](https://crates.io/crates/rcalc_lib) . Though, the library, being internal in the beginning, lacks documentation.
You should use [`f32::to_bits`](https://doc.rust-lang.org/std/primitive.f32.html#method.to_bits) and [`f32::from_bits`](https://doc.rust-lang.org/std/primitive.f32.html#method.from_bits) for this, since they are safe.
ohh lol
I don't think it's the place to argue about that. I was just intending to point that not everyone's favorite option was there, that's OK life goes on. (Maaaybe I have been a little tiny bit proselytist; sorry for that)
What are you using to program the chip? I had a whole lot of 'fun' with my nucleo board until I updated the firmware on the connected ST-Link.
In my understanding, anything that may need to be polled to completion belongs inside `poll`. Also, as futures lack a way to report errors outside of polling, it may be sensible to put any fallible operations performed by a future under `poll` as well (another alternative is to make the function that produces the future fallible by returning `Result`). Any non-blocking, infallible operations can be performed on future's initialization.
It's a problem because it's surprising behaviour - something that looks like a macro, but doesn't quite always act like a macro (and importantly isn't a macro under the hood) is going to cause confusion in the rare edge cases where it works differently - and there inevitably will be rare edge cases where it does work differently.
Futures don't do anything until they are polled, but in my opinion the async operations they represent need not do the same. If it's easier to start the operation immediately, just do it. Often (usually?) it's simpler to implement an operation as a future that only starts when poll is called because you are given a `Waker` to signal the polling thread that the operation has completed. If this doesn't fit your design or if the operation could be completed in the time between the future's creation and its first `poll`, you might find that it's better to start it immediately.
I'm not sure I understand what you mean. I got OpenOCD on the laptop + GDB that connects to it; and I got the board directly connected to the usb port of my laptop.
Is there any summary of how proposed syntax might be reused in future features, e.g. for generators? Has postfix with parenthesis - fut.(await) - been ruled out? I think I recall reading so but can't recall the reasoning.
Does the board have a JTAG or SWD programmer on it or are you copying directly to flash (eg via a bootloader)
These is some talk in internals on the topic of implementing `TryFrom&lt;f64/f32&gt;` for integer types :[https://internals.rust-lang.org/t/tryfrom-for-f64/9793](https://internals.rust-lang.org/t/tryfrom-for-f64/9793)
I'm on mobile so I can't look it up but isn't there optional but recommended accessories in the book? If you're not using them that could be the problem? Might be best to open an issue on the books repo as well you might get more experienced people to answer.
Generally speaking `Option`s and `Result`s are conceptually very different, so the standard practice would be to return both. `Option`s represent the potential lack of value whereas `Result`s represent a potential error occurrence, and as such they're not really interchangeable. The `.ok()` is only really handy when you wish to treat an error occurrence as the lack of a value (i.e. discard the error as nothing) whereas `.ok_or()` is handy when you wish to treat the lack of a value as an error. If you've worked with files or buffers you might've come across `io::Bytes`, which is essentially just an iterator over a readable. Since an iterator may or may not yield a value (potential lack of value), all calls to `.next()` return `Option`s, but since it also reads from a reader behind the scenes (which might fail, so a potential error occurrence) it needs to expose any such errors that might occur, so its item is a `Result&lt;u8&gt;`. The meaning of these two things are very different. Lack of value means iteration is finished, whereas an error means just that, so the full return type of a call to `.next()` ends up being `Option&lt;Result&lt;u8&gt;&gt;`. This is perfectly fine to do, and is frankly the nicer option since otherwise you'd have to invent new semantics for handling errors during iteration.
What makes you think it's the world's first private cargo registry?
Interesting! No `cargo publish` yet, but it's as easy as doing `cargo package` and then uploading the `*.crate` file to a file dropper. Woot! I had a few problems mixing this with Crates.io, though, and I'm not sure if they're an issue with Cargo proper or just Cloudsmith. I tried uploading few dummy packages with variations of Crates.io and alternate-registry dependencies. [Here](https://cloudsmith.io/~erichdongubler/repos/problematic-crates/groups/) is the registry repo I'm using with Cloudsmith, and [here](https://gitlab.com/erichdongubler-mre/2019-05-cargo-alternate-registry) is my current workspace repo I'm using to publish to that registry. I'll inline the notes I've taken in `problems.md` at the root level of the latter. --- The issues I've encountered with using alternate registries for Cargo have happened while using the Cloudsmith repos. You can get your own free public Cargo registries there for reproducing these issues. - Impossible to `package` only one crate from a workspace if something else depends on a crate that's not uploaded yet. - Example: 1. Create your own repository. Don't upload any packages yet. 2. Comment out everything in the workspace `Cargo.toml` except for `no-deps` and `alternate-registry-deps`. 3. Run `cargo package` in the `no-deps/` folder. I would expect this to Just Work‚Ñ¢, since `alternate-registry-deps` conceptually seems to have nothing to do with the scope of `cargo package` in `no-deps/`. You can work around this by commenting out `"alternate-registry-deps"` from the workspace members in `Cargo.toml`. - This also, strangely, problematic with the dependency chain `transitive-crates-io-deps -&gt; crates-io-deps` despite calling `cargo package` in the `no-deps/` folder. Whaaat? - Even dependencies explicitly marked as being from the `crates-io` registry only seem to be searched for in the registry of a dependency. - Example: 1. Create your own repository. 2. Comment out everything in the workspace `Cargo.toml` except for `crates-io-deps`. 3. Upload `crates-io-deps` to your repository. 4. Uncomment`transitive-crates-io-deps` from the workspace `Cargo.toml`. I would expect this to Just Work‚Ñ¢ since `crates-io` is specified for the `asdf` dependency of the `crates-io-deps` crate. However, it seems that the `cargo package` invocation for `transitive-crates-io-deps` only searches `problematic-crates`.
It does sound ambiguous when you say it like that! What it means: The first private Cargo registry \*service\* that works like crates.io, as in, it'll provide private Cargo registries as and when they are needed for anybody, at the click of a button. Not that it itself is a new private registry. :-)
Really awesome feedback - Thanks for taking the time to play around with it! Interestingly we had the opportunity to automatically proxy the missing dependencies from [crates.io](https://crates.io) (or elsewhere), but we actively chose to not implement (yet) because it technically went against specification; that isn't to say that we won't implement it. This is sounding an awful lot like a +1 to make that less of a pain. Although given what you've said I'm not entirely certain it would completely solve the scenario you outlined. We'll have a play with it as well to see if we can't come up with something, and if not, then I agree filing it over on the Cargo repository would be the best thing to do. Very interesting use-case on usability though. :-)
Hah, I was just thinking of how to handle some loosely-typed configuration I'm making for work, and this looks like it could simplify the task quite a bit. Thanks for contributing this! :)
&gt; Although given what you've said I'm not entirely certain it would completely solve the scenario you outlined. It seems that Cargo simply isn't searching the correct registry for the problems I described above. That definitely seems like a Cargo problem to me, but I just wanted to be cautious about saying so without a better understanding of how Cargo interacts with registries. :) &gt; Interestingly we had the opportunity to automatically proxy the missing dependencies from crates.io (or elsewhere), but we actively chose to not implement (yet) How would this work, exactly? Would this just search `crates.io` when a specified dependency is missing?
Yes. You'd follow steps #3 and 4 from this: [https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-quick-start.html](https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-quick-start.html) I'll update the steps in the README soon.
It seems we had the same idea more or less at the same time: [https://github.com/mcorbin/meuse](https://github.com/mcorbin/meuse) ;)
I hope the full futures, async/await and related implementations are stabilized soon as well.
I don't know very much about the internals of the compiler, but my gut feeling says that both of these issues could be solved by making the macro generate a compile-time assertion that fails if it's used in the wrong context. I would guess that the reason they've been marked as "wait until we have a syntax decision" is that there's no point in solving them for macros and then solving them again for a first-class syntax.
Shouldn't it be written in Rust? Heathen! ;) Seriously though, looks great. I told someone else we are expecting other open-source alternatives soon, and we'll be contributing something of our own in the future.
Any reason your "JSON Pointer syntax" uses slashes instead of periods? xpath uses slashes, but [`jq`](https://stedolan.github.io/jq/) uses dots. It could be nice if you gradually copied features from `jq` with the same syntax it uses. You can't fully copy xpath's syntax anyway because XML structure is too different.
The [`static-assertions`](https://crates.io/crates/static_assertions) crate has the [`assert_eq_size`](https://docs.rs/static_assertions/0.3.1/static_assertions/macro.assert_eq_size.html) macro (and a few similar ones) that I've used -- they're nice. Might they fit your use case?
Apache Arrow already has its own rust native implementation: [https://github.com/apache/arrow/tree/master/rust](https://github.com/apache/arrow/tree/master/rust).
 Finished dev [unoptimized + debuginfo] target(s) in 3.35s Running `target/debug/examples/ui` thread 'main' panicked at 'The 'conrod' feature must be enabled for this example to work.', examples/ui.rs:19:5 note: Run with `RUST_BACKTRACE=1` environment variable to display a backtrace. I get this error when running the UI example, any idea how to fix this?
&gt;Arguably, that's seems like a bad way to design an API so you shouldn't be doing that in the first place. The language has to be able to handle edge cases anyway. And sometimes ... there's no saner way to design an API. (Sure, nowadays Rust code is new and shiny-ish, and simple, and easy to change, redesign, refactor, rectify the kinks and so on, but later, you might get into a situation where you have to wrap a future in a future.)
Probably because the spec for json pointers uses /s https://tools.ietf.org/html/rfc6901 Personally I prefer jq's syntax, as it's more similar to code, but I'm not sure if there's a technical reason they used a more code like syntax over json pointers, or if it was just the authors preference.
Isn't this \[turning compiler intrinsics into proper APIs for better error handling/reporting\] basically a main roadmap item for 2019 (and in general)?
This is my new favorite blog theme. Also, this presents a great collection of some standard concurrency patterns.
I agree. I'm just motioning that the syntax for a "bad API design" should be allowed to be worse. Arguably, the only solution I think it even matters for is the "magic" one: `let str_response = await http::get(url)?.to_string();`. And I suppose if it's literally called the magic solution, it ought to be able to look at the shape of the functions and do the right things in both cases. Although then if it's Result&lt;Future&lt;Result&lt;T&gt;&gt;&gt; then it would be magical to see `await weird_get(url)??` with two question marks. And the magic solution is the one I don't really like anyways, so it seems like a moot point. I prefer the c# way (`let str_response = (await http::get(url))?.to_string();`) or the "method call" (`let str_response = http::get(url).await()?.to_string();`) ways anyway.
&gt; That said, this does give me an alternative idea: a prefix keyword (e.g. await) can trivially be turned into a postfix macro, if that macro definition is something like expr =&gt; await $expr. So implementing a &gt; prefix keyword does not preclude the possibility of postfix userland abstractions being implemented later, as soon as postfix macros are enabled. This combination is my preferred option too. It seems like the best of both worlds. Familiar syntax and obviousness (when wanted), and easy chaining (when wanted).
Hey Erich, Paddy from Cloudsmith here. Thanks for taking the time to try this out and provide feedback, we really appreciate it! &gt; Even dependencies explicitly marked as being from the crates-io registry only seem to be searched for in the registry of a dependency. This one's on us, we aren't correctly passing through the source registry for a crate's dependencies (so cargo isn't aware the dependency comes from elsewhere). We've identified the fix and should have it shipped soon. &gt; Impossible to `package` only one crate from a workspace if something else depends on a crate that's not uploaded yet. I believe you can add `path = "../no-deps"` to your dependency specification in `alternate-registry-deps` to make this work like so: ``` [package] name = "alternate-registry-deps" version = "0.1.0" authors = ["Erich Gubler &lt;erichdongubler@gmail.com&gt;"] edition = "2018" [dependencies] no-deps = { version = "0.1.0", registry = "erichdongubler-crates", path = "../no-deps" } ``` According to https://doc.rust-lang.org/book/ch14-03-cargo-workspaces.html#creating-the-second-crate-in-the-workspace you need to explicitly specify the relationship: &gt; Cargo doesn‚Äôt assume that crates in a workspace will depend on each other, so we need to be explicit about the dependency relationships between the crates.
&gt;How would this work, exactly? Would this just search [crates.io](https://crates.io) when a specified dependency is missing? Yup, effectively proxied, although we're looking at adding the capability to passthrough+cache later too. We still need to work out if it's right for Rust semantics though. Any thoughts on what this functionality would mean to you?
As mentioned by /u/nbsdx it's because that's the syntax for JSON Pointer RFC. &amp;#x200B; As to the reason I picked JSON Pointer, it's two fold: * I had an implementation to pull from in serde\_json that is ready to go with very little modification * It's very simple That being said, I can see this being expanded to allow for a `jq` style syntax as well, I consider this to be a minimal implementation at this stage.
It's only a bit magical in other languages. In Rust it is supposedly exactly as performant as hand crafting a Future. &amp;#x200B; And in any language, where you have strict and strong typing, you can't really miss a Future, it's in the fn/method/trait signature. Sure, it might be less obvious than a "return", but just as there are many bad examples of long functions sprinkled full of early returns, people can hide I/O too. &amp;#x200B; And of course, stabilizing the macro and targeting the the use of a postfix-macro (or even just macro-like thing) later would probably settle this problem. &amp;#x200B; &amp;#x200B; However, it's a pretty fortunate situation that Boats and others are actively looking beyond this problem, because it's highly likely, that with more concrete examples (Streams, async generators, for/loop await combined with yield and error handling) and use cases the decision will be more straightforward.
There's a pretty great .await in a Scala library for ElasticSearch: [https://github.com/sksamuel/elastic4s#example-application](https://github.com/sksamuel/elastic4s#example-application) &amp;#x200B; Clear and simple, easy to chain. Internally it uses the much less nice Await magical global thingie: [https://github.com/sksamuel/elastic4s/blob/master/elastic4s-core/src/main/scala/com/sksamuel/elastic4s/ElasticApi.scala#L88](https://github.com/sksamuel/elastic4s/blob/master/elastic4s-core/src/main/scala/com/sksamuel/elastic4s/ElasticApi.scala#L88) &amp;#x200B; Also, the problem with await is that the timeout has to be configured somewhere, and usually doing it globally is not what the programmer wants. (So using a method-like postfix thing with an optional timeout would be better than a prefix.)
The webdav protocol is not symmetric like a RPC protocol like JSONRPC, XMLRPC or SOAP is. Client requests and server responses are quite different. Though for a unit test of the entire crate at the http handler level, the webdav-handler code should probably include some rudimentary client code to do testing. It does not do so right now. I noticed that there's a [webdav client available](https://docs.rs/hyperdav/0.2.0/hyperdav/struct.Client.html) via crates.io though. I haven't used it, but I took a cursory glance at the docs and it looks reasonably complete.
Just in case it wasn't clear: I'm not the author of this post, I just submitted it here.
If you don't need to be able to send it between threads, you may be able to use [https://doc.rust-lang.org/std/macro.thread\_local.html](https://doc.rust-lang.org/std/macro.thread_local.html) instead of \`lazy\_static\`.
Thank you! I‚Äôm really happy with how the blog looks as well.
It's probably a better idea to a single thread that handles rendering and the rendering context and instead send the things to render to that context. instead of passing the context around, pass messages with just what is needed to render to it. often it's better to have the rendering component check some collection of things to render and then render them, this leaves some other thread to do the logic of *if* those things are to be rendered in another thread. I'm not sure if this directly helps you, but often this kind of inversion of the view of the problem is the right step.
&gt;The remaining 3% or so is some extra wiggle room to handle whatever edge cases were needed to make it a bit more flexible around the bits of DirectX12 and Metal and such that didn‚Äôt quite fit. Can you tell more about those 3% and how they influence overall `gfx-hal` API? (disclaimer: I do not work with graphics too much) Personally I would've preferred if we treated Vulkan C API as The API and build all abstractions exclusively on top of it. And if needed use projects like `gfx-portability` to port our applications on targets without native Vulkan support. Though IIUC it's not possible to support shaders compiled to SPIR-V on OpenGL, DirectX and Metal, right? Also I don't quite understand how `gfx-hal` developers plan to build on top of WebGPU. IIUC it's significantly more constrained API, so shouldn't it be quite weird? If application wants to support Web and native targets it looks like it should be built on top of something like `wgpu`, i.e. the arrow from WebGPU to `gfx-hal` may be redundant.
can you share a link to the project, please? I ve started digging into rust and learn about compilers at the same time and so wanna read as much as i can on the subject. Looks even cooler that you used that language to actually build something, congrats!
It's not public yet, but I will post it here once it's ready
&gt; Because it's a great video. That 's not an acceptable excuse. The video has nothing to do with Rust. It's off topic and would be a blatant violation of one of this subreddit's rules (unless the mods are Holier-than-thou).
It's now been replaced with a different video... and the rules have been updated, so the meme link is now directly under a rule saying "No memes". :]
Wow, I just visited your github page and see that you are 16 years old and you produced this? I am seriously impressed. You might be interested to take a look at [https://github.com/apache/arrow/tree/master/rust/datafusion](https://github.com/apache/arrow/tree/master/rust/datafusion)
I was coding in c++ since I was 14 and now I'm 17 so programming in rust is so easy and I don't copy code from another repositories.
It's the mods being juvenile. Disable custom theming for this subreddit, and install something like umatrix to disable loading resources from third parties. This should put a limit on what they can do.
&gt; This one's on us.... &gt; EDIT: A fix for this issue has been shipped. /me goggles the timestamp on the original reply and the edit announcing a fix an hour after. Now that's some quality turn-around time right there! :) This will almost certainly let me play with a crate registry for work tomorrow... &gt; According to [the docs] you need to explicitly specify the relationship.... Funnily enough, I already came to the same solution (from this [Cargo book section, last paragraph](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#specifying-path-dependencies)) before I saw your reply here. I also discovered [`cargo-publish-all`](https://gitlab.com/torkleyy/cargo-publish-all), which seems the flow that I wasn't getting earlier. So, this definitely doesn't seem like a Cloudsmith problem. See also my edits to GP!
I would use this, thanks! I like the idea of making use of events without needing to understand what they mean (especially since it's exhausting and often impossible to understand them, even after you find the right Intel manual to look in)
I think you might want to change it, since the definition is that Futures are ‚Äûcold‚Äú. They don‚Äôt do anything as long as they are polled. And unless they are polled dropping them should be 100% side effect free, which your Futures apparently are not. One alternative API for you application might be returning awaitable Oneshot channels from the calls that start the operation. Since it‚Äôs a channel, it can be assumed that the operation it already. In that case you also might want to check how users can safely cancel the operation if required.
The thought of that functionality actually gives me the willies. If I fat-finger a proprietary package name, that would open up risks like [typosquatting](https://en.wikipedia.org/wiki/Typosquatting). The Rust-shaped part of my brain prefers things to either exist as specified or be forced to correct things -- otherwise, my mental model will be more susceptible to unexpected things like that! What's the use case? Is it to avoid the need to specify the `registry` option for every dependency?
When it comes to multithreading, will async/await/futures be just as useful as they are for IO-based parallelism? &amp;#x200B; I.e., it's easy to "await" a network operation. But can I fire off a computation on a thread, keep doing some work (assuming the OS has dispatched everything properly), then "await" it? ...but then, I guess "join()" is like "await" here...
Sorry to derail from the content (im reading it as I type!) but what blog engine / theme is this? I love it too!
&gt; It's a problem because it's surprising behaviour How so? &gt; something that looks like a macro, but doesn't quite always act like a macro (and importantly isn't a macro under the hood) is going to cause confusion in the rare edge cases where it works differently - and there inevitably will be rare edge cases where it does work differently. Can you give an example? I find the [cfg](https://doc.rust-lang.org/src/std/macros.rs.html#845), [include_bytes](https://doc.rust-lang.org/src/std/macros.rs.html#799-802) and [line](https://doc.rust-lang.org/src/std/macros.rs.html#660) macro ‚Äì to give some examples ‚Äì not confusing. These are, as far as i know, "no real macros" and i cannot see how these are confusing or what the problem with these are (and there are many more).
&gt; Can you tell us more about those 3% and how they influence overall gfx-hal API? Unfortunately I don't know that much about it since I've never had to touch those parts -- much as I like to talk my knowledge is not encyclopediac. Paging /u/kvarkus ? &gt; Though IIUC it's not possible to support shaders compiled to SPIR-V on OpenGL, DirectX and Metal, right? Its easy, you just [compile the SPIRV to whatever shading language is natively supported.](https://crates.io/crates/spirv_cross). :D &gt; Also I don't quite understand how gfx-hal developers plan to build on top of WebGPU. IIUC it will be a significantly more constrained API compared to Vulkan, so shouldn't it be quite weird? Less weird than building atop OpenGL, and they're doing that already. I expect, practically, most features will be a close match and some will have to be emulated. Again, I don't know details of how WebGPU is intended to stack up, just skimmed notes and draft documents. I would certainly expect implementation differences in error handling, with the WebGPU backend catching errors at runtime that would make a vulkan backend crash. &gt; If application wants to support Web and native targets it looks like it should be built on top of something like wgpu It doooooes look that way, doesn't it? I'm excited. üòÉ Just also cautious of the tradeoffs to be made. I'm not compiling all my programs to webassembly by default, for comparison. Maybe I will someday, hopefully. But for now there's downsides and tradeoffs that make it inconvenient.
Thank you so much, i went with the write! method and its working great! I really appreciate the in-depth response :)
Thanks for the quick response. So can you please share some piece of code to demystify it.
Thanks for the quick response, can you please explain it with the help of code snippet
Thanks so much for putting this together! It's super helpful. Have you heard of [Azul](https://azul.rs)? Apparently its based on Mozzila's Web Render (assuming that WebGPU?). If you feel inclined, I would love to hear your opinion on what the best option is for 3D engineering graphics (i.e. CAD) when the backend is written in Rust.
Probably even for /r/playrustserver
We are working on nannou as well. The new version that is about to come out has full cross platform support for vulkan. Lots of examples to get going with as well. Github.com/nannou-org/nannou
The repo says Hugo and a custom theme
I think that's idiomatic. `as_ref()` is necessary in some situations.
Rust's escape sequences are a little bit different from Python's. You want to use `\o33[32m` (with the `0` replaced by an `o`).
Should the language have been called Rustn't?
I can't recommend anything, but [this issue](https://gitlab.redox-os.org/redox-os/termion/issues/103) on the Termion repo might be of interest.
I am not an expert in this. But, from what I understand, async &amp; await themselves don't require heap allocation. They just return something implementing Future on the stack. You need to move the Future to the heap in two (and maybe other) situations: (1) If you want to move the Future after it was started or (2) when you need to store / manage futures of different types together.
[This table](https://doc.rust-lang.org/reference/expressions.html#expression-precedence) indicates that `&amp;s[n]` is parsed as `&amp;(s[n])`, not `(&amp;s)[n]`.
Thank you for the details. I'm aware of hyperdav but I couldn't get it to work a few months ago. I don't remember what was wrong but iirc it didn't compile. I shall try it again and report the issue or maybe fix it now that I know rust better.
Did you actually tried to resed the device before load? &gt;reset halt &gt;reset run
The Book is more heavyweight and gets more into the details. Rust by Example is more example-oriented (obviously) but isn't quite as thorough. If you're interested in getting working programs as quickly as possible, I would go with Rust by Example and then refer to The Book if you need to know more about something. If you're confused about any particular issue that neither text seems to address, feel free to ask r/rust or the #rust or #rust-beginners IRC channels.
Hey guys, so ive got a vector full of strings, and im trying to get it so that it's a vector full of u8's so that i can convert those u8's back into chars. Any help would be appreciated, still learning Rust and I'm in a bit of a time crunch lol this is essentially where im at: let mut splices = contents.split_whitespace(); for x in splices { y = x; y.as_bytes().to_vec(); vec_bytes.push(y); } This is giving me [ "101", "88" ] of type Vec&lt;&amp;str&gt; when i need [ 101, 88 ] of type Vec&lt;u8&gt; so that i can use from_utf8(vec_bytes).unwrap() to get my chars back.
The timing of this to me is great. I'm trying to get into rendering/gpgpu in Rust and this helps a lot. One suggestion: [the graph of how the ecosystem looks like](https://wiki.alopex.li/AGuideToRustGraphicsLibraries2019#so-what-do-i-actually-use-to-make-triangles-appear-on-the-screen) is somewhat layered into lower-level above, and higher-level/safer below, but some of the boxes could be aligned on a better level: vulkano and glium are higher-level than what they're next to, maybe on the same level as wgpu/rendy (maybe luminance too), WebGPU would maybe be on the same level as Metal/Vulkan/... or maybe in between (and is that what wgpu-native provides?). Hope this helps.
&gt;Though IIUC it's not possible to support shaders compiled to SPIR-V on OpenGL, DirectX and Metal, right? In addition to the previously mentioned possibility of compiling from other shading languages, OpenGL 4.6 actually [directly supports ingesting SPIR-V.](https://www.khronos.org/opengl/wiki/SPIR-V) This feature makes a lot of sense given that any driver with Vulkan support can add this relatively easily
If you're interested in using an existing graph implementation, [petgraph](https://crates.io/crates/petgraph) offers a few different different kinds depending on your needs (I've used them for [DSP](https://github.com/RustAudio/dsp-chain), [GUI](https://github.com/PistonDevelopers/conrod/blob/master/conrod_core/src/graph/mod.rs), arbitrage, [a graphical programming lang](https://github.com/nannou-org/gantz), so many other things I'm probably forgetting). If you're set on rolling your own, they might still serve as a useful reference.
You need to change var to ver, for a start :)
you have to use `borrow()` method on it if you want to read it, or `borrow_mut()` if you want to write to it :) https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=9906c2b84c949e8c876a6efc35920826
`y.as_bytes().to_vec()` returns a `Vec&lt;u8&gt;`, but you are not binding the return value to anything. `y` stays a `Vec&lt;&amp;str&gt;`. Using iterator adaptors is more idiomatic in Rust: let vec_bytes: Vec&lt;u8&gt; = splices.flat_map(str::bytes).collect(); If you only want the resulting chars, you can even do: let vec_chars: Vec&lt;char&gt; = splices.flat_map(str::chars).collect();
Thanks... Yea... my brain getting crashed sometimes :-)
x\[0\].borrow().ver is working...
If you mean the reset button, then yes - I tried pressing it and even holding it down, but nothing seems to work
since you're targeting wasm, you can cheat it with forcing your struct to implement Send + Sync: `impl Send for MyStruct {}` `impl Sync for MyStruct {}`
That‚Äôs cool! You might also like to share it in /r/generative.
Especially if it's already technical documentation. Why would you use a service that can be used by 14-year-olds if the target audience knows Git (with high probability).
Ah yes, dumb mistake, thanks. So I've tried those methods and a few others, and the problem i keep running into is that its giving me the byte/char for each individual int, rather than reading it as a whole, if that makes sense. So if its giving me the byte for 104, its giving me the byte for 1, 0, and 4...
Hmm interesting. It's probably compiler magic, but may be look at the source for transmute?
Try explaining that to the cucumber!
So, I am sure that I don't have either JTAG or SWD, and according to the board description I got ‚ÄùA second microcontroller: a STM32F103. This microcontroller is actually part of an on-board programmer / debugger and is connected to the USB port named "USB ST-LINK" ". So, I just have a USB cable from that port to the USB port on my laptop, nothing else.
Thanks for the info. I will try to use petgraph.
Hmm Azul is already the name for a Java vm with little GC pause
No. Once you connect to the debugger after loading tue code into device. You probably need to run commands: &gt;reset halt And then &gt;reset run
Oh! In that case, you want to employ [`str::parse`](https://doc.rust-lang.org/std/primitive.str.html#method.parse). However, it can fail (in case the number isn't actually a number or doesn't fit into a `u8`). [Rust by example](https://doc.rust-lang.org/rust-by-example/error/iter_result.html) actually uses this very example to demonstrate approaches to error handling.
I don't think you necessarily have to change it. IIRC, if your library consumer wants to delay the creation of the future and with that the sensing of the initial command, they could just wrap it in a `futures::lazy`. In the wild I've seen it both ways, with some library authors putting every initialization part into a `futures::lazy`, and some just leaving it up to the user.
no fun allowed
Okay i definitely see how this could be the answer, but im not sure how to use this? Ive got it giving me the [ Ok(104),.... ] but im not sure what i can do with that type now, or if i should be mapping to something different? Sorry if this should be obvious, its been a very long day lol
Oh. Ok. I'll try that when I get back home.
Question from someone with no graphics programing experience to speak of (who is happy to be corrected about their wrong assumptions): Isn't DirectX more than just a graphics API? Doesn't it like also contain sound and input handling and things like that and Direct3D is the graphics API?
Depends on how you want to handle the errors. A simple but bad way to handle errors is to simply assume they don't happen and then `panic!()` by `unwrap()`ing if they do happen: let string: String = String::from_utf8(splices.map(|s| s.parse::&lt;u8&gt;().unwrap()).collect()).unwrap(); There are two error cases you can handle: 1) The individual string slices you parse cannot be parsed as a `u8`. This is the first `unwrap()`, invalid numbers panic the program. 2) The bytes may not be a valid `utf8` string. This is the second unwrap, invalid byte sequences will panic the program. Properly handling errors is a bit more difficult: match splices.map(|s| s.parse()).collect() { Ok(n) =&gt; match String::from_utf8(n) { Ok(s) =&gt; println!("{}", s), Err(_) =&gt; println!("Invalid byte sequence"), }, Err(_) =&gt; println!("Not a u8"), }
It‚Äôs on my Github. It‚Äôs a fork of a fork. I‚Äôve made some changes to fix comments and clean up some other parts. https://github.com/ajmwagar/hugo-theme-hello-friend-ng-ng
It‚Äôs on my Github. It‚Äôs a fork of a fork. I‚Äôve made some changes to fix comments and clean up some other parts. https://github.com/ajmwagar/hugo-theme-hello-friend-ng-ng
This is a really good question. I‚Äôll be honest, I haven‚Äôt played with futures in Rust a whole ton (I do a lot of async/await in JavaScript land). I‚Äôm mainly waiting for the built in syntax to stabilize and be implemented. I think that we will end with a mix of both async and multithreading. For instance if your in a situation where their would be too much overhead to spawn more threads people are going to just use await. With a rayon iterator for example. But in other cases it will be viable to spawn a thread while you await something. Really only time will tell, once async and futures are build into the language.
The animation on github is too long, it shows a progress bar for 99% of the time, then a result for a second, and then it loops again. There are no buttons for navigation of the video, so could you at least make it shorter?
.cargo/config
"OpenGL: Basically Javascript for GPU‚Äôs" - funniest description I read in a while :D
I write APIs in [ASP.NET](https://ASP.NET) Core / C#, but since I come from C++, I am interested in Rust.
&gt; The programming model in C++ I described is quite different (no "resumable" async functions). There actually are now (co_await)! And heap allocation is a hard requirement for them if you're using them for something like async io.
Originally, DirectX was a whole family of vaguely related media APIs, like DirectDraw for 2D graphics, DirectInput for joysticks and gamepads, DirectMusic for MIDI playback, etc. Some of those APIs have already been phased out, others only exist for backwards-compatibility reasons. A bunch of Direct-whatever APIs eventually got replaced by Windows ports of the equivalent XBox APIs, like XInput and XAudio. [These days](https://en.wikipedia.org/wiki/DirectX#Components), pretty much everything that still has "Direct" in the name is a graphics API of some kind.
Thanks! I'm not sure why I thought this was different than what I already do for aarch64 builds. :facepalm:
That makes a lot of sense and is all working, I cannot thank you enough, you have been an incredible help i really appreciate it!
Great article, as always! Thank you for the hindsight and kind words. If people are interested to know what the next steps about [luminance](https://crates.io/crates/luminance) are, [you can read this article I wrote a few days ago](https://phaazon.net/blog/pre-luminance-n-random-thoughts). TL;DR: I plan to make a small design change that will make luminance somehow backend agnostic. The main differences with e.g. [glium](https://crates.io/crates/glium) or [gfx-hal](https://crates.io/crates/gfx-hal) is that I will not break the current ideas, concepts and public design of luminance. I‚Äôll just allow to have luminance code run on WASM, more OpenGL versions (basicaly as stated by /u/icefoxen, OpenGL 3.3+) and Vulkan. In theory, anyone can just add an implementation for whatever technology. My idea is that the current API of luminance is something I‚Äôm comfortable enough with (I wrote two demos with it and it works). I keep maintaining and adding features (read the blog article, I explain what kind of features get added) and the design might _slighly_ change if I get into a situation I‚Äôm blocked with (for instance, memory synchronization and fences is something I have in a corner of my head to look after), but I‚Äôm pretty confident it shouldn‚Äôt change that much. Then, I don‚Äôt want to make luminance to adapt to all the possible techs (which is a bit what gfx does, since you can do pretty much everything with it). The idea is: I have a given API with luminance, using `Buffer`, `Texture`, `Framebuffer`, `Shader`, `Program`, `Pipeline`, `ShadingGate`, etc. and a way to use them (using the control flow of your code as an AST directly to build the graphics pipeline; having a typed uniform interface; having vertex semantics; etc.). Each implementation will just implement those concepts for a given tech (i.e. `GL33`, `VK11` etc.). So, in a way, it‚Äôs using a subset of a given tech to implement the luminance interface. But to me, it‚Äôs pretty enough for now. And of course, I‚Äôm open to suggestions, issues and PRs (and it‚Äôs already happened!).
(if i remember correctly) I think that the point in (1) is inaccurate. Yes, in order to **start** a task it must be pinned, but only tasks whose state machine requires self-references (caused by borrows between yield points, which are common) can not be unpinned. If i followed the blog posts correctly, you can move an Unpin task after it has started. The hall allocation is needed in most cases because the storage of the task is often disassociated with the stack. That is, a running task may generate a bunch of tasks, which would be owned by the executor which has not preallocated space for them on the stack. Otherwise, a task may be pinned and run on the stack, if you write it in a way that allows that
does the format! macro accept octals? `\o33[1;32mEXAMPLE\o33[0m` gives me syntax errors saying `unknown escape character o`.
That's it, thanks a lot ! Yes the as_ref().map() isn't very pretty but that works very well for me, I like it.
It's not in our plans for now, and I'm not sure it will be in the near future (for now we're doing only pure time synchronization). But I'll try to remember that if that happens !
cosmic coincidence brought these two things to Reddit after I asked the questions: * [https://www.reddit.com/r/rust/comments/bjk1qu/worlds\_first\_private\_cargo\_registry\_rust\_134/](https://www.reddit.com/r/rust/comments/bjk1qu/worlds_first_private_cargo_registry_rust_134/) * [https://github.com/mcorbin/meuse](https://github.com/mcorbin/meuse) meuse in particular is interesting to me because it's open source and is supposed to work with cargo publish.
Sure. In archery you use a pointer type `SharedPointer`. It behaves like `Rc`/`Arc`, but you can pick if it is atomic by specifying a type parameter: ```rust let rc_ptr = SharedPointer::&lt;_, SharedPointerKindRc&gt;::new(42); // The type parameter `SharedPointerKindRc` means we get an Rc pointer. This is not `Sync`. // // Does not compile with a "cannot be shared between threads safely" error: // let _: Box&lt;dyn Sync&gt; = Box::new(rc_ptr); let arc_ptr = SharedPointer::&lt;_, SharedPointerKindArc&gt;::new(42); // If we use `SharedPointerKindArc` we will have a pointer that implements `Sync`: let _: Box&lt;dyn Sync&gt; = Box::new(arc_ptr); ``` If you want to create a data structure that can be both atomic or non-atomic you can make pointer kind a parameter: ```rust struct ListInt&lt;P: SharedPointerKind&gt; { head: SharedPointer&lt;i32, P&gt;, tail: Option&lt;SharedPointer&lt;ListInt&lt;P&gt;, P&gt;&gt; } ``` Same thing holds: give it a `P = SharedPointerKindRc` and it will not be `Sync` and will have the performance of `Rc`; give it a `P = SharedPointerKindArc` and it will be `Sync` and will have the performance of `Arc`.
Does rust itself rust?
I'm more worried about the usage of TLS, which is quite [apparent](https://www.reddit.com/r/rust/comments/bi9yzs/async_is_not_zerocost/) in benchmarks.
If you want to look at different approaches to a problem: [https://exercism.io/tracks/rust](https://exercism.io/tracks/rust) Pretty likely the game of life is an already existing exercise.
Ha! I don't blame you at all. That's more or less the reason why we didn't bake it in immediately. It is likely that we'll be offering *something*, but I would expect it to be (a) off by default, (b) configurable (as to what is/isn't allowed), and (c) obvious (make it clear something will be fetched from X). The reason for implementing this type-of functionality is usually for users that want to completely isolate themselves from public registries. So they effectively want a mirror snapshot of all of the dependencies at a particular point in time, and then Cloudsmith will guarantee to serve them. Rust is a little different from some of the other packaging formats in how dependencies are specified, in that they tend to be explicit or same-source; so yeah, I could see this as meaning "I want all of my dependencies from the same-source", and then the user sets up rules as to what that means on the server-side. Take it with a pinch of salt though; it doesn't *exist* yet. :-)
The problem with using {} like this, is that it makes it at a glance look like a scope, which it clearly isn't. For that reason, I feel like the `(await future)?` syntax makes the most sense. I'll agree that it doesn't feel ideal simply because it adds more parentheses, but at least it's consistent with existing behavior in Rust (and most other languages) and would behave exactly as you'd expect from looking it it.
I learnt rust before but want a refresh. The Book is very verbose and long, anyone have a quicker reference?
Uh, that article uses the outdated 0.1 futures‚Ä¶
On Tuesday, I posted a small survey to have a better vision about how the Rust community on this subreddit felt about the different options As of now, 482 people answered, 95% of them being current Rust users (casual and full-time rustaceans being equally represented). Caveat: after I posted the survey some people wanted more syntax options to be added, so I added a few of them yesterday, but since the survey was already quite deep in the Reddit feed at this point, they have been significantly less answered than the first ones (only 64 times) so the result for theses questions are even less representative than the whole survey. **Subjective comments on the results:** The first observation of the survey are really not surprising : - There is no solution gathering a majority of users as an ideal one: The ¬´most **loved**¬ª solution merely has 22% of fans. - Every proposed syntax has a significant number of **haters**: the ¬´least hated¬ª proposition is hated by 13.1% of respondents. But this survey is still pretty informative, since we can group the syntax options in 3 different categories : - The ¬´hated ones¬ª: it contains every options but 3, for which the majority (or almost the majority: &gt;47%) of the respondents abhor. Since they reach such a high level of hatred, I personally don't think their adoption would be viable for the language. - The dividing one: the ¬´Postfix macro syntax¬ª is a bit special. It's the most loved option (22% loved) and has a majority of favorable opinions (albeit a short one 52%). But it also generates a significant amount of hatred, with almost 1/3 of the respondent ¬´hating¬ª it. - The conservative ones: ¬´mandatory delimiters¬ª and ¬´obvious precedence¬ª (implying parenthesis most of the time) are not really loved (resp. 19% and 12%) but they do not arouse much hatred either (19% and 13%) and they have the best non-negative reception overall (64% and 67% somewhat positive). If anyone wants to dig a little more in the figures, you can find the raw survey results [here, as a tab-separated ‚Äúcsv‚Äù](https://framadrop.org/r/M1WkrglbFB#3nd1m0Xzhkz84USSXAhHVhLWu4TOKEiuji1q1e33zFo=)
The survey is still open btw if you didn't participate so far. And it might also be interesting to get insight from people out of the Rust community.
Can you link the article the survey is referring to? I missed it.
Sure: [https://framaforms.org/unofficial-rust-asyncawait-survey-1556655135](https://framaforms.org/unofficial-rust-asyncawait-survey-1556655135)
[Rust By Example](https://doc.rust-lang.org/rust-by-example/index.html) illustrates many parts of Rust with concise examples and interactive exercises.
Thanks!
Cool! Seems awesome
Your GitHub link points to a different repo.
Thanks! Fixed.
Yeah, I was playing with a new graph software, MermaidJS. It's nice but I can't find a good way to organize things like that. I might redo it in graphviz.
Azul is the name of the company that makes the very low pause JVM. The JVM itself is called Zing.
thanks @slashgrin, thread\_local is a better direction but I'm still having issues. Let me try to example what I'm trying to do, maybe there is a better solution. I want to load a wasm module up, then have javascript call an initialize function, I pass in a string with the name of the canvas to get the context from. In rust, I am able to get the context and use it for that function call but once that function ends I loose the context. So if I want javascript to call into rust with another function, Render, I don't have the context anymore. So normally you'd have a global variable to hold these sort of things. &amp;#x200B; Also, I want to be able to cache specific objects like shaders, materials, textures, ECS entities, etc. Basically I need an application state that I can store that lives beyond the initial function call. Once I have this global variable, is there an easy way to get references back when I need them. Most cases read only but for entities and materials I need to grab mutable references because those things will change beyond the initial creation. &amp;#x200B; I've build an engine with WebGL and Javascript already, just wanted to try to recreate it in rust and the aspect of holding data beyond the life of a function call has gotten me stumped. Something so easy to do in other languages like C++, Java, etc but seems to be a very difficult thing to setup in rust.
It seems to be officially called [Blog OS](https://os.phil-opp.com/status-update/2019-05-01/#blog-os), now :)
&gt; Or just use Godot or Unity like a sane person. I wrestle with this way too much
You are missing the colors from the legends. This makes it a bit difficult to understand.
&gt; If you feel inclined, I would love to hear your opinion on what the best option is for 3D engineering graphics (i.e. CAD) when the backend is written in Rust. Exactly the same set of choices. Engineering graphics and game graphics use the same hardware and software, one of the first market uses of GPU's was high-end CAD software. Also take a look at the `lyon` and `genmesh` crates for nice ways to generate geometry for lines, bezier curves, fancier shapes, etc.
I think this would be easier to understand if the title of each graph was an example of the syntax rather than a description, and also if there were colored legends.
Don't we all!
I started something for LD43 in Godot, but once I hit a point of where I realized the UI needed a complete change, I started a new rust project. Recently I've been busy with a contracting project, but have still been working on some art. I was poking around in unity a few days ago, setting up frame by frame animation of the art I created more recently. Then last night trying out Godot 3.1 lol. Game engine/framework ADHD at its finest.
It seems you're new to Reddit as well, I think you should post it to r/rustgame. r/rust is a subreddit for Rust, the programming language, and not for Rust, the videogame.
You could just slab allocate your futures.
UNCS for macros (so that fut.await!() and await!(fut) are possible, same for "number {}".format!(4)) is the most reasonable thing I saw so far. It's not as nice as keyword but at least it's not a special case.
Missing a consistent colour scheme? I hate it!
Has there been a proposal about using a closure like syntax? I couldn't find any rationale for it (not) being considered. Something like: let str_response = await(|| http::get(url))?.to_string();
I agree. Unfortunately the survey tool I've used didn't give me these options :/. The example of the syntax was available as ¬´description¬ª in the survey itself, but I can't make it appear on the summary.
What does it mean? "Particularly anal graphics programmers"
I know‚Ä¶ The survey tool I've used doesn't do that and that's annoying, I agree. If it helps: Light blue= Perfect Dark blue= Not optimal but Ok Light green = not really good Red: I hate it Other colors: variation on the ¬´I hate it¬ª answer. I thought about extracting the result and generated the charts by hand, but that sounded tedious. And now I realize I could have just edited the screenshot to add the legend I just gave you ‚Ä¶ I feel stupid now :/
tl;dr "I hate it" :P
Yeah, I just wanted to see if you had any knowledge of an API that was tailored for this application. I will definitely look into those crates!
How is that better than the simple obvious preference order ? ``` (await http::get(url))?.to_string(); ``` The ‚Äúissue‚Äù with this one was the almost always mandatory parameters, but with a ¬´closure syntax¬ª you need it too, and it looks like a closure while it's not one‚Ä¶
IMHO postfix \`.await\` or \`.await()\` are counter-intuitive, since fields and methods are already user-definable. In the other hand, you can't define more sigils than the defined by implementing operator traits. They could follow the question-mark path, by adding a postfix sigil \`@\`. I know sigils were discarded, but it seems to be the less frictional path to follow.
and what advantage does this have over `await!(http::get(url))` worth all the extra symbols?
Well, it is and has always been the name of the [repository](https://github.com/phil-opp/blog_os), so there's nothing new here :D. I thought about giving it an more unique name after that talk and the following discussion, but I don't think that it's worth it. I like the title "Writing an OS in Rust" for the blog because it directly communicates what it is about. Also, I think the current name is already etablished now and recognized by people, so I don't see any real reason for changing it.
Good point. Though "all the extra symbols" is just '!' vs '||'.
Wait, there're more questions than what I have seen? I think the survey site has a design problem.
&gt; just '!' vs '||' fair enough
Given how expression oriented Rust is and the fact that all problems seem to come down to precedence, and given that most solutions boil down to adding parentheses to make this work correctly, forcing us to always use parentheses in a way consistent with the rest of the language doesn't seem too problematic. I almost expect the \`await\` keyword in your example to turn in to a best practice Lisp-like await notation (which doesn't really match the general Rust syntax).
&gt; user definable Macros, then (either postfix or prefix). We already have a precedent for compiler-defined macros (like `include_bytes`) Sigils aren't googleable and add syntactic noise. A big part of the complaints for Perl were over sigil usage...
People who worry a lot more about the fiddly details than they really should. See [here](https://en.m.wikipedia.org/wiki/Anal_retentiveness) . The psychology is nonsense but the term persists.
Desktop link: https://en.wikipedia.org/wiki/Anal_retentiveness *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^255057
I was thinking of doing something like this but you beat me to the punch! I'd be fascinated to read a follow-up post to see how its going in six months or a year.
I don't think the survey site is responsible this time: I added 4 new options yesterday after many people complained their favorite option wasn't in the survey. I don't think it's a methodological problem, because the question ask you for your feeling on each syntax, and it should not vary with the introduction to new options, but I understand your frustration‚Ä¶
Can you share your key insights from the data? I'm not very familiar with day to day rust development but would appreciate a high level written summary and interpretation. thanks for compiling this data!
Absolutely! Expect to see us add additional support as well, especially for things like \`cargo publish\`. I'd expect to have some decent feedback for the Cargo team as time goes on too, so hopefully everyone can benefit from it. :-)
&gt;Sigils aren't googleable and add syntactic noise. A big part of the complaints for Perl were over sigil usage... I think those macros are still compiler-defined for historical reasons, since today they could be defined as procedural macros. I think they added those macros with the hope of procedural macros landing some day. And if google-friendly syntax is an issue, then question-mark sigil shouldn't be added in the first place.
Personally, I'd like to see this option shown too, not sure how to call it : _let str_response = http::get(url)@await().to_string();_
Thanks for creating that survey and for publishing the results. I see there are new options compared to the time I opened the survey, which is great. That was one reason why I did not submit it. The other reason was the use of the word "hate". It may sound petty not to take part in the survey because of it, but that's too antagonistic.
Sounds like the survey tool is itching for a rewrite.
Also, just to add a bit more thing to argue about: I think the compiler could provide some ambiguity checks, and warn/abort if it finds something that would be too magical, even if decidable from the signature and context. For example it could allow the "simple" await http::get(url)?, but say no if the return type of get involves something problematic. &amp;#x200B; But yes, I don't remember seeing anyone rooting for the magical way, it's just there as an option someone (likely everyone) though of ... kind of as a token example of what not to do.
In Pathfinder I just use gl-rs directly. I have a [small GPU abstraction](https://github.com/pcwalton/pathfinder/blob/master/gpu/src/lib.rs) that I made myself exposing only the pieces of OpenGL that I use, and there's an [OpenGL implementation](https://github.com/pcwalton/pathfinder/blob/master/gl/src/lib.rs) of it. This is a bit ad-hoc, but it's actually not that much code. Graphics abstractions have a way of becoming really large and intricate, and I don't need that much functionality, so I found it easier to just write a minimal abstraction myself and call it a day. I can't say this approach will work well for everyone, but for projects with limited scope it's worked well for me.
I'm not quite sure whether this is memory unsafe or not, but it is possible for a file descriptor to be owned by both `StdoutOverrideGuard` and something else, which may cause issues with types assuming ownership of a file descriptor. use std::fs::File; use std::io::{Result, Write}; use std::os::unix::io::{AsRawFd, RawFd}; use stdio_override::StdoutOverride; struct MyFile(File); impl AsRawFd for &amp;MyFile { fn as_raw_fd(&amp;self) -&gt; RawFd { self.0.as_raw_fd() } } fn main() -&gt; Result&lt;()&gt; { let mut file = MyFile(File::create("test")?); let _guard = StdoutOverride::override_raw(&amp;file)?; write!(&amp;mut file.0, "Multiple writes to ")?; println!("Hello, world!"); drop(_guard); Ok(()) } I don't think it should cause practical issues, but may be problematic.
Thanks for the feedback! I'd say it's antagonistic by design: I made this survey because I wanted to get the gut feeling of people on the subject. It's something which is usually considered bad to express in a technical discussion (and I agree), but in the same time, programmers are usually \*passionate\* humans and the main communication issues usually tend to be on the emotional level. (And syntax issues are at least 80% irrational). In my opinion, this aspect is too often disregarded when taking decision, and this could lead to ‚Äútechnically good decisions‚Äù being taken and then rejected by a part of the community. &amp;#x200B; But I totally understand that some people would rather not answer to a survey for that reason. That's indeed a bias of this one.
Yes you can always open a file twice and it won't be memory save. I thought about using the \`[IntoRawFd](https://doc.rust-lang.org/std/os/unix/io/trait.IntoRawFd.html)\` instead, but it's not implemented on stdio, and sometimes you want to move stdout to stderr, and then you won't be able to do it. What do you think? should I use \`IntoRawFd\` instead? should I make more warnings? I feel like this is as obvious as opening the same file twice but I'm not sure.
So no matter what the lang team chooses in the end, there will be an enormous number of people who hate it. That's rough. I imagine we'll get a couple days of blog posts about Rust has "ignored community feedback" and made a choice that was "rammed through by a small group." Incidentally, what are the odds we wind up with a couple of different syntaxes supported at the same time, one favoring method chaining and one not? Is it written in stone that There Can Be Only One?
Thanks, I hadn't seen that article. Making luminance backend agnostic is fascinating, though I'm a little skeptical of such designs cause it adds a lot of sneaky complexity... hence why I want `gfx` to do all the hard work. I would love to see what you come up with though. You may find some of [my own notes](https://github.com/ggez/ggraphics/blob/master/README.md#design-thoughts) on the topic helpful.
So no matter what the lang team chooses in the end, there will be an enormous number of people who hate it. That's rough. I imagine we'll get a couple days of blog posts about Rust has "ignored community feedback" and made a choice that was "rammed through by a small group." Incidentally, what are the odds we wind up with a couple of different syntaxes supported at the same time, one favoring method chaining and one not? Is it written in stone that There Can Be Only One?
Okay, I think Stderr is good enough of a use case for `AsRawFd`.
This seems like an excellent plan. In particular, seamless cross-compilation will be a big win. The only nit I have, is that I believe `cargo add` ought to be a a part of the core of cargo (probably with high priority too). Adding a dependency is one of first things that new users of Rust want to do, and: cargo add serde is a much nicer experience than: - Google version number of latest version of serde - Open add Cargo.toml - Add `serde = &lt;version&gt;` line - Run cargo check to ensure you have added it correctly.
I did a quick analysis [in comment](https://www.reddit.com/r/rust/comments/bju8di/asyncawait_syntax_survey_results/emb5sbn?utm_source=share&amp;utm_medium=web2x).
The existence of the summary document and this polls makes all such statements nakedy false. Half the point in doing them in the first place is as a form of accountability to the community.
Agreed. `cargo-edit` should have been added to `cargo` a long time ago. Some alternatives: [chit](https://github.com/peterheesterman/chit/) by /u/abitrustyy, [this](https://github.com/serayuzgur/crates) VS Code extension, [this](https://www.reddit.com/r/vim/comments/be48lw/meainvimpackagejson_plugin_to_show_npm_package/) VIM plugin.
&gt; Another potential avenue is pipelining builds. Consider two crates with a dependency relationship: currently we have to completely finish building the first crate before we can start to build the second. However, in theory Cargo could start building the second as soon as the first's metadata was generated, before running LLVM (and potentially borrow checking). I think using compiled crates will be a bigger win and lower risk, so this idea is definitely a nice-to-have for this year rather than a top priority; it's also possible that the ongoing work on incrementalising the compiler will make this work unnecessary or impossible. This is actually [quite close](https://github.com/rust-lang/cargo/pull/6883).
Also we can get `.try!()` as well!
\&gt; So no matter what the lang team chooses in the end, there will be an enormous number of people who hate it. That's rough. I imagine we'll get a couple days of blog posts about Rust has "ignored community feedback" and made a choice that was "rammed through by a small group." That's one of the reason why I wanted to make the survey, so people realize that there wasn't a single best choice and they eventually had to decide on something nonetheless. That being said, if they decided to go with ¬´Field access syntax¬ª, which is the most hated version (63% of respondents), the outrage would be quite legitimate ;). \&gt; Incidentally, what are the odds we wind up with a couple of different syntax supported at the same time, one favoring method chaining and one not? Is it written in stone that There Can Be Only One? No matter what is chosen, even if it's my least favorite, I sincerely hope there's only one way.
I find "at operator rust" pretty easy to google. Searching for "rust questionmark operator" on DuckDuckGo gives no unrelated results on the first screen.
It seems to me that await { ... }? is both the least special and most obvious solution. It could allow direct execution of an implied closure (the await body) allowing some chaining in a procedural style and it looks a lot like an if expression. It's a bit more noise for the simple case of await { thing() }, but there is no `if x &lt; 5 thing() else thing2()` in the language either.
Postfix macros seems like a clear winner here. Every other option has few responses (not taken seriously?) or &gt;50% "I hate it" responses. Postfix macros is only about 30% "I hate it", and even has the largest percentage of "perfect" responses.
The IntelliJ plugin has version autocomplete built-in.
If you're interested, you can give help to _Framasoft_ who's behind this site. It's a French non-profit who's developing and deploying free-software alternatives to proprietary services. They're the folks behind [Peertube](https://en.wikipedia.org/wiki/PeerTube) for instance.
interesting that the obvious precedence way seems to be pretty much everyone's second choice -- few love it, but most find it acceptable. I wouldn't be surprised if it ended up as the final syntax (and maybe we figure out some way down the road to make chaining nicer -- general postfix macros or something)
\&gt;"Assembler (TODO)" Aren't you taking RIIR just a little bit too far guys?
Oh shit thanks ya I‚Äôve been on Reddit for a little bit just got on this sub Reddit thanks for the info
And other neat things such as `val.dbg!().do_something().dbg!();`
I'm implementing the Debug trait for a recursive data structure, and would like to indent the output to indicate tree depth in the data structure. How can I maintain state that indicates the current tree depth without using a global variable? There doesn't appear to be a way to do this given the Debug trait's fn signature. fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { }
I‚Äôll read them for sure! I will make a blog entry about it because it has been weeks I‚Äôve been doing that. :)
"obvious precedence" and postfix macros seem like the two best options based on the poll. Most everything else has few votes overall or &gt;50% "I hate it" responses. The obvious precedence route has fewer "I hate it" responses than postfix macros, but also fewer "perfect" responses. I think it would be good for the purposes of this decision to narrow things down as much as possible at this point. I think there is clear favor toward postfix macros (done it a principled way, eg permitting await!(fut) and "{} bar".format!(42)) over other postfix syntaxes, while "obvious precedence" seems most favored among prefix syntaxes. Both of these suggestions have been around for months without clearly better new ideas coming to light- I think we can consider the design space explored. I don't think the community would be overly upset over either outcome in the long term. The difference between them seems to capture the main difficulty of the decision- balancing weirdness versus composability, etc. Focusing the discussion on these two options seems like our most promising step forward now.
I think this is a great fallback option, but if they could make UFCS work for macros, wouldn't that be swell?
I agree that "I hate it" is a valid option, and I'm probably as passionate as the next developer, but it's missing some shades there :). I would be fine answering "I hate it" for a few that I really dislike, but because there's no in-between I was filling up the survey and end up "hating" everything, even though in truth I don't hate any. My concern is also for the core Rust developers who take this antagonism straight in their face...
AFAIK the allocation is elided in most, if not all, practical situations.
\&gt; Aren't you taking RIIR just a little bit too far guys? for the related projects, that's just my interest to learn how they work and implement them. So I think this should be no problem. And I have also mentioned that the branch was different and the related thing would be in the specific branch.... \&gt; As for the video, it's not even close to being a tutorial. This is just an intro, as for more details, I assume every one willing to write their own simple compiler, should at least read some materials related to it, and also I plan to explain them in short in the later episode. I don't think it's necessary to use my words to read their definition again and draw pictures. And by the way, this tutorials didn't even start, I just post one to see anyone is interested, if there's no one, then I shouldn't waste time. &amp;#x200B; BTW, thanks for your comment, I will improve it, if that is necessary.
This is not the right subreddit - you want /r/playrust, though you're probably going to get banned from there.
The issue is that the `.` (dot delimiter) is used for namespacing fields and methods. Having postfix macros would reduce the surprise when reading `.await!()`, but in my opinion the best way to get rid of the surprise is to use *another* delimiter. We already have `::` for namespacing types, and I'd add a `@` or `#` delimiter to disambiguate fields/methods from "special stuff" such as await (and possibly later postfix macros).
You need to define a helper function which can be placed inside the method.
[I made a more readable version here](https://i.imgur.com/PlFVOKg.png)
&gt; I would be fine answering "I hate it" for a few that I really dislike, but because there's no in-between I was filling up the survey and end up "hating" everything, even though in truth I don't hate any. Sorry. Can you explain me why ‚Äúnot really good‚Äù wasn't the appropriate option in your case though ? &gt; My concern is also for the core Rust developers who take this antagonism straight in their face... Oh, I didn't thought about that. I sincerely hope they don't, that wasn't the purpose at all!
This is nice :-). Sharing files or URLs is way harder than it should be.
I'm a web developer. We have a web based JavaScript CAD program that we'd like to speed up in places with wasm. Rust seems like the best fit for us because of its mix of high level features, safety and speed.
Is TLS still used? I thought it had been ripped out in favor of passing the "context" explicitly?
The postfix macro syntax is definitely my second favorite, especially if it comes with a guarantee that it will be usable for user-defined macros and thus non-special. I personally find a prefix await keyword makes it more directly obvious what is async and what isn't, and makes awaiting on a closure clean, but if we can do UFCS macros that does mean we don't need a new keyword which is always nice.
I don't think that would work more that try is a reserved keyword right? Iirc it has to be `.r#try!()`.
`Context` is just a wrapper around the `Waker`, so nothing really changed there. TLS is used for.. something else, not sure what.
I'm holding out for the space savings. With 32G of diskspace, Rust stuff takes a significant portion now.
Question mark postfix operators do have precedent elsewhere and a somewhat intuitive interpretation. Postfix @ has neither. Not a 100% reason not to go that route, but I think postfix macro or prefix keyword are both clearer and not strictly counter-intuitive given postfix macros get user definable. I agree field/method call syntax should not be done, it's magic to the extreme and is confusing.
&gt; My concern is also for the core Rust developers who take this antagonism straight in their face... Because only the "hate it" answers have reasons. Sorry :P. and thank you for discussing this and the initiative, it is appreciated :)
Associated macro ftw!
Just curious, what device are you using with only a 32 GB drive? Sounds like a netbook or phone. Do you find it comfortable to write code on? Can you add a flash drive?
Yeah, though the keyword could probably be "unreserved" in the next edition.
&gt;Can you tell us more about those 3% and how they influence overall gfx-hal API? Usually it's more about restrictions to what values you may pass to this API depending on the backend. The part of Vulkan we covered so far doesn't deviate from it. The only real API difference I can think about at the momement would be the initialization for OpenGL. &amp;#x200B; &gt;Personally I would've preferred if we treated Vulkan C API as The API and built all abstractions exclusively on top of it. I tend to agree with you but to be fair that caused by how the API evolved over the last few years. Starting from the initial pre-ll design, over an approach which tries to find a common subset for Metal/Vulkan/D3D12 and at some point we steered towards the Vulkan Portability concept. The API would be less opinionated with a Raw C approach and splits the implementation work from the issue of building a wrapper around Vulkan, on the other hand it would introduce a slight overhead if you target the native Rust API. Some more background as this topic has come up some time ago already: [https://github.com/gfx-rs/gfx/issues/2206](https://github.com/gfx-rs/gfx/issues/2206)
The thing is `await { ... }`would work "soon", while UFCS for macros is a different language feature, that would have to go through the process.
I think this is useful information. I didn't realize the magic field and magic methods were so hated. I was also under the impression that postfix was more popular than the prefix methods. That being said, polls are probably not a great way to design a language. In any case, I'm glad that the language team is taking it slow and thinking about this deeply. There's clearly not an obvious or perfect solution. I hope we can accept whatever decision is made.
You should try replacing the spawned processes with Rust code. Your distro checking code, for example, starts five processes, including three interpreted languages.
what would the postfix macro expand to ?
Have you seen [`trust`](https://github.com/japaric/trust)? It's an awfully handy CI template for deploying to several architectures and platforms, and I believe it includes those you've mentioned having a problem with.
Maybe I'm reading it wrong but I assumed that was 32 GB of space used by Rust projects.
Using the red color for all the 'I hate it' options? I love it!
I'm still a beginner Rustacean, so there's a lot I have to learn first just to be able to start. =) But in the meantime take a look at [taskell](https://github.com/smallhadroncollider/taskell). When I make some progress I will create a post.
I personally love and hate the ?. I always miss it when I'm skimming across code and then get confused about how it's able to compile, but at the same time it does make error handling code so much nicer to write.
Gamedev/Apps and VFX. I used to be a 3D Generalist, now I'm a TD and co-founder of my own company (with a friend) [HeadlessStudio](http://headless.studio). I'm replacing all our tools and future tools with Rust. Most of the tools, are C++, Python or C#. We work mainly with Blender, Houdini, 3DS Max, Unity and UnrealEngine.
&gt; That being said, polls are probably not a great way to design a language. That's for sure. But I still think it's useful, especially because many people take this really seriously and want to be heard, which lead the core team to [have a hard time dealing with all theses inputs](https://internals.rust-lang.org/t/await-syntax-discussion-summary/9914/89). I really like how slow and transparent they are being on that topic
I'm not sure, but maybe something like this will work for you? let street = row.get("street").map(String::trim); let additional = row.get("additional").map(String::trim); let address = match (street, additional) { (Some(street), Some(additional)) =&gt; { street + " " + additional }, (Some(str), None) | (None, Some(str)) =&gt; { str }, None =&gt; { "".into() }, };
Yep this was the motivation behind the tool. It's very exhausting especially because event descriptions/meanings may also change between micro-architectures.
A new sigil for a new different category of meaningful relationship in code makes the most sense, instead of overloading a previous one with a layer of ambiguity or staining the code with too much noisy extra symbols. I too like the sigil option the best (any of @, #, ~, ^ would work well) and I don't understand how this option isn't more loved, honestly.
The most obvious temporary solution is the one that that requires zero language changes. `await!(future)` isn‚Äôt the simplest to type and might not be ideal from an aesthetic perspective, but anyone who knows Rust will understand it...it‚Äôs just a macro. It seems to me that the conservative path would be to move forward without making changes to the language and, in the future, make a decision on the right language change based on the code that we see people writing in public crates. Being able to look at real-world code to see things like how often `await!` is nested or used in constructions that could benefit from chaining vs how often only a single future is awaited. The other advantage to punting on a language change now would be that, once the decision is made that it‚Äôs time to revisit the issue, we could look at the various options applied to real-world code snippets to see how awkward/elegant they really are. It seems like all of the options proposed thus far have a significant level of dislike in the community and moving forward with any of them, at this point, feels premature and likely to anger more people than it pleases.
Thanks, you are absolutely right the video should show what the tool does in a more meaningful way!
Why on earth did you normalize the graphs?
Because not everyone answered every question.
I would have expected that to work. Can you share a [more complete](http://sscce.org/) example?
"...I was honestly very skeptical of \`rendy\` at first, partially ‚Äôcause to me Amethyst feels a bit like vaporware ‚Äì it‚Äôs super ambitious and innovative, and that makes it hard to have incremental progress where you learn from design mistakes." Ouch.
 if street1.is_some() { unwrapped_street1 = street1.unwrap(); You can replace this with just if let Some(street1) = street1 { // do stuff with street1 here } Also, you can easily extract that code into a function and use some `Option` combinators: fn clean_address(address: Option&lt;&amp;str&gt;) -&gt; Option&lt;&amp;str&gt; { address.map(str::trim).filter(|&amp;x| x != "") } // ... if let Some(street) = clean_address(row.get("street")) { parts.push(street); } if let Some(additional) = clean_address(row.get("additional")) { parts.push(additional); } You can even use some iterator trickery to do something like: vec!["street", "additional"].filter_map(|x| row.get(x)).map(str::trim).filter(str::is_empty) etc.
I have a very good friend who is a Technical Director for a VFX company! He specialises in crowds and uses Houdini a lot. He was actually one of the first people I asked about Rust before I decided to learn it. He mentioned it was a pain getting people to move from Python 2 to 3 due to the amount of tooling built in the former, so adoption of Rust would likely take a while. I'm glad to see it slowly making its way into the industry!
IIRC, async / await is currently unable to pass the context argument through, so it stashes the context argument in a TLS and reads it before calling another Future::poll.
Not all hero wear capes. Thanks! Can I give you the latest data to have an updated version latter ? (because more people are currently answering the survey)
The only thing I really care about is whether or not an attribute macro that simulates implicit syntax is possible or not.
Sure, glad to help.
Thanks for the link! From what I understand, this is close, but still requires a CI integration (and only integrates with Travis and Appveyor for the time being). For a language like Rust, I would hope that we could make the cross-platform compilation strategy recommended to newcomers something that supported both local compilation and a variety of CI solutions. Somewhat related, I'm hesitant to use Travis CI at all after their recent [bad press](https://news.ycombinator.com/item?id=19218036)
Hi friend, you seem to be lost. I think you might want to repost that at r/rustgame or r/playrust. This community is for the programing language of the same name.
&gt;With their own (not-yet-public) requirements. Mozilla was once a star on the open source sky ‚Äì and now they won't publish requirements for a chat platform?
You are in the wrong subreddit bro, this is Rust Lang not Rust the Game
It might be worth posting over on the rust discord and other rust community forums to increase the sample size and diversity.
It's a HP Chromebook 13 G1 (which is sadly no longer produced) sporting a power-thrifty skylake Core m3, 4G RAM and 32G disk. I also have a 128G microSD card, but the card reader is too slow to use it for dev work. The highlight is the bright and colorful 3200x1800px HiDPI screen. At the moment I run GalliumOS, but plan to change to a minimal Fedora install once I get around to it. All in all it's an awesome dev machine for half the money you'd spend on a XPS13, Macbook Pro or ThinkPad. I certainly can live with the restrictions.
If you can think of any other place it can be worth posting, please go ahead and share it there. Reddit is the only Rust forum I use, so that's why I posted it here. But I'll be happy to have the widest possible input.
Why not choose the one that causes the least harm to the community? Postfix seems to be the most polarizing.
It's not apparent in any real benchmarks. Other issues, like generator layout, are far more significant. That benchmark is basically the worst-case for angling at TLS, since it's a hot loop over a future which does nothing other than yield a value immediately, which isn't a realistic usecase.
I've gotten it to work with this code: //~ use rusqlite //~ use serde //~ use serde_derive //~ use serde_rusqlite use rusqlite::{params, NO_PARAMS, Connection}; use serde_derive::{Serialize, Deserialize}; use serde_rusqlite::from_rows; #[derive(Debug, Serialize, Deserialize)] struct CustomerAccount { id: String, name: String, username: String, } fn main() { let conn = Connection::open_in_memory().unwrap(); conn.execute("CREATE TABLE customer_account (id TEXT, name TEXT, username TEXT)", NO_PARAMS).unwrap(); conn.execute("INSERT INTO customer_account (id, name, username) VALUES (?, ?, ?)", params!["foo", "bar", "baz"]).unwrap(); conn.execute("INSERT INTO customer_account (id, name, username) VALUES (?, ?, ?)", params!["quux", "bob", "alice"]).unwrap(); let mut stmt = conn.prepare("select id, name, username from customer_account").unwrap(); let rows_iter = from_rows::&lt;CustomerAccount&gt;(stmt.query(NO_PARAMS).unwrap()); let customers = rows_iter.collect::&lt;Vec&lt;_&gt;&gt;(); println!("got customers: {:?}", customers); } I hate to ask this, but are you sure there is data in the table when you make the `select` query?
Still, it makes it hard to compare graphs.
I'm new to rust and I don't understand \*\*mandatory delimiters\*\*. Isn't the problem to signal precedence? \`{await http::get(url) }?.to\_string();\`
I mean, the thing is, it's not _just_ a macro. It might look like one and use the same syntax, but you wouldn't be able to write it yourself.
Unfortunately democracy doesn't work great for rapid language development. Sometimes the language team has to make hard decisions that will make people angry for the good of the language, lest we keep arguing async syntax until 2030. I'm glad they are willing to even if it makes some people, including myself on occasion, unhappy.
If it's anything like the Acer C720 I have you should be able to replace the SSD inside of it. With this one, any M.2 SSD should work if you crack it open and swap them out, which allows for a ton more space if you do end up deciding you need it.
Whatabout? ` let str_response = http::get(url)‚úãawait().to_string();
I suppose it would be better to scale each graph based on the total number of responses to that question.
&gt; I wouldn't be surprised if it ended up as the final syntax (and maybe we figure out some way down the road to make chaining nicer -- general postfix macros or something) I like this approach. I feel like the obvious precedence way with the prefix keyword is the most natural when coming from other languages and likely to result in the least confusion for new users. Then down the line, we can explore UFCS for macros to allow for a x.async!() macro which simply expands to (async x). This would also mean that this macro is an actual macro instead of a magical compiler implemented thing.
Just use tokio. It is multi-threaded by default
So with just having a \`TcpListener\` and doing something like the [TCP echo server example in the docs](https://docs.rs/tokio/0.1.19/tokio/index.html) would work? &amp;#x200B; Would make sense doing something like this?: \`\`\` tokio::run(listener.incoming() .map\_err(|e| eprintln!("Failed to accept socket, error: {:?}", e)) .for\_each(|socket| { std::thread::spawn(move || handle\_client(socket)); Ok(()) }) ); \`\`\`
Tokio automatically uses multiple threads, you don‚Äôt need thread::spawn
what's you're cut &amp; dry opinion of amethyst? I know you allude to it a couple of times, but it doesn't state your as-of-now opinion
But... internet points üò¢
I really think we should just have `await &lt;expression&gt;` and be done with it. You can never satisfy everyone, but at least this option would be more or less consistent with language itself
Yeah thanks
The screws are behind two rubber strips, one of which I haven't yet removed (and don't plan to yet). For now, I'm thinking about removing XFCE and changing the file system to BTRFS, where I can use compression, which might even improve timing. Also getting Cargo to more efficiently cache compilation artifacts (both in time and space) would be a boon to all of us, regardless of available disk space.
Cannot people even write CI script and then copy-paste it? With Azure Pipelines it should be easy to get by with single CI file &gt;x86_64-pc-windows-gnu msvc &gt; gnu
First, how it works- the boundary of a task is the top-level future spawned on an executor. This is sometimes the boundary between async and sync, but async code can also spawn new tasks. It's *not* every async function or every await. Second, why this can still be considered zero-cost- the allocation is not required by async/await, it's simply the way most executors are implemented, so that they can handle an arbitrary number of heterogenously-typed tasks. Your example of homogeneously-typed tasks inlined into slab allocated connection objects is also 100% doable- it's all up to how the executor works. Whether the ecosystem handles that case well is another question, of course. There has been some work on `no_std` async/await, which is related, but the server design you describe probably doesn't have as many restrictions.
TLS was removed from the `Future` trait, but the current implementation of async/await just piggybacks on generators, which don't support continuation arguments (yet?), and so it uses TLS as a stop-gap solution pending further work on the desugaring.
Actix-web does this really well out of the box, for HTTP. I take it this isn‚Äôt http though. What I would probably do is source dive the actix web code, and build my own TCP code that works much like their web server, but speaking your protocol. With actix, the cache would be an actor, call it CacheActor. It owns all the cached data. There‚Äôs only one instance of CacheActor, and it interacts via messages. So there would be a fetch message and a set message, maybe. Or, maybe, you have a DataActor which implements caching internally. Which ever. The deal with actors though is that they should never share state. They only pass messages. On the up side, there is no locking code to write, because the actor will only run on one thread at a time. On the down side, actors are single-threaded. If a given stateful actor instance becomes a bottleneck, you can figure out a way to split its various jobs into several actors. If you find yourself using Arc or Mutex or any other sort of lock in your actor code, you‚Äôre not really doing actors, and you‚Äôre probably torpedoing your performance to boot.
Wrong sub. This is a sub dedicated to the programming language.
Thanks for this answer. I'll think a little bit more about how to implement the server with your advise. &amp;#x200B; And your suggestion about the Cache as `CacheActor` is really nice, I'll see what I can do and maybe ping you back if needed :) Again, thank you!
&gt; Cannot people even write CI script and then copy-paste it? Even if every dev could easily write a quick CI script without digging into the documentation of the CI-service-du-jour (which I don't think is the case), there's a lot to be said for ease-of-use. If we'd like to see wider Rust adoption, we should lower the barriers to entry across a variety of use-cases. &gt; With Azure Pipelines it should be easy to get by with single CI file The point here is to avoid tying oneself to a CI service. Of course we could spin up a CI pipeline with appropriate host machines for a wide mix of target triples, but that shouldn't be a requirement to deploy your command-line utility in Rust. &gt; msvc &gt; gnu Agreed, but `gnu` is the easier target to hit on Linux at the moment... `msvc` is for the next attempt!
I hope cargo will start putting things into proper directories soon. I hate clicking the ‚Äúfree disk space‚Äù pop-up (which will clean out ~/.cache or equivalents for other platforms) and having to remember that cargo isn't a good citizen on any platform and uses ~/.cargo.
I didn't participate because I have no strong feelings to any option. I think all the arguments are well thought and can live with any choice the team makes.
That implies await is just a function which it isn't
This solution seems much better than the rest to me. Not hard to implement, based on existing features, and we basically get other cool perks for free
I love this idea. It feels neat, consistent, and somehow obvious where many of the other options are baffling.
I'm partial to calling it `phobos`, regardless of its actual name.
 macro_rules! await { ($fut:expr) =&gt; {{ let f = $fut; loop { match futures::poll_with_tls_context(unsafe { Pin::new_unchecked(&amp;mut f) }) { Poll::Pending =&gt; await, Poll::Ready(x) =&gt; break x, } } }}; } Yup, totally can't write it yourself. P.S. Why is async/await being stabilized before generators?
The same thing the current macro expands to?
Because `@` and `~` are on most keyboards while `&lt;high_five&gt;` is not?
Does `cargo search serde` not always give the latest version number?
it was more like `&lt;stop&gt;`. joking is hard.
I mean, what is that await thing in your await? That is the reason you can't write it yourself.
Fixed.
Okay but yield is also not a thing in rust.
Hi, I made a crate that helps make \~/.cargo/ manageable and helps sorting out what to delete and what to keep. It only displays the sizes of the different subdirs of the cargo cache by default. Hopefully it will make your life a bit easier :) [https://crates.io/crates/cargo-cache](https://crates.io/crates/cargo-cache)
Well, your comment definitely helped. After not finding `reset` in gdb I started searching; found that one can flash using `telnet`, tried that; got and error message I could google for; then found [this post](https://stackoverflow.com/questions/32333434/trying-to-flash-an-stm32f3-discovery-board-using-openocd-no-flash-bank-found) and after adjusting my memory mappings gdb can finally `load` the code in.
I always assumed that \`Box&lt;dyn Fn(Args) -&gt; Ret&gt;\` is type-erased function equivalent to \`std::function\` in Rust.
My as-of-now opinion is I haven't tried to touch it in a couple years so my opinion is outdated. I need to do a similar article that's an overview of Rust game engines someday.
Show me some game jam games or such made in amethyst! If there are any, why aren't they advertised better on their project pages? They have lots of examples in their github, but the most sophisticated one is pong.
either people are agreeing with me cause they dont understand or cause I'm showing how it would be hard for new people ü§î
Uh... yes it is. `#![feature(generators)]`
Futzing with /u/q9c0tB14_kB8 's graphs in gimp, I removed the options that were obviously overwhelmingly hated, as well as the ones that got hardly any responses: http://imgur.com/c0abGnal.png "obvious precedence" and "postfix macro" are the only ones you could possibly justify choosing based on this data. That said I'm concerned with lack of responses for later choices, as well as how much weight should be assigned to these opinions (50% respondents are dabblers, 1/3 did not read the writeup carefully, majority did not read the forum thread carefully). I don't have any personal opinion on this syntax issue and haven't been following carefully.
I think I understand your example, and like the syntax a lot. But I could not figure out what ‚ÄúUNCS‚Äù refers to. Lil help?
&gt; await!(fut) this.
Can I just say that this is not a particularly good survey? The choices for answers seem loaded.
Assuming `await` is a keyword, why would we even need the `!`?
&gt; That said I'm concerned with lack of responses for later choices, By request from reddit users, I added the last choices only one full day after I posted the survey on reddit.The lack of response for the last choices is just a consequence of that. Now there is almost 200 answers to these questions as well, and the ratio is still approximately the same. &gt; (50% respondents are dabblers, 1/3 did not read the writeup carefully, majority did not read the forum thread carefully) It may be worth it to control for these factors, I didn't have time to do that today but that's why I shared the raw results in comment. Maybe I'll do a more in-depth analysis and a blog post this weekend, but it will depend on how much spare time I can find ;)
`Box&lt;dyn Fn(Args) -&gt; Ret&gt;` always requires an allocation and isn't clonable. Therefore, it doesn't satisfy the `Waker` use case as I understand it (namely, of being able to hold an `Arc` and know how to call into and clone it, all without allocations).
This is awesome and very exciting - I didn't know kyren was working on this. It sounds like it is a bit early, but does anyone know of any numbers comparing performance with this vs rlua? Looks like there is a lot of stdlib work to be done which should be easy for potential contributors to pick up.
I'm guessing async/await will be stabilized first by a significant degree unless I haven't seen something behind the scenes. It might still be possible to write as a macro of some sort with current rust, but given that this feature is a high priority, that doesn't help for it.
What would you gain from comparing graphs of different questions?
[https://github.com/rust-lang/rust/issues/57640#issuecomment-455493242](https://github.com/rust-lang/rust/issues/57640#issuecomment-455493242)
This is my favoured option too. It seems like the best of both worlds. Plus a general UFCS feature would be super great for all sorts of things.
Regarding compiled crates - why not teach Cargo how to use a per-user directory for compiled crates and artifacts, instead of a per-project one? That seems much easier to accomplish on a shorter time scale, and would alleviate this issue pretty substantially, I'd guess (e.g. every Windows project depends on winapi at some level, and everybody uses serde).
That's a legit criticism, I'm not a professional AND English is not my native language, which makes it even worse. But in French we have an adage : ¬´Un con qui marche ira toujours plus loin que deux intellectuels assis¬ª (lit. ‚Äúan idiot walking will always go farther than two seated intellectuals‚Äù) ;)
Ahm, folks, what in god's name is the purpose of closures? What are they useful for? And why do parts of the stdlib (thread::create) force me to use them?
Well the whole point of the debate was to measure which solution is the best. Which is obviously try await, but I digress.
The difference between "obvious" and the mandatory delimiters is this: "Obvious precedence": `await thing()` or `(await thing())?`. `await thing()?` looks decent to the eye but likely doesn't do what you want. Thus you can more easily do the "wrong thing". &amp;#x200B; "Mandatory delimiters": `await { thing() }` or `await { thing() }?`. In my opinion, the mandatory delimiters with {}s make await a block keyword, just like if or an `async` block. It also makes it obvious where the ? applies.
There are some really good thoughts on privilege separation and other security design concepts in a [recent OpenBSD presentation at CarolinaCon](https://lteo.net/blog/2019/04/27/carolinacon-15-writing-exploit-resistant-code-with-openbsd/)
10/10 for the title
I am in the process of writing a rust program that parses a lua script so I can then extract a table that is assigned to a variable. I then convert the table to JSON. I don't want to write a lexer and parser myself so I just dropped rlua in and just tried luster out of curiosity. The lua file is about 50mb, has a couple other variables but 95% of the data is contained in the table. Rlua parses it in about 350ms and luster parses it in 850-900ms.
Is await!(future) not an option? Honestly it seems fine to me
This is what I use; it even prints the line that is needed to be pasted into Cargo.toml
Thanks, I hate it.
I believe it stands for Unified Call Syntax
Sounds fair.
Damn, that's dope. Installed. Tips: add include/exlude params. For example i don't need to dig my .git folder ;)
It's an universal/uniform call syntax, essentially making it work like a method or free function https://doc.rust-lang.org/book/ufcs.html
For a new dependency, is it expected that most people, most of the time, will just want to use the latest stable version of a library? If that's the case, `cargo add` would be awesome.
I've found that when you ask people if they like something or not, they tend to be substantially more critical than if you just gave them the thing and talked to them about it in general. It's like they're specifically trying especially hard to find any reason to not like it. It's often getting at things they care about so it can be useful, but it definitely tends toward an exaggerated sense of *how much* they care about it.
Has this been suggestion yet (UNCS macros for await)?
Thanks!
I like "obvious precedence way" because it doesn't jam too much into single expression. But I would write it like follows: ```rust let response = await http::get(url) let str_response = response?.to_string() ``` I don't see single line making harm, and it's more readable, imo. Many find async/await hard to read, I wouldn't make it harder by adding special cases
It's also not something that most people would immediately think to do, I suspect, especially when compared to simply adding a dependency via a command, which is possible with most other modern package managers.
Interesting, I like the way you abstracted over the different types of storage (in-place and on the heap) by relying on the fact that `Box&lt;F&gt; where F: Fn` implements `Fn`, and simply calling a generic function on `Box::new(f)` instead of `f` if `f` is bigger than a pointer. I also found it interesting that you used a single function pointer with multiple call modes (Call, Clone and Drop) instead of a table of functions. I guess the problem with vtables is you couldn't construct them at compile time... although I think I've heard of some procedural macro crates that might help with that (it would be hacky though). One unsafe thing I noticed: you also need to check if `align_of::&lt;F&gt;()` is bigger than `usize`.
I hate this.
Using that logic we should stabalize the macro instead...
My Japanese co-worker gonna be so confused.
One large benefit to this is it solves similar issues in the future. The order of operations stuff was one of the main problems with the try! macro. While Result/Option is ubiquitous enough for a special sigil, and async might be. There's going to be other more probably niche cases in the future that will benefit from postfix chain-able control flow, that can't justify a sigil. Also were a prefix might makes more sense, the current macro form await!(fut) as works. I would expect like how result? is preferred over try!(result) that fut.await!() would be preferred over await!(fut) Some may not like there being two ways to call the macros. But there's already two ways to call methods with self, since that's really just sugar. So that's not unprecedented and the macro is still quite searchable due to the !. For those who don't like typing someone suggested that when the macro with one input is called postfix to allow ignoring the (), so "fut.await!()" -&gt; "fut.await!" which I like but wouldn't mind if that extension wasn't used I also like how this allows an obvious path forward. We start with the await! macro syntax, and once UNCS works we can switch to that, and if it seems a good idea removing the () can be done latter, and all of these are backwards compatible and all go through the same await! macro. From a learning perspective I would think that UNFCs is about as easy explain than a special keyword, and more universally applicable.
I love these postfix macros.
So is Yoda.
100% agree on the benefits of caching, it's always a good idea to save disk space when possible. And I don't blame you for not digging into the laptop, if you don't absolutely *need* the space then there's not really a great reason to go rooting around in there. I am currently using the stock 16GB drive in my chromebook as I don't need the extra space either. I have had a lot of fun playing around with BSPWM, takes getting used to but it's very light on disk space and very amusing to learn if you want to try something neat you might not have. :)
Problems I've found: * `Function` is always `Send + Sync` but doesn't currently require the wrapped callable to be `Send + Sync`. Fixing this is easy but then `Function` is less useful; perhaps it makes sense to have two versions, one that is thread-safe and one that isn't.
That's great, thanks! I may try to drop luster into some of my projects that don't need the standard library or metatables and see how it does.
Not so simply, in some cases; presumably you'd need flags: `cargo add chrono --version =0.4 --features serde,... --path /home/me/rust/chrono` etc etc
No, no, then the criticism changes to "pandered to the community, then ignored their input"
Great article! I've been working on a [typed Lisp compiler](https://github.com/etaoins/arret) in Rust and there's a lot of parallels between the examples in the article and constructs I've been using. I guess the simplicity of Lisp's syntax and primitives means there's a limited number of sane ways to represent it.
But I suppose they would still require parenthesis, wouldn't they? &amp;#x200B; `makro!(123)` would be `(123).makro!()`, but not `123.makro!()` `makro!(a.b.c)` would be `(a.b.c).makro!()`, but not `a.b.c.makro!()` \- otherwise, is it applying to the field `a.b.c` or taking `a.b.c` entirely into the makro? &amp;#x200B; So wouldn't the future awaiting still require parenthesizing? `(fut.a().b()).await()` instead of `fut.a().b().await!()` which is pretty different form what I imagined at first
Post the error.
If only we had associated statics
There is a clear consensus that there is no consensus. That is all that can be said. Most people hate everything.
Don't macros already let you use your choice of `()`, `{}`, and `[]`? So `await! {}` would come for free, to use at your discretion wherever you feel it would improve readability.
But those are relatively rare occurrences. Not many people start by installing an out-of-date dependency, and most people want to install directly from cargo, not from a local path. (In addition, doesn't setting the path define the version, making that somewhat redundant?) The features would probably be the most used part, but I would guess that most users don't need to worry about features, at least when they first install a dependency. Even in that case, knowing that the option in the TOML file is called `features` suggests that the command will provide an equivalently-named flag. To be clear, I'm not saying that the current situation is unworkable or that there aren't better ways of doing this than the Google method outlined by /u/nicoburns (which I do myself as well). `cargo search` is a good current solution. However, adding the `add` command (and its friends from `cargo-edit`) would make a very common interaction that people have with Rust significantly easier, and much more intuitive in the average case. (And still very intuitive in the more complicated case you outlined there!) That seems like a good usability win.
It's still a compiler built in, so normal macro\_rules macros don't apply. Procedural macros don't have that property.
Sadly, `Box&lt;F&gt; where F: Fn` doesn't actually implement `Fn`, but the wrapper I wrote at the top (`Boxed&lt;F&gt;`) does! Regardless, yeah, that abstraction was nice and roughly halved the amount of unsafe code necessary for this. I moved to the single function pointer because, sadly, there didn't seem to be a way to make vtables that didn't leak memory or have global state. I don't think there's any downside to the single function approach, though. It avoids an extra indirection at the cost of the function having an extra branch; probably a net positive overall. I already assert that `align_of::&lt;F&gt;() &lt;= mem::align_of::&lt;Storage&gt;()` in `fn f_to_storage`. I'm not even sure that that's strictly necessary, though. According to [this](https://doc.rust-lang.org/reference/type-layout.html), alignment is always &lt;= the size of an object, so `F` fitting in `Storage` implies that alignment is fine (assuming `align_of::&lt;Storage&gt;() == size_of::&lt;Storage&gt;()` which is AFAIK always true since `Storage` is a pointer type, and if it weren't, we could force it to be aligned to its size anyway).
I just interacted with the io, lexer and parser but it seems easier to work with than rlua.
https://doc.rust-lang.org/cargo/guide/build-cache.html sccache saves 50% of the time but from what I see, crates are still compiled surprisingly often
I wouldn‚Äôt mind if general UCS wasn‚Äôt stabilised before the special case of `.await!()`. The arguments against prefix syntax are compelling and having postfix field access or method calls causing flow control in the caller is very surprising. The `!` indicates that arbitrary code might be placed at the invocation site, possibly including flow control.
That may be how it's currently implemented, but `futures::poll_with_tls_context` is an implementation detail that's going away at some point in hopefully the near future. async/await is being stabilized before generators because generators as they are right now are not sufficient to implement async/await, hence the tls context. They need resume args still, but ironing out the actual api for that is in the backlog as far as I know.
There's a [whole chapter](https://doc.rust-lang.org/book/ch13-01-closures.html) dedicated to closures in the rust book, so that might be a good place to start. As for the last question, you don't *have* to use closures in `thread::spawn`, though it's often convenient to do so. See https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b44686e54470f60765e994d361b31111
As a somewhat uninformed observer, this really seems like the winner to me, by far. postfix/'dot' macros have been requested for ages. Things like \`"foo {}".format!(bar)\` would be so great and this feels very consistent with how the rest of the language works.
That would imply three different syntaxes. If we really want a thing that naturally evolves from UFCS for macros, we should only do await!(...). Fully different syntax for the same thing is usually a bad thing, an upgradable and semantically identical syntax is much better. Any deprecation requires developer effort and a new debate in the future
Doesn't \`format!\` / suffer from the same issue? Why is this important?
Where can I find the writeup mentioned at the top of the survey?
Where can I find the survey to better understand the results?
For anybody who, like me, doesn't know what is a _plumbing and porcelain architecture_, here is a link that can help you: https://git-scm.com/book/en/v2/Git-Internals-Plumbing-and-Porcelain
In JavaScript, the Parcel bundler will actually add dependencies automatically based on includes. `cargo-edit` is awesome but it would be perfect for cargo to go one step further like Parcel. Just add `use something` to your file and cargo will see you don't have it installed and try installing it automatically.
The comment immediately after that nicely describes my position on the issue, and directly opposes the one you linked.
on my phone so I have to be terse but have a look at https://blog.yoshuawuyts.com/runtime/
The other option was 'Lust' üòÇ
Also note [Make a Lisp](https://github.com/kanaka/mal) - language-agnostic educational Lisp tutorial with a lot of implementations (that include intermediate steps), including multiple Rust ones.
Well, that's a little disappointing. Could an ugly workaround be to make it a trivial macro that expands to an internal keyword or macro name which handled the *real* implementation? Alternatively, I don't see a good reason why procedural macros can't have braces (not to say there isn't one! nor have I bothered to google it yet...), and changing that certainly sounds like the more correct way to enable that syntax.
What does lisp stand for anyway? Logic in symmetrical parentheses? Would that make this rust inside symmetrical parentheses?
Could have gone with Rutht
Portmanteau of list processing.
A basic add subcommand without flags could be added first and options added later I guess.
Oh, cool, looks like sccache got a lot easier to set up since the last time I looked at it. I still think it should be part of Cargo but this will at least alleviate my problem. Thanks!
&gt; Sadly, Box&lt;F&gt; where F: Fn doesn't actually implement Fn It does in Rust 1.35 (currently in beta): https://play.rust-lang.org/?version=beta&amp;mode=debug&amp;edition=2018 &gt;I moved to the single function pointer because, sadly, there didn't seem to be a way to make vtables that didn't leak memory or have global state. I don't think there's any downside to the single function approach, though. It avoids an extra indirection at the cost of the function having an extra branch; probably a net positive overall. Yeah, I wonder about that, maybe it is faster. If it is, it seems like it could be a common compiler optimization. Anyway, I started writing a version that uses vtables, but the borrow checker is being stupid - it thinks that the lifetime of a `Vtable&lt;Args, Output&gt;` is dependent on lifetimes of `Args` and `Output`, even though they aren't stored in `Vtable`. https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=01ad1878dd34c3783647ae5cf999f68d &gt; According to this, alignment is always &lt;= the size of an object Cool, I didn't know that.
I tried making rusp back in the day: https://github.com/brendanzab/rusp/ - didn't get far, but it's an amusing blast from the past :)
So much better. Pie charts are never the right answer. They‚Äôre terrible.
It's cool though that Godot is now far enough along that it's considered one of the "sane" choices. It used to be a total pie-in-the-sky thing, the choice for the free software idealists only. Who knows, maybe Amethyst will get there too one day. Right now it sounds about as utopic as Godot did back then.
They literally _just_ announced that they're starting to look into this. They will be talking about the requirements, they just haven't yet. The current announcement is basically a declaration of intent, saying what the plans are but not yet laying out all the details. If you wanted a full list of requirements along with this announcement, that just means keeping this plan internal for longer and publishing this along with the requirements in the future. That's _less_ open.
ah...like apply `await` to `thing()`, then `?`
Nice! I made something similar but much less featured a few months ago. Of note is the crate terminal\_size, which offers a way to get your terminal size on at least windows and linux. Here's mine :) use std::io::Write; use image::{GenericImageView, Pixel}; use termcolor::{BufferWriter, Color, ColorChoice, ColorSpec, WriteColor}; use terminal_size::{terminal_size, Height, Width}; fn rshow(path: &amp;str, w: u32, h: u32) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; { let img = image::open(path)?; let img = img.resize(w, h, image::imageops::Nearest); let pixels: Vec&lt;[u8; 3]&gt; = img.pixels().map(|(_, _, p)| p.to_rgb().data).collect(); let mut rows = pixels.chunks(img.width() as usize); let bufwtr = BufferWriter::stdout(ColorChoice::Always); let mut buffer = bufwtr.buffer(); while let (Some(row1), Some(row2)) = (rows.next(), rows.next()) { for (&amp;top, &amp;bottom) in row1.iter().zip(row2) { let mut color = ColorSpec::new(); let [r, g, b] = top; color.set_fg(Some(Color::Rgb(r, g, b))); let [r, g, b] = bottom; color.set_bg(Some(Color::Rgb(r, g, b))); buffer.set_color(&amp;color)?; write!(buffer, "\u{2580}")?; } buffer.set_color(&amp;ColorSpec::new())?; writeln!(buffer)?; } bufwtr.print(&amp;buffer)?; Ok(()) } fn main() { let path = if let Some(path) = std::env::args().nth(1) { path } else { println!("Usage: rshow &lt;image&gt;"); return; }; let (Width(w), Height(h)) = if let Some(size) = terminal_size() { size } else { eprintln!("rshow must be run from a tty to know the screen size!"); return; }; let w = u32::from(w); let h = (u32::from(h) - 1) * 2; if let Err(e) = rshow(&amp;path, w, h) { eprintln!("{}", e); } }
Don't roast me too bad. But I've been trying to get my head around this compiler message due to this code: impl FileType { pub fn new(file_name: String) -&gt; Result&lt;Self, Box&lt;NoneError&gt;&gt; { let extension = Path::new(&amp;file_name).extension()?; let file = resolve_file_type(&amp;extension, file_name)?; Ok(file) } } fn resolve_file_type(s: &amp;OsStr, file_name: String) -&gt; Result&lt;FileType, Box&lt;NoneError&gt;&gt; { let extension_str = s.to_str()?; let file = match extension_str { "json" =&gt; FileType::Json(file_name), "csv" =&gt; FileType::Csv(file_name), _ =&gt; { println!("File format not supported {}", extension_str); exit(1) }, }; Ok(file) } And the compiler notice is: | 14 | let extension = Path::new(&amp;file_name).extension()?; | ---------- borrow of `file_name` occurs here 15 | let file = resolve_file_type(&amp;extension, file_name)?; | ----------------- ^^^^^^^^^ move out of `file_name` occurs here | | | borrow later used by call As I understand the Path struct "borrowed" the value and retains it as long as it exists? So I can no longer use it in the scope to create an enum? Given this issue I'm having, I guess borrowing values for structs aren't the neat approach and I should use clone instead? But shouldn't the struct just read the value, create a copy of that value during initiation process and return it back to it's owner after borrow? That's what my original thinking was, but now I'm a bit confused.
Those are definitely on my todo list. Though I don't know where I would start with replacing the spawned processes. I literally just started Rust with this little project. Could you point me to some good documentation on what I'd need to do?
Strings are not `Copy`, and you don't `.clone()` them either. The easiest way to do it is probably creating an empty `FileType` enum (without the filename) and doing the `match` first, then return `(FileType, String)`, or you can match on the `FileType` to create your result enum.
Awesome! I will have a look at the crate. Its a fact that I have not even tried the tool on Windows - might as well do that soon while it is still cheap to do major refactors. I might steal some ideas from the code you provided!
Not sure if I was clear enough in my explanation, or I'm too confused about my problem. The idea here is to create a enum from a string argument provided by a command. There is no enum struct to speak of, this is it's initiation from a mare command line input. What I want to do, is based on the condition met, certain path extension match, create a certain kind of enum. So I need to use file\_name for: 1) resolving the extension. 2) Filling the enum. The clone actually works, but something tells me it's not the best way to handle such situations. And I'm not yet aware where I'm making the big mistake. It might be that whole architecture is wrong, but I don't mind. I have this particular problem I want to solve now :D and learn something from. Perhaps I made myself a bit clearer, or if you already got it from the first time, can you please elaborate in more detail, I'm afraid I'm not following.
Sigils are hard to pronounce, create line noise, and encourage people to create.magic().code()?.that_does@things().that().differ_from()?@how.it.reads().
So is Scooby.
If you want to share a playground link, you have to click "Share" at the top right, then "Permalink to the playground". I can't see your code in either link.
Simple, but important (and missing): a good hdf library.
 -% target/release/spruce -d1 spruce : 157.75 MB ‚îú‚îÄ target : 157.26 MB -% du -hd1 74M ./target -% du -Ahd1 132M ./target The difference between the `du` calls is down to ZFS compression. The difference between `du -A` and spruce seems to be hardlinks: 4292456 -rwxr-xr-x 2 freaky freaky 1743096 May 3 00:54 build-script-build* 4292456 -rwxr-xr-x 2 freaky freaky 1743096 May 3 00:54 build_script_build-127f95a5baf5ab96* Note the identical inode numbers to the left. You may want to use some of the features exposed by [`std::os::unix::fs::MetadataExt`](https://doc.rust-lang.org/std/os/unix/fs/trait.MetadataExt.html) to give more accurate results.
List
What would cause the following error message? &amp;#x200B; \`thread 'main' panicked at 'broken at 203: Os { code: 11, kind: WouldBlock, message: "Resource temporarily unavailable" }', src/libcore/result.rs:997:5 stack backtrace:\`. &amp;#x200B; The code that causes it is: &amp;#x200B; let stdout = stdout(); let mut lock = BufWriter::with\_capacity(10\_000, stdout.lock()); lock.write(b"BEFORE").unwrap(); self.list .iter() .for\_each(|\_d| { lock.write(b"beg - ").expect("broken at 203"); });
This is the winner here.
Try r/playrust
As neat as this might be, I expect this would do terrible things to how Rust code looks day-to-day. Generally speaking using the requirements of new features to significantly change how other, working parts of the language look is inadvisable, since things should be designed on their own merit more than ‚Äòby association‚Äô. This isn't really a problem I have writing Rust, it's not a solution I'd consider asking for if `await` wasn't a thing.
Fair point! I'm not opposed to the initial syntax just being await!() assuming the implementation is just a normal macro. However, [I remember this comment](https://www.reddit.com/r/rust/comments/bj9n2p/how_do_you_feel_about_the_proposed_await_syntax/em7mta1/) that said the implementation cannot be a macro because of poor error messages (and maybe because it could make a generic yield macro). If the options are to have a custom macro that plays by special rules or a keyword + simple macro, I'd prefer the keyword, but honestly at this point either is fine with me.
[These new graphs should be easier to compare across questions.](https://imgur.com/a/0qkdKFV)
Definitely agree. Even if short term we only get `await!(fut)` and we get `fut.await!()` later when either UCS/Postfix macros are stable or as an early special case, the end language design will be so much nicer. All the special case magic solutions are as goofy to me as if we started adding `println`, `assert` and `include_bytes` as unnecessary keywords to replace macros. Trying to get await to look exactly like other languages rather than like rust is premature and irreversible "polish" when a macro solution is viable. If a feature is representable as a macro, does some codegen like a macro, is mentally consistent with being a macro, just leave it as a macro. Especially to start with. UCS/Postfix macros also look like they could have obviated the need for \`?\` as a special case, and will continue to be the reusable solution to these text order and order of operations issues.
There are dozens of us! [DOZENS!](https://m.youtube.com/watch?v=lKie-vgUGdI) haha. Seriously, though, just having a chance to check out quic and my first impression of Quinn was it only offers a tokio/futures interface. There are those of us who actually prefer manual event loops. I will check out the -proto crate now that I know about it. The other main question I came away with was how to harness the multiplexing across threads. E.g. can streams from the same connection be parceled out to worker threads for parsing? cc /u/Ralith
Fwiw I've previously searched for this pipelining to clean up code in Rust and found it non-existent.
oh no
You want r/playrust. This is for the rust programming language.
I think postfix macros is a feature which many would like to see implemented, and some have asked for functions pipelining as well which will help to make code more clear and easier to understand in some cases (though proposals haven't found much traction for various reasons). So I've seen here a chance to do a generalization, which may side-step debates around async/await entirely and will be useful outside of async code as well.
Is there any reason it shouldn't be a new scope, though (just like a conditional)? There may be some context of the discussion I'm missing, but I think it's probably important to distinguish between awaiting for a future value (i.e. the value being awaited on had already been evaluated and is if the type `Future&lt;T&gt;`) or if it's something more akin to a thread join. If it's just a future value - which is the impression I've gotten from what I've read - then creating a new scope that just happens to result in a future should be fine, right? await { 1 } That should result in a type error. await { do_something(); returns_a_future() } That should be fine. I agree that barring `{}` the parenthesis version is preferred over some special syntax. Rust already went through syntax hell growing pains with all the various sigils for memory management, etc. I'd have to see it slowly as them all back in over time.
The description of the GC is really promising. Is it possible to use it in other interpreters, or it is limited to Luster?
Other languages, like Elm o Elixir, use `|&gt;` for this feature. IMHO it is easier to read than `@`.
I feel like that could cause parse issues, but I don't think the @ sigil is used anywhere else so it would be unambiguous. Then again, I don't work on the compiler so I don't know.
There is a [concern](https://internals.rust-lang.org/t/9973/13) that using `|&gt;` may be a backward-compatibility hazard. Personally I don't find `fut|&gt;await` easier to read than `fut@await`, plus one-symbol sigil is easier to read and takes less space (we also could use `#` and `~`), but either way I will not be strongly against using two-symbol sigils if it will be a preferred direction.
`@` is used for [pattern bindings](https://doc.rust-lang.org/1.8.0/book/patterns.html#bindings), but I think it should not create any issues.
LOOOOOOLLL thanks a lot for the detailed and funny reply! I will investigate this further as a 3 months old lol
Some fresh exploration around cargo features would be great, especially as I‚Äôve been feeling like libraries are becoming naturally more complex and need to integrate in various ways that are hitting existing limitations around managing features in dependencies more regularly.
And the changes required on the rustc side have also landed: [#60006](https://github.com/rust-lang/rust/pull/60006) [#60385](https://github.com/rust-lang/rust/pull/60385).
You're looking for https://www.reddit.com/r/playrust/
You wanted /r/playrust - This is the sub-reddit for the rust programming language.
&gt;my first impression of Quinn was it only offers a tokio/futures interface. Thanks for the feedback. Would it help if we mentioned the custom event loop use case in the README? &gt;The other main question I came away with was how to harness the multiplexing across threads. E.g. can streams from the same connection be parceled out to worker threads for parsing? The `quinn` crate's stream handles are `Send` for convenience, so this will Just Work there. Conversely, from the perspective of `quinn-proto` this doesn't really make sense; there's no significant processing of incoming stream data left to do once it's demultiplexed by the connection state machine, though you can of course ship the received data off to other threads by hand at your leisure.
Ah, thanks!
Anybody know if it is possible to write a repetition in a macro without a repeating variable in the inside of the repetition? This is a smaller example of what I want to achieve: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=70a48c320afe3586591dc0b0929ebfdf
I just don‚Äôt get this controversy at all. Just let me type some braces around the future expression. I type braces all the time. It‚Äôs one of my talents.
Lotsa Irritating Superfluous Parentheses
I would suggest wrapping any 3rd party library you use in your own trait (using your own models too) which gets injected in as a dependency. This way, you can easily inject your own mock in too and also you are free to change library if need be.
Yes, I can follow you. What you want to express is a common pattern, and you want to keep the two phases, analysis and result composition, separate. So you have two options: 1. Use an intermediate enum without the `String`s to store the file type during analysis 2. Create enum values with empty `String`s, fill in the filename later In your case, knowing that `String::new()` doesn't allocate, I'd choose the latter option.
Too bad the article never mentions there's a Github repo for Risp (besides the gists): https://github.com/stopachka/risp
That would be better that any retarded postfix variant. But `await &lt;expression&gt;` is the only right way to do this operator regardless.
Aw, crap. I probably lost it then.
My approach is like this: start off as simple as possible: one library with one module and an executable. Then start to grow this bit by bit while not being afraid to reorder everything from time to time. There never was a moment for me where I went out of options to go forward. Splitting up things into seperate crates is beneficial for compile times and reusability but might be more work to restructure.
It is not elixir and there is no concept of pipelines in Rust. Method chaining is just syntax sugar and `await` is not method in first place P.s. if we'd to have pipelining then it should not be for `await` only, but in general
Confirmed.
Please, read the link first before commenting...
If I've gotten right what you said: you don't bundle modules into directories? That's one of the basic ways of structuring
If it's trending as you say, it may or may not be because of the possibility to generate WebAssembly. But there's also more mundane value in it. Suppose you want to create an application which you write in Rust. Furthermore, you want to allow plugins to be created by other people and suppose they lend themselves well to being written in a scripting language such as Python. You don't expect the general user to be able to quickly and easily produce a Rust plugin. So this Python interpreter in Rust would help integrate your Plugin Framework into your application. (As would bindings to libpython, but that's an architecturally different approach.) The same goes if your application is a game (your main Engine and Framework being in Rust) and you want to provide scripting ability for the game world and/or the actors in Python so as to help your team to more easily create content and/or to support modding. That's generally the same concept as the plugin framework above just in another guise.
I never knew how much I needed it now that I've seen it &lt;3
Whoa this is so cool, I was t aware this was possible :o great job
(New reddit account, still kyren) I would caution people against jumping into the stdlib just yet, there are a couple of problems that make writing bindings right now not so great: * Arguments / returns are Vec&lt;Value&gt; type and require a lot of boilerplate to convert, and are generally slow. I need to finalize a new API here, and the callback API is still rough in other ways * The sequence system is missing some things like "loop_fn" and Loop from futures that it needs to do some things like iterators * A lot of the stdlib is actually frustratingly difficult, most of the table API can't be implemented on top of a hash table without direct access to the hash bucket vector. I mean, there is probably some stuff available to do, but it's not a great experience just yet. It's okay if people try but I don't want to give anybody the impression that I think it's a good API currently.
&gt; what in god's name is the purpose of closures? From a mathematical perspective, allow you to separate the substitution of variables into a formula from the evaluation of that formula. --- In practical imperative programming terms, the presence of closures makes it possible (or at least *much* more concise compared to the corresponding C idiom) to express control flow with functions instead of needing a new keyword and language support for every new control-flow idea which is ever invented. Because closures exist, `std::thread::spawn` can do something different from `rayon::join` and `rayon::Scope::spawn`. The `rayon` versions have much less of a performance penalty if you use too many (and a much higher level of optimal use) and they define how all subtasks must be completed before the original control flow continues. But the standard library one is suitable if you literally do want an independent OS thread for, say, disk operations or certain kinds of robustness which interact with the OS. And not only that, the differences between these concepts can be explained to the computer *using Rust itself.* If you don't need the "substituting values into variables" feature of closures, you may use a `fn` as a value (`spawn(run_watchdog_thread)` instead of `spawn(run_watchdog_thread())`) as long as it has the correct signature.
I've been waiting for this moment for a long time... /r/beetlejuicing
You probably want /r/playrust.
Even if it would be nice to do some pair programming, I think you are looking for r/playrust
Any chance we could hear a little more about how your exploring Rust in telecoms?
I should make the current gc crate it's own separate crate as it's still pretty general purpose, but I should add a finalization system when that happens though. Eventually luster's gc will have to become Lua specific unfortunatey.
Do you feel Rust is lacking in simulation all together or have you just found it less applicable in your line of work?
That would make it a lot easier to add and remove `dbg!()` in code as you go; there's only one run of characters to deal with each time instead of two. It feels right. :)
Note: you're assuming it's going to always be the last word in the file -- someone could potentially put a comment on that line (or some line below it) and mess everything up. Running with the assumption though, you probably just want to get the last line of the file and split it with [`split()`](https://doc.rust-lang.org/std/primitive.str.html#method.split).
Maybe try a cargo clean?
Ooh I got this one https://github.com/EasyPost/duo-auth-rs
Yeah, luster isn't the fastest just yet. I haven't done much perf work, I've only really been trying to avoid the most major performance pitfalls. I also don't have a ton of time currently, unfortunately.
So if I just want to do some basic graphics tasks in Rust with cross-platform support, use glium?
That's something I've been trying to figure out. How would I go about actually getting the last line? With bash, it's simple to just `tail -n1`. (I bring up bash, because this is from a fetch tool I'm making.) Before, I'd just use: let wm = Command::new("/usr/bin/bash") .arg("-c") .arg("tail -n 1 \"${HOME}/.xinitrc\" | cut -d ' ' -f 2") .output() .expect("failed to execute process"); But someone suggested that I use only Rust, as what I was doing before was spawning multiple different processes at the same time. (If you want some context [this](https://github.com/Phate6660/fetch) is the repo for it.)
I never liked using Lisp, and so on principle, I hate this. But the title gets the point across well, and I'm okay with that. :P
A couple of comments things that might make your life easier: * The [std::path](https://doc.rust-lang.org/std/path/index.html) module. In particular, [PathBuf](https://doc.rust-lang.org/std/path/struct.PathBuf.html) will allow you to build a path from its components. * Using [std::env::var](https://doc.rust-lang.org/std/env/fn.var.html) to fetch the value of `$HOME` is probably easier and a bit more correct than invoking `whois`. There's also a [dirs](https://crates.io/crates/dirs) crate that can help you get the home directory. * Creating a [std::io::BufReader](https://doc.rust-lang.org/std/io/struct.BufReader.html) from the result of `File::open` will allow you to call the [lines](https://doc.rust-lang.org/std/io/trait.BufRead.html#method.lines) method which returns a standard Rust [Iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html). That lets you call [last](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.last) to get the last line. If you want to skip right to code rather than figuring it out yourself, [here's a playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=070079962b10c16d05c109979ac3a979)
Lust would‚Äôve been a suitable alternate.
Thank you so much for all of the information. I'll be sure to check all of the out links you shared. Thank you for the playground as well. It's really appreciated. While I can usually understand the documentation for the most part, every once in a while I come across stuff that's kind of confusing. So it really helps to be able to see the output of the actual code.
IIRC, `try` is a reserved word, `try!` is not
FWIW it does not allocate for ZST. i.e. if you create it from function or closure without captured values.
Do you know how I might go about splitting the WM from "exec" in the string? I figured I'd use `split()` like kabocha_ suggested below, but it appears that you have to know what will be output. I tried to do this: let last_word = last_line.to_string(); let v: Vec&lt;&amp;str&gt; = last_word.split(' ').collect(); assert_eq!(v, ["exec", ""]); But it expects "xmonad" to be in the second set of quotes. Is there a wildcard I could use for it? Or is there a completely different method for this that I'm missing?
For something large, I'd kind of like to have a reasonable idea where I'm going before jumping in head first. My head is large and kind of squishy, but still... Actually I'd kind of also just like to know that Rust is even mature enough for such things at this point, in terms of practical development process.
Thank you for the example, I have been playing with `archery` over the last day and I think my understanding has improved. HKT is a new concept for me, so forgive me if I'm not quite grasping it yet. Am I right in saying that once we have created an instance of a struct, we can no longer change the `SharedPointerKind` from an Rc to an Arc? One of the reasons I am interested in [darc](https://crates.io/crates/darc)'s POC was the ability to switch between an `Arc` and `Rc` after a struct has been initialised. I haven't been able to do the same with `archery` so far but wanted to be sure I wasn't missing something.
`split` is returning an Iterator, so `last` or [nth](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.nth) will help you zero in on just the word you want. You can also collect it into a `Vec` like you're doing and just use an array index.
A couple of days ago, I posted [a question on StackOverflow](https://stackoverflow.com/questions/55939552/parallel-access-to-arbitrary-indices-of-a-large-vector-that-are-guaranteed-to-be) about indexing into disjoint elements of a vector in parallel, where a straightforward `split_at_mut` didn't seem like a good solution. I've since received some answers, including one that mostly accomplishes what I need using safe Rust. While I will select that answer as 'the answer' unless somebody provides an even better solution soon, I would like to expand an idea someone provided in the comments as another answer. Before I do so, though, I would like to be somewhat certain that my alternative solution is actually correct. Hence this post: could any of you comment on the correctness of this solution? Specifically: is my use of unsafe access to an `UnsafeCell` sound? use rayon::iter::IntoParallelIterator; use std::cell::UnsafeCell; use std::collections::HashSet; use std::hash::Hash; pub trait ParallelIterableSet&lt;K: Eq + Hash + Send + Sync + 'static&gt;: IntoParallelIterator&lt;Item = K&gt; { } impl&lt;K: Eq + Hash + Send + Sync + 'static&gt; ParallelIterableSet&lt;K&gt; for HashSet&lt;K&gt; {} struct ExternallySynchronizedCell&lt;T&gt;(UnsafeCell&lt;T&gt;); unsafe impl&lt;T: Send&gt; Send for ExternallySynchronizedCell&lt;T&gt; {} unsafe impl&lt;T: Send&gt; Sync for ExternallySynchronizedCell&lt;T&gt; {} pub struct SetIndexedVec&lt;T&gt; { store: Vec&lt;ExternallySynchronizedCell&lt;T&gt;&gt;, } impl&lt;T: Send&gt; SetIndexedVec&lt;T&gt; { pub fn with_capacity(capacity: usize) -&gt; Self { SetIndexedVec { store: Vec::with_capacity(capacity), } } pub fn push(&amp;mut self, value: T) { self.store .push(ExternallySynchronizedCell(UnsafeCell::new(value))) } pub fn pop(&amp;mut self) -&gt; Option&lt;T&gt; { self.store.pop().map(|cell| cell.0.into_inner()) } pub fn try_for_each_by_index&lt;Op, Err: Send&gt;( &amp;mut self, indices: impl ParallelIterableSet&lt;usize&gt;, op: Op, ) -&gt; Result&lt;(), Err&gt; where Op: Fn(&amp;mut T) -&gt; Result&lt;(), Err&gt; + Sync, { use rayon::iter::ParallelIterator; indices .into_par_iter() .try_for_each(|index| op(unsafe { &amp;mut *(&amp;self.store[index]).0.get() })) } }
what a great post! I love how it started low-level and worked its way up.
Thank you for your help! You just saved me from a lot stress. :)
which teams?
Depends on the compiler. Clang is better at it than MSVC at the moment.
Feature request: a borrow checker would be nice...
Say a function returns a Tuple of Futures, can I use await to destructure the Tuple?
It is. Take a look at larger rust projects and see how they do it. Try not to do it 1:1 the C++ way and try all available options.
&gt; makro!(123) would be (123).makro!(), but not 123.makro!() Why not? If function calls can do it I don't see why macros can't. &gt; makro!(a.b.c) would be (a.b.c).makro!(), but not a.b.c.makro!() - otherwise, is it applying to the field a.b.c or taking a.b.c entirely into the makro? That's true, but if you pick one there's always going to be someone that needs the other.
Why is it the only right way to do this operator?
Currently it doesn't expand to Rust. Its a compiler intrinsic.
Could `-&gt;` be used? `db.get_value()-&gt;await?`
Thanks a lot, it is really refreshing to see that people like it!
For the same reason as `return`, `yield` and other friends
&gt;Is there any reason it shouldn't be a new scope Strictly speaking, that syntax would work, but using scopes this way is also already a fundamental part of the Rust language, and it would presumably be syntactically valid even with the "obvious precedence" way. (ie. not requiring any form of special characters around the value) We can already do this in pretty much any context: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=605409f3f7ca48cfb45cc91da721b8a1 Example of using this with "obvious precedence": let str_response = (await { do_something(); returns_a_future() })?.to_string(); Using this syntax as a way to avoid the precedence issue with ? would introduce a special case when using it with the await keyword, which would be inconsistent with the rest of the language.
Since C2Rust seems to be not bad, i'd investigate from there: [https://github.com/immunant/c2rust](https://github.com/immunant/c2rust)
And what are those reasons?
You do realize that language syntax should be consistent? Math operators are often seen as part of expression and for them it looks natural. They do not change control flow or context of expression. They are just there as part of expression But keyword operators modify the context of expression. Now imagine you would have `"result".return?()` As people tend to read from left to right, you first read expression and only then you actually understand what's going to happen with it after seeing `return` In context of `return` it seems like a trivial thing but for `if` and other operators that change the flow of program should be understood at the begging of line, rather than at its end. If people suggest `&lt;expression&gt;.await?()` then why not have `&lt;expression&gt;.if?()` The more magical methods, the better, no?
That appears to use libclang.
Thank you
Fair enough. Maybe using Haskell is an option? * [https://github.com/jameysharp/corrode](https://github.com/jameysharp/corrode) * [http://hackage.haskell.org/package/language-c](http://hackage.haskell.org/package/language-c)
Not currently, but there is no disadvantage to just await each one in turn
It really isn't, using haskell has the same problems as just using libclang: i'd need to, like all other libraries do, re implement a non-reusable C AST in Rust.
Impressive! Is the choice to use discrete offsets (-0.2 or 0.2) of key positions intentional? The [Normal](https://docs.rs/rand/0.6.5/rand/distributions/struct.Normal.html) distribution may look more natural (e.g. `Normal::new(0.0, 0.2).sample(&amp;mut thread_rng())`).
I was using a similar project you might be interested in checking out for inspiration: [https://docs.rs/ketos/0.11.1/ketos/](https://docs.rs/ketos/0.11.1/ketos/)
Thanks :) &amp;#x200B; That's a great idea!
This was some very enlightening information! I had no idea about the existence of the Acquire/Release hardware construct, it's very nice to know more about what goes on under the hood!
Seems great for fine-grained control! It would be a great addition to built-in crude tools like what I mentioned.
Someone proposed uniform call syntax for macros. Making await!() a simple macro would then allow people to use it as prefix or postfix depending on use case: let thing = await!(some.other().thing()); or pipeline.with().await!().in_the(middle);
Hi, I‚Äôm one of the folks developing c2rust. Right now our clang AST extractor serializes the AST to CBOR which is then deserialized and parsed into Rust structures. We‚Äôre planning to get rid of cbor and build the AST directly as Rust structures. I‚Äôll definitely aim for reusability when we do that.
Defining new extension traits is a (admittedly cumbersome) way to do it.
Slurpist
&gt; You do realize that language syntax should be consistent? I competely agree, but I reject the idea that `await` as a keyword is objectively the most consistent. Besides I think it's OK to to occasionally break consistency if it improves how understandable the language is (after all keywords themselves are inconsistent with the rest of the language). &gt; But keyword operators modify the context of expression. But you could make exactly the same argument about `panic` or `assert`. &gt; Now imagine you would have "result".return?() `return` can be the way it is because you never want to return halfway through an expression. Also as far as I can tell `return` _has_ to be a special case in the language. &gt; then why not have &lt;expression&gt;.if?() Some languages _do_ have something like that (Ruby does I believe). However I think having an if-then-else done in that style would be difficult to understand and I don't think adding that style just for if-then statements (i.e. without an else) would bring any benefit to the language. And again I don't think it's possible (for a language without `goto`) to implement if-then-else without special casing it in the language (I'm less sure about that than `return` though). &gt; The more magical methods, the better, no? I don't understand why you is believe this, to the point where I think you must be joking, but if you were joking then why would you be advocating adding more magic to the language?
Or alternatively, a malamanteau of lisp processing.
It might probably be used but I believe it would be even more disturbing than `@` since it has absolutely nothing to do with function definition.
Can you then serialize the C AST back to C in an idempotent way ? Also do you provide APIs to modify or fold the C AST into another C AST that can then be serialized ? What I like about `syn` is that it is a Rust parser that not only gives you an AST, but also gives you the tools to work with it.
So we *can* do the same thing with `await`, then? The are no reasons not to keep the macro...
&gt; Personally I don't find fut|&gt;await easier to read than fut@await ... I think it's more likely to be written as: `fut |&gt; await`, which IMHO increases readability quite a bit.
You could look into cargo workspaces with sub-crates, as that seems like it would solve your issues. You say "these are not just disjoint libraries", but that does not matter much. It's fine if you split your project into crates just to modularize it. I don't know if you can group the crates themselves into sub-directories, but it shouldn't be impossible. You might also want to take a look at larger Rust projects (e.g. rustc, amethyst, ripgrep) for inspiration.
Post-fix method call is very close to being a trait method. Can we not simply pretend that it is, i.e. ``` trait Awaitable { type Result; fn await(self) -&gt; Self::Result where Self: Sized; } ```
Playground remembers the last thing you did there; maybe it's still there.
Very very cool! I read it yesterday and enjoyed it! I'll play with it for sure! Congrats on the good work!
This is interesting! I haven't done a thorough analysis, but one thing that stuck out when reading the code is your use of `mem::uninitialized`. Some of it is "just" questionable, but this is definitely wrong: ``` let mut res : ManuallyDrop&lt;Output&gt; = unsafe { mem::uninitialized() }; ``` If `Output` is, for example, `bool`, then this line is instantaneous UB: The compiler assumes that a `bool` is always either `true` or `false`, and this is also true for a `ManuallyDrop&lt;bool&gt;`. `mem::uninitialized` is basically impossible to use correctly, which is why it is going to be deprecated and replaced by a type-based approach with [`MaybeUninit`](https://doc.rust-lang.org/nightly/core/mem/union.MaybeUninit.html). That should be easy to use in your case though: ``` let mut res : MaybeUninit&lt;Output&gt; = MaybeUninit::uninit(); unsafe { (self.vtable)(Mode::Call( &amp;self.data as *const Storage, args.deref() as *const Args, res.as_mut_ptr(), )); } res.assume_init() ``` I suggest to also use `MaybeUninit&lt;*const ()&gt;` as the return value of the "vtable", then you can avoid `mem::uninitialized` altogether. Regarding your reimplementation of `Waker`, I am curious: can you handle the fact that the latest `RawWakerVTable` has two operations (besides `clone` and `drop`): `wake` and `wake_by_ref`?
We‚Äôve wanted it for a long time. There‚Äôs just been a lot of implementation work in the way and not enough people to do it.
You're getting a star from me and silver.
Why is `slice::binary_search_by` doing 3 extra comparisons instead of returning early when it finds a match? [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=782f5c3becb87bf1925f0d6666e79bea](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=782f5c3becb87bf1925f0d6666e79bea) And here is the implementation: [https://doc.rust-lang.org/src/core/slice/mod.rs.html#1398-1421](https://doc.rust-lang.org/src/core/slice/mod.rs.html#1398-1421)
You may be running into this: https://github.com/rust-lang/rls/issues/1449 There is a workaround.
Thanks for the support!
Very nice. So far I'm just using a shortcut to open the current directory in sxiv, which also gives me an overview of all files. But this is purely terminal-based, so maybe this could even be used for picture previews. For example vifm lets you define custom commands for file previews.
 -m, --mirror Display a mirror of the original image That's an interesting flag to include. What is the use case?
Is there a way to remove a crate from crates.io ? I have a few crates that I initially published with the intent of developing the idea further, but I realised that I probably won't have the time. With all the recent discussions about name hogging on crates.io, I thought it may be better the crate names could be available to other people, as some of them are names that would fit into the ecosystem thematically. AFAICT no one uses those crates and all of the downloads are just bots, so yeah.
For large projects with multiple libraries that are potentially used separately but still have inter-dependencies and should share one repo, CI setup, etc, workspaces are a great solution. You can have many crates in one workspace, compile each one separately, but they all share one `target` directory and no rebuilds are necessary. For examples, you can check out [juniper](https://github.com/graphql-rust/juniper/blob/master/Cargo.toml), [diesel](https://github.com/diesel-rs/diesel/blob/master/Cargo.toml) or [futures](https://github.com/rust-lang-nursery/futures-rs/blob/master/Cargo.toml).
I'd recommend iterators for this! If you're willing to use the `itertools` crate, it has a nice `join` functionality directly on the iterators. Should be fairly efficient, and nice to write once you're used to them. Something like this will combine three options: use itertools::Itertools; fn main() { let x: Option&lt;String&gt; = Some("hi".to_owned()); let y: Option&lt;String&gt; = None; let z: Option&lt;String&gt; = Some("bye".to_owned()); let merged = x.iter() .chain(&amp;y) .chain(&amp;z) .map(|s| s.trim()) .join(" "); } Merging this with your original code, I think the following should work: for row in &amp;conn.query("SELECT ...", &amp;[]).unwrap() { let street = row.get("additional").iter() .chain(&amp;row.get("street")) .map(|s| s.trim()) .join(" "); }
TLS usage is still an overhead, so I don't see how async/await in its current state can be called zero cost.
Try deleting `Cargo.lock` and `./target`.
That is about it, interesting. I was playing around with the [image](https://github.com/image-rs/image) crate and decided to just leave it there.
Because the current implementation doesn't short-circuit when `cmp` (line 1413) is `Ordering::Equal` ‚Äì it would have to `return Ok(mid)` in that case ([proof of concept playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=06c12f818aade9605a0a6d47a13e387b)). Although this seems like a pretty obvious thing to do, it's possible that the current implementation simply performed better for the average case in benchmarks. It's definitely worth filing an issue at [https://github.com/rust-lang/rust/](https://github.com/rust-lang/rust/), because either way, this should probably be documented in the implementation.
Episode 20 of the New Rustacean podcast gets into many of these issues: [Putting Code in Its Place] (https://newrustacean.com/show_notes/e020/index.html) (Episode 30 touches on the issue too in the course of discussing the more advanced privacy settings for crate items. )
Something set your stdout filedescriptor into non-blocking mode, and you are using it in normal blocking code. The write() system can then return `EWOULDBLOCK` if the kernel buffer you are writing to is full, _instead of_ blocking. Are you mixing blocking and non-blocking (mio / tokio) code?
&gt;But you could make exactly the same argument about panic or assert They are not per se modifying context of expression. Rather than that they can be considered a free functions like `exit` &gt;However I think having an if-then-else done in that style would be difficult to understand I used `if` as example of why adding magic methods instead of having proper operators is bad. &gt;it's that await as a keyword isn't objectively the only sensible way to implement it. `await` will be operator that operates on all expressions. You cannot have it without being keyword, unless you'll make it part of `Future` trait. And no, it cannot be magic method, it should be visible to user through API documentation then.
One cannot create macros with the same names as keywords without using raw identifiers.
That's true. Especially if you have a "mature" pipeline with a few years, which is probably mostly Python 2. But some of the gains, are huge. We replaced a python ImageMagick tool, that works 360 images, with a much leaner rust cli tool, and made a huge difference in speed. I even wrote the same tool in C++ and C# and rust won everytime :). The only down side, is that for UI we still need to use Python or C#, with all the work done by rust in the background. We also wrote a tool for Unity where the all the processing is done in Rust, and we got "free" support to run it on Windows, Linux and Mac ([https://assetstore.unity.com/packages/tools/painting/hdr-creator-143353](https://assetstore.unity.com/packages/tools/painting/hdr-creator-143353)).
&gt;Finally, this is the first program I wrote in Rust. I may have misused some things, so if you‚Äôre a Rust hacker, I‚Äôd love to hear your feedback. I skimmed over your block post and didn't read the code in depth. But the one thing I noticed was this: &gt;We first need a way to convert our `RispExp` to a string. Let‚Äôs implement the `to_string` trait You basically never want to implement `ToString` (see [documentation](https://doc.rust-lang.org/std/string/trait.ToString.html)). Instead you want to implement `Display` and get the `ToString` implementation for free. &gt;It‚Äôs the least mental overhead I‚Äôve had to maintain with a systems language, and it was a blast to use. If you like that the compiler "annoys" you all the time, to write good code, you should use [Clippy](https://github.com/rust-lang/rust-clippy). We just reached the 300 lints mark, which will annoy you even more, so that you write even more correct and idiomatic code! :D
It does sound like one if this counter intuitive performance optimizations.
Awesome! &amp;#x200B; Started doing a quick test for one of our cases but ran into some problems with pushing a crate with the Cloudsmith CLI app, it created the crate and published it in the repo but then got stuck and isn't synchronising over the file. This was on Mac. &amp;#x200B; Also was a bit unsure how you you should specify the .crate file because if I just push say \`target/package/mytest-0.1.0.crate\` it uploaded it as a package with name \`mytest-0.1.0.crate\` instead of it being named \`mytest\` with version \`0.1.0\` which is what I would have expected. &amp;#x200B; Where is the best place to give you guys feedback or reported issues in more detail?
Is this link helpful? [https://community.amethyst.rs/t/games-made-with-amethyst/134](https://community.amethyst.rs/t/games-made-with-amethyst/134)
Couldn't you just count which option has most number one spots in the different graphs?
Dammit, now I have to change the name of my lisp written in rust when I release LOL Nice write up btw :3
Check out Carp then :3
This is a good way to go about it because you also get decoupling for free if you want to switch the implementation
Having an `await` keyword means we'll never be able to have an `await!` macro
We can get a regular prefix macro for now `await!(future)` then no rush for the postfix UFCS macro version.
I thought it wasn't a compiler builtin with the `generators` feature?
I just noticed that `StepBy` does implement [`ExactSizeIterator`](https://doc.rust-lang.org/std/iter/trait.ExactSizeIterator.html) when its underlying iterator does, so that `.size_hint().0` can be replaced equivalently with `.len()`. This doesn't change the optimization result.
Regarding question 1, all struct data is stored in contiguous memory region, but any heap allocated data which it contains pointers to is obviously stored separately
I like the "Rust by Example" . But, is it enough? How much % of "Read the book" content do I cover, if I take the "Rust by Example" instead of reading the book contents? Thank you.
Good link, thanks! &gt;But because Git was initially a toolkit for a version control system rather than a full user-friendly VCS, it has a number of subcommands that do low-level work and were designed to be chained together UNIX-style or called from scripts. These commands are generally referred to as Git‚Äôs ‚Äúplumbing‚Äù commands, while the more user-friendly commands are called ‚Äúporcelain‚Äù commands.
structs may have padding added, fields are not always contiguous. fields may also he reordered. you can add attributes to control layout though
Owner of NYAR here. This tickles me pink to see that my project helped you to find one! :) This looks so cool!
&gt; All memory accesses that happen before/after SeqCst operation stay before/after it on all threads. I think this rule is true of other _atomic_ operations, but not of ordinary reads and writes, which are allowed to move into (but not out of) a critical section. That is, ordinary reads and writes may move down across an atomic read, or up across an atomic write. &gt; Rust implements SeqCst by inserting a memory fence that prevents undesirable reordering. Is there a source for this? That would be very surprising to me. As Herb Sutter describes in his talk, part of the goal of atomic operations is to avoid emitting memory fences. My understanding was that Rust implements atomics by just passing them along to LLVM, which compiles them like it does for C/C++.
Herb Sutter's Atomic Weapons talk in the references there is phenomenal if you want to do a 2 hour deep dive into this stuff. But I had to watch it twice so maybe 4 hours :-D
Hi. I searched /r/rust and quora and stackexchange and the internet for this but I couldn't find an answer. Thanks for helping. So I am a rust newbie and I made a cargo new project, then I went in and wrote some simple code. There was an error (I typed println("whatever");) and cargo build told me there was an error. Then I fixed the error, saved the file, and typed cargo build again. It showed me the same error, as if I didn't change the file. But I did -- I checked. It wouldn't work until I did a cargo clean then cargo build again. How can I make it so cargo build recognizes when there is a change in the .rs file and rebuilds the file? This happens all the time and is very annoying to me to have to type cargo clean all the time.
I implemented a small web service to generate badges for the hits of code metric in Rust using actix-web: https://github.com/vbrandl/hoc
`await` probably shouldn't be implemented as a [macro](https://internals.rust-lang.org/t/await-syntax-discussion-summary/9914/52), as it inevitable leaks implementation details. IIUC the main reason for it is that macro can't right now check if it's called in async context.
it isn‚Äôt clear exactly what you want to do, but typically if you want to arrange your data to encourage autovectorization or to do vectorization by hand you arrange your data in a struct of arrays or vecs.
Ah sure, I meant ‚Äúmake it syntactically work just like a macro‚Äù
Programmer?
This looks great, and it's awesome to see you implemented some of the Galois Field error correction stuff yourself. I'm bumping into some BCH codes in another project I'm working on, and started to write a `bchlib` crate that is based on some BCH code that can be found in the Linux kernel. It would be great to get some feedback on it: https://github.com/yuvadm/bchlib/ https://github.com/yuvadm/bchlib-sys/
Most compiler-related teams. rust-lang.zuliphat.com
It won't be on the list much longer! üòã
You ruined my joke by proving that reality is even more insane! Thx for the pointer to Carp though. :P
Pipelining just looks really awkward to me.
The link says "if people like post fix await let's just add pipelining" and suggests that @ be used to represent pipelining.
In this case reading the text on the link would have been enough to at least hint at why the comment wasn't really useful ("Universal", "generic")
I think you have some misconceptions as to what vectorization means -- it has nothing to do with the `Vec` datatype in specific. Aside from that, whether it is "good" to create a struct with vectors of values (rows, I suppose?) vs a matrix datatype -- this depends completely on your definition of "good", e.g. what you want to do with the data in your program. Without further details it is difficult to give advice.
I worked on **three issues** this week: 1. So far I had only implemented [homogeneous media](https://www.rs-pbrt.org/doc/crates/pbrt/media/index.html), but wanted to render some [heterogeneous](https://github.com/wahn/rs_pbrt/issues/91) ones. 2. Looking at the example scenes I figured I needed a new [integrator](gihttps://github.com/wahn/rs_pbrt/issues/91), the `VolPathIntegrator`. 3. While working on both issues and related test scenes I found a [bug](gihttps://github.com/wahn/rs_pbrt/issues/91) in the current parser code ... and fixed it. Now, I'm at the point that I can render the first test scene with **heterogeneous** media, but: 1. It **renders** far **longer** than the C++ side 2. It **looks different** So, that gives me something to do for the rest of this week, and probably the next week as well ...
I'm sorry I took so long to respond, here's a pastebin of my compiler output after running cargo clean and deleting Cargo.lock [https://pastebin.com/xDhiAXvf](https://pastebin.com/xDhiAXvf)
That‚Äôs funny, I was working on a DataMatrix encoder this week :-) Will have a look at your code!
Darn tootin'!
&gt; The main differences with e.g. glium or gfx-hal is that I will not break the current ideas, concepts and public design of luminance. I don't think it's a fair comparison with glium or gfx-hal. Neither of those have been breaking ideas/concepts/design for the past year, and they don't intent to in the future. &gt; I‚Äôll just allow to have luminance code run on WASM, more OpenGL versions (basicaly as stated by /u/icefoxen, OpenGL 3.3+) and Vulkan. In theory, anyone can just add an implementation for whatever technology. Frankly, I find this line of reasoning to be rather naive. And trust me, we've been in the same boat with gfx pre-ll. You can't claim to "just add Vulkan in the future" until you actually do it, because what happens in reality is that Vulkan can't be bolted on something with great benefit. It has to be deeply integrated into your pipeline, affecting the internal abstractions and likely the end user API. My recommendation wold be to be more modest. Just say this is yet another graphics library that is a bit different, and that you have no guarantee that it will stay unchanged in the future.
Unfortunately, what you call a graphics abstraction would only work good on GL. So at the end of the day this layer doesn't make it easier to implement it on, say, DX12. It becomes just one more layer to churn through on the way.
&gt; in it's current state What state is that?
That‚Äôs a very interesting idea! It is an intentional choice just in that there is no right answer and it is pretty simple for a tutorial, but your comment is the kind of thinking that makes generative art fun!
Thank you phaazon!
while the optimizer does a fantastic job to optimize out the loop, I usually prefer a simpler operation like this: pub fn div_up(a: usize, b: usize) -&gt; usize { (a + (b - 1))/b }
Is there a way to only take an enum's variant into account when deriving `PartialEq`/`PartialOrd`? The default implementation also uses associated values to compare variants.
This one is not quite overflow safe: When `a &gt; usize::MAX - b` then the result is a small value rather than the correct one.
IMO it's confusing to have invocations of it look like a macro when it isn't a macro, and can't be imported, exported, or used like a macro. Even our other builtin macros can still be treated like normally-defined macros at usage sites. We could hack around to make this work, giving up await-as-a-keyword in the process, but I don't personally think it's worth it.
I've been summoned! Prepare for a long read. &gt; Can you tell us more about those 3% and how they influence overall gfx-hal API? We could split those into the following categories: 1. idiomatic Rust API: accepting iterators everywhere instead of slices 2. conceptual change of having non-copyable handles (as opposed to things like `VkImage` which are just usize values), which makes us to expect a generic `Borrow&lt;&gt;` of things instead of actual handles 3. Common limitations of the backend API, including things like the missing `TRIANGLE_FAN` primitive topology. These are in process of being specified by Vulkan Portability Initiative of Khronos, which we are a part of. 4. Stuff we just haven't yet got our hands on (but is on the roadmap), like Vulkan events. 5. Parts of the Vulkan spec that are *extremely* unsound. I can only think of the clear color list provided for a render pass. We expect a value per attachment that is cleared, while Vulkan expects just a value per attachment (but not necessarily as many values as there are attachments, d'oh). &gt; Personally I would've preferred if we treated Vulkan C API as The API and built all abstractions exclusively on top of it. This has been discussed a lot, as pointed by /u/msiglreith . I'm not a fan of going through a Vulkan Portability library for Rust applications for the following reasons: - there still needs to be *a* library for them to talk to Vulkan. It might as well be gfx-hal with Vulkan backend. - that prevents optimizations (mainly inlining) on short function calls like "draw()` - having to hide behind Vulkan handles introduces the need to box types (basically returning pointers as handles), which brings an unnecessary cost on DX12 and Metal &gt; Also I don't quite understand how gfx-hal developers plan to build on top of WebGPU. IIUC it will be a significantly more constrained API compared to Vulkan, so shouldn't it be quite weird? It's actually easier than building on top of Metal. Surely, there are bits that are not mappable to WebGPU, and we'll likely describe them in some sort of a Vulkan Portability for the Web specification in the future. &gt; If application wants to support Web and native targets it looks like it should be built on top of something like wgpu My vision is that 95% of applications (that want to program graphics workloads directly instead of relying on engines like AmethysT) would be fine at building on top of `wgpu` even if they don't care about the Web. It's just a nice abstraction level to work with, and the safety guarantee plays quite nicely with Rust.
Is there a planed date for the 0.11?
Can't wait to see what you guys have come up with :)
Interesting, thanks for the link! &gt; use only pure-rust libraries How is this going to play with the fact you are moving to Vulkano? Clearly, a simple "cargo build" wouldn't be enough to deliver on MacOS and Windows platforms that don't have Vulkan.
The next step is port it into wasm to use it in web projects ;)
you‚Äôre right. hmm‚Ä¶
&gt; You cannot have it without being keyword Yes you can, in fact one to do it would be to &gt; You cannot have it without being keyword I'm just still not convinced that the compiler _must_ have special knowledge of await.
I can see two potential issues, though I definitely could be missing something. 1. There is no gaurantee that `indicies` doesn't contain duplicates, which would lead to multiple &amp;mut to the same item. 2. This one is probably unavoidable since it is part of this particular design, but there is no gaurantee that `op` will not keep it's &amp;mut longer than its real lifetime. I don't think there is any issue with the way you are using `UnsafeCell` other than the things above.
No date but expected to be ready in a few weeks.
s/principals/principles
Haha glad to have tickled you ;) When learning a new language I always like to do something that hasn't been done before so your list came in quite handy!
Like, for use on a phone?
Cool, I see those everywhere, especially as an alternative to the traditional barcode. I am wondering though how to detect them in images, they don't have those nice locator patterns QR Codes have.
I must admit, I didn't fully understand all the math and had to copy a little bit from quirc (and the QR spec definitely didn't help!) but I'll have a look at your projects later on :)
Yes. For example in my past projects I needed to read barcodes on web client side.
I wanna ask smth. so when you pass a mutable reference to a function, why do you deal with a pointer to your reference inside that function. ex: `fn increment(x: &amp;mut i32){` `*x += 1` `}` why is there a pointer?
Kansas quarters reportedly misprinted to say "In God We Rust"
Sounds pragmatic to me :)
Thanks Mate. As far my understanding goes, SIMD (Single Instruction Multiple Data) is a form of vectorization and it requires data to be contiguous. In that respect, `Vec` data structures are suitable/good candidates for exploiting vectorization capabilities of the compiler. As to what I intend to with my data: I primarily work with large sparse matrices. Typical operations are `exp, transpose, trace, multiplication`. At times I also compute some statistical parameters such as `mean, variance, std, kurtosis` etc., In such a scenario what would be your suggestion?
That's a nice and informative video... I am wondering, what about floats when it comes to auto-vectorization?
&gt; Runtime, a crate that makes working with async code feel closer to working with std, and a stepping stone toward ecosystem standardization. This library looks really interesting!
Thanks mate. That clears my doubt. Would there be any performance difference between the following two data structures (theoretically): `struct Abe {x: Vec&lt;f32&gt;, y: Vec&lt;f32&gt;}` vs `[Vec&lt;f32&gt;; 2]` except the fact that the former has a handle and the later goes by indexing. Help is much appreciated.
Thanks jackmott2. This is exactly I wanted to know. If you can suggest me a place where I can learn to control the layout of \`struct\` fields would be great.
Oh wow. Good job. I'm also starting out, but I'm just animating a bunch of little blobs under environmental pressure. I'm trying to trick them into evolving. This is way more useful!
Hey there repilur, Paddy from Cloudsmith here. Thanks for trying out the service! Unfortunately you uploaded at almost the exact time we had a small outage in our package processing layer and so your upload got stuck in the queue behind a bunch of others. The outage was resolved shortly after and processing picked up from where it left off. &gt; it uploaded it as a package with name `mytest-0.1.0.crate` instead of it being named `mytest` with version `0.1.0` which is what I would have expected. This is expected given the issue described above. Basically, when a package is first uploaded we haven't yet parsed all the metadata and so will show the raw filename in the UI. Once we've processed the package we'll show the crate's name and version seperately. If you check back on the UI now you should see the package has been fully processed and looks as you expect. Sorry for the troubles. If you have any feedback then the best place is either to email support@cloudsmith.io or use the live chat functionality on the site.
It is not about its internals that require await to be keyword, but the fact that it is special operator and therefore should not be re-defined by user like `async`, `as` and etc. It doesn't matter how you want to implement it, but `await` should become keyword if it is to become operator
&gt;I think this rule is true of other *atomic* operations, but not of ordinary reads and writes, which are allowed to move into (but not out of) a critical section. That is, ordinary reads and writes may move down across an atomic read, or up across an atomic write. You might be right, the docs seem to imply it. I was not able to find a source that would be explicit about that. [https://en.cppreference.com/w/c/atomic/memory\_order#Sequentially-consistent\_ordering](https://en.cppreference.com/w/c/atomic/memory_order#Sequentially-consistent_ordering) &amp;#x200B; &gt;Is there a source for this? [https://doc.rust-lang.org/nomicon/atomics.html#sequentially-consistent](https://doc.rust-lang.org/nomicon/atomics.html#sequentially-consistent) Quote: &gt;Even on strongly-ordered platforms sequential consistency involves emitting memory fences.
I don't qualify by any stretch of the imagination, but my best guess is that it would be possible so long as it's possible via LLVM, since Rust's primary implementation uses the LLVM toolchain.
Thanks, fixed now.
Hi everyone! I released a small routing library a little while ago, and this is the blog post I wrote alongside it to talk about it a little bit. I wanted to show how easy it is to interact with Hyper and Usher to create a small server with more flexible routing capabilities. I tried to be detailed but wanted to avoid talking too much. Let me know what you think!
https://doc.rust-lang.org/reference/type-layout.html https://doc.rust-lang.org/nomicon/data.html
Thanks, and yes the upload looks correct now, great! Will test more and mail if we run into any other issues.
I'm not very versed when it comes to implementing high-performance matrix operations manually, but you could take a look at [nalgebra](https://crates.io/crates/nalgebra) or [ndarray](https://crates.io/crates/ndarray) to help you out with that.
Not when deriving, but you can just compare the [discriminant](https://doc.rust-lang.org/std/mem/fn.discriminant.html).
If you're talking about the `*x += 1`, that's not a pointer; that's the dereference operator - it gets you the thing that your reference is referring to.
yeah, you get the metadata for two vecs on the stack packed tightly, and they each point to some arbitrary vec data out on the heap. The biggest difference is, as you say, in the struct you select via named field and in the array you select via index. However, there is also a more subtle distinction: in the case of the struct it's actually totally undefined which of the fields is first and which is second, and in the case of the array it's absolutely defined which is first and which is second.
use the nalgebra crate. very smart people put in a lot of work to make it as fast as possible, and they do a good job.
What an I supposed to do if a dependant crate I import no longer builds because of errors in it's code? Maybe they want nightly? Maybe they want Rust 2018? Really deflating coming back to a project and not being able to build because of something out of my control. Also makes me concerned about the future of my Rust projects, any of the many dependant crates couple push broken code and put me at a stand still.
As a general note re. LLVM, you should not assume that because something is possible and defined in LLVM, that it is also defined and possible in Rust. For example, in our codegen we may generate LLVM bitcode that is defined according to LLVM but undefined according to Rust.
Huh, I didn't realize that. That's not really useful for the `Waker` use case, which will always have some tag data, though. An additional difference is that calling a `Box&lt;dyn Fn&gt;` involves a double indirection while calling this only does a single indirection (since the function pointer is stored in the object).
This is becoming a war this days let's rust complete its internal implementation and create a bunch of creates with everybody's requirement then the most favored one will be ported to core. :) FYI I am new to rust so no insult
llvm can do it, but you must pass it a special flag "fast-math", and I don't think there is a way to pass that flag when compiling rust code.
here you go: https://doc.rust-lang.org/reference/type-layout.html You could used the packed layout I think, to force contiguous struct representation.
I fixed the `mem::uninitialized` UB (see post for updated code); thanks for telling me about that. That means that [the docs for `mem::uninitialized`](https://doc.rust-lang.org/std/mem/fn.uninitialized.html) are completely wrong... it says that creating uninitialized values is fine as long as you overwrite them before reading them. The example even creates an uninitialized `Vec&lt;u32&gt;` which *could* presumably include a `bool`. I changed the implementation of `FnOnce` to actually consume the contained object (rather than just forwarding to `Fn`) by adding a new `MoveCall` mode to the "vtable" function. This made having both `wake` and `wake_by_ref` in the `Waker` implementation trivial.
Isn't stepping like this potentially veery slow, to the point where casting to wider data type for overflow avoidance usually better?
Ow, I thought it's a pointer, it makes sense now
What's the error that your getting she trying to compile your dependent crate
Excellent summary of the current state of the art, researched graphics libraries for my own project and arrived at [similar conclusions](https://github.com/iceiix/stevenarella/issues/34), Rust (and graphics programming in general) seems to be in an awkward transitionary phase with no clear best recommended practice... So I inherited a Rust application written to use OpenGL through [gl_generator](https://crates.io/crates/gl_generator) and [khronos_api](https://crates.io/crates/khronos_api) with a custom unsafe wrapper ([steven_gl](https://github.com/iceiix/stevenarella/tree/master/gl)) written 4 years ago. Would like to move off this custom code to a newer safer library, [glium](https://crates.io/crates/glium) or [luminance](https://crates.io/crates/luminance) or [gl-rs](https://crates.io/crates/gl) are options if I want to continue targeting OpenGL, but if I'm going to go through the trouble of porting to a new graphics layer, why not go all the way and upgrade to a cross-API compatibility layer like [gfx-rs](https://crates.io/crates/gfx)? But another wrench in the machine is WebAssembly support: Rust is in the unusual situation where *C/C++ can actually (currently) be a better platform for writing native/web 3D games*, at the moment. As a C developer you can write against OpenGL with SDL or GLFW, then port to the web with [Emscripten](https://emscripten.org) without too much trouble. Rust supports wasm32-unknown-emscripten theoretically, but with the [rustwasm WG](https://rustwasm.github.io), the community is moving towards wasm32-unknown-unknown instead, and the emscripten target is not as well supported. So I switched my Rust app from the [sdl](https://crates.io/crates/sdl) crate to [glutin](https://crates.io/crates/glutin)/[winit](https://crates.io/crates/winit), a pure Rust alternative to GLFW, but [winit doesn't work with emscripten](https://github.com/rust-windowing/winit/issues/760), older versions hit other bugs but newer versions break compatibility, I [took a stab at fixing it](https://github.com/rust-windowing/winit/pull/767) but this only uncovered more incompatibilities. It does look like wasm32-unknown-unknown is the way forward over -emscripten, but this requires reimplementing much of what Emscripten already solved, not clear how long a way it is off. What is clear is the desire is there, with [luminance planning to support WebGL/WASM](https://phaazon.net/blog/pre-luminance-n-random-thoughts) and [Amethyst receiving a $10,000 grant to run on WebAssembly](https://amethyst.rs/blog/moss-grant-announce/), I'm optimistic. These are the pull requests I'm watching closely: * [winit #797: stdweb support for eventloop 2.0](https://github.com/rust-windowing/winit/pull/797) * [gfx-rs #2554: [WIP] Add wasm32-unknown-unknown/WebGL support](https://github.com/gfx-rs/gfx/pull/2554) but if "WebGPU" takes off (confusingly, not this WebGPU: https://github.com/webgpu nor http://www.webgpu.com, rather, https://github.com/gpuweb/ and https://www.w3.org/community/gpu/), perhaps I'll port to the [wgpu](https://crates.io/crates/wgpu) crate instead. It is a confusing time to want to develop 3D games in Rust for WebAssembly, lets hope we can get through this transitionary stage and the Rust community will come out stronger on the other side.
If you could post the error, it would be easier to find out how to solve the problem. The issue you have, is not a Rust specific problem but rather an open source problem. The only thing you can do is forking the repo and fix the issue and use that in your cargo file as a temporary solution. Then you have to pray that the maintainer still takes pull requests and pushes a new version to crates.io.
`size_hint` and `len` do not actually step, only `count` will at the moment and that is not strictly necessary but more complex. In terms of alternatives, `usize` may already be the widest available data type. The handwritten version works within the same datatype but this is mostly about convenience and expressivity. If in some code (i.e. a decoder) I want to pre-compute the number of chunks that `[T]::chunks` will give me but I have no instance of that slice yet, what is the order of obviousness of these ways (not intended to be a rhetorical question)? * `len / chunk + (len % chunk == 0) as usize` * `(0..len).step_by(chunk).len()` * `vec![(); len].chunks(chunk).len()` The last using, extremely subtly, the fact that `Vec` doesn't actually allocate for a zero-sized type. I have a little bit of fun with finding the less widespread possibilities right now ;)
Oops, you're right! The macro would need to be called something like do_await!(). I could see that being a deal-breaker for some people, but I'm leaning toward keeping some sort of prefix syntax anyway for better scanability. My preference would be to avoid these long await chains, so I'd be willing to sacrifice a few characters per macro invocation to get it where needed.
Oops, I'll paste it to pastebin: https://pastebin.com/ypnU62tC Should note, I'm trying to install wasm-bindgen with `cargo install -f wasm-bindgen-cli`, I have had issues though with crates I was dependent on. I guess I was just wondering in general if there was a best practice to know what I'm doing wrong. &gt; The issue you have, is not a Rust specific problem but rather an open source problem. Yeah I guess, but at least with Java Maven, by default it doesn't try to grab a higher version than you specified. Also this is a weird case where I need a tool installed and that tool is failing to build.
Welcome to the Rust community!
I thought they don‚Äôt get polled until you start awaiting on them, that‚Äôs why ‚Äúwhen all‚Äù is not the same as awaiting to each future consecutively.
I'm excited about the renderer. Really looking forward to using it. Great work!
You don't need the \`.iter()\` on \`main.rs:14\`. In this case, you don't need \`jobs\` after this point, so you can just say \`for job in jobs\` (equivalent to \`for job in jobs.into\_iter()\`, which consumes \`jobs\`). If you do need it later, you could say \`for job in &amp;jobs\`, which is equivalent to the current code. &amp;#x200B; In \`get\_jobs\_from\_file\`, you use \`.enumerate()\` to handle the first line of the file. Instead, you could write &amp;#x200B; // This is hacky, and would be better to actually report an error for being unable to read the line, vs parsing failure let capacity = lines .next() .and\_then(|line| line.unwrap().parse::&lt;usize&gt;().ok()) .expect("Could not read capacity"); let mut jobs = Vec::with\_capacity(capacity); for line in lines { let line = line.unwrap(); // No need to collect vs just working from the iterator let mut split = line.split(' '); let weight: i64 = split .next() .and\_then(|s| s.parse().ok()) .expect("Error reading weight"); let length: i64 = split .next() .and\_then(|s| s.parse().ok()) .expect("Error reading length"); jobs.push(Job { weight, length }) } &amp;#x200B; (There's also a lot to be done to improve error handling here, rather than using \`unwrap\`/\`expect\`) &amp;#x200B; In [jobs.rs](https://jobs.rs), I don't understand why you can't just use the derived \`PartialEq\` implementation as \`weight\` being equal and \`weight - length\` being equal should imply that \`length\` is also equal &amp;#x200B; You can replace your implementation of \`Ord\` with &amp;#x200B; impl Ord for Job { fn cmp(&amp;self, other: &amp;Job) -&gt; Ordering { let self\_score = self.calculate\_weight(); let other\_score = other.calculate\_weight(); if self\_score == other\_score { self.weight.cmp(&amp;other.weight) } else { self\_score.cmp(&amp;other\_score) } } } &amp;#x200B; A getter for a public field also feels odd.
Just to nitpick, far and near pointer in "C" are not standard but an extension of your compiler. Likewise, you might need to extend Rust for this target. I think distinguishing addresses of code vs. data is probably "easy" (if not already done for some targets, I don't know), while intuitively I would not even attempt to have far and near pointers...
Let see if I get it right: I have to define a trait to abstract all redis commands and impl a struct that forward the calls to redis and a mock struct that store the data in memory?
If you expect people to read about something that you're supposed to explain in a tutorial, don't call it a tutorial, moron.
Found it [here](https://gist.github.com/rust-play/01ad1878dd34c3783647ae5cf999f68d) by appending the gist hash to gist.github.com
&gt; size_hint and len do not actually step Oh. Right. Silly me. &gt; Rust promising zero-cost abstractions, I had hoped that the optimization would turn all constructions into the same result. I think people are often reading it too rigidly. Zero-cost abstractions just mean that there is no fundamental reason why sufficiently smart compiler couldn't optimize the abstraction to the same code not using given abstraction. Even with a code looking really trivial optimizer can sometimes get confused, or just miss simple optimization opportunities.
What's the "post above" is referring to?
https://paper.dropbox.com/doc/Await-Syntax-Write-Up-t9NlOSeI4RQ8AINsaSSyJ
Thanks :-)
So, seeing as I was doing something with `GetCompressedFileSizeW` anyway, I thought I might as well package up something to make it easy and cross-platform: https://crates.io/crates/filesize let physical_size = filesize::file_real_size(path)?;
Would it be usable in tests? E.g. can there be two overrides running at the same time?
Gotcha, thanks for pulling that up. &gt; Even on strongly-ordered platforms sequential consistency involves emitting memory fences. I think on x86 this is depends on what you mean by "memory fences". A SeqCst write [is an `xchg` instruction](https://youtu.be/KeLBd2EJLOU?t=1858). That instruction does act as a full memory barrier, so it's a lot like a fence. But it's not the same as the `mfence` instruction that you'll get if you call `std::sync::atomic::fence`. Other platforms do use fences to implement SeqCst, but hardware support for sequentially consistent instructions ([for example in ARM v8](https://youtu.be/KeLBd2EJLOU?t=3220)) will make fences less common in the future. The distinction matters because fences are usually stronger and more expensive than what SeqCst atomics strictly require. &gt; Rust implements SeqCst by inserting a memory fence that prevents undesirable reordering. I think this summary goes a little farther than what's in the 'nomicon. It sounds a little bit like every mention of `SeqCst` leads to a memory fence (or a fence-ish instruction like `xchg`). But depending on the platform, atomic reads might not involve any special instructions at all. In particular on x86, an atomic read is just a `mov`, exactly the same as a non-atomic read. That's because x86 is fairly strongly ordered by default, compared to a more weakly ordered platform like ARM. So exactly when we do or don't get memory fences is a complicated agreement between the compiler and the hardware.
Will it eventually be possible to use enums values in const generics? That would be liiiiiit. I'd love to be able to have statically type-checked state machines.
Yes that's right. You don't need to abstract all of them out too, just the ones you use. Also, you don't have to copy the redis libraries API exactly but you can think of one that abstracts the data access away from your business/domain logic nicely. Otherwise you might let that library influence your data access API too much making the coupling to that specific library slightly tighter. That 2nd point I mentioned can actually be very tricky to get right so don't worry if you don't get it right away.
Would you consider writing a Go game as part of the dog-fooding process?
Good job!
I'd love to see this pave the way for variadic generics, too.
I've read the chapter (before asking) and didn't find it particularly clarifying ‚Äì especially it confuses me what the weird syntax with the double pipe is hiding As for your example, how would it look if you'd like to pass arguments to the function?
Looks good, and I like the trend of these types of libraries. Sadly, these types of libraries almost all suffer some of the same problems. Lack of examples (beyond the one). They usually have some kind of unsafe or tricky behavior that isn't corrected because it's complex and would take work to do right (but would actually need to be done in a real framework). Finally, these things usually just scratch the itch the user had and then is thrown into the wild, this leaves it not offering all it could for other users. Lastly, the big one: Docs. I think this is the right way to go gui wise for standard utilities for rust (and something like piston/conrod for games).
I know you can't use enum values, but is that necessary for statically type-checked state machines? I thought that was possible with the generics we have already.
It's not necessary, but it would be kind of nice to group all possible states into an enum.
Thank you very much for the extensive review! I have fixed/refactored many of the things you have mentioned. I still have a lot to learn, currently I have no good understanding of how the error handling is working in rust and how traits work. I have added the getter because the plan was to keep the fields private and create a factory method for the struct, but did not have time and forgot to do it. Is it recommended to have the fields public or is it better to have them private and have method for creation/read/update?
I just add and use test run target.
How did you added that? Is the output interactive, like run command (I mean err/wanrs from run command are links to files which is cool)? &amp;#x200B; (I'm still a newbie in IntelliJ)
I have a crate which contains a main binary which is the application, and also a support binary that is only executed by integration tests. I.E. the integration tests execute the support binary using `std::process::Command` in order to perform their tests. Is there a way to specify that the support binary should only be built for integration tests? The reason I'd like to do this is because the support binary has some dependencies that the main binary doesn't use, so I'd like to be able to put them in `dev-dependencies`.
That would certainly be more concise. Aha, I found where I learned about this. I'd have never thought of using generics like this on my own. https://hoverbear.org/2016/10/12/rust-state-machine-pattern/
I think it already works (modulo `fixme`s): enum Variants { A, B } struct Foo&lt;const V: Variants&gt; {} type FooA = Foo&lt;{Variants::A}&gt;; IIRC according to RFC 2000 you have to use curly brackets in cases like this to make parsing easier.
That's OP's code unfortunately
update your compiler
Dope, that's awesome ^_^
I'm happy to answer any questions about this! This was a satisfying project to work on. &amp;#x200B; This uses Futures 0.1 + Hyper + Tokio. I'm looking forward to translating this to async+await when it is stabilized.
Yeah, after looking at the chapter myself it seems like it goes into a lot of detail about how one would use a closure without first describing their syntax. Maybe the corresponding chapter in [rust by example](https://doc.rust-lang.org/rust-by-example/fn/closures.html) will serve that purpose better? As for how you would pass arguments into `thread::spawn` via a regular function? Well, the answer is that you can't. If you look at the [definition for the `spawn` function](https://doc.rust-lang.org/std/thread/fn.spawn.html), you can see that it takes any type `F` that satisfies the trait bound `FnOnce() -&gt; T` (as well as requiring that `F` is `Send` and `'static`). The `thread_fn` in the example is of the type `fn() -&gt; ()`, which satisfies that bound. However, a function that takes an argument such as `fn(i32) -&gt; i32` would not satisfy that bound, since it has 1 argument and 0 arguments are expected. You can see here how a closure is able to take input from the local environment and still satisfy the zero arguments bound while a normal function is not: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ca07625fedb156679e43e5ad0543b932
Also quite interesting: if I change calculate_weight to return a float, the following error is thrown in ord: no method named `cmp` found for type `f32` in the current scope note: the method `cmp` exists but the following trait bounds were not satisfied: `&amp;mut f32 : std::iter::Iterator`
This is really cool, do you have any thoughts about supporting authentication so it could be used on the open web?
What else does one have to do to get this to compile? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5a2e901043189bfca8de16386861e13d
Floating point numbers only implement `PartialOrd`, rather than `Ord` because all comparisons involving NaN (Not a Number) return false (even with itself). E.g. `3 &lt; NaN` is false; `3 &gt; NaN` is false; `NaN == NaN` is false. For this reason, floating point numbers also don't implement `Eq`, but only `PartialEq`. There are crates like [noisyfloat](https://docs.rs/noisy_float/0.1.9/noisy_float/) for wrapping floating point types in wrappers that disallow things like NaN and +/- infinity, and implement `Eq` and `PartialOrd`.
Authentication can be a big can of worms with LFS. Before this, we were using Artifactory for hosting LFS objects and using LDAP for authentication. There would always be problems when someone recently changed their password. They would need to run a command to remove their cached credentials so that they get prompted again. &amp;#x200B; I currently have no need for authentication because I run this on an internal network with clients I trust. However, I'm open to taking pull requests that optionally implements authentication.
&gt;A reference of an object that implements Send is Sync, in other words, implies &amp;T: Sync I thought it was the other way around, `T: Sync` means `&amp;T: Send`
Really excited about the 0.11 release. I'm planning on trying Amethyst when it's released. Hopefully I will have learned enough Rust by then.
Re. getters/setters, they don't seem to be as common in the Rust world as in, say, Java. I think a lot of this comes from having nothing like JavaBeans, which required them. In your case, if somebody modifies `weight` or `length`, there aren't any derived values that will become invalid as a result. If you created a `new` method that computed `calculated_weight` and stored it in the `Job`, then you'd need to add appropriate getters, and possibly setters. Similarly if there were combinations of `length` and `weight` that are invalid, and you were validating them in the constructor. I suspect that in most cases in Rust, if you're going to provide both a getter *and* setter, the field is usually just made public. If you're implementing a getter only, it usually shares the name of the field that it wraps, e.g. `fn length(&amp;self) -&gt; i64 { self.length }`.
Any chance you could add prefix-sugar with the pipelining proposal?
in the top right you got run configurations. click on edit, then the plus and select the cargo template. replace run with test and save it. now select it from the combo box and press run.
2048 should be fairly easy to implement with an ECS so I'd volunteer for that, but Amethyst lacks a "debug"/"shape" renderer (AFAIK) to make that easy. I'm not sure how much work would go into creating such a renderer using something like Lyon for example.
Here links if you'll need them: - [without `await?` sugar](https://gist.github.com/newpavlov/aa3c613e8339b11c6de607b79b57cdb1) - [with `await?` sugar](https://gist.github.com/newpavlov/e0c99d4fa2fe770b2a7a40eba083232a)
Can you target specific crates and get a build from there down through the dependencies?
The prefix mandatory looks really nice. It‚Äôs similar to another language and stand out from the rest of the code as other flow control construct. There is no nesting future needed as well.
&gt;Any const expression of the type ascribed to a const parameter can be applied as that parameter. When applying an expression as const parameter (except for arrays), which is not an identity expression, the expression must be contained within a block. This syntactic restriction is necessary to avoid requiring infinite lookahead when parsing an expression inside of a type. While it's a little more noise, I guess that makes sense.
Huh, interesting. It looks like there's two distinct modes of handling the handshake between the LFS server and the LFS client, from what I can get out the docs (they're very short!) The suggested means is to have a username and password which the LFS server itself knows how to interpret and allow or deny access based on. I think that this can be accomplished trivially with your existing server using HTTP basic authentication on a reverse proxy to your server. The next method is a little more complicated. The LFS client uses ssh to run the git-lfs-authenticate command, which returns an authorization the client will add to the header it interacts with the server with. (example: https://github.com/ksurent/git-lfs-authenticate). Keeping with the reverse proxy theme from before, I reckon that's a separate, more complicated reverse proxy situation. I've done similar things in the past with Squid's [`external_acl_type`](http://www.squid-cache.org/Doc/config/external_acl_type/) directive - literally for each request call a program to tell whether to allow or deny. The flow would be, the `git-lfs-authenticate` program generates an authorization token and writes it to a store; the external acl program reads this store and rejects requests which have a token not found in the store. I'm not quite happy because I would rather use NGINX for this, but I'm not aware of an equivalent directive for this which doesn't use Lua (nothing against Lua, I just don't like mandating which language you use). All of this just puts more stuff in front of your program, keeping it really quite nice and pure. These are just thoughts, I could be misinterpreting (a lot) of documentation here.
no postfix sigils? :'(
Yesterday I was reading the amazing [Writing an OS in Rust](https://os.phil-opp.com/) tutorial, and when they implements a VGA Writer with a fixed size array within, I realized how important are const generics are for systems programming.
Oh god we can we declare structs and functions within that block? Not saying I will...
&gt; If you want to contribute a translation to another syntax, open an issue and propose the creation of the appropriate branch. To keep the repo focused, please don't propose syntaxes which aren't in the lang team's writeup. Then, create a PR against the new branch. Bah. I think an example showing implicit await and explicit deferral is worth. I strongly feel it's been dismissed out of hand because of questionable reasoning about what constitutes surprising behavior.
```static something:&amp;'static str = "YOUR STRING HERE";```
Depending on exactly what you need to do, you can either create a static &amp;str instead of a string, or you could look at a crate called lazy_static to actually have a static string. If it needs to be mutable, you'll need to use a mutex or rwlock with lazy static.
Do you need to be able to modify the static String?
Yes.
Regarding error handling, Rust has three main approaches: 1. Where things can fail in only one, very obvious way, return `Option`. For example, `str::find` returns `Option&lt;usize&gt;`, where `None` indicates the case where the substring wasn't found. Similarly, many collections have a `.get()` method, where `None` indicates that the requested key wasn't in the collection. 2. Return a `Result` with an appropriate error. Lots of methods return results, and you need to decide if you want to 1. Try to handle/recover from the error locally (e.g. if a line is missing a length, you could just skip the line) 2. Return the error verbatim (usually using the `?` operator) 3. Wrap the error in your own error type or otherwise providing context, and then returning it. How much you wrap errors can depend on things like whether you're writing a library (so want to provide enough information to others to figure out the problem), or an application (where you can decide how much extra information *you* need.) 3. Panic! In general, a library should never panic. Most of the time, applications shouldn't either. Panicking should be reserved for cases where something has gone wrong enough that it suggests that the program is now in an invalid state, and cannot reasonably recover. (E.g. Rust panics if you try to access an out-of-bounds array element, because you've demonstrated that your program thinks that there are more array elements than there are. The `.get()` method, which returns `Option`s, can be used in cases where an element might not exist, and the program is willing to handle the possibility.) There are crates like [Failure](https://docs.rs/failure/0.1.5/failure/) and [Snafu](https://docs.rs/snafu/0.2.3/snafu/) for creating your own error types. If you really don't care, you can also return `Box&lt;dyn std::error::Error&gt;` from a function as a catch-all for all errors that implement the `Error` trait. Using `Box&lt;dyn std::error::Error&gt;`, `get_jobs_from_file` looks like: fn get_jobs_from_file(file_name: &amp;str) -&gt; Result&lt;Vec&lt;Job&gt;, Box&lt;dyn std::error::Error&gt;&gt; { let file = File::open(file_name)?; let mut lines = BufReader::new(file).lines(); // This is hacky, and would be better to actually report an error for being unable to read the line, vs parsing failure let capacity = lines .next() .ok_or("File ended too early")?? .parse::&lt;usize&gt;()?; let mut jobs = Vec::with_capacity(capacity); for line in lines { let line = line.unwrap(); // No need to collect vs just working from the iterator let mut split = line.split(' '); let weight: i64 = split.next().ok_or("Line missing weight")?.parse()?; let length: i64 = split.next().ok_or("Line missing length")?.parse()?; jobs.push(Job { weight, length }) } Ok(jobs) } It's a bit nicer since we can use `?` to bail early if we see an error. Note the `??` when computing the capacity: `.ok_or()` transforms the type from `Option&lt;Result&lt;String, std::io::Error&gt;&gt;` to `Result&lt;Result&lt;String, std::io::Error&gt;, &amp;'static str&gt;`. Each `?` then peels off one level of `Result`, also calling `.into()` on the error type to convert it into ` Box&lt;dyn Error&gt;`. I'll leave it as an exercise to you to modify `main` to handle the fact that `get_jobs_from_file` is now returning a `Result` instead of a `Vec`, but will note that since [Rust 1.26](https://github.com/rust-lang/rust/blob/master/RELEASES.md#version-1260-2018-05-10) the `main` method can now also return `Result` as a convenience.
Interesting thoughts! It's still not clear to me what the best way to implement authentication is. There's also the question of whether or not to control access on a per-project basis. In that case, the LFS server would need help from GitHub (or GitLab) to authenticate.
I have a big project (dealing with network traces, think rudimentary tshark) where I use a workspace. My policy is to create a separate crate for every major moving part, eg. one for parsing ipv4, another for udp etc. Also, whenever something becomes shared, like a common trait ('Parsable') or struct definition ('MyError'), I create another crate (or put it in an existing one, if sensible) and use those definitions from there, so nothing is duplicated. Workspaces are cool, you can even go into one of the crates, do cargo test or run and all dependent crates will be built and only the crate you are in will test or run. You can also just stay in the top directory and use \`--bin foo\` or just invoke \`cargo build --release\` to build all binaries for deployment at once.
I'm aware that Vulkan and DX12 are bindless and this API is bind-ful. But my needs are so minimal that it it shouldn't be hard to implement on DX12. There's already a work-in-progress gfx-rs implementation: https://github.com/pcwalton/pathfinder/pull/132
It is very inconvenient to compare these. A lot of clicking to switch branch.
Ok, so you'll definitely need a mutex around it to prevent race conditions. `Mutex::new` is also not a const fn, so it can't be used in a static variable initializer either. The [`lazy_static`](https://crates.io/crates/lazy_static) crate is designed for handling this, by running the initialization in a thread-safe way the first time that the value is accessed. [Here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;code=use%20std%3A%3Async%3A%3AMutex%3B%0Ause%20lazy_static%3A%3Alazy_static%3B%0A%0Alazy_static!%20%7B%0A%20%20%20%20static%20ref%20SOMESTRING%3A%20Mutex%3CString%3E%20%3D%20Mutex%3A%3Anew(String%3A%3Anew(\)\)%3B%0A%7D%0A%0Afn%20main(\)%20-%3E%20Result%3C(\)%2C%20Box%3Cstd%3A%3Aerror%3A%3AError%3E%3E%20%7B%0A%20%20%20%20println!(%22Before%3A%20%7B%7D%22%2C%20SOMESTRING.lock(\)%3F\)%3B%0A%20%20%20%20%0A%20%20%20%20*SOMESTRING.lock(\)%3F%20%3D%20%22Hello%22.to_string(\)%3B%0A%20%20%20%20%0A%20%20%20%20println!(%22After%3A%20%7B%7D%22%2C%20SOMESTRING.lock(\)%3F\)%3B%0A%20%20%20%20%0A%20%20%20%20Ok((\)\)%0A%7D%0A) is an example of how to use it.
If you can't use a variable to create or call such templates dynamically, and if you can't use the variant as a type to hold any data, what's the point ?
Sort of related, `serde_derive` wraps its generated code in `const #dummy_const: () = { ... }`, which I gleefully stole for `num-derive` too.
I prefer prefix-sugar, natural to read, at least for me.
The whole thing of tests in the actual code base is a mistake, IMO. It won't work as well as dedicated test frameworks, which will keep separation of tests and code clean. External tests are also just as much about testing external accessibility and real world use of the code as they are the functionality of the code.
You are right: https://doc.rust-lang.org/std/primitive.reference.html#impl-Send The `Sync` docs flip it though: https://doc.rust-lang.org/std/marker/trait.Sync.html &gt; The precise definition is: a type `T` is `Sync` if and only if `&amp;T` is `Send`.
That's why I lean toward using a reverse proxy - maybe there's some defaults (if gitolite or whatever says I can access, then LFS is yes) but it leaves the door open for more custom situations to build their own out-of-band solutions.
You want /r/playrust. This subreddit is about a programming language, not a game.
You will have to forgive me, it has been a few months since I messed with Rust and completely forgot I had to do that. Thank you.
Hmm... I think it's interesting that on the prefix with `try`-sugar, there were only 15 instances of `await?` compared to the 28 of `await`. At the same time, there were 16 instances of `(await`, largely due to adding context to the results before aborting. (This also implies that there were only 12 cases of bare `await`s, all of which that I've seen using manual error handling.) What does this say about the value of `await?`?
Nice
The current implementation was designed to minimize branch mispredicts at the cost of a few extra comparisons: https://github.com/rust-lang/rust/pull/45333
It sounds like you got the answers you wanted, but one suggestion is to use \`git blame\` on the implementation locally to see if the commit message describes why it's like that. But as others said, it might be a good thing to add as a comment.
Feels like an orthogonal problem.
You‚Äôre looking for r/playrust
These days you don't even need the `'static`, rust can infer it. It makes static strings a lot nicer.
Yeah, I was iffy on it before but seeing it here made me feel a lot more comfortable with `await?`
Agreed, they're not standard but they're also very common in the embedded world, partly why LLVM has it built in. Until I can tag rust variables/globals similarly I may need to hold off on picking it up, it may be a bit much to try and add myself :(
This really solidified my dislike of the postfix field syntax. It doesn't pop out like a blocking operation should.
thanks
Might be worth letting it specify the mirror axis or breaking it out into flip and flop.
&gt;whoops sorry man thank you
1. Clearly warns about control flow, which is what `{}` brackets do, like `loop {}`, `if {}` etc. 2. Cannot be confused with a field or a method 3. Postfix syntax works great with errors and chaining 4. It seems to me like the `.await{}?` at the end of a line pops out [even more than prefix](https://sjc1.discourse-cdn.com/business6/uploads/rustlang/optimized/2X/b/bf2ce5e63c85efa160fe5fbe90b84f2408f0ecc2_2_1380x358.png).
I actually prefer this over multiple files because then I can use `git diff &lt;branch&gt; &lt;other-branch&gt;` to compare the differences between the syntaxes.
while Rust probably means: Requires `Unsafe` Some Times
I feel the same incredulity except I think it should be await { future }.
You will need to iterate over them as trait objects (e.g. &amp;Trait) or use some generics magic to put them in a cons list. You probably want the former.
&gt;External tests are also just as much about testing external accessibility and real world use of the code as they are the functionality of the code. Those exist too. Put a `*.rs` file in a `tests` and `cargo test` will build and run it
Yes, "mandatory delimiters" is definitely my favorite prefix option (hence the comparison in point 4). It just works. I have a preference for the postfix I'm suggesting because: 1. It makes the mental overhead of brackets smaller in chains 2. Just from looking at syntax-highlighted code I was surprised to find .await{} more visible I think both variants are great though.
I'm sorry, but I can't see myself getting behind this. 1. Brackets don't always indicate control flow (e.g. declarations, struct initializers). When they do indicate control flow, it's generally assumed that their content is the code that will run. This proposal looks strange because it would be the only place in the language with a pair of brackets that was syntactically required to be empty. 2. Yes, but it might be hard for humans to parse (for example `if foo.await{}{ ... }`). 3. Yes, postfix does have some advantages. 4. It does jump out, but only because it is completely syntactically unique (it's essentially a keyword that must be paired with a symbol). 5. `{}` is effectively a new sigil since there isn't anything like it anywhere else. It isn't intuitive to me. Brackets generally come with the expectation that there will be something in them, and this just feels strange.
It's true it still happens, but the goal is it wouldn't. The aspiration isnt wrong or worthless just because it isnt perfectly realized. Also, rust is much better than most languages in this regard.
You can have await *look* like a macro (with bonus `await! {}` as a free option when it would improve code clarity!), by having it trivially expand to the "real" keyword, so I don't imagine macro-like syntax is a hard "never!".
Thank you for your input! Indeed, the fact that `{}` remains empty did come to my mind. There is one other place in Rust where this syntax is used, an endless loop: `loop {}`. I like the similarity of `loop {}` and `.await{}` taking a long time.
Could this be used with a barcode scanner somehow?
I think it would help a lot, yes. Another thing would be an example of how to integrate with mio, if that's possible. (Raw fd). Understood about proto having nothing to do with networking or threads.
Is there any way I can make this compile? I can't seem to figure it out... feels like a bug to me. Error is that a particular struct cannot impl Copy, because the only field doesn't impl Copy, however that field's type derives Copy. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1472da8a612ad8ce5b807ca9a5a5caff
Yep, same here - it's really easy for my eyes to spot blocking awaits since the code reads left-to-right. `let response = await!(wlan_svc.create_iface(&amp;mut req)).context("error getting response")?;` is just really easy to parse since I can just scan the left half(/third) of the code to pick out the relevant parts.
If you want a lisp with safety and pure functions, look no further than ACL2, which is built on Common Lisp, has a theorem prover, and has been used many times by IBM, Intel, and AMD to prove the inner working of microprocessor microcodes, etc.
Hardcore lisper here. What would be nice (no joke) would be a full implementation of Common Lisp that compiles to Rust. It doesn't even need to be written in rust (all Common Lisp compilers are either fully written in lisp or mostly written in Lisp). Although writing one in Rust would be cool too... i pity the guy that undertakes such a task, though. A starting point might be ECL (Embeddable Common Lisp), which compiles Lisp to C code and allows also to embed such code (or the complete ECL implementation) into a C program. It is partly written in C too. ECL is a mature product (at version 16 right now).
Since I was just on the website, there are already text-implementations of Sudoku and 2048: * [Sudoku](https://rosettacode.org/wiki/Sudoku#Rust) * [2048](https://rosettacode.org/wiki/2048#Rust)
Hey that code looks familiar ;)
I skeptical of it, but I also agree with you.
Vulkan and DX12 are not bindless, but the binding model is indeed different. That, among other things, is what makes implementing them fore a GL-centric "trait Device" rather painful. The minimal needs still include things like `Program`, `Uniform` and `VertexArray`, which simply don't exist in the nowadays APIs.
Which sigil do you like?
You mean, the way I had been doing it?
`prefix-mandatory` looks the prettiest to read but might be most annoying to type.
Ah, there it is! Thanks so much. Do you think it would make sense to have this documented in the source code?
You can own them with some indirection, like in Rc or Box, depending on whether you need to share them. You can still borrow from those to return your references. A cons list is a heterogenous list on the stack where the type is the types of all the elements in order (you can google an example in Rust). You can own it no problem, but the type is awful to specify so it really needs to be worth it.
How, though? I tried `bufs.map(|b| b.borrow_mut())` but it didn't get me what I needed...
It's not a bug, it's a limitation of derives. Derived implementations for generic types apply the derived trait as a bound for all type parameters, so the generated impls look like this: // input type #[derive(Copy, Clone)] struct Foo&lt;T&gt;(T); // expanded derives impl&lt;T: Copy&gt; Copy for Foo&lt;T&gt; {} impl&lt;T: Clone&gt; Clone for Foo&lt;T&gt; {} In this case (the most common) this is the correct behavior, but for cases where the parameter is used in an inner type (or is behind an immutable reference which is copyable), the derive can't be any smarter about it because it only knows the definition of the struct it's currently being applied to. It could _probably_ be smarter about type parameters behind references but I'm not sure why this hasn't been improved yet. There's an issue with a lot of discussion and related links here: https://github.com/rust-lang/rust/issues/26925
Anything except prefix sugar! (Though i didn't see the sigil one)
Where do you see postfix-sigil?
`Vec&lt;&amp;mut dyn SomeTrait&gt;` is straightforward: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=bb313667baaf633335b600c97c2bab47
Wow... thanks for the info. Seems that simply trying to `impl&lt;'a, T: PartialEq&gt; Copy for RefPartialEq&lt;'a, T&gt; {}` also does not work. This is actually very frustrating... I can work around it but it very much not ideal. Not going to lie, I feel like every project I've worked on with Rust has lead to discovering ugly inconsistencies in the language. I mean, I still like the language, but this in particular feels like a big oversight. Oh well... guess I have to rewrite some code.
Ok, but that example is based on being passed in collections of mutable refs. If, instead of that, you're implementing the method on a struct that contains a `fields: Vec&lt;Box&lt;dyn ParsingBuffer&gt;&gt;`, how do you use it to return the `Vec&lt;&amp;mut dyn ParsingBuf&gt;`?
I more meant that all the work put into refactoring the generic system hopefully makes it less difficult to design and implement variadic generics in the future.
Great idea!!
rustful AI prog on the way. Libs inc.
Brackets that can only ever be empty seem like a weird special case. I'd prefer postfix macros before this. Props for outside-the-box thinking though! I just realized I kind of like the idea of await being confusable for a method. Isn't that actually kind of a useful way to think about it, most of the time?
I would make the support binary a separate crate checked into a subdirectory of your project. As far as I know, the `cargo test` command never builds any binaries. When shelling out to local binaries happens to work in a test, it can be because a previous run of `cargo build` left some binaries in the `target` directory, but that means you have no guarantees about what commit those binaries were built from. In my tests, I end up [explicitly shelling out to a `cargo build` command in the test itself](https://github.com/oconnor663/blake2b_simd/blob/0.4.1/b2sum/src/test.rs#L10-L15). And once you're explicitly shelling out, there's not much downside to making it a separate local crate; plus you can give do whatever you want with the dependencies.
Await macro is the only one I like out of the current options on the repo. Are there any reasons not to stabilize the await macro now and then maybe add something else in the future, like what was done with `try!` and `?`?
Are you sure that `cargo test` doesn't build binaries? [This post](https://users.rust-lang.org/t/cargo-how-do-i-make-a-integration-test-a-depend-on-binary-b/9821/2) makes it seems like it does, and have integration tests which shell out to the main binary, and I don't think I've ever seen them unexpectedly pick up the wrong binary.
I'm not sure the second one can happen -- without a lifetime constraint on the argument to `op`, I don't think the closure can keep the `&amp;mut` anywhere. Otherwise APIs like scoped threading wouldn't work either.
Honestly, I like the `await!` macro the best. But if we need promote `await` to a keyword, it looks like `prefix-mandatory` is the way to go. I dislike the implicit magic of all of the other options.
Oh wow I was totally wrong! I guess I just never tried this with integration tests. (I had run into the binaries-not-getting-built issue before because I only had unit tests.)
But it's not being highlighted as a keyword. I'm sure that would help a lot.
Yep, you are right. I wasn't thinking clearly and forgot rayon's for_each blocks the current thread.
Not for me. It takes a few scans for me to find the double right parenthesis to know what is being awaited.
Doesn't pass "the principle of least surprise" for me.
&gt; It's true it still happens, but the goal is it wouldn't. Agreed.
It sounds like you just want an enum?
üëé@await
Nice explanation. Can I understand \`struct\` meta-data is stored in stack whereas the data the \`filed\` holds stored in heap?
It would at least be possible to map each variant to a const "discriminant" using macros. enum-map already does something like this to map enum variants into array indices.
Data goes on to the stack regardless of being an array or a struct or anything similar. _Until_ you do a heap allocation, also known as "boxed" data, and that is on the heap. Internally a Vec is a pointer to the start of the allocation, the capacity of the allocation, and the length of how much of the allocation is currently used. The pointer and the two tracking values are on the stack. The data _pointed to_ is where the actual content of the Vec is, and that's somewhere in the heap.
I prefer syntax that's recognizable even if not highlighted. Not everyone has good color vision.
This example game might help: https://github.com/Skytrias/everpuzzle
These examples really made my solidify my dislike for the prefix syntax, it's really jarring and doesn't fit with the rest of the syntax at all The postfix syntax seems far more Rust like. I get the impression that people prefer the prefix syntax since that's what they're used to from other languages, but that doesn't seem like a good reason to make the syntax inconsistent
Postfix in practical code is very difficult to read. Control flow should be easily read from the left, especially in Rust, where we have `if` expressions instead of a ternary operator.
You're not wrong, this is definitely unnerving, and it's a good idea to be super careful. That being said, this problem is not unique to Rust. Basically every package management system that offers pre/post-install hooks has a similar problem. This includes Python/PyPI/Pip, Javascript/npm, and even Ubuntu/Debian .deb packages.
How are magic fields/methods more consistent with rust syntax than a new keyword?
Oh, I was only speaking for myself. I think that for me I would prefer prefix await over postfix definitely, I don't have any special insight on the matter, however - just surprised by the legibility after reading about the matter and how lackluster the survey results made the solutions seem :). I'm pretty comfortable with parsing syntax and symbols however - so I think it would be in everyone's best interest to put their accessibility hats on and think about people on the opposite side of the spectrum who might struggle with dyslexia or other feature sets that would benefit most from legibility improvements.
Syntax highlighting isn't limited to colors. It can also use bold and italics. Perhaps the argument is more about things being recognisable without any syntax highlighting at all.
After looking at that, I definitely prefer the block-like await-mandatory.
If the barcode scanner can produce a 2D image that you can process with this library it should be possible.
Yes, that's the core of the argument. Also, often you can't choose the highlighter, e.g. on GitHub.
A list of requirements was posted here: http://exple.tive.org/blarg/2019/05/03/goals-and-constraints/ I opened a reddit thread here: https://www.reddit.com/r/rust/comments/bki94p/goals_and_constraints_for_ircmozillaorg/
By the way, just wanted to ping you that a list of requirements was posted here: http://exple.tive.org/blarg/2019/05/03/goals-and-constraints/ I opened a reddit thread here: https://www.reddit.com/r/rust/comments/bki94p/goals_and_constraints_for_ircmozillaorg/ Please note that threads of /r/rust will probably not be read by the relevant Mozilla personnel, so going through the channels listed in the blog post will probably have most impact.
Please note that threads on /r/rust will probably not be read by the relevant Mozilla personnel, so going through the channels listed in the blog post (e.g. the IRC channel) with relevant feedback will probably have most impact. Also, as someone wishing an open alternative to succeed, please be realistic on their needs and don't try to debate them away, instead focus on how your proposed solution fulfils them.
Rust supports two types of testing * Unit tests, which are with the code and intended to test that.. unit of code. These are especially useful when you need to test private functions/structures/etc. * Integration tests, which go in the `tests` directory next to `src`, which only have access to your crates public API and behave like any other crate using yours would.
Oh wow! Just as I published the first version of my `quirc` rewrite in [Rust](https://github.com/WanzenBug/rqrr)! Looking at your code, it looks way cleaner then my approach, which still has a lot of artifacts from the C translation in it. Great work! I noticed in your readme you give the tip to keep the image size small. I wonder if there is a posibility for improvement there. I will have to test my own implementation now :-)
`\^_^` I just fixed one of my own on another thread.
&gt; what happens in reality is that Vulkan can't be bolted on something with great benefit. It has to be deeply integrated into your pipeline, affecting the internal abstractions and likely the end user API. This was my instant reaction as well. Un(?)fortunately, it's really not feasible to reap the benefits of VK/any next gen api without designing with those APIs in mind.
Thoughts after looking at the branches: * I thought I was a prefix sugar fan, but it requires too much mental state-keeping when reading, especially when dealing with method chains. * I thought I was OK with postfix, but in real code, they're too magical--pretending fields/or methods that don't exist. * TL;DR: prefix macro and/or prefix-mandatory preferred.
I'm for `await { ... }`
^^^^_______^^^^^
Pretty nice :-). I kinda' wanted to work on something like this, inspired by https://github.com/daleroberts/bv. I suppose GDAL would be a bit heavy for your app, though.
- for command line parsing, look into `structopt` - for `whoami`: look into the `parsswd` or `users` crates - to trim whitespace at the end of the line, use https://doc.rust-lang.org/std/primitive.str.html#method.trim_end - to get the uptime, try `/proc/uptime`; take a look at `man procfs`, it's pretty useful, also the `chrono-humanize` or `humantime` crates - for the kernel version, `/proc/sys/kernel/osrelease` might be useful - you can use the `dirs` crate to get the home directory - you already know how to retrieve the `EDITOR` env var, so you can do that - for the shell, the two crates I mentioned above might help - use `request` or `hyper` for the HTTP request - there's also a `mpd` client crate and one for `libalpm`, but I've never tried them
One helper that I would find useful is a `cargo` tool/plugin that tells me what features my dependencies have enabled, as I might want to disable them.
I think a postfix version is definitely "more rust", in that it works really well with method chaining and the try operator, but I think the specific method and field accessor syntaxes are very not-Rust, just because of how surprising they are given most people's expectations of what a method or field should be able to do. Which essentially leaves the operator, or the postfix macro. The operator, for me at least, doesn't play well with the try operator, in that two sigils next to each other just look a bit weird. I was originally opposed to the postfix await macro because it would have been implemented internally as opposed to as a genuine macro, but then someone pointed out that this is true for a number of other macros as well, so maybe it's not a terrible idea. Although I think my favourite idea is still to standardise the prefix notation first, as something that people can understand and use coming from other languages, and to get the ball rolling, and then add postfix macros as a general feature. As long as the syntax exists, postfix macros can easily turn any prefix-based syntax into a postfix macro, which means we can implement the isomeric Rust chains then.
See also https://github.com/rust-lang/cargo/issues/5931.
I know you're aware of it, but it's unfortunate that https://github.com/rust-lang/rfcs/pull/1615 got blocked like that.
I think you should rename the binary to something like "rsfetch" since "fetch" already exist.
Oh wow... thank you for all of this! I'm gonna get to work on this right now.
thanks for the ping! had missed this.
Is that a happy spider? :P
Having seen all the discussion about await syntax (especially pre- vs post-), it feels to me more of a philosophical preference than anything else. People from the C/Go style of "explicit and visible over expressive and functional" prefer the prefix, people from the Ruby/Haskell style prefer the postfix. Not unlike the old `try!` vs. `?` discussion. Being in the middle in terms of both syntax and purpose, Rust is perpetually torn between the two sides. One side will win of course, but I don't think think there can be a reconciliation from the side that didn't win, just grudgy acceptance.
Yeah. The PR author hasn‚Äôt replied in a year, so I think there needs to be someone picking up the torch and doing a new PR.
Yeah, I just found that out. I was stuck between choosing "rsfetch", "vfetch", or "fetch-rs" for the new name.
The requirements look to prioritise usability, accessibility, user empowerment and community management (ie moderation) - which makes a lot of sense. It feels like the FOSS aspects have taken a bit of a back seat, and some ways the requirements look to be a bit of a rebound away from IRC, but hopefully folks will be able to see that these days it‚Äôs possible to have both great usability and a11y and community quality whilst still being open source, open standard, and even an open network :)
While it is easy to create sprites with e.g. 2, 4, 8 written on it and background with different colors like in this repo, I think it'd be much cleaner design if Amethyst had shape and 2d text rendering abilities (world space, not UI), and would be more interesting to show since we already have this repo for a sprited-puzzle game
Same for me. That's why out of these alternatives I liked prefix-mandatory the most. There's often not that much curly braces in expressions, so it stands out clearly. Maybe postfix macro would be ok too, but I'm not sure it wouldn't have the same disadvantages as other postfix solutions. That is being easy to miss awaits while skimming.
There have been thoughts about mitigating that. For example, Crater prohibits network access at build time. It could be made more generic and enabled by default, see https://github.com/rust-secure-code/wg/issues/29 if you're interested
&gt;There have been thoughts about mitigating that. For example, Crater prohibits network access at build time. It could be made more generic and enabled by default, see &gt; &gt;https://github.com/rust-secure-code/wg/issues/29 &gt; &gt; if you're interested thanks
The team already ruled out sigils
Nothing prevents your highlighter from giving special treatment to well-known macros. Most highlighters already do that for struct names. Almost always, `String` or `Vec` have a different colour compared to whatever my structs are named.
If you one to use one exact version, you can use the equality sign [Cargo documentation](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html): dep = "= x.y.z" The problem you have is that wasm-bindgen-cli requires Rust edition 2018 (no extern crate anymore which is why you get those errors). Rust editions can be mixed, meaning you can use any crates together but they require to have you Rust version 1.31 (2018 edition release) installed. Newer crates will have 2018 editions as cargo will add this by default in newer versions. The issue you're running into is known as that we cannot specify the Rust version for crates which is annoying because that has to be tested in CI and written to the README. There should be a post called Cargo in 2019 where this is shortly mentioned I think.
If you are really paranoid, you might want to forbid write access to the file system as well. Otherwise a build script could trash all your hard drive.
That not a security breach - -
In order to avoid the allocation, the compiler needs to prove that the stack frame can't move once it's created. And really the only way for that to happen is for you to consume the entire coroutine in the stack frame that it's created, ie like a generator. For the case where you start a coroutine that suspends until some I/O is done and then put it into a collection to be polled later, I have a very hard time imagining how the allocation would be elided. Although I'd love to be proven wrong.
No one said it was a security breach
If you think that reminding others that there is a risk here is paranoid, then I have nothing to say.
Is there a difference between marking a variable static and making a const variable with static lifetime?
`await` using TLS.
Very cool! What‚Äôs performance like? Any notable limitations?
Statics always have the `'static` lifetime, and they have a fixed memory address. Constants on the other hand are usually inlined when used, the variable doesnt actually exist in code and has no fixed memory address. They can only be constant expressions and also have the `'static` lifetime.
And if no open-source project meets the requirements *now*, at least with an explicit list in hand their developers can attempt to close the gap.
Is it too much for performance to run a game with svg images as sprites? Have you seen any limits around max svg elements in scene?
Could someone explain to me what this tool does? "Info fetch tool" could mean almost anything. Maybe `fetch` is a known unix utility and everyone except for me knows what it does, but I guess some more information would be nice \^_\^
But this risk is present _any_ time you run other people's code on your computer, as far as I can tell there's nothing about build time here? If people are security conscious at run time then they will be security conscious at build time, if they aren't security conscious at run time then telling them to be security conscious at build time is only closing off a tiny portion of vulnerabilities. Unless I'm missing the point of this post (which could very well be the case), it feels like we're paying attention to the wrong things.
Is this on [crates.io](https://crates.io) at all? I was looking for something almost exactly like this and would love to start using it.
Sorry, I should elaborated. I'll edit the post after commenting. What the tool does is display info like user, uptime, distro, kernel, etc. It is essentially a fast and (kind of) minimalistic neofetch-esque tool.
A bunch of quick, unsorted suggestions: - Use `rustfmt` to correctly format your code (this includes: using spaces and not tabs for indentation) - Make sure to use correct naming. `print_defaultlogo` and `printlogo` should be `print_default_logo` and `print_logo` (just to name a few) - Use proper error handling. I see a bunch of `expect` calls around the code when opening files does not succeed or something like that. As a first step, you could rename your `main()` to `run()` and return `Result&lt;(), String&gt;` from it. Then, create a new `main()`, call `run` in it and print the error messages, if an error occurred. Then at least, users wouldn't see panics. Panics are not something the user should ever see. But you can do much better than `Result&lt;(), String&gt;`. You can use one of the error handling crates, like `failure`: then you can return `Result&lt;(), failure::Error&gt;`. This error type can store a chain of errors which makes it possible to output something like "Could not determine product name. Caused by: no permission to open file." I can't fully explain good error handling in this comment, so read some of the docs! - Several things about reading CLI arguments. - `clap` is already a good choice, but I would recommend `structopt` for several reasons (it uses `clap` under the hood, but has a better interface IMO). Most important thing: it automatically converts the clap args into the correct type. In your case, you have a lot of bools and you should deal with them as bools, not as `String` as you do right now. - Furthermore, use the "default" feature of clap/structopt. Then you can avoid all the `unwrap_or` lines and the user even sees the default. These are the points that immediately caught my eye. I hope it doesn't sound too negative, I just don't have a lot of time :P Good on you for asking for a code review!
I see! Thanks!
I can't really blame them with the amount of pushback that they received from people close invoiced with the language.
&gt; I hope it doesn't sound too negative Not at all. I appreciate that you went through my code and pointed out the various things that could be done better. Really, thank you for being detailed and thorough in your explanations in what could be done better. Because the more things I know I can do better on, then (hopefully) the better I can become. &gt; Good on you for asking for a code review! It's nothing really. It's just that you can not improve without knowing the various flaws or things that could be done better. I could pretend like my code is perfectly fine the way it is, because "Hey it works, so no need to change it!". But if I did that, I would continue coding in the same way that I am now and I would never grow as a programmer. Also, I'm sorry about my post being vague. I was really excited to share what I made, and during the excitement I forgot to elaborate on the important details.
&gt; "Varisat is a CDCL based SAT solver written in rust. Given a boolean formula in conjunctive normal form, it either finds a variable assignment that makes the formula true or finds a proof that this is impossible." For those of you who didn't feel like going to the site.
\&gt; It's nothing really. It's just that you can not improve without knowing the various flaws or things that could be done better. I could pretend like my code is perfectly fine the way it is, because "Hey it works, so no need to change it!". But if I did that, I would continue coding in the same way that I am now and I would never grow as a programmer. &amp;#x200B; This is exactly the attitude I love to see. However, I feel like many many people just don't give a shit at all. I know a disturbing amount of people in important programming/computer science positions who do not care about code quality at all. Therefore, I want to make sure to encourage reaching out for feedback. &amp;#x200B; \&gt; Also, I'm sorry about my post being vague. I was really excited to share what I made, and during the excitement I forgot to elaborate on the important details. &amp;#x200B; No problem!
Thanks. About the first one: right, I guess I should have made `pub trait ParallelIterableSet` `pub unsafe trait ParallelIterableSet` instead. Whoever implements `ParallelIterableSet` for some type `T` has to be sure that `T` indeed implements a set, i.e., cannot yield duplicate items. I was mostly worried about the absence of, e.g., any `std::sync::atomic::Ordering` in my code. Which part of the Rust language enforces that memory writes before the call to `try_for_each_by_index` are completed before `try_for_each_by_index` starts, and that any writes during `try_for_each_by_index` are synchronized by the time `try_for_each_by_index` returns?
&gt;&gt; or finds a proof that this is impossible. Is it always possible to find a proof that is shorter than enumerating all possible variable assignments, and noting for each one that it does not satisfy the formula?
Please elaborate. I too, was working on that tutorial and It didn't come to my mind as to why/how const generics would be important in that case.
I think this is precisely what cargo [crev](https://github.com/dpc/crev/) is meant to solve?
The story sounds similar to a 3D game - you can draw a decent amount of polygon with modern GPUs, but at some point you would start to use textures as a compromise. &amp;#x200B; If the display size of the sprites changes, it makes sense to draw them as vector each frame. Otherwise, just render them to a texture beforehand.
With the techniques currently implemented in Varisat, which are justified by resolution, there are known families of problems that require exponentially large proofs. (And you can always find an exponentially large proof for any problem by doing what you described.) One such family are the formulas that encode the pigeon hole principle. You get such a formula by taking a n x n+1 grid of variables and adding constraints to force exactly one variable to be true in each row and in each column. There are techniques used by some SAT solvers that go beyond resolution and are for example based on extended resolution (I also plan to add some). Extended resolution allows short proofs of the pigeon hole principle. I'm not really sure which lower bounds exist for extended resolution or other proof systems that are more powerful. If NP != co-NP there must be super-polynomial lower bounds for any efficiently checkable proof system. Existence of a short proof also doesn't mean the solver will be able to find one. It depends on a lot on how good the heuristics work. The good news is that for a problem that is quickly solved by a SAT solver, the corresponding proof will also be short. So if a SAT solver can be used successfully at all, which is the case for many practical problems, the result can also be verified.
&gt;Is it always possible to find a proof that is shorter than enumerating all possible variable assignments, and noting for each one that it does not satisfy the formula? In general, I do not think so. SAT is NP-Hard. I think that is the difference between NP-Complete and NP-Hard. In practice, it proofs tend to be short.
Basically this allows you to do: const MAJOR: u32 = pkg_version_major!(); const MINOR: u32 = pkg_version_minor!(); const PATCH: u32 = pkg_version_patch!(); I've wanted this a surprising number of times, so here goes. The only other way to access the package version is via `env!("CARGO_PKG_VERSION_MAJOR")`, and then you only get a string, not an integer that can be put in static data.
I don't think there is something wrong with it. It is pretty convenient to be able to download something at build time, and I think you should have a habit to audio code of libraries anyway. So no problem per se
Hang on. SAT is an NP-complete problem (and every NP-complete problem, by the way, is NP-hard), wouldn't you agree?
I was going to say the same, it actually makes a lot of sense I the Rust ecosystem for it to stay a macro. Making it a keyword seems to be making it more complicated and I'm not sure I understand the benefit other than to say we have an await keyword.
It's not really possible to answer your question without knowing more about what you're trying to do. Are we talking flappy bird or super hexagon or something more?
Trait implementations are additive. You can't exclude State&lt;T,T,F&gt; by requiring some `SomeFalse` for `(T, F)`, because someone can always implement `SomeFalse` for `(T, T)` in the future and that would satisfy the constraints on both impls.
It's a huge use case for qr readers :)