This was a fantastic explanation of HKT!
I feel Monads would be helpful in Rust, at least to ease error handling (and avoid code duplication).
I am just learning rust, do you have explicit control of when and what heap is used for allocations? Otherwise you can't really build an RTOS. But, getting compile time guarantee of safety instead of using the mmu could be huge performance win.
Hmm.. I'll have to go through everything again, but, out of the [two code snippets][1] above, I much prefer the second snippet to the first snippet when developing a web application. I guess it's a matter of taste :) [1]: https://www.reddit.com/r/rust/comments/5q2l44/what_librariestools_are_missing_in_the_rust/dczuoga/
It's actually an affine type system.
Perhaps a simple hyperlinked annotation indicating that, while the new book is under heavy development, this section is in a usable state?
Hello, this is the wrong subreddit. You're looking for /r/playrust. Good luck!
Hmm... I'm skeptical that it makes sense to end the lifetime of one field of a larger object while continuing the lifetime of the larger object (the trie). 
I think if you were the kind of person who thinks that tackling a RTOS project is within their capability, then sure it will be a practical project. Rust places little runtime overhead and none if you opt-out (e.g. you can turn off runtime bounds checking of array access if you want.. perhaps at your peril). You will need to make sure that your platform has an LLVM backend (unless you also want to write an LLIR compiler for your target!)
Could someone please flesh something out for me.. this sentence in the introduction took me by surprise &gt; I’ve been looking for a way to correct a number of flaws and shortcomings in the current implementation, not the least of which is that it’s performance is not that great. Is this referring to the compile-time speed or runtime speed or both? Answering own question perhaps, but right at the end there is a comparison with MIR, so I'm assuming compile-time speed
&gt; Hmm I think it might have had something to do with the fact that serializing fixed size arrays for sizes larger than 32 had to be implemented by me? That's not related to this; that's just the lack of const parameters (so you can't have a type `forall&lt;n: usize, T: type&gt; [T; n]` (not Rust syntax obviously). &gt; It might also have been something else, could have been something to do with wanting code to work regardless of whether I was using Option or Result. We want to make `?` work with both types which should ease this problem. Though I think that suggests there might be an issue with your code where semantically you have a `Result` with only 1 error case, and you are using an `Option` instead of a `Result` with a unit struct for the error type. (This doesn't impact the compilde representation at all, but I think using the result type does make your intent clearer)
&gt; Not bold and italic things. Given that your comment used a lot of bold text I assumed that is what you meant. There's nothing to quote? I guess you can add things like notes and stuff, but those make more sense in full-length books IMO. This is a smaller book, as books go.
Thanks!
Fixed, thanks!
Thanks! Your solution works with my macro too, which is great - but makes we wonder if our macro system is unhygienic w r t lifetimes? [Code here](https://github.com/diwic/dbus-rs/blob/master/src/arg/msgarg.rs#L146)
Perhaps a `⚠ nightly only!` label?
When you write an operating system you have to write your own memory management, so yes you would have explicit control by virtue of being the one that implemented the thing.
It advocates the use of `for` when you wish to have side effects, which makes sense because iterators are lazy.
Very Welcome Steve!
Not sure you can compare them. C# is very easy to write. You get used to the fact that you just don't care and hope that GC does its job. In rust it's opposite - it's not language that does all the job, it's compiler that forces you to care about every single detail. Also, I had this project lying around for few months. It was just too tedious for me to work on. I don't know if I would have finished it any time soon if RLS didn't release. And last thing. I never thought I wouldn't miss breakpoints. I just don't need them anymore. If code compiles - it works exactly as I wrote it (except if I messed with glsl code and it crashes, while trying to compile on runtime) and it's beautiful. I do believe that rust should be next big thing in game development. It eliminates almost every problem that games constantly have. And complexity is very small price to pay for it.
Your repository is lacking a README, link to the documentation and release tags - but besides that this looks interesting!
Yes, I won't stop on what I have right now. Maybe eventually it will grow in little happy procedural planetary system. 
Seems like `flame` doesn't handle threaded programs. extern crate flame; fn main() { flame::start("print"); println!("Hello, world!"); flame::end("print"); let r = std::thread::spawn(||{ flame::start("thread print"); println!("Hello, world!"); flame::end("thread print"); }); r.join(); flame::dump_stdout(); } What is a good way to merge `threadlocal` data on a single thread? 
Strange, I think it *should* do that. I'll look into it.
Rocket is promising but it currently miss CSRF protection, so handling form are not fafe. In fact, it is not the only one, take iron, the only implementation I found is https://github.com/huin/iron-csrf-rs and is not on crates.io 
For another approach/shameless plug: I wrote a small library for this a little while back, [rust-lazy](https://github.com/reem/rust-lazy). It has versions of the `Lazy` type for both single and multi threaded uses, using ~~RefCell~~`UnsafeCell` and a custom synchronization primitive [`OnceMutex`](https://github.com/reem/rust-once-mutex) respectively.
`unsafe` is the key bit. If the C++ code had had a big "UNSAFE" warning, it would have attracted sooner. However here it's just regular code, business as usual, so it doesn't warrant more attention than usual. Our first thought (and avenue of investigation) was that we had a stale pointer to a disposed of object (wouldn't happen in Rust), it took some time to realize the issue occurred with objects fresh out of the pool, and we stared at the code for some time not seeing anything amiss. The memory is zeroed, the constructor doesn't override the field, why could we see anything else than 0? We couldn't reproduce in debug, and couldn't isolate the scenario in release. It occurred once every often (maybe 1%?). So our second thought was that we may have a synchronization issue (the pool is multi-threaded after all). The pool uses spin-locks, so we first checked the lock was taken for the whole concurrent part, then checked the memory ordering to ensure that the reads/writes were correctly ordered wrt the barrier. Didn't see any reason any thread would come scrambling over the memory at the same as the constructor, but well it would not be the first data race (another thing that wouldn't happen in Rust). Also, the pool is heavily used, and it only occurred with *this* specific struct. All others were fine. Puzzling... Reviewed the last changes. Didn't see anything. Finally managed to setup a good reproducer with a minimal number of threads; upon breaking all but our allocating thread are waiting on I/O locks. Systematically. The data-race idea is *really* unlikely at that point. Back to the drawing board. Checking the assembly doesn't tell much. It is zeroing the memory. Yet it's not zeroed according to the debugger. "Light bulb on" moment: wait, look at the offset for the zeroing and the offset for reading, it's reading way past the zeroing! Instrument the code with `static_assert` checks on the struct sizes. Sure enough, it's only zeroing the base and not the derived. Even though the first `memset` takes the `Derived` size. Paint puzzlement on the faces of the audience :(
&gt; Btw, I'm not sure Rust can claim to avoid deadlocks, and I believe you're still going to need to be disciplined to make threads reliable. Rust doesn't prevent deadlock, livelock or event concurrent updates, only data-races. &gt; if you haven't applied discipline the whole way through your development, you're going to regret being multi-threaded Yes, most problems we've had come from attempting to be *more* parallel. When two functions expect to run on the same thread, or an object expects never to be shared, and new changes suddenly introduce multi-threading, it's inevitable that there will be issues in C++. In Rust, the `Send` and `Sync` bounds would catch the issues. &gt; I hope you find it, but trust me - a lot of experienced C++ programmers look at memory errors in the same light as a paper cut. They can be unpleasant, but after you've had a few, you get better at avoiding them. I consider myself experienced and I don't see them as papercut. I see them as risk. I don't encounter them often, but each time I can't shake the feeling that for each one I fix there's another two lurking and bidding their time. My team has got to deal with complicated and rapidly evolving specifications, we've got to squeeze the last ounce of performance out of the hardware, all the while juggling with loaded shotguns. We've got extensive test suites and safety checks, in multiple layers, and we keep adding more, but those errors are inherently finicky and keep finding their ways in production despite our efforts. And for software which juggles millions in microseconds, it's not a comfortable thought. 
What is the reason for separating `new` and `get_or_create`? Intuitively I would have expected something like: impl&lt;T: Sync&gt; Lazy&lt;T&gt; { fn new&lt;F: FnOnce() -&gt; T&gt;(f: F) -&gt; Lazy&lt;T&gt;; fn get(&amp;self) -&gt; &amp;T; } I find the idea of having a deferred initialization somewhat annoying since it means that calling `get` may fail... I don't deny it might be useful to separate initialization sometimes, but it seems like a less common usecase, so I would have another `DeferredLazy&lt;T&gt;` type for it, rather than have all clients pay for the API complexity even when they don't need to defer.
It was the first thing I looked at because I encountered the same problem in my codebase and I wanted to see how flame solved it. https://github.com/TyOverby/flame/blob/master/src/lib.rs#L399 and https://github.com/TyOverby/flame/blob/master/src/lib.rs#L466 Essentially it seems to just print out the spans of the thread where `dump_stdout` was called.
Heh, that's awesome.
Clang/LLVM have a UB sanitizer nowadays that's super helpful.
If it helps, the code is here: https://github.com/jamespharaoh/rust-output/tree/channel_recv_panic
Also FYI just tried this with nightly and getting the same error.
Note: this is the function in question https://doc.rust-lang.org/src/std/up/src/libstd/sync/mpsc/mod.rs.html#809
burntsushi, I've spent some time thinking about some of this this thread and aliasing rules. I would be nice to have have definition or tools in unsafe (besides memcpy) for working with pointers that break traditional strict aliasing rules. Right now it's really hard or impossible to do that in C/C++ (there's the `-fno-strict-aliasing` used by Linux, but not only) It would be nice if was possible to do that in unsafe Rust in a defined way (even if it's "platform specified"). There's clear real wold use cases here working on databases, filesystems, ondisk-memory-gpu data structures (where there's no serialization), DMA, iomap devices. Also, going forward pmem is already on the horizon when you're going to have persistent data structures that are not always mapped in the same location (app / system restart) that will need manual pointer relocation. IMHO this would be a nice arrow in Rust's quiver for this work that C/C++ cannot guarantee.
I agree that having it labeled as `unsafe` is a good thing. But it should still attract attention in a C++ codebase * `g++ -Weffc++` tells you that the members should appear in the initialization list * `cppcheck` warns about a member variable not being initialized in the constructor * `clang++ -fsanitize=memory` warns if you try to read from `DerivedMeset`'s members
do you wanna build an RTOS? :3
Isn't there a rust implementation that compiles to machine code without the use of LLVM though?
The big question is, do ATMEL and PIC chips support LLVM?
Thanks for your advice! Actually it's using SQLite so if the initialization fails, the program is unlikely to be able to recover. But yeah, I'll take your advice when network gets involved.
I almost threw away the code I’d written when I realised it needed admin on Windows; the relaxing of that rule is the only reason I decided to go ahead and publish it. I think I’ll write a proper RFC for integrating this when Windows 10 Creators Update gets stable. Remember that there are a minimum of *three* added functions: it’s not just `symlink_file` and `symlink_dir` (though the former is technically supplied by `soft_link` so it *could* just be undeprecated); `remove_dir_symlink` is also required. (`remove_file` will do for `remove_file_symlink`.)
/u/seanmonstar What do I need to say to you, to convince you that exposing a sync interface is a bad long term decision? Meanwhile, if you do make a sync interface, would you please not name one "defacto-default"? i.e. Calling them: `reqwest::AsyncClient` and `reqwest::Client` implies that the sync client is the default and Async is somehow special and warrants investigation. `reqwest::SyncClient` and `reqwest::AsyncClient` should also suit the requirements in your last post.
`memory` is useful, but you need clang for it. I'm curious what came of this by the way. I guess you might be able to use something like T* t = reinterpret_cast&lt;T*&gt;(ptr); T::create_in_zeroed_memory(t); return t; instead of using a constructor if you were _very_ careful. Is this optimization worth keeping?
Oh wow that's a nice footgun. Thanks for clearing that up!
That would mean the Lazy&lt;T&gt; has to store the FnOnce within the struct, doesn't it? I guess you could have an enum like LazyState { Uninitialized(FnOnce), Initialized(T) }
Hmm. I feel like with removal, the "auto" option is better. You don't have an issue with the destination not being present in that case (all it needs to look at is the symlink itself), you don't have choose between a weird inconsistency between `remove_dir_symlink` and `remove_file` or adding two new new ways to remove symlinks that you have to remember to use appropriately. Yes, it means one more stat on Windows to determine which type it is before removing it, but there are precedents for that, where there are some filesystem APIs that require an extra stat and some that don't depending on the platform (for instance, when iterating over directory entries, different platforms provide more or less information in the directory entry itself). And that stat would only ever fail, I think, if the underlying removal would fail (unless Windows permissions allow you to be able to delete a file but not allow you to stat it). But, I am open to discussion on this, which I suppose can happen when you write the RFC.
Yes, which might require boxing of course.
`fn(&amp;mut T)` is a function pointer to a function that takes a `&amp;mut T` as an argument. You can't use a closure in place of a function pointer, but you can make a normal function and use that. You can also pass a method, but it must be accessed like `Foo::bar`. Function pointers are showed in the book [here](https://doc.rust-lang.org/1.10.0/book/functions.html#function-pointers).
It'll be `$crate::macro_defs::Cell` with that structure.
&gt; Also, move constructors just slow down things like vector reallocation since you need explicit calls everywhere. This is not necessarily true. Many move constructors simply copy the pimpl pointer from the source to the destination and set the source to null. The move constructor for placement new is frequently inlined, the destructor can be inlined and sees a nop for a null pointer (which the compiler omits), and it all happens about the speed of a memcpy. It's nice that Rust can always use memcpy for moves, but I think we'd need to see some benchmarks before claiming that move constructors necessarily slow things down. 
Curious if anyone knows whether std::io experimented with anything like this in the past?
Different problems need different solution. Perhaps consider yourself lucky that you get the time to aim.
Also From
Nice! If you need a really accurate reference for the 6502 checkout visual6502.org. They developed it by taking high resolution photos of the layers in the CPU and then building the network of transistors based on that and then simulating the flow of electricity in the transistors. This allowed them to confirm why/how the undocumented instructions work.
Perhaps consider yourself undisciplined and reckless if you don't take the time to aim before firing a shotgun.
I'm not sure about Rust's story on asynchronous programming and concurrency. Nescc has a neat scheme for this that I'm not sure Rust can compare to.
Released my command-line utility for Matlabbing Rustaceans (I'm sure there are _dozens_ of us!): [cellsplit](https://github.com/durka/cellsplit). It's one of those tools that I wrote for me, to get my research done by the deadline, and finally got around to sanding down the rough edges in case it might be useful to anyone else. Matlab supports writing scripts in a "cell mode" which is sort of like an IPython notebook, but you just split a script file into cells by writing specially formatted comments, and then you can run one cell at a time from the Matlab editor. You can also "publish" such a script and it formats the code and results more like a notebook. I have two problems with this: I like to write code in Vim, and I like to run my machine learning code on remote servers where I can't use the Matlab editor, but cell mode is really useful for iterative development. As an aside, Matlab has a nice feature where you can set it to break into the debugger on any error, but it can get wedged when that happens during execution of a single cell. Anyway, cellsplit solves the problem by exploding the script into a sub-script for each cell, so you can run each individually. You can even edit the sub-scripts and have them reassembled. I'm thinking about ways to integrate it with editor plugins, so you can have the full cell mode experience without using the Matlab editor at all.
rust handles async quite cleverly imo, so I don't think that's gonna be much of a problem. The biggest issue is writing a low-level scheduler to curate that concurrency
&gt; This is anecdotal, but I've had issues with move ctors on large vectors turning up in profiles before. I've also had issues where significant time was wasted in the default constructors of small objects that were about to be overwritten from a file or socket. Honest question: can Rust elide those? 
You have perfect control although, for low-level things you'll need to use `unsafe` blocks. Ideally, you'd abstract them. The abstraction for heap-allocated pointer in `std` is called `Box`.
It's not public because it's an absolute mess right now. I will definitely clean it up and publish it eventually.
I honestly think Go is a better first language today, but I'd love to see Rust get to the point where I can call it my preferred first language. 
In simple words function pointer is an alias to the function (simplifying things) and closure is function with entire context in the moment of creation (referenced or moved).
Looks like it's currently an [issue](https://github.com/rust-lang/rust/issues/30132), I am also not sure why this is!
I'll probably write a post about it on the subreddit. 
Footnotes don't seem to be working correctly? For example, if I click “notechars” in https://locka99.gitbooks.io/a-guide-to-porting-c-to-rust/content/features_of_rust/types.html it links to `#fn_notechars`, but the anchor has ID `reffn_notechars`. 
Wouldn't work, replace doesn't let you change the version for some reason. It would have to be an old-fashioned [path override](http://doc.crates.io/specifying-dependencies.html#overriding-with-local-dependencies).
Hmm... Devil's Advocate says that `AsMut&lt;[u8]&gt;` has no size-mutating methods like `mut Vec&lt;u8&gt;`, so having a `Write` impl for the former would lead to unexpected behavior regarding the need to keep an instance of the latter appropriately pre-allocated. So something like this: let mut v : Vec&lt;u8&gt; = vec![]; let bytes = File::open("foo.txt").unwrap().bytes().map(Result::unwrap).collect::&lt;Vec&lt;u8&gt;&gt;(); println!("{}", v.write(bytes.as_slice())); ... would always do nothing to the vector `v`. 
Well, sure, there will always be better-suited languages for specific problem sets, but I don't think Rust should have to fall back to unsafe code 99.99% of the time and Go really should have generics.
There's [a crate](https://crates.io/crates/strong_rc) that does just that. Quite recently published, too. Maybe we have a mind reader in our midst! It doesn't have `Arc` but I'm willing to bet the author would welcome that addition if you need it for your use case.
This shouldn't be an issue; if you want to not have std but want Vec, you can hook up an allocator and pull in liballoc and libcollections, and leave out the rest of std, for example.
Interesting. I opened an issue to convert Arc. It's probably more involved than Rc, because the standard Arc manipulates the weak count even for strong pointers, but hopefully it shouldn't be too hard to convert.
In many high-level languages functions and closures are pretty much one and the same. The reason Rust makes a distinction is that closures, unlike functions, can access/capture variables outside their scope (their enclosing “environment” or “context”). This has implications on how the function/closure gets stored in memory at a low level: whereas a function in rust is just a raw function pointer and usually takes up [8 bytes](https://en.wikipedia.org/wiki/64-bit_computing), a closure could capture an arbitrary amount of data from its environment and is therefore unlimited in size. Here's an example of what I mean by capturing variables outside their scope. This first snippet is perfectly fine: let x = 3; let triple = |y: i32| -&gt; i32 { x * y }; // a closure In contrast, this snippet is not allowed: let x = 3; fn triple(y: i32) -&gt; i32 { x * y } // a function (invalid) Another important distinction is that whereas all functions that take an `i32` and return an `i32` have the exact same type `fn(i32) -&gt; i32`, every closure has a *unique, anonymous* type (“Voldemort type”). That would make it seem useless, if not for the fact that all closures that take an `i32` and return an `i32` implement a common trait\* `Fn(i32) -&gt; i32`. The `Fn` trait unites the closures together (as well as functions!). Rust's way of handling closures and functions does introduce a complexity though: the fact that every closure is its own unique, anonymous type means that you can't expect to store them inside an array, which requires a single type. The solution here is to make use of trait objects, which allows different types that share a common trait to reunited into a single reference type (possibly boxed). \* I'm a bit simplifying here, there are 3 separate traits `Fn`, `FnMut`, and `FnOnce`, in order of decreasing flexibility to the caller but increasing power to the callee. `FnOnce` can be called only once (and the closure gets consumed in the process), `FnMut` can be called as many as as you like but requires exclusive control of the closure, whereas `FnOnce` can be called as many as you like without exclusive control of the closure.
It seems like you can do `as_mut_slice` on the Vec reference: https://is.gd/4VgJGO
You can find a variety of perspectives captured here: https://brson.github.io/fireflowers/ 
I don't believe it is a bad long term decision. It turns out that there are some classes of applications where asynchronous programming is just a hindrance. Even the async client in a sync fashion wouldn't necessarily be as easy as `client.get(url).wait()`. There's complexity there which depends on what thread is driving the reactor. And, some just wish to be able to use the `std::io::{Read, Write}` traits. Seems pretty easy to provide this. I do agree with the notion that having one be 'blessed' as the default `Client` could be setting the wrong tone. It seems feasible to rename the sync client into something different, with a `#[deprecated]` attribute on a type alias of `reqwest::Client`. Something like: #[deprecated(note = "renamed to SyncClient")] pub type Client = SyncClient;
Some more relevant links: [r/rust: Why Should I Use Rust?](https://www.reddit.com/r/rust/comments/4l44z3/why_should_i_use_rust/) [Stack Overflow 2016 survey: Most Loved Languages](http://stackoverflow.com/research/developer-survey-2016#technology-most-loved-dreaded-and-wanted) [Dropbox: Real World Comparison of C to Rust](https://blogs.dropbox.com/tech/2016/06/lossless-compression-with-brotli/) [OneSignal: Using Rust for a notification delivery service](https://onesignal.com/blog/rust-at-onesignal/) [Friends of Rust (Companies using Rust)](https://www.rust-lang.org/en-US/friends.html) I could write about my own experience with Rust, but I think it might be more interesting to see these things.
I'm sorry. I am a fan of Rust but that web page is very thin on content and very too thick on self-praise.
I am a fan of Rust but much of those show only popular opinion and industry usage which do not indicate very much. For example, PHP is widely considered very popular. However, those in the know consider PHP very depressing instead. Industry usage is not a measure of programming language value but instead a measure of human perversity.
I think you're correct, that industry usage is not a measure of programming language value. Unfortunately, I'm not sure how to measure the value of a programming language in a scientific way, and after reading through so many of these discussions about language X vs language Y, I think everything I have to say has pretty much been said before.
I am wondering if a automated tool is possible for C/C++ to Rust. Go team has done it for [python -&gt; Go](https://github.com/google/grumpy) recently and earlier C -&gt; Go when Go compiler was ported from C. 
I'm having some trouble with error handling. I'm currently trying to use the library rusqlite and I'm deliberately causing an error when opening the connection. The error I'm currently getting is `SqliteFailure(Error { code: CannotOpen, extended_code: 14 }, Some("unable to open database file"))` I can print exactly the error code, but I don't know how to check which error code it exactly is. Error: Error { code: CannotOpen, extended_code: 14 } Error code: CannotOpen The code to get the error code is match err { ConnectionError::Rusqlite(SqliteFailure(err, ..)) =&gt; println!("Error: {:?}\nError code: {:?}", err, err.code), _ =&gt; println!("Ha ocurrido un error inesperado"), } I was able to found that the type of the error code is `libsqlite3_sys::error::ErrorCode` but I don't know how to import or try to match that type. I tried with `extern crate libsqlite3_sys; ``use rusqlite::libsqlite3_sys;` `use rusqlite::ffi;` And I found that rusqlite has a directory called `libsqlite3-sys` at the same level of `src` and they import it with `extern crate libsqlite3_sys as ffi;` So, how can I compare the error code? With the extended_code? Because I would prefer to use the Error code provided by sqlite, but don't know how. Edit: I changed it to this match err { ConnectionError::Rusqlite(SqliteFailure(err, ..)) if err.extended_code == 14 =&gt; { println!("No ha sido posible abrir el archivo.") }, _ =&gt; println!("Ha ocurrido un error inesperado"), } But I'd prefer a better way of handling it.
I've uses Erlang for a month and Rust for a few years. Some of the following opinions will not be popular on this sub: For a distributed application, at least the parts that are network-centric, Rust is not a good fit. This is partly because the libraries are incomplete, and partly because Rust's type system isn't much help. If you're hitting the network for everything, then everything's fallible, and you basically have to percolate everything to a top-level error handler to retry / fail, which is a PITA if you also want to do it inside iterator code. Not to mention Rust's type system can't help with avoiding common distributed computing pitfalls (or at least nobody's figured out a way to do it). Where I would pick Rust over Erlang is if the performance difference matters. Any optimization you or the BEAM can make to an Erlang app can be done in Rust, too (like arena allocation). Erricson uses C for their codecs; Rust would be a good fit for that, too.
Because Rust is the only systems language without a runtime that offers completely safe pointers and a more robust generic programming story than C++'s while also minimizing or eliminating its most painful issues (like having too many implicit features, and exceptions spaghettifying your control flow). If none of that is compelling, then (hypothetical) you shouldn't.
What about languages like ATS or using verifiers like Frama-C? Besides it is entirely possible to program in C++ with exceptions disabled.
You mean like [Corrode](https://github.com/jameysharp/corrode)?
Rust's strength isn't in any one of its features, it's the *combination* of features it offers. I don't have time to rehash what everyone else has said, but some of the things which brought me to rust personally were: * Functional programming constructs like the ones I prefer to use in Python or better * A C abstract machine so I can reason about performance more comfortably than Haskell * A community and tooling that presents "hobbyist programming to accomplish goals" as a viable way to get into the language. (ie. not as "big iron"-oriented as Ada and MISRA-C++, but with API stability and a library ecosystem that'll let me get useful stuff done and not have to babysit API changes forever.) * A type system powerful enough to ensure correct use of a state machine (C++ falls a little short) * Monadic error handling so I can have greater confidence that I've handled everything compared to exception-based error handling. * Easy to build and deploy * Suitable for replacing shell-scripts which I need to be extremely reliable. (must be able to produce small binaries which start quickly in addition to its security features) * A resource-management paradigm where I can't forget to free/close something *and* it's also viable for maintaining predictable resource load when managing things like file handles and network sockets (unlike GC). * All of this with a syntax that satifies my preference for a balance point between the verbosity extremes of Haskell and C++. * Must provide a net reduction in perceived effort to accomplish these goals * Provide an approximation of the high-level comforts of languages like Python with C++-like zero-cost abstraction. * The so-called "fearless refactoring" mentioned in https://brson.github.io/fireflowers/ which a very strong type system and good compiler errors bring. * The so-called "fearless concurrency" mentioned in https://brson.github.io/fireflowers/ which comes from language-enforced prevention of shared mutable state. * A type system which doesn't make it onerous to implement things like taint checking or unit annotations. * A happy medium between "trip over diamond inheritance" multiple inheritance hell and "reinvent the world" interface hell. * Easy cross-compilation * No C++-style "you are the package manager and half of the build tool" nonsense * No requirement for an IDE to make writing it viable (partly because I can't stand bloated UIs and I've yet to find a visually minimal, free-software tool which is also a suitably un-buggy IDE.)
ATS is call by value and does not support references. If you use the unsafe pointer types, you're on your own. People claim Rust is hard but, well, just try using those static analyzers... It is a lot harder to start with an unsafe language and then provide guarantees on top than it is to just start with a safe language.
I think I must have asked my question poorly. Looking around, something like std::mem::uninitialized() is what I was trying to get at. Sometimes, you really don't want to pay for initialization if you're just going to immediately replace the values in a large array. Admittedly, these cases are about as rare as when you should care about the costs of move constructors.
ATS provides more abstractions then just raw pointers. https://bluishcoder.co.nz/2013/01/25/an-introduction-to-pointers-in-ats.html
&gt;When Safety &amp; Performance (in term of speed/memory/ondisksize balance) are #1, go Rust. But why not Ada SPARK, Java or ATS?
Interesting! I'll give it a look over sometime, but there are plenty of competitors in the "low overhead, high abstraction, not c++" domain. I think Rust is in the lead here, or at least it looks like that in my bubble, but for years D looked like it was picking up steam, too. I think Rust's advantage over these other languages is that it's here, it has serious backing, a vibrant community, and wonderful tooling and documentation. 
Ada SPARK and ATS have very little mindshare compared to Rust. While language popularity may not be everything, strong ecosystems really help in terms of library availability, support, and people you might want to hire. Java's memory management is based on garbage collection. This means you may have long pauses during collection phases, or low throughput in memory management if you prioritize short pauses instead. It also likely means a significant amount of overhead in heap allocation/memory usage. More abstractly, the Java VM is a pretty big layer of abstraction, at run-time, sitting between your program and the machine. If you use it in anger, chances are it will bite you some time. (True story: at work, we had a Java program that was designed not to touch the disk ever. At some point, a customer mounted it on a machine that had network filesystems only. It turns out the JVM, by default, writes some performance logs to disk, and waiting for this process when the network is busy can cause a significant holdup in processing.)
Right, you don't use `uninitialized` in that case, you just use an Option that is set to None. `mem::uninitialized()` is useful in some very specific cases like this, but in general Option works.
Ada SPARK should, in theory, be able to provide better safety than Rust; as it allows you to specify various conditions about functions, and use a theorem prover to prove them. However, that also makes for a very conceptually heavyweight approach to safety; you have to annotate with appropriate conditions, and I believe that you may need to assist the theorem prover for complex code (never have tried using it, this is just based on a cursory glance so correct me if I'm wrong). This kind of conceptual overhead is fairly high extra burden to add on the everyday programmer; for truly safety critical systems, it may be acceptable, but for the vast majority of software, and especially free software which may be written in people's free times or as side projects at work, it is probably too high to expect that people will do that rather than writing in less safe languages. Misra-C/++ is not really something amenable to automatic verification. It is a set of guidelines on writing safety critical C, and some of them can be checked by lints or static code analyzers, but I don't believe that all of them can. And even those that can be checked, are usually only available in the form of expensive commercial tools. Additionally, while some of the rules and guidelines in things like Misra-C/++ and Ada SPARK might be acceptable for real-time control systems, like no dynamic allocation or forbidding pointers, they aren't nearly as acceptable in things like a web browser which needs to parse arbitrary data and build up a complex tree structure based on it. In many cases, using fixed size buffers to parse arbitrary input data can lead to more problems of truncation or edge conditions when something is split across buffers. Dynamic allocation and pointers have their place, and in Rust it is ensured that the pointers are never dangling, and allocations are automatically freed unless you go out of your way to leak them, eliminating that several of the reasons for these kinds of restrictions. Rust aims to be something that can be used for writing day to day software, where memory safety is important to prevent a very wide class of easily exploitable bugs, but where people aren't going through the effort to write formally verifiable real-time control systems. It would be nice if extra formal verification could be added to Rust, to help take it in that direction, but for the fairly wide range of software it is targeting, the extra safety that Rust provides over vanilla C or C++ Gotten a bit long, so I won't address the points about Java and Erlang now. Maybe someone else can fill that in, or maybe I can come back to this later.
As a long time Erlang programmer who still thinks its awesome. - Creating a deadlock in Erlang is insanely easy and often they show up under stress (i.e. in production). No one tells you that you should avoid gen_server:call for anything not absolutely necessary. - Refactoring without introducing bugs is difficult. - Most bugs are a result of something being the wrong type. - Its relatively easy to create something production ready. If you start running into performance issues, you will often spend so much time optimizing all the development speed you gained will be lost. Though few actually hit that performance problem. On the other hand its a very easy language to learn and use. Even un-experienced (or less capable) developers can start getting productive in it pretty quickly. Rust barrier to entry is insane.
&gt; immutability by default (Erlang), process-local mutable state Rust has both of these. &gt; garbage collection (Java, Erlang), GC solves use-after-destroy problems for memory resources, which are the most common, but the lifecycle of an object is often more than the lifecycle of its memory. &gt; forbidding unchecked deallocation (Ada SPARK, Java, Erlang) Only a very limited number of programs can get away with only-static-allocations/no-deallocation like SPARK. &gt; Instead pause times are better managed by statically allocating data See above. &gt; separating segments of the program into multiple noninteracting heaps such as in Erlang This is essentially something Rust does too, it just enforces it statically, avoiding the need to *force* immutability or deep-copy (both of which are a performance drain). &gt; Reference counting and affine types still allow for complicated graph hierarchies to build up and a long chain of objects to be freed at once at inconvenient times Such systems allow it, yes, but Rust also gives you the tools to avoid it: the programmer has full control over all allocations. --- I think rayon is almost the perfect example for "why rust": *safe* parallelism with low overhead, high performance, a simple interface, and you can add it to your program with only a few lines (and, cross-compile your program using it in a snap).
I have been waiting for something like this! Many thanks, looking forward to the finished version! :)
&gt; Forbidding pointers is a weakness, not a strength This is highly context-dependent; any claim that a lack of pointers is *always* a weakness really ought to be accompanied by some concrete evidence to that effect. I can't really speak for other languages, but at least in the context of Erlang, there's rarely an actual need for low-level concepts like pointers from a programmer's perspective (and when there *is* a need, you can always use NIFs and drop to virtually any language that provides a C-compatible ABI, including Rust), and most Erlang code forsakes raw sequential and memory performance for safety and fault-tolerance (and concurrency/parallelism enabled by said safety and fault-tolerance). &gt; nor does separating GCs between threads solve the fundamental problem of GC pauses No, but it solves the big practical problem (namely: the tendency for GC implementations to "stop the world") rather elegantly; given that Erlang is (again) not the go-to choice for raw sequential performance, the other problems of full-blown garbage collection (versus RAII or reference counting or stack allocation or whatever) are comparatively negligible (and probably happen when the affected process ain't running anyway, i.e. when it's used up all its reductions; I don't know enough about BEAM internals to make an authoritative statement to that effect, but it'd be a reasonable assumption that garbage-collection happens when the process is already paused to yield execution to other processes). &gt; and restricts them in other ways, such as when using shared memory. If your architecture relies on shared memory, then Erlang is definitely not the right choice for your program; the whole point of Erlang's model of lightweight *processes* (as opposed to lightweight *threads*) is that processes are isolated from one another, only communicating through message-passing. This ain't for everyone (in particular, it tends to be a bit heavy for "real" embedded work), but in most production-grade Erlang codebases, safety and fault-tolerance trump sequential and memory performance. Of course, these restrictions only apply to the Erlang code (and/or the resulting BEAM bytecode) itself; internally, BEAM can do whatever it damn well pleases in order to squeeze out further performance, and I'm sure things like pointers and shared memory are involved. In this case, the assumed immutability of data is a critical aspect in BEAM being able to safely apply certain optimizations (for example, it can know with reasonably-high confidence that the same exact value passed to 1,000 processes can be safely represented with the same exact pointer, since it knows that none of those processes are able to actually modify the data behind that pointer; this goes out the window when using NIFs, just like how such guarantees go out the window when using `unsafe {}` in Rust, but such is life in the unsafe world).
I definitely need to make mention of that!
Thanks a million! I'll add links into the section on porting and I'll read through the blog to see if there is anything I can use in a more generalised form 
Generally speaking you need to be able to run the future on a separate thread, and therefore the contents of `Thing` has to be wrapped in an `Arc&lt;Mutex&gt;&gt;` to avoid data races. Technically speaking the method named`map` requires you to use a move-closure. This is the reason why you write `move |i| {...}` instead of just `|i| {...}`. The borrow checker doesn't allow you to use a `&amp;mut self`inside this closure https://doc.rust-lang.org/book/closures.html#move-closures Note that a rust future does not contain an event-loop, so they they will not execute automatically. Therefore you have to use futures in combination with `futures-cpupool`or `tokio-core` or a similar library.
&gt; Ada SPARK, Java, Erlang and a plethora of other options are safe, fast and industry proven technologies. That may be true, but they (and Rust) all target very different use cases: * Ada is probably the closest in use-case to Rust, having a proven track record in embedded and mission-critical scenarios. Its strength lies in being able to eliminate the risk of undefined behavior (read: crashing) through formal verification. The differences between the Ada approach and the Rust approach mostly lie in the complexity of Ada codebases (for example, Ada enforces a C-style header v. body distinction, encouraging programmers to define public interfaces versus private implementations) and how types are derived from other types (for example, Ada can define types based on ranges of integers or collections of other types; Rust can do this, too, but usually not as [succinctly](http://www.adahome.com/Tutorials/Lovelace/s6s3.htm) or [elegantly](http://www.adahome.com/Tutorials/Lovelace/s6s4.htm)). * Java is industry proven, but it doesn't really offer the same safety guarantees as Rust or Ada or Erlang. `NullPointerException`s are a common sight if you're sloppy with references * Erlang takes almost the opposite approach from languages like Ada or Rust; instead of trying to handle/prevent every possible runtime error, it instead relies on constructs like supervision trees to isolate errors to specific processes, which then die and can be restarted or otherwise handled. Erlang's mandatory data immutability also helps eradicate whole classes of errors. On the flip-side, Erlang is much higher-level than even Java (let alone Ada or Rust), and while it's technically a "soft real-time" programming language, sequential performance ain't nearly as high of a priority as it is with, say, Java. So, where does that leave Rust? * It has Ada's safety guarantees, but entirely at compile-time and with a fraction of the cognitive overhead * It's not really comparable to Java aside from being in the same performance class (if not faster) and being a bit weird when it comes to pointers * It's not really comparable to Erlang, either, but it inherits its immutability-by-default policy and a reasonably-safe concurrency model (falling short of a full-blown supervision-tree-driven actor-model-based lightweight process implementation like with Erlang, but Rust sits at a much lower level than Erlang, so it's generally acceptable to not have such a massive feature built-in) Basically: Rust inherits a lot of good parts from the mentioned languages and brings its own good parts (namely: being reasonable as an incremental replacement for C and possibly even C++), but there are cases where the mentioned languages are still preferable (for example, Ada works remarkably well for large teams, and Erlang (and descendants, like LFE and Elixir) works remarkably well for networked systems requiring extreme fault tolerance at runtime). Which language is "right" for the job depends on the job.
From what I've read, it may be worth writing 2 guides, one for C and once for C++. I just had a brief skim but here are a few thoughts: **Introduction:** &gt;Object lifetimes are tracked automatically to prevent memory leaks and dangling pointers Rust doesn't protect against memory leaks (any more than c++ does anyway). [Memory Leaks are Memory Safe](http://huonw.github.io/blog/2016/04/memory-leaks-are-memory-safe/). Also, C++ users are thinking "Ok, RAII + smart pointers". **Types:** &gt;This loop only uses positive integer values so it should use an unsigned int but writing int is easier to write, or size_t for that matter. Signed integers can be optimised better than unsigned integers and therefore are sometimes preferable. If the author does not acknowledge this then it makes it appear that they don't understand some of the details of writing performant code. This is not a good look when you're trying to sell your programming language as meeting those needs. I'm not sure why size_t is mentioned as it is unsigned, I think the author confused it with ssize_t. Primitive types are not a sore point in C or in C++, just add stdint to the first table and make the section as small as possible. &gt; C/C++ types can also be needlessly wordy such as unsigned long long int. Again, this sort of puffery encourages code to make bad assumptions, use a less wordy type, or bloat the code with typedefs. The best action is of course to use &lt;cstdint.h&gt; / &lt;stdint.h&gt; if it is available. Due to the existence of stdint, belabouring this point just weakens the whole argument for Rust. This is not where Rust is making improvements. At this point in the article the reader has gone through all this thinking to themselves: "Just use stdint and std::pow like we've been doing for a decade". Not a good frame of mind for reading about the actual improvements Rust makes. Typo: instead of `let degrees = 45.0f64;` it should be `let angle = 45.0f64;`. Admit it, the last time you used C++ was in the 1990s... // malloc returns a void * which must be cast to the type need file_stat *s = (file_stat *) malloc(sizeof(file_stat)); // But casting is not required when going back to void * free(s); In C++ this is: auto s = std::make_unique&lt;file_stat&gt;(); //Destructed with RAII (Originally I said `std::unique_ptr&lt;file_stat&gt; s(new filestat());` which is 3 years out of date now) &gt; E.g to create a 100 element array of double values in C++: double *values = new double[100]; delete []values; Anyone allocating memory like this is probably not interested in Rust. In C++ this is written as: std::vector&lt;double&gt; values(100); I suppose you could point out that it is still possible to do and that those programmers writing C in C++ (we all know them) aren't forced to do it properly. &gt; Note how Rust provides a shorthand to initialise the array with zeroes or any other value. The C++ code above would be pointing at garbage unless the code explicitly set it to something. Both C and C++ language users are wondering how to avoid the overhead of initialising the array. This should be mentioned. &gt;One serious disadvantage of C++ arrays is there is no .len() method so the length has to be passed in to any function that wishes to manipulate it. Those are C arrays, C++ has `std::array` which has `.size()` as well as iterators. Don't attack a strawman or you lose all credibility. **Strings:** You make it look as if unicode literals cannot be written in C++ code. In fact auto hello_chinese = u8"你好"; works fine. **Variables:** C++ uses `nullptr`, not `NULL`. For the C++ floating section: auto a = 100.0; auto b = 0.134; auto c = 2.3f; // But 2.f is valid auto d = 12E+99; **Structs:** &gt;So a class may specify public or private when deriving from another class Can also be `protected` Also, interesting note. Rust can't emulate the `Size` class with the `width` and `height` members as const (interior **im**mutability). &gt; We saw on page 73 why this could be really bad news. Reading the HTML document, I have no idea to what you are referring. &gt;What becomes obvious from reading there is a lot of noise and potential for error in C++. There would be even more if raw pointers were used instead of a std::unique_ptr here. Looks like this line should have been deleted. No mention of drop order in structs. This is undefined in Rust (tsk) but defined as reverse order of creation in C++. No mention that drop does not take ownership of structs so members may have to be wrapped in `Option` in order to do cleanup. **Comments:** Unicode in comments is perfectly fine in C++ and will work everywhere Rust can be used. C++ doesn't define an encoding for source code though. Docs are done in C++ with doxygen, using /// or /** **/ **Expressions:** C++ uses lambdas to convert statements to expressions. (I forget what this is called, FINI or something). Eg: auto x = [](){ auto pi = 3.141592735; auto r = 5.0; return 2.0 * pi * r; }(); Or: auto result = [&amp;](){ switch(server_state){ case ServerState::WAITING: return "Waiting"; case ServerState::RUNNING: return "Running"; case ServerState::STOPPED: return "Stopped"; } }(); Note that with the compiler option `-Wall` (very common) there is a warning generated for the second example. You need to throw an exception explicitly after the switch statement because server_state could be a some other value and then result would not be initialised. **Casting** doesn't discuss downcasting (which is an issue in Rust as you have to use the Any type). Also no mention of C style casts which are still used widely even in modern code. **Enumerations:** Note `enum class` which has stronger guarantees than `enum`. **Loops:** C has `goto` which is widely used (no RAII), C++ also has `goto` but it is almost never used. **Switch/Match:** &gt;Switch statements can be a source of error because behaviour is undefined when a default clause is not supplied This is false. If there is no case which matched in a switch then it is skipped. &gt;Additionally switch statements only work on numeric values (or bool) I would clarify that it also works on `enum`s and `enum class`es. Note also that `-Werror=switch` is required for switch statements to disallow missing cases which is a nice default for Rust. **Functions:** C++ does not distinguish FnOnce and Fn, though Rust requires FnBox for FnOnce which is unstable. **Error handling:** `boost::optional` is the equivalent of `Option`. Funnily enough, the semantics are the same as for pointers (which I believe is the reason null pointer referencing is less common in C++ than other languages where no distinction is made between a reference and a pointer). ~~panic::catch_unwind requires UnwindSafe which often means overhead (wrap in a Mutex).~~ (You can use `AssertUnwindSafe` to avoid overhead). `panic`s are untyped which means that when one occurs the only information that can be gleaned is that an error occurred, not what that error was. Additionally, there is only one global panic handler (I think) so different crates can't define different panic handlers. Not sure about this though. **Lambda Expressions / Closures:** Rust does not have anonymous functions, only closures. **Attributes:** Formatting issue on this page. C++ equivalent of `rustc -C lto` is `-flto` **This guide is way longer than I thought, I'm spent.** EDIT: Updated code to use std::make_unique, updated misinformation about panic_unwind overhead, added additional issue with panic handling (there is only 1 global error handler).
Questions like this can be answered by looking at the [syntax index](https://doc.rust-lang.org/book/syntax-index.html).
Yes. Comprehensions are the idiomatic way of doing data transforms and I think they look lovely. 
yea sorry. I realized only now, that I'm in /r/rust and not /r/python. Silly me.
Firefox is not using any of the proper modern C++ idoms as stated above but rather has downgraded C++ to C level with classes. It shall be used as an example of how not do it. Taking bad examples to make a point destroys the point.
Found a better way to write this and it gets compiled into a proper memcopy pub extern fn shift(n: u32, slice: &amp;mut [u32]) { let mut v = n; for i in 0..slice.len() { v = replace(&amp;mut slice[i], v) } }
Macros are not allowed in all positions. "On the left side of an assignment" is one of the positions where it is not allowed. So this works: ( $left:expr =&gt; $right:ident ) =&gt; { $right = bar!{$left} }; And this does not: ( $left:expr =&gt; $right:ident ) =&gt; { foo!{$right} = bar!{$left} }; 
It's just something I wrote off-the-cuff to sum up my opinion on languages where you're forced to write tons of boilerplate to compose things because there's no way to have default/inherited implementations for more than one trait/interface/ancestor at once.
I'm sorry, but I'm going to have to emphatically call that "a matter of taste". I consider your Smalltalk examples quite ugly. (But then, I am one of those people who explicitly uses parens in CoffeeScript, even though it allows them to be omitted.) Regarding keyword arguments, I do like them, but I've seen some pretty reasonable cases made in RFCs for why they're hard to square with Rust's other goals.
It's still a byte literal in Python... it's just that `str is bytes` in Python 2.x, so you only see it in code that's either aiming to be compatible with Python 3.x or written by someone who habitually codes for Python 3.x. (In Python 3.x, `unicode` got renamed to `str` and APIs were adjusted accordingly.) **EDIT:** Why the downvote? I was just trying to be helpful to save him a novice-level post over on /r/python
**Exception Handling / Safety** Rust crates suffer the same issue as C++ libraries with regards that some will panic and others not. I've seen too many cases people using unwrap which means your application will panic and you as programmer cannot do anything about it, not even trying to die gracefully, i.e. bring the application context (database, shared resources, etc) in a consistent state. Whereas with an exception, the application developer can catch it the most appropriate point and die gracefully. Yes, it does require discipline but this is the only way to handle shared resources, just like not using unwrap requires more work. Panics are almost as bad NPE for users when it comes to software in production. Unfortunately, there is no consensus around exceptions versus return value checking. However, Rust's approach is so far the best approach for the return value paradigm and if the compiler would warn pedantically about unwrap will maybe discourage using it abusively.
I was trying to replace the default markdown renderer of cargo doc, but markdown rendering doesn't seems to be a part of cargo. Where should I start looking?
Yeah sorry, my workplace is still on C++11 Edit: I'd say any use of `new` in C++14 is unwarranted with the introduction of make_unique.
Are you interested in embedded development or you just see value in having flexible libraries?
b'\n' has type u8 while '\n' has type char.
Unwrap is not the only function which may panic. A recursive [no_panic](https://internals.rust-lang.org/t/no-panic/1356) annotation would be more appropriate. C++ has a specific issue with NPE in that they are segfaults, not exceptions. Though panics and segfaults have similar outcomes in most Rust applications. Using `Result` is the best approach in my books as well, however it does lead to people just blindly calling unwrap which means errors propagate as panics which are (purposely) handicapped compared to exceptions. There is a clippy lint for unwrap usage on Results, but it is allow by default so you'll only find it if you look.
Many of us speak python as well. HISSSSSSSSSS unicode/bytestrings in python are a common problem, because python's behavior on normal string literals isn't necessarily consistent across versions, so its inference of the behavior you want may not always be correct. It's a ***very common issue*** and came up recently in my local PUG for people to need to convert from `b'string'`s to `u'string'`s.
Would you mind elaborating on what it actually does when you give it the file full of `process name;threshold;process executable absolute path` triples? (In greater detail than the title)
I think you need to do something like this: fn doit(&amp;'a mut self) -&gt; impl futures::Future&lt;Item = bool, Error = std::io::Error&gt; + 'a { let list = &amp;mut self.list; self.get_socket(self.dummy).map(move |i| { let int = i.parse::&lt;i8&gt;().unwrap(); list.push(int); true }) }
Regarding Java and pauses, try playing Minecraft on a machine with not too much RAM. Choose hard difficulty. Then observe how easy it is to get killed by a monster because of lag caused by GC. ;) (Yes, it happened to me many times.) C++ is not only a language but also culture. And the culture is influenced by it's backward compatibility with C. This culture often doesn't use RAII and other techniques, so it's sometimes difficult to find safe, high-quality library. And the obvious problem with RAII in C++ is that you can't return `Err` from destructor - you have to thow exception (costly). Which also remembers me that Rust has probably the best error handling tools I ever saw. I don't know Erlang much but is it possible to use it on bare metal? I doubt it.
I would offer a tip: when demoing an API, show I/O calls. Almost all REST APIs that people make IRL use a file read, db call, or subsequent network I/O. These are things I know how to do in Iron, but I haven't yet RTFM'd enough to know if these same approaches would work with Rocket. I assume not, since one of the ways I maintain a connection pool is by using `iron::middleware::Chain`s. Also, using `unsafe {}` in an API seems kind of unnecessary, though it is a helpful peek into Rust/C interop. All in all, a good read, though.
Thanks for your feedback! I agree with you on showing up some "real" I/O. However, this was prepared for a 45m workshop and I had to cut a lot of stuff. I had two goals by using `libc`. The first one was to emulate some I/O without having to explain or to make decisions about storage. The latter was actually to give some insights into Rust/C interop, even while I didn't go through all the implementation details in the talk, because I already knew the audience had a good percentage of C/C++ and JNI people.
Hey, I don't really have a stake in it either way... I'm just saying that I understand their perspective.
Erlang's approach to concurrency is basically the functional counterpart to Go's goroutines, so I seriously doubt you could implement it for bare metal and still have Erlang.
rustdoc is part of the rust-rang/rust repo. But be advised, it's a complicated piece of software in need of refactoring. You should probably talk to the folks in #rust-docs who have been wanting to get rid of hoedown for some time.
I don't have direct proof but observation: this doesn't happen when I have more RAM, it happens more often as the map grows. And of course, I tried to turn swapping off.
It'll come but after the 2nd of February.
If you don't have enough ram to load the map, I don't see how the garbage collector has anything to do with performance. Wouldn't the same occur if minecraft was written in rust?
Ah, OK, so this doesn't use connection pooling. It establishes a new db connection every request. When I use Iron, I'll use the r2d2 crate to handle that, but you also have to know how to inject the resulting shared symbol into each request.
&gt; hmarks are usually affected a lot more by how optimized the code in a specific language is, and not by how good the compiler is. Can you give an example of what those optimizations are? So is it the case that the benchmarks for Rust aren't as optimized or is it that we're not allowed to optimize the code to the point you're able to in C/C++?
You're able to use r2d2 as well. In the current release a [combination of lazy_static! and a database pool](https://gist.github.com/lholden/a9126184923def301e2b7b436f2f65cb) can be used to manage database connections. In the near future, a new feature called [managed state](https://github.com/SergioBenitez/Rocket/commit/c81591170554bf70304390325657c6f2108e9c24) will make this easier to handle. 
Thank you
Isn't this a browser? Maybe websockets and SVG or WebGL?
I thought deadlocking in erlang is impossible. How can that happen without shared locks?
Hm. That makes sense. Is there a way to timeout the receive?
/r/playrust? Maybe? I don't even know anymore.
[removed]
[removed]
I know the guy personally, he isn't hacking. Kids just need to get over the fact that people are better than them lol. #FreeWisdom
Probably also the only FP thing in python that's great.
[removed]
What are these tasks that certain languages are better at than rust, and which are things caused by the current state of rust and which is because of the design and intention of rust and will probably always be better using other tools than rust?
There is, absolutely. By default [`gen_server:call/2`](http://erlang.org/doc/man/gen_server.html#call-2) has a timeout of five seconds. It is possible to specify an infinite timeout with [`gen_server:call/3`](http://erlang.org/doc/man/gen_server.html#call-3) but that's almost surely a bad idea. Without explicit locking the way you deadlock an erlang system is similar to the way you deadlock a distributed system: recursive waits on resources or responses. 
I have now added the ability to inject functions that you have requested, please check out the repo again.
Looks like `rusqlite` should re-export that error code enum. I'd open an issue there and ask.
&gt; It is possible to specify an infinite timeout with gen_server:call/3 but that's almost surely a bad idea. But then if the system gets overloaded or database access gets slow, calls might take long. Then you are erroring out when the call was actually successful. This can also lead to ugly situations.
Can't borrow immutable field list as mutable :(
It makes me laugh when I see these posts.. Do they not go.. WTF is all this complicated shit!?
Re: event loop, yes, I just took it out for brevity's sake. I suppose wrapping it in Arc would let me move a clone into the closure? That makes sense, thanks.
&gt; Refactoring without introducing bugs is difficult. &gt; &gt; Most bugs are a result of something being the wrong type. My personal favorite is passing module and function name as arguments to function calls. A pattern which unfortunately seems quite common.
Async IO, specifically in the context of networking are big ones. Go is basically designed for this purpose. Erlang/Elixir are designed for a related purpose. UI stuff. Most UI toolkits are built with the assumption of a GC. Java excels here, as does Swift. Rust is a bit annoying to work with here (but needs more good Rusty UI toolkits)
Converting C++ to C will lose abstraction and idoms will be lost, so it will end up with a machine translated pseudo assembly which then gets translated in rust. I'm sure it will look ugly. It's like translating Russian to French going over English. This is why ideally it should go straight while trying to converting abstractions from one good idiom to an equivalent.
very cool, have not seen this before
Thanks to @quxxy https://www.reddit.com/r/rust/comments/5qt7il/what_does_bn_mean/dd1www3/
&gt; This is highly context-dependent The context against it was one of caveats. Those caveats are benefits of pointers in the situation you gave; performance by default and not needing to interop through a C layer when you do need it. There are more advantages of pointers, but I see no need for a long list when native performance suffices as a justification. &gt; No, but it solves the big practical problem (namely: the tendency for GC implementations to "stop the world") When your main thread, or UI thread, pauses, the world stops. When any thread on which many other threads depend upon pauses, the world stops. When pauses are unpredictable and long, many programmers will just refuse to use the language for their use-case. &gt; If your architecture relies on shared memory, then Erlang is definitely not the right choice for your program So you agree with my argument? Why are you phrasing it as a refutation? 
I would use the https://crates.io/crates/streaming-stats or https://crates.io/crates/statistical crate. You can always look at the documentation a see if a crate provides the functions you need. The first one has the advantage of using iterators but they seem to be equally popular.
Yes; I think this rule _does_ make *some* sort of sense overall, but not in our specific case. That is, in some sense, it's more of a test of a "usual" situation with a language. But the rest of the game isn't about that, so...
thanks!
Ahh good shout!
Thanks to /u/quxxy https://www.reddit.com/r/rust/comments/5qt7il/what_does_bn_mean/dd1www3/
[removed]
No. GC in the best case is little more than arena allocation. And that can outperform individual allocation/deallocation easily.
the rust equivalent to node would be cool. But no, well designed native gui apps work this way also.
&gt; the rules say that if your language's standard library has a HashMap, you must use it, rather than writing your own. C doesn't have a HashMap, so they get to write one specific for the benchmark This is not true. The rules say you must use either the built-in hashmap or a preexisting library hashmap. Nobody gets to write their own. There is nothing stopping Rust from using a library. 
Is there a page for reserved (but unused) keywords like `do` and `virtual`?
&gt; This is somewhat smelly C++; it is better to use: &gt; auto s = std::make_unique&lt;file_stat&gt;(); For me, without context, even this is a smell. I'd prefer : file_stat s; // destructed with RAII 
Many thanks for your constructive criticism! I'll go through the doc and make the changes that clarify the points you made. One point concerning memory leaks is I'm not referring to unbounded expansion of a vector (for example), but an explicit memory allocation which has not been balanced by a free. The sort of thing that happens all too often in C or C++ especially where the issue of who owns the point becomes confused. Even shared pointers are not always the answer because it muddies where the shared pointer is actually deleted which can be a problem in itself.
If that's the case I'm pretty sure Rust could squeeze much better performance in many of these benchmarks, bar the SIMD stabilization. There are some benchmarks that are actually really slow and to have comparable speed with languages such as C, it's hard to market that when benchmarks are often 10s slower than the C counterpart IMO. 
Author of [statistical](https://crates.io/crates/statistical). I'm not actively developing the library right now, but will fix any problems and consider adding features if an issue is filed. Statistical is fine for common use cases; however, if your dataset is streaming or you have a very large dataset, I'd recommend using a crate with an iterator api like streaming-stats.
I'll take a look - I'm trusting gitbook to produce the right footnotes but perhaps I've broken it
I assert that it's better to have known upper bounds, which simplifies reasoning about behavior in situations of overload or slow network requests. In the example of the database, sure, the request might eventually succeed or, perhaps, the database is offline. There's no good way to know. Much better to know that at least _your system_ will take only X seconds to do some synchronous call. 
Thanks! I have never written an rfc. Feedback has been all over the place when I shopped it around. Who knows what will happen. https://github.com/rust-lang/rfcs/pull/1875 
The reference has a list of [all keywords](https://doc.rust-lang.org/grammar.html#keywords), but libsyntax contains a list that is helpfully divided by comments to show [unused keywords](https://github.com/rust-lang/rust/blob/82611a022468bb54476f149a0e77901ed48bcb9a/src/libsyntax/symbol.rs#L202).
In the doc, it says: &gt; T: ?Sized: allow generic type parameter to be a dynamically-sized type. See Unsized Types (?Sized). Is this specific to `Sized`? Or can it be used for other trait? Also, the `!Trait` syntax (e.g. `!Sync`) doesn't seem to appear (unless I failed at ctrl-fing). Similarly, I wonder if it's special syntax for `Sync`/`Send` or if it can be used for other traits? 
&gt; I'd happily use Rust for an application that needs to saturate a NIC to copy some multi-gigabyte file between machines, but for a logic-centric app that spends most of its time waiting for other apps to do their computations, I'd probably choose Erlang first. So would I; the question is if this is a fundamental property of Rust that can't be overcome. Rust will never be as perfect as these languages in this field since the languages were designed around this, but it might be able to good enough; enough that any disadvantage of using Rust would be made up for by the type system or other things. I don't know, it certainly seems possible, and it seems like a direction the Rust community wants to take.
C can't use a custom hashmap. The fastest benchmark is in C and use khash http://attractivechaos.github.io/klib/#Khash%3A%20generic%20hash%20table
I was definitely not my most calm; this was the last of a few threads over a couple of days. If that's true, that's more reasonable, though also kind of silly; given there's no difference between some code pushed up on crates.io and being inside of your project.
Unhelpful bikeshedding, but this feels more like linting your package, which I'm 100 percent for, and I think would make for a simpler name as `cargo lint`, especially since it includes running Clippy.
&gt; So you agree with my argument? Why are you phrasing it as a refutation? I'm phrasing it as a refutation because you don't always need shared memory or pointers or raw performance. Sometimes safety, fault-tolerance, and ready-to-go concurrency/parallelism are what you need, and that's where Erlang comes in. If you need to implement your own low-level logic, then do it in a NIF or a port, or just don't use Erlang; nobody's forcing you to use Erlang for every last bit of code. Basically: if you need raw performance, go with C (or Fortran or assembly or what have you). If you need to prevent errors entirely, go with Rust or Ada. If you need maximum survivability and fault-tolerance (possibly across multiple nodes), go with Erlang. Use the right tool for the right job. &gt; When your main thread, or UI thread, pauses, the world stops. That's the point: there *is* no "main thread" in Erlang. You might as well be arguing here that garbage collection in a single OS process stops the whole operating system, which is plain untrue (at least so I hope; if that *were* true, then I'd be very concerned about the operating system's design!). [You can read more about the basics of how Erlang's garbage collection works here](http://prog21.dadgum.com/16.html), but the gist is that Erlang's garbage collection is per-process, not global (since each process has its own heap). Thus, the stoppages are per-process and *not* global. In many cases, you don't even need to garbage collect at all; Erlang processes are sufficiently "cheap" overhead-wise that it's common for them to be short-lived, and thus it's common for their heaps to be short-lived. Given this, a process can easily spawn, exist, and die all without needing to trigger any sort of garbage collection, since the VM can just free its heap after death. ---- Basically: Erlang's strength lies in not having to deal with pointers or shared memory directly; it abstracts these low-level concepts away from the programmer, instead favoring message passing and isolated lightweight processes with their own heaps. This ain't always the right answer, but it's very rarely the wrong one. In other words: &gt; Those caveats are benefits of pointers in the situation you gave; performance by default Not every single programming problem requires performance by default; I think this is our primary point of contention here. C has "performance by default" at the expense of safety. Erlang has "safety by default" at the expense of performance. Java, Rust, and Ada sit between those two extremes; they're not *quite* as fast as C, and they're not *quite* as fault-tolerant as Erlang (actually, Ada might be in that realm, but it's still in Rust's category of "prevent errors entirely" rather than Erlang's category of "errors will happen no matter what, so make sure it's at least isolated and doesn't stop the rest of the system"), but rather occupy various middle grounds in that spectrum of "performance by default" v. "safety by default".
&gt;So what's the fastest k-nucleitide performer rust or C? Bernie Sanders
&gt; Is this specific to Sized? Or can it be used for other trait? Yes, it is specific to Sized. It's necessary because generic parameters `T` are `T: Sized` by default, so you need this to remove it. &gt; Similarly, I wonder if it's special syntax for Sync/Send or if it can be used for other traits? It can be used with any auto trait. `Send`/`Sync`/`UnwindSafe` are the ones currently in the stdlib, but you can make your own.
What if it's UTF-8?
So what? Code points are up to four bytes in size in UTF-8.
&gt;Golang doesn't have generics. Sad! It's type system is a total disaster.
Sure, the borrow checker's errors can feel like getting mauled by a bear at the beginning, but it just takes practice.
&gt; However, there are programs that are not decomposable into thousands of threads. Games are a good example. Games are actually a *very* good example of programs that are decomposable into thousands of threads, especially in more complex games (think a real-time strategy game or an MMO). In fact, Erlang itself has been used to rather great effect in multiplayer games, since its concurrency primitives are well-suited to handling hundreds or thousands or even millions of simultaneous players. There are some parts of games that *don't* decompose into thousands of threads, though, the rendering loop being among them. In these cases, you don't want your rendering loop to be stopped because some background process needs to garbage-collect its heap. Erlang works well here, too; *because its garbage collection is process-local and not global*, your rendering loop can chug along without worry. Of course, Erlang is poorly suited to the rendering loop itself for other reasons (namely: because the rendering loop needs to run as fast as possible, and shouldn't have to compete with other tasks in the background). This is where a port comes in: write the rendering loop in a more performance language (like Rust) and have it send/receive messages as part of the loop. It can then run independently of the parts of the game that *do* decompose well into thousands of threads while still behaving as if it's an ordinary Erlang process (thus still abstracting away the need to manually manage communication; your native code can still send messages as a result of, say, user input, and can still respond to messages like, say, a player moving around in the game world). One of my pet projects is actually using Erlang (really Elixir) and Rust in tandem in that exact same setup. The bulk of the game logic is implemented as an ordinary Elixir application, and the actual rendering is done in a port (written in Rust) that just sends/receives messages and maintains a Glutin window. As things continue to develop, I'll very likely offload other performance-sensitive things to Rust as well (like collision detection). If something drastic happens in my rendering code causing it to crash, I can handle it gracefully from the Erlang/Elixir side of the equation (whether that means restarting the rendering program or doing cleanup for a graceful shutdown, perhaps with an error message explaining what went wrong). In other words: this is the sort of case that involves *hard* real-time programming, whereas Erlang provides *soft* real-time programming. Thus, it's logical to split off the hard real-time parts from the soft real-time parts. Use the right tool for the right job :) Of course, for simpler games, the overhead of Erlang is probably not necessary, in which case C++ or Rust is a better choice for the whole codebase. Likewise, not all games require 2D/3D rendering (such as text-driven games), in which case you can probably get by without needing to run some loop as fast as physically possible. &gt; Rust is comparably fast to C in a way Java is not. They're actually more-or-less on par on average, last I checked; Sun (and subsequently Oracle) has put a lot of work into the JVM over the years to squeeze all sorts of performance tricks into its JIT compiler. The fact that Rust is already at that level at a much younger age bodes well for future performance. &gt; Similarly, if I understand correctly, Rust is safer than Erlang when dealing with errors isn't as simple as restarting a server. It ain't quite that simple, and it's actually the other way around. The difference between Rust and Erlang safety-wise is that Rust's safety mechanisms happen at compile-time while Erlang's happen at run-time. Compile-time safety checks (like the ownership/lifetime model) work great for preventing a lot of common errors (like use-after-free), but they're not a complete solution for handling runtime errors that happen regardless (in other words: your program might not segfault, but it can still `panic`). Erlang's safety model, on the other hand, assumes that run-time errors will happen anyway, and thus seeks to do two things: * Handle the error cleanly, usually by trying again (which works reasonably well if it's a transient issue) * Don't let the error stop the whole program; other parts should continue to function Erlang's process model is key to both aspects of that safety model. If a process crashes, its supervisor can handle the crash, and can even be patched in real-time to fix a problem (if the error is *not* transient), all while letting every other process run normally as if nothing was wrong. ["Erlang: The Movie"](https://www.youtube.com/watch?v=xrIjfIjssLE), while by no means modern, is a good introduction to exactly how this works in practice; it demonstrates (starting from about the 5:30 mark) a phone call staying connected despite the rest of the telecom system (written in Erlang) being hot-patched to handle an error due to a typo in the code that handles conference calls. Pretty slick stuff. Rust *can* do this, but not out of the box. It also doesn't have out-of-the-box support for things like inter-node communication, nor does it have out-of-the-box support for a lot of the concurrency primitives involved (though there are crates that do some of the legwork). It provides a nice foundation, though, and I wouldn't be surprised if parts of the Erlang VM do end up being rewritten in Rust to take advantage of that foundation. At the same time, Erlang doesn't catch a lot of the compile-time stuff that Rust catches, and the run-time error handling probably incurs quite a bit of computational overhead compared to Rust's zero-cost abstractions. Erlang does have tools like Dialyzer that help here, though. Basically: compile-time error prevention does help with a lot of cases, and is usually sufficient in embedded contexts, but sometimes errors happen anyway, and you need to be able to handle them gracefully if you want your system to achieve the fabled "nine nines" of availability. Erlang (really, OTP) does precisely that out-of-the-box. Rust makes it easier than C to implement it yourself. An Erlang VM written in Rust (plus the use of tools like Dialyzer) would likely achieve the best of both worlds, but we're not quite there yet).
Anyway, I've been wanting to use this https://ivanceras.github.io/spongedown/ and be able to write diagrams with ascii scribbles and be rendered nicely in SVG.
Again, `unwrap` is an overspecification. The result of `unwrap` isn't an error message. It's a bug that should be fixed. I agree that using `expect` is generally nicer. &gt; There are ways to avoid unwrap, except in some rare cases where you just checked for something so **you know unwrap will never fail.** I mean... yes... that's what I'm saying. You use unwrap where its failure implies a bug in your code. For example, if you want to pop from a stack that you know to be non-empty or index into a slice whose index you know to be valid.
&gt; Games are actually a *very* good example of programs that are decomposable into thousands of threads, especially in more complex games (think a real-time strategy game or an MMO). Give me one example of a AAA game where the client code consists of thousands of threads. &gt; There are some parts of games that *don't* decompose into thousands of threads, though, the rendering loop being among them. In these cases, you don't want your rendering loop to be stopped because some background process needs to garbage-collect its heap. Erlang works well here, too; *because its garbage collection is process-local and not global*, your rendering loop can chug along without worry. Synchronous GC in the rendering thread is a terrible idea, because any pause in that thread is going to hit *hard*. Further, heavy context switching will hurt the rendering thread because that too introduces stochasticity and random pauses. &gt;&gt; Rust is comparably fast to C in a way Java is not. &gt; They're actually more-or-less on par on average I don't want to get into a long discussion about why I disagree, but I do. The JVM is not magic, and cannot make up for language semantics that are hostile to performance. A language which doesn't give you direct access to memory, or even basics like value types, is not generally suitable for extremely high performance domains. EDIT: This ended up sounding dickish. That isn't my intent. &gt;&gt; Similarly, if I understand correctly, Rust is safer than Erlang when dealing with errors isn't as simple as restarting a server. &gt; Basically: compile-time error prevention does help with a lot of cases, and is usually sufficient in embedded contexts, but sometimes errors happen anyway, and you need to be able to handle them gracefully if you want your system to achieve the fabled "nine nines" of availability. No, I understand this. You're not understanding what I'm saying though. Nine-nines is a *server* concept, and "gracefully handling errors" is only a safety concept on massively redundant hardware, where a single process failing or locally corrupt state is recoverable. This is not an acceptable way to handle failures on a single machine; consider using such a concept to build a VM, or filesystem. These are things where correctness absolutely trumps over robustness. 
Ah I didn't know that, interesting. IIRC, the issue is one of those "this is the right strategy for a general HashMap, but on this benchmark you could do better by picking a different one." That is, it's not about the hash function, it's about the allocation strategy or something. It's been too long, I don't remember the exact details.
It's worth noting that on my Enjarify benchmarks, Rust was twice as fast as Go, despite both versions implementing essentially the same code. P.S. It's not just generics. Rust's ownership system is a really powerful way to safely avoid unnecessary data copies and heap allocations. Go has no equivalent. Also, compact typesafe enums make a big difference too. The closest equivalent in Go is an interface, which comes with extra allocations and runtime type checks.
Yeah, the 8 in UTF-8 is the size of the code unit. Some code points take up multiple code units in UTF-8 (also in UTF-16). Only in UTF-32 do all code points fit inside a single code unit.
This would be a case where `StrongBox`/`WeakBox` types would be useful (they act like `Arc`/`Weak` except that there's only ever one strong reference). The `StrongBox` would only require a `Send` bound on its type argument, not `Sync`. On the surface they seem somewhat useless when you have `Arc`/`Weak`, but uses actually come up surprisingly often...
In C++, null pointer dereference is undefined behavior, not a segfault. UB often results in a segfault at runtime, but you could just as easily end up with nasal demons.
&gt; Signed integers can be optimised better than unsigned integers Is this true in the absence of undefined behavior? The only reason signed integers are faster in C is because signed overflow is undefined behavior while unsigned "overflow" isn't, assuming you didn't pass -fwrapv or whatever.
&gt; Give me one example of a AAA game where the client code consists of thousands of threads. It depends on how you're defining "thread". It also depends on how you're defining "client" (there are plenty of games that don't fit into the client/server model, as I'm sure you know). Few (if any) games use thousands of OS threads. That would be silly, and your concerns about things like context switches would be very justified. I reckon most games - including AAA ones - use some form of either coroutines or lightweight/green threads, however. [Unity3D has such functionality built-in](http://www.theappguruz.com/blog/how-to-use-coroutines-in-unity), and [games like Uncharted and Jak and Daxter used similar constructs extensively, from what I understand](https://news.ycombinator.com/item?id=2476379). Not to mention the recent trend Hard to say without seeing some source code (since - again - such "threads" are not OS threads, and thus don't show up as such). Whatever the case, the "actor model" commonplace in game development is pretty much Erlang's programming model; replace the word "actor" with "process" and there you go. &gt; Synchronous GC in the rendering thread is a terrible idea, because any pause in that thread is going to hit hard. Further, heavy context switching will hurt the rendering thread because that too introduces stochasticity and random pauses. Again: *Erlang's garbage collection is process-local, not global*. Garbage collection in one process does not affect the running of the other processes. Even if it did, I addressed this exact situation in the paragraph immediately after that one (namely: by running the rendering thread in an entirely different OS process not subject to garbage collection at all, meaning that there's literally no way for the GC on the Erlang side to affect rendering except *maybe* in the sense of resource consumption). Additionally, Erlang's processes do not involve context switching in the same sense as OS threads/processes. It's totally feasible to run thousands upon thousands of processes. They're much closer to coroutines or "green" threads in terms of overhead, but still isolated from one another. &gt; Nine-nines is a server concept It doesn't have to be. It's just that servers are usually the things that can't afford to be rebooted every week :) There are other things that lie outside the client/server model (at least in the typical sense) that benefit from high-availability. Power plants and spacecraft are probably the most extreme examples, but more mundane things like thermostats and irrigation systems benefit from "nine nines", too. Granted, I'm not aware of very many such systems implemented in Erlang (this is more the realm of Ada or MISRA C), but I reckon most such systems implement fault-tolerance mechanisms similar to those provided by OTP. &gt; "gracefully handling errors" is only a safety concept on massively redundant hardware Pardon? Graceful error handling applies no matter if you're running a giant datacenter of high-end SPARC servers or a single Raspberry Pi. In fact, Erlang's particular brand of fault-tolerance is very well suited to allowing a single machine to keep chugging along. Even in the context of games, it's nice to have an opportunity to do things like finish writing to a savefile (lest it become corrupted) or present a nicer error message (perhaps even with some error reporting functionality) rather than just crash straight to desktop (or crash to homescreen, or lockup the console, or whatever happens when your game suddenly and unexpectedly terminates). &gt; A language which doesn't give you direct access to memory, or even basics like value types, is not generally suitable for extremely high performance domains. And yet it seems to be used in those domains to great effect. Once upon a time Java had a reputation for being slow, but those days seem to be more than a decade in the past. It's still no C or Fortran, but it's no Python, either. I don't really want to get into a lengthy discussion about the JVM either. I rather strongly dislike Java, too. It has its uses, though, and it seems similar to another point: that much like how very few humans (if any, nowadays) can hand-write assembly that's faster than the output of modern C compilers, we might very well see a day and age where high-level language compilers (JIT or otherwise) end up emitting more efficient code than what humans can write by hand in C-like languages. A lot of this discussion feels a lot like a "Real Programmers Don't Use Pascal" type of situation; if history is anything to go by, I reckon technology will end up marching on, and compilers will get smarter and smarter at turning high-level programs into increasingly-efficient machine code. That's purely speculative, though, so I won't blame you for disagreeing with that sort of prediction. It's also not reality (yet). &gt; consider using such a concept to build a VM, or filesystem. These are things where correctness absolutely trumps over robustness. Let's start with the filesystem analogy here. What happens when you have a marginal disk? Maybe it's failing, maybe it got a bit too close to a magnet, maybe a cable's loose, maybe it's overheating a bit. Either way, subtle errors start to creep up. Your implementation can (and should!) be totally provably correct, but these aren't things that can be addressed at compile-time; you need runtime checks to detect these sorts of faults. That's where robustness comes in. If my filesystem process crashes, there should be a supervisor process to receive the exit message and act accordingly, be it by restarting the faulting process, alerting some other process of the fault, or what have you. This, mind you, is exactly the difference between monolithic kernels and microkernels in operating system design. In the former, even a totally provably correct monolith would crash, throwing a kernel panic and forcing you to reboot. In the latter, the microkernel can keep chugging along even if the filesystem driver crashes, giving the rest of the system an opportunity to properly cope. Of course, microkernels are usually less performant than monoliths (though some newer designs like L4 are starting to change that). That brings us again to that safety v. performance balancing act. Meanwhile, VMs are actually one way of implementing robustness; if a VM crashes, a correctly-written hypervisor should be able to contain the crash within the VM and act accordingly, be it by restarting the faulting VM, alerting some other system of the fault, or what have you (I feel like I'm repeating myself here... (: ). This ain't even beginning to address things like actual corruption of compiled code (be it through marginal disks like above or through cosmic rays or what have you). The Curiosity rover is (presumably) loaded with software that's provably correct in every way possible, but it still experienced at least one catastrophic runtime failure, in which case robustness came into play and allowed Curiosity to keep chugging along with an identical backup computer. Point being, both correctness and robustness are important in the overall world of fault-tolerant application design. One does not replace or "trump" the other. However, a robust system can at least confine the effects of incorrect behavior to a specific execution unit and allow the rest of the system to continue to operate, while a correct system can at least reduce the probability of incorrect behavior happening in the first place. They work hand in hand. Neither Rust nor Erlang are the end-all-be-all implementations, but Erlang seems to have a pretty significant head start here. Hopefully we'll start to see some "best of both worlds" development in the near future, whether that means bringing Rust concepts into the Erlang ecosystem or building Erlang-like fault tolerance systems on top of Rust. I'm excited either way.
I'm interested in this also. I find myself casting a lot to usize when computing an index and it feels like I'm doing something wrong.
Guys, take it to /r/programmingcirclejerk
You can do that. But if the object is too big to fit on the stack it doesn't work - which is when you'd want to allocate through make_unique to put it on the heap.
A while ago I compiled something simple to asm.js/web assembly. Worked fine. Now I have significantly more code that I want to compile to either of those targets, but I'd like it to be a library (no main function) and I'm not sure how to approach this, or how you would access the functions in the library from JS. From this thread: https://users.rust-lang.org/t/compiling-to-the-web-with-rust-and-emscripten/7627, I found this suggestion: https://users.rust-lang.org/t/compiling-to-the-web-with-rust-and-emscripten/7627/24 but it looks like this won't compile on stable. I can switch to nightly and keep playing around with that solution, but I'm just wondering if there's been progress in this area since that post was made or if anyone has advice on how I would approach a rust module containing some number of function that gets compiled into wasm/asm.js using emscripten. Thanks
&gt; [games like Uncharted and Jak and Daxter used similar constructs extensively, from what I understand](https://news.ycombinator.com/item?id=2476379) Games can happily use cooperative threads, yes. But these are not at all the same as the preemptive threading model Erlang pushes. Remember also the context in which you raised threading as a solution. You raised it as the solution to GC pauses, because on a GC pause another thread can step in to do work. This argument does not hold for cooperative threading as games use it, because game logic is highly sequentialized and not decomposable in this way. A pause in one cooperative thread will block the whole queue. Further, these cooperative threads, though large in number, are not the meat of execution time - instead they are the glue between the real components, and processes like the rendering thread will still have their own, uninterrupted execution time. &gt; Again: *Erlang's garbage collection is process-local, not global*. Garbage collection in one process does not affect the running of the other processes. I'm saying that if the rendering thread was written in Erlang, you would get garbage collection pauses from garbage collection in the rendering thread. &gt; Additionally, Erlang's processes do not involve context switching in the same sense as OS threads/processes. It's totally feasible to run thousands upon thousands of processes. If you switch away from a latency-sensitive thread, it doesn't matter how fast you do it. That thread is still paused. &gt;&gt; Nine-nines is a server concept &gt; It doesn't have to be. It's just that servers are usually the things that can't afford to be rebooted every week :) It's the other way around. Servers are the things that *can* be rebooted every week, because one server failing doesn't break the whole farm. The same is not true for a client software. &gt; Power plants and spacecraft are probably the most extreme examples And these are things where one mistake will break the whole thing. One engine going haywire and exploding will crash your ship. It's not like a phone system, where one part crashing can be immediately patched over by another thread; if you make one mistake you can lose. In these scenarios you want to know you're correct first time. Obviously you also want redundancy, probably even redundant hardware, but all of that is secondary to doing the right thing from the start. &gt;&gt; "gracefully handling errors" is only a safety concept on massively redundant hardware &gt; Pardon? Graceful error handling applies no matter if you're running a giant datacenter of high-end SPARC servers or a single Raspberry Pi. In fact, Erlang's particular brand of fault-tolerance is very well suited to allowing a single machine to keep chugging along. Exactly what I said. If you can't recover from failure, Erlang's model can't work. If you have a bug that deletes the only copy of a file, that copy is gone. Throwing up another thread won't fix that. Redundancy in computation can only suffice if you have redundancy in resources. &gt; And yet it seems to be used in those domains to great effect. See: general lack of Java in scientific computing, games, realtime software, high fidelity simulation software, etc. &gt; very few humans (if any, nowadays) can hand-write assembly that's faster than the output of modern C compilers This is plainly false. You should give it a go sometime; chances are you'll find it easier than you expected. That said, it's often possible, and generally recommended, to write assembly code through proxy of a low-level language (especially with the aid of intrinsics). This doesn't change the fact you're writing code directly for the underlying hardware rather than the abstract C machine; it just means you're doing so through a lossy and often-frustrating intermediary. The same is not true for Java, which generally lacks the language needed for such things. &gt; Let's start with the filesystem analogy here. What happens when you have a marginal disk? Maybe it's failing, maybe it got a bit too close to a magnet, maybe a cable's loose, maybe it's overheating a bit. Either way, subtle errors start to creep up. Your implementation can (and should!) be totally provably correct, but these aren't things that can be addressed at compile-time; you need runtime checks to detect these sorts of faults. &gt; That's where robustness comes in. If my filesystem process crashes, there should be a supervisor process to receive the exit message and act accordingly, be it by restarting the faulting process, alerting some other process of the fault, or what have you. You can't just restart a filesystem to make it robust, the Erlang way. You need things like journals and error correction and specific protocols to check for corruption and misbehaviour. Those things require correct implementations, not restarts. Restarts are only a good solution when your disk is replicated three times and you can swap the server's malfunctioning one out in the morning. Outside of that context they are merely a last resort. Obviously it's still good to have graceful error handling on top of a correctness-first mentality. But that is still possible in Rust, where the static checks work nicely in tandem with threading, preserving correctness properties even as you add thread-based redundancy on top. 
Might feel like a PITA, but the example code does not feel abstract enough in the first place. It feels mechanical, like in a language that is way less capable than Rust. You are one level below abstraction level you should be, IMO. That would read better: for dir in Direction::all() { let cur_candidate = dir.from_pixel(cur_pixel); if cur_candidate.is_within_bounds() &amp;&amp; self.ca_grid.contains(cur_candidate) { cur_pixel = cur_candidate; } } Probably could be written even better, using iterator combinators (filter, max etc.) If instead of working on `(u32, u32)` level, you will make it `struct Coordinate` then you can implement `Index` and similar utility methods, and cast stuff only there.
Make sure it is unsafe to construct a `TrustMe`, otherwise this looks fine.
That place doesn't seem to be lighthearted enough. I figure this fits under the second to last rule of "chill out"; but if the joking is getting too out of hand I'll stop.
If you're using a number as an index all the time, it should probably be stored as an index. Obviously, this is extremely general, so I can't say if it applies to your situation, but usually when I do a number of number casts it's a sign that I chose the wrong type in the first place. (This is kinda what /u/yodal_ is getting at below, for example.)
It's really part of the more general problem that people don't read (or even really just *peruse*) the documentation. I mean, it's been part of the Rust book from the get-go. If people don't see a link right there in the contents of the single most prominent piece of Rust documentation now, I don't know what *would* work.
str supports inline mutation of ASCII values?
That's a nice idea, I'll probably move towards something like that after I've done a bit more prototyping. At minimum, it hides the casts fairly well to a few places. It would be nice if Rust was a bit more ergonomic, and allowed for automatic casts in some situations like these.
That's a bit harsh! First off, people don't read any book end-to-end. And online books generally don't keep an "index" page, and people don't expect to find one, and don't look for one. One thing that at least 60% of the Rust learners are guaranteed to do is read the first few chapters of The Book. So having links in [Introduction] and/or [Syntax and Semantics] chapters will give it much more visibility, I believe. [Introduction]: https://doc.rust-lang.org/book/README.html [Syntax and Semantics]: https://doc.rust-lang.org/book/syntax-and-semantics.html
The `core` subset of the standard library has a wide variety of allocation-less string manipulation functions: almost everything on `str` works fine. If you're trying to mutate/dynamically construct strings without allocations, writing into fixed sized stack buffers (of type `[u8; LENGTH]`) works.
These automated casts are dangerous, because they can fail in some cases. If they can't, you can use `Into` or `From`.
You're looking for /r/playrust.
I started [stdx-dev](https://github.com/llogiq/stdx-dev) last week and intend to extend it if $life permits. Help would be appreciated. Also I've been putting off revisiting my fn lifetime ascription RFC, changing it to cover full lifetime ascription.
This is gonna be a busy week! On Wednesday, we are having our monthly Rust meetup in Cologne, where we'll spend some time playing with macros 1.1 to prepare for the rust 1.15 release. [I'd love to meet you there!](https://rust.cologne/) I'm also hoping to get around to merge a few Diesel PRs ([basic JSON support](https://github.com/diesel-rs/diesel/pull/561), [`diesel print-schema`](https://github.com/diesel-rs/diesel/pull/577)) early this week. There were a few problems with recent nightlies, but according [rustc issue #39377](https://github.com/rust-lang/rust/issues/39377#issuecomment-275968580) it should be fixed by removing `#![feature(proc_macro)]` (which is stable in nightly and beta).
In many cases you can remove the casts, but there are many other cases where you want to use indexes that aren't usize, and this makes the code more bug-prone, because casts are noisy and dangerous. Example: you store indexes in a vec&lt;u32&gt;. If your indexed arrays are short, then doubling the memory using a vec&lt;usize&gt; sometimes slows down your code. I have seen many examples of this.
I'm not sure what you mean by ATS not supporting references: fun foo(x: &amp;bar): void = ... This is a function that takes a bar object by reference. You can also use safe pointers, pointer arithmetic and derefencing that is statically checked. ATS can specify interfaces to C functions [in fine detail](https://bluishcoder.co.nz/2012/08/30/safer-handling-of-c-memory-in-ats.html) with no runtime overhead. Much of what Rust does in unsafe code can be done in safe code in ATS. That's not to say ATS doesn't have its own warts of course. Rust is a fine language but I wanted to address that its not "the only systems language without a runtime that offers completely safe pointers and a more robust generic programming story than C++'s while also minimizing or eliminating its most painful issues".
Trying to figure out tokio and use tokio_curl. So far I have only managed to throw myself into a deep depression.
Is there a function to count how many bytes a str needs to store?
You could define you constant as the smallest unsigned integer type possible. Then `FOO.into()` should work in most cases.
It would only help for `u8` though.
Very good point. However, wouldn't it already be possible to implement `Index` for newtypes? Implementing `Into` might be nicer/more general of course.
Well if also newtype your vecs and slices then yeah you're right. 
The second would increase flexibility for libraries (or applications) where we only care about 32bit or 64bit platforms.
Good idea, I didn't think so far because of the primary problem. I get an error message I don't understand: cursor.inspect(|item| match item.as_ref() { Some(doc) =&gt; println!("Found one"), ^^^^^^^^^ expected enum `std::result::Result`, found enum `std::option::Option` mismatched types None =&gt; panic!("Server returned no results!"), ^^^^ expected enum `std::result::Result`, found enum `std::option::Option` mismatched types }).collect(); Ah, Now I understand. But now I get: cursor.inspect(|item| match item.as_ref() { Ok(doc) =&gt; println!("Found one"), Err(err) =&gt; panic!("Server returned no results!"), }).collect(); ^^^^^^^ cannot infer type for `_`
"One hash table ought to be enough for everybody." Not like a program might need more than one.
I ran into a lot of type-inference related problems with that technique. Not even something as simple as [this](https://is.gd/keZrZo) works.
As usual I want to link [this old thread](https://internals.rust-lang.org/t/implicit-widening-polymorphic-indexing-and-similar-ideas/1141). If someone wants to write an RFC...
Or a function: fn push_len(v: &amp;mut Vec&lt;usize&gt;) { let len = v.len(); v.push(len); } (I reckon functions should be preferred to equivalent macros.)
That's assuming there's any garbage to go find during the execution of the program. Few allocations = no sweep.
Getting Ruby bindings into imag and releasing 0.3.0 then. Build setup and Testing is missing, everything else is already there.
Finally got [memcached binary packet parser](https://crates.io/crates/mbpr) working working on integration tests to move forward and finish a full client. Question(s) for the community (as I don't have much experience with larger memcache installations): * On the TCP/client side of things is creating a connection pool *worth it*? I know memcached can throttle client requests after N packets (set at startup), so should that be configured in the connection pool? (I'm just assuming an atomic CAS is faster then a TCP handshake) * The few client libraries I've read don't specify a *single* consistent hash algorithm for selecting which server to send a request too. So is *always* on the end user to just offer *many* hashing algorithms and hope the end user configures their stuff right?
`collect` is generic over the returned type, so most of the time you need to be a bit more explicit to let it know what you want. Try collecting into a vector: `.collect::&lt;Vec&lt;_&gt;&gt;` (this means a Vector of some elements of which the type can be infered by the compiler) If it still complains you have to replace the `_` by whatever the right type is. Again: if it is only about inspecting it is better to use the for loop as it will avoid allocating additional memory.
Macros are probably faster for most cases, because there is a chance that the function may not be inlined, but a macro is always inlined.
You can't pass a macro to a function, they use duck typing, and they leak from the module they're defined in. In addition, LLVM looooooves inlining.
Can't argue over your assumptions sorry, you're just basically asserting what people is doing and/or should be doing, even what they want. If you think there should be those guides, then write them. Per definition a guide to port code to Rust must be just that, it doesn't make any sense that it **must** target porting to **"**modern C++**"**. The only addition that could be sane, probably, would be to title it as porting from C and _legacy_ C++, just to try avoiding the **"**modern C++**"** crowd from jumping in.
I don't mean not having enough RAM. Let's say that if you ran GC after every dealloc, the game would never use more than 3G of RAM. If you have 4G RAM available, JVM will stop the game and run GC every time you hit 4G and cleans unused objects (1G difference). Some Java advocates argue, that it's faster to clean up once in a while and I agree that might be true. However that is unusable in the case of games and other real-time applications. If it was written in Rust, it'd clean up memory each time it'd became unused. So it would slow down the game a little but more evenly. I guess humans wouldn't notice the difference.
For a moment, I thought "video localisation" was going to be taking a video and figuring out where in the world it was recorded.
&gt; _peruse_ Hmm…
Thank for the explanation! &gt; It can be used with any auto trait. Send/Sync/UnwindSafe are the ones currently in the stdlib, but you can make your own. Is there some documentation for that? I had no idea you could make your own, I thought it was some wibbly wobbly compiley stuff.
Do you have any idea which languages are the most in need of translators? I guess asian languages would be top candidates, but I would be curious if we have more concrete data :)
in my case I'm frequently converting points to indices. i'd prefer if point x's and y's could be signed so usize isn't really an option. /u/dpc_pw had a nice suggestion, just implement a to_index on the point struct that handles the casting in one place.
How much of the current Rust code is going to work on a system where usize is just 16 bits? How much of the current Rust code is designed thinking of that system? Is it a good idea to worsen all Rust code to make it a bit better for 16 bit systems? Can we find a way to solve this problem? The current situation is not good enough. 
Would it be worthwhile to create some kind of compiler setting (somewhat like the `recursion_limit`) that indicates a minimum acceptable `usize`...size for the target platform?
Hello there! I'm a PhD Student in CS and my research field is that of string metric, where we defined a string metric such as the Levenshtein distance which *works* on heterogeneous streams, i.e., strings defined on different alphabets. The problem _per se_ is NP-Hard, so I developed an implementation in C++ which uses some heuristics in order to attack the problem. I writed it again in Rust, which I'm willing to learn and [here is the repo](https://github.com/finalfire/RustMPED). It works but is not efficient as the C++ version. I'd appreciate some reviews of the code, is there maybe something which I could do better (at least from the syntactic point of view)? 
Got basic borders working, which is great. It's awesome to finally have a visual indicator of which window is the selected one. There's still work to do on borders (borders for containers, title bars, etc.) but I think I'll take a break from that this week and restructure the configuration file. I need to start nesting configuration options. Eg `way_cooler.active_border_color` is less nice looking than: way_cooler.borders = { active_color: 0x5a73d9 } 
Yes, but running destructors is fine, raw performance is rarely the issue in RT contexts, it's *predictable* performance that matters. The cost you pay in sending these allocations across threads on a queue may well outweigh the average overhead of allocating and deallocating on the RT thread itself. The problem is that allocation is only *usually* fast - it will occasionally require taking a mutex, which may pause the entire thread. The atomics used in a lock-free queue actually have a decent performance impact, but the important thing is that it doesn't vary by much, so you can rely on your RT thread running smoothly.
I probably should have been clearer, but what I meant was that even with a variable that is `u8`, the type checker doesn't accept `slice[index.into()]`, e.g this fails: let index = 50u8; let arr = [25;100]; let foo = arr[index.into()]; (or see [the example from another commenter](https://pay.reddit.com/r/rust/comments/5qy23h/strategies_for_avoiding_constant_number_casting/dd3f7bs/) for another situation where type inference fails.). On the other hand, `usize::from(..)` does work but is a bit more bulky. Though, of course the question of whether to implement `From` for more types is also something that is worthy of discussion, I think there is an issue for that somewhere already. I wonder what type of system usize would actually be less than 16 bits though, given that even the C standard requires `size_t` to be at least that large.
Thanks, some of those look really good! I'm really hoping for just a general code review style video that doesn't aim to teach one thing in particular, just to get a feel for how other people think when writing Rust - most of these seem like they are teaching individual topics or aren't spending a lot of time with the code. Do you know of anything like that? Thanks again.
Learning rust by writing a server (and eventually a client?) for a MUD-esque game. :) Coming from C# it's been a real challenge wrapping my head around some of the language's concepts, but it's slowly starting to feel good.
Try looking on Youtube for "Rust Advent of code", you should find some good walkthroughs there. Eg http://www.youtube.com/playlist?list=PLIbQqI9hzo4Iy8_FUnP0LgWR6ZaRnr2XT (Carol and Jake of Integer32)
Is it the case that a weak reference to an Arc ensues that memory is not freed, or is this a constraint that we are adding to the hypothetical WeakBox. I was under the impression that Arcs get dropped entirely (including memory) when the last strong reference goes out of scope, regardless of the number of weak references.
Are subtitles for English going to be accepted? I know youtube has auto-CC for english, but it is imperfect, and manual captions are usually going to be more accurate.
Having big use blocks is sometimes unavoidable--you still need to import dependencies. Some things I do to keep it tidy: * Split block by std, crate, intra-crate, and submodule imports * Alphabetize each block (most editors have a way to sort a selection of lines). * Put `use` block at top of file (ie move `mod` declarations down) * Put `self::use` block after `mod` declarations Taking this all into account would make your case look like //! session.rs use std::collections::{HashMap, VecDeque}; use std::io::Read; use std::net::{TcpListener, TcpStream, Ipv4Addr, SocketAddrV4}; use std::str::FromStr; use std::sync::mpsc::{Sender, Receiver, channel}; use std::thread::spawn; use time::{Duration, PreciseTime}; use uuid::{Uuid, NAMESPACE_OID}; use configuration::Configuration; mod remote_client; mod request_cache; use self::remote_client::request::REQUEST_TYPE_VERB_MAP; use self::remote_client::{RemoteClient, Message, Request, RequestType}; use self::request_cache::RequestCache; Beyond simple organization, you can always split files into submodules so less imports are needed overall, but this can needlessly complicate project structure in some cases.
You create needless copies in read_strings when you could just return the result of `.trim()` as `&amp;str`s. I don't get what you try to accomplish with that sigma stuff, but a sorted vec or even better vec_map is likely faster. I'm on mobile right now, so this is all from looking at your code. Note that oprofile and perf [work](http://llogiq.github.io/2015/07/15/profiling.html) with Rust code.
Okay, so, are you willing to actually explain what the rule is, exactly, so we can get this straight? I don't want to mis-represent the rules, but it's hard whenever you won't actually give a direct answer. [The page for k-nucleotide says](http://benchmarksgame.alioth.debian.org/u64q/knucleotide-description.html#knucleotide): &gt; Some language implementations have hash tables built-in; some provide a hash table as part of a collections library; some use a third-party hash table library. (For example, use either khash or CK_HT for C language k-nucleotide programs.) The hash table algorithm implemented is likely to be different in different libraries. &gt; &gt; Please don't implement your own custom "hash table" - it will not be accepted. You ended our last conversation with this: &gt; If you want an additional Rust hashmap implementation then you need to persuade the Rust community to provide one in std::collections. How do you reconcile this last statement with the rest of these rules? Why does Rust have to have the hashmap in `std::collections`? In your last comment, you've now agreed with /u/TeXitoi that some measure of "popularity" is important here; exactly how is that defined? Is that why it has to be in `std`? What is the difference between an implementation of a HashMap that's identical, but in `std` or a cargo package as opposed to in the program itself? Again, I understand that the game is a game. It's very frustrating when the rules are not clear, or when they appear to be biased towards particular languages.
Hello there! In easy and fast words: the sigma stuffs are the alphabets on which the strings are defined; in the `hill_climbing` function I just perturbate the original sigmas in order to evaluate a functions which those. Perturbate means that I enumerate some permutations of the vectors sigmas! Thanks for the other suggestions! 
The convention is to import types directly, but not functions. Unless there's a conflict, in which case, don't import the type directly. &gt; you can see where, for example, the SerializableRequest is coming from if it's written like request::SerializableRequest. Yup, this is exactly it.
It isn't; it's only in the nomicon.
Is there a roadmap to make `asm!` works on stable?
Wow, I expected that to work! I guess you have to fall back to the longer `u32::from`.
I see no `black_box(_)` method. Does this work with `#[bench]` on nightly or with [bencher](https://crates.io/crates/bencher) anywhere?
It would force Rust to never support 16 bit platforms. Maybe we should create a library that only works on 32 bit and 64 bit platforms, supporting this?
I think it would be nice, and it could also make the translation to other languages easier if correct english subtitles already exist (don't know if there is a way to work from existing subtitles though, just began to toy with amara).
Sure, the transcripts I hint point to created for RustFest are such transcripts. Also, many people that don't struggle with english are helped through CC. This is less about "accepted or not", if you signed up for transcription, you can provide any at your hearts extend :).
I'm surprised no one mentions importing modules instead of the objects themself: Instead of e.g. use std::thread::{spawn}; use std::sync::mpsc::{Sender, Receiver, channel}; do use std::thread; use std::sync::mpsc; It has several other advantages as well: 1. Suddenly, the items actually makes sense. Nobody will know what `Sender` means without looking in the imports: It could be a builder struct for a mailing library, a HTTP client, or hundres of other things: `Sender` is a pretty damn useless name, on its own. Now, `mpsc::Sender` explains what it actually *is*. 2. It means you can modify code and add or remove uses of items from the module, without having to change the import list. 3. It gives nicer autocompletion in racer. 4. You will almost never encounter naming collisions, even if you use many different "incompatible" libraries. The disadvantage is that you need to type slightly more, but in all honesty, it is *by far* outweighted by the points above.
&gt; The convention is to import types directly You know, *personally*, I kind of dislike this convention. I think it encourages putting the module name in the type name, exactly like `SerializableRequest`, instead of, say, `request::Serializable`, and (*personally*) I prefer the latter. Although, `SerializableRequest` reads better. This is something I have thought about quite a bit actually lol. Edit: Despite having thought about this a lot, I didn't realize the style guide advocates for this! My mistake!
This is really helpful. Thanks
Hardly. Look at MFBT, which is used throughout the codebase.
Thank you :) I did a [writeup](https://everyweeks.com/entry/5814c12e6965033a77743f63) that at least briefly covers getting stuff small. I don't think macros would really hurt here; it's really more about avoiding the standard lib at all costs and relying on win32 only as much as possible. I agree that could make a cool tutorial series! If someone's willing to dig into that I'd be happy to provide insight/direction. Don't think I'd be the guy to write such a tutorial tho :)
&gt; Also, I don't think there is a lot of room for "resource management" here. I mean, even if you say e.g. russian should be a higher priority than french, it won't change the fact that I speak french and not russian and haven't much room to say "alright, I'll work for russian translation first". Yes, that, too. Yep, we can prioritize the videos, definitely. There's many that are mostly of historical value (like pre-1.0) ones, which should probably be of less priority.
Well, I just took the liberty of creating one: https://github.com/rust-community/localisation
Might as well use `as` then, at least it's shorter.
ditto. i'd get one of these if it only had the gear, w/o crab
Not that it helps you right now, but there has been talk about improving the borrow checker to allow situations like that, so maybe in the future v.push(v.len()); is possible.
Portuguese, Chinese, and maybe Russian probably should be the ones you start with. These three all have large programming communities of folks who do not speak English. Of course, there's less of a need for prioritization since it's not a matter of limited resources; someone who can translate language A probably can't do language B.
I'm trying to continue expanding my knowledge of rust. More specifically, I'm looking to work with rusqlite, but I'm having some problems getting it to actually build. You guys will probably see a question about it soon.
The [`retain`](http://kylemayes.com/microbench/microbench/fn.retain.html) function fulfills the same purpose. With the `nightly` feature enabled, it is implemented with `black_box` from the `libtest` crate. Otherwise, for the stable and beta channels, it is implemented in the same way as `black_box` is implemented in the `bencher` crate (`ptr::read` and `mem::forget`). **Edit:** It works with `#[bench]` in the sense that you can certainly call `microbench::bench` or some other benching function from within a `#[bench]` function but it doesn't interface with `test::Bencher` in any way.
This looks like a nice example. I just want to note that this forgets the (in my experience) most common mistake when implementing second factor with OTP. The rate limiting of the login. 6 (or even 8) digits is extremely easy to brute force (couple of hours at most when trying a crappy server). The seeming security of the rotation of the key does not actually add to the security. By just starting over with brute forcing from the start at every rotation the correct key will eventually be in the range you're able to try (because of basic statistics). 
I haven't put anything online yet, as it's still pretty messy. I'll see about doing that. ioctl is just because that's what I came across for unix domain sockets. I'll try fcntl, thanks! Edit: Ah. No actually I use ioctl because that's what mio_uds used.
My thoughts exactly. Minus the running clippy part, I think most of this could be done on either * The crates.io side of things, such as part of [RFC 1824](https://github.com/rust-lang/rfcs/pull/1824) * As part of `cargo publish`, either by default allowing opt-out (`cargo publish --no-lint`) or as a purely opt-in option (`cargo publish --lint`)
From what I understand from the linked hacker news link, Rust *could* potentially use `khash` if it was available in pure Rust as an external library. However, I understand your position that there were mixed messages since Rust has a hash map in `std`. /u/igouy (I don't know if you're the maintainer of the game or not) - Is this accurate? If someone rewrites `khash` in a Rust library, could the Rust implementation use that library instead of the one bundled with the standard library? This would put Rust on equal footing with C since they're using the same hash implementation, and that's important for Rust since Rust is trying to compete head-to-head with C.
Does the [cast crate](http://japaric.github.io/cast.rs/cast/) look any better?
I feel like any discussion about porting C/C++ -&gt; Rust is incomplete without mentioning [bindgen](https://github.com/servo/rust-bindgen), which can reduce the time it takes to get a working product. I haven't read through it all yet, but I saw that you mentioned [Corrode](https://github.com/jameysharp/corrode), which is awesome, but doing that to a huge project seems like a nightmare and I'd prefer to do the port in 1-2k SLOC chunks if possible. So my high level process would be: 1. rewrite main function in Rust (if it exists) 2. create bindings using bindgen 3. test the code from a minimal Rust entry point 4. port one subset at a time, testing as you go (preferably with unit tests) 5. repeat steps 2-4 as necessary until you're done I'll have to give the rest of this a read, as it looks like it's packed with good information. I think it would be awesome to do something similar for Go, though probably less of a priority.
I definitely meant idiotic there. I've seen some terribly written C code mistakenly assumed to be fast because C.
So I have a follow up question. Could one simply ban the use of call/3 and therefor avoid this blocking forever situation? I'm assuming there are other ways to block forever, like infinite loops, I suppose. Is this a very common issue (deadlocking) in Erlang? You mention: &gt; No one tells you that you should avoid gen_server:call for anything not absolutely necessary. But in Armstrong's Thesis on Erlang he states: &gt; The most common abstraction used by applications written in Erlang is the client–server abstraction. In virtually all systems that are programmed in Erlang, use of the client-server abstraction far outweighs the use of any other abstraction. For example, on page 174 we see that 63% of all the behaviours used in the AXD301 system were instances of the gen_server behaviour which provides a client-server abstraction. Is this just an outdated idea to use it, or is gen_server:call something else?
&gt; (I don't know if you're the maintainer of the game or not) They are, yeah. Also, I think this form of the question is much better than mine was. Knowing the answer here would be great.
Is there a write up on this phenomenon? I know python still uses reference counting for most stuff, and GC for cycles. It seems to me, though I could be wrong, that stuff with actively changing counts are likely to be cached, so the common case (no cycles) will not cause things to be brought into cache. I guess it would be different if you use tracing GC. I suppose you could have references structured like A -&gt; B -&gt; C -&gt; D -&gt; etc... where things further down the line haven't been touched in a while. When the last reference to A drops, the whole chain goes. But this could happen in just about any language.
The standard Rust HashMap is designed to not be bad at any one use case while a standard no-frills linear probing HashMap would beat it if you have a low occupancy, good hash function, and low/zero negative lookup rate. This is because when you have a hit on a lookup and have a low probe length the extra checks for the robin hood score just slow things down.
&gt; a nightly-only SIMD version exists, but is not allowed Why isn't [the current default Rust install](https://www.rust-lang.org/en-US/install.html) *a nightly* instead of Rust 1.14.0 from December 22, 2016 ;-) &gt; or the rules recently changed [May 2016](https://alioth.debian.org/tracker/index.php?func=detail&amp;aid=315195&amp;group_id=100815&amp;atid=413122) &gt; with a single compile time argument can handily beat C Mostly I use the compile time arguments I've been asked to use, if you have demonstrably better suggestions…
Thanks for the plug! I'm the author for Statrs. I can point you towards the [Statistics](https://docs.rs/statrs/0.4.0/statrs/statistics/trait.Statistics.html) trait which you might find helpful. Cheers and feel free to reach out with any questions or issues!
Yeah I tried to simply git clone the source and compile it but I was running into some errors on my phone so I kinda didn't try to do anything with it. For other people, Termux is pretty neat. It is a terminal emulator that also installs apt and has it own repos(modest 500 packages) Termux has clang, go, Python, git, different shells, vim etc, so its fun to play around, and unless I'm mistaken(im rooted), you don't need root, it just has ~/home to its data folder, if you have root you can su and grant permissions. 
You'll have to bootstrap as rustc is written in rust. This is a bit complicated. You can follow japaric's awesome [manual](https://www.reddit.com/r/rust/comments/5ag60z/how_do_i_bootstrap_rust_to_crosscompile_for_a_new/d9gdjwf/) he gave on reddit.
Usually I asked people if they read the whole assignment and tried to understand it all before they started coding. If they said no, I knew the tutoring session was going to be a rough time.
&gt; Why isn't the current default Rust install a nightly instead of Rust 1.14.0 from December 22, 2016 ;-) Nobody thinks that the rule against nightly is bad. But it is a reason why Rust is behind, so it gets brought up. I don't think the game should use nightly, personally.
I just got https://github.com/llambda/jwt-secret-finder working. It's a JWT secret brute forcer, inspired by https://github.com/brendan-rius/c-jwt-cracker.
&gt; it should specify that copy is often the default action But it's not! You need to explicitly opt in to it. And, if anything, most people new to the language come from languages where copy is implicit; so there doesn't need to be as much emphasis on teaching how it works. Regardless, the new book does explain Copy in its ownership chapter. http://rust-lang.github.io/book/ch04-01-what-is-ownership.html
Yes, but I think the problem is that it isn't explained that copy is relatively common behavior, and is something that is *always* implemented with primitives. Obviously copying is implicit in most languages, but it seems very counter intuitive to bang ownership into newbies heads and then only at the end of the chapter explain that copy exists (and hardly a word about primitives), when in reality copy is something that they will encounter the first time they try to write a program.
Ok, cool. If I get motivated, I might just do it.
&gt; I did not mean to criticize the benchmarks game site. Do criticize! (Better -- provide solutions). There's plenty wrong; there's plenty wrong that won't get fixed - but maybe there are things that could get fixed. &gt; You are absolutely right with using stable. It would be better to say that, instead of *"is not allowed"* which suggests you feel it should be allowed.
&gt; C doesn't have a HashMap, so they get to write one specific for the benchmark… That's a very definite claim. Please show the URL to a current C k-nucleotide program where "they get to write [a HashMap] specific for the benchmark…" ---- edit: **Steve you have now admitted** that [The [C] library wasn't invented for this benchmark…"](https://www.reddit.com/r/rust/comments/5queq5/how_high_performance_is_rust/dd77vv2/) so please correct your posts which untruthfully claim "…they get to write one specific for the benchmark…"
&gt; … Steve is trying to find out… Steve repeatedly makes a definite claim -- *"C doesn't have a HashMap, so they get to write one specific for the benchmark…"* If that was the case then he could just provide you with the URL to the C program that used a HashMap written specifically for the benchmark. We can all see that C does not [*"…get to write one specific for the benchmark…"*](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=knucleotide&amp;lang=gcc&amp;id=1). Why does Steve say it does? 
&gt; But allowing C to use a custom crafted Hashmap… **Please** show the URL to a current benchmarks game C k-nucleotide program which uses "a custom crafted Hashmap" for k-nucleotide. We can all see that the C program **does not** [*use a custom crafted Hashmap*](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=knucleotide&amp;lang=gcc&amp;id=1). Stop [making stuff up](https://www.facebook.com/carrieunderwood/posts/10151639746554568).
http://benchmarksgame.alioth.debian.org/u64q/program.php?test=knucleotide&amp;lang=gcc&amp;id=1 https://www.reddit.com/r/rust/comments/5queq5/how_high_performance_is_rust/dd46tio/?st=iykqy48x&amp;sh=23bcf270
It's important to remember that "implicit copy" is the same exact thing as a move. The only difference is what you can do with it afterward. Most of the people I've talked to don't get hung up on it at first, at some point they go "wait a minute" but have learned enough that the explanation makes sense.
[removed]
Though I also didn't much like that comment, let's keep it civil. This is a cross-site community, after all.
&gt; Please remove the strawman in your post. While the Trump Administration did enforce this legislature, the groundwork was laid by the Obama Administration on the recommendation of the DHS in 2016. Temporarily refusing refugees from failed states is within the rights and legal powers of the Executive office and it wasn't racist then and it certainly isn't racist now. &gt; &gt; If you really care forfeit your deposit. Otherwise stop virtue signaling. &gt; &gt; And if it was religiously motivated (IE a muslim ban) Indonesia would be on the list too since it has the highest muslim population in the world. &gt; &gt; Salaam &gt; &gt; Double Edit: I can't figure out how to respond but thanks for not being hypocrites at least. Was there another comment that was deleted by mods or something? I can definitely see why someone would disagree but I don't think such words are deserved.
Yes, I have admitted as much. The difference is that they do so as last-resort damage mitigation, not as their modus operandi, the way Erlang's dynamic types with massively redundant computation does. For example, rather than defaulting to rebooting when hardware corruption is detected, as per Erlang's "hardware is faulty, live with it" ethos that makes so much sense for server farms, they may first attempt to make the computation robust, for example by replicating it and taking consensus.
Does the tool handle Unicode homographs?
I don't think this is a particular nice idea, since a) your fancy_push does not do what the OP wants (pushing the length of the vector, not some arbitrary element), b) you lose access to the other vector methods, c) you need to keep track of the length, a property which you already have in `Vec`, which can lead to bugs and violates the single source of truth principle, and c) Rust has much nicer mechanisms to extend the functionality of types, as you can use traits to add methods to existing types, like trait PushLen { fn push_len(&amp;mut self); } impl&lt;T&gt; PushLen for Vec&lt;T&gt; { fn push_len(&amp;mut self) { let i = self.len(); self.push(i); } } fn main() { let v = vec![1, 2]; v.push_len(); // v == [1, 2, 2]; } In my opinion, traits are often nicer than wrappers/adapters. Wrappers are only needed if you can't modify the original class, which is the case in e.g. Java with interfaces (because you can't implement interfaces after the class is defined), or in Rust if neither the type nor the trait are defined in your crate (see orphan rules).
I get it, I'm pissed about the travel ban as well and I think the user in question is defending the indefensible. But there are clear standards of behavior in the Rust Code of Conduct on how to treat fellow users.
Given the context of what's going on, I think the insult is totally deserved. Let's break this down point by point: &gt; Please remove the strawman in your post. There is no strawman in the post. Aturon's post is purely factual. &gt; While the Trump Administration did enforce this legislature, the groundwork was laid by the Obama Administration on the recommendation of the DHS in 2016. Temporarily refusing refugees from failed states is within the rights and legal powers of the Executive office and it wasn't racist then and it certainly isn't racist now. This is extremely misleading (even putting aside assertions that places like Iran are "failed states", which it pretty clearly isn't). What the Trump administration has done goes far beyond anything the Obama administration did. The Obama administration temporarily stopped granting people from Iraq refugee status, but still allowed them to apply for visas the normal way. The Trump administration has banned non-US-citizens from seven nations from entering the US for any reason. This includes permanent residents, i.e. people who live and work in the US and whose families reside in the US. Trump has also proposed religious tests to enter the country. Additionally, there are reports that CBP officials have threatened people with five years in prison if they do not sign away their green cards. Trump claims he did this "for national security", yet not one person from the seven nations involved has committed a deadly terror attack in the US in the past two decades. Rudy Giuliani has out-and-out stated that this was supposed to be a Muslim Ban done legally. It is arguable whether the Obama administration refusing to take refugees from Iraq was racist then, but this is *certainly* racist now. &gt; If you really care forfeit your deposit. Otherwise stop virtue signaling. "Virtue signaling" is an white supremacist phrase meant to shame people who stand up to bigotry. The use of this phrase is a dead giveaway that ShibbyContinuum is a white supremacist. &gt; And if it was religiously motivated (IE a muslim ban) Indonesia would be on the list too since it has the highest muslim population in the world. &gt; Salaam Again, from the Trump administrations statements, it is *very* clear that this is an attempt at a Muslim Ban, with the barest fig leaf over it to make it seem legal. It is clear that ShibbyContinuum is a white supremacist arguing in bad faith in order to support discriminatory policies. The fact that this post is the first reply to a thread attempting to help people affected by said discriminatory policies is embarrassing and should be called out. People like ShibbyContinuum should not be welcome in any community.
&gt;"Virtue signaling" is an white supremacist phrase meant to shame people who stand up to bigotry. The use of this phrase is a dead giveaway that ShibbyContinuum is a white supremacist. I know them and they're not even white. And we've never been welcome in the community and we continue not to care.
Interesting. I did not know there was _any_ copying being done. I had naïvely assumed the compiler was telling itself "ok now X owns this region of memory".
http://slatestarcodex.com/2014/02/23/in-favor-of-niceness-community-and-civilization/ The reason there's a need to be civil is because there's a symmetry to these things. It might not be "everyone is equally right" but it's at least "everyone sees the other side as equally wrong." If seeing other people being wrong is enough to be uncivil, no one will be civil, ever.
For what it's worth, as someone learning Rust, even though it is in the documentation, I still find it kind of goes against the "implicit is bad" opinion that I often read in RFCs and answers here. Some types are copied, and yes it is in the documentation, but it is not very explicit and can be surprising.
Agreed. If &gt; we are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, disability, ethnicity, religion, or similar personal characteristic then we *must* stand up against Islamophobia and those who support it.
[removed]
&gt; Do moves actually copy data or just change ownership? You've already got good answers, but one way to think about this "from first principals" is: what happens when you call `push` on a `Vec&lt;T&gt;`? You pass it a value of type `T`, which is moved into the vector... which means some how getting the value onto the region of the heap that the `Vec` manages. That is to say, it's often necessary to move things in memory when transferring ownership. For types like `Box&lt;T&gt;` and `Vec&lt;T&gt;`, a move is much more like a change of ownership, since it's only the raw inline storage (just a pointer, or a pointer plus two integers, respectively) that is moved in memory, but even for them that inline storage is still bitwise-copied.
Is this satire?
No.
Everyone upvoting this should be aware that this user means they are "not welcome" because our community has a Code of Conduct. See how people of this political stripe will manipulate your 'neutrality' for their benefit. Context: https://www.reddit.com/r/rust/comments/5q45gh/new_rust_tshirts/dcwxskd/
[removed]
&gt; The Rust community wants bigots more than it wants Muslims. Message received. I think this thread is being invaded by another subreddit and/or offsite trolls. Don't let the downvotes drive you away from the Rust community, because my guess is they don't come from the Rust community. Overall the Rust community strives to be tolerant and welcoming, and is often attacked by bigots specifically because it attempts to be tolerant and welcoming.
[removed]
I don't blame you. Documentation is there. If you didn't know where to find it that's one thing. Once you've been directed there I don't think there's an excuse.
&gt; Advocates moving the conference outside of the US for political reasons This is incorrect! Aaron only expresses his opinion about the executive order, he does not advocate moving the conference as a result. You have extrapolated that idea from his post without basis. Before you try to convince me that your extrapolation is justified, you should consider these facts: * I was privy to the conversation about the possibility of moving the conference, my read of which was that we were undecided but leaning against it. * It was my suggestion that Aaron make this post to gather more information instead of us speculating wildly about who might be impacted.
[removed]
In more detail the post came across as advocating it was a good idea, but not necessarily worth the associated costs. If that wasn't the intent behind the post... well oh well... I do apologize if I've managed to offend anyone by misinterpreting it. Either way, regardless of the motivation behind the original post, the points I made still stand.
More accurately, it's a pointer to such an array, so `&amp;[0xA]`, with the type `&amp;'static [u8; 1]`.
Yeah, but you don't speak for the community, so stop pretending like you do. Unless we don't count. In which case you're a hypocrite. Now I respectfully ask that you leave me alone, you're just wasting energy, you and I will never see eye to eye.
I suspect that Aaron may have intended to link to the version of his post on users.rust-lang.org (https://users.rust-lang.org/t/rustconf-2017-and-the-us-travel-ban/9214) rather than the version on internals.rust-lang.org, given that the former is preferred for user-facing feedback.
[removed]
Please behave honestly. I haven't claimed to speak for the community, and I am not stalking you. We have had two recent interactions - in the first, you were the one who brought up that we 'don't get along,' and in this one you have again brought up that you don't feel 'welcome' because we have a code of conduct. When you just say 'we don't get along' or 'i don't feel welcome' to an uninformed observer you present yourself as the victim of some unkindness. But most members of this community would not agree, knowing the facts, that you have been the victim of any unkindness. To avoid their confusion, I have demonstrated what this disagreement or unwelcoming actually is, so they can judge the situation in its proper context.
I contribute actively to the language and would not if there were not a Code of Conduct. Graydon Hoare has said publicly he would not have agreed to initiate this project without establishing of Code of Conduct. I'm confident the Code of Conduct is a requirement for many other major contributors to the project. Therefore, the Code of Conduct adds *enormous* technical value to this project.
So for the record, the now-removed post wasn't mine. Although I agreed with that post, the moderators think that it crossed a line, and I understand and respect that. I strongly agree with your point that civility is strength, and I usually try to be civil to people who disagree with me. However I do think that valuing civility over standing up against bigotry is wrong. As cliché as it is, I'm going to quote MLK, because he puts it quite well: &gt; I have almost reached the regrettable conclusion that the Negro's great stumbling block in the stride toward freedom is not the White Citizen's Council-er or the Ku Klux Klanner, but the white moderate who is more devoted to "order" than to justice; who prefers a negative peace which is the absence of tension to a positive peace which is the presence of justice; who constantly says "I agree with you in the goal you seek, but I can't agree with your methods of direct action;" who paternalistically feels he can set the timetable for another man's freedom; who lives by the myth of time and who constantly advises the Negro to wait until a "more convenient season." Shallow understanding from people of goodwill is more frustrating than absolute misunderstanding from people of ill will. Lukewarm acceptance is much more bewildering than outright rejection." &gt; -[Letter from Birmingham Jail](https://kinginstitute.stanford.edu/king-papers/documents/letter-birmingham-jail) This is all getting fairly far removed from the original discussion about potentially moving the Rust Conference, however, so I will drop the argument for now.
&gt; ban doesn't realistically effect a significant number (if any) of the RustConf attendees Minority groups in our community are precisely the attendees we care the most about accommodating. This is how you achieve diversity. If we don't care to expend effort to be more accommodating, then we can also abandon all efforts to support the attendance of people who are female, LGBT, disabled, or basically anything other than "white dude". After all, we know from the [2016 Rust Survey](https://blog.rust-lang.org/2016/06/30/State-of-Rust-Survey-2016.html) (and other resources) that our community is mostly white dudes, with everything else making up a couple percentage points here and there. But thankfully we care, so we will try. Caring about these things is foundational to the project and its community. If anyone here disagrees with this, then they should absolutely leave. This place is not for them.
My response [here](https://www.reddit.com/r/rust/comments/5r4b6w/rustconf_2017_and_the_us_travel_ban_community/dd4l5qj/) covers the rest of this. &gt; I don't think there would be much impact of such a statement even if we wanted to. Being able to point to this and say "These policies are causing highly skilled technical talent to leave the US" sounds like a pretty effective statement. If it inspires more conferences or such to do the same even more so. &gt; We don't know that, this is exactly why Aaron made that post. Yes, but we can state it with high probability. In the rare case where that doesn't end up being the case my post is of course irrelevant, I should have made that clearer given how sensitive the topic is. &gt; The country is currently in a constitutional crisis over the executive not listening to the courts. While I'm aware of the issue, if this continues to be the case for months we have a much bigger problem at hand than RustConf... in such a case might I advocate we move ~~me~~ RustConf to Australia, it seems almost far enough away.
&gt; Yes, but we can state it with high probability I'm not so sure.
[removed]
Great quote! I agree that in some cases its okay to do things that are outside of the rules to achieve your goal, but by insulting people you don't achieve much. Either way, you are right that it moved off quite far, so I'll do different stuff now as well.
&gt; There is no consitutional crises, at least not a new one! CPB (the border police) was refusing to let detained travelers go in violation of a court order. That's about as constitutional crisis-y as it gets, the executive not abiding by the judiciary's rulings. Entirely different from violation of constitutional rights that have been going on since 9/11. 
Okay, I'm going to stop both of you here. This discussion is over. Feel free to argue all you want in private.
Personally I don't worry too much if I end up with a long block of `use` lines. They may not be the prettiest, but those lines are unlikely to hold bugs or confuse people reading my code, so I focus my efforts elsewhere. I agree with the advice to prefer importing modules rather than individual functions or (in many cases) types, though. In particular, I agree with /u/ticki_ that I'd much rather read `mpsc::Sender` than `Sender` every time it's used. Although obviously I import specific traits when I use them or my code wouldn't compile.
I can totally see where you are coming from with your moderation decision, and I completely respect it. Good on you for keeping a cool head, and good on you for protesting at an airport this weekend. Btw, if you want me to edit the top of [my post](https://www.reddit.com/r/rust/comments/5r4b6w/rustconf_2017_and_the_us_travel_ban_community/dd4h4mh/) to remove the quoting of the deleted post, let me know and I'll happily do so. Although I think the insult was warranted, I also understand that the Rust subreddit is not be the place for it so I'm fine with deleting the reference to it.
I wrote a server for a SCADA protocol using Tokio. For this case, the code below sufficed: pub struct ModbusService { block:Arc&lt;Mutex&lt;BlankRegisters&gt;&gt; } impl ModbusService { fn new ( block:Arc&lt;Mutex&lt;BlankRegisters&gt;&gt;)-&gt;ModbusService { ModbusService{ block:block} } } impl Service for ModbusService { type Request = ModbusTCPRequest; type Response = ModbusTCPResponse; type Error = io::Error; type Future = future::FutureResult&lt;Self::Response, Self::Error&gt;; fn call(&amp;self, req: Self::Request) -&gt; Self::Future { let mut a = self.block.lock().unwrap(); future::finished(Self::Response { header:req.header, pdu: a.call(req.pdu) }) } } But for the next version I really need the Service struct to be initialized with a Channel to send messages to a central thread. In Tokio-Lang, this involves using futures::sync::maps::channel. Unfortunately, trying to use one of these fails because the call() function requires (for its trait) a non-mutable reference to self. Is there a way around it? 
Wondered that too, ended up creating an account on internals. Hoping it won't be seen as opportunistic
Yeah, probably. It was just weird that it worked fine for many months, and then suddenly stopped working.
Here's the recent forum thread on [improving nested method calls](https://internals.rust-lang.org/t/accepting-nested-method-calls-with-an-mut-self-receiver/4588).
Oh wow, if so it's working well then :) Though I don't know if that could make it fail "randomly" like OP suggested?
&gt; The reason is that English is the lingua franca of CS, and any developer who has one of those as their native language will speak at least technical English. Just to be clear, while this does apply to Hindi and probably German, this isn't a general statement, many non-English programming communities do exist, with their own terminology and stuff. It's not even all European ones. Portuguese for example has a very large programming community of folks who speak _only_ Portuguese. This is mainly localized in Brazil, not Europe, but the language is European.
Sorry, to clarify: the call to inet_addr() was always failing. The subsequent error code returned by WSAGetLastError() was random, but that could have been caused by my debug output. Good call, /u/joshmatthews, that's almost certainly what it was.
I was hung up on this for a while when I started. It did not help that most of the docs used primitives that implement Copy. When I would swap out the primitive for a String or custom type I struggled to understand why it was different. It prompted me to write a number of blog posts on the subject. I will mention that this was prior to Steve's awesome work on the docs.
Sitting in the echo chamber wont help anyone. 
Don't forget all kinds of factories! Before C++11 those where clumsy to code...
I was GOING to write a post about how I'd expect most C++ compilers to throw a warning about this sort of thing, but as it turns out... nope. The following compiles with `g++ -Wextra`, with no warning. I can't even seem to get clang-analyzer to complain about this. Since it looks like Clippy will detect this, I think we can once again claim that Rust is "better" - although in this case it still provides a pretty big footgun. #include &lt;stdio.h&gt; #include &lt;string&gt; int main(int argc, char** argv) { auto foo = std::string("Hello, world!").c_str(); printf("%s", foo); } I am, as always, surprised about the things C++ compilers DON'T warn about.
Damnit, why are you telling users to use `kind="static"`? Do you hate bunnies or something? Resource files are *not* static libraries, and if you try to link them into a rlib as if it was a static library rustc will stupidly bundle the resource file into the rlib which will *break* it. Also, why do you even demand that the user manually link to the resource file or manifest, isn't that supposed to be the job of your library? Since your library is going to be called from build scripts only, what you should do is have your build script output the relevant `"cargo:rustc-link-lib=dylib={}"` bit so that it is automatically linked by the linker. Note the `dylib`! If you really want the user to have to manually link it, at least tell them to use `kind = "dylib"` and not `kind = "static"`. Also, why do you ask the user for an out directory? Just get the output directory from the `OUT_DIR` environment variable in the build script. You already tell the linker where to look anyway using `"cargo:rustc-link-search=native={}"`.
Funny. I was just reading this, then a few minutes later I casually found a [dangling `CString` bug](https://github.com/crumblingstatue/rust-libxdo/commit/37480e3074075959bd9746a4d4b2d79544168c42) in one of my own projects. Not even clippy warned me about this one.
I'd like to remind everyone here to stay civil. Please note that this community strives to be welcoming, but that also means everyone has to follow the code, lest they sour the welcome for others.
You have to compare a very good GC to a very bad allocator before you'd be able to observe that result. I'd be very interested to see a benchmark which actually showed that result. Saturate all threads or lock affinity to one core, then do some test with tight loop allocations. I don't think the GC version will be very close, but I'd be very interested if the results showed otherwise. 
It might be a silly idea, but is it possible to hold the conference right on the border? The ban affects people in both directions, leaving and entering the US.
Among other things, I'd be happy to take a PR to add a benchmark to [peg_tests.rs](https://github.com/google/xi-editor/blob/master/rust/lang/benches/peg_tests.rs). I certainly didn't mean to exclude any actively developed parser combinator library, but didn't trawl thoroughly.
Can't agree more, this doesn't benefit anyone. It's also quite sad to see when people you were working with are revealing themselves as political extremists.
In my opinion a lot of categories are missing though. I think there should be some sort of metaissue or thread where people can post the names of the libraries that they think don't belong to any existing category. 
How does one get a package listed under a particular category?
Author of combine, something like this should work in combine but I can't test it at the moment. fn my_number(s: &amp;[u8]) -&gt; ParseResult&lt;(), &amp;[u8]&gt; { ( optional(b'-'), token(b'0').or(take_while1(is_digit)), optional((token(b'.'), take_while1(is_digit))), optional((token(b'e').or(token(b'E')), optional(token(b'-').or(token(b'+'))), take_while1(is_digit))), ).map(|_| ()).parse_stream(s) } Combine uses a similar approach with traits so the translation is pretty straightforward. It is however extended to allow input from anything implementing [Stream](https://docs.rs/combine/2.1.2/combine/trait.Stream.html) and it provides pretty nice error messages (at a small runtime cost) so the trait does not look quite the same as yours [Parser](https://docs.rs/combine/2.1.2/combine/trait.Parser.html). Happy to answer questions if you have them! (Reminds me, I should probably write something about combine's internals at some point since they have been extended in a few different non-trivial ways to make the code actually optimize well under LLVM.)
combine's choice of trait based parsers was definitely hurting back in the beginning so going with macros was certainly correct back then :). The compile times have improved massively over the last year however so the big types created only result in a fairly small linear overhead now. https://github.com/rust-lang/rust/issues/21231 https://github.com/rust-lang/rust/issues/23069 https://github.com/Marwes/combine/issues/21
Thank you for the question. If I'm not wrong, Rust by default uses unicode strings, so the answer is yes. If I'm wrong please let me know. :)
There has also been discussion on this in https://www.reddit.com/r/rust/comments/5p4n9n/ann_categories_and_ci_badges_are_now_available_on/
Once I understood what was going on under the hood, I found the "things should generally be `Copy` if possible... but remember that Copyness is part of your API promise" advice from the docs to be counter-productive. Looking at how it's used in `std`, it makes more sense to think of `Copy` as a flag to the compiler indicating that something is primitive enough that asking people to explicitly clone or borrow it would hurt more than help. (Especially in cases where an unoptimized borrow in a debug build might result in taking a 64-bit pointer to an 8/16/24/32-bit number/struct, like a `u16` or an RGB888 pixel value) (ie. `std` usage of it makes more sense if you think of it as being part of Rust's commitment to making compiler errors as helpful as possible, rather than part of Rust's safety guarantees and API-enhancing syntactic sugar.)
To be honest I'd really like if we had to call `.copy()` on a variable to get a copy from it. I say that because for non-primitive types, I never know if I'm moving or copying unless I actively look at the documentation or source code. In this case, being explicit helps a lot, because then all assignments will only have one action by default, which is moving.
The best resource for finding out about the current state of the Rust web ecosystem is '[Are we web yet?](http://www.arewewebyet.org/)'.
&gt; I think there should be some sort of metaissue or thread where people can post the names of the libraries that they think don't belong to any existing category. You mean like a category of categories? Some sort of higher category, perhaps?
There is a [categories](http://doc.crates.io/manifest.html#package-metadata) field in your toml now, where you can add [specific categories](https://crates.io/category_slugs) 
&gt; users to use kind="static" I don't know, because I make a static library, maybe? &gt; Do you hate bunnies I'm indifferent about bunnies, but I prefer eating them to looking at them, so you could say that. &gt; Resource files are not static Of course they're not... Up until I compile them (and explicitly make them into a static library with `ar` on non-MSVC), by which point they (or, rather, the thing I link to) are. &gt; link them into a rlib &gt; rlib which will break I've no idea about the customs of ~~this land~~ rlib. Elaborate? &gt; have your build script output Well I [tried that and it didn't work](https://github.com/nabijaczleweli/cargo-update/commit/ef4346c96b1e55bb837557520e6ea09d3f0d867e#diff-639fbc4ef05b315af92b4d836c31b023R1). What did work was explicitly linking from `main.rs`, but that was a couple of versions ago, so maybe it'll work "normally" now? I'll test. &gt; Note the dylib! I'm not making a `dll`, I'm making an `a`/`lib`. &gt; least tell them to use That's the third time you said that and I've no idea as for the reason :v &gt; ask the user for an out directory It's called a customisation point. &gt; Just get the output directory from the OUT_DIR environment I [do](https://github.com/nabijaczleweli/rust-embed-resource/commit/7c5c0740998abd1d68ccfc28443a7acc086d713e#diff-b4aea3e418ccdb71239b96952d9cddb6R24) &gt; already tell the linker where to look anyway using Yes, so I can link to shit in there. Point?
So it is true that you need to know category theory in order to use Rust?
Perhaps there is a misunderstanding. I don't see any shadowed type names in my code. It's a dangling pointer, beacuse the `CString` goes out of scope prematurely.
Awesome, thank you!
I'm planning to turn [PlanetKit](https://github.com/jeffparsons/planetkit) into a "proper" library and one or two demo apps using it, instead of having all the code specific to an individual game mushed up with the library code. At the moment, you can't even choose which systems (a la ECS) you want -- it's just whatever's in my demo app -- and I'd like for that to be the main way to mix and match different kinds of behaviours. I've also written about my last bit of work on PlanetKit, which was to [implement basic mining](https://www.reddit.com/r/rust/comments/5r7vna/these_weeks_in_planetkit_7_changing_the_world_one/). Aw yis, it's practically Minecraft now!
What's the purpose? Testing? Automization?
Maybe offtopic but the mobile site needs some fixing.
I think that without `Copy` or with explicit `.copy()`, Rust would be nigh unusable.
Is the [new version of the Book](https://rust-lang.github.io/book/) similarly confusing? If so, maybe you should file an issue. IIUC, the version I linked will be the “definitive” Rust Book, printed on paper and all. The other is kept online until the new version is ready, but doesn't seem to be updated any more.
I just found it amusing that "written in C++" with no qualifier added (i.e. it doesn't say "written in *bad* C++") is called an issue that browsers suffer from.
Can you disable/reduce the quality of error messages, like `attoparsec` vs `parsec`? Probably not necessary for a lot of use-cases, but for mostly-automated message passing it'd be nice to turn them on for debugging only and get a nice marginal speed boost in release.
Yup, I'd put that in API and Hardware as well if I were you. Edit: And if you mean for it to be at least partially used for tests and automation as mentioned in the other comment, there's the development tools category. ( You can specify up to 5 btw)
I think calling `enqueue(|_|loop{})` on a separate thread will quickly reveal that the ring buffer is not very lock-free at all :D
&gt; Can you disable/reduce the quality of error messages, like attoparsec vs parsec? That's something I would like to have but since I haven't had a need for it myself and it is a lot of mostly uninteresting refactoring (threading an associated `Error` type everywhere) I just haven't gotten around to doing it. The overhead itself is only about 10-15% at most in the cases I have tested as the `Parser` trait has been created in a way that lets parsers avoid actually creating an error message in common the most common cases such as `token('a').or(token('b')).parse("b")`
I'm new to rust so I didn't know about the new book so thanks for linking that. It should probably be added to the sidebar (or as a link from the old book for that matter). As far as I can see, the new book doesn't seem to cover this in detail yet, though there is something at https://rust-lang.github.io/book/ch14-02-publishing-to-crates-io.html, which at least doesn't repeat the confusing things mentioned above. So I suspect by the time the new book is released this will likely have been dealt with better.
I have that on my todo list now, thanks for helping me!
According to my (limited) knowledge, that lint is very naive. It pretty much just checks `CString::new("foo").unwrap().as_ptr()`, and that's it. To implement this check "properly", clippy would have to do do things similar to what rust's lifetime and borrow system is doing right now, which would be a huge undertaking. ~~Hmm, thinking about that... Couldn't there be an `as_ffi_ref()` or something like that for `CString`, which would be a proper borrow, which can then coerce to a raw pointer?~~ EDIT: Actually, this wouldn't help in the case linked above. I guess sometimes the programmer has to take responsibility when working with `unsafe` code, and examine carefully what they are doing.
Why does this queue lock the index when reading / writing instead of atomiclly advancing the indices so multiple readers/writers can operate together? Also, for a thought experiment, say a thread writing to the queue is interrupted and the interrupt handler wants to send a message o the queue. Will the handler (or other writers) be able to make meaningful forward progress? 
It's more to do with the way that lock-free is defined rather than the actual behaviour of popular operating systems. The hypothetical environment used in the definition is not guaranteed to ever schedule any given thread.
If a thread trying to write is interrupted and the interrupt handle wants to write as well, it will not be able to make progress doing so and not writing doesn't count as progress. So just from that this queue is not lock free, unless the system has no sort of interrupt handlers. Also, it's really the other way around - in conditions where the runtime of some code can be given an upper bound, this is technically lock free. But in those cases a normal mutex is trivially lock free as well since most of the conditions which make lock free an interesting property don't apply (bounded execution, no interrupt handlers).
I'm starting to learn Rust while writing a stepper-motor controlling app for my brother. We want the motor to be attached to a RaspberryPi while the app will run on some other device (probably his Windows tablet and my Linux computer) and send commands over Bluetooth or Wi-Fi. For GUI I'll probably use Conrod as it seems to be the most portable UI toolkit available. For the communication, I'm not decided yet which crate to use (does anybody have a suggestion?).
On the other hand, people in the US have more options than people outside. They can try to be politically active inside the US.
No. The only building allowed that cross borders are border control buildings.
We used to require that you write `move` for moves, just like you need to write `mut` for mutability. It was really bad, ergonomically speaking.
Where does glium fit? I cant find it under Graphics or API Bindings.
&gt; never link against a .dll anyway Well, yes I do, but the rest makes sense. &gt; bundled into the rlib I've still no idea as to what that bloody rlib is :v &gt; then link.exe won't I don't have `link.exe` so &gt; doing it inside a binary crate I use this in library crates (that also happen to have execs so I do link to them) so nah &gt; kind=dylib is what you want I don't really see the clear benefit -- on one hand there's a logical connection static library-`static` link type (and at least three people can vouch for that working), on the other a fix for something that doesn't seem like it's broken. But do enlighten me as to what an rlib is and why it'd break.
Should totally warn and doesn't. Built without optimizations it "works", since the freed memory still has the string in it. If you build it with optimizations the generated code prints garbage. It uses an unitialized value on the stack as the string pointer, and will output whatever is at that address. This is expected, I think. The compiler "knows" that we can't use a pointer after it's freed, so the alloc/free, without a use in between, can be optimized away. That leaves us passing an unitialized ptr to printf. As far as the compiler is concerned, this is no worse than passing a freed one, although in practice they have very different implications.
I see no reason to accommodate for minorities. "White dudes" make up the largest percentage of all programmers rust or no rust. If you see that as a problem, I don't know what you can do besides forcing women into the industry. In terms of ethnic groups, I believe college access might be the reason for lack of diversity on this.
An rlib is a rust static library - it is the same as a C static library except that is has some extra bundled metadata and has the .rlib extension. Only the -gnu toolchain is capable of linking directly to .dlls. The normal practice on windows is to also produce a static import library when building a dynamic library, and downstream crates only link to the import library. `kind=dylib` is the correct option, it doesn't matter that three people "vouched" for it, since clearly none of them actually tried it on an -msvc toolchain!
Pretty sure I read somewhere that the mosque in texas got burned by a muslim.
Practically speaking, there likely don't exist many programmers in Yemen and Syria. Maybe some in Iran.
SJWs seem like the norm today.
http://stackoverflow.blog/2017/01/Developers-without-Borders-The-Global-Stack-Overflow-Network/#seven-countries Anyway, this is exactly why we're asking, we don't want to speculate.
Not that I know of.
For everyone suggesting live streaming from an in-person conference: as a conference organizer, I've looked into this and it's EXPENSIVE to do in any sort of usable way (quality wise). I have an agenda item on for [tomorrow's community team meeting on IRC](https://github.com/rust-community/team/issues/122) to discuss an all-remote conf, which could be done with a business sponsoring by letting us use their webinar tech. Having to *only* worry about the live stream and not about in-person folks too would be a much better experience for organizers, presenters, and audience members.
Which ones?
The use case of porting legacy code to Rust [must not be dismissed](https://www.reddit.com/r/rust/comments/5qq7ty/a_guide_to_porting_c_c_to_rust/dd32xrb/). If you rewrite it to become from **"**modern**"** C++ to Rust, it becomes useless for a deal big a amount of legacy C++ codebases that exists. **"**modern**"** C++ is a relatively new thing, so be wise.
I haven't really thought about it. I just wanted to have some place where I can dump the markdown and also have some sort of comment section. On a second thought, I can use the overview page to have an index for the posts. Also I could use tags -- not sure if gists have that feature as well.
I derped
No particular advantages I suppose in the end. If you're wanting to have comments then I guess it's the best way through github to use issues. It was just a little curious :) You could alternatively use Disqus for comments if you'd use github pages, but then suddenly there's a lot more work if you just wanted to quickly jot down a post and not have to worry about anything else.
I did use `PhantomData` but it doesn't prevent me from having a proxy that live longer than the structure: #[derive(Default)] struct Owner&lt;'a&gt; { _p: ::std::marker::PhantomData&lt;&amp;'a ()&gt; } #[derive(Debug)] struct Limited&lt;'a&gt; { _p: ::std::marker::PhantomData&lt;&amp;'a ()&gt; } impl&lt;'a&gt; Owner&lt;'a&gt; { fn limit&lt;'b&gt;(&amp;'b self) -&gt; Limited&lt;'a&gt; { Limited{_p: ::std::marker::PhantomData} } fn mutate&lt;'b&gt;(&amp;'b mut self, limit: &amp;Limited&lt;'a&gt;) -&gt; &amp;'b mut Self { self } } fn main() { let c = { let mut owner = Owner::default(); let l1 = owner.limit(); let borrow = owner.mutate(&amp;l1); l1 }; let d = { let mut owner = Owner::default(); let borrow = owner.mutate(&amp;c); }; println!("{:?}", c); } This compiles, but it shouldnt, right?
Honestly, I think that this will just foster confusion. Just put a prominent link to https://crates.io/keywords at the top on the front page and maybe add a tag cloud so that crate owners can converge to commonly used tags. The categories features IMO is an anti-feature. 
And there's also the issue of virtual attendants. It's easy for people in North America/Western Europe/... to suggest live streaming, however watching a live video feed requires a relatively good connection. Actually, even in "rich" countries, the hotels I've slept at generally had such a terrible connection that this would be untenable. Live-streaming has no border, but it is not all-inclusive either. I suspect that for people in Eastern Europe or the Balkans it might be easier to travel to Germany (by car) to attend in person than get a good quality live stream. Of course, as I personally live in Western Europe, I would be more likely to view the presentations live if it was live streaming rather than attending a US conference.
IMHO it probably deserve a big link in the front page.
Guy writes buggy leaky c++ code complains rust won't let him write as sloppy code.
This is absolutely wonderful. Thank you for putting this up!
try `a + a * b - (a / b)`
From [An Overview of Macros in Rust](http://words.steveklabnik.com/an-overview-of-macros-in-rust): &gt; The plan is that with the new macro systems, you’ll be able to use the regular module system, and use macros just like you use functions today. Thank God. Macros being in the global namespace is one of my biggest pet peeves in Rust. It makes me cringe every time I have to put a `#[macro_use]` attribute somewhere, so I'm glad to hear the devs plan to work on that.
&gt; I reckon most games - including AAA ones - use some form of either coroutines or lightweight/green threads, however. Unity3D has such functionality built-in, and games like Uncharted and Jak and Daxter used similar constructs extensively, from what I understand. Not to mention the recent trend FWIW most AAA games these days use thread pools with a job system to dispatch work.
A unicode homograph is a unicode character with a totally different value from a typical one such as a Cyrillic value but that looks exactly the same or only very slightly different. They decided to allow these instead of combining them because they didn't want to have the Han unification controversy all over again. Also, they already expanded UTF-16 to a variable length encoding so they have plenty of space. I suspect the answer is no. Not sure how to appropriately deal with Unicode homographs though.
We don't have auto-borrowing for ops, and even if we used functions, auto-deref only gets us so far. Also it interferes with type inference.
&gt; perhaps I want to execute it on disjoint subsets of the larger collection. https://doc.rust-lang.org/stable/std/primitive.slice.html#method.split_at_mut
There's been a Rust k-nucleotide program that replaced the default hash function with [FnvHasher since September 2016](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=knucleotide&amp;lang=rust&amp;id=2). TeXitoi already contributed [a custom-hash-function program](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=knucleotide&amp;lang=rust&amp;id=3) Jan 29 22:09 UTC and measurements were published Jan 30 19:35 UTC. Hash function in the program source -- so we can all easily see it on the website.
So what's the use case for Copy outside operators then? Because it sounds like it's mainly to accommodate math syntax that we have Copy, at least based on what you're saying. But then I'm confused why the docs for Copy advices that your types probably should be Copy if they can be... And even with your explanation here, it still seems like math syntax could have been made to work reasonably without Copy; as far as I can tell your reasoning is mainly based on design decisions as opposed to hard technical limitations. Sorry if I come off as pushy, but in all the research I've been doing on why Rust has Copy, the answers are all broadly in the category of "Why wouldn't it have?". But given that Copy fundamentally changes the semantics of the code compared to non-Copy in an extremely implicit way, I really don't find those answers satisfactory.
&gt; Could one simply ban the use of call/3 and therefor avoid this blocking forever situation? Nope! The implementation of call is just one process asynchronously messaging to another and waiting–by default for five seconds–for the process it sent a message to to asynchronously message it in a special fashion. `call/3` is very useful. &gt; Is this a very common issue (deadlocking) in Erlang? Oh no, not in my experience. It's a _possibility_ but something I've rarely seen in practice. That said, I don't often wait infinitely on responses. &gt; You mention: &gt;&gt; No one tells you that you should avoid gen_server:call for anything not absolutely necessary. I don't think I did? &gt; Is this just an outdated idea to use it, or is gen_server:call something else? Nope, still current. There is a possibility that any unbounded wait will be, well, unbounded. 
yes
Ah, you're right, someone else said that. Cool, thanks for the information.
that is the work that needs championing, yes.
Panicking is safe. It will usually end up closing the application, but it can't leak arbitrary memory. Folks generally _don't_ use unwrap. In libraries, you should use `Result`. In applications, you may want some kinds of errors to crash it, in which case you use `expect`. It's a thing to be avoided. But it's also useful in some cases, e.g. when there are invariants you know are satisfied from the surrounding code (and if they aren't, something has gone horribly wrong). Edit: when I say "leak" I mean "leak to an attacker", which is something most use-after-free bugs open an application up to.
But by that definition of a "non-hosted" environment, every terminating program is lock-free (hence why lock freedom is defined the way it is). What you really have here is a wait-free SPSC queue, and you're extending the functionality by wrapping each end in a mutex... That's certainly useful, but I just think describing it as "atomic" or "lock-free" in combination with MPSC is very misleading.
&gt; But it's also useful in some cases, e.g. when there are invariants you know are satisfied from the surrounding code (and if they aren't, something has gone horribly wrong). This came up for me today. I have a hard-coded array of elements. The `last` function on slices returns an `Option&lt;T&gt;` because if the list is empty, it needs to return `None`. I know the list will never be empty, because I hard-coded it, and if I hard-code it to an empty list, my application will not work. At all. So I used `unwrap`, and I don't feel bad about it in the slightest.
But what is your `Error` type? You don't define it anywhere, nor do you have a need to use Box, at least from what you've pasted here. Would this suffice? pub fn run() -&gt; Result&lt;(), &amp;'static str&gt; { Err("bad input") } To elaborate, in your current function signature, you describe your function as returning either `Ok(())` or `Err(Box&lt;Error&gt;)`, but you are trying to return `Err(&amp;'static str)` (no `Box` or `Error` to be seen here).
&gt; No worries, but sorry to hear that this is leaving you in a bad mood Don't worry about it, emotions don't always make sense. I'm feeling better today. &gt; Your original claim (at the point in which I first responded to you) was that a lack of pointers is always a bad thing. You're getting caught up on semantics. If your kettle doesn't work on Sundays, that's a bad trait. You might not be affected by this flaw, perhaps you only use it on workdays, but that doesn't stop it being bad - it just stops it mattering to you specifically. This is the sense in which I said not having pointers is a bad thing. It may so happen that for you the kettle is better because it lowers the price, so ends up actually to your benefit. But that doesn't mean someone is wrong to criticise the kettle for not working on Sundays. The difference here is solely one of the English language, not an actual debate about programming languages or kettles. &gt; You're still misunderstanding (or perhaps ignoring) that rebooting is not the only option in an Erlang-like system. It's one of many. I'm perfectly aware that you don't have to restart into exactly the same code as you broke out of. But the choice of how you handle things is completely irrelevant to my point. My point, to restate in different terms, is that Erlang's philosophy is to *allow* you to enter a corrupt state and then deal with them as they blow up. This works when corrupted states can be handled, and typically you do so by restarting the computation with a fresh view of data, though you may do so in a fair few varieties of the concept. But this doesn't work when you're likely working on the *only* copy of data (or hardware, in the case of a rocket), in which case when you enter the corrupt state there's a nonzero chance that you *cannot* recover. In these cases "fault tolerance" is a last resort, and "fault resistance" comes first. A fault resistant filesystem driver that occasionally blue-screens is far, far better than one that seamlessly "recovers" but does so more frequently, each time with a greater chance to permanently corrupt your data. &gt; Then you need to define "filesystem", because otherwise it's a very nebulous and broad term that - yes - does often encompass the management the medium upon which the files are stored, or at the very least awareness of that medium. Given I've never written a filesystem, I can absolutely imagine in practice the divide might be messy, but at least in principle the divide is clear. In vague terms, a filesystem is a data structure that provides file-like operations over a flat chunk of memory. That's why you can `dd` from a disk (or even a bunch of disks in RAID) to an `iso` file and then mount the `iso` - the backing disk is irrelevant to the functioning of the filesystem. &gt; I provided that suggestion as one very common example of a potential means of addressing such a failure. Like I said before, there are many other alternative courses of action. [List of examples] Beyond the joke options, those are all fundamentally the same approach: let it burn and pick up the pieces. That requires a place to pick up the pieces from, which means it's only a good idea to be reliant on that if you already have robustness, which is typically in the form of redundancy. A general purpose filesystem cannot assume that it has redundancy, which is why you need to stop fires before they happen. Frequently this includes things like extremely thorough journaling protocols, so that as long as feasible you never enter an unrecoverable state even in the face of misbehaviour. Note how this has nothing to do with *availability*. The filesystem may completely lose availability when recommitting journaled entries after a crash. This is why I say availability is not a safety concern, even if it is a usability concern. &gt;&gt; That assumes redundancy. What if you're running the filesystem on a microcontroller? &gt; What if you are? The point is that a general purpose filesystem, which is basically every filesystem not purpose-built for a server scenario, *cannot assume* that it has redundancy. Admittedly the example here wasn't a good one, but I was feeling particuarly lazy at the time. 
Well, the book uses `?` to do the conversion to `Box&lt;Error&gt;` (`try!` would also do this). To do it manually use return Err("...".into()); This works for any type that implements `std::error::Error` ([docs](https://doc.rust-lang.org/std/error/trait.Error.html)) as well as `&amp;str` and `String`. You can see the [From](https://doc.rust-lang.org/std/convert/trait.From.html) docs to see the implementations. These are on `From` because it implies `Into`.
I once read about a town that crossed the US-Canadian border, with some buildings crossing the border. But I think they closed that all off after 9/11. Perhaps if you had a stadium on the border with loudspeakers, people on both sides could attend the same talk. But that's probably infeasible.
Thanks! I tried your suggestion and now it compiles to "the trait std::convert::From&lt;std::io:Error&gt; is not implemented for &amp;str. I guess I trimmed too much from my sample. ;) It's basically the sample code 12-11 from the Rust Book, where the Error type comes from File::open and File::read_to_string() and the expect/? operators? I'm just doing a bit of extra work to screen the file text before continuing. My own changes are minor! Here is the run function from the book, with comments added where I want to bail out before doing more work. fn run(config: Config) -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { let mut f = File::open(config.filename)?; let mut contents = String::new(); f.read_to_string(&amp;mut contents)?; println!("With text:\n{}", contents); // return if some condition is met // initial check good, now process the file Ok(()) } Let's say after getting the file into the contents variable, I want to stop processing if there are any lowercase letters (or what have you) and return some useful message, something like Err("lowercase character in the file detected"). I think I'm asking - given this existing function and return type, how can return my own text message (i.e. convert a slice into a Box&lt;Error&gt;)?
&gt; I see no reason to accommodate for minorities. We wish to be an inclusive community. &gt; "White dudes" make up the largest percentage of all programmers rust or no rust. That does not mean we should cater to only them. &gt; I don't know what you can do besides forcing women into the industry. There's a lot you can do besides that. Outreach. I really don't want to get into this here, but there's plenty of material online about this to educate yourself with.
What are the advantages of a parser *combinator* compared to a parser *generator* (like [rust-peg](https://github.com/kevinmehall/rust-peg))?
Just to clarify a bit more. Panicking won't violate rusts definition of safety. Also by default all drops (deconstructors), will be called while unwinding the stack, which will clean up memory as expected. Notably leaking memory is safe though hard to do accidentally. The typically source is circular references with reference counting. But is as easy as mem::forget. One subtly of unsafe rust is that you can't count on drops being called, so they can't be used to enforce safety. Rust can be configured to abort (essentially kill the process) on panic instead of unwinding. Even with unwinding if there's is a second panic during the unwind then it will abort the process.
His concerns are completely valid. I've given up on implementing a number of things in Rust when I couldn't figure out how to do it as efficiently as I could do it in C. There are instances of having multiple mutable pointers to a buffer where *I* know that it'll be safe, but I could never convince the Rust compiler that it was safe. So I gave up and wrote those parts in C. For a language that touts itself to be a systems programming language, that's terribly embarrassing. Maybe there was a "Rust friendly" way to do what I was doing, but I couldn't figure it out from the documentation.
I've just played around a bit with github pages -- I did not know that you can now can use [markdown files](https://github.com/blog/2289-publishing-with-github-pages-now-as-easy-as-1-2-3). The generated [page](https://jaheba.github.io/stuff/communicating_intent) looks a lot easier to read when compared to github issues. Although the markdown [preview](https://github.com/jaheba/stuff/blob/master/communicating_intent.md) itself isn't too bad either. The only thing which is missing, are the comments. On the other hand people aren't too eager to comment. And it's really nice to see some thumbs up below the post :)
Thanks for the link. Definitely a good read.
The main advantage is that you don't need to go through any kind of code generation step, you're always using the vanilla language underneath. Aside from build issues (and the usual issues around error messages and debuggability, which in fairness are about as bad with macros as with code generation), it's usually easier to freely intermix grammar expressions and plain code.
Hm, I totally missed this. I should have suspected something when it was so easy to implement. I'm going to fall back to an other implementation idea I had, or fix the docs. Thanks a lot for calling this out!
It would be nice to have an "experimental"/"prototype" category for libs that I pushed that are that sort of thing. Although maybe there are better ways to mark a crate as "use at your own risk/potentially abandoned". 
As an aside, "non-hosted" environment is indeed very bad phrasing here, since there are non-hosted preemptive environments as well as hosted non-preemptive. "Non-preemptive" would be much better.
You seem to not be listening. This isn't a Rust exclusive situation. You don't need to cater to anyone, its already an inclusive community.
Cool, link us when things get going! :) Take a look at some code I am working on to be something similar: https://github.com/viperscape/stratis
&gt; My point, to restate in different terms, is that Erlang's philosophy is to allow you to enter a corrupt state and then deal with them as they blow up. Then I think this betrays a different misunderstanding of Erlang's safety model, which actually does maintain a philosophy of disallowing things that frequently cause failures (hence the mandatory immutability, the lack of pointers, the total isolation of memory between processes, etc.). It ain't like Erlang code is some kind of wild wild west like in C or assembly. This also continues to betray a misunderstanding (or perhaps a reluctance to admit) that even perfectly-safe code can make mistakes, be it due to the programmer's fault ("oops, I left a minus-sign somewhere and now the rocket's pointing the wrong way") or data corruption ("oops, the Van Allen belt flipped the 'burn time for Jovian insertion orbit' bits, and the rocket thrusted retrograde for 1011 seconds rather than 0100 seconds; oh wow, for some reason it feels like I'm plunging into Jupiter"). In other words, it's not a matter of *letting* things burn; it's a matter of realizing that fact that things often burn anyway for reasons entirely outside the programmer's control, thus warranting preparedness to pick up the pieces afterward. &gt; A fault resistant filesystem driver that occasionally blue-screens is far, far better than one that seamlessly "recovers" but does so more frequently, each time with a greater chance to permanently corrupt your data. I guess we'll have to agree to disagree on that one :) Personally, if a filesystem crashes - *even on a desktop machine or an embedded device* - I would very much prefer the ability to at least *try* to recover than for the system to just give up. Giving up does not fix the problem. Carrying on at least offers some probability of fixing (or at least working around) the problem. I certainly don't want my whole desktop session to grind to a halt just because I yanked out a thumb drive without unmounting it first. I'd also argue that a "filesystem driver that occasionally blue-screens" is the opposite of "fault resistant". It's clearly not resisting faults. Another note on this topic: even if restarting a faulting process was literally the only thing Erlang could do, rebooting a whole machine or device is already a very common troubleshooting technique, whether it's a server or a desktop or a router or a Furby. Why not make that more fine-grained and allow rebooting on a component-level? The traditional answer is usually "we don't have the technology", but we *do* have the technology. It hearkens back to my monolith v. microkernel analogy earlier; a microkernel-based operating system *can* withstand drivers crashing because they run in userspace, isolated from the kernel itself. Erlang-like fault tolerance systems just take that concept and apply it to general-purpose software rather than the OS itself (though [Erlang itself can *be* the OS itself](http://erlangonxen.org/)). &gt; A general purpose filesystem cannot assume that it has redundancy, which is why you need to stop fires before they happen. Frequently this includes things like extremely thorough journaling protocols, so that as long as feasible you never enter an unrecoverable state even in the face of misbehaviour. Sure, but this doesn't mean you have to bring down the whole system. There's nothing stopping you from delaying or even rejecting file operations temporarily while a newly-spun-up filesystem process performs those journaling-based recovery operations following the gruesome death of its predecessor. That's basically what filesystem drivers do anyway (check if the filesystem is clean, and if not, request a `fsck`); the difference is that - in the "Erlang way" - the filesystem can do this while the rest of the system continues to function. Basically: if the filesystem crashes, you have to restart the filesystem driver anyway so it can do its initialization stuff and verify the filesystem's integrity. The difference is between doing this on booting the whole operating system v. doing this dynamically while the system is still running "normally" (obviously in a degraded state, but not totally failed yet). Personally, I'd opt for the latter in pretty much every situation, and only resort to the former when the latter is physically impossible. In a redundant setup, it gives the overall system the opportunity to switch to a backup component. In a non-redundant setup, it at least buys time to send an alert to someone that the device needs serviced, or to spawn a debugger, or to do the myriad of other things aside from just giving up.
We plan to look into this already, this post is independent of that.
Sounds like you might be able to get paid to do it
I personally consider that to be a variation on the same theme, but good to know either way.
You can use `unbounded()` instead. Of course, it doesn't support a fixed-size buffer, but `UnboundedSender` shadows `send()` with an inherent method which takes `&amp;self`. Though, to be honest, `Sender` should have the same API because the implementation details are identical. In fact, `UnboundedSender` is just a wrapper *for* `Sender` that skips the backpressure part of the implementation.
X-Post referenced from [/r/programming](http://np.reddit.com/r/programming) by /u/amc22004 [MIT says their modified LLVM compiler optimizes parallel code "better than any commercial or open-source compiler"](http://np.reddit.com/r/programming/comments/5ra59l/mit_says_their_modified_llvm_compiler_optimizes/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
[/r/programming thread](https://np.reddit.com/r/programming/comments/5ra59l/mit_says_their_modified_llvm_compiler_optimizes/) I haven't read the article yet myself, the title just caught my attention and I figured it merited some discussion in a Rust context. There's some concerns in the comments that the article has a heavy PR spin on it and that the practical improvements to runtime have yet to be demonstrated. [This comment](https://np.reddit.com/r/programming/comments/5ra59l/mit_says_their_modified_llvm_compiler_optimizes/dd6266g/) appears to be particularly insightful. And [here](https://github.com/wsmoses/Parallel-IR) is the link to the author's LLVM fork.
I wonder if this feature could be implemented in a separate library using procedural macros. EDIT: I think that it is better to teach newcomers to add the parent as field to the child struct and write the delegation method by hand if needed. But in some special cases such as simple mmorpgs and computer algebra systems (and browsers engines?) it could be useful to have short hand notation for delegation.
Unfortunately not. Read from [here](https://github.com/rust-lang/rfcs/pull/1406#issuecomment-269240198).
And you can always go back later and replace the unwraps with proper error handling. Using unwrap everywhere is great when you're just trying to validate an approach, or get a basic prototype working.
What we do at work is use `expect` and write a "proof" of success in the given string. It's self-documenting and lets you immediately know which of your assumptions is no longer valid
Good idea. I didn't think to be that formal about it, but I do prefer things like`.expect("Failed to parse hard-coded value")` over `.unwrap()`.
Can someone suggest a concrete example of a problem not easily tackled without inheritance? (Bearing in mind the [XY problem](http://xyproblem.info/))
Enum to me would imply that these are different entities that are under some generic category (like colors of a traffic light or states of a transaction). Whereas Fahrenheit and Celsius are equally valid (IE interchangeable) ways of representing the same underlying quality.
A non-immediate-mode GUI framework is really straightforward to implement and use with inheritance. I'm sure there's technically a way to do it without inheritance, but it wouldn't look anything like what anyone is used to dealing with.
Have you seen [lopdf](https://github.com/J-F-Liu/lopdf)? I've been playing around with it and seems to work pretty well. https://github.com/jrmuizel/pdf-info/blob/master/src/main.rs
I'm unclear what the actual intent of comparison here is. The Rust function is just a wrapper over the symbol exported from libc.
You probably meant to post in /r/playrust.
I couldn't agree more!
Considering getting back into the Rust ecosystem by implementing a very basic scm tool similar to git.
Thank you for the explanation!
Does anyone else see clippy listed twice and dhinghy listed thrice here? https://crates.io/categories/development-tools
What a fantastic read! You seem to have some serious talent in technical writing. These kind of articles are excactly what is needed to convince people to try Rust.
I've also been working on some lock-free datastructures: https://github.com/Diggsey/lockless As you say, MPMC queues are hard and I haven't implemented one yet! It's also difficult when rust doesn't have double-width CAS yet. I would be interested to see what you think of the "IdHandle" abstraction I created to avoid memory allocation during send/receive operations.
It's not unsafe.
An excellent read. Very well written and perfectly demonstrated with your well selected examples.
I'm glad to hear it's being looked into, but why do you think it is separate? The linked post describes two main problems: * some people can't travel into America * some people can't travel out of America I would have thought that solutions which don't require cross-border travel in _either_ direction would be highly relevant.
Ok, my bad. It is of course safe in the language sense. :-/ Thanks for pointing that out.
Funny enough, this is actually on my short list of crates to make. Just someone posting they are in need of it is enough to make me want to finish what I have so far (mostly done minus polish and docs). Don't have any interest in doing it as work-for-hire though. Whomever does this, ping me if you want to collaborate instead of starting from scratch. Just going to bed now but I'll edit this post with a GitHub link tomorrow afternoon (work is just local on my desktop right now).
When you will have results for clang? So we could see real difference between C and Rust.
A bug I guess: http://i.imgur.com/QIfWCfE.png - it shows two instances of microfacet in Rendering. Where is a better place for reporting bugs in crates.io? Edit: fixed link
:-) your call, if I can support in any way (spec and testing) let me know.
You want r/playrust 
I use it when I'm prototyping things. I also unwrap when I want it to panic on wrong API usage of my function, or when an invariant would be violated, so panicing would indicate a bug in my program.
The nearly empty list already contains some opinionated choices (e.g. slog and rayon). With [cargo-esr](https://github.com/rust-alt/cargo-esr), I'm rooting for an unopinionated ranking approach. This topic is being discussed in [this RFC](https://github.com/rust-lang/rfcs/pull/1824).
I fully agree to this as a newcomer to Rust.
Getting a bunch of bits and pieces put together and fixed in the ecosystem to be able to have a first fairly basic version of a pure rust image viewer[1]. So far that has meant fiddling with conrod, winnit, glium, creating a new crate with a simple cache[2] and generally learning a bunch of stuff about how all these crates work. [1] https://github.com/pedrocr/chimper [2] http://crates.io/crates/multicache
Cupi is indeed a good choice. Sysfs-gpio could work too (not dedicated to RPI)
It's safe in every sense that Rust is safe, it just may not be simantically what you wanted. [You can also handle panics](https://doc.rust-lang.org/std/panic/fn.catch_unwind.html), so as long as that's what you intended, panics are safe.
Thanks for the answer and the pointer to more docs!
&gt; &gt; Additionally I don't necessarily agree that variable naming is the correct place to express units, I think a comment and using the type system is the appropriate approach. Yeah, I put that out there and if I didn't make it clear: I agree that's the superior solution. But there's lots of us out there who work on teams and who work on C/C++/other code where we could implement or leverage a physical units type system. In order to do that, we have to achieve consensus on which existing library or whether/how to implement one. Some slow-moving teams can take forever to make a change like that, yet physical units are slung around everywhere. If you are just now trying to convince the team that it's a net benefit but they haven't caught on, you can still write better code tomorrow morning. If you're in a review and you see flap-&gt;timeout = this-&gt;m_timeout; ... your instinct might be to just keep reading through the function. OTOH if it looks like this: flap-&gt;timeout = this-&gt;m_timeout_ms; ... your instinct will probably be: "hey...is 'flap-&gt;timeout' measured in ms too?" And you can look up the flap docs or ask the author, or all kinds of other good checks.
&gt;Even faster than NodeJS and Go Is NodeJS known for being fast? I mean async I/O is cool but a "hello world" does not really go in the direction NodeJS is known to be useful. And for Go there is fasthttpd with decent req/s rates. Apart from that [Rust beats them all](https://aturon.github.io/blog/2016/08/11/futures/)* And what i see this is very concentrating on HTTP pipe lining and OTTOMH almost no HTTP client is using HTTP pipe lining. I guess Firefox has an implementation but its not on by default. Chrome used it but its disabled now? I have no clue about MS browsers, but I've never heard from it so i guess its not implemented either. So its good for benchmarks! *take this with a smile and a grain of salt ;) 
When will *you* ? :-) stock answer -- *"If you're interested in something not shown on the benchmarks game website then [please take the program source code and the measurement scripts and publish your own measurements](http://benchmarksgame.alioth.debian.org/play.html#languagex)."*
The annotations gave me a clear picture of when the data is freed, and how I can think like the compiler when passing arguments and designing functions. I've been hitting my head against the &amp; key trying to get it to work, but this really helped me understand. I do wonder one thing: Why is it that every example has this before it? &gt; Filename: src/main.rs Isn't it pretty obvious that these examples are rust files that go in the src dir, and if you are compiling them, you name them? Wouldn't it be better to actually name them something useful so they are easier to reference, or so they can be bundled and downloaded? Just a tiny rant.
Yep! The `concat!` macro exists for this: https://doc.rust-lang.org/std/macro.concat.html Edit: Hmm, I could be wrong, looks like `concat!` only supports string literals and not `&amp;'static str` values.
It's separate because it can be discussed independently of that, and we're looking into it regardless of the decision there. If it turns out that we have a large number of people in one of those two categories but not the other, we can tweak the conf to fit that. _Independently_ of that decision, we can try to livestream. Livestreaming is not a complete solution and ignores one of the main reasons why people come to confs -- to network and chat. Doing it does not obviate the possibility of having to move the conf.
This isn't Python, this is C with a Python API wrapper.
Yeah, I'm aware. Thanks for the link. Brain malfunctioned at that time.
That is how you are supposed to use many dynamic languages like Python, though. I don't think dismissing it _in this way_ is useful; but as a component of something more comprehensive, it makes sense.
Macros are expanded after rustc parses syntax (which means, for example, parentheses have to match up properly), but before any semantic processing. So you wouldn't be able to make a macro expand `join!(X, Y)` into the contents of X and then of Y. For literals there are still things you can do to at least help with inserting delimiters [playground example](https://is.gd/VTDTlJ). Procedural macros might help (e.g. allow you to write a DSL for static string manipulation), but there is currently nothing stabilised.
&gt; Plus, on top of that, in most cases, you'd have pipelining delt with similarly to SSL termination; that is, your application server wouldn't have to worry about this. But would it not make sense for the TLS termination proxy to use pipelining to speak with the application servers?
&gt; So wouldn't that make rust faster than all other options then? Hopefully. But as always, it depends. Write code and benchmark it, don't speculate.
In general, you can't just command a piece of data to have a certain lifetime. You have to store it somewhere such that lives for (at least) long enough to satisfy the given lifetime. Here, your struct definition says that the lifetime parameter to `Cookie` needs to match the lifetime parameter to `NaiveCookieJar`. All you need to do is change the function declaration from `add&lt;'b&gt;` to `add&lt;'b: 'a&gt;`, which specifies that `'b` is at least as long as `'a`, ensuring that a `Cookie&lt;'b&gt;` can be stored in the map. Also, your local `cookie` function doesn't need to be a reference: impl&lt;'a&gt; NaiveCookieJar&lt;'a&gt; { pub fn add&lt;'b: 'a&gt;(&amp;mut self, domain: &amp;'b str, name: &amp;'b str, cookie: &amp;'b Cookie&lt;'b&gt;) -&gt; bool { let cookie = cookie.clone(); self.data .insert((String::from(domain), String::from(name)), cookie) .is_some() } } 
http://forum.dlang.org/post/fwmdvszlchmonkpjlcwn@forum.dlang.org sums it up, IMHO.
I think that the lack of overall support for HTTP 1.1 pipelining and HTTP 2.0 having pipelining (without the drawbacks that make 1.1's not supported, in my understanding) means that we can't learn very much, to be honest. It just falls out of "support HTTP 2".
It is fine as an application writer. However, as a library writer this is horrible. You remove the ability of the application to handle the error. What is the library is used in an to drive a car? Safety is not only about memory leaks and data races. Industry that needs safety the most need to have predictable behavior in all conditions, even in error conditions. Rust has already dropped GC, which isn't loved in the real-time world. It has his chance to replace languages as Ada but not only Ada.
&gt; No, I don't know it isn't true. That's what you said. You know it isn't true because you've looked at the only C k-nucleotide program and seen that program uses `khash` - part of the [klib](https://github.com/attractivechaos/klib) open source library. You know it isn't true because you know I am the singular authority on the benchmarks game, and I've repeatedly told you it isn't true. For example, 5 months ago: *No, they don't "get to choose one that's good on this benchmark". They get to use [a third-party library that was not invented for this benchmark](https://news.ycombinator.com/item?id=12327570) -- that would be the point!"*
I've written assembly code for several weird little DSP chips in my life. Here are some questions to ask before you get too deep: 1. Does the the chip use the same address spaces for code and data, or do it use separate busses? 2. Do you need to manage the processor caches manually? (The ancient DSP3210 has some cache weirdness, if I recall correctly.) 3. Does the chip support a full set of basic data types? I think the TI 320C40 chips might have "32-bit bytes", with no ability to address anything smaller, but it's been a while. 4. Does the chip support interrupts? What happens if you address non-existant memory? My gut feeling is that if you can compile C code for the chip using LLVM, it's probably possible to get Rust's `core` running with sufficient effort. Except possibly in the case of (3); I'm not sure how to handle chips where the smallest addressable data type is `u32`. In C you just declare that `char`, `short`, `int` and `long` are all the same size. But Rust takes a hard line here and insists that you have `u8` support (which I agree with). Another cool/horrible thing to keep an eye open for, though your C compiler should handle this for you: Some DSPs refuse to "stall" processor pipelines until data is available, so the results of an operation might take, say, 3 cycles to appear in the destination register.
Permissions issue, perhaps? I happen to run VS under account that's a member of Administrators, plus UAC is disabled on the machine...
If you don't anticipate that your library will be used in safety-critical applications, then I don't see the problem. If someone can come up with a good way to deal with it they can submit a pull request. Getting it out there is more important than getting it right. You should always review the error handling of any library you're using for safety critical applications. This is the cost of pulling in dependencies. This is no different from any other programming language. If you're writing software for a self-driving car, then maybe it's better that you do everything yourself to avoid these scenarios. Don't code like your library is going to be used in a self-driving car. Code like your application is going to be used in nothing more important than what you're using it in. If dying is acceptable for your application of the library, then it's acceptable.
Thanks! I'll give those a look.
On my desktop machine mioco was doing 10 million requests per second, by not doing http parsing at all and just pushing out as many http responses as possible (so like pipelining, but without parsing request), while only 380k if proper http parsing was done and requests handled one-by-one (so no pipelining). That just to give some estimates on how much of help is pipelining here. The main reason is that in "Hello world", server does not have anything to do, so without pipelining stresstesting is bounded by the latency. And even on localhost, there's still quite a bit of latency added to communication between two processes. I guess efficiently handling pipe-lining in http server doesn't hurt.
Exactly. Once you increase the complexity of the program, you lose most of the gains you got in your really fast HTTP library. It doesn't matter if your HTTP library can process 1 million packets per second if your code can only process 1k, and then you port that code to C and you just lost most of the benefits of Python. I'm not ragging on Python or anything, I just don't think it's the right place for high performance networking code.
There are a few few variables at play here, so you need to make sure you're measuring the right thing. You have: - HTTP packet parsing (depends on the OS, mostly I/O bound) - async vs sync (depends on efficiency of task switching and async APIs) - Windows and Linux vary drastically here in gotchas - routing (calling the right endpoint; CPU bound) - data processing (maybe some kind of computation; CPU bound) - client to server transport (little to no control over latency, 100% I/O) If you want to measure one, you need to make sure you're not hitting the other three), and a lot of synthetic benchmarks like this show off their good parts and ignore the bad (e.g. this benchmark is obviously avoiding Python's slow parts).
&gt; I would recommend not copying the infrastructure of RBE; it's one of the huge things holding it back. Write it with mdBook instead. What are the reasons (apart from being Rust-based of course)? I'm genuinely curious, as I wrote [24 days of Rust](https://zsiciarz.github.io/24daysofrust/) with GitBook and found no big issues/blockers. Is it due to RBE interacting with playpen?
So, I took a look at cupi, and all the .unwrap() in the example made me wary. I can see how the file open to do the write might fail, but telling new users "Oh just unwrap that and the Result goes away" seems wrong.
I think GitBook is a fine project, to be clear. But RBE uses a hacked together custom GitBook with custom plugins, and it means that it's basically frozen in time. If we had someone who was good with GitBook, that might not be a problem, but we don't. Virtually all other Rust book projects use mdbook, with the exception of the in-tree stuff, which will be ported to mdbook soon.
&gt; Contribute a program that calls the C library. So, again: this means that we can use other hashmaps than the ones in `std::collections`? Do we have to call into the C library, or can we port khash to Rust? &gt; but it was chosen for this benchmark. It was only chosen because you won't allow any other choice.
No, I get a &gt;100% speedup over the same Rust program without the additional argument. That's 20% faster than the fastest gcc entry on this machine.
&gt; I've been hitting my head against the &amp; key trying to get it to work, but this really helped me understand. Oh, sorry I left this out in my original reply: I'm very glad that this helped you :D
You can use pattern Matching!
You might be looking for [Rust, the game](https://www.reddit.com/r/playrust), this is [Rust, the programming language](https://www.rust-lang.org/en-US/)
Already been reported! https://github.com/rust-lang/crates.io/issues/524
Already been reported! https://github.com/rust-lang/crates.io/issues/524
I had a try at adapting this, but it didn't quite work, a bunch of type mismatches I couldn't easily figure out. Again, a PR would be quite welcome (not necessarily from you).
Yeah hitting 1mil reqs/s is a great way to pull on clicks but I don't think Rust has much to learn except optimize for microbenchmarks to get higher numbers I don't mean to disparage the underlying technology. It is probably really interested. Just don't know if this particular blog post serves the project well
Don't get the idea I'm criticizing nom or suggesting you do things a different way. The main reason I'm doing my own thing rather than using an existing library is that I don't need a result, just recognition. Speaking of which, what's wrong with returning `()`? It's a perfectly valid result type, and in hand-testing it it seemed to do what I want (modulo returning "Incomplete" sometimes, which I'm sure there's a simple way around, to tell the parser the input is complete).
Ohh sorry
You said that when using Intel syntax, one must write e.g `1fh` instead of `0x1f`. This isn't true, `0x1f` is legal Intel syntax and has the benefit of not causing clashes with registers or labels (`0xa` is not ambiguous, whereas `ah` is).
I'm a bit biased but I think the right option here is to use the Linux sysfs interface for accessing GPIOs. I have written an rolled into the rust-embedded org code for interacting with GPIOs under Linux from Rust: https://github.com/rust-embedded/rust-sysfs-gpio is the library. There are some examples included which should get you started quickly. Handling pin export and figuring out pin mappings can be a bit tricky. Another project, https://github.com/rust-embedded/gpio-utils, provides a way to refer to pins on boards like the RPi by name with the help of ([a toml file](https://github.com/rust-embedded/gpio-utils/blob/master/examples/raspberrypi.toml)). With that library you can then do things like: # output configuration and state of pins gpio status # read the value of an input gpio read &lt;pin&gt; # set the value of an output gpio write &lt;pin&gt; &lt;0|1&gt; # wait for the status of a pin (input) to change gpio poll &lt;pin&gt; All of the underlying source for this is in the repo! Explore at will.
`sysfs_gpio` is good one and I have experience with it. One important thing you should know about it is that you should wait after export, because it takes some time for udev to set correct permissions.
There is a big effort underway to solve these problems. In fact, it's one of the main goals on the roadmap for Rust in 2017. See https://github.com/aturon/rfcs/blob/roadmap-2017/text/0000-roadmap-2017.md#rust-should-have-a-pleasant-edit-compile-debug-cycle note both "Rust should have a pleasant edit-compile-debug cycle" and "Rust should provide a solid, but basic IDE experience". The RLS project is meant to take this on directly. RLS is only in pre-alpha, so it's certainly got a long way to go, but I hope very much people get behind it.
We already basically address point 1 - with the right flags, the compiler can give the RLS the data it needs even with quite broken code. There is still room for improvement here (especially when we do our own code completion), but I believe it is not a fundamental limitation. For point 2, I agree with the latency vs throughput distinction, but inferring anything about how a compiler must operate from that seems like a false conclusion. I believe that we can modify the compiler towards incremental compilation in a way that will be low latency enough for IDEs. Having said all that, I do think that if you gave me 100 engineers, we could build a new compiler that would be better for IDEs than the existing one + the RLS. But we don't have those resources and given the resources we do have, improving the compiler and RLS combo is the only real option, and I believe a pretty good one.
There is [StackOverflow Documentation](http://stackoverflow.com/documentation/rust/topics) which is always a great resource in my opinion.
In Ada SPARK. procedure Memory_Copy(Source: System.Storage_Elements.Storage_Array; Destination: out System.Storage_Elements.Storage_Array) with Global =&gt; null, Pre =&gt; Source'Length = Destination'Length, Post =&gt; (for all II in Source'Range =&gt; Source(II) = Destination(II - Source'First + Destination'First)), Depends =&gt; (Destination =&gt; Source); 
Do you know why Chrome removed it/why it's not popular?
https://www.chromium.org/developers/design-documents/network-stack/http-pipelining Stack overflow http://stackoverflow.com/questions/30477476/why-is-pipelining-disabled-in-modern-browsers IEFT https://tools.ietf.org/html/draft-nottingham-http-pipeline-01#section-3 Basically it is a small gain for a well written server. But it assumes all proxies are also well written. Lastly it a performance loss to most clients 
In theory they could, yes.
Thank you!
Ok. I cleaned up (a touch) what I had and pushed it. https://github.com/mehcode/schedule-rs What it has: - Scheduler (second granularity) - Schedule is parsed in cron syntax - Job priority queue that is managed through an Agenda - Scheduler "engine" supports all features that anacron has What it doesn't: - API could be a bit cleaner - Nice error messages on parse failure - Documentation beyond what's on the readme - Labels `@hourly` / `@daily` / etc. - Lists `0 2,3,5-6 * * *` - Thread-pool Dispatch of Jobs - Blocking run (instead of polling approach on readme) - Constant Delay; an extension I've seen that is neat is `@every 1h` to define a delayed task instead of a scheduled task - Limits; It'd be nice for a Job to to have a general execution limit to support one-shot tasks - Decorator support; it'd be cool to do this: #[schedule("0 * * * *")] fn task_hourly() { ... } That's my info dump. I have a big list of crates I'm making for work. This one is done "enough" for me but it could be a lot better. --- To be clear; you're welcome to throw resources at working on this. Just let me know and I can add contributors. There is a lot to do. You're welcome to make your own crate too, of course. I just thought I'd push up my start on it.
Hi guys, I'm trying to implement the htsp protocol from TVHeadend in Rust. I wanted to write an application that talks to TVHeadend, and thought this would be a nice exercise. I'm using `tokio` (a multiplex protocol) and `futures`, to do the network stuff. Note that I implemented more than is in the blog post; I'm splitting things up and will continue writing after that. Relevant: https://gitlab.com/rubdos/htsp-rs
Are IDE compilers actually compilers, or are they more like interpreters?
It has better integration for Rust specific things; see https://azerupi.github.io/mdBook/format/rust.html for example. And it can test your Rust code automatically. It could reasonably be used for non-Rust stuff too, though it doesn't have specific integration. It could syntax highlight anything though. I'm planning on using it for a non-Rust book in the future, personally. It's a bit easier to use a Rust binary rather than have a whole Node tool chain installed.
Yeah. I agree. Should have said "compiler that hasn't thought about IDEs" :p
But are interpreters more like dynamic compilers, or are compilers more like static interpreters? :P
This is a rather dumb idea. Rust can hit UB in perfectly safe code. The fear of UB is rather irrational. Say we have. Structure #[repr(packed)] #[dervive(Copy,Clone)] pub struct Foo { a: i8, b: isize } Now can I index a vector of type Foo without UB? Nope. The read maybe unaligned and trigger an instruction fault on ARM or MIPS. UB is like the *here be monsters* on Ye Olde maps. No there aren't monsters there. Just nobody has defined what is there. UB isn't a monster, just a failure of the standardization team to think of/account for an edge case. It is the leaky abstraction that all abstractions must create. UB is part of life, you can't avoid it. Embrace it. 
I tried to write you a really good answer with details but when I went to post it I clicked cancel. Now I'm really annoyed because it took a while to write and I don't want to do it again...
Just an example (rust vs python vs js): https://github.com/RazrFalcon/svgcleaner#cleaning-time
&gt; Folks generally *don't* use unwrap. Oh man, I might have to do some looking at how other people handle errors in that case; I've got so many usages of that in my projects.
&gt; So why was #[repr(packed)] stabilized and pushed into standard? The problem was only noticed after it was stabilised (the issue date is after 1.0, and `repr(packed)` was stable then). Destabilising it was [considered](https://github.com/rust-lang/rust/issues/27060#issuecomment-124760510) but there was push-back, as you can see in the following comments there. Also, note that it is only taking references to fields of `packed` structs that need to be unsafe: loading and storing them by value is semantically fine, modulo the compiler bug. &gt; I should have been more clear this is what I meant by failing to think of something. This is why the Intel FPU has so many damned modes. The standardization team can't be asked to think of alternative floating point calculation routes/algorithms. It is best left to the chip designer. I don't understand what this means, or how the FPU relates to UB-for-optimisations. Do you mean that the standard writers/compiler authors failed to think of optimisations that result in the same performance when things are defined more strictly?
&gt; So why was #[repr(packed)] stabilized and pushed into standard? Rust needs to have it for FFI.
I suppose, but pretty much anything pre-1.0 is "unstable" regardless of how many people use it. Hitting 1.0 doesn't mean that it's "stable" though, so I think it should be a binary condition. I'm any case, I think it's cool you're doing this. Hopefully you can get it to a place where it's useful for funding quality crates.
It's the intent that counts :) Perhaps this could be clearly documented somewhere? Reddit really isn't the best place for long term documentation anyway...
I do want to style the filename annotations in a less jarring way, perhaps to look similar to the way they'll look in print, but I haven't seen any print-ready chapters yet so I'm not sure what that'll be. Plus we're still writing, so there's less time for styling right this second :) I have a feeling you'll appreciate the filenames once you get to chapter 7! ;) I'm glad the book has helped you &lt;3 &lt;3 &lt;3
Thanks a lot for the prompt answer! The trick to get the error message on non-string is great! I did not know that a parsed object cannot be turned into tokens. Thanks for the detailed explanation! It is very helpful :)
Do you know what the plan is for integrating macros into the IDE user experience? Will the IDE see your code post macro expansion or pre-?
I don't have time for a full response right now, but note that UB is not the same as `unsafe` code: it is absolutely incorrect for any code to (dynamically) result in undefined behaviour, whereas `unsafe` is a static property that just represents the *risk* of undefined behaviour because the compiler won't catch every possibility. Being alerted to every instance `unsafe` code being executed is rather pointless, but finding places where actual undefined behaviour is triggered is very useful. Tools like asan, tsan and ubsan (sanitizers that find undefined behaviour in C) have had thousands of person-hours poured into them because it is such a problem.
I imagine it would have to be post-expansion, since otherwise e.g. any methods added to types via derived traits wouldn't show up for dot-completion (to say nothing of the practical impossibility of type checking at all without knowing what traits were derived for which types). Why do you ask, is Dart thinking of adding sweet.js-style macros? :)
I have some mathematical computations involved(Calculating shortest distance for a location based on priority, time availability for a delivery guy),So only thought of using RUST. 
ah ha! Makes sense. Thanks. I am so bad at parsers :(
Yeah, I meant something like "most compilers, in my experience, which are not implemented with this kind of thing in mind."
gah! too many parsers with p in the name :p
https://crates.io/crates/ring
We should collaborate! Check out https://github.com/mehcode/schedule-rs See https://www.reddit.com/r/rust/comments/5ra31f/comment/dd7khbo?st=IYNUOOI4&amp;sh=68d9c087 for some more explanation 
[*ring*](http://github.com/briansmith/ring) is a library based on a subset of BoringSSL, with most of the C code removed or ported to Rust. It has a philosophy similar to NaCl; it focuses on providing high-level operations that are hard to misuse, rather than low-level primitives that the user must assemble into higher-level operations. [sodiumoxide](https://crates.io/crates/sodiumoxide) is a safe wrapper around libsodium. [rust-crypto](https://github.com/DaGenix/rust-crypto/) is a collection of crypto primitives implemented in pure Rust. [openssl-sys](https://crates.io/crates/openssl-sys) contains raw bindings to OpenSSL, and the [openssl](https://crates.io/crates/openssl) crate contains safe wrappers around those bindings.
To see what kind of work would be needed to get this to work look at the [MSP430 PR](https://github.com/rust-lang/rust/pull/37672). If Blackfin needs weird intrinsics or calling conventions it may look a bit more like [Nvidia PTX](https://github.com/rust-lang/rust/pull/38559). Edit: https://github.com/japaric/xargo may be a helpful tool.
The beauty of RLS is that a new ide compiler could come along and fill the gap without the RLS interface changing significantly.
Cool! Since some people might have a use for the expression parser on its own, we might want to develop that piece in the `cron` crate and then have `schedule-rs` depend on it? You could create a bunch of `CronSchedule` iterators and chain them together with [itertools::kmerge](https://docs.rs/itertools/*/itertools/fn.kmerge.html) to get a single iterator that always picks the next job from across all of the schedules.
Thanks for the detailed response!
Actually, I had [a go](https://github.com/steveklabnik/semver-parser/pull/12) at it, and I think it turned out pretty well. There's a little bit of by-hand interleaving of the `usize` values for the number of bytes recognized with the actual values we care about, but not too bad.
The reason you can do this is because `&amp;'static` references implement `Copy`. They can do this since they are basically constants; they will never change so we can pass references to them around however we want since they're hard-coded into the binary.
You want /r/playrust! Please make sure to check which subreddit you submit to in the future. It helps both you and us!
&gt; do its best to map that information to the pre-expansion code which is what the user is editing. Yeah, that's part of what I'm really interested in. Any docs or code you can point me to? As far as I know, this is fairly uncharted waters for most languages.
Well, you are cloning the domain and name anyway, so there's no reason to tie their lifetimes to the cookie. Just leave out the lifetime specifiers for those parameters and Rust will add invisible lifetime parameters for them.
No real plans or anything, but I do think we could use some kind of static metaprogramming story. We're increasingly trying to be an ahead-of-time compiled cross-platform language thanks to Flutter on Android and iOS, and every successful AoT cross-platform language I can think of (OK, mainly just C++) has *some* facilities for doing a little compile-time metaprogramming for handling platform differences. Also, with frameworks like Angular where you take templates and compile them to code ahead of time, it would be nice if that was a little more seamlessly integrated into the language.
I don't think that's it as the code still compiles if we change `name` to be a Vec&lt;f64&gt;: [playground](https://play.rust-lang.org/?gist=deb56847964e22001bd5753d40cd2365&amp;version=stable&amp;backtrace=0)
What have you tried so far, and what problems are you encountering? There are examples in [the docs](https://doc.rust-lang.org/beta/std/io/index.html#standard-input-and-output) -- it's hard to give a more specific answer to such a vague question.
Remove the reference lifetime from `&amp;'b Cookie&lt;'b&gt;` as well (so it's just `&amp;Cookie&lt;'b&gt;`).
Hi everybody. Please check it out.
`let cookie = Cookie::parse(cookie.to_string()).unwrap();` worked but this is... lol
Unsafe Rust is a part of Rust
Apologies for the vagueness of the question. I have seen the example from "the book", in the guessing game section, and have seen some stack overflow questions. Let's start with what confuses my the most. Some solutions I see require a call to stdin ().lock() What is the .lock() portion actually used for? My guess is that it's related to threaded applications?
That's not always true. Look at regex for example.
Wouldn't compilers be static interpreters?
I suppose it doesn't have to be on by default, but I think it's a pretty reasonable weeder criteria and definitely useful as an option. Btw, do you know why `regex` isn't 1.0? On GitHub issues, there's a 1.0 milestone with all the issues closed, so at the very least there's nothing documented as blocking a 1.0 release. Perhaps they want more real world usage before committing?
 extern crate cookie; #[macro_use] extern crate lazy_static; use std::sync::Mutex; use std::collections::HashMap; use cookie::Cookie; struct NaiveCookieJar&lt;'a&gt; { data: HashMap&lt;(String, String), Cookie&lt;'a&gt;&gt;, } impl&lt;'a&gt; NaiveCookieJar&lt;'a&gt; { fn add(&amp;mut self, domain: &amp;str, name: &amp;str, cookie: &amp;Cookie) -&gt; bool { /* this works for static 'a self.data .insert((String::from(domain), String::from(name)), cookie.clone().into_owned()) .is_some() */ self.data.insert((String::from(domain), String::from(name)), cookie.clone()).is_some() } } fn global_jar() -&gt; &amp;'static Mutex&lt;NaiveCookieJar&lt;'static&gt;&gt; { lazy_static! { static ref JAR: Mutex&lt;NaiveCookieJar&lt;'static&gt;&gt; = Mutex::new(NaiveCookieJar { data: HashMap::new() }); } &amp;JAR } fn main() { let mut jar = global_jar().lock().unwrap(); let cookie = Cookie::new("foo", "bar"); let result = jar.add("foo", "bar", &amp;cookie); println!("{}", result); } I think this addresses the issue.
This is kinda a corollary to the fact that you can do partial moves out of a non-Drop struct. Basically, you're allowed to do [this](https://is.gd/AshNQh): struct Foo { bar: Vec&lt;u8&gt;, baz: Vec&lt;u8&gt;, } fn main() { let x = Foo {bar: vec![], baz: vec![]}; let y = x.bar; let z = x.baz; } You can have a struct containing whatever, and you can move individual fields out of it. The act of moving an individual field out does not invalidate the existence of the other fields, but it does make it impossible to use the struct as a whole. But, you can also put the field _back in_, making usage of the struct valid again, like [this](https://is.gd/qUucki): #[derive(Debug)] struct Foo { bar: Vec&lt;u8&gt;, baz: Vec&lt;u8&gt;, } fn main() { let mut x = Foo {bar: vec![], baz: vec![]}; let y = x.bar; // println!("won't work {:?}", x); x.bar = y.clone(); println!("will work {:?}", x); } Interestingly, this only works if you are moving fields, not the entire struct ([playpen](https://is.gd/f1I3HA)): #[derive(Debug)] struct Foo { bar: Vec&lt;u8&gt;, } fn main() { let mut x = Foo {bar: vec![]}; let y = x; // println!("won't work {:?}", x); x.bar = vec![]; println!("will not work either {:?}", x.bar); } The model to use when thinking of non-Drop structs with fields is that the struct is effectively a bundle of local variables. These local variables can be moved around independently, and you can even move things back in, much like you can reuse a moved-out variable [by writing to it](https://is.gd/YfEvBQ) fn main() { let mut x = vec![1]; let y = x; x = vec![1]; } However, it's a tiny bit more than a bundle of local variables; the struct itself has its own identity separate from the bundle of local variables. You can think of a local variable `foo` of type `struct Foo {x: String, y: String}` to be three separate local variables. `foo_identity`, `foo_x`, and `foo_y`. Reading from `foo` requires all of these to be present. Reading from a field of foo requires that field and the identity variable to be present. If you move `foo`, all three of these are moved out. If you move a single field, only that variable is moved out. This means that you can move fields and replace them, and read/write to individual fields as long as they have not been moved out or have been replaced if moved out. However, it also means that if you move `foo` in its entirety you can only write to its fields. You cannot read from the fields because even though you can reinitialize the fields, there is no way of setting `foo_identity`, which is a magic hidden field. The only way to get it back is to set `foo` to a completely new instance of `Foo`, which reduces to the `let y = x; x = vec![];` code above. Now, this is just a consistent model to explain how it works now (I do not know how it is implemented). That quirk with the "identity" is not necessary for Rust to work. Without it, you'd be able to truly treat non-Drop structs as bundles of local variables with one variable for the field. This is https://github.com/rust-lang/rust/issues/21232 as /u/dbaupp pointed out, and is IMO a bug. (`Drop` structs do not have these semantics since the entire struct must exist for the destructor, which operates on `&amp;mut self` and has no knowledge of partial moves in the callers, to work)
Yeah, I noticed a couple of months ago there was another plugin. I didn't even realize that RustyCode has stopped being maintained.
When this gets released, do we need to download/install the rls ourselves to set it up, or will it automatically try to do that for us like with rustfmt and racer?
Also I encourage you to try the extension and open issues if something is wrong or missing.
&gt; We already basically address point 1 I think there's more work to be done, starting with the parser. Consider the following code snippet: const X: T My understanding is that the parser fails to produce any parse tree for this case (`rustc -Z ast-json -Z continue-parse-after-error` bails with error). The problem is, compiler does not have any other choice because the AST type requires the type and the expression to be present: https://github.com/rust-lang/rust/blob/1b6b20ac173eeb9ee50077a3e7614b37299cdbb7/src/libsyntax/ast.rs#L1808. In contrast, here's the syntax tree produces by IntelliJ Rust for this file: FILE(0,10) RsConstantImpl(CONSTANT)(0,10) # we understand that its a constant PsiElement(const)('const')(0,5) PsiElement(identifier)('X')(6,7) PsiElement(:)(':')(7,8) RsBaseTypeImpl(BASE_TYPE)(9,10) # and we know that `T` is type RsPathImpl(PATH)(9,10) PsiElement(identifier)('T')(9,10) PsiErrorElement:';' expected, unexpected end of file(10,10) # look, and error! &lt;empty list&gt; This is quite important! First of all, you need to parse file at least somehow, to be able to find visible identifiers. And you need to understand that this is a `const`, and that `T` is actually a type, so you can show an autocompletion popup.
I would say that the actual interface does not matter much. Bridging the IDE and the server is a relatively small amount of work, compared to actually doing code analysis. To put it another way, if there's a Rust crate which exposes analysis API, writing a fronted binary for language server protocol, or a custom protobuf-based RPC, or whatever, is not a problem :) 
Hah, that's an excellent name for a podcast. I'll check it out later - any particular episode recommendations?
We struggle with this a lot (mostly theoretically at the moment :) ) in IntelliJ Rust. Currently, macros are not analysed at all, but there are some ideas of how this could be done. The problem with macro invocation like `m!(1 + foo())` consist of three parts: 1) First, you need to figure out where does `m!` comes from, you need to resolve the macro name. 2) Then, you need to figure out what's inside the macro, to see `foo()` as a function call, and not as a sequence of three tokens (I think this is the part that is interesting for you) 3) Finally, we need to expand the macro, because it can introduce new names in the surrounding scope and affect the code outside. For 3), we haven't done anything yet, but there is an infrastructure in the IntelliJ platform to inject additional syntax tree nodes into the file. So, you can have a macro node which has a set of real children for pre-expanded code, and also shadow post-expansion children. We actually have tried to pull out 2) :) The experimental work was done by https://github.com/HeyLey, the code is here: https://github.com/HeyLey/intellij-rust/commits/master. Here the "by example" nature of Rust macros helps a lot. What HeyLey was able to do is to see "inside" macros defined with the `expr` pattern, like `macro_rules!assert ( ($cond:expr) =&gt; { ... } )`. This was done via two phase parsing: in the first phase, we parse macro invocation bodies into the token trees. But we parse them into so called lazy element, which can produce AST on demand. So, when the AST is requested, the macro definition is resolved, macro pattern is matched against macro argument, and the parser is invoked again to produce a tree. At least, that's the thinking, the implementation is pretty bare bones :) The crux of the code is here: https://github.com/HeyLey/intellij-rust/blob/70a375a3c2778df8e941b250b511d73b4b3ae489/src/main/kotlin/org/rust/lang/core/psi/RustMacrosElementType.kt#L30 Obviously, this can only work if the pattern is good, like `$expr` or `$item`. The bad case is when the pattern is just an `$ident`, which is then used as a part of the expression in the expansion. Than, we can't actually connect the dots and understand that this `ident` is something that needs to be resolved. The 1) is actually the most fundamentally complicated. The problem is, macros 1.0 name resolution rules are actively hostile to the IDE requirements. Basically, `m!` macro is not imported at all, and it is visible if the parser has previously came across it. So, this really depends on the order of parsing files. I don't know any really good solution here, which would not require looking at the all code of a crate at once. But a nice approximation is possible, we can just index macros by their names and apply some coarse grained checks, like the presence of `macro_use` on modules. Also, huge shout-outs to the Dart team for making the Dart analysis server (https://github.com/dart-lang/sdk/tree/master/pkg/analysis_server). It is really how the language server should look like, in my opinion :) 
This is going a bit off topic, but as I've been switching between Eclipse (which I currently use by employer's mandate), IntelliJ, NetBeans and various editors I have a more balanced perspective: Both early Eclipse and NetBeans were sluggish to the point of being barely usable. IntelliJ had a head start, but that left less room for improvement. Nowadays all of them are usable for all but very large projects, for which I'd suggest IntelliJ. With Rust and the RLS, the distinction between IDEs and 'normal' editors becomes a bit more blurry. Once I can get all that functionality in vim (or hopefully xi), there's little need to spin up a full-blown IDE anymore.
OK, I'll try to dig in Visual Studio in my next Rust soirée and probably do one more post if I manage to make it work. Just one more question: do you use the VS profiler/debugger together with the Visual Rust extension or without it?
Elasticsearch has Lucene underneath it. Tantivy is a project to build an indexer similar to Lucene in Rust. RocksDB is a key/value store. I'm not familiar with it and do not see any features for text indexing in it's documentation. How will rusticsearch index text?
Yes sysfs is pretty slow (compared to cupi for instance) but it is more than enough to make a led blink.
Blackfins are amongst the least weird DSP architectures that I have come across. They're sort of a hybrid MCU/DSP, and would probably not be too terrible for someone who knew what they were doing to get Rust core running on. There is apparently already an LLVM target, although I don't know what state it's in.
This is not achievable as far as I know. The operations and elements to build a constant is largely limited. The only similar macro is `env!` (which could be expanded to a literal), and it's implemented by a compiler built-in. But perhaps this is related to https://github.com/rust-lang/rust/issues/24111 ?
&gt; ignores one of the main reasons why people come to confs -- to network and chat I didn't ignore this at all, I recommended having some form of chat alongside. I definitely understand that some people prefer chatting _verbally and face-to-face_, but for others that ranges from difficult to impossible. If you're wondering why I keep banging on about this point: software conferences tend to naturally become the "main event" of the calendar year for their communities. Everyone who's anyone will be there. It's a great place to "network" with others and become more involved in the community. Unless you're not able to go to conferences, in which case tough luck. EDIT: I tried to word this to not sound like a grumpy asshole but I'm having a rough week and not sure how successful I was. Caveat lector I guess. EDIT^2: Yeah, on further reflection imma go ahead and take a break from the Internet for a week or two. It won't help but at least it's fewer flame wars
I guess that in the end you always have to measure time spent in the operation and/or profile the program. That is the only general way. Further, to second K900_ only optimize once your code becomes too slow for your use case.
There's no such thing as "properly optimized". If there were, computer science research wouldn't be a thing. There's just "optimal enough that it's not worth it to optimize more" and a curve of dimishing returns which informs it. Also, even if you are willing to throw tons of man-hours at optimizing something to the very limits of possibility, optimization beyond avoiding pitfalls is always a space-time trade-off. (eg. Monomorphizing functions avoids the time overhead of dynamic dispatch but costs more space overhead to store specialized versions of the functions.) If you're anything like me, what you're probably asking is "How do I know if I've made a dumb design mistake that's causing my code to be slower or more wasteful of memory than some other design which is comparably easy to read and maintain?" ...and the answer to that is basically "Read a lot of articles on good and bad ways to design things for your target language, so you'll build the right habits, and use profiling tools to keep an eye out for things which take more CPU/RAM to run than it seems they should." Anything beyond that is premature optimization. (Human time is much more valuable than computer time. Do a quick off-the-cuff estimate for how much time you'll save later by spending time to profile and optimize now.) ...and, if you don't believe me, read the [History category](https://blogs.msdn.microsoft.com/oldnewthing/tag/history) on Raymond Chen's blog, The Old New Thing. The kind of tricks they had to use back in the day to fit a workable Windows GUI into single-digit megabytes of RAM would drive modern programmers mad. **EDIT:** That said, I too would appreciate it if people would share any tips they have on how to play as nicely as possible with the optimizer without having to become a wizard at reading LLVM IR or x86 ASM.
This is big. I really wish one day I do not need to install JVM anymore. Rust is a language well suited to win this race.
Bike Shed (http://bikeshed.fm/) is not strictly about Rust, but many episodes (seeing as one of the host is an author of Diesel) are Rust-heavy.
The end of my post might be misleading, but I was talking about rust specifically (and maybe llvm as well if it applies), not programming in general. There are tons of articles about C or C++, but there aren't much about Rust so I was just wondering
In that case, would it be correct to characterize your question as "What are the pathological cases for Rust's abstractions and how do I know when the LLVM optimizer is generating poor output?" That's something I have next to no experience with but one tip I was given in #rust is that, if you wondering whether it successfully vectorized a loop, check the LLVM IR (eg. via the [playground](http://play.rust-lang.org/)) for angle brackets in the types. No brackets, no vectorization. I also came across this on /r/rust a few months ago, which should help in that sort of investigation: http://rust.godbolt.org/ (It compiles Rust code to x86 assembly and then colour-codes the correspondences) It's [on GitHub](https://github.com/mattgodbolt/compiler-explorer) if you want to run your own instance and the system can also work with [C++](https://gcc.godbolt.org/), [D](https://d.godbolt.org/), and [Go](https://go.godbolt.org/).
Oof, thanks for looking into and pointing out the performance of pom. I was going to jump over to it at some point just so I don't have to wrangle error messages from macros, but I guess I'll have to be a bit more wary and do some serious benchmarking of my own. I wonder if pom can't be optimized so it does compile down or if that is just a problem with the design/compiler.
For this one, I'd start at the beginning. Most of them are short, and take the format of Chris Krycho reading something that he wrote ahead of time, and often that will involve trying to read some small bits of syntax aloud (when he's explaining how something is expressed). Usually that sort of thing doesn't go well, but I find that Chris is so careful in his diction that it works. My absolute favorite episodes, though, are the ones where he's interviewing someone – because then it's a conversation, which is much more enjoyable to follow, and a longer episode at that.
There's one awesome episode of CppCast from July `15. http://cppcast.com/2015/07/steve-klabnik/ I keep hoping they'll do another.
&gt; How does the indexing work roughly when RocksDB is the storage method? Kite divides the index up into "segments" of up to 65536 documents. Each segment is like a mini inverted-index and these are stored in a key-value store (RocksDB) as a mapping of terms to lists of document IDs (along with stored field values and some stats). I had to limit the number of docs in each segment to stop the keys getting very big (as rocksdb doesn't support partial loading of keys). But I worked around this using RocksDB compaction feature to locate each ID list for a term ajacently on disk (which should massively improve speed).
Sorry to reply to my own comment.. but I have a couple thoughts. 1) Visual Studio (real VS - not VS Code) is of course Windows-only.. so that's a problem for general adoption. However, even though I mostly use MacOS and Linux at this point and hardly care about Windows as a target platform, I will still make the effort to use Windows+VS for native (largely C++) development if it gives me a better debugging experience. I've done so in the past for console games, and I'll do it again since it's been very worthwhile. 2) Perhaps some sort of Rust debugging server could help bridge the gap between gdb/lldb and IntelliJ IDEA (and other non-native debuggers). That way, gdb/lldb could be leveraged for debugging in a Rust-specific manner without plugging directly into IDEA - and so JetBrains wouldn't have reason to worry about it cannibalizing CLion business. This wouldn't be ideal, but nothing is ideal at this point.. so it's an option.
LLVM isn't going to optimize away heap allocations, so your example is going to build a second map and copy everything across that's not filtered out. 
As mentioned in another comment, I think your best option to see how good the optimization works is http://rust.godbolt.org/. It will generate assembly with some highlighting to make it easier to look at.
Theoretically that would work, but since that the timestamps can be updated or delayed at any point (even though that doesn't happen that often I guess), I'd have to delete and reinsert the tuple so that it is properly sorted again. I guess since it's a binary heap it wouldn't be too costly, but I think tests and benchmarks are required to see whether or not this is the right solution.
Yep, I will try to test that. My main concern is the allocation process: since drains deletes the entries but keeps the allocated memory, I wanted to know whether or not that "replacement" re-used that memory via some sort of optimization of some kind.
I need a compiler for my comments, apparently...
I am pretty sure you cannot, no. Lots of functions that could be `const fn`s aren't marked as such yet, in my understanding.
I was planning on working on getting the UaRT working on my Teensy or Discovery board to test out gattii, my serial terminal. It's on crates.io if you want to try it out with your testing. And if you want I'd be happy to proof-read your post if you'd like. 
This is the subreddit of a programming language named rust Try /r/playrust instead
If that's the case, then why does this work? https://is.gd/U2DRF6 I think that /u/Manishearth is correct, this is a consequence of partial moves out of a non-`Drop` struct
https://crates.io/categories/cryptography
I find them usable because thankfully machines given by employer have gotten much better than before. Just few years back that latest Rational Application developer was crawling on my mediocre machine. Java and increasingly other language editors have set expectation that RAM is cheap/hardware is cheap, so upgrade and stop whining. I do not think most understand not everyone can either afford or allowed to use hardware to their preference.
No, it's still about Ruby (or whatever they are using for current project) but there are full Rust episodes due reason stated above.
Awesome. Curious, could this sort of scheme work for a more secure form of e-voting, where everyone makes their encrypted vote public? To my understanding, given encrypted values e1 and e2 and a public key, you can calculate enc(dec(e1) + dec(e2)) without knowing the decrypted values of e1 and e2. However, if the sum is encrypted, wouldn't it be impossible to figure out who actually won without being able to discover what each vote was? Or is there some way to release a final decrypted value which is proven to be the results given the encrypted votes? Homomorphic encryption is pretty cool and seems to be underused in general unless some common schemes use it that I don't know about.
Wow, I never realized all that. Thanks!
Update: It turns out that it is impossible to efficiently reimplement A/Rc in stable because NonZero is unstable. Therefore, there is no way to avoid the weak refcount unless you're willing to go Nightly-only. What a shame.
Yes! I've been excited for this one to come for a while now. Great job!
You could leave the old incorrect timestamps in the binary heap, but update the record on the hashmap with the new timestamp and add a new entry to the binary heap for the new timestamp. When you get an entry off the heap, you double-check the timestamp on the hashmap record. So effectively treat the binary heap as a queue driving a 'check me' call on the ID.
Thanks for the info. I'm actually returning from about a 3 month break from rust. Seems I've forgotten a lot of the minor details, im probably gonna take some time to re-read some of the docks. 
(It's okay, you don't sound grumpy) &gt; I didn't ignore this at all, I recommended having some form of chat alongside. I hang out on IRC every day. I go to the Rust meetups to chat with people, not to watch talks (talks are good too, but I'd go regardless). &gt; I definitely understand that some people prefer chatting verbally and face-to-face, but for others that ranges from difficult to impossible. Right, that's my point. And that's why livestreaming is not a complete solution. Livestreaming is an _awesome_ solution that would be great to have regardless of how off his rocker our President is, because a lot of folks can't come to confs due to time/money/etc reasons. I didn't go last year to any of the three confs, because I was going to be moving at the time. But if there are a lot of folks being excluded from the conf that otherwise wouldn't be, it might be worth doing more than livestreaming (moving the conf to a more accessible venue). That's why I consider these two to be independent. So far it doesn't seem like the conf will be moved, but we will try and look into livestreaming (It's more complicated than it sounds though, so let's see). 
The newly-stable signature `fn as_mut_slice(&amp;self) -&gt; &amp;mut [T]` is incorrect as there's nothing stopping one from calling that multiple times to get multiple `&amp;mut [T]`s to the same data. It needs to be `&amp;mut self`. (*e*: quick turn-around by /u/acrichto who opened https://github.com/rust-lang/rust/pull/39466 .)
Looking at the source seems to confirm your statement: [Seems like there was reuse of unsafe code without maintaining the guarantees](https://doc.rust-lang.org/src/collections/vec.rs.html#1899).
It definitely seems like it should be taking `&amp;mut self`.
I went and filed https://github.com/rust-lang/rust/issues/39465. Seems broken.
The benefits of pipelining goes away if you "terminate" it before it reaches the final endpoint. So it is not really analogous to SSL. 
If I wanted an SQL database for my rust app, what's the easiest way to make that happen?
I've been hapilly awaiting this release. I have been heavily updating my rust first Rust library so it makes use of the new derive API, so that it could be used by stable Rust. It adds derives for common traits such as Add and From: https://github.com/JelteF/derive_more . Any remarks/tips are very much appreciated.
&gt; Homomorphic encryption is pretty cool Not OP, but a few years ago I looked into it to see whether it would be possible to have a Dropbox-like system using homomorphic encryption (i.e. even the server doesn't know what files you have, much less what your changes are), but that seemed impossible at the time. It still may be impossible, but the field is very interesting and, from what I can tell, quite active. I'd be very interested in follow up posts about possible applications of existing homomorphic encryption schemes. I'm not very good at crypto (I was considering starting a venture with someone in the field), but I'm very interested, so these types of posts really scratch my itch to learn.
Wow! Building Rust with Cargo is something I looked forward to. Makes it easier to hack on the compiler. Time to "fix the language"! Mwuhahaha!
Happy to invoke some interest :) There are a few companies offering solutions based on secure computation (the broader field which homomorphic encryption fits within) already, including sharemind.cyber.ee, sepior.com, and dyadicsec.com. The former is quite general while the latter two are essentially secure key storage in the cloud. As for Dropbox-like system, http://css.csail.mit.edu/cryptdb/ and https://github.com/XPIR-team/XPIR take two different approaches, with Google experimenting with the former (https://github.com/google/encrypted-bigquery-client).
Right off the bat, I see unsafe code with no documented invariants. If I see unsafe I want to see a comment explaining exactly why it's really safe.
How do I specify an inherent fn over a trait fn? It comes up like this: pub trait Float { fn sqrt(self) -&gt; Self; } impl Float for f32 { fn sqrt(self) -&gt; Self { self.sqrt() } } impl Float for f64 { fn sqrt(self) -&gt; Self { self.sqrt() } } Rust compiler warns about infinite recursion but I meant to specify the inherent sqrt fns for f32 and f64.
Awesome, am very excited for custom derive :D Docker side note: `clux/muslrust:stable` now points at `clux/muslrust:1.15.0-2017-02-02` and tests `hyper` (0.10) with `hyper-openssl`.
Nice job. Updating right now! Beautiful baby 👼
I was wondering when you were going to announce this! I've been loosely following progress for a while now. Top work so far, it's a huge amount of effort.
I am fluxommed, here's what I'm getting locally: warning: function cannot return without recurring, #[warn(unconditional_recursion)] on by default --&gt; src\unit.rs:58:2 | 58 | fn sqrt(self) -&gt; f32 { self.sqrt() } | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | note: recursive call site --&gt; src\unit.rs:58:25 | 58 | fn sqrt(self) -&gt; f32 { self.sqrt() } | ^^^^^^^^^^^ = help: a `loop` may express intention better if this is on purpose warning: function cannot return without recurring, #[warn(unconditional_recursion)] on by default --&gt; src\unit.rs:61:2 | 61 | fn sqrt(self) -&gt; f64 { self.sqrt() } | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | note: recursive call site --&gt; src\unit.rs:61:25 | 61 | fn sqrt(self) -&gt; f64 { self.sqrt() } | ^^^^^^^^^^^ = help: a `loop` may express intention better if this is on purpose Version info if relevant: rustc 1.14.0 (e8a012324 2016-12-16) binary: rustc commit-hash: e8a0123241f0d397d39cd18fcc4e5e7edde22730 commit-date: 2016-12-16 host: x86_64-pc-windows-msvc release: 1.14.0 LLVM version: 3.9
Thanks but this does not appear to work (see below). I am on windows although that shouldn't make a difference ._.
&gt; embedding python within a C program No, a C extension to CPython, like a lot of Python app servers.
What's the rest of src/unit.rs? Are you using the `num` crate perhaps? Same results (as the playground) with rustc 1.14 here.
Has anyone gotten around to writing a Rust modding API in Rust? If The Algorithm can figure that one out, we're all doomed.
Definitely lowers the entry bar to modifying the compiler, which is great!
Maybe, but I'd like to run this "QML" without ahead-of-time native compilation (without rustc). More of my ideas: using [wasm](https://github.com/joshuawarner32/rust-wasm) as the scripting interpreter, using CBOR to represent the object tree, compiling "QML" + "JS" (but simpler) to this CBOR object with wasm code inside, having [cassowary](https://github.com/dylanede/cassowary-rs) based layout as one of the primitive (native) objects, shipping the whole thing as a (possibly [self-sandboxing](https://github.com/myfreeweb/rusty-sandbox)) binary, not a library — "qml browser" sort of thing, works standalone to open these compiled files like a browser would open html, just from the command line, but also if you want to drive the GUI from any programming language, start the binary with a pipe/socket and interact with the GUI over RPC. I wish I had time to implement all of this. Especially the damn UI widgets themselves :D
Trying to build a transactional storage engine for store bytes on a single file, from scratch in rust https://gitlab.com/tglman/persy 
Grenades implement `Copy`? That sounds `unsafe`...
PR at https://github.com/google/xi-editor/pull/154.
You raise one hypothetical issue after another. Contribute *something* that is more than hypothetical. &gt; It was only chosen because you won't allow any other choice. Please provide URLs to the other Rust HashMap libraries that could be chosen.
It looks like the inherent `sqrt` functions aren't added at all in core, only in std where they are implemented with intrinsic functions.
I've filed an [issue](https://github.com/rust-lang/rust/issues/39473) for it, I hope that's ok.
Please provide URLs to the other Rust HashMap libraries that could be chosen -- just to show they are more than *hypothetical*.
Oh, interesting! I'm not that familiar with the details of either one. That's good to know.
Looks good!
&gt; Do we have to call into the C library, or can we port khash to Rust? Not a hypothetical question.
I like this idea quite a bit. Maybe even give it a special syntax in rustdoc.
Oh, so audio only? The deal's off ;)
Anybody who uses `Option&lt;weakless::Arc&lt;T&gt;&gt;` or similar would experience reduced performance, which defeats the purpose.
Implemented in the Rust game, of course.
It basically runs off the `Span` concept in rustc - for every span that is touched by macros, we keep a reference (via `expn_id`) to the stack of macro calls which created the span. In analysis we can then map backwards through that to the edited code. Source maps (e.g., in JS) for debugging are a more common and related feature, if you're interested in this stuff.
My favorite was "Can you run Rust on Windows 10?"
Ohh nice idea! I've been thinking about something similar (in my idea journal), we should discuss!
Thanks, merged. For the record, I get 19ns on my machine, on the same scale as the numbers I cited above.
Ok, good to know. I'm hoping to strike it out on my own once I have some savings and dedicate a significant portion of my time to open source, as it's a cause I believe in. Making the money work is a significant concern. Anyway, thanks for all you do :)
In my pure Rust native user interface library [Derin](https://github.com/osspial/derin-rs), you can now press buttons and have the buttons do stuff! https://gfycat.com/SkeletalElegantGoral There's still a crap-ton of stuff that needs to get done (notably integrating custom derives, adding more widgets, improving custom layouts, and fixing various bugs), but for the first time since I've started working on this an initial alpha release is in sight. I'm stupid excited.
a fellow rust player! r/playrust is what you want. This is for the programming language.
Right at the top. Open the terminal/command prompt and type &gt; rustup update stable
Congrats on the release! Every release I love it more! Great job to all involved!
Define "easiest": * Least amount of boilerplate/dealing with SQL directly? (I want an ORM) * I just want a way to connect to a database and query some data (I want bindings for SQLite, etc)
Pick an API. Build a client for it. I always find that to be a nice, small, manageable project. Good for getting a quick intro to a language.
I'm going to create a channel called `cron_crate` on Mozilla's IRC server on Sunday around 10AM EST. I'll hang out there for a couple of hours if you can drop in. CC /u/stephanbuys
Not with that attitude!
Sure thing. If you run into any problems, feel free to ask on this sub, the forum, or IRC.
Was that a reference to baby Ruby? :) I was going to name our first girl Ruby, but we kept having boys and my brother beat me to it. Not sure if Rust will fly with the misses...
...how is any of this a "stupid trick"? I mean, this is kind of describing the sort of thing `impl Trait` is *for*. I feel like I'm missing something.
Man that confused me for a second when I saw my name in the contributor list! I had completely forgotten what I'd done. Thanks for listing me though, despite my contribution only being some documentation fixes :)
And it may actually be useful after you build it instead of just being a throwaway project. Good idea!
This is really great. I tried to use Diesel for the first time yesterday, and now just a few hours later it works on stable Rust! Also congrats to Sean on the beautiful little one! `^^,`
I think it can't; IIRC it's used to get a mut reference from an immutable binding.
Introducing rustbuild: the flawed buildsystem that doesn't accept dynamic linking any system libraries other than libc!
Here's a little example I whipped up in the last hour that shows what parsing a tiny subset of a semantic version looks like with my in-progress work of Peresil: #![feature(conservative_impl_trait)] #![feature(field_init_shorthand)] #[macro_use] extern crate peresil; use peresil::combinators::*; type Point&lt;'s&gt; = peresil::StringPoint&lt;'s&gt;; type Master&lt;'s&gt; = peresil::ParseMaster&lt;Point&lt;'s&gt;, Error&gt;; type Progress&lt;'s, T&gt; = peresil::Progress&lt;Point&lt;'s&gt;, T, Error&gt;; #[derive(Debug, PartialEq)] enum Error { ExpectedLiteral(&amp;'static str), ExpectedNumber, OutOfRangeNumber(std::num::ParseIntError), ExpectedCharacters, } impl peresil::Recoverable for Error { fn recoverable(&amp;self) -&gt; bool { use Error::*; match *self { OutOfRangeNumber(..) =&gt; false, _ =&gt; true } } } fn literal&lt;'s&gt;(lit: &amp;'static str) -&gt; impl Fn(&amp;mut Master&lt;'s&gt;, Point&lt;'s&gt;) -&gt; Progress&lt;'s, &amp;'s str&gt; { move |_, pt| { pt.consume_literal(lit).map_err(|_| Error::ExpectedLiteral(lit)) } } fn run_of_chars&lt;'s, F&gt;(predicate: F, error: Error) -&gt; impl FnOnce(&amp;mut Master&lt;'s&gt;, Point&lt;'s&gt;) -&gt; Progress&lt;'s, &amp;'s str&gt; where F: Fn(&amp;char) -&gt; bool { move |_, pt| { let width = pt.s.chars().take_while(predicate).map(|c| c.len_utf8()).sum(); if width &gt; 0 { pt.success(width) } else { Progress::failure(pt, error) } } } fn number&lt;'s&gt;(pm: &amp;mut Master&lt;'s&gt;, pt: Point&lt;'s&gt;) -&gt; Progress&lt;'s, &amp;'s str&gt; { run_of_chars(|c| c.is_digit(10), Error::ExpectedNumber)(pm, pt) } fn characters&lt;'s&gt;(pm: &amp;mut Master&lt;'s&gt;, pt: Point&lt;'s&gt;) -&gt; Progress&lt;'s, &amp;'s str&gt; { run_of_chars(|c| c.is_alphabetic(), Error::ExpectedCharacters)(pm, pt) } fn number_u64&lt;'s&gt;(pm: &amp;mut Master&lt;'s&gt;, pt: Point&lt;'s&gt;) -&gt; Progress&lt;'s, u64&gt; { number(pm, pt).and_then(|n| n.parse().map_err(Error::OutOfRangeNumber)) } #[derive(Debug, Clone, PartialEq)] struct SemVer { major: u64, minor: u64, patch: u64, suffix: Option&lt;String&gt; } fn semver&lt;'s&gt;(pm: &amp;mut Master&lt;'s&gt;, pt: Point&lt;'s&gt;) -&gt; Progress&lt;'s, SemVer&gt; { sequence!(pm, pt, { let major = number_u64; literal("."); let minor = number_u64; literal("."); let patch = number_u64; let suffix = optional(suffix); }, |_, _| SemVer { major, minor, patch, suffix }) } fn suffix&lt;'s&gt;(pm: &amp;mut Master&lt;'s&gt;, pt: Point&lt;'s&gt;) -&gt; Progress&lt;'s, String&gt; { sequence!(pm, pt, { literal("-"); let suffix = characters; }, |_, _| suffix.to_owned()) } fn parse(s: &amp;str) -&gt; Result&lt;SemVer, Vec&lt;Error&gt;&gt; { let pt = Point::new(s); let mut pm = Master::new(); let result = semver(&amp;mut pm, pt); let result = pm.finish(result); match result { peresil::Progress { status: peresil::Status::Success(v), .. } =&gt; Ok(v), peresil::Progress { status: peresil::Status::Failure(e), .. } =&gt; Err(e), } } fn main() { let p = parse("0.0.1").unwrap(); println!("{:?}", p); let p = parse("0.0.1-beta").unwrap(); println!("{:?}", p); let p = parse("0.01"); println!("{:?}", p); // The location of the parse failure is available, but I'm not currently returning it } ---- SemVer { major: 0, minor: 0, patch: 1, suffix: None } SemVer { major: 0, minor: 0, patch: 1, suffix: Some("beta") } Err([ExpectedLiteral(".")]) 
Maybe the article can help serve as a gentle nudge to get `conservative_impl_trait` onto a release train sooner rather than later! \^_\^
We definitely have oscilloscopes to go around. That's great. Sounds like it should be smoother than expected.
It turned out that coz Cookie holds a Cow&lt;'c, str&gt;, when you do cloning it won't copy the referenced data but the pointer itself. So the copied pointer cannot live any longer than the original one.
Does nightly support incremental compilation with cargo, or do I have to pass arguments to rustc directly or something?
 let a = vec.as_mut_slice(); let b = vec.as_mut_slice(); You are allowed to do this by the type system because `as_mut_slice` currently borrows `vec` immutably, and you are allowed to have any number of immutable borrows as you want, its perfectly safe. However, you now have two mutable references to the exact same data, which is super unsafe and can cause ugly problems. Switching the signature to a mutable borrow makes it so that the second attempt fails: you can only borrow it once, and it must be "returned" before it can be borrowed again.
Indeed. I can't imagine the motive.
The borrow checker doesn't care whether `Cookie&lt;'a&gt;` contains `&amp;'a str` or `Cow&lt;'a, str&gt;`. It just tracks the lifetimes.
I have actually found that Discord is a lot better than Slack and Gitter.im (personally). While it was not initially designed for this purpose, the origin of Discord (a game chatting without taking too much resource[tm]) makes it much more responsive than other alternatives, while having a good mobile client, decent API and reasonable channel management is a plus. I have abandoned Gitter.im in the past but I'll try to stick there for a longer time (as a nickname *yurume*).
Nice article. Maybe I'm weird, but I still think higher order functions are really cool. I was disappointed when I realised how limited they are on stable rust, but I live in hope that `impl Trait` will land soon. Considering many use cases for `impl Trait` require ATC to be ergonomic, I'd stuffed my excitement into a closet, while waiting for the trait system to be refactored, the ATC RFC to be accepted and implemented. Your post has reminded me there are plenty of reasons to be excited about what we can do with `impl Trait` today, so thanks. I'll be keeping an eye on Strata. :D
Yes, it's done automatically, you don't have to do anything special.
So how do you solve this problem? use std::borrow::Cow; #[derive(Debug, Clone)] struct MyStruct&lt;'a&gt; { s: Option&lt;Cow&lt;'a, str&gt;&gt; } impl&lt;'a&gt; MyStruct&lt;'a&gt; { pub fn new() -&gt; MyStruct&lt;'a&gt; { MyStruct { s: None } } pub fn set(&amp;mut self, s: &amp;str) { self.s = Some(Cow::Owned(s.to_owned())); } } #[derive(Debug, Clone)] struct MyStructWrapper&lt;'a&gt; { d: MyStruct&lt;'a&gt; } impl&lt;'a&gt; MyStructWrapper&lt;'a&gt; { pub fn new() -&gt; MyStructWrapper&lt;'a&gt; { MyStructWrapper { d: MyStruct::new() } } pub fn set_data(&amp;mut self, s: &amp;MyStruct) { self.d = s.clone(); // we want this clone to live 'a, if any referenced data of "s" don't, we'd like to copy those data as well } } fn main() { let mut my_struct_wrapper = MyStructWrapper::new(); { let mut my_struct = MyStruct::new(); my_struct.set("hello world"); my_struct_wrapper.set_data(&amp;my_struct); } println!("{:?}", my_struct_wrapper); }
Here's the trap. Exactly the same as `cookie::Cookie`, the member (`s.s` in this case) is private and there's no API provided to access it.
&gt; why didn't you use Iter in BytesReader In practice it was really not easy to borrow the bytes in the reader. I'm not saying it is not possible but it really complicates things when simple indices are enough (We keep on iterating then getting a slice etc ... ). &gt; you could abstract Reader with AsRef[u8], it'd provide greater flexibility Good idea! Doing it now &gt; I'd be glad if there was some no_std alternative. I have absolutely no experience with no_std. I'd love trying that but I'll probably try to implement some missing protobuf features first. I'd welcome any PR though if you have the time :)
I enjoyed doing the [Advent of Code](http://adventofcode.com) problems as a way to practice with Rust.
Probably making a crack at go
The lifetime parameter doesn't really have any bearing on how long the cookie lives. `Cookie&lt;'static&gt;` means it doesn't contain any borrowed references, so it can live as long you want it to, but you can drop it at any time (as long as you haven't let someone else borrow it).
Really? But referring to http://rustbyexample.com/scope/lifetime/static_lifetime.html, &gt; A 'static lifetime is longest possible lifetime, and lasts for the lifetime of the running program.
Yes, really. This may be one of the larger naming mistakes in Rust -- experience with C should have taught us not to give more than one meaning to the `static` keyword! Anyway, "consists entirely of owned data or references to static memory" is a much more useful definition of `'static`.
Thanks, I've read pretty much all of libfuse, osxfuse, the kernel module and rust-fuse. I was hoping there was some actual documentation, since those C-devs really like their non-descriptive variable names and comments are sparse. Guess I just need to spend more time with it. 
You have just thrown a bomb into my understanding to static lifetime in Rust! So if no threads, data races, etc are involved, I can effectively mark everything as static without using a bit more memory?
Congratulations! What's the news on `const fn` functionality? I wrote a yet-to-be-released library year or two back that requires compile-time data transformation to preform well (The penalty of doing the transformations during run time can become unacceptably large, exponential in some cases). 
Hell yeah it is! I just started removing the custom Serialize/Deserialize implementations for one of my crates. I really hope it works!
This is my favorite stupid trick you can do: fn curry&lt;T, U, F, X&gt;(f: F, t: T) -&gt; impl FnOnce(U) -&gt; X where F: FnOnce(T, U) -&gt; X { move |u| f(t, u) } fn main() { let add = |x, y| x + y; let incr = curry(add, 1); println!("{}", incr(1)); }
Looks like little Ruby gives his/her blessing for the new release. :-)
rustbuild only works for the buildbot, and distro packaging which involves system LLVM/jemalloc is broken. I have fixed two issues yesterday and today.
You can't evaluate that collect expression in gdb, no, but if you had that expression in your code you could print the value of v. You can also set breakpoints in monomorphized functions, I usually use `info function` (`im loo -r -n` in lldb) with a regex to find the name and copy paste.
Gosh, this is mind-blasting to me. I thought I should never use `static` unless I need it to live through the whole program.
I have a workspace with a few crates, one of them producing cdylib. However, when building this crate, I don't see a nice libfoo.so in wks_root/target/debug, only libfoo-eb27f2049e336663.so in wks_root/target/debug/deps. Further build steps will have to locate and package this .so for non-Rust consumers, which makes it non-trivial.
Meybe even `#[deny(unsafe_without_comment)]`?
We hope our fork is only a temporary measure allowing to us to move faster than ramp. We have authored some fixes for the non-assembly fallback allowing the code to cross-compile to all rust-supported platform (with ios, android and the pis being the one we are most interested with). We have also implemented a relativelly efficient modpow operator (which is ultimately what the Paillier bench tests). Most of these fixes have been merged upstream, and we hope we can get the rest merged as well. We have some interest in improving the raw performance of ramp but believe the low hanging fruits are gone already: platform-by-platform assembly by people who know what they are doing is required to get closer to GMP.
Yesterday I got quite excited about it, so I think I might help. However, I'm working on another project currently, so I'm not sure about when I'll be able to. I'd like to try to use `Iter` too and make a PR if I'm successful.
I'm not using Visual Rust at this moment
"Ferris" maybe?
So I know a prominent Python guy with a daughter named Py, a prominent Ruby guy with a daughter named Ruby, and a (presumably vim-using) programmer with a son named Vim. I like this trend :) 
I'm really really tired, so the writing might not be that good. But figured it's better to get this out here sooner rather than later. I'm pretty sure the alternatives section's second sentence explaining why not to go with the alternative is really poorly worded. Sorry.
While I've always wanted something like this and think it would do good, I'm not certain it could have prevented the iter mut thing. That's the simpler kind of unsafe that's basically "this is safe because it obviously is" used by thin unsafe wrappers like IterMut, which works until you make typos or copy paste mistakes. But we should totally get this and also bulk up our review process so that this gets caught in the future. This won't solve the problem completely, but it's a step! And there are other steps we can take to bridge the gap.
Counterpoint: If I was reading the code, and wondered "but have they considered what happens with signalling NaN?", I could check the safety justification, see that it's not mentioned, and know to be *extra* suspicious. I mean, this is a *bit* like saying "well, comments can be wrong, so they're not very useful." The point is not to be perfect, but to capture the writer's thinking at the time. The lint just makes it easier to self-enforce "thou shalt document thine `unsafe` blocks, or thou shalt find thineself consigned to the stocks and *yea* shall thee be mocked and ridiculed." ^\[1] --- \[1]: I have no idea how to write proper old English.
The biggest drawback I see would be that you could change the code and not update the safe attribute. Maybe it would be good to have a policy, that you have to add somehow when you last checked if your code is safe (maybe a date or commit hash)?
That's a good start. I think we should try to at least document the invariants, perhaps even test them with `debug_assert!(_)`s.
&gt; [The newly-stable signature `fn as_mut_slice(&amp;self) -&gt; &amp;mut [T]` is incorrect as there's nothing stopping one from calling that multiple times to get multiple `&amp;mut [T]`s to the same data.](https://www.reddit.com/r/rust/comments/5roiq7/announcing_rust_115/dd8vujs/?st=iyprgkx3&amp;sh=22c96475)
This could be handled by git hooks. If you change `unsafe` code and not it's description, you have to put annotation in commit message explaining why it's still safe after the change. If you did change explanation, it's assumed you were thinking about it.
&gt; [1]: I have no idea how to write proper old English. You got the thou/thee subject-object distinction right, recognized that "shalt" is the "thou" conjugation of "shall", recognized that "yea" is an archaic form of "yes", and used "thine" over "thy" before a word that begins with a vowel. You did better than most fanfic authors I've seen. There are only two issues with it: 1. "and yea shall thee be mocked and ridiculed" is right on the edge of my expertise, so I can't be sure if it works. ("and oh will you be mocked and ridiculed" sounds valid in Modern English, but I'm having trouble analyzing the grammar to justify the archaic phrase of the same form.) 1. Use "thyself", not "thineself". "Thy" and "thine" follow the same rules as "my" and "mine": * "Thy" is the 2nd-person singular/informal possessive adjective in Early Modern English, as "my" is the 1st-person possessive adjective in Modern English. * We form the reflexive (myself, thyself) from the possessive adjective. * As a special case that was dropped from Modern English, the possessive pronouns "mine" and "thine" are used as adjectives if the noun being modified starts with a vowel. ("My hand before mine eyes". It's a pronunciation optimization similar to "**a** hand holding **an** apple" or the French [liason](https://en.wikipedia.org/wiki/Liaison_(French)). 
I will probably translate it to french and change some little things here and there. Thank you for this work and for sharing it ! Vag'
&gt; Do nothing. There's already a lint in the ecosystem for the // SAFE: comments. I was unaware of this, I use clippy in a nearly "turn up to max, then whitelist back down" configuration (I'm still on enabling `clippy-pedantic` and a couple of other lints, but I plan to go full whitelist), and I'm the kind of person who'd definitely take advantage of it. At the very least, it should be advertised better.
Documentation fixes are arguably more important than code fixes
Ah that's a good one too, thanks!
Thanks!
So the new book isn't at chapter 20 "Advanced Type System Features" yet, but I guess this will go there in the future? Would it be a good idea to create an issue about this to make sure it isn't forgotten / open a PR to add the description from the nomicon to that chapter?
Can I just say how great it is that rust is able to move so fast on new features while still doing a very through and public job of vetting out issues and problems with it? Compared to many other languages opaque attitude towards language evolution, it really is a breath of fresh air.
The word order is correct. It's a phenomenon known as [V2 word order](https://en.wikipedia.org/wiki/V2_word_order) and it's very common in the germanic languages. V2 has fallen out of use in modern English except in a few edge cases, but it was much more common in the past.
I think that is the more important thing to do. new or changed unsafe blocks should require extra signoff. Adding a safe annotation doesn't really increase safety, it just adds more pain around doing unsafe. I don't see it as adding a lot of benefit. Perhaps another way to approach this is to do code coverage checks and make sure every unsafe block has a unit test. With that in place, having something like valgrind in the works to verify that the unit tests finish without memory errors would be a good way to approach this IMO.
Sure. Keep in mind that I don't necessarily think the OP is a bad idea, I just think we should address all drawbacks. :-)
Thanks. :) Another thing for me to get a feel for and add to my guide.
Thank you.
Thank you
I just don't know what it does, and there's no documentation.
Does the choice of c compiler affect the results at all?
Thank you!
"only documentation fixes" are so important, and I think we should all scrub the phrase "only documentation" from our vocabularies :)
Yes, I saw the README. That's the only documentation, and it shows how to use the derive, but it doesn't show how to use anything useful from the derive. I think I know what the library does, but I'm still not 100% sure.
You can iterate over variants of an enum and turn a string into the corresponding variant. That's all ...
Discord should make a separate brand and sell this for enterprise. It's a lot better than Slack.
I currently use rust-postgreSQL which is much simpler than Diesel ,but at the cost of writing own queries and making the are correct to stop run-time errors. 
/r/playrust
You're looking for /r/playrust. This subreddit is dedicated to the Rust programming language.
Make it work on every scope. I could do fn foo() { #[safe("reason")] unsafe { bar(); } } to explain one unsafe, or #[safe("reason")] fn foo() { unsafe { bar(); } unsafe { baz(); } } to explain all unsafes in a function, or `#![safe("reason")]` to explain it for a whole module.
No macros, but lots of overloaded operator abuse!
wouldn't a `#[safe("TODO")]` not show the warning thus defeating the purpose?
Whatever the outcome of the RFC, the **standard library** should definitely require unsafe blocks to have comments explaining the safety rationale behind them.
Good article, even though I don't fully agree. Although I can understand most points, I don't really see where the complexity of the type system comes from. I had the experience that the strong type system really helped me getting to where I wanted; especially after reading the rust book. The types available in the standard library are well documented and also well named, I fail to understand where one might have problems after reading a few examples except you really need to dig into fully generic higher kinded functions or similar. Maybe people coming from more dynamic oriented or scripting languages do have more problems there and I just don't see them. Also I don't agree you should consider Rust only for performance critical and security relevant systems. While there are domains where other languages are simply better suited than Rust, there is no code worse than code that does fail, may it be due to memory bugs, performance problems or other problems, which Rust tries to avoid by its security guarantees and strong type system.
[Calibre](https://calibre-ebook.com/) allows this iirc.
People think that they can learn tricky topics without reading books ;) The type system _appears_ complex at first, because you need to understand how the parts fit together, especially the dozen or so key traits. With familiarity of course, it all appears well designed and no more complex than it should be. 
&gt; It's not just about safety. I think Rust's PR over-emphasized memory safety to the point that the other benefits from a stronger type system got drowned out :(
There isn't enough hype about zero cost abstractions. Rust lets me write pretty bitchin code that's also blisteringly fast, close to the metal, and safe. Combined with nice abstraction layers for using rust from other languages and other niceties on the 2017 road map, I feel like rust is very close to being the official Cat's Pajamas
Yup I was waiting a long time for that!
Great work! Thanks so much for sharing your effort with the community! I have one suggestion, and this is just for the README: add a section to describe a possible use case that this crate solves. Your explanation to /u/coder543 details that, but most devs who come across your crate aren't going to see this comment section. ;)
(I'm not even a developer but... :) Someone's posted PDF and EPUB versions [here](https://killercup.github.io/trpl-ebook/). I think you can use it to convert either to mobi, but the EPUB would work best.
Great work! One question: Is there a plan to ever enable incremental compilation by default for `--release` builds?
&gt;If your software isn’t complex or the security isn’t critical (e.g. when writing a backend service that will not face the internet), but you still need performance, Go or even C/C++ might be a better choice. This will allow you to avoid the complexity cost. This is a nightmarish idea. Back-end services need to be secure even on a closed network. Just saying *our network is closed therefore secure* is a horrible horrible threat model. [Article on the subject](https://medium.freecodecamp.com/hacking-imgur-for-fun-and-profit-3b2ec30c9463) 
I am having trouble using traits. I have a trait and its implementation, as follows. pub struct Foo { a: i32, } pub trait Greet { fn hello() -&gt; String; } impl Greet for Foo { fn hello() -&gt; String { "Hello!".to_string() } } I tried using it from my main as follows. extern crate traits; use traits::foo::Foo; fn main() { let f = Foo { a: 5 }; println!("Hello from the other side: {}", f.hello()); } lib.rs contains pub mod foo; and Cargo.toml is as follows. [package] name = "traits" version = "0.1.0" authors = ["xyz"] [dependencies] But I am getting error: no method named `hello` found for type `traits::foo::Foo` in the current scope What am I missing here?
You can't use methods defined in a trait until you import the trait itself.
Incremental will never produce binaries that are as well-optimized as a full compilation cycle, due to the restricted information that the compiler has available, since it can't see the full picture, so I don't think they will ever do that, based on the discussions I've seen. There would be really no benefits. If you need optimizations turned on for your debug builds, you can edit your `Cargo.toml` file [to enable them.](http://doc.crates.io/manifest.html#the-profile-sections) But, `--release` is for when you're producing a binary that you would conceivably distribute to other people... and you want that to be the highest quality binary that it can be.
Yup!
Incremental compilation should be augmented with [thin]LTO to mitigate performance loss. 
It is free. Do whatever you want with it :-). Remove my name, put yours, I don't care ;-).
For my main project, incremental compilation seems to be *slower* than non-incremental, even on subsequent builds. $ rustc +nightly --version rustc 1.16.0-nightly (eedaa94e3 2017-02-02) $ CARGO_INCREMENTAL=1 cargo +nightly build Compiling app v0.1.0 (file:///.../app) Finished dev [unoptimized + debuginfo] target(s) in 31.37 secs $ vim src/main.rs # Change a single character in an unimportant string $ CARGO_INCREMENTAL=1 cargo +nightly build Compiling app v0.1.0 (file:///.../app) Finished dev [unoptimized + debuginfo] target(s) in 24.94 secs $ vim src/main.rs # Change a single character in an unimportant string $ cargo +nightly build Compiling app v0.1.0 (file:///.../app) Finished dev [unoptimized + debuginfo] target(s) in 23.37 secs How should I go about debugging this? (Unfortunately, this project is not open source.)
Are you on windows?
 Note that you can get the same effect in a regular build by setting the number of codegen units to roughly the number of modules in your crate, e.g. with rustc -Ccodegen-units=140 Oh, didn't consider this, but it makes sense, I wonder if codegen units can get smaller than module sized...
Except that you can see that I didn't mention signalling NaN in my rationale for why it was safe, and see that it's actually undefined behaviour. You checked my reasoning and found it wrong because of something I did not know. I switched the example over from f32 to u32.
Yes! Something like this. Right now the tag needs to be a string but I filed [serde-rs/serde#745](https://github.com/serde-rs/serde/issues/745) to follow up on allowing integers too. #[macro_use] extern crate serde_derive; extern crate serde_json; #[derive(Debug, Serialize, Deserialize)] struct Version1 { old_field: String, } #[derive(Debug, Serialize, Deserialize)] struct Version2 { new_field: String, extra_field: Vec&lt;usize&gt;, } #[derive(Debug, Serialize, Deserialize)] #[serde(tag = "schema_version")] enum X { #[serde(rename = "1")] Old(Version1), #[serde(rename = "2")] New(Version2), } fn main() { let j = r#" { "schema_version": "1", "old_field": "s" } "#; let x: X = serde_json::from_str(j).unwrap(); println!("{:?}", x); }
Not now. It will with incremental type-checking.
*/me prepares for Fireflower Onslaught 2: Electric Boogaloo*
OP. Thanks for all the feedback. I'd like to ask if you are aware of the difference between descriptive vs prescriptive linguistics? I favor strict descriptive approaches to language. I vehemently reject anyone trying to claim ownership or privilege over the words that me or my friends use. Historically academic coverage of programming has been comparatively prescriptive à la "use my idea thing". By contrast, what I see in Rust is a pragmatic [Creole](https://en.wikipedia.org/wiki/Creole_language) programming language. What I would like to see more of, if I were to ask for it, would be more [Pidgin](https://en.wikipedia.org/wiki/Pidgin) use of the language. Basically more libraries, community, and a little bit more sanity wrt sharp edges.
Note that this doesn't support binary strings or encoding/decoding yet, but I figured it was already good enough to be useful and that I should release it to get feedback and see if there was anything that needed to be changed. Also, there were a lot of String methods that I couldn't properly wrap due to Pattern being unstable, so I just made them take &amp;str instead, except for trim_matches, which takes a char.
https://crates.io/crates/lazy_static probably
Maybe there should be a new --dev configuration: debug: incremental, with debug symbols, debug assertions and overflow checks, ... for finding bugs dev: incremental with some slight optimizations for fast compilations / fast code release: non-incremental, highly optimized code
&gt; Shame, I would have hoped for a built in solution. This is maintained by the rust team; it's one hair's breadth away from being "built-in".
Oh there was an icon? I got frustrated and left. Figured I'd read it on the desktop later.
I'm not opposed to the idea, but for me 99% of my use of `unsafe` is for FFI code, so it'll just look like `#[safe("This C function has no invariants that aren't already trivially satisfied")]`.
It's worse than that. Usize is only guareneed to be at least 8 bits.
[removed]
What would this mean for the benchmarking game for those benchmarks that use the slower std::collections::HashMap?
It is not clear since the maintainer still won't answer my questions with regards to non-`std::collections` hash maps.
I feel an issue in terminology is making our communication unclear. When people who use C++ see "C++" they think "modern C++". When people who do not use C++ see "C++" they think "legacy C++". The clear issue then is that writing a guide called "porting from C++" is ambiguous. You may not realise that **the current guide mixes C++ and legacy C++. This is a misrepresentation of the state of things** and makes the guide less useful for porting from either. In essence, we agree. There is a difference between porting from C/legacy C++ and porting from C++ (sometimes called "modern C++"). We agree that these would probably best be separate guides, assuming unlimited time/resources/energy. The options are to either remove all the modern C++ and call it legacy, to have both and call it C++, or to separate the two. I would go for the second option, it gives a clear indication that most of the things Rust solves are solved in modern C++, however there is a lot of legacy syntax, traps, and no guarantees of safety. &gt;If you think there should be those guides, then write them I did spend two hours reviewing the current guide for free to help ensure the Rust community isn't driving C++ developers away from their language. I don't have a horse in this race.
In other words, it's only true in C/C++ due to a quirk of the language specification. Signed integers aren't any faster than unsigned integers in Rust or other languages without UB.
I'll have to check that out.
Thinking about it more, wouldn't it actually maybe make sense to do something like this? enum EzString { Literal(&amp;'static str), Owned(Arc&lt;String&gt;), } That way you get rid of the HashMap completely. Not sure if it makes a whole lot of sense, since this would introduce a general cost, instead of a cost that only happens when turning a literal into an easy string. Btw, I would potentially market this crate differently. This string type is really great and should be used in a ton of situations, but the initial impression the ReadMe gave me, was that this is a type for beginners who don't want to deal with the different string types and lifetimes. But in reality this type is super useful for situations where you want to have owned strings and you might need to clone them a lot. This type provides owned strings that behave exactly like normal owned strings except it **reduces deep clones and unnecessary allocations**, which is a super useful property that the normal String type does not have.
Oh, right. I forgot about that. Now I can be even *more* pedantic about misuse of `usize`! :D
Can I move my post? (New to reddit)
Yes, I should have been more clear. Using signed integers in C/C++ can be an optimisation because the compiler can legally, as per the specification, assume that overflow does not occur. Some examples would be assuming that `x + 1 &gt; x` and `x / 2 * 2 == x`. *Other languages which specify overflow behaviour do not get that advantage.* Furthermore, if Rust code is compiled for a platform which does not do two's complement wrapping then it will emit extra instructions to ensure that the behaviour is simulated in software (I think? There have been a number of changes to how Rust handles this and I'm not sure where it finally ended up). C and C++ would not have this overhead either. The optimisation is not a quirk of the specification, it is an engineering decision and has real world benefits and trade offs today. Given Rust has been created in a different era of hardware and with a different focus it makes sense that it is different.
The docs for `CHashMap::insert_new()` refer to a `replace`method but it appears it was renamed to `insert`, based on the documented semantics.
You are definitely right, that is why I mentioned Rust being designed in a different era of hardware.
Thank you, it's helping me.
"Actually can" must be properly delimited, for example https://www.reddit.com/r/cpp/comments/5qu8fr/a_guide_to_porting_c_and_c_code_to_rust/dd40vau/?context=2.
This is how I feel. std should always be held to a much higher standard.
Rust is impl Trait
Doesn't it make more sense to use the uninhabited `!` type?
Yes but there's no jokes there :p
All it does is wrap [the existing String method](https://doc.rust-lang.org/std/string/struct.String.html#method.to_lowercase). And yes, they are unicode aware.
Serde is really going from strength to strength at the moment.
Awesome project. Better string ergonomics is super important to rust. I hope you learn things that can feed back into rust proper.
I love Discord, it's way easier to get people on to talk than anything else like Mumble or Skype, since they can do it from the browser.
Yep, that's what I like about it. Also, it works on phones too :D
The java version imports a hashmap from fastutil, so I guess that rust can do the same. Actually it could be interesting to have something like fastutil in rust. * http://benchmarksgame.alioth.debian.org/u64q/program.php?test=knucleotide&amp;lang=java&amp;id=1 * http://fastutil.di.unimi.it/
Clickbaitish title. 
Legit, love it. Will for sure look into using it. 
My word that's amazing, as someone who uses a dark theme for absolutely everything possible this would be fantastic. Was it hard to do? I'm considering doing Dracula theme too.
Chrome dev tools make it reasonably easy to do :). You could have Dracula up and running fairly quickly just by forking and changing the colors (I do have at least some comments on what things are for the rustdoc css). 
I think I fixed it. Can you confirm that it works for you as well? It is tricky because (1) we want desktop browsers with JS disabled to show the sidebar by default (2) we want mobile to hide the sidebar by default (3) I don't understand CSS (4) I don't understand JS (5) I barely understand HTML (6) nobody else is willing to work on the website.
A `Vec` allocates memory, so you can't create one at compile time regardless. 
Once in a while I really want a concurrent hashmap in rust, and I'm always like "Ticki is going to give this to me one day, I know it." And today is that day. Thanks for another killer data structure implementation.
Not sure I'm understanding the purpose. It looks more complicated than just using the built in String type.
&gt; Incremental will never produce binaries that are as well-optimized In theory, compilation should be able to in some cases, and be able to tell when it can't and do a full build in that case.
The general problem of everything in the stdlib is that a) it has to be rock stable, b) it needs to be released together with rustc. A library maintained by the core team has much more flexibility, including just trying out a solution and breaking it if it sucks. Or deprecate it and write a new library.
My guess would be, that in "fast" debug symbols are stripped and whatever optimization possible to infer from incremental builds is applied. Just a guess though. Edit: damn auto-correct for another language...
 extern crate futures; use futures::{Stream, Future, IntoFuture}; trait StreamNext : Stream { fn next&lt;F, U&gt;(self, f: F) -&gt; ::futures::BoxFuture&lt;Self, Self::Error&gt; where F: 'static + Send + FnMut(Self::Item, Self) -&gt; U, U: IntoFuture&lt;Item = Self, Error=Self::Error&gt;, U::Future: 'static + Send, Self: Sized; } impl&lt;S: 'static + Stream + Send&gt; StreamNext for S { fn next&lt;F, U&gt;(self, mut f: F) -&gt; ::futures::BoxFuture&lt;Self, Self::Error&gt; where F: 'static + Send + FnMut(Self::Item, Self) -&gt; U, U: IntoFuture&lt;Item=Self, Error=Self::Error&gt;, U::Future: 'static + Send, Self: Sized { self.into_future() .map_err(|(err, _)| err) .and_then(move |(item, stream)| { f(item.unwrap(), stream).into_future() }).boxed() } } * You need to constrain `U` by `IntoFuture&lt;Item=Self&gt;` in addition. (causing `mismatched types` error) * `BoxFuture` is an alias to `Box&lt;Future + Send&gt;`, and `Box` requires `'static` bound by default. So you need to add `'static + Send` bound for `F` and `U::Future` that are being boxed. (causing `the trait bound ... is not satisfied` error) * Closure `f` will live with a future returned. Move `f` into it. (`closure may outlive the current function` appears after you solve two errors above)
Well, for one, it cannot properly handle Turkish because case change works differently there, but there is no way to pass in a locale.
I think you've antagonized him a bit. My off the cuff understanding is that he wouldn't approve of a crate from crates.io which isn't used by anything, but if there were a library in wide use then it'd be greenlit to be used The benchmark game is a game, &amp; he's the referee to bring an element of human decision making so that rules don't have to be written with lawyers in the room (even then, law brings in judges &amp; juries to bring a human element to the interpretation of law)
[This comment](https://www.reddit.com/r/rust/comments/5ny09j/tips_to_not_fight_the_borrow_checker/dcfjnp1/) contains a suggestion because this pattern doesn't work very well in rust: instead of storing the reference, pass it as an argument to any method that might need it.
Would you consider using `RefCell` instead of references?
Indeed! Works now. Thanks.
Hmm, I haven't used RefCell before. I can't tell straight from the docs how it would solve this dilemma. Can you share what the resulting declarations would look like?
Yes. And its really nice if you have a really big block of code that contains `/**/` you want to comment out. In C you could do `#if 0` as a trick, but you don't have it in Rust (you do have cfg but it only works on modules/blocks and its a hack just as `#if 0` is).
Is enumerators correct? I'm used to something like enumerated type or enumeration.
RefCell is essentially the same as a reference, but the borrow rules are run at runtime. This means the borrow checker will not complain anymore. However, I'm not sure how to construct Foo with Bar containing a RefCell to common, because you can't access `foo.common` yet at the construction time of `foo`. That said, you'd have the same problem with regular references.
How would this interact with actual python strings?
Just to be clear. It sounds like the elements of foo form a graph. Is this graph a tree? Raptor suggested using RefCell. Alternatively you can store all the nodes in a vector and use indexes instead of references. Here are two tutorials * https://github.com/nrc/r4cppp/blob/master/graphs/README.md * http://featherweightmusings.blogspot.dk/2015/04/graphs-in-rust.html 
Spam marked &amp; banned
It is not possible in rust to observe an immutable reference changing in value. So you can *never* have a struct containing a piece of data, and a reference to that data, unless it is implemented using unsafe code, or an abstraction around unsafe code. The reason for this restriction is quite simple - it makes reasoning about data structures much simpler, especially when it comes to concurrency. Optimizations are made that rely on the fact that the referent of an immutable reference cannot change (it doesn't need to be reloaded from memory each time it is used). In a language like C++, you could get away with this, but it would lead to data races and/or undefined behaviour. Consider you had a function impl Foo { fn change_common_data(&amp;mut self, new: i32) { let ref_to_common: &amp;i32 = self.bar.common; println!("before: {}", ref_to_common); self.common = new; println!("after: {}", ref_to_common); } } This code clearly observes an "immutable" reference changing if we used your example; and if this is allowed, *every* read of an immutable reference would have to be considered effectively volatile, rendering its immutability useless. Moreover, if the object were more complicated than a simple i32, it could be in an indeterminate state as we, say, iterated over it, leading to undefined behaviour. struct Foo&lt;'a&gt; { common: Vec&lt;i32&gt;, bar: Bar&lt;'a&gt;, } struct Bar&lt;'a&gt; { common: &amp;'a Vec&lt;i32&gt;, } impl Foo { fn uh_oh(&amp;mut self) { for val in self.bar.common { self.common.clear(); // depending on the implementation of the iterator, it could get stuck in an // endless loop here, referencing memory past the end of the vector } } } If you really want to be able to modify data in one place, and read it in another, you need to use unsafe code, or an abstraction around unsafe code. This allows "interior" mutability of a struct. The standard library's `Rc&lt;RefCell&lt;T&gt;&gt;` is such an abstraction for single-threaded code. It cannot be used in multi-threaded code as it does not use thread-safe locks. For multi-threaded code, you could use `Arc&lt;Mutex&lt;T&gt;&gt;` or `Arc&lt;RwLock&lt;T&gt;&gt;`. use std::cell::RefCell; use std::rc::Rc; #[derive(Debug)] struct Foo { common: Rc&lt;RefCell&lt;i32&gt;&gt;, bar: Bar, } #[derive(Debug)] struct Bar { common: Rc&lt;RefCell&lt;i32&gt;&gt;, } impl Bar { pub fn new(common: Rc&lt;RefCell&lt;i32&gt;&gt;) -&gt; Bar { Bar { common: common, } } } impl Foo { pub fn new() -&gt; Foo { let cmn = Rc::new(RefCell::new(42)); Foo { common: cmn.clone(), bar: Bar::new(cmn) } } } fn main() { let foo = Foo::new(); println!("{:?}", foo); *foo.common.borrow_mut() = 6 * 9; println!("{:?}", foo); } 
If the borrow checker allowed your code, it would be a memory error. When the `Foo` is moved out of `new()`, it goes to a different place in memory. However, `Foo.bar.common` is pointing to the old location, which will be overwritten next time you call a function. To avoid this, you would need to have a piece of code called with every move, to update `foo.bar.common` to point to the new location of `foo.common`.
Seems to work great on my mobile now, thanks!
&gt; I think you've antagonized him a bit. He antagonized me first. :p This has been going on for months. &gt; My off the cuff understanding is He literally said &gt; If you want an additional Rust hashmap implementation then you need to persuade the Rust community to provide one in std::collections. He also said "call into khash" and when I asked him if that had to be in `std::collections`or on crates.io, no answer. It's not just me, /u/jeremiahs_bullfrog asked extremely reasonable questions for clarifications. &gt; The benchmark game is a game, &amp; he's the referee I agree 100%. That's why it's so frustrating; all I want to know are the rules. If the rules are "I make my own judgements", that's fine too, but the response to my extremely basic and straightforward questions not being answered is, frankly, infuriating. Even "I am arbitrarily deciding if it's allowed or not" would be a better answer than the situation as it is now.
I'm just wrapping the standard method. You should file a bug against Rust.
This is impossible to do in safe rust, but the [owning_ref](https://github.com/Kimundi/owning-ref-rs) crate allows you to do this with a bit of unsafe code. Note that you'll also have to box common so it has a stable memory location.
&gt; I wonder how well a whole stdlib like this would work for the cases of someone wanting a "lower cognitive overhead" approach to rust I have thought for a long time that this would be a cool idea.
I'd just submit a pull request and see if he will accept it.
yeah another rust player! this is for the programming language, you probably want r/playrust!
How does serde deal with a changing schema. So you are deserializing an old struct that lacks some fields?
Yes! You can put `#[serde(rename = "m.room.create")]` on the variant and that applies to both externally tagged and internally tagged style.
Optional fields are optional. #[derive(Serialize, Deserialize)] struct Request { stable_field: String, extra_field: Option&lt;String&gt;, } This struct can be deserialized from `{"stable_field":"..."}` and `{"stable_field:"...","extra_field":"..."}`. Other than that, you can handle it using exactly what this post is about. An internally tagged enum if there is one field that identifies which schema version it is, or an untagged enum if Serde needs to figure it out on its own. Are there any other schema changing scenarios you are worried about that would not be covered by any of those three approaches?
Rust is
&gt; since the problem was imgur deliberately exposed their development servers to the internet for periods of time. Except the services assumed they were on a trusted private network. The issue wasn't they were connected to the internet. But they assumed they could trust external connections. They would have behaved similiar on an untrusted network. Except instead of an untrusted internal network. They were on a untrusted external network. The Internal/External is semantics. The *assumed trust* is the real flaw. 
Are you sure? Having a global lock (even if it is only taken read-only) means there is contention on the internals of the lock for all accesses, since there has to be at least one write to [lock](https://github.com/Amanieu/parking_lot/blob/eb92e2c5426085f7d73d812f3344f236c3af8c3a/src/raw_rwlock.rs#L117-L121) and [unlock](https://github.com/Amanieu/parking_lot/blob/eb92e2c5426085f7d73d812f3344f236c3af8c3a/src/raw_rwlock.rs#L163-L172) it, putting an upper limit on throughput. (Also, there are claims of excellent performance, but neither the documentation nor the repository have benchmarks.)
&gt; I'm also certain that if I went and tried to learn C++ now I would find it exceedingly complex compared to Rust. I'd recommend reading [this](http://blog.regehr.org/archives/213) series of blog posts, if you're not familiar with C and C++. Rust can feel a bit restrictive from time to time, and often times it's because the compiler is keeping you from writing fundamentally dangerous code. And on top of that, the C/C++ compilers focus on speed, not security. As the compilers keep getting more advanced, the more undefined behavior in existing code starts to backfire. There's a lot of interesting stuff to read on this subject. And this is something very experienced developers keep encountering as well. Not too long ago a lot people were blaming gcc for changing the way `memcpy` works. The C standard explicitly states that the two memory regions shouldn't overlap, and a lot of people neglected that because they knew the implementation started copying at the end. That is, until it didn't, and people starting blaming the compiler developers for introducing bugs, which is so hilariously unjustified. And there are more obscure examples as well. I remember reading about a bug in Postgres. As I recall, C assumes that every function call returns, while they had a function call end with an `exit` instead. And this _somehow_ broke something like a decade after writing that code, because the compiler optimized some critical code away because it should've been unreachable if they kept to the standards. 
Ideally it'd be a small pull request. Add in a preexistig hashmap library to the Cargo.toml, replace HashMap with NewHashMap, make PR
Oh my god. I need this exact kind of thing for something I'm planning to do, and I was stuck on a brick wall of how I would best do this. The thought of a concurrent hash map didn't even occur to me. Thank you so much! This is gonna make my project a lot easier (and probably a lot more efficient!) 
The benchmark game does not use github; it uses http://fusionforge.org/ , which means creating a new account, managing patches, etc. It's not super trivial to contribute to. It's not the hardest thing in the world, but it's still going to give me enough hassle that I'm not going to bother unless I know that it's workable. Furthermore, it's not clear _what_ to send until these questions are answered: should it be this hash? should it be a rust wrapper around khash? Should I re-implement khash in Rust? If so, should that be via corrode + some cleanup vs a cleanroom implementation of khash? Which one of these options is actually the fastest? etc etc etc.
oh sweet, will be using this to avoid getting my eyes blasted whenever I switch from editor to docs. Thanks!
Nice puzzle. Title kind of gives away the answer though.
Nice. I've been using [Dark Rust World](https://userstyles.org/styles/137697/dark-rust-world) lately. I like how this looks more. I'd love if this worked better on the user forums and playground too. I'll have to stick with DRW on those for now.
Ah, I forgot about the playground. I'll get that done over the next few days. As for the user forums, I'll look into supporting those as well, but it will likely take a bit longer.
In my experience it's the opposite. For instance, CMake usually provides Debug, Release, and ReleaseWithDebugInfo build types. While I'm developing I'll use the latter. That way code still runs tolerably fast and you can see which line simple errors come from, which is often enough to fix them. If I hit a bad problem then it's recompile in Debug mode to step through the code. Hit a point version and I'll compile in Release for that last bit of extra speed.
it sounds like fast here refers to the performance of the code &amp; not the compiler
I feel like this is a bug, since we have nested comments nested `//` comments should be recognized as inner comments as well as nested `/*` comments. So the `//` should be consumed by the parser, stopping it from finding a nested `/*`, as happens in the uncommented case. Though I guess `/* // */ stuff` shouldn't comment out stuff, so maybe it's not that clear cut.
I'll ask my wife about naming our next child "mofo" and let you know how it goes.
her. :)
I mean you could just name them `None::&lt;!&gt;` for the double whammy
badass!
Found that already. I'm using it for now but I find procedural macro more elegant, so I plan to switch to it later.
What's wrong with .matches().collect()? Is the problem that it returns borrowed slices? If so, you can just call .map(str::to_string) or similar.
The problem is I don't know exactly how the pattern looks like. With *matches()* I'd have to know the full link, which I don't. I only know that it **is** a link. So this: .matches("https://").collect(); will return: ["https://", "https://", ...] but I need this: ["https://somesite.com", "https://othersite.com", ...]
&gt; regex Yeah, seems like it. But I'll try to do it with string slices now.
Seems you can pass a closure to `matches`, in which you could check against a regex
So I grabbed your repo and replaced the std hashmap with /u/bluss 's excellent [ordermap](https://github.com/bluss/ordermap). On my machine the runtime drops from 5.2s to about 3.3s. I think that would qualify as a library hash map in use (it's hardly tailored for the use case, it's just modeled after Python 3-s dictionary. Do you think trying a submission with this would be worth it? (e: I created a PR: https://github.com/TeXitoi/benchmarksgame-rs/pull/39 , I think it's worth a try)
I just started with rust this week. I have a struct that contains a `BTreeMap` with `Vec` values. I want to iterate over the elements as if they were a single iterator: i start from the first btreemap element (a vec) and iterate over its elements, then move on to the second map element and so on. The problem is that I'm completely lost on how to implement my iterator. Any help? Or do you know where I can find an implementation of a nested iterator that I can look at. use std::collections::BTreeMap; use std::collections::btree_map; use std::slice; #[derive(Debug)] pub struct MyStruct { data: BTreeMap&lt;u32, Vec&lt;u32&gt;&gt;, } impl MyStruct { pub fn new() -&gt; MyStruct { MyStruct { data: BTreeMap::new() } } pub fn push(&amp;mut self, k: u32, v: u32) { let mut vec = self.data.entry(k).or_insert_with(Vec::new); vec.push(v) } pub fn iter(&amp;self) -&gt; Iter { Iter { outer: self.data.values(), inner: None, } } } pub struct Iter&lt;'a&gt; { outer: btree_map::Values&lt;'a, u32, Vec&lt;u32&gt;&gt;, inner: Option&lt;slice::Iter&lt;'a, u32&gt;&gt;, } impl&lt;'a&gt; Iterator for Iter&lt;'a&gt; { type Item = &amp;'a u32; fn next(&amp;mut self) -&gt; Option&lt;&amp;'a u32&gt; { None } } fn main() { let mut s = MyStruct::new(); s.push(123, 1); s.push(123, 2); s.push(120, 3); let v = s.iter().collect::&lt;Vec&lt;_&gt;&gt;(); // v should be equal to [3, 1, 2] } 
Awesome work, thank you!
 &gt;`fn insert_new(&amp;self, key: K, val: V)` &gt; &gt;Insert a new entry. &gt; &gt;This inserts an entry, which the map does not already contain, into the table. If the entry exists, the old entry won't be replaced, nor will an error be returned. **It will possibly introduce silent bugs**. &gt; &gt; To be more specific, it assumes that the entry does not already exist, and will simply skip to the end of the cluster, even if it does exist. &gt; &gt; This is faster than e.g. insert, but **should only be used, if you know that the entry doesn't already exist**. Maybe this function should be declared `unsafe`.
Will try. Thanks!
are you sure you want to do this with simple search/regex? xml documents are not plain text, using this method you would for example also catch just plain text urls, content of &lt;link&gt; and &lt;meta&gt; tags, and would not catch relative links. maybe use an xml parser to parse xml?
You've got a reasonable structure in place already. [Here](https://is.gd/YwYsQX) is one way to finish it up (though you'd probably want to loop rather than recurse in `next`). But what you're doing is the same thing [`iter::FlatMap`](https://doc.rust-lang.org/std/iter/struct.FlatMap.html) returned from [`Iterator::flat_map`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.flat_map) does, so you can make use of that (and see the source with the link in the top right). The easiest way is with the nightly-only "impl Trait" feature, [like this](https://is.gd/5ua1rj). If you can't or don't want to use nightly, you can explicitly wrap the `iter::FlatMap` struct, it's just [a little ugly](https://is.gd/7kVzNX).
For sure. There's certainly a balance, like most things in life. My heuristic goes something like "Spend the maximum amount of time on optimizations that wont piss your boss (or customer) off".
Thanks for checking out the project! I really wanted to use the built-in op traits but orphan rules prevented me. The issue is that I need to be able to add any `Expression` implementers (which includes Variables) - but Rust doesn't permit this. The `Variable` creation is also a fairly complicated situation. I have to store the value in another struct (`Context`) so that I can change it between gradient computations (rather than completely rebuilding the expression). This means that I have to assign an index for each `Variable` in the `Context`.
I've just gotten started working with microcontrollers for the first time, and I just so happen to be using Teensy. I'd love to try using Rust for these, but seeing as how I have absolutely no idea what I'm doing I'm a bit apprehensive at the idea of moving away from everything that Teensyduino comes with out-of-the-box. That said, I do have a few questions: 1. You say "To connect the serial pins of the Teensy to our computer, we will need some sort of USB serial interface. I’ll be using an Arduino Leonardo for this.", but the Teensy I'm using (3.2) has a USB connector right on the board, which I've used to communicate via serial to my development machine. What is the role of the other Arduino here? 2. I see you have some panics in the code, but what does panicking actually do in your implementation? 3. Does the section on setting up the serial pins imply that you can use any digital pin for serial communication? If so, then why does the Teensy pin diagram have only a few specific pins that are labeled as Tx/Rx (e.g. https://www.pjrc.com/teensy/card7a_rev1.png )? 4. Is "GPIO" just a synonym for "digital pin"? I'm sure this sounds like a stupid question, but I'm teaching myself all of this and my knowledge is spotty. :)
In general, a wrapper-type based approach is the way to go. I would delegate the methods directly instead of relying on auto-deref, because with the latter, you lose control over the resulting type. If you want to go further, you may want to look into the [dimensioned](http://github.com/paholg/dimensioned) crate.
You're likely looking for /r/playrust
&gt; - `Variables` are very weakly linked to `Context`. There's a way to do it using [dummy lifetimes](https://github.com/bluss/indexing), I think.
I also wrote a toy autodiff library long time ago. I didn't look at your implementation in detail but I think it will be interesting to compare. https://github.com/kkimdev/autograd . I chose to make few dirty design/code structure tradeoff for performance.
Link from Mutabah: https://github.com/thepowersgang/rust_os/blob/master/UnsafeAudit.sh
Disclaimer: it was long time ago so I might have incorrect memories. For tieing `Variables` to `Context`, I made a `new_autograd_context!` macro that defines unique `Context` type for every instance, and `Variable` type is dependent on that. So users can't mix `Variable` types if they are tied to different `Context`s, since the type is actually different, although the implementation is the same. This can go wrong if the function that has `new_autograd_context!` is called recursively and users mix variables of them, but I'd say this is a super contrived case :). IIRC, I did this for performance reason though, not for preventing wrong use.
Nice work there! From a cursory look, you appear to be constructing some sort of directed acyclic graph (a.k.a. "expression template") with topological sorting? As I suggested on the other threads, it might be useful to try the branded indexing approach to avoid mixing the variables in different contexts, and see if you can use a wrapper to sidestep the orphan rules. The last time I tried doing expression templates like your code, but using the Add, Mul etc traits, I ended up overflowing the compiler's trait resolver. I eventually worked around it somehow but I ever understood why that happened (nor can I remember how I caused that). Not too long ago, I sketched an [extremely rudimentary reverse AD library using a tape-based ("Wengert list") approach](https://github.com/Rufflewind/revad/blob/83a86f458e7d72d45253ef805675f80e3700eab0/src/tape.rs). The tape implementation is probably the simplest/dumbest way to implement it, and should be relatively simple to extend. However, I wasn't satisfied with it, because it assumes each node to be a binary operation on f64s. I wanted something that could work on arbitrary numeric types so as to discourage "[f64 blindness](https://existentialtype.wordpress.com/2011/03/15/boolean-blindness/)" in numerical code. This would also allow operations like `f64 -&gt; f64` or `[f64] -&gt; [f64]` to be treated on equal footing. I'm not quite sure how to get that though. There are other things I would be interested in an AD library. As you suggested, being able to define custom operations with minimal effort is crucial. It would also be nice to avoid allocations unless absolutely necessary ("zero-cost" in Rust). Unfortunately, the "reverse" part of reverse AD is a real pain to handle because it runs counter to a lot of Rust's semantics and computation in general -- even Haskell needed to do something crazy behind the scenes to get AD to work. I wrote a list of [ideas](https://github.com/Rufflewind/revad/blob/de509269fe878bc9d564775abc25c4fa663d8a5e/ideas.md) a while back but didn't have enough time to explore all of them.
If you like programming languages, then I would recommend writing rust versions of entries in the PL zoo: http://plzoo.andrej.com/
Sure that'd be great! Youd be more likely to get caught with a large transfer, but it's definitely acceptable!
Thank you :)
haha, nice hack. Hopefully it doesn't blow up in your face.
What about using the `Box`? trait Node&lt;T&gt; { fn left_child(&amp;mut self) -&gt; &amp;mut Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;; fn right_child(&amp;mut self) -&gt; &amp;mut Option&lt;Box&lt;Node&lt;T&gt;&gt;&gt;; fn get(&amp;self) -&gt; &amp;T; fn set(&amp;mut self, v: &amp;T); } struct IntNode { pub data: i64, pub left: Option&lt;Box&lt;Node&lt;i64&gt;&gt;&gt;, pub right: Option&lt;Box&lt;Node&lt;i64&gt;&gt;&gt;, } impl Node&lt;i64&gt; for IntNode { fn left_child(&amp;mut self) -&gt; &amp;mut Option&lt;Box&lt;Node&lt;i64&gt;&gt;&gt; { &amp;mut self.left } fn right_child(&amp;mut self) -&gt; &amp;mut Option&lt;Box&lt;Node&lt;i64&gt;&gt;&gt; { &amp;mut self.right } fn get(&amp;self) -&gt; &amp;i64 { &amp;self.data } fn set(&amp;mut self, v: &amp;i64) { self.data = *v; } } fn main() { let mut root: IntNode = { let left = IntNode { data: 0, left: None, right: None, }; let right = IntNode { data: 2, left: None, right: None, }; IntNode { data: 1, left: Some(Box::new(left)), right: Some(Box::new(right)), } }; if let Some(ref mut left) = *root.left_child() { left.as_mut().set(&amp;10i64); } if let Some(ref left) = *root.left_child() { println!("Updated left child: {}", left.as_ref().get()); } }
The main problem is when interior mutability is required, and `Rc&lt;RefCell&gt;` start to replace `Box` for a few nodes.
At least for x64 that should be seriously cheap with lock elision.
I have not used rust on a microcontroller before, but I think I can answer your three other questions. 1. You are right about using the USB connection to communicate to your development machine. The teensy 3.2 has two types of serial ports. Three UART ports using pairs of GPIO pins and one serial over USB. The connection to your machine is using the second type while this post is talking about the first. The other arduino is used as the receiving part of the UART connection. 2. Cannot say anything about this. 3. https://www.pjrc.com/teensy/td_uart.html shows which pins can be used for each of the three hardware serial ports of the teensy 3.2. So while you are fairly restricted you have a choice in which pins to use. Another reason is that you have to configure the pins to be connected to the serial port. Many pins can be configured to be used for one of many purposes, for example digital i/o, analog input or serial rx/tx. 4. GPIO stands for General purpose input/output as in you can configure what the pin is used for. It can not only be an digital input but also output, configured by the user at runtime. So you are right, its basicaly a powerful digital pin.
&gt; Those things are primarily disallowed to allow for fast recovery (aka. to avoid the need for OS threads), not for before-the-fact resiliance. That doesn't mean you couldn't (or shouldn't) use them for before-the-fact resiliance. It also doesn't mean they do a poor job at it. Just because trees weren't designed to be burned doesn't mean they aren't able to fuel a campfire :) &gt; Erlang's principal philosophy is literally "Let It Crash", and many of its features are built around this. That doesn't mean you have to follow "best practices" to the letter. I certainly don't. That said, the point of "Let It Crash" is often to prevent exactly the sort of situation you're seeking to prevent: the sooner our filesystem process (for example) crashes, the less risk of it (in this example) doing something harmful to the underlying data, and the sooner its replacement can check journals and reinitialize and all that jazz. The C2 wiki entry actually seems to be a good synopsis of our so-far-week-long conversation :) &gt; Saying "you can't be perfect so don't bother trying" is a terrible argument. Indeed, which is why it's not my argument. My argument is and has been "you can't be perfect so be ready to eat your mistakes". Like I've said: you need to try to prevent errors *and* try to handle them when they happen anyway, and while Rust does a better job at the former (at least in theory), Erlang currently does a better job at the latter (at least out of the box, though even Rust's crate ecosystem has a long ways to go last I checked) while doing enough of the former to be tolerable in a system that is both "fault-resistant" (as you say; I'd probably opt for a term like "fault-preventative" to better describe the Rusty approach) and fault-tolerant. Like I've said (or at least think I've said) repeatedly, it could be improved considerably with stronger compile-time sanity checking, and I'd welcome it with open arms. &gt; How can you possibly prefer spending hours to restore from backups to spending half a minute rebooting? I don't. I prefer spending half a *second* "rebooting", and not losing the entire system state when I do so :) This is again comparable to the difference between a monolithic kernel and a microkernel (in fact, it might as well be synonymous): all your drivers sharing their memory with one another and the kernel v. all your drivers being isolated processes that can stop and start independently from one another (respectively). At this point, I feel like associating fault-tolerance with data corruption is itself a strawman. Again: nothing stopping you from writing your journaling code in Erlang. Real-world journaling filesystems are implemented in languages with far worse "fault-resistance" than Erlang (*cough cough* C *cough cough*) and do a reasonably good job at it. (Of course, the half-second-reboot bit is an exaggeration, and a filesystem replaying its logs and checking its journals and such will likely take at least a few seconds to "reboot", but at least that's just a few seconds rather than having to wait for everything else to load) &gt; I've answered this so many times that I'm struggling to see why you're not grokking my answer. Because the provided answer is still grounded in incorrect assumptions. I grok the answer fully; I just don't agree with it :) Must like how it's not fair of me to assume that Rust's only recourse in the face of an error is to `panic()`, it's not fair of you to assume that Erlang is entirely incapable of preventing errors before they happen. &gt; corruption can result in permanant, unrecoverable errors And the sorts of corruptions we've been discussing are very rarely (if at all) subject to mitigation by compile-time safety checks (at least not the sort that Rust provides; last I checked, it doesn't come anywhere close to [the sorts of things normally implied by the term "formal verification"](https://en.wikipedia.org/wiki/Formal_verification)). Rust and Erlang are actually on equal footing here, because the sorts of problems we're talking about at this point fall into two categories: * The compiled code itself becoming corrupted after compilation * The code being written with an incorrect/incomplete model of the in-production environment (be it due to unexpected hardware failure, programmer forgetting to implement some safety mechanism or other feature, programmer getting the order of some sequential series of events wrong, etc.). Neither Rust nor Erlang can do a whole lot to prevent either of those categories; both of their "fault-resistance" mechanisms are at too low of a level to prevent high-level programmer brain farts, and preventing compiled code from becoming corrupted is beyond the scope of most programming languages, Erlang and Rust included (indeed, if there's any place to implement that, it's usually in either the filesystem or the underlying hardware thereof). &gt; Having a journal in the first place is a fault resistance strategy It's actually closer to fault tolerance; in most (all?) journaling systems, the point is to be able to recover from a write that failed midway, and usually to do so after-the-fact (usually the next time the filesystem is mounted). Journaling filesystems of this nature actually mesh well with a stereotypically-Erlang-like "let it crash" philosophy, since the filesystem process crash itself can be safely recovered so long as the replacement uses the journal to reestablish filesystem integrity. &gt; if your journal is handled sloppily then you're fucked regardless. And your journal can be handled sloppily no matter how "fault resistant" your language may be. Rust v. Erlang is entirely irrelevant in that context. I'm perfectly capable (at least in theory, and albeit not at all willing) to write an ext4 "implementation" in Rust that completely fills my partition with zeroes whenever I want to save a file, and as far as Rust cares this is perfectly "safe". There's very little (if anything) stopping me from using Rust to write a journaled filesystem that - whoops - doesn't actually use the journal because I stubbed that out and forgot to unstub it (and it'll still compile, albeit with some possible grumbling due to unused functions). There's very little preventing me from doing all sorts of silly things to destroy my data, but hey, at least my code won't segfault.
Does this still clone the Git repo in tha background?
Great answer! Thanks.
For parsing links and the like from HTML I have personally used [select](https://github.com/utkarshkukreti/select.rs) in the past. This is mostly due to the fact that you don't need to reinvent the wheel (and because I used Python with BeautifulSoup before and that spoiled me).
Thanks for pointing me towards this. I haven't checked it out before but it looks like it would indeed be very helpful. I don't know Haskell but hopefully I can make enough sense of it.
Could you do this? let x = context.create_variable(1.0); let f = x.sin() + x; where I assume `x` has already been wrapped by `create_variable`. Here `.sin()` is from `num_traits::Float` presumably.
Nice to see more databases covered! I've never used Cassandra myself but from a few google search, it seems they do have schema migrations right? If so, I'll probably add it to https://github.com/Keats/dbmigrate using your crate!
You’re taking an different approach (not using pjrc’s C/C++ code, as far as can tell), but have you seen https://github.com/jamesmunns/teensy3-rs/ ?
Why not map each variant in the `Vec` into their corresponding `&amp;str`?
Eh. I think judicious use of macros like this is OK. It's hard to know whether I actually agree with your use of it without seeing the code though. I don't think I've ever felt inclined to write your specific macro. Instead, I tend to write it out like this: let value = match option_value { None =&gt; return None, Some(x) =&gt; x, }; If I did have to write that out *a lot* and a macro would generally make the code clearer, then I think I'd go for it. But I wouldn't start using it everywhere. Another case where you might want a macro is when writing iterators that yield `Option&lt;Result&lt;T, E&gt;&gt;`. e.g., [`itry`](https://github.com/BurntSushi/walkdir/blob/6a49e22bd2996ca58814a74d1a02cacbb2154180/src/lib.rs#L109).
Great! If you have any question feel free to ask me here in PM or on Github
This doesn't help now, but [the `Carrier` trait](https://doc.rust-lang.org/std/ops/trait.Carrier.html) that allows `Result` to be used with `?` is planning to be extended to `Option` in the future. For current development, I kind of like monadic error handling, so structuring the code like initial_option.map(|val| { do_thing_with(val) }).and_then(|val| { do_fallible_thing_with(val) })
JetBrains is the answer to like every IDE question for like every language. Other than the vim and emacs people.
There is also a great vim plugin (ideavim) for that ide. 
Is there a build somewhere that doesn't require you to agree to the "we may spy on you" clause in Microsoft's license for it? (That's what kept me from evaluating its suitability to my needs.)
Wasn't that only for the beta?
As well as these groups: * People who don't like freemium models aligned on axes other than "free for open-source projects, paid for private repositories" * People who don't want to be at odds with their IDE vendor's goals if they insist on trying to replicate the paid version's language/framework support in the open-source version. (eg. JavaScript, TypeScript, Django, Node.js, Grunt, etc.) * People who don't like using Java for GUI applications
I use emacs + rust-mode. If you don't have any investment in emacs, it's probably not worth it to pick it up just for rust. I'm still in the learning phase for rust, but my workflow is: * edit file * hit `C-c C-c b` to build * (if there is an error) switch to build output and select error, which is hotlinked back to the file/line number * edit and repeat I never leave emacs, not even for the terminal. For instance: * `C-c C-c t` for tests * `C-c C-c r` does a cargo run It's kind of hard to visualize, but if your project doesn't have long build times, this is a pretty rapid process. I'm sure there is a flycheck mode for on the fly syntax and error checking, but my current workflow is pretty fast too. I also have racer doing autocomplete, to the best of it's abilities anyway. 
&gt; Other than the vim and emacs people. Even still. I'm a Vim guy, and I think "IntellJ + Vim plugin" is a better Vim than the real Vim.
VsVim for Visual Studio (not vs code), Ideavim (intellij) and Evil-mode for Emacs are both as close to perfect vim emulation as I think you can get. Meanwhile, I'll try doing something that Vs code doesn't support at least once per minute, and I'm a pretty novice vim user.
number + `f` is currently working fine for me
It's still in the license I was presented with when I went to check it out about a week ago.
Thanks
Last I heard, the rustc codebase had three separate implementations of that pattern (`try_opt!`, `option_try!`, and `otry!`). I wouldn't worry about it.
I haven't programmed Clojure in half a year, but I always found emacs to have the best IDE experience. Similarly, emacs + proof general is the best IDE for Coq IMO, and similarly emacs + Idris mode is the best IDE for Idris. My next project at work is in CUDA; in the past I didn't find CLion to be all that great but I'll be researching this soon.
I am done.
Last time I tried it it didn't support Cargo. Has that changed?
Qt Creator is better for C++ IMO. Also free unlike CLion.
You may want to ask /r/playrust
Not true. Visual Studio Code isn't Java-based and isn't text only. It has 'go to definition/peek definition', RLS based errors, debugging, the works. It's not all flawless yet, but it works very very well when it does. Edit: And it's open source too.
Yes, of course! I made this change which certainly helps to keep things tidy. I'm still playing around with things but you can see how it looks to the user on the repo README.
I meant wrapping them with appropriate copy on write mechanics - no change, no copy.
i have no idea what do you exactly mean by supporting cargo, but it is possible to add cargo run configurations (build run test etc.).
I have no idea what caused your errors (although I suspect it might have been using `str` bare somewhere), but you don't need your`f` variable in `main` to be mutable; the `mut` there is strictly unnecessary.
As a vim user who has been working in VS Code the past week, its vim plugin is indeed not very good. A lot of the bahavior is unexpected (e.g., yanking and pasting doesn't put the cursor in the correct position), and it breaks the native editor (e.g., redo). It's way too buggy in its current form. 
You probably want to post this to /r/playrust 
You probably meant to write this: ¯\\\_(ツ)\_/¯ Type this, and it will show up right: `¯\\\_(ツ)\_/¯` It came out wrong because the backslash is used to escape special characters in Markdown. This means the backslash part of the figure's arms is not shown, because it escaped the underscore part. You need to escape the backslashes and the underscores. (You can actually use one less underscore than I did, but I like consistency.)
Hard to tell, but yeah, I don't think the new release would have actually affected anything.
Having spent 3+ weeks each using [intellij-rust](https://intellij-rust.github.io/), [vscode-rust](https://github.com/KalitaAlexey/vscode-rust) and various different plugins for rust support in Sublime Text 3, I can confidently say that the best experience I've had up to this point was with the vscode plugin(s). Sublime Text 3's plugin situation is, at least for me, rather wonky; while I was able to get things mostly working on macOS, I was never able to get working autocomplete on Windows 10 (in addition to the rather long and painful setup time). Intellij-rust was certainly extremely easy to get going with, but the bloat of IJ itself drove me away. Vscode strikes the perfect area for me; it was instant to get up and running with (since I already had the necessary tools cargo install'd and the rust src component added via rustup, everything worked out of the box) and still maintains the editor experience. The only thing I haven't been able to get working is the LLDB frontend, but that's due to my use of the WSL, not the fault of the plugin itself. TL:DR, I recommend vscode.
IDEA (on which you can use almost every plugin) is free and under a permissive license.
What's the situation like for working with JavaScript, TypeScript, Node.JS, Django, SQL, and PHP in it without the paid plugins?
[FOSDEM blackboard after the BOF discussion](http://imgur.com/a/hEmv8)
Haha? LOL.
You should be able to get JavaScript support by adding the appropriate plugin. I don't know the rest, because I'm not a webdev. You're welcome to download the community edition, open the plugins panel and see if it meets your needs.
Add the following to your personal settings: "telemetry.enableTelemetry": false, I really think the "spy on you" is hyberbolic -- the release build collects usage and crash info by default, and you can disable it. Further, VS Code is MIT licensed, so can examine the actual telemetry code, and are free to do your own build with the telemetry not just disabled, but deleted. Edit: See [here](https://github.com/Microsoft/vscode/issues/60#issuecomment-161792005) for clarifying comments from Microsoft.
This is a consequence of the `Fn`-bound syntax being treated specially with respect to lifetimes; the trait bound `Fn(&amp;str, i32)` is actually sugar for `for&lt;'a&gt; Fn&lt;(&amp;'a str, i32), Output=()&gt;`. You can write out the higher-ranked lifetime binding explicitly if you want, and then it will apply to more than just the `Fn*` traits.
Sublime Text 3. It doesn't have the best features set, but it's fast and small (low on RAM and Disk Space).
I'm using ST3 as well, but have found Rust plugin support to be rather poor. What are you using for linting? Every plugin I've seen is old and doesn't support the new error format.
This thread is about a Rust HashMap [CHashMap](https://docs.rs/chashmap/0.1.2/chashmap/). It is a library written for general use, not specifically engineered for the benchmarks game. Is it permissible to use in the benchmarks game? 
Is it? Most IDEs with "Vim support" leave a lot to be desired. I use quite a few Vim features (macros, registers, etc) and few plugins, and most IDEs I've used the Vim plugin with (Eclipse, VS) feel half baked and I tend to just avoid it since it's less frustrating than just using the built-in WYSIWYG editor. Right now I'm using Rust in Vim, but do you recommend trying IntelliJ + Vim? Have you found that it's mostly complete in terms of Vim compatibility? Does the Vim mode work with alternative keyboard layouts (I use Dvorak, but my system keyboard is Qwerty so some editors use that instead, e.g. Android Studio uses it for shortcuts)? I'll have to try it out. IIRC, Android Studio is now IntelliJ, which I currently use.
The compiler should emit a pretty clear warning here as well. Not too critical to example code though.
Hey everyone, Does Rust support integration tools like MQ IBM Series, and does it have a driver for Oracle DB with connection pooling? Sorry I am super new to Rust and looking for options to replace Java at work.
The only use I can see for this is what the README demonstrates, which is visually comparing two strings. I say that because encoding as emoji uses high bits, so it can't be used to turn binary into 7-bit text, and also encoding as emoji is a pretty significant size increase, using base64 probably produces fewer bytes. So the benefit here is in having fewer characters. Given that, why not Base512? Or even higher?
`unwrap_or_return!` from the `mac` crate.
For that specific example, you could simplify it to `initial_option.map(do_thing_with).and_then(do_fallible_thing_with)`. (You probably know this, but OP and others may not.)
I might just do that once I can spare the time. (Right now, I'm having trouble keeping my TODO list from growing too quickly as-is.)
So, I've played around with a pretty different design for an efficient, concurrent HashMap. This post made me decide to polish it up, run some benchmarks, and publish it. It exposes a somewhat different API than a regular HashMap, but the transformation shouldn't be too bad. And it has *really* fast reads! I'd love some feedback for it: https://github.com/jonhoo/rust-evmap.
I took the liberty of also posting it as its own thread at https://www.reddit.com/r/rust/comments/5saw4z/evmap_another_efficient_concurrent_hashmap/
It's true that Rust is only mentioned on two slides. The other slides cover libraries where the community tries to integrate Rust into them, rewrite parts or everything in Rust, partly because of security concerns. So these mentioned libraries have ties with Rust and the community.
VSCode + [vscode-rust](https://marketplace.visualstudio.com/items?itemName=kalitaalexey.vscode-rust) + [vscode-lldb](https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb).
Intellij + Vim is pretty good as far as vim support goes. I used it before; I could do regex, searching, pretty much every text editing option out there, etc. Only thing I really missed was the plugins and the fact that it's not 100% so every now and then you hit some weird edge-case and can't do something the "vim" way you normally do. I like it a lot better than just intellij, and it's my favorite Java setup because Java is far too painful to do without an IDE.
Heartbleed is an implementation error, due to reading past a buffer's end. Mandatory bounds checking, such as implemented by rust, would have prevented it. Of course there are some protocol design errors which rust wouldn't have stopped at all, but heartbleed isn't one of them.
Base 65,536?
Then you've got to worry about endianness in transcoding ;).
Yeah, the goal was to write something that was for visual comparisons. I was pretty careful to build out the emoji table such that it had the following properties: 1. No similar characters - this is why there's no faces, since it may be hard to tell the difference between, for example "Kissing Face" and "Kissing Face With Smiling Eyes", etc. 2. Easy to tell what a character is: most of the characters in the list are easy to look at and read out in English, in case you needed to e.g. read over the phone, out loud, etc. This isn't perfect, since I actually ran out of distinguishable emoji that didn't require support for Unicode 9.0. In addition, as /u/zamadatix mentioned, having the encoding be octet-aligned makes it much easier to encode: a single emoji is a single character, so the implementation is trivial. Also, it was a fun excuse to play around with [trust][t], for automatic testing and binary releases :-) I might eventually offer an extended option which can be used for "compression"; something like base1024 is probably doable with common emoji. [t]: https://github.com/japaric/trust/
Re point 2: Using `xargo` to compile will turn panics into aborts. I haven't tested this but it will likely reset the processor. 
hi i was trying to setup coverage for rust project;but i was unable to do so. this is my fork https://github.com/harrydevnull/cdrs test cases are executing correctly on travis https://travis-ci.org/harrydevnull/cdrs/ i had setup travis.yml as per https://github.com/huonw/travis-cargo but coveralls.io coverage is still empty https://coveralls.io/github/harrydevnull/cdrs what am i doing wrong any help is appreciated
For a more complex example of where this really stands out is, see http://manishearth.github.io/blog/2015/05/03/where-rust-really-shines/
Changing it to be single value should be pretty straightforward, but unfortunately expressing it solely in the type system would lead to a pretty funky interface, and quite ugly code. I'd probably recommend instead that people either fork it and remove the few places where a `Vec` is used, or just use it anyway. The performance overhead is pretty tiny. The reason I chose to do multi-value is (like is often the case) because the use-case I needed this for needed multi-value. And it's next to impossible to emulate a multi-value map on top of a single-value map through an oplog.
Which version of Rust are you building with? As far as I know this just got stabilized in the most recent Rust (1.15) so if you are running an old version then you'll need to update.
What rust version are you compiling with?