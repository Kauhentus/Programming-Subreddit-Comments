It is, because it's the only efficient way to scale to 4D or 5D tensors, see my comment to chrismorgan.
No general-purpose language (putting Julia, Matlab, Fortran in DSL) as a native multidimensional array syntax, they have arrays of arrays. The synctatic sugar for the nice notation Foo[1, 2, 3] is provided by libraries (Numpy, Eigen, Torch ...)
Multidimensional arrays are not implemented like arrays of arrays and do not need language support, you're right. You just need a struct that has metadata, describing if it's a 3x4 or 5x6x7 multidimensional array, and a "storage" in Rust it would be a Vec or a pointer to a GPU location, and done.
https://github.com/bluss/rust-ndarray
It certainly is hard to get right as shown by all the bugs I have raised to the Nim bug-tracker. I'm happy it's being tackled now in Rust.
Nice ! (and my go bot was written 2 years ago ;) )
His vitals are fine sir: he's been tweeting steadily since the operation.
Also it has frameworks implementing asynchronous event loops – like [Vert.x](http://vertx.io/). I think Vert.x coupled with `CompletableFuture`s for nice futures chaining (eg. using [`VertxCompletableFuture`](https://github.com/cescoffier/vertx-completable-future)) is basically equivalent to Tokio – gives you working event loop and chaining asynchronous computations with composable futures.
*functional*. heh.
Author here, allocations and deallocations are really expensive, especially in tight loops. And Monte-Carlo algorithms and Stochastic Gradient Descent produces a lot of temporary values (random simulated games in one case, and gradient in the other) that are throwed away. For example, Monte-Carlo simulation are evaluated in the order of 2000~10000 full games per second each full game is about 300~400 19x19 game board that you just throw away the next second. For Deep Learning, I load 4GB of images, feed that to my GPU, it gives me gradients (doubling memory use to 8GB), I take them into account for a new batch, and fresh new GB batch loaded in memory. This is done in milliseconds hopefully. I dare say, 90% of the Deep Learning performance challenges is how to feed data fast enough to the CPU/GPU. This is detailed here in my article on writing a "[high performance tensor library](https://andre-ratsimbazafy.com/high-performance-tensor-library-in-nim/#how-controlling-overhead)" In the end, I had to do heap allocation anyway to store the data in my tensors because too much operations in data science require it (concatenating two matrices, stacking 100 of images into a batch to feed to a neural network, etc ...).
hit me instead ;)
I'm not sure that's quite right. Tokio is for asynchronous IO; the equivalent of that in Java is the java.nio package, and things built on top of it like XNIO and Netty. Netty in particular is comparable to tokio-proto. Future, CompletableFuture, ExecutorService, etc are the equivalent of futures and futures-cpupool. As in Rust, in practice, you will need to use both.
In C#, there is a significant difference between a `T[,]` and a `T[][]`, in that the second allows a jagged array. That is, it allows for each "sub-array" to be of different lengths, while the first requires that they be of the same length.
Science is not CPU bounds, it's memory-bound, there are very few algorithms that can reach the 90-100% theoretical GFLOPS of your CPU, matrix multiplication is one of them. Looping through all elements of a matrix/tensor/vector would just bring you to 20% at most because memory is the bottleneck. So for speed you need to carefully tune your memory access pattern, make sure your data resides in the L1 or L2 cache. In this [integer matrix multiplication benchmark](https://github.com/mratsim/Arraymancer/#micro-benchmark-int64-matrix-multiplication) I am 10x faster than Julia and 22x faster than Numpy because I carefully manage my memory. Even without multithreading I am still 3x faster. (Note that it is integer so no optimized implementation from OpenBLAS/MKL). I like Haskell too, it teached me a lot and I like coding in it, see [this repo](https://github.com/mratsim/haskell-numbertheory). Why I didn't consider Haskell was indeed due to memory management. For your third point, I didn't say Rust was bad in general, but it was not suitable for scientific computing.
I tried using Julia for Machine Learning [here](https://github.com/mratsim/MachineLearning_Kaggle/blob/master/Kaggle%20-%20001%20-%20Titanic%20Survivors/Kaggle-001-Julia-MagicalForest.jl). The goal is nice but I didn't like the language during use (v0.4). I preferred Haskell, Rust, Python and Nim. The main thing is that actually using/enforcing types in Julia is clunky, also there is a lot of hype regarding Julia speed but in practice I didn't see a difference with Python/Numpy, also Julia package management was really bad compared to cargo.
Absolutely right, though theoretically Julia can be statically typed.
What operation?
1. They are not, Crystal, Nim and to a lesser measure D do not need them. In any case to make your code readable for humans you will need to use indents, code block and such, i.e. visual cues. Now you do the same for the compiler with semicolons, braces, etc. Hence you're doing twice the work, I believe the compiler/machine should be working for you here. 2, 3. I back-pedaled after experimenting with static arrays for data to use dynamically sized array. However it is still relevant for board games for example. Also I think the people you talked to would care if using the stack instead of the heap would cut some computation times by 30%~50% by allocating stuff on the stack. (That happened to me when I moved my metadata data that described my Tensors to the stack)
It definitely works with racer. https://i.imgur.com/2r2vmrT.gif
Ghc itself actually does this too: http://www.aosabook.org/en/ghc.html Pretty cool stuff!
I do know about rust-ndarray, and uses it as reference as well. Bluss did an impressive job kickstarting the Rust scientific stack. However I believe it will have issues to convince the scientific community to switch to it. Researchers usually use a high-level language (Python, Matlab) and when they encounter a bottleneck, drop to C/Fortran. I don't see them dropping to Rust due to the steep learning curve while they want to iterate fast. Also, I might be wrong but even though I started on Nim and writing a tensor library in April, I offer already much more features than ndarray in [my own library](https://github.com/mratsim/Arraymancer) in about 6 months and 360 commits while ndarrays has 1900 commits and 3 years of existence. Features including: Numpy-like slicing syntax, array broadcasting, custom operators like in Julia and Matlab, parallelism (done by rayon in ndarray), GPU computing, autograd and deep learning gradient descent I believe there are several reasons for that: - Steep learning curve of Rust - Verbosity of the languages makes it harder to get into a codebase - Ease of use and fast iteration: Rust compilation is slow - Easy to port C and Python to Nim
It was just a joke about responding "he's still tweeting" to the question "is he ok?"
Rust is still a bit lacking to reach fortran speed. This is Nim &gt; # 99% of matrix multiplication time is spent here &gt; # I tell the compiler: &gt; # - that my data is aligned on 64 bytes boundaries and can use intrinsics &gt; # - via restrict that only a single variable/pointer can access the memory location at any single time (no aliasing) &gt; # - I unroll a double nested 4x4 loop into 16 assignment statements for optimization. (MRNR = 16) &gt; {.pragma: align64, codegenDecl: "$# $# __attribute__((aligned(64)))".} &gt; var AB{.align64.}: array[MRNR, T] &gt; var voffA = offA &gt; var voffB = offB &gt; {.pragma: restrict, codegenDecl: "$# __restrict__ $#".} &gt; var a {.restrict.}= assume_aligned(A.data, FORCE_ALIGN) &gt; var b {.restrict.}= assume_aligned(B.data, FORCE_ALIGN) &gt; ## Compute A*B &gt; for _ in 0 ..&lt; kc: &gt; # for j in 0 ..&lt; NR: &gt; # for i in 0 .. &lt; MR: &gt; # AB[i + j*MR] += A[i + voffA] * B[j + voffB] &gt; unroll_ukernel(AB, a, voffA, b, voffB, MR, NR) &gt; voffA += MR &gt; voffB += NR Rust implementation by [bluss is there](https://bluss.github.io/rust/2016/03/28/a-gemmed-rabbit-hole/#fn:2) Compared to Rust, Nim can tell that pointers do not alias (like Fortran) and I can force the compiler via __builtin_assume_aligned to use efficient SIMD operations. Result is 3x (without OpenMP) or 10x faster than Julia (22x than Numpy) on [integer matrix multiplication](https://github.com/mratsim/Arraymancer/#micro-benchmark-int64-matrix-multiplication) (no BLAS) on 1500x1500 matrices
I'm using VSCode with the official Rust extension and run into [this issue](https://github.com/rust-lang-nursery/rls/issues/227). :-/
Author here, sorry for the distress. I'm pretty sure Rust is awesome for various use cases. You don't want to be Jack of all trades, master of none anyway ;). So don't feel bad about it not being suitable for only a domain.
Yes, that was one of my planned refactoring
Full code here: https://github.com/mratsim/rustygo
I would say half of the Nim community are game devs ;). And you have 3 type of object in Nim: type Foo = object (stack allocated) type Bar = ref object (GC based) type Baz = ptr object (heap but no GC, need to use malloc/free)
Sure they do. C# was one example.
For someone who is not from the area and would need to drive in, how is the parking situation?
`let add = |a: i32, b: i32| a + b;` I _think_ you could just use `i32::add` (with `std::ops::Add` in scope), or at least`&lt;i32 as Add&lt;i32&gt;&gt;::add`, no?
that's a very imprecise question, can you explain what you are trying to achieve? unless you're interacting directly with your operating systems, the network access applications get won't be able to tell the difference between wifi, a regular ethernet connection, and bluetooth or usb tethering.
Ok, that is what I thought. Have you considered using a language like java? Heap allocations there are very cheap. And if throughput is what you are after, java's GCs are unparalleled. (Ok, Haskell's is better, but it cheats).
I don't know, but if it doesn't go to ideavimrc or vimrc and source the file (source ~/.config/nvim/init.vim). I think it should work. Back when my vimrc was split in several files that I sourced from the main vim file I had no problem.
Most of you probably read the readme, but definitely check out his other project language Gluon, interesting blend of haskell and lua https://github.com/gluon-lang/gluon
libuv is mio, not tokio. tokio is sorta similar to a promises-only node, but there are differences. Even though promises/futures are conceptually similar, their implementation differs. One area is cancellation, that proposal is DOA for node, but works just fine with Tokio. Different choices.
Tokio is largely based on Finagle in scala.
https://doc.rust-lang.org/stable/rustdoc/ exists now, and is intended to be full docs for rustdoc.
It's two years old, but https://github.com/Geal/pgo-rust
&gt;&gt; "half of the Nim community are game devs" casual , or AAA console gamedev even if today the requirements aren't as stringent, my requirement for a language is that it could handle anything I've dealt with in the past: the rationale being who knows what new niches may emerge. &gt; type Baz = ptr object (heap but no GC, need to use malloc/free) can it do pointer-arithmetic (I guess if doing manual malloc-free you could still do 'blobs') .. and can it do move-semantics like c++ or Rust
There is [newtype_derive](https://crates.io/crates/newtype_derive) though I haven't used it personally.
Re. gluon (and other VMs in Rust): i've noticed that all these projects represent a language value as enum ([gluon](https://github.com/gluon-lang/gluon/blob/master/vm/src/value.rs#L279)). How one would implement values packed into pointers, NaN-boxing, etc? Matching on enum variants would have to go, right?
That's actually a bad idea because one could write async-incompatible Reader/Writer and accidentally use it in tokio. It's better to have separate traits for guaranteeing correctness.
Honest question. Why not just use rustup's docs?
I'm clearly not understanding something. No, Eigen does not use compiler extensions. But Eigen arrays with sizes known at compile time are stack allocated (until they get too large), and each size of array will be its own type (i.e. you can't add a 2x3 array to a 5x4 array). At least, that's how I've always understood it to work. Dynamic (only known at runtime) arrays will of course be allocated on the heap.
&gt; Dynamic (only known at runtime) arrays will of course be allocated on the heap. Sorry, I mistook your comment to mean that it could stack-allocate dynamic bounds as well. We're on the same page now. :-]
It looks like a compiler bug, briefly discussed [here](https://github.com/rust-lang/rust/issues/43370#issuecomment-321647649)
Thank you!
Tensorflow can be compiled to use either Eigen3 or BLAS as the CPU driver. Choosing the Atlas implementation of the BLAS API can speed things over Eigen3 as Atlas parallelises ops by default. Tensorflow’s GPU implementation is _also_ built on BLAS APIs, using the cuBLAS library which dispatches CUDA instructions to the GPU. Tensorflow is a decent example of what one could build on Rust using a BLAS backend. If they were starting from scratch now Rust would be more attractive to Google than C++. Tensorflow also provides the usual decompositions such as SVD. Plain matrix algebra is insufficient for most tasks. However it lacks important numerical primitives like under/overflow resilient implementations of things like `exp(1+x)`. A popular misconception I see on /r/rust is that SIMD is the main blocker to scientific computing: in point of fact clever algorithms to manage memory bandwidth (such as the tiling algorithm) and overflow and underfloor (eg for exp1a) are much more important to both performance and utility. It’s also worth nothing that Tensorflow does not use compile-time static matrix dimensions: as I mentioned earlier, in the overwhelming majority of cases: — whether doing a matrix factorisation for recommenders; a logistic regression to identify contributory factors in a statistical analysis; or an eigen-decomposition in audio-wave analysis — the data determines the size of the matrices involved. The 4-vector and 4x4 matrix are things that only apply to graphics. Rust has everything C++ had when Google chose it for the Tensorflow implementation. That’s done. However absent a Tensorflow style implementation of its own, it’s hard to justify Rust as a platform for productionising scientific models. 
If you don't mind me asking, why do we need the traits in scope?
That would be a nice feature, but no, there's no way to do that automatically, I'm fairly certain. You just have to check which version `ncollide` is using and then use that version in your toml file.
Why? You could partially unpack the variant data without unpacking the stored value. There is no formal requirement that the variant must be a 1, 2 or 4 bytes long. You can do 3 bits too. However cross compatibility support will take a hit, both FFI and cross-platform.
I've run into problems where different crates have different dependency versions and then things fail to compile. It definitely sucks.
Especially with a trend towards 'modular' libraries, like `piston`, or `futures`, I think there should be a way to make sure that libraries can actually use their common dependencies to interoperate. Doing it manually sucks and it very error prone.
I'm not sure how. Julia has an eval function, reflection, and you can construct types at runtime. Subsets of Julia could be restricted to static typing but I remain skeptical that the full language could be. 
&gt;Now you do the same for the compiler with semicolons, braces, etc. Hence you're doing twice the work,... Actually, no. Rustfmt takes care of _all_ of my formatting for me, I don't waste any brainpower on it. The compiler (because rustfmt plugs into it) is working for me!
Except you can't just replace `dep="1.0"` with `dep="2.0"` and expect the code to work. If they're semver incompatible, they're not interchangeable. This is a bit like wanting to be able to take a library that uses `gtk2` and another that uses `gtk3` and force them to both use either `gtk2` or `gtk3`. It ain't gonna work. The *real* problem, if there is one at all, is people being way too fast and loose with bumping semver major versions, leading to incompatible libraries, for trivial reasons. I lost count of the number of libraries I *could* have used, if the author hadn't gone and `s/try!/?` through the codebase the *nanosecond* that feature was stabilised.
It does at least provide a link to FreeBSD's implemention, and uses similar terminology, which is what prompted my comment.
But you're going to run into a compile-time error if the versions don't match, right? This isn't a silent bug that's going to sneak up on you, AFAIK. And generally, once you've specified your dependencies and things _work_, you don't have to worry about it very often. Whenever you choose to update your dependencies, you check to make sure everything still compiles, run your tests, and you're good to go. It's not like your dependencies are continuously, slowly changing in the background, ready to break at a moment's notice, since you have a `Cargo.lock` file that locks your dependencies precisely. Tools like `cargo-tree` can give you better visibility into your dependency tree to see what versions everyone is using. You say it's "error prone" and it "sucks", but this is not an issue I've ever had. I've certainly heard of people encountering it before, but my opinion is nowhere near as negative.
Which part or parts - isn't the* haskell compiler internally divided into 'systemF' and 'c--' layers (roughly analogous to rust::MIR and llvm ?) (* or one of them)
I have been using gluon as an embedded scripting language. Gluon kind of, “Just works,” so it’s been a very positive experience so far.
I work in Kendall and live out west in the burbs, and I'm not terribly familiar with the Milk St CIC building, but there are definitely various parking garages around. If it were, I'd probably drive to the address and then punch in parking garages into my phone and feel pretty confident that I could find parking.
(Multiple answers, because I don't know how much you know about Dash) The Dash docset contents are exactly the same as the rustup docs, just indexed to be more accessible. Dash is probably one of the most productivity boosting pieces of software I use (Zeal doesn't compare last time I checked). I prefer using Dash over rustup docs in a browser because there is way way less friction when searching for anything, and that effect is even more pronounced when working on a single monitor. Steps for finding the docs for `::std::process::exit` in rustdoc: - Switch to my workspace with browser - (Find and switch to the tab with rustdoc open if it isn't open already) - (Go back to the top of the page) and focus search field - Type "exit" (search is also slower than in Dash) - Find and click on the result I was looking for Steps in Dash: - Global Dash shortcut - (Type "rust:" if I'm not in the docset) - Type "exit" - (Go down a few results, if the top hit wasn't what I was looking for) In the usual case that's 20 vs 2 seconds. That's not only important in raw time, but there is way less risk of content switiching (and getting distracted in the browser). I'm also not exclusively working in Rust, and Dash has docsets for every major language and technology. I've also written a tool (https://github.com/hobofan/rsdocs-dashing) for generating docsets for every crate I extensively use, and I am also pushing for first class support of docs.rs in Dash (https://github.com/onur/docs.rs/issues/145). I hope I was able to answer your question. If there is anything you'd like to know more about, just ask! :) 
To be precise: the actual output is the same, we're just emitting these warnings even on the old renderer. If you run into these warnings and don't know how to deal with them, let us know! The most direct way to see what's going on is to use both renderers and compare the output in a browser - most of the time it's easy enough to see where the issue is from that. If you're totally stumped, post in the tracking issue (it's linked in the post at the top and bottom) and i can take a look.
Right. The official boxes are broken and never ssh. uchida/freebsd is the first box I found that successfully vagrant up’ed reliably. I think the official boxes need some maintenance.
In between, a game studio getting its income from a Facebook game released an in-depth article of his choice of Nim [here](https://yglukhov.github.io/Making-ReelValley-Overview/). Another dev is building a game engine entirely in Nim that can be used in browser, see [zengine](https://github.com/zacharycarter/zengine), furthermore Nim has bindings to many game frameworks: [Unreal Engine 4](https://github.com/pragmagic/nimue4), [Godot Engine](https://github.com/pragmagic/godot-nim), [Urho 3D](https://github.com/3dicc/Urhonimo), [SDL2](https://github.com/nim-lang/sdl2) (maintained by @dom96 who wrote Nim book), [GLM](https://github.com/stavenko/nim-glm), if that doesn't convince you of Nim attractivity for game devs, well come to Nim IRC/Gitter, there is always one up ;). Pointer arithmetics can be done, I use them to make sure memory is aligned in my tensor library (operator is `+%`), see [here](https://github.com/mratsim/Arraymancer/blob/master/src/tensor/fallback/blas_l3_gemm_data_structure.nim#L55) and a gist with all [pointers operators implemented](https://gist.github.com/mratsim/0bf8a8ea45b36f7bf79c43c9a98411a2#file-pointer_arithmetic_arraymancer-nim-L16-L42). Regarding move semantics, the primitives and built-in seq (equivalent of Rust Vec) do not allocate when passed to function or used as return value. For custom objects, Nim has a "result" special variable and you can directly build your return value with it, even using a {.noInit.} pragma to avoid allocating it to a default safe value if you want, I use that extensively in my library. Nonetheless, Nim core devs are aware of the need for move semantics (at least I need it) for certain case where directly building the result value is impractical. Lastly, Nim Garbage Collection by default is deferred reference counting (not stop the world), you can choose no GC, mark-and-sweep (stop the world) or [region-based GC](https://en.wikipedia.org/wiki/Region-based_memory_management) and it's probably quite easy to write your own memory pool.
What is interesting that it doesn't use 3rd libraries (crates) which is really rare nowadays (looking at npm with tons of 1-function packages).
While not a breaking change in the traditional sense, wouldn't the change to how code blocks are detected break backwards compatibility with crates that compile under the current rendered? That is, crates that used to compile successfully on older releases will cease to do so on newer compilers? I imagine companies that pin rust releases for a long period (and skip versions as a result) might miss these warnings and be in for a surprise when they make the next leap. Has this change been tested on crates.io crates? Good job on the informative write up.
What a slave driver ;)
That was pretty convincing, I'll give dash a try :) Thanks!
There's always the chance, but we had actually landed this in nightly originally as just a straight-up breaking change, complete with a crater run. Not many crates, something like 30 were affected. Some of the bigger crates that ran into it have been with us the whole way here, and already made said changes long ago. Additionally, as said in the other comment, this isn't breaking *yet*; this is going from "opt in with a flag" to "warn by default", so even then, there'll be a period of time for things to update.
Java was no go for the start It definitely have strength: scalability potential with Spark, Hadoop, etc but: - I don't like it's full Object Oriented paradigm, on the JVM I probably would use Scala instead. - On a single machine it's slow, heap allocations are never cheap, if it's cheap it's because the JVM detected ahead of time that it could be stack allocated. Memory is the most important resource in Deep Learning because we need to process huge stack of images and I want to be able to manage it manually in critical paths.
Indeed, I stand corrected.
&gt; Mac only :( Yup :/
As mentioned by Steve, this article is already being discussed at https://www.reddit.com/r/rust/comments/76olo3/why_rust_fails_hard_at_scientific_computing/.
Yea, I really can't see a way around this with the current dependency management systems. You would need a tool that had a lot of knowledge about library compatibility, and once you get the types working, correctness is a whole other matter.
&gt; heap allocations are never cheap, if it's cheap it's because the JVM detected ahead of time that it could be stack allocated. Sorry, but that isn't true. (the part about never cheap) For unmanaged languages (C, Rust, C++), heap allocations are expensive because they translate into, at best a skiplist lookup (log n) and at worst communication with the OS to get more pages for the application. This is what makes them expensive. However, JVM languages first start off by overallocating memory, to decrease the amount of OS back and forth. Then, when an allocation is requested, they save off a pointer on the heap and add the amount of memory requested to that pointer. If the pointer grows past the newgen bounds, a minor collection is triggered. If the memory is extra big, it will go to old gen straight away, depending on the GC algorithm that is either a pointer bump or a skiplist lookup. For apps targeting high throughput, it is again another pointer bump. If you give Java a large enough heap, the amount of time GCing will be fairly minimal and the heap allocation speed will be almost non-existent. Java heap allocation is generally nearly as fast as stack allocations. As for slow, depends on what you are doing. But if you are in a memory intense scenario and you are using a lot of things like reference counted memory (RC in rust, shared_ptr in c++) Java will beat the pants off of it with it's GC. Now the bad news, while Java does a pretty good job of memory management (and even keeping related things relatively local to each other). It does have problems with double lookups. To do things really fast in java you end up needing to do tricks like SOA to get around it's memory problem. That will be somewhat solved with value types, but those are a ways off.
&gt; Nim has a "result" special variable and you can directly build your return value with it that does sound quite neat, although I do really like Rust's expression-oriented approach. (I guess Nim would use tricks like that to work with simpler type inference?) &gt; the primitives and built-in seq (equivalent of Rust Vec) do not allocate when passed to function or used as return value Is that like auto-referencing (or auto-coercing to a slice) and RVO or something I guess that does handle a lot of cases. could they copy the old Rust sigil idea :) 
The project's README has a lot of good info, including a section on why there are completely separate implementations for multiple languages rather than just bindings to the Rust version: https://github.com/miscreant/miscreant
Kind of embarrassing, I actually have that book sitting in my bookshelf. I need to arrange some time to read it.
How long is this warning mode expected to be in place before the switch? At least one stable release?
It was mentioned as "Zeal/Dash" above because [Zeal](https://zealdocs.org/) is an open source clone of Dash that runs on Linux and Windows. They use the same docsets, and Zeal doesn't have a macOS port to avoid conflict with the original Dash project (which does much of the work in making the docsets available).
i see so basically JVM languages are just starting a big memory pool.
I'm implementing a scripting language in Rust using NaN boxing. My value type has a method that does the necessary bit manipulation and then returns an unpacked enum that represents the possible values without actually matching the memory layout.
I actually the result value is not forced it's an option, you can also use "return" like in many languages. I think the name is copy elision (which encompasses RVO). What is that sigil idea?
Wait, VSCode can debug Rust? How?
I don't know why you were downvoted for proposing Java, though I don't like it, forgot to talk about the boilerplate, I think it's a perfectly fair question to ask so here is an upvote.
Author. I actually have an experimental crate which [implements nanboxing](https://github.com/Marwes/nanbox) and while you do have to abandon matching on enums directly, the macro defines both a nanboxed type and a normal enum as well as functions to convert between them. So in theory all that needs to change is match enum_value { match enum_value.unpack_nanbox() { Haven't prioritized implementing it in gluon yet though https://github.com/gluon-lang/gluon/issues/303
I recently had an issue where my binary directly depended on a crate, say Foo, and one of my dependencies depended Foo as well. Except the version bounds were different between the two so I ended up with two versions of Foo. The ensuing type errors were madness. In other words, the current state of things is horribly broken in terms of usability. The compiler needs to give a hint that the type errors were happening because of version skew. Cargo needs to warn when it uses multiple versions of the same package. Etc.
:)
Effectively yes, and each GC cycle (most jvm GC algorithms) will compact the memory which is how it is able to just maintain the one pointer at the tail of the allocated memory. The exception is the concurrent Mark and sweep.
Author. Actually, this is mainly a consequence of cargo not existing while I was working on it. gluon, the compiler I work on now uses crates.io quite frequently https://github.com/gluon-lang/gluon/blob/master/Cargo.toml#L24 .
"horribly broken" is far too strong of language for this issue... I do not disagree that it could and should be improved.
I mean, what cargo does "works" but the usability of it is the part that I feel is busted. It's quite surprising when it bites you and the tooling masks the problem instead of bringing it to your attention.
The usability is great 99% of the time, it's _only_ when you encounter this issue that usability goes out the window. The issue is [tracked here](https://github.com/rust-lang/cargo/issues/1636), and it has barely gotten any comments over the years, so I really feel like it doesn't affect people often at all. But, there is [an RFC](https://github.com/rust-lang/rfcs/pull/1977) that was recently affected which is going to try to address this and some other related issues soon, which will be nice.
Yes, most of the time cargo works well. I meant to scope my comments to this exact situation. As for barely getting comments, I ran into this problem saw the issues about it and didn't add my voice because the only thing I would be able to say is "bite me too". Perhaps others don't add comments as well? Also, how many people ran into it and didn't realize what the issue is?
There's a Maching Learning API named gluon: https://github.com/gluon-api/gluon-api/ Is this an issue?
I'm just a user of Rust, but the times that I've gone to the issue tracker about similar bugs, they usually have more comments. This is purely anecdotal evidence; I was just presenting that this issue seems to me to have a lower number of comments than issues that are commonly encountered. I really do hope it will get fixed with that RFC, though;
I'm probably missing something, but why not just make nonce 128-bit and generate it randomly each time? Looks like the simplest solution to me.
I think I'm going to try and do one in about half a year or so, so don't give up all hope yet! 
Here's tptacek's comment from HN: &gt; This library implements a crypto primitive that sacrifices a marginal but measurable amount of performance to avoid a very common user error with crypto primitives --- repeating a nonce (a cryptographic counter). For perspective, this week's KRACK 802.11 bug is an instance of nonce reuse. &gt; The primitive being provided here is an instance of SIV, which is widely considered the most conservative mainstream cipher mode that addresses nonce reuse. SIV is a moral cousin to Deterministic DSA and EdDSA, in that the "nonce" is based on a hash of the message. You can add additional nonce material, and that will improve the security of the system, but even with a constant all-ε stream of additional nonces, for most applications you're fine. &gt; The downsides to AES-SIV are that the mode is "offline" and two-pass. You have to have the whole message available to encrypt with AES-SIV (the state needed for CTR mode comes from processing the whole message). This makes some kinds of streaming interfaces hard to implement. On the other hand, you can almost always delegate that kind of interface up one layer in your application stack and pass AES-SIV chunks of messages. &gt; This library or something like it will eventually hit some kind of "1.0", and, at that point, if you can get away with the performance hit --- and you virtually always can, because bulk encryption isn't a bottleneck in most systems, and on the systems where SIV's performance hit matters you tend not to get much benefits from the "faster" stuff --- you should use this for bulk encryption. (Unfortunately, KRACK is a very good example of a setting that probably couldn't get away with using AES-SIV). As a crypto interface, it's better than NaCL. https://news.ycombinator.com/item?id=15492951
I'm a little unclear on what it is your trying to do. First in your constructor you need to be explicit impl WidgetWithType for StructThatImplements { type AType = AnEnum; fn get(&amp;self) -&gt; Self::AType { // you cant just use Self::AnEnum AnEnum::WithString("Hello World!".to_string()) } } You need to know the concrete type of an enum to pattern match on it. And you need to know the type of an associated type to use it. let strct_ref : &amp;WidgetWithType = &amp;strct as &amp;WidgetWithType; Will error with &gt; missing associated type `AType` value So you need to write. let strct_ref : &amp;WidgetWithType&lt;AType = AnEnum&gt; = &amp;strct as &amp;WidgetWithType&lt;AType = AnEnum&gt;; --- But maybe step back first. What would you expect the line &lt;StructThatImplements as WidgetWithType&gt;::AType::WithString(the_string) does when StructThatImplements has a different associated type for AType ? 
The instructions are slightly different depending on your OS. If you are on windows you can follow the instructions [here](http://www.brycevandyk.com/debug-rust-on-windows-with-visual-studio-code-and-the-msvc-debugger/). On Mac or linux the instructions are similar, you just need to use the gdb/lldb debugger instead.
IPFS isn't quite deterministic - for example, the chunking (which affects the final hash) is determined by the client, rather than being specified. In addition, the routing process to find peers is not particularly verified, making false claims of hosting content a potentially feasible way to drown out working hosts and establish a DoS. Beyond that, IPFS has no capacity for algorithmic agility - if object A in IPFS refers to object B in IPFS, and the digest used is found insecure, one _cannot_ handle this in any other way than mutating the _contents_ of A. This is incredibly _detrimental_ to reproducible builds in the farther future; orthogonal addressing and verification (as in [TUF](https://theupdateframework.github.io/)) avoids the issue. (I, personally, am also working on a couple of ideas for mitigating the algorithm-agility issue for content-addressed networks.)
[For the curious](https://github.com/graydon/rust-prehistory/)
&gt; What is that sigil idea? it was a concise syntax for declaring 'uniquely owned objects' .. ~ ~T=Box&lt;T&gt; ~[T]=Vec&lt;T&gt; ~str =String , @ for 'shared ownership'
That was a lot more political than I was expecting
Oh man, thank you so much. I finally got a chance to try this out and now I can test my particular changes in about 1 minute. You're a life saver. 
Works perfectly in theory. Still a great way to do it. The goal of this isn't to be 'more secure', it's to be 'less susceptible to fuckups'. Given your cousin Steve who wants to start his own backup service and asks you what operating system he should program with, pointing him at this library may be a better choice than teaching him how to do it himself. 
That entire quoted bit of text is just wrong. You don't *need* to use C any time you want create something of significance. I mean, [imagine an entire operating system written in Rust.](https://www.redox-os.org/) The concept of being "back to square one" by using *any* C whatsoever doesn't even make sense anyways. That's a logical fallacy centered around throwing the baby out with the bathwater. The more code that is written in a safe language, the fewer lines of code that are vulnerable to a plethora of coding errors. Maybe that author can clarify about "the mistake".
Perhaps they're referring to the soundness fix in [1.15.1?](https://blog.rust-lang.org/2017/02/09/Rust-1.15.1.html)
1.15.1 is nowhere near the 1.0 release, and those soundness fixes repaired an issue that existed for basically hours. I don't think they're what that comment is referring to.
Probably talking about the [leakpocalypse](https://github.com/rust-lang/rust/issues/24292)? Not that it really has to do with C, (rather the unsafety had to do with unsafe Rust code that made assumptions about destructors).
I'm not saying that generating nonce should be left to the user. Why couldn't library just generate it the way I proposed? It seems that everyone wants to use more complicated methods to avoid repeating nonces, so there must be a good reason which I don't see.
This is a real possibility for what they're referring to, but it really sounds like they're implying that they rely on projects which have never made any mistakes whatsoever... and those don't exist.
Yes, this is what I'm assuming they're talking about.
How do I pass the results of a macro into another macro? I have a macro right hand side that looks something like this: macro1!(macro2!($stuff), macro3!($other)) it fails to compile with the message "no rules expected the token 'macro2'", so it looks like macro1! is being evaluated with "macro2" as its first argument instead of the result of the evaluation of "macro2!($stuff)". How do I fix that?
This is really neat! I have some yet to be released code that heavily utilizes then for compile time guarantees. Pair that with the builder pattern and it can be quite powerful. It's nice to see others use it, especially in an environment that demands those kinds of safety guarantees.
Ah, my bad. Misunderstood. Probably just cause they can. Crypto people like solving challenges.
&gt; Why couldn't library just generate it the way I proposed? I think part of the problem is that it's tricky to get good randomness from the OS in a portable way. You can say "just use `getrandom` on Linux", and that's probably good, but that might not help you when you're trying to get crypto working on some random embedded system. It also means you're introducing an operation that can fail, at least in rare circumstances (like file descriptor exhaustion on Linux versions that don't have `getrandom`). Asking people to handle error in their encrypt function might turn people off?
Indeed, there is a plug in that uses lldb. Has all of the nifty things like stepping in, out, and over as well as seeing the contents of variables in scope. (sorry I can't link right now, I'm on mobile) 
I remember the week when this was first switched on and I fixed my docs so that they worked with the new renderer. Sad to see it reverted again after that. Good it's finally back...
Identifier information is part of the Haskell ABI. 
Is there a way to verify the resource usage of a function? Like a benchmark that returns the amount of memory consumed.
Yeah it's really taken a while, we ran into issue after issue. :/
At least one stable, yeah, though in practice it may be longer because i want the warnings to hit stable first before we switch it on nightly. Also because i want to be more cautious than necessary in switching this over. `&gt;_&gt;`
Nice, I'll be rooting for you!
I had a typo in the playground link. Meant to do `&lt;strct as WidgetWithType&gt;::AType::WithString(the_string)` rather than `&lt;StructThatImplements as WidgetWithType&gt;::AType::WithString(the_string)`. But I would expect an error if `strct` had a different associated type for `AType`. &amp;nbsp; I had expected to be able to use `AType` as an alias for `AnEnum`. &amp;nbsp; I could have sworn that it didn't complain earlier today when I did `Self::AType::WithString("Hello World!".to_string())`. That it refuses to do so now is even more annoying, as the function declares that it returns `Self::AType`, but disallows the use of `AType` when creating the value to be returned. The error message for that (`no associated item named `WithString` found for type 'AnEnum'`) even knows the concrete type. 
You should read/comment on https://github.com/tokio-rs/tokio-rfcs/pull/2
Java 1.4 added nio, which is comparable to mio (low level async IO library). Java 8 added CompletionStage and CompletableFuture, which are an implementation of futures that allows for combinators and multiple backends (threadpools, io libraries, etc). This is built to fulfill a similar purpose as the Rust Future trait. Java 8 also has Streams, which could be compared to the Stream trait in Futures, in the sense that it is pull-based. As far as a "tokio" to tie them together, there are lots of different libraries, but nothing great. Java tends to be be fairly thread heavy.
The target instruction set is a bytecode for which a VM interpreter s included
&gt; I have some yet to be released code that heavily utilizes then for compile time guarantees https://docs.rs/vulkano/0.7.2/vulkano/pipeline/struct.GraphicsPipelineBuilder.html
Cool project, but the name is unfortunate.
It was already mentioned in another comment. Made a mistake 😌
I would change the name, considering the fact that ML is the language from which Rust derives much of it's syntax.
Also an ideology
I may be out of the loop but,... why not just follow CommonMark?
A software development ideology?
Not exactly.
Then why does it matter?
Because it's also an unfortunate name collision.
I think these are related directly to "morphisms" (from Category Theory) where you can take one type and morph (transform) it to another type. Not every type can be trans formed to every other type and, in a language like Rust, you'd probably have to define each morphism as you go. But that's pretty much how statically typed languages work - you start with a data structure with some set of behaviors and you decide later in the execution of a program that you need to transform that data to something else, which has its own set of behaviors. At some point I need to go back and learn more about Category Theory because damn, this is extremely applicable.
You're talking about open source software. You're going to find a lot of people with ideas like that. Best to leave the politics in other forums.
I added [Shio](https://github.com/mehcode/shio-rs) server support to [ReverseGeocoder](https://github.com/llambda/rust-reverse-geocoder), and compared with the existing Iron and Hyper web server support. Interesting to see async Shio apparently providing performance benefits here for something that is ostensibly CPU bound (reverse geocoding).
That’s exactly what the move is to.
Even in languages that support static arrays you'll have this problem with dynamic arrays. Though I guess in Rust a multidimensional dynamic array will be a library type anyways so it could enforce such things...
We pretty much get CVEs all the time for C based code so one time isn't even that bad for Rust. Even the 2 security disclosures of crates.io were implementation error, not memory errors. I don't know what this guy was talking about. I don't recall anything happening during 1.0 when I started using it
That one came afterwards. 
I don't disagree that once you're involved in async, you should be considerate of the event loop, but I *strongly* disagree with the notion that all client code should consider what event loop to use. My preference is that the future version of Tokio have a way for you to say, "Ok, did I get an event loop? No? Ok, please let me use the named event loop blah.blah.blah". Then, if someone in a controlling application somewhere wants to override an event loop choice, they can specify the event loop at a named level. This would be identical to the way that structured logging is setup. No one has a problem with structured logging having spooky action at a distance, but that's because everyone realizes that it's not feasible to pass a logger around explicitly.
&gt; I would change the name... &gt; ...the name is unfortunate. &gt; (downvotes &gt; 0) Feedback about the project or uses of it would be cool. I didn't name the project, I only found it. If you want the author to change its name or perhaps have another to offer, he has an issue queue for it. I had to give it some id for this post..
Not really. As a rule of thumb, put whatever version of nalgebra has in its Cargo.toml into your Cargo.toml, then run `cargo update`. You'll end up with something like: [dependencies] ncollide = "0.12" nalgebra = "0.12" // if ncollide's Cargo.toml depends on nalgebra 0.12 That'll work. If then you want to upgrade ncollide to another backwards incompatible version, e g 0.13, you need to look up what those backwards incompatible changes are, and (if necessary) adjust your code accordingly. When that work is done, you can re-check what version of nalgebra that new ncollide uses and adjust your Cargo.toml again. 
&gt; The one exception is crates that use a global resource, like rayon, where your code will run less efficiently because there will be two workers per core on your machine, instead of one. That's the worst-case scenario I've seen. A worse one is when two of your dependencies end up with different versions of the `log` crate. Everything compiles, but half of the messages just won't be logged, because `env_logger` (or whatever front end crate you're using) will only initialize one of the log crates. :-( This has happened to me, but it was a long time ago. Looking at it now, `log` has been at `0.3` for two years so hopefully everyone has `log = 0.3` in their `Cargo.toml` by now. 
So, currently macros are evaluated from the outside in. AFAIK there is no solid way around this.
It's all good - I think the assumption is that if you don't say so otherwise in comments, you're the author of whatever is being posted.
Hm, you could probably mark each variant with `#[doc(hidden)]`, but that'd be a ton of code for 64 variants. Personally I would make a wrapper `pub struct Square(SquarePosition);` with the useful methods, and then just have SquarePosition be a private enum. Then maybe allow creation via File &amp; Rank for when the variant would need to be specified?
I've always loved session types though, I didn't know that was their name. In a similar vein there is a good series tutorials detailing running Rust on the Teensy microcontroller dev board that used session types in a similar manner to what was done here. [link](https://branan.github.io/teensy/) Part 2 is where the session types come into play.
Thank you. That pattern of "link + op comment" slipped my mind but definitely would have made the most sense for clarity. One other thing I would have mentioned since it's not totally clear from the project page, is a link to [adjivas/ml's own diagram](https://adjivas.github.io/ml/mml/ml.svg). Next time.
Why is this in /r/rust?
This is so awesome man! Keep it up!!
TiKV and TiDB use a lot of Rust
/r/playrust
OH! Thank you, that makes much more sense. 
I'm curious how Cap'n Proto performed in the benchmark. I like it very much because it's random readable and the schema is somewhat flexible.
I concentrated more on the asynchronous "building blocks" but I think your examples are good expansions. Just not something you really understand without learning about Future &amp; Co. first.
You were right . It's [this issue](https://github.com/rust-lang/rust/issues/26264). --- So rereading your question im assuming your frustrated that in your real code the path to Self::AType is much shorter than the full path to the enum in use. So i suggest going with an import at some level. For example , you can go all the way down to the enum scope and this will work: use AnEnum::*; if let WithString(the_string) = get_val { println!("{}", the_string); } 
&gt; Tensorflow’s GPU implementation is also built on BLAS APIs, using the cuBLAS library which dispatches CUDA instructions to the GPU. Tensorflow's GPU implementation can also be compiled to use either Eigen3 or cuBLAS, and in fact, Eigen3 is the _preferred_ way to write user operations and custom kernels for both GPUs and CPUs. &gt; If they were starting from scratch now Rust would be more attractive to Google than C++. Except for the extreme awkwardness of writing custom kernels in Rust that also work on the GPU. It can be done, but it doesn't work out of the box, and it is extremely unergonomic. In C++ i can just use a lambda function as a kernel, I can use a `std::vector` with host or device allocators and the std algorithms on top of that (e.g. via `thrust`), etc. Rust is far from offering support to writing libraries that would allow you to do that. &gt; Tensorflow also provides the usual decompositions such as SVD. These decompositions are just... [wrappers over Eigen3](https://github.com/tensorflow/tensorflow/blob/6b1d4fd8090d44d20fdadabf06f1a9b178c3d80c/tensorflow/core/kernels/svd_op_impl.h)... 
I see, so that would be more like `Vec&lt;Vec&lt;T&gt;&gt;` in Rust I guess. I guess that makes sense for C# since everything is garbage collected anyways.
It works on your 24/7 Webserver. But imagine an IoT sensor waking up from deep sleep, measures the temperature and sends it to a server, goes back to deep sleep. There is no real source of entropy, maybe not even a RTC. So its not that easy to get true random numbers. (Of course using the hash of the temperature as a nonce is not secure either.)
Maybe segmented stacks, which are difficult to integrate with C callbacks? I don't know the details.
Thread local storage.
Thanks for info!
Sorry for late reply. The other guys described exactly those things that I've read in the other HFT posts.
I remember chasing memory-safety bugs in the C++ code I was working on when rust shipped 1.0; does that count?
Is there a way to have `Box&lt;Error&gt;` as associated type? This code gives compilation error `the trait bound `std::error::Error + 'static: std::marker::Sized` is not satisfied`, but I cannot specify that the boxed error is Sized since only Send/Sync can be used as additional traits trait T { type E: std::error::Error; } struct A; impl T for A { type E = Box&lt;std::error::Error&gt;; } fn main() {}
And it removes a C dependency (that's an important point too!). :)
&gt; For unmanaged languages (C, Rust, C++), heap allocations are expensive because they translate into, at best a skiplist lookup (log n) I've never heard of an allocator using a skip list. The fast path of modern allocators tends to be: - translate requested size into one of a number of size classes (for very small allocations there's a new size class every 8 or 16 bytes; after a while the spacing increases) - access the cache for that size (in thread-local storage) - the cache is a linked list of free allocations; pop the first entry if present, otherwise fall back to a slower path (which may take locks, ask the OS for more memory, etc.) This is definitely O(1), but the constant factor tends to be relatively large - largely, I think, because of legacy design issues with the malloc interface rather than anything inherent to non-GC allocation. (Not that that makes them any less problematic.)
Here is the link for the TiDB best practice: https://pingcap.github.io/blog/2017/07/24/tidbbestpractice/
But... why **are** you using an enum? Are you planning to have gigantic `match`es everywhere that address each square individually?
So, if you disregarded memory management haskell would have been appropriate for your field? 
I'm rewriting the [nanovg](https://github.com/KevinKelley/nanovg-rs) bindings. The crate currently targets a very outdated nanovg version, which I upgraded (trivial). Now I'm in the middle of implementing are new, more rust-like Api on top of the ffi (a bit more work, but still mostly trivial). After it's done, I'll use nanovg for my [chorus_studio](https://github.com/Lisoph/chorus_studio) project instead of my own crappy renderer, together with a layout engine based on the new CSS grid system (have yet to implement this).
&gt; I know I can define the type as `Square(u8)` instead but I would much rather keep it as an enum. My I ask why you want to keep it an enum?
You have to specifically mark T::E as `?Sized`
Doesn't work. The Sized requirement is because of the Error trait implementation for boxed errors. I actually think that this impl&lt;T: Error&gt; Error for Box&lt;T&gt; In std should be impl&lt;T: Error + ?Sized&gt; Error for Box&lt;T&gt; Shouldn't it?
Ah, it's deeper than I thought. Good catch
&gt; I remember chasing memory-safety bugs in the C++ code I was working on when rust shipped 1.0; does that count? Oh, wow! You're the Rust original creator :D Unless, that was a joke - I thought Rust was written in OCaml, with some glue code in C/Assembly. 
Well, arrays in C# are not resizable, so I think a closer equivalent would be a `[Option&lt;Box&lt;[T]&gt;&gt;; N]`. Option because of the nullable thing. It's basically a result of having an array of arrays, but the length of the array not being part of the type like it is in Rust.
I"m not affiliated with the author or publishers in any way, I just thought others might also like this. I was waiting to buy this book, and thought I'd share. 
Does "MySQL compatible" imply that TiDB follows all the weirdness and data-unsafety of MySQL, like allowing NULLs to be inserted into NOT NULL columns and the like?
More like `Option&lt;Box&lt;[Option&lt;Box&lt;[T]&gt;&gt;]&gt;&gt;` then, no?
True enough, but the type was already a bit of a mess, and that just makes it worse.
Yea, though ~~I would argue that C#'s type system is the _real_ mess~~ `Option`'s presence is probably undesirable in most scenarios, so at least that much can be removed.
what do you need your crypto library to do?
When I saw "Rust" and "50% off" in the title, I was getting ready to refer the OP to /r/playrust, and here it turns out that this is in the correct subreddit after all :p
&gt; Publication in Early 2019 Is that a typo or is it really planned for 2019?
I might be interested in buying this book, depending on what it contains and how good it is. Assuming I already write plenty of Rust code, what might I learn from this book? Has anybody read it yet?
No, I plan to have tables with 64 elements that can be addressed safely using this type rather than use `get_unchecked`
Selfless plug: https://github.com/RustCrypto It's not a library per-se, but ecosystem of crates with a lot of code derived from rust-crypto, but with substantial reworks. Currently it can't cover all needs, but in future I hope it will. (warning: RustCrypto crates have not yet received any formal cryptographic and security reviews)
If you don't actually need to do processing on the macro results, you can just keep `macro2!($stuff)` as an expression until the end. This is what happens with `println!("{}", some_macro!())` for example. If you do need to expand the output of `macro2` and `macro3`, then you basically need to use [continuation passing style](https://en.wikipedia.org/wiki/Continuation-passing_style) to solve the issue /u/yodal_ brought up. So you'd modify `macro2` and `macro3` to be invoked something like `macro2!($stuff, -&gt; macro3($other -&gt; macro1))` or similar. It's definitely not ideal but it also happens to be the only way to do it.
&gt; (downvotes &gt; 0) Reddit fuzzes votes, you can't guarantee that that number is accurate in any way.
Lapack provides SVD. This is why I've referred to the Lapack/BLAS API in my original comment. [Intel MKL](https://software.intel.com/en-us/mkl) provides BLAS/Lapack support, so does the [AMD AMCL](http://developer.amd.com/tools-and-sdks/archive/acml-downloads-resources/), the [ARM APL](https://developer.arm.com/products/software-development-tools/hpc/arm-performance-libraries). While Eigen3's matrix type can support compile-time dimensions, as the [Eigen SVD documentation illustrates](https://eigen.tuxfamily.org/dox/classEigen_1_1JacobiSVD.html), it's more common to use the dynamically sized `MatrixXf` instead. Tensorflow uses MatrixXf. It doesn't need type-level constants. There is some very limited support for using Eigen3 in CUDA kernels. There is no CUDA backend for implementing the full suite of Eigen3 operations. Unlike Tensorflow, Eigen3 does not have complete GPU support. To return to my original point: without type-level consts, but with matrix algebra, SVD, and a solver (e.g. based on QR decomposition), I could whiten a dataset, centre it, and do a linear regression. With type-level consts, but without SVD or QR, I couldn't actually do any of that. It is not the absence of type-level consts and stack-allocation that preclude scientific computing. Numpy on Python, ND4J on Java/Scala, Tensorflow on C++, GSL on C, Math.NET numerics on C#/F# and R provide full support for scientific analysis, without type-level constants, and all have had wide success in industry. To conclude, it's important to note that Eigen provides _two_ things: an idiomatic front-end, and a high-performance backend. Tensorflow equally provides an idiomatic front-end, but delegates the backend to Eigen3, or CUDA/cuBLAS with native assist. Hence to facilitate scientific computing on Rust, the easiest way is just to write an idiomatic _Rust_ frontend, on a pre-existing backend. The BLAS/Lapack standard provides the widest variety of backends, on all the CPU architectures Rust targets. Why didn't Google choose Rust? In early 2015, when Tensorflow development started, Rust language was perceived as unstable (1.0 was released May 2015) and had limited tooling. Nowadays Rust has _everything_ necessary_ to build an idiomatic BLAS/Lapack wrapper like Tensorflow, ND4J or Numpy. This in turn would enable scientific application development. 
Just FYI, I have opened an issue about this for cargo: https://github.com/rust-lang/cargo/issues/4641 I had this problem, too and no, to this date there is no solution as far as I know.
I am not fond of the idea of seeing random ads in this subreddit. Time limited discount sales aren't some great benefit, they are a buisness practice designed to exploit loss aversion weaknesses in the human psyche. I'm fine with people linking books as a resource, but can we skip the scummy marketing posts?
In hindsight, putting a relative amount of time in a Reddit post title is a bad idea.
I agree in general, but I wouldn't call a well-intentioned post by someone who isn't affiliated with the authors or publishers "scummy"...
In Java, I actually strongly prefer IOC:ing my loggers because that permits testing them easily while running the tests in parallel. I don't think your comparison is apt. You usually associate loggers with instances, so there's not much passing around going on. Loggers are also typically global, while the current task in futures-rs is thread-local.
I'm surprised RustBeltRust isn't on the list of events.
[OT] I've submitted a link to HN, you can find it in https://news.ycombinator.com/newest with the headline : "TiDB – a global scale distributed DB – Reaches 1.0" upvote it if you can. This should get more press. 
Looks really cool. Do you have this online somewhere yet?
Makes sense. I think in Rust using a `Vec&lt;Vec&lt;T&gt;&gt;` would be a more idiomatic way of doing this kind of thing. I mean, if you don't care about a flat memory layout for all elements, then the overhead of `Vec&lt;Vec&lt;T&gt;&gt;` over `[Option&lt;Box&lt;[T]&gt;&gt;; N]` is negligible. I think I am going to implement a flat jagged array type in Rust for fun.
Looks like you get to read the various chapters as they are written. Kinda like an early access for books.
Sorry, I didn't mean to imply anything about the person who shared it. It's was intended as a judgment of the linked post itself, rather then the reddit post, but I failed to make that clear.
I really hope TiDB manages to gain popularity and customers. The big competitor (with a bit of a headstart) is CockroachDB, which supports Postgres instead of MySQL. Anyone here played around with either of those?
Making my way through exercism.io exercises (I HIGHLY recommend it). After I'm going to convert one of my NodeJS projects to use Rust instead. The goal is to use less memory - speed is not a concern. As someone who rarely uses typed languages, Rust has been very easy to learn quickly.
The 'classic' way is to use [massif](http://valgrind.org/docs/manual/ms-manual.html), or some other profiler.
The task is local, but the event loop is not.
I can understand this sentiment, but at the same time, people writing and buying Rust books is very good for Rust. If this was a weekly thing, yea that'd be bad, but every few months or so? Not a bad thing IMO. (NB: I don't make any money off of the book I'm writing that you can buy)
This is not a representative or scientific benchmark, and is not a value judgment regarding simple-server, but here is a quick benchmark of simple-server's `server` example vs. the same thing in Hyper 0.11 (release builds with Rust 1.20 on a small CentOS 7 box): simple-server Running 10s test @ http://localhost:7878 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 9.93ms 38.38ms 905.82ms 98.31% Req/Sec 3.16k 3.96k 18.95k 87.78% Latency Distribution 50% 4.58ms 75% 8.80ms 90% 14.39ms 99% 119.74ms 28329 requests in 10.08s, 829.95KB read Socket errors: connect 128, read 28329, write 0, timeout 0 Requests/sec: 2809.44 Transfer/sec: 82.31KB hyper Running 10s test @ http://localhost:7878 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 676.33us 2.26ms 79.55ms 97.76% Req/Sec 96.67k 17.64k 177.40k 90.00% Latency Distribution 50% 470.00us 75% 628.00us 90% 781.00us 99% 7.01ms 1924820 requests in 10.02s, 234.96MB read Requests/sec: 192114.50 Transfer/sec: 23.45MB
Sounds like a very cumbersome way to do it - and it does not really add much safety - certainly not if you consider how much more complex it is. There are four ways to get a `Square`, be it an enum or `Square(u8)`: * Use a literal - `Square::A1` or `Square(0)` * Deserialize - `Square::from_str("A1")` * Get it from somewhere that already has one - `piece.move_to(move.target_square);` * Functions that return a new square based on another square and/or some other arguments - `square.north()`(or `square.neighbor(Direction::NORTH)`) Literals should not be a safety issue - just use `Square(u8)` instead of `Square(pub u8)`, and the risky literals won't be usable outside the module. If you need them for the pieces' starting positions just use associated consts: impl Square { const A1: Square = Square(0); const A2: Square = Square(1); const A3: Square = Square(2); // ... } Deserialization is not guaranteed either way - even if you have an enum your source may be an illegal value. Copying/cloning another square is always safe - if the source square was illegal that's not a problem of the cloning operation. This leaves us with functions that return a square. Whether they should return a `Square` or a `Result&lt;Square&gt;` should depend not on the internal structure of `Square` but on the logic of the function. `square.north()` should return a `Result`, because there may be no north. This is true whether or not `Square` is enum. `square.opposite()` can return a `Square` because every square have an opposite. This, too, does not depend on the internal representation - `Square(100).opposite()` may be illegal but that's only because `Square(100)` is illegal. So, interface-wise - an enum has no advantage over a struct with private fields. Well, it does have one advantage - you can do an exhaustive `match` on all the fields - but since you do not want to do these anyways(to easy to make copy-paste errors in these giant `match` tables) it's not a problem. What about the implementation? Surely we want safety when implementing that module to? Well, we do, but... how will you implement them? * Use giant `match`es? We already agreed these are bad... * Use macros to generate the code for these `match`es? I'd argue the considerably greater complexity of the macro implementation will make your code more error-prune, which is much worser than using `u8` and `panic!`ing when the input is illegal. * Use `uncon` - which is what you chose to do. How is it safer than using `u8`?
I hope to open source the benchmarks at some point in the future. IMHO, performance comparison of competing technologies is a worthy topic in and of itself.
That's unfortunate. Luckily I was able to re-write the macro to use matching to avoid using the results of other macro invocations.
I just used the ‘[openssl](https://crates.io/crates/openssl)’ bindings crate as that gave me exactly what i needed 
I'm working on it. Parts of the code are pretty rough, but I spent the better part of the morning getting rid of dozens of warnings and cleaning out / commenting code. I want to do some more of this and also maybe write some high level thoughts on my current challenges and then post it up on GitHub. I don't want to let the perfect be the enemy of the good here, so if I find its taking too long I'll likely just bite the bullet and throw it up there. 
Thank you! Its great fun. 
I think it probably was a joke. But also, I don't think Graydon was working much on the rust codebase when 1.0 happened.
If you want to keep the safety guaranteed with the enum while reducing the variants, how about making a `File` and `Rank` enum, like so: ``` enum File { A, B, C, D, E, F, G, H } enum Rank { _1, _2, _3, _4, _5, _6, _7, _8 } struct Square(File, Rank); ``` This would bring you down to two enums of eight variants each, which sounds much more manageable. 
I believe that a full implementation is underway
If you want to get a job I imagine you'd be much better off learning Java or C#. There aren't that many Rust jobs available. I'm not sure where you are from, but there are statistics available of the most used languages in various countries. To maximize employability, that may be worth looking into.
No.
Congrats, PingCAP!
/r/playrust
Maybe file issues for the things you need with ring? I've thought it was intended to be as general as possible.
Would love to hear any feedback y'all can offer! - [Episode 0 - Blockchains From Scratch](https://medium.com/mimir-blockchain/the-birds-the-bees-and-the-merkle-trees-ep-0-blockchains-from-scratch-3cedb1e669eb) - [Episode 1 - Hashing Things Out](https://medium.com/mimir-blockchain/the-birds-the-bees-and-the-merkle-trees-ep-1-hashing-things-out-10d41ab839ac) 
Rust doesn't have great resources for people who are new to programming. Rust takes time to learn. There aren't many Rust jobs. This means that, sadly, the answer to your question is "no", IMHO. That said... &gt; I have been learning programming basics, on and off for about an year now, with python and js. You're not that new to programming! The first steps are the hardest ones. Don't be too hard on yourself :)
Can you link to it? I only see stale attempts and libp2p pieces mentioned [here](https://github.com/ipfs/ipfs/issues/5). There is a C impl I am aware of [here](https://github.com/Agorise/c-ipfs) but among other things, they're hardcoded to posix only IIRC.
Ah. Yeah ok. The two topics are closely related and I misunderstood you.
Feel free to submit a PR!
Nah, it's much more dramatic to read the title and "submitted 3 hours ago" and come to the realization that you've missed the meetup. :/
Yup! I based that design on the same post about Rust state machines that was referenced in this article.
No, it means that it uses the MySQL wire protocol, and you can use a MySQL client for any language to access it rather than having to write a new client. Similarly, CockroachDB uses PG's wire protocol
The famous Merkel^1 Trees by the German Chancellor! ^^^1: ^^^Merkle
Haskell memory management doesn't prevent you from using it for Deep Learning as proven by [Grenade](https://github.com/HuwCampbell/grenade), [HLearn](https://github.com/mikeizbicki/HLearn) and [neural](https://github.com/brunjlar/neural) and bindings for [Google Tensorflow](https://github.com/tensorflow/haskell) and [Caffe and Facebook's Torch](https://github.com/ajtulloch/dnngraph). HLearn even showed that Haskell allowed it to exploit the algebraic nature of [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) to be more than [400x faster than Weka](https://izbicki.me/blog/hlearn-cross-validates-400x-faster-than-weka) (which is one of the slowest framework to be honest but oh well). Cross-validation is partitioning your data into for example 10 sets, you train your model on 9 sets, and verify that it generalizes on the 10th, and rince &amp; repeat with all sets being part of the validation test. I still wouldn't use Haskell because it's unfamiliar to most data scientists, they are using Python or R, Julia is seen as a curiosity and [is broken since more than a year on Kaggle.](https://www.kaggle.com/product-feedback/25044). Also interfacing with Cuda is possible but I will probably struggle to use C++ features like C++ generics/Haskell parametric polymorphism or C++ ill-named functors (function-object) It would be fun but probably impossible to develop an efficient go bot in Haskell, you need 2000~10000 Monte-Carlo simulations of 300 game boards (1 per move) per second in a graph like structure. Immutability would make
While there aren't literal textbooks for [college classes](https://cis198-2016s.github.io/) out yet (*cough* [Rust Programming Language](https://doc.rust-lang.org/book/) *cough* looks at you *cough*), you shouldn't be so hard on the language you are working on, haha. I would say that there are lots of sources out there for anyone willing to learn and the evidence is there to prove it based on how much community involvement there is for such a new language. I think Rust's problem is just a general learning curve. It's strict on its users for good reasons and that can honestly suck. Sure, maybe 3-5 years from now, we'll benefit from some additional pedagogical insights we don't have now, but I do think Rust is a language doomed to be **slightly** harder because it has **warranted** check mechanisms built into it in order to achieve our beloved trifecta.
I started learning Rust as my first language, aside from some attempts in learning Python, Ruby &amp; Javascript, but I got gave up again &amp; again. Then I stumbled upon Rust, and found myself really interested in the language. I actually took a course on understanding the "lower levels" of Javascript at the time and realized I wanted to really learn how stuff works under the hood. I wouldn't get caught up in the language as much as learning programming. You can learn a new language pretty quickly once you're pretty familiar with programming. For example, you can pick up C# pretty fast after understanding Rust (imo), but then things might get complicated once you start messing with Rx. If I were you, I'd try to figure out the following: 1. What programming language is appealing. 2. What do you want to learn. 3. Do the above. If you have friends or people you know that are learning a language that might be a good benefit vs learning on your own, and so on. Also, motivation for me at least, did not come easy. Routine &amp; discipline is what creates motivation. I don't think you will find that many Rust jobs just yet. I've bet all my money on Rust because I believe it's the best language on the market at the moment, but it'll take time for Rust to grow to even become close to what C# is in the software development world; at least from a developers perspective. However, if the language isn't important, I'd stick with Rust and just keep on learning! You can always learn a new language &amp; or framework. The difficult parts are learning to program.
&gt;they're hardcoded to posix only IIRC Good.
I think you should definitely continue to pursue Rust as an intellectual/fun hobby because it is indeed a great language with amazing features as you have hinted at. For a job in the market as of today, you should not depend on it nor focus on it as a marketable skill. If you keep working on it as a hobby, I'm sure you will be able to sell yourself as a rust engineer at the plethora of rust-lang jobs that we'll see in a few years :)
My mistake. Looking over jemallocs docs, it looks as if allocation follows pretty much exactly what you said (find the arena for smallish memory allocations, pop the next available, request more if none is available). The only time it would degrade into log n lookups is if the allocation size was larger than the current arena's memory chunk sizes. Then it hits a red/black tree to find a suitable option. Some of the JVM collectors will beat it for large allocations (Definitely parallel, maybe G1GC, not Concurrent mark and sweep). For small allocations, though, it probably will be close to a tie.
ahaha, oops. Good catch.
Wow, that's quite the praise indeed.
&gt; you shouldn't be so hard on the language you are working on, haha. I hear you, but at the same time, I have professionally taught people new to programming for a few years. They need very different resources than people who have programmed at all. We don't have those kinds of docs yet. The book doesn't have the right kind of material. I think Rust *could* be a great language to learn from, but you need those materials.
I think we can infer that he was talking about _other_ C++ code. Not related to Rust at all.
&gt; `fn verify(password: &amp;str, challenge: &amp;str, response: &amp;Hash) -&gt; bool` I would suggest to use Result&lt;(), VerificationError&gt; instead of the simple `bool`, this way if user forgets to check verification result he'll get warning from compiler, plus in my opinion it will be a nicer API in the context of a bigger application. Also it's better to notify readers that in practice it's better to use specialized password-hashing functions, like: [pbkdf2](https://github.com/RustCrypto/password-hashing), [argon2](https://crates.io/crates/rust-argon2) or [scrypt](https://crates.io/crates/rust-scrypt). Isn't it better to teach users how to use crates directly instead of using wrapper in the form of `eth-crypto`? P.S.: Shameless plug: take a look at [sha3](https://crates.io/crates/sha3) crate too. ;)
I had completely missed [The Case for Writing a Kernel in Rust](https://www.cs.virginia.edu/~bjc8c/papers/levy17rustkernel.pdf)!
I added it.
Thanks for the feedback! I agree about `Result` being a more appropriate return-type. I actually initially began with `Result` as the return, but changed it. I'm trying not to assume any pre-existing knowledge of Rust for this series, and I didn't want to get into enums and generics on the first exercise if I could avoid it. My reasoning was the same for using the `eth-crypto` crate; I wanted to reduce boilerplate and front-loaded complexity. Basically all the crate does is simplify the APIs and add a bunch of trait implementations to make printing and conversion nicer for concise and clear examples. You're absolutely right about the specialized password-hashing functions. I will look into adding a note about the importance of using the right algo for the job. Nice work on the `sha3` crate, I'll definitely play with that.
From a job perspective, C# and Java are the way to go. From both languages, C# is more modern. .Net Core which C# depends on, is also platform independent.
This is nice, thank you for creating this. :-)
We bootstrapped off Ocaml in early 2011 (~4 years after starting). Mid 2013 I left the project. 1.0 was in early 2015. By 1.0 I was working on a different C++ codebase, back fighting memory errors. I've been working on C++ codebases ever since, and they're just as memory-unsafe as they ever were. I was making a joke, perhaps a bitter one, at the degree of armchair quarterbacking in the original reference to some apocryphal Rust Mistake involving Talking To C and being Sent Back To Square One. Like .. Rust was built to interface with C at _every level_ and all the current and former Rust devs -- myself included -- have to regularly write C/C++ code. That's life. If you're writing systems-y programs on a computer in 2017 and think you've somehow avoided interfacing with C code, you're either in a very peculiar niche -- safety-critical SCADE or Ada or something? -- or imagining things. That fact has absolutely nothing to do with the viability of writing safer layers on top (or piecewise-rewriting lower levels with safer, compatible replacements).
I'm juggling between convenience of type usage versus convenience of documentation readability. Associated constants for each square leaves me back to where I was initially. If anything, they waste even more vertical space due to how they're currently rendered. If multiple specific squares need to be used, it results in many `Square::new(File::*, Rank::*)` calls, which isn't too great. Regarding table addressing, what I meant was something like `TABLE[sq as usize]` where the table is `[T; 64]`. LLVM doesn't emit a bounds check this way. Otherwise, with a struct, I'd need to use `get_unchecked`. While I am avoiding giant matches, I do plan on matching against a small number of squares here and there. `Square` being an enum makes this easier. I think I'm going to hide the variants and mention them in the docs.
Sorry, but I can't take this seriously. Five (!) spelling mistakes in the opening abstract before even reaching the "Introduction" headline without counting the misspelled "Merkle"... When you start a series of blogs please at least use a spell checker if you aren't confident enough in your own ability to write correct English. This just throws the reader straight off.
I did not look too much into the parser itself, but I have some remarks about your op-char-to-closure functions: 1. There is no need to pass `op` by reference. It's a `char` - a primitive type that's both cheap and safe to just copy. 2. That long `if`...`else if`... chain is a perfect candidate for `match`. 3. No need to box the result - operators don't need context, so they don't need to be closures. You can use regular functions. 4. Everything that's not `+`, `-`, `*`, `/` or `%` is considered a power? Yes, you first check that your op is one of `+-*/%^`, but that still doesn't feel right - certainly not for a util function that needs it's input validated by the caller... I'd prefer to also check for `^`, and `panic!` if it doesn't match anything. Or even better - return a `Result` and let the caller decide what to do in case of illegal operator. So, this is how I would have written it: https://play.rust-lang.org/?gist=0d58237323aa707780920379e03d6826&amp;version=stable
Could use a macro like this: macro_rules! doc_hidden { { $(#[$m:meta])* pub enum $t:ident { $($v:ident),+ $(,)* } } =&gt; { $(#[$m])* pub enum $t { $(#[doc(hidden)] $v),+ } } } This avoids having to write `#[doc(hidden)]` for each variant.
It allows for safely indexing into tables of 64 elements without emitting a bounds check in release mode. Also, `Square::C7` is much nicer to write than `Square::new(File::C, Rank::Seven)`.
To add onto what /u/somebodddy said, I would remove the `ERR` and `EOF` variants from `Token` and instead have `parse` return `Result&lt;Option&lt;Token&gt;, ParseError&gt;` where the `Ok(None)` would be `EOF` and `ParseError` would be `ERR`.
&gt; There is no need to pass op by reference. It's a char - a primitive type that's both cheap and safe to just copy. To add to this, `char` is always 32 bits, this means that on a 64-bit system, the `usize` that `&amp;char` is is actually larger than `char`, so it's both larger *and* causes you to follow the pointer.
So, I'm coming from a C and Fortran background in HPC, and I've just recently started working on a new hpc code in C, and I thought while this code was still pretty early on in development why not make a rust version of it to learn rust. In my C code, I'm using MPI and OpenMP to parallelize my code across several computing nodes. I'm just curious what might be equivalent libraries might be in Rust. Based on what I've seen, it looks like Rayon might be able to take the place of OpenMP, but I haven't seen any examples where it can also work across compute nodes. I also came across the Timely-Dataflow library, and it kinda looks like it might allow me to send necessary data across nodes similar to MPI. However, I'm still really new to Rust, so I have no idea if the combination of the two might work or if there might be a better way to do this in Rust.
To be fair, these are probably going to be optimized away...
yeah that's also true...
You already know ECMAScript and Python. Add Java and you have the three languages most widely deployed in an enterprise setting. (As a source, I've been working in steady employment with those languages for the last 16 years)
&gt; Regarding table addressing, what I meant was something like TABLE[sq as usize] where the table is [T; 64]. LLVM doesn't emit a bounds check this way. The `Index` operation (`a[i]`) is overloadable. You can create tables that are indexable by `Square` instead of by `usize` and if you use the `slice::get_unchecked` method to implement `Index&lt;Square&gt; for Table` then you won't have the runtime cost of bounds checking either. The only downside of this approach I see is that it requires a smidge of `unsafe`. I disapprove of a strict "no unsafe" design rule when it hurts code clarity, and that seems to be the case here. 
Ah thanks. That's actually a lot better than what I had mind.
Thanks.
I think I might have just asked this in the wrong place. I'll ask it again here. How do I get this to work? let mut v = Some(Arc::new(vec![1])); if let Some(ref mut q) = v { q.push(2); } I get "cannot borrow as mutable" referring to q inside the "if let".
Actually I have been meaning to learn Java for quite sometime now for native android dev. I will head to the sub for resources. Thanks.
`Arc&lt;T&gt;` allows you to have shared ownership of a value, but does not allow for mutation by default. You need to wrap your type `T` with some thread safe type like a `Mutex`. You can change your example to: https://play.rust-lang.org/?gist=65bdf15a45e47e4403c0a4b480a74e22&amp;version=stable
haha nevermind. 1.21 fixed it
It's got nothing to do with `match` or `if let`. You can't mutate something that's shared. `Arc` is a shared pointer type. Thus, you can't mutate anything behind an `Arc`. You need to use something like `Arc&lt;Mutex&lt;Vec&lt;i32&gt;&gt;&gt;`; `Mutex` ensures exclusive access dynamically, allowing you to modify its contents, even if the `Mutex` itself is shared.
Ah yes of course. Thank you. I misunderstood how Arc worked.
Perfect. Thank you that's exactly what I'll do.
You can define module with aliases (e.g. generated using macro to reduce amount of boilerplate): type A1 = Square(File::A, Rank::One); type A2 = Square(File::A, Rank::Two); ... type H8 = Square(File::H, Rank::Eight); One drawback is that compiler will not use those aliases in e.g. compiler messages, but other than that it will be much more manageable compared to your current solution. Plus it will be much easier to encode possible moves using such types.
You need to call `Arc::get_mut(q).unwrap()` (or e.g. match on the resulting Option). https://play.rust-lang.org/?gist=90d0ef6ce44d81d11f8b462fc1304619&amp;version=stable
Same thing here. All those mistakes distract me from the content and makes it much harder to follow. 
Since you mention Ethereum, it might also be worth mentioning that its Parity client is written in Rust.
/u/llogiq gives the answer if you have only one Arc reference. If you have more than one, which is the normal scenario where you'd use an Arc, then for shared mutation you need additional synchronization. Arc gets you the shared ownership. For mutation, you can wrap a Mutex or RwLock inside the Arc, so you'd do this: let mut v = Some(Arc::new(Mutex::new(vec![1]))); if let Some(ref q) = v { q.lock().unwrap().push(2); } 
They are mostly standard things but I need them in a different way that what ring provide. For example, X25519 where one of the key pair is static non-ephemeral while ring only provide agreement with two ephemeral keys at this moment. The algorithms offered by ring is also limited. Say, no RSA encryption. While I can understand that ring aimed at a crypto API that is safe. However, as a user implementing an existing protocol, some not ideal constructs are still needed. I need some not so standard cryptographic operations too. Say, to implement a Bitcoin’s HD wallet-like scheme, it will need raw EC arithmetic support. But I can totally see that these kind of low level API is too danger to be exposed in ring’s API. I like that ring is based on boringssl so it is inherently tested and fast. I also like the overall code quality. But the very restricted design approach largely limit its use cases. rust-crypto provides a large range of options in an okay API. Although many high profile project use it (including an ethereum client parity written in rust,) some implementation is somewhat questionable and in many cases slow. And now it is being abandoned, it seems that the chance it will receive the needed security review and optimization is low. A OpenSSL binding will of course provide all I need. But OpenSSL itself is already enough to make me worried. Perhaps a boringssl binding that expose the functionalities in comprehensive API like rust-crypto will be perfect. I wonder if something like this already exists. 
I'll elaborate a little bit since this is a bit terse for a top comment. No, I wouldn't.
The earlier part of this week was to continue working on flushing out my game design. Now though I'm starting to implement things, doing some clean up/improvement tasks I have listed in my trello. One thing is increasing some numbers 100x, so I can apply small percentage boosts and get whole numbers as a result. The other is removing the original win condition that was in the game when I made it for ludum dare. I wrote a blog post on Monday that has some more of this in detail: http://www.agmprojects.com/blog/taking-my-jam-entry-further Much like when I posted back in July, I'm using Glutin, gfx-rs, specs and rdio.
Thoughts on whether we should do these every 2 weeks or every month? Not sure if every 2 weeks is too spammy or not.
To aid mobile users, I'll link small subreddits not yet linked in the comments /r/playrust: The subreddit for the game Rust --- ^I ^am ^a ^bot ^| [^Mail ^BotOwner](http://reddit.com/message/compose/?to=DarkMio&amp;subject=SmallSubBot%20Report) ^| ^To ^aid ^mobile ^users, ^I'll ^link ^small ^subreddits ^not ^yet ^linked ^in ^the ^comments ^| ^[Code](https://github.com/DarkMio/Massdrop-Reddit-Bot) ^| [^Ban](https://www.reddit.com/message/compose/?to=SmallSubBot&amp;subject=SmallSubBot%20Report&amp;message=ban%20/r/Subreddit) ^- [^Help](https://www.reddit.com/r/MassdropBot/wiki/index#wiki_banning_a_bot)
yes. That game was created long after the programming language, and this language will be used long after that game is forgotten, if things go according to plan.
Hey, good on you for doing this! I know some people have stated problems, but I want you to know that doing stuff like this is good. It helps you learn, and it helps you share your knowledge with other people! One thing I’ve found is that people in the Rust community are often happy to proofread and give feedback on things before you publish them. Maybe reach out to some folks here, on IRC, on the user forum, on Twitter, wherever, before you post the next one. Getting feedback can be so helpful both to correct mistakes and more importantly to expand your own knowledge!
Well now I'm curious; what was the gist of the original post? "How dare you squat on the name obviously meant for the thing I care about!"?
the content of the post was literally the word "Title", indicating we should read the title. No idea what the intent was. haha, but I am personally a little bitter about the video game being named Rust.
*Huhn.* First time I've seen deleting a post making the content *longer* :P
Thank you! @the___duke. It means a lot to us!
Thank you so much! 
The game's wiki comes up a lot when you google "Rust Crate".
Way to be patronizing to someone asking an honest question.
They didn't ask a question.
It wasn't intended to be patronizing. Who made you the judge of a man's heart?
I can infer it from your tone. If the person asking a question could infer the answer, they wouldn't have asked it.
You're wrong, though. I'm biting my tongue not to actually be patronizing to you. Every time you comment on one of my comments, it's to attack me. I recognize your username. I will block you if you do it again, so I'll never even be able to see you on Reddit, let alone see your replies. I'm tired of your nonsense. "We" was not referring to OP. "We" are the readers of all the comments on this chain. After OP had posed their question, other replies were made which created sufficient information for the answer to be inferred. I presented that inference along with a hint to OP that more information had become available. I'm sorry if I suck at communicating, but at least I'm not going around being a jerk to people. I *was not* patronizing them. I'm the only one who can make that judgement call, because I am the one who made the comment. I'll accept your retraction any time now.
You're welcome for the down vote, by the way, since you're the one attacking me for no reason whatsoever. I don't know who hurt you.
You're condescending to most people who post here, and most people who post here don't call you on it. &gt; I recognize your username. I will block you if you do it again Good god; narcissist poster-child. Please do. &gt; I'm the only one who can make that judgement call, because I am the one who made the comment. I was observing, not judging, and that you can't take criticism is the _least_ bit surprising. &gt; I'll accept your retraction any time now. Thanks for proving my point.
You're welcome to your opinions, you're welcome, and done.
Pointing out that you were rude to someone other than myself is not an attack. a person willing to improve themselves rather than already thinking they're superior would probably have perceived it as such, but I wouldn't expect that of you. :-]
In case you want see a benchmark between the libraries, I made one using briansmith/crypto-bench: https://gist.github.com/kcchu/99cf83c516bccc26b7fdeb8bc7e85f7a AES-GCM in rust-crypto is devastatingly slow which make me suspected that the benchmark was wrong. I checked the code which seems reasonably correct. I reran it and I still get the same result.
&gt;You can install the latest version of the Rust compiler, as well as its associated package-manager, cargo, like so: &gt; &gt; curl https://sh.rustup.rs -sSf | sh NOOOOOOOOO -- friends don't let friends pipe foreign content through a shell (even if it is https:// )
I am not sure if this is the right place to ask but - I am looking at Tokio / network coding for the first time. Does anyone have any resources to dive a bit deeper into lower level networking code that I can use to learn? If it is centered around Rust that is great, but if it is more general theory that also works. Thanks!
You might be interested in including a simple emulator in your book (like the chip 8), since it would allow you to represent a lot of the cpu parts, how ram works, and some fundamental opcodes, using rust structs :) My first "large" project in rust is actually just that, a chip 8 emulator, so maybe I'm just trying to convince myself that my research on this topic wasn't pointless haha
Funny, seems like emulators are more common than I thought haha. I'm currently finishing up the last 5 opcodes in mine https://github.com/maximveligan/chip_8/blob/master/src/main.rs
Currently finishing up a chip8 emulator. I started with a NES emulator a while ago and it was a bit over my head. Hoping to learn more about type safety and how to write good rust! If anyone has time, I would greatly appreciate feedback :) https://github.com/maximveligan/chip_8/blob/master/src/main.rs
Yes, I meant to add that, and then promptly forgot. Thanks. I'd still like to note that in the example, a Mutex or RWLock isn't needed as long as we have a mutable reference, since Rust guarantees that we are the only one looking.
I enjoy this content, and will continue to read and follow along.
From what I have read of your code, I find your code to make a whole lot more sense, both in the sense that I can wrap my head around how the pieces fit together better and the API its self. It just makes sense to use the wonderful type system that Rust gives us to prevent problems at compile time such as the `Notify`/`NotReady` footgun that I have seen talked about a lot recently.
One interesting takeaway from this post is that Rust may be useful for testing your code even if said code is written in C. With test code that is usually easy enough to understand, this might be a great way to introduce Rust to teams reluctant to take the plunge.
I'm glad to hear that! Even though it's unlikely to get adopted into tokio proper, it can hopefully still serve as a useful mental model.
The write_all function is pretty simple: https://github.com/rust-lang/rust/blob/master/src/libstd/io/mod.rs Does inlining it speed things up at all? You could simplify it a bit since you don't check the error. I'm also a little skeptical about the necessity of cow, seems like either a static str or an arg should be convertible to a osstr. You might need an extra variable to hold the arg reference but I'd expect this to be simpler than cow, although this probably won't affect the critical path.
That will depend on how much news and information you have to share. If by the fortnight ends up meager, you can always switch a monthly debrief.
https://sandstorm.io/news/2015-09-24-is-curl-bash-insecure-pgp-verified-install
As far as I'm aware gtk runs ok on osx.
Also see fuzzing! Real talk property testing makes code flooooooooow. But so many projects don’t even bother to maintain even basic unit tests lol.
The Rust Programming Language, a.k.a. The Book, is free and available [here](https://doc.rust-lang.org/book/second-edition/).
It is lovely to see that you are going to support WebAssembly and Emscripten! Is there anything that total newbie to graphics, gfx-rs and emscripten (but not to rust!) can do in order to speed up web support implementation?
That's actually a really neat idea. I wonder if I can explain a stack pointer without explaining what the stack is (yet, that's next). My "CPU" might only have ADD and MOV but that might be enough
Last year I tried to use it on Windows and it worked well.
I managed to get it to work on windows, but you need to distribute a bunch of dlls with the exe. Here's a comment that explains what to do : https://github.com/gtk-rs/gtk/issues/422#issuecomment-270259393
I only play with Cockroach when it reach 1.0 And I unfortunatly see that it miss few precious types like uuid and json. Now TiDB is proudly here it's time to take a look. I know it has json but I did not see an uuid type.
Thanks for sharing, this looks interesting! Author's [Twitter is here](https://twitter.com/fspmarshall), in case anyone else wants to follow there for new posts.
Sure, testing C in Rust is tempting, although I have found it difficult to do in the current state (at least for embedded C). For this it would be great if: - Cargo would integrate C (as a plugin of sorts?) without the need of build-scripts (or external build systems like in erfc #2136) including incremental compilation. - Mocking of C code would be supported somehow (maybe similar to the C-testframework Ceedling?).
You always help writing docs or tutorials. Especially Fronten perspective of a beginner I think they hold value.
How might be this problem be solved of we were to complicate it further? What if the OP wanted to have types for a board of arbitrary size. Like a 5x10 board? I have found this post interesting as a rust newcomer.
I think they usually publish a new release when the build breaks because of changes to rustc? So… we need more plugin-breaking changes! ;) There's also an ongoing effort to integrate clippy into the rustc repo. Last thing I saw in that regard was https://github.com/rust-lang/rust/pull/45177
In chess the naming convention for squares is file + rank. You could borrow that convention for a 5x10 board (E9 for 49th square). However, as the board gets bigger, it becomes less of a good idea to use an `enum` for indexing.
uhhh..... Most crates don't publish new versions more than once a month (it's often much less frequent!) The only reason clippy has a lots of releases is because nightly breaks it often. It hasn't for the past 20 days (this was serendipitous, since for the last week I was in a different country and would have been too busy to fix things). However I know that there is incoming breakage that should show up on one of the coming nightlies so we will cut a new release soon.
Author here. Recently I had a need to parse [https://cvsweb.openbsd.org/cgi-bin/cvsweb/src/usr.bin/ssh/PROTOCOL.certkeys?annotate=HEAD](OpenSSH certificate keys), so I thought that's a good opportunity to dive into Rust again. My Rust experience dates back to pre-1.0 and since then I haven't done much with the language, so I thought I should spend some time with Rust for this task. The result of my work is the `sshkeys` crate which can now parse OpenSSH certificates and public keys. I did my best to document the crate and include tests as much as I can. The crate is now available on crates.io, and I would like to ask if you could review it for me - what I did right or wrong, what I can further improve, code organization, etc. Thanks! 
Timestamped links to individual talks: 1. [Korhal.io – Application container deployment for the Internet of Things with Rust](https://air.mozilla.org/rust-berlin-meetup-october-2017/#@2m18s) by [Arvid E. Picciani](https://github.com/aep) 2. [rspec – Making a BDD framework in stable Rust](https://air.mozilla.org/rust-berlin-meetup-october-2017/#@32m00s) by [Vincent Esche](https://github.com/regexident) (itsa me!) (For the second talk the audio is missing during the first few minutes.)
Hmm? I've been not able to install clippy using `cargo install clippy -f` for at least a week I deem... But you guys can?! LOL now the title should be what the heck is going on with my local environment
If you're starting with Android development now I think Kotlin (or Scala) is a better alternative. Less jobs in general, but certainly a nicer language to use.
Ah I missed half of my question! For an arbitrary size board - not known at compile time! Say you let the user decide which board to play on by entering width and height. Would you have to lose the benefit of errors being caught at compile time?
Kotlin looks interesting, scala seems a bit too confusing. :(
Note that the instructions on that page are a bit outdated. I sent a PR to fix them, but I don't know where the changes went.
Second speaker here. :) Happy to answer any questions regarding my talk or rspec. [Here](https://github.com/regexident/talks/blob/master/Rust-Berlin/2017-10-18/2017-10-18.pdf) are the slides as PDF.
Are you sure you're building it using the nightly toolchain? To be sure I always run: cargo +nightly install clippy Or when updating: cargo +nightly install-update clippy
Happy to answer any questions here as well, further discussion on [/r/Citybound](https://www.reddit.com/r/Citybound/comments/77dc7m/my_full_rustfest_talk_with_networking_live_demo/)
I don't think install-update works as the version doesn't change; just do cargo install --force instead.
GHC uses Core as its internal language because full Haskell is gargantuan, both Haskell and Core are extensions/variants of System F. Contrary to Haskell Core is explicitly typed and also has explicit strictness. GHC does tons of optimisation passes over that. C-- is a backend detail. I'm not really up to date, but it might be that it's not even in the compiler, any more, the llvm backend instead going directly from core to llvm ir.
X-Post referenced from [/r/citybound](http://np.reddit.com/r/citybound) by /u/theanzelm [My Full RustFest Talk (With Networking Live Demo)](http://np.reddit.com/r/Citybound/comments/77dc7m/my_full_rustfest_talk_with_networking_live_demo/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
They'd been removed some time before 1.0 so I'm guessing not.
Incorrect indexing for sizes known at compile time just emits a panic, not a compile error. Bounds checks can be optimized away if the index is known to be valid. Depending on how you plan to represent your data, you'd probably want to represent a board as a `Vec&lt;T&gt;` where `len` is `w * h`. If the board doesn't get resized, you can save 8 bytes by using a`Box&lt;[T]&gt;` from calling `Vec::into_boxed_slice`. As long as your math is consistent regarding `w` and `h`, your code should be safe. If you need the speed and are absolutely certain your indices are valid, consider using `get_unchecked`. For efficiency reasons, you _do not_ want to represent your board as `Vec&lt;Vec&lt;T&gt;&gt;`. So yes, you'd lose some of the benefits of sizes known at compile-time.
Yep, 0.0.165 fails to compile on 1.22.0-nightly (b7960878b 2017-10-18).
If the strong count is zero, it will be dropped, yes. That said, I'm not sure *why* you're using `Rc` at all here. `Option&lt;i32&gt;` would work just as well in this case. As an aside, asking "what should I do here" with a bare-bones one-line (presumably simplified) example isn't going to get you much in the way of good answers, if only because it's impossible to know what you're actually trying to do. If you want advice on something, you need to tell us what you're trying to accomplish (and not just *how* you're trying to accomplish it).
If you always update `value` from a `&amp;mut S` you should use just `Option&lt;i32&gt;`. If you want to be able to update it from a non-mut `&amp;S`, use `Option&lt;Cell&lt;i32&gt;&gt;`.
Hmm you are right. I will update the question. Actually the field will be a cyclic refernce to an enum, which itself has a variant of the type of the struct. 
I saw this at Rustfest, it was my favourite talk there. Nothing else actually changed my view on anything or really got me thinking about a new way of programming.
Thank you, that means a lot!
TRPL and Programming Rust (early access) are rock solid. Just picked up Rust In Action (early access), don't know how good it is yet. Can't go wrong with the Rust book online.
Keep up the good work, everyone. I would say that last time I used this (about 4-6 months ago) the asset pipeline was the biggest pain in the ass in the library. I'm glad to hear it's got some love. Looking forward to trying it out again some time soon!
As if someone was asking for it... I may have some time to look at it laterz today, but will be happy if someone beats me to it.
I usually don't like demo-style talks, but I'll make an exception for this one because it was. Just. So. Awesome. Kudos!
Thank you! It was a pleasure to meet you, by the way.
Wow! Very informative / interesting talk, a breath of fresh air. I have lots of new ideas. Thank you for sharing your knowledge.
Sounds amazing, thank you!
My first thought was "Oh this is like Fuzz Testing - The Next Generation"
I was just double-checking that it was called ASLR on my phone when the other dude asked about it and then got commended for it. I felt like the "high on potenuse" kid XD (https://www.youtube.com/watch?v=k1tsGGz-Qw0)
Same here; went in thinking that it would be one of the least relevant talks for me, ended up my favorite! Well done friend.
Is there an epub/mobi/azw3 version of the book available somewhere as well, I'd enjoy going through it on my ebook reader.
I've heard [good things](https://www.reddit.com/r/rust/comments/5ny6xp/blandy_programming_rust_book_status/dcfh26q/) about Programming Rust.
I think rust-crypto uses safe Rust but ring uses unsafe code.
https://github.com/killercup/trpl-ebook
Thank you! :) I'll put calibre to work then ;)
Click the print button, print to pdf, is one option. Eventually there will be more formats, but that's something to worry about after it's actually done.
Sadly the kindle is completely crap at displaying PDFs so I'm staying away from that as anything else than a last resort.
UPDATE: we've merged the `rust-server` generator into master. Here is the enhancement list for tracking: https://github.com/swagger-api/swagger-codegen/issues/6756 We also need help from the community to consolidate the Rust API clients generated by `rust` and `rust-server` into one (`rust-server` generator generates both server and client code)
I want to return an iterator from a function. I don't want to box it and I'm using nightly so I had a go at using `impl trait` to return an unboxed closure. #![feature(conservative_impl_trait)] pub fn vec_vec_eq&lt;T:PartialEq&gt;(a: &amp;[T], b: &amp;[T]) -&gt; impl Iterator&lt;Item=usize&gt; { Box::new(a.iter().zip(b.iter()) .enumerate() .filter(|&amp;(_, (x, y))| x == y) .map(|(i, _)| i)) } This is the compile error: error[E0564]: only named lifetimes are allowed in `impl Trait`, but `` was found in the type `std::box ed::Box&lt;std::iter::Map&lt;std::iter::Filter&lt;std::iter::Enumerate&lt;std::iter::Zip&lt;std::slice::Iter&lt;'_, T&gt;, std::slice::Iter&lt;'_, T&gt;&gt;&gt;, [closure@src\filters.rs:7:17: 7:38]&gt;, [closure@src\filters.rs:8:14: 8:24]&gt;&gt; How can I fix it?
Amethyst is now being developed at a rate of knots. Can't want too see what we end up with when things settle down!
This is pretty awesome. Are you aware of Entity Component Systems like [specs](https://github.com/slide-rs/specs)? It seems similar but still a bit different. How do you actually share code? For example lets say you have people with different jobs, like Policeman, Programmer, Firefighter etc. All of those people share common functionality but also have specialized functionality based on the job. For example all persons can sleep, walk, talk, eat etc but a policeman can also arrest other people. I assume you have to manually create different actors for these roles? Or is one person composed of many different actors? 
Thank you. Been a lurker for a while; seemed overdue that I try to give something back. I've been consistently impressed by how helpful and friendly the community is here. I will definitely take your advice for the next episode :)
Seeing the sort of load you are able to accomplish with actors is finally pushing me over the edge to really figure out how to make them work.
Great question! Yes, I am aware of ECS and share some basic mechanisms (IDs and slot maps), but didn't have the need yet to fully separate what might be components within each entity. For me ECS implies two things: 1) code reuse and polymorphism and 2) optimisation of memory layout and traversal. 1) is already partially achieved in `kay` using actor traits and might be further enhanced by having reusable actor "aspects" that a larger actor would be composed of, which each completely handle *some* messages for the whole actor. 2) could be introduced as a more complicated scheme of storing the actor state, where the state would actually consist of separate components and then each message type that the actor receives could specify which components are needed to handle that message type. Both changes should be possible, but again, I haven't really felt the need for it yet.
Cool! Keep in mind that actor systems can exist on the whole spectrum of simple/high-performance to fully-fledged/slow.
What would you say is the advantage of your actor system over an ECS?
try `pub fn vec_vec_eq&lt;'a, T:PartialEq&gt;(a: &amp;'a[T], b: &amp;'a[T]) -&gt; impl Iterator&lt;Item=usize&gt; + 'a`
Honestly, I think that having a portable graphics framework that supports wasm and emscripten would really be a killer app for Rust as a whole. Could we get together perhaps half a dozen interested people sometime and all devote a few weeks or a month to making it happen? Anyone besides me interested and not too scared of digging into OpenGL guts?
Async message passing and completely isolated actor states and all the benefits that brings (see my talk). As far as I'm aware, ECS `Systems` typically expect having access to several interacting entities at once, right?
Worked! Thank you. Can you explain why/how you can use '+' with lifetime parameters with traits?
Thanks, I'm really interested in blockchain tech. Btw, will you also cover untraceable ring signatures and all that stuff?
The way I understand it (without knowing the exact mechanisms) is that "whatever you return" has to be both an `Iterator` of the correct type, and it shouldn't be able to live longer than you borrow the slice elements. That makes obvious sense, but for some reason, the compiler cannot infer that yet for `impl trait`. The syntax for specifying that manually looks like I showed. You can think of it as the return value "implementing" both `Iterator` and the lifetime `'a`
&gt;Async message passing and completely isolated actor states and all the benefits that brings (see my talk) &gt;As far as I'm aware, ECS Systems typically expect having access to several interacting entities at once, right? Okay I now see the biggest difference. Everything is a message, so if some actor wants to know something about an other actor it happens with a message. This is what allows easy multithreading, but I guess the downside is that you may end with a lot of copies? For example you probably can't send pointers because it is completely async. In contrast to this, an ECS just iterates over components and you usually care about the order in which you execute the systems. I think for an ECS you would differentiate between outer and inner parallelism. Where inner parallelism is trivial with something like `rayon` and outer parallelism would be the order in which you execute different systems in parallel. Outer parallelism seems harder because you need to know about read and write access but specs already does that (I think?). It is always interesting to see different solutions, thanks for the talk! 
You may want to look at [Rust in Action](https://www.manning.com/books/rust-in-action). Author explains everything in easy and understandable language. 
You want /r/playrust
Yeah, but you also may be able to convert it or the HTML single-page into an ebook with various conversion tools.
That's true, I mean, the text is there, maybe calibre can even do it by itself.
Taking that time to thank the authors of Rayon, Syntect, Clap and all the other crates I'm using for their nice work!
Besides C#, all major descendants from Algol and Pascal.
If you'd like to be able to parse expressions with multiple operators without needing parentheses, respecting operator precedence, you could use the [shunting-yard algorithm](https://en.wikipedia.org/wiki/Shunting-yard_algorithm). It's complicated enough to be interesting, but simple enough not be be frustrating!
My favorite [line in the code](https://github.com/Keats/gutenberg/blob/20c1947b478e877d55fc3134028e42b2229edcf1/components/site/src/lib.rs#L131) so far: /// What the function name says pub fn enable_live_reload(&amp;mut self) { self.live_reload = true; } 
Not in the short term. My immediate goals are to cover the core tools &amp; patterns that are common to most blockchain implementations. Anonymization isn't an area that I've done much with, so I'd need to play some catch-up before I'd be comfortable speaking about that family of tools. That said, I'm definitely interested in covering those things that people find interesting and useful, so I'll definitely add it to the list of potentials :)
I don't even remember why this is a method to be honest.
That was very interesting, thanks!
The only problem is that the dll are ~50MB, if you want to do a simple application the overhead from the dll size is big. :(
Really exciting!
Glad to see you've gotten it far enough along for all this press. The docs and concepts look great! I just need to get cobalt into such a state :)
rust-crypto uses ghash implementation using safe Rust, while ring utilizes CLMUL instruction set through hand optimized assembly inherited from BoringSSL, so I think your measurements are completely correct. I have plans to implement GCM mode in the same way I did AES (and AES-CTR) in [aesni](https://github.com/RustCrypto/block-ciphers/tree/master/aesni) crate, but not a concrete timeline yet.
&gt; For example you probably can't send pointers because it is completely async. In a language like Erlang, sure. In a language like Rust you can pass Arc's around. Also, if you just 'move' data from one actor to another, it should be a shallow copy.
There have been a few new actor projects in the past few months. I'm really excited to see more work done there - I think Rust + actors has a lot of potential. If you look at the work done with Pony you can see some of that potential (type safe, efficient actors) manifested.
Done! I definitely can't go to the workshop (based in a different country), will the results/analysis be put online afterwards?
I like it, but why is it listed as version 0.0.1 on crates.io when the cargo.toml in github says 0.2.1?
It's not available on crates.io because of https://github.com/rust-lang/cargo/issues/2263.
[stdweb](https://github.com/koute/stdweb/) looks pretty lit.
Happy to share it yes! :-) I'll do a blog post I suspect.
Pony looks very interesting indeed!
I'm not a big expert but GTK runs on Windows and MacOS yes but I read nothing but pain from everyone who tries to use GTK3 outside of GNOME. The majority conensus I seem to read is that GTK has far nicer APIs than Qt and far more language bindings and Qt more or less forces you to use either C++ or Python but that GTK cross-platform support is pitiful compared to Qt and because it's essentially made by the same people that name GNOME people complain a lot about things changing all the time for the sake of GNOME not considering other consumers. Just what I'm reading everywhere and just a warning before you dive into GTK; naturally you'd wanna do your own research to confirm the stories.
Gutenberg is wonderful - rewrote [my website](http://seventeencups.net/) a few weeks back to replace a Ghost blog that was costing me a fiver a month, and it was really low friction to get everything up and running. 100% recommend it to anyone else looking for a static site generator!
Something I was hoping would be addressed in the talk and what I didn't really see in the code on a quick perusal was the notion of Actor state transition (beyond living and dead). One of the things that I've always found pretty cool about actor systems is the ability of an actor to evolve to a different state based on some message. Is that something you considered or is it not a goal of your system?
[Here](https://play.rust-lang.org/?gist=7ae1dc7c3a114fd4914c2a9cd3b49dfe&amp;version=stable) is a playground link demonstrating what happens when you reassign a Rc like that. You erase the reference that was held within the Option, which drops the value as long as there weren't any other outstanding references to it.
You can do that by hand quite comfortably (and I do it in a couple places) by just having the main actor state be an enum with each variant representing a sub-state.
Would you consider this post meager?
What is your enum doing that it's not `Copy`?
I literally just went on my github notifications which I cleared like two days ago and there's like 50 notifications from amethyst alone. Not all the same person either, lots of different avatars which is nice to see!
Here's a direct transliteration of the original, "broken" version of the Swift code to Rust: trait Animal { type FoodType; fn eat(&amp;self, &amp;Self::FoodType); fn walk(&amp;self); } struct Cow { name: String } impl Animal for Cow { type FoodType = Grass; fn eat(&amp;self, food: &amp;Grass) { println!("{} eats {}", self.name, food.name); } fn walk(&amp;self) { println!("{} is walking in the farm.", self.name); } } struct Tiger { name: String } impl Animal for Tiger { type FoodType = Meat; fn eat(&amp;self, food: &amp;Meat) { println!("{} eats {}", self.name, food.name); } fn walk(&amp;self) { println!("{} is walking in the jungle.", self.name); } } struct Grass { name: String } struct Meat { name: String } fn main() { let tiger = Tiger { name: "My Tiger".to_string() }; let cow = Cow { name: "My Cow".to_string() }; let animals: &amp;[&amp;Animal] = &amp;[&amp;tiger, &amp;cow]; } Here's the error one gets: error[E0191]: the value of the associated type `FoodType` (from the trait `Animal`) must be specified --&gt; src/main.rs:46:25 | 46 | let animals: &amp;[&amp;Animal] = &amp;[&amp;tiger, &amp;cow]; // error[E0191]: the value of the associated type `FoodType` (from the trait `main::Animal`) must be specified | ^^^^^^ missing associated type `FoodType` value Normally one would resolve this by specifying the associated type like so: let animal_tiger: &amp;Animal&lt;FoodType=Meat&gt; = &amp;tiger; The naive reading of Swift's error message for this case ("error: Protocol ‘Animal’ can only be used as a generic constraint because it has Self or associated type requirements") leads me to believe that it doesn't yet have the capability to specify associated types in this way when constructing trait objects (or whatever their term is for them). But of course this doesn't immediately do the Rust version any good either, as in this specific example we're trying to construct a heterogenous array and `&amp;Animal&lt;FoodType=Meat&gt;` and `&amp;Animal&lt;FoodType=Grass&gt;` aren't the same. A workaround will still be required. However, we can use the aforementioned capability of Rust's to change the workaround from needing an additional `AnyAnimal` enum with all sorts of type switching to simply making the heterogenous collection into a homogenous one by using `std::any::Any` for the associated type, like so: use std::any::Any; trait Animal { type FoodType; fn eat(&amp;self, &amp;Self::FoodType); fn walk(&amp;self); } struct Cow { name: String } impl Animal for Cow { type FoodType = Box&lt;Any&gt;; fn eat(&amp;self, food: &amp;Box&lt;Any&gt;) { if let Some(grass) = food.downcast_ref::&lt;Grass&gt;() { println!("{} eats {}", self.name, grass.name); } } fn walk(&amp;self) { println!("{} is walking in the farm.", self.name); } } struct Tiger { name: String } impl Animal for Tiger { type FoodType = Box&lt;Any&gt;; fn eat(&amp;self, food: &amp;Box&lt;Any&gt;) { if let Some(meat) = food.downcast_ref::&lt;Meat&gt;() { println!("{} eats {}", self.name, meat.name); } } fn walk(&amp;self) { println!("{} is walking in the jungle.", self.name); } } struct Grass { name: String } struct Meat { name: String } fn main() { let tiger = Tiger { name: "My Tiger".to_string() }; let cow = Cow { name: "My Cow".to_string() }; let animals: &amp;[&amp;Animal&lt;FoodType=Box&lt;Any&gt;&gt;] = &amp;[&amp;tiger, &amp;cow]; // error[E0191]: the value of the associated type `FoodType` (from the trait `main::Animal`) must be specified } It might be that we're no longer adhering to the spirit of the original (somewhat contrived) example, but this does demonstrate a small bit of extra flexibility that Rust affords you. Of course, the `AnyAnimal` workaround is perfectly possible in Rust too, though it's not very interesting (and as predictably ugly as anything involving trait objects, heterogenous arrays, and `Any` is, given that Rust hates all of these things :P ). Finally, I wonder if generic associated types would help here? In other words, replacing the above associated types with `T: Food`, and making both `Grass` and `Meat` impl `Food`. I suspect not, but I'd be happy to be surprised.
Is it possible that way to both ensure that Actor IDs are not invalidated while not having to implement handling logic for all messages across all sub-states?
I'm not sure if I understood you correctly, but yes, in every message handling function you have to first have a match on the current sub-state and if a message doesn't make sense for the current state, you have to manually either discard it, panic, or somehow store it somewhere for later (the trivial thing would be to send it again to yourself, so it just gets bumped to the back of the message queue)
That's really cool! Gotta love macros in rust!
I actully decided to unwatch for a little while because it was swamping my feed :)
I actully decided to unwatch for a little while because it was swamping my feed :)
I usually doc-comment those with [`/// Exactly What It Says on the Tin`](http://tvtropes.org/pmwiki/pmwiki.php/Main/ExactlyWhatItSaysOnTheTin)
The main goal of Pony is performance, and there are some clever things going on in the runtime that isn't obvious from the language itself, such as the garbage collector (which allows not just for distributed actors, but also for shared memory between actors using Refcounting, which is not trivial (since actors may pass references to the memory between themselves).
There is a common way in Rust where you pass something mutable to a function and still get to use it later: a simple `&amp;mut` borrow. No need to resort to `Clone` fn use_fn&lt;F&gt;(f: &amp;mut F, x: u32) where F: FnMut(u32) -&gt; u32 { println!("{}", f(x)); } fn now_it_compiles() { let mut add5 = |x: u32| x + 5; use_fn(&amp;mut add5, 0); use_fn(&amp;mut add5, 0); }
If you look at the bottom of the docuementation for (fnmut)[https://doc.rust-lang.org/std/ops/trait.FnMut.html] you'll see that if a type implements FnMut then a reference to that type also implements FnMut. That means you can pass a reference to your add5 closure instead of the closure itself to your use_fn function, and you can have as many of these (immutable) references as you like.
The demo was incredible! I love the idea of a multiplayer SimCity, especially if the cities are huge enough to avoid stepping on the other players' toes. What's your next milestone in development?
Cool thank you! Next steps are finishing implementing basic economy and overall making the development more scalable by increasing the approachability to contributors.
Iron is not based on tokio. You might get better results by using a web framework based on tokio.
Swift also has Any, to be clear (e.g. print() takes Any). The AnyAnimal pattern is a common and idiomatic one in Swift, which I think has its root in ObjC compatibility (e.g. [AnyHashable](https://developer.apple.com/documentation/swift/anyhashable)). The need for AnyHashable is an interesting limitation in Rust and Swift's interface system, in contrast to e.g. Java. Specifically, by allowing `Self` to be referenced (iirc it can't be in Java interfaces?), and making certain operations statically typed, we lose the ability to easily use those operations dynamically. Consider how easy it is to make a `Set&lt;Object&gt;` in Java, because the rhs of `==` is an `Object`, and not `Self`.
Thanks. My mistake. So Iron is just spinning up a new thread per request right?
I noticed a few of you are writing Chip-8 emulators. Feel free to join the Emulator Dev slack team if you want (note, not my team - I just found it myself after starting emulator dev): http://emudev.slack.com. I noticed the Chip-8 channel is pretty quiet since I think most of the users have moved on from Chip-8. But, since there is a group of you here maybe you can collaborate there? In either case, there is a #rust channel that is much more active. I'm writing a Gameboy emulator and so the #gmb channel is pretty active with my ramblings lately. Oh and the #8080 channel for the Intel 8080 also has some activity at the moment. Just throwing that out there anyway - I've found emulator implementation is easier when you can get near instant feedback on your thoughts/ideas.
Mhm, I saw `Any` in the Swift code in the article, but the way that I'm reading that error message makes it seem as though Swift has no way of turning `let animalArray: [Animal] = [myTiger, myCow]` (which is the line that the OP originally chokes on) into (inventing some syntax here) `let animalArray: [Animal&lt;FoodType=Any&gt;] = [myTiger, myCow]`. In other words, that Swift can't create "protocol objects" out of any protocol that has an associated type at all, even if that associated type is `Any`. Am I incorrect? Also, wait, is that Java example implying that Java's much-maligned type erasure was actually good for something for a change? :P (Also also, can you confirm that generic associated types wouldn't help here, as per the last paragraph of my previous comment? I want to suspect that they'd still resolve to different types, but HKT are supposed to be magical, after all...)
Feedback on the survey itself: "Doesn't matter" and "I don't consider this at all" mean roughly the same thing. Likewise, "nice to have" and "factored into consideration" also mean roughly the same thing. Makes it a little bit harder to answer the questions.
Yes Swift (last I checked) can't do the `Trait&lt;Type=Foo&gt;` trick. It's in the [Generics Manifesto](https://github.com/apple/swift/blob/master/docs/GenericsManifesto.md#generalized-existentials) which amounts to a giant feature wishlist. Swift's implementation of traits is generally 1-2 steps behind Rust -- they're still finishing up getting `impl Hashable for Array&lt;T&gt; where T: Hashable` to work, I think? (very close, if not actually done) (Also full disclaimer there's a few places where they're more powerful, but this mostly amounts to "things Rust will never implement because it requires runtime magic") Generic associated types are completely unrelated, as far as I know. The issue is fundamentally that you need every implementor to provide a Java-style `if !x.instanceOf(MyClass) { ... }` fallback implementation.
Ok. I think that if I were a priori designing an actor system, I might want to come up with something to make that a little easier to handle, but I understand how as a subsystem of Citybound this is a totally fine way of doing it.
I preordered Mastering Rust and Learning Rust. Learning Rust has been delayed over a year, Mastering Rust is quite difficult to follow and filled with errors.
To me it feels Rust's best wasm use cases are waiting on threading support. https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md
Not exactly one per request, it uses a pool of [8 * number of cpus](https://github.com/iron/iron/blob/a7c2ed64e6200ba96c1dd77f0eddf527bf0d51a3/src/iron.rs#L107).
Look at reqwest, high level crate that makes http eaaasssy
You know, now that I think about it, I should be checking if every dependency I use has high quality tests, and CI pipeline, etc.... but truth be told, I just pick the most popular one found on crates.io, and unless I have some serious problems with it, I just stick with it.
Yes, I was going to say the same thing. 'Nice to have' being the middle option doesn't quite feel right. I'm basically taking it as if it's labeled 1, 2, 3, 4, 5 instead.
Thanks for the input. Errors are definitely a deal-breaker.
&gt; the field will be a cyclic refernce to an enum Not sure I'm understanding you correctly, but in general `Rc` doesn't work with cycles. If you need references and cycles are unavoidable then you'll need something else like `Gc` from the [gc crate.](https://crates.io/crates/gc)
I did exactly this recently, using rouille and reqwest. It resulted in me writing https://wiki.alopex.li/AnOpinionatedGuideToRustWebServers which doesn't quite do what you want but does use both various web frameworks, and reqwest for unit tests. It's all synchronous, though. It was suggested to me I use tokio for async client requests, but I haven't gotten around to it.
Where is the best place to get support for TiDB? I don't see any user forums or other places where the developers hang out and answer questions. One big advantage that CockroachDB has is an excellent official forum. The developers are very active and answer questions every day.
I have a crate that specifically emulates the Node api: https://users.rust-lang.org/t/a-new-crate-simple-server-a-basic-webserver/13407 An express port is underway.
Did not use the release flag. Keep in mind that the benchmark tool only did 10 simultaneous requests at once, and the server I was calling had a 1 second delay. I’m getting the sense from this and a couple other answers that it might be better for me to do this synchronously for now and enjoy the convenience of blocking the thread. It’s mostly for embedded devices anyway although parts of it may need to run on servers and scale more.
Unfortunately, every time I try to compile it it fails for some reason or another. This time is no different. There's an issue opened, though.
Timely-Dataflow is pretty neat. I hadn't heard of it before. Rayon communicates using shared memory in the same process, so I don't think it's possible to combine the two.
Tiny bug report from mobile: https://www.getgutenberg.io/documentation/content/shortcodes/#gist The list says that the mandatory argument is `url`, but the usage examples use `id` as argument instead, might want to fix it to whichever one is correct.
&gt; In a language like Rust you can pass Arc's around. Presumably not if the actor is running on a different machine, though?
Totally! With kay, I’m doing pain-driven-development specifically in the context of Citybound, not more.
Any review would be welcome!
Awesome! I followed along this really basic blockchain impl https://hackernoon.com/learn-blockchains-by-building-one-117428612f46 in python and I've ported it to rust https://github.com/stevenpack/learnnet. I'll be following along with interest!
Hmm, it has few few variants with structs. Actually I am not clear when I should use `Copy` and when not to.
I am a noob, but I thought the book said Rust provided Rc for easy cyclic references?
`Vec` has a method `contains`. It's unfortunate that if I have `Vec&lt;String&gt;`, and a needle of type `&amp;str`, I can't call `contains` with that. Many collections remedy this kind of thing using `K: Borrow&lt;Q&gt;`, where `K` is the type contained in the collection, and `Q` is the type that is passed to the method. My question is, has there been talk about changing `contains` to more flexible direction? Is it even possible to change? (Might break type inference? But IIRC inference breaks that can be addressed with more explicit type declarations aren't strictly forbidden?)
You can have multiple references to the same value (aka shared pointer) and the memory will be automatically freed when the last reference goes away. This is implement by simply incrementing and decrementing a shared counter. Now imagine these references as a graph. The nodes are the values and there is a directed edge when there is a value holding an Rc to another values. If you have a cycle in this graph, then a shared counter is no longer sufficient. For figuring out when to clean up the memory. This is because the reference count never goes to zero when there is a cycle. Garbage collectors assume there will be cycles and deal with that case. 
Likewise.
Oh. Okay. Thanks, I will look into gc.
Good feedback, naming things is hard :-(
This week I did a spontaneous implementation of the RFC 6902 (JSON Patch) for Rust: https://github.com/idubrov/json-patch
I'm wondering if rustc and cargo can be built to wasm, enabling something like a client-side playpen, for instance to develop in rust on chromeos...
reqwest for the client rocket for the server https://github.com/stevenpack/learnnet Has examples of each.
Hyper and tokio are too low level for getting started imo. You’ll be scratching your head about why it’s so complicated until you use reqwest, where all the building blocks have been assembled for you.
ah copy paste gone wrong, thanks for the report!
That would require access to a file system, wouldn't it?
Could be localstorage-based? Doesn't _need_ to be arbitrary filesystem access... Though I see how it starts to be tricky.
Yeah that's cool! Thank you for the work.
You can't pass pointers to different machines in any language
It would be interesting to benchmark Rust library solutions against Pony someday.
Why does your crate contain binaries?
Thanks for the link! Do you know who I could contact to get a login?
How does this compare to jekyll or hugo?
The crate *is* a binary.
In memory? Interesting. But you'd have to download the whole file system every time you open the window. And you'd have to build half an OS on top of that, inside the browser, to allow cargo to call exec("rustc"). It's always possible one way or another, but it seems to be a tall order.
I would imagine the filesystem isn't that big compared to rustic itself, especially compressed. As for the dependencies, I'm not sure it'd need an entire OS there? Since we'd be recompiling cargo for this, we might find a way to have it only call the wasm-rustc instead of using system calls?... Darn, it's certainly not as easy as I initially hoped :(
I have never used Jekyll so I can't compare to it other than Jekyll requires a Ruby environement. It's more similar to Hugo, I wrote a small comment about it on HN: https://news.ycombinator.com/item?id=15507870 If you are using Hugo, the main points would be a better template engine, Sass compilation out of the box and imo a much simpler tool. Gutenberg still lacks some features Hugo like i18n though so it might not be usable by everyone right now.
Perhaps `|x: u32| x+5` should implement `Copy` then...
If I'm adding images to a post can I put them int the same directory as the markdown rather than in some separate /static directory?
Yep, here's an example in a test site: https://github.com/Keats/gutenberg/tree/master/components/site/test_site/content/posts/with-assets and the relevant part of the docs: https://www.getgutenberg.io/documentation/content/overview/#assets-colocation
Don't despair, this is a temporary setback. Your method of learning is exactly what I do as well. "How do I learn Rust"? Do what you're doing, then ask if you get stuck, like you just did. Anyway the stuff at the end of the loop, where you say let new_last_node_list = ... let last_node_list = new_last_node_list; let number_of_items_in_last_node_list; The `let` statement defines new variables effectively, it doesn't change the value of the ones that already exist. What you're doing is like if in java you did: int x = 0; while x &lt; 10 { int x = x + 1; } All you need to change is declare `new_last_node_list`, `last_node_list` and `number_of_items_in_last_node_list` as mutable (using `mut` like you're doing for `hidden_layer_layers_list`). Then inside the loop, get rid of the `let`-s on lines 145, 147 and 149. That should work, let me know if it doesn't.
If I am not mistaken a struct that derives `Queryable` doesn't actually need to have all not null columns as members. So I think the load turbofish syntax with a different struct should just work. Something like: `table::load::&lt;MyStruct&gt;(connection)`
Saw this at RöstiFest! It was awesome! The live demos were really cool. I loved that it was also not just a talk about Rust, but a talk about how the Actor model can be built in Rust, and actually built to scale.
At least the RFC of auto implementation of Copy/Clone approved: https://github.com/rust-lang/rust/issues/44490
It seems that while it's unproblematic to derive `Queryable` for a struct that doesn't include all the columns it does require the `select` when actually loading from the database. Following your suggestion gives me an error that indicates that Diesel plans to read out all the columns and is unable to fit this into the given struct: error[E0277]: the trait bound `(i32, i32, i32, chrono::NaiveDateTime, std::string::String, std::string::String, bool, std::option::Option&lt;std::string::String&gt;): diesel::types::FromSqlRow&lt;(diesel::types::Integer, diesel::types::Integer, diesel::types::Integer, diesel::types::Timestamp, diesel::types::Text, diesel::types::Text, diesel::types::Text, diesel::types::Bool, diesel::types::Nullable&lt;diesel::types::Text&gt;), _&gt;` is not satisfied --&gt; src/state.rs:133:22 | 133 | Ok(query.load::&lt;models::ArticleRevisionStub&gt;(&amp;*connection_pool.get()?)?) | ^^^^ the trait `diesel::types::FromSqlRow&lt;(diesel::types::Integer, diesel::types::Integer, diesel::types::Integer, diesel::types::Timestamp, diesel::types::Text, diesel::types::Text, diesel::types::Text, diesel::types::Bool, diesel::types::Nullable&lt;diesel::types::Text&gt;), _&gt;` is not implemented for `(i32, i32, i32, chrono::NaiveDateTime, std::string::String, std::string::String, bool, std::option::Option&lt;std::string::String&gt;)`
Errors quadrupled. I've already surrendered this code to Rust. Right now, due to me trying to debug and troubleshoot it in tons of different ways for hours, it's not really what I would consider coherent or functional code anymore. I mean, half the variables there aren't even needed, and I only had them there to troubleshoot. Right now, I just want to relearn in anyway possible.
I would advise reading the book and doing something simple like a brainfuck interpreter, or fizzbuzz, to get started
Huon Wilson actually is the one working on it 💪: https://twitter.com/slava_pestov/status/920477411535237121
So is reading the book cover to cover the only other way?
Yeah you are correct. Makes sense now that I think about it, diesel doesn't really have a way to establish which struct member is which column.
Ok, thanks anyway :)
Chapters 1-6 are probably enough to understand the basics of rust, but don't be scared to play around while reading, https://play.rust-lang.org/ is useful for that. And if you get stuck ask on here, the IRC or discord server, I know they are active 😄
I think associated types in Rust and Swift are too limited. In Scala this just works: trait Animal { type FoodType def makeFood(): FoodType def eat(food: FoodType) def walk() } ... val tiger: Animal = Tiger("My Tiger") val cow: Animal = Cow("My Cow") val animals = Array(tiger, cow) for (a &lt;- animals) a.eat(a.makeFood()) 
That's a good point, this should become an issue in https://github.com/rust-lang/rust
Honestly, I don't know what's more frustrating. Not being able to learn Rust like I've done with every other language before or Rust's ownership rules. If one fixes one reference problem, now the compiler complains that a variable is in two spots at once in the same scope. This just seems like such a nuisance to me.
Echoing the overall sentiment here - this was a great talk and gave me lots of new ideas for a few projects I've been thinking about. Also, for anyone who wants more detail on what was presented, I found this article creeping around the citybound site: http://cityboundsim.com/devblog/an-architecture-for-millions-of-things
You're following the wrong solution path. You can't look into GC in Rust - it's a highly advanced and very immature topic. You need to design something that doesn't have cycles, or at least only cycles using weak pointers.
This "nuisance" prevents the whole class of often hard to catch bugs, so while it can be quite frustrating while writing the code (especially for beginners), it's worth to remember what it will probably save a lot of your time and nerves later. Also, I think it's a bit rude to past image instead of an actual code. The best way is to get a minimal snippet (e.g. in the form of the link to https://play.rust-lang.org/ ) which demonstrates an encountered problem. Often while constructing such snippet you'll understand the issue and why compiler was unhappy without external help.
On a related note, are there any plans to bring clippy to stable Rust? It seems annoying to have to keep up with nightly all the time.
Thank you! I kind of forgot that I wrote that article, but it does nicely correspond to my presentation.
I would definitely advise that you read the book; it introduces all those concepts well, and the second version takes a more hands-on approach so with projects to follow along. There's a nice tutorial on making a webserver at the end. After that, I'll never stop recommending [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) The point here isn't to replace your method of learning by doing, it's just to give you the basic tools to enable you to do so; then you can go back to learning-by-doing in a much more rewarding way. You can also look out for the This Week in Rust newsletter, which always contains a section listing contribution opportunities, many of which ideal for beginners to the language. Good luck!
Wasn't trying to be rude, just more comfortable with images. https://play.rust-lang.org/?gist=21e37b841032c28f4cfaf6ff3a87845d&amp;version=stable There's the entire source file I was playing with. It's without my recent edits asked of me from nwydo as it's just the latest stable version. And one of the things I don't like is when I do something like: let mut x = 5; println!("{:?}", x); x += 1; And the compiler complains that x moves within the scope. Very frustrating.
In https://www.getgutenberg.io/documentation/themes/installing-and-using-themes/#using-a-theme I guess it should be `themes/simple-blog`
Why is that? Is there something stopping it from consisting of source code that the user compiles, like other crates?
Thanks, but I wonder on the topic of the book, would you recommend the second edition over the first?
Yes. The second edition is a full rewrite that adresses all the pain points of the first one, especially regarding hard-to-teach topics like lifetimes and ownership. It's also more hands-on like I said, which fits your approach better.
It's already that, you can git clone and cargo build it if you want. The issue is if you are using `cargo install`, it will not use the lock file of the binary so if a dependency had breaking changes in a minor version, it might (or might not) install but panic at runtime in the case of Syntect for example. I'd rather not care about those issues.
What you describe sounds kind of like a reverse proxy, so here's [a link](https://ayende.com/blog/176705/rust-based-load-balancing-proxy-server-with-async-i-o) to a simple one that might help.
It raises a question about the future i18n: will these files be copied in all language dirs at build? I think it wouldn't be a problem. And maybe catch the opportunity of localised files, like `infocraphic.jp.png`. I'll comment the PR.
Check out [Rust by exsmple](https://rustbyexample.com/). You see a lot of practical stuff. 
Thanks, fixed.
&gt; let mut x = 5; println!("{:?}", x); x += 1; Here is the link to [playground](https://play.rust-lang.org/?gist=586185fcdd0f3895cfea08ae70658180&amp;version=stable). As you can see those three lines work without problems, which means the real problem originates from the different place. Thus again point about minimal snippets which demonstrate problem.
I've having an issue with macro matching, as shown here: https://play.rust-lang.org/?gist=9e27f869cfa4ea523c968e894595c10b&amp;version=stable I have two macros, gray_image and rgb_image, each of which has a match arm which lets you provide an optional type annotation. However, rgb_image doesn't seem to match without the type annotation, while gray_image does. What am I doing wrong?
Yeah that article together with reading some of the code for the engine definitely clarified a few points that made sense at a high level, but I didn't necessarily intuit the details on right away. I've been reading the Compact / MultiSized code tonight as well as some of the actor stuff and it's interesting both rust-wise and generally. Seems like there are quite a few traits with only one impl - leaving plenty of room for future features. Anyways cool stuff and thanks again!
I know it works, but I was just trying to illustrate the problem I experience. The problem being the compiler not liking a variable being called sometimes for reasons unbeknownst to me. What seems like code that should work and has no reason not to work in my eyes, just doesn't.
When when you call `.clone()`on a r2d2 pool, does it spawn another pool? 
So give us the code that doesn't work, not code that resembles the code that doesn't work.
You brave, mad man (I mean the creator not OP).
So I want to start off by agreeing with the other posts. The Rust book is an excellent resource and skimming through it (with a few rereads of the Ownership and Pointer sections) should help a lot in getting started. Also the Rust through too many linked lists resource that someone else mentioned, should be particularly helpful for this use case. Looking through the playground you linked, one particular thing stuck out to me, the Rc&lt;RefCell&lt;Vec&lt;Rc&lt;Refcell&lt;Node&gt;&gt;&gt;&gt;&gt; structures. I don't presume to know much about your use case or know much about Rust at all, so perhaps this is unwarranted and I apologize if it is. But it seemed to me you were building a vector of the previous layer, with a single reference to each Node, then simply cloning a lot of references to the vector itself and not incrementing the references on the Nodes. It feels a lot more natural (and readable) to me to build a Vec&lt;Rc&lt;RefCell&lt;Node&gt; of the previous layer and do something like: let mut output_node_list = Vec::new(); for node in &amp;previous_layer_list { output_node_list.push(Rc::clone(node)); } let new_node = make_node(..., output_node_list, ...); Building a new output_node_list for each node and cloning references to the past nodes. If I'm misinterpretting what you're trying to accomplish, I aplogize, but this just feels more natural to me.
&gt; Interestingly, these files all contain code that is derived by hand from the Interpreter and a limited set of built-in functions of the JavaScript engine. But why do it by hand, when we could automatize the process, saving time and risk? HolyJit is exploring this possibility. IIRC that's also [pypy](https://en.wikipedia.org/wiki/PyPy)'s process: you write an interpreter in *rpython* (a restricted and statically inferrable subset of Python), and from that the toolchain compiles a native interpreter, inserts a GC (multiple strategies are available) and generates a tracing JIT (you can annotate the RPython code to provide JIT hints).
That name is unlikely to fly long term. Just saying.
What?! Does Terry finally decide to use Rust for his browser development?
Wait a minute! Can this be used to create JIT for Dyon?
I wrote a tutorial on cross compiling from linux to windows with gtk. Works pretty well. Even if you are compiling on windows the packaging section at the bottom shows how to set the icon and theme, so it integrates better with windows. http://gtk-rs.org/tuto/cross
We'll see about that when the Jit hits the fan.
Maybe for chaining?
&gt; This week, during the JS Team meetup, we have demonstrated the first prototype of a Rust meta-Jit compiler ... Is there a link so we can see this as well?
&gt; Garbage collectors assume there will be cycles and deal with that case. No, it just does not assume there won't be cycles. Very important logical difference; if it assumed there would be cycles then it would go horribly wrong.
*chuckle*
Thanks for this link! It seems the feature itself is also implemented, just not stabilized. 
I highly recommend the second book. I had a lot more trouble getting started with rust then other languages I've tried but the second book made things click. I'm not saying you'll be an expert after but it will set you on the right track.
Right now, I use Jekyll for most of my blogging needs, and have been toying with Nuxt. I'm curious if you've tried either of those, and what your thoughts might have been about them -- the experience you describe in your blog posts sounds valuable!
Looking at this, it involves a rustc fork. Is there any intention to upstream the functionality?
I'm so sorry I completely forgot you need an invite, heh. You can go here and request an invite apparently: https://slofile.com/slack/emudev The Slack team is the Slack chat for /r/emudev. At the top of that subreddit there's a sticky for requesting an invite. Again - sorry about that. I've been a member so long I forgot it required an invite, heh.
Like I said I'm really new to Rust so I'm sure I'll have plenty more questions as I get better at it. However, I don't see how a problem with Rayon being a shared memory parallelization library, and if I'm understanding the [Timely-Dataflow github](https://github.com/frankmcsherry/timely-dataflow) correctly it's a distributed memory library. For example, OpenMP is shared memory and MPI is distributed memory, and they are still able to work together. Though, I will say I have a lot more experience working with them separately, and I've really only started working with combining both of them recently on this new HPC code I'm working on. Now this is the big thing that I could see stopping Rayon and Timely-Dataflow from working together is if Rayon doesn't allow finer control on the parallelization say something like only one thread run a section of the code, let's say to send data to the other nodes, while the other one continue working on stuff until a certain point. Another issue I could see coming from the Timely-Dataflow side of things is if it also uses some additional threads to send data which could cause problems on the Rayon side of things. If this is the case then I might need to just find a library that simply sends data across nodes, and then lock the program until the data is received. I don't know I guess the big thing is I just need to get a better feel for all of Rust's different parallelization libraries.
&gt; If you can stomach the smell, put yourself briefly in the shoes of a programming language designer. Love it.
/thread
&gt; from which Rust derives much of it's syntax. Wat?
Here are the slides, at least: http://nbp.github.io/slides/HolyJit/JitTeamIntro/?full#cover
Even if that's within Mozilla and even one of the offices where Rust is developed, this is currently just someone elses prototype. Before such functionality is upstreamed, I'd expect an RFC. That said, this wouldn't be the first time something like this happens.
It's hard to contain the excitement here.
Ah, that makes sense then. When I replied it was late last night, I thought I might be missing something. But even then, `--release` can sometimes give a 60x or 100x speedup; benchmarking without it is generally just going to be a bad time. Can't fix a one second delay though.
In theory, it looks like it, yes.
It's not just a fork, it basically uses all the guts of the compiler as a library. The fork is small: https://github.com/rust-lang/rust/compare/master...nbp:register_opt_mir_pass but it pretty much reverts a patch: https://github.com/rust-lang/rust/pull/40239 &gt; In recent months there have been a few different people investigating how to make a plugin that registers a MIR-pass – one that isn’t intended to be eventually merged into rustc proper. &gt; &gt; The interface to register MIR passes was added primarily for miri (&amp; later was found to make prototyping of rustc-proper MIR passes a tiny bit faster). Since miri does not use this interface anymore it seems like a good time to remove this "feature". &gt; &gt; For prototyping purposes a similar interface can be added by developers themselves in their custom rustc build. 
i was actually working on new ui for cookbook. not sure how much of it will be used in the actuall cookbook, but you can see preview here if you are interested: https://github.com/jaroslaw-weber/cookbook-new-design we also need people to comment and give feedback on ux ideas, so if you have any opinions or ideas on cookbook please join gitter or github issues! i also had an idea for a simple and flexible static site generator. the crate name is slime and its on crates! also wrote few dozen lines of readme file. https://github.com/jaroslaw-weber/slime 
It states it depends on compiler plugin functionality. I have no idea about the official roadmap for rustc, but I guess they want good plugin support eventually.
Being able to add additional components to the compiler would make it ideally suited for SoC/ASIC development where lots of custom functionality exists in the hardware.
Scala should only be as confusing as the functional parts of Rust are. If Rust is a functional more modern and powerful C Scala is a functional Java.
I misread a few sentences there and thought for a second they were advocating writing webapps in Rust. I mean...yes, please! But I doubt Google would comply xD
congrats! actually i started my own static site generation library, it is using handlebars and json. if anyone interested: https://github.com/jaroslaw-weber/slime
Did you consider using a TypedArray, Vec or similar?
I wonder how much benefit is ascribed to Rust's compile time guarantees; from reading the article it appears the abstractive capabilities (in the case presented, macros) have been instrumental to reach much higher cohesion for individual features compared to existing code bases.
&gt; So, how do I learn Rust? My method of just programming in it, isn't working like it did every other language I've used, so I'm sorta confused and directionless here. Seriously, this method has never failed me so much, and I've never had to use any other method. This method tends to work well when the programming languages share common paradigms. For example, if you knew C++ pretty well, you could probably learn C, Java, C#, Python, Ruby, and Javascript fairly well using this approach. This doesn't work though when the language you are trying to use is very different than the ones you already know. Try learning SQL, Haskell, Racket, or Prolog using that approach and you will probably fail. Rust is the same way. If you're coming from a language with a GC, you're probably not used to thinking about memory in the low-level way Rust requires. If you're coming from C or C++, you're probably used to the compiler being very relaxed and letting you get away with anything. Rust's approach to memory management is different than pretty much every other mainstream language out there. Once you understand the paradigm, then you can go back to using your approach to learn the language. The easiest thing to do is probably just read the Rust book (I'd recommend [v2](https://doc.rust-lang.org/book/second-edition/ch01-00-introduction.html)). However, if you really don't want to learn the language this way, I'd recommend reading these specific sections before trying to dive back in: - 3.1 [Variables and Mutability](https://doc.rust-lang.org/book/second-edition/ch03-01-variables-and-mutability.html) - All of Chapter 4 [Understanding Ownership](https://doc.rust-lang.org/book/second-edition/ch04-00-understanding-ownership.html) - All of Chapter 15 [Smart Pointers](https://doc.rust-lang.org/book/second-edition/ch15-00-smart-pointers.html) - Or, at least, 15.1 [Box](https://doc.rust-lang.org/book/second-edition/ch15-01-box.html) 
I don't think anyone disputes that :)
https://internals.rust-lang.org/t/state-of-webassembly-and-rust/6077
On a literal level, `Copy` means that the compiler is free to implicitly clone values as they're moved around, leaving the origin side of a assignment reusable afterwards. (If the value is not `Copy`, you'll get an error about the latter being used after move IMO, `Copy` means that a value is both entirely self-contained (i.e. isn't holding any references, including heap allocations) and small enough that the CPU time required to clone it is trivial. C-style enums come under that heading, so if all your enum is doing is acting as a "type identifier" that other methods match on/dispatch to, it should definitely be `Copy.` 
Right, if it's running on a different machine you'll be copying it over.
&gt; Is there a link so we can see this as well? There was no recording made
I'm reading some links about this technique now, and this stuff is mind blowing!
I can't reproduce your issue. Reordering the rules makes everything compile.
I don't know how applicable it'll be to tokio, but if you want to know about network communication, you gotta read [Beej's Guide](http://beej.us/guide/bgnet/).
I really want to see what kinds of things would be created if he felt commanded by God to "cleanse" and perfect already-existing software systems.
Can't you just specify exact dependencies in your cargo.toml? Or are you worried about this happening in things your direct dependencies rely on as well?
That's unfortunate. Luckily /u/fgilcher provided the sheets which has some interesting info.
At [Faraday.io](https://www.faraday.io/), we use a fair bit of Rust code behind the scenes. `geochunk` is used for a parallel map/reduce over many gigabytes of geodata, as part of our [Pachyderm](http://pachyderm.io/) data-cleaning pipeline. We also have some other open source utilities, many of which rely heavily on u/burntsushi's excellent `csv` library, and which we use together with his [`xsv` command-line tool](https://github.com/BurntSushi/xsv): - [`scrubcsv`](https://github.com/faradayio/scrubcsv). Clean up common kinds of mangled CSV data - [`catcsv`](https://github.com/faradayio/catcsv). Recursively merge directories of `.csv` and `.csv.sz` files. - [`credentials-to-env`](https://github.com/faradayio/credentials_to_env). Fetch credentials from Vault and copy into environment variables, with the ability to just pass in the environment variables when Vault is unavailable. There's also a Rust crate `credentials` which allows you to do this without environment variables. Our big open source Rust tool, however, is [`cage`](http://cage.faraday.io/), which we use to develop large microservice applications using Docker. 
Can you explain what the benefit of using this over std::Result is?
Tbh writing a any part of a js VM/RE in Rust seemed a bit overkill to me. Not that Rust isn't perfectly good at writing compiler, but js specifically is tied quite deeply to the C++ object model and most awesome libraries for node (some of which can be of help for web apis) are built using C++ (I mean, outside of the native js ones). I'm just wondering if at this point it wouldn't be better if FF swallowed their pride and used V8, I mean, it's got amazing support because of node and it's by far the best VM when it comes to performance (and, in the end, security is very much tied to the amount of pair of eyes looking over it and trying to exploit it).
A JS VM monoculture is just as bad as a browser rendering engine monoculture, as far as I'm concerned.
[removed]
My understanding is that the biggest issue this is trying to solve is that in a typical js runtime you have several "sub-runtimes", for example in spidermonkey there is the interpreter, a baseline jit and an advanced jit. Each of them is a different compile-time/run-time tradeoff. They each have their own "macro-assembler" and the glue between JS and the compiled pieces of the code that need to be inlined for performance (for example accessing a property on a DOM element) are hand written for each of these assemblers, and that's very error prone and hard to maintain. The compiler plugin first and foremost makes it possible to take pieces of the interpreter that need to be inlineable and have the various macro assembler versions for these pieces generated automatically by the plugin, instead of writing it N times in some obscure representations. Beyond that the benefits of rust's type system are the same as in regular code. Rather than write some stuff in a bunch of obscure asm format you get to write in nicely typed language.
Why would the language the JIT was written in have any effect of the JIT's ability to convert &lt;language&gt; into &lt;machine code&gt;? V8 isn't coveting JS to C++ so the C++ object model is irrelevant?
&gt;I was just trying to illustrate the problem I experience. A better illustration would be one in which the problem you experience actually happens. The Rust playground is *super* helpful when sharing around troublesome Rust code. I get that you're frustrated, but all of the code you've shared seems to work (except the code in the screenshot, maybe, but I'm not sure because it's a screenshot), and it's hard to troubleshoot code that doesn't really have troubles.
Thanks, I was hoping to learn the right way to do things async, since coming from node, blocking feels dirty. But maybe that’s too complicated for now.
Do you understand which types are `Copy` and which are not? It sounds like that might have been the problem. (The `println` snippet above even works with types that are not `Copy`, so I'm not sure what the problem could have been.)
Wow awesome work! &lt;3 And you're even [updated with the latest and greatest](https://github.com/faradayio/geochunk/blob/282cbb735d0fffb1dcbfeaa274ac4035850273e7/Cargo.toml#L18). :-) I look forward to reading the blog post once it's back up! Did you happen to notice any performance improvements when upgrading to csv 1.0.0-beta.x?
&gt; I mean, it's got amazing support because of node and it's by far the best VM when it comes to performance No, it's not. SpiderMonkey's code is quite a bit cleaner.
Browser rendering engine monoculture would be a dream come true for me. What's bad about it (if the browser engine is FOSS)?
To be honest that is true, my argument is rushed there. But having multiple teams work on the same projects does help it improve. I mean, C++ is where it is performance wise nowadays partially because of the clang&amp;gcc friendly rivalry and the same can be likely said about many language.
FOSS doesn't address control, which is another way of saying "power". Historically, browser monoculture in any form has led to stagnation, frustration, and just generally isn't good for the web. If you want the web to remain an open, vibrant platform, it can't be a monoculture, Free Software or not.
You can coerce a closure like that to `fn(u32) -&gt; u32`, which in turn can be copied.
That seems to be against your argument, no? clang and gcc are two different projects, not the same. That said, this is also (in my understanding) the exact opposite of what V8 does; V8 generates an interpreter from their JIT, while this generates a JIT from the interpreter. So you can't really try out this approach with V8; it'd be tantamount to a re-write which is basically an entirely separate project anyway.
Pretty sure I made a Rc for the vector as I needed to make it so each node could reference the vector to then be used to make the node struct key outgoing_node_list, but really, at some point I was just throwing a hail marry at the thing to make the main while loop work, to the point that I threw a Rc that any and everything, especially when I kept getting the frustrating "You can't use the same variable more than once," compiler error. Really makes things complicated.
yeah, PyPy was immediately what I was reminded of as well. I think they're doing very cool stuff that needs to be picked up in the rest of the compiler development world. I wonder if the author of HolyJIT has checked out their research.
Yes, thank you for the confirmation. I will begin to read through the book soon, and I agree Rust has a very different memory management system, as the compiler just says, "Okay yeah, I'll store the information in this variable in the memory for you, but if you try to read, access, or do anything with it, I'll cut you." I've used the 'jumping right in' method for a lot of languages, including SQL and Racket actually, and it worked just fine. I actually remember what I used for each, I created a database for a web-scraper with SQL very quickly and used Racket to make a game of pong. Though I do admit I don't know Haskell or Prolog, never had a reason or desire to use them. They any good?
Very well, thank you.
Yes it is against my argument, I did say, my argument is rushed and in actuality if you had a few good competitors to V8 things would likely be better for every user.
Alright, thanks for the tips.
Thank you, I'll be sure to read it, most likely after I read the second edition of the main popular book.
"This means more time to implement JavaScript features" - yes, because JavaScript isn't getting enough features fast enough :-p Jokes aside, I love this kind of work from the Mozilla team. This and the bits going into Quantum are really amazing pieces of software engineering in my opinion.
Based on the source [here](https://docs.rs/r2d2/0.7.4/src/r2d2/lib.rs.html#311-313) and the definition of the struct [here](https://docs.rs/r2d2/0.7.4/src/r2d2/lib.rs.html#304), the answer is no it does not.
Ah sorry, I misunderstood what you said. No worries!
In which case, what is the benefit of using this over a bool?
&gt; I wonder if the author of HolyJIT has checked out their research. PyPy is mentioned in the slides where they announced this, so they're aware. There's a link elsewhere in this thread.
I've added a reproduction here https://play.rust-lang.org/?gist=6f3d43861b8002eb1763b77ac2b0c49a&amp;version=stable The final line is the invocation that now fails. I've got a tolerable workaround which is to specify the type in square brackets like this https://play.rust-lang.org/?gist=b6184717e45a1a9893eb5e5ec81a42ae&amp;version=stable But it would be nice to have a clearer understanding of what the issue is with the other version.
&gt; Did you happen to notice any performance improvements when upgrading to csv 1.0.0-beta.x? I believe this tool was written against 1.0.0-beta in the first place, IIRC, so I don't have a comparison with the older APIs. Honestly, now that we've moved our main [ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load) pipeline to a Pachyderm cluster, your `csv` library is so fast we rarely even bother benchmarking it any more. :-)
[removed]
Unfortunately, I won't be reproducing it. Reason being nothing other than I hate the error/limitation so much, I don't want to perpetuate its discussion anymore than I have to as thinking about it makes me feel a certain type of rage that only a compiler error can give you. If after a period of study, I still am unable to bypass the compiler's unreasonable demands of not accessing variables/memory, modifying variables/memory, or doing anything other than just stating a variable (let), I will return to this very Reddit for help, or I'll just give up, cry, and go back to asm or something.
They will definitely change the way you think about programming. Think for a second about how you'd write a sudoku solver. A brute force implementation would be pretty simple but it would take a long time to run. In order to speed it up, you'd need to implement some caching, efficient search algorithms (perhaps A* or similar), backtracking, etc, etc. [Here's](https://swish.swi-prolog.org/example/clpfd_sudoku.pl) the solution in Prolog. It's less than 40 lines including whitespace, comments, and some niceties like pretty printing. The core of the code is really only 24 lines long and it runs in a fraction of a second. The code basically just describes what a solution looks like, what the problem is, and, is if by magic, the language finds the solution. Of course, it's not magic and learning the language will teach you how it works.
[removed]
As a workaround, can you use something like [this](https://play.rust-lang.org/?gist=7f8d8f8014227baca271e32e4a5f7cb5&amp;version=stable)?
Yes. This has been the plan for like a year, we took first steps a month ago. It's mostly blocked on RLS pioneering this model.
This may throw a runtime exception for bad input (e.g. feeding a tiger grass). The design philosophy of Rust (and Swift) is to eliminate runtime exceptions insofar as possibly by disallowing risky behaviour at compile-time The exact Rust translation of that code is using boxes and runtime casting, as /u/kibwen demonstrated above. The issue ultimately is that `Animal&lt;FoodType=Grass&gt;` is a different, _incompatible_ trait to `Animal&lt;FoodType=Meat&gt;`. The former has an `eat(&amp;self, Grass)` method which the latter lacks, and conversely the latter has a `eat(&amp;self, Meat)` method which the former lacks. Therefore the same code isn't guaranteed to work on both. If you used a generic instead of an associated type it would be clearer that you couldn't add a Animal&lt;Meat&gt; to a Vec&lt;Animal&lt;Grass&gt;&gt;.
Thanks for the comment, but I'm aware of the copy thingy-mcjig, and it was actually the first thing I tried before becoming aware of and subsequently using the Rc thingy-mcjig. Unfortunately copy doesn't work on vectors, which is sad for me because for what I wanted, I needed to use vectors. Really, I was happy when I discovered the vector type because it was actually what I was looking for as far as a list type that could supposedly be modified and such, but that hope that was spawned by vectors was immediately crushed by the revelation that they can't be copied. And yes, before it is suggested, I know clone exists, but I really needed copy.
Thanks, I appreciate your care, really great community member, like everyone else here, but I'm not really looking for trouble shooting. The code is crap, and I don't understand Rust one bit, but if you really to or just want it for trouble shooting practice: https://play.rust-lang.org/?gist=21e37b841032c28f4cfaf6ff3a87845d&amp;version=stable
Readability? I once read a blog post (I'll post it here if I find it back) advocating against the generalized use of naked primitive types in Haskell. The argument basically was that `data ShouldIDoThis = DoThis | DontDoThis` is strictly equivalent at runtime to using a Bool, but is much, much easier to read, can be documented, etc. Eg, compare (in Haskell): listFiles True False True and listFiles Recursively ExcludeHidden FollowSymlinks 
&gt; I think they're doing very cool stuff that needs to be picked up in the rest of the compiler development world. I believe Oracle's Graal project is somewhat similar, or at least has similar facets.
I don't think lines required to implement a solution is a good way to measure a language's efficiency, at least when some functions that aren't included within the line count are used in the solution. Though I assume that the functions used are included standard (exception for rendering,) so I will say that if the language's loading times are similar to its peers, it's impressive that it's able to have such functions included as a base, and I may one day spend some time to learn it, but I think most of the fun of programming is figuring out a solution for ones self, and not relying on something else to do everything for you. The old Python joke comes to mind: import program.
Just pronounce it Holy-J-I-T around management
It seems like a bug... I can't explain why the two macros should be treated differently, and why the order of arms can influence whether there are multiple successful parses.
Couldn't failing to downcast have the same result? Would it be possible to have a type of constrained `Any` which only admits a limited number of otherwise unrelated traits. For instance, I could say something like: impl AnyOf&lt;Trait = Animal&gt; for Tiger {} I'm thinking of it like an implied `enum`, this would simple require that `Tiger` implements all of the required elements of `Animal`.
I am, for GPU allocations in my Nim tensor library which are even more expensive than on CPU, see what I'm exploring [here](https://github.com/mratsim/Arraymancer/issues/112). I've put my go bot in Rust to rest though, but next time I use Monte-Carlo or any backpropagation algorithms I will look into memory pool/arenas.
&gt; Historically, browser monoculture [...] There has never been a real browser engine monoculture, except maybe Trident in ~2005, but that was proprietary. &gt; FOSS doesn't address control, which is another way of saying "power". Non-monoculture (multiculture?) doesn't address control either. Currently we don't have a monoculture, still you're basically done if your website doesn't work in Chrome. To really fix this, I guess we'd need standards and laws, something more democratic.
Yes, I agree regarding lines of code but it's important to realize this isn't a `import sudoku; solve_puzzle()` trick. This is **actually** a sudoku solver. There are no sudoku functions in the base library. The only things imported are some basic list functions like `length`, `append`, etc and a pretty printer to give you the nice grid output. If you comment out the pretty printer line, you'll see that it's actually outputting nested lists. [Here's](https://programmablelife.blogspot.com/2012/07/prolog-sudoku-solver-explained.html) an explanation of how it works. This isn't relying on somebody else to do everything for you. This is all there is to do.
Yes, the name is even a reference to it.
I mean you *could* just run it in JSLinux. Seriously though, building a FileSystem in memory incrementally wouldn't be too difficult and you wouldn't need all of the system libraries or anything else that makes up a traditional OS. Maybe web workers could be used to cache an archive file which could be referenced by byte ranges, handling requests for byte ranges through the Fetch API. If cargo supported binary WASM packages this would be even easier. I'm actually working on an offline playpen myself, but it won't be a full `rustc` environment.
Maybe you could skip LLVM entirely and go straight to WASM, (mir2wasm) that should cut down on the requirements quite a bit.
Are you planning on moving Kay to a crate?
&gt; This may throw a runtime exception for bad input Though to be fair, the Rust and Swift versions simply don't do anything at all on bad input, which may or may not be better than outright crashing (you can make the Swift version prefer to crash by using `as!` instead of `as?`, and the Rust version by using `.unwrap()`). None of these are as good as a type-enforced solution.
&gt;I really needed copy. Why?
`Option` has different meaning attached though, for a value that may or may not be present. Using `Ok(value)` and `Err(())` is a poor fit for this, even if it would functionally be the same. Whereas `Outcome` seems to have the *exact* same meaning as `Result&lt;(), ()&gt;`.
[removed]
Does this enable a future rewrite of spidermonkey in rust?
&gt; I guess we'd need standards and laws, something more democratic. W3 is a standards body that is democratically controlled. They can only put out guidelines, they cannot force vendors to implement their tools in accordance to their guidelines. Furthermore, their specifications maybe incomplete at various edge cases.
&gt; I look forward to reading the blog post once it's back up! It looks like the post is [available again](http://blog.faraday.io/geochunk-fast-intelligent-splitting-for-piles-of-address-data/). (Just responding to your message so you find out about it!) 
I would be interested in such links. 
Two questions: 1. How to correctly handle the result of join() on a thread if I don't want to ignore it? '?' seems to complain the trait `std::convert::From&lt;std::boxed::Box&lt;std::any::Any + std::marker::Send&gt;&gt;` is not implemented for `std::io::Error` Do I write a match statement to handle this? 2. How do I handle the value of String::from_utf8(something) without using unwrap()? Thank you! I'm sure it's something really straightforward!
The discourse on this thread is civil AF for Reddit. 👏👏
You can run [Linux in your browser](https://bellard.org/jslinux/).
Thanks for having a look. I'll just go with the workaround for now then.
I wanted to see why Box was required, but I don't know if I understand the error message for sure: error[E0277]: the trait bound `std::any::Any + 'static: std::marker::Sized` is not satisfied --&gt; src/main.rs:29:6 | 29 | impl Animal for Tiger { | ^^^^^^ `std::any::Any + 'static` does not have a constant size known at compile-time | = help: the trait `std::marker::Sized` is not implemented for `std::any::Any + 'static` Does this mean associated types are required to be Sized? I think google shows a few results indicating this, but no docs came up laying out clearly what the required bounds on associated types are.
Your doc comments for the two variants of Outcome are a little too sparse. Given how rustdoc lays out documentation for enum variants, you should probably aim for a full sentence for each. Are you using Cargo's doctest functionality? I don't remember but I think you might need to indicate that the code blocks in your documentation are syntax-highlighted as Rust code to enable it. (If not, it'd still be a good idea.)
[removed]
I consider [Dolphin emu's monthly progress reports](https://dolphin-emu.org/blog/) the gold standard. They're usually super meaty (although to be fair I reckon Dolphin has more contributors).
Alternatively, the author working an a french office of a US company, they could have called it NTM (New Translation Magic).
&gt; but js specifically is tied quite deeply to the C++ object model Haha what? No it's not. 
Read this now: http://tratt.net/laurie/blog/entries/fast_enough_vms_in_fast_enough_time.html
While rust does have a steep learning curve and you can certainly criticize it for it, I don't think your current problem can be attributed to rust's ownership model at all. Your misunderstanding is super simple, and the exact same mistake can be made in pretty much any language (C/C++/Java/Go to name a few). It's just the difference between creating a new variable vs assigning a value to an old variable. I made a super simple example to show you: https://play.rust-lang.org/?gist=2981e8201acd20f930d8b2968552b8b3&amp;version=stable And here's an example of the same mistake in Go: https://play.golang.org/p/53jk7YodGP
Indeed! This seems very interesting, but I'm having a hard time picturing just how this works, so I'd love more material on the subject 🙂
I asked the same question on Gitter a while ago, and got the same answer about selecting a subset of columns. This is what they do in crates.io https://github.com/rust-lang/crates.io/blob/b0c3cdeffdd8f54e9e3611024dd97677d842782c/src/krate/mod.rs#L74 A more magical solution is a DB view that only includes what you want, but still a bit of a manual solution.
Though I'm never an IDE folks, but I've heard [Intellij Rust!](https://intellij-rust.github.io/) has good features, showing inferred type, for example.
https://areweideyet.com/
Ok, I guess that settles it. There's a bit of manual keeping-in-sync to do for my use case :)
[removed]
I had the same problem on windows and I fixed it by setting LIB variable pointing to postgresq\lib and adding postgresql\bin to the PATH variable
* Your previous experience doesn't include manual memory management ( 'C' ). * After skimming your code , i don't see any 'ranges', 'map' , 'fold'. Instead i see a couple of while loops and mutable integer definition. Luckily you should have experience with the second point from your LISP work. Personally i really like rust because it allows me to write code with these functional constructs at the level of 'C' within the stdlib , without the fear of seg faults. As for a method of learning, i basically did the same. read a quick start tutorial , write your own program , google your errors , fight the borrow checker, cry in a corner , revaluate life-times , actually read the book. But don't shy away from the tough learning curve. You can teach somebody 'C' very fast. The downside is that they think they understand, while in reality they will simply have to learn the tricky parts by using the debugger. 
Jekyll's support on Windows was really flaky last time I tried it, so that kinda ruled it out for me ): Although that's more an issue with Ruby than anything else, I think. I can't really comment on Nuxt.js, but I did try Next.js (which I believe was the inspiration for it?) while rewriting my blog. Really liked it, but I feel like it's better suited for building applications rather than sites - it doesn't come with stuff like a markdown renderer, syntax highlighting, etc. You can use plugins to add them, but I was looking for something that'd work a bit more 'out of the box'. I imagine the same would go for Nuxt.
vscode + rls is by far the most mature right now
Cycles are not always avoidable, even with weak pointers. There is a [gc crate](https://crates.io/crates/gc), that while immature, does work. The implementation is an advanced topic, but using it is dead simple.
I love the combination of these! Really opens up a world of possibilities. The one command I'm still trying to replace is `cd` itself. For instance, can anyone suggest a way to add bookmarks, so that I can move around faster? I found a few, but was never happy with them.
Have you tried just setting `CDPATH`?
Q2 `String::from_utf8` returns an enum `Result` either the String or Error. match String::from_utf8(something) { Ok(somestring) =&gt; { //do something with somestring }, Err(err) =&gt; { //do something with err } }
Vim and Emacs setups work really well too.
Thank!
`Copy` is not only about relaxed move semantics: It also means that the type is stack-allocated and cannot be `Drop`. This is why vectors cannot be `Copy` but arrays usually are. What do you mean by "I really needed copy"? Note that references are `Copy`, in particular `&amp;Vec&lt;T&gt;` (or `&amp;[T]`) are `Copy`.
 I put the following in my ~/.zshrc for bookmarks with fzf fuzzy matching. unalias cdg 2&gt; /dev/null cdg() { local dest_dir=$(~/.cdscuts_glob_echo | fzf ) if [[ $dest_dir != '' ]]; then cd "$dest_dir" fi } cdg_add() { local curr_dir="${PWD}" if ! grep -Fxq "$curr_dir" ~/.zsh_bookmarks; then echo "$curr_dir" &gt;&gt; ~/.zsh_bookmarks fi }
My IDE of choice is linux. That might sound a bit odd, so let me elaborate. I use tmux to manage lots of shells, but I also run my editor inside tmux (vim and emacs are my goto editors). I use language specific plugins in my editors (for rust that means racer) to give them language-specific smarts. I use command line tools, say grep/find and lately, their rust alternatives: ripgrep and fd) to help me locate things. You can also use tag files. I have a thing in my .vimrc so that if I type `:Grep foo`, then I can easily navigate to all uses of `foo` in the codebase. It's integrated in the sense that all my tools work from from a single terminal and everything is keyboard driven. The only wrinkle is using alt-tab + mouse when I need to use the browser (mostly for looking at documentation). If that really bothered me I could use a terminal based browser, but I'm okay with using a graphical browser. 
The error type for `Thread::join()` is going to be the argument of any `panic!()` invocation that occurred in that thread before it returned. Because it's a `Box&lt;Any&gt;`, it needs to be downcast to its original concrete type to be inspected. This is typically going to be `String` if it was used with formatting arguments, or `&amp;'static str` if it was just passed a string literal; however, any value that is `Any + Send` can be used as argument to `panic!()`, though it's pretty uncommon to see this done. I would only worry about the string types: use std::any::Any; use std::borrow::Cow; match thread.join() { Ok(val) =&gt; /* consume the value returned from the thread */, Err(e) =&gt; println!("background thread panicked with message: {}", string_val(e), } // this covers both string types by returning `Cow` which can hold either fn string_val(any: Box&lt;Any + Send&gt;) -&gt; Cow&lt;'static, str&gt; { any.downcast::&lt;String&gt;().map(Cow::from) // if `.downcast()` fails it returns the original `Box&lt;Any&gt;` .or_else(|any| any.downcast::&lt;&amp;'static str&gt;().map(Cow::from)) // this will re-panic with the same argument on the current thread // you might prefer to handle it differently .unwrap_or_else(|any| panic!(any)) }
I don't bother with docker, I just build. It looks like it might work.
Yes
&gt; Non-monoculture (multiculture?) doesn't address control either. Currently we don't have a monoculture, still you're basically done if your website doesn't work in Chrome. This has to be seen from the users perspective: the non-monoculture enables you to browse the web with a client that isn't built by Google. Sure, as someone offering services, this means compatibility testing, but that's a good tradeoff.
HolyJit vs TurboFan
&gt; I thank you for your concern I'm not concerned at all. You came in here moaning about issues you had, but wouldn't provide anything nearly sufficient for us to help you. &gt; If after a period of study, I still am unable to [...] I will return to this very Reddit for help Well it doesn't sound like you've really studied at all, you've just started throwing code at the compiler without knowing what you're doing, and are frustrated that it acts differently to languages you already know. You're saying you've gotten stuck, but it seems like you've just come here to vent on all of us, why come back another time when you could ask questions on what you're struggling with *right now*?... Lots of languages you *can* just get away with throwing code at a wall until something sticks, but it for sure isn't going to be good quality or idiomatic. Why bother working to be able to say you know a language if you never bother to learn to code properly in that language. 
Another approach to this would be to provide an extension trait to `bool`. Like the [boolinator](https://github.com/DanielKeep/rust-boolinator) does.
There is a subtle difference, which is that the remove feature was adding MIR passes at the beginning of rustc pipeline. The current patch adds a plugin interface for adding MIR passes at the end of rustc pipeline. 
No, that will give a compile time error. `Animal` with unknown `FoodType` is a proper type in Scala, but it's not compatible with another `Animal` with unknown `FoodType` unless it's the same `FoodType` which is the case in `a.eat(a.getFood())`.
Not sure how I'm supposed to interpret this.
Rather than a rewrite, I'd say think of it like how bits from Servo are gradually being integrated into Gecko. SpiderMonkey isn't going to stop development in the meantime, so the best thing to hope for is that they eventually coalesce.
This plugin was only meant to reduce the prototyping effort. When this experiment would be mature enough, then we should have this discussion, to choose the best approach. So far I can think of 3 solutions: 1. Maintain it as a side-project, like miri or clippy. 2. Standardize a LIR and a plugin interface for it. 3. Add a MIR plugin interface. (less likely) 
For those who want to know what this has to do with Rust just from looking at the headline: the very first sentence of the article says this: &gt; What do ParaSail, "modern" C++ and Rust have in common? They focus on "pointer free programming" (ok, maybe Rust doesn't, but it uses similar mechanisms). In this blog post I am exploring how we can move Nim into this direction.
It looks to me that Nim really needs move-by-default. Just like about any language that is using copy semantics. Also isn't the whole "Return values are harmful" ignoring the fact that compiler can optimize them away trivially? I used to be very concerned about big return values in Rust, when I was a beginner coming from C/C++, but after I got used to it, I stopped noticing. Either something fits stack, or it goes into a box. How exactly is it being returned is implementation detail.
&gt;&gt; FOSS doesn't address control, which is another way of saying "power". &gt; Non-monoculture (multiculture?) doesn't address control either. But it does, to an extent: the existence of viable alternatives prevents power from consolidating in any one organization, which means that the usual mechanisms of competition help guard against practices that would benefit the organization at the expense of its users. This isn't necessarily a fair democracy, but it's far preferable to an autocracy (especially when the autocrat is a company for whom web browsing is only a tangential corporate concern, which includes Apple, Microsoft, and (yes) Google). And if there had to be a sole organization whose implementation determined the entire web, I'd prefer one where decisionmaking is not limited to employees; open source isn't enough. And even though a monoculture built on OSS would be the best of a bad situation, I'd still prefer a scenario where multiple (at least three) OSS projects were viably competing.
&gt; js specifically is tied quite deeply to the C++ object model I'm not seeing how; Javascript's prototypal object model is pretty distinct from C++'s. Are you thinking of the DOM?
I'm confused by the use of the word interpreter and such, but the way I read is that the native codegen is being replaced with one written in Rust. Correct? How is Rust and LLVM used at runtime in the engine in a desktop browser session? I'm confused about that part. I mean, if the codegen emits native code to inject into the JavaScript process, where is LLVM and Rust used?
It doesn't return anything so it can't be chained.
&gt; At the moment HolyJit relies on a patched version of rustc, which allow to create compiler plugins. Not sure I get this. What does this need beyond our current nightly support for compiler plugins?
Ah thanks!
&gt; the way I read is that the native codegen is being replaced with one written in Rust. I'm not sure what you mean by this, exactly. &gt; How is Rust and LLVM used at runtime in the engine in a desktop browser session? LLVM is not used by this. `rustc` is used as a library like any other library.
I linked to the diff, you can see it elsewhere in this thread. (The answer is MIR passes)
Well, I mean, this is /r/rust. 
these are sort of automatic bookmarks: https://github.com/wting/autojump https://github.com/rupa/z
Even in C++, the copy from returning a big value can be optimized away. 
Yeah but this would allow builds of every type of rust target via docker on one platform. No need to have a seperate windows vm
elinks is great cli web browser but many websites use js and don't look great in terminal. A+tab is far from best option, you can place web browser on different desktop and navigate with C+A+arrowkeys. That way you won't have to change window focus which alt+tab does. You can go hardcore and completely separate your cli and gui work by running two different environments in two ttys. One reserved for let's say i3 for terminal work and another for GUI stuff under KDE or Openbox. Overhead won't be big, and switching from one tty to another is pretty fast although not as sleek like desktop switching.
Writing a paranoid Cargo.toml would solve this problem, yes, but that's annoying. I personally provide cargo install for my binaries, but if it breaks then I don't worry about it.
&gt; I'm not sure what you mean by this, exactly. JIT involves emitting native code, like the codegen in LLVM does for different ISAs (AARCH64, AMD64). My reading of the post is that the codegen written in C++ has been rewritten in Rust and in the process of a rewrite made easier to extend/maintain. &gt; LLVM is not used by this. rustc is used as a library like any other library. rustc is used to build the experimental JIT engine which becomes part of the JavaScript engine. This is at development/build time. The question is about the part where it says Rust generates the native code, instead of maintaining snippets of assembly. This would imply that rustc and therefore LLVM will be part of the JavaScript engine in order for it to emit native code. I feel like the blog post isn't written unambiguously for someone who isn't intimately familiar with the project.
Ah I see, thanks! &gt; My reading of the post is that the codegen written in C++ has been rewritten in Rust Yes. &gt; and in the process of a rewrite made easier to extend/maintain. So, to be clear, what's easier to extend/maintain here is "a jit" not "rust's codgen". This is because (in my understanding) the JIT and the interpreter are maintained separately; this lets you generate the JIT from the interpreter. So it's easier to extend because well, you just extend the interpreter. It also means you know that correctness is good, because they come from the same source; with them being separate, drift is always a possibility. &gt; The question is about the part where it says Rust generates the native code, instead of maintaining snippets of assembly. This would imply that rustc and therefore LLVM will be part of the JavaScript engine in order for it to emit native code. Not *quite*. This takes rust source code, runs it through `rustc`, and generates MIR, and then does its own codegen from MIR. So LLVM isn't actually invovled. &gt; I feel like the blog post isn't written unambiguously for someone who isn't intimately familiar with the project. That is true; the readme of the repo is much better in this regard.
I use intellij, and it's great.
This looks interesting and shares some similarities with the language that I'm currently working on. (It's nowhere near done, so don't ask for an example.) The fact that I'm designing it as a functional language means I can make a few more optimizations at the cost severely limiting the programmer.
Is it really? IntelliJ's Rust plugin seems to be better. I don't know if I did something wrong, but I've just installed VSCode and the official RLS plugin and I noticed some things: - Autocomplete seems to be almost text based. On IntelliJ it knows about the scope of things (and types, it seems). - Code navigation (go to definition) didn't work for me. - The RLS crashes sometimes. - Can't use the usual command to run the program (Ctrl+F5). We have to use Run Task and choose the `cargo run` task Do I need to install any other Rust plugins?
VS Code with RLS.
I was perusing one of the examples and noticed that you have non-JS driven syntax highlighting using pulldown-cmark and syntect! That is something I've been meaning to do in one of my projects, but never had the time to figure out. Your code will be quite helpful. Thank you!
As a note, C++ solved this problem in 2011 with move semantics and rvalue references. So its been solved for years, and C++11 is the minimal modern C++ standard.
One sentence... I was expecting a comparison or something, this looks more like just a move to get more views.
I mostly use VSCode, but keep IntelliJ close. IntelliJ can make sense of deep tokio-futures chains, showing types all the way down.
That’s not my experience when making heavy use of futures, streams and sinks. IntelliJ seems to really grok the code.
* Autocomplete should work from all crates in the namespace, like when you type :: anywhere it will present you all the root level types and modules. * Goto defs are finicky. They don't go to modules and renaming modules / reexports break them. Unmodified types usually pass through fine though, so if *nothing* works... * Yeah, its finicky. RLS really likes to crash on broken macros, especially recursive ones. One crate of particular humor is Keat's Jsonwebtoken crate - I haven't checked in two months but a while back the RLS infinte looped on a recursive macro until it poisoned itself. * I have no idea about this, I always have a terminal open on the site I run commands in. If it doesn't have integrated project management that is a bit of an oversight. You may not need to install other plugins, but do make sure you have the Rust (rls) extension, not the Rust Language Server or Rust Language Support ones. There are three different Rust extensions out and about but the Rust (rls) one is supposed to supplant the others.
Maybe, but it does lend further credence to my old prophecy that within ten years all systems languages will have move semantics and borrow checkers. :P
[Not according to Chandler Carruth.](https://www.youtube.com/watch?v=fHNmRkzxHWs&amp;feature=youtu.be&amp;t=1934)
&gt; Not quite. This takes rust source code, runs it through rustc, and generates MIR, and then does its own codegen from MIR. So LLVM isn't actually invovled. So rustc is used to generate the JIT which is sourced from the interpreter, in order to write it once. Correct? Then, what we get is the same old JIT which generates native code out of pre-defined snippets like before, no rust or llvm needed in the JS engine. Correct? It would be fair to assume LLVM will be involved in the final engine as a requirement since JavaScriptCore has been doing exactly this, albeit they are free to link in the parts of LLVM they need without having to bundle `opt` and such binaries, especially because using the API directly is faster than spawning the binaries each time you want to use LLVM to generate code from JS.
? Windows docker containers don't magically run under a Linux kernel. There would definitely be a VM in there somewhere.
["Creating Instances From Other Instances With Struct Update Syntax"](https://doc.rust-lang.org/book/second-edition/ch05-01-defining-structs.html#creating-instances-from-other-instances-with-struct-update-syntax)
While I'm talking about Cargo, does anybody know how to change the source directory if I want to have all of the Rust source code in its own directory without having to move the whole crate tree into its own directory?
This is called struct update syntax. - [First edition](https://doc.rust-lang.org/book/first-edition/structs.html#update-syntax) - [Second edition](https://doc.rust-lang.org/book/second-edition/ch05-01-defining-structs.html#creating-instances-from-other-instances-with-struct-update-syntax)
Nevermind, I read the README and things are much clearer on what it actually is.
just in time?
I believe those edge cases were fixed in C++17 http://en.cppreference.com/w/cpp/language/copy_elision
Afair, he just means that in this particular case this optimization doesn't apply. 
&gt; There has never been a real browser engine monoculture, except maybe Trident Chrome is getting dangerously close. Developers regularly target Chrome exclusively, or just wait for bug reports from other browsers. And from the other direction, Opera switched to Blink, Electron has no real competition, and the vast majority of mobile browsers are just wrappers around Blink or WebKit.
Working for a large corporation has given me amazing abilities in re-stating the obvious.
Sorry I didn't mean to disrupt anyone. I meant, if even after I study, I'm unable to learn the correct way, I'll come back. I know I haven't studied, and the program I've shown is literally my first program in Rust and is almost entirely me just messing around and experimenting. I only read the bare minimum to scrape things together, and I've come here to ask how to learn Rust properly, as I realized I was going about it incorrectly. I really didn't want to come here to, "vent," but people asked about the code, and I supplied them with it, and I would like to empathize that the code isn't clean at all, and I know that, and that's because it's just an experimental battle ground of spaghetti.
Yeah, I don't have much memory management languages under my belt, and I need to start using more effective methods. And while I did use those functions in LISP, I didn't use them nearly as often as I should have. If this was a serious program and not me experimenting and trying to learn the language (see all those commented lines on the bottom?) I would clean it up way more and you wouldn't see so much spaghetti. I've begun reading the book. Thanks for your input.
Thanks for the example, but I tried something similar in my first implementation, and I got the same result as I currently do, and in an attempt to debug or figure out what was happening, I just started throwing lets at everything. The source I gave, if I remember correctly, is the result of me trying to debug what was happening. 
It will be interesting to see where Nim goes, and Swift is taking similar steps too. Though it's not clear to many existing languages will actually fully pursue safety to the same degree as Rust. It certainly seems like going forward though it will be the static paradigm, with the dynamic world moving towards whatever that black magic jit stuff is. Just think about combining the two together!
I wrote this a while ago exactly for this purpose and I'm really satisfied with it tbh https://github.com/zakkor/shortcut
Why have a special `from_bool` method. Could you not implement into `std::convert::From&lt;bool&gt;` for `Outcome` instead? Which would, by proxy, cause `std::convert::Into&lt;Outcome&gt;` for `bool`.
Don't know if one already exists, but there's probably a way to write a macro that could generate both versions of some given code.
Just for completeness, the standard library seems to always just provide both, see for example https://doc.rust-lang.org/std/collections/struct.HashMap.html#method.get_mut
Are you a beginner? If so this may be helpful... https://github.com/cis198-2016s/homework?files=1
Cite or you are just back dating your awesomeness.
New to rust but not new to programming. I'll check it out, thanks.
``` macro_rules! same_code { ( $x:expr ) =&gt; { match $x { None =&gt; None, Some(ptr) =&gt; if ptr.is_null() { None } else { Some(*ptr) } } } } ``` I guess? I haven't tested it though.
I suggest asking /u/pmeunier if he'd be interested in using it for ThruSSH and/or if ThruSSH already has one.
This post is a good read: https://www.reddit.com/r/rust/comments/5i63se/abstracting_over_mutability/
Have you seen the Servo logo? (Yes, I know that it predates the meme)
Macros are quite tricky to get right. Happy to take a look at more code.
Did the servo logo contain a Shibe before Doge was a meme?
I was referring to a comment on here (https://www.reddit.com/r/rust/comments/6ujdir/slug/dlt9jmz), but it rereading it, it seems like I misunderstood it.
I wrote [this monstrosity](https://github.com/haptics-nri/nri/blob/2f2570e1f153efa022353913b3aeb53e50aa853a/crates/utils/src/lib.rs#L262-L278), used [like this](https://github.com/haptics-nri/nri/blob/2f2570e1f153efa022353913b3aeb53e50aa853a/crates/utils/src/lib.rs#L343-L366). For the code in the OP it would be const_and_mut! { [ $next:ident =&gt; next/next_mut, ] pub fn $next(self: cm!(&amp;Self), height: usize) -&gt; Option&lt;cm!(*Node&lt;K&gt;)&gt; { match self.forward_.get(height) { None =&gt; None, Some(ptr) =&gt; if ptr.is_null() { None } else { Some(*ptr) } } } }
There was also a [talk at CPPCon](https://youtu.be/PNRju6_yn3o) this year on "the nightmare of move semantics" as well.
It's usually used for `Thing { foo: "bar", ..Default::default() }` when Thing implements Default.
&gt; This has to be seen from the users perspective: the non-monoculture enables you to browse the web with a client that isn't built by Google. I could still browse the web with a client that isn't built by Google if all clients were using WebKit.
I see a problem with Chrome, but no problem with Blink or WebKit.
I could do that but I still wouldn't be sure of dependencies' dependencies as you mention. Rather than worrying about some non-deterministic build, I prefer to just compile it myself so it's guaranteed to work. 
Vendors could be forced by competition laws (they already are to some extend, still lots of room for improvements).
I still think that multiple browsers should exist, I just don't see how each one reimplementing a browser engine really helps. The important decisions (e.g. including EME) could still be handeld differently even when using the same engine.
This reads like a copypasta.
I prefer fd-find because it's Rust. It's a command not TUI though.
Huge work!!!
[This one](https://marketplace.visualstudio.com/items?itemName=rust-lang.rust)?
I can confirm that the Servo project doesn’t officially have a logo. The Servo Doge was made as a joke, I think initially for the twitter avatar. And yes, very much based on the Doge meme. But we’ve since started using it as an application icon, and it’s become an unofficial logo.
&gt; W3 is a standards body that is democratically controlled. I’ve been involved with W3C for several years. There is nothing democratic about its governance. The only form of voting it has is among representatives of its Members (who are companies and other legal entities, not individuals). And even then The Director has ultimate decision power.
AF = Amazingly Friendly?
Then post the original simpler code that wasn't working. Having other look at the code that you yourself see as a mess that should be expressable in a much more succinct manner isn't very productive.
&gt;A OpenSSL binding will of course provide all I need. But OpenSSL... Does the OpenSSL binding support libreSSL?
Can I get an example? :D (I am genuinely interested, not just trolling)
Haven't used IntelliJ, vs code is ok but Emacs is my preferred editor. Needs Melpa plugins though
Try /r/playrust
I would note that RVO is still NOT a silver bullet. The first big issue is that as any optimization it's unreliable at the best of times; there is desperate need for a syntax which would force a compile-time error if RVO is not applicable (and ideally, the compiler would point out *why*). Secondly, even when RVO kicks in, it's still not a home run. RVO doesn't let you reuse memory buffers, whereas out-parameters do. Consider: int main() { int sum = 0; for (std::string line; getline(std::cin, line);) { auto [a, b, c] = parse(line); sum =+ a; } std::cout &lt;&lt; sum &lt;&lt; "\n"; } At some point the loop will reach a steady rhythm where the inner buffer of `line` has grown enough to accommodate all lines. This means that after a warm-up sequence *there are no further memory allocations*. Contrast this with the hypothetical: int main() { int sum = 0; while (std::string line = getline(std::cin); cin) { auto [a, b, c] = parse(line); sum =+ a; } std::cout &lt;&lt; sum &lt;&lt; "\n"; } Here, at each and every iteration, a new `line` is allocated. Meaning `malloc` + `free`. It's bound to be quite slower.
Do your priorities and needs exactly align with Google’s, now and forever? If not, your long-term options in a Blink monoculture world are “tough shit”, “fork Blink and hope it catches on with other devs and/or that you can keep up with Google’s patches alone”, and some variation on “build a new engine from scratch”. Two of those end the monoculture if they succeed, but history shows they both take years to bear fruit. Some OSS fans talk about forks like they are the magical pixie dust of democracy, but LibreOffice took basicallly every OO.o developer (including every company but Oracle) jumping ship together and the only successful OSS browser engine forks were Apple forking KHTML and Google forking WebKit. There is a resource cost to creating and maintaining a fork and getting it to succeed. That’s why successful forks have had lots of resources from the get-go. The resources didn’t meritocratically (that may be a new word) seek out the best fork, they were put where they were wanted by people with the power to do so. Corporations with deep pockets have a massive advantage, even in OSS utopia. It’s no accident that 3/4 of successful browser engines are built by three of the largest software companies in the world. The fourth is built by the wholly owned subsidiary of a plucky little non-profit, and I’d much rather they keep doing what they do instead of rolling over for Google.
See http://robert.ocallahan.org/2013/02/and-then-there-were-three.html I should elaborate on my last point in that post. When developers have to test in multiple browser engines, they can't treat the bugs of one engine as "correct behavior". Thus, multiple engines with significant market share reduce the occurrence of browser bugs being treated as de facto standards. This means that browser vendors are more likely to be able to fix their bugs without breaking sites, which means improved browser implementations and a less quirky Web platform for developers. To put it in reverse: the more Chromium/Blink has a monopoly, the more likely it is that sites rely on Chromium/Blink bugs, thus the harder it is for the Chrome team to fix engine bugs without breaking sites, thus the more unfixable cruft accumulates in their code and the more unfixable quirks are baked into the Web platform.
I tried both. I tend to prefer IntelliJ rust plugin.
Nice work. I only have one question (surprise): &gt; Tests with big files showed that memory mapping page by page is faster despite its overhead. One reason is that the other solution does not launch the scanner right from the start: **the operating system reads the whole data in memory before giving the control back to the calling program.** This does not only consume a lot of memory but also holds back the scanners when the program starts. This is why the solution Memory mapping page by page was selected: it reads only very few memory pages into memory and the scanner can start their work much earlier. Really? I thought (naively) that mmap'ing a large file would only ever pull into physical memory the pages of the file that were actually accessed? 
The technology sounds cool but I worry that this is a very implementation-oriented ... and complicated ... approach to designing type inference which will make it hard to specify exactly which programs are valid in Rust. It will also be hard to understand why inference fails, when it fails. It will be very hard to implement an alternative Rust compiler, and by extension to evolve the main Rust compiler. Do other people worry about this or am I barking up the wrong tree?
&gt; The methods `String` would inherit from `Collection`, where similar to higher-level string algorithms, have the right semantics. For example, grapheme-wise `lexicographicalCompare`, `elementsEqual`, and application of `flatMap` with case-conversion, produce the same results one would expect from whole-string ordering comparison, equality comparison, and case-conversion, respectively. I am surprised that applying `flatMap` with case-conversion on a per grapheme basis would yield the same result as case-converting a whole `String`. Some languages have graphemes that are to be lowered differently depending on their surroundings. For example, [in Greek](https://en.wikipedia.org/wiki/Greek_alphabet#cite_note-nicholas_finalsigma-16): &gt; The letter sigma ⟨Σ⟩ has two different lowercase forms, ⟨σ⟩ and ⟨ς⟩, with ⟨ς⟩ being used in word-final position and ⟨σ⟩ elsewhere. And I do not see how a grapheme-wise `flatMap` would perform this conversion correctly.
how could i read registry values from regedit in Windows?!
&gt; I worry that this is a very implementation-oriented ... and complicated ... approach to designing type inference which will make it hard to specify exactly which programs are valid in Rust "All programs for which the SLG algorithm produces a successful output are valid Rust programs". Obviously, it isn't this simple, but my point is that this uses an algorithm for type inference. As long as we keep the number of hacks in the algorithm low, this might make Rust way easier to specify. &gt; It will be very hard to implement an alternative Rust compiler, and by extension to evolve the main Rust compiler. The algorithm is published. Alternative compilers will just get the paper and follow it, or what am I missing? Chalk is also a normal Rust library; alternative compilers can just use it if they don't want to reimplement the algorithm from the paper. 
AFAICT this isn't about defining which programs are valid Rust, just about how to check the validity of code given the existing rules. How hard it is to understand why inference will still be determined by how good the error messages are, although I suppose this might influence how easy / hard it is to produce good error messages. I also don't see how having something like this changes the difficulty of creating an alternative Rust compiler. You don't have to implement the exact same constraint solving strategy `rustc` does, you just need to find the correct solutions. (I would say same solutions as `rustc`, but of course every software has bugs)
Thanks Brian! This looks awesome. Parsing OpenSSH keys is quite painful, because there seems to be lots of different formats and encryption algorithm, and this crate is a cool step in the right direction. Looks like this would be cool inside a "auth_publickey" handler of Thrussh's server trait: https://docs.rs/thrussh/0.16.2/thrussh/server/trait.Handler.html#method.auth_publickey However, the `sshkeys` crate would need to either: 1. be a contribution to `thrussh-keys` instead (I'm happy to share ownership of `thrussh-keys`). 2. use keys from `thrussh` and `thrussh-keys`, which would not restrict you much, and would share the code review efforts from the community. By the way, Paul Colomiets wrote another crate in late 2016 to parse some SSH keys, see https://github.com/tailhook/ssh-keys.
omg. Does this work inside an `impl` block?
Odd that it isn't planned to merge upstream. Seems best to have renderer configurable
Chrome uses Blink, so a problem with Chrome *is* a problem with Blink. And Blink forked from WebKit recently enough that virtually the same problems apply there as well.
[rust-learning](https://github.com/ctjhoa/rust-learning) is what you looking for
It should, macros can output impl-items.
I'll add that.
This is awesome!
Whoa, this is... really nice. TIL!
Yea, the other thing is if you are on the nightly toolchain both compiler updates and rls updates through rustup can break the extension a lot. Some weeks the gotos are perfect, some weeks they don't work at all.
From witnessing the discussions, the main argument brought for choosing [gecko-media](https://github.com/servo/gecko-media) over something written from scratch (using [rust-media](https://github.com/pcwalton/rust-media) or gstreamer as a backend) was that gecko-media has a far less buggy MSE (Media Source Extensions) support than the other rendering engines. Starting from scratch would likely require a big effort to reach that status and until then it would mean giving up that competitive advantage provided that servo one day maybe wants to leave the research project stage. Given that both for gstreamer and for gecko-media the main used decoders are still written in memory unsafe languages, it definitely is an issue, but from my own experience I know that getting Rust rewrites done that have feature and performance parity with native C is very hard to do for decoders. Often they are optimized very well, and often the Rust language is not your friend e.g. when it comes to eliminating bounds checks on arrays (iterators are not an option because often the access patterns are highly customized).
If I was Mozilla I would not want GStreamer either. It exists for so many years already and it's still a mess. Every time I tried using it, it failed in some way that was impossible to understand as a user. Elements don't want to connect for some reason or they connect and can't start playing. Also who knows what kind of nasty security issues plague that mountain of C code. 
There's also a blurb about it in the reference https://doc.rust-lang.org/beta/reference/expressions/struct-expr.html
In this case, you can easily make both call a helper function: fn next_internal(&amp;self, height: usize) -&gt; Option&lt;*mut Node&lt;K&gt;&gt; { self.forward_.get(height).and_then(|ptr| { if ptr.is_null() { None } else { Some(*ptr) } }) } pub fn next(&amp;self, height: usize) -&gt; Option&lt;*const Node&lt;K&gt;&gt; { self.next_internal(height).map(|x| x as *const Node&lt;K&gt;) } pub fn next_mut(&amp;mut self, height: usize) -&gt; Option&lt;*mut Node&lt;K&gt;&gt; { self.next_internal(height) } 
While it wouldn't compile right now (because nothing does), my plans include something like. raw :: Box a -&gt; Ptr a -- unsafe, possibly intrinsic from_raw :: Ptr a -&gt; Box a -- unsafe, reverse of raw raw_call :: (a -&gt; b) -&gt; Ptr a -&gt; Ptr b -&gt; Ptr b -- unsafe, compiler builtin. map_box :: (a -&gt; a) -&gt; Box a -&gt; Box a map_box f b = let (p, r) = clone (raw b) in from_raw (raw_call f p r) `raw_call` gives explicit RVO. The plan is to make all functions take a return pointer argument. This allows map_box to avoid deallocating and have the transform function place the return value directly in the existing memory. The explicit `clone` call might be temporary, it will probably to more friendly to insert them implicitly like Rust's Copy, though raw pointers may be made explicit anyways. the whole thing would efectively compile to: fn map_box&lt;T, F: Fn(*T, *mut T)&gt;(f: *F, in: *Box&lt;T&gt;, out: *mut Box&lt;T&gt;) { unsafe { let p = in.into_raw() ; let r = p.clone() as *mut T; let new_r = f(p, r) // new_r has same address as r (and p). *out = Box::from_raw(new_r) } } That said, nothing is final. While I am aliasing the pointers for the call, the function argument and return pointers should be the only pointers that could be aliased. In addition, ignoring TCO, fact would look something like fact acc n = case n of 0 -&gt; acc -- if doesn't work here, because the comparison (might) consume n, if it doesn't, it didn't get consumed in the base case. n -&gt; let (n1, n2) = clone n in fact (acc * n1, n2 - 1) -- clone might be added automatically. compiling to fn fact(acc: *int, in: *int, out *mut int) { if *in == 0 { *out = *acc; } else { let n_2 = n.clone(); let tmp = n2 - 1; let tmp_acc = acc * n; fact(&amp;tmp_acc, &amp;tmp, out); } } That's before TCO, I might implement TCO such that it reuses the initial pointers rather than values. Since the parameters are by reference as well, I can pipe the pointers directly to sub calls just like tail calls. I'm far from implementing any of this right now. I just managed to get type inference working with rudimentary overload of function application: ((+) 5) isn't an `Int -&gt; Int`, it's a `Int -&gt; Int [Int]` (a closure with a captured Int.)
I think you meant to post this on /r/playrust bud. This subreddit is about the [Rust programming language](https://www.rust-lang.org/en-US/) not the [game](https://rust.facepunch.com/).
Oh sorry bro I’ve never been on this sub Reddit. My bad 
Cool ok. That explains why I couldn't get it to compile. It's still workable but only half way one can split inherent `impl` blocks, but the split is visible in the docs. I'll definitely come back to this macro and try to apply it in other places.
Its okay, I am sure this happens all the time. Kinda like people walking into /r/trees to post about actual trees lol.
/r/playrust
It's not too terrible to stuff an entire impl in the macro, IMO, since you can create as many bindings as you need. However it could be modified to make things easier, maybe by interleaving bindings with items.
I think that having a whole block inside a macro is a no-go anyway. I can see how useful it would be to reuse the same bindings, that pays off. But at the same time, the error messages for macros are so bad it's just not worth it to put "all" code inside a macro.
Another possibility is to split it up, like this: const_and_mut! { foo =&gt; [ /* bindings */ ] /* item */ } impl Whatever { foo!(); } 
/u/nmatsakis - as you seem to be enjoying a progressively-deeper dive into logic programming, I suspect you might enjoy this paper [Constraint Handling Rules — What Else?](https://arxiv.org/abs/1701.02668) It's a brief introduction to the state of research into the programming language CHR, a logic programming language with several VERY nice properties: - Powerful: CHR is Turing-complete. This is a prerequisite to represent Rust's type system. - Manageable: A well-founded termination can very often be found for a given program in CHR. - Convenient: If a CHR program terminates, there's a decidable test for confluence, and if a CHR program is _confluent_ then it gives an _online, anytime_ algorithm for free. In an online algorithm, you can feed in more data incrementally - and in an anytime algorithm, you can pause and resume it at will, incrementally generating output. - Designed for embedding: CHR is more properly CHR(L), where L is a host language. Implementations exist where L is Prolog, C, C++, Java, Haskell, Javascript... - Efficient: There's a proof that any algorithm implementable efficiently in the random-access memory model can be implemented equally efficiently in CHR, via a bidirectional reduction between existing implementation techniques of the CHR abstract machine in the RAM model, and an implementation of the RAM model in CHR. - Parallelizable: CHR programs naturally admit parallel implementations, and parallel evaluators have been implemented. - Optimizable: CHR has decidable operational equivalence for confluent programs; as a result, one can show that an optimization has no semantic effect on such a program. - Usable: To quote the paper: &gt; CHR has been used for such diverse applications as type system design for Haskell, time tabling, optimal sender placement, computational linguistics, spatio-temporal reasoning, verification, semantic web reasoning, data mining and computational linguistics. Successful commercial application include financial services, network design, mould design, robot vehicle control, enterprise applications and software verification
I will admit I'm impressed by how fast this website is, by far it's probably fastest website I've used. Good job on it :).
- [CIS 198: Rust Programming - University of Pennsylvania](http://cis198-2016s.github.io/schedule/) - Not all but best collection of resources to learn Rust [Rust Anthology Master List](https://github.com/brson/rust-anthology/blob/master/master-list.md) - [Programming Rust by Jason Orendorff, Jim Blandy](https://www.safaribooksonline.com/library/view/programming-rust/9781491927274/)
You can see if the [winreg](https://crates.io/crates/winreg) crate works for you.
Nah, please don't make me go digging through my old HN comments. :P
Maybe I'm just blind, but why does this not compile? struct Foo(i32, i32); fn try_match(foo: &amp;mut Box&lt;Foo&gt;) { match **foo { Foo(ref mut a, ref mut b) =&gt; {} } } [Playground link](https://play.rust-lang.org/?gist=5da5d8877430ff592d8c93ebfcb1c1b3&amp;version=stable)
I think wasm is going to be the best fit for places where Flash would've been used previously. I can also see people wanting to opt out of the DOM/CSS model entirely and build their own GUI toolkits with custom, imperitive layout that isn't going to change from browser to browser. They just draw pixels to a canvas in their own custom way. This would imply things like 2D drawing and animation frameworks would be key, along with gui toolkits. Maybe even having a backend for 3D stuff like gfx.
After the [previous blog post](https://redd.it/7312zm), Lambda3 released a podcast episode talking a bit about Rust in portuguese. I hope you enjoy it (:
Associated types are not required to be `Sized`, but are by default (like other generic arguments). You can specify them to be possible Unsized: trait Trait { type Associated: ?Sized; fn foo(&amp;self, a: &amp;&lt;Self as Trait&gt;::Associated); } impl Trait for u8 { type Associated = [u8]; fn foo(&amp;self, _: &amp;[u8]) {} } though of course it then follows that they are submitted to all the limitations of possibly Unsized types, such as having to be taken by reference not value, ...
Maybe /u/Gankro can give us some insight as to whether Swift's string manifesto has any lessons that Rust ought to learn from.
Sounds interesting. Is the project on github, too? Explicit RVO sounds like a great idea, it's always a lot of mess in C++. Implementing tail-call optimizations must be interesting, since Rust doesn't have them. Functional programming + Rust is a really interesting combination
Partial borrows don't work through `Box`.
Thanks for clarifying! I didn't want to write anything about the reason because I wasn't involved in these discussions and just got a "no" without much explanation on IRC.
Indeed, this works: struct Foo(i32, i32); fn try_match(foo: &amp;mut Box&lt;Foo&gt;) { let foo2 = &amp;mut **foo; match *foo2 { Foo(ref mut a, ref mut b) =&gt; {} } } That kinda sucks.
&gt; The algorithm is published. Alternative compilers will just get the paper and follow it, or what am I missing? I don't know the specifics of this case, but not all papers are created equal, nor are the algorithms within. The algorithm might be difficult to independently implement due inherent complexity of the algorithm, or because the paper omits some details. The different implementations also might produce different results due some minor implementation details. So it is not enough to have a published algorithm; care must be taken to make sure the description is both sufficiently clear and completely unambiguous in any way.
It’s fun to listen to a language I do not understand. There were a few words I could understand. I heard “monomorphization” once.
[/r/playrust](https://reddit.com/r/playrust)
I think you wanted to post this in /r/playrust.
It's not so bad, [try using `as_mut`](https://play.rust-lang.org/?gist=35571c7fb1e13797d296e52992651bbf&amp;version=stable)
Seeing as how common this mistake is, I'm tempted to say "another one bites the dust" as this thread is deleted sooner or later. 
How do people keep making this mistake?
It's not the same person every time so it will continue to happen but with lower and lower frequency until the interest for the game rust fades out. 
Because people type in "rust" into the subreddit when clicking "submit a text post" and don't pay any attention. Reddit's UX is bad.
idk, it's broadly too late to change what Rust does
Not yet, because it doesn't compile anything yet. Everything I put in the previous post is some ideas for how it will end up. I would only say "explicit" RVO in so far as it would be explicit in the spec (if and when it's finalised) or explicit in unsafe code like the map_box. Otherwise it would happen unconditionally for all functions. Unless of course I get to that point and realise it doesn't work, then everything could change I just pass everything by value in LLVM like a normal programming language.
I can see the purpose of `&amp;mut T` (modify or replace but don't take ownership), `Box&lt;T&gt;` (must take ownership) and `&amp;mut Option&lt;Box&lt;T&gt;&gt;` (may take ownership). `&amp;mut Box&lt;T&gt;` allows you to take ownership, but only if you replace the old box with a new one. Doesn't seem very useful. So unless you have a very specific reason otherwise, the best fix is most likely to use `&amp;mut T` instead of `&amp;mut Box&lt;T&gt;` in the function signature. There is a deref coercion that will allow the function to be called with a `&amp;mut Box&lt;T&gt;` argument.
I'm a big fan of posts like https://www.reddit.com/r/rust/comments/77ss20/chalk_meets_slg/ and thought perhaps somebody would my tiny library for automated theorem proving interesting.
Depends on your requirements. * `num_bigint` works on stable and does not have unsafe code. * `ramp`uses unsafe and does not work on stable Rust, but it is faster. * `rust-gmp` and `rug` bind to the state-of-the-art bigint implementation in C (GMP). They are the fastest and have the most features. You probably want to use one of those.
Thanks. There was a bit more to it that was confusing me. This helps!
Thanks, I'll come back to this after reading some more on Cow.
That section talks about machine processed text. So maybe they are talking about case conversion that's just A-Z &lt;-&gt; a-z.
In a sense rust "inherits" from a collection class, in our case, Vec. Better word is derive I guess here
Right but who said that means we can't still uselessly self-flagellate and pine for Rust 2.0?
If you read the blog post it's pretty clear that different algorithmic choices accept different sets of programs.
This kind of thinking makes using computers PITA for everyone born outside US and UK. Less so nowadays than 10 years ago, but it's still not perfect.
Personally, I found `rug` a lot more user-friendly while also providing more features.
&gt; I thought (naively) that mmap'ing a large file would only ever pull into physical memory the pages of the file that were actually accessed? That's my experience on Linux; the mmap call is fast even with a cold cache, following accesses (or mlock calls) cause major page faults.
I would google “rust macros”. That’s how I learned about them. They’re also in the official rust book 2. There’s tons of material online for this feature and this approach works for basically all languages and languages features/aspects. If there’s no third party explanation, no reference docs, and no first party explanation, you infer from context, interface names/options/arguments or read the source code itself.
https://danielkeep.github.io/tlborm/
[The Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/index.html) helped me get a very good understanding of how they work.
You couldn't steer the direction of WebKit effectively though. Google Chrome is _not_ using WebKit, but a fork, by the way, for those reasons.
&gt; when the Jit hits the *TurboFan* FTFY
What do you mean? Same way you learn to understand anything else, like the tax code, or the will of the Old Ones who lie beneath. Just let the voices in your head explain them to you. All m͢ake͞s̀ ͏per̸fec͘t ̴se͘ns͢e͘ tơ ͜me.̴..
thanks, i will give it a try
You want /r/playrust
We are a bunch of programmers here, sorry
Maybe there should be a 'Rewrite Rust the Game in Rust the Language' campaign. I hear it has terrible memory issues.
thank u very much.
[Original post from January.](https://reddit.com/r/rust/comments/5oknaf/forensictool_development_with_rust/)
You are correct in that it the algorithm specification has to be good, but the GP was arguing that having type checking specified as an algorithm wasn't the best path forward. If you are a language implementor, type checking specified as an algorithm + an implementation of this algorithm in a reusable library like Chalk that you can test against is as good as it gets. AFAIK Rust is the only production-quality language that aims to provide this. 
I'm using rayon for the first time. I'm trying to `.skip(1)` on `Lines`, which seems to work great for `std::str::Lines`, but I *cannot* figure out how to do similar with `rayon::str::Lines`. There is a `Skip` struct in Rayon, but there is no method on `Lines`, and I don't know how to access the underlying `ParallelIterator`, if that's even possible, to be able to call `.skip()` on.
ended up doing a `.lines().skip(1).collect::&lt;Vec&lt;&amp;str&gt;&gt;().into_par_iter()`, but I feel like there has to be a cleaner way.
&gt; They’re also in the official rust book 2. Are they? There link [here](https://doc.rust-lang.org/book/second-edition/) is greyed out, and I can't find a file for them [here](https://github.com/rust-lang/book/tree/master/second-edition/src).
I would recommend the book "Programming Rust" by Jim Blandy and Jason Orendorff, which (among other things) contains a detailed chapter on macros. The book is not yet out, but a DRM-free ebook can already be purchased in pre-release from O'Reilly. The pre-release is not yet finalized, but all the content is already there.
`Rc` is not for cyclic structures, it is for shared ownership of an object. In regular Rust, you tell the compiler in advance who owns an object, and everyone else must borrow it - which is also visible at compile time. `Rc` allows you to create a "communal" object without a real owner. Each owner of an `Rc` may request a temporary borrow of the object. As always, the mutable borrow is exclusive and multiple shared borrows are allowed, but both properties are checked at run-time. To handle cyclic structures, forget about `Rc` and use something like [vec-arena](https://crates.io/crates/vec-arena) instead.
You want to recruit Rust players, not programmers. Try /r/playrust
You want /r/playrust
struct UciInputStream&lt;T: Read&gt; { stream: T }
Thanks. Whenever I searched for stuff I got results for generic traits rather than bound generics.
Pretty cool. Proofers are definitely fun! :-) The example from the readme did not give me a good idea of how this works. I think it may be because the proof seems a bit trivial. Looking at the code, it looks like this should be able to locate the murderer given enough constraints (and solve a murder mystery). The example seems to just prove that shooting a gun implies aiming (or did I misunderstand it?). Perhaps you could include a second snippet from the groceries example if it is not too much work?
Good idea. Thanks for the feedback!
Maybe? I mean, they do say "grapheme-wise" in the paragraph.
There's also a Rust FZF clone: https://github.com/lotabout/skim.
Last weekend we had our annual family secret santa name drawing. As always, it took about 10 attempts at drawing the names until nobody had his/her own name or the partner's name. I then turned to technology and looked for a website or app to resolve this issue. But either the system would not support additional constraints, or it would require a registration/login, or would only send the results out via e-mail. I wanted something that we could use on the spot. Writing this library took only few hours but could potentially save millions of families from anger and hate, just because the last person drew his own name from the basket for the 10th time!
Well I mean I live outside the US / UK but I don't think you meant Australia. Joking aside though there's a demand for these functions in protocols that were initially case insensitive for ASCII. I think only a sadist would want to extend that case insensitivity to unicode.
&gt; How much does it matter that Rust isn't formally specified? It's a [vast topic](https://en.wikipedia.org/wiki/Programming_language_specification). First of all, I'd like to distinguish between: 1. a specification, or standard, 2. a formal specification. To the best of my knowledge, only **very** few languages even have a formal specification (2). This is important because only a formal specification can be "proven" in rigorous sense. C++ is an example of a language with a standard (ISO, with red tape and many brains at work) but not formal specification. This regularly lead to ambiguities in the specifications, and diverging compiler behavior. Actually, the C and C++ languages can be somewhat infamous for the amount of **Undefined** and **Unspecified** behaviors that they have; such as the order in which arguments are evaluated before a function call being explicitly unspecified, leading GCC to evaluate right-to-left and MSVC left-or-right (yay for portability). Formally, evaluation of the arguments could even be interleaved... Back to Rust. The practical implications for the lack of formal specification: - the safety of the Rust language cannot be proven, - the safety of `unsafe` library functions cannot be proven either. Rust claims to allow writing safe code, but it's only backed by experience, not theory (not fully, at least). It may well be that a soundness hole is discovered in the future whose patching will be backward incompatible... or even impossible. The practical implications for the lack of standard: - it's more difficult to write an alternative Rust compiler or standard library, - when writing an alternative Rust compiler or standard library, it's unclear whether some behaviors are coincidental or are intentional. A standard would put the spot light on ambiguities, and help clarification. Now, I will note that the *absence* of such probably helps speeding up the development of the language. It's not all black or white. &gt; So essentially, I'm just curious regarding what the thought is on the choice between using Rust or using C or some other language for implementing things that are particularly security sensitive, but not to the point that using rigorous C development practices and so on like is used in Aerospace comes into play. I would note that for cryptography, often times both Rust and C are actually too high-level. Protecting against timing attacks often require directly writing primitive blocks in assembly to ensure that all execution paths have exactly the same latency. Other than that, I would pick Rust over C anytime from a security standpoint^1 . C may have a standard, but it does not have a formal specification, and it's full of holes (~200 instances of Undefined Behavior in its standard!). The C compiler implementations are generally claimed to be more mature, but: - proprietary C compilers provided for embedded platforms often only implement a subset of the standard, and are far from being bug-free, - even mature toolchains such as GCC and Clang have bug-fixes related to C in their release notes at every single major release (at least); and of course so do the various implementations of libc (remember [gethostname](https://tools.cisco.com/security/center/content/CiscoSecurityAdvisory/cisco-sa-20150128-ghost)?). Thus experience suggests that the rustc toolchain and standard library can perfectly hold its own in this domain. It may not be perfect, but it does not appear to be significantly less trustworthy. Of course, as mentioned, it has not been proven either... ^1 *On the other hand, C could be required for portability reasons.*
NB C has CompCert
The last person can't pull their own name if nobody else has pulled their own name prior It's simple enough to have people toss their name back into the hat if they pull their own name, having them check their result immediately after pulling
No worries and thanks for sharing ;-)
&gt; (interestingly that struct compiles without warning but fails if I ever try to construct one) That's because the type is valid, but impossible to (directly) construct. A `Read` has no statically-defined size, so you can't ever have a value of it *except* behind a pointer. To put it another way: Java only has one kind of pointer, so it can assume that when you say `Read` you mean `GcPtr&lt;Read&gt;`. Rust has many kinds of pointers, so you have to specify which one you want. It's also because traits in Rust **are not** the same thing as interfaces in Java. If that's how you're thinking about it, you need to go back to the book and re-read the sections on traits with a clear mind.
Have you considered a tiling window manager like i3 and either a browser designed with vimlike bindings (qutebrowser) or extensions with like cvim for chrome or saka key for Firefox?
My point was more that this is never valid is it? So should it perhaps fail to compile when you have a trait used this way?
To quote myself: &gt; ... the type is valid, ... You just can't directly create it. It's like how `[i32]` is a valid type, but you can't directly create one because the compiler can't deal with types of indeterminate size. Instead, you create a `[i32; N]` for some fixed `N`, put it behind a pointer of some sort, then cast from (say) `&amp;[i32; N]` to `&amp;[i32]`. Something similar for traits.
Thanks you cleared things up substantially for me. I will continue on with my plan to use Rust for security related programming then, and am happy with the understanding you've helped me to reach, because I like using Rust but was somewhat uneasy due to there being a camp that suggests staying with C, and my lack of sufficient background knowledge to come to an education decision regarding whether Rust could hold its own with C or other languages in this paradigm. 
I don't know why you're downvoted, but I'm using the same thing and would like better Vim plugins for Rust.
Yeah it's not written yet. Maybe they were thinking of the first edition? https://doc.rust-lang.org/book/first-edition/macros.html
&gt; The last person can't pull their own name if nobody else has pulled their own name prior That's not correct. If you have A, B, C, D and E, then you can end up with A&lt;-&gt;B, C&lt;-&gt;D, and person E will draw his/her own name. &gt; It's simple enough to have people toss their name back into the hat if they pull their own name, having them check their result immediately after pulling. If you have 8 people, and the 7th person draws his/her own name and puts the paper back into the hat, then you know that the 8th person will get it. If it happens earlier, the information leak is less bad, but you still know for sure who *doesn't* get that person's name.
Missed a chance to name it "_Secret Rusta_"...
`Box&lt;Read&gt;` is the correct pointer type. You do not need to unbox it; you can call any method of `Read` on it directly. Rust doesn't have automatic boxing, so you'd make the constructor generic over the `R: Read` type. The trait bounded generic also works, `OciInput&lt;R: Read&gt;`, but results in a lot of duplicated codegen because now *everything* that touches `OciInput` must be monomorphized. Oops. Java doesn't have this pitfall because it has a runtime compiler and can choose between static and dynamic dispatch at runtime. The constructor probably should wrap the input stream in `BufReader` however. A parser typically makes many small reads and those could result in many system calls, depending on how `Read` is implemented.
The voices: &gt; Read the little book of macros.... Okay now try writing a simple one..... Now look at a complex macro in a crate and try to figure out what's going on...... See if you can reproduce that..... &gt; &gt; [Boo](https://i.imgur.com/w2XLWbX.gif)
I've gone for the generic version right now. Might change that choice later. Already ran into the need to do *impl &lt;T: Read&gt; UciInputStream&lt;T&gt;*. Good thought on the BufReader, UCI passes lines of commands rather than chars and right now I'm parsing it byte by byte. Though I think I'd rather that be handled by what is being passed in rather than wrapping everything in a BufReader (I believe BufReader implements Read).
Slides are available here, including all the skipped ones: https://coaxion.net/~slomo/talks/gstconf-2017/Rust.pdf
It seems like you might want to check out the [Rust FFI Omnibus](http://jakegoulding.com/rust-ffi-omnibus/) for starters. The [Rust FFI Guide](https://michael-f-bryan.github.io/rust-ffi-guide/) is small but has some useful tips as well. For what it’s worth, I just integrated rust into my large Objective-C app and have no regrets!
Did you encounter any particularly difficult problems? I'm particularly interested in how you are meant to deal with error handling, seeing as passing around `Result&lt;T, E&gt;` now requires boxing everything and adding helper methods to access their contents.
&gt; the safety of the Rust language cannot be proven, My understanding is that the borrow checker is a formally verified concept, it's just that implementations are not formally verified. So we have soundness holes in rustc, not soundness issues in borrow checking as a concept.
I see that rust std-lib string api wont chang anytime soon and that extended unicode functionality was deliberately removed. But what would you (or anyone else here) think about a third party string library that is more high level, application focused and more akin to what swift does?
`Box&lt;Trait&gt;` and `&amp;Trait` (trait objects) provide *dynamic dispatch*. Basically, they can point to any object that implements the trait, but because that means the locations of the method implementations can vary at runtime (with the type), any method call made through them must be resolved at runtime via a list of pointers (a [vtable](https://en.wikipedia.org/wiki/Virtual_method_table)). A definition with a type parameter is instead just a sort of template for the compiler. Every method call can be resolved statically because the compiler generates a variation of the method/struct/enum for each set of types you apply to it. That means faster function calls but longer compile times and larger executables.
General note about video playback: Pleaseplease make sure that one kind of thing works perfectly, flawlessly, every time, without lag: Displaying the UI, stopping/pausing the video, exiting fullscreen, and closing the containing tab. I guess the only real reason that Android ships with a youtube app is that Chrome isn't any better at any of that than Firefox, either...
This gives a 403 forbidden on my end.
One step toward your goal is the [independent compiler implementation mrustc](https://github.com/thepowersgang/mrustc) written in C++.
Lol love this: `dhl::simply_deliver().unwrap();`
Until there's proof that it cannot be proven, your guess is as good as mine.
[Documentation](https://doc.rust-lang.org/std/macro.stringify.html) for the `stringify!` macro says that it accepts the `tt` (token tree argument): ``` macro_rules! stringify { ($t:tt) =&gt; { ... }; } ``` This then works for examples like `stringify!(1 + 1);` However if I write my own macro with the same argument: ``` macro_rules! my_macro { ($t:tt) =&gt; { unimplemented!() }; } ``` and then try to use it like `stringify`: `my_macro!(1 + 1);`, it fails to compile: ``` Standard Error Compiling playground v0.0.1 (file:///playground) error: no rules expected the token `+` --&gt; src/main.rs:6:17 | 6 | my_macro!(1 + 1); | ^ ``` Why?
The chapter on [generics](https://doc.rust-lang.org/book/second-edition/ch10-00-generics.html) in the second book, and [trait objects](https://doc.rust-lang.org/book/first-edition/trait-objects.html) in the first should tell you what you need to know.
&gt; such as the order in which arguments are evaluated before a function call being explicitly unspecified Is that actually important? I can't think of a situation where that changes a situation.
Thanks, fixed!
As far as error handling goes, when embedding Rust in other languages, you’re basically having Rust act like C. This means that you’re limited to using C-style error handling idioms in your interface (which you would be anyways if you were implementing your C library in C). One really annoying thing for me was catching panics at the FFI boundary involved a lot of boilerplate. I would recommend looking into how panics in FFI, ‘catch_unwind!’, and panic safety work now, so you can design your library with this in mind.
func(a++, a++) or similar I guess
Awesome! If you're open to a few quick notes: - Input seems laggy, not sure if it's because of the animation of the 'bubbling squares' but I feel like my LEFT/RIGHT keys can't seem to fire off in time to hit the row I'm trying to hit - Try using `requestAnimationFrame` instead of `setTimeout` - You can control the FPS by tracking the last request time and current time to ensure you're hitting a consistent rate (60, 30, etc) Overall great stuff though!
Hm, can I ask what sort of environments you hang out in? In the environments I'm familiar with I rarely hear anyone caring about formal specification, in any language. When you say "I notice there seems to be some animosity related to the topic", do you mean on this forum?
Unique pointers and borrowing were not invented for rust (preexisting in research and in research languages like Cyclone), and do have proofs associated with them. Additionally, here has been work on proving the rust safe memory model safe: ftp://ftp.cs.washington.edu/tr/2015/03/UW-CSE-15-03-02.pdf But this is supposed to be more safety of a rust-like memory model than a proof of safety of rust's actual memory model. I feel like this can be summarized as: - Is borrow checking safe? Proven - Is rust-like borrow checking safe? Proven, though only AFAIK in a masters' thesis that may never have been through peer review. - Is rust borrow checking safe? Can't do, requires formalizing rust's borrow checking (which is what chalk is aiming at, I suppose) - Is rustc borrow checking proven safe? Not proven (Wanna learn coq?)
Thought it’s for Go lang because of war*go*
&gt; To install, use npm with Node 6 or newer^1 &gt; ^1 The original version was written in Rust, but the multiple-minute compile times got a bit annoying, especially in CI. And if you’re writing WebAssembly, you probably have Node installed already. Compile times strike again!
No I don't mean on this forum, I just wanted to make clear that I'm not trying to start a language war in case my post would be perceived that way. I hang out for example in #privacytech on oftc where I defended Rust to some extent a few days ago, however people brought up concerns including the ones I mentioned in this thread. I also know an older fellow who is quite competent with computers having advanced education and experience in the field, who said it is a principle for a language to be specified and that the lack of Rust being specified is greatly concerning. Earlier today I found a site where people were expressing similar concerns, however I can't find it immediately now. My perception is that some people who may be established C programmers have some animosity toward Rust, and I just think of for example how people always say there are flame wars between like emacs and vi and it is frowned on to do this on much of the Internet, and wanted to make clear that I am not looking for a flame war regarding Rust versus C but rather am interested in strictly technical information regarding the matter to help me reach an educated decision given my lack of computer science background in this area. 
Yeah, this is basically the state that I was expecting/ remembered. Thanks.
Doesn't the same logic apply to car**go**?
Just to expand on my previous reply a little more, I mean it is natural even for people to be somewhat defensive regarding a language they have spent much time learning. For example, as I said, I've spent over 800 hours now studying and learning Rust, so of course with that time investment I like thinking that Rust will be a successful and highly useful language for what I intend to use it for, because even though I've gotten much secondary benefit such as learning the functional paradigm and substantially improving my general programming knowledge, my intention is to know a language that will be useful in itself primarily, with the numerous secondary benefits being icing on this primary cake. So it makes sense as well in my opinion, for people with careers and even many thousands of hours of C experience, which I also have thousands of hours of C experience actually, to feel uneasy about a new language that is sort of making a claim to some territory that has traditionally been in the area of the language they have mastered, and brings up feelings of having to start over to an extent in the learning process, and sort of evening the playing field with newcomers. This is what I want to avoid, feelings like this, which I perceive are clouding some of the discussion I've had related to Rust in various areas. Ultimately, I just want objective knowledge that isn't biased by the investment that people have into the language they're using, is what I tried to convey. 
Crashes my WebView in Relay app (Reddit client) on Android, after clicking the button.
There is ongoing work in that regard, e.g. [Ralf Jung et al](https://www.mpi-sws.org/~dreyer/papers/rustbelt/paper.pdf) verified the memory safety of various usages of unsafe code in the standard library against a formal specification of Rust's memory model.
`tt`is a *single* token or a tree surrounded by brace, bracket, or parenthesis. So for example, this invocation should work: my_macro!((1 + 1)); If you want multiple tokens without brackets, you can use repetition in your rules: macro_rules! my_macro { ($($t:tt)*) =&gt; { $($t)* }; } I don't know why the stringify source works that way, perhaps because it is built-in to the compiler?
&gt; I rarely hear anyone caring about formal specification There seems to be a trend lately, of people using the term "formal specification" when they just mean "standardization".
/r/playrust
Thanks for the link. Does it also cover macros 2.0, procedural macros, or whatever those are called these days?
I like the way you write! you should pack in this code stuff and negotiate world peace and cooperation.
&gt; They’re also in the official rust book 2 I read both books. It is present in the first edition only, the chapter is too short since macros could use an entire book on their own.
I can stand the voices as long as I'm not parsing HTML with regex.
Obviously it's a cat written in Go /s
I think, the lag is probably because I needed a way to make sure snake can't turn "backwards" between ticks (if you're interested, it's the function in snake.rs, starting from line 33). The implementation could use some work, though this is purely for learning purposes. Of the second tip - Thanks, I didn't know of that!
You don't pass around Result into C. You write explicit C interface functions that translate between the two worlds and expose an interface that is entirely C like. If something fails return a NULL or an integer that is some error code. FFI Omnibus pretty much has all the info required.
What goes into formal verification? Are things proved through a language like agda or coq or is it more by hand?
One thing I did was define a JSON interface. This way I can easily spawn a web server and interface with HTTP and I can also have a very simple C interface to the lib. Only three function: start, close and cmd that receives a json string and replies a json string. Obviously not a high performance interface but easy and good enough for lots of use cases. 
There's actually a neat physical solution if you don't need additional constraints https://youtu.be/5kC5k5QBqcc
thanks for letting us know!
I use [decimal](https://crates.io/crates/decimal). 
It's possible to avoid all the into's when calling the library code with the into trait and generics. http://hermanradtke.com/2015/05/06/creating-a-rust-function-that-accepts-string-or-str.html Note that for the function that takes multiple strings you should need to make a separate generic type for each, since the inputs could be mixed between &amp;str and String. There is a fair way to do a Secret Santa without a computer or redrawing. But for that the only constraint is avoiding drawing your own name, though maybe it could be extended somehow. https://www.youtube.com/watch?v=5kC5k5QBqcc
This is great! Thank you so much for making something so complex/annoying so much simpler.
Thanks for this. Added a branch to my (webpack-boilerplate)[https://github.com/bananenmannfrau/webpack-boilerplate/tree/web-assembly] to up and running quickly on projects. 
This is UB IIRC. A simple example is `func(f(), g())`where f and g have side effects like writing data.
I see, I didn't know that was UB. Yeah, that's probably a better example.
I would call it bad form to write something like this, c( a(), b(), ) if `a` or `b` have side effects. But it *is* legal syntax and invokes `a` `b` `c` in order.
Cool ^Please someone stop me from googling DHL WTF images with trucks in pools and DHL DeLoreans for on-time deliveries and … just top me now^
I didn't know what GStreamer is: https://en.wikipedia.org/wiki/GStreamer
Take a look at [Compcert](http://compcert.inria.fr/). It uses coq to verify a C compiler. In general it would be too tedious to manually verify a usable language
&gt; invokes `a` `b` `c` in order Isn't the parent's point that the order is implementation defined?
Yeah the audience was GStreamer developers, it didn't have to be explained
We need to prepare a little addendum with all the new stuff that has happened since tlborm! - nested macro_rules - better backtracking or less ambiguities - macro reexport
An old C compiler may do `b` `a` `c` instead. Rust shouldn't have this inconsistency.
does anyone think it's a good time to RIIR?! /s
Yeah, those macro definitions for the builtin macros are basically just documentation, and this one is wrong.
&gt; Still, I could imagine that in some narrow circumstances, especially in crates like Diesel that use traits as a complex form of meta-programming, this extra expressiveness may be of use. Yup. This actually answers some questions for me about why certain types weren't inferring when I expected them to.
Wouldn't this only work if the rlibs you were using were from the same compiler?
Done.
Some Rust advice: - you should put your tests inside a `#[cfg(test)] mod tests { ... }` block. No point in compiling unit tests when building the actual game. - your `Game` struct has all of its fields `pub`lic, but most of them could be placed behind accessors, or are not referenced at all. Some more advice, not exactly Rust specific: - I've noticed that most of your GitHub commits simply have the message `ok` or other one-worders. While you don't have to write a huge description, the commit message should be descriptive of the change.
Oh, was that Rust code? I assumed it was C
Thanks, sound advice. I guess it's better to fix them in case someone uses this as a reference
Not sure if it's wargo or emsdk doing this, but it expects /usr/bin/python to symlink to a python 2 install, which is a royal PITA cause mine symlinks to python 3 
Anywhere I can read about type macros?
Interesting! One question: Why WebDriver instead of Karma? I think of Karma as having fewer compatibility issues, and I don't see anything this test system is doing that requires WebDriver.
I think that feature is simple to explain — macros can expand in type position. They work as usual. You can see that in action in the [`Hlist!`](https://docs.rs/frunk/0.1.33/frunk/macro.Hlist.html) macro (using a capital `H` for a type I guess). 
I have done the tiling window manager in the past. I might do it again but I feel like tmux works better for me than tiling. I use vimium in my browser.
To clarify, because these terms are often confused, when you say "formal specification" do you mean an implementation that is proven correct by an executable mathematical proof (a.k.a. formal validation, like CompCert), or do you mean a specification document that has been ratified by a standards body, like ANSI C or ISO C++? As for avoiding flame wars, we're with you on that one: see rule #4 in the sidebar, "no zealotry". :)
I don't understand the hate either. It's an honest answer and it is my preferred development environment. Have you tried racer in vim yet?
Doesn't the comma act as a sequence point, or is it different within function evaluation? 
It seems the snake turns when the key is released rather than pressed which is surprising.
The comma *operator* is a sequence point, but this code does not use the comma operator.
Either. The expression syntax looks very similar on the surface.
My understanding is that Python’s recommendation is that “python” should always be 2, and “python3” should always be 3. Some distros, like Arch, don’t follow that of course...
When used as an operator comma guarantees left-to-right evaluation (except if it is overloaded, then I'm pretty sure it is treated as a regular function call). Within function evaluation the comma is a separator (as well as in a macro or initializer list), not an operator, and doesn't guarantee an execution order. In fact, until C++17 the order of evaluation of all expressions within arguments to a function call were unspecified. So in the case of `function_call(std::unique_ptr&lt;int&gt;(new int()), bar());` It is possible for `new int()` to be evaluated, then `bar()`, and finally `std::unique_ptr&lt;int&gt;(...)`. This can introduce subtle errors in the case where `bar()` throws because `delete` will never be called on the allocated `int`. As of C++17 it is guaranteed that each argument's sub-expressions will be fully evaluated at once. But the order of evaluation of the arguments are still unspecified.
I think the `nom` crate has some cool macro tricks I learnt from
Ah I'm looking for arbitrary precision integers. Thanks for the answer though! May come in handy.
Thanks!
Well, no. You're telling your **car** to *go* xD 
There is some confusion out there as to what "formal" means in the world of specifications; this is not really a matter of right or wrong meanings but rather a collision of contextual meanings where not everyone is even aware that the other context has a different meaning for the word! Unfortunately, this is not an uncommon occurrence in the world of computing, which often brings together long-lived domain specialties with their own jargons. So, in the world of international specifications, "formal" often carries the common meaning of "official" or "according to the blessed procedures" where the procedures are the ones agreed upon by the official standards body. In that sense, something like C becomes formalized by ANSI or ISO standards being accepted by a recognized standards body. In the world of logic, however, the word "formal" has a completely different meaning. A formal system in logic is one in which the rules of the system depend only on the *form* of sentences written in it; in other words, the system is a purely syntactic one and the rules can be performed on valid sentences without making reference to any *meaning* the sentences might be given. Formalizing a statement in logic means to translate the statement into one of these formal systems, which (assuming the formal system chosen is consistent) allows proofs to be done that can be mechanically checked. Most languages have at least a partially-formalized specification in this second sense; the specification of syntax in terms of BNF grammar is an example of formal specification. The use of BNF for Algol 60's syntax specification was so helpful that the working group okayed the effort to attempt a more comprehensive formal specification in Algol 68; this ended up being somewhat less useful and is probably responsible in part for souring the greater programming language community on the idea of formal language specifications in general. There is an example of a more recent language with a formal specification, however, in the Standard ML language. The effort was published in a book, which is now available here: http://sml-family.org/sml97-defn.pdf That book and retrospectives on the effort are worth reading for anyone interested in formal specification of programming languages. It helped that ML was born out of a system for automation of formal reasoning, and most of the developers thus had familiarity with the concepts involved and some level of facility with using the tools and ideas together. Even so, it was not a simple task to complete it! So, how does Rust stack up in these two areas of "formal" definition? It clearly doesn't have a definition that's either completely formalized in the logical sense or in the authoritative sense, but it *does* have greater aspirations in both areas than most other new languages that have come along in the last 10 years or so. The RFC process shows a clear intent to have the language development governed by the sort of open, transparent process that standards bodies typically follow and to make it possible to develop independent implementations. And there are ongoing efforts to formalize simplified models of the language, which at this point are probably of more practical use than attempts to formalize the entire language. What Rust really lacks right now is a complete specification document aimed towards implementation maintainers. You can sort of piece together what one might contain from the user-oriented documentation on the official website along with accepted RFCs, but it's the sort of thing that would take a tremendous amount of work to put together and maintain and would not be of as much immediate benefit to anyone as user-level documentation or implementation work. It will be more critical to have one when/if multiple implementations appear. Although industry people may say that they value official specifications, I think that's just a proxy for what they really value, which is having a large community who has already done a lot of work with the language and found many of the areas where understanding of the language is fuzzy and got them ironed out. I think Rust is really promising in this regard due to the fact that it's sponsored by Mozilla specifically for web browser development, which is one of the most technically challenging areas of systems programming today. It's a great crucible for quickly maturing a community's understanding of how a language really works in demanding circumstances.
Really? That's super annoying if true.
&gt; I would note that for cryptography, often times both Rust and C are actually too high-level. Protecting against timing attacks often require directly writing primitive blocks in assembly to ensure that all execution paths have exactly the same latency. Some cryptographers have had success recently in writing constant time code in pure Rust. I'm very excited about the possibility of using crypto primitives written in an accessible language instead of hand-rolled assembly. https://www.youtube.com/watch?v=tH_pdYyqK4o
I agree. I haven't used it for years, but when I did it barely worked at all and crashed all the time. Not confidence-inspiring. I'd probably use VLC's renderer since it is very good and also is in the process of at least partially being rewritten in Rust. Video codecs are one of the areas that should benefit the most from Rust. Lots of bugs come from C codecs.
Python added that recommendation after Arch made the change, iirc. It shouldn't matter though, the scripts/tools should explicitly state a python version imo.
Technically yes, but python2 always ought to exist also, and we're getting to the point where distros are planning to switch the default (that's the plan for Ubuntu 18.04 LTS AFAIK).
&gt; It's possible to avoid all the into's when calling the library code with the into trait and generics. I really wish we could just do this: fn new (name: impl Into&lt;String&gt;) -&gt; Person { 
I wonder if we'll see any interop a la Cargo crates in Meson builds.
I'd assume, that you're being downvoted because OP asks for an IDE, which is linux isn't in the commonly agreed upon definition of an IDE. You're describing a development environment, not an IDE. Thus your answer is not really relevant.
You want /r/playrust. [Crates](https://crates.io/) here hold no guns.
Wrong subreddit \^\^ This is programming, not gaming ;)
&gt; I would note that for cryptography, often times both Rust and C are actually too high-level. Protecting against timing attacks often require directly writing primitive blocks in assembly to ensure that all execution paths have exactly the same latency. It's worth noting that even then, you can't 100% "ensure" this. This is something you can _improve_ on, but basically never reach perfection. Assembly is also "too high level"; e.g. x86 is actually a high level language that CPUs JIT to a RISC instruction set (the actual instruction set of x86 CPUs). You can't really control that. Similarly cache based attacks also exist (you can have _some_ mitigation here). Someone recently described a branch prediction priming based attack; where you prime the branch prediction in an attacker process so that the target process takes the wrong branch in such a way that isn't constant time anymore. I recently had the privilege of listening to Ian Goldberg rant about this. I was aware of the JIT thing but never had thought of it in this context and it was pretty enlightening :) (This doesn't mean that constant time is hopeless; but it does mean that you should be wary of considering your work "done")
Wow, it took me until &gt; I have a level 2 workbench and 500+ scrap sitting around... to realize that it is about the game :D
Great work on `sha3` crate! Are you planning to add cSHAKE ParalledHash{128, 256}? ![sha3 speed](https://keccak.team/images/KeccakOnSkylake.png) https://keccak.team/2017/is_sha3_slow.html I'm keeping an eye on [Keyak](https://keccak.team/keyak.html)'s progress in CAESAR, as it'd be great to use [KangarooTwelve](https://keccak.team/kangarootwelve.html) for performance on existing devices, at least until SHA3-512 hardware implementations become ubiquitous. 
Rewrite it in Dost! So /u/jpakkane has brought up some criticism at the way a hypothetical language called "Dost" is managing things (which is very similar to Rust). Some key points of criticism that also affect Rust: * Statically linking all dependencies leads to a blow up in computation time if you want to update one dependency and it triggers an update of many downstream dependencies. * Often there is not much care on smaller target platforms, with the language developers saying in a very nice way that they don't care about the platform. * Multiple versions of some dependency may end up being used in bigger projects. * Some projects depend on Github repositories with questionable license declarations. For the first point, I'd say that its actually a valid problem. You shouldn't have to re-compile an image decoder and an UI library for every Rust based UI application in your operating system. Right now cargo does precisely that however. The Rust compiler itself does support dynamic linking, its more of a cargo issue. There is a compiler component to the issue as well however, which is generics. Often a library contains generic APIs. Only a part of the library can actually be compiled into a dynamic library, the part where the values of the generic parameters are known beforehand. The remainder of the library has to be stored as MIR or another form of IR without being actual native code. Even your image decoder might be affected by this, if your functionality is abstracted over a `Read` trait. The solution to the generics problem (which doesn't just affect Rust, it also affects C++ and any other language that has generics) is not easy. Maybe create a distro-wide cache for various instances for the generic parameters, so that `ImageDecoder&lt;std::fs::File&gt;` only gets compiled once. But of course once closures are involved, you can't really do anything. For the second point, Rust does have a [large list](https://forge.rust-lang.org/platform-support.html) of targets it supports. Of course, C has a much better story on those platforms, which might have to do with the fact that when you develop an ISA, the first thing you do is to create gcc patches to support the ISA. I'd say this also has something to do with demand. For most users of Rust its enough to have x86_64 and popular arm targets. For the targets where many people do care about (wasm) its planned to create better support. For the third point, servo actually has a policy of only having one version of a dependency at a time, with only few exceptions. However, not every project has such a policy, and I'd guess having multiple projects in your ecosystem with such a policy could create tricky situation. The alternative is making your code to be compatible with multiple versions of the upstream library, but this makes the developer experience worse IMO. For the fourth point, this is obviously an issue due to the sheer amount of crates involved. C projects usually have less dependencies in their transitive closure, so its less of an issue. However, crates.io has two protections built in: First, all uploads of crates with git dependencies are forbidden to crates.io. Second, Cargo has a formal way of specifying the license, and crates.io disallows any license that is not inside a whitelist. That check is however not very thorough, as it still allows crates with "custom" licenses to be published (that might not fulfill the four freedoms; [example here](https://crates.io/crates/text_io); essentially crates.io allows publishing of proprietary software), and cargo also doesn't ship with any tooling to check for license incompatibilities (the [actual feature being rejected](https://github.com/rust-lang/cargo/issues/4252#issuecomment-325841604) by the cargo team). Fortunately there is [cargo lichking](https://github.com/Nemo157/cargo-lichking) to do some of that checking via a third party tool.
Specifically, this is an implementation of the fastest algorithm identified in "[Memory Layouts for Binary Search V2](http://cglab.ca/~morin/misc/arraylayout-v2/)" (paper [here](https://arxiv.org/abs/1509.05053)). It is used to solve the problem: given n comparable data items in an array, A, of length n, and a query value, x, quickly find the smallest value in A that is greater than or equal to x. Rust today only provides `Vec::binary_search` and `BTreeSet::range`, both of which are slower than the proposed solution.
I guess I don't understand what IDE should mean. The 'I' is for integrated, and as I explained my environment is quite integrated. One terminal and everything is keyboard driven.
Honestly `/usr/env python` is the best since that'll find the first executable in the path that matches python. Might be the system python, might be a venv. Unless it's a script that'll be run by the system and not the user, then specifically declaring the system python is better. 
Awesome it's about time! Emscripten is such a pain in the arse to get working.
&gt; but python2 always ought to exist also Python2 does not exist for the vast majority of environments.
Wait you need Python for compiling Rust to WASM using a C++ compiler? Whaaa?
Such a shame too. One the big reasons I'm interested in Wasm is to get away from Node.
FYI, there's also [cargo-web](https://github.com/koute/cargo-web) which is somewhat similar.
Could you add documentation somewhere (like maybe readme.md) that explains how this works? Some of us are not familiar with WebAssembly. For example, here are some questions I have: * What do I need to install to build this? Obviously a rust toolchain, but what else? * How big is the generated js? Is it just bundle.js? I tried a similar thing with Unity once and it was pretty huge (I forget the exact size) just for hello world. This seems to be leaner, perhaps due to the magic of web assembly. * How hard would it be to use Pixi.js instead of Vue? Like, would I need a binding in Rust or would it just be a matter of dropping it in? Thanks!
No, it doesn't cover those. They are easier to write because they are "just" rust code.
Don't forget `:vis` obsoleting [this chapter](https://danielkeep.github.io/tlborm/book/pat-visibility.html) entirely!
There's actually a footnote about type macros [here](https://danielkeep.github.io/tlborm/book/mbe-syn-macros-in-the-ast.html). I don't think there's too much to explain -- it's more surprising that they _weren't_ supported, IMO.
Correct. Since the ABI is not stable, artifacts must be generated for each compiler version you want to support. You can use `{{rustc_short_version}}` on the end users' side to seemlessly import these different artifacts based on the compiler version.
* Your construction benchmarks are biased toward sorted vectors. You are always putting the numbers you want in a vector first, and with `BTreeSet` and `OrderedCollection` you are then using the vector as a source for the actual collection, but with sorted vectors you are sorting the vector itself! This means `BTreeSet` and `OrderedCollection` benchmarks need to allocate their memory while sorted vectors don't need to allocate anything and just use the pre-allocated vector you put your data in. * Why are you dropping the construction result? Is this part of the bench? It's better to return the result from the benchmark's closure to make sure nothing gets optimized away - see https://doc.rust-lang.org/1.12.1/book/benchmark-tests.html#gotcha-optimizations. (though with these numbers there may not be much optimizations...) * Same for searches - return the search result from the benchmark closure.
I just pushed some changes to the benchmarks to make them more comparable with https://github.com/rust-lang/rust/pull/45333. In particular, the `search_*` benchmarks now use `test::black_box` to ensure they don't get optimized away. You are entirely correct about the sorted vector benchmark having an advantage in not having to allocate. I'm not terribly concerned about that here, as I mainly wanted to measure the kind of order of magnitude up-front cost you'd have to do. The search is what matters most in practice.
Yes, I plan on writing a simple guide how this is set up in readme
Yep.. and nodejs too :)
:(
&gt; More conretely concretely
Thanks! Will fix.
I have a fix coming soon that uses `black_box` for the construction results too :)
The emscripten toolchain requires Python2, I have been meaning to submit a patch to detect that it is running under Python3 and relaunch under 2. I think `python` should forever be Python 2, nothing but pyrrhic in winning that battle. `python3` would be the new one.
Ask Redhat about system Python.
Maybe [this](https://graydon2.dreamwidth.org/1839.html) (admittedly outdated) blog post by Graydon Hoare about formal specification and how it relates to Rust is worth a look
Just tried it, it worked like a charm. Kudos
More a Debian guy myself. I do know some Python folks at red hat though
Yea the whole Emscripten toolchain is honestly a complete mess. There are some efforts to build a proper standard cross compilation toolchain for it, but it's not really usable.
That paper mentions conditional mov asm ops as one of the main reasons there is a speedup. How do you ensure that condition mov instructions are used?
It's complicated. [Relevant PEP](https://www.python.org/dev/peps/pep-0394/)
This is why one distinguishes between case conversions for printing (aka. Python's `str.lower`) and for comparisons (aka. Python's `str.casefold`): "ΣΣ".lower() #&gt;&gt;&gt; 'σς' "ΣΣ".casefold() #&gt;&gt;&gt; 'σσ' I don't know Swift, but I expect it also supports both.
Thanks. I would appreciate it. I saw there is another post here on /r/rust about using WebAssembly so now I at least know how to get started, but I still look forward to your documentation as well.
In C, evaluation order is not only unspecified, but can happen interspersed if the compiler chooses. Therefore, in something like `f(a(), b())` side effects of both functions `a` and `b` can happen intermixed with each other. (At least as far as I understand, correct me if I am wrong).
Thank you! I don't currently plan to implement it myself, as work on RustCrypto ciphers is higher priority to me for now, but I happily accept [contributions](https://github.com/RustCrypto/hashes/issues/1)!
You should try running clippy on it. Format it first: cargo +nightly install --force rustfmt-nightly cargo +nightly fmt Run clippy: cargo +nightly install --force clippy cargo +nightly clippy Follow any advice it has.
Right, just needs an update.
You should read the rust book. It helped me to understand the language much better
Is this different than a `levelorder_vector` ? - [Cache-friendly binary search](http://bannalia.blogspot.de/2015/06/cache-friendly-binary-search.html) - [Traversing a linearized tree](http://bannalia.blogspot.de/2015/06/traversing-linearized-tree.html) - [Traversing a linearized tree: cache friendliness analysis](http://bannalia.blogspot.de/2015/06/traversing-linearized-tree-cache.html) 
&gt; The Rust compiler itself does support dynamic linking, its more of a cargo issue. No. Compiling Rust for C works via cheddar and such. Compiling C for Rust works (via ffi and bindgen). Compiling Rust for Rust [does absolutely not work right now](https://users.rust-lang.org/t/compiling-a-rust-library-as-a-dynamic-library-then-using-it-from-rust-projects/13055) - and this is the problem the presenter wanted to adress, I think. Rust does not have an ABI so it cannot support dynamic linking like C or C++. If the guy who uses your library uses a different compiler, you're out of luck. Plus, it's also a size issue, not only a compilation issue. Rust needs an ABI, then these problems could be solved. But the current stance is that "we don't want to hinder development by restricting us to an ABI". I can understand it, but tbh - other languages almost regularly break their ABIs. I also understand (from a [HN thread](https://news.ycombinator.com/item?id=11879464)): &gt; The reason Rust doesn't have a defined ABI is basically that it wouldn't buy the same benefits it does in C. Specifying an ABI requires a lot of per-platform work (which the C community has already done), and, because of the importance of cross-crate inlining (all generic functions get inlined into call-sites by default), would not be sufficient to provide the benefit of in-place library updates. If you rewrite generic code in libfoo, and libbar depends on it, you can't get around recompiling libbar. And after all, the question is if dynamic libraries are worth it. The design of Rust is not to build huge, monolithic code bases (like GLib), rather to break it down and projects use only what they need to use. My opinion - in order to properly solve the static / dynamic linking problem, rust / cargo needs a method to determine whether a library is small enough to be inlined or not, ex. a crate like `num_cpus` only has one function, so it's a no-brainer to inline it. However, a library like winit or similar should be compiled into a dynamic library. Maybe the lines of code in the source repo or number of functions / generic functions would be a good metric for that, just an idea.