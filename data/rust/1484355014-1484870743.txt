I figured out the problem. The ```mod``` keyword is only used to declare modules inline and not in a separate file. Removing that fixed the issue.
That verbiage is confusing to me. 1. Why would the new abstraction render `mio` non-useful? 2. Why would it *hopefully* render it non-useful? 3. If `mio` is non-useful for anyone except `tokio-core`, then why are they two separate crates and why does `mio` exist as a separate crate? 
I'm a long-time Python developer, and I think the OP overstates the BDFL power. In just a handful of cases, a new package has come along that is so much better than the standard library that it comes into the standard library (e.g. argparse, mock, almost requests). But, for the vast majority of packages, it is reputation that determines use, and that seems to work pretty well. (The general philosophy is the module doesn't get brought into the standard library unless development is "complete".) One issue that hinders Go and Rust (and boy if you think Rust has a shitty package problem, take a look at Go) is that it is actually too easy to publish a package. There's a little bit of friction with Python, and that means that someone has to be at least a little bit committed to put something out there.
The point is I don't want invisible inference to do anything expensive. This is why, for example, assignment is move by default, and if you want to make a copy for any non trivial type, you have to manually call `.clone()` (as opposed to the compiler just inferring a clone or something). Its a pretty core part of the language philosophy.
I think the answer to all of this is that there is a trend towards a single high-level async lib (tokio), but we're at the beginning of that transition. So it's likely things will evolve such that mio is either made unnecessary by tokio or subsumed entirely, and it might be kept as a separate crate even afterwards for posterity (the namespace is already reserved).
FYI, I think the situation is now explained more clearly, targeted for Rust on http://stackoverflow.com/questions/41643335/why-dereferencing-a-null-raw-pointer-is-undefined-behaviour.
Very nice work! I look forward to reading more of these.
It's hard to tell from crates.io which crates people have rallied around. You have to do extra research, read mailing lists, forums, reddit, look at github projects, blogs etc. Or you risk using a library that the community is moving away from, or one recently abandoned. Or you risk using `mio` when you really wanted `tokio`.
/u/phayzfaustyn's response was spot-on.
Plus there are cases where people might want `mio`, but not the full `tokio` stack, like a mid-range embedded program.
Especially since every download of `tokio` is also a download of `mio`
I would disagree. The main criteria I think for inclusion is that the new library would bring more value to the rust contributors being included. This could mean the library would bring more contributors to rust, is used by the existing contributors and etc. If that's not fullfilled the library won't be maintained. Unfortunately I think it's fairly hard to encode such a thing in a checklist.
Having seen problems of this regard in Ruby, I too would not mind this. Plus `cargo new` could easily stick this in `Cargo.toml` on creation -- just use the current `rustc` version, and the user can rewind it manually if they plan on restricting themselves. What would be *really* cool, though understandable if it's deemed too much work, is if `rustc` could keep track of its own changelog, so you can continually update your own `rustc` but have it able to say "you want me to operate on syntax from this older version, so that particular syntax isn't acceptable," thus getting all the performance benefits of `rustc` updates without losing track of where syntax showed up.
What I'm saying is, this is the current criteria.
I agree 100%. I like both Python and Rust. But Python's standard library is not something that should be emulated for the exact reasons you mentioned. I would also mention that it's a goddamned pain in the ass to convince other people, even other Python users, to install a library they don't personally use. I'd much rather use PySide (a Qt implementation) to write GUIs, but we're stuck with TkInter. But at the same time, I do kind of share the author's gripes in general. But that gripe really boils down to this: Rust is still getting off the ground and still experimenting, whereas Python is 25 years old. There aren't as many standards because there hasn't been enough time, not because of any design/ecosystem flaw with crates.
Maybe we should keep the rustkell meme alive, just so that people know that they're entering new and scary territory. Honestly I feel like the Rust book needs more, self-contained tutorials. Eric Kidd posted a pretty amazing reply to someone saying that useful languages do string concatenation like `“hello, ” + “world”`, [here](http://esr.ibiblio.org/?p=7294#comment-1797783). If we could add explanations like that as early as possible into the book, people might come over their misconceptions more quickly. 
As much as I appreciate you taking the time to write a proper reply I really believe it's off-topic. I believe it's better to discuss the article itself, not the author. When it comes to the difficulties of having a mindset which differs from rusts I think it's worth keeping in mind but I'm not sure that will help when discussing this article, which seems a bit more like a rant than well founded criticism.
I consider supported compiler versions to be part of the public API, and thus subject to SemVer. My interpretation of .Y.Z releases is that they do not break existing users, except in extreme circumstances. Rust defines those circumstances as "bugs that affect memory safety" (more or less). I'd expect crates to adhere to the same standard. "I wanted to use a new language feature" is definitely not an extreme circumstance. It's always tempting to rev to the next language version, but it has to provide a benefit to your users. Don't break just to make your own life easier.
Meh they same problem existed for Java until Apache libs and other orgs arose. 
Great stuff. I'm a few episodes behind but I will eventually catch up!
You'll have to wrap the Vec in a Arc for the borrow checker to be satisfied. I think I what's happening is that is possible for the parent thread to end before the children threads' end. This causes the lifetime of the references to Vec to outlive the Vec itself AFAIK
I think the biggest thing with Python is that having a batteries-included monolithic stdlib, and having that mentality carry over to other libraries (Django and Tornado come to mind, amongst many others), leads to a smaller total number of important dependencies (the ones where making a wrong choice will lead to lots of heartache down the road). Looking at our pip-requirements vs package.json files, I can see the net effect. Python has 47 dependencies, of which maybe 10-15 are used as more than one-offs. JS has lots of heavily used dependencies, any of which would be a pain to replace (and that's despite the fact that we lean on 3rd party libraries much more on the server side than the JS side). But that's not necessarily the stdlib's problem. People could maintain curated re-export crates to group large sets of tools together, maybe taking the Rails approach of shipping a set of defaults and expecting them to work for 90%+ of people. Better search would also help cut down on total time spent searching. I'm hopeful about the experimentation that'll happen on crates.io.
`Box` being always non-null is orthogonal to dereferencing a null *raw* pointer being undefined behaviour. Rust could easily define the behaviour of dereferencing a null pointer while still retaining the ability to optimise `Option&lt;Box&lt;_&gt;&gt;` (and vice versa). That said, I don't know of any particular reason null needs to be called out specifically, rather than just it falling out of being a dangling pointer... maybe because it gives a way to construct a *guaranteed* dangling pointer, that the compiler can reason about for optimisations? Also, note that the spec saying something is undefined behaviour doesn't mean that a specific implementation can't define it, just that the spec has no opinion on what behaviour happens and portable code has to assume compilers won't handle it in a predictable way. If a specific platform has something relevant accessible at null, a compiler for it can say that dereferencing null is OK and code written for that specific platform can work with that assumption.
One option is the scoped threads in `crossbeam`: https://aturon.github.io/crossbeam-doc/crossbeam/struct.Scope.html
I definitely agree! I was surprised that libc doesn't seem to be owned by rust-lang, presumably just an oversight, so maybe /u/acrichto (and/or others who own rust-lang crates) could go over the current set to make sure everything is owned appropriately.
yeah, we're working on a second edition of this, it's currently here http://rust-lang.github.io/book/ it's not done yet. there's a whole second project as chapter 12, and we'll probably end with another.
The entire thing though, with all the attention it needs? I have _tried_ to read many parts of it multiple times as well. It seems like you need to infer a lot of information from simple toy examples, and think for yourself how it would extrapolate to non-trivial problems. The section on borrowing only contains toy examples for example, Stack Overflow has been a lot more helpful to me than the book. And although this is somewhat common, it's certainly not a good thing. Especially since that means I wasn't the first person to get stuck with the exact same problems. Maybe it could use a few data structure implementations as practical use cases. Or another example, which also made me realize I didn't know how bad my C++ was/is. Trait objects in a collection have to be wrapped in a box, which in hindsight makes sense. I was thinking in Java and had no idea why it wouldn't let me shove trait objects in there. It would'be been nice if the learning resources mentioned that excitedly somewhere, for the same reason as the string concatenation: Rust doesn't hide the memory, it just makes sure you don't abuse it. In that last case someone from the rust-beginners IRC channel was more than helpful to me. But I felt that his ~10 sentence explanation helped me get into the Rust way of thinking a lot more than the book. 
Regarding `Box` and `Option`, I ended up commenting the answer there in the same vein. I understand regarding UB, this line of thought was what made me accept [this answer an year back](http://stackoverflow.com/a/28581547/1000282), still, I see no point in special casing UB for an address. I know that in thesis implementations could look to make an specific UB _defined_, but from what I read, it seems just rare to happen (ever?) and the word UB serving solely as door open for surpring object code elimination by optimizer freaks :) Regarding _guaranteed_ dangling pointer for optimization reasoning, this can happen in two levels, the null existing (or not) as literal vs existing (or not) as stored value, which is also discussed on http://stackoverflow.com/questions/28573215/.
Nice! Glad to see a section on OOP as well, I could definitely use that. 
There are a couple of big ones. They don't handle all the tasks, so you still end up having the problem. "What parser library should I use in C++" isn't an easy question to answer. Same goes for XML. Or JSON. There are a million different libraries that come up when you google "C++ epoll library".
It's possible my understanding is wrong here, so I'd appreciate a bit more detail. I live most of my work-life in C++, so I might have remembered something in Rust incorrectly. As I know it, `extern` and `no_mangle` behave as follows: * `extern` makes a function behave as a C function. You can safely pass an `extern` fn as a callback to C code, and it will work correctly * `no_mangle` on its own isn't useful. It would cause the fn to have an unmangled name, but that fn could still be using an implementation-defined Rust calling convention. Combined with `extern` it exposes a symbol that looks like a normal C public symbol. It's also been a long time since I've read the rustonomicon, so if I mis-remembered and said something wrong here I'd like to fix it!
Two alternatives to the `Arc` mentioned in a sibling (which is the most minimal) are [`crossbeam`](https://crates.io/crates/crossbeam)'s scoped threads or [`rayon`](https://crates.io/crates/rayon). If you're doing things in parallel to pieces of the vector then the latter's parallel iterator functionality may make life very easy.
People are discussing the post because they think the points raised are worth discussion. Telling people they shouldn't have this discussion because of an ad-hominem is neither constructive nor helpful.
Oh, also, it isn't a breaking change to add/remove/upgrade dependencies that are only used internally in one's library (i.e. not reexporting anything nor using any of its types in a public signature), so the question could be still phrased as "is rustc an internal dependency or an external one?", but having it in the same "mental framework" as dependencies might simplify thinking.
Just got a chance to read this proposal - so many amazing things in here! :D
&gt; C's stdlib is basically a rubber chicken and a heap of POSIX APIs \*actual LOL\* That one's going in my quote bin.
This seems to reinforce my interpretation: * An extern fn is callable from C (and thus from hardware, in the ARM case) * Adding `no_mangle` flags the symbol as "external" to Rust, which not only disables mangling but ensure the symbol is visible outside of Rust code If there is something you think I got wrong in my previous comment and this one, please be more detailed - I'm obviously not getting what's being said, and I'd like to learn.
I'd say that's an issue to be solved by filtering on the crates.io side. If I'm even remotely representative, then trying to limit Crates.io to "mature" stuff would just cause more people to not parcel their projects out into reusable components until they *actually* have a *personal* need to reuse them. I see PyPI or Crates as a "DNS system to map names to code-hosting providers" so that I have a single location to make fixups if my relationship with GitHub ever sours and I move to BitBucket or GitLab. My stuff meant for public consumption has been on GitHub with GitHub Pages homepages and references from sites like alternativeTo for years without showing up on PyPI. (In part because the habit was built in the context of programs which depend on things like PyGTK which can't be pip-installed on Linux.) When my PyPI account was stuck in limbo for months while I tried to remember to contact someone who could force it to cough up an activation e-mail, my behaviour, *even though I should have known better*, was to be lazy and store all of my reusable components of varying degrees of maturity and testedness in the same repo and, for the small routines shared between projects, like the Python-function version of `/usr/bin/which`, just copy-paste them from project to project. I'm *still* trying to bring together the time and willpower to do the necessary busywork to correct that. That doesn't really help people if I'm the only one who knows that my big experimental, incomplete "sorta PyGTK but in the process of moving to PyQt" application contains a self-contained filename-to-title inference engine with a pretty comprehensive test suite that grew quite good due to "I have 5 minutes and thought of another heuristic or test case to add" but haven't had the will, time, and presence of mind to split it out into its own package during the last year. (Disclaimer: I've been too busy to fix certain known inference bugs, so it's not what I'd call 1.0 yet. For example "tidalis_linux_64bit" becomes "Tidalisbit" instead of "Tidalis")
I don't think that you can quite compare C and C++. Sure, C has an extremely minimal stdlib, and C++ less so but still doesn't include any kind of async I/O. But he's not really comparing to C and C++. They are well established, widely used, lots of people know them, you can buy lots of books, hire lots of engineers, buy lots of fancy tools for them, the platform libraries all use them so there's no wondering if you will need to find bindings or wrappers to make the best use of some functionality (OK, maybe outside of mobile platforms). They're established, and next generation languages like Go, Rust, and Swift are trying to convince people to have a reason to use them. If you try out Go, and get your basic example working in a few hours of study and coding, and then take a few days of coding and study in Rust and realize you don't even know how you would do the kind of async I/O you need to do and it seems like the whole ecosystem is fragmented, you might bounce off. His point isn't that Rust needs to compete with C and C++ on issues like the learning curve or other things that could cause you to bounce off; people learn these languages in school, or there's enough job demand to learn them, and enough of an existing usersbase of people who have been dealing with them and learning the ecosytem and quirks for a long time. His point is that you need to compete with Go and Swift and the like. When people are looking for the next language for a new project, but don't have a lot to go on based on an existing codebase or the need to use an existing language due to that's what your team uses, first impressions are pretty important. And for this use case, Go gives the better first impression. Now, I find Rust to be a much more interesting and robust design; but at my job, we've made significant investments in one technology over another (including hiring several of the developers) because while the other one seemed like a more robust architecture in theory, the one we chose was the one that we were able to get up and running quickly and it just worked when we tried it out.
It's also nice to see that, so far, the comments on this ESR blog post have been much more civil. At this point, I count only two comments which aren't "argument-heavy, emotion-light" and one of *those* is just a very flippant and informal way of saying "IBM's actions cast doubt on your statement".
You can totally pass `&amp;mut` around, it gets implicitly reborrowed instead of moved.
Does `rotor` not count?
I said this as a sub-comment on the last post but I think it's worth reiterating here: As a new Rust user, the thing that is missing that would be most useful to me is an introduction *to the community*. Reading the book is well and good to learn the language (well-known and well-understood deficiencies aside) but that's the only entry point that's really advertised. Beyond that dipping a toe into the community gets quickly overwhelming (a brief list of things that I saw mentioned and had a hard time pinning down exactly what they were: "the nomicon", procedural macros/macros 2.0/macros 1.1, RFCs, who the core team is). A possibility for providing a lot of this would be a section in the release notes talking about "what's next" or "this is the current state of interesting things, even if they aren't actually in this release". That would be a good anchor to refer to for context on "how real is this thing?" when you come across a discussion here/on the mailing list/on IRC.
&gt; I feel like he's missing a bunch of things in here . . . C and C++ have the exact same problem as Rust. While true, I don't think that's exactly fair to the author; he's *not* comparing rust to C or C++, he's comparing it to Go. I'm not too familiar with Go but my impression is that a lot of what he would want there is in its standard library. As you say, the rust community is working on it, but I think it's worth taking a key point from this: for those projects that _could_ be solved by either rust or Go, the stable, batteries-included nature of Go is a big selling point right now. Now for projects that _can't_ be written in Go, rust may have a leg up on C/C++ in terms of libraries.
I've always wanted a Tree of Knowledge of ~~good and evil~~ Programming. Even better would be an oracle that you could tell "I want to get this thing done" and it would say "Then you should learn all of these things!". But it seems like it would be a difficult thing to produce. Maybe with a statistical approach based on input from a large number of experts...
That's fair. I have no ideas even remotely reasonable to find a good balance between "hey guys let's actually publish some useful libraries and improve the community collection" and "goddammit the long tail of practically useless crates is long and practically useless." If the long tail is an unavoidable consequence of having the phenomenal few, well, so be it.
&gt; I've recently started the Rust::from(lang) repo I hope at some point someone writes a book along the lines of `Rust::from(none)`. It would help beginner programmers get started. And maybe when someone in /r/programming says "I'm new, which language should I learn first?" Rust will get a mention. I have yet to find a book, tutorial, presentation, etc. that doesn't at some point, and usually fairly early on, explain a Rust concept with reference to another language. It's like saying "if you want to understand this Rust feature, go and learn that other language, then come back here." Even *The Book* can't get more than half way through the "Getting Started" chapter before it uses "If you come from a C or C++ background..." to explain a concept. I'm just using that as an example, on the whole, *The book* is excellent and quite new user friendly. Personally, when I started playing with Rust I hadn't done any programming in well over a decade and that was all in Forth. And before that it had been PL1, BASIC, &amp; assembly decades before. None of those languages really prepares you for the concepts used in Rust and I would have appreciated a beginner's programming book or even a YT lecture series based on Rust. 
&gt; It's also nice to see that, so far, the comments on this ESR blog post have been much more civil. I think it will remain that way. His previous post was borderline hatefull and fueled by frustration which attracts other similarly minded people.
See my response to https://www.reddit.com/r/rust/comments/5nu1w7/rust_and_the_limits_of_swarm_design/dcend4n/ :) The problem with the Go comparison is that he's picked something that falls squarely within Go's design niche and generalizing from there. His use case was a networky app that needed to have async IO. Go is the answer there. Period. Rust could have been an answer if the async IO was optional, but it wasn't. Even if Rust does get tokio, Go is still better for this from a newcomer's POV. As someone who knows both Rust and Go I'd choose Rust for this because free speed and type safety, but Go would definitely be the easier language to do this with if you don't know either. This is never going to change. What folks forget when they say "Go has a large standard library" is that the standard library is specifically tailored (with the possible exception of the debuginfo bits, though those are probably there because the compiler needs 'em anyway) to its relatively narrow target field (networky applications). Like I mentioned in the other comment, Rust wouldn't have async IO (or XML parsing) even if it did decide to have a standard library the size of Go's. So it wouldn't have solved his problem. Go, too, has a discoverability problem outside of the stdlib. I'm sure that you would have similar issues if writing programs that are in the center of Rust's target field. I totally agree that Rust has issues here and Go does have a leg up in this space currently. I think that his post leaps to conclusions about the "swarm model" and BDFLs from a single datapoint, and also makes conclusions about what the community thinks from only a couple days of observing it.
I think in this particular case, the [author is very much alive](http://tvtropes.org/pmwiki/pmwiki.php/Main/DeathOfTheAuthor), so while it's definitely straying, I don't think we're completely out of sight of the topic. I can definitely sympathize with half the people in the article, though. I'm trying to learn Tokio and man does it hurt my brain. I'm muddling through it, but I can definitely see why people would abort.
Oh, had this page open for a while and probably should have refreshed before commenting. That comment says much better what I was trying to get at. Looks like that particular discussion point is well covered.
&gt; note: an implementation of `std::ops::Add` might be missing for `&amp;str` I thought we'd fixed the issue of the compiler suggesting you add impls to things you can't touch, but looks like we haven't. filed: https://github.com/rust-lang/rust/issues/39058 I've already filed diagnostics issues for the other ones. https://github.com/rust-lang/rust/issues/39029 is currently unassigned, willing to mentor anyone wanting to work on it!
Yep, saw that one. I've also [submitted an implementation of `ToSocketAddrs` for `String`](https://github.com/rust-lang/rust/pull/39048) which will fix this specific case, but the warning fix will help in the general case.
Oooooh neat. I know the common sentiment is against namespaces, but I *personally* would feel a lot better about publishing to crates.io if I had a GitHub-like username/crate namespace for experimental or other exploratory crates, and when I was ready to really release I'd move it up into the global namespace. Which I guess is exactly what GitHub already is, except Cargo doesn't crawl GitHub. So if I want to make something public, I would have to commit to a spot in the global namespace, which is rather irrevocable if I later decide to withdraw. Idk publishing is hard, especially when any name I pick is going to permanently (or near enough) remove that name from everyone else. Or do the opposite of my username/ and global namespace idea, and make it so that "blessed" packages get put in their own namespace, kind-of-ish like how Arch has official/, extra/, and community/ package repos? A main/ or similar prefix would be populated with components of the core distribution (libstd and all the crates behind it, the compiler and cargo crates, other things I'm forgetting about), an extra/ for "blessed" (by which I mean the de facto community standard, for things like Hyper, Tokio, Regex, and friends who aren't in the distribution but are basically peerless), and everyone else hangs out in the global namespace? To keep things on the bazaar side of the cathedral, the general-population crates might be able to say they add to, or replace, second-tier crates in extra/ and crates.io would update the second-tier crates with links to the gen-pop crates that refer to them, for visibility. I.E. if the current `nmea` crate were in extra/, and I were writing a replacement, I would publish it in the general population with something saying "This replaces crate `nmea`," and then crates.io would toss in a "see also: `nmyrrea`" under "Accessories" at first and eventually "Alternatives". And maybe if my crate were more popular than nmea, there might be a vote and we would swap places and mine would become the "blessed" crate and `nmea` would go to gen-pop. ... I can see that going downhill real quick if crate authors get overly competitive or the system gets gamed, but, idk I'm not on any language teams and I'm kind of okay with that haha.
Yea as long as you are statically linked and nobody can tell that's not breaking. But, if you were dynamically linking to a C library and internally started making use a function that didn't exist in an older version of the library it would be effectively the same situation as the rustc version dependency I think. All becomes quite a bit more "interesting" if rust ever really starts supports dynamic linking to rust shared libraries.
Please re-read Manish's statement at the top of this thread. We are here for discussing ESR's *article* and the points raised within, not for discussing about ESR.
Heh, I didn't bother filing for an impl of TSA for String because I'm not very fond of things accepting moves when they can borrow. It's against the "don't pay for what you need" philosophy, and I don't like the idea of newcomers sticking unnecessary clones in there because they didn't know it could be borrowed. But I don't feel strongly about this, on the contrary I expected the rest of the community have strong feelings about it and so I just didn't file thinking that nobody would agree with it, and even I sort of don't agree. If the libs team likes it, great!
I'm not keen on having that impl consuming the String. It will lead to more confusing errors down the line when trying to re-use the `String`. Can we `impl ToSocketAddrs for &amp;String` instead?
Thanks. :)
Of course! Coming from C++, `String/&amp;str` felt like the most natural thing, and so well thought out. Only way to immutably borrow from `std::string` is `const char *` and then you're in C territory. Once I thoroughly internalized the UTF-8 requirement, it then became a necessary fact that there should be `OsString/OsStr` as well. Dynamic languages (in which I would include Java) have encouraged the idea that one kind of string can do everything. This is a hard habit to unlearn.
It would be most cool (later in the 21st century) when `rustc` develops a bot interface, and then you could have a conversation about your errors. But I like this idea - it's a classic expert system, harvesting from the experience of engineers. But opinions are so varied that such a system might end up a confused mirror of all the perspectives possible in software development.
[removed]
btw, what happened to your github account? Looking at past discussions where you participated, it seems deleted, but apparently someone created an account under your name 28 days ago.
Ooooh, this RFC has come far! This looks like a fantastic thing to have for crates.io ^_^
Along the lines of this article: in Python, there's plenty of resources to writing good, efficient, idiomatic Python. As in, using `squares = [x**2 for x in range(10)]` as opposed to squares = [] for n in range (10): squares.append(n**2) I wish there were guides in writing idiomatic Rust. The only thing I've ever seen written on this subject is in the Book, where it says the `return` keyword isn't considered idiomatic, and it's the last bit of a function that gets returned automatically. 
I'm sorry but you simply cannot say that Rust will "*remain* a toy language". The effort that has been put into this project is visible on GitHub both in the official Rust repo and the many other open source projects using it. The reason why the stdlib does not contain whatever OP is looking for is precisely because there is a lot of thought process put into stabilization. I have the impression that OP is missing a very simple solution to the problem: Rust has a small stdlib and new crates that *may* not be maintained in 10 years, but Rust itself it definitely going to be around. So, why not simply write your own crates?
I've seen people getting hit by this regularly, and given newcomers to rust probably don't know about clippy from the start, wouldn't it be good to integrate this lint into rustc?
&gt; Has anyone brought up the idea of rating crates? Yes, many times. :) You'll see when you dig through the thread.
There I would agree. However when you understand what theory stands after each command most of them are obvious and natural. The only problem are inconsistent nomenclature for flags. However even that could be fixed as git was created as a library, not tool. And there were other "UIs" for git like easygit, but "mock" that was distrbuted together with library got popular, and now none want to waste time on something different.
&gt; This is why git merges ultimately require manual resolution I'm not claiming that files merged by Pijul will have the correct semantic. My claim is much weaker than that: I'm just claiming that our merge has algebraic properties that I used to assume about git when I started using it: - *associativity*: you can merge the commits of a branch one by one and get the same result as merging the whole branch at once. This is false in git, because 3-way merge works by optimizing a problem with non-unique solutions. Worse, git won't warn you when this it happens. - *commutativity*: two patches that don't depend on each other can be freely reordered, which allows one to do cherry-picking transparently (i.e. staying consistent with the branch one cherry-picked from). Git can do cherry-picking, but not transparently. - *inverses*: every patch/commit has a patch/commit with the opposite effect. This is true in Pijul, and true in git for most commits (although committing the opposite commit of a merge is not always totally intuitive). I'm not sure talking about algebra to describe a tool as "super intuitive" is the best approach ;-) The hope is that algebra was modeled after intuition, and these properties really are what we have in mind when we start learning a DVCS, even without knowing their names. &gt; "Pijul is git, but with slightly more caching" isn't a very compelling story. This is not what I said! I said "Pijul used as a merge algorithm in git might be inefficient without caching. Adding a cache basically amounts to using Pijul *in the same way you would use git*", i.e. thinking in terms of commits, branches and merges. And, as I wrote here before, you could use Pijul following git good practices, but then you'd definitely be better off staying with git, as the tooling is much better. The point of Pijul is to allow you to work without good practices.
I disagree with you for a number of reasons (I realize you won't see this, but hopefully it can make sense to someone else). 1) Regardless of whether this is in the roadmap, we cannot expect everyone to have read it. This critique can and most likely will come from other people as well, and while it may not be particularly enlightening for the direction Rust should go in (since it's already going in that direction), it is a great exercise for the community in my view; it helps spread the knowledge. 2) I don't know of Eric's past actions, nor do I particularly care. These two blog posts are not much different from what I would expect any other newcomer to write if they got off to a bad start with the language, and I don't see any reason to treat them differently based on the author alone. 3) Even if we are being massively trolled, who cares? The troll? Those being trolled? If the community didn't care about being trolled (from outside the community at least; I think the CoC is great keeping things civil "internally" at least), then why would it ever matter? Even if that makes us look naive or silly to some, isn't that completely irrelevant? 4) I don't think we are validating the author in any of his opinions outside of Rust by taking these particular blog posts seriously. But that may just be me. tl;dr - I don't think we are being trolled at all. These looks like the impressions of somebody brash, who got off to a bad start. I expect this will happen again, which is why we should take these particular texts seriously, regardless of what the author has written before.
It does... it's just that ESR was trying to do the equivalent of `String.push_str(String)` which isn't implemented. `String += &amp;str`, `String.push_str(&amp;str)`, and `String = String + &amp;str` work. (And, because of `Deref` coercion, so do the `String + &amp;String` variants) [Playground link](https://is.gd/C7GIa3) The *only* flaw in Rust in this particular case is that the error message doesn't suggest that you add a `&amp;` to your right operand to trigger auto-deref and `Deref` coercion.
To add to /u/steveklabnik1 's answer, clippy is basically ready whenever, we just wait for the infrastructure to get ready (however, the people doing this are swamped with work), which will still take a while.
When I first saw the OP, I read it about halfway, thought "geez, ESR is at it again" and closed it. The fact that people are willing to not just deal with this kind of tone and attitude, but look past it to see the valid (if already known) points the author brings up, is incredibly impressive to me.
No worries! :)
I thought it would be bad at first, and was ready to write an opposing viewpoint, but reading the thread, there were two motivations which I found quite convincing: Alex Crichton's "In general perf probably isn't too much of a worry here b/c you're doing a DNS lookup as well." and the point that if you are using a String that you don't need an ownership of in the future, the odds are that you've built that string for that occasion, for passing that into a function, and just have no use for it afterwards. If you have an use for it, unless you are a total newbie, you are going to prefer passing a reference over cloning it, and if you are a total newbie, that's not likely to be the most pressing problem in your code.
Coming from that background, too (after _some previous exposure_), I found Rust _nice_ in those terms though. In C, I always struggled with sizedness. In Rust, Sizedness is expressed in the type system. &amp;str and String being different takes a while, but becomes very clear once you finally grocked the stack and heap divide.
Undefined behaviour outside unsafe is considered a bug, from what I understood. I don't think it should be expected to know these bugs. Warning about undefined behaviour in unsafe rust would be good, but might be difficult to detect.
Only if the branching point goes back that far, or always? Does Pijul ever need more context than up to the branching point?
annodomini, that is an almost eerily accurate reconstruction of how it went down. I did finally land on TcpListener::bind(&amp;*addr); by a series of half-random guesses, and then sat there staring at the screen wondering "why?" Good guess that I stumbled over the collections::string::String vs std::string::String thing, and that it indeed left me further frustrated and confused. Then, of course, I had to endure people showing up to lecture me on the basics of the memory and ownership model. No, dammit, I'm not stupid and I've been writing dynamic allocation code in C since like 1983; I *got* the theory about halfway through my second readthrough of the Rust book. It's all the weird little jagged bits you list that don't seem to be entailed by the theory that threw me. Now I'm trying to figure out how to declare "a reference to an object with a Reader trait" so I can make a Vec of input sources that are either stdin or a TCP stream. I bet you can imagine some of those false starts, too. 
&gt; and a vote count on each answer. Beware... time depreciation. When a better library appears after 3 years, how long will it take for it to reach the top? The StackOverflow has such inertia that it may never happen. I am all for a vote tally, but I would recommend introducing exponential decay in the mix, so that new libraries have a chance to rise to the top.
&gt; I'll try going through the RFC after my sister's wedding. Congratulations and best wishes to your sister ;)
I know I can pass an individual `&amp;mut` around, but my function is receiving a `&amp;mut` to one end of a linked list (on the stack) and I'm trying to work out if it's possible to retrieve a `&amp;mut` to an arbitarary other item without having to do anything unsafe.
I would say there is one missing maintenance label: **Deprecated**: consider using `x` or `y` instead. This is a stronger statement than "Looking for maintainer" or "Passively maintained": it's not that the author(s) do not want to support any longer, it's that they feel there are *better* options out there.
&gt; I would really like to Then learn Rust :) &gt; Is this language meant as a science experiment? Yes, as well as a practical language. Mozilla is investing heavily in Rust both by developing the language and by using it in Firefox, and there's already Rust components in Firefox today. It's designed to efficiently solve the types of problems Firefox has. In fact, check back at all the security vulnerabilities, most of them would have been avoided had they used Rust (buffet overruns, use after free, etc). However, it's a new language, so few companies have switched to it. However, there are real people building real things in Rust. In fact, I'm building my current side project in Rust, which I hope to earn real money with. &gt; I fear that after I put too many hours in learning rust, it will never amount to a good job opportunity As others have said, Rust will make you a better programmer. &gt; I'm having a very difficult time finding any legitimate practical uses of rust. I'm basically replacing my usage of Go with Rust because I've had concurrency errors with Go (which is its forte) that would have been caught with Rust that have cost me lots of time debugging. I feel like Rust is worth the time investment, and it's honestly not that hard once you understand the borrow checker. When I started learning, I had tons of compiler problems, but now I don't have them nearly as often, and the ones I *do* get tend to highlight actual problems. Even if you never use Rust, I think you'll be better off for the time investment. As a manager that's involved in hiring at my company, listing Rust as a proficient language would definitely get my attention even though we don't use it at my workplace and likely never will. 
Go has a much bigger problem with this. Having everyone self-classify their project as alpha, beta, stable is one easy solution. (If the project doesn't assess its own maturity level, then ignore it.) There have been some efforts to produce a "best practice" checklist for Go that a project can run down and claim compliance with. I think Rust is stronger here by default due to the technical level required to get started. Perhaps a similar "best practice" checklist might help.
I'm surprised leaf is so high on that list. It bugs me that it talks about being a **machine learning** framework but you have to dig way into the docs to find out it's exclusively a neural network implementation.
Why isn't track factor shown for all projects?
I wonder why [Parity](http://github.com/ethcore/parity) isn't up there...it's got about 100-150kloc of Rust making up its core.
There is an RFC for types that are parametrized over numerics. As far as I understand this RFC would allow simple refinement types to be implemented as a library. https://github.com/rust-lang/rfcs/issues/1038
Oh, didn't think about that. Shipping clippy directly sounds like a great idea!
No. I'm referencing *that* article and also C's weak separation of stdlib and system code.
Just as an aside, I found Python a breeze to learn in spite of it being fairly different from any of the many languages I have under my belt. Maybe it's because I've learned dozens of languages at one time or another but the elegance of Python made me love it from the start. This is not to make any comment on the difficulty of rust. I'm not qualified (yet) to make that determination but I certainly am prepared for a much steeper learning curve, and that's OK.
&gt; If I do break it at some point, so long as I'm still supporting two stable releases back, I'll bump *the minor* That seems odd, my reading of semver is it should be the major since the change breaks existing deployments.
1. Use `mut` variables only when you need them to be mut. 2. Limit the scope of variables and the borrows. Use smaller blocks. 3. If you call `foo.bar()` where bar takes `&amp;mut self`, that means another borrow. 4. If you are in a function call which takes `&amp;self`, you can't call `bar()`. 5. If you borrowed a field of `foo` and try to call `bar()` - yes, that's a reborrow so it won't compile. If that helps, try to imagine the stack. Your borrow will end when the variables are dropped. Returning from a function call, exiting from a block is enough to drop the borrows.
I would add: * Make your `struct`s as small as possible (in the number of fields) by grouping related fields into their own structs on which you write methods that mutate them: that will reduce the occurrence of case #5
idk, I premature optimize my rust code all the time. Must easier to just figure out how to do things with lifetimes instead of heap allocation if you do it from the start, in my opinion.
&gt; idk, I premature optimize my rust code all the time I tend to do this too, because I get the kicks out of it. Though I try to teach myself to be motivated by other things. But if the goal is **not** to fight the borrow checker, than a Rust beginner should maybe consider shifting her priorities for a moment. &gt; Must easier to just figure out how to do things with lifetimes instead of heap allocation if you do it from the start, in my opinion. Not everybody likes / can afford to climb that steep a learning curve. And even when you're an expert, sometimes it's better to prototype with borrow-less code, exploring the solution space first, optimizing second. That's what refactoring is for, isn't it?
I admit, `String` not automatically going to `&amp;str` is something that I've unenthusiastically accepted as a fact of life. &gt; Now I'm trying to figure out how to declare "a reference to an object with a Reader trait" so I can make a Vec of input sources that are either stdin or a TCP stream. I bet you can imagine some of those false starts, too. Ah, you've stumbled across another of the parts of Rust that I'm less fond of - trait objects (see https://doc.rust-lang.org/beta/book/trait-objects.html#dynamic-dispatch). You may have already solved this problem, so I'll just touch on the key points (mentioned in that doc): - 'any struct with trait X' is unsized (of course, the structs may have different sizes) so they're basically only usable if they're behind a pointer (Box, &amp;, \*), known as a trait object. This means that you can't have a vec of 'struct with trait X' directly, you have a vec of Box/&amp;/* to traits (or 'trait objects'). - to create trait objects you tend to have to explicitly tell the compiler what type you're looking for, i.e. cast them explicitly (`let file = Box::new(...); let writer = f as Box&lt;Write&gt;;`, https://is.gd/h3TGnr) - a Box/&amp;/\* to a struct with trait X ('trait object') is quite different to a pointer to a normal type because it's actually two pointers (one to data, one to vtable). So, for example, you can't easily pass a `*const Write` to C because it's actually 16 bytes. See also https://doc.rust-lang.org/std/raw/struct.TraitObject.html Hope things go well!
Yes, if people object to the implementation for `String`, we can do it for `&amp;String` instead. I'm prefer the impl for `String`, since if you're building up a string for this purpose it's likely to be just to pass it in here, consuming it doesn't hurt, and if you get an error about a moved value I think it's pretty clear that passing it in by reference would help. But I don't feel too strongly about this, so if others do, I'm happy to switch this to be on `&amp;String`.
It should be possible to make a safe abstraction for this, right? fn leak&lt;T&gt;(vector: Vec&lt;T&gt;) -&gt; &amp;'static [T] { unsafe { mem::transmute(&amp;vector) }; // mem::forget(vector) ? } fn leak&lt;T&gt;(box: Box&lt;T&gt;) -&gt; &amp;'static T { unsafe { mem::transmute(&amp;box) }; } This would be great for game engines and command line data processing utilities that typically just load a bunch of stuff and keep it for the lifetime of the program.
&gt; Java made the mistake of making the stdlib everything+the kitchen sink. And they are now fighting it. They have multiple date APIs, multiple GUI APIs, and things that have been deprecated since 1.0. I think most people who use the Java stdlib are happy enough with it. Considering the size of it, the number of deprecations is not that bad - historically the only truly irritating case for me was Date. I think the attractiveness of batteries-included libs depends on your situation, but when I was working for $largemultinational I heavily favoured larger libs: because I had to get permission and a security review for every library that hadn't previously been reviewed. Not arguing for a large stdlib for Rust (particularly at this stage of its evolution), but I do think a Boost or Apache Commons equivalent would have value - mini-libs can be painful for some environments.
You don't have to leak the memory when transmuting to a static lifetime, but it is perfectly safe to leak memory. Some libraries are already doing precisely this. My [Parallel implementation](https://github.com/mmstick/parallel/) greatly benefited from precisely [this optimization](https://github.com/mmstick/parallel/blob/master/src/main.rs#L40:L52). I can't fathom why this approach would cause me to be downvoted. It's perfectly valid and safe. As long as your values [outlive the joining of the thread handles](https://github.com/mmstick/parallel/blob/master/src/main.rs#L204) it will be perfectly safe.
That is...almost exactly the same path I took. I was incredibly frustrated, and the final solution "&amp;*" reminded me of a criticism one of my colleagues once made about Rust: that there are times it unexpectedly turns into operator soup.
How do I get an upstream crate used to FFI to a C library to link against a locally compiled musl version of the library? Specifically, I'm trying to make a static executable that uses Linux capabilities (i.e., links to libcap). I have successfully locally compiled a libcap against musl and found https://crates.io/crates/capabilities. However, every attempt I make to use the crate results in a dynamic library. For a naive example which doesn't do anything to try to specify my local musl libcap: $ cargo new example --bin Created binary (application) `example` project $ cd example $ echo 'capabilities = "0.2.0"' &gt;&gt; Cargo.toml $ echo 'extern crate capabilities; quote&gt; quote&gt; fn main() { quote&gt; let _ = capabilities::Capabilities::from_current_proc().unwrap(); quote&gt; } quote&gt; ' &gt; src/main.rs $ cargo build --target=x86_64-unknown-linux-musl --release Updating registry `https://github.com/rust-lang/crates.io-index` Compiling libc v0.2.19 Compiling capabilities v0.2.0 Compiling example v0.1.0 (file:///dev/shm/z/example) Finished release [optimized] target(s) in 1.26 secs $ ldd target/x86_64-unknown-linux-musl/release/example linux-vdso.so.1 (0x00007ffd69519000) libcap.so.2 =&gt; /lib/x86_64-linux-gnu/libcap.so.2 (0x00007f78ef58f000) libattr.so.1 =&gt; /lib/x86_64-linux-gnu/libattr.so.1 (0x00007f78ef38a000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f78eefde000) /lib/ld64.so.1 =&gt; /lib64/ld-linux-x86-64.so.2 (0x000056233d1ee000) It's linking to the system's glibc-compiled, dynamic libcap and ignoring my --target. (Ignoring `--target` seems like bad form - why isn't it erroring? Rust is good about catching silly mistakes and making me fix them, I figure Cargo should similarly yell at me for trying to link glibc and musl libraries together instead of silently guessing at what I want.) I've tried experimenting with things like `rustc-link-search` and `LD_LIBRARY_PATH` to get Cargo to use my library instead of the system one without success. I've either missed or misunderstood the relevant bit of documentation. Could someone point me in the right direction? EDIT: Got my answer in #cargo: There is no way to do this as-is; it requires adjustment in the upstream package. The prefered convention is to have a build script read environment variables to determine linkage specifics, as demonstrated [with the rust-openssl crate](https://github.com/sfackler/rust-openssl/blob/master/openssl-sys/build.rs).
The trick is to make your `get_mut(&amp;mut self, x, y)` into a free function which doesn't borrow self, but borrows the grid, like `get_mut(grid: &amp;mut [u8], x: usize, y: usize)`. I do see that it's not as ergonomic as taking `&amp;self`, but it works nicely and it's totally safe. Sort of get used to it :( pub struct Foo { // 10x10 grid: [u8; 100], bar: u8, } pub fn get_mut(grid: &amp;mut [u8], x: usize, y: usize) -&gt; &amp;mut u8 { &amp;mut grid[x * 10 + y] } impl Foo { pub fn foo(&amp;mut self) { let v = get_mut(&amp;mut self.grid, 5, 6); *v = self.bar; } } Note, that in `foo()` you borrowed an `&amp;mut Foo`. You can sacrifice that borrow to have `&amp;mut ` borrows to all of your fields simultaneously, but you won't be able to call a method which takes either `&amp;self` or `&amp;mut self` in the same time.
&gt; I would prefer for my projects not to be at 87.x.y simply because of using new lang features, while the rest of the community is as 0.x.y. &gt; Even though on paper it seems like it's not a huge deal, there are people who see rapid major version bumps as something to actively avoid when picking libraries. Surely that makes sense? If every update is a breaking change the dependency has a higher "maintenance cost" than one which never does no? &gt; I'm also a firm believer that you should be able to signify significant breaking changes to you consumers. Surely the "significance" of a breaking change is in the eye of the beholder, or rather the user of the library, and one's irrelevant change (because they didn't use that feature, or already used a recent version of a dependency) is the other's show-stopper? I mean take `?`, it's has no impact on somebody living on "the edge" of rustc, but it kills the dependency for somebody whose organisation only validated, say, 1.8. In fact, thinking about that this issue is going to rear its head if distributions start including rustc (rather than just e.g. rustup) as the more conservative ones aren't going to live on the edge. If we're not going to use semver so downstream can get information about a change being breaking or not, what is the point of using it at all? On the other hand, you could argue that it's an implementation detail of the compilation process since "binary crates" would have already compiled the construct internally and would not impact dependents, so you're right that `?` is a bit of an odd duck there.
Think about everything is terms of ownership. Everything can only have one owner at the time, or be temporarily mutably borrowed in single place. After you internalize this, you're golden. I am coming from C background too - initially I had to fight borrowck a lot by restructuring the data. And afterwards I figured out that I was just structuring my data wrong. Now when I write C code, I do it as i would do it in Rust (I think about ownership, borrowing, mutable aliasing very clearly) and it helps my C code a lot. Don't optimize too early. When you're writing your code initially feel free to needlessly `clone` and make copies of small data instead of spending hours trying to get lifetimes in `MyData&lt;'a, 'b, 'c&gt;` to work. "Make it work, make it correct, make it fast" - the order is the point. 
This error occurs when you are attempting to pass a reference to something that may outlive the current scope. Your problem is that `to_str` returns a `&amp;str`, which is a reference to a `str`. You will be unable to store a reference to this because its 'borrow' expires at the end of scope of the for loop. In other words.. let mut assets = HashMap::new(); for path in read_dir("assets").unwrap() { let path = path.unwrap().path(); // Borrowing a &amp;str here... let key = &amp;path.file_stem().unwrap().to_str().unwrap(); let value = renderer.load_texture(&amp;path).unwrap(); assets.insert(key, value); } // ..will expire here. // but assets outlives this scope and will continue to store that reference // which may expire/the memory being pointed to by the reference may be // overwritten. There a couple of options you can use here - unfortunately, both options require ownership of the value in question. This shouldn't be a problem in this case, from the looks of things. 1. Store the offending value in a `Box` rather than a raw borrow. This stores the value on the heap, allowing it to outlive the current scope (the current scope being the 'for' loop). This has a performance penalty. 2. Store the `PathBuf` object itself. You can't store the result of `file_stem` without using a Box as this is also a reference. This should fix your problem. let mut assets = HashMap::new::&lt;PathBuf, T&gt;(); // where T is the result of `load_texture`. // this annotation is not necessary, but it's easier for me to work out what is going on here with it for path in read_dir("assets").unwrap() { let path = path.unwrap().path(); let value = renderer.load_texture(&amp;path).unwrap(); assets.insert(path, value); } However, this is assuming that your `path()` method does not return a `&amp;PathBuf`.... Be wary of your very extensive use of `unwrap`. I'd certainly expect the possibility of `load_texture` going wrong, or `read_dir`.
you should propogate the `Result` up the call stack until you reach a piece of code where it makes sense to actually handle the error. In terms of `Option`, if it's not acceptable for the result to be `None` then you should probably return a `Result::Err` from the function. Basically, if you have the following functions - A (handles errors) - B - C - D - E (returns `Result`) Then the `Result` should pass up to the error handler at A, such that B, C and D all return `Result` too. Unless.... you know an error from a Result is completely unrecoverable then you *could* panic (but you probably want to 'recover' by logging information about the error instead)
&gt; My Parallel implementation greatly benefited from this precisely this optimization. It says &gt; To guarantee that this is perfectly safe, and that the reference will live outside the scope, the value will also be leaked so that it is forced to remain in memory for the remainder of the application. But the function is marked as `unsafe`. Is this trick safe or not? I mean, would it be okay to implement it like this? fn leak_string(comm: String) -&gt; &amp;'static str { let new_comm = unsafe { mem::transmute(&amp;comm as &amp;str) }; mem::forget(comm); new_comm }
The borrow checker is stupid simple and can boiled down to these simple rules: - You may only have one mutable borrow at a time - You may have as many immutable borrows as you want - You may not borrow immutably and mutably at the same time - Taking a value by `self` drops the original value - Instead of attempting multiple simultaneous mutable borrows, queue your future changes in a separate location and apply them later
I like to think of the borrow checker has a kind of locking system (read-write-lock). If you have an immutable reference, you basically have a shared lock to the original object, whereas if you have a mutable reference you have an exclusive lock to it. And, like any locking system, it's usually not a good idea to hold on to them any longer than necessary. This is especially bad for mut refs. - Some code can be restructured to avoid overlapping locks. This is usually the ideal solution, but it isn't always possible nor always elegant. - If you run into issues where you want to mutate things but also want to share the reference all over the place, then Cell and RefCell come in handy. But be aware that it is just punting the locking system to run time. Violations of the exclusive-write rule will lead to panics. - If that still doesn't work (usually with things like self-referential graph like structures), you can emulate references using indices to an array, or equivalently use Arena or TypedArena. If you have a specific problem in mind it'd be useful to ask that and see what folks here can come up with. Sometimes all you need is a little hint in the right direction and the rest will follow :P
That's a bit of Rust folk knowledge I've never read about. Reminds me of the recent blog series by /u/Manishearth.
I get that in theory, but in practice, many of the algorithms that I know or come up with violate one or more of these rules. I am looking for ways to rework algorithms that violate the rules into those that do not.
That means you are doing very bug prone and dangerous stuff in C.
In case anyone else comes across this, I've now released string-wrapper 0.1.6 after some help from @mbrubeck. It also has a from_str method.
Documentation and deciding requirements is huge to a project too, that is why I wrote rst https://github.com/vitiral/rst
Have any examples?
With gcc 6.3.1 -O0 or -O2, valgrind 3.11 does warn, here on fedora 24.
Cool! Note that we're not exclusively writing it for newcomers to DVCS, but also for anyone requiring strong correctness guarantees. **The problem with associativity is really bad**, and can silently hit anyone at any time. Its translation in day-to-day git usage is that no matter how careful you are when doing code review, git gives you no guarantee that in all cases, the code you merge is the code you reviewed. &gt; Would it be fair to phrase this instead as "the good practices required for Pijul are much more minimal?" I guess, but OTOH I've never used Pijul on a large scale project ;-)
I don't mind about the postponed release schedule. It already has the best explanation of ownership memory model and lifetimes that I know of. If only the final version had a nice and _juicy_ chapter of futures in it, I'd say the book was the best programming language ebook I bought in 2016.
&gt; consuming it doesn't hurt It does, if the String may be used later, e.g. for logging. We'd also gain nothing over a borrowing impl, because the address cannot reuse the memory of the consumed String.
That's a really good idea in general that I think could help Rust error messages. Any time adding an `&amp;` to an expression would fix it should definitely be reported by the compiler!
The `arrayvec` crate has this, https://docs.rs/arrayvec/0.3.20/arrayvec/struct.ArrayString.html, maybe you can join efforts. To make it more obvious that the changes are good, you could just delegate everything to the `Deref` implementation and the corresponding implementations on `str`, e.g.: impl&lt;T: Buffer&gt; hash::Hash for StringWrapper&lt;T&gt; { fn hash&lt;H: hash::Hasher&gt;(&amp;self, state: &amp;mut H) { self.deref().hash(state) } } This way, less code needs to be unsafe, less code needs to touch the potentially uninitialized buffer `buffer`.
[Michael Aaron Murphy, if you're reading this, please stop posting "nuh uh"-style retorts.](http://esr.ibiblio.org/?p=7303#comment-1797906) We should welcome constructive criticism, rather than try to silence it with "your experience is wrong". This is particularly grievous considering "Rust fanboys" were explicitly called out in ESR's post. Also, [as /u/eminence points out](https://www.reddit.com/r/rust/comments/5nu1w7/rust_and_the_limits_of_swarm_design/dceeiy7/), &gt;Another observation is that a lot of people have very reasonable answers to ESRs questions (especially in the previous blog post). To many, I bet those answers were obvious. It occurs to me that those answers were only obvious because those people are participating in the swarm, and ESR is not in the swarm. (By 'participating in the swarm' I mean keeping up to date on /r/rust, {users,internals}.rust-lang.org, subscribing to interesting github issues and RFCs, etc). Maybe parts of what ESR said about Rust were wrong; if that's the case, it speaks to something **we** need to rectify. The flip side of his failure to learn is our failure to teach.
Ah, the "state machine" problem: you have a `&amp;mut` of some enum, and you want to take ownership of its contents and possibly replace the enum with a different variant. You can use the `std::mem::replace` trick here: replace the tree temporarily with `None` and the restore it when you're done. The only downside is that if you panic while the subtree is being modified, you lose the subtree entirely, leaving the AVL tree in an inconsistent state. I think you can work around this by moving the key comparison part (which could panic) into a separate match clause, capture the comparison result, and then use *that* result during the replacement process. pub fn remove(&amp;mut self, key: &amp;K) -&gt; Option&lt;V&gt; { let (result, new_self) = match ::std::mem::replace(&amp;mut self.0, None) { None =&gt; (None, AvlTree(None)), Some(mut node) =&gt; { if *key == node.key { let node = *node; let new_self = match (node.left.0, node.right.0) { //has no subtrees, nothing needs to be done (None, None) =&gt; AvlTree(None), //has one subtree, just put the one subtree in place (Some(left), None) =&gt; AvlTree(Some(left)), (None, Some(right)) =&gt; AvlTree(Some(right)), //two subtrees, must find a suitable replacement (Some(left), Some(right)) =&gt; { // you have ownership of both left and right here! panic!("not yet implemented") } }; new_self.update_height(); (Some(node.val), new_self) } else if *key &lt; node.key { (node.left.remove(key), AvlTree(Some(node))) } else { (node.right.remove(key), AvlTree(Some(node))) } } }; *self = new_self; self.rebalance(); result }
left and right can't be instances directly, they have to be some kind of pointer. The simplest, `&amp;` references, requires explicit lifetime validation. You're much better off using Option&lt;Box&lt;AvlNode&gt;&gt; (or some other pointer type like Rc or Arc instead of Box), so that each node can point to nothing (None) or something (Some(n) where n is a pointer to another AvlNode)
Honestly I found the explanation on the official site more clear. :/
Use String and Vec more, especially as return values. And clone(). Zero-copy is all well and good, but if you're having trouble getting your code running at all, feel free to make extra owned copies to smooth things out. This is especially true if you find yourself adding lifetime parameters to a struct, so that it can hold references. Strongly consider making it hold owned copies instead, at least until the borrow checker feels more intuitive to deal with. Anything involving `Cow` is almost certainly not worth the trouble in the beginning :)
Not necessarily – see, borrowck relies on heuristics, but those are by nature imprecise, and so borrowck will balk at a lot of perfectly safe programs. Luckily there's usually a fairly trivial way to change the code to appease borrowck. In practice, the awesome safety guarantees seem to be worth the occasional code change.
&gt; I work with C a lot and I am so used to being able to mutate and move whatever I want whenever I want. 
Please make sure you understand why it fixed your problem and feel free to ask if its not 100% clear what was happening. 
Can you say why you want this? My intuition is that your use case can probably be satisfied nicely with an `unwrap_or` somewhere. ~~Otherwise you could probably cobble something together with `peakable`, but it won't be pretty~~ (EDIT: This is definitely a bad idea). Or you could implement the method yourself, properly, introducing a `DefaultIfEmpty` struct and a trait that implements a `default_if_empty` method for `Iterator`.
Just getting in to Rust now and I have reached the Closures topic in the book. I am trying to understand how this works: fn factory() -&gt; Box&lt;Fn(i32) -&gt; i32&gt; { let num = 5; Box::new(move |x| x + num) } let f = factory(); let answer = f(1); assert_eq!(6, answer); Specifically, I am trying to understand how `f(1)` works. The type of `f` is a Box that holds a closure, then how is `f` callable unless we somehow extract the closure out of it? If I'm not wrong, this looks awfully similar to a functor in C++. Looking at `std::boxed::Box`, I can see that it implements `call_once()`, but how does that work? Thanks!
I feel that this is going in the wrong direction. Two main things that irk me about crates.io: 1. flat namespace 2. curation by rust developers. Fixing both will fix the only legitimate claim in that otherwise trollish post. These ideas aren't new. Both successfully exist for decades in other ecosystems. Debian has meta packages that allow to aggregate sub -packages. C++ has collections of libraries: Boost, qt, to name a few major ones. The other point is that curation by rust devs violates SRP. People that are expert compiler writers are not necessarily experts in other domains, and I for one do not think that it makes sense that e.g libs for image formats handling is something that the core devs should be proficient in. Just like in debian I can install kde-desktop and trust the curation process of the KDE community OR choose a different *-desktop package, I think rust should allow such mega packages to emerge and the user can choose by reputation which curated list he trusts. Just like a C++ shop can choose to trust BOOST libs. I'm sure that some general purpose "boost-like" standard will emerge as well as more field specific lists, e.g. for game-dev, for embedded, etc.. If specific rust developers choose to participate in any of those organizations they should be welcome (depends on the specific org's own rules, obviously) just as there is plenty of overlap and coordination between boost developers and the c++ standards committee, but not all compiler developers are boost contributors and it is wrong to put the Rust banner on these "boost-like" standardization efforts.
Different explanations are going to work better for different people, that's why it's important to have many!
But the full one does.
I've been reviewing chapters for the book and am reviewing 11-14 now. After the first 10 chapters there were a number of months without new ones, where I gather they were revising. While the previous chapter drafts were incomplete in places, the new chapters are really thorough. For the topics covered this book should be a solid tome of reference material. The examples of minor topics are particularly insightful and well-considered, often cleverly illustrating subtle aspects of the design. I've definitely learned a few things. It's an excellent Rust book, and the chapters available now are all high quality and complete. 
It ends up calling `Fn::call`, via the magic of _deref coercions_. You can imagine `f(1)` turning into `f.call((1,))`, and there's no `Box::call`, so it derefs the `Box&lt;Fn(i32)-&gt;i32&gt;` to `Fn(i32)-&gt;i32`, and there it finds a `call` function. The closure doesn't need to be extracted from the box in order to call it, because you only need a `&amp;`-reference in order to call a `Fn` closure. You need a `&amp;mut`-reference to call a `FnMut` closure, so that also works from within a box. The one that doesn't is `FnOnce`, since those closures get consumed when you call them, which explains why you don't want to put `FnOnce` closures in boxes.
&gt;he's not comparing rust to C or C++, he's comparing it to Go. That's exactly right. Remember my context: I'm trying to choose something to _replace_ C for NTPsec's use, so the competition is at the level of Go and Swift and Erlang. Furthermore, my evaluation is that NTPsec _can_ be written in Go. Which means that Rust could only compete by demonstrating some advantage over _Go_ that defrays the additional complexity cost of Rust.
That's an accurate description of programming in C no matter how safe you're being.
I have a question about this code actually. Specifically this line: let node = *node; I would have thought in match (node.left.0, node.right.0) node would have been auto dereferenced. When I take it out, I get a "Use of moved value" error because i am trying to use node.right after moving node.left. When you explicitly deference the node, this error goes away. Why is that?
lmao. Yeah, I did that, too. https://github.com/archer884/or-iter But I wondered if I was reinventing the wheel.
Honestly think this is the best way I have seen to go about it because it does away with the necessity (in both my code and in /u/minno's) to keep track of whether or not the source iterator has produced anything. Thanks for that. :) Edit: does away with the need for *my* code to do it. :p
It does keep track, that part's just abstracted away. Specifically the `.chain` call creates [this](https://doc.rust-lang.org/src/core/up/src/libcore/iter/mod.rs.html#504-508) struct, which keeps track of which iterator to use.
One thing, a common pattern in C++ code is for child objects to hold a reference to their parent. That doesn't work out so well in rust. Instead, loan the reference to the child on each method call that needs it. Having a clean hierarchy without circular dependencies, where possible, helps a lot. Edit: I know you specifically said C, but if you are writing C in an object-oriented style this would apply as well.
Thanks for showing me this, gonna use it.
Qt isn't a collection of libraries. And boost is sort-of a collection of libraries, but not in the same way that a Debian meta package is; they're quite coherent and similar.
Less so if you're making an effort to be const-correct.
You're welcome and I hope it will be useful to you.
I originally ordered the book from Amazon UK in November 2015 - as the order had been open for so long, their system cancelled it in December 2016, but I immediately re-ordered and luckily the price hadn't changed! =)
... or then it's just me, who really, really, really wanted to learn the memory model :)
What's the state of constant and real-time systems in Rust? #arewerealtimeyet
While asking complete strangers for help is something that some people are comfortable with, we really shouldn't expect everyone who has a problem to turn to IRC (and more to the point, they shouldn't have to).
I have the same issue on windows7, I don't exactly know what is causing it but I temporarily fixed it by adding `C:\Windows\SysWOW64` to my user path. May not work for you tho.
It's less "shoulda gone to IRC" and more about the fact that if you're going to write a blog post about how everything's so awful, you should do your research.
This is really cool. If I had time I'd love to work on a more general gfx ui package for Rust terminals, like Go's [TermUI](https://github.com/gizak/termui) or what's possible with [ncurses](http://invisible-island.net/ncurses/). 
A new update was pushed to oreilly.com on Dec 26th for those with early access to the WIP ebook.
My vague understanding is that Perl 6 has a global table of `u32 -&gt; &amp;str` mappings that lets it give each unique grapheme cluster a "codepoint", which allows it to represent strings as `&amp;[u32]`s. I don't think you can really *solve* this problem at Rust's level of abstraction. I think we just need to keep beating people over the head with the fact that they do *not*, in fact, understand how text works. Everything else is really just papering over the issue and hoping people don't notice. Like trying to paper over how floating point can't do `0.1`, or that integers aren't *Integers*. People have to learn this crap at *some* point... :P
&gt; it give each unique grapheme cluster a "codepoint" How ... how does that work? Grapheme clusters can be arbitrarily large. Or is it a table that gets filled up as it encounters GCs? Swift internally has a trie which it uses to do things efficiently. &gt; I don't think you can really solve this problem at Rust's level of abstraction I mean, making `.graphemes()` the advertised/default way of iterating over a string does solve it. Kind of. Have `.code_units()` instead of `.chars()`. It's extreme, and not something that can happen now, but we could at least put the graphemes function in the stdlib. &gt; I think we just need to keep beating people over the head with the fact that they do not, in fact, understand how text works Yeah, I guess so.
I feel like recommendation of alternative crates is something that would be better in the description of a crate, rather than adding metadata to a badge that could otherwise be one token. I could see "Deprecated" being one of the values, though.
You can name crates starting with `yourusername-` whenever you like, there's nothing *stopping* you from using namespaces!
Thank you so much for this! Until I started learning Rust, I didn't know much about Unicode... I'd never had to deal with the details before. I've read a decent amount on Unicode since then, but only after reading this article do I think I finally get it. I nominate this for inclusion in TRPL and I agree `unicode-segmentation` should move to the nursery, then std. I think the book should have a section explaining this, with example Rust code showing how to do common things people take for granted in higher-level languages. 
Outside of font rendering libraries I don't understand why you'd even care about grapheme clusters and probably the same for code points too. The main times I've used string indexing it's for some pseudo text encoding where the only characters I would care about are all ASCII anyway but as_bytes works fine for that. And even if they are utf-8 characters a substring match would work fine.
Wait, what happened to the `graphemes()` method? Evidently I haven't mucked with strings in a while, because it's been deprecated since 1.0, but I remember it being the recommended way to iterate over a string.
ESR is not from a language with a central repository either. His career starts well before there was a google to google fu with or an ~~intetnet~~ internet for that matter. If you haven't read [The Cathedral and the Bazaar](http://www.catb.org/esr/writings/cathedral-bazaar/cathedral-bazaar/) you really should. It's essentially the original condensation of the foundational ideas behind the way all modern open source development projects are developed, including Rust. The way the Rust community operates is pretty much one of the purest manifestation of his ideas seen thus far. It's the bazaar with no cathedral in sight. He understands exactly why the community operates the way it does, because it operates that way because its creators either read his book or worked on projects whose creators had. The point he's making is that sixteen years on after a lot of the cathedrals have been torn down, the bazaar isn't entirely the right solution either. It's not precisely a criticism of Rust so much as it's a lesson for Rust based on what has come before and what continues to happen today. The problem in some ways is more serious for Rust though. Rust isn't a JS web front end framework that will be outdated and forgotten in 18 months. It's a systems programming language where the code written in it is probably still going to be maintained and still need some degree of feature stability in a decade. Right now it's very difficult to determine which crates are going to be around in 10 years. Which ones are going to be maintained even if the creator gets bored or hit by a bus. That's really what moving into the standard library is all about. It's about the knowledge that unless the whole ecosystem dies that library will still be around.
They seem to be sorting by stars, and number 40 has 39 stars. There are plenty of rust repos with more stars than that not on this list. Heck, I've got two. I wouldn't put much faith in this.
Very good explanation of the basics of text processing. One inaccuracy that I noticed in the post is: there is no 1-to-1 mapping between grapheme clusters and glyphs in fonts. For example, in Latin scripts, we have two separate letters "f" and "i" but variable length fonts can render the string "fi" as a single glyph. I forgot the name for this though. As for rust, I would simply want to NOT have the word "char" in any APIs. It's just too overloaded a term and will always give false impressions. 
&gt; We still don't support the #[test] attribute so, if you add new functionality, please add a smoke test in the form of an example that exercises the new functionality to the examples directory and to the list in ci/script.sh. What's required to support `#[test]`? --- Some similar efforts: * [Baby Steps: Slowly Porting musl to Rust](https://www.reddit.com/r/rust/comments/4nqwfg/baby_steps_slowly_porting_musl_to_rust/) ([rusl](https://github.com/dikaiosune/rusl)) * [relibc](https://github.com/mattico/relibc) * perhaps others?
Thank you for the ping, /u/matthieum! The problem with referencing online resources from a printed book is that the links can get out of date. Even describing processes-- maybe in a few years the RFC process will have changed into something else. We're definitely going to be pointing out rust-lang.org, and that page could definitely be better about surfacing things like the roadmap, current progress on various fronts, [the currently-in-proposal bookshelf](https://github.com/rust-lang/rfcs/pull/1828), [the teams page](https://www.rust-lang.org/en-US/team.html), etc.
 or-iter [refine-inner-working●] cargo bench Finished release [optimized] target(s) in 0.0 secs Running target/release/deps/benchmarks-9ac57933bc586ab6 running 6 tests test iterator_10 ... bench: 15 ns/iter (+/- 2) test iterator_1000 ... bench: 1,075 ns/iter (+/- 186) test iterator_empty ... bench: 2 ns/iter (+/- 1) test vector_and_count_10 ... bench: 23 ns/iter (+/- 1) test vector_and_count_1000 ... bench: 398 ns/iter (+/- 38) test vector_and_count_empty ... bench: 2 ns/iter (+/- 0) Seems like results are in line with what I expected wrt time. The longer the collection gets, the more impact branching on every item is going to have, which means that (at least for a collection of a thousand integers) the iterator is three times slower than the vector. I don't know if this will change for larger items or not. I'm guessing the size of a memory allocation has no impact on how long it takes, but I'm one of those guys who writes jitted, garbage collected code for a living, so I have no idea. :)
Very true.
&gt; For example, in Latin scripts, we have two separate letters "f" and "i" but variable length fonts can render the string "fi" as a single glyph. I forgot the name for this though. These are *ligatures*. (Confusingly, Unicode does have some code points allocated to ligatures, presumably for round-trip compatibility with legacy encodings.)
Yea its the collective impact of the branches racing against the allocation cost. I agree the size of the allocation is probably not a big issue and I shouldn't have said 'small' (what matters more is if you're saving 1 or many allocations). The branching iteration might also impact what optimizations can be performed on this code, since iterating over a vector is designed to be extremely optimizable.
Yeah, my point is that you should care _more_ about grapheme clusters than code points. For many application domains text is just an opaque blob of ... well ... text, and you don't actually peek into it, so you don't need indexing at all (of code points, graphemes, or whatever). In that case you don't need to care. It does get useful outside of font rendering, e.g. in handling text editing and selection, or truncation. Even when designing a regex or string search library you may want to make it handle GCs. It might not even be too expensive, since you can do a code-point based search and filter the matches based on EGCs later. Though it depends. It's annoying when you Ctrl-F for something and something else comes up that's only a match due to the underlying encoding. I wouldn't want EGC based matching for Rust's regex lib except maybe as an option, because it's unexpected. Writing an encoding library falls under the "implementing a Unicode algorithm" thing I mentioned in the post.
Yeah, it's sort of like car/care but more frustrating. Must be even worse for Thai text because they don't use spaces (but have a concept of word boundary). Yeah, solving it in external libs is fine. Just demonstrating that it's something some use cases need to care about.
That's [schwa deletion](https://en.wikipedia.org/wiki/Schwa_deletion_in_Indo-Aryan_languages), basically when you don't pronounce the schwa even if there is no virama. It's one of those irregularities that native speakers don't notice at all but those learning the language have to deal with. I'm looking at _you_, French conjugations. I don't pronounce my name muh-nee-shuh^1, I pronounce it muh-neesh. The schwa is deleted. Similarly, कानपुर is pronounced Kanpur, not Ka-nuh-pu-ruh. Schwa deletion happens pretty commonly at the end of words. The virama is usually used to make consonant clusters. If you hear an Indic word without a schwa at the end, that's almost always schwa deletion, not a virama. I've only seen viramas being used at the end of words when foreign words are involved. You will rarely see bare viramas in text because they almost always form consonant clusters. Unless you're reading sanskrit (which has some crazy consonant clusters) and your font isn't that great. I actually suck at spelling so I often use a virama in the middle of a word when there's schwa deletion by accident. Fortunately, in many cases there's a lack of consistency on the spelling _anyway_, so it doesn't matter. ^1: When I was a kid, my parents would pronounce my name letter by letter if I'm ignoring them when they're calling out to me. In that case it does become muh-nee-shuh. That's about the only time I can recall the schwa being used, and that's probably because it was split into letters.
&gt; One inaccuracy that I noticed in the post is: there is no 1-to-1 mapping between grapheme clusters and glyphs in fonts I'm not sure I ever mentioned that? I'm well aware that grapheme clusters don't map to glyphs 1-1. That concept is called a ligature. But we do have multi-EGC glyphs even when it's not a ligature.
&gt; It flies in the face of everything we've been taught as software developers. Asking for a friend: Could you repeat what that was we learnt again?
The only bug-free code is the code nobody writes. One must resist the temptation to replace code that's known to work unless one has a *really* good reason. Or you know, for funsies.
I mean, you're arguing with a platitude, but I'll bite. Code that works does not imply that the code is perfect. Often one has to weigh the cost of working around *known* faults in existing code versus creating new code with its own *unknown* faults. Sometimes it's worth it. All too often, it isn't, and we only do it to play into our hubris. By all means, have fun. Just keep your ego in check.
&gt; It's unprincipled: instead of extracting the risky code out into a safe abstraction (see below), it's just scattered at the use-sites that happen to need a bit of speeding up. It already is a safe abstraction, and it is certainly not scattered. Did you even read the source code? It's only used once throughout the entire program, in the main thread. Leaking a value and returning a static reference is a perfectly valid and known tactic for Rust. There's no need to import an external crate to add a sleuth of dependencies when that functionality is not needed. &gt; The power of Rust is the ability to build safe abstractions around unsafe code, instead of having it just permeating one's library. Rust is many things, and this entire argument is just your own personal opinion. Allowing you to perform this kind of optimization is another one of Rust's powers. &gt; I've had many experiences of eagerly jumping to using unsafe code, getting told to rewrite into safe code during code review, and then finding that the safe code has equal (or better) performance, and is easier to maintain. If you read my prior comment that you just replied to, this is not the case. The safe method would only add to maintenance burden and damage performance. &gt; The functions in your crate do expose a safe interface, but it is not an abstraction. Are we going to become lawyers now and argue over semantics? What's the purpose in that? A function is both an abstraction and an interface, and therefore both a safe abstraction and interface. &gt; Copy-pasting error-prone code into projects is not an abstraction. No part of this is copied and pasted. I'm not sure where you're getting that idea. &gt; whereas this code adds unsafe burden to your crate, more places to think about, more places where the compiler can't help you. First of all, it's not a crate. It's an application. Second, what I stated before still stands. This is perfectly safe -- leaking memory is valid and allowed by the standard library. Leaking memory is safe. A value that is leaked will exist forever, until the OS reclaims the data after the program has exited. It therefore has a static lifetime that is as static as any other static variable. Using the transmute function is done to tell the compiler that it now has a static lifetime, which is again: safe. The compiler does not need to help you. &gt; This particular case is notably error-prone, because the recommended code doesn't compile It compiles fine, just build my project. It's been in use in production for many releases upon releases. Benchmarks on the front page were conducted with this in place. &gt; making use-after-free a real possibility depending on how it is used and how it will be used in future, as code is refactored I'm not sure what you're talking about here but use-after free isn't allowed by the compiler after this is done. The value is taking by self and the forget function is called. Any attempt to re-use the original value, thus attempting to modify it, would simply cause the compiler to warn that the value's ownership was already moved. &gt; (I'm sorry if you feel like I'm targeting you, but I truly do think that encouraging this sort of use of unsafe is irresponsible, especially with things like the incorrect use of mem::uninitialized, and, more "selfishly", is making life hard for developers,) It's not incorrect in the least. Such a strategy has been recommended before in the past by others. It is a perfectly valid strategy and it is not wise to frown upon an unsafe function so harshly. They are tools that exist to be used, not to serve as an object to slap someone's wrist over just because they used it. &gt; by not letting the compiler help as much as it can. The compiler is already doing all the help that it can, but the compiler is not perfect. It does not know that it's safe to share the reference across the threads because that reference will outlive all the threads. This is not working against the compiler but working with the compiler. It is vitally important that any Rust software engineer understand how to do tricks like this.
I'm aware of what you meant and it's kind of part and parcel of the whole idea. A standard library doesn't actually gave to be standard in the clib kind of way either. Rust-lang and rust-nursery are fine along with a system of promotion within that structure. I'm fairly new to Rust, but I've had enough to do with enterprise development over my career to know a few things about how long term support projects work. I also know enough of our industry's history to know that if ESR is saying something it's at least worth listening to, even, and perhaps especially, if he's coming at something from an outsider's perspective. The man is essentially the original exemplar of the idea of open source pragmatism. The arguments you and I and everyone else made or make for using open source in an enterprise setting mostly come from him. He might very well be wrong about Rust, but his opinion merits at least consideration.
Hi. I once wrote (in C++) an extremely comprehensive and advanced Unicode library (it was part of the core of SAP's NW-MDM product line, but I wrote it prior to our aquisition by SAP), and I encountered, and dealt with, most of the issues you cite here. I actually provided size counts and iterators for bytes, code points, and graphemes (EGCs, to the degree that they were defined as of the Unicode 4.0 publication), but it turned out that even grapheme clusters were not the appropriate programmatic segmentation. In fact, what turned out to be the appropriate segmentation could occur partway into a code point: the collation sequential primary element. Which is locale dependent. Which sucks. But, if you're trying to handle expressions, language based data normalisation and mining, unstructured textual data processing, etc, etc, etc, that's your unit of written language. So, yes, I provided iterators and indexing on that, too. And unlike all of the others, including the grapheme boundaries, it worked the way people expected it to work. Just something to consider. 
&gt; http://www.unicode.org/reports/tr29/#GB12 Ah, for some reason I missed that they fixed that in 9. Good to know. In any case, needing all this back context certainly makes things harder for xi-editor, because the number of leaves needed to find a grapheme cluster is not bounded. I've seriously considered putting Regional Indicator Symbol parity in the `NodeInfo` for strings (ie using a monoid homomorphism to compute it) so it can be found in O(log n) time, but that's probably gold-plating things. This is likely to be a serious problem only with malicious inputs.
I'm guessing you're not using a very mainstream browser.
Yeah, the collation spec might be better for some tasks related to this. When _specifically_ dealing with language-related things (NLP, the stuff you mention, etc), UAX 29 is not what you need. It basically says that it doesn't attempt to deal with many more language-specific issues and you should tailor it in that case. You'd probably want something even more specific than what the collation spec provides.
Firefox and Chrome on a mac both backspace "ᄀᄀᄀ각ᆨᆨ" by jamo (one stroke at a time), and they both delete accents individually. Bear in mind that this is only for accented chars made of letter + accent codepoints, not precomposed accents (the default Mac press-and-hold input method uses precomposed accents). It's basically a rough version of "backspace as you would have typed it"; if you had typed an accented char in two steps, it backspaces in two steps. So, "ᄀᄀᄀ각ᆨᆨ" will backspace the kiyeoks one by one, but the central "gag" syllable block will be deleted in one go. Unlike the previous example where the central gag block will first become a ga and then just a kiyeok. Backspace doesn't do NFD to extract accents on any system I know.
Oh, for operating with slices that are not on code point boundaries?
Yup. (Additionally, `closure_egc` for operating on slices that are not on EGC boundaries. Again, my naming is crap, I'm just starting to think about this.)
No, provably correct would imply perfection. The MIT/Jersey battle is over. Jersey won. "Known to work" is a statement of experience. If you're lucky, you might even get some unit tests out of the deal. 🙄 I think your hubris is showing. Yes, I agree reimplementing working code is not useless, but for none of the reasons you described. You'll likely introduce more flaws in the new code than you'll find in the original. Your work will likely be lost to the ether when you lose interest, so it will lead to nothing. And new developers are just as likely to make the same mistakes you are. The real value in wheelcraft is in improving *yourself*. Any coder worth talking to can use library to do something complex. But implementing it yourself will give you a deeper understanding of the problem than making use of a known solution ever will.
Mhm. In the end, this is a pattern I normally use to minimize impact on ram, but I'm not real sure how to benchmark that. I guess that, in Rust at least, you can just do plain old math. In C#, you normally have to profile it.
This is a bad solution but there's nothing else posted here so it's better than nothing. If you compile [using codegen](https://serde.rs/codegen-stable.html), you can view the generated code in target/ and hopefully untangle what it's trying to do.
Oh, right, you typed the tick and then e, not e and then a combining mark. Yeah, that makes sense. 
In a highly generic or macro-y situation I can very easily see `&amp;mut &amp;mut` happening. With generics you may end up having something that expects `&amp;mut T` being composed with a case where `T` itself is a mutable reference. 
Clippy is the best we have in this area AFAIK.
RE: getting user input: fn main() { use std::io; loop { println!("Enter Filename."); let mut input = String::new(); io::stdin().read_line(&amp;mut input) .ok() .expect("Couldn't read line"); let mut raster = Raster::new(read_array_from_file(&amp;input)); } } This doesn't work. It panics when it tries to open the file based on user input. However if I substitute the user input with the identical file name hardcoded in, it reads the file fine. I'm using std::fs::File::open to open the file.
&gt; collation sequential primary element Can you give an example, please?
But ultimately they are just expectations. If you really wanted to, you could still just string together POSIX APIs without trying to make things more generic or rely on generic libraries. And then later as you find which libraries become maintained over the years, you can switch to those as benefits the program.
there's nothing stopping ME from posting `carols10cents-` crates either
At the same time, rewriting code doesn't mean you have to ignore the bugfixes in the existing implementation. Much of the discipline in rewriting code comes from resisting the urge to introduce *new capabilities*, rather than directly porting existing capabilities. At least, that's been my (very limited) experience.
I think that's the idea behind the [Platform Abstraction Layer (PAL)](https://internals.rust-lang.org/t/refactoring-std-for-ultimate-portability/4301), which /u/japaric mentions as an eventual future way to integrate this into the standard library. For now, the standard library isn't structured in a way that makes this particularly easy, so it's easier to fork now and be able to experiment, which will help inform what that PAL needs to look like.
I generally shy away from `impl`ing `Deref`. In this case because, your example aside, the member struct isn't typically going to be for the sake of a single variable, but some semantic set of them, and more generally because implicit conversions can get out of hand very quickly.
I used code points when I wrote a statistical morphological analyzer for Russian language, which is non-ASCII. First and last 1/2/3 letters (usually 2/4/6 bytes for Russian) are the most important word parts for morphological analysis and you need to extract them fast to have high throughput. I used code points because the conversion from UTF-8 is very fast and also self-contained, it doesn't need any extra tables and external library dependencies. Even if some Unicode exotics from foreign languages get into the text, they are still statistically insignificant and can't be mapped onto Russian morphology anyway.
Yeah, so for parsing and stuff like this, where you're only *matching* against a string, code points are fine. This is because your input conditions operate on code points (e.g. when parsing your condition is like "is that code point a plus character?", and in your application it's "is that code point one of these n russian chars?"). You're not ascribing meaning to code points here, you're just dealing with operations and conditions that still make sense in the context of code points, because the constants in them are themselves valid code points. I'm not saying code points aren't useful :) But you should be thinking about CP vs EGC a lot more when you're dealing with stuff like this.
Please add: SPOILER ALERT! 😂 Also, I tested this with a 4K Display and it worked fine… Maybe you accidentally set the "magic surprise multiplier" ("scaling factor" on some systems) too low?
My mistake! Thanks for clarifying. :)
Um , that's the point of my whole post, I'm not talking about code points here, I'm talking about EGCs, which are the more natural human "unit" of a string. Basically, a Ctrl-F ending with an e without an accent should not include non-precomposed és.
Lol yeah just realised my mistake XD 
Ah yes I see what you mean. You have to make more library decisions in Rust.
so can we add `type codepoint = char;` to the prelude and deprecate char
If you think *that* is strange, clearly you haven't seen `&amp;mut &amp; _` and `&amp; &amp;mut _` yet. The former can be quite useful, e.g.: let mut hello = "world!"; let mut world = "Hello "; // Here we go, `&amp;mut &amp;str` twice: ::std::mem::swap(&amp;mut hello, &amp;mut world); println!("{}{}", hello, world);
&gt; UTF-16 is mostly a “worst of both worlds” compromise at this point, and the main programming language I can think of that uses it (and exposes it in this form) is Javascript, and that too in a rbroken way. Also Java and most JVM-native languages, C# and the other .Net-native languages, and C++ if you use the Qt or wxWidget frameworks. Not to forget that ICU, the most complete Unicode handling library AFAIK, uses UTF-16 strings in its interface.
Great list. The documentation could really do with some "common borrow checker issues" and a tips bit. As it is now it more or less says "here's how it works, here are some trivial examples to demonstrate it, good luck!". Then you go and try and write some real code and it all falls apart. What you said about not being able to borrow *part* of a struct is a particularly big limitation that you kind of have to find out on your own.
There's a Microsoft tool called Depends.exe that is like ldd for Windows. Maybe that will help?
No, O(1) indexing is useful. I had to parse a text file format in C#, I simply converted it to the built-in `string` type and used string operations to extract the necessary information. C# uses UTF-16 strings and allows indexing them (which is wrong in general case but I only had to deal with latin and cyrillic characters which always take one UTF-16 codepoint). If I used Rust it would be much harder to do it: 1. If I convert it to `String` I will lost ability to easily index it and take substrings by indexes. 2. If I keep it in its original 1251 encoding and use `Vec&lt;u8&gt;` I will lose all the handy string operations and ability to declare cyryllic string literals in my source code (because these literals would be utf-8). 3. If I convert it to `Vec&lt;char&gt;` this would have the same disadvantages as the option 2 above. Thankfully I was using C# which doesn't have this attitude that if its wrong it some cases we should never do it, and instead provides solution which works in most usecases.
It even had a choice of two algorithms for delimiting graphemes.. Which sort of sends the signal, unicode is complicated and what algorithms to use for "proper handling" is application-specific.
Btw. building static binaries is already possible using MUSL; I'm doing that with my web project: https://github.com/golddranks/ganbare Check out the docker files, they are quite well documented. (I have two: one for building, since setting up the cross-compiling environment on macOS was a pain, and one for running. That uses the "scratch" base image.)
&gt; I'm looking at you, French conjugations. I never realized how difficult French could be until I started helping coworkers learn the language. I still remember a discussion that went: - me: "ent" is pronounced "an" as in "flan" (a cake) - coworker: really? when I say "ils chantent" (they sing) though I don't pronounce it right? - me: of course, it's a verb - coworker: but if I don't know the words, how can I know it's a verb? - me: well... the grammar may help... uh... Amazing all the things you don't notice as a native speaker oO.
That was what I understood from the bit talking about searching for glyphs after you talked about the irc client. Perhaps it was just my misunderstanding. I'd suggest to at least mention ligatures if talking about fonts. I don't understand what would be a valid use case to query the font or glyphs for text editing, it's just a display thing, isn't it?
You need to ask that at /r/playrust
Go: result, err := call(); if err { return err; } Rust: let result = call()?; =&gt; the type signature is complete, like in Go, but unlike Go it's also rather painless to handle errors.
Just an idea: keeping a minimal container with the libs/compiler you want may be easier. You could maybe even use only chroot to run the compiler.
[Alternate version](https://play.rust-lang.org/?gist=01dd4c569e415c87e43327988e59e6ce&amp;version=stable&amp;backtrace=0), using the trick that putting an expression in a `{block}` forces it to be moved instead of reborrowed.
If I ever get elected President of the United States, I'm having you head the Department of String Primitives.
If you're parsing a text format, you can just use `as_bytes()`. Look at how pulldown-cmark does it.
Hi /r/rust! This is my first advertised Rust project. It's a small HTTP to HTTPS redirector. Even though minihttp implement just the bare minimum of HTTP, this task seemed really suitable for it.
There's always the indexing trick; where a struct has a `String` and you feel you want to keep a `&amp;str` ref to it as well; keep the slice bounds instead and define a method to provide the slice to those that need it. If the struct has a `Vec`, then likewise. It really is an old C habit that gets tricky in C++ as well with move semantics.
Has someone started working on a replacement for ICU in pure Rust? It's scary that Unicode gets bigger and bigger each year, now even with multi-colored glyphs, and a reasonably safe icu.rs would help a lot to trust the code. Maybe expand Raph's unicode crate, which is also used by Servo, into something complete.
Yep, part of the exciting part about steed is that if it works out, you avoid the pain of setting up the cross-compiling environment on macOS. Technically, I think it will take steed and getting lld fully working and distributed with Rust, but that's [another thing japaric is working on](https://github.com/rust-lang/rust/pull/36120).
older thread with more comments at https://www.reddit.com/r/rust/comments/5o1fzu/lets_build_a_standard_library_std_free_of_c_code/
Ask them if they've ever been paged in the middle of the night because of a `NoneType object has no attribute...` or `NullPointerException`. :)
I guess it solves a mental tax that can sometimes be frustrating with C/C++. Namely writing boilerplate to write memory safe code, that is also robust in error handling. Rust gives some new things that you have to keep in your mind, but I feel it's at a level where your are given guarantees and from those your can confidently build up semantics. For example, I really like the use of functional iterator semantics in conjunction with safe borrows. Instead of writing loops, just construct a lazy iterator and map it onto a closure to process it. It's amazing how easy it is to build up robust features quickly, and with incredible performance. 
I also discovered that rustc spends a scarily amount on time on release builds with lot of meta data, and wonder if anyone out there knows what the problem is. Seems very straight forward code to me. It has been the longest built on any project I've done so far. Could it be LLVM? See my comment https://github.com/PistonDevelopers/dyon/issues/430#issuecomment-272698220
Five things: 1. A way to escape the hegemony of C erected due to unfortunate events in the 1980s where safe systems languages lost to Unix and C and that way regain a little more confidence in all the code talking to the Internet or processing random input. 2. A familiar syntax for all the C and Java coders which will attract enough users that it'll be realistic to replace many C and C++ libraries with pure Rust which is more comfortable and harder to make mistakes in. 3. Getting rid of the distinction between .h and .c with crates 4. A macro systems that's not very comfortable but safer and more powerful at the same time. 5. Much easier cross platform story in a statically compiled language.
IIRC Japanese word boundaries are easy to calculate? In Thai there are basically rules on the form of a word so you know where the word ends by analyzing its characters, so it's very nontrivial.
&gt; I don't understand what would be a valid use case to query the font or glyphs for text editing Text selection is a valid one. Most places don't do this, but you might want to do text selection on rendered glyphs. For Indic consonant conjuncts, you _probably_ want to do this but nobody does.
http://github.com/unicode-rs/ does some of the operations from the unicode spec.
Nitpick: In Chrome I'm pretty sure it includes é whether it's precomposed or not, and I think that's the right call. Yes, there are false positives, but it makes searching a lot easier, especially for users with ASCII-only keyboards.
Actually just really simple ODE integrations using explicit Runge Kutta methods, sometimes with some orthogonalization and diagonalization mixed in. I'm primarily interested in stuff like Poincaré sections and Lyapunov spectra. The main difficulty with my systems is that you cannot really parallelize their evolution, so everything is sequential. That's why I need to make sure that my integrations are fast. :) From time to time I might need Fourier transforms for power spectra, adaptive time solvers or solvers for stiff ODEs (so implicit methods), but that's really rare. Then there is also the inverse problem of finding e.g. Fokker Planck coefficients from time series. For stuff like that Monte Carlo and Kernel Density estimators are needed... But I almost never dabble with that. 
Yeah, for my (limited) knowledge, Rust don't support yet OMP pragmas and vectorization one. 
One thing that I like a lot about rust is how a function can return multiple values, of which some might be optional. For example, in a ray-tracer you'll need a find_intersection(ray :Ray) -&gt; Option((distance :f32, se :SurfaceElement)) function (added names for clarity). In C++, if I recall correctly, the way to go was; bool find_intersect(Ray ray, float* dist, SurfaceElement* se) Which is pretty awkward. (I'm not an expert in c++ and don't know how other languages might do this). 
Actually, I just realized the bug is not in grapheme segmentation, but in word segmentation. The grapheme rules are still complicated (mostly because emoji), but I think our grapheme segmentation impl is correct now. Ignoring the fact that the tables haven't been updated by Unicode yet so some emoji zwj sequences (firefighter emoji, for example) aren't considered single EGCs.
Isn't that just the GC vs EGC stuff? Unicode explicitly specifies both :)
If you're parsing you're iterating through it anyway. And, like /u/matthieum said, it's O(1) to index by bytes. As for dealing with other encodings, Rust doesn't forbid you to do that, just that the builtin literals don't handle it. http://doc.servo.org/tendril/struct.Tendril.html will help. 
Yes, you are right, there *appears* to be nothing there, but if you magically know where the modules are, e.g. [lint](https://manishearth.github.io/rust-internals-docs/rustc/lint/index.html), you'll see it's there ;)
That worked! Thanks!
Yeah, legacy GCs don't matter much.
To be honest, I don't care much for the cost of writing code. I hate boilerplate because of the cost of reading code: 99% of the time it's boilerplate, but 1% it's a subtle variation that bears consideration, so that when reading you always have to pay attention to it to check which it is.
It isn't that obvious. In C and C++, `&amp;&amp;x` is invalid: taking the address of a temporary ("r-value") is disallowed, only things with memory locations that the programmer has declared, the compiler won't implicitly create a stack slot for the innermost pointer. The difference is that the Rust compiler can detect dangling pointers, whereas the C and C++ ones cannot and so this rule helps stop people shooting themselves in the foot.
nit: &gt; For now, here are the three big issues for Rust documentation: There are only two issues mentioned here?
If it's write-once code then I could deal with it, but without a generator AKA syntax sugar this gets annoying quickly and, as you mentioned, unnecessarily worsens readability. But the opinionated idioms of Go are certainly a boon because they free you of having to make choices.
I think the whole approach is doomed from the start. It seems to me you would have to call this before each allocation just to be sure you won't violate the limit. Of course once you have multithreading this becomes a nice race condition: Thread #1: I want X MB, is there enough memory available? It seems so. Thread scheduler: Thread #1, I preempt thee! Thread #2: I want X MB, would that be under the limit? It seems so. Thread scheduler: Thread #2, I preempt thee! ... Thread #n: I want X MB, would that be under the limit? It seems so. Thread scheduler: Thread #n, I preempt thee! Thread scheduler: It sure is quiet now. Thread scheduler: I will now reactivate n threads that will all allocate X MB (muhuhuh). Thread #1: Allocate X MB! Thread #2: Allocate X MB! ... Thread #n: Allocate X MB! OOM Killer: DIE YOU FILTHY GLUTTONOUS PROGRAM! Checking whether a resource is available before claiming it is usually quite pointless in the presence of concurrency. It's like checking whether a file exists before opening it, why would you when the file might disappear between the 'exists?' and 'open!'? RAII is your friend. I think the right way to go about this would be for *all* operations that allocate memory to return `Result&lt;T, OutOfMemory&gt;`. Naturally this requires you to reinvent large parts of libstd, because this is not compatible with its current contents. Of course your strategy will *usually* work, and if you have only one thread or sufficiently overestimate `MINIMUM_REQUEST_MEMORY` you'll probably never see it fail. I just don't expect something that could theoretically fail to please the people who complain about the abort-on-OOM behavior in Rust :)
As u/dbaupp mentioned, parallelization along the lines of omp seems to be solved by rayon. The parallelization issue I mentioned above are intrinsic to my system and have nothing to do with rust. Though simd support along the lines of d's mir glas would be nice.
[Here](https://graydon2.dreamwidth.org/218040.html) (things rust shipped without) you have the answer to your question :p .
Faster than nginx?
Well, `Vec`s own and can resize their storage, so you cannot simply cut the `Vec` in two and expect them to work as new ones. If you had a `Box&lt;[u8]&gt;` instead, it would probably be easier.
The Rust compiler uses LLVM, and as such you cannot (at this time) compile to platforms that are not supported by LLVM. Rust doesn't have varargs.
Fixed, thanks!
Project configuration with macros a la #define _WIN32_WINNT 0x0A00 automated by something like CMake. Rust/Cargo features are extremely limited in comparison. "Selective" static array initialization const int table[10] = { [POSITION_A] = 10, [POSITION_B] = 11, // All other elements are 0 }; Conditionals in constant expressions, including the preprocessor (and other math in the preprocessor actually) #define A (CONDITION ? VARIANT1 : VARIANT2) Unsafe variadic functions. `goto`, less restricted `switch`(Duff's device). `sizeof`, `alignof`, `offsetof`in constant expressions. Bit fields. &gt;untagged unions in Rust are a work in progress Hey, they are completed, they are just on unstable channel (which is, of course, the true Rust, compared to Home Edition stable).
Thank you for the feedback! &gt; I think the whole approach is doomed from the start. It seems to me you would have to call this before each allocation just to be sure you won't violate the limit. The idea is that you'd do this centrally, in a global dispatcher routine, with a fairly generous per-request minimum, and that you already have some other backpressure system in place to prevent an unbounded number of incoming requests. The alternative, as far as I can tell, is catastrophic, cluster-wide failure. Here's how it plays out: 1. Each backend server can handle 100 simultaneous requests before the cluster scheduler kills it, and there are 10 backend servers. The site is currently handling 1,000 total requests. 2. A 1,001st request is added. This is routed to server 1, causing it to run out of memory and crash, failing all 101 requests. The cluster scheduler will notice this and spin up an extra server container, but this will take approximately a minute (assuming we're on a system like ECS). The users all hit reload in their browsers. 3. Now we have 1,001 requests and only 900 slots. Our 101 extra requests will be evenly distributed across all our remaining servers, causing all 9 of them to crash. 4. Server 1 finishes restarting, thanks to the cluster scheduler. It's now hit by 1,001 requests, and promptly melts down again. The correct fix is to simply reject the 1,001st request (load shedding). If we have a properly designed backpressure system, we could even say, "Hmm, I have 500MB of RAM available and I know it takes roughly 50MB of RAM to handle one request. Let me announce demand for 10 requests." And if the inbound number of requests exceeds the advertised demand from all works, we can start rejecting requests and start booting up more worker instances. It's basically like balancing a game of [factorio](https://www.factorio.com/). :-) &gt; Naturally this requires you to reinvent large parts of libstd, because this is not compatible with its current contents. This isn't going to happen for any of the server applications that I work on. The Rust ecosystem is already sparse enough without throwing out everything that uses `std`. I do agree that for kernel mode and embedded use we should have a version of `collections` which returns errors on allocation failure, though. Anyway, thank you for your comments!
Rust can't do alloca. Not that you should use it in C though, unless you know what'cha doin' :P However, as of late, there has been some design discussion about supporting safe alloca in Rust.
Rust does have those in [std::mem](https://doc.rust-lang.org/std/mem/index.html), they're just not evaluated at compile time (unlike C where `sizeof` is compiler magic).
I've been toying with the idea of making a documentation linter for quite a while (see also [cargo-deadlinks](https://github.com/deadlinks/cargo-deadlinks), which was not a "real" linter). Then two weeks ago I saw /u/carols10cents [comment](https://www.reddit.com/r/rust/comments/5le832/rust_is_please_read_one_and_all/dbv95bz/) about a [spellchecking PR to the book](https://github.com/rust-lang/book/pull/338), and thought "Hey, every Rust project should have that!". Looking through the source of it, I was really surprised that there is a widely available tool to do easy spellchecking (in hindsight, why wouldn't there be?): aspell (and ispell and hunspell). So here I now humbly present the first version of `ronat`, which really does just the bare minimum of spell checking as a Rust compiler plugin.
Yes, Cargo does support [build scripts](http://doc.crates.io/build-script.html).
&gt; Rust's real strength is basically as a better C++ with [...] a better cross platform story What do you mean by this? Because I still use C++ for these kinds of programs primarily because C++ supports the platforms I still need to run on, and Rust (LLVM) does not. 
On this note, does the Rust core language have any plans to make it possible to catch OOM conditions? 
What do you mean? To some extent those must be evaluated at compile time even if it's part of a full-featured run-time type info system.
I was actually working with BoxSlices/Raw Vecs. The issue was if I re-alloc in place I seem to de-alloc the rest of the buffer. I was just going though the heap API. [here is my current attempt that is segfaulting](https://play.rust-lang.org/?gist=a1bb7cd82b4ad59b28fb0d75e0d2151d&amp;version=nightly&amp;backtrace=0)
I am very excited about the metaprogramming (macros), although that story isn't really complete yet. I'm secretly a LISP guy at heart but I work in embedded (which means C), so every time I have to write some convoluted preprocessor macro (or worse, push something that should absolutely be knowable at compile time to runtime) I die a little inside.
I don't know the state of `impl Trait` return types, but maybe they will soon make these kinds of error messages shorter …
i don't think that checking before every allocation is viable, but using this in a way you present in readme might be very helpful. If you are working with system based on requests, it might be useful to be able to reject/ postpone request processing when memory is running out. Or maybe dynamically adjust cache sizes when you know that larger caches of your application will just get swapped to the disk.
That I'm using the Teensy for this is really just coincidence - Rust can target it, and it's hardware that I have on hand. The goal is to get people thinking about what safety means for hardware, not to build the perfect Kinetis library. There are already a number of compromises in the code to make it easier to talk about (some of which I want to fix up in later posts as separate teaching moments) I'm definitely interested in spending more time interacting with the Rust embedded community, though! This has been mostly a self-taught solo effort for me. Is there an IRC channel folks hang out in? 
It's already possible isn't it (assuming unstable), just check for null after calling [allocate](https://doc.rust-lang.org/alloc/heap/fn.allocate.html). The standard library (which I assume you don't include in the "core language") just happens to choose to abort when that happens.
Bit fields are available as a [procedural macro](https://github.com/dzamlo/rust-bitfield/), but I'd love to see them as a built-in language feature at some point. 
Hey! I've been following Dyon since that first blogpost about it; I really like it looks superb. I'm just a beginner programmer though so I can't do much with Piston yet, however looking forward to using it when I can.
Oh shit!
Yes, in the beginning I wanted to do that, but there were multiple reasons why I decided against it. A big one is that it required additional dependencies (markdown parser) to get to a workable solution. With some more lints in the direction of grammar checking / NLP, that would introduce even more external dependencies. I also think that the lints in `ronat` will be much more configuration-heavy (in part because of the dependencies), which I don't think would fit in very well with clippy.
Cargo is used to build the compiler and standard library: https://github.com/rust-lang/rust/blob/master/src/bootstrap/README.md
Coming from C#/Unity - a lot easier to implement many things without garbage collection and an unreliable engine getting in the way.
&gt; Project configuration with macros a la I know it' a workaround, but `build.rs` should be able to generate a `src/consts.rs` or something like that based on features passed to `cargo`. Or am I wrong?
I really like the JVM behaviour for server applications. We have a backend system running on its own VM with -Xmx=3072m and -Xms=3072m. This combination practically ensures that the system doesn't get hit by Linux' OOM killer. Last year we had one request fail with an OutOfMemoryError. The reason was a bug in an untested code path, that was executed the first time after the system was already in production for half a year. The bug caused the buildup of a huge DTO that was first serialized into a byte[]. The allocation for the byte[] succeeded. Then this UTF-8 had to be decoded as String, but the allocation for the String failed with an OutOfMemoryError. The error was logged with a full stack trace, and all other parts of the system (sending and receiving messages, executing scheduled background jobs) continued operating normally. We didn't consciously design the system to survive an OutOfMemory error. A hypothetical Rust implementation by us would have caused unrelated requests to fail as well. If the JVM can do it, couldn't Rust provide a portable function in the standard library to limit the heap size of the process, and also unwind the allocating thread, instead of aborting the process? 
Error-handling with algebraic types, stupid simple performance optimizations without worrying about segmentation faults, managing and importing dependencies with cargo, test driven development built-in, and very easy to perform large amounts of refactoring often.
The ndarray repo has a Game of Life example in the `examples` folder, if you need help getting started.
There's nothing funny about `unsafe`. There's nothing wrong with `unsafe`. It's not a joke or a trick. It is there for a good reason, so if you're to compare C and Rust, you must not ignore `unsafe`. Some people in Rust community spread an attitude that `unsafe` is some kind of a problem, want to count them, display in red and so on - making it feel like there's something wrong with it. But there really isn't.
Nitpick, but rust can do conditionals in macros too, the right-hand side of a C preprocessor definition doesn't know anything about conditionals.
Sounds reasonable. Thanks!
Didn't know about rayon. Thx! 
You'll probably get quicker responses if you also explain what you're trying to accomplish in plain English so we know which details are significant and which ones are just part of the approach you decided to take.
At some level, there will always be a need for unsafe operations (in all senses of unsafe). With the way I asked the question, I was just trying to pre-empt unhelpfully smug answers comparing Rust to C.
A linter for… human languages? What a great idea! I keep making mistakes in those! Other than that, I initially thought you'd taken up my ideas regarding [doc comment style](https://scribbles.pascalhertleif.de/machine-readable-inline-markdown-code-cocumentation.html), or maybe even wrote a linter using something like [this](https://github.com/killercup/rust-docstrings) :) PS: Oh, and [also](https://github.com/killercup/english-lint)… :D
The right hand side of a `#define` is just an arbitrary sequence of tokens that gets pasted in place of the name, the preprocessor doesn't care or understand what those tokens are until they've been pasted. The example in the top-level comment doesn't do anything with the ternary (which is what I assume was meant by "conditional") that Rust can't also do: the right-hand side of macro definitions are not places that require constant expressions in C.
Oh, I've never seen someone do that; thanks for the example. (I just edited my parent comment to add "the right-hand side of a ... definition", which is what I was trying to convey originally anyway.)
I was thinking of this the other day! It should be named "libr" though.
I was surprised to find that there wasn't another crate that does this. Adding "Access-Control-Allow-Origin: *" to all responses in an Iron project is easy, but host based filtering takes a few lines of code to implement. After implementing that feature in a project of mine, I thought it could be useful to others and extracted it into this crate. Preflight requests are not yet supported, but "Access-Control-Allow-Origin: *" and a host-whitelist based approach are already implemented. The crate is (hopefully) well documented and tested. There's [a clone()](https://github.com/dbrgn/iron-cors-rs/blob/master/src/lib.rs#L93-L94) that I'd like to get rid of though. Any pointers?
I know a lot of people work on Unicode and it is very standardized and the goal of having all written word represented coherently is a noble one... But uhhh... maybe it's more trouble than it's worth? I feel like no one can fuckin understand how to use it because it's such a crazy superset of all language.
I feel the same, but the only thing I wish Rust had was mature and expansive libraries (this comes with time and is highly unreasonable to expect it this early into it's lifespan) among the likes of Boost, QT, and etc. Most of the ecosystem are essentially bindings, but I think it will give Rust a very nice PR boost to have it's own pure Rust version of an extensive library. But I agree, there is an excitement that comes with uncharted territory. You feel like you can have an impact on it's ecosystem and growth. 
This is an interesting idea—Rust could certainly handle failed allocations with a panic, and panics can be caught.
Hmm, at least with GCC, `&amp;&amp;x` seems to make the compiler complain that the label `x` isn't defined. I offer three defenses: first, I grew up on Visual Basic where taking the address of a temporary was *perfectly fine*, and I've never really accepted C++'s *not* being able to do this. Second, C++ is hardly a paragon of good design, so I don't see why its limitations should necessarily imply anything about Rust. Finally, even if it didn't make sense, with the way Rust's grammar is structured, it'd probably still be valid *syntax*... just not valid semantically, so I feel I would still be *technically* correct.
&gt; What happens if you feed it a bazillion distinct grapheme clusters, I don't know. A 20 minute exchange a couple years ago between nwc10 and jnthn that started [here](http://irclog.perlgeek.de/perl6/2015-04-07#i_10400549) may be informative.
What we had before Unicode (a million different encodings) was more trouble than it's worth. Unicode is better. If we're to have an Internet and software that works for everyone, we need something like this.
And not only PR boost, it helps with building and especially with cross-compiles too. Rust crates are tremendously easier to cross compile than native dependencies :)
Couldn't someone just do a grep and then set exception breakpoints in their favourite IDE to track it down?
I found a tracking issue for this: https://github.com/rust-lang/rust/issues/27700
&gt; Unicode doesn't really work for anyone. Languages and scripts are hard. This is not a Unicode problem. This is a fundamental problem.
What is a "smol"?
Yep, this works! I'd completely forgotten the proper method for passing lifetimes as generic parameters.
I hope it is clear that my suggestion was not serious. The intent of such a try-catch is not to aid debugging, but to prevent people from paging the developers in the middle of the night by making them think the unexpected software shutdown is somehow *their* fault. If those people are able to access the source code, fire up a debugger, and set breakpoints, obviously they have things under control and don't need to start paging sleeping colleagues.
How about: pub struct CorsMiddleware { allowed_hosts: Option&lt;Rc&lt;Vec&lt;String&gt;&gt;&gt;, allow_invalid: bool, } The clone would remain the same, but it would be a cheap integer increment rather than an allocation. In addition, I would recommend using a `HashSet&lt;String&gt;` instead of a `Vec&lt;String&gt;` because its `contains` scales better (of course `Vec&lt;String&gt;` is better when the whitelist is short).
&gt; I hope it is clear that my suggestion was not serious. I know :\^). &gt; The intent of such a try-catch is not to aid debugging, but to prevent people from paging the developers in the middle of the night by making them think the unexpected software shutdown is somehow their fault. Ah, the good ol' [Wing Commander school of trickery](https://redd.it/3bmszo). 
Yes, see [here](https://is.gd/a5QXXQ). Note that we had to get rid of the associated type in order to match the return type of `get_foo` to the return types of the two different `new` methods. Also notice that we had to take `&amp;self`. Without taking some sort of `self`, there is no way to determine the appropriate function to call when using dynamic dispatch. For more on this, see [this StackOverflow question](https://stackoverflow.com/questions/38159771/why-can-a-trait-not-construct-itself).
Try pronouncing the name.
Like "small"? You should write it with [this](https://en.wikipedia.org/wiki/International_Phonetic_Alphabet).
Oh, sweet. Thanks for this! I have an old side project with hacks to just allow all cross origin requests with a big "TODO delete this evil" comment.
Merci pour le post! Le lien à votre page d'accueil ne marche pas - il a besoin d'un `/` au bout.
It's just a silly way of saying "small." It gets used a lot on r/rarepuppers.
&gt; When we are talking in a single language, we don't expect the rules of other languages and their writing systems to be in play. I regularly chat with my friends in a mixture of two scripts. Sometimes a mixture of three languages (two share the same script though). You will regularly see English text interspersed in other scripts in many countries. This should not be something hard to do. &gt; When we are writing software though, we now have to understand the fundamental limits of every language? Yes? If you want your software to work for people all over the world? If not, just use ASCII or Latin-1, and declare your software English-only. &gt; I just don't know exactly what we're getting for the trouble. A Web that actually works for other scripts, for one.
Only because you're not able to create the same name for yourself since I took it first. If I find a new project on your github I could squat the crate name before you get it up on crates.io
IIRC Linux, FreeBSd, NetBSD maybe OpenBSD all have stable syscall abis
I think you fixed the bug while simplifying the code. I [mocked up](https://gist.github.com/e3111c3f134bfc1dc2af669193ddbb31) the missing functions and it runs fine: Enter Filename. blarg 1: TASK 1. 2: TASK 2. 3: TASK 3. 4: TASK 4. 1 task 1 1: TASK 1. 2: TASK 2. 3: TASK 3. 4: TASK 4. 2 task 2 1: TASK 1. 2: TASK 2. 3: TASK 3. 4: TASK 4. 3 task 3 1: TASK 1. 2: TASK 2. 3: TASK 3. 4: TASK 4. 4 task 4 1: TASK 1. 2: TASK 2. 3: TASK 3. 4: TASK 4. ^C My guess is the original code missed one of the recursive `get_task` calls. As an aside, using unconditional recursion like that, instead of a loop, will eventually overflow the stack.
Joke's on you, I put my secret stuff on gitlab! :)
If we're doing this for the web then that explains why Unicode is so hard to work with. Literally none of the web technologies are well thought out and designed. They're just patches on top of patches for what was originally supposed to just be a way to write documents that linked to each other. Oh well, I guess we're stuck with bad decisions for the rest of eternity.
&gt; Those optimizations are only available to Rust on very limited occasions, i.e. if rustc can 'prove' to LLVM that certain preconditions hold. On the other hand, Rust guarantees non-mutability of non-mutable references and uniqueness of mutable ones, which opens a whole world of possibilities that can never be used in C even by the most aggressive optimizer.
Rust is one of the worst at this. It still explodes my head to read things like: fn apply&lt;A, B, C, F, G&gt;(mut f: F, a: A) -&gt; impl FnMut(&amp;B) -&gt; C // must still be `for&lt;'r&gt; impl FnMut(&amp;'r B) -&gt; C`, because that’s what filter requires where F: FnMut(B) -&gt; G, // must not be `for&lt;'r&gt; FnMut(&amp;'r B) -&gt; G`, because regular functions do not implement it G: FnMut(A) -&gt; C, B: Copy, // for dereferencing A: Clone { move |b| f(*b)(a.clone()) // this must do any bridging necessary to satisfy the requirements } even with comments, this is just really gross to read
&gt; C has goto, which is unavailable in Rust, despite it's usefulness for state machines (keeping and dispatching on a state variable is only the second best solution). The Rusty way is to use parameterized `impl` in concert with the transition functions consuming the old state, so that the compiler can verify correct use of the state machine. (eg. Hyper uses it so that mistakes like setting an HTTP header when headers have already been sent are ruled out at compile time.)
Is there any way I can use thread-local variable from shared library in rust? Variable is defined as this in header file: extern __thread int lib_error; Trying to get it into rust like this: extern { pub static mut lib_error: c_int; } produces an error: TLS definition in libtest.so section .tbss mismatches non-TLS reference in rtest.0.o
I would think not as glarea likely manages its own gl state which would conflict with glium. You would likely need to reimplement your own version of glarea using glium.
Hmm ill have to check it out then :)
&gt; I would think not as glarea likely manages its own gl state which would conflict with glium I do not believe this is the case as it would make GLArea almost entirely pointless. It's specifically meant for applications where you want to use OpenGL to render inside of the GUI The problem I'm encountering is creating the glium context.
Importing other files in Rust in reasonably easy. I don't know why people would do this. Maybe if you can collapse blocks in your editor you can have massive files.
Forgive me if I'm being dense, but I don't really understand what this utility does. What is a "fuzzy finder"? It kinda maybe looks like a file navigator? But an example pipes `find` into it. It also maybe kinda looks like a text filter, and says to use it instead of grep, but then kinda looks like it integrates with `ag`? I just find the description very confusing. 
Depends on the kind of state machine. I was thinking of things like network protocol client libraries where the state machine has to be driven externally if you want a sane design.
If you have ever done something like: $ find . | grep something ... $ find . | grep 'something.*specific' Then tools like skim and fzf make it nicer, by behaving like an interactive grep. In particular, I have my history-search command piped through `fzf` so every time I `ctrl-r` in the terminal I get an interactive search through my history that shows a bunch of lines that match, giving me the ability to filter down to exactly what I want to type. It's amazing. 
How do you customize ctrl-r to do that? Edit: Nevermind. I'm an idiot. Shell integration comes with fzf. It's in fzf's readme.
Now that I think about it, I really think this is this "uncharted territory excitement" that drives me to Rust. It took writing this post for me to realize it, I had not realized that at all when I started writing it.
I guess, because the base language of my website is french? I managed to setup multilingual setup with pelican, but my base theme is french only :/
Having multiple libraries is perfectly fine. This is how software has always evolved, and will continue to evolve. It is simply a matter of natural selection, regardless of what language you choose. If a library is good, then it will see adoption. If it is no good, then it won't see adoption. Eventually, solutions converge until the best solution is culminated. Cargo has merely allowed this process to advance at a faster rate than what was possible before. Having a massive crate containing random functionality is never a good idea, because then you end up with a jack of all trades and ace of none. You end up with a library that is difficult to manage with little mobility for integration into other libraries. Instead, there is a trend in Rust for large projects to split their generic functionality into a series of crates. The Piston game engine project, for example, has spawned a number of crates that are useful in a wide range of areas, such as `image`. It would be silly if a web browser had to import a game engine just to take advantage of that engine's image library, for example. As for web frameworks, there's already a lot of work being put into this territory with a number of different frameworks being worked on. There's been good progress made in this area, and that outlook is only getting better each day.
Parceque c'est la langue de /u/levansfg. Ou _une_ langue qu'il parle. Nous avons une grande communauté française, et il est un membre actif. Discuter dans d'autres langues ici est très bon. /je devrais rejoindre #rust-fr
I really hope this changes in the near future, as I'm *very* interested in writing some mobile apps with Rust. For now, I'll probably have everything be a library called from Swift or Java, but it would be very nice to have this work well.
On the other hand, it is not a good idea to have the user list all the separate components of a game engine when they actually do want the default game engine in order to just get things done and only worry about their actual game. Boost is actually a *modular collection of libraries* and a user can pick and choose which parts they want to use. I hope Rust grows a few Boost-like cargo meta-packages that in turn aggregate other crates in order to provide sane defaults for those production users that don't want to spend the time &amp; effort to research each individual tiny crate they need. 
 Does rust have setjmp/ longjmp ?
I know that the unit tests are kept in the same file because the public/private access control system operates on a module-by-module basis (to call private functions and play with other private things, tests have to be in the same module) but I don't have enough experience to weigh in on the rest. As a Python developer, I like to keep my Rust source files short too. That said, based on my experience with Python, I'm generally wary about being too quick to DRY. It's very easy to misjudge a problem's inherent complexity (eg. not noticing subtle differences, mistaking "looks similar" for "is semantically similar", etc.) and end up with a solution where, by the time you get it working, it's just the old syntax in newer, harder-to-maintain clothing. However, I could be wrong there. It's entirely possible that someone might be able to write something that'd compact it down to something like this. I haven't really dabbled in macros yet. add_debug!(&lt;'a, T: 'a&gt; for Drain&lt;'a, T&gt; as "Vec::Drain { .. }") I know that, in a lot of places, just sticking `#[derive(Debug)]` above your struct is a perfectly good solution. Also, for historical reasons (the Rust language changed a *lot* before 1.0 and the compiler had to follow along), it's fairly well known that the Rust compiler is very much *not* an example of idiomatic Rust. They always welcome people willing to volunteer to help tidy it up.
Maybe rustc can take advantage of those properties now that its uses MIR?
Sounds like we should add a `fn close(self) -&gt; io::Result&lt;()&gt;` method to `File`. We probably can’t change the fact that `Drop` closes files, but we can add `close` recommend using it instead. Could you file an issue? (Having `close` moving / taking ownership of `self` seems to make sense, but it could be inconvenient at times. But if it’s `&amp;mut self` it can’t prevent the destructor from being called, unless we add a flag to the struct or something. Is it bad to double-close a file?)
The problem is that that data only becomes available *after* const-evaluation, at least in current Rust. It's kind of a chicken-or-egg thing. 
&gt; maybe OpenBSD Definitely not &gt; FreeBSd, NetBSD Not to my knowledge, although I am open to evidence. That they don't change every other release does not make them stable let alone a supported api which is the bar you want to clear. 
Maybe you could define Empty type and a trait IsEmpty with single fn is_empty() -&gt; bool. Whenever you want to do check, you call is_empty. The compiler will optimize it away. (If you want to be sure, you can force inline that fn.)
Perhaps you can create a [`HeadlessContext`](https://docs.rs/glium/0.16.0/glium/glutin/struct.HeadlessContext.html)? (I don't know how to do it) It implements [`GlContext`](https://docs.rs/glium/0.16.0/glium/glutin/trait.GlContext.html) but doesn't have its own window.
LLVM takes advantage of some of it. We don't give LLVM full aliasing info (not sure if LLVM has that support), and LLVM doesn't optimize it.
Yep! I picked this other emu up just for fun and was still working on it when I was thinking of streaming again and just thought why not stream this too; it will be "done enough" soon anyways :) . I expect to pick up the n64 emu again at that point, which should be pretty soon.
Thanks, I'll remember `Rc` for next time. But this time, it actually turned out to be simpler than I thought: https://github.com/dbrgn/iron-cors-rs/pull/1 Regarding HashSet, thanks for the hint: https://github.com/dbrgn/iron-cors-rs/commit/5dedc000edd4cfb1c2f5a3916e16e7bd65a87829
I'm not the author, and I'm not sure if he reads /r/rust, so you might want to open an issue on GitHub to ask.
Yes. As you can see there, `Response` is generic over a parameter which can take states like `Fresh` and `Streaming`, but methods are only `impl`'d for the states where they make sense. The compiler can then catch nonsensical operations at compile time as a simple case of "no such method on that". It's actually possible to get most of the way there in C++, but it's Rust's "a method can consume ownership of its parent struct and return a new one" combined with `let`'s type inference that really make it reliable and comfortable.
That's basically what `close(2)` suggests: &gt; A careful programmer who wants to know about I/O errors may precede &gt; close() with a call to fsync(2). 
Setting the file descriptor to -1 would allow you to "safely" double close. Closing the same file descriptor twice can cause a race condition where a someone opens a file after the first close and the 2nd close closes someone else's file. It my expectation that `std::fs::File` always represents an open file. (Note that `std::fs::File` is just `File(RawFd)` on Unix.)
&gt; DRY is encouraged; common code is extracted and imported into multiple places. In Rust this is often done with macros (sometimes for internal use, eg. to define 10 instances that have the same boilerplate)
You can actually keep the same API by doing a sort of inverted version of this: https://is.gd/GhjDQr This example uses `!`, but you can also create your own `NoParams` type that can have a dummy impl of `Deserialize`. The issue, in both cases, is going to be that the current specialization rules are pretty restrictive &amp; make it difficult to handle the fact that there are 3 different params you want to specialize on in the same trait. With the 'intersecting impls' enhancement this would be more straightforward. IMO this is a very important use case for specialization in general. Without specialization, failing to implement some behavior for an endpoint would be a type error. With this pattern, you can instead allow users to accumulate additional behavior on the endpoint and your framework can extend what it does appropriately.
Also related: void foo(int size) { int arr[size]; 
I want to make hobbyist video games with reasonably complex mechanics and a DIY engine stack. I want a language that compiles to easily distributable (no need to think about runtime installers, you should just be able to download an .exe and run it to start the game) native binaries for Windows and Linux. The games will involve some interesting algorithms that they want to run on every frame, which at least used to rule out interpreted languages like Python efficiency wise. I'll also forget what I was working on months ago and will appreciate a type system where I can encode my design ideas and then have it work as a safety harness. C++ is ruled out by annoying busywork like header files, having to remember to disable implicit footguns like automatic copy constructors in classes that shouldn't have those and constant annoyance with not having established conventions for build systems, symbol naming, module structuring and dependency management. C is less annoying, but [doesn't really do](http://nethack4.org/blog/memory.html) the no-GC thing in a way that's acceptable in this day and age like Rust and modern C++ do. C# is okay. It's gotten a bit bloated, but it still hits a pretty nice level of expressibility and typing. The hit against it is dependency on the heavy runtime, which you're usually expected to install separately. There are probably tools for packaging a C# runtime and an application into a single exe file, but I haven't looked into it. Go is pretty good. I feel like I can fit the whole language in my head in a way that I still can't with Rust, which is great. But Go seems to be fine-tuned for the sort of old-school Unix style where you write small, single-resposibility tool programs from scratch and hook them together in the OS. The target complexity of the games I want to be writing is higher than for the ideal Go programs, and at that point I start needing heavy library machinery, and heavy library machinery needs type parametrization, which Go doesn't have. I did work with Go before switching to Rust and found it very fun, so there is that. Nim and D are intriguing, but both suffer from lack of ecosystem mass. Nim isn't picking up steam and D seems to be losing ground to Rust as the up-and-coming C++ replacer. Some indie game developers are using Haxe, which has the same problem of being an ambitious language while also being obscure enough that I'm not sure the ecosystem can support implementations that match the ambition. Then there's the extra fun thing where some languages seem to eliminate a whole class of common bugs if the code compiles. These are basically Haskell, OCaml and Rust. The secret sauce seems to be something in the lines of type inferece plus algebraic data types. I have no idea how to make complex (as in NetHack, not Space Invaders) games in idiomatic Haskell, and I'm not sure if anyone else has either. People joke about monads being incomprehensible, but it seems that if you try to make a game with a state monad, you just end up turning Haskell into a really clumsy imperative language, and for actually doing things properly you'd need to get into stuff like [arrows](https://wiki.haskell.org/Yampa) or [lenses](http://www.haskellforall.com/2013/05/program-imperatively-using-haskell.html). And at this point it looks like you're pretty much in open research problem territory. OCaml is a lot more pragmatic here. Last I looked at it though, it didn't have a corresponding structure to Haskell's type classes or Rust's traits (ad hoc polymorphism), which made it a bit clumsy to express stuff in it. I haven't actually looked into OCaml in ten years or so, so I don't really have a lot on it other than the ad hoc polymorphism problem and that it doesn't seem to have that big of a game development scene or ecosystem despite having been around for a while. It's definitely up there in the promising language list. So Rust looks like a good fit for the engine layer of a video game written from scratch. The no-GC thing hasn't been terribly important for me so far, but it is nice that it keeps the door open for some very ambitious real-time algorithms without running into GC runtime issues. The gameplay logic layer is a bit more of a question mark. Current plan is to use Rust for everything, but with gameplay logic you want *very* fast turnaround when editing things (Rust needs a recompile, holding out for incremental compilation to help here), and game objects stop being a very good fit for Rust's type system, as you can see from the thing where everyone rolls their entity component system. Some kind of scripting language or data language on top of Rust might be a lot better solution for the gameplay programming problem than using plain Rust for all the things.
HeadlessContext is created through HeadlessRendererBuilder The problem with that is that the GL context provided by glutin is not the one provided by gtk (through the GLArea). Some data can be shared between contexts but unless I'm mistaken it's not enough to get things working. And even if there was a way, the whole thing would be an awful hack that may or may not break unexpectedly.
Not in the RFC, unclear if it needs a new RFC entirely. It is one of a handful of changes that would be needed to make this rule true: "You can always add an all-`default` impl of any trait for any type without it being a breaking change."
Not necessarily. If the `write()`/`WriteFile()` system call returns, all you know is that the kernel has stored your data in the I/O cache and/or the disk's cache.
I cannot say you are wrong, this was mostly a sharing of feelings.
If writing the disk cache to the disk fails, doesn't this mean that something is seriously wrong?
Yes, but you'll never know that if you don't call `fsync()`/`FlushFileBuffers()`. It is acceptable for a kernel/disk controller to defer writing your file to disk even after you've created the file, written to it and then closed it. I'm not a filesystem developer, but IIRC ext4 has a default write back delay of 5 sec. So it's perfectly possible (in theory, at least) for a program to create a file, write to it, then close it in 1 sec and ext4 will not write the file to disk until after 4 sec have passed.
Great! Another suggestion: make it possible to load the image from an in-memory binary buffer. Is the raster-cli intended to be something like imagemagick? Would be great to have an alternative to that, imagemagick is having constantly security problems.
Perhaps open an issue at Github about this? But note that [Glium appears to not be actively developed anymore](https://users.rust-lang.org/t/glium-post-mortem/7063) (even though the author still accepts PRs) and there's [200+ open issues](https://github.com/tomaka/glium/issues). So perhaps an alternative is implementing this yourself. Anyway, pinging /u/tomaka17.
&gt; and ext4 will not write the file to disk until after 4 sec have passed. Does this matter though? When someone opens the file again the kernel should give it the version from the cache. If every program blocks because Rust uses `fsync` when dropping a File this would slow IO down, wouldn't it?
It just allows you to filter whatever you pass to it. It's basically sublime's ctrl-p fuzzy algorithm, but you can use it for anything you want to write a small shell function to (not just finding files). I use this insane looking function to fuzzy find stuff from my chrome history and reopen them: ch() { local cols sep cols=$(( COLUMNS / 3 )) sep='{::}' sqlite3 -separator $sep ~/.config/google-chrome/Default/History \ "select substr(title, 1, $cols), url from urls order by last_visit_time desc" | awk -F $sep '{printf "%-'$cols's \x1b[36m%s\x1b[m\n", $1, $2}' | fzf --ansi --multi | sed 's#.*\(https*://\)#\1#' | xargs xdg-open } https://github.com/junegunn/fzf/wiki has a bunch of other examples.
&gt; Does this matter though? It matters if you pull the plug/take out your laptop battery while a write to disk is pending. &gt; If every program blocks because Rust uses fsync Only the program that called `fsync()` is blocked (i.e. it is put on hold by the kernel until all relevant DMA operations and SATA commands are completed). If another process/thread accesses that data, they will be served via the kernel cache.
Yes, fsync() can be a very slow operation, as the (poorly specified, but still) semantics essentially says to block until the data has reached persistent storage. For a HDD or a networked FS, this can be very slow compared to just a close(). I'd say that Rust (nor any other language stdlib) should not put implicit fsync()'s anywhere, they should always be explicitly specified by the programmer.
explicit simd types and instructions in stable builds. And [this thread](https://internals.rust-lang.org/t/getting-explicit-simd-on-stable-rust) doesn't look encouraging
If you're unsure about how your project's modules are structured, then my [cargo-modules](https://github.com/regexident/cargo-modules) tool is convenient for visualizing them: foobar : crate └── catmodule : private └── catmodule : private From the output it's clear now that you ended up with redundant modules.
&gt; But in that case, any call that at any point in the stack touches unsafe code (such as working with intrinsics or low level operations that internally use unsafe), would ultimately need to be unsafe, and we'd see unsafe blocks littered everywhere in application code. This obviously isn't the case, but I don't understand why. There was an April fools that proposed marking anything that does I/O as `unsafe`, even `println!`. [It was glorious](https://internals.rust-lang.org/t/pre-rfc-mark-all-apis-that-allow-access-to-arbitrary-files-as-unsafe/3330) ([link here for the extended discussion](https://github.com/rust-lang/rust/issues/32670)). [The greatest comment](https://github.com/rust-lang/rust/issues/32670#issuecomment-204982595): &gt; Imagine implementing a library for controlling a repair robot. It has long flexible manupulator which can grab things, solder, connect to pins and do JTAG, etc. Should functions like `Manipulator::raise` or `SolderingIron::activate` be unsafe? No. &gt; But one can program the RepairBot to loop back the manipulator to the robot's own back, open the lid, solder to JTAG pins and then trigger overwriting memory, hence causing memory unsafety in Rust terms.
An attempt has been made [here](https://github.com/gtk-rs/examples/pull/44). I think it's still pertinent and might be worth another try.
So there are two issues here: 1. Rust doesn't check the return value of `close`. This is bad, in my opinion. You're really supposed to do that. I agree that we should add a proper `close` API that returns an error, and we should strongly encourage people to use it instead of letting files go out of scope. Or we should have `drop` panic if it fails. That's a breaking change, but arguably falls into the "severe bug" category. 2. Rust doesn't automatically call `fsync` before every `close`. _This is the correct choice for a systems language, in my opinion._ We have production Rust programs that write many large temporary files to disk, and in no case do we care about them surviving a power failure. (Our servers usually don't even have persistent disk!) The `fsync` API is both slow and terribly designed, as I understand it. There should be an easy, simple way to call `fsync` (or the portable equivalent), and it should have well-documented semantics. But it should also be very easy to _not_ call `fsync`.
If I know you dislike peanuts, it's rational for me not to attempt to sell you peanuts. Whether *your* dislike is caused by an allergy (rational) or a dream in which a pink frog told you to avoid peanuts or suffer bad luck (less rational, unless the frog has proven to be very reliable...) does not affect the rationality of *my* choice. Another reason for not using complicated features could be to make it easier for other people to contribute to the program.
Jeg snakket norsk, ikke svensk. Selv om det kan være lett å forveksle dem.
&gt; One option there is to return (Self, Error)in the Err variant. This is what I did when I wrapped similar functions: consuming function which does `forget` and returns `Result&lt;(), (Self, Error)&gt;`, and a "fallback" `Drop` implementation. An additional complication was that the "close" functions [take a flag](https://pcsclite.alioth.debian.org/api/group__API.html#ga4be198045c73ec0deb79e66c0ca1738a).
Panicking in drop doesn't sound like a good idea. When an unrelated panic occurs, it runs the destructors. If a destructor then panics, the process aborts.
I'm sure I'm missing something, but why not port musl to rust instead?
Will implement [this](https://github.com/tomaka/vulkano/issues/354) in vulkano, and hopefully find a good design for [this](https://github.com/tomaka/vulkano/issues/355). Any help is appreciated for the latter.
Why is `File` not `#[must_use]`? The user has the choice between (1) ignoring, but getting a warning and (2) taking proper action.
https://www.bassi.io/articles/2015/02/17/using-opengl-with-gtk/
By the way, you can use a tool like this as a menu with my library [interactor](https://github.com/myfreeweb/interactor).
as long as you can scroll or search it's not too painful i prefer it this way
Those things `Point { x, y }`, `2` and `_` in your examples are called *patterns*. `match` try to, uh, match its parameter with a pattern; if it fails, tries another; and another; etc. So `match` is used to treat something case by case (that's why its Haskell analogous is called `case`). Its usefulness is more obvious when treating each variant of an enum. See [this example](http://rustbyexample.com/custom_types/enum.html). For this match let p: Point = Point { x: 1, y: 2 }; match p { Point { x, y } =&gt; println!("x is {}, y is {}", x, y), } You only really have a single case here, and `match` is just destructuring the struct into its components. In this case I would use `let` let p: Point = Point { x: 1, y: 2 }; let Point { x, y } = p; println!("x is {}, y is {}", x, y); `let` works a bit like a `match` with a single pattern, but it only binds the variable, it doesn't receive a block (its "block" where the bindings are valid is the rest of the scope). But it works only with irrefutable patterns (that is, a pattern that covers alone every possibility of a value). If you want to use `let` with a refutable pattern, you need to use `if let`: let x = Some(10); if let Some(inner) = x { something(inner); } This is equivalent to a match that is like this let x = Some(10); match x { Some(inner) =&gt; something(inner), _ =&gt; (), } The reason `if let` is useful is that the patterns of a `match` must be exhaustive (they need cover every possibility of the value); if your patterns have something they don't cover, you need to add an `_` that stands for "anything else". Anyway [here](https://doc.rust-lang.org/book/patterns.html) is the book chapter on patterns on the old book, and [here](http://rust-lang.github.io/book/ch18-00-patterns.html) is it in the new book. (the new book is much easier to follow IMO)
Sad news and sorry for the authors loss; losing someone close is very difficult.
Writing an OPC UA implementation for Rust - https://github.com/locka99/opcua
Continuing work on an "egornomic" AMQP library. Wanting to work on handlers-- session negotiation, frame handling, and content handling. A bit behind where I wanted to be-- some failed experiments combined with the holidays. It'd probably progress a bit faster if I wasn't trying to make it work for multiple versions of AMQP-- but that's a part of the challenge (provide a simple, expandable interface; make it work with multiple versions; minimize overhead).
That would just warn you if you don't call any methods at all on your file. But you're probably already calling write.
It's possible that write_all could finish in a single write call, and in that case it wouldn't be any different from write I think? It can't close the file, because you need to be able to call it more than once.
I thought I read that the llvm supported giving the information but it is currently mostly unused.
You mean silently closes unsynced files? That's certainly possible (though depending on the required accuracy may be rather complex). Perhaps file a [clippy issue](https://github.com/Manishearth/rust-clippy/issues/new)?
Sparse BLAS. I know there have been various libraries here and there wrapping existing BLAS packages to expose them to Rust, but I've not seen an easily accessible sparse BLAS package anywhere other than MKL and SuiteSparse (they are not directly comparable) which are C and C++. I'm sketching a rough version within Rust to get a feel for how it should be designed before committing to a full version accounting for performance, numerical stability, and compatibility with existing software. This is a long-term project, though I intend to have something usable by the end of the year. I've attempted this previously in C++, though I've since lost the code.
Wir sind eine internationale Gemeinschaft ------ Jesteśmy wspólnocie międzynarodowa.
That's low-key rad, thanks for the heads up.
I'm curious to hear how *undefined behavior* can possibly help in bug detection
Haha, I was trying to read the second part of your comment as hindi only to be confused two words in. Then I realised it's marathi.
&gt; Which platforms are these? I contract and sometimes I work on IBM AIX, among others. &gt; By better cross platform story I think they're talking about platform-agnostic libraries. The C++ libraries I use are platform-agnostic as well (and not all Rust libraries are platform-agnostic) so I'm not sure I'm following. I love Rust and wish I could use it, don't get me wrong. I just don't think "portability" is a key feature in Rust at the moment for certain kinds of situations (like mine).
Relatively new to Rust, but am working on a Chipmunk 2D Physics engine (7.0.1) binding. Wondering if to publish on crates.io. (Any ideas for a name? ChipmunkRs or something more elaborate?). May put it on git hub if anyone is interested in having a look. I don't want to take any wind out of the sails of the nphysics project, but things look a bit dormant there any way.
`ctrl-r` is incremental search through history, but fzf's history search with tmux integration is so much more, [does your history search do this?](https://camo.githubusercontent.com/0b07def9e05309281212369b118fcf9b9fc7948e/68747470733a2f2f7261772e6769746875622e636f6d2f6a756e6567756e6e2f692f6d61737465722f667a662e676966)
I think the implicit reason is that macro tricks make the code more complex, especially to read and understand since macros can introduce an entirely new language that readers have to learn. I agree with the authors that some Rust programmers are a *little* too quick to jump to macros. As an example look at Iron's router: let mut router = Router::new(); // Alternative syntax: router.get("/", handler, "index"); // let router = router!(index: get "/" =&gt; handler, router.get("/:query", handler, "query"); // query: get "/:query" =&gt; handler); The alternative syntax using macros introduces all kinds of 'magic' that I have no idea about and isn't even shorter in this case. I don't even know the syntax anymore.
UB sanitizers. If you have a wide contract for something like integer overflow and it's well defined as, e.g. wraparound, then intentional overflow is indistinguishable from an error. UB on overflow gives sanitizers an opportunity to insert traps and therefore detect errors. If integer overflow is UB, then you have speedy code in release (loop counter optimizations) and bug detection in sanitizer mode.
&gt; That is the same level of guarantee that C gives you. Entirely false. C does not have move semantics. &gt; It works, until it doesn't because you forgot that in that one edge case your value would actually be freed before all the worker threads exit. Easily solved by inserting a drop call at the end of the function so that the compiler will complain if it was dropped before the thread handles were joined.
Note the past tense – when the C standard was created, programmers were quite unhappy with the UB. Other language standards had *unspecified* behavior, or implementation-defined behavior, but *undefined*? That was unheard of.
Nope it does not. Will have to check it out! Cheers
Linear types (`must_consume` annotation) would definitely be useful, for more than just this case. I assume it's not so easy to add though? Google brings up several discussions, and also an attempt to implement with a plugin: https://github.com/Manishearth/humpty_dumpty
* Inline assembly in stable release * SIMD in stable releases * Platform intrinsics in stable releases * compiler buitlins for platform intrinsics. * Function multi-versioning for handling compiling to platform with differing degrees of support for said built-ins. * Ways to pass platform version information to the backend engine. * Naked functions in stable release * Arbitrary stack alignment guarantees in stable release * The ability to split 1 allocation into 2 allocations without reallocating or copying. `alloc::heap::reallocate_inplace` will drop everything else in the buffer on first call. * The ability to disable redzone on AMD64
So many useful cargo tools. Thanks for showing me.
&gt; doesn't look encouraging Why not?
Nitpick: rust can (somewhat unsafely) still do varargs for C FFI. It's not amazing, but it's doable. 
Thank you. I am not really familiar with the inner workings of the borrow checker as much as I am with the usage of the borrow checker when writing code. However: &gt; Ideally the temporary variable should live till the end of the function. I think this is not possible because of the semantics of the language. I also think that this would be a backwards-incompatible change, because if some code has a mutable borrow in such a function chain, and a Rust compiler update makes the borrow last until the end of the function, that could cause the borrow checker to complain about the first problem that I discuss in the post. That being said, perhaps it is possible in a way that I don't know about.
That's true, you lose the guarantees, because the indices can become stale, and even point to wrong referents. This isn't as bad as dangling pointers though, because type-safety isn't broken – but that certainly has a lot of room for logic errors. Especially if the objects in the area have non-uniform lifetimes. Btw. there's a trick I learnt from the Bitsquid game engine blog: you can have a system of "generation-tracking indices" that keeps track whether the referent is still alive: you can have a "generation" counter that's incremented each time an object in the arena at that slot "dies" and is replaced by new one. In the index value, you have the actual index that points to the slot, but also the generation number which you can use to distinguish alive indexes from stale ones. (Edit: the Bitsquid implementation even saves the generation number as a part of the bit pattern of the index value, so that you can stuff the index into a pointer-sized value, because you aren't probably going to need the full amount of bits for just the index. You could have an opaque newtype wrapper around an integer to do that neatly.)
Interesting, the first two words aren't valid Hindi either. None of the words in that sentence are. The second word is _close_ to a Hindi word (दोनो instead of दोन्ही), and the first one kind of is (हाँ instead of होय), but they're different enough that you should be able to detect it? Or are you from Mumbai? Mumbai Hindi contains a lot of Marathi thrown in, and basically is okay with being mixed with Marathi words. It's how I bootstrapped my Hindi when living in Mumbai; I used to just use all the Hindi words I knew and mix in Hindi-ized Marathi nouns and verbs when I didn't know a word, and folks would understand me. 
toki pi toki pona li pona! taso toki Rust li pona mute kin.
Ah, interesting. There are a lot of folks who are like "C has way better platform support than Rust for embedded", without specifying what these platforms _are_; almost all of the modern embedded systems are LLVM targets. C has more support, but mostly on older embedded systems, not stuff folks actually use today. Legacy systems like IBM AIX are an interesting niche. I wonder if LLVM/Rust will ever attempt to target those. Yeah, portability isn't really a key feature. I like the rustup cross compilation system over C++ though. But you still need a cross ld so it's not much better.
Yeay! \o/
This readme is glorious! When I worked on fire detection software, we were stuck with the older OPC DA protocol to retrieve informations. it was a pain to use because it was based on Microsoft COM. OPC UA was the future, not-yet-finished multi-platform solution. Has OPC UA become successful in replacing the old OPC DA?
In the first example, the language semantics dictate that the result of `name()` will be dropped when the statement is done. Because nothing could possible reference the result (because it is not stored in a variable), there is no use keeping it alive. In the second example, we bind it to a variable. Now in this case, I used `name` twice, but let's just assume we name the first variable `name_1` and the second `name_2`. Because we store the result of the call in the variable `name_1`, this result will continue to be in scope until the end of the current block. All of the above has nothing to do with the borrow checker; it would be the same if Rust didn't have a borrow checker. But if we add the borrow checker, you can see why it complains: in the first example, the result is dropped immediately, while in the second, it lives on until the end of the block. I hope this explanation is more clear?
Haha that's thing, since both hindi and marathi share the same script, my brain defaulted to Hindi. And that's why the Marathi caught me by surprise. I have a few Marathi friends so I understand the language a bit :) Also, how did you learn French? I've been trying to do so using duolingo, not very successful so far. 
Not only do I need a cross-ld, I need a new set of executable/library file formats (XCOFF). And IBM AIX isn't legacy as far as I know, unless you just meant "has a long history".
These are shadowing bindings. It's like this... let a = get_some_value(); { let a = get_another_value(); .... } ...but the scope here is implicit. The value returned by `get_some_value()` will live until the end of its scope, although the name `a` is shadowed by the new binding. So it isn't the same as reassignment.
Ahhhhh that would explain it.
It's missing a very important example, and that example is what to do when you need to mutably borrow twice at the same time. Can happen when you are working with a `HashMap`, for example. Instead of attempting to make two simultaneously mutable borrows, you should queue any future changes that you need to make in another temporary location in memory, and only after the first mutable borrow is finished do you perform the second mutable borrow and make the changes you need to make.
Working on wrapping Apple's Metal (and what bits of Foundation / Cocoa / etc. are necessary) - https://github.com/rawrasaur/metal-rs
Well, it could be considered a run-time dependency, but definitely not a build dependency, which is what matters for cross-compilation.
Downloaded and tried it out. 
Can I get an IPA on that? I have an American Midwest accent and I read small as smäl and smol as smōl or smo̞l. They're very distinct.
You do not need UB for bug detection. Rust has two behaviors for integer overflow, for example: - checked behavior: a panic occurs - unchecked behavior: the integer wraps around No UB, and bugs are still caught in checked mode. --- Historically, the key usecase for UB has been, ironically, portability. A good chunk of the UB cases in the Standard boil down to: different hardware handles this in different ways, so one true behavior cannot be applied uniformly. There was from the beginning a performance aspect: nobody wanted a software emulation layer to patch the hardware behavior if it didn't conform, but it was not necessarily the first reason.
&gt; I'd say 1 is more that "other languages have gone out of their way to let you call C from them" rather than it being something you can't do in Rust. No, C has a defined ABI, rust explicitly doesn't.
&gt; However, I think the core issue stems from things like padding and struct layout not being known until the compiler invokes LLVM, but I couldn't say for sure. This seem mostly like a state-of-the-art, but not an intrinsic limitation: there is no use-case today for computing the layout beforehand, so it's part of code generation. However I see no reason why it could not be computed in advance, as it's only driven by the ABI of the target. On the other hand, the chicken-and-egg problem can indeed be a thorny one. But that's a generic issues with compile-time evaluation used to build types.
&gt; It's a simple language It's a deceptively complex language, actually. There are a lot of corner cases hidden in the specs that a casual compiler writer is unlikely to get right. You can get a compiler that compiles a hello world program, but real big codebases (which unwittingly rely on those corner cases by sheer volume) are another beast entirely. Hell, just getting the preprocessor right is not that trivial.
A lot of interesting points, but most (all?) are *compiler extensions* rather than *C features*. I don't recall the C standard mentioning any of those.
So if you actually read the whole man page, you'll see that on Linux it's probably not a big deal if close returns an error. Not saying we should be ignoring the error - it makes portability more difficult - but most people will not be seeing extraordinary "silent data loss" because of this.
&gt; This is what I'm currently researching. Various people have done some heroic efforts here, but it all needs to be brought together in a way that mere mortals can use with confidence. Exactly, and as a mere mortal, I opted for using a different language for the frontend because it just wasn't worth it. My current idea is: - whatever is native for the UI - Lua for scripting (lua runs on iOS and Android I believe, so the last hurdle is web, and I'm hopeful that WebAssembly will help here when I'm ready to ship) - Rust on the server (again, with Lua for scripting in development) I'm hoping that the Lua code will be sharable between client and server for things like simple AI and level design (i.e. for offline play and interpolation for performance). However, if I could run Rust on iOS, Android and JavaScript (WebAssembly), then I can put all of my CPU-intensive stuff in Rust and share that instead of trying to make Lua fast enough everywhere.
I assume Rust has sent patches back to LLVM. Do you know if this is something that will: 1. be likely to make it into LLVM? 2. be worth the engineering time to do so? (i.e. are the potential gain significant)
So, for the sake of hubris and learning tokio, I am trying to set up a Modus-TCP server using the Modbus-RS client crate. The thing is, for the ServerProto bindings, all the examples tell me to do this: &gt; type BindTransport = Result&lt;Self::Transport, Self::Error&gt;;//,io::Error&gt;; But when I try to build I get this: &gt;error[E0244]: wrong number of type arguments: expected 1, found 2 &gt; --&gt; src/lib.rs:174:26 &gt; | &gt;174 | type BindTransport = Result&lt;Self::Transport, Self::Error&gt;;//,io::Error&gt;; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected 1 type argument What should I be putting here?
Rust sometimes does. I think LLVM is fine with accepting backends. Unsure if it's worth the engineering time, creating backends is hard.
OPC UA is quite common in PLCs and other industrial control software these days. I use it at work so in a moment of madness thought I'd try and implement my own in Rust. It's a horribly complex spec so I'm hoping to make baby steps to something that's actually useful for something even if it's not all-singing, all-dancing. There are perhaps 3 or 4 open source impls in C out there and ones for Java, NodeJS and C#. We'll see how far I get... OPC DA is pretty much dead except for legacy work. My work code is transitioning over between DA, UA and supports either through a datasource. 
You are basically proposing a Linear Type System addition to the language (which would be most welcome, on my end). Note that `#[must_use]` is very limited today: moving the `Result&lt;&gt;` into a `Vec&lt;Result&lt;&gt;&gt;` counts as using it, and `Vec&lt;Result&lt;&gt;&gt;` is not itself `#[must_use]` so now it can be ignored. A "proper" Linear Type System would probably make linearity "infectious".
Rounding is good. Floor and ceiling ops on both ends, so you can choose to get the full exterior, full interior, slide left to fit, or slide right to fit.
http://doc.crates.io/build-script.html
Oh oops. I thought this was a different discussion I am involved in about IBM AIX support for LLVM. It could be worth the effort. The benefit is far more aggressive optimizations. One of the blockers right now is for the Rust team to pin down the exact semantics of unsafe code and what invariants must be upheld. This doesn't matter at function boundaries, but if we were to start optimizing based on the full level of aliasing info we'd have to be clearer about what exactly you must do to avoid undefined behavior in unsafe code. I'm not sure how LLVM works internally; it probably recalculates some points-to analysis internally anyway, so basic support could still go a long way. More advanced support means writing more optimizations. But I don't know how much effort it would be. It could potentially have significant gains, with a lot of redundant reads being elided, and scope for more aggressive reorder operations for optimization.
A common mistake in Go is closing over a loop variable. Rust prevents this at compile time. Also, you can just write ? instead of if err != nil { return err; } all the time, and the compiler prevents you from accidentally using the return value in the case of an error.
&gt; Match looks at patterns, from most to least specific. Does it not match them in source-code order?
&gt; Why would you pick rust instead of go Conciseness, type safety, performance, and less boilerplate.
This is not really the same kind of scripts; npm's scripts stuff lets you add custom subcommands runnable as `npm run`.
Now I get something more inscrutable: &gt;169 | impl&lt;T: Io + 'static&gt; ServerProto&lt;T&gt; for ModbusProto { &gt; | ^^^^^^^^^^^^^^ expected enum &gt;`modbus::Error`, found struct `std::io::Error` &gt; | &gt; = note: expected type `modbus::Error` &gt; = note: found type `std::io::Error` &gt; = note: required by `tokio_proto::pipeline::ServerProto` 
No, I mean, if you don't explicitly close the file, it tells you.
It uses source order, yes. e.g. If you have a `_ =&gt; ...` catch-all and try to add any patterns after that, you'll get an error that they are unreachable.
"American accent" is too broad; this one is a word that gets pronounced differently based on region.
Heck, I'm from Pittsburgh, which has enough regionalisms + dialect to have a wikipedia page: https://en.wikipedia.org/w/index.php?title=Pittsburghese (though they redirect it to "Western Pennsylvania English, psssh!)
A friend of mine showed me an interpreter he wrote a while back in both C++ and Rust. The C++ version used a GCC-specific feature, computed gotos, and was much faster than the Rust version as a result. All of his attempts with Rust involved at least one more indirection which ruined branch prediction. For an interpreter with a tiny main loop and lots of instructions to grind through this made a big difference.
I have recently become less and less of a fan of rule based validation frameworks and more and more grown to like validation frameworks which aim for looking like normal imperative code. Imperative code tends to handle complex cross field dependencies in a much cleaner way compared to rules based validation frameworks. Imperative code with well designed helper functions can handle validation really well in my experience, while at the same time is very flexible. For an example of what I refer to you can look the [Sequel's validation framework](http://sequel.jeremyevans.net/rdoc/files/doc/validations_rdoc.html#label-validation_helpers). Is there anything like this for Rust? 
I have a simple newtype that [looks like this](https://dnaq.github.io/sodiumoxide/sodiumoxide/crypto/onetimeauth/poly1305/struct.Tag.html): `struct Tag([u8; 16])`. It's easy to turn a `&amp;Tag` into a `&amp;[u8; 16]`, but I'm wondering if the opposite way is possible? Can I turn a `&amp;[u8; 16]` into a `&amp;Tag`, without actually copying all the bytes? Do I need transmute for this? Would transmute even be valid here?
I can’t speak to what is going on with cargo-bundle (though maybe its worth opening an issue), but I wrote the blog post about wrapping a Rust binary. If your app is entirely self-contained, you can probably take one of the projects in the [examples repository](https://github.com/kattrali/rust-mac-app-examples) and replace the bundled rust binary and app name with your own and it should just work. At that point, any questions would be regular Xcode usage ones and easier to search for, like how to change the icon or sign the app bundle.
Thanks for the blog post. Not sure what you mean by self-contained, but my program has dependencies on SDL2 and it has a few data files in an assets directory. I haven't checked if the binary is statically linked on macOS or not.
You might try opening an issue on the GitHub page for cargo-bundle. It's possible that the author would be interested in making sure it compiles on the latest stable. You can make it compile on stable simply by running `cargo update` to update the dependencies, then `cargo build --release`.
Ah I see. I meant that it doesn’t need to touch arbitrary files on the system so that it is sandboxing-compatible, but I see how that was ambiguously worded. You will probably have to include everything in the bundle (SDL library &amp; headers, assets), though I’m not sure how you’d find the assets at runtime outside of Cocoa. It’s an interesting problem though. Maybe the easier path is getting to the bottom of what’s wrong with cargo-bundle.
Finally working on borders again. Struggling against wlc because when the buffer I use to render the borders is bigger than or otherwise clips past the screen it wraps internally. This means my nice looking borders suddenly turn into diagonal lines. Got it working correctly on floating views though, just need to fix it for tiled, improve performance (resizing tiled windows is very sluggish when both border buffers need to be reallocated), and then do clean up. _Should_ hit master by next week at the latest, assuming school doesn't ramp up faster than I expect it to
My OSS video game project [Widelands](http://wl.widelands.org) uses a shell script to create Mac OS X Bundles. The relevant 10ish lines are [here](http://bazaar.launchpad.net/~widelands-dev/widelands/trunk/view/head:/utils/macos/build_app.sh#L47). 
Have you actually used this for anything useful? I would be curious to hear how it worked out in practice! AWS Lambda seems very interesting on the surface, but it seems somewhat intimidating to apply.
Gonna try to make a Spelunky level generator based on [this](http://tinysubversions.com/spelunkyGen/). Will be my first Rust project, can't wait to start working on it :)
I wouldn't worry about the copy. 1. Copying 16 bytes is damn cheap and 2. The copy is likely elided anyway.
Would incremental compilation work on per file, or would it work per module? I'd assume it would per module, so you can still have it on monolithic file right (not that I advocate for that sort of thing, I try to keep my modules as close to the hierarchy of the file system as I can (probably since I come from a python/C back ground)) 
You want to reinterpret a reference to 16 bytes as a reference to your newtype struct? Sounds like a job for mem::transmute to me. I'd think hard about actually doing this, though, and try to see whether LLVM can optimize a more trivial version to the same machine code.
&gt; Rust gives me even better guarantees that my code will work even after heavy churn. Agreed. With Rust, I feel like if it compiles, there's a good chance it'll work, as most of my refactoring problems have boiled down to nil pointers and concurrency errors (especially in Go).
What would be the best way to read a space separated matrix from a file? I'm talking stuff like this: 0 1 2 3 4 5 6 7 8 2 3 9 9 9 1 1 1 Would be read line by line, slpit on space and try to parse, or is there a better way, like a scanf of sorts?
&gt; You implement one method on your type, and then you get another 10 methods for free is pretty awesome. Go. However: &gt; You implement one method on your type, and then you get another 10 methods for free is pretty awesome Is so true in Go. I really wish I could have default implementation for interfaces in Go, but I can't. If Rust allows adding fields to Traits, then it'll completely replace my desire to use Java-style OO. Also, one thing I love about Rust traits is that you can implement a trait for a type *not in your library*. This means that even if a library doesn't support a Trait, I can implement it for them without having to go through a PR process (that they'd probably reject anyway, but I can at least try it with the stable lib). This is *huge* for me since I often need to fork a Go project or alias it or something to add functionality.
&gt; Would incremental compilation work on per file, or would it work per module? I'm not sure. There'd always be some small parsing overhead to putting multiple modules in a single file, since the filesystem doesn't track things like `ctime` at a sub-file level, so Rust would unavoidably have to hash and compare every module in the file, but I don't know what other constraints come into play. &gt; not that I advocate for that sort of thing, I try to keep my modules as close to the hierarchy of the file system as I can (probably since I come from a python/C back ground) Likewise, the main situations where I have big Python scripts are cases where I'm reluctant to migrate away from the "just copy the one file wherever you want and run it" deployment strategy that it started with when it was smaller. I think the main situation where any reasonable codebase would use multiple modules in a single file is to keep small bits of related code together while still minimizing the amount of code that has to be careful about maintaining each set of `unsafe`-related invariants. (eg. I have one project where I wrote a quick little wrapper around `access(2)` for bailing out early if the target directory isn't writable and it gets its own "inner module" since it'd be kind of silly to have a whole file for two tiny functions, just to isolate against certain incorrect ways one of them could be called.)
The decision what to do on close() failure should be made by the application, not a general purpose file API implementation.
Awesome! I've really been hoping to see this! I do wonder if there is any clever way to "lift" `&amp;self` (or maybe just `&amp;mut self`) into `self` on chained calls provided the owned `self` was introduced in the same scope. Maybe it sounds a bit magical, but it similarly removes temporaries, and it seems like it could unite the 2 builder patterns, and allow for other kinds of chaining that alternate between borrowing and consuming.
You may be interested in [scan-rules](https://docs.rs/scan-rules).
[removed]
Features comparison?
I'm writing a FORTRAN read/write library. There's plenty of scientific data-sets in ridiculous formats, defined by FORTRAN code, so this library is supposed to ease the reading and writing of such formats. It's pretty early to show significant results, I've only had three programming+debugging sessions dedicated for this library. Currently, only format parsing and literal writing is implemented. I expect to complete formatting soon^(tm). https://github.com/m1el/f77-io The more I learn about FORTRAN format specifiers, the more I think it's a horrible tool. At some point I considered writing an bytecode interpreter for FORTRAN formats. It was then I realized that those formats are completely absurd. Hopefully, when I complete this library, nobody'll have to re-implement FORTRAN reading and writing.
Doesn't look like Rust to me. Where's the blazing speed, guaranteed memory safety, and fearless concurrency?
I've read through the comments here, and it's got me thinking: we could implement two different kind of file saves: a quick-and-dirty best effort save, and a slow and deliberate ensure data was written correctly save. That is a 'close()' function (which is what would be used with a destructor), and a `close_and_confirm()` function that makes sure the file was saved correctly. Both of these would return `Result` values.
&gt; What to do depends on the situation Not in the slightest. If `close()` on Linux returns an error the state of the file descriptor is *corrupted* and unspecified. So you cannot preform any more actions on it. Yes IOError can tell you what happened (interrupted by a signal, drive unmounted, etc.). But this is no different then having `sync_data`give you the same error. When `sync_data` returns if/if not your file descriptor closes correctly doesn't matter the data is on disk 
Thanks for writing this! It is a great resource. I added a link in the `syn` readme.
As far as I know, not tested yet. Given that it only implements a subset of features, probably worth holding off until then.
That's not quite how I would summarize the manual. &gt; … Failing to check the return value when closing a file may lead to *silent* loss of data. This can especially be observed with NFS and with disk quota. &gt; &gt; Note, however, that a failure return should be used only for diagnostic purposes (i.e., a warning to the application that there may still be I/O pending or there may have been failed I/O) or remedial purposes (e.g., writing the file once more or creating a backup). &gt; &gt; Retrying the close() after a failure return is the wrong thing to do, since this may cause a reused file descriptor from another thread to be closed. … &gt; &gt; … &gt; &gt; A careful programmer who wants to know about I/O errors may precede `close()` with a call to `fsync(2)`.
This is not the problem. The problem is that an automatic close via `Drop` *cannot* report failures at all, short of panicking and/or terminating the program.
How do other languages handle this? For example Java's try with resources, or RAII in C++?
So you call `sync_data`, log the error (if any), and make no attempt to recover from failure. I fail to see the issue. The only issue you wouldn't want to do this is you don't actually want the data to end up on disk ever.
select/poll/epoll_wait (see also http://esr.ibiblio.org/?p=7294 )
Closest you can really get is to have a `scripts` directory and run its contents manually. You can use `cargo script` to run scripts written in Rust. Personally, I'd love a way to have per-package commands that integrate into Cargo, but you can't currently do it.
Wrong subreddit: https://www.reddit.com/r/playrust/.
Yup, that is indeed the issue. Thanks!
sure. Maybe go was a bad example; people do tend to use it for all sorts of things it's not really suitable for. (I think though, for reading and parsing a text file go would be just fine though, honestly. ...but you're right, python would probably be an even better choice)
1. The answer he's linking to is from 2014. 2. The libc crate provides access to those specific C APIs and is maintained by the Rust team * https://doc.rust-lang.org/libc/x86_64-unknown-linux-gnu/libc/fn.select.html * https://doc.rust-lang.org/libc/x86_64-unknown-linux-gnu/libc/fn.poll.html * https://doc.rust-lang.org/libc/x86_64-unknown-linux-gnu/libc/fn.epoll_wait.html 3. It's the safe, idiomatic, cross-platform abstractions for those primitives (eg. [tokio](https://tokio.rs/)) which are still very young.
To be fair, if computed gotos are a GCC feature that some (but not all) other mainstream compilers have copied, it's up for debate whether you can call it something "C has". (Last I heard, GCC, Clang, and ICC had computed gotos, but MSVC didn't.) **EDIT:** \*chuckle\* I initially typo'd that one letter away from "computed goats"... now that'd be an interesting feature.
Python 3 added that, though I believe it was more because people have a bad habit of relying on CPython's reference-counted garbage collection to promptly close files when they go out of scope. ...wwhich isn't part of the language spec, so Jython, IronPython, PyPy, etc. are free to behave differently. (eg. By delegating to the JVM or CLR garbage collector)
That's a fair point.
Another basic question since you mentioned it: when an instruction is only supported on some subset of CPUs of a given architecture, how does the compiler know whether it's allowed to emit that instruction? Does it have to be enabled by some compiler flag? Or is there some sort of "fallback" that you can put in the binary itself?
This could be used for online process restarting, right? (e.g. have an HTTP server restart itself, possibly loading a new version of itself, without dropping any connections.)
Oh it sounds like you're writing a game? This is actually a type of app that benefits a lot more from native toolkits. You'll be able to reuse a lot more code than a regular app that has to interface tightly with the host OS and have a lot of platform-specific code there. Rust doesn't have fast turnaround yet but in this case it definitely sounds more reasonable. I'm not an expert on the game front but you might want to read anything by Noel Llopis and related -- lots of interesting stuff there.
The Java case is even worse (at least on Android's Java; I haven't kept much up to date with what's happening on the desktop or server). Yeah, tuples are nice. :)
Thanks. Yeah that does work and I was able to use `cargo-bundle` to cut a release for my friend. I also left a comment on their issue tracker about it.
Thanks. I ended up doing something similar with my SDL2 dependency.
You would supply features in the `-C --target-feature=` codegen flag when you build the final binary. Try running `rustc --print target-features` to get a list of them, it's kinda long. If you want to just enable all features supported by your host CPU (on the building machine), you would do `-C --target-cpu=native`. This would obviously cause problems if you tried to run it on a CPU that doesn't support the same features your CPU does. These flags basically tell LLVM what instruction sets it can use in building a binary. For specifically copying `[u8; 16]` in one instruction, that would be the SSE2 instruction set which supports 128-bit (16 byte) integer operations. However I think the compiler assumes SSE2 is enabled by default, so you don't need to do anything special, just compile the final binary in release mode.
My main concern with using rounding terms verbatim is that they're vertical metaphors, while I tend to think of strings in horizontal terms.
There's something that would be nice if incorporated into some sort of scoring system on crates.io: Mark things down if they don't provide a repo URL or the repo has diverged a lot from the state it was in at the time of the most recent crate upload. (Yes, it'd downrank people who prefer GIMP-style "infrequent, massive releases", but I actually consider that a feature.) Heck, given that this isn't the first time I've seen a crate being out of date and I don't like relying on direct git URLs for my dependencies (for cargo *or* pip), I'll probably eventually end up writing some sort of analyzer to check that myself so I can avoid crates like that. (If I don't have a crates.io or a PyPI insulating me from GitHub 404 errors, I don't want to depend on it.)
I think whether it's intuitive will depend on how well the associated verb is chosen. Headward and tailward are fairly clear... but a verb is necessary to answer "Yes, but how far?". "Outer" and "inner" are much more context-dependent terms, so I can't give an opinion on them at all without a verb. If it weren't such a DSP-specific term, I'd suggest something based on the word "quantize" since quantization is basically a [very fancy form of "snap to grid"](https://www.xiph.org/video/vid2.shtml). (Quantization is the process of reducing continuous input to one of a number of discrete values, so it's not that alien an analogy if you pretend that byte/codepoint offsets within a codepoint/grapheme stream as continuous values that need to be made discrete.) **EDIT:** To anyone reading this, the video I linked is a great watch for fun, even if you're not into DSP programming. (I'm not)
more fun: //does the monoid operation on the slice of tuples if the closure evaluates to true fn accumulate&lt;'a, T: Monoid&gt;(tuples: &amp;[(&amp;'a str, &amp;Fn(i32) -&gt; bool)], i: i32) -&gt; Option&lt;T&gt; where T: From&lt;&amp;'a str&gt; { tuples.iter() .filter(apply(second, i)) .map(first) .cloned() .map(&lt;&amp;str&gt;::into) .fold1(T::op) //op just concatenates, but Cow&lt;'a, str&gt; does not satisfy Add } I really love how the FUNCTION BODY looks, it's quite succinct but that function signature...
My thinking was to be able to specify scripts in `Cargo.toml` (defaulting to `.rs` files and folders with `Cargo.toml` in them in the `script` directory) available as cargo commands. So if `scripts/package.rs` exists, then `cargo package` builds and runs it. Super bonus points for being able to specify a package *somewhere else* (*e.g.* in a git repo or just a regular crates.io package) to pull scripts from, so I can just centralise all my personal tools into one package and re-use that everywhere.
 4. C doesn't "provide" these either. They're libraries, just like Rust uses. (lol markdown I can't start a line with `4.`.)
The whole point of rust is so that programmers like you (and me) can achieve systems-language performance while writing idiomatic, safe code. No nullpointer exceptions, no segfaults. Rust can be hard to learn, but also fun to write. Start with [Rust By Example](http://rustbyexample.com/hello.html), or [The Rust Book](https://doc.rust-lang.org/stable/book/). Don't forget the \#rust-beginners IRC, and this sub. The kind people here have helped me many times in the past.
Rule based validation can work phenomenally when applied at the right place. Django Rest Framework's [Serializers](http://www.django-rest-framework.org/api-guide/serializers/) use a validate_(fieldname) method for custom field-level validation and a validate() method for model-level validation. You have model invariants that are eternal. You try to put as much of that into the type system as possible, and failing that, you put them somewhere where the validation must always be true before persisting. Then you also have situational invariants that correspond to different workflows, which is usually handled in most frameworks by way of "forms" or "serializers" which encode the particular invariants.
I do love the title of that talk.
One of Rust's weaknesses is that it's hard to explain how rewarding it is once you get over that initial hump. I haven't had much time to practice anything significantly complex but, already, I'm getting a glimpse of how much responsibility the Rust compiler removes from my shoulders and I can't put into words how enticing it is just to *taste* the benefits more experienced Rust devs write about. You just never realize *how much* of a weight other languages are making you carry because you're so used to it. (Or, to put it another way, Rust makes you spend a little up front, but then it spares you ages of slowly being worn down by little thing after little thing popping up just when you thought you were done.)
&gt; Oh it sounds like you're writing a game? Yup! &gt; You'll be able to reuse a lot more code than a regular app that has to interface tightly with the host OS and have a lot of platform-specific code there. Sort of, but right now I'm planning on either using a battle tested cross-platform game engine (like [libgdx](https://libgdx.badlogicgames.com/) for the UI and keep the Rust code either on the server or in a library. I'm hoping that the cross-platform tools will come about once I've finished my current project and I'm ready for a bigger challenge. &gt; Rust doesn't have fast turnaround yet but in this case it definitely sounds more reasonable. With scripting it's really a non-issue, and I can definitely tolerate sub-optimal performance while in development in exchange for quick iteration time. As the game grows, I'll migrate portions to Rust for performance. &gt; you might want to read anything by Noel Llopis Seems interesting, I'll have to check it out. In looking up his name, I found [this batch of articles](https://github.com/pravic/rust-gfx/blob/master/info/research.md), which all seem interesting. 
Looks neat! A lot cleaner then the javascript I cobbled together to call a executable I built. Also thanks for the aws docker example. 
I'm from Perth, but I don't really spend much time in IRC stuff...
Yeah, that's probably a better way to put it. Very, very thin libraries ;)
Is it actually safe to do that transmute? IIRC it's UB to transmute `&amp;thing` to `&amp;mut thing` regardless of the contents/context. Rust is allowed to make assumptions based on the immutability of references.
I think what's confusing in your two examples is that in addition to one of them matching a primitive and one a compound type, one of them is also matching against a literal, while the other is matching against a variable. These are two separate axes. Consider this [modification of your first example](https://is.gd/2aFpzS): let x = 2; match x { 2 =&gt; println!("two"), y =&gt; println!("something else, specifically: {}", y), } Here we have both the literal pattern `2`, and the variable pattern `y` matching against the value held by`x`. We can also [modify your second example](https://is.gd/31ZpoB) to use literals in places, like so: let p: Point = Point { x: 1, y: 2 }; #[allow(non_shorthand_field_patterns)] match p { Point { x: 1, y: y } =&gt; println!("x is one, y is {}", y), Point { x: x, y: 5 } =&gt; println!("x is {}, y is five", x), Point { x: x, y: y } =&gt; println!("x is {}, y is {}", x, y), } (Usually, one writes something like `Point { x: 1, y }` instead of `Point { x: 1, y: y}`, but I wanted to illustrate the symmetry of how these match. That's what the `#[allow(...)]` thing is about)
Write a general bash script that writes to the specification.
Basically, same performance as `itoa`, but with zero unsafe code, `#![no_std]` support, support for more than just base 10 conversions, and not requiring that the input implements `io::Write`. No temporary arrays are created internally for buffering the state -- didn't see a reason for that if the function returns the indice where the number's first character starts. It's ideal for some scenarios where `itoa` doesn't exactly fit, such as buffering the number into an array before writing it somewhere (`itoa` requires a `Vec` heap allocation to do the same), or using this in your `no_std` software.
It implements a trait for you. As far as I know, traits can only be implemented for structs and enums. For what are your trying to use it?
Would it be possible to contribute this code to rust lang?
The api was designed to be limited so that it could be stabilised sooner. This is because custom derive is currently a pain point on the stable compiler (eg. Diesel and serde), and to serve as a stepping stone for the full proc macro 2.0 api.
Macros 1.1 were specifically designed with a limited scope so they can become stable soon (i.e., in 1.15). There are ways to work around this though…
You mean like the one I currently use:- #[derive(Commands)] struct _Commands; or there is an even better workaround?
[removed]
Yes, I have to admit I intentionally made that example a bit silly to prove a point. I originally had a different example that was less contrived, but it was really basic and didn't show what I was trying to explain very well.
An example of this please?
Something that's for Rust as Lua is to C would be quite interesting for the scripty programming part. Not sure what it would look like. You can bind to the actual Lua using a C-like API of course, but I'd really like interop with more rustic language constructs like iterators and ADTs. Maybe [dyon](https://github.com/PistonDevelopers/dyon) will end up being something interesting.
Builds and runs fine on Linux, x86-64, with an older Intel GPU. Performance seems fine to me, although I'm getting messages like these: missed frame Duration { secs: 0, nanos: 16549956 } missed frame Duration { secs: 0, nanos: 16751312 } missed frame Duration { secs: 0, nanos: 16762441 } missed frame Duration { secs: 0, nanos: 16785054 } missed frame Duration { secs: 0, nanos: 17079730 } missed frame Duration { secs: 0, nanos: 16712018 } 
Makes a lot more sense!
See [rawloader](https://crates.io/crates/rawloader) for a way to be able to also load raw image files into raster. There's a simple API to give you an RGB decode of the file that can just be treated as any other raster format.
I'd certainly be interested. I've been working on and off on an SVM (SMO) impl in my free time, but only have rudimentary (non-mathy) knowledge on perceptrons and basic backprop. Notable mention: https://github.com/autumnai/leaf by /u/Hobofan94 (orphaned afaik. The crate, that is. 😅)
 let res = client.get(url) .headers(headers.clone()) .send(); res can be simplified to client.get(url) .headers(headers.clone()) .send() Same goes for all those let body_as_json: whoami::WhoAmI = res.json()?; Ok(body_as_json) You can just return `res.json()`. Well technically `res.json().into()` would be equivalent, but as you return a `Result&lt;E = reqwest::Error&gt;` anyway, the `into()` wouldn't do anything. Also, you can rewrite all those `Result&lt;T, reqwest::Error&gt;` to [`reqwest::Result&lt;T&gt;`](https://docs.rs/reqwest/0.3.0/reqwest/type.Result.html). These are just very basic things that clippy will probably also tell you, but I'll look a bit more. EDIT: Oh, all the other files just contain structs for deserialization. Well then this is pretty much it I guess. Although I noticed one last thing: In `Client::request`, you create a `Headers` instance to supply to your `RequestBuilder` at the end of the function. Why do you clone it there? You should be able to move it (just remove the `.clone()`).
So Leaf got the low level bit, I think, correct. They really new how to do those kind of things and the guys did them well. However, they did not use a graph representation of the program, but rather an easier module based (e.g. having a few specific layers). However, the drawback of that is that does not scale (e.g. to experiment with different model architectures and optimize the computation globally rather than each op on its own). Actually combining the powerful backend of what leaf had, with a graph representation could make this a really nice project. Do you hang in some channel where we could maybe chat up. Also just to point out that this will be quite some effort as essentially for GPUs we have to know how to write kernels, which is definitely out of my expertise. 
Released https://github.com/Keats/validator 0.2.0 (macros 1.1 custom derive to add validation to a struct) that works on stable on 1.15 + struct validation + must_match validator. I'll also try to do some more progress on jsonwebtoken 2.0
You're right. I like how [Rustonomicon](https://doc.rust-lang.org/nomicon/transmutes.html) explains it: Transmuting an &amp; to &amp;mut is UB * Transmuting an &amp; to &amp;mut is always UB * No you can't do it * No you're not special
[Here's the documentation on Rust's release channels](https://doc.rust-lang.org/book/release-channels.html).
&gt; Is systems programming even enjoyable by sane people [...]? It was not, until Rust came along ;) One of Rusts main goals is to make low-level "systems programming" possible without constantly shotting yourself in the foot, which IMHO is very enjoyable, at least when you can appreciate the level of control you get from systems-programming-capable languages like C, C++ and Rust. &gt; Where does a pleb like me learn what to do with this skill and how can I get interested in this language beyond its 'oh neat' factor? The language is inspiring enough to me to be interested in systems programming but I have no idea where to go from here. Make an OS? Well that is a possibility, but I think if you just generally want to expand your Rust knowledge, small command-line programs should be pretty good already. I think clippysay is a good example. It's a cowsay-like program that you just pipe text into and it displays that text in a speech bubble coming from [clippy](http://static3.businessinsider.com/image/519285ffecad046054000014-506-253/clippy-microsofts-talking-paperclip-is-back.jpg). I discovered it from a friend who had written it in Python, then I reimplemented it [in Haskell](https://gist.github.com/jplatte/764d4436609fb3b18edc) and now I'm reimplementing it in Rust. But this time with [command line arguments](https://github.com/kbknapp/clap-rs#clap), [unicode-aware word wrapping](https://github.com/mgeisler/textwrap#textwrap) and a line to the speech bubble that adapts to the text height. So here's a project idea for you: Do the same with [Ferris](http://www.rustacean.net/)! You'll learn more about command line argument handling, managing dependencies, error handling, and ASCII art! Oh, and IO.
In my personal experience form level validation is pretty common, especially for signup forms or forms for adding customer details. Form level validation can be implemented with custom field level validators, but that has usually been much uglier than the equivalent imperative code for the cases where I have needed validation of interdependent fields. Django's serializes framework looks nice, but it is also has the kind of validation which I do not feel scales well to really complex forms.
Actually [apex](http://apex.run) has [rust support](https://github.com/apex/apex/tree/master/_examples/rust)
You probably mean /r/playrust as in Rust the Game. Otherwise Rust the Programming Language gets updated every six weeks like clockwork.
The basics of C are easy to understand, the basics of Rust are not easy to understand.
To be fair, Python isn't *always* installed, it just is very common to have it installed, plus right there is a fine example of what is wrong with Python, you can't even give a simple answer as to how to run it :P
This is great! Thanks. That's an impressive list of format support. 
I don't think non-floating types will be added to the language, because of ambiguity when parsing Dyon data. Although, it is not certain yet. One idea I had about namespaces was to use [parent functions as "module functions"](https://github.com/PistonDevelopers/dyon/issues/391) for namespaces , another idea was [dependent parameterized imports](https://github.com/PistonDevelopers/dyon/issues/393). Once I started thinking about namespaces, I came up with this https://github.com/PistonDevelopers/dyon/issues/434. An optional namespace could make it easy to go from default namespace to more organized code.
I think it is possible to put features that doesn't work with webassembly behind a Cargo feature to run Dyon in the browser. Have not tried this yet.
[Macros 1.1](https://github.com/alexcrichton/rfcs/blob/macros-1.1/text/0000-macros-1.1.md) was designed to just stabilize a small subset of procedural macros, so it could be stabilized sooner in order to allow a few very prominent crates, like Diesel and Serde, to be usable on the stable compiler without having to use a painful build process. This is intended to be an incremental step towards a full "procedural macros 2.0", but the full feature will need a lot more design work so it was seen as being worth it to stabilize one of the most commonly used parts right now to give more time to design and implement the full feature while getting a good win by reducing the number of people who require a nightly compiler or complex build setup.
Honestly though, Java/C# is the bar that needs to be reached (in terms of IDE support), nothing less. Basic stuff, like renaming a struct member throughout the entire code base, moving a file or extracting a method (without breaking the code!) just need to work, to be used as a productive environment. I was quite happy to read that IDE support is one of the main goals for 2017, as this really is one of the biggest pain points.
if you need one of these - fast startup - deep control of what is actually happening - low resources - small/no dependency/runtime then rust will help you (and i) normal folks to make a non buggy program. it put system programming in the reach of normal folks. at the beginning it's painful to use, because it guards us from falling into traps we don't see yet (the very reason we chose rust). recently i had to build an agent that is currently running on a few hundred containers, rust was a no brainer.
So I already have implementation of a graph interface (its currently in work but soon will be done). Currently it supports most popular operations, forward and backward autodiff and I think would be quite easy to add a few common sense optimizations (for instance look at Canonization in theano, which is essentially common sub-expr elimination). However, I agree the general notation of `Graph` by default in Rust is a bit tricky, so there are different options. Currently I use vector of nodes basically with indexing. Do you think if you have access to a graph of the computation you can port what is already in Leaf? One think, which actually the graph interface could allow you, compared to Leaf's approach, is to have a global memory manager and you can preallocate memory exactly (E.g. static memory allocation like MXNet). 
Do you know how to include the people from those posts? Maybe if we get a few people into this it might be possible to get it moving. 
After some showerthoughts and having my first cup of coffee, I can definitely see the concerns. Let's assume the worst (or – depending on the viewpoint – the best) of the optimiser. Here's some assumptions it can make: 1. It can inline and optimise globally. 2. Type system invariant: If there exists a `&amp;mut V` pointing to v, there exists no other references that point to v. 3. The type system invariants are expected to hold everywhere, even inside unsafe blocks. 4. Raw pointers coerced from references are expected to have same equality/unequality properties transitively. Now let's imagine that there has been one call: `get_mut("key_one")` and we have a `&amp;mut V` returned to us that points to some value `v`. In the buffer that saves the already-fetched values, there is now a raw pointer that has the same equality properties with `&amp;mut V` because of rule 4. After that, we call `get_mut("key_one")` again. The getter – inside an `unsafe` block – returns a `&amp;V` that points to value `v`. After inlining (rule 1), the optimiser is able to see that there's two references, and they cannot be the same due to rule 2, and this is true even inside the `unsafe` block because of rule 3. Then, `&amp;V` is coerced to a raw pointer that has the same equality properties with `&amp;V`. Next, the raw pointers are compared. But because of the interplay of the rules, the optimiser can skip this comparison – it knows – or thinks it knows – that the pointers can't be the same! Finally `&amp;V` is transmuted to `&amp;mut V` and returned. Now we have two `&amp;mut V` that point to the same value, and our type safety is broken. However, I think that no reasonable memory model should be able to assume all these assumptions at once! Especially the part that aliasing invariants can be expected to hold inside an unsafe block is too strict in my opinion, and judging from the discussions on Internals, I'm not the only one who thinks so. Also, optimising a comparison between raw pointers because of the aliasing invariants is surprising and IMO too strict too!
Yeah, but this his comparison between Ruby and Rust is true of any statically typed language. If he were using something like Go or Java or (whatever), a static lang with solid tooling, refactoring would be even easier. I love Rust, but refactoring rust is a total pain compared to more mature static langs. Fortunately, this isn't inherent to rust, and it will get better once we get better tooling.
have you seen https://github.com/dtolnay/itoa and https://github.com/dtolnay/dtoa ?
Doesn't it already know that information? The trait object includes a pointer to a vtable for the trait functions? All the debugger needs to know is the mapping from the vtable objects to types.
I'm writing a macro (called foo) to reduce the boilerplate of implementing a trait (Foo) for a number of structs (Bar, Baz) while still allowing me to customize those structs. Right now I have something like this: foo!(Bar, {}); foo!(Baz, { custom_field_1: usize, }); impl Baz { fn custom_func(&amp;self) -&gt; usize { self.custom_field_1 } } Which expands to this: struct Bar { field_1: usize, field_2: usize, } impl Foo for Bar { fn do_something(&amp;self) -&gt; (usize, usize) { (self.field_1, self.field_2) } } struct Baz { field_1: usize, field_2: usize, custom_field_1: usize, } impl Foo for Baz { fn do_something(&amp;self) -&gt; (usize, usize) { (self.field_1, self.field_2) } } impl Baz { fn custom_func(&amp;self) -&gt; usize { self.custom_field_1 } } I have two questions. First, is there some Rust feature that I'm missing that would make this pattern easier to deal with? Second, is it possible to write this macro so it looks like this (after the fashion of macro_rules!): foo! Baz { custom_field_1: usize, }
Indices is, however, the correct plural of index. Thanks Latin.
OS X 10.12 (Sierra). The latest stable rustc (1.14 I think), and Intel Iris 6100. I'll verify all those later.
Yes, but the numtoa crate has better performance.
&gt; But it works currently, Undefined behavior is allowed to do anything, including "works currently" ;)
https://github.com/nrc/r4cppp
Oh man I was starting to work on this, but I think I'll just contribute to your impl. as mine is nascent. (I have part 6 of the spec floating around on my desk somewhere... )
Why not make a new frontend for [clippy](https://github.com/Manishearth/rust-clippy) using clippysay so you can have clippy tell you what clippy thinks of your code?
yuuuuuuup
My question would be how much more work I have to put into a &lt;choose project type here&gt; instead of using Python, Haskell, Scheme, Go, etc. Clearly, manually managing memory gives some overhead. But how much more? Is it worth choosing Rust as a general language? Or should I invest (considerable) time into Haskell or another nice GC'ed language for my hobby stuff? I do stuff in Python these days (fun, amazing library support, but quirky/hacky), and I love Scheme for its simplicity (define SICP "mindblowing"). For Rust I have to wade through low level, strict type, and borrow checker concepts, for Haskell I have to go deeper into functional territory than ever and learn its crazy sophisticated type system. Would love to hear some thought from people that realized small projects in both languages and lived to tell a tale.. 
I have ben following rust for some time now. Does tihs series of you'rs work for beginners?
When you say "new frontend", do you mean just a wrapper around the normal executable? Or do you have something more fancy in mind? I kind of really want to do this now :D
Oh, it could easily use the existing clippy (look in https://github.com/Manishearth/rust-clippy/blob/master/src/main.rs), get the JSON output and munge it into something MS clippy says.
He'll add one, he just forgot.
Rust is also one of the few languages that forces you to initialize variable. If you add a field to a struct in most language your program compiles and gives you "zero values" , Rust breaks .
If I remember correctly, that's a GCC extension??
The intent for the series is to work well for anyone—whether you’ve already managed to learn the foundations of the language or not. It attempts to explain Rust’s various different concepts at a level beginners can understand, whilst at the same time handing out clues for the more advanced viewer. Good luck!
[removed]
A bit off topic but I have also been thinking of adding some extension method to HashMap but with a bit different API, and a bit different purpose. Would like to hear comments about safety and convenience of the following idea. The purpose is to provide read only access to a hashmap while holding a mut ref to an item in the map. You add a new method to hashmap called super_nice_get_mut() which takes a key and returns a pair. The pair is the usual option mut ref to value, plus a new wrapper type which holds a shared ref to the hashmap plus a copy of the key from your call. The wrapper provides a get method which first checks if the key is the same as what you gave before, returns None in that case. Else forward the request to the map. By doing things this way the user can avoid removing a value from the map and later putting it back in again.
Well yeah using the existing clippy is a no-brainer, I just thought when you said "new frontend" that clippy had multiple front-ends like e.g. JSON and plaintext, and I should add my own in a fork for some reason. I think the easiest way to go about this would be use the plaintext though, assuming that I can tell clippy to output its usual format including the color escape codes. Otherwise I'd have to skip colorization or do it myself. I guess there is still word-wrap to do though, unless I can somehow fake a terminal environment with a slightly smaller amount of character columns.
Trying to compile the todo_mvc example, I get this error: = note: ERROR root: /home/user/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/lib/rustlib/a smjs-unknown-emscripten/lib: Input file has an unknown suffix, don't know what to do with it! error: aborting due to previous error error: Could not compile `domafic`. I have added `asm32-unknown-emscripten` and `wasm32-unknown-emscripten` as targets to rustup, and I have `emscripten` installed via `apt-get`. I'm not sure what I'm doing wrong.
Unfortunately a not-so-"jaj"-update from the imag project.
Thanks so much, I'm really happy to know it works with an iGPU. The missed frames don't surprise me: I get them quite a bit on my 2011 laptop at work. The main reason for this is how I structured my renderer. Everything [pushes jobs onto a queue](https://github.com/drbawb/megumin/blob/master/src/render.rs#L114) so that when it's time to draw the frame the relevant data is in a contiguous block of memory. (Plus in the future I envision the renderer doing some optimization passes on the queue to minimize draw calls.) Most of these jobs are trivially copiable, so it's no problem, however a few things (the starfield &amp; the weapon sprites) reuse textures so they pass in [a huge list of quads to draw at once.](https://github.com/drbawb/megumin/blob/master/src/entities/map.rs#L84) At the moment there's an allocation per frame to copy this buffer into the queue to avoid ownership problems. I'm working on convincing the borrow checker to let me pass it by reference instead. (I have a branch that works but it uses `Rc&lt;RefCell&lt;Vec&lt;Rect&gt;&gt;&gt;`which makes me sad.) Also you'll definitely get at least a few of those if you didn't build in `--release` mode, the optimization-fu is strong!
&gt; Clearly, manually managing memory gives some overhead. But how much more? Is it worth choosing Rust as a general language? Or should I invest (considerable) time into Haskell or another nice GC'ed language for my hobby stuff? Great question, I also feel the same. Is it good as a general language? I do still enjoy writing application level software. 
You might also be interested in the book ["Programming Rust: Fast, Safe Systems Development"](http://shop.oreilly.com/product/0636920040385.do) by Jim Blandy. It is written with C/C++ programmers in mind, and draws many comparisons to C++.
It should be possible. Finding optimal solutions seems like a hard problem, but even greedy two-pass "allocate in statically-known unused space if possible or request more space at the end" would likely deal with most cases. For host memory it would require unsafe, for CUDA possibly no, since interface currently tracks memory as c_longlong integers. It looks like CUDA memory is linear, pointers are not opaque and so it should be possible to do pointer arithmetics. That said, AFAIK weights take most of memory, and some forward pass results have to be kept for faster backward pass, so there may be not much to gain, possibly just several percents, maybe a bit more for convnets.
It looks like your blog generator forgot to include links to the posts.
&gt; That said, AFAIK weights take most of memory, and some forward pass results have to be kept for faster backward pass, so there may be not much to gain, possibly just several percents, maybe a bit more for convnets. Yup, that's what we found when working on Leaf too. You can get a bit of a memory advantage against lazily written networks by reusing e.g. the shared workspace that most convulution-related operations in cuDNN use. I think another limitation was that you have to keep a lot of the forward passes, not for speed optimization, but to get a correct result at all.
Excellent, thanks. I found the official tutorial, which claimed prior programming experience was required to read it, agonisingly slow and patronising.
I agree, but essentially the graph will already tell you what you need to keep and what you can throw away (it actually will tell you when exactly you can throw it away) as well as if you can do in place operations, at least the way I am currently doing that information is fully exposed.
So I think most of the memory is in fact taken (especially in deep nets and RNNs) as Hobofan94 said by the fact you need intermediate results of the forward pass to do the backward. However, as you go backward you can drop certain things. As long as pointer arithmetic works, I think it would be easy for me to write on the graph a memory provider which can directly tell you offsets for each tensor in the memory blob, essentially doing this at compile time of the graph. 
I see that `numtoa` panics if the buffer is not large enough, but I don't see how, as a user, I can ensure that my buffer is indeed large enough before calling this function (other than giving it a very large buffer). I think the API should either provide such a function, or return a `Result`. Also, it is very surprising that the output is written at the end of the buffer. I guess it's because you compute and write the last digit first, and you don't know how long the output will be, so you have no choice but start from the rightmost position. In practice, it means that I cannot use this API to write directly in a stream buffer. I can only use this API to write to a temporary buffer and copy data around.
I started to use some `constexpr` magic in C++ so I can switch on pairs of integers... 
I think he means that if other nodes on backward pass require temporary storage, then just freed memory can be reused. Since all this planning is done at graph's compilation time, malloc()/free() aren't actually called. Calculations at nodes just use stored pointers to overlapping memory, so there is no overhead.
Note that the official book tries to cater to all audiences, including people from Javascript/Python/Ruby, so it will spend time explaining concepts that feel obvious for C++ programmers.
Not quite. Typestate was the idea of annotating types with predicates. The problem is that composition was difficult: you feed `f(i32) -&gt; i32` an `i32` that has the `is_even` property, does the result has this property? You can't tell. On the other hand, Affine and Linear are properties that can be verified: - an Affine value can be used (consumed) *at most once*, this is any value in Rust that does not implement `Copy`. - a Linear value shall be consumed *exactly once*. The latter is much stricter, of course. Today Rust has an approximation (`#[must_use]`), which is used on `Result`, however it's incomplete because not infectious.
Looks awesome, and I think will move the needle significantly on the "are we web yet" idea. Many thanks!
I don't mean to rationalise UB in general, I just changed my viewpoint and started to think how the optimiser could break the code – it's not a bad exercise to do. But do I understand you correctly: what is UB is defined first, and then everything else, including optimisations, follows, right? So I shouldn't think what the optimiser might do, but instead, what is defined to be UB and not do that? Because I agree with that. The problem is that we don't have a definition of UB currently, at least I'm not aware of any. (Yes, there is Rustonomicon, but it's not like a bible or anything? It explicitly says that it's a draft document and may contain serious errors, and I know that much of discussion about defining UB has happened after Rustonomicon was written.) For example, even if `&amp;V` → `&amp;mut V` transmutation was *defined* to be UB (as Rustonomicon says) or *may cause* UB as rustc says (Note the difference in wording! This stuff is confusing!), there is not a clear word about if it's about literally calling `transmute` with `&amp;V` and `&amp;mut V` type arguments, or is it also about achieving the same effect using other means, like I did it by first converting the refs into pointers after getting well-deserved criticism. Anyway, I keep thinking about what invariants of HashMap I might be breaking. Any insight on that? Because I'd very much like to have this kind of interface to HashMap, and don't want to do this just because of trickery :) Edit: Also, I'm a bit sad about getting downvotes on some of my comments on this thread. I don't know why I'm getting them, but I don't mean to spread misinformation or anything; so if someone disagrees with something I said, please write a comment instead of downvoting! Constructive discussion about UB and unsafe contracts is more than welcome!
Well not quite universal... yet :) Awesome work! 
&gt; but what if a future version of Rust that combines any no-op functions into a single pointer somehow? [...] This is the difference between Debug and Release modes: - in Debug (-O0, -O1), you expect a 1-to-1 mapping to the source code, with no omission - in Release (-O2, -O3) or with -OS, you expect fused types, inlined functions and stripped frame pointers Yes the latter lacks introspection (even without stripping the debug symbols), it's also wickedly fast. That's a trade-off. However, since both *should* have the same semantics (unless unsafe code is mixed in), you should be in a position to use the Debug version for debugging. 
That's music to my ears. Thanks! I really hope we will see these on stable soon. &gt; These don't seem to be on a fast-track to stabilization like custom derive (not as high demand) I think there is a high demand. It's just that it's not voiced out much because there are hacks like the ones in this thread making it possible to workaround this. I just picked up macros 1.1 a few days ago and I have already ran into this. I wasn't surprised to learn that Diesel is also using such hacks. Sure it's not a big deal when you have to resort to such hacks a couple of times in your entire codebase. However, I'm working on a RethinkDB driver with more than 150 commands. I have each command in a separate module to make documentation more maintainable. I have to use this hack in everyone of those files.
Refactoring in Rust can be time-consuming, but it's also brainless: follow the ~~white rabbit~~ compiler error messages, and fix as they arise. I've had *very* bad days in Java, because of all the reflection magic that the tools didn't support. The failures were far away from the code, and of course only occurred at run-time. Reflection + Downcasting are a real pain in the butt for refactoring: I find it far easier to follow the compiler error messages than stare helplessly at a failing test-case in a downstream module I've never used which never directly reference the class I just touched.
Saying match is like switch is like saying reddit is just a forum.
Basically, the only way to obtain the resulting string from the standard library is to perform a heap allocation and have the result written into a string. For example, `number.to_string()` performs a costly heap allocation, resulting in half the performance.
Actually I have been following your pull request ever since the Macros 1.1 pull request thinking that it allowed me to set attributes on derive macros. I only learnt that this was already possible yesterday. Since then, I no longer have any idea what your pull request actually does. Unfortunately I haven't had much time to dig deeper into this.
&gt; There's currently no guarantee that HashMap must return a difference reference for different keys :) But if I don't compare the keys, but the references (or pointers) themselves, this shouldn't be a problem per se? If HashMap returned the same references for different keys, the methods of this crate would panic but nothing more drastic than that. But yeah, I understand that 3rd party people "hacking" around the limitations of `std` stuff creates some pressure. And there's always so much stuff that is almost impossible to take into account especially when doing unsafe code. But if 3rd party hackery is frowned upon, do you think it'd be feasible to have this kind of an API officially on HashMap sometime in the future? Because as an idea, there shouldn't be nothing wrong with it; it should make HashMap strictly more usable. Returning pairs is feasible at the moment, but the generic thing is a bit awkward. But that problem should fade away once we get type-level integers sometime in the glorious future.
C doesn't content itself with footguns though, it also has a veritable array of footcannons.
You can just use `write!(&amp;mut buf, "{}", my_number)`. `buf` can be any stack allocated array, or some other type that implements `io::Write` or `fmt::Write`. The `arrayvec` crate even comes with a nice array-based String type that implements `fmt::Write`. Also `io::Write` is available through the `core_io` crate in case you want that one instead of the other one.
&gt; I no longer have any idea what your pull request actually does. Procedural macros come in two flavors: * attribute like: `#[get(/)]` (from Rocket) * function-like: `println!("hello")` (from the standard library) "Macros 1.1" is a nickname for a subset of the first: only `derive` attributes can be implemented. This PR implements the rest of the stuff needed for full-on attribute procedural macros. Later, the function-like ones will be implemented as well. That's "macros 2.0".
Can you please make your critique actionable? As it stands, you're not bringing anything positive to the discussion. Please respect rule #2.
Looks neat! I think I remember Alexandrescu discussing an implementation based on division by 100 (instead of 10, so halving the number of divisions), preceded by a manually balanced `if` tree in charge of computing the number of iterations (a la Duff's Device) to completely unroll the loop.
Ah, I see. Thanks a lot for this explanation!
Thanks for the writeup! I might need to do something like this in the near future, so it's nice to have an example out there. A couple of critiques: UserRolesToken::has_roles() does not need ownership of role, so the argument should instead be a &amp;str. That lets you change this: if token_data.claims.has_role("admin".to_owned()) { ... } to this: if token_data.claims.has_role("admin") { ... } This avoids some extra syntax and an allocation. In admin_handler(), PathBuf is not the right type here. Path and PathBuf are solely for filesystem paths. String will do for a fragment of a URL.
'a la'*
Yeah I wouldn't really say `match` is much like `switch` at all.
&gt; do you think it'd be feasible to have this kind of an API officially on HashMap sometime in the future? Yes. I've been thinking about how we can make type level integers work, might pre-rfc it soon.
I'm not sure how the text you cited is refuting my point. Care to explain? My read of the man page (and my understanding of unix IO) is that typically a file descriptor will be closed even if the `close` system call returns an error, and you need to call `fsync` to ensure that data is actually written to the disk. Otherwise, the data may must be stored in a queue waiting for a good time to actually get written. So while the man page is correct that ignoring the return value of `close` could cause silent data loss, it's more because the contents of the file might not get synced to the disk correctly; any time you want to make sure that happens, you need to call `fsync`. That's why databases will typically call `fsync` whenever they write something, for example.
This is a great resource. C++ programmers learning Rust should also read through the Rust FAQ, though, to understand some of the philosophies, which are mostly distinct from those of C++.
Do you mean that after getting the first mutable ref, the wrapper allows only getting shared refs while checking that they don't overlap with the mutable one? That should be doable quite easily, but the same caveats hold as with this `multi_mut` crate – check my and /u/Manishearth's discussion. The problem is that for comparing the references, they must first exist, and it's not clear if that causes already UB, just by existing, plus should it be allowed to transmute immutable to mutable refs, even provided that the invariants hold. If there was a way to get raw pointers from HashMap, it would be easier.
Hi, many thanks for your answer and your example. I understand that you will have to think upfront about memory management before actually putting down any code. How much much impact does this have in a small/medium sized project when compared to, say, Python/Scheme/Golang/Haskell? I know that the first two languages allow for fast writing/prototyping of applications, while the last brings with it a completely different set of rules (and complications). I am just trying to figure out whether I should go with Go, or invest the time that is needed to get into a language like rust or Haskell.
I noticed that your SplitMut trait is generic over the types the mutable references are retrieved from. I tried to make my traits generic too at first, but it's the iterator-returning method that seems to make this impossible to do. I wanted to have an iterator because I couldn't think of other feasible ways to have it be generic over the number of values to be retrieved. The problem is the same as described here – the iterator is an a generic associated type, and the exact type depends on the method that returns it, not on the trait, so it can't be done without associated type constructors: http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/ 
How big is a minified hello world program? Also, how do you quantify "high performance"?
Hmm, compiling with `--release` doesn't seem to change anything. I can't tell a difference in-game and the messages are still there. Regarding your lifetime problem: Have you considered doing away with `DrawMany` completely and just using a bunch of `Draw`s instead? I'd just go with the simpler solution, unless I actually needed the performance and could show that the more complex solution is really more efficient. (Warning: That's just an idea based on a cursory glance, so feel free to disregard.)
I don't see a vim syntax in my repo, where can I find that?
/r/playrust
Feel free to criticize or offer any feedback / suggestions Edit: Currently increasing usage of all error combinators to get rid of many match / if let
**Update**: When using a debug build with base 10 conversions, the function will panic with a message if the buffer is too small. On second thought, I may add some runtime checks in debug builds to check if the supplied array is large enough to fit the largest value for each possible type. The `i8` type requires at least 4 bytes and the `u8` type requires at least 3 bytes, for example.
The template functions can be built no_std and no_alloc, so it should be possible to get it running on embedded devices and such.
Yup. Unfortunately, non-conservative `impl Trait` and ATCs are both blockers on major ergonomics and performance improvements.
&gt; it's probably not a big deal if close returns an error. This is the part I do not agree with. *Silently losing data* is kind of a *big deal*. The fact that `close()` is not guaranteed to error is a separate issue, and I understand that. The fact that `close()` always closes the FD is another unrelated issue, which I also am aware.
Wrong subreddit. See /r/playrust 
First you should learn how to read during daytime (Rust is a programming language), than ask your question in another [sub-reddit](https://www.reddit.com/r/playrust/) ;)
Thanks for the review! It was a year since I made it, so I have to refresh my memory a bit. &gt; The SplitMut trait should be unsafe to implement. This is because get_mut has an invariant it must uphold -- it may not actually mutate the thing (and there's no guarantee that a custom collection won't do that). You mean `get1_mut`, I suppose - and I see now that you're right. Will fix. &gt; Also I'm skeptical that this doesn't trigger UB. It won't cause any problems with the current set of Rust optimizations, but it's in that gray area of UB where the unsafe semantics team has yet to decide on the boundaries of UB. I try the best I can to make sure two `&amp;mut` pointers never point to the same value, by converting them to `*mut` (which are, and will be, allowed to alias), and then use that for the comparison. They are turned into `&amp;mut` s at the very last time, after verification that they are all different. And that is the only part that is unsafe. Two `&amp;mut`s is UB, and I check that properly. Is there something else that could cause UB? Btw: I don't compare the keys, I compare the pointers of the returned values, in order to protect myself from evil `Eq` implementations.
Looks neat. What's your long-term plans for it (if any)?
I'm adding a `Closed RFCs` section to TWiR starting today's issue. Hopefully that helps.
Well, `get_mut` is allowed to mutate the structure. E.g. in a btreemap `get_mut` may try rebalancing while it's doing the search. It doesn't, but it's allowed to. Other data structures may. This is not a guarantee safe APIs must hold, and your trait relies on it, ergo the trait itself must be unsafe. I feel like doing multiple get_muts on multiple unsafe `&amp;mut` aliases of a container is strictly more prone to actually causing problems over doing multiple gets on multiple safe `&amp;` aliases and later converting the obtained pointers to `&amp;mut` (which is what the OP does here). Using raw pointers doesn't magically make it safe, the aliasing is still happening. You are not allowed to break the invariants of `&amp;` and `&amp;mut`, period. Unsafe semantics team probably will clarify this and provide sensible rules for unsafe code, though. Idk.
Oh haha. I thought that this was the sub reddit for the game. Lol
To be fair you're missing the target by quite a bit, but you're still getting ~60FPS which is probably why the difference isn't super noticeable in game. (The target is a fairly ambitious 120FPS, honestly I just set it that high so that I'd see serious performance regressions at a glance.) The funny thing about your suggestion is that the renderer used to only have `RenderJob::Draw` and the performance was pretty abysmal, it wasn't even hitting 60FPS on my GTX 980Ti when firing the crates. The name of the game for making modern GPU acceleration go fast seems to be minimizing state changes e.g minimizing individual draw calls. So DrawMany was a way to say "just reuse the state for this next group of primitives." For the record Rust is actually totally correct in preventing me from just passing in a reference in this instance though, one scenario I can come up with for e.g: - The background builds a batch of quads - It sticks a reference to those quads into the render queue - Imagine that I accidentally tell the background to update itself a second time before the render queue is processed: if the list of quads were to resize it would move in memory. There's now a reference to freed memory sitting in the render queue! Anyways what I can do is just prove the ownership at runtime which is exactly what RefCell would do for me. This will prevent the background from getting a mutable handle to its drawlist while the non-mutable reference is alive in the render queue; it's just enforcing that check at runtime instead of at compile time. So this is actually kind of a perfect use-case for RefCell, I just wanted to carefully think through the design to see if I can prove it statically before I commit to that.
Looks really cool! I've been wondering about something like this. From the looks of it, this doesn't include an HTTP server, is that right? So it's a way of writing HTML/CSS/JS applications, that can be served by another web server of run locally? My ideas revolve around having an HTTP/2 pipeline between server and client so that you can have a full-stack Rust application that runs actual Rust on the server and runs the asm.js/wasm-compiled client part on the client.
I guess what you want is `Vec&lt;&amp;Bar&gt;`? You will probably need to add lifetimes so be prepared and read the book!
Is your goal to be productive as quickly as possible? Then I would probably pick Go. Like /u/burkadurka said, Rust trades runtime errors for time you have to invest in learning the language and appeasing the Rust compiler. It will take longer to learn the language and to get your program to compile, but you will have less runtime errors. Does this tradeoff appeal to you? Personally, I really like strong type systems, so I would prefer Rust or Haskell over Python or Go any time (I still use Python for scripting though). If you want a high-level language and predictive/good performance, there are not that many options besides Rust and C++, that's how I ended up here.
Author here. I haven't been writing a lot of rust in the past, when writing an app I couldn't find a prompting library, so I wrote one my self. I would love to get comments and feedback on things I am doing wrong, sub-optimally or in a non-idiomatic way.
I am thinking about buying that book, as I found the official tutorial hard to follow. Do you need to know C++(or the basics of any systems programming languages) to get through it? I only know C# and Python.
I believe that details would help. I'm unsure of what you want to achieve.
&gt; Is systems programming even enjoyable by sane people or is it one of those 'hardcore' branches of coding? I'm insane and I love Rust! :D Many people consider systems programming 'hardcore'. I consider it 'core', because it's foundation for their fancy, boring interpreters. :) (Disclaimer: this post isn't meant to attack anyone. Have fun!)
Easier than C# ? I don't know how you work, but in my C# project (500k loc), renaming *anything* is a breeze and will take me literally 2 secs with 100% confidence that it is going to do the job. You are telling that you can do the same in a Rust project ? How ?! I have a small rust project (5k loc) and tried to rename a struct member I just gave up after all the results returned by grep/rg/ag. I also use ctags + gnu global but it is just not context aware so not really useful for refactoring.
I spotted [this post][1] on the rust users forum which includes an outline of an example usage when converting numpy arrays to rust-compatible code. I had to make one small change: I changed `_as_f64_array` to this: def _as_f64_array(array): return ffi.cast('double *', array.ctypes.data) [1]: https://users.rust-lang.org/t/calling-into-rust-from-python/8923/2
It's mostly a re-implementation of rawspeed, a C++ codebase. It's my second time round doing a lot of these formats as a way to learn rust. Seems to fit this problem domain very well. Needs to be fast, low level is useful because of all the bit twiddling but at the same time safety is very important as you're dealing with outside input in binary formats with a lot of corner cases. Getting pretty close to a 1.0.0 now.
I'm really looking forward to projects like [rustls](https://crates.io/crates/rustls) becoming more utilised by other crates and then finally reaching a point where we can get rid of OpenSSL entirely.
Thanks for responses, that were quick, even though the lack of plan English (for which I'll try and do better next time). Thank /u/cramert for the link to StackOverflow question, where it is said, that adding constraint Sized to the trait works, which is what I used. The main problem with using boxed() or similar is that objects are a bit more complex and just Bar1{} does not suffice and "constructor" in a form of new() is what I want. So, my solution: https://is.gd/tnqkyB
Small typo: "libarary". Should be "library." (I'll dig into this more later)
The basics of C are easy to *think* you understand. I've read enough about C and Rust to know that it's easier to actually understand Rust than C.
Poking about a bit, Unicode whitespace is fun! There are 25 defined whitespace characters(https://en.wikipedia.org/wiki/Whitespace_character), meaning that I need to filter on individual graphemes for each word. I could use the stable character above for the most common use case, but that only covers 8 of the 25. These first 8 are top out at a decimal value of 160, less than the 256 value of a full byte. The docs say that .graphemes() will give me each glyph. The notation above says that I simply pass the glyph to a predicate, which I can implement in a separate function via a match on value. I need to chew on this a bit before I write it up. Do you think there would be enough interest for me to post a full solution here?
Sniðugt! :) Suggestion: Implement Default::default() that uses stdin/stdout for input/output to cut down on boilerplate.
Good work! This looks cool. A couple of thoughts: `min_len` and `max_len` feel a little out of place in here. A minimal prompt library, like this crate seems to be, doesn't *need* this. Leaving length validation to the user of the library would be my choice. Taking the input &amp; output by value, instead of mutable reference, could allow for a simpler API: let mut trompt = Trompt::new(input, output); let usr = trompt.required() .prompt("Username: "); let pwd = trompt.silent() .min_len(8) .prompt("Password: "); This would allow you to implement a `default` for input and output, as well.
This is par for the course on ESR's blog. The number of genuine non-troll comments may indeed surprise those familiar with the usual comments sections there.
If you want something cython-like, there's https://github.com/dgrunwald/rust-cpython/ Unfortunately it's still highly incomplete. In particular, there's no safe wrapper for memory views, so you don't have any efficient way of accessing the numpy array elements (though I guess you could drop down to the unsafe C API).
You mean as a separate post on the sub? Sure! A lot of people still have trouble understanding how they're supposed to handle Unicode so some more reading on that bit would be very welcome.
Yeah, that's my fault. I should have put 'npm install' as one of the steps, which I think should also work.
&gt; Will it be a component you add to your rustup builds? Yes. Along with Clippy. (To elaborate a little bit further, the plan is to pull both into tree, and give them the same "yeah this is unstable but since we distribute it we'll let it work on stable" treatment that the standard library has.)
Very cool project. Once webassembly gains Dom interop, it could be even more awesome, but that's still quite a ways of I reckon.
Tokio 0.1, macros 1.1, RLS alpha... if the Rust Team keep being so productive they may need to rename "2017 Rust Roadmap" to "January 2017 Rust Roadmap" ;)
graphemes will give you each extended grapheme cluster. You can't get glyph info without having the font. A grapheme cluster is an approximation to "user perceived character", basically as close to the concept of a "letter" as you can get. There is no guarantee that an EGC will take up one column of text, or if it will render as a single glyph, or whatever. Try ᄀᄀᄀ각ᆨᆨ for example, it's a single EGC but multiple glyphs, and multiple columns wide.
Couldn't you just increase the timeout for the compiler?
Part of what makes Rust's optimizer work and helps to ensure Rust's "minimize surprises" behaviour is that it defines copying as bitwise copying (eg. no copy constructors because they bring in arbitrary performance implications and make moving no longer semantically equivalent to copying and deleting the source). Because you can't bitwise-copy things like file handles and network sockets and get safe, meaningful behaviour, you also can't `Copy` things which contain them. Having a `Drop` implementation means "I need cleanup beyond just freeing all bits I own, directly or indirectly" and that means that copying has the aforementioned unpredictable implications. However, you are free to `impl Clone` (which provides `.clone()`) however you want and `#[derive(Clone)]`lets you skip the boilerplate for anything where all members already `impl Clone`. &gt; Also, does that mean that an assignment like &gt; let a = b &gt; can have a different meaning depending on the type of b? Yes. `#[derive(Copy)]` is typically used for primitive or near-primitive structs (eg. `Point(x, y)`) where copying them into a new stack frame doesn't appreciably increase memory consumption or reduce performance. (Though that's more an artifact of how containing a reference to something heap-allocated makes your struct ineligible for `Copy` semantics. Here's [the official advice](https://doc.rust-lang.org/std/marker/trait.Copy.html#when-should-my-type-be-copy) for when to make your type `Copy`.) `let x = y` will invalidate future access to `y` if a type isn't `Copy` but, if it is `Copy` then it's up to the optimizer whether they're separate variables. (ie. if you never use `y` again, the optimizer can just treat it as a rename which vanishes with the human-friendly labels.) &gt; And what if I want a copy of a non-trivial type like a string? Types which can be safely duplicated implement `Clone`, so you can call `thing.clone()`. (Or, in the case of string slices, use [`.to_owned()`](https://doc.rust-lang.org/std/borrow/trait.ToOwned.html) because `.clone()`'s type signature prevents it from returning `String` when called on a `&amp;str`.) Here's a [Rust Playground link](https://is.gd/o4RXNG) to illustrate what I'm talking about.
In case you didn't know, there is an RSpec inspired rust library called [stainless](https://github.com/reem/stainless).
Bit of a hiatus past couple of weeks due to holidays / working on some of my Go projects but finally got back on the [Statrs](https://github.com/boxtown/statrs) train, looking to release v0.5.0 sometime in the next week or so
I always liked system level programming as like toy optimization logic puzzles, but never wanted to actually do it for real applications until Rust came around.
Yeah, I've shown it to Sam before, it was a long time ago though... he was working on his own port of "rspec to Rust" for a minute. He actually maintains RSpec, so sometimes you use the tools you know...
Typically types with destructors own some resource (eg. Box owns memory, File owns a file handle, etc.) - that means that copying the type involves duplicating the resource (to avoid the same resource being released by both destructors), which in turn means it will be more than a simple `memcpy`. Rust chose not to allow implicitly copying types which require anything more than a `memcpy` to clone. Instead, these types will be moved when assigned: copying must be done by implementing the `Clone` trait, whose method must be called explicitly (`x.clone()`). This makes it easier to reason about rust code (for example, it guarantees that simple assignments cannot panic) and also avoids behaviour that might be surprising (eg. assignments taking a long time because cloning a resource is slow). Theoretically, you could have a type which needed code to run on destruction but can also be cheaply copied with `memcpy`. However, in practice this doesn't happen (just try thinking of an example and you'll see why)
`--lib` and `--bin NAME`. You can pass more than one of these to a single `cargo test`.
One of the things that is different here is that Rust doesn't have copy or move constructors; these things are _always_ just a `memcpy` of the structure itself. Non-trivial copies are done using `Clone`, which is never implicitly called, and runs arbitrary Rust code.
Could you give an example of a useful object in C++ that is trivially-copyable, but with a custom destructor? From my experience it usually means somebody forgot to impl/disable copy-ctor.
Kærar þakkir :) Thanks I didn't know about Default::default(). I will look into that.
Thanks for the feedback, especially about taking `input` and `output` by value. I will definitely look into that. The reason I decided on mutable reference was so that I could check their status afterwards in my unit tests. It is a pretty silly reason to compromise a nice API for that.
It it is needed for the compiler, then last time i checked, the compiler needed 2.7. I think most, if not all, of the scripts are 3.x compatible though.
It is for the typical use case: matching enum variants. But yeah, it had different symantics and additional features, so it's more of an analogy than a straight replacement.
I was using `to_owned()` there because `Vec&lt;T&gt;.contains(&amp;T)`, e.g. in this case a `&amp;String` instead of `&amp;str`. I tweaked it to take `&amp;str` and call `to_string()` for cleanliness elsewhere. Do you have a route example for the latter point?
It's outside the scope of the language, but not outside the scope of the standard library. I don't think anybody is saying we should modify the language itself to deal with this.
After taking a look at the Rocket site, it looks like you can use &amp;str. The first example on the site should work for your case.
I'm sorry -- I don't quite understand your question. If you want to notify the users participating in the [linked thread](https://github.com/autumnai/leaf/issues/108) about this discussion, you can actually ignore my first post. Commenting on the [linked issue](https://github.com/autumnai/leaf/issues/108https://github.com/autumnai/leaf/issues/108) should ping everyone participating in or watching that discussion.
&gt; Clippy: Consider using: `!rust_jobs.is_empty()` :D
&gt;&gt; Clippy: Consider using: `!rust_jobs.is_empty()`
Note that the only difference between a `move` and a copy is if the original value is consumed or not.
What typo? I don't know what you're talking about? ;)
This is what [`pub_restricted`](https://github.com/rust-lang/rfcs/blob/master/text/1422-pub-restricted.md) is all about. It’s [not stable yet](https://github.com/rust-lang/rust/issues/32409), though, and may well change somewhat.
 &gt; Well, get_mut is allowed to mutate the structure. E.g. in a btreemap get_mut may try rebalancing while it's doing the search. It doesn't, but it's allowed to. Other data structures may. This is not a guarantee safe APIs must hold, and your trait relies on it, ergo the trait itself must be unsafe. This part I totally get. [Fixed now.](https://github.com/diwic/splitmut-rs/commit/6e7a387cb03a7bd998fe00f454ee4d7f8cb5563d) &gt; Using raw pointers doesn't magically make it safe, the aliasing is still happening. Raw pointers are, and will be, allowed to alias. Otherwise, the following safe code would be UB: let mut h = vec![1]; let z1: *mut i32 = h.get_mut(0).unwrap(); let z2: *mut i32 = h.get_mut(0).unwrap(); println!("{:?} {:?}", z1, z2); 
Thanks for the feedback! Will look into Rust and give it a try. 
&gt; At first I choose to use nom to create a PDF parser, it turns out a special PDF feature blocked me. When parsing a PDF stream object, it's length may be a referenced object, hence the need to get the length from a reader. Damn. I'm writing PDF parser with nom at the moment and next step is a Stream Object parser. But according to PDF spec one should not read whole stream into memory so \Length could be resolved later.
+100. I have a pet-project that needs a Delaunay triangulation for part of it, and I really didn't wanna do it myself. I didn't look for very long (yay, mobile) but the panic! in `triangulate` should probably be changed into returning an Err(). Other than that, looks good. 😊 
They're allowed to alias. You can't read/write from raw pointers which alias to non-raw values. You can only do so if they're the _only_ aliases available (e.g. in C code). It gets fuzzy here though.
Fantastic news!
I would first decide on where to move the discussion to: - Rust Users Forum - Rust Reddit. There actually is a dedicated (yet mostly silent) #rust-machine-learning channel on Mozilla's IRC server (formerly used by the Leaf guys). IRC is great but doesn't allow for documentation of previous discussions, so I'd rather not use it for any "official" discussions. As for how to include the people from the Github issue: post a comment there, @ing them and pointing them to wherever the new discussion is meant to take place. If they wanna join forces, great.
Great news! Is there already some WIP branch of reqwest available from somewhere, that also provides an async API based on this?
I unironically like using C, although I can't say the same for C++. I don't trust myself to use it for large projects, however (then again, I'd say the same for Python or JavaScript).
I fully agree with the approach of the official book. I think it's brilliantly written, and I'm now starting Chapter 10 (Generics). I only suggested "Programming Rust", because OP specifically requested a C/C++ resource. Personally I quite liked the way the official book makes sure all concepts are clearly understood, but then again I only formally know C and C++. I can certainly understand C++ veterans being annoyed by the pacing ...
&gt; despite the very first line insulting me for choosing to use C++! Yeah, now that you say it, isn't this somewhat problematic? I really liked C++ before learning Rust and still consider it much more pleasant to use than e.g. Java. I think if I had started with this tutorial, I'd have been annoyed after the first paragraph, and that doesn't seem like a good way to go into a tutorial to me.
I wonder if it would be useful to override the defaults for `confirm()` to allow for i18n?
Few comments about your code: Perhaps you can derive PartialEq of Point, and leave just the empty implementation of Eq. pub fn new(x: f64, y: f64) -&gt; Point { Sometimes I'd like to derive new ( https://github.com/rust-lang/rfcs/issues/1318 ). panic!("Can't triangulate less than three points.") Better to return an Err or Option (as said by cedrickc). to_remove.extend([j, k].iter().cloned()); Simpler: to_remove.extend(&amp;[j, k]); You can probably make the code less noisy if you give names to the tuple fields: fn in_circumcircle(point: Point, (p0, p1, p2): (Point, Point, Point)) -&gt; bool { // Handle coincident points in the input triangle. if (p0.y - p1.y).abs() &lt; std::f64::EPSILON &amp;&amp; (p1.y - p2.y).abs() &lt; std::f64::EPSILON { return false; } // Compute the center of the triangle's circumcircle. let mut circumcircle_center = Point::new(0.0, 0.0); if (p1.y - p0.y).abs() &lt; std::f64::EPSILON { let mid = 0.0 - (p2.x - p1.x) / (p2.y - p1.y); let mid_point = Point::new((p1.x + p2.x) * 0.5, (p1.y + p2.y) * 0.5); circumcircle_center.x = (p1.x + p0.x) * 0.5; circumcircle_center.y = mid * (circumcircle_center.x - mid_point.x) + mid_point.y; } &gt; for i in 0..points_count { To make the code more readable I like to put a space before and after the ..: &gt; for i in 0 .. points_count {
Comparing keys has some other problems: 1. It's slower. A reference is pointer-sized (or double pointer in some cases), but a key can be arbitrarily large. 2. It's not safe, part 1. The `Eq` of the types used as keys might be malicious and return false even if the keys are same. Your unsafe code shouldn't trust that. 3. It's not safe, part 2. The HashMap type itself might be changed to return a reference to the same value for two keys, and this is all in limits of it's "unsafe contract" – it's not unsafe thing to do per se, so our unsafe code shouldn't trust it does that. Comparing raw pointers has none of these caveats: comparing pointer-sized things is fast, the comparison code is known to be just... a comparison, and even if HashMap returned same refs for different keys, we would catch that when comparing the pointers after getting them. I don't think "indirect" aliasing (in the sense that a thing has reference to it, and that thing has a heap pointer, and somebody has a reference to the stuff stored in heap) counts as aliasing. Aliasing has to do with processor caches (of course it might be defined differently, but the problem originates from caches): if I do stuff through this pointer here, does it invalidate the cached value of that pointer there. So, we do have a reference to the container, and a thing contained in it. If we know the container struct – let's say `HashMap` is on stack, and the contents in heap, it's pretty safe to say that the references don't alias. However, I now get what /u/Manishearth might have meant by breaking the contracts of `HashMap`. Let's say that there would be a miraculous optimisation where part of the values contained in HashMap would be directly stored in the stack struct of `HashMap`. We then have a reference to the zero offset of that struct, plus a reference to the "contents" which is a reference to some offset n in the struct. Does that count as aliasing? I don't know, but might well do. Another thing HashMap could do is to return references to a composite value `v1` when called with "key_one", and a reference to a value `v2` contained *within* `v1` when called with "key_two". The mistake we made is that we assumed that the values contained in `HashMap` would be disjoint. It would be very surprising semantically if they weren't, but nowhere in the documentation does it say that `HashMap` *wouldn't* be allowed to do such things. So as long as the HashMap docs doesn't explicitly promise that the values contained within are disjoint with each other and the `HashMap` struct, my `multi_mut`, /u/diwic's `splitmut` and your proposed API would all break the unsafe contracts of `HashMap`. And as /u/Manishearth said, I shouldn't just rationalise based on how things might break. But I'm now a bit unsure what `HashMap` would even need to state as safe assumptions for us to be able to safely do these things. Is a permission to assume disjointness even enough?
Good idea! [I have now implemented](https://github.com/diwic/splitmut-rs/commit/f3118969966285ab6e995563a8009c4b6f69667f) 1) borrow functionality for my splitmut as well as 2) an iterator adapter that maps an iterator over keys to an iterator over values.
One of the [requirements](http://en.cppreference.com/w/cpp/concept/TriviallyCopyable) for a type to match the TriviallyCopyable concept is that it has a trivial destructor, so no I can't by definition :-) 
So excited for this. Hopefully it will reach production-ready status this year.
I guess I can see that tradeoff. I was just curious as we see different approaches in different languages: afaik nim (and possibly jai if it materializes) will allow anything while D and C++ restrict it to pure functions but otherwise still allow looping and other branching constructs. I can get that it's a hard design space and there's no one right answer! :)
Posted this as an issue to the Rust repo: "Guarantee that values in hash map are disjoint from each other and the HashMap struct" https://github.com/rust-lang/rust/issues/39155 Not sure if I expect that to happen, but I had to try :D
I'm glad you've created a new proposal for this; in [my epic RFC](https://github.com/rust-lang/rfcs/pull/1824) creating a committee for manual creation is a common suggestion but not something I'm willing to make the functionality of crates.io dependent on. I like that you've at least got a target pool of committee members :) I fear that it will still be a challenge to get enough people to do some work so that the burden of time isn't largely on a small number of people. Starting this as a separate thing from crates.io and testing its viability and usefulness is a great idea :)
Looks like there's an nvim plugin being worked on here: https://github.com/tjdevries/nvim-langserver-shim You can find editor support at the bottom of this page: http://langserver.org/
Sure, though next few days will be quite busy for me. I think gitter would be ok, at least it duplicates unread messages to email.
Actually, from the reqwest docs: &gt;The reqwest::Client is synchronous, making it a great fit for applications that only require a few HTTP requests, and wish to handle them synchronously. When hyper releases with asynchronous support, reqwest will be updated to use it internally, but still provide a synchronous Client, for convenience. A reqwest::async::Client will also be added. 
With regards to using smart pointers, I found this chapter of the new book to be really well written: https://doc.rust-lang.org/beta/book/choosing-your-guarantees.html One downside to using actual borrows into the interior of the vector is that you won't be able to take a mutable borrow to multiple such elements at the once. (Since Rust can only prove you're mutably borrowing the entire `Vec&lt;T&gt;`, it won't try to reason about you borrowing disjoint indices.) I find that smart pointers are a nice way to work around this at runtime in games (which tend to be mutation heavy since they aim to avoid copies/allocations in my experience.)
This is interesting. I liked the idea of a "Matrix4Pipe"! Nice to see accelerations structures too, like "OcTree".
&gt; will not generate a file Unless you passed the `--no-index` flag to the server.
How can I implement a struct which wraps a Hashmap that's generic on the type of the key? https://is.gd/jLBu8G I see the compiler errors, and I'm sure once I understand them, they will make sense. I can tell that hashmap keys must be sized, but I'd appreciate advice on getting things to compile and doing the generic thing properly. For more background this is part of an attempt to make a distinct counting library accept more than `Strings`. https://github.com/shanemhansen/countish-rs 
Try the `feature/36-range-header` for a working implementation, please.
Will the dependency on npm and python be removed in the final release? I'll wait until then, but if it won't be removed, I'll have to pass on RLS. I suppose racer will also not be needed in a future rustc. Correct?
I'm most excited about refactoring since I never really liked autocompletion in any ide, but accurate renaming of symbols is very useful. Let's see if I can find an Emacs client that has all these features and works across different LPS backends.
If you have a pointer, you can make a 'POD' struct have a destructor that checks if the pointer is nullptr before freeing the memory, and after it does free the memory, sets the pointer to nullptr. This could also be done atomically, though the free/delete will likely still lock (maybe not with jemalloc).
I made some examples of the third choice: https://is.gd/uF6EHA
Thanks, that helped remove some of my errors. I think I understand. I was creating a single specific impl for a dynamic dispatch thing, rather than a template for any type implementing Hashable. I'm now seeing this error trait bound `std::string::String: Hashable` is not satisfied Now I'm confused because String should implement Eq and Hash right? Do I somehow need to reimplement the methods because I've created my own Hashable type?
Does atom have other autocomplete-style plugins/addons?
&gt; yes, they're only build dependencies. It's a binary, like all Rust code. That's good to know. I'll wait until it builds with cargo alone. Or is npm just for VS Code and optional?
Correct. Ah, yes. Just because a type implements `Hash` and `Eq` does not mean that it automatically implements your new trait. There are two ways you can solve this. Either you can create a blanket impl so that all `Hash + Eq` types also implement `Hashable`, i.e. impl&lt;T: Hash + Eq&gt; Hashable for T { /* empty */ } Or you can replace all occurrences of `Hashable` with `Hash + Eq`. 
It looks like Cargo should have had compatibility with OpenSSL 1.1 [since 0.16.0](https://github.com/rust-lang/cargo/commits/master/Cargo.lock). Right now, the version of Cargo installed with stable rust is 0.15.0; so if you install stable Rust, it may not work with OpenSSL 1.1. If you install beta or nightly, it should.
Taking a look at the original post, it's from October of last year. OpenSSL 1.1 support was added to Cargo in November. Though his newer post seems to claim that building Rust, I can't see why it wouldn't; I don't think that `rustc` has any dependence on openssl, and the latest Cargo should support OpenSSL 1.1. Since Cargo 0.16.0 is currently the version shipping with the beta version of Rust, it's possible that if he's trying to build stable packages he might run into the issue.
For `p &lt;op&gt; q` I'd use `*` for "return both results", `&lt;` for "return left" and `&gt;` for "return right". Reason being that a tuple is a product type, and less-than and greater-than point to the returning parser *and* they're symmetric. Can the error handling question mark (is "eh?" a thing by now?) be used for overloading? If yes, I'd use `p?` instead of `-p`, then `-p` is free for discarding output. In the end, though... *That is why Haskell has user-defined operators*. People are going to overload no matter what you do, and unlike C++ or Rust in Haskell each set of operators at least makes sense.
I have been thinking about that, and I am leaning on “yes” it could be useful. Perhaps if these helpers were a trait, that users could implement. It should be relatively easy, since `confirm` is [just a map][L268-274] over the result of `prompt`. [L268-274]: https://gitlab.com/runarberg/trompt/blob/master/src/lib.rs#L268-274
I did think about naming the struct `Prompt`, and I think I will. I come from javascript world, and over there it is idiomatic that if a module exports one thing, that thing should be named after the module. I suppose no such idiom exists in rust land.
Great idea. I'd like to have following things: 1. Have a concept of topics visible in crates.io search and rust documentation. So if someone is searching for "xml", a note listing (or linking to) most popular crates related to this topic would show. Probably just having this in rust book would help a lot. 2. Have a list of crates that are: * Officially and heavily promoted * Blessed by rust community as reasonable default choice * Receive some (the more the better) support in ensuring standards in terms of quality, documentation, test coverage, supported platforms and usecases. * Are guaranteed to work for reasonable amount of time across range of plarforms and rust versions. * Are stable enough not to break my code without absolute need (or ever) * Are compatible with/ supported by other popular libraries and frameworks. 3. Have a process for nominating and selecting candidates for such list, as well as place to discuss it.
If crate-owners could classify their own project's maturity level (e.g. alpha, beta, stable, in production live, etc) that would be a start. Also having a checklist of "best practices" that they could claim to pass or conform to. Perhaps this information and recent download stats would be enough for cargo.io to put search results in mostly the right order. If anyone games the system by claiming something untrue, then people can file bugs against it .. or complain somewhere else. Here's an example project release checklist for Go: https://github.com/matttproud/gochecklist This kind of system of self-classification (if well designed) may avoid needing curated lists for most things, and drive project owners in the right direction to improve their own projects.
Actually, [wait](https://docs.rs/futures/0.1.8/futures/future/trait.Future.html#method.wait) does continuously poll + block until completion. As such it's an incompatible alternative to using an event loop.
&gt; If an object has a destructor then it has move semantics. If it does not, then all of its fields are examined and if any of those do then the whole object has move semantics. And so on down the object structure. If no destructors are found anywhere in an object, then it has copy semantics. I think this is out-of-date. Rust used to infer Copy. Now you have to explicitly opt into it. /u/nrc should update his tutorial. Also, they need to stop referring to `int`. That was removed from Rust awhile ago, too.
Those are great suggestions and some of them could even be criteria to become 'promoted/suggested'
Essentially, what I'm proposing is a kind of [Rust Platform](https://internals.rust-lang.org/t/proposal-the-rust-platform/3745) "Lite"; the [Rust Platform idea wasn't very popular](https://internals.rust-lang.org/t/follow-up-the-rust-platform/3782) for a number of reasons, but I think the idea of picking out some high-quality, ready for production crates from the ecosystem is a good one. I just think that it's more of a matter of selecting, highlighting and documenting them, than of adding any extra functionality to support this and pin down a particular set of versions that are all guaranteed to interop.
thank you, with --lib tests now run only src tests. I don't understand how to run only "tests" folder test but it's not very necessary because i put there only integration tests. Only for curiosity, can you do this?
Hmm, fair. Still has the issue of API backpressure I discussed in the other thread above, but should be okay.
As someone not closely following Hyper, or really even tokio, could someone explain why this is great news? Sounds like this is more than just it switching to a different poll abstraction, which is what I would assume it is.
Reported [#26](https://github.com/jonathandturner/rls_vscode/issues/26).
Yes absolutely! :)
/r/playrust
reqwest, will require a tokio Core regardless of the exposed interface sync/async. The `Client` will likely handle that behind the scenes tho, or at the least at initialization time. At usage time, it really should be the difference between `client.get(url)` or `client.get(url).wait()`.
What’s the idiomatic way to ignore some values in a `match` expression? Trivial example (of course, here, a wrapping `if place &lt;= 3` would be more appropriate, but that’s beside the point): match place { 1 =&gt; println!("first place!"), 2 =&gt; println!("second place!"), 3 =&gt; println!("third place!"), _ =&gt; (), } Should that last arm be `_ =&gt; (),`, `_ =&gt; _,`, or something else entirely?
 error: expected expression, found `_` --&gt; main.rs:76:34 | 76 | _ =&gt; _, | ^ error: expected expression, found `_` --&gt; main.rs:82:13 | 82 | _ | ^ error: aborting due to 2 previous errors Well, that answers part of my question.
Thanks for the tips!
Just a quick note, if this pans out (and as you mention, lets see it first),I imagine that there would be reference/mention/encouragement to this initiative/team in the book and on the website.
Previously, `hyper` has only had a synchronous API in its released versions. There was almost an async version based on `rotor`, but it ended up getting killed at the last moment when `tokio` showed up. I believe this is the first time an async API has made it as far as being merged into master. Lack of a robust async-http library has meant that Rust was not as performant as other options. Given Rust's design goals, some might have been a bit embarrassed to see something like node.js outperforming it. People are excited because this is the first, and probably biggest, step in having performant web frameworks.
Might want to add `appdirs`, `arraymap`, `bytecount`, `wait-timeout`, `smallvec`, and `sys-info`
Hyper was originally synchronous, built on top of std I/O. The async rewrite has been in progress for many months and this signals that it is just about complete.
&gt; but what if a future version of Rust that combines any no-op functions into a single pointer somehow? Or combines functions that happen to share the same machine code into the same pointer? Or all manner of other optimisations that would cause this approach to blow up unexpectedly. FWIW, MSVC's linker has implemented this optimization (as "identical COMDAT folding") for years, and [Google implemented it for the gold linker](https://research.google.com/pubs/pub36912.html) a few years ago. During the course of that implementation Google proposed some new DWARF annotations that would allow usefully debugging code that had been optimized this way.
Great works, looks promising. The missing feature I see is translations of error messages. I am using colander a lot for python/pyramid for data validation and like it to have clear error message when you are writing an API. Translating error messages helps a lot in design of i18n. It avoid glue in frontends, for translating api error, which can be really painfull.
Might be interesting to compare to other standard libraries like [Python's](https://docs.python.org/3/library/) or [Java's](https://docs.oracle.com/javase/7/docs/api/). From a quick rough comparison of your categories to that list of Python top level modules I see many useful things still missing: complex numbers, diff, decimal, fractions, statistics, lzma, tarfile, csv, xml, html, email, mimetypes, base64, cgi, ftp, pop, imap, nntp, smtp, telnet, xmlrpc, ipaddress, audio, windows registry... (Typo: mongling should be mangling I think.)
This actually just gave me an idea for automatic classification. I am imagining something like a section in `Cargo.toml` where the user feels in: - a domain - the maturity of the project - the market reach of the project (number of clients?) - the criticity of the project (?) then, when `cargo` connects to crates.io, it would transmit this information. Crates.io would have to filter the domain (reverse DNS look-up to see if it matches where the request is coming from, for example) to avoid false reporting; if no domain or the domain is filtered out, then the data is anonymous (so much less trustworthy). Of course the client could lie, especially for internal products, so I would tend to "cap" the statistics for anonymous data to avoid faking. Also, a fade-away would be necessary. Maybe only retaining the statistics from the last 6 months of download for example, because nobody cares that the crate was used widely 3 years go if nobody uses it any longer. --- In short, the idea is to do rate the crate similar to what /u/carols10cents is proposing, but gathers real-world usage statistics rather than what the maintainer of the crate *thinks*. Then, when filtering, you can play snob: - only show crates used in production for &gt;100k clients - only show crates used by Amazon, Dropbox, Google, Microsoft or Mozilla - only show crates used in production for &gt;100k clients by Amazon, Dropbox, Google, Microsoft or Mozilla - ... which allows you to select the level of maturity/production-readiness of the crates you expect for your project.
vi?
Very cool. I love seeing academic work in Rust. Thanks for posting.
If a `match` arm is unreachable but the compiler can't figure that out, then you can stick in an `unreachable!()`, which panics if reached. A panic expression has the type `!` which can take the place of any other type because it will never be possible to observe a value of it.
Yeah, sorry, I actually hadn't read your proposal yet when I wrote this, just your text post, and now I see that this overlaps a lot with the ideas that you suggest. I think that with a focus on maybe making this an official Rust team, and getting it added to the docs or put on rust-lang.org, it should probably follow something fairly similar to the Rust team approval process (not necessarily the full RFC process, but at least the process the Rust teams use to evaluate proposed changes to the standard library that are small enough to not require a full RFC, like adding a new impl for a trait). Essentially, pick out a team of people to evaluate proposals, have people nominate particular crates along with some reasoning for why this is the right choice and how it meets the criteria, allow for some discussion, and then accept or reject a nomination (with rejection allowing for future re-nomination if circumstances change). To provide my thoughts on some of your open questions: &gt; * Is this a viable idea? Yes, I think so. &gt; * Should this be surfaced as something that aspiring Rustaceans can easily stumble across? Yes, I think that would be a good idea; I really favor having this be official enough to be published on rust-lang.org, or at least linked to from the docs page. &gt; * What are the categories that would interest production developers? There are a ton of categories I can think of, and I imagine that over time new categories would need to be added as the ecosystem matures and there are more production-ready crates. Beyond the ones you've already listed, I can think of: * network protocols * text processing (like regex) * serialization * command line * terminal * graphics * audio * gamedev (may be separate, or may be covered by other categories) * UI * platform bindings (unix, windows, os x, mobile frameworks, etc) * numerics/math * scientific computing * machine learning * concurrency The list could go on. Some inspiration could come from the [Python documentation](https://docs.python.org/3/library/index.html) (not a perfect set of categories, but good for some inspiration). I don't think it's important to fill in the full list immediately, that would be a huge undertaking; I would imagine we would start small, have both a "nursery" and a "production ready" list with most things going into the "nursery" list at first, and as things are proposed and production users start to settle on particular common solutions would be able to propose new categories and crates in those categories, and migrate some from the nursery to production. &gt; * How should the information be presented? I would put it in a documentation/book format. Have a section for each category, and subsection (page) for each recommended crate. In the section introduction, discuss the category a bit and how the crates in the ecosystem fit into that category, and list each of them with a brief explanation so people can find the crate they need. In the page for each recommended crate, include an example of how to use that crate, and a link to the crate's homepage/full docs/crates.io. Basically, I think it would look something like the [book made from the 24 Days of Rust blog series](https://zsiciarz.github.io/24daysofrust/), except arranged by category with an introductory article for each category. &gt; * Is this an awful idea that should rather just be solved through crates.io? No, I don't think so. The proposed crates.io ranking system would be complementary to this. If this does turn into an official Rust team, some links to this could be added on crates.io, we might add a badge or something to crates listed here, and it could possibly feed into the ranking system. &gt; * Is there such a thing as a "production" user/developer, how do we define them? This is a little hard to define. I think that the main criterion would be "have they written code that depends on crates in the ecosystem that they or other people actually use and maintain". For instance, I would call /u/burntsushi a production user at this point, since ripgrep is a real tool that people use day to day, he maintains it, and it has dependencies on a number of crates, both his own (like regex) and those written by others (like clap). Or maybe that could be rephrased as "have you shipped or deployed code intended for use by an end-user, whether commercial or open source"? Anyhow, I don't think that having a specific definition is as important as just selecting a team of people who have good judgement, and allowing them to evaluate nominations based on a set of guidelines but without having to adhere precisely to a strict set of rules. &gt; * Isn't the rust-nursery enough? I don't think that this is quite good enough (and rust-lang-nursery sort of implies that the crates aren't ready yet; it's really the ones promoted to rust-lang). This requires maintainership of crates to be given over to the libs team, and not all of the crates that should be recommended will want to do this, nor would the libs team have the time to maintain all of the crates that you might want to see highlighted this way. Also, the one big thing still missing from rust-lang-nursery and rust-lang crates is discoverability. I think that we need the extra docs that I mentioned to explain what each crate is for and give an example of how to use it. Right now I think that the nomination process and criteria is reasonable for rust-lang-nursery and rust-lang, but there's nothing pointing you to those crates. Finally, I think there's at least one community crate, `clap`, that I would recommend over the rust-lang-nursery alternative, `getopts`. &gt; * Isn't awesome-rust enough? No. awesome-rust doesn't have strong criteria or a process for adding things beyond a pull request, and doesn't do more than just link to them. I think that awesome-x lists are great for quickly iterating on a list of "the most useful packages out there right now to solve various problems", but I think that a process that is more selective and has higher standards for stability, possibly a nursery and stable level to separate out "up-and-coming but not quite ready yet" from "yeah, we're ready to endorse this", and adds value by showing a quick example of how to use the crates, would add a lot of value. So yeah, definitely support your idea. Sorry for writing so much text; I don't mean to hijack your proposal. I've just been thinking about something in a fairly similar space, but hadn't written anything up, so using this thread as a place to write down my thoughts.
It should say that the analysis started, but sometimes it doesn't. We're hoping to have a more robust status indicator as the vscode plugin continues to improve.
Your comments on scope and practicality are excellent. I didn't realize until you said it but one of the implicit goals would be to have no more than two crates that do more-or-less-the-same-thing, ideally only one. If you need to load a PNG as an incidental part of your main project, you really don't need every PNG loading crate under the sun, you only need one that works. I'd forgotten about `stdx`, it's quite solid! Maybe I should just contribute to that instead? There's not much I'm willing to do to make presentation better unless people actually want something like this. Which it seems maybe they do, so I'll think about that. Your ideas are good ones. This is also something I don't want to become a major project that I do all on my lonesome. I have too many projects already. Making a metacrate would make life a lot harder for minimal benefit, and may or may not make compilation of big things take longer than it already does.
Oh! Oh! I actually much prefer this analogy! /u/nasa42: I'd like to nominate this one for QotW next week!
I would not recommend it: you don't want a backward-compatible upgrade of the compiler to pull in a non-backward-compatible upgrade of a library. I would be more in favor of a "Boost" (C++ world) delivery mode, where a second set of libraries (those owned by the rust-lang organization?) are released as one coherent whole (to avoid dependency hell) every so often. Though maybe this could be cumbersome, as some libraries would want to use the latest shiny new features of rustc, while others would opt to be usable even with rustc 1.0... Then again I guess that this "minimum compiler version" issues exist no matter the distribution mode.
&gt; I'd forgotten about stdx, it's quite solid! Maybe I should just contribute to that instead? I would not suggest that at the moment, since I don't have the bandwith to maintain it. Though if you wanted to just take it over I'd be amenable. I don't particularly think the stdx brand means much though, so starting over from scratch is no big deal.
What are you talking about? I do have a .vi file in .gitignore if that's what you mean, but thats just a local file I don't want in the repository.
Don't they mention just falling back to a function and apply! at some point in the docs?
Any feedback and constructive criticism is appreciated.
Thanks for everyone for the replies, your help is greatly appreciated!
Exactly my questions as well! The answers here are most helpful (along with the blog post, of course)!
Not [docs.rs](https://docs.rs)?
If you could do a write up describing how those features would impact your project that would be great :-) (to be clear: it would be great for helping motivate work on those features)
Yeah, that seems solid.
&gt; Typically types with destructors own some resource Typically, but not necessarily. Which is why it seems strange to me that the compiler assumes such types can't be `Copy`.
Just published my server
crate ndarray supports creating array views from a raw pointer and custom strides, so it can represent the simple cases of numpy.ndarray.
Actually, it's slang for "molest" which I've seen used when it's OK to use "molesting your data" as a tongue-in-cheek synonym for "working with your data". As far as I know, it originates in the "Cockmongler" meme, which is one of 4chan's oldest. (Know Your Meme has a good worksafe explanation for anyone who doesn't remember it.)
I'm talking about destructors. You can't check the error if the object is gone.
Well of course, but if necessary you can check. Or wrap and use exceptions.
Apparently the issue is that the snapshot cargo downloaded by the source repo bootstrap does not run on his system because it depends on a older OpenSSL not installed in his system.
I still use an editor for storing large or many notes, so I only use this occasionally.
&gt; Rust’s native shared-state/mutex system looks fussy and overcomplicated compared to CSP, and its set of primitives is a known defect attractor in any language. While I give the Rust designers credit for course-correcting by including CSP, Go got this right the first time and their result is better integrated into the core language. This is +1 for Go. I'd argue that the whole point of Rust's added complexity is cancelling out that "known defect attractor" property to make it viable for situations where CSP simply isn't suitable. The rest has already been addressed when ESR said this on his personal blog, so I won't rehash it.
Ok so I made a chat room here: https://gitter.im/rust-ml/Lobby?utm_source=share-link&amp;utm_medium=link&amp;utm_campaign=share-link Feel free to come in when you are ready, I would probably be busy until next monday as well.
This is not about Rust, but about language splits sync vs async. Now that Tokio is getting more traction, I thought it could be interesting. I've never actually used Tokio, but I wonder whether it might give us a similar split of Tokio-based and non-Tokio-based code in the Rust ecosystem. Since it's not integrated into the language itself, could it?
I'm totally okay with the feedback. I'm okay with the "Rust is hard" feedback. I am less okay with the tone and the repeated inaccuracies even after being informed of the inaccuracies. I don't consider the "Rust is hard" bit to be inaccurate.
I'm all for criticism for being posted if it's legitimate. It helps identify possible pain points we don't know about (I.e. not the borrow checker) but this is ridiculous coming from ESR. He's been told all that was wrong on his previous blog post, took that criticism and then chucked it away and said exactly the same stuff on this blog. This is just approaching the levels of ignorance and stubbornness that was Zedd Shaw's Python 3 hate article. Urgh.
This is one of the things I love about rust right now, the thing I was complaing about last week has an alpha fix this week :)
[removed]
Some ideas: - `futures-rs` for async - `rayon` for parallelism
We will certainly experiment in that direction. At the moment, we can't get the data for completions out of the compiler. Once we have that, we already cache data from the last compilation so we can continue to use it once another compile has started. The question is whether Racer or slightly stale compiler data gives better results.
NPM is just for the VSCode plugin
I'm the same way. But I would gladly use Python if it could offer what C does. And even though I prefer C to C++, my employer &amp; coworkers do not. So I write C++ all day, regardless of whether I like it or not. Well, except when I am writing Rust, which is entirely by choice and for fun. :)
I've got almost an identical setup and it works for me. Please do file an issue, as there might be a missing step that needs to be documented.
I too found these bits about concurrency to be particularly troubling. &gt;While I give the Rust designers credit for course-correcting by including CSP This statement is just flat-out wrong. Rust had libgreen and *binned it.* Channels mostly exist today in their current form because thread safe queues are indeed a useful primitive. The language does not go to any special lengths to make them as ergonomic as they are in Go. I feel this effort is better spent developing far more useful primitives at the language level which serve to enable high level abstractions such as tokio-rs to be developed *entirely in the library space.* It is much harder for the average Rust developer to add a feature to the language, yet we ship an excellent package manager that makes developing libraries a cinch. --- As for the known defect attractor bit: he conveniently ignores that Rust's ownership system &amp; mutex implementation work in concert to avoid that exact class of bugs. As such I find this statement to be borderline disingenuous, and harmful to Rust's image in the eyes of anyone using ESR's words to form their first opinions of Rust. 
Nice. In what way is `trace-error` "a more lightweight [...] alternative to `error_chain`?" 
&gt; harmful to Rust's image The reverse is also true. Why is the author of The Cathedral and the Bazaar complaining that there are too many stalls on the bazaar? And if he claims to like parsing and translating programming languages in previous blog posts, surely he should know that _epoll isn't part of the C core language either_. How could a Linux specific command be part of any cross-platform language. 
The invite link has expired
&gt; So as long as the HashMap docs doesn't explicitly promise that the values contained within are disjoint with each other and the HashMap struct, my multi_mut, /u/diwic's splitmut and your proposed API would all break the unsafe contracts of HashMap. Every value that HashMap hands out via `get_mut` (which `splitmut` uses) must be disjoint with any other value. Otherwise, it would be possible to modify `v2` with just a mutable reference to `v1`, which of course breaks hashmap. This reasoning does not hold for `get`, which hands out immutable references. OTOH, `get_mut` (as Manishearth pointed out), is allowed to mutate the hashmap, which means that it could potentially move values in memory. I e, if you first ask for `v1` and then for `v2`, when you ask for `v2`, that could potentially move `v1`, causing `v1` to point to invalid memory. I guess one could protect oneself against this by first asking for every value via `get_mut`, and then ask again for the same value via `get` (and panic (edit: or retry?) in case if the value has moved in memory), but that means having to do two lookups of every value now, for something that seems quite unlikely to happen even in the future...
That's the overall theme of the blog post, yes. But at that point it felt like he was only talking about Rust. If having `epoll` as a language primitive was that important to him, he wouldn't have used C either. Go just offers a very thin wrapper around syscalls, in a package called `syscall`. And despite what it name implies, this package is different for every operating system you run it on. The Go developers are aware of this; &gt; Compatibility. Despite best intentions, the package does not meet the Go 1 compatibility guarantee because operating systems change in ways that are beyond our control. The recent changes to FreeBSD are one example. And they're not going to fix it themselves. &gt; As of Go version 1.4, the syscall package is frozen. Any evolution of the system call interface must be supported elsewhere, such as in the go.sys subrepository. So if you want any hope of a cross-platform library, you'll have to use third-party packages. Which is exactly the thing ESR was accusing Rust of. And for what it's worth, Go's neglect of anything not plan9 or Linux is exactly why I gave up on the language. I'm glad Rust is taking a different approach. 
After reading all of this I find it hard to believe anything he says. If you agree with him that's fine, but you won't convince me anytime soon. https://eev.ee/blog/2016/11/23/a-rebuttal-for-python-3/
This seems simple enough to me, the non-Tokio code should be marked as deprecated. Crater should find crates using deprecated APIs, and create GitHub issues for them. Honestly, I feel like the core devs made a giant mistake. If you're not willing to include non-blocking IO in std, don't include any IO in std. If one can be "solved by the ecosystem" both can be "solved by the ecosystem". However, since we can't go back in time, and since a lot of crates already use blocking IO, we can just hope that we don't have the same issues Ruby, Python, C, C++, Java, all have in common. i.e. Legacy libraries obfuscating blocking IO. Other Legacy libraries using a thread-pool to simulate non-blocking IO[0]. Hopefully, enough education is spread through the community that "what color is your function?" doesn't become a problem in Rust. [0] Sadly disc IO has no non-blocking APIs in Linux, for now, it needs a thread-pool based solution.
I understand match matches patterns now, but how does it work? I mean in the second example, when it walks into `Point { x: x, y: 5 } =&gt; println!("x is {}, y is five", x),`, how does rust know this matches? Is it like `try destructure p if success and y is 5 then do something`? If it's like that, then patterns seem like a function with a signature like `(some_param)-&gt;bool`, please correct me.
`--test NAME`
`*`'s higher precedence also is not suitable for "return both results",. e.g. `A-B-C+D =&gt; (A,D)`, if replace `+` with `*`, `A-B-C*D =&gt; (A)` `A*B*C+D =&gt; (C,D)`, if swap `+` and `*`, `A+B+C*D` do return (C,D) but the parer with parse C first, while we expect it to parse A first. We only need to use `*` ignore the result of first operand on the start of an expression, `+` and `-`can fulfill the need on the rest of the expression.
Within a program this can be helped by isolating IO, so that most of your code is pure functions. However this principle in general is a real problem that doesn't only apply to async IO, but also can crop up with things like integrating Results and Iterators sometimes. Its just hard to cleanly manage entering and exiting all the different monads (and I don't think that a `Monad` trait would help).
Don't mistake what I'm saying as disagreeing with your original comment. This blog post is disingenuous! However, I do feel there is one of his points really hits the nail on the mark, and the Rust core is arguably too stubborn to do the language a favor here: &gt; As a special case of the previous point, primitives required for NTP such as select/epoll are not yet a stable part of the language. While implementations exist in the crate system, there is not yet any guarantee that any of the alternatives will be maintained over 10-year timescales. Yes yes I get it, Tokio. But what precedent does that set? What statement is this making to the broad community? I'll tell you what it says from my perspective. "There is a certain set of tasks suitable for prioritization by the Rust core team. Async IO is not one of them!" digging further, "Blocking IO has been included in std because without it, Rust would be unusable. Blocking IO also has a stable interface, and it is easy to get right. In other words, currently Async IO doesn't yet have a stable API, we are unsure how to get it right, and in general it is not necessary for Rust to be useable. Succinctly, Async IO just hasn't proven itself yet, and when there is a crate that solves that problem, cool, we don't want anything to do with that implementation."[0] Now, I'm not saying this is what the Rust core team intends to broadcast. Infact, having some Rust core members working on Tokio says a lot by itself. However do take note, not having a concrete plan to move Tokio (or any other popular/must-have crate) into std, is unintentionally sending the above message across the wire[0]. [0] I acknowledge these words I've put together are not entirely correct, there is definitely some hyperbole. However, I put together the best words I could, to adequately describe the intangible feeling a user of a language gets when reading, "It can be solved by the ecosystem. It doesn't need to be in std.".
Can you suggest a way for us to emit a better message without actually committing to a path that brings async I/O into `std`? That a standard library is relatively small really should not be a foreign concept to C programmers, so I'm having trouble understanding how folks are getting the interpretation you've described. Could you perhaps elaborate?
&gt; Hint hint. :-P If I wrote it, it would be a slog ad. :D But if I was to sum it up from my perspective: There's a long established `log` facade crate that is de-facto standard, and bunch of backends attempting to implement different ways of actually logging stuff. AFAIK `slog` is the only alternative to `log` as opposed to be it's backend, with two way compatibility support for `log`. The biggest differences: it supports structured logging, it's non-global and backends are composable (meaning one can use any [many slog backends](https://github.com/slog-rs/): JSON, journald, colorful terminal, syslog, html, etc. at the same time, in different combinations, without altering any existing code (think open/close principle from SOLID)). So on that list it would have to be like: * log and it's backends: * emit * fern * ulog * ... * slog and it's backends: * ... So yeah, that's the ad. But in other areas things get probably even more complicated, and it would be awesome if we could collaboratively keep track of relationship, state, etc. in different areas of Rust ecosystem as opposed to just listing them. "A State of Rust" wiki or something. 
That's a great idea that I'm not going to do. :-)
Just looked at it, it seems to not automatically build error and result types for you.
Actually, mio has not been stable for years. They've introduced major breaking changes as recently as a few months ago.
If you can comment on https://github.com/Keats/validator/issues/10 with what you are currently using/need it would help me quite a bit. Rust currently doesn't really have a great i18n like the `_("blabla")` we have in Python so I'm not sure what to do with it
Yeah, stable wasn't the right term to use. It's been in a very usable and _mostly_ stable state for the last year, and version pinning mio would be fine (the upgrades haven't been too hard either iirc). Tokio OTOH is extremely new and subject to lots of churn for the next few months.
That's true, for some reason I thought the author specifically wanted `epoll`. Goroutines are amazing things. 
Not a bad ad! Thank you.
Indeed a `Path` is [just an `OsStr`](https://doc.rust-lang.org/beta/src/std/path.rs.html#1355-1357) (but that's an implementation detail).
Just pointing out that Java does not have green threads - it has OS threads
&gt; Or - the other way around, easy way to opt out of hygiene and be able to introduce new names etc., breaking out of hygienic rigor. This is what Scheme, which popularized Hygienic macros has. Scheme also allows "low level" macros where you directly manipulate the syntax tree which are still hygienic. Or not.. The most common use of unhygienic macros is to be able to introduce identifiers that were not suplied from the expansion context into the expansion context. You can do this in a way that the macro still isn't breakable and will behave properly regardless of the expansion context. Generating names which are guaranteed to be unique only solves the downwards hygiene problem which in fact doesn't even occur in Rust because you can't introduce items inside of most macros anyway. The real stickler is the upwards hygiene problem when your macro relies on on some standard feature of the language which locally has been given a different name. If your macro wants to call another macro but the user has accidentally overwritten that macro locally because she didn't know it existed then it breaks.
The difference is that it's _possible_ to run a process with thousands of threads most of which are blocked on I/O, but it's reasonable to run a process with thousands of goroutines doing the same thing. OS threads are very expensive compared to goroutines, in terms of memory requirements and in terms of creation/destruction overhead. OS threads also can't cooperate as tightly – e.g. a producer context switching to a waiting consumer when it sends on a channel. This isn't because OS threads are somehow deficient, it's because OS threads are general in ways that goroutines are not. In other words, the contract the OS makes with a thread is much stronger than the contract the Go runtime makes with a goroutine, so it is unsurprising that threads would be more expensive. Servers written in C don't use thousands of threads blocking on `read()`, they use a smaller number of threads and and event loop driven by `epoll()` or similar to use those threads efficiently. Servers written in Go _do_ use thousands of goroutines blocking on `read()`, while _also_ using a smaller number of threads and an event loop driven by `epoll()`.
ESR is one person with one opinion. Rust is not going through puberty because one project and one person decided they didn't like rust. Rust is a compiler, not a biological entity and now you're just being melodramatic. Getting upset over a person who didn't give your favorite language a fair shake is ridiculous. You are feeding the trolls. Putting your money where your mouth is would be implementing NTPSec with Tokio, it'd be crushing the arch problems the debian folks are having and addressing the portability issues that were presented. It'd be literally anything but writing a blogpost feeding the trolls and the next iteration of flamewar.
&gt; Async IO is opinionated and complicated and harder to justify it being in std. Other languages have managed. &gt; This is very different than the team not considering async I/O to be important. Yes yes, I hear you, in all of the posts you've made on this thread; but the point being made is that it needs to obvious and externally visible what the *The Plan Is(TM)* for new comers to the language. &gt; you see tokio bubbling up... &gt; Alex was giving talks about futures all over Europe in June 2016... Which are not visible. I think the point being made is that the 'async io' story need to be clearly articulated. ...this is the same issue we have with all the other stuff on crates.io. Given a task which should be easy, how do I do it? What crate do I pick? How do I know which crates have 'high reputation'? There's more going on here than just 'this blog post is wrong'. People are being turned off rust, because they **cant solve their problems**; even when solutions to those problems exist, they can't easily find them. Clearly... something isn't working.
Given the discussion that was generated by https://www.reddit.com/r/rust/comments/5oqjnn/are_we_stdlib_yet/, I thought it might be helpful to post the collection of libraries that I prefer to use in Rust projects. It's definitely incomplete, but that's partially because I don't think there are good solutions for everything yet. If you think there's a crate that I'm missing from my list, or you think one of my opinions is silly, please share your thoughts in the comments!
With Tokio, you can write functions generic over "red" vs. "blue". This is made apparent by the fact that the openssl crate was never written with Tokio in mind, yet it worked out of the box with Tokio sockets... How can this be? It turns out that there is no such thing as pure blue (synchronous) functions and Tokio isn't really red (asynchronous). Well written functions need to be able to handle things like interrupts, etc... The rust openssl library did just that. And Tokio isn't really red (asynchronous). It's non blocking. And since WouldBlock is similar to an interrupt, it "just works". Now, it is true that most blue (synchronous) functions don't handle all the potential edge cases that can come up, but that is another story...
This is a very extreme stance to take. Although Async I/O is great boon for performance, it's also overkill for 90% of usecases. This is especially true with regards to disk I/O. Thread per socket + sync I/O can take you pretty far.
I think at this point we should wish ESR good luck with his choice and just wait and see how it comes out in the end. He has already made up his mind, and continuing arguments over this will only make us look needy.
That is an excellent selection of crates! I like every one of them. 
Thanks I did not know this. In fact I was able to change only the signature, to take the `input` and `output` by value (as opposed to a mutable reference), and eliminating the lifetime annotations. And everything just worked. All my test cases still worked unchanged. Pretty amazing. https://gitlab.com/runarberg/trompt/commit/19a55517b83941668b80f558b18135015c271eeb
I was sitting here going "This is a great way to lead people into pure functions versus functions with side effects!". I wonder how many other 'classes' of issues this could help introduce (mutable versus immutable, perhaps?)
webrender could be a pretty awesome cross platform UI renderer. It needs a widget library though.
I'm really strongly against the idea of a boost-like library, where we just have one giant dependency to pull in. It would be no different than just adding all the libraries to the stdlib. If everyone depends on it, then backwards compatibility restrictions would still kick in (because we can't break the pseudo-stdlib and piss off everyone whose relying on it). After years of gathering cruft we'd end up with the graveyard that is the java and some parts of the python stdlibs. Worse case someone else starts up another boost-like library which is incompatible with the first, and then the real fun begins. We should definitely have sets of blessed crates, however, which are easy to discover, and, specifically, advertised well to new users. But a boost like library Is probably not the answer.
Being patient and tolerant is hard; but it's the right thing to do. It's not going in circles. If someone wants to criticise rust, let them. It's fine. Not everyone has to love the language. If you see a criticism that you technically don't agree with, by all means; ignore it, comment on it. Hostile replies do more to damage the reputation of the community than the original comments. &gt; I'm now beginning to agree with /u/llogiq and the rest that these posts are borderline trolling and should not be entertained within our community. Come on. Censoring criticism, regardless what form it takes, it *always* a mistake. Just ignore it. If no one cares, the thread will naturally die. Why is any discussion a bad discussion? If you're sick of responding to them, let it go. Let other people argue it. &gt; I don't see why I should repeatedly acknowledge that in each comment I make... So don't. But if you're wrong (and you are; that post is not 100% bad, I don't care if you acknowledge it or not, or if you've seen the same arguments or not), people will argue with you. People have different opinions... that's great! It's a good thing. Let people make their own decisions. If some one disagrees with you, its because they're thinking about the issues around whats going on. The more the merrier. 
there's already one built with nom https://crates.io/crates/tomllib :)
Yes, I'm aware of it, but I'm not that excited. I mean - it is some improvement and useful but I think some more community-curated effort is better and will emerge at some point.
&gt; There probably aren’t any Rust projects large enough to need the extra complexity offered by slog Sure there are. :P I know of at least couple instances of people using it in some form of production already or doing bigger scope research. Remember that companies don't push their code to crates.io or github. Business is serious about collecting data: logs, metrics etc. where structured logging shines. As soon as you write any part of distributed system, or any business system, you'll want to log stuff and send it to a logging store for many, many purposes. Not sure what to do about better documentation - I'm trying hard already :D. But anyone is welcome to ping me on slog's gitter for help. It is a bit more complicated to get started with slog, but it's very simple to use afterward understanding around two main objects (Logger and Drain). Anyway, good list, and I'm happy that you've mentioned slog. 
this approach looks interesting https://github.com/Immington-Industries/way-cooler/issues/65#issuecomment-241577607
I'm working on a UEFI framework for Rust, so that you just `git clone` and `xargo build` to create your Rusty UEFI application. However, I cannot promise how long you'd have to wait until it's done. **Edit:** *I had mistakenly called `rust-bindgen` `corrode`. Brain mixed up stuff. D:* If you just want to use the official C API, you can use `rust-bindgen` or whatever to create FFI bindings for the GNU EFI headers and just get going using GNU EFI. In case you might not have found these things yet, [here](http://wiki.osdev.org/UEFI) is a nice explanation of how UEFI works, with simple example codes, and [here](http://wiki.osdev.org/UEFI_Bare_Bones) is a short tutorial on how to build a simple hello world UEFI application in C. Though being C, this is still usefull in case you go the FFI way. *(I'm not. My UEFI framework in progress has a completely new Rusty API.)* Using GNU EFI, however, you will need a C compiler and use `Makefile`s instead of sexy `cargo`. In case you want to get past hello world and do something actually useful with your UEFI application, e.g. find a kernel file on disk and load it, then there aren't many tutorials out there waiting for you to read them. Instead, I'd recommend reading the [official UEFI specification](http://www.uefi.org/sites/default/files/resources/UEFI%20Spec%202_6.pdf). Beware, as this PDF is an enormous 2700 pages monster. However, you absolutely do not have to read all the chapters to understand how UEFI works. The specification is really well written, and every single UEFI function has a huge piece of documentation explaining to you what exactly is going on, why, and how and when this and that function should be used.
Thanks! Good to hear that people are using your crate. No need to mention business needs - remember that the vast majority of people posting here work for companies and already deal with business needs every day. :) I personally don't think the increased complexity is worth it in the vast majority of projects (especially Rust projects, which at this point are mostly small), but it's always good to have alternatives available.
We already build awesome stuff in Rust. It's not either-or.
Also use [quickcheck](https://github.com/burntsushi/quickcheck), [clippy](https://github.com/Manishearth/rust-clippy) and [rustfmt](https://crates.io/crates/rustfmt) for well-tested, rustic and consistently formatted code. Not to forget [bencher](https://crates.io/crates/bencher) for benchmarks if you need them.
I must agree with @manishearth here. ESR provides mostly valid facts, but: 1. Mixes them with a large amount of whining and insults. 2. Repeats the same theses even when was provided with explanations and/or counters. Even so, after his generally insulting first post, several people politely (!) responded to his claims. Yet we see what we see. Please compare with the tone of these two blog posts (not about Rust): http://blog.cleancoder.com/uncle-bob/2017/01/11/TheDarkPath.html http://blog.cleancoder.com/uncle-bob/2017/01/13/TypesAndTests.html
&gt; Or we need to reconsider the content on Rust by Example to make new comer friendly. Not sure how that would work. When I was learning Rust, I really appreciated that Rust by Example minimized the fluff. So I don't think adding longer explanations would improve it. But maybe you thought of something else to make it more beginner friendly?
The example looks a bit silly, but it can be more subtle, for example when you have a C++ string and want to return a C string from a function using `c_str()`.
&gt; I don't know the corresponding command on Windows. `set` in `cmd`, `ls Env:` in PowersHell.
I don't care to engage with the points of this post, but I really don't understand the claim that the post's tone is somehow off. It's pretty much a factual cost/benefit analysis with very little emotion. What about it is "abrasive"? Just because it's not published on Medium and doesn't have meme gifs spliced in after every paragraph?
I suppose you meant built-in to Cargo. https://github.com/rust-lang/cargo/blob/master/src/doc/environment-variables.md#environment-variables-cargo-sets-for-crates
&gt; What's ESR? Eric S. Raymond. 
Much is made about lifetimes (specifically, borrow-checking), but personally, that wasn't that hard to pick up. What was frustrating however - and sometimes still gets me - are: * `AsRef` and `Deref`, and why I sometimes had to explicitly add `*` or `&amp;` to expressions * Automatic type conversions that would sometimes (sometimes not!) kick in * The fact that `Box&lt;Trait&gt;` and `Box&lt;Type&gt;` are not equivalent, even though `Type` implements `Trait` (yes, I know the technical reason why, but if you come from an OO background it's annoying and made it hard for me to write test code in some cases) * Heck - trait objects in general!
Solid, solid selection. I agree with your 100-foot opinions of the crates as well.
Actually, a more awake version of myself does have a suggestion. Random paraphrasing of comments I've seen over the last year: "we let the crates ecosystem deal with it" "We don't deal with that in std. Have you seen Tokio?" "Tokio exists.. why is this person complaining(bringing up this point)?" "No. Of course we have async. Just see Mio ..." "... or Tokio. Dang this is hard to answer.. the real problem is they didn't ask the question well enough. I don't know which level of abstraction to recommend them".[0] 1. Don't disagree with people, point to a solution (sometimes people just want to bitch and have you agree). Instead agree, and then point to a solution. 2. Don't disregard the idea of including a lib in std (Even if that is in reality disingenuous). Try something closer to "Yeah lol, we all agree the async story in Rust kinda sucks. We are working on it. In the meantime, try Tokio. Some of the core team members are trialling a production worthy implementation in that crate. It may eventually make its way to standard, but that is a discussion for a different time." [0] Note these are not real quotes. They are intentionally slightly meaner/blunter than the ones you would normally read to reflect the fact that a question asker or commenter reads this over the internet and has vested emotion into it. And discouragement or negativity is enhanced.
&gt; Clearly... something isn't working. tokio 0.1 was just released. How about we give it a chance before declaring that something isn't working?
Lets just make a Go to Rust transpiler. :-) 
No, I am not telling to add more explanations. We should add minimum explanations as we can. ex * http://rustbyexample.com/hello.html ; isn't it too much, can't we remove anything? * http://rustbyexample.com/scope/lifetime/fn.html it starts with 'Ignoring elision' and having more explanations and bit complex ex. can't we more simplified it, ex https://gist.github.com/dumindu/539d81d8d3fe18d45a7b5cafd89e7a38 with more usage. And simplest as we can. * And adding more related content ex, https://gist.github.com/dumindu/e6c2284c1c03d0bfb8f97c8b4f2f5ff9 we don't need to write explanations, code explain itself * And https://www.reddit.com/r/rust/comments/5a2q4k/suggestion_rust_by_practice_practicing_rust/
Since 2017 is the year of the rust IDE I'm wondering if we could get metadata on lifetimes and then color code variables based upon their lifetimes. While I'm throwing out IDE features that are unlikely to happen: I'd also like to see the results of type inference as uneditable text floating to the right of each line. Much like a dynamic language worksheet, but instead of the actual result of execution the type of the expression.
Then maybe if you're building self evidently awesome stuff, you don't need to go into every single thread and reply to every single point you don't agree with? Maybe, just building awesome stuff is enough.
Also, no-one needs care especially what ESR thinks, because he already has a reputation for being outspoken and prejudiced, rather than balanced and fair. So I would say if I heard ESR ranting about some language I knew nothing about, I definitely wouldn't take it as truth.
Why xargo instead of cargo?
/u/burkadurka has done so already: https://www.reddit.com/r/rust/comments/5olcan/announcing_rust_language_server_alpha_release/dcl8y0m/ https://github.com/jonathandturner/rls_vscode/issues/26
I have the following code (copied and modified based on the Json enum in hyper): https://is.gd/Jnk4C2 What I'm confused about is how the match in the `as_str` function works and what it is doing. I noticed that I add or remove as many `&amp;` as I want and it still compiles. DataTypes::Str(ref s) =&gt; Some(s) DataTypes::Str(ref s) =&gt; Some(&amp;s) DataTypes::Str(ref s) =&gt; Some(&amp;&amp;&amp;&amp;&amp;&amp;&amp;s)
I don't feel that `++` and `--` are simpler than `var += 1`/`var -= 1`. They are semantically confusing to me as they modify the original value and *sometimes* (depending on if it is prefix or postfix) increments the returned value. As for changing the type declaration, overall I feel that making a change to the syntax is kind of arbitrary and would be breaking change to the language.
With Tokio still all functions are red. Red is simply a different shade of red than the red from the article. In some red variants you need to pass a callback instead of getting a synchronous result. In others the red variants use promises which you must await or where you attach callbacks. With Tokio you always have functions that can return a "not yet completed" info instead of running always to completion and returning a result (like blue functions would do). The combinators and Task magic work a little bit around that, but it's still not blue functions. E.g. you can't use normal loops to repeat a Tokio action. You can't (or shouldn't) call long blocking operations (blue functions) inside red functions.
Yeah I'd say it's a compiler without biological function. You can bring evidence to the contrary and I will look at it thoroughly, until then a 1 year old language going through puberty makes no sense in any context unless you intend to contrive one to fit your agenda.
Also, do you see the lack of any third party compilers( and pretty much no one will do it, as the community is built on rustc) as a problem? Even go has gccgo, which being part of the GCC as some benefits like adoption among certain(rather fanatical) people and the support on many different architectures and OSes.
Yeah changing the syntax a lot may hurt rust alot. As to the other point, you could include both. But also the fact that rust is a systems programming language, I'm willing to bet most people trying it are use to ++, and were confused on why it didn't work.
That doesn't seem like a problem to me. Now that we have MIR, introducing a new compiler backend *should* be easier, so perhaps we'll see a gcc backend at some point. I seem to recall someone already working on an alternative backend, but don't remember what the project was called. I think time would be better spent on improving LLVM (e.g. by adding backends for currently unsupported architectures) than on creating alternative Rust compilers.
True, but it's still a bug that's easy to catch and fix ("huh this string doesn't look right") and that doesn't come up too often in real life (from my own experience at least). It's hard to explain how amazing the borrow checker really is without showing code that would be a real nightmare to debug without it. 
I love both of these ideas actually.
But Cargo also supports defining your own target, no?
What does having this particular special syntax for incrementing a variable have to do with being a systems programming language? As far as I'm aware Pascal has no ++, but JavaScript does. Being a "systems programming language" has nothing to do with having a particular flavor of syntax.
I'm not 100% sure but I think what you're running into is [deref coercions.](https://doc.rust-lang.org/beta/book/deref-coercions.html) In my limited understanding if there's an implementation for `Deref` Rust will insert as many calls to [`Deref`](https://doc.rust-lang.org/std/ops/trait.Deref.html) as it needs to make code typecheck. In [the documentation for the trait](https://doc.rust-lang.org/std/ops/trait.Deref.html) you'll see there's a blanket impl: `impl&lt;'a, T&gt; Deref for &amp;'a T where T: ?Sized` So what I think is going on is that for e.g: `&amp;&amp;&amp;T` coerces to `&amp;&amp;T` which coerces to `&amp;T` which type checks so rustc stops there.
Cargo already supports custom targets, but xargo will build core/alloc/collections/rustc_unicode for you.
I think the nomicon was what made me really understand the way Rust's guarantees work. 
AFAICT from the limited time I spent in the C++ ecosystem it is kind of a mess when some compilers implement features but other compilers of the *same* language don't. My only conclusion from that is that it would likely fracture the community if there were to be more than one compiler with differing feature sets. Also on your point of "support on many different architectures and OSes", AFAIK LLVM has most of the platforms out there in its compatibility list and I remember from a while back there was a guide on how to add Rust support for a platform as long as LLVM already works on it (the process with bootstrapping, testing, RFCing and the like).
There are some things in ESR's post that are totally made up, however, such as the points about concurrency. ([I elaborated here](https://news.ycombinator.com/item?id=13434329).)
Rust is also Cargo, the docs, Crates.io *Obviously* these are all software and none of them are experiencing hormonal changes or sexual development. The better term would have been adolescence, rather than pubescence, to reduce this level of meaningless pedantism. Rust *is* in an awkward growth phase where it's approaching real maturity and visibility, still has problems to work out, and needs to start working on its place in the ecosystem at large rather than just its own clique. The term for a similar phase to which is humans can relate, is adolescence/puberty. Also, in what world is Rust 1 year old
&gt; OS threads are very expensive compared to goroutines, in terms of memory requirements and in terms of creation/destruction overhead Those two are not actually not the expensive part. You can get the thread stack size down very small with 1:1: 10kB, 6kB with upcoming Linux kernel versions. Creation and destruction are mostly just syscall overhead, which is very small (nanoseconds). For a good presentation (and what I believe the best solution to this problem to be), see here: http://www.linuxplumbersconf.org/2013/ocw/system/presentations/1653/original/LPC%20-%20User%20Threading.pdf
I know I was forgetting something, thank you!
&gt; C++ ecosystem it is kind of a mess when some compilers implement features but other compilers of the same language don't This. The same (non-trivial) line in one of our projects would build under OSX clang, fail under Linux/GCC and Linux/clang, but for two different reasons.
I feel like this is all much ado about nothing. No decent engineer is going to say "I'm not going to use this language because the variable name comes before the type". They chose this syntax because they felt it was better. Whether you agree or not, it's not really important. It's already there, it doesn't affect usability in any significant way for better or worse, and you'll probably have to deal with a language with the name before the type at some point in your career (Go, Scala, Kotlin, Swift, Pascal, and many others). If they wanted to just appease C++ users who fear change to the degree of not even being able to handle the name and type being swapped, they'd never be able to make any changes. Things like the borrow checker are way bigger barriers to getting started than syntax. 
Interesting, but it's unfortunate that it can lead to such weird looking code and it may cause confusion unless you know about Deref.
Not too much. But works.
Changed to this: &gt;impl Service for BlankRegisters { &gt; &gt; type Request = ModbusRequestPDU; &gt; type Response = ModbusResponsePDU; &gt; &gt; type Error = io::Error; &gt; type Future = BoxFuture&lt;Self::Response, Self::Error&gt;; &gt; &gt; fn call(&amp;self, req: Self::Request) -&gt; Self::Future { &gt; match FunctionCode::from_u8(req.code).unwrap(){ &gt; FunctionCode::ReadHoldingRegisters =&gt; { &gt; future::ok(self.read_holding_registers( &gt; req.code, &gt; req.address, &gt; req.q_or_v)).boxed() &gt; }, &gt; _ =&gt; panic!("Not ready") &gt; } &gt; &gt; } &gt;} Now I get this: &gt;error[E0277]: the trait bound `BlankRegisters: &gt;tokio_service::Service` is not satisfied &gt; --&gt; src/lib.rs:282:10 &gt; | &gt;282 | .serve(|| Ok(BlankRegisters::new())); &gt; | ^^^^^ the trait `tokio_service::Service` is not &gt;implemented for `BlankRegisters` &gt; | &gt; = note: required because of the requirements on the impl of &gt; `tokio_service::NewService` for `[closure@src/lib.rs:282:16: 282:44]` &gt;error: aborting due to previous error 
But why start mixing the concepts? C++ only has `auto` because it wasn't born with type inference, and `auto` was the best way of adding it while still being backwards compatible. That is, in C++ you still have to have some word (`auto` in this case) to replace the concrete type (e.g. `string`); but in Rust, the type is simply optional, because type inference was part of the language from the beginning. But what you're proposing is to target Rust very squarely at people who already know C/C++, which would also be a big limitation to put on the language; the point of Rust is not only to be a natural replacement for C and C++, but also to welcome more people to systems programming. And those people may only know languages that are completely different from C/C++ anyway, so why not design Rust's syntax in a way that makes the most sense for Rust's capabilities?
GCC for example has many OSes and architectures that llvm doesn't support iirc, or atleast rust doesn't. https://gcc.gnu.org/install/specific.html That's not all of them either 
Swift and Kotlin also follow this syntax, it definitely makes type inference cleaner.
You are comparing Rust with Go which also has types after names.
Very nicely explained, even through Google translate; I really liked the realistic example, and then explaining a few different ideas of data modeling in Rust. (Domain specific wrappers, Error handling as wrapper types, sharing references for value reuse, insisting on ownership passing to force a single consumer). Something like this is a great resource for all the people who come from OOP and are unsure how to domain model with the new tools.
GCC for example has many OSes and architectures that llvm doesn't support iirc, or atleast rust doesn't. https://gcc.gnu.org/install/specific.html That's not all of them either 
Being in Europe I can attest to Alex' talks being very visible here.
No, but if your trying to be the C replacement, wouldn't you try to be a little closer syntax wise?
Thank you for the feedback!
I'm on mobile right now, but if there's no [issue](https://github.com/rust-lang/rust/issues) for it, perhaps create one?
Even though I would like more friendly competition, I think that getting llvm to support as many OSes/architectures as first class citizens as possible, ala GCC in some regards.
Yes but go has simpler syntax to begin with, almost to a fault(no generics circlejerk inc). Also go isn't a c replacement. Maybe a "next gen c", but I doubt you will be written kernels and low level things in go. Maybe I'm wrong.
Simple but good. Eventually I'd like to write a similar article in my language too (perhaps just a translation of yours). Rust is good not just for system programming, but also for business logic code!
This is great, thank you! I've stumbled upon the patterns you've used here, but having them written out as a cohesive example really solidifies them. I can see this really helping people who haven't had a chance to just tinker with the language extensively, and wish I had had the resource earlier myself ;). Rust has fantastic documentation and articles, but there are less things written about structuring programs using all the expressive constructs available. (On a separate note, I'm currently in Portugal and trying to learn Portuguese as my first non-English language, so having a programming article that piques my interest is great!)
Thank you for this question - we used the nightly version because we used some feature flags before the release. Now, we do not need those, so we plan to move to the stable version of Rust soon ;-)
Yes, exactly. Syntax is the least of the OP's future troubles. It kind of reminds me of reading a thread with pilots griping about how unsafe autogyros are (PPO,etc), when they wouldn't even consider getting into a helicopter without hours of training. So maybe Rust is *too* similar to C/C++, so people think they can just walk into it and pick it up in a weekend (ESR?), whereas if someone suggested learning Haskell in a weekend everyone would agree you'd be better off dedicating several months to it. Cultivating an slight aura of difficulty or challenge (but counterbalanced with a helpful community and tools) may be to Rust's advantage.
How so?' Let var: u8 = y compared to something like int var = y or auto var = y. In c++ it's simply less to type to declare something. 
I mean, why make semicolons required then like Go? (Just playing devil's advocate). Out of curiosity, not trying to sound like an elitist it anything, but what would someone who doesn't know system programming concepts(say someone who only knew js) have a need to use Rust? They can get similar/good enough speed with Go for most of their needs. How many js programmers jumped into kernel development? In that case why would they use rust? If they are trying to learn low level development, why use a language that only has first class treatment on the big 3 and x86? Also picking js was kinda bad since C-style syntax. I'm willing to bet more people know/come from C-style syntax (C/C++/Js etc), so instead of making 2 groups uncomfortable, give the most popular and most likely to use rust group an easier time? I know it's a kinda shitty argument.
I appreciate the feedback. Obrigado! I hope I manage time to get more written in Portuguese (:
The thing is you can't code Rust like it's C. If you do you'll hit the "wall of errors" which you will beat your head against until you learn to do things the Rust way, i.e. the way the the compiler can prove to itself is 100% safe. So syntax is the least of your problems. There is a lot more to learn beyond that, but it's worthwhile.
&gt; I don't see why variable++ can't be support `variable++` and `++variable` are confusing and frankly, unnecessary. Even if we only add one of them, people will expect it to evaluate to the old value, which still leads to confusing code. The designers do not feel that prefix/postfix increment operators are worth the confusion. `variable += 1` is not much more typing over `variable++`. Meh. Besides, due to iterator you don't even end up incrementing vars that much. We have 43 instances of `+= 1` in Servo, which is only slightly more than the number of `+= [something that isn't 1]` (38), and Servo is one of the largest single Rust codebases out there. &gt; nor do I see any reason to have to use variable: type versus "let u8 variable = value" I can ask the same about the reverse. C++s syntax isn't superior in any way, it's just what C/C++/Java use. You're used to it. Many languages go the other way. Besides, `let u8 variable = value` is confusing when you throw inference into the mix. 99% of lets in Rust don't have a type annotation, so now your mind needs to jump around when reading the declaration to tell if the next identifier is a type or a variable. The colon makes it very visually clear. (As other people have noted, Rust lets bind patterns to values, so it's even more complicated than that, because you can do `let (a, b) = c`) I've often found the C++ syntax (and I learned C++ before Rust) to be jarring especially because there's often no convention for capitalization of type names. &gt; Did rust not want to be a C superset ala C++? Definitely not, Rust wants to be able to replace C and C++, not provide the same interface. We stuck with some C++-like syntax (braces, etc) so as not to be too new but a lot of things were decided upon independently. &gt; disregarding Google's support and it's longer lifetime But these are some of the main reasons behind that. And yes, Rust and Go appeared around the same time, but Rust was experimental and unstable for years. Go has had a pretty large headstart when it comes to being a language people can actually use in production. Go _is_ built to be easier to pick up, and that will help it. But Go differs from C++ with the syntax plenty. I've always found the `func (*Receiver) (args args) return_type` function syntax weird. That's one of many ways Go differs. It's not Go's syntax that makes it easy to pick up.
When all else is equal, Rust syntax tends to be pretty similar to C. But it is also not afraid to pick a better syntax when the C choice is clearly inferior, and I deeply appreciate that. I don't want a C clone, I want something better.
Would you? I got the impression that `++` and `--` are present in C primarily because they compiled to nice instructions on the PDP-11. But I don't think anyone particularly needs them (although they have been adopted for iterators in C++), and it turns out you don't really miss them once you try a programming language that doesn't have them.
that ~~memories~~ languages actually
That fair. Thanks for the response
Hi, I'm a production user of Rust with 6 production apps (and a bunch of libraries) under my belt. I'd definitely be interested in helping. We have established answers for logging, HTTP, error handling and serialization that make life pretty easy even inside Docker containers somewhere on a cluster. Feel free to PM me. I may drop by the issue tracker later if I don't forget.
Thanks for the response. I agree and I'm coming to terms with my bad attitude(hah). Syntax, I think, does play a part in adoption, esp for people who are new to a topic. 
It's explained in the thread (or possibly in the GitHub issue that originated that thread, can't remember). The problem is that Core doesn't have String, so it isn't allowed to have that impl.
I agree that rust can be a language that can be used for all things and reasonably as well. Thanks for the response.
Interesting note about the origins of it. I'll just need to get used to it. Thanks for the response
It's mostly me being stubborn. Hopefully I can use rust as comfortably as I can C/C++ soon! There are clear benefits to rust that I want to use effectively.
That's something I can get behind. It's probably due to my unfamiliarity with it and of other language families(ML). Thanks for the response.
Interesting. I have no Windows, so I cannot reproduce, but if you file an issue, we can have someone look into it. May be just a path thing, though.
That was indeed an issue. Thanks!
Pretty sure HTTP2 is based on keeping one TCP connection open to retrieve all of the files it needs. Currently, your browser opens a TCP stream for every single image, javascript file, CSS file that the website needs. That's very susceptible to latency.
I don't understand your example as Cargo has an algorithm to produce one of the above scenarios for me (1 or 3, I think). What would you prefer, to have huge monolithic crates that duplicate functionality unnecessarily? That's what happens in C++ land where you have many conflicting implementations of common basic types like string. The point is that we already have many small crates in the ecosystem and the end user needs to do the discovery, selection, curation, etc, themselves. The community can do that collaboratively once. I'm suggesting that this should be integrated into the ecosystem - specifically, on crates.io. Having manually kept lists of links on github doesn't seem maintainable to me. 
Thanks! If I'm understanding you correctly, serde-json can do that too using its Value struct (which will work on stable Rust).
This is Fefe's follow up blogpost to the OpenSSL 1.1 post mentioned here: https://www.reddit.com/r/rust/comments/5ok6r8/openssl_11/ Mostly he criticize that you need a Rust binary to build Rust and cargo to build cargo.
(Also, on a quite subjective note, I personally think that C-style "type before" syntax tends to get a bit messy when you have functions that takes function as arguments and/or return other functions)
I agree that it does good at combining alot of different aspects of other languages
the whole posts seems a bit uninformed. there is some criticism about neither cargo nor rustc being bootstrapable, which i think is simply not true for cargo. he also seems to be confused about the function of nightly, or has not updated his compiler in quite a while, as he seems to be unable to build openssl or ripgrep without nightly. in the end he suggests to call give rust a 0. instead of a 1. version number due to these issues. to me it seems a bit like he is making a fool of himself.
I think the Ocaml example he gives is quite elegant. I guess you should be able to assume at least a c compiler to be present. 
What's the purpose of building from source? I can think of three reasons: - making modifications (doesn't seem to be happening here for Rust and Cargo), - not wanting to run an "untrusted" binary... but there's too much code for codebases like Rust and even Cargo to vet, so one is still effectively running an arbitrary binary even if it happened to be produced locally, - wanting to optimise/[funroll](https://fun.irq.dk/funroll-loops.org/) all the loops, which is nice, but seems... unfortunate to restrict one's computing experience just because some code is running a few percent slower (and, it seems like bootstrapping is perfectly compatible with this). &gt; Binary packages is the bad compromise for people who are too stupid to build from the sources. And they are not a target group at Rust. The learning curve is too steep for Rust. WTF? I hope Google translate is making this more insulting than it is in the original. For one, just because one is able to spend hours of CPU time building a compiler doesn't mean one wants to, maybe one is running on a shared/locked-down computer where install the prerequisites is hard, or maybe even Rust is someone's first experience dipping down below JavaScript or some "all-in-one" development environment, so adding irrelevant barriers like "work out how to compile from source" is the stupid thing (I'm sure they'd be *able* to work it out, that's not the question). &gt; Ripgrep can not compile with the Stable version of Rust. And also not with the beta version. This needs the bleeding edge version. Uh... https://github.com/BurntSushi/ripgrep/#building &gt; ripgrep compiles with Rust 1.12 (stable) or newer.
it is a good literal translation, but you need to consider that there are cultural differences. in german its more normal to be quite direct. this is still harsh though.
&gt; not wanting to run an "untrusted" binary... but there's too much code for codebases like Rust and even Cargo to vet, so one is still effectively running an arbitrary binary even if it happened to be produced locally, Well, you can somewhat trust that the community which works on the codebase would catch any malice. It's harder to trust the uploaded binaries for that; that's a much smaller group of people with less oversight. Even if you do trust them, you may not trust that the infrastructure is secure. I personally don't really see this to be a problem, but I can imagine that some people might.
[removed]
ESR crystallizes strong reactions: you should expect a few people who have brushed with him before to react strongly. Do note however that those are individuals, not the community. The moderators considering the topics is not about ESR or his articles. I would personally be saddened but it appears a subset of the community cannot help but discuss the author rather than the post, and this results in sprawling comments that have to be moderated because they violate a number of the rules so helpfully laid in the sidebar. As a result, I can understand the moderators frustration with the commenters; they're not paid to clean-up after all, and it's not fun, so if it's too much work for them, then deleting the posts is a last resort solution that will avoid them drowning.
I do not recall any low-complexity promise. The ease of writing Rust, for me, had more to do with the fact that it was *safe* and therefore much easier than C in the sense that you would not spend hours tracking down crashes, data-races and memory-corruptions which are a pain to deal with.
It's not irrelevant; Rust is seven or so years old, not one and a half. I agree that getting bogged down in the pedantism of how to correctly apply anthropomorphic metaphors to a programming language is bikeshedding to the extreme, but if we're going to do it at least do it correctly. Besides, what else am I going to do after [punching compile](https://xkcd.com/303/)
[Image](http://imgs.xkcd.com/comics/compiling.png) [Mobile](https://m.xkcd.com/303/) **Title:** Compiling **Title-text:** 'Are you stealing those LCDs?' 'Yeah, but I'm doing it while my code compiles\.' [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/303#Explanation) **Stats:** This comic has been referenced 839 times, representing 0.5793% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dcn1nd3)
those actually are good questions, and thats a computer science field currently being worked on, its just not easy to solve the trust problem.
&gt; Did rust not want to be a C superset ala C++? No. Rust wants to replace C, but carefully *avoided* standing too close to C because the language has intractable issues that only a "rewrite from scratch and applies lessons learned" solution can avoid. (Aka: organic growth cannot challenge the foundations, it's only about the outward appearance)
Are you looking for an Active Record replacement? That'd be [diesel](http://diesel.rs/)
Thanks! &gt; Programming languages are afraid of only being taken seriously once the are self-hosting. I can only concur here; I've always found it strange how boot-strapping was supposed to be how it should be done. I find it has a lot of disadvantages, as evolving the language then requires careful lock-step upgrades, and worries about backward compatibility, etc... And as for informing language design, well it helps in creating a language suited to write compilers, but compilers are very niche, and exercise little of the language: batch-type job with I/O only at the beginning and end? That's quite feature poor!
I've read two and I skimmed the third, and it seems to reinforce /u/amoe_'s perspective, which I share. I'm sure he could have done better to avoid unnecessarily inflammatory language, but I've certainly read posts with more "tone" from highly regarded members of this community.
futures, which is the brace that keeps tokio upright, is the kind of fundamental abstraction I could easily see in std someday. Some abstractions in tokio similarly seem std-able, including things like the async TCP connection. The event loop that tokio provides is a big, opinionated piece of software, not an abstraction, and not really appropriate for std. But if futures is in std, tokio::Core will be the 'omakase' event loop you use to run your async IO, and other people writing similar event loops with different performance characteristics or API properties will be writing against the same interface. But we don't really have the data to confidently say that futures and tokio are a solution worth endorsing forever. I feel that they almost certainly will be, but for *forever* we would want some actual empirical production data. We could put them in std behind a feature flag, and then only nightly users could use them. But by building them outside of std, they can continue to evolve while still running on stable Rust.
Ahh ok thanks for the response
This looks an awful lot like our standard stack at Faraday, except: 1. We don't use GL from Rust. 2. We use the `reqwest` wrapper around `hyper` to avoid the upcoming API breakage. 3. We only use `clap` for things with complicated subcommands. We use `docopt` for simple CLI tools because it's so easy. 4. We're going to let other people experiment with `tokio` before we even think of using it in production.
You responded to my OP. Not the other way around. I suggest we part and spend our time in wiser ways.
That would depend on your iterator. If it's just a slice iterator, you can simply call `.len()` on it before the function consumes it. If it's `Clone`, you may be able to clone it before giving it away.
No. Fefe always compiles C code to machine code using pen and paper, only typing in the resulting bits. 😎
You are looking for /r/playrust :)
It is as insulting as the translation.
Fefe is our local conspiracy theorist. No way he's going to run code from untrusted sources (like, say, *Mozilla* – they're part of the ~~Illuminati~~ whatever)...
Those of us suffering from actual diabetes are probably not laughing when reading your comment.
You are mostly right, that exactly what happens. now the point is that you are not actually magically creating bandwidth by using this tool, but taking it away from others. your isp not buying as much bandwidth as they sell to their customers is _completly normal and nescesary_. if you as a private person were to actually pay for even 10 mbit of reserved bandwidth you would quickly be poor. ratios of 10:1 to 15:1 (sold speed to bought speed) are absolutely common. this works because people usually only use 1-5% of their total bandwidth (rate you booked*month). the problem you observed (not being able to reach the rate) is due to your isp being a bit too aggressive in that regard. also it is not really the routing software that does the shaping/balancing, but thats a whole new topic.
I think strategy is most effective for download hosts (e.g. sourceforge) that cap download speed per connection. These tools effectively circumvent any per-connection bottlenecks imposed by the server/infrastructure owners. It's for this reason that these tools were pretty popular back in the early 00's, when sites like download.com and sourceforge were at their peak.
Yeah, code-wise i think memory maps are a good fit for the problem.
Compared to C and C++, Rust uses keywords like `fn` and `let`, because it's also much easier to parse them, so it has some benefits for the compiler as well (C and especially C++ are famously hard to parse). Having both syntax would mean massive complexity in the compiler.
another solution would be to switch away from your current isp to another one. thanks to capitalism and free markets you should have a choice in that regard. it is kind of unlikely that the slowdown is due to torrents. torrent clients in general aggressively back off when they notice something else is using the network, so they generally play nice. so it is probably your isp not buying enough bandwidth to satisfy the users need.
&gt; We use docopt for simple CLI tools because it's so easy `clap` is also quite easy, so why not use it everywhere? I mostly copy/paste stuff between projects anyway, so it's really just stripping out stuff I don't need when I start a new one.
Yes. Diesel handles database creation, migrations, etc., as well as database access.
&gt;Please don't do this, this is hurting either yourself or the internet at large Most the time it is CDN rules. Some sites host HTML5 video, but throttle downloads to 200KB/s-250KB/s. So you can only *stream* the video. If you download it, it'll take the same amount of time as watching it. If I can only download a file at 1/10000th my ISP speed quoted speed... I'm using a download accelerator. If your website is struggling that hard to keep up with load an accelerator is the least of your problems.
I've been thinking that if I could manage to make Servo embeddable and expose DOM to native Rust code, then that could be awesome replacement for [Electron](http://electron.atom.io) which seems very popular way of building cross-platform applications these days. The challenge is that the DOM lives deep inside the scripting module which runs in its own thread, so it is not easy to mutably access it safely from "outside". My best idea so far is to try to embed capnp-rpc server inside the scripting module, running in the same thread and hopefully that way avoiding any problematic sharing issues.
&gt; Yeah, I understand that I'm not creating bandwidth out of thin air. But I'm pretty sure other clients are using torrents and probably tools like this, so if I don't do the same I'm not going to get my fair share. Tragedy of the commons in action! Problems like this (if I don't contribute to the problem, I'm screwing myself, since others already are) are completely of a piece with capitalism and free markets with their emphasis on individual choice! (I'm only pointing this out because of my already-posted sibling touting free markets as the solution.)
Frankly, I don't know why people are publishing half-finished or non-production-quality crates to begin with. Things can be open source without being on crates.io. But my lament changes nothing.
Ah, okay. When I was looking for an argument parser, `docopt` seemed too simple, so I decided to just go for `clap`. That actually does sound pretty nice.
It's not currently active unfortunately, but a few coworkers and I are thinking of bringing it back to life eventually.
Good Old Capitalism
Perhaps `cargo` being able to use `git` repositories isn't well known? Or it could be namespace reserving, because renaming a project later when-you-find-out-someone-took-the-name-while-you-were-ironing-out-the-bugs is a pain. It could also be a, "even the best intentions sometimes fall short" type deal where people *intend* to flesh out a crate, but then life happens.
I wish you wrote more about your string concatenation solution and less about the zits. It was sickening.
&gt; This permits interesting optimizations, like a producer that context switches straight to a consumer via a channel send without a scheduler in the middle. The 128 bits needed to resume the consumer can be stored in the channel, making a context switch roughly the cost of an indirect jump. Did you see the performance numbers for switchto quoted in that slide deck? We're talking *fewer than 200ns*. The various other overheads, for example of allocating whatever message you're going to send on the heap, will matter a lot more in practice. &gt; This is interesting, and like Go's goroutine switching scheme, it might just be cheaper than what the OS would do with a C program. I don't think it's necessarily true that this is cheaper. Not only do you have to copy the stack, but you also have to update all the old pointers into the stack to point to the new one. It's not just a memcpy. (I suspect that Go simply doesn't allow pointers from heap to stack, which obviously has a lot of costs itself.) Contrast this with hitting the guard page and growing, which has no copying costs at all. It's just a signal handler and a page remap. It's actually *asymptotically* faster, because growing via copying scales quadratically, while modifying page tables scales linearly. And switching from kernel to user is about 50ns. &gt; including platforms like Windows which have significantly more expensive thread creation and a 64 KB allocation granularity. Windows already has user-mode scheduling, which is 1:1. So it's Linux that needs to catch up. Once we have that, then 1:1 will have a clear advantage, I think: the gains of M:N over 1:1 with switchto are marginal, while the drawback of a slow FFI is huge.
My point is that that Rust solves some hard problems. If I care about those problems there's a good chance I'll care about Rust because regardless of how hard it is to learn, it (aims to be) easier to solve those problems with Rust than without. If I don't care about those problems then Rust may not be the tool for me. But I don't complain when `cat` doesn't provide me with paging, I just use `less` instead. If Eric cared about no-gc, managed memory and safety from segfaults he shouldn't be comparing Rust to Go, he should be comparing Rust to C or C++, specifically trying to write safe code in C or C++. If he doesn't care about those things then Rust isn't the tool he's looking for. /r/rust shouldn't navel gaze and try to be all things to all people, writing a "Rust for people who've never programmed before" book and trying to make the language easier to learn at the expense of adding complications to the language that make it harder to master. Rust isn't for the problem he's trying to solve and unless he feels he's been misled to believe otherwise he shouldn't be acting like the rust community has an obligation to work to keep his "business". Respectfully, this is a bazaar not a cathedral, if you don't like it go to a different stall.
One feature I wish to see is auto complete for options that make sense. E.g if the value is one of few options. Or if the value should be a path, auto complete will make it easy
Exactly, there are no incentives to write a third-party Rust compiler rather than contribute to the Rust project itself.
Huh. Was wondering why Rust disappeared after the first two lists. Upon closer examination, the first two lists tracked open pull requests, while the rest only looked at closed pull requests. Which means that the ratios calculated later were ignoring pull requests that were just left open forever, never merged or closed.
&gt; ripgrep BTW, ripgrep is awesome, and it's now replaced `grep` for me. :)
C++ gives a *terrible* first impression, especially when you do something that induces messy template errors, but it is the highest-paying and highest-regarded programming language in the United States [according to this Quora post](https://www.quora.com/Financially-speaking-which-computer-languages-can-earn-the-most-for-the-programmer), so people are willing to put up with its quirks. Rust, while I believe it to be the future, does not have that sort of pedigree in 2017, so people are banking a lot on first impressions. 
Optimism, partially.
Cargo already has a tags system that seems ideal for this... perhaps it could be as simple as making the default `Cargo.toml` file created by `cargo init` include a set of useful tags and a suggestion to pick one in a comment? For example, Python's pip repository has a "Development status" tag that you can set to "planning", "pre-alpha", "alpha", "stable", "mature" and "inactive". Or omit entirely if you feel like it.
Crates on crates.io get tested with crater.
He doesn't say but he probably wants ripgrep for its speed and that means nightly for SIMD support.
The trouble isn't publishing half-finished crates. It's taking a name from the global crates.io namespace name for something that might never become usable. I know this has been proposed and rejected ad infinitum, but: we should have an `username/crate` name on crates.io for half-baked stuff, that would be upgraded to `crate` only when it reach some level of quality.
Good enough for now I suppose
Thanks
A database of users on a messaging system where I log message data as it's being sent and received.
&gt; I'm not sure if you can do much about it thought, because you cannot overload operators that are not predefined in Rust I'm not saying its a great idea, but there are "inventive" ways to do so. See https://code.activestate.com/recipes/384122/
:) Glad you're enjoying it! Please feel free to stop by the repo anytime and ask questions, make suggestions, anything!
Hey, I might just do that! I might even throw a PR or two your way if things work out between us :)
That's how I do it too but I find it inefficient and makes me unwilling to refactor my code constantly. In any case, this is unimportant now that we have [RLS](https://github.com/jonathandturner/rls).
Modern languages with iterator-like substances rarely need an increment, especially if you can generate iterators over a range of numbers.
Having both *would* be terrible because why muddy the syntax with many versions of the same thing?
In my case, when I have something to publish, it's because, if I can't use a service like crates.io or PyPI as a single point of DNS-like abstraction between my projects and my hosting service, I'll satisfy my need to have a high-efficiency GitHub exit strategy by making big monolithic projects. (TL;DR: I refuse to depend on raw Git URLs)
GPU enhanced terminals? Interesting! Hyyyyyype!
You can name your crate `username-crate` whenever you would like.
At best, automatic transpiling from a GCed language to a non-GCed language produces output you're not going to enjoy hand-editing.
Well, just let the author decide when it reaches this level of quality.
The biggest upside of `++` in C/C++ is also its biggest downside: it's an expression that can be part of a statement, rather than an entire statement by itself. The `=` operator is an expression too. That lets you write lines like this: if (x = y++) { ... } That's convenient sometimes, but other times shoving side effects into a line like that causes more trouble than its worth. (It also leads to the dreaded `=` vs `==` bug that hurts beginners so often in those languages.) Python decided more than 20 years ago that allowing those operations to be expressions wasn't a good idea. Rust followed Python's lead on this one I think. It might've been possible to include `++` only as a statement, but that would probably just make both sides angry :) ---- I think [/u/KasMA1990 is right](https://www.reddit.com/r/rust/comments/5owqam/discussion_about_rusts_syntactic/dcmmg7q/) about putting the type name after the variable. That's important when you have type inference, because the type name is optional, and you don't want an optional thing to come before a mandatory thing, or else it's annoying to read. ---- For what it's worth, a lot of us are familiar with a tame and reasonable subset of C syntax that we learned in school, but there are many [dark corners](https://docs.google.com/presentation/d/1h49gY3TSiayLMXYmRMaAEMl05FaJ-Z6jDOWOz3EsqqQ/preview?slide=id.gec7eb408_3500) in that old language. Rust did try to stick to C and C++ syntax where it made sense to do that. See `T&lt;U&gt;`, `&amp;&amp;`/`||`, `*`/`&amp;`, semicolons, etc.
ripgrep is still pretty fast without the explicit SIMD support btw (which is mostly courtesy of your friendly neighborhood libc's memchr implementation, which will probably use SIMD internally). The explicit SIMD in Rust land only comes into play when you want to search for multiple patterns, e.g., `rg 'foo|bar'` or even `rg -i foo`.