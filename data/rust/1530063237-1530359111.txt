Are there any good options for hot-reloading templates in any of the rust web frameworks? I've looked at actix and rocket, plus the templates they provide support for, and I can't find anything short of having to make a hacky solution myself? I really want to use rust for my next web project but it's going to be a hard sell to the person doing the front-end if he needs to restart an app every time he changes a template. 
Submitted a review (yet another 5 stars). Still only at 7 reviews when I looked, so its not hard to add perspective.
[removed]
Will the "Improved ergonomics for the Request object's API" get it closer to Rocket's Request guards? https://rocket.rs/guide/requests/#request-guards
I've never written a macro, and as a user I consider println! the name :\
Ah, not quite. Thruster's architecture actually achieves that by using middleware and the middleware chain. Basically all middleware (or route handlers if you like,) are functions that take a context to pass state, and a chain to allow the next function in the chain to be called. For the improved ergonomics, I'll provide convenience methods for string conversions of the body, but will also allow access to the raw buffer of data for the request. That sort of thing :-)
Would have been a bit much to call it `futures-future`, I imagine? =P
Has a decision been made as to whether `never_type` will block Rust 2018 release or not? (Or will the deciding team make that decision later?)
If you're unwrapping all your `.get()`s, you can use the indexing operator instead, which panics if the key isn't present (and automatically copies out the value): fn solve(coins: &amp;Vec&lt;i64&gt;, target: i64) -&gt; i64 { let mut values = HashMap::new(); values.insert(0, 0); for x in 1..=target { values.insert(x, i64::max_value() - 1); for coin in coins { if x - coin &gt;= 0 { // this temp var shouldn't be necessary in the future let insert = cmp::min(values[&amp;x], values[x - coin] + 1); values.insert(x, insert); } } } values[&amp;target] }
Oops, I missed the part of the documentation above Safety that says it's not a move. But it doesn't say similar to one semantically, it says it is one semantically. So the compiler isn't blocking your usage as with a normal move, but otherwise using the source would be like trying to use a moved value. I'm not sure what you mean by the thing about two variables with the same mutable reference. ptr::read moving values isn't inherently about mutable references, it's about moving and copying. My example is just showing that this "copying" can be dangerous, and should be considered a "move" (i.e. not allowed to use the old value) even though the compiler does not check that. Here's an example with the typical copy mechanism: http://play.rust-lang.org/?gist=0939c483e053624fe45d2be39ced4657&amp;version=stable&amp;mode=debug `let mut_b = mut_a` is either a copy or move depending on the type involved (note that mut_b and mut_a are just variable names). Since I try to use mut_a later, that would only be legal if I could copy `&amp;mut`s, which I can't. The other version with illegal_copy() uses `ptr::read` to perform the same operation without the compiler complaining. A &amp; or &amp;mut pointer doesn't do anything fancy on being dropped. "Uninitialized" refers to memory not being set up before hand. It's a state that Rust tries to avoid programmers interacting with. `mem::uninitialized()` can give you a value of any type based off whatever garbage is lying around in memory. I'm trying to argue that after a `ptr::read()`, if the type is not Copy, you should consider the source to be garbage, even though it contains what should be a valid value of the type, because otherwise you've basically copied something you're not allowed to copy, with hard to predict consequences. Sorry if this is a bit of a mess.
Hey thanks, I should have looked at the docs harder. I guess it's similar to Python's dict `[ ]` and `get` methods. Would you say that using unwraps in cases like these is a bad idea? (Or indexing directly in to the hashmap and `panic`king on keyerror?) Also out of curiosity, the temp variable not being required in the future, that will be a consequence of NLL, right? Thanks again for all the help. I'm still trying to grok when to: - panic - ? - match - unwrap 
Yeah, but I wanted to get all the events for all objects, including a mouse move event on an object. It sounds like Subclasses are the only way to do it.
Thanks for the great article! However I have trouble thinking of a use-case/motivation for this "select" thing (I'm not a go programmer either). When do people typically use them?
&gt;Temporarily out of stock. darn it. maybe it's like the situation with diamonds. making people want it more by limiting supply.
I agree, and perhaps it is useful to think about `pub(crate)` as '*published* at a crate level', rather than *public*. Also, whilst I can see how `crate struct` and `crate mod` might make sense (it is a module or struct which *belongs to the crate*), I find the `crate` qualifier next to struct fields **very unintuitive**. I mean take a look: pub struct Foo { crate a: i32, crate b: String }
Trying to make my first public crate. I made simple settings / configuration program for my usage in cli apps but it only handles `Strings` and hardcoded to use `Toml`. I wanted to make it more robust before publishing it (handling multiple variable Types and config file types - Serde!). So I have a basic idea working but I'm wrapping my head around generics and traits so I can get something user friendly. The idea is something that you can use in a CLI (or other app) to easily read and write configurations locally and globally with minimal code. You create an empty `struct` and implement some rules (filename, path, what serde library / format you want, some optional parameters) and then you can read and write date as simple as `settings_file.get_value("user.name")` or `settings_file.set_value("program.theme.ui.color",[1,0.5,0.34,1])`. And it can be overwritten by a locally configuration (a file in global user location and one in the current working directory). Working repo here [Settingsfile-rs](https://github.com/snsvrno/settingsfile-rs). Better name hopefully before pushing to crates. Hoping something like this is useful, I was looking for one but didn't find one.
Hey /u/epage, I don't mind at all, but this post isn't really very information dense, there's a lot of copy that you could do without... I'd suggest maybe going through and distilling it a bit... Also, I'm not sure what you mean by documentation PRs? A PR with documentation in it? like a foreword about the article? the article itself?
Awesome, I did the python tutorial a while back and kind of abandoned it because python kept giving me issues. (user error?). I like rust a lot more and might check this out! A comment, I'd like to struggle through some of it myself, maybe a thing at the top of each "lesson" where you say what you are going to accomplish that lesson so I can fail on my own first. Lesson 1 definately shouldn't have it (since its mainly setup), but it would be cool alter on when you are implementing features (like (1) this week we will use traits to implement damage! or (2) implementing random dungeon generation.)
On the topic of in-band lifetimes: it's not bad if you use meaningful names for your lifetimes. The current pattern is to use `'a` everywhere. I don't like this, even though I do it; `'a` contains no meaning and should be as bad as using `let a`. In addition, no capital lifetimes are used currently. When in-band lifetimes become a thing, I'm going to start using capitalized lifetimes for my types and lowercase lifetimes for my functions. In this way they won't overlap and it should be clear.
Unwrapping and panicking is generally reserved for exceptional conditions, like assertion errors and the like. When you `.unwrap()` an `Option`, you're basically saying "it is a bug for a value not to be present here, not normal program state". You can think of the indexing operator as a shorthand for `.get().unwrap()`. Compare to Python, where the dict raises `KeyError` if the value wasn't found, and you have to catch it if you want to recover. If you didn't care to catch `KeyError` in your Python version, then in Rust you'll probably just want to `.unwrap()` or use the panicking index operator. If you want to handle the case where a key isn't present, that's when you use `.get()` with `match`, or one of `Option`'s methods to extract the value or use a substitute (e.g., `.unwrap_or()`). The `?` operator is just a shorthand for match expr { Some(val) =&gt; val, // extract the value, remember `match` can produce a value None =&gt; return None, // return early, assuming the function returns `Option&lt;something&gt;` } This is useful for when you have a lot of fallible operations in a row and every subsequent one depends on the previous one succeeding.
When you want a channel that’s ready to be chosen at random you use this feature. It comes from Hoare’s Communicating Sequential Processes. It’s like a concurrent “switch” statement. I’ve often wondered about how “fairness” is implemented in alt though. I guess I should look.
Have you seen [sn](https://github.com/vmchale/tin-summer)? I haven't had time to work on it recently (there are outstanding issues...) but it should do approximately what you want. It may also be faster than `ripdu` though I don't really know if `ignore` has changed in the meantime. 
I think it's just a tag which was accidentally added on as part of No Starch's process? They do do manga releases as well.
Thanks!
Oh, it looks like you want to do nice auto wrapping of various things into your content wrapper? ``` pub enum Content { Text(String), Number(u32), } trait IntoContent { fn wrap(self) -&gt; Content; } impl IntoContent for String { fn wrap(self) { Content::Text(self) } } impl IntoContent for u32 { fn wrap(self) { Content::Number(self) } } fn any_content&lt;T&gt;(value : T) where T : IntoContent { let content : Content = value.wrap(); } ``` Maybe this helps?
Well, "the" canonical roguelike tutorial is a python+libtcod one. http://rogueliketutorials.com/libtcod/1 and the project is following those steps in that order. I guess i could be more explicit about it, but each section has a header that says what the section is about. You can just stop when you see a header i guess. Week 2 is up now, https://github.com/Lokathor/roguelike-tutorial-2018/blob/master/lessons/week02.md so see if that's close enough to what you're after
After looking at the RFC in question, it looks like the distinction between `mem::uninitialized` and `ptr::read` is that it's too easy for `mem::uninitialized` to introduce a `!` value into scope, whereas presumably that's a bit more difficult for `ptr::read`. Not really an issue of uninitialized memory in general, just that uninitialized `!` breaks stuff sooner than most generically written unsafe code might expect.
Yes! This looks exactly what I'm trying to do! It looks so simple when you do it. Thanks for the help!
Glad you enjoyed it! I think leimy's answer is great so I'll just write a little more about how I've used it. I have had to write code that uses a timeout to prevent runaway processes. So using the crossbeam-channel crate that might look something like this: ```rust select! { recv(r, value) =&gt; println!("got value: {:?}", value), recv(channel::after(timeout)) =&gt; println!("timed out"), } ``` So what this will do is block on either receiving a value on the channel `r` or timing out after some time `timeout`. Any case where you want to multiplex on multiple channels can be very useful too since it will only block if no options are ready. Of course you can also use the default case too. Hope this helps!
Commercial Rust work is cool, but don't forget to make sure it's for a company you're comfortable working with. I haven't used Ticketmaster since 2012 or so - so it's entirely possible they've changed radically - but historically their business has been founded upon the idea of lock-in, rather than providing a service that concert-goers and artists _want_ to use. They're one of the most hated brands out there, and it would be ignorant to claim that 100% of that hatred is ill-founded. Anyway, like with any work, do your own research; make sure _you're_ happy with everything that comes along with the position. I'd sooner live out of a box than contribute to Facebook, but tens of thousands of people feel differently and are living very enjoyable lives for it.
It's a fork of minihttp, so currently is lacking several HTTP/1 features. Biased, I know, but I actually think it'd be a huge boon to put hyper underneath. Then you'd have a framework with great HTTP/1.1 support, fast, and Thruster's router on top!
[@burntsushi's latest tweet](https://i.imgur.com/QkOzOwC.jpg) [@burntsushi on Twitter](https://twitter.com/burntsushi) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
It’s all good :)
You can use it to do timeouts, and prevent a process talking too long. I've also used it in a main event loop of a small game, sending different events down different channels
I think you're over-thinking this. Perhaps it would make more sense if it was written as: * A mutable reference cannot be *actively* aliased Note that `*mut _`s are *absolutely* included in this. They cannot be aliased by *anything*, no matter what it is. However, pointers and references aren't magic. At the machine level, they're just numbers. The compiler doesn't actually know about what pointers do and don't exist in any global sense. The only thing that matters is what is observable, and for something to be observed, something needs to *happen*. You could have a million `&amp;mut _`s all pointing to the same thing, and that wouldn't matter *provided you never use any of them*. That they exist is kind-of irrelevant. The reason the `split_at_mut` code is safe is because there is no way to *use* both the original `slice` and the returned sub-slices at the same time. Invoking `split_at_mut` causes the compiler to statically lock out access to the original `slice` until the sub-slices are destroyed. Similarly, having `*mut _`s aliasing a `&amp;mut _` is fine, *provided you don't use them at the same time*. Remember, the compiler assumes that, if it has a `&amp;mut _`, *nothing* else can read or write the thing being pointed to. Once you involve aliased `*mut _`, `&amp;mut _`, `&amp;_`, or anything else, it's *your* job to ensure those accesses don't overlap. Oh, and that doesn't mean "just use synchronisation". If no one else can access something pointed to by a `&amp;mut _`, the compiler is free to not actually perform reads or writes when you ask it to. It can cache or delay them as it sees fit. This is probably *why* the advice is written as "no aliasing", because any level of aliasing at all requires additional care. If you understand what that additional care is, then you also understand the unstated nuance behind that rule. So, really, an honest writing might be: * A mutable reference cannot be aliased (but it's more nuanced than that). Learning unsafe programming is basically all about that "more nuanced than that" part.
Per [https://twitter.com/whoisaldeka/status/774030536897683456](https://twitter.com/whoisaldeka/status/774030536897683456), Ferris will respond to pretty much any pronouns (preferably not "it"). So sure, agender.
Yeah, the book cover was a "work for hire", so unless there's something saying otherwise in the book contract I expect the rights are No Starch's. I don't know what their policy is around cover art!
I think that you should think long and hard before working on a anything with "patents on how the technology is used". Patents are antithetical to open source software, and dare I say many of the Rust community's values.
Because this will have had a great effect on the ecosystem, the new version should've been named future-perfect to be [grammatically](https://en.m.wikipedia.org/wiki/Future_perfect) correct.
&gt; You could have a million &amp;mut _s all pointing to the same thing, and that wouldn't matter provided you never use any of them. [...] Similarly, having *mut _s aliasing a &amp;mut _ is fine, provided you don't use them at the same time. See, that's what I was afraid of. There's some special compiler black magic that can happen if I have a `*mut` and `&amp;mut` exist at the same time that can blow up my shit with UB. Rust docs tell me that I'm not supposed to alias a `&amp;mut` with a `*mut`, but of course I need to do that just to create a `*mut` in the first place. Oh, and the compiler may chose to reorder my loads and stores as it pleases based on "`&amp;mut` can't be aliased" and this black magic happens... _whenever_ in some completely unspecified fashion. That's painfully confusing. There's no clear definition for "provided you don't use them at the same time" when the "same time" part is utterly unspecified. There's the compiler doing reordering, there's the CPU doing it as well and also prefetching code etc. What is "same time" here? And yet the docs state these invariants that _must_ be upheld otherwise "UB for you!" and the invariants are incredibly fuzzy. I spent 10+ years of my life writing C++ and I know _exactly_ how a plain pointer works there. I also know any C or C++ compiler is going to be _incredibly_ conservative when it comes alias analysis; it always assumes the worst possible case because there are no special pointers that can't be aliased. That's why C added [`restrict`](https://en.wikipedia.org/wiki/Restrict). But those aren't commonly used, whereas `&amp;mut` and `&amp;` are used everywhere in Rust.
**Restrict** In the C programming language, as of the C99 standard, restrict is a keyword that can be used in pointer declarations. The restrict keyword is a declaration of intent given by the programmer to the compiler. It says that for the lifetime of the pointer, only the pointer itself or a value directly derived from it (such as pointer + 1) will be used to access the object to which it points. This limits the effects of pointer aliasing, aiding optimizations. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Will this play well with ALPN-based upgrades? 
If I'm having difficulty, I Rc that thing and my performance is still great
Those are different. This is specifically about HTTP/1.1 Upgrades. What ALPN upgrades are you trying to do?
I've got a question.. what triggers the safe zone turrets to attack aside from carrying weapons
Got the notification that my pre-order through No Starch shipped today. Looking forward to getting it! By the way, does anyone know if No Starch is going to be making an epub or mobi copy available? I noticed that I now have a new file of RustProgrammingLanguage.pdf available to download, but couldn't find anything for epub or mobi.
(Professional Rust experience is hard to come by right now, it might be wise to settle for open source Rust experience.)
Back again! Thanks for the pointer, it works well. Also figured out I can do things with `str`s too! But I have a question, wonder if you know. I was doing `let content : Content = "a str instead of a string".wrap()` (basically) and it told me to implement `str`, so I thought I should do it like this. impl&lt;'a&gt; IntoContent for &amp;'a str { fn wrap(&amp;self) -&gt; Content { Content::Text(self.to_string()) } } But it didn't work so I just did it like this: impl IntoContent for str { fn wrap(&amp;self) -&gt; Content { Content::Text(self.to_string()) } } And it works. Question, does implementing `&amp;'a` version do anything? The compiler doesn't complain but it doesn't seem like its used. I'm assuming the "borrowed" form is assumed but I can also implicitly define it.
The borrow checker. Kidding aside, you're better off asking /r/playrust. This is a subreddit about the Rust Programming Language.
Lol I feel so smart rn
To cut off my own rambling: I think the best advice I can give you is to look to the standard library for examples of unsafe code that are, on balance, almost certainly correct. If the standard library is doing something unsafe, and you don't understand how it's safe, you still have more to learn. Rust absolutely has a higher minimum bar for writing correct unsafe code, and there's nothing you can do about that other than either *not* writing unsafe code, or getting stuck in. --- I'm not an expert on unsafe programming, but I don't think it's *quite* as bad as you make it out to be. The point is that it's not *obvious*, so you need to put in the effort to really learn what's going on. I (and I suspect others, too) avoid being too specific about the requirements on places like Reddit because a quick summary is unlikely to give you enough information to write correct unsafe code. Basically, I'd rather people be afraid and overly cautious than the opposite. I really doesn't help that the Rustonomicon was never finished. I believe the author ended up getting a job that made continuing to work on it not feasible, and there aren't that many people who are really qualified to contribute to it. I personally wouldn't *dare* go near it. With that in mind, and to be entirely clear: what follows is my best understanding of the topic and may be completely wrong and/or misinformed. You should do your own research and apply your own reasoning, and not take this as correct. There is no warranty, implied or otherwise. If this sets your computer on fire, eats your dogs, or causes significant mental impairment (such as preferring vertical video), that's not my problem. The reordering thing *should* be handled by putting the pointee behind a cell like `Cell`, `RefCell`, `UnsafeCell`, or any other type built on them. Reading the length of a slice or turning it into a pointer don't count as using it, because neither involves dereferencing the internal pointer. You shouldn't need to worry about threads provided you ensure the types involved *cannot* be `Send` or `Sync`; if they are... you're on your own, I ain't touching that viper's nest. And, yes, this stuff is complicated and hairy. That's just reality for you. If you don't want to deal with it, that's fine; that's what safe Rust is *for*. But if you *do* want to write unsafe code, you *need* to dig into this cesspit as much as you can stand. &gt; I spent 10+ years of my life writing C++ and I know exactly how a plain pointer works there. I've seen *way* too many people say that only to conclusively disprove it immediately afterwards to *ever* believe it. I mean, unless you're John Carmack, or Linus Torvalds, or someone of a similar caliber. It's nothing personal, I just don't trust programmers to *actually* know what they're doing, and I include myself in that. :D
Probably around 2018-10-25 :)
I don't really agree. Most public projects are under MIT licenses which means it is ok from the author point of view to use it in a non open source software. I do love open source and I wish they would open their projects but i acknowledge that there is a value in closed source software (even patents), in particular if you are already ahead of the competition.
Is it more expressive than a single `Receiver&lt;MessageTypeEnum&gt;`?
They haven't changed in case you are wondering. I am glad big companies are looking to hire people for Rust, but I also agree with the skepticism you mention because I have paid ticket fees of $8 on a $15 ticket.
Write it all in one big file. No really. Once you have written a bunch of code it's often not too hard to stop and look at it and see which parts naturally form related chunks. You don't need to over think it until breaking the program into modules becomes actually useful to you.
No Starch has a Manga Guide series of books; this is just some kind of error. I mentioned it to them the other day and they laughed and said they had no idea how that happened, I’m sure it’ll be fixed soon.
Great to see progress on const generics! Can't wait to simplify my code once that lands :)
You state (correctly) in the `README` that a `vec!` macro would conflict with the one in `std`; what about `vecn!` or even `vector!`? I don’t see any reason you can’t just use a different name (and it should be easy to generalize to higher orders, too, which will only make things more maintainable for you).
I forgot to note that NLL (non-lexical lifetimes) is the general solution to borrowing issues like the one you ran into. It's a big project but there was supposed to be a specialization of it for situations like that which was supposed to be easier to implement, called "two-phase borrows". It appears to be implemented but gated under the `nll` feature. The tracking issue for NLL is here: https://github.com/rust-lang/rust/issues/43234 
&gt; The upgrade plan will ask you to use crate in a bunch of places but you don't have to. Ahh. Something else to note down for potential inclusion into a CI format canary system if I feel that manual auditing for style has become unfeasible before the stable subset of rustfmt's options become flexible enough.
This seems like a problem that might be better handled with traits than with macros. Something like: struct AVX2; struct SSE2; trait SIMD { fn set1_ps(a: f32) -&gt; f32; } impl SIMD for AVX2 { fn set1_ps(a: f32) -&gt; f32 { _mm256_set1_ps(a) } } impl SIMD for SSE2 { fn set1_ps(a: f32) -&gt; f32 { _mm_set1_ps(a) } } But anyway, for the macro solution, what you could do is redefine the macros locally: macro_rules! define { (AVX2) =&gt; { macro_rules! v_set1_ps { ($a:expr) =&gt; (_mm256_set1_ps($a)) } }; (SSE2) =&gt; { macro_rules! v_set1_ps { ($a:expr) =&gt; (_mm_set1_ps($a)) } } } macro_rules! alg { ($x:ident) =&gt; { unsafe { define!($x); let one = v_set1_ps!(1.0); one } } } 
What about the Turbofish? ::&lt;&gt;
That explains why I didn't find much when searching for it. But source code for screenshot that you linked is more than enough to get me started. Thanks
🎉🎉🎉
Have you seen [this announcement from earlier today](https://www.reddit.com/r/rust/comments/8tz3d7/zapper_a_very_fast_templating_engine/)? There's not much detail on the hot-reloading support, I wonder if it just watches for modifications to the template files.
If you take the (1) approach, mio is probably the crate you’re looking for (though the IPC stuff you’d need to play with a little bit). Also tungstenite should be able to help with websockets, I think it’s advertised as a websocket crate that can work with mio. 
Thanks for managing the ship so well! As you mentioned it, I can only imagine how is it difficult to organize such kind of release. So thanks!
[Killing off](https://github.com/PistonDevelopers/inflate/pull/43) `unsafe` blocks in `inflate` crate. It is used under in `png` crate, among [other things](https://crates.io/crates/inflate/reverse_dependencies). One of those `unsafe`s actually posed a security vulnerability given certain inputs, but fortunately the rest of the code just so happened to never pass bad parameters to it. Still, it was *this* close to a devastating vulnerability that [plagues C libraries](http://seclists.org/fulldisclosure/2013/Nov/83). That's a reminder to be **paranoid** every time you write `unsafe`, and ask others to double-check your code. I wouldn't even have found the vulnerability on my own; we've only found it after looking at the code together with the crate author.
&gt; [disposition: close] Reserve `f(a = b)` in Rust 2018. This makes me a *little* bit sad. To my mind, if Rust ever does get keyword arguments for functions, this is the only syntax that makes sense, given the precedent of `println!("{foo}", foo=5)` and `Iterator&lt;Item=u32&gt;`, so it's reasonable to reserve it. On the other hand, though, I understand that reserving syntax for "perhaps" features has caused grief in the past and if you allow one, people are going to expect you to allow all of them, etc. etc. Oh well. Hopefully nobody nabs that particular syntactic niche for type ascription or something in the mean time.
use MIO. It's what tokio futures are based on and its very easy to use. FWIW , the biggest obstacle for me was getting it to work with stdio. I could not find a standard solution. What im working with now is: let fd0 = TcpStream::from_stream(unsafe{::std::net::TcpStream::from_raw_fd(0)})?; let fd0_e = EventedFd(&amp;0); poll.register(&amp;fd0_e, token.into(), Ready::readable()| UnixReady::hup(), PollOpt::edge())?; I doubts this even works across different kernels. If anybody knows a better way please share. 
There is a value in closed source code, but i rarely see value in software patents. As John Carmack said: &gt; Get a dozen sharp programmers together, give them all a hard problem to work on, and a bunch of them will come up with solutions that would probably be patentable, and be similar enough that the first programmer to file the patent could sue the others for patent infringement. Why should society reward that?
Just thinking ahead for QUIC support. 
Type ascription currently uses `:`, so I doubt it will suddenly be grabbed. Everyone who's working on this stuff is aware of both features, so I don't think you have to worry about it being missed accidentally :)
Surprised no one has mentioned ArcCell in cross-beam for this https://docs.rs/crossbeam/0.3.0/crossbeam/sync/struct.ArcCell.html How would this be different from that solution?
Incidentally, I was listening to http://freakonomics.com/podcast/live-event-ticket-market-screwed/ a while back, and it's a very interesting look at how this all developed. A sort of summary: &gt; But all the evidence we’ve been hearing today — from economists who’ve researched the ticket industry and governments who’ve investigated it — it seems to back up the argument that Ticketmaster does the bidding of other parties. The evidence also points to a fairly bizarre ecosystem where certain parties want to keep prices low, for appearances’ sake, but also want to make as much money as they can. And they’ve built in a series of opaque transactions to make that happen. and &gt; BUDISH: Something that’s not widely understood is that these service fees often — part of them goes back to the venue. &gt; &gt; MARCUS: In a percentage that varies widely, frankly, depending on the venue and the relationship they have to Ticketmaster. &gt; &gt; BUDISH: So Ticketmaster takes all the P.R. hit for these egregious service fees. But actually a lot of that money spreads its way around the rest of the food chain. So, it may not exactly be fair to get mad at solely ticketmaster for this shenanigans.
The rest of the error message goes: = note: method `id_from_string` has no receiver = note: method `name_for_id` has no receiver It's not a great explanation of the problem, but it's complaining because the methods do not have `self` parameters. This compiles: trait Database { type IdType; fn id_from_string(&amp;self, id_string: &amp;str) -&gt; Self::IdType; fn name_for_id(&amp;self, id: &amp;Self::IdType) -&gt; String; } struct DatabaseUser { database: Box&lt;dyn Database&lt;IdType=u32&gt;&gt;, } 
&gt; I have no idea what nostarch They're the publisher.
It might be helpful if you shared some of the code you're not happy with; it's possible that you're missing something. It's also possible that the non-macro version will be significantly more helpful to you; it just landed in nightly. https://play.rust-lang.org/?gist=b0108cbad56616d2a2f99b47162eac2c&amp;version=nightly
Ah, my bad, then, thanks for clarification. It worked just fine for me for allocating large arrays, so I didn't bother to read docs further.
Yes, trait objects must have associated types fixed. Is there a particuar reason you're using a trait object here? You could use a type parameter https://play.rust-lang.org/?gist=f8b3f46cb02d0f7dc9481a336fee4f37&amp;version=stable&amp;mode=debug
There's also [EternalTCP](https://github.com/MisterTea/EternalTerminal) with tmux's control mode.. alas there's ony [iTerm2](https://www.iterm2.com/) that really has support for tmux CC mode. That gives you a setup like mosh but with the ability to use multiple terminal windows. 
A small note on list comprehension - there are crates available that provide a macro based solution: [https://github.com/johannhof/pipeline.rs](https://github.com/johannhof/pipeline.rs) [https://github.com/andylokandy/comp-rs](https://github.com/andylokandy/comp-rs) [https://github.com/mattgathu/cute](https://github.com/mattgathu/cute)
&gt; Sorry if this is a bit of a mess. Its not a mess, it is clearly explained in the Rust memory model part about load and stores (ptr read/write) which you seem to be completely. Also, you are still completely wrong. The following is not undefined behavior: let mut v = [0_u8; 10]; let ptr = &amp;mut v[0] as *mut u8; let c = ptr.read(); // read value let d = ptr.read(); // read value AGAIN assert_eq!(c, d); 
/u/Quxxy has given you some answers, but to provide some other perspectives: &gt; The documentation on unsafe Rust (TRPL and the Rustonomicon) needs improvement. This is true, but it's also not that simple. The straightforward answer is, we actually don't 100% know the rules ourselves, and therefore, they cannot be documented. This works because the vast, vast, vast majority of Rust code does not need to use unsafe directly at all. I've been programming in Rust for five years and the only time I've ever needed it was writing an OS. Nailing this stuff down is something that's being worked on, but until it's actually strictly defined, it can't really be documented. The reason it's taking a while is that we don't want to paint ourselves into a corner, and are working with a number of people in industry and academia to provide real, formal semantics. Once we *do* get this settled, it should be *very very very* clear, but until then, it's just going to be vague. If you're not willing to dig into a lot of details, which is 100% reasonable, unsafe may just not be for you yet.
reddit doesn't support backticks, you need four space indent.
Yes, sure. The option of "battling it out" with futures still seems pretty good in comparison. Currently I'm stuck with this one: \#\[async\] fn handle\_client(client: Client&lt;TcpStream&gt;, world: Rc&lt;RefCell&lt;World&gt;&gt;) -&gt; Result&lt;(), ()&gt; { let (sink, stream) = client.split(); await!(sink.send\_all(handle\_message(stream))); Ok(()) } \#\[async\_stream(item = OwnedMessage)\] fn handle\_message(stream: SplitStream&lt;Framed&lt;TcpStream, MessageCodec&gt;&gt;) -&gt; Result&lt;(), ()&gt; { \#\[async\] for message in stream.map\_err(|\_| ()).take\_while(|m| Ok(!m.is\_close())) { println!("Message from Client: {:?}", message); let reply = match message { OwnedMessage::Text(msg) =&gt; { web\_server::on\_message(world.borrow\_mut(), &amp;msg) .map(OwnedMessage::Text) }, OwnedMessage::Ping(p) =&gt; Some(OwnedMessage::Pong(p)), OwnedMessage::Pong(\_) | OwnedMessage::Binary(\_) | OwnedMessage::Close(\_) =&gt; None, }; if let Some(r) = reply { stream\_yield!(r); } } Ok(()) } Which gives the following errors: error\[E0243\]: wrong number of type arguments: expected 1, found 0 \--&gt; src/world.rs:129:1 | 129 | #\[async\_stream(item = OwnedMessage)\] | \^ expected 1 type argument error\[E0277\]: the trait bound \`websocket::WebSocketError: std::convert::From&lt;()&gt;\` is not satisfied \--&gt; src/world.rs:125:16 | 125 | await!(sink.send\_all(handle\_message(stream))); | \^\^\^\^\^\^\^\^ the trait \`std::convert::From&lt;()&gt;\` is not implemented for \`websocket::WebSocketError\`
&gt; Sorry if this is a bit of a mess. Its not a mess. The Rust memory model is crystal clear. The following is not undefined behavior: // Read from &amp;mut [NonCopyDrop] slice let ptr = &amp;mut x[0] as *mut NonCopyDrop; let c = ptr.read(); // read value let d = ptr.read(); // read value AGAIN forget(d); // value is only dropped once let v = NonCopyDrop {}; ptr.write(v); // set the source value // c is dropped here 
I thought that bare Trait objects are only a warning before the edition, but in the edition they are hard errors and rustfix **will be** automating that. 
Rather than inventing an `IntoContent` trait, use From: https://doc.rust-lang.org/std/convert/trait.From.html
&gt; it would be ignorant to claim that 100% of that hatred is ill-founded. Wellllllllllllllll.... see below.
God I do love rust
And often, those functions can be methods of your data struct.
Update: nevermind the problem above. The error messages are not very helpful but after getting some food I managed to figure it out. Solved.
Right, but we’r talking about the Rust 2018 edition there.
Hm, no special reason for trait object. Will consider this, thank you.
&gt; So, it may not exactly be fair to get mad at solely ticketmaster for this shenanigans. If I understand correctly, part of their job is to take the blame.
Thanks for the hint.
If someone here has an AMD CPU, I could use your help in a quick check. I have some code that for some weird reason runs faster if I wrap it in the equivalent of `if black_box(true) { ... }` and I'd like to rule out CPU influences, however unlikely that is, before I do any time consuming asm analysis. All I need is two benchmark runs. Clone https://github.com/Emerentius/sudoku.git and run `cargo bench` for both of the git branches `with_branch` and `without_branch` and report results. Thanks!
Yes, to take it *even though it's not exactly their fault*.
So with this crate we could put a Vec&lt;&amp;str&gt; into the shared memory and read it out on the other side? Could this act like a custom allocator - like a cross-process arena. I'm trying to understand if we can use this as a zero-copy way of sharing immutable rust objects between processes?
Glad to hear it. Can't wait for real async/await to be done...
Thank you, especially your trick for stdio, that was not an obvious one.
Is there such a thing as a reusable `BufWriter`? The only way to induce a flush seems to be to drop it. I want to (repeatedly) send clumps of bytes together into a `TcpStream` with NODELAY. To prevent repeated writes per clump, I'll use a `BufWriter` to flush to the stream all at once. However, I want to do this repeatedly, safe in the knowledge that between clumps, the messages are actually sent. Would I need to repeatedly create a BufWriter and use `.inner()` to unwrap (and flush) the writer every time? It feels wrong to need to keep moving the TcpStream in and out. I'm expecting there to be a `.flush()` function for `BufWriter`. What should I do, here?
Sorry that came across too harsh... I just get tired of seeing people being so quick to criticise things before getting the facts straight. For reference, this is the page for the book on nostarch: https://nostarch.com/Rust - they offer a nice pdf version of the book. To be honest though, if you're wanting a digital copy, the version at doc.rust-lang.org is probably nicer with all its html goodness.
Also 'most pregnant' and 'most dead'.
async/await won't _replace_ Tokio, it will augment it.
This, `pub` is a visibility modifier and `pub(crate)` just one of the high-level possibilities. I don't see any benefit in hiding it to new users behind behind auto-magic.
I wrote this rather quickly a couple of days ago. Figured it might be a fun example of how to interface with the linux notification system using [notify-rust](https://crates.io/crates/notify-rust).
Quite a bit more expressive, yes: * A select can synchronize on both sends and receives simultaneously. * A select can execute a default action if none of the other actions are ready to synchronize. * A select should automatically treat each synchronization point fairly such that a very busy channel won't starve a less busy one. Aside from that, a select statement is arguably quite a bit more ergonomic than defining your own enum. I'd recommend reading John Repy's paper from the early 90s introducing Concurrent ML.
&gt; There's some comparisons with other PRNGs which seem convincing enough. Oh, and a link to the PCG website. "What's Wrong with Your Current RNG" oh no! "The PCG Family Is Better" oh my! Ah, there's a whole paper if you want to know more. Please note that the PCG website is a bit misleading. Especially the claims about "Prediction Difficulty" are questionable. There are other generators with similar statistical quality and speed, see for instance the [xoshiro](http://xoshiro.di.unimi.it/) family.
I'm sure they negotiated the current conditions, so I don't think it is fair to not blame them at all either.
Done: https://github.com/djc/template-benchmarks-rs/commit/5ddf70c72b9b21c12836c9bb8bed25f0641e0905
That one is basically a spinlock inside, so neither get or set is lock-free. That one is being pulled out of the next version. https://github.com/crossbeam-rs/crossbeam/issues/160 As I said, the crossbeam people are working on a replacement ‒ something based on hazard pointers.
Hey, thanks for your time and feedback regarding learning backend. I am currently looking into choosing a language (used Python for various things, but really looking for something statically typed that is advanced. Looking at Haskell at the moment). The thing I am afraid re Rust is that it might be overkill for a backend when it comes to the overhead that comes with its kind of manual memory management and more code. And, 2 years of time to get proficient with it is quite something. 
Websockets are the main usecase, but the mechanism is also used for other things. For example, Second Life had a thing called “reverse HTTP” (PTTH), which works via upgrades as well. http://wiki.secondlife.com/wiki/Reverse_HTTP
Agreed, hence the “solely” :)
You can sort of get around if you implement Default for the struct you are allocating and use Box::Default, as that uses box syntax internally.
As the other comment says, it’s not an either/or. That being said, these projects are in heavy flux for the next few months. So learning now means that you learn the concepts, but you may need to update your understanding a few months from now. If you wait, you only have to learn once. Which makes sense for you just depends.
Starting with the rust 2018 preview, if one of your dependencies isn't sufficiently crate, you can import it with the following syntax to make it up to 100% crater than the default: crate extern crate foo;
Is it normal that the cyr/simd benchmark contains a lower bound higher than the upper bound? R² 0.8711453 0.8771452 0.8704802
\&gt; Can one thread be writing using the raw pointer while another is writing using the mutable reference *provided correct synchronization is used*? Yes, but \*\*only if it's inside \`UnsafeCell\`\*\*. Further, you \*\*must use \`get()\` method\*\* of \`UnsafeCell\` to obtain \`\* mut T\`. If you want to have a mutable *reference*, you must also use \`get()\` and convert returned pointer to reference (\`&amp;mut \*foo.get()\`).
I also set some termios flags to put the terminal in raw mode. Works both on linux and macos. Just don't forget to set the flags back when exiting the program. https://docs.rs/crate/rcom/0.1.1/source/src/mio_stdio.rs
Here's an example WebSocket server using hyper+[tungstenite](https://github.com/snapview/tungstenite-rs): https://gist.github.com/bluetech/192c74b9c4ae541747718ac4f4e20a14 There is definitely space for a WebSocket library which would integrate well with hyper. IMO it should look like this: 1. A pure handshake function, taking an `http::Request` + configuration and returns `http::Response` + whether to proceed or not. Does not perform any IO - the HTTP is handled by the HTTP server (hyper). 2. An implementation of the WebSocket frame protocol - assumes the handshake is complete, takes just an `IO: AsyncRead + AsyncWrite` + configuration, sends &amp; receives WebSocket messages. If I had time, I would have liked to write it, or adapt tungstenite to work like this.
This looks really interesting but I won't be able to attend. Will there be a livestream/recording? Thanks! :)
Cool! Thanks, hadn't seen it mentioned in the article or discussion.
Totally agree about `crate` being a bad visibility modifier. As well as being unintuitive, it means that there are now two ways to make an item public to the crate. It is also inconsistent with `pub(module_name)`. It's more for a new user to learn, more potential code inconsistency, with no benefit I can think of. I'm surprised there weren't many comments against it in [the rfc](https://github.com/rust-lang/rfcs/pull/2126). Is it too far along to reconsider?
I'll look into this, it'd be great to have a lot of the established functionality supplied for us rather than having to reimplement.
yes, a `not` keyword feels very natural to express a condition but I'm pretty sure the Rust team discussed that. Maybe s.o. knows what the downsides are?! And I wouln't add `std::ops::Not` to the std prelude. In general I don't like to have things in scope I didn't ask for.
Out of curiosity, did `Box::new` not do the same in that case? It uses the `box` keyword and has `#[inline(always)]`.
Not recent but search the compiler codebase for "zombie jesus" ;)
Not sure if it's the most recent one, but to me the most important one: You can generate functions, structs etc out of custom derives, not just traits. This apparently means that you can [implement proc-macros](https://github.com/dtolnay/proc-macro-hack) on top. On stable Rust.
Thank you so much /u/DroidLogician. I can't tell you how much you and everyone who replies on these threads helps. I will try to answer questions if I'm able to as well. Truly, truly appreciate the help.
Perhaps you could use `!!!` to make it stand out more? if !!!foo.some_condition() { // etc. }
I do agree that writing a server for Tokio is significantly easier than writing a client, which I am currently in the process of trying to do myself here - https://users.rust-lang.org/t/how-to-create-reuseable-client-with-tokio-tcpstream/18058/9 . Thanks to vilalyd I have made some progress, but it hasn't been easy. It's worth knowing that it's a pain point.
I'd be fine with adding `std::ops::Not` to the std prelude. There's almost no downside that I can see, because it's very unlikely to cause any naming collisions and also should have a negligible impact on compile times. But if the `.not()` is at the end of the expression, I can't help but read it the way Borat says it.
`!` feels natural if you grew up using C/Java/etc. `not` feels natural if you grew up using Python/Ruby/etc. The `.not()` method feels natural if you grew up with nothing but jq. This is pure dogshedding. I don't think it would make a good PR.
Poor error messages are the biggest downside for the current macro-based async/await in my experience as well. I'm surprised some people still argue against the current initiative to bake async/await into the language advocating for this macro-based approach.
Off-topic question: Where can I find a big table with all Rust operators and their precedence?
Try marking your closure as `move`. 
For some reason it did not and line like ```let x = [0u32;1_000_000]``` caused stack overflow.
Most recently would be this one: struct Foo&lt;T&gt;(T); let Foo(x): &amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23);
I think I won't be the first to "wtf is Rust 2018?", so I'll leave a shortcut here for others: [https://rust-lang-nursery.github.io/edition-guide/editions/index.html](https://rust-lang-nursery.github.io/edition-guide/editions/index.html)
I don't know if I should feel admiring or disgusted :)
Thank you! Nice solution, and yes I'm playing around with a trait based solution as well, which should work fine as long as inline(always) can be trusted! 
Not seeing anything weirdly. Kind of curious what it's about now haha. https://github.com/rust-lang/rust/search?q=zombie+jesus&amp;unscoped_q=zombie+jesus
https://doc.rust-lang.org/reference/expressions.html?highlight=precedence#expression-precedence
That's ok, I love it too. - God
I think this is a misconception. There exist type systems (homotopy type theories, Agda, Idris, Coq, F*..) that can rule out more or less every possible bug using termination checking and dependent types. Of course, ensuring that every function terminates means you give up on turing completeness, but it is kinda overrated. You will also need to actually use the facilities given to you by the type system, but all invariants are encodable. Perhaps you don't want to go through that tedium for a script however. Automation is key for making it more widely used. The only possible faults you can't reasonably account for then are OOM, incorrect input, someone pulling the plug on the computer.
Also, the learning experience itself is a bit rocky right now. I hope / expect there'll be a whole bunch of blog posts about the new system for various audiences as projects move to it, but right now the best content is written from the perspective of developers exploring the design space instead of end users trying to write / port projects.
HTTP2 does upgrades only if on cleartext (i.e. non-HTTPS, also known as \`h2c\`) AND if without prior knowledge about the specific server. This is mostly non-existent in the real world, as all browsers pledged to not support cleartext HTTP2. Usual HTTP2 negotiation goes over ALPN at TLS level.
I'll bite the bullet and admit, yes I admit!, that I often find many async solutions so uncomfortable to work with that I fall back on spinning up threads myself. Especially for small to medium projects, I think the risks and pitfalls of multithreading are vastly exaggerated. Especially with Rust you get good safety guarantees, which also help with many logic errors. I don't regret having done IPC for my projects via std::threads.
It's without the space: https://github.com/rust-lang/rust/search?q=zombiejesus&amp;unscoped_q=zombiejesus [Related question on StackOverflow](https://stackoverflow.com/questions/50717243/what-does-this-strange-line-do/) 
Interesting project. Would love to collaborate :D 
Same problem here, maybe related with my sight not getting any better after a few decades of coding. Anyway I often end up using if `some_condition == false` to make sure I will notice the negation, which makes clippy kind of sad.
I have always found writing loops in Bash to be fickle, tedious, and needlessly complicated. `loop` allows you to write intuitive, powerful looping one liners, with many useful features like breaking on pattern matching, timed loops, and loops for a specific duration. For instance, to try a thing until it succeeds, every 15 seconds, for a maximum of five times in Bash: n=0 until [ $n -ge 5 ] do do_thing.sh &amp;&amp; break n=$[$n+1] sleep 15 done becomes: loop './do_thing.sh' --every 15s --until-success --num 5 This was also my first Rust project, so [feedback is welcome](https://github.com/Miserlou/Loop/issues/3)!
Thanks! Pull requests are very welcome.
&gt; I don't mind at all, but this post isn't really very information dense Mostly, I'm interested in someone familiar with or passionate about gitlab to help write the gitlab documentation. My issue for this is me just collecting resources to pull from when doing so. &gt; Also, I'm not sure what you mean by documentation PRs? A PR with documentation in it? like a foreword about the article? the article itself? Sorry, I was being too brief. I meant a PR against the crate-ci book to add information about gitlab to it. It might not literally take the form of this article. As I mentioned earlier, I'm more interested in that you have experience and care enough to post about it. In looking at the book, you'll see I only do a brief explanation of a [basic github / appveyor configuration](https://crate-ci.github.io/pr/testing.html) and then, in a modular way, add features over the next several sections. My hope is that we can be similarly brief.
Goes along well with crate use crate::foo; or crate struct Crate(crate());
Weird it works fine over here (but I'm on the new reddit interface).
Ok, so the signature `fn wrap(&amp;self)` is not the same as `fn wrap(self)`. The first one means a method that takes `self` by reference (borrowing it), the second means a method that takes `self` by value (taking ownership of it). So when you write `"a str".wrap()` this can work in one of two ways: - By invoking `str::wrap(&amp;self)` like you wrote it. - By invoking `(&amp;str)::wrap(self)` with the trait definition I originally wrote. Which one you use is your preference, they have slightly different tradeoffs (`fn wrap(self)` doesn't need to copy data to store it). In your other case: ``` impl&lt;'a&gt; IntoContent for &amp;'a str { fn wrap(&amp;self) -&gt; Content { Content::Text(self.to_string()) } } ``` This is something you can invoke like so: `(&amp;"Hello").wrap()`.
it's valid to put a \`return\` as a condition?? Why?
Is there a solution that I am not aware of that allows a dedicated IO thread to do blocking IO calls and still be reachable from the main thread? For example: have one thread for each client, requests from one client can cause events to be sent to other clients. How does a thread block on a socket read and also remain reachable from the main thread? I can only think of timeouts and calling the socket read in a loop. Which seems very ugly. Never even thought of it as an alternative until now.
If the library doesn't care about type of streams, it should be generic over `T: io::Read + io::Write`. You didn't write whether you use synchronous or asynchronous IO, so I'm assuming synchronous. Once your library is generic, you can use `Cursor` with a slice to test it.
Unfortunate naming, Zapper is a well known company already
This is very cool. Honestly, I'll do anything to avoid writing bash scripts so hopefully I'll remember to use this one.
for ((n=1;n&lt;=5;n++));do ./do_thing.sh &amp;&amp; break;sleep 15;done
Because the condition holds an expression and `return` is an expression.
Yeah, I know the syntax stuff just was merged so I didn't want to rain on everyone's parade by being very negative about futures. I haven't given up yet on them and hope the new syntax will help with better error messages. Having a function actually return a different type than what it says after the arrow is easy to forget. And async for loops that can actually cause early return. Etc. Lots of ways to screw up and need good error messages. 
The whole file is hilarious.
This is actually an idiom in languages that have "falsy" values, if you want to convert something to a boolean, you first ! it, which converts "falsy" to true, and then a second ! converts true to false.
I think there is a flush method on BufWriter, but it is part of the [Write trait](https://doc.rust-lang.org/std/io/trait.Write.html#tymethod.flush).
&gt; The only way to induce a flush seems to be to drop it. If you have `std::io::Write` in scope, then it has a `flush` method.
I know, but it's the first time is see it used only for “clarification” of code!
and `return` has type `!` so it works anywhere.
Not about that specific test, but https://news.ycombinator.com/item?id=15491180#15495027 is sorta what this file is about.
By the way, you can only use negative impls for "auto traits", which is itself a pretty obscure feature. 
Well this is more or less how the bottom most implementation is. Futures are generally implemented as a kind of a task queue where each future is handled by a thread from a thread pool. The other way to look at it is that futures give you the means to synchronize concurrent code without having to do this synchronization manually. In the I/O task processed in its own thread, you can either use a blocking function with a timeout or use non-blocking alternatives and loop over them. To pass data to/from the threaded task, you'd have a few alternatives. Rust has [a fairly solid message passing](https://doc.rust-lang.org/book/second-edition/ch16-02-message-passing.html) system for the purposes of threaded applications. You could also use RwLock to lock a data structure or you could use [a lockless data structure](https://github.com/Diggsey/lockless).
I can't seem to define both \`fn foo()\` and \`const foo\` or \`static foo\` simultaneously . [(rust playground)](https://play.rust-lang.org/?gist=f6ec06100d4a60acb5ed8b43f43f944d&amp;version=stable&amp;mode=debug)
yep, definitely falls under the "tedious" and "needlessly complex" categories mentioned in the parent comment
You can use GNU tools like `watch` and `timeout` for these things, which is typically what I do. Although `watch` is a bit annoying with its flags if you want it to actually stop on a condition. You'd have to use `-g` afaikt, and then only change the output of `do_thing.sh` you succeed/fail. timeout 75 watch -n 15 -g ./do_thing.sh
As far as I love Linux, I hate bash too. It's horrible.
This isn't really esoteric, but apparently it's existed for a while and I had no idea that it was a thing: you can put defaults in generic type definitions: pub type MyResult&lt;T = ()&gt; = Result&lt;T, MyError&gt;; So now you can use `MyResult` as the return value of a function, instead of having to write `MyResult&lt;()&gt;` everywhere. And if you are returning, say, `u32` then you can still write `MyResult&lt;u32&gt;`.
this looks super useful, thanks!
Is it possible to name your crate `crate`? Then you could have a very cratey crate: crate extern crate crate;
I knew about pub(crate) but only recently found out about pub(in module) to restrict visibility to modules inside a crate
I think on mobile it works, but on the main website, it doesn't.
And led to a real neat bug with MutexGuard sometime last year!
I'm wondering if there is a way to approximate something like inheritance with impls, consider the following scenario, with two impls for a triat, where some of the functions (\`bar\`) are identical for both impls. Can I void repeating myself? trait MyTrait { fn foo() -&gt; i32; fn bar() -&gt; i32; } impl MyTrait for A { fn foo() { 1 } fn bar() { 2 } } impl MyTrait for B { fn foo() { 3 } fn bar() { 2 } // this is the same as in A, any way to share it? }
I consider that esoteric as I didn't know about it :P. I knew about defaults but not that you can use them there. 
Isn't this kind of like the `watch` command?
Awesome, thanks I didn't know that one either. 
Well, technically I believe it's three ways: * `crate struct X` * `pub(crate) struct X` * `pub(in crate) struct X`
I haven't played with `loop` yet, but `watch` swizzles around stdout and doesn't obey shell escape codes which has been a bugger for me.
&gt; Use glib and gio bindings. Uses good old callbacks. But gio does not have websocket support it seems. You can use libsoup, which is a HTTP library with WebSocket support and there are also Rust bindings for it.
And once `crate` becomes a part of paths you can also do `pub(in crate)`.
thank you
Where else can you use defaults? Is it just the `Default` trait?
And it also is not only for Tokio but can be used for anything using futures
`watch` is designed to show program output change over time. `loop` is designed to allow users to write powerful and complex looping one liners. They are similar in some ways and different in others. I think `loop` is more generally useful and intuitive.
You can use [try_clone](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.try_clone) to get a second handle to the same TCP socket, so you can read and write from separate threads. Have one handle owned by a thread per client performing a blocking read. Put the other handle in shared Mutex that any of the threads can lock and write an outgoing message to.
The occam programming language might be good to look into as well. 
interesting! I noticed that the linter complains about the second line of ``` let _a = return; println!("foo"); ``` It emits a warning about unreachable code. But I would expect that the `let _a` is also unreachable, since (presumably) the assignment never happens. Also, `if return { ... }` doesn't compile (this `if` statement has a condition, but no block). OTOH `if (return) { ... }` compiles, but the linter emits a warning saying that the parentheses are unnecessary. Strange!
Default trait is different. Default trait initializes the type it is implemented on to a default state, for example I believe i32::default() is 0, I think integer types typically default to 0. This is default value for a generic. The place I've seen it before is on say pub trait Add&lt;RHS = Self&gt; { type Output; fn add(self, rhs: RHS) -&gt; Self::Output; } And it means that implementors of the Add trait that don't specify Add&lt;T&gt; will have T default to Self, so if you implement Add for MyOwnInt impl Add for MyOwnInt it is like impl Add&lt;MyOwnInt&gt; for MyOwnInt 
* Wayne Jetski
In fact see the “alt” example here https://en.m.wikipedia.org/wiki/Occam_(programming_language) 
My goto way of doing this is either: while true; do cmd; done Or sometimes: while sleep 1; do cmd; done Anything more complicated than that and it starts getting messy. This loop command is pretty useful.
Yes! Thanks that was it of course. That is exactly what I want.
Yes! Thank you. That was exactly what I was looking for
Thanks. It’s interesting that calling an `#[inline(always)]` function is not the same as inlining it manually. (Arguably a bug?)
Their business model is to transfer hatred from event organizers onto themselves. This comment proves it’s going swimmingly. 
You could also write `not` as a function with a one-liner: http://play.rust-lang.org/?gist=1434052276de34362138cba939f6967a&amp;version=stable&amp;mode=debug (Might be easier to read in a voice that doesn't sound like Borat)
Lovely idea. I have a small amount of "issue" with the way you're doing the command line though. It's more typical to see commandlines of the form: loop --every 15s --until-success --num 5 ./do_thing.sh i.e. where you give the command "last" and where if you want to give that command arguments, you use -- to separate: loop --until-success -- ping -c5 myserver As a long-time CLI user, having to put the command, and its arguments, first just feels wrong. Well done on your project though, and +1 for using clap :-)
and Rust is already a well known metal oxide.
Hi Xaeroxe, thanks for replying. I completely agree with you, I have come to find out that RUST was developed by Mozilla and has only been around for 2-3 years. Checkout this link to see companies that are using RUST! https://www.rust-lang.org/en-US/friends.html
tbh, i had thought the premise of move was that copying could be avoided. if copying is happening, it would seem basically the same as cloning all-the-things... (except for affine symantics at the type level).
Congrats, looking forward to the evolving project. I just tried to run the example in the project readme but it doesn't compile because of the `smallvec!` macro usage... would be great to adjust that example code!
Remember the distinction between copying (I.e: moving) and cloning. Cloning is a deep copy that replicates the entire structure. If you clone a `String`, you end up with two independent `String`s. If you move a `String`, the stack data (which is just a glorified reference to a buffer on the heap) gets copied but the heap data it points to isn't touched.
Thanks for the feedback! You don't actually have to put the command first, the examples you gave will work fine (although it appears the second one will need your ping command quoted). I just put the command first in the README because I think it makes the line read more like English does, "do thing until thing" rather than "until thing, do thing". I adopted this philosophy from _why the lucky stiff's book.
I came here to say exactly this. Almost every unix command taking a command as an argument will take it as a last argument, potentially separated by ` -- `.
Thank you for providing the background info! Unfortunately, I really need to write low level code that manipulates raw pointers. I guess we'll see how that goes.
You can setup a simple stub service on a random local port (bind to port 0, and the OS will allocate a port for you) as a fixture for the tests, and run your tests toward it.
This is nice! But one small nit-- &gt; Have custom counters! &gt; $ loop "touch $COUNT.txt" --count-by 5 You probably wanted `touch $COUNT.txt`. It's good practice to run all of your examples first-- just like rust does doctests.
Regarding delegate/proxy keyword: Proxy over delegate as the better keyword? You're going to use delegate in like one spot per impl. It being four characters longer is not even close to worth choosing proxy just for the global semantic confusion alone. I also don't understand concerns about it being used in GoF patterns and stuff: the GoF pattern is literally about implementing a delegate feature in a language that doesn't have built-in support for doing delegation. I have literally never heard of any talk about "delegates" outside of politics that wasn't about basically taking some set of inputs in one context and routing them to another. Am I missing nuance here? Was there a previous drawn out discussion about "delegate" at some point?
I can’t remember what the reason was for putting it off in favor of the macro was anymore either. 
I want something like this, seeing I don't use a DE, so should check it out soon
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [Rust is the best manga of all time](https://www.reddit.com/r/rustjerk/comments/8uavlc/rust_is_the_best_manga_of_all_time/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
No worries, it exists to be used. Sometimes, it is what you need.
Hi Rodarmor, appreciate the feedback regarding patents. Unfortunately when dealing with a system as large as Ticketmaster's, they need to protect their product. Although these patents are a result of many people contributing, it occurred under the roof and with the resources offer by TM. 
I do like the readability of this command, but most of the examples are fairly simple in their bash equivalents: &gt; Run on controllable timers! $ loop "ls" --every 10s $ while :; do ls; sleep 10; done &gt; Have custom counters! $ loop "touch $COUNT.txt" --count-by 5 $ for i in {0..5}; do touch $i.txt; done &gt; Loop until output matches a condition! $ loop "./get_response_code" --until-contains 200 $ until ./get_response_code | grep -q 200; do :; done &gt; Loop until a certain time! $ loop "./poke_server" --for-duration 8h $ start=$(date +%s); while now=$(date +%s); [[ $((now - start)) &lt; $((8 * 60 * 60)) ]]; do ./poke_server; done (okay that one was ugly, I'll admit) &gt; Loop until a program succeeds (or fails!) $ loop "./poke_server" --until-success $ until ./poke_server; do :; done &gt; Iterate over the standard input! $ cat files_to_create.txt | loop "touch $ITEM" $ while IFS= read -r ITEM; do touch $ITEM; done &lt; files_to_create.txt That one wasn't so pretty either, but oh well. I need to read the source first, but loop might handle some edge cases better, while bash covers them up. For example, when I was piping to grep before, if the first command fails but grep doesn't, it will ignore the failure! This definitely shines with the cases where bash makes things ugly or has hidden footguns.
Even you aren't suggesting that Ticket Master is 100% off the hook though (or at least, you didn't explicitly claim so) ;-) Thanks for the comment. My goal's not to convince anyone that Ticket Master is evil. I took care in attempting to word that comment such that it doesn't claim that everyone here should or shouldn't follow up on the position. The point I really want to get at is this: &gt; like with any work, do your own research; make sure you're happy with everything that comes along with the position. Among the people I know working CS-related jobs, few of them considered social responsibility when comparing companies and eventually accepting a position at the one they're at now. When you're in an industry in where you can typically obtain offers from multiple companies, and where said offers often cover many times your living expenses (depending on your own circumstances), social responsibility really ought to be something you consider when looking for a job. For many people in our field, sacrificing 10% pay - or perhaps sacrificing their ability to use the language of their preference - in order to contribute much more meaningful things to society is an option they have, but never even consider. I want to help change that. I want to encourage that for those who have the privilege to do so, they think about their values and the ways in which whatever work they do will effect those values before they commit to doing any work. Maybe thinking through that lens will sway a reader to not apply for this position, or maybe it will sway a reader _to_ apply. This is one of those cases where I care less about the outcome and more about the process.
A variation that stops when the command fails: while cmd; do sleep 1; done Or negate it to retry until the command succeeds: while ! cmd; do sleep 1; done
I wonder about adding this as a feature to the ion shell. That would allow loops that contain more than just the one command.
Hi Ponkadoodle, thank you for your thoughts. I am not familiar with where TM stood at or before 2012. Moreover, I am not sure what you are referring to when you say "lock-in." Their business model links sports and concert venues with a ticketing system that offers premium service, a widely recognized brand, and a variety to discounts and rewards for customers who frequently use TM. As for the position, this would be a unique opportunity for someone to add an enterprise software company at the top of their resume and grow their career.
&gt; The .not() method feels natural if you grew up with nothing but jq. Or if you are German. It is the common way to express negation in German language.
Hi Crazysim, that's a great idea! Soon enough, there will be many companies in Arizona utilizing RUST. 
Sorry, I was vague in the above post *and* made a typo :) There currently is only one keyword to look for: `pub`, which may include modifiers (i.e. `pub(...)`). In 2018 edition, there are now two keywords to look for, which is less intuitive.
You can #! any script interpreter you want though.
&gt; Unfortunately when dealing with a system as large as Ticketmaster's, they need to protect their product. Why? Because someone else will make a better product and Ticketmaster will be unable to extract economic rent without the artificial moat granted by its patents?
Thanks for your detailed dive here! I think the usability of the tool is well demonstrated by that comparison. Also I think it really shines when you start to _combine_ functionality, ex: `cat things | loop './do_thing.sh' --every 15s --until-success --num 5`. There are also other examples deeper in the README, like looping until a future datetime, and matching a regular expression. Thanks again!
This project has excellent documentation and a great README! &gt; Existing solutions were either too complicated, awkward to use, or required too many dependencies. Have you seen [`numeric-array`](https://crates.io/crates/numeric-array)? It seeks to provide highly-optimized component-wise operations on fixed-sized arrays and is also extremely lightweight. It doesn't have a particular focus on ergonomics for computer graphics, but it is an excellent foundation to build cg-friendly abstractions atop of. However, I think as these two crates stand, numeric-array actually has some substantial ergonomic advantages over `Coord`. First, what `numeric-array` _doesn't_ have that this crate does: convenient type aliases. These can be implemented easily: extern crate typenum; extern crate numeric_array; #[cfg(not(feature = "large_defaults"))] mod inner { pub type Float = f32; pub type Signed = i32; pub type Unsigned = u32; } #[cfg(feature = "large_defaults")] mod inner { pub type Float = f64; pub type Signed = i64; pub type Unsigned = u64; } use inner::*; pub type Vec1&lt;T=Float&gt; = numeric_array::NumericArray&lt;T, typenum::U1&gt;; pub type Vec2&lt;T=Float&gt; = numeric_array::NumericArray&lt;T, typenum::U2&gt;; pub type Vec3&lt;T=Float&gt; = numeric_array::NumericArray&lt;T, typenum::U3&gt;; pub type Vec4&lt;T=Float&gt; = numeric_array::NumericArray&lt;T, typenum::U4&gt;; pub mod defaults { use ::*; pub type Vec1b = Vec1&lt;bool&gt;; pub type Vec1f = Vec1&lt;Float&gt;; pub type Vec1i = Vec1&lt;Signed&gt;; pub type Vec1u = Vec1&lt;Unsigned&gt;; pub type Vec2b = Vec2&lt;bool&gt;; pub type Vec2f = Vec2&lt;Float&gt;; pub type Vec2i = Vec2&lt;Signed&gt;; pub type Vec2u = Vec2&lt;Unsigned&gt;; pub type Vec3b = Vec3&lt;bool&gt;; pub type Vec3f = Vec3&lt;Float&gt;; pub type Vec3i = Vec3&lt;Signed&gt;; pub type Vec3u = Vec3&lt;Unsigned&gt;; pub type Vec4b = Vec4&lt;bool&gt;; pub type Vec4f = Vec4&lt;Float&gt;; pub type Vec4i = Vec4&lt;Signed&gt;; pub type Vec4u = Vec4&lt;Unsigned&gt;; } With that gap closed, another ergonomic gap remains: `Coord` defines something like twelve new traits; `numeric-array` defines no new traits. This means I'm good-to-go to use `numeric-array` just by importing the struct `NumericArray`. `Coord` solves the trait importing issue by defining a prelude module that users can glob import items from, but some rustaceans (including myself) are a little allergic to glob-importing from dependencies. Basically, as it stands, the ergonomic gap is so narrow between these two crates, that I'd probably just use `numeric-array`, create some type aliases, and reap the performance benefits. Disclaimer: I haven't used either crate, this is just how I'm feeling after reading both of their docs. If `Coord` had benefits over `numeric-array` that I'm not picking up, the README should point these out! If not, figure out what `numeric-array` (and other existing solutions) doesn't do and fill the gap. (For instance, [`mint`](https://crates.io/crates/mint) integration is a good addition for any cg-focused crate.) Regardless, I'd suggest that instead of a blanket "existing solutions are too complicated, awkward to use, or require too many dependencies" statement, the README should name names and actively contrast these projects. 
I've opened a ticket for this: https://github.com/Miserlou/Loop/issues/16
An unsafe shallow copy of the keys would be enough and does not require dynamic allocation. See https://stackoverflow.com/a/46044391/6086311.
I'm already on it. https://github.com/PistonDevelopers/inflate/pull/43 https://github.com/PistonDevelopers/image-png/issues/79 (PR incoming) https://github.com/PistonDevelopers/image-png/issues/80 (need advice on resolving) https://github.com/kornelski/lodepng-rust/issues/28 https://github.com/RustAudio/lewton/issues/27 But I'm just one guy, so feel free to take this up.
Nice work! I like how it's really clear what something like the command below does even if you're completely unfamiliar with the tool: loop "./poke_server" --until-success --every 15s In a professional setting, the main obstacle for me for introducing a new tool, aside from deployment, is adding cognitive overhead for the other developers that might interact with the same code. For example, I really like the idea of switching over to fish shell for shell scripting but I couldn't ever do it because it's just unjustifiable to require other people on my team to learn this new big thing just so they can work with my scripts. This tool seems to pass that test where I could drop it into a script and not feel like I'm imposing a burden on the rest of my team.
You can destructure nested structs / enums in match patterns: if let Stmt::Expr(Expr::Lit(ExprLit { lit: Lit::Int(i), .. })) { println!("{}", i); } I've used it [here](https://github.com/fschutt/gsr-jit/blob/46bb6aa8a3cdb2b649c434d9e6d9ec655740336f/src/compiler.rs#L310) for example. Enums don't have to have any items, which makes them inconstructable: enum Inconstructable { } let enum = Inconstructable{ }; // error! let enum = Inconstructable:: ; // ? I haven't had any use case for this yet. Doc comments with `\\\` are basically syntax sugar for `#[doc = "my documentation"]`. Useful for conditional documentation or running or ignoring doc test based on features: /// ## Example /// #[cfg_attr(feature = "no-opengl-tests", doc = " ```no_run")] #[cfg_attr(not(feature = "no-opengl-tests"), doc = " ```")] /// ``` If you build the crate with `--features="no-opengl-tests"`, it will add a `no_run` to the doc test. Used it [here](https://github.com/maps4print/azul/blob/5ea52bbfb4c815dee54405f9ff10d24fcd2a6428/src/app.rs#L411-L414). And traits themselves can be generic, i.e `trait X&lt;T, U&gt; { fn something(T) -&gt; U }`.
Interesting! I'll take a look at `numeric-array`, I've not heard of it before.
Various disadvantages. Adding a keyword means you can't use \`not\` as an identifier. It would add a second syntax for the same thing. Which means more to learn, including learning that they are exactly the same, as well as adding variation in code depending on which style individuals prefer (of course, \`.not()\` has that issue too). If you added \`not\`, you would probably want to add \`or\`, \`and\`, etc. For better or worse, Rust chose to provide \`!\`, \`&amp;&amp;\`, \`||\` like C instead of \`not\`, \`and\`, \`or\` like Python. You can make arguments either way, but I don't think it make too great a difference, and supporting both might be worse than either individually.
ALPN is not used for upgrades. The client offers a list of protocols it supports. And the server accepts one of those protocols. Then a TLS connection is established.
This one feature makes me a little jealous of D. The compiler is so fast that they can use it as a scripting language with shebangs. https://dlang.org/rdmd.html
Would this work on windows?
How about using a coding font where the '!' is bigger? My ! doesn't look anything like l or | or I or 1.
`let` is a variable binding, not a concrete memory location, until much later in the compilation process, especially for the purposes of Drop and ownership semantics (you can even have zero sized structs with no location in memory that are tied to or represent lifetimes). For example, you can write `let x = X { ... }; let x2 = x` and most of the time it will be optimized to use a single space in the stack for both x and x2. As such, let bindings like this aren't dead code because they aren't really code, just a level of abstraction that works well for rustc and the programmer for representing higher level memory manipulation.
If you want to block on select() or whatever, you can create a pipe to use to signal one thread from the other (on UNIX at least). `man 2 pipe`
As far as I know there's nothing UNIX-specific here (`Exec::shell` uses `cmd.exe` on Windows), but I don't have a Windows machine to test/build on so I can't make any promises yet.
The graphics card doesn't matter at all, it's really just down to your CPU since the compiler doesn't use the GPU at all. You might also try /r/playrust next time.
This is normal, it's expected for bigger crates to compile longer, and Rust doesn't provide any feedback that the compilation is in fact going. Please be patient.
You mean `while ! ./do_thing.so || [[ ${n:=0} -gt 5 ]]; then sleep 15; (( n++ )); done`?
tuple struct constructors (`Type(a, b, c)` or `Enum::Variant(a,b,c)`) can be passed as function pointers (0..10).map(Some)
Yup, and you can't return non-borrowed data from `Index` either. The traits in the Rust standard library have some annoying restrictions. It probably *could* have been defined as pub trait Borrow&lt;Borrowed&gt; { fn borrow(self) -&gt; Borrowed; } The impl for `T` would have to go, but the one for `&amp;'a T` could stay. But those changes would probably have other downsides (although I can't think of any right now). Oh well. You can work around this problem with some custom structs. Sadly `Cow` won't help. But hey: [https://play.rust-lang.org/?gist=275b519e021bc0d2731d697bc28856aa](here you go).
How long is this expected to occur? I have already played for around 6 hours and the lag has persisted. Should i just wait and endure the lag?
I haven't seen this new syntax, what does it mean?
I think you're slightly misinterpreting the OP. /u/boojies, please correct me if I'm wrong, but doesn't your question come down to whether you should pursue learning to use Tokio in its current state, or wait for async/await to provide ergonomic improvements?
It's equivalent to `pub(crate)`
Nebulet Is one of the most exciting projects that I've seen recently. It takes an old concept (language based operating systems) and uses a preexisting IR that even C can use.
`for&lt;'a&gt;`
In my previous team, I had managed to convince people to use `not`, `and` and `or` in C++, instead of `!`, `&amp;&amp;` and `||`. I simply showed them code samples with `&amp;` or `|` instead of `&amp;&amp;` or `||` and which hid the `!` in non-obvious places and asked them to spot the bug. Then I repeated the experimented (different examples) with `not`, `and` and `or`, and the bugs immediately jumped out to them. Unfortunately, I am back to the cryptic operators now... so for `!` I make sure to put a space before and after it so it really stands out.
That was a joke, this isn't a subreddit for Rust you think it is, please check out /r/playrust.
Oh, please don't bring that nonsense rivalry in here. PCGs can be given any seed at all, which is reason enough to pick them when you're letting the user pick the seed. Unless there's some generator you have to show off that can run 8 lanes wide in SIMD, I'm just not interested in PRNG fights. The point of the lesson is that you can read how a thing works and then implement it yourself. So, sure, go read how xoshiro works and then implement it yourself if you like.
It's as simple as http://i.imgur.com/rCr9A.png
Is this caused by match ergonomics? It seems like it should be ergonomics for ``` let &amp;&amp;Foo(ref x): &amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23); ``` because `x` is `&amp;i32`, but I can't find any match that typechecks with `&amp;Foo&lt;i32&gt;`.
The git repo: https://github.com/Azure/iotedge/tree/master/edgelet
That is quite an amount of Rust code. This and actix means Microsoft is becoming quite a player in Rust.
Reinventing the wheel is fun
 Is actix a Microsoft thing? Or are they just using it? 
Main actix developer works for MS.
I know about `unsafe` to fix this, but it’s a hack (since `unsafe`).
Honestly, I'm unsure. I'd expect it to be a combination of match ergonomics and some reference coercion. E.g. I'd assume it'd be let &amp;Foo(ref x): &amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23); but that doesn't compile by itself due to the type conflict.
Also HTTP/2 and protocol upgrades!
Uhh, nice! Reminds me of Haskell.
I get the following when I try to do `cargo install loop-rs` on windows: Compiling loop-rs v0.3.3 error[E0432]: unresolved import `isatty::stdin_isatty` --&gt; src\main.rs:16:14 | 16 | use isatty::{stdin_isatty}; | ^^^^^^^^^^^^ no `stdin_isatty` in the root. Did you mean to use `stderr_isatty`? 
IIRC this is how Hash Map/Set and friends got custom hashers added in a backwards compatible way
Incremental parsing for IDEs is crucial and, as should be clear, really hard. I say rather than trying harder and harder with parsers, just get rid of text (and edit a tree directly). Cut the gordian knot.
You can even include it in many places as `for&lt;&gt;` :-)
And microsoft allegedly put actix-web in production.
SIMD is the first thing that comes to mind. Learning how to enforce alignment requirements was pretty interesting. If you naively try to load four f32 values from an array in order to do some vectorized operations, it's likely that you'll quickly run into something *safe* Rust helps you avoid: segfaults. This is because an f32 and arrays containing values of that type only need to be aligned to four bytes. In order to load them efficiently, though, the alignment of the array should be 16 bytes. (There's an operation which works even if the alignment requirement isn't met, but there's a performance penalty in that case) A way to enforce the alignment to be 16 bytes is to do the following: use std::arch::x86_64::__m128; struct Aligned { data: [f32; 4], _align: [__m128; 0] } The empty array does not make the struct larger, but it does enforce the alignment requirement. 
Which isn't quite the same thing. Are they working on `actix` during their work hours, or free time?
&gt; But I would expect that the `let _a` is also unreachable Prefixing a variable name with an underscore disables lints about the variable being unused. I don't think there's a separate lint for the assignment that is never run.
https://zapper.com
Damn! Can you maybe open a ticket about that?
Wirklich? Ich habe kein Beispiele wo einen ".not() method" natürlich ist.
Interesting. Do you have a source for that?
Don't you have to make `Aligned` `repr(C)` to ensure rust doesn't one day decide to swap the order of `data` and `_align`?
what is this innermost `crate()`?
my point is that everything already exists. your complaint isn't helpful.
It's the unit type `()` with a `crate` visibility.
OK then, thank you for your reply. I always tend to overengineer my projects, which is probably the main reason I always fear to make mistakes :P Let's get to work!
Bizarre. Note: There are a few instances of people surprised by match ergonomics. If you or someone you know has a 🛸close encounter🛸 with match ergonomics, post your experience in the [lived experience](https://internals.rust-lang.org/t/lived-experiences-strange-match-ergonomics/7817) thread on the internals forum!
As a thought experiment, I like to try to imagine what it would look like to program with completely panic-free code. I think panic free code would have some good properties. I guess you would need to somehow program invariants on all of your data, at compile time, so that you can be sure that necessary conditions are always met. That would probably entail creating new types and proving theorems about all of the code that you write. But if you think about it, it would be extremely annoying to program this way. You wouldn't even be able to index an array with a normal integer! Rust also panics when println fails or when memory allocation fails, right?
I'm not sure. Hopefully, some way to easily express an alignment requirement without wrapping an array this way will be available soon. I would love to be able to use something like `Vec::with_alignment(alignment: usize)`.
(FWIW, Rust is typically stylized as "Rust", not "RUST".)
[Yes.](https://godbolt.org/g/1N2Ztw)
The main problem with Mio that's solved by Futures/Tokio is that the async programming isn't composable, i.e. it's not easy to build on top of crates offering Mio-level abstractions. [Rotor](https://github.com/tailhook/rotor) was an early attempt at one such way of composing Mio-based libraries. Having tried both Rotor and Futures, I personally found Rotor much harder to scale up in complexity.
It is interesting. Just yesterday I tried to build basic actix-web project using the latest msvc-toolchain and got a build error.
Just the word of the project owner.
As an approach (4), you might have more luck with futures if you don't use the combinators and simply implement `poll` by hand. It's actually pretty straightforward -- it kind of feels like a simpler Mio -- and you won't run into crazy types.
&gt;I haven't had any use case for this yet. Oh, it's very useful. So useful indeed that it in process of being integrated into the language as the never type `!`.
This is really exciting. It's crazy to see just how far Rust has come when _fucking Microsoft_ adopts it and puts it in front of their Hardware Security Modules. That's just so cool to see.
Traits can provide default method definitions (example at Traits in Rust By Example). So, your trait would look like this: trait MyTrait { ... fn bar() -&gt; i32 { 2 } } Just implement MyTrait on your data structure without defining bar. Of course you can override bar in your implementations. 
Tokei says it's currently 60k lines worth. So certainly one of the bigger Rust projects out there.
Or for _ in {1..5}; do ./do_thing.sh &amp;&amp; break sleep 15 done
It's because let statements are coercion sites and auto-deref comes into play. \[Nomicon\]([https://doc.rust-lang.org/nomicon/coercions.html](https://doc.rust-lang.org/nomicon/coercions.html)).
Sure. [Here you go](https://github.com/Miserlou/Loop/issues/17).
The names of enum variants are two things at once. They are both the variant "type" (with respect to which variant of the enum it is), as well as a function that creates an instance of that variant: ```rust #[derive(Debug)] enum SomeEnum { VarOne(usize), VarTwo(usize), } fn enum_builder&lt;F: Fn(usize) -&gt; SomeEnum&gt;(ctor: F) -&gt; SomeEnum { ctor(0) } fn main() { use SomeEnum::*; println!("{:?}", enum_builder(VarOne)); //prints "VarOne(0)" println!("{:?}", enum_builder(VarTwo)); //prints "VarTwo(0)" } ``` A function that looks a lot like this one is used in rustdoc when building up the "auto-trait implementations" section - the details are even more obscure, but there's an enum in the compiler that has a bunch of variants that "look" the same, so it uses this feature to make some generic instances based on what the caller wants.
Interesting. I found out that let &amp;Foo(x): &amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23); works, but let &amp;Foo(ref x): &amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23); fails to compile.
Hä? 
Thanks for the explanation!
If you want to learn about asynchronous networking, you might as well learn to use mio directly instead. What you learn will translate to the async networking primitives in every language, /and/ it will become more obvious what problems tokio and async/await are trying to solve.
I see a lot of `and_then` and `map_err` where I'd expect to see just `?` in Rust code written after 1.13. Does anyone know if that's a policy decision they made?
`true == !!!!!!true`
The level of bikeshedding has overflown.
It's not really an operator if you express it as \`not()\`. std::ops is full of operators, of which ! is one of them. It would be pretty confusing to have a whole bunch of operators then a random postfix method. I think it's safe to say the ship has sailed, but nothing is stopping you from making a Not trait and writing your own \`not()\` instances in your own code.
https://github.com/DanielKeep/cargo-script
^The linked tweet was tweeted by [@shoez](https://twitter.com/shoez) on Jun 27, 2018 08:47:34 UTC (19 Retweets | 50 Favorites) ------------------------------------------------- Logistics Algorithms team at [@DeliverooEng ](https://twitter.com/DeliverooEng ) have just released a major rebuild of our rider dispatch service, moving from Ruby to \#rustlang. As you’d expect, its insanely fast! 12.5x faster. ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
Ah, you're right. I was thinking about the Alt-Svc header at the HTTP level. It looks like hyper does not provide support for that, right now.
`Iterator&lt;Item = u32&gt;` is just a way to talk about associated type families, you cannot change the order of the type variables [as this example shows you](https://play.rust-lang.org/?gist=38aab2cc9f8bec62338d44ee373d6f73&amp;version=stable&amp;mode=debug).
Go for using mio. It's a very nice library.
The "new side" Microsoft is a thing of beauty. They made typescript too! Love that direction.
Perhaps they don't like single character type-converting return statements :-p
Yes. In fact, I [have a crate](https://github.com/novacrazy/numeric-array) specifically designed to exploit auto-vectorization.
This sounds cool from a technical standpoint, but I can't help but feel uncomfortable about MS given the recent Azure news.
Link?
What news might that be?
Presumably the one offering supported private cloud services
Microsoft's Azure division is assisting the US government in building concentration camps. https://www.vanityfair.com/news/2018/06/microsoft-employees-azure-ice-partnership
I still don't see a connection. Why might MS offering supported private cloud services make one uncomfortable about their use of Rust (as an open-source project no less)?
From my conversation with him at a recent Meetup, he’s now working on it full time at MS. Assuming I herd him correctly. /u/fafhrd91
How exciting! How exciting!
In this case you can use `watch` which is quite broadly available. 
Last one can be easily done by using `xargs`. 
So it could act as a custom allocator but i honestly have no idea how that works in rust :/ As of right now, you cant safely put non primitive types into the shared memory 
What message should I report to the user for an unrecoverable error? A panic sounds like it's for developers, while \`process::exit()\` does not free memory. Classic scenario: a non-existent file for the file path provided.
Ah, this looks perfect for me, thanks!
Looking for feedback on this post. I am sure there are many more good examples, and probably there were a couple mistakes too.
I hate to be a debbie downer, but a 12x improvement over Ruby sounds awfully small. Ruby is notoriously slow. Even amongst dynamic languages, it's dog slow. It must have been a service which was mostly network focused.
I don't like it either but that's quite hyperbolic. They're providing things like email and calendar tools, nothing more. At some point you have to realize that the software you write is going to be used for immoral purposes, especially if that software is something as universal as *email* or *a programming language.*
Good god. Sometimes I'm reminded how little I know about programming.
Rust (the rust complainer), did you do that on purpose :p? 
Well given that about half of the Americans voted for the president responsible for those so-called concentration camps (have they started mass exterminating the immigrants yet?) it seems strange to single out MS as 'bad' for selling some business software to the government. Regardless, your concerns seem pretty off-topic on this particular subreddit. If your concerns cannot be discussed without going off-topic, it seems (to me) best not to voice them at all.
Trolled by /r/saddertadder. My induction into the RESF is complete.
Wait, what does `rustc` actually stand for!? /s yes I did
they said in a follow up that they are not 100% Rust yet so many marshaling still occur with some Ruby code 
From the tweet chain: &gt; There's loads more to do; we're not 100% Rust - and so lots of time is spent marshalling data between Ruby and Rust.
A bit more info [here.](https://globenewswire.com/news-release/2018/06/27/1530116/0/en/New-Photon-Release-of-Eclipse-IDE-Ships-With-Full-Rust-Support.html) It seems Eclipse now supports Language Server Protocol, and therefore, supports Rust and its native tools as a result.
Oh, thanks! On second thought: What?
Teaching my 12 year old game programming with Piston. We have a square that can move using arrow keys!
I heard he works for MS.
ah, ok. I stand corrected then. That explains it.
See also: [faster](https://github.com/AdamNiederer/faster)
1. Microsoft buys Github 2. Microsoft adopts Rust 3. Microsoft renames Github to Pijulhub!
Fuzzing is great for crates like this. Even without unsafe, one still has to worry about hitting unexpected panics that could be used for DoS etc.
The fact you know my username for trolling either means I'm doing something really great, or really stupid with my spare time. Anyways, I kinda misposted that, thought this was /r/programming, not /r/rust, and if I knew that before I le epik trolled u RESF style, I wouldn't have posted it.
`process::exit` will *absolutely* free memory and resources on any operating system that isn't a giant house of cards in the first place. It won't call `drop` code, but that's a completely different problem. You probably want to use `Result`s all the way up to `main`, where you can print out whatever you want and exit cleanly.
The bounds checking that Rust does for indexing can often inhibit auto-vectorization (cleverly avoided in the example of /u/zenflux, because iterators are used). You can see the difference in action [here](https://godbolt.org/g/szPgVZ). 
Nope not a good idea for std::ops, but the beauty of rust is that you are free to make a crate for it, which is what I recommend.
I'm interacting with a C FFI. In C: Host* pHost = NULL; HRESULT hr = c_func((LPVOID*)&amp;pHost); Basically, pass the address of a null pointer to a struct, cast as an LPVOID *. In Rust, I've mirrored the relevant struct with and prefixed it with #[repr(C)]. let mut pHost: *mut Host = ptr::null_mut(); 
&gt;We create a pointer to an int with the value of NULL. When we try to write to or read from that location, a SIGSEGV happens. It is undefined what happens. You promised to the compiler that you passed valid C. The compiler/implementation promises that, when executed, valid C behaves as defined. No guarantees are made for null dereferences. Saying, a segmentation fault occurs, assumes a lot of things (maybe Linux environment with GCC or Clang?). &gt;Of course, this way we do get a SIGSEGV. The behavior in Rust is undefined in the same way. It is enough to say that the behavior is undefined. This is a post about C and Rust. There is no need to constrain it to a particular set of implementations.
Is there a way to specify alignment on references? Then we could eliminate the branches at the beginning.
And that coming from a person that makes comments [like these](https://www.reddit.com/r/rust/comments/8shjfd/comment/e0zjudg): &gt; Hitler also owned a dog. I guess we should all be cat persons now? But alright, sure. For me technology and ethics are heavily intertwined. If Azure is currently in a scandal about ethics, isn't it relevant to stop and think about their moral code when talking about the technology they release? I think it is.
You can see how to godbolt exampes do it if you click the 'Save/Load' button above the code pane and see the difference between an example and its `(Optimized)` variant. I believe you can also just branch (`assert`) on the condition as well, instead of only using `assume`.
I'm not involved, but here are some links to what I think is the [project's homepage](http://projects.eclipse.org/projects/tools.corrosion) and [github](https://github.com/eclipse/corrosion), if you feel like pitching in!
Wow! This is exciting! I'm gonna have to try this out.
Oh, good. Now we can trust the code and not trust the product at the same time. Microsoft's paradox?
with_branch: running 13 tests test easy_sudokus_solve_all ... bench: 143,283 ns/iter (+/- 6,417) test easy_sudokus_solve_one ... bench: 155,448 ns/iter (+/- 8,213) test generate_filled_sudoku ... bench: 21,181 ns/iter (+/- 930) test generate_unique_sudoku ... bench: 126,536 ns/iter (+/- 7,917) test hard_sudokus_solve_all ... bench: 11,094,600 ns/iter (+/- 343,592) test hard_sudokus_solve_one ... bench: 5,276,785 ns/iter (+/- 159,278) test is_solved_on_solved ... bench: 18,196 ns/iter (+/- 922) test is_solved_on_unsolved ... bench: 8,851 ns/iter (+/- 607) test medium_sudokus_solve_all ... bench: 157,815 ns/iter (+/- 61,706) test medium_sudokus_solve_one ... bench: 170,102 ns/iter (+/- 8,378) test parse_line ... bench: 274 ns/iter (+/- 13) test parse_lines ... bench: 278,050 ns/iter (+/- 14,723) test shuffle ... bench: 310 ns/iter (+/- 20) without_branch: running 13 tests test easy_sudokus_solve_all ... bench: 150,318 ns/iter (+/- 9,559) test easy_sudokus_solve_one ... bench: 160,333 ns/iter (+/- 13,379) test generate_filled_sudoku ... bench: 21,006 ns/iter (+/- 951) test generate_unique_sudoku ... bench: 130,636 ns/iter (+/- 7,243) test hard_sudokus_solve_all ... bench: 11,562,970 ns/iter (+/- 361,940) test hard_sudokus_solve_one ... bench: 5,494,745 ns/iter (+/- 189,127) test is_solved_on_solved ... bench: 17,842 ns/iter (+/- 859) test is_solved_on_unsolved ... bench: 8,415 ns/iter (+/- 386) test medium_sudokus_solve_all ... bench: 167,297 ns/iter (+/- 8,757) test medium_sudokus_solve_one ... bench: 173,127 ns/iter (+/- 8,885) test parse_line ... bench: 260 ns/iter (+/- 33) test parse_lines ... bench: 273,463 ns/iter (+/- 12,917) test shuffle ... bench: 319 ns/iter (+/- 62) Processor: Processor Intel(R) Core(TM) i5-4590 CPU @ 3.30GHz, 3301 Mhz, 4 Core(s), 4 Logical Processor(s) OS: Windows 10, Professional The branch is definitely faster. I expect that the branch helps the CPU make better branch predictions and thus executes the code faster. 
Awesome! Usually my orders take close to an hour to arrive. Food in five minutes, yay!
Cute. Some things that I noticed at a glance (not to be taken too seriously): * Fully agreed on examples should have commands in the end. * Feels like you could just drop the -- from long options to make the interface more fluent. Any ambiguities can be resolved by having (optional) `--` to separate options from commands * I feel it highly surprising that loop behaves differently depending if the input is attached to pipe or tty. Make one or the other behavior default and stick with it. * The `for` variation should respect `$IFS` * Introduce basic boolean operators (and, or, not) to conditions, similar how `find` works. * `$ACTUALCOUNT` feels like a poor name. Not sure if you could simply turn `$COUNT` =&gt; `$ITEM` and `$ACTUALCOUNT` =&gt; `$COUNT`? * Allow `\0` separated items similar to `xargs`. Otherwise it is very difficult to safely handle file names (among other things).
/r/playrust
/r/playrust
Yes but I believe you have to compile with `RUSTFLAGS="-C target-cpu=native" cargo build --release` to fully enable it (which makes the binary less portable).
There are many reasons why I would consider ```and_then``` to be a better choice: 1. It is a functional approach that works for different kinds of mondads, e.g. the code can be pretty much the same for both sync and async versions. 2. ? just doesn't work with futures. 3. Correct me if I'm wrong, but I think ```?``` doesn't invalidate the need for ```map_err```.
I'm usually skeptical of using cases like this as an example of a new tool being genuinely better. Often there are problems with a first implementation that could have been addressed in-place, but a rewrite is easier. As a result, a rebuilt system gets the benefits of a new tool mixed in with the substantial benefit of being built with a better understanding of the core problem. When that's the case you can never really tell whether it was the first tool that was the problem, or the first modelling of the problem. That said - in this case it genuinely does seem like a reasonable apples-to-apples comparison. They appear to have moved a core part of application logic from being in Ruby, into Rust code embedded within their existing Ruby stack. As a result it sounds like the Rust code really is doing the same thing as the Ruby code was, and is doing so better. That's a really great situation and I'm glad this worked out well for them!
Look, you're dragging the conversation off-topic already, exactly as I said would happen in the very post you reply to. Now you're crawling through my posting history attempting to find dirt for personal attacks. I would like to point to the sidebar, which lists such rules as "Constructive comments only.", "No zealotry", "Submissions must be on-topic.", and "Chill out!" :-)
Oops, sorry about that! A rogue find and replace -- should be fixed now.
Clippy lints should be disabled when they aren't helpful to you.
`pub(crate)` is like `pub`, but only to things within the crate. For things outside the crate it's as if it weren't public.
I think we missed each other on IRC. Saw discussion of `ptr::read` having misleading documentation. Sounds like it would be more like half of a move (same at runtime except old value still exists). There are still dangerous operations on `d` depending on the exact type and why it's not `Copy`, but it's a subset of operations that are dangerous on uninitialized memory. I have no idea what the dangers of multiple `&amp;mut` to the same location existing are, and when things cross into undefined behavior. This could impact the safety of `take_mut`.
To your number 3, I believe it does. As with try!, ? implies a call to From::from.
How do you manage to be faster than actix while using so little unsafe code? And do you plan to implement async once async lands in stable rust?
 I believe the increase in speed lies in the lack of branching code. That also belies the breadth of accessibility, to be added at the developers descrestion. And I absolutely plan on implementing asyc once it lands in rust -- itd make the whole framework far more concise!
Wow, your framework looks like one of the best so far!
Thank you!! It's very heavily influenced by both tokio-minihttp for rust, and Koa for NodeJS!
&gt;I do like the readability of this command, but most of the examples are fairly simple in their bash equivalents I agree, but I think that this `loop` command is very useful for writing in the prompt. If you want to write portable scripts you have to keep using `while`, but, on the prompt, the simplicity of the command is very welcomed. I use `while`, `for` and `xargs` a lot, and it is a bit cumbersome sometimes. 
&gt; I see a lot of and_then NO AND THEN!!!
Does this mean my "Start treating your employees like humans, you monsters"-messages arrive even faster at their headquaters? I love Rust, but every piece of good news for Deliveroo is bad news for the world! Fuck those guys.
Why is reading the contents of a file into a string so hard? Apparently I have to write all this: let mut file = File::open("foo.txt")?; let mut contents = String::new(); file.read_to_string(&amp;mut contents)?; Though, I still get the error `the trait 'std::ops::Try' is not implemented for 'std::string::String'` when I do that which led to me fruitlessly wrestling with the compiler for at least 15min. I'm used to just writing `(slurp "foo.txt")` in Clojure. What's the point of all this ceremony?
Not all possible transformations can be done by `From:: from` though. And if you're using `and_then` anyway...
The fact that you got this "simple" command wrong (`then` instead of `do`) speaks for itself, I think.
So after some figuring out, the branches at the beginning are from bounds checks. I've tried a few things: [Link](https://godbolt.org/g/Tv48t2) * Fixed 16B size works (\`f\_fixed\_size\`). * Multiples of 16B are harder (\`f\`) and we do not get optimal codegen.
A better way is \`#\[repr(align(16))\]\`
Unless the multiples are also hardcoded. Try 272. (less and it unrolls the whole thing)
Swapping the order shouldn't affect anything. `Aligned` will still have alignment 16, and `data` will still be at the first address.
Vilalyd - the hero of users.rust-lang!!
`watch` actually doesn't ship with OSX.
Why is not on `Ok` so we can return `Ok` rather than `Ok(())` everywhere?
Rust just recently got a convenience function for this: use std::fs; let contents = fs::read_to_string("foo.txt").unwrap(); The docs for `slurp` don't say how it handles errors. I assume it can throw `FileNotFoundException` and `IoException` but if you don't bother catching those then `.unwrap()` is the closest equivalent, though I recommend using `.expect()` instead which lets you add some context to the panic message.
I love this! Just the other day I was trying to explain how to do particular commands for a duration to a co-worker who isn't a bash person *at all*. This would have perfectly solved their problem in "English like" syntax!
My favorite thing is how the second example is a valid syntax but is completely useless.
Rust has a drop operator, which can be useful for dropping runtime borrows: `val;`.
You want /r/playrust
https://docs.rs/stripe-rust/ seems promising from a 30 second overview.
"How exciting!" but unironically
Concentration camps are the step before death camps. They were not originally intended to turn into those in fact. The technique was pioneered by the British in their African colonies, particularly in Kenya I think.
Should've searched for stripe! Thanks
&gt; new side That's a good way to describe it, because the much bigger "other side" is still proprietary and malware-like.
Man, I just remembered I can just MEASURE branch misses. Face meet palm. Barely a change but the number of instructions executed shoots up. It's probably excessive inlining (code bloat) and the branch makes llvm more conservative.
They've absolutely turned from a company I begrudgingly used software from to one I actively enjoy. They seem to have been serious in their efforts to earn trust and respect.
Woah. Horrorshow has dramatically better marks. Can anyone comment on user experience?
Can anyone give a high level summary of the status of const generics? How far out are we from having them in nightly?
Using `#![no_main]` is doing nothing. Litterally nothing. It still acts like I need a start file, I have no idea why. I'm totally lost
Ok isn't a type, so it has no type parameters to default.
Yea my rule is program in main until you notice a group of code that could be its own function. That being said it should only be its own function of its useful to reuse it. 
A rule of thumb seems to be that a FFI hot path Rust implementation will be one order-of-magnitude performance improvement, whereas a full Rust port will be a two orders-of-magnitude performance improvement (vs. Python/Ruby/PHP/etc.)
September!?... At least leave a link to the old page up. Or a link to the github. 
 $ loop "ls" --every 10s $ while :; do ls; sleep 10; done But, in this case, *loop* gives the correct behavior. If, for example, the *ls* command (or whatever you were doing) took 5 seconds to execute, then the second code block would repeat every 15 seconds. With the loop command, you get perfect 10s repeats (I tested it). Well done!
Ananysis of this: \`\`\` let f:&amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23); \`\`\` compiles. So the you can get a reference to \`T\` from a reference of reference to \`T\`. Now, \`\`\` let Foo(x) = f; \`\`\` was the ergonomics for \`\`\` let &amp;Foo(ref x) = f; \`\`\` Except that \`x\` is an \`&amp;i32\` in the later, not \`i32\` in the former. However, match ergonomics go further to use the fact that \`i32\` is \`Copy\`, so simply types the variable \`x\` to be \`i32\`. For me, this is not too hard to understand, but the only barzard piece of the picture is the last part to infer \`i32\`. 
Does loop ship on OSX? 
Wait really? Where?
&gt; Even amongst dynamic languages, it's dog slow. I think you're talking Ruby circa 2006, modern ruby has had a lot of effort put into performance and it's now comparable to python and friends now, iirc.
You can use the `std::os::raw::c_void` typedef and cast an `&amp;mut` reference to `pHost` to a void pointer: use std::os::raw::c_void; unsafe { c_func(&amp;mut pHost as *mut *mut Host as *mut c_void) } You may not even need to import `c_void`, you can actually use typecasts with inference variables and this will probably work here: unsafe { c_func(&amp;mut pHost as *mut *mut Host as *mut _) }
https://www.ralfj.de/blog/2017/06/09/mutexguard-sync.html
Isn't `drop(b);` clearer?
what does it mean？
What are you trying to do? Build a library or provide your own `start` function?
&gt; Assuming I herd him correctly. Why are you herding people?
The way the borrow trait is used inside things like hashmaps requires that it take `&amp;self` as an input. The requirement of `K: Borrow&lt;Q&gt;` on the get function is key here - after filtering based on hashes and such you call `.borrow()` on each key to transform it into `Q` before doing the comparison. If it took self you’d drain half the hashmap trying to do a lookup. I think the solution here is to have something like ``` impl &lt;T1, U1, T2, U2&gt; Borrow&lt;(U1, U2)&gt; for (T1, T2) where T1: Borrow&lt;U1&gt;, T1: Borrow&lt;U2&gt;, { ... } ``` And so on for all other tuples. The issue with that is that the impl of `T: Borrow&lt;T&gt;` will conflict with that in the case where T1 == U1 and T2 == U2. I think what we’d need is specialisation? 
Hmm, can you run it and see what happens if a command on a 10 second timer takes 15 seconds to complete? Do you get a system slowly choked with processes, or.... ?
CardConnect looks pretty nice. Their documentation makes it look fairly easy to integrate hardware, too.
Glad I helped! Xdd. 
Yeah, I eventually figured it out, but thank you for the answer. 
Change the title. 
I’ve been attempting to do the same but with Unix Domain Sockets. Turns out the latest release won’t even work and you need to use master. I’m cheering for you and would love to see you write a blog and post it here when you are successful. As for myself I think I’ll have an async server and a sync client for now. 
Well, it's not the first time the US government has built concentration camps, anyone remember the ones they made for japanese immigrants and descendants in WW2?
Yeah, Rust doesn't support keyword arguments for function calls or type-constructors. But in the places where it supports anything at all like keyword arguments (the `format!()` family of macros, and associated types) it uses `=`.
You stand correct. They are doing an awesome work, performance wise. Ruby 2.6 introduced also a (partial) JIT implementation.
`unsafe` is not a hack. It's an escape hatch when the rules of safe Rust are too limiting.
Even clearer - give the slices a size and it's nothing but vectorised code. https://godbolt.org/g/jTzbTU
Then we'll suggest something to replace the dot `.`, right? Or `-`, it's not readable enough sometimes. N.B: there are better fonts (and font sizes) for source code.
Planning a more in-depth write-up, but code is published [here](https://github.com/bspeice/dtparse/tree/benchmark). On my computer CPython takes ~8ms per iteration of the test suite, Rust is ~3ms. So significantly faster, but not order-of-magnitude.
This is fantastic, and exactly what [I went with](https://github.com/bspeice/dtparse/commit/4b92fe9123dc5cea90794d005613f992ba45db05)!
Yup, that's also what I've been doing. Findings so far: https://github.com/PistonDevelopers/image-png/issues/79 https://github.com/PistonDevelopers/image-png/issues/80 https://github.com/kornelski/lodepng-rust/issues/28 https://github.com/RustAudio/lewton/issues/27 One of them is a memory leak and another can be used for making the program allocate huge amounts of memory. Others are just panics on things that would have been exploitable in C. Sadly, by their nature fuzzers can only scratch the surface. They will pretty much never discover vulnerabilities that a very specific sequence of bytes, which is what would have been required if the bug in `inflate` was exploitable.
Somehow i don't think it works that way...
There's also a typo (`so` instead of `sh`), since I've written that on my phone. Point I wanted to make is that it isn't 'needlessly complicated' - sure, if you force it to be (like the original example) it will bee needlessly complicated. Cases in the first example are what I've updated - deliberately not using a compound for the conditional, choosing a deliberate unreadable version of `(( n++ ))`, placing `do` on a new line for extra length. Tedious? Only if you don't use the features shell offers you. Fickle? Yeah, that is true, shell is too fickle. That comes from the flexibility though, I'd say.
Title is temporary so far, agree that it is not great.
Good point of course, I will clarify that.
When clippy is sad about some code, it makes me think that every other rust developer will feel the same.
That impl cannot exist, because the trait demands you return `&amp;Borowed`, you *can't* create a new tuple and return it here.
I've been a bit skeptical after that one: https://www.reddit.com/r/programming/comments/8s2mvs/no_we_are_not_rewriting_office_in_javascript_and/
Aaaaand then?
Those email and calendar tools are being used to coordinate the detention of immigrants into concentration camps. IBM provided Germany with machines for tabulating censuses, nothing more. Microsoft's services are not open source and they could terminate their contract with ICE at any point. We have a moral duty as technologists to protest when our industry acts in concert with evil.
I cant believe that you say that, when you can clearly see the clusterfuck called windows 10. I mean yes, typescript, visual studio code and so on are amazing, but microsoft is still not one entity, but many people and some are great and some arent. I wont believe in a good microsoft until they fix their dirty operating system or give us an alternative, though. And before anyone says that i should back up, why it is so horrible: Shitty updates, ads in the ui, no privacy, trying to gain a monopoly position with the windows store, the way their software for it is so closed up and incompatible with open standards....... Im sorry for the rant, but them having changed is a bluff, they just added some sugar and glitter to their poop.
Thanks! Appreciate the time to explain it more. Definitely helps me understand it better.
That makes lot of sence though. With `struct Foo(Bar)` expression `Foo(bar)` is ordinary function call. But result of this expression is instance of `Foo` 
&gt; A quantum leap &gt; Rust Coincidence ? :p
A nested function definition can act like a `safe` code block within an `unsafe` function. When writing unsafe code, I try to minimize the code in the `unsafe` block/function to only the absolutely necessary bits. I'll often write a safe version of the unsafe function that performs the desired logic, which is then called by the unsafe function. This can get messy though, and the direct association of the unsafe/safe functions might not always be obvious to the reader. A way to more directly communicate that the safe code only exists for the unsafe function is to declare it as a function inside the unsafe function. E.g., unsafe fn do_my_things(arg: UnsafeType) -&gt; Output { fn logic(ensafenated_arg: Type) -&gt; PreOutput { // Attempting to do anything unsafe here will fail during compilation } let ensafenated_arg = unsafe_transform(arg); let pre_output = logic(ensafenated_arg); final_unsafe_transform(pre_output) }
who designs a software landing page with no screenshots?
Microsoft is a fucking gigantic company made of lots of little parts. Recently, there have been more less-bad parts. There are still a lot of bad parts. I don't like Microsoft, and I greatly dislike most of their actions. I'm glad we're getting the benefits of these less-bad parts. That doesn't excuse the bad parts, or exonerate Microsoft's name. But it's still nice to see.
https://doc.rust-lang.org/nomicon/hrtb.html
There is one on the github: https://github.com/eclipse/corrosion/blob/master/README.md
I was kinda hoping they had updated the UI at least a little. I remember too many unpleasant memories when I see that UI.
&gt; Sadly, by their nature fuzzers can only scratch the surface. I thought AFL analyses the assembly to change input to maximize the coverage level. Doesn't it give enough depths?
As others have said using mio is fine and for stdin/stdout it really should not be that complicated. For websockets you can use [mio_httpc](https://github.com/SergejJurecko/mio_httpc) and keep everything in a single event loop. 
Hey, thats Eclipse. Early 2k UI is a selling feature. I (have to) work with this every day for 10years now, still waiting for a mousewheel driven way to change font size, ergonomic block marking and so on. At least there is now a dark theme to avoid eye cancer.... But brain cancer is still guaranteed if you try to configure Eclipse.
&gt; so-called concentration camps (have they started mass exterminating the immigrants yet?) This is very... historically problematic. Concentration camps were there and inhumane long before the death camps.Concentration camps were not necessarily extermination camps. The first one was https://en.wikipedia.org/wiki/Columbia_concentration_camp, which I happen to live next to. Much of the leading personnel (and especially Arthur Liebehenschel) later went to Auschwitz in leading positions. It's notable that this was all not secret, but in plain sight (Columbiadamm is _right_ in the middle of Berlin). So, it pains me to see this kind of off-hand dismissal. I guess we all hope that this ends up not being the turn of history, _but_ the point that this matches the beginnings is not easily disproven by asking if the started killing yet. (WTF?) &gt; it seems strange to single out MS as 'bad' for selling some business software to the government. Yosh is _not_ singling out MS (they are the subject of this news) and not singling out due to "seeing some business software to the government", but to ICE and bragging about the efficiency improvements there. That's a little different. 
Of note, source code has `Copyright (c) Red Hat Inc.`.
But is easy installable as it is available in HomeBrew and probably in other package managers too.
The ideal case is that we have better APIs that don't need unsafe for this. Hence, a hack to workaround a deficiency in the API (ultimately caused by language restrictions as thiez said).
Certainly. I would love for Microsoft to terminate that contract. But that doesn't change anything about Microsoft's use of Rust, or ICE's use of *literally email and calendars*, for which there are several FOSS solutions. Should we give up on free software altogether because evil people happen to use tools?
It would be neat to introduce a fixed version of `Borrow` and make `HashMap` use it, something like that, I suppose: use std::borrow::{Borrow, BorrowMut}; pub trait IntoBorrow&lt;Borrowed&gt; { fn into_borrow(self) -&gt; Borrowed; } impl&lt;'a, T, U&gt; IntoBorrow&lt;&amp;'a U&gt; for &amp;'a T where T: ?Sized + Borrow&lt;U&gt;, U: ?Sized, { fn into_borrow(self) -&gt; &amp;'a U { self.borrow() } } impl&lt;'a, T, U&gt; IntoBorrow&lt;&amp;'a mut U&gt; for &amp;'a mut T where T: ?Sized + BorrowMut&lt;U&gt;, U: ?Sized, { fn into_borrow(self) -&gt; &amp;'a mut U { self.borrow_mut() } } impl&lt;'a, T, U, W, X&gt; IntoBorrow&lt;(&amp;'a U, &amp;'a X)&gt; for &amp;'a (T, W) where T: Borrow&lt;U&gt;, U: ?Sized, W: ?Sized + Borrow&lt;X&gt;, X: ?Sized, { fn into_borrow(self) -&gt; (&amp;'a U, &amp;'a X) { (self.0.borrow(), self.1.borrow()) } } impl&lt;'a, T, U, W, X&gt; IntoBorrow&lt;(&amp;'a mut U, &amp;'a mut X)&gt; for &amp;'a mut (T, W) where T: BorrowMut&lt;U&gt;, U: ?Sized, W: ?Sized + BorrowMut&lt;X&gt;, X: ?Sized, { fn into_borrow(self) -&gt; (&amp;'a mut U, &amp;'a mut X) { (self.0.borrow_mut(), self.1.borrow_mut()) } } fn main() { let tuple = (String::from("a"), String::from("b")); let _x: (&amp;str, &amp;str) = tuple.into_borrow(); }
"Analyze assembly" approaches have been explored in academia, but are way too fragile for any practical use. If we could fuzz C/C++ code and find all the bugs that way, we wouldn't have needed Rust for security in the first place. AFL inserts "hey, this code was reached!" callbacks on every if branch, looks at what paths through the ifs a randomly generated input takes, and once that it hits a new path it remembers it and starts mutating it. ([More info](https://lcamtuf.blogspot.com/2014/11/afl-fuzz-nobody-expects-cdata-sections.html)). This works well enough to find real bugs in binary parsers, but is by no means exhaustive. AFL itself works poorly for text formats. [You can improve coverage by using a mutation strategy tailor-made for your format](http://www.vegardno.net/2018/06/compiler-fuzzing.html), but you're still just scratching the surface if you're facing something complex, like a compiler. Notably, ALF-like tools it will never discover security bugs that depend on e.g. four bytes in a row being set to a single special value, and a private function in `inflate` had exactly such a bug: you needed one variable set to 13 and another one to 40959 in order to exploit a memory disclosure vulnerability, and you also need to be running the fuzzed process under memory sanitizer to notice it even if you're amazingly lucky because it does not result in a crash or even a different path through ifs.
Thanks for the informative reply!
No one said anything of the sort; your response is absurd. What I believe is that we, as people of good moral character, should take this opportunity to respond to this news unequivocally: Microsoft Azure is entitled to use Rust according to its license, but we see nothing to celebrate in its usage until Microsoft Azure stops collaborating with ICE.
because micro-kernel architecture. hur hur hur(d) (I'm sorry that my joke isn't funny.)
Sorry, I may have badly explained my point: I grew up using C then C++. It is not a question of habit, but only a question of readability in my opinion. When I discovered C++ after C, I was glad they have the `not` keyword.
TBH I also prefer `and`, `or`, `not` over `&amp;&amp;`, `||`, `!`. It doesn't matter, though: Rust chose the C style boolean operators, and they're not going to change now. If you have readability issues, you can switch your font. I don't believe it's worth expanding the prelude for this.
It could be on the T of the Result type though couldn't it?
Neat, I didn't realize that a function nested in an unsafe function is a safe function. 
* https://github.com/fafhrd91 * https://www.linkedin.com/in/fafhrd/de
Why do I need parens around this match block: `match 2 { _ =&gt; true } &amp;&amp; true` like so `(match 2 { _ =&gt; true }) &amp;&amp; true` ?
It's different as we have actual code open sourced for Azure IOT Edge, unlike Office.
A good rule of thumb is that a reference or pointer doesn't exist unless it is used. Within the bounds of one function, you shouldn't be able to mutate the same value through disjoint mutable references and you shouldn't be able to mutate a value through an immutable reference unless it transitively contains an `UnsafeCell`. This is because if you have an immutable reference the compiler must be able to (for example) reorder reads around function calls, so this: let val: &amp;_ = ..; let a = *val; foo(val); let b = *val; Can be transformed into this: let val: &amp;_ = ..; let a = *val; let b = a; foo(val); Skipping one memory access and improving performance. There isn't a formalisation yet, but in general it's OK to mutate through a raw pointer that's derived from a mutable reference, but if you turn that back into a mutable reference you should invalidate the original reference.
Did you try to do some kind of a comparison of resource (esp. memory; ideally also CPU) usage between Tantivy and Elasticsearch/Lucene? Even some quick &amp; rough one would be very interesting to me!
Please never sell Rust to Microsoft!
Yes. Let me answer you in pm because I'd like to wait a little bit before making that public info.
Until the next discount starts...
Is this used for Eclipse Photon to provide the integrated Rust support? Or is this separate from that and an additional alternative method of getting Rust support in Eclipse?
How good is it even?
Yay ! I was looking for a supported Eclipse plugin, if it uses the language server, it's perfect! Thanks for the link.
Oh god... i hate the new `crate` visibility syntax. This is disgusting.
For memory... I didn't check. Tantivy has almost no anonymous memory footprint. The memory is the mmapped index so 5GB for wikipedia. If your machine is tight the OS will just discard the least accessed pages from pagecache. (Usually thst's parts of your position file) I am not sure which codec elastic search uses but I thought it was roughly similar with a few 100s MB for java's heap &amp; loaded classes. 
Of course, the whole talk is worth watching! Matt Godbolt is great. For those who don't know, he is the creator of the "compiler explorer", a web tool to explore the assembly code generated by your compiler. And [it supports Rust](https://rust.godbolt.org/) :) To be honest, while watching him talk about the benefits of C++, I couldn't help but think "yeah, Rust has that feature too, but better" fairly often :P
I honestly cannot believe that the "Godbolt" in "Godbolt compiler explorer" is actually \*his last name\*.
”maybe I’ve stunned you all into a catatonic silence now” lol
The article explains that "False Sharing" only results in performance issues, not, that it results in "Last one Wins".
Doesn't mean those mistakes have to repeated...
Ah great, that was the part I missed. I already thought all I know about how all this works was wrong! Thanks a lot for the super-fast answer
Hmm not familiar with Udemy, found the course and enjoyed it.
Not sure, I enjoyed and found it helpful. It is pretty basic thou.
Beware, dark theme is not necessarily good for your eyes: https://tatham.blog/2008/10/13/why-light-text-on-dark-background-is-a-bad-idea/ There are also extensions on marketplace to allow customization of themes if you want your own. What is it you call "ergonomic block marking"?
That being said, it'd be interesting to explore whether LLVM, when compiling Rust code, considers any of this during its optimization passes. If not, it could result in some bad performance that could otherwise be mitigated.
The licence is EPLv2, which is a pretty nice OSS and business friendly licence. The copyright of Eclipse.org code still belongs to those who wrote the code; Red Hat in this case; but because of the nice license, it doesn't really matter.
Because there are two ways Rust can parse "control flow" constructs like `match`: as an expression, and as a statement. They are always parsed as a statement *unless* they appear in a position that requires an expression. Thus, what the compiler is seeing here is two statements: `match 2 { .. }` and `&amp;&amp; true`, the second of which is obviously not a valid statement. If it didn't do this, you'd have to always put a `;` after a `match`.
Yes, it is the plugin that's used in the "Eclipse IDE for Rust Developers" package.
``` let &amp;Foo(x): &amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23); // x is i32 let Foo(x): &amp;Foo&lt;i32&gt; = &amp;&amp;Foo(23); // x is &amp;i32 ``` I'm pretty sure the first case occurs because i32 is `Copy`.
Sure, but why does adding the `ref` cause a type mismatch?
Any ideas why Rust didn't auto-vectorize in the case he gave an example of?
If someone is interested here is the snippet which was shown in the talk: https://godbolt.org/g/nwZ4tx Autovectorization in the highlighted part kicks-in if we'll change `-C opt-level=2` to `-C opt-level=3`.
That would have been a more correct question, but I actually thought that async/await was an alternative to Tokio. 
I'm glad to know that I'm not the only one in roughly the same position of begrudgingly accepting that synchronous clients may make the most sense for now. 
It's really hard for the compiler to keep track of. You're best off keeping track on your memory block sizes and alignments to minimize false sharing when designing a program. I too would love to hear if any mitigation strategies exist in the compiler but I doubt they are smart enough that you still don't have to manually consider it.
**[Top comment on /r/cpp](https://www.reddit.com/r/cpp/comments/8ua7tr/matt_godbolt_why_c_isnt_dead/e1e0ts7/)**
Have a look at the [Lisp loop macro](http://www.gigamonkeys.com/book/loop-for-black-belts.html). After getting used to it, its quite nice: for i from 0 below 10 // 10 is not included for i from 0 upto 10 // inclusive 10 for i from 0 downto -10 // includes -10 for i below 10 // 'from 10' can be left out for i from 0 below 10 by 2 // step wise increment counter by two for i from 0 below 10 when (&lt; i 6) // only numbers below 6 I would also love to see an `--example` flag for every command so that it would be possible to write `loop --until-match --example` and see some code examples on how to use it. This way I don't have to lookup online for a example. 
Thanks! What do you mean by "anonymous memory footprint"?
Yes, true, but I wonder if something like [Rayon](https://github.com/rayon-rs/rayon) could/should/does take this into consideration when parceling work?
See [this comment](https://www.reddit.com/r/rust/comments/8uhyj4/matt_godbolt_why_c_isnt_dead_he_talks_about_rust/e1fkxyu/). Also: later in the video (around 1:33:30), he gets asked about this snippet. And when he turns the `f32` into `i32`, it is auto-vectorized. He says something about fast-float. So apparently Rust/LLVM doesn't optimize because `a + b` is not necessarily the same as `b + a` for floating point numbers. Or something like that. The C++ example apparently allowed for relaxed floating point precision. 
Well, I made it 100 seconds instead of 10,000, but, only one process for *loop* and one for the command were ever generated. It repeated every 100 seconds. So, that would be the correct behavior, in my opinion. 
I would also be interested. A recording would be great!
Anonymous memory = non mmapped memory. Tantivy and elastic search rely on mmap a lot. The RAM you use is mmap + anonymous memory. In tantivy anonymous memory is extremely small. In ES I don't know. 
I was blessed with a very cool last name :)
I'm not sure that's doing autovectorizing; it seems to be doing something different for certain, but not doing more than 8 bytes at a time. I'm on a cell phone and Compiler Explorer doesn't work well enough to be sure though. Later on an attendee points out the autovectorizing is inhibited because of IEEE rules, and we rewrote the example using integers, and definitely saw vectorisation. If opt level 3 turns on the equivalent of -ffast-math then maybe it's vectorizing I guess.
Yes, I used -Ofast in the C++ version which is the same as -O3 -ffast-math :)
Didn't like 3 months ago ruby removed a trace command that was put for each opcode in production, but was never used? So basically they got a 30% improvement by removing something that shouldn't be there, but was for years? I work with ruby daily and man, that shit is reaally fucking slow, you can't compare with python and friends, specially when there are really good JIT implementations for them.
Thanks!
Yeah the `vaddss` in the hot loop is just adding single floats, not vectors. &gt; If opt level 3 turns on the equivalent of -ffast-math then maybe it's vectorizing I guess. No, rustc doesn't do that. (that would be quite un-rustic, changing behaviour depending on the opt-level)
The estimate for a while has been “on nightly by the end of the year”.
Sad but true, didn’t think of that 
Also when you use FFI, the compiler can't make some optimizations. 
So, would it be fair to say, that the auto-vectorized version sacrificed correctness (for some definition of correctness) for speed? If that is the case, that should be mentioned.
I don't think there's even a good way to enable ffast-math in rust right now without using wrapper types. Here's an internals discussion: https://internals.rust-lang.org/t/pre-rfc-whats-the-best-way-to-implement-ffast-math/5740
Having followed Ruby since the last 1.6 release: It's staggering how much they have improved it with such a small team. Just to be clear: the Rust team _dwarfs_ the MRI team by far.
That is indeed fair in this case yes. I forgot I had -ffast-math on and should have mentioned it.
That seems like an unfair comparison as that's not even a rust issue necessarily. rustc doesn't expose it but `-ffast-math` could be turned on in the LLVM backed with the same result. And there are wrapper types in rust that will do `-ffast-math'.
A reference must point to an owned object. When dereferencing, there is no object for a reference to point to.
Agreed! It was absolutely unintentional. And I was corrected later on during the questions by an astute attendee.
&gt; change `-C opt-level=2` to `-C opt-level=3` What does `cargo build` and `cargo build --release` correspond to? More generally, how can I see what commands cargo is running?
I hope there will actually be a flurry of work around these things now that SIMD is in stable. rust should be a really good language for SIMD stuff. Low-level like C but with a bunch of ways to express more complex relationships and enforce invariants through types. Should be a fun couple of years in rust land. Maybe someone will finally even crack "write-once and run on CPU or GPU reasonably well". Hand optimization will probably be king for a long time but for 90% of code that you want to be fast enough there is no time to invest in versions in straight code, SIMD variants (sse,avx,neon,etc), OpenCL, etc.
Is this for those pita impl where you have to make struct wrapper?
That's interesting. It's been a couple of years now since I've used ruby for web projects, i've mostly moved on to node. I like using rust for personal projects, but haven't touched it for web yet. My worry would be loss in productivity when you're building an MVP or something for a smaller team. Do you folks think Rust is something one can move to if they feel certain pain points that Rust would be good at solving? Or do you think it's something one can use starting out?
That looks quite interesting. I have a very simple use case where I need to do multiplication of RGB values by a matrix to get normalized RGB (colorspace conversions). I've even done a minimized example here to test auto-vectorization and rust vs C: https://github.com/pedrocr/rustc-math-bench I will see if I can use numeric-array to do that. The only thing I don't see in the `NumericArray`API is a `.sum()` so I'll have to see if iterating is fast enough. Other than that it will probably look quite clean.
I think /u/sanxiyn wanted to point out that Red Hat is paying for code supporting Rust, not the copyright.
There is now a great feature where you can annotate a single function to be optimized with a given feature set (e.g., avx). And there are crates in the works to compile the same function with several feature sets and dispatch at runtime so you can have a portable binary that's fast when the features are available: https://github.com/parched/runtime-target-feature-rs
It's not getting auto vectorised because Rust floats confirm to IEEE 704. There's intrinsics on nightly that will allow the compiler to auto-vectorised - https://godbolt.org/g/LcrZut
You can just add option `-v` behind the command, like this `cargo build --release -v`.
The CPython (reference implementatioo) does not have a JIT afaik. Also, last i checked actual benchmarks, Ruby was comparable to Python.
But there are alternatives that are mainstream. Besides most things I ever used in python were using FFI and were not written in it. My experience with rails is that itss really fucking slow even for io bound it makes it cpu bound... CPython is not really fast, but it's just the edge, there is a shitton more to optimize python out of the box. My experience with ruby has been, well this is life, fire up another machine.
&gt; "write-once and run on CPU or GPU reasonably well" Are there libraries in other languages (or Rust) that I can look at where this is the case?
I don't think anyone has truly cracked it yet in any language. You can run OpenCL on the CPU and there are a few more experimental projects that seem interesting: http://halide-lang.org/ (does CPU and GPU but focuses on image processing in particular) http://ispc.github.io/features.html (targets only CPUs but the model seems extensible to GPUs in the future)
As is `loop`..
Just started learning Rust. C++ has `auto p1 = std::make_unique&lt;int&gt;(42)`. What's the equivalent code in rust? 
Would you really want to crack it though. The way GPUs and CPUs execute is so different that they're not really interchangeable. What possible workload would you really get value out of being interchangeable? 
Yes, OpenCL.
Maybe in Brew (however I do not see it in `brew search loop`), but I do not see it it MacPorts nor Nix. Also I cannot use it on many servers that I manage without building it from source (ARM machines). So `watch` is way to go for me. Sorry, but I see little to no point for this utility as almost everything can be made easier by using tools already available to me as it would be useful in one-shot tasks, and manually compiling it just for that just misses the point. I prefer to use `xargs`, GNU `parallel` or just plain old shell loop, battle tested, popular, and have manpage for them. This is nice learning project, but for real life administrators it has no value. 
`Box::new(42)`.
Because negation is (often) a "nicht" suffix in german whereas in english it's a "not" prefix.
Have a look at [cache coherence](https://en.wikipedia.org/wiki/Cache_coherence)
well jruby is also an alternative that is mainstream and is naturally JITed. &gt; Besides most things I ever used in python were using FFI and were not written in it. Ok...so you're now comparing C extension performance to Ruby performance. Plz stop. 
FWIW, Rust was chosen by those developers mostly because it's hype and requires good tools; it shouldn't be interpreted as one strategical move from Red Hat as a whole towards Rust. It's more a strategical move for Red Hat towards faster adoption of languages in the Eclipse IDE through language servers.
The point is the usability, my python code is IO bound, the CPU bound is always a FFI. In rails my CPU bound endsup being solved by ruby. That's the point. Out of the box python is way faster.
Thanks for the quick answer. 
What are the differences from gfx-rs?
Seems like you're just babbling incoherently tbh.
IIUC, `&amp;Foo&lt;i32&gt;` coerces `&amp;&amp;Foo(23)` to `&amp;Foo(23)`. `&amp;Foo(x)` matches `&amp;Foo(23)` with `x` as an ownership binding. This is more clear if you use a type that isn't `Copy`: ``` struct Foo&lt;T&gt;(T); let &amp;&amp;Foo(ref x): &amp;Foo&lt;Foo&lt;i32&gt;&gt; = &amp;&amp;Foo(Foo(23i32)); // expected struct `Foo`, found &amp;Foo&lt;_&gt; ``` Without the coercion, it works fine.
There are some guides and open source projects. They work fine.
There is no reason to use C/C++ in my opinion. Rust only has advantages. It does take some setting up though.
https://github.com/MaikKlein/rlsl
That was the understanding I had, but misreading the Intel article made me believe that this was actually wrong and they do weird things nowadays in the name of performance. Fortunately I just misread.
Sure, but that's not the part that's confusing me. In contrast: struct Foo&lt;T&gt;(T); let Foo(x): &amp;Foo&lt;String&gt; = &amp;&amp;Foo(String::new()); compiles, with `x` being `&amp;String`, so far so good. But: struct Foo&lt;T&gt;(T); let Foo(ref x): &amp;Foo&lt;String&gt; = &amp;&amp;Foo(String::new()); does not compile. It says error[E0308]: mismatched types --&gt; src/main.rs:3:36 | 3 | let Foo(ref x): &amp;Foo&lt;String&gt; = &amp;&amp;Foo(String::new()); | ^^^^^^^^^^^^^^^^^^^^ expected struct `main::Foo`, found reference | = note: expected type `&amp;main::Foo&lt;std::string::String&gt;` found type `&amp;&amp;main::Foo&lt;std::string::String&gt;` So changing the pattern `Foo(x)` to `Foo(ref x)` inhibited the coercion of the outer type somehow. This is exactly the same for `&amp;Foo(x)` versus `&amp;Foo(ref x)` patterns. This is one of the reasons I have a dislike for these ergonomics changes. In many cases I have no idea anymore why some stuff compiles and other things don't.
&gt; What's the point of all this ceremony? The function /u/DroidLogician mentions was recently added to reduce this, but it didn't exist for a long time because while it's convenient, it's only barely shorter, and is strictly less flexible. Writing those three lines enables you to re-use `contents`, saving on allocations. It took some time to debate if it was worth adding the convenience to the standard library, since it was extremely easy to write your own three-line function yourself if you really wanted those semantics. Stuff in the standard library has to exist for all time, so it's a pretty high bar. Eventually, we decided it was worth it, specifically because of this kind of feedback.
I count myself among those whith a cool name: - First name is Dos - In Spanish it's the number of digits in the binary system, so related to computers. - Also there is an OS called DOS, you, the reader, may have heard of it. Again related to computers. - Last name is Moonen - let's ignore that it is spelled the same as the word for mooning in my native language. (Dutch.) - when you pronounce D. Moonen in dutch it sounds like demonen, which means demons. Linux has daemons, I think it counts as being related to computers... - bonus: my sister and I are demons! No, my parent's didn't name me after an OS... My mother's uncle didn't like his first name, Dolf, some time between WWII and me being born. Door Oefening Sterk translated literally would result in By Practice Strong or something like that. Which was kinda like his sports motto or something... (Might have been the name of a Gym, or his Gym, or...) Anyway, I look forward to watching that talk when I get home.
&gt; I have no idea what the dangers of multiple &amp;mut to the same location existing are, If somewhere in your program you have multiple `&amp;mut` to the same location, that's undefined behavior. What you can have is multiple `*mut` pointing to the same location.
In that case, your code sample IS undefined behavior if NonCopyDrop is a &amp;mut T.
I am by no means an expert in Rust, and I'm still much more comfortable in Python (and more recently, C#). My perspective on when to use/switch to Rust is that I'd prefer to start out using Python, simply because I can get stuff done much faster than in any other language (although if we're comparing Rust to C++, Rust definitely has a lot more helpful built-in features; things like being able to debug print non-trivial data structures is a huge win). Then, if and only if performance is insufficient, I'd consider switching to Rust. Unless I know performance is going to be crucial and speed is a priority, I wouldn't start with Rust from scratch.
Hmm, `NonCopyDrop` is just a struct there. I've edited my comment above a bit to include some caveats, don't know if this still applies.
I don't disagree, as I've said three times now. Microsoft should end their contract with ICE. Microsoft employees should work to make that happen. My point is that the services Microsoft is providing there are the same services they're offering everyone, one the main points of free software licenses. So just as we wouldn't see "nothing to celebrate in Mozilla's usage of Rust until ICE stops using Firefox," there is no reason to ignore the Azure IoT work- which is unrelated to the ICE contract anyway.
The problem is... Rust... and I think its a good thing. In Rust trade-offs are explicit, which means you can get worse performance if you choose the wrong trade-off. In this case, you are defining a type, and want to operate on it in a data-parallel way. If you define your `Pos` type to contain its data in a packed vector, then your code becomes shorter, and you get much better code generation: https://godbolt.org/g/DBL93i However, putting data in vector registers is typically slower if what you end up doing is only scalar operations on it (e.g. only working on the `x` component of your vector without touching the `y` components.
How should it? Suppose you have the following code: struct Thing { // ... } impl Thing { fn apply(&amp;self) -&gt; &amp;i64; } Then the result of `apply` is either contained inside `Thing`, or it is a global. Either way, it already existed before you calculated the function. It wasn't computed, just passed. The same applies to your case. `deserialize(&amp;'a str) -&gt; T` can return a `&amp;'a str)` because it already existed before you called the function - it's part of the argument, after all. However, `T` can't be a `&amp;SomeRecord(String)`, since the record didn't exist before you called the function. There was a post linked on this subreddit about that principle, that for example `fn thing&lt;T&gt;(t : T) -&gt; T` *must* be the identity function, but I'm too lazy to search for it.
Better stay distributed. Still, I laughed :D
there's already xeon-phi, intermediate between CPU and GPU, and there are intermediate processors being developed for AI. the proposed hwacha vector engine for RISC-V is also intermedaite (they say 'ditch traditional CPU-SIMD and make an integrated vector accelerator that can do everything GPGPU is doing now' basically. although this is taking years to play out, I do believe it would be more elegant to fully integrate the 'main computation engine' (which is what GPUs have become..) with the CPU instead of it being this bolt on requiring seperate APIs
This kind of dubious metric is as old as the hills. I remember a presentation entitled something to the effect of "We got a 10x speedup by rewriting our C application in C." Turns out when you rewrite something you have the benefit of hindsight.
https://phaazon.net/blog/luminance_comparing
Heavy SIMD CPUs and GPUs are adequate for the same kinds of processing. At least in image processing it's often not worth it to do the round trip to the GPU for some operations because the CPU is more than fast enough and memory transfers to/from the GPU are expensive. And that's very often hardware dependent so you can't even do a fixed decision of OpA I'll write it to the CPU and OpB I'll write it to the GPU even if you had a guarantee you always had a GPU. If you could write a reasonable implementation that is compiled both into AVX and SPIR-V you'd have two targets that are guaranteed to give the same results and are not as optimized as doing manual optimization so you're leaving performance on the table. But the alternative isn't to have hand-rolled code for all targets, the alternative is often to only have a CPU solution. If you suddenly had decent AVX and SPIR-V kernels you could with much less effort invest in a bit more code to benchmark the specific hardware you are running on and making a slightly better decision. The end result would be something like having an image editor run a quick benchmark suite on startup to decide which ops to run on CPU and which on GPU and have those settings used throughout the user session. If we could get good rust crates to handle some of this complexity it would be used in a lot more situations and suddenly everyone would use it because it's just a few imports/annotations/code structure changes. Each individual app wouldn't be fully optimized, and the ones that want performance above all will still hand-roll per target but a lot more apps will take advantage of this so in total we'd have much more efficient software.
You can work around this limitation by using [`Cow`](https://doc.rust-lang.org/std/borrow/enum.Cow.html) in `RecordHasAProblem`. So you can use a borrowed `SomeRecord` in your errors for efficiency, and serde would deserialize into owned variant. [Playground](https://play.rust-lang.org/?gist=1be9890d12a4d27104036ffafa69c605&amp;version=stable&amp;mode=debug)
&gt; So changing the pattern Foo(x) to Foo(ref x) inhibited the coercion of the outer type somehow. I think I found it: let ref y : &amp;Foo&lt;Foo&lt;i32&gt;&gt; = &amp;&amp;Foo(Foo(23i32)); let Foo(ref x) = y; I don't know if there's a way to combine those statements into a single pattern, but it presents the same error.
Actually the first line alone already seems to have the problem.
Thanks! Here's a test run, for others who want to see what it does: ~$ cargo new minimal Created binary (application) `minimal` project ~$ cd minimal ~/minimal$ cargo build -v Compiling minimal v0.1.0 (file:///home/bromskloss/minimal) Running `rustc --crate-name minimal src/main.rs --crate-type bin --emit=dep-info,link -C debuginfo=2 -C metadata=e2cc902f4b4deae9 -C extra-filename=-e2cc902f4b4deae9 --out-dir /home/bromskloss/minimal/target/debug/deps -C incremental=/home/bromskloss/minimal/target/debug/incremental -L dependency=/home/bromskloss/minimal/target/debug/deps` Finished dev [unoptimized + debuginfo] target(s) in 0.46s ~/minimal$ cargo build -v --release Compiling minimal v0.1.0 (file:///home/bromskloss/minimal) Running `rustc --crate-name minimal src/main.rs --crate-type bin --emit=dep-info,link -C opt-level=3 -C metadata=9f0b90135c31f5eb -C extra-filename=-9f0b90135c31f5eb --out-dir /home/bromskloss/minimal/target/release/deps -L dependency=/home/bromskloss/minimal/target/release/deps` Finished release [optimized] target(s) in 0.29s Summary of differences: debug | release -|- `-C debuginfo=2` | `-C incremental=/home/bromskloss/minimal/target/debug/incremental` | | `-C opt-level=3`
This is how I'm testing one of the libraries I'm writing. All of the methods I have take the generic `Read + Write`, and then I use [Mockstream](https://crates.io/crates/mockstream) to test. 
Adequate, maybe, but even remotely close to optimal, not really. You're adding a huge amount of complexity for a really minimal payoff. I mean I'm sure workloads exist for it, but I'm struggling to think of one. Code architecture for a CPU and code architecture for a GPGPU are just too different, and expecting the compiler to sort that out for you is a really big ask. 
Yeah. I included the 2nd line because it's part of the desugaring.
Please call your kid Zeus
You should include this in your `.gitlab-ci.yml` so that you can cache the compiler's output and other dependencies. cache: paths: - target/ 
And his Daughter Roxanne 
I attempted a comparison of Rust and C++ in 2020 [here](https://www.reddit.com/r/cpp/comments/8ua7tr/matt_godbolt_why_c_isnt_dead/e1g764k/). Review/Correction would be welcome, especially with my estimates of when some Rust features should land.
One of the nice things about Rust is that it's relatively easy to pick up chunks of code and shuffle them around between modules. You might have to fiddle around with names a lot but the compiler won't let you actually break anything.
Not unreasonable, but it's perfectly reasonable to have something be its own function even if it's only used once. The truism is “Programs must be written for people to read, and only incidentally for machines to execute.” This is not a big deal when it's only one person working on a relatively small or short-term project, but the more people are involved and the longer the project gets worked on the more important it becomes.
That's... most often true. In the case of a dynamic language calling into a compiled language, such as here, you're probably toast indeed. In the case of a compiled language calling into a compiled language, you can (1) compile both to IR and (2) use link-time optimization to merge the two IRs together and optimize across language boundaries.
I get what you're saying and Windows 10 definitely sucks, but that's just one of their products. There are also many alternatives to this product that are completely free to use (namely Linux distros). Why not use one of those instead? If enough people make the switch, Microsoft will listen.
give us --ffast-math =)
We sympathize with your frustration, but you'll need to give more context about how your crate is structured before anyone can try to diagnose the issue. 
Or Thor
This is a real shame. Eclipse headlines their annual release with first class Rust support, [provides packaging](http://www.eclipse.org/downloads/eclipse-packages/) for Rust development, and the response on r/rust is to grouse about the UI and call Eclipse cancer. This isn't a small signal of support for the Rust language. I'm sure the RedHat team who put this together for you will just take it on the chin and move on. They are professionals.
&gt; As a result, a rebuilt system gets the benefits of a new tool mixed in with the substantial benefit of being built with a better understanding of the core problem. https://en.wikipedia.org/wiki/Second-system_effect
&gt;I cant believe that you say that, when you can clearly see the clusterfuck called windows 10. Windows 10 is the endpoint of a &gt;10yr strategy to try to make windows subscription-based. Unfortunately, every attempt MS has made at making it's OS unit profitable has failed. Windows marketshare is declining, the Xbox division is breaking even, and Zune and Windows Phone were failures. I suspect the strategy for Win 10 is to maintain the appearance of being a Tier 1 product long enough to achieve unified cross-platform + web codebases for Visual Studio, Office, etc. I don't have proof, but just follow the money - MS's profits come mostly from Azure and their business software. On the Azure front, they're doubling (tripling?) down on Linux, and on the business software front, the signs point to them working towards a unified cross platform codebase. Add to that users' increasing reliance on phones, tablets, and chromebooks, and the entrenchedness of MacBooks, MS will have a hard time clawing away marketshare on the low end \*and\* on the high end. The titanic (Windows) is sinking, it's just going to take a long time before it finally does under.
I don't see why a system level language necessarily has to be verbose. Anyway, Rust has much cleaner and simpler syntax than C++ (for example generics/templates, closures etc.), but in general explicitness and readability is prioritized over reducing verbositity (which mostly is a good thing IMHO). One might argue that C also has really simple and clean syntax, but it also lacks a ton of language features that Rust and C++ has.
What is this used for?
I absolutely agree that C++ also needs to catch up with Rust. However, to be fair: - Template specialization: "a few kinks to iron out" sounds too optimistic to me. AFAIK there is at least still one serious soundness holes and no one has really figured out how to fix it. I remember an "eureka moment" a few months ago but haven't heard anything new about it. Also, it won't be as powerful as C++'s template specialization, due to Rust's "no breakage" philosophy. Basically, Rust is fairly strict in what is allowed for specialization. The specializing impl needs to be strictly more specialized in all cases. And "in all cases" is more difficult than one would think, because Rust considers every possible implementation of traits that might happen in the future. Take a look at [this question about implementing `std::remove_reference` in Rust](https://stackoverflow.com/questions/51026536/implement-something-similar-to-cs-stdremove-reference-in-rust) and [this question about something similar](https://stackoverflow.com/questions/51022636/mismatch-between-associated-type-and-type-parameter-only-when-impl-is-marked-de). The more I try to use `#![feature(specialization)]` the more I notice how many problems it *can't* fix. - Template templates: (on terminology: ATCs are called GATs -- Generic Associated types -- now.) GATs will already be powerful and solve *most* problems that can be solvable with higher kinded types. But they are not equivalent to having full support for HKTs. Correct me if I'm wrong, but AFAIK in C++, everywhere where you can have "normal type parameters", you can also use template templates, right? - Variadic templates: Sure, not as useful as in C++ (tuples are awesome!), but they would still be useful in Rust. The past few days I was working on a type that needs to store a heterogeneous list of stuff, with full type information preserved. There is the crate `frunk` which is pretty awesome, but also still pretty limited. I got it to work, but it's *really ugly*. In particular, it would be really useful to say "all types in this list have to satisfy these bounds" (`List...: MyTrait` or something like that). I'm sure Rust's solution to variadic templates will be closely related to tuples. (The more I think of it... the language delta might not be too great for a basic version of variadic templates). Anyway: I think Rust needs this feature. 
Weird, I'm pretty sure the commutative law holds for floats (though the associative law does not).
I totally agree with you, i am in fact writing this from solus. :)
People love to hate Eclipse nowadays. 
You were able to say the same thing that i wanted to say, but yours was way nicer. Have an upvote :) I am also glad about visual studio code and typescript, i am even using them, although i am a linux user.
Is there a reason for const_fn?
MRI has a JIT these days, but it hasn’t shipped yet, I believe.
I have many times wondered if delivery routing algorithms were something that I would be able to offer companies, or if everyone already has good ones, or if there already are such services readily available for low prices. Does anyone know what the state of affairs is? What companies use automated route optimisation, and how sophisticated are they?
[@shoez's latest tweet](https://i.imgur.com/NXPyn2c.jpg) [@shoez on Twitter](https://twitter.com/shoez) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
I must have a look but yes, I used to use them. However, you installed a doubt in me. :D
When I removed the feature it compiled, but I didnt test it ebcause im to lazy to set up make on my laptop.
The C language is simple (no abstractions). But this means that C programs are complex and verbose, because things like memory management and error handling are not abstracted away. C++ and Rust, in contrast, have abstractions. This makes the language more complex, but the programs much simpler. In terms of syntax, C's syntax is the simplest. Rust's is mostly like C++, but fixes some of the parsing issues. Also, because some of Rust's features are implemented as templates, Rust can use a simple syntax where C++ has to use templates. One example is tuples.
Have you tried any of the alternatives like Zsh or Fish? Personally I use Zsh and am quite happy with it.
I have mixed feelings about this. On the one hand, making it easier to produce educational examples with a library is nice. And certainly having more documentation is a good recommendation. On the other hand, a library like *ring* is designed to be a building block for implementations of TLS, SSH, and other higher level protocols. Is a higher level API for *ring* even an appropriate thing to have? In a real sense, TLS is the higher level API. To be more concrete, what might a high level encryption function look like? Presumably it would take something like `plaintext: &amp;[u8]` and `key: &amp;[u8]`, and return a `Vec&lt;u8&gt;` ciphertext. That's a performance-for-usability tradeoff that seems ok. But then I imagine it would also generate a fully random nonce and include that with the ciphertext, since nonces are even trickier to get right than in-place encryption. Now this high level function probably isn't usable in a real production protocol, where the protocol usually wants to choose the nonce. Including an argument for associated data risks confusing people further, but again omitting it rules out more real world callers. If the function is only useful in examples and classroom work, does it make sense to include it in the *ring* API?
This is great info, thank you!
Udemy is well known for running 70%+ discounts pretty much all the time.
Howdy! Criterion.rs maintainer here. For your first question, I think you can move most of the setup to before the `bench_function` call. You might run into some ownership problems, but I think those should be solvable. I should probably document this better, but in general, there are three important regions of benchmarks in Criterion.rs: fn my_bench(c: &amp;mut Criterion) { // One-time setup code goes here c.bench_function("my_bench", |b| { // Per-sample (note that a sample can be many iterations) setup goes here b.iter(|| { // Measured code goes here }); }); } As for your second question, although technically you could configure Criterion.rs to do this (set sample count to 1 and the warmup/measurement time to very small) this isn't really a use case that Criterion.rs supports very well. Could you explain why you want to run a single iteration of your code?
Neat! You're really keeping up on your demoscene tool coding.
I'm writing an image processing pipeline. Most of the operations are so simple that I struggle to see how it's not possible for a compiler to do a good job with them. They're things like multiply every 4 values of this buffer with each of these 4 4-wide vectors, sum the values and put them in each of these 4 values of the output buffer. There's not even many ways to describe this in high-level code.
Would you say you oppose the FSF because their definition of free software prohibits restricting the use of the software in any way? E.g. the JSON license includes the clause: &gt; The Software shall be used for Good, not Evil. This clause has made a lot of people very angry (e.g. Debian). What clauses should be added to the Rust license to prevent use for 'evil'? Or should open source get a free pass in the 'moral duty for technologists' department?
Fantastic! I'm lost in the API though, how would I start a server which serves both HTTP (static files, get, post) and WebSocket connections on the same port? I've been looking at the webchat and static files examples but can't see how to bring the right function calls together.
yeah, it is, but you would also need associativity in adition to commutativity to be allowed to reorder `a + b + c + d` into `(a + c) + (b + d)` like you need for vectorization.
First of all, thanks for maintaining it! &gt; You might run into some ownership problems, but I think those should be solvable. I think it's a fundamental problem that's not really solvable. Check out [this commit](https://github.com/KillTheMule/nvimpam/commit/9120f6a065bb034e06dd0e02d00b6af5d01b749b) where I try to move the setup code out of the loop. It fails with the error message error[E0373]: closure may outlive the current function, but it borrows `nvim`, which is owned by the curr ent function --&gt; benches/integration.rs:36:36 | 36 | c.bench_function("integration1", |b| { | ^^^ may outlive borrowed value `nvim` 37 | 38 | let curbuf = nvim.get_current_buf().expect("3"); | ---- `nvim` is borrowed here help: to force the closure to take ownership of `nvim` (and any other referenced variables), use the `mov e` keyword | 36 | c.bench_function("integration1", move |b| { | ^^^^^^^^ But now, what can I do? I can't move `nvim` into the closure, it would get consumed, and is needed in every iteration. It's not cloneable, too. But since the closure might outlive the main thread... well, I don't see a way to fix that. Do you have any hint for me? &gt; Could you explain why you want to run a single iteration of your code? I figured "I have all this complicated code, and I don't want to run benchmarks on CI, but I'd like to have CI test if the benchmarks still run (I've had trouble with this in the past), without taxing CI too much". So I don't really want "one iteration", rather "as few as possible", so I can turn the benchmark into a test on CI.
previous discussion at https://www.reddit.com/r/rust/comments/8jzyy6/rust_and_bitter_c_developers_with_jim_blandy/
My bad I missed it, seems like the url to the podcast has changed since it was posted.
I'm gonna be the detractor and say that I prefer C++ lambdas to Rust's closures, mostly due to the explicit capture list. 
Not fair! I hated Eclipse bevor it got cool!! ;)
It is used here: https://github.com/Ragnaroek/mithril to determine the optimal count of threads for mining.
I completely agree! I’ll try that when I have some spare time. :)
Maybe read the sidebar, you'll see that this place does not discuss what you think it does.
I agree that explicit captures are pretty much required for C++ because it's very easy to get runtime bugs like use after delete. In Rust you will get compile time errors for this so it's basically a non-issue.
I see, Thanks!
Does enyone know how to fix this. When i join a server my game freezes, me and my 3 friends just bought the game and it is happening to all of us. 
Just a tip in case anyone else is running a HiDPI Linux system. After installing and launching for the first time the UI was a complete mess, clearly very confused by the 2x scaling. After quitting and restarting it though, it seems to have sorted itself out and is rendering properly.
&gt;is there eny way to fix this By Rewriting It In Rust of course!
You'll find better luck getting this answered over at /r/playrust. This is the subreddit for the Rust programming language.
I mean, the post got 60+ upvotes and is 98% upvoted. My comment was saying that I wish they would update the UI because the UI of eclipse brings back unpleasant memories, which means that I remember a time when it was terrible. I'm sure they've made huge strides in improving the product, and it's important that people *see* the change. This is actionable feedback, not a put-down of hard work. This isn't about people "taking it on the chin" and having a stiff upper lip, far from it! People judge books by their cover all the time, so it's important to have the cover give off the right impression. The one super negative comment is the one you replied to, and it hasn't been upvoted.
You are partially right and i would like to apologize for my harsh words this morning. Please let me explain some points regarding Eclipse and my love-hate for it. Long time ago we choose Eclipse for our team IDE for C++ dev on the "brandnew" STM32 uC line (anyone remember the STM32F2?) for our new product line. Coming from a proprietary IDE (I will not tell you which it was in order to not hurt anybodys feelings again - it was a complete desaster...) i drove the decision into the usage of a completely FOSS toolchain (eclipse, gcc +openocd) despite hating eclipse already for its bloat. The reason we choose Eclipse was simple: It was the only IDE by that time that allowed integration of openocd and gdb. It is not easy to configure, but it is doable. And it got easier nowadays. When i make fun about Eclipse's oldschool UI, it is also one of the main points i love about it: It is conservative to the bone. And thats a good thing! Every year around midsommer you get a new version that looks, behaves and feels exactly like the last one. But from time to time you discover some little enhancements and stabilisations under the hood that make your day a little brighter. My personal opinion nowadays regarding IDE's is the following: avoid them if possible and use a simple editor+ CLI based buildsystem.. IDE's hide the details from you (thats their job) and once there is a problem in your build process you are completely lost. To come to an end: Red hat and Eclipse teams: thank you for your work. I was really surprised to see rust on board this year. Well done. Also apologies to all persons wit eye or brain cancer. I will NOT tell you which "simple editor" i prefer since the editor wars have been ended three years ago if i remember correctly.
It's Emacs btw.
Is there a way to control whether captures are referenced, copied or moved?
Yes, `|a,b,c| { ... }` borrows, `move |a,b,c| { .... }` moves and copies happen when the moved value implements the `Copy` trait. 
&gt; The C language is simple (no abstractions). But this means that C programs are complex and verbose, because things like memory management and error handling are not abstracted away. I absolutely don't agree with the notion that C has no abstractions. C in itself is an abstraction.
Ahh, of course. I've seen that before. Thanks.
In my above comment, I took C as a baseline. Of course it has some abstractions. IMO, C is a middle level language: It abstracts away the hardware specifics and offers types, structs and control flow. But memory management, error handling and cleanup in error cases are always manual and explicit. In comparison, error handling in Rust is arguably non-manual with the `?`-operator. And in C++ it is automatic and implicit with exceptions. An algorithm implementation is more readable, because the details happen under the hood. So it is fair to say that C has no abstractions compared to high level languages.
&gt; Presumably it would take something like `plaintext: &amp;[u8]` and `key: &amp;[u8]`, and return a `Vec&lt;u8&gt;` ciphertext. This is an area where a strong type system would likely allow us to pick more precise types for `key`. Many ciphers want fixed-size keys, and many cryptographic noobs don't seem to understand this fact. I've seen some libraries (e.g., [`miscreant`](https://crates.io/crates/miscreant)) that use [`generic-array`](https://crates.io/crates/generic-array) for keys. &gt; But then I imagine it would also generate a fully random nonce and include that with the ciphertext, since nonces are even trickier to get right than in-place encryption. The problem here is that many current ciphers have short nonces that should not be picked randomly. One recent approach I liked is the interface that [Keyak](https://keccak.team/keyak.html) proposed: you initialize the cipher with a **secret and unique value** ("SUV"), and you interact with it as a stateful **session** that processes a sequence of messages, for which nonces don't have to be supplied—the session-based interface takes care of making the message encryption depend on both the SUV and the message history. It doesn't make the nonce problem go away entirely, but it reduces the number of call sites where a nonce is required. Keyak got knocked off the CAESAR competition, though.
Regarding your `A Word of Warning` section - does the mutagen mutation happen to code even when not compiling in test? Would this impact actual production code?
Is there a crate that allows me to display an in-memory image? I want to work with raw pixel data and show the results in a window for debugging. I'm used to being spoiled with Java Swing, any Rust alternative?
You're looking for r/playrust , this subreddit is about the programming language called rust.
The 12x speed-up is comparing against an earlier version of the algorithm, which was already using Rust for the most expensive operations. (We've been running Rust in production for over a year now!) Comparing against a pure Ruby implementation would have shown a much bigger speed-up, even without any optimisations. Our recent project has moved even more of the computation from Ruby to Rust. We've been focusing on incrementally moving code from Ruby to Rust, without altering the algorithm. We're now beginning to optimise and parallelise what we can now that we've moved most things over.
My reasoning is more ergonomic than technical. If I forget to put a variable in a capture list I'll get a compile error in C++. If I try and use a variable after capturing it in a closure I'll get a compile error in Rust. Either way, I'm going to have to keep track of things. What I like about lambdas is that it's easy for me to see exactly where a variable is being captured, so I don't get a compilation error in the first place or have to hunt down where I need to make a copy. 
You may be interested in [rpds](https://github.com/orium/rpds), a persistent data structure library for rust. It lets you "add an element to a vector" without copy, and still use both vectors afterwards.
John Carmack on this subject: [http://number-none.com/blow/john_carmack_on_inlined_code.html](http://number-none.com/blow/john_carmack_on_inlined_code.html) Since reading this (years ago) I slowly switched to writing in style C (with liberal use of {} to create new scopes) and I've come to prefer it. YMMV :)
Urgh I feel like we should be able to do better on fp even if we can't get nice mathematical properties we could at least simplify the state machine stuff that means if someone sets your fp rounding they can break your code
I usually hear this called "theorems for free" in reference to [P. Wadler's paper](http://ecee.colorado.edu/ecen5533/fall11/reading/free.pdf).
I think it is essentially is: e.g. when splitting a slice between threads, it does so [with `split_at`](https://github.com/rayon-rs/rayon/blob/8ba64ab93068004770d002116066aa7d91d8401a/src/slice/mod.rs#L498) meaning two contiguous chunks, rather than two interleaved sequences.
&gt; but in general explicitness and readability is prioritized over reducing verbosity (which mostly is a good thing IMHO) This is not an absolute though. *Some things* are considered to be worth forcing explicitness, such as types in function signatures (to ensure well-defined API's) and mutability annotations (to make the program easier to reason about, and to help the user understand why rustc might reject a program). But in many other cases, the choice has been made to allow streamlined syntax over the "full" or "technically correct" forms (see for example the lifetime elision rules and default match bindings rules, which have rules that are more complex than they seem on the surface in order to make the experience of programming smoother).
First time I've downloaded Eclipse in years. I chose the Rust-only supported version. Code completion feels pretty fast and _accurate_. I really like the extra context you get in code completion! I am in small projects right now, though, so I'll need to try and boot up something larger to see if it's still fast. I've recommended Intellij/CLion as a Rust IDE to friends before, and this now feels like a great alternative. I'm usually a vim person, but sometimes it's nice to read and step through code in an IDE. I still wish there was a default dark theme I could just drop in, but clearly the Eclipse way is to configure it all yourself. I'm an editor pluralist so I'll keep this around.
This is the kind of verbosity you need to deal with in C++ that just isn't a factor in Rust - https://en.cppreference.com/w/cpp/language/rule_of_three Even if rule of zero applies most of the time you still need to be aware of this for when it doesn't.
Yes, you're basically correct. See also http://smallcultfollowing.com/babysteps/blog/2018/02/01/in-rust-ordinary-vectors-are-values/ However, it makes much less sense to avoid `&amp;mut`/mutation in Rust than in other languages: mutation is so much more restricted in Rust, that a function like `fn foo(_: &amp;mut T)` is essentially equivalent to `fn foo(_: T) -&gt; T`, just likely to be more efficient (due to being able to pass a single pointer, instead of having to possible move a large value in and out), and able to be called on more values (since the second one requires being able to move the value).
My last name "Redwood" pales in comparison :p
My point is that the overall execution pattern you choose is always going to be slower or at best about the same running on the architecture you didn't write it for. Maybe in a few instances it might be marginally faster, but that's going to be a rare occurance. Given that, why would you want to do it? Why slow your startup with a benchmark? Why at least double the amount of code the compiler is generating? We **know** that the best case scenario the GPU will be slightly faster, and most of the time it will be slower. Why execute it on the GPU at all then?
Redox is not a good example of is design? Can anyone elaborate?
Sure thing. I'm not saying that Redox isn't a great thing. It was the first project to seriously open up the possibility of writing operating systems in Rust and I will forever be thankful to it for that. To elaborate on bad design: there are a number of questionable (at least to me) design decisions. For example, why are schemes designed the way they are. It seems to me like if they want to change the api between usermode and the kernel, they should either go all the way or none of it. Schemes change it a bit, but they don't reconsider and fix bad design choices in posix and linux. Furthermore, Redox is simply not designed for performance. Even the scheduler, one of the most important contributors to the overall performance of a system does far more work than necessary. It exchanges performance for slightly more simplicity, which, when designing an operating system, is rarely the correct choice.
&gt;since y has to clone all of x and allocate space for it. In Haskell that is not usually the case. It simply uses a linked lists. Since values are immutable in Haskell, you can pass `x` using the pointer. Ideally you would avoid appending and instead *prepend* to the list. You would use a different data structure if you wanted to be able to append efficiently. &gt; it seems that if I were to simply use Rust without &amp;mut anywhere in my code, I could use a similar functional style and the code would be more efficient. Is this a correct assumption? It wouldn't do the same thing since it would be a destructive update. While it is not unreasonable to say Rust is faster than Haskell, it's really not easy to compare a linked list to a vector, especially when the linked list is immutable and may be involved in something like memoization. 
You could have a convention of putting `let x = x;` at the top of the closure for each captured variable. Or just leave a comment. Of course, nothing would stop you from forgetting to...but documentation can become obsolete in a lot of ways anyway.
I suppose Conway's law could be pertinent to Rust if for example the modular file system of the compiler is reflective of the company structure of Mozilla or the general Rust compiler developer community. See, thinking this made me think that Conway's law could possibly be seen in code compiled with a given compiler transitively, such that via Conway's law the compiler takes the form of the organization that develops it, and then via the compiler taking this form code compiled with it is molded by the social network form of the organization that made the compiler for it as well as the organization that made the code that it compiled. This is largely unrelated to Rust and is conjecture regarding Conway's law, but perhaps it was pertinent to this thread? This thread is pertinent to Rust! 
[Here](https://crates.io/crates/axpy) is another example that uses a ridiculous macro to rewrite linear combinations of slices into a form that can be auto-vectorized (specifically by rewriting the arithmetic expression in terms of zipped iterators). 
You're being downvoted because it's literally impossible to sell the language to Microsoft, with exception of copyrights of logos and trademarks. They cannot buy the future of the language, especially with Mozilla as its biggest financial contributors.
&gt; functions aren't even first-class values They are as of 1.26, no?
&gt;In a real sense, TLS is the higher level API. I think you're mostly right. I created \*ring\*, in fact, as part of the process of creating a TLS implementation. Later we extended it to support the crypto needs of SSH implementations. In both cases, we tried to create a usable API *that had minimal performance cost* for those protocol*s that works for #!\[no\_st*d\] give*n severe development time constrain*ts. That's why, for example, some APIs write directly to` a &amp;mut [`u8\] instead of having a nicer "output type" abstraction. Besides TLS and SSH and some other high-level crypto protocols, there are also things like Tink that try to provide a highly-usable high-level framework for cryptography. I think \*ring\* can have a more beginner-friendly API, if/when we have more time to improve the API's usability, we should do so. It is harder for \*ring\* than for other libraries because we hold ourselves to strict "no significant performance regression without an important reason" rule and some other constraints, but there is still a lot of potential for improvement.
&gt;This is an area where a strong type system would likely allow us to pick more precise types for key. Many ciphers want fixed-size keys, and many cryptographic noobs don't seem to understand this fact. That works if you want users to couple themselves tightly to specific algorithms and key sizes, and/or if you want to force users to add type parameters throughout their code to allow the algorithm and key sizes to be abstracted. In \*ring\* we try to avoid making user code tightly coupled to algorithms &amp; key sizes in this way so we've moved those checks to a very small number of runtime checks. \&gt; \[T\]his session-based interface might be something that can be offered through a generic construction on top of a nonce-based, message-at-a-time cipher. I agree that's a good way to do it. Because we want \*ring\* to be able to support TLS 1.2 implementations we can't enforce the exclusive use of such an API in \*ring\*, but we could definitely make such an API available.
&gt; A lot of people don't like some or all of these less explicit things in Rust. Personally I think a lot of that comes from dealing with languages that leave a lot more room for devils lurking in details than Rust does. I'd disagree with that. Mine and many other complaints about ergonomics I've seen directly relate to Rust, low-level programming on Rust's level, ownership-clarity, reviewability and so on.
It's also worth noting that stuff `.into()` can be made more clear with extra annotations, even if they aren't strictly necessary. I tend to explicitly type for documentation reasons when I think it'd be hard to understand what is going on. One useful side-effect is that, unlike comments, they can't be wrong in working code. 
[im](https://github.com/bodil/im-rs) is also a good one!
I thought they were even before then. What changed in 1.26?
Asking out of interest: how close mutagen is ready to be used?
What if it's just an alias for a `&amp;mut` (which isn't Drop but is non-Copy)? The following code compiles (http://play.rust-lang.org/?gist=747f95c5e2ddf35120d1f49e577dab9a&amp;version=stable&amp;mode=debug): type NonCopyDrop&lt;'a&gt; = &amp;'a mut i32; // Not actually Drop. But it is non-Copy. fn main() { use std::mem::forget; unsafe { let mut val: i32 = 0; let mut val2: i32 = 0; let mut x = [&amp;mut val]; let ptr = &amp;mut x[0] as *mut NonCopyDrop; let c: &amp;mut i32 = ptr.read(); // read value let d: &amp;mut i32 = ptr.read(); // read value AGAIN. Now we have two &amp;muts pointing to the same location forget(d); // value is only dropped once let v = &amp;mut val2; ptr.write(v); // set the source value drop(c); } } Is this defined behavior?
I haven't looked, but I'd bet the recently announced [nannou](https://github.com/nannou-org/nannou) makes it pretty easy.
impl Trait, but I don't think that can actually do much that Box&lt;Trait&gt; doesn't, at least not in this context.
What can be done with Haskell functions that can't be done with rust functions? The only think I can think of that that you'll often need to box the,, but Haskell has to do that as well much of the time (just not explicitly). 
The impl keyword in the return position allows you to return bare closures (as opposed to boxed). You couldn't do it before because each closure has an unwritable, unique type generated by the compiler. The impl keyword gets around that.
In retrospect it was a pretty bad idea to word that in a way that makes claims about other people's experiences. It's a bad habit I have when speaking off the cuff.
My quick guideline for relevancy is as follows: if the linked content contains a mention of Rust, or a mention of any software that uses Rust, then that doesn't fall afoul of the relevancy rule. If neither of those criteria are met, then we require the OP to make a top-level comment explaining the content's relevance to the subreddit.
Thanks for clarifying that for me. I noticed that the community here was allowing me to make threads like this, but I wasn't sure if it was strictly allowed or if they were humoring me. I've had trouble with various IRC channels where they have very precise definitions of what on topic content is . Places where \&gt; This rule applies to all content that does not relate to the Rust programming language Would be interpreted to mean the Rust programming language in a very direct manner, but here there is more indirection allowed it seems. 
&gt; But this session-based interface might be something that can be offered through a generic construction on top of a nonce-based, message-at-a-time cipher. That sounds like what libsodium has done with the crypto_secretstream_* API.
Actually, the `&amp;mut` reference type also exists to reduce the verbosity of `let x = vec_app(x, 5);`. Since moving a value into a function and borrowing it exclusively in that function (this is what `&amp;mut` actually means, and if you have unique ownership of a value you're free to mutate it, hence the `mut`), are the same, there's no need to write code like you suggested. You just write it with `&amp;mut`.
I saw you edited-- in what way is their first-classness not the same as in haskell? Just the lack of language idioms being built around them?
&gt;fo =&gt; for &gt;fn =&gt; fn &gt;if =&gt; if &gt;mo =&gt; mod &gt;us =&gt; use Has science gone too far?
try it, then you tell me. they are very easy to remember as they are only first two letters of keywords, and of course fast as hell to type. i might just release a verbose version for the luddites :P
Oh, I hadn't seen that one.
I’ve mainly used this in unit testing. 
Profiling on Windows without full blown VS? Sign me up.
You need the `nvim` object to be moved into the outer closure (`bench_function`) but not the inner one (`b.iter`). I've checked out your code and made the change myself; it does compile. If you just want to verify that the benchmarks are being run, I would set the sample count to 1, and the warmup time and measurement time to a very small value. I've [raised an issue](https://github.com/japaric/criterion.rs/issues/162) to look into supporting that pattern more directly, but I can't promise that it will be completed any time soon. Good luck with your future benchmarking!
Does this count external crates which are developed primarily for firefox but are not in-repository?
Could someone more knowledgeable than me tell me what the heck all that java is doing in there? And also how they have that much assembly? It's not hand written... is it?
That didn't _make_ them first-class values. Even before 1.26, you could do this: let f = |x: i32| x + 1; due to type inference, even though you could never give `f` a proper type annotation. Return position `impl Trait` is essentially just limited return type inference, which is what allows you to return closures.
Yes, because external crates are vendored in repository. See https://github.com/mozilla/gecko-dev/tree/master/third_party/rust.
I should have said please be careful with Microsoft instead. Obviously you are right, you can‘t sell a language. But there are other ways too. Take JavaScript for example. They could not buy it. So what they did was to copy some key technologies atom =&gt; vsc, webpack+babel+flow =&gt; TypeScript, and now they gain more and more control over the JavaScript world. So never say never. You can sell things in a more metaphorical way and not only for money. Please just be careful. I like rust and I don‘t want to see it one day under their control. I don’t trust them that they have changed and I think this is just a matter of time so they show their true ugly face. And maybe they buy Mozilla one day too? They really need a good browser ;)
Firefox for Android is largely written in Java. See https://github.com/mozilla/gecko-dev/tree/master/mobile/android.
Doesn't seem to work in Firefox (Nightly) for Android. 
&gt; Is this defined behavior? Its undefined, you can't ever ever have two `&amp;mut` pointing to the same location. Never ever. That's instant undefined behavior and AFAIK all rust memory models consider this at such. When you create `c` you take a `read/write` lock on `val`, when you create `d` you try to do that again and any run-time undefined behavior detector should panic.
Ah, awesome!
My only gripe is that rustfmt does not like a space after !. My decades-old preference is to let ! Breathe a little- easier to see.
&gt; Recent nightly releases &gt; you can install using the command: `rustup component add llvm-tools` So, it must be `rustup component add llvm-tools --toolchain nightly` at the moment.
How was it? Any flaws? Because despite the all excitement just RLS isn't automatically make an IDE from a simple text editor. &gt; Corrosion uses the lsp4e project to integrate with the Rust Language Server and TM4E project to provide syntax highlighting in order to provide a rich Rust editor in the Eclipse IDE. So, it's a text editor.
I mean, yes, you can do that, but I think Godbolt's point was that the original code should have been autovectorized, while here SIMD is used explicitly.
&gt; I mean, yes, you can do that, but I think Godbolt's point was that the original code should have been autovectorized, Well, the post and the tracking issue actually give many reasons while the code should not be auto-vectorized. I've tried to address that as clearly as possible in the post. At the end I think this might bolt down to Rust is not C++. &gt; Not to mention, while this code uses vectorization, it could have vectorized more than two f32s at the same time. Agreed. This is currently an LLVM bug (a couple actually). LLVM has trouble extending short vectors to match the number of lanes of the target machine.
There are several tools that can do this. Very Sleepy is a pretty good lightweight one. On mobile so no link but should be the top hit for "very sleepy profiler".
By the way, I updated my comment, after checking more carefully I noticed that the assembly is practically identical. Diff View for provided Compiler Explorer link should make the issue obvious.
&gt; My point is that the overall execution pattern you choose is always going to be slower or at best about the same running on the architecture you didn't write it for. I'm not writing it for any architecture. I'm writing very generic code that should be translatable to both architectures. &gt;Why slow your startup with a benchmark? I'd do it only on first startup and save the settings. Probably rerunning if I detect new hardware. &gt;We know that the best case scenario the GPU will be slightly faster, and most of the time it will be slower. You seem to know that, I bet against it. I'm betting that code like this: https://github.com/pedrocr/rustc-math-bench/blob/b0e3c047dcdbb2bb0fdcb29eac31f7838f83beab/src/main.rs#L46-L55 or versions of it written in more DSL like fashions, can be reasonably compiled both to CPU and GPU kernels.
`cargo install cargo-mutagen` and try it out! You'll of course need a nightly Rust of recent vintage and add the `#![feature (plugin)]` and `#![plugin(mutagen)]` annotations to your crate, and annotate your mod, impl or method to mutate with `#[mutate]`. Be sure `cargo test` works correctly. If you find any bugs, I'll be keen to know them.
It also has export as Crate, Execution and Debug support (over GDB) integration; those are not provided by RLS but by direct integration with cargo and rust-gdb
It seems you're right and csv only does zero-copy when used to serialize into a struct through serde, which is unfortunate. It seems [quick-csv](http://tafia.github.io/quick-csv/quick_csv/index.html) does exactly what you want, though.
If you annotate with `#[mutate]`, yes, mutagen will unconditionally mutate your code (for now). That's why you use `#[cfg_attr(test, mutate)]` instead.
I'm a little confused by what "zero-copy" might mean here. If there are escapes in the source, I think they'll have to be processed at some stage?
The talk that the author of im did at RustFest was excellent, too: https://youtu.be/Gfe-JKn7G0I
I'm just looking for duplicate cells in each column, so I could get away with not doing this at all. But you are right of course, for nearly every other application that would need to be done, good catch!
It does not work on my Firefox(61) for Windows too.
I don't think so, I scanned the source and it appears to be allocating for each row, see [here](http://tafia.github.io/quick-csv/src/quick_csv/src/lib.rs.html#238-241).
Diff view is awesome! I had never tried it before, thanks!
It seems you're right! Note that just because there's a Vec doesn't mean it needs to allocate: It could reuse the Vec. But it does not: http://tafia.github.io/quick-csv/src/quick_csv/src/lib.rs.html#201
I think you are looking at JS, assembly is barely visible
I think serde has a feature where they only need to allocate if there's actual escape chars in the string. Would this work for csv as well?
I didn't know about `mockstream`, looks like a great crate! Thank you!
The proper code syntax for Reddit is indenting by 4 spaces.
&gt; In comparison, error handling in Rust is arguably non-manual with the ?-operator. This is a very weird comparison, as `?` has a straight-forward relationship to a macro and C _does_ famously have macros. Maybe we're disagreeing what an abstraction is, but `?` (and its friends `From`, `Into`, `Try` etc.) are _named operations_ but I would _not_ call them abstractions.
I guess the cases where your struct (or a part of your struct) forms a logical vector ate pretty clear. Could this be a case for simple annotation. not to say the compiler could never vectorise without the annotation but to be used as a direction to the compiler 
There's 0.6%, that is 140,187 lines of assembly, which is not insignificant.
Thanks! Need to try then. 
Is it? struct Foo { u: f32, vel_x: f32, v: f32, vel_y: f32 }
I'd love such a chart for servo as well, with cargo vendor being run. It's not pure Rust, contains some C++ stuff as well. Wondering if Firefox's Rust share is bigger than Servo's C++ share and if not when we reach the tipping point.
I wrote ```rust ... ```, but it seems that reddit doesn't support specifying the language on block quotes. I prefer block quotes to indenting every single line with 4 spaces :/
I'll check it out, thanks.
You need to explicitly cast x as a f32 in your operation.
Reddit Markdown doesn't have syntax highlighting.
still Compiling playground v0.0.1 (file:///playground) error[E0308]: mismatched types --&gt; src/main.rs:7:15 | 7 | let x:f32 = 5; | ^ expected f32, found integral variable | = note: expected type `f32` found type `{integer}` error[E0277]: cannot add `{integer}` to `f32` --&gt; src/main.rs:10:13 | 10 | let x = x + 1; | ^ no implementation for `f32 + {integer}` | = help: the trait `std::ops::Add&lt;{integer}&gt;` is not implemented for `f32` error: aborting due to 2 previous errors Some errors occurred: E0277, E0308. For more information about an error, try `rustc --explain E0277`. error: Could not compile `playground`. To learn more, run the command again with --verbose.
So... what's the difference between using 4 spaces and just the three ticks \`\`\` ?
Can be and should be are not the same thing. Dual compiling this code adds massive complexity penalty to the application. This is **only** a worthwhile thing to do if some of the time you're going to see a statistically significant performance benefit out of the code in question when it's run on the GPU, but not all of the time. I'm not at all convinced that this is so, and you've provided no evidence at all that this is the case. There's just no reason to sometimes run code on the GPU and sometimes on the CPU. The tradeoff in complexity is too damned high.
still Standard Error Compiling playground v0.0.1 (file:///playground) error[E0308]: mismatched types --&gt; src/main.rs:7:15 | 7 | let x:f32 = 5; | ^ expected f32, found integral variable | = note: expected type `f32` found type `{integer}` error[E0277]: cannot add `{integer}` to `f32` --&gt; src/main.rs:10:13 | 10 | let x = x + 1; | ^ no implementation for `f32 + {integer}` | = help: the trait `std::ops::Add&lt;{integer}&gt;` is not implemented for `f32` error: aborting due to 2 previous errors Some errors occurred: E0277, E0308. For more information about an error, try `rustc --explain E0277`. error: Could not compile `playground`. To learn more, run the command again with --verbose. 
`stdsimd` is being updated in rustc, so those changes should land on nightly soon :)
Is there a semantic diff/merge tool for Rust? I think that the basic diff tools are stupid enough that there's definitely stuff to improve. For example, I'm thinking of something that would parse the source code to token trees and then do a diff.
I think you'll have to write the parser yourself, luckily if format is well know parser can be quite [simple](https://play.rust-lang.org/). BTW I think `memmap` could be a better choice for using memory mapped files.
&gt; So why would anybody use 4 spaces if three ticks look identical? Three ticks don't work at all on the regular desktop site: https://i.imgur.com/DThEtzw.png
I was curious about the assembly too, and tokei says gecko-dev contains just over 400,00 lines of assembly, so I browsed through the directory to find some hot spots of assembly (manually, with the help of `for f in *; do (printf '%s ' "$f"; tokei $f | grep Assembly) | grep Assembly | awk '{print $4, $1}'; done`). The main spots I found: * [gecko-dev/gfx/skia/skia/src/jumper](https://github.com/mozilla/gecko-dev/tree/master/gfx/skia/skia/src/jumper) * [gecko-dev/media/libjpeg/simd](https://github.com/mozzilla/gecko-dev/tree/master/media/libjpeg/simd) * [gecko-dev/media/ffvpx/libavcodec/x86](https://github.com/mozzilla/gecko-dev/tree/master/media/ffvpx/libavcodec/x86) * [gecko-dev/media/libvpx/libvpx/vpx_dsp/x86](https://github.com/mozzilla/gecko-dev/tree/master/media/libvpx/libvpx/vpx_dsp/x86) * [gecko-dev/security/nss/lib/freebl/mpi](https://github.com/mozzilla/gecko-dev/tree/master/security/nss/lib/freebl/mpi) 
Thanks! I'll try it out.
`5.0` and `1.0`
They meant `let y: f32 = x as f32 * 2.1;`
I suspect it's a new-reddit-layout versus old-reddit-layout thing; my [understanding](https://www.reddit.com/r/rust/comments/7utj4t/reddit_is_hiring_a_senior_rust_engineer/) the new layout is driven by a more-commonmark-compatible markdown renderer... written in Rust!
 ?
 Compiling playground v0.0.1 (file:///playground) error[E0425]: cannot find value `x` in this scope --&gt; src/main.rs:7:15 | 7 | let x:f32 = x+5; | ^ not found in this scope error[E0277]: cannot add `{integer}` to `f32` --&gt; src/main.rs:10:13 | 10 | let x = x + 1; | ^ no implementation for `f32 + {integer}` | = help: the trait `std::ops::Add&lt;{integer}&gt;` is not implemented for `f32` error: aborting due to 2 previous errors Some errors occurred: E0277, E0425. For more information about an error, try `rustc --explain E0277`. error: Could not compile `playground`. To learn more, run the command again with --verbose. i don't how you guys program with rust, i really like the notion of the language but i think it still has to be more mature
Still Compiling playground v0.0.1 (file:///playground) error[E0425]: cannot find value `x` in this scope --&gt; src/main.rs:7:15 | 7 | let x:f32 = x+5; | ^ not found in this scope error[E0277]: cannot add `{integer}` to `f32` --&gt; src/main.rs:10:13 | 10 | let x = x + 1; | ^ no implementation for `f32 + {integer}` | = help: the trait `std::ops::Add&lt;{integer}&gt;` is not implemented for `f32` error: aborting due to 2 previous errors Some errors occurred: E0277, E0425. For more information about an error, try `rustc --explain E0277`. error: Could not compile `playground`. To learn more, run the command again with --verbose.
Looks like most of it comes from external libraries.
Hmm, this works on 1.27.0: &gt; cat src/main.rs fn main() { let x: i8 = 5; let x = x + 1; let x = x * 2; let y: f32 = x as f32 * 2.1; println!("The value of x is: {} and y is ;{}", x, y); } &gt; cargo run Compiling headsup v0.1.0 (file:///home/rake/example) Finished dev [unoptimized + debuginfo] target(s) in 5.94s Running `target/debug/headsup` The value of x is: 12 and y is ;25.199999 What is the output of `rustc --version &amp;&amp; cargo --version`?
[Like this](https://play.rust-lang.org/?gist=1a4828476c58d349062276a771865263&amp;version=undefined&amp;mode=undefined)
I believe you should be able to use the `csv-core` crate, which is part of the same project as the `csv` crate (the `csv`uses internally
&gt; In my above comment, I took C as a baseline. "Rust has no abstractions" "Oh, I took Rust as a baseline"
&gt; Not to mention, while this code uses vectorization, it could have vectorized more than two f32s at the same time. No it cannot. The program is roughly: ```rust let mut total: f32x2; loop { total += f32x2::load(...); } total / len ``` If you want to vectorize it to four or eight `f32`s, you would have to transform that to: ```rust let mut total: f32x4; loop { total += f32x4::load(...); } let total = f32x2::new(total.0 + total.2, total.1 + total.3); total / len ``` but that changes the results because floating-point arithmetic is not associative, and that transformation changes the order in which the floating-point values are added. 
I meant clear to the programmer
What if I want to borrow `a` but move/copy `b` in the same closure?
What browser are you using? I am using chrome on a MacOSX desktop and the three ticks are rendered like this for me: https://imgur.com/a/qbvnPrJ =/
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/Dl4kF58.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e1hncvz) 
nope,sorry it didnt work i just updatede . this is the entire code. info: removing component 'rust-src' info: removing component 'rust-analysis' info: installing component 'rustc' info: installing component 'rust-std' info: installing component 'cargo' info: installing component 'rust-docs' info: installing component 'rls-preview' info: installing component 'rust-src' info: installing component 'rust-analysis' info: checking for self-updates stable-x86_64-pc-windows-msvc updated - rustc 1.27.0 (3eda71b00 2018-06-19) nightly-x86_64-pc-windows-msvc updated - rustc 1.28.0-nightly (e3bf634e0 2018-06-28) C:\Users\Tommy\Desktop\desktop\Learning_Rust\numbers_convertions&gt;cargo run Compiling numbers_convertions v0.1.0 (file:///C:/Users/Tommy/Desktop/desktop/Learning_Rust/numbers_convertions) error[E0425]: cannot find value `x` in this scope --&gt; src\main.rs:7:15 | 7 | let x:f32 = x+5; | ^ not found in this scope error[E0277]: cannot add `{integer}` to `f32` --&gt; src\main.rs:10:13 | 10 | let x = x + 1; | ^ no implementation for `f32 + {integer}` | = help: the trait `std::ops::Add&lt;{integer}&gt;` is not implemented for `f32` error: aborting due to 2 previous errors Some errors occurred: E0277, E0425. For more information about an error, try `rustc --explain E0277`. error: Could not compile `numbers_convertions`. To learn more, run the command again with --verbose. C:\Users\Tommy\Desktop\desktop\Learning_Rust\numbers_convertions&gt; does anyone know how to requste a fix i dont know how to report it sorry+ plus after microsoft im not sure if the rust code is in github or in GitLab .
That's a bit of a rare case, but: let a = &amp;a_owned; let b = b_owned; let closure = move || { ... } (In this case, you move the reference ;) )
Looks like you're using the reddit redesign beta, which apparently has a different parser for posts. Really a bit inconvenient how little that is communicated to the user. You can check the old (regular?) version [here](https://old.reddit.com/r/rust/comments/8ur1ee/how_to_make_matt_godbolts_example_faster_by/)
Oh, I thought the new version was enabled for everybody :/ I've updated the post with 4 spaces, sorry about that!
What is the source of `main.rs`? 
&gt; There's just no reason to sometimes run code on the GPU and sometimes on the CPU. The tradeoff in complexity is too damned high. That's how darktable works for example. It has hand-rolled GPU kernels and intrinsic-based SIMD code for the same ops and uses one or the other depending on the hardware it's on and the settings you set. Speedups are relevant. I'd like to do the same but with a single codebase to not get the QA nightmare that comes from the hand-rolled approach.
Most of the assembly I can find in their repository lies in third-party dependencies, mostly revolving around media encoding/decoding. This makes sense as these are highly focused projects aiming to squeeze the most performance out of whatever platform they happen to be running on. 
I invite you to the RFC I have just posted: https://github.com/rust-lang/rfcs/pull/2490
Oh, following the tree: I haven't noticed that ``` _does_ work at some places now, so I missed telling you that. Yes, my issue was that it wasn't highlighted in the browser. Sorry, I should have extended that!
FYI, to discuss this optimization I wrote an RFC: https://github.com/rust-lang/rfcs/pull/2490
Doesn't work in any Tracking Protection enabled Firefox.
this is the [main.rs](https://main.rs), I just want to explore rust , but it appers to be more complex than i thought.
Ahuh , i got it .Thank you very much.
Im sorry i think i write it wrong on the first place,anyhow Thank you very much for you time guys, any recommendation on how you did to become great rustication?
 Any recommendation on how you did to become great rustication? 
As others have stated, you need to explicitly cast `x` as an `f32` before multiplying. This works just fine for me: ``` fn main(){ //comment test let x: i8 = 5; let x = x + 1; let x = x * 2; let y: f32 = (x as f32) * 2.1; println!("The value of x is: {} and y is {}", x,y); } ``` [Link to Playground](https://play.rust-lang.org/?gist=5e71dc93853b397b7ac77c928296de75&amp;version=stable&amp;mode=debug)
Link: http://www.codersnotes.com/sleepy/
If we want it to work the same as C++, can't it be as simple as passing on the fast math flag to llvm? That's still explicit/opt-in, and is what the C++ example is doing: https://www.reddit.com/r/rust/comments/8uhyj4/matt_godbolt_why_c_isnt_dead_he_talks_about_rust/e1fmgzh/
The link you provided is broken. Could you please fix?
Rust is generally pretty easy to work with. You just happened to trip over one of the areas where, in order to avoid subtle bugs, it's more demanding than other languages. Specifically, you have to explcitly convert between different types of numbers. It complains about this line because you're not explicitly converting one of the two types (`u8` and `f32`) to match the other: let y:f32 = x * 2.1; When I copy-pasted your code into the playground and changed that line to this, it worked perfectly well: let y:f32 = x as f32 * 2.1; Here's the actual playground I used: http://play.rust-lang.org/?gist=63a01e1a6ced0305f1765978542f7ad2&amp;version=stable&amp;mode=debug
No worries! I was really confused because for me it was looking fine, and I thought that maybe using 4 spaces enabled syntax highlighting or something that wasn't triggering with the three ticks :D 
Alternatively, if you choose to remain on the redesign beta, you could click the _Switch to markdown_ button in the editor, and then you can use standard Markdown as you please.
It's not really that crucial. Most of IntelliJ uses a combination of incremental lexing (which is easy) and non-incremental, but non-allocating parser (which is not that complex if you design tree data structure in such away that it doesn't allocate). 
The issue is that there are too many problems with that. For example, you typically don't want fast math for the whole program, but for a single function or part of it. Also, you typically only want the optimizer to assume specific things like associative math, or lack of NaNs, instead of anything that somebody might think belongs behind a fast math flag (like approximative sqrts, trigonometric functions with ... unspecified precision that might be insufficient for your use case...). Also there is the tension between people developing libraries and people using them. For example, a library implementing a ray-triangle intersection algorithm might require some precision guarantees for the algorithm to work correctly (and who knows, maybe even for the library to be memory safe). A user changing fast-math for the whole dependency graph might make the library uselessand I've worked on code bases with &lt;100kLOC that had fast-math enabled, and that as they grew had to disable it and now they don't produce proper results with fast-math anymore because some parts of the code rely on IEEE-754 arithmetic for correctness. had to disable them as they continued .
[Here](https://doc.rust-lang.org/) is a list of resources to learn rust. "The Rust programming language" is the book recommended as the introduction to Rust.
It looks like you're trying to copy and paste code that doesn't work with your code, and trying to use syntax from other languages. Please post your entire code to the rust playground and we can help point out the small mistakes. That said, rust is not a beginner friendly language. It sounds like you're pretty new. You might practice some more in whatever language you started with and get some more experience first.
Is that code that does the same thing as Firefox on other operating systems, so that whenever one of the implementations change, the corresponding change has to be done in the other?
&gt; vendored Does _vendor_ mean keeping a copy of it in case the original goes away?
That's not a cast, that's a type annotation. To cast, write `x as f32 * 2.1` in the line producing the error.
Zero copy CSV isn't really a thing, because you need to handle escapes. Serde is orthogonal to this. quick-csv certainly does not do anything that the csv crate can't also do. Indeed, quick-csv will do an allocation for every row, and there is no API to amortize this. The csv crate has multiple different ways of amortizing allocation, including not using allocation at all (but there's still a copy going on).
Maybe this is the wrong place to ask, but does operations on \`ndarray\`s use SIMD automatically? Like if you want to reduce a 2D matrix to a 1D matrix by bitwise or, and do this: \`\`\` let arr: Array2&lt;bool&gt; = ... let mut res: Array1&lt;bool&gt; = Array::default(K); for vec in arr.outer\_iter() { res.bitor\_assign(&amp;vec); } \`\`\`
Yes. I believe vendor as a verb comes from the Rails community where it's also the directory name.
Firefox for Android pretty much doesn't share any UI code with desktop Firefox. Because it's UI layer stuff, there's not too much that needs to be changed in both.
There is definitely some confusion here, so I'll try to straighten this out. First and foremost, unless otherwise stated, the "csv" format generally includes the ability to handle quoted fields, which in turn implies the ability to handle escaped characters. That is, if you have a row like this abc," foo ","bret ""the hitman"" hart" then that should be read into memory as abc foo bret "the hitman" hart The simplest way to solve this problem in a general CSV parser is to copy the data from the CSV format into a new region in memory with the express purpose of unescaping the escaped quotes. The csv crate is designed to handle the fully general CSV format, and thus, always does a copy from the source stream to some region in memory. The csv crate permits _amortizing allocation_, which means you don't need to allocate new memory for every row. You can allocate space once and then reuse that space to parse each subsequent row. Moreover, the lower level `csv-core` crate will let you do this without allocation at all, and only requires a `&amp;mut [u8]`, which might be a fixed size scratch buffer on the stack. But still, there's always a copy happening because of the aforementioned unescaping required in the CSV format. With all that said, there are of course different architectures that could be employed to exploit special cases like this. The csv crate (well, csv-core) already has a fast path for data that doesn't need escaping, but it still must do a copy. The copy is necessary because the API requires it. A different architecture, meaning a different API, could permit the copy to be elided, but only in the case where escaping isn't needed. Another architecture would be to perform unescaping on demand. That is, the CSV parser could avoid the copy entirely and just give you back a parse of the data without doing any unescaping. The reason why the csv crate doesn't do this is because it makes the implementation more complex and probably also makes the API more complex. This would likely necessitate layering a ergonomic API on top of the complex one which did the unescaping for you transparently but lazily, but this in turn makes the allocation profile a bit harder to reason about. Basically, when I thought about the design of the csv's crate, this just didn't seem worth doing. But of course, others can prove me wrong and build something better. :-) The reason why the csv crate doesn't expose an alternative API for zero copy parsing in the case where unescaping isn't necessary is because the unescaping is kind of the trickiest part of parsing CSV. Namely, if you don't need to handle escapes, then that means you probably don't have quotes. And if you don't have quotes, then you can probably parse your data by something like for line in my_memory_map { for column in line.split(b'\t') { // column is just a &amp;[u8], no copy, no allocation, no fuss } } So basically, I just don't think it's worth the implementation and API complexity of adding a whole new API to solve a problem that is, by comparison, much simpler and honestly, probably more niche. My guess is that most people just want the CSV parser to work and handle anything you throw at it while still being fast. Which, it is. :-) &gt; for mmap there is the filebuffer crate I can almost unequivocally say that you should be using the `memmap` crate. &gt; The csv crate has a zero-copy feature, but as I understood it that works only if you know how many columns you'll have, which I don't unfortunately. This is the part that I don't quite understand. Neither the csv or csv-core crates have a zero-copy feature (as explained above). csv-core does expose a zero-_allocation_ API, and the csv crate will permit reusing allocations, but neither do zero copies. Moreover, neither the csv crate nor the csv-core crate require you to know how many columns you'll have. If you were looking at [`csv-core`'s `read_record` method](https://docs.rs/csv-core/0.1.4/csv_core/struct.Reader.html#method.read_record), then I can see how you might think that, but it's not true. `ends` is just a buffer, and all you need to know is how much space you're willing to use at once. Once `ends` gets full, you either need to process what's there or give the parser more space. This is the API that the `csv` crate uses, and if the `csv` crate required you to know exactly how many columns you were going to parse, I dare say nobody would use it. :-) My general feeling here is that the csv crate is going to be pretty fast, given that it can handle any reasonably formatted CSV data (on par with Python's csv parser flexibility). But, if you need to go faster and you can make more assumptions about your data, then you can almost certainly beat the performance of the csv crate. I would encourage you to go that path if you need to!
Does anyone else have trouble with autocompletion? It does autocomplete but it can resolve not nearly as much stuff as VSCode. Also sometimes it only toggles snippets.
Learn to read the compiler errors: ``` error[E0308]: mismatched types --&gt; src/main.rs:7:15 | 7 | let x:f32 = 5; | ^ expected f32, found integral variable | = note: expected type `f32` found type `{integer}` error[E0277]: cannot add `{integer}` to `f32` --&gt; src/main.rs:10:13 | 10 | let x = x + 1; | ^ no implementation for `f32 + {integer}` | = help: the trait `std::ops::Add&lt;{integer}&gt;` is not implemented for `f32` ``` It tells it expected a float, but got an integer literal (`{integer}`). The fix is to use a float literal instead.
`a + b` is the same as `b + a`. What isn't however would be `a + (b + c)` and `(a + b) + c`.
As /u/burntsushi suggested, zero-copy CSV is not possible in general. I would suggest to convert the CSV to a binary format that supports random access.
You should ask for support or report issues to http://github.com/eclipse/corrosion
Unless your default toolchain is nightly, of course :p
/u/bluss should know. IIRC you could enable `rayon` (multi-threading) as a feature, but that's it.
I mean this happens in a lot of statically typed languages. If you try to add an int and a float in java for example you're going to run into the same problem, and I'd call java "mature " enough.
During the QA someone pointed out that with floats, a + b != b + a, which is the actual reason it didn't autovectorize. The C assembly was generated with fast math enabled so the fact that is wasn't as precise was ignored. He switched the floats with ints and it autovectorised.
Alternatively, supporting `-ffast-math` probably does the trick as well.
It's not so much in case the original goes away, but more to make versioning, packaging and continuous integration easier. The monorepo philosophy is to put everything in one giant repo and not worry about versioning.
I can't find it now, but I'm sure I saw a "hoping to get it on nightly in July" on one of the github issues / PRs.
thank you for this detailed reply! the csv crate seems to perform very poorly with my data (~100MB, huge cells). I'll try to restructure my code like you suggested (2 for loops). Why is memmap preferred? 
Did you mean to reply to /u/Cybil_7?
&gt; Serde is orthogonal to this. My guess is that people see serde's zero copy API and assume the underlying formats support zero-copy as well. I know I had assumed csv would support this serde feature before reading your post.
&gt; the csv crate seems to perform very poorly with my data (~100MB, huge cells). Is it possible for you to reproduce the performance problem on a corpus we both share, along with code? Otherwise, it's really hard for something like this to ever get fixed, if it can be fixed. The code may also be doing sub-optimal things. &gt; Why is memmap preferred? I'm not going to do a full crate review, but `memmap` is what most people are using and the API has benefited from that. Moreover, it looks like `filebuffer` doesn't require the caller to use `unsafe` to access the buffer, but the general consensus, AIUI, is that this is wrong. See the `memmap` issue tracker.
You don't have to pass `Pos` as `f32x2` to support this auto-vectorization, the function could convert it to such a format internally, then operate on it as such. This is especially not a problem at all, since the representation in memory for `f32x2` and `Pos` is the exact same, so it would be a no-op. But I would personally say that this is a bug not in rustc, but in LLVM, since LLVM has all the information needed to do the optimization itself.
Floating Point math is commutative, but it's not associative.
I don't really understand why there's a difference between library and binary crates. From what I understand you can't even write tests for binary crates. So if you want to test anything you need to have a lib.rs file whether there's anything in it or not - making the project emit a library crate. This arrangement strikes me as very weird. Who would ever want to construct a nontrivial project without tests? So is every project a library then? Then why keep the distinction?
Use a move closure, explicitly borrow `a` from outside the closure and capture that borrow rather than a itself. Basically, `move` closures are the more general one, ref closures are a special case though they're usually more convenient (hence being the default).
There's also [CodeXL](https://gpuopen.com/compute-product/codexl/) which is the only one so far who can read Rust function names under Windows + MinGW.
Oh, oops, I did.
Instead of making the entire position an f32x2 you should make the x and y each either a f32x4 or f32x8 (Depending on if you want it to use SSE or AVX) Seeing a Vector and thinking "oh I can pack the x,y/x,y,z/x,y,z,w into a simd type" is everyone's natural first reaction but it is an order of magnitude better to not do it that way. As an aside, I'm working on a library that lets you abstract over simd vector width while doing explicit simd instructions: [https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez)
But it's still barely visible on the chart, which is what I wrote about.
Yeah, if you can do that, you definetely should. This is what ISPC does automatically for you, e.g., using hybrid layout. In Rust I tend to create `PosN` types, which contain `N` `Pos` inside, and that are vectorized: https://godbolt.org/g/83K6FG
Can you provide some reasoning as to why this is? Aligned SIMD loads I presume? If it was integer types that actually seems like a potential pesstimization. It should be relatively trivial to add four `i32x2` in one AVX instruction after loop unrolling, while if you have `i32x8` to start with that would require the compiler to realize that some elements are actually unused.
&gt; require the caller to use unsafe to access the buffer, but the general consensus, AIUI, is that this is wrong. But why creation of read-only `Mmap` should be unsafe? Yes, other process potentially can change data under you, but I don't see memory safety hazard here.
Personally, I would love to see someone dive into this, because it's the only thing I use `unsafe` for that I'm unsure of how to encapsulate. Anywho, I'll just defer to the issue tracker: https://github.com/danburkert/memmap-rs/issues/25 --- It doesn't say much, but this did go through the library team as well.
My past self agrees with you: https://github.com/rust-lang/rust/issues/48426#issuecomment-376865118 However, because we are passing the struct between functions, which on their ABI need to initially respect the layout, a lot of things need to happen for something like that to trigger. After inlining everything basically a pass has to extract vector code from scalar code, which is something that is already happening in the original code up to a degree. Personally, I'd switched to the mindset that this should be a guaranteed optimization, and not something that happens by chance. 
&gt;modern compilers can do pretty amazing things, icc and ifort perform memory layout optimizations like AoS to SoA Guys, what books do you read to get to know stuff like that?
I'll send you a gist! I didn't know, thank you!!
Nothing to do with aligned loads. The assumption if you are even bothering with this is you would have many Pos structs, by making a vector for each X and Y, you can process 4 or 8 or 16 (however big your vector lanes are) Pos at a time, no matter the operation. When you pack the x and y into the same vector, many operations get weird/hard or impossible to do vectorized at all. 
At the moment I've given no thought as to how/if simdeez could work with iterators. I wanted to provide a programming interface that was very similar to working with plain intrinsics. In fact if you have intrinsics code you have written in Rust or C, you can convert it to simdeez form with simple search/replace operations really quick. But yeah if anyone has ideas on how to build iterators that can work with it, that would be cool! 
What about #[vectorize] struct Quaternion { x: f32, y: f32, z: f32, w: f32, } ? I feel like that's much more readable than the \`f32x4\`, you can access individual fields, and the the `vectorize` attribute could throw a compile time error if all fields aren't the same type, or aren't supported types
I thought the consensus during the Q&amp;A session and the thread yesterday was that C++ could autovectorize it because it was using the flag -ffast-math, which makes C++ not worry so much about correctness of floating point math. The rust program was correct not to autovectorize the program because it would have made the floating point math incorrect. Alternatively, if rust allows LLVM to make that optimization at the expense of correct math, rust could have this optimization too. I don't understand why anything in this current post is relevant at all.
playing with the benchmarks game, nbody #1 is basically ifort...
See basically this comment: https://www.reddit.com/r/rust/comments/8ur1ee/how_to_make_matt_godbolts_example_faster_by/e1hvfij Which shows how to explicitly vectorize it by changing the floating-point semantics in Rust, without fast-math: https://godbolt.org/g/83K6FG 
I have been waiting for redis compatible protocol for TiKV. Is `ekvproxy` proxy opensource? 
vendor branches existed in CVS.
&gt; You need the nvim object to be moved into the outer closure (bench_function) but not the inner one (b.iter). I've checked out your code and made the change myself; it does compile I knew it would be easy the moment I wrote "fundamental". *Sigh* Thanks a lot! I'll take some time to study the error message and the solution, since I seem to have understood something pretty wrong.
Note that to reduce the cache line sharing between two threads, the user has to provide the index as a multiple of of the size of a cache line.
Hi everyone, I'm the author of the repo. It was a small project for an evening, and I'm happy it got some attention from the rust crowd. There were many questions below about the numbers in the chart. I think I will answer all of them by explaining how these numbers are calculated. First, I grouped the files by file extension with [git-file-stats](https://github.com/4e6/firefox-lang-stats/blob/63912019312ac0b25701092b06fde64bec341f64/dev/git-file-stats) script to figure out the languages of the repo. Here is the [output](https://github.com/4e6/firefox-lang-stats/blob/63912019312ac0b25701092b06fde64bec341f64/git-file-stats.log). Then I just counted LOCs for the most significant languages, and pasted the numbers into the chart library. For example, for the Assembly language, I considered only the `*.asm` files, and `*.rs` for Rust. Maybe the resulting chart is not the most precise, but I hope it shows the big picture of what's going on in the mozilla/gecko-dev repo, and I hope I got the numbers for Rust vs. C/C++ right, because we want to focus on them and see them changing in the process of C being replaced with Rust.
I am confused with the wording from TRPL. * If an item is public, it can be accessed through any of its parent modules. *If an item is private, it can be accessed only by its immediate parent module and any of the parent’s child modules. What does "any of its parent modules" means? Shouldn't an item just have one parent module? Or does it refer to parent of parent, ancestors? There is no explicit definition of "parent module" in the text. It's confusing because when I just look at the first rule(without looking at the second one), `A::B::f()` seems legal. mod A { mod B{ pub fn f() {} } pub fn f() {} } fn privacy_test() { A::f(); A::B::f(); } 
In implementing Iterator for custom types, is it idiomatic to require an attribute to track state, e.g. `count: i32` in `Counter` from [this tutorial](http://gradebot.org/doc/ipur/iterator.html#create-iterators)? If so, it seems like `fn next()` will usually increment this counter at the beginning of the function -- which means that a variable tracking the index would either need to be instantiated at `-1` as in the example above (and therefore be signed instead of unsigned) in order to keep things zero indexed for the first run. Is this how people usually do this type of thing? It just doesn't feel quite right coming from Python generators, want to make sure I'm learning things the Rust way. Alternatively, I guess the counter could maybe be an `Option&lt;u32&gt;`, initialized as `None`, and `next()` could increment as `Some(num)`, but I'm not sure if this is better or worse.
&gt;From what I understand you can't even write tests for binary crates. That's incorrect, where did you get that from? It's absolutely possible to write tests for binary crates.
That’s awesome. The “end of the year” estimate was because the teams cant focus on it until after the edition, but if someone else is stepping up, it can happen sooner.
Indeed. For floating point, This is true: a + b == b + a This is false: a + (b + c) == (a + b) + c
Hi! I posted this link. If you are happy I am happy. :) Is there a plan to track changes through time?
The thing is though you don't need to change the layout in this case, since they have the same representation in memory.
There are differences when passing the type through ABIs though. You would pass `Pos { x, y }` as in two floating-point registers, and `f32x2` you would pass it by memory to avoid hardcoding `xmm` registers or worse in the ABI.
Wait, I thought people wanted Microsoft to change and become more open. Changing more stuff to open source instead of proprietary. Wouldn't that make VS Code (MIT License) and Typescript (Apache License) examples of positive progress for Microsoft? I thought the issue people had with Microsoft was platform lock-in. And Lock-in != Competition. Competition can be healthy and help progress the whole ecosystem, especially since it's all open source and we can learn from each others code. For example VS Code being way faster on launch then Atom showed that the slowness wasn't inherent to the Electron framework both used and pushed the Atom team to catch up and progress in this area.
Yes, I thought about it. Ideally, I wanted to associate the git commit with Firefox release to see the progress between releases. But I didn't find any related tags or branches, probably because it is a mirror of original HG repository. Anyway, the aggregation of language details is already automated, and the page is updated weekly with a Travis Cron job. So it should not be that difficult to save the results of each run and create a time series out of it. Sounds like a task for another free evening :)
The proportion isn’t really relevant; Firefox has a huge amount of code. That’s a lot of assembly
Sorry I meant incremental text processing in general, not parsing as opposed lexing.
It also makes common workloads slower at the moment.
Out of curiosity, have you read [TRPL](https://doc.rust-lang.org/book/second-edition/foreword.html)? In particular, have you read the sections related to [data-types](https://doc.rust-lang.org/book/second-edition/ch03-02-data-types.html) and operators? If not, be sure to read those. That being said, the fundamental issue you are running into is that you want Rust to treat and i32 (32-bit integer) value as if it were a f32 (32-bit floating point) value. This can result in errors because an i32 has a range of values that is greater than the range of values that can be expressed in an f32 without loss of precision. Many are recommending that you simply use the "as" operator to cast it to an "f32" forcing a potential loss of precision. That is also, in my opinion, not correct. The whole reason that Rust refuses to do this implicitly for you, is that it is incorrect. You should either make the value an f32 to start with if your intent is to not require precise computation. Using "as" is code-smell and means you haven't thought through your algorithm carefully. This is a somewhat sophisticated point, and you aren't at that level of sophistication yet, but, it is important that you understand that just using "as" is not the proper way to address this issue. You can do it for now, just to make some progress, but, once you've learned more, you need to explore this topic more deeply.
Well, good sense dictates that tests should go into a separate directory where they're not mixed with the source code and don't contribute to the final executable. [Rusts page on test organization then states](https://doc.rust-lang.org/book/second-edition/ch11-03-test-organization.html#integration-tests-for-binary-crates) &gt; **Integration Tests for Binary Crates** &gt; If our project is a binary crate that only contains a src/main.rs file and doesn’t have a src/lib.rs file, we can’t create integration tests in the tests directory and use extern crate to import functions defined in the src/main.rs file. Only library crates expose functions that other crates can call and use; binary crates are meant to be run on their own. &gt;This is one of the reasons Rust projects that provide a binary have a straightforward src/main.rs file that calls logic that lives in the src/lib.rs file. Using that structure, integration tests can test the library crate by using extern crate to exercise the important functionality. If the important functionality works, the small amount of code in the src/main.rs file will work as well, and that small amount of code doesn’t need to be tested.
Desktop Nightly with Tracking Protection, works fine for me
I'm curious about the sizes of the outputs generated from WebIDL. Servo generates Rust code from specifications and I assume SpiderMonkey/Firefox do too. Rust might generate significantly more code to make up for the lack of objects or C++ might because of verbosity.
Same for me, no idea why it doesn't for others...
Yes, but if I may make a pedantic point: autovectorized floating point math is not necessarily less correct, sometimes it is \*more\* correct. But it is \*different\*, and changing the behavior of the program automatically is a no good for automatic optimizations.
Clang isn't smart enough to auto-vectorize across `Pos` structs even with `-Ofast`. However, at `opt-level=2` (the opt level used in the talk), [rustc outputs this assembly](https://godbolt.org/g/1ZfofQ) in the inner loop: vaddss xmm0, xmm0, dword ptr [rax] vaddss xmm1, xmm1, dword ptr [rax + 4] vaddss xmm0, xmm0, dword ptr [rax + 8] vaddss xmm1, xmm1, dword ptr [rax + 12] vaddss xmm0, xmm0, dword ptr [rax + 16] vaddss xmm1, xmm1, dword ptr [rax + 20] vaddss xmm0, xmm0, dword ptr [rax + 24] vaddss xmm1, xmm1, dword ptr [rax + 28] vaddss xmm0, xmm0, dword ptr [rax + 32] vaddss xmm1, xmm1, dword ptr [rax + 36] vaddss xmm0, xmm0, dword ptr [rax + 40] vaddss xmm1, xmm1, dword ptr [rax + 44] vaddss xmm0, xmm0, dword ptr [rax + 48] vaddss xmm1, xmm1, dword ptr [rax + 52] vaddss xmm0, xmm0, dword ptr [rax + 56] vaddss xmm1, xmm1, dword ptr [rax + 60] This computes both "x" and "y" of each `Pos` independently. In contrast, for `-O2 -march=native`, the [equivalent C++ code](https://godbolt.org/g/FWsbqU) outputs: vmovsd xmm1, qword ptr [rdx] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rdx + 8] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rdx + 16] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rdx + 24] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rdx + 32] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rdx + 40] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rdx + 48] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rdx + 56] # xmm1 = mem[0],zero vaddps xmm0, xmm0, xmm1 This assembly computes both `x` and `y` of each`Pos` at the same time. It doesn't vectorize across independent `Pos` structs, but does vectorize within the `Pos` struct. This doesn't violate floating point semantics, and rustc could definitely do this optimization without [rust-lang/rust#48426](https://github.com/rust-lang/rust/issues/48426). Switching from `opt-level 2` to `opt-level 3` in rustc will produce the [same assembly](https://godbolt.org/g/szdXPN) as the C++ version: vmovsd xmm0, qword ptr [rax] vaddps xmm0, xmm1, xmm0 vmovsd xmm1, qword ptr [rax + 8] vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rax + 16] vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rax + 24] vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rax + 32] vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rax + 40] vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rax + 48] vaddps xmm0, xmm0, xmm1 vmovsd xmm1, qword ptr [rax + 56] vaddps xmm1, xmm0, xmm1 This is also pretty much identical to the assembly displayed in the talk for the [C++ example](https://godbolt.org/g/un8em2). The only "problem" is that `opt-level 2` in rustc is not the same as `-O2` in clang for some reason.
Not really a problem I have, but something i noticed: with traits you can create a trait with a method like `fn call&lt;'a&gt;(&amp;'a self, foo: &amp;'a Bar) -&gt; &amp;'a Baz`. Is this possible to represent as a closure? `for&lt;'a&gt;Fn(&amp;'a Bar) -&gt; &amp;'a Baz` is equivalent to `fn call&lt;'a,'b&gt;(&amp;'a self, foo: &amp;'b Bar) -&gt; &amp;'b Baz` so it's not the same.
"Any of its parent modules" means any of its ancestors, ie. its parent, or its parent's parent. This is a little misleading - the entire chain of items needs to be public for this to work. In your case, `mod B` is not public, so `A` cannot access it, nor can `privacy_test()`. Since they cannot access `B`, they cannot access `B::f()`. If you change `mod B` to `pub mod B` this will work.
&gt; Also, it won't be as powerful as C++'s template specialization I consider it a feature. C++ specialization is *too* powerful as far as I am concerned. It goes as far as allowing changing the *interface* of a type, such as removing associated items! &gt; Correct me if I'm wrong, but AFAIK in C++, everywhere where you can have "normal type parameters", you can also use template templates, right? Yes, but I don't see why that would not be possible with GATs. Actually, as I mentioned, C++ `Allocator` concepts used to feature an inner template `rebind` such that `Allocator&lt;T&gt;::rebind&lt;U&gt;::type` would be `Allocator&lt;U&gt;`. This is a GAT. And anywhere you'd pass a template template you can simply pass a trait with a GAT instead (a bit more indirect, maybe, but as powerful). It may still not be full support for HKT, but it's on par with C++ as far as I can see. &gt; Variadic templates Oh sure, I don't deny there *are* usecases; but most usages I've seen in C++ seem to be induced by C++'s own quirks. The most common is argument forwarding, and in Rust you can just pass a tuple for that (or a `T: SomeTrait`).
How can I prevent the allocation of a console when using rust on windows?
Is it really a function call? I thought all it does is create a new type `Foo` wrapping `bar`. Seems distinct from an ordinary function call to me. Does it execute any code at runtime?
I use `WPA/WPR` very successfully. Which comes with the [ADK](https://docs.microsoft.com/en-us/windows-hardware/test/wpt/windows-performance-analyzer) so not tecnicaly all of VS.
Right, but I agree that it is a little confusing in the case of `Ok(())`, because the type `()` has only one possible value, which is `()`.
Small rant: I hate the new onlinexperiences.com player, the old air.mozilla.org was much better. It allowed you to download video, had simple black background instead of an annoying image, had no stupid animations, pop-up windows, "system checks" and several redirects. And it simply was loading faster...
Clearer yes. As esoteric, no.
And for now it's used by the [`void`](https://crates.io/crates/void) crate to provide a single type that acts like this.
&gt; Yes, other process potentially can change data under you, but I don't see memory safety hazard here. You can violate the invariants that other people's unsafe code relies on. For example, you can pass a `&amp;[u8]` to `std::str::from_utf8`, get a `&amp;str` from that function, and then modify the bytes after the fact to be invalid UTF8. Constructing an invalid string is supposed to be impossible in safe code, and unsafe code can rely on that to e.g. skip bounds checks when reading multi-byte characters. There are old fashioned C libraries out there that "parse" structs by casting them directly from raw memory, and sometimes those structs can contain internal lengths and offsets, like for variable length strings. (I don't know if many new libraries do this, but it used to be a big deal for performance.) If you're very lucky, the library validates those offsets after parsing, to make sure they aren't going to cause illegal reads and writes down the line. If someone exposes a safe Rust wrapper around that library, but then you start changing the data out from under it after validation, you can break the world in "safe" code.
How is SIMD float math different from regular float math?
You need to specify #![windows_subsystem = "windows"] (Probably at crate root)
Hmm, why is Atomic&lt;u8&gt; expensive? I thought it was essentially free compared to normal memory accesses, just preventing optimizations.
Thank you for clarifying.
Personally, I would initialize to 0 and increment after I find the return value. I would also name it `next_index` or something instead of counter, as that name makes more sense to me between calls to next: let index = self.next_index; self.next_index += 1; if self.index &lt; self.max { Some(self.count) } else { None }; 
Ironically had to use Chrome for this lame popup page to work.
When I clicked the link in Firefox, it tried to launch a popup which was blocked. So then I had to find Rust in the channels section, which is just big colourful buttons seems to be ordered completely randomly. Then the Rust talks were ordered by name rather than most recently uploaded. Look at the URL this sequence of steps generted! Yuck! https://onlinexperiences.com/scripts/Server.nxp?LASCmd=AI:1;F:US!100&amp;PreviousLoginCount=0&amp;ForceProfileToBeFilledOut=0&amp;DisplayItem=E265931&amp;ShowKey=44908&amp;ShowFrameFormatOverride=NULL&amp;RandomValue=1530296198228
Even if you have a lib.rs you can't write tests *for the binary*. So the common practice is to put all the real functionality in the library and make the binary a thin wrapper over it. 
I‘m glad you mentioned VSC. It is not truly open source: https://www.reddit.com/r/opensource/comments/8rzpr1/is_microsoft_allowed_to_call_their_visual_studio/?st=JJ0B11FV&amp;sh=d62c2b2c And this demonstrates well what I mean. I have nothing against competition. But to pretend to be open source when you are not is hypocritical und this make mit sceptic. And reminds me of the past days. To be the most terrible opponent of the open source and trying to destroy Linux and now tell everybody that Microsoft loves Linux is hypocritical too. TypeScript is good and I even use it every day. But instead of making established key technologies like Babel better for everyone they invented their own wheel. Nothings wrong about that. But I see in this move a strategic calculation to gain more dominance over the web development landscape and not the desire to make a world a better place for everyone. And this makes me sceptic too. And if I would spend more time, I could give you much more examples from the past. This is not my first discussion on this topic and I feel myself always like a father who needs to explain to his daughter that her new friend is an asshole. Or at least was. But okay we will see. I really hope that they have changed. But for now I don‘t buy it! 
&gt; Since moving a value into a function and borrowing it exclusively in that function are the same Since the invention of `Pin`, this is no longer _entirely_ true.
&gt;Yeah, Rust doesn't support keyword arguments for function calls or type-constructors. But in the places where it supports anything at all like keyword That is a terrible error message. Filed [\#51913](https://github.com/rust-lang/rust/issues/51913).
Incidentially I just discovered we need another rustup.
The rendering engine(s) (Gecko, soon Servo) are compiled for ARM, and then loaded as a native library. So the Java stuff is for the UI layer like /u/gsnedders said and as well as some of the other Android-specific stuff.
vendoring != monorepo Although monorepos often use vendoring in places.
The last time I built a csv library (in C++), I separated the layers to provide zero-copy iteration with a relatively simple trick, the `Cell` was implemented as a `&amp;[u8]` under the hood and the parser would: - trim the leading and trailing quotes if the content did not require further decoding (no escaped quote inside), - keep the leading and trailing quotes if the content did require further decoding (at least one escaped quote inside). This was pretty neat since: - it occupies the same space as a regular `&amp;[u8]`, - checking if decoding is required is immediate (check if the first byte is `"`, if any). On the other hand, it has its own inefficiency: cells containing escaped content are essentially parsed twice! A first parse to store them into a `Cell` and a second time when actually decoding it. It was not a problem in my case, as those were exceedingly rare, but I imagine on some data-sets it could easily become an issue. The one thing I never resolved was how to elegantly go from a stream of cells to a stream of rows... that is, how to easily signal an "end-of-row" in between two cells. In the end I cheated by going SAX-style (two different callbacks), but I'd be happy if someone had an alternative to passing a flag in each element returned by the stream. I considered packing elements, aka `(void*, u32, bool)`, but... :x
The problem is that IEEE floating point addition is commutative but not associative. This means that (a + b) + c is not necessarily the same as a + (b + c). So if you write a program to sum up floats in a particular order, the optimizer can't change that without possibly changing the behavior of the program.
&gt; Assembly: 140,187 Okay, this is scary.
Are these inherent design decisions reflected in the API/ABI, or they could conceivably be fixed later on without breaking the user-mode programs? &gt; Schemes change it a bit, but they don't reconsider and fix bad design choices in posix and linux Could you point me to any reading on what those are?
&gt; and if you do so for memory safety, fast-math could introduce memory unsafety in your program. Relying on *floats* for memory safety seems... odd. Definitely not a choice I would make, and I can't think of any cases where *real* code can usefully rely on floats in such a way that can't just be replaced with ints.
Wrestled with the popup too, but the talks are excellent, thank you!
The `csv` crate is fast in my experience, but very slow in debug mode. Are you compiling with the `--release` flag, as in `cargo build --release`?
Yep, Safari wouldn't let me open it, Firefox had issues, what is wrong with an inline video player? Damn you onlineexperiences.com, _damn you_.
Found the issue: You have to implement the functions separately from the definition, otherwise they are not exported. This is a general thing you have to keep in mind when creating libraries in C++. so you have to change `class cla{` `void fun(){...}` `};` to `class cla{` `void fun();` `};` `cla::fun(){...}` And for the linking: You have to link the libraries in the right order. From most specific to most abstract. For example if you want to use a certain library and also have a wrapper in C++ written on top of it to use with rust, then use these commands: [build.rs](https://build.rs/): `println!("cargo:rustc-flags=-L lib_dir");` `println!("cargo:rustc-flags=-L wrapper_dir");` `println!("cargo:rustc-link-lib=wrapper");println!("cargo:rustc-link-lib=lib");` `println!("cargo:rustc-link-lib=stdc++");`
&gt; To be more concrete, what might a high level encryption function look like? See NaCl's [crypto_box](https://nacl.cr.yp.to/box.html) for a good example of this, in friggin' C. It provides a single go-to "encrypt your data" solution that also does authentication and *explicitly documents* what to do with nonce, and provides an example. The 4 short paragraphs under "Security model" explain it all. However, when building protocols on top of that in practice people also desire forward secrecy, so every single NaCl-based protocol also rolls its own forward secrecy from scratch. This is a major missing piece, and a source of vulnerabilities in those protocols. I suspect resolving this would be possible with minimal code in NaCl itself and a bit of documentation - in the vein of "If you do this, you get these guarantees. So do this."
&gt; changing behaviour depending on the opt-level Clang has `-Ofast` which *may* violate strict compliance with language standards. Maybe rust should have an optimisation level similar to that, something where you're not guarenteed to get the same results between two -Ofast builds or an -Ofast and regular build, but maybe have bounds on the amount of imprecision it can create beyond what a perfect calculation would be.
Only made it through (most) of the Sunjay talk thus far, and it's excellent. A few things that weren't immediately clear to me: - Is Chalk a general purpose Prolog-esque interpreter, or is an implementation of the rust trait system? I've seen both descriptions used, so I'm wondering where the distinctions lie. - My understanding listening to the talk is that predicates are defined in chalk, and then chalk analyzes Trait impls to determine coherence. How are the predicates determined? It sounds like pretty hairy category theory stuff, but for example (paraphrasing), "For any impl with a non-local trait one of the type parameters p0-pn must be local." How was this rule devised? I assume there are some sort of proofs associated with it?
No clue. In order to read from an atomic you need to specify a memory ordering. Presumably, a relaxed memory ordering would be sufficient and as cheap as a normal load/store (on x86?). But, actually using a `&amp;[Atomic&lt;u8&gt;]` would be terribly horrendous for ergonomics. What happens when you actually want to look at it by, say, using APIs that want a `&amp;[u8]`? I dunno. Take what I say here with a grain of salt. Honestly, I'm out of my depth here.
`crypto_box` and `crypto_secretbox` were a leap forward in terms of crypto API design, for sure. But still I think they're at least as hard to use as any of the APIs discussed in the paper here. For example: &gt; The caller must ensure, before calling the C NaCl `crypto_box` function, that the first `crypto_box_ZEROBYTES` bytes of the message `m` are all 0. Libsodium introduced the `*_easy` functions to get rid of that requirement, but even their documentation lists a gotcha: &gt; `c` and `m` can overlap, making in-place encryption possible. However do not forget that `crypto_secretbox_MACBYTES` extra bytes are required to prepend the tag.
I'm sorry, I can't watch this, the video player is just too shitty. It constantly locks up for 30 seconds every few minutes even though my internet connection is fine and I'm already watching at the lowest resolution possible. I don't have the patience to sit through a video that can't be sped up (no 2x video speed control like on the old player) and constantly locks up (while YouTube works absolutely fine). So either fix the video player or upload it to YouTube. Also the lower control bar doesn't go away if you fullscreen the video, it always stays there. onlineexperiences... well you've surely made me have an experience, just not a good one.
and japaric is the embedded guy, pretty much everything he does is on nightly.
&gt; don't contribute to the final executable. If you include unit tests in the crate, it is typical to wrap it with the `cfg(test)` attribute so that it is not included with the final executable (it is only included when building the test). #[cfg(test)] mod tests { #[test] fn it_works() { } } In this example, the module `tests` will only be included when building tests. Not everyone likes doing it this way, though. 
In the past I have used [minifb](https://crates.io/crates/minifb), which is very easy to use, but fairly basic.
Oh wow. For a "we pioneer web technologies" company, this is a big fail.
The error you get is probably because your function returns `String`, change it to `Result&lt;String, Error&gt;` or Option&lt;String&gt;. Otherwise the `?` operator doesn't know what to return in case of errors. 
You're the best, that's exactly what I was looking for. I actually prefer how basic it is compared to something like Piston. The projects I'm doing are just simple things to learn Rust, I didn't want to have to dig through documentation. Considering I figured out everything I needed from just looking at the examples, this is perfect. Thanks again
&gt; Column-oriented databases like Cassandra and Vertica support elastic scalability of both computing and storage with safe and fast DDL, but they are non-relational databases Vertica is a relational database, however it is not designed for OLTP workloads
&gt; Many are recommending that you simply use the "as" operator to cast it to an "f32" forcing a potential loss of precision. OP’s original code is attempting to cast an `i8` as `f32`, not an `i32`. I wouldn’t recommend casting an `i32` to an `f32`, for the record. 
https://aaronweiss.us/posts/2018-02-26-reasoning-with-types-in-rust.html
I've always wondered about this! Is floating point math some particular type of algebraic structure? Without associativity it can't be a ring, so is it something else? 
&gt; I‘m glad you mentioned VSC. I just stuck with the two examples you gave. &gt; It is not truly open source: https://www.reddit.com/r/opensource/comments/8rzpr1/is_microsoft_allowed_to_call_their_visual_studio/?st=JJ0B11FV&amp;sh=d62c2b2c And I agree with the highest voted comment there. This is done in an acceptable way. Their precompiled version is just Microsoft branded and the only difference to the open source version are integration with some additional Microsoft services that don't alter the editor experience in any major way: 1. Shortcut to send feedback to Microsoft through 'send a smile'. 2. Telemetry for Microsoft that can be disabled of course. 3. Direct integration with the Extension Marketplace. The proprietary license just seems like a standard defensive corporate license to cover themselves, especially in regard to feedback and the integrated extension marketplace. While this dual licensing might be regrettable it's done in a decent way and far from the 'Embrace, extend, and extinguish' mentality many still fear monger. --- The code of the editor is open source (https://github.com/Microsoft/vscode/blob/master/LICENSE.txt), some additional bundled services in the branded download aren't. 1. There are other ways to give feedback easily, this is just a small shortcut. 2. Will anyone actually be sad about not being able to turn on telemetry? 3. The missing marketplace integration is the only actual backside for myself but at least you get it completely free from any communication to proprietary services. I don't think anyone ever claimed the marketplace to be open source. And downloading/installing the relevant extensions yourself is absolutely trivial. --- &gt; But instead of making established key technologies like Babel better for everyone they invented their own wheel. And from your previous post: &gt; Take JavaScript for example. They could not buy it. So what they did was to copy some key technologies [...] webpack+babel+flow =&gt; TypeScript [...] Typescript wasn't just a "we'll do our own version of already available X to get more dominance on the web". It was a new attempt to bring type safety to the JS world while still being compatible with using vanilla JS code. And there wasn't really an equivalent existing project at the time that could have been contributed to. Flow didn't exist yet and Dart had vastly different goals.
/r/playrust
Floats aren't actually numbers, they're best thought of binary scientific notation that approximates numbers. What this means is every operation involves some rounding. So instead of thinking of this like a + ( b + c ) = ( a + b ) + c You should think of it like | a + ( | b + c | ) | = | ( | a + b | ) + c | And that seems fairly reasonable if you're constantly rounding between each step. --- Now for most *common* usages floats appear associativity, and the rounding is standardized so it behaves *sanely* for the vast-vast-vast majority of cases. But in the strictest set, no the ring isn't closed.
Wrong sub but you gotta talk to people and help each other. Gl. 
Alternate link on Mozilla's YouTube channel: https://www.youtube.com/watch?v=Pc6ednHfsQg
You want /r/playrust This subreddit is about the programming language named Rust. It isn't related to the game (aside from just happening to share a name).
Uh xD
Good clarification! This is in the context of mozilla-central which is a monorepo.
Parsing this title was difficult. I imagined people meeting up at a rusty plant trellis in a raspberry field until I read the description.
That attribute essentially exists, as `#[repr(simd)]`, and it's how the `f32x4` etc. types are defined.
I like your specification of "strict developer time constraints". It's a very really restriction that lots of people kinda gloss over.
That is a scary amount of assembly. How does that work on non-x86 platforms?
you are a real MVP – i am just 100&amp;#37; unable to see the video from the original link. Just weird stuff happens and at the end i don't even know where i am anymore – lost in the dark! Thanks for your helping hand and for shedding some light through the valley of darkness. I just felt like an old man overwhelmed by some future technology i just can't fathom anymore – you are my guardian angle :D 
Authenticated encryption requires extra bytes to store the authentication tag. There are no ways around that. If you add information to something, you get something bigger. Two issues with `crypto_box`: users have to provide nonces, and nobody uses it (people prefer to compute a shared key themselves, sometimes in very insecure ways). Which is way it is not present in libhydrogen. It was replaced by a `secrebox` operation that transparently handles nonces, and with sane ways to compute shared keys.
I will always guard you, but from an angle :D
&gt; a bit of documentation - in the vein of "If you do this, you get these guarantees. So do this." People don't read documentation.
My mistake. I didn't catch that. For some reason, I thought it was i32 -&gt; f32.
&gt; One might argue that C also has really simple and clean syntax Except for the [really infamous function pointer declaration syntax](https://cdecl.org) :D
Some of them are just internal, like the scheduler, but others are part of the syscall abi.
As he says in the talk, the rule was devised through discussion etc. on the team. It was a set of rules that they all agree, that if met, result in it being impossible to have overlapping impl's based entirely on local knowledge only. In other words, these are rules that they agreed could be implemented only on knowledge of the current crate being compiled that, if met, make it impossible to have and "Orphan Impl". So, you can think of the rule as an axiom/postulate that when combined with the declarations in the crate &amp; dependent crates will result in an up or down on the predicate, "Is this impl and orphan?".
How is it not closed? Adding two floats gives a float.
A magma only has closure/totality. I don't think there's a special shorthand for a commutative magma.
Recently (as in within the last year or so), there was a publication by Google about ML-optimized data structures. I'm not sure about the actual implementation, so maybe they sanitize it well enough to not be affected by fp inaccuracies, but that's an application I could imagine floats touching memory.
&gt; Shitty updates I agree, assuming you're talking about [the red X trickery](https://www.pcworld.com/article/3074339/windows/how-to-escape-that-forced-windows-10-upgrade-you-mistakenly-agreed-to.html), that's about the shittiest thing I can think of that Microsoft has done recently. It is very, very, very shitty. &gt; ads in the ui I agree. That is shitty. If the user doesn't want to use Edge, don't pop up talking about it; respect their decision. &gt; no privacy I agree. I don't actually have a problem with by-default telemetry, [but they not only take it too far](https://www.zdnet.com/article/windows-10-telemetry-secrets/) in the "Enhanced" setting, [they're not very good about staying off the internet](https://arstechnica.com/information-technology/2015/08/even-when-told-not-to-windows-10-just-cant-stop-talking-to-microsoft/) even when you turn it all off. &gt; trying to gain a monopoly position with the windows store What?! The Windows Store is literally the same thing that Ubuntu, Apple, and Google are doing. Users like the central store; it makes sense for Microsoft to want one, too. The only thing I'd change, if I were god-king of the Windows division for a day, is that I'd allow alternate web browsers in there. Firefox should be in the Windows Store, just like it's on Google's Play Store. &gt; when you can clearly see the clusterfuck called windows 10. It's not a clusterfuck. It has problems, but so do Linux distros (keywords: pulseaudio, systemd, wayland). And they can't just open source NT. Even if they wanted to, there's stuff in there licensed from other companies; it might not even all *have* a clear copyright owner nowadays, if they got a license for something and the company they bought it from got sliced up and bought out.
I was thinking it might look something like a semiring, but I think those still need addition that is associative. Also there's the fact that it's bounded to consider. 
Pijul is distributed.
All that means is that you can't drag them to court over it. But nobody's trying to do that. Everybody's discussing *on a public forum* about their misgivings over the unsafety (and the way it was handled). So, what you're saying is that people aren't allowed to talk about this issue? That people aren't allowed to share their opinion on what they consider acceptable (or not)? That they should just shut up and "not use the library"? Also, because crates.io is managed by the Rust team, if the *Rust team* decided that this behavior is unacceptable, then they could jank the crate. And the MIT license wouldn't protect actix-web from that. I don't think the actix-web crate should be yanked, I'm just pointing out that the MIT license is completely irrelevant to this discussion, since we're discussing *community standards*, not *legal retribution*.
oh jesus christ we're fucked https://groups.csail.mit.edu/carbon/wordpress/wp-content/uploads/2011/03/eastep-smart-data-structures-icac11.pdf is some paper that I found from 2011. They seem to be using ML to tune aspects of the data structures. Like in a hashtable you would tune the resize threshold, maybe other things that I can't think of at the moment. But getting that wildly wrong won't cause *unsafety*. It'll just mean your data structure is either slow or wasteful of space. I imagine Google's doing something similar. In any case, if you're using machine learning, you *have* to be tolorant of wildly wrong answers. Because that's what you can get. So slight inaccuracies shouldn't make a difference. Though I suppose it would actually still be a breaking change for floats to change. Like, it would be perfectly valid and safe for me to do a full float self-check at the start of every function, then memcpy /dev/urandom to your program's memory space if any of them fail, that's safe.
Think about it in base 10 with 2 digits of precision though. (1.4 + 1.4) + 10 = 13, but 1.4 + (1.4 + 10) = 12
Media codecs, at that, where it's not really unexpected.
I've got a [hacked-together userscript](https://alexburka.com/misc/reddit_markdown_corrector.user.js) for you and /u/gnzlblg_! 
around 35m sunjay answers basically your question about chalk, essentially saying it's not a general purpose prolog(-ish) implementation, and is basically a purpose-built system for the rust compiler.
This was asked during the talk, so I’ll answer as best I understood the response. As I understand it, there is a minimal language they’ve written that is only used for testing chalk, integration like tests. There are no plans to expose this outside the testing framework. Otherwise the engine is programmatic API only, to be integrated into Rust cat some point. Now, I did get excited about the idea of using this as a more general purpose library too, and it sounds like that should be possible.
&gt;So, what you're saying is that people aren't allowed to talk about this issue? You are trying to put your words into my mouth, let's not do that, because these are not mine. Neither do I claim that MIT has anything to do with availability of the package on Crates. Instead, take a look at the claims that actix made on their website and documentation, and compare it with the expectations of those who think that certain aspects of the development are unacceptable, and that people "are felt betrayed". Actix is advertised as "type safe, feature reach, extensible, and blazingly fast". Do these propositions still hold? Yes. Is there anything about UB-free codebase? No. Is there anything about acceptable level of unsafe blocks? No. Is there anything about the obligation to maintain a certain level of speed and quality of responses on code reviews/requests? No. Then, on what basis anyone should "feel betrayed" and "regard this behaviour unacceptable" but a deception of their own imagination of how things were promised to be implemented in this project.
When has progress in web technologies *not* meant almost breaking everything?
The worst part is that when I clicked the "Share" button, it didn't even give a URL! It just had buttons for email, tweet, etc. I clicked the email button and it opened my email client with this link: https://onlinexperiences.com/Launch/Event.htm?ShowKey=44908&amp;DisplayItem=E265931 I think that link actually works, but it should really just show you the link when you click "Share" (like it does on, say, StackOverflow).
No, the engines are shared, it's the UI that's in Java (and that's Android-specific)
I believe they published a learned hash function. That could conceivably lead to invalid indices, but again I'd imagine there's explicit guarantees/checks.
Complexity doesn't miraculously go away because the compiler is doing it.
The GitHub repo for [Chalk](https://github.com/rust-lang-nursery/chalk) has more to say.
This is a nice writeup of the bug, but as a "debugging story" I was left a little unsatisfied. You ended the blog post rather abruptly. I kind of expected to see the *actual* code that the buggy mutagen was producing (after you showed the hypothetical expanded code), and how it got that way. As it is, after reading I don't understand why you got the original "static method" error or what you actually changed in mutagen to fix it (you mentioned `self_sym` but it's not clear what that refers to). I'd be interested if you could expand on the fix. 
I see that part of the problem is a bad error message. E0424 means "`self` used in static method" (what the message says) but also "`self` used as variable name" (what you were doing). 
Oh thanks, didn't know the videos were mirrored on youtube!
Yeah when sharing the link I was aware that this new site was crap but didn't know of a better alternative when linking to it. It is comforting though to see the responses in this thread. If everyone feels that way about it then it won't stay around for long :).
If the contents of the file is known at compile time, you can use the include\_str!() or include\_bytes!() macros provided by the standard library. This will include the bytes of the file into the binary, and return a reference with a static lifetime.
&gt; It's not a clusterfuck. It has problems, but so do Linux distros (keywords: pulseaudio, systemd, wayland). Linux has plenty of issues, but at least it doesn't have telemetry built-in that you can't disable. Besides that, while I think Windows 10 is relatively usable, I admit that I want to gouge out my eyeballs every time I have to open anything with a Metro UI, like the control panel.
Just the presence of [dev-dependencies] mutagen = "0.1.1" mutagen-plugin = "0.1.1" leads to: graph-service/target/debug/build/mutagen-28d4cc400087a244/build-script-build` (exit code: 101) --- stderr thread 'main' panicked at 'called `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: "No such file or directory" }', libcore/result.rs:945:5 cargo 1.28.0-nightly (e2348c2db 2018-06-07) Running `cargo mutagen` gives the same error. Also, I use `proc_macro`, which appears to be incompatible with `custom_attribute` - can I just use on or the other?
It's the same as your code above, except with `NonCopyDrop` being (or containing) a `&amp;mut`. So if you're correct about mutable aliasing, your code is also undefined behavior.
Thank you! This is so much easier than trying to use the baffling new air Mozilla site
Honestly, if an integer constant fits into the requested float type, it should coerce. Not being able to say `let x : f32 = 5` I think is silly.
I use both `proc_macro` and `custom_attribute` in [flamer](https://github.com/llogiq/flamer), so they are likely compatible. I recently had a rustup (but will now need yet another one), that may be the culprit. Is your code publicly accessible?
You're right. I failed to shine light on the underlying problem, which is indeed the confusing error message.
&gt; You are trying to put your words into my mouth, let's not do that, because these are not mine. No you didn't *literally* say that, but you *strongly implied it*. They said that actix-web's behavior is unacceptable. You then quoted the MIT, acting as if that's some sort of proof that actix-web's behavior *is* acceptable. They didn't say "illegal", they said "unacceptable", which is a subjective opinion. So the MIT is completely irrelevant. So since the MIT is completely irrelevant, what purpose does quoting it serve other than to try to tell them that "no, you're wrong, it is acceptable"? Also, you said this: "If it's unacceptable for yourself, you should not use this library, which is exactly the point made by the license agreement" Once again, your implication is, "the MIT is right, you're wrong, if you don't like it then just don't use the library, stop arguing about it". You may not *literally* say that, but that is how other people are interpreting it. &gt; Actix is advertised as "type safe, feature reach, extensible, and blazingly fast". Do these propositions still hold? Yes. Is there anything about UB-free codebase? No. Let's not word-lawyer here. "Type-safe" implies a certain level of correctness. If a library claims to be type-safe and it has pervasive undefined-behavior, I *would* call that false advertising. In fact, undefined behavior often *causes* type-unsafety, so you can't even say that "type-safe" is technically correct! In addition, there is a *general* expectation for *all* Rust crates: that they are safe and don't have undefined behavior. This is a reasonable expectation, especially because *the Rust language itself encourages this expectation*. Every mention of unsafe in the book (or otherwise) is that "you should not use this to do unsafe things, you should use this to do *safe* things which the compiler cannot prove". In other words, if a Rust program causes undefined behavior, then that Rust program is *wrong* and must be fixed. This is not *my* opinion, it is the opinion of the Rust team, the Rust books, and the Rust community as a whole. It is a community standard. It is reasonable for some people to feel betrayed by that standard being broken, especially given the *unbelievably bad* consequences of undefined behavior. This is serious stuff. &gt; Is there anything about the obligation to maintain a certain level of speed and quality of responses on code reviews/requests? No. Putting a public crate up does have a lot of implicit promises toward the community as a whole. Especially a large crate that many people rely upon. You seem to be focusing a lot on technical/legal obligation. You are correct that they are not *legally* obligated to do anything. Everybody knows that. You are correct that we cannot *force* them to do anything. Everybody knows that. But that doesn't stop people from having *expectations*, especially based upon *community standards* which are enforced *by the community*. You're not going to convince anybody that they are wrong for having those expectations (because they're not wrong).
Just to make sure that we are on the same page, the "right" order doesn't compile either: [https://play.rust-lang.org/?gist=d53f49a1506d4a1552ea705a7322c67e&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=d53f49a1506d4a1552ea705a7322c67e&amp;version=stable&amp;mode=debug&amp;edition=2015) simply because the syntax is for associated types (as you mentioned but I still misunderstood you first).
Where exactly will this event be? I'm doing my PhD in the Computer Lab and work with Rust on the Raspberry Pi, so this is right up my alley.
The Junction.
yes I do!
That sounds like a good design. In Rust I'd let Cell be Cow&lt;Vec&lt;u8&gt;, &amp;[u8]&gt; to deal with "maybe needs copying". For the stream I find the idea of an iterator yielding iterators quite nice. That would allow code like: for row in rows { for cell in row { //do smth } }
I'd say that if reliability is a concern for the MVP, then use Rust - it rids you of a lot of unpredictable errors in production that dynamically typed languages tend to have. If you just want to hack something together as a proof of concept and see if works, go for a higher-level language. Python is a good candidate because it has libraries and frameworks for pretty much everything ever and is not boggled down by decades of legacy and poor design decisions of JavaScript, and does not suffer from lack of backwards compatibility like nodejs.
https://www.youtube.com/watch?v=Pc6ednHfsQg mirror
Integrating callbacks with FFI is a must of course.
I would love a section on how to efficiently work with more complex structures (HashMap/Vec etc.) across FFI-boundries.
Yep, that's something I've had to do at work. For example, being able to pass in a `progress` function that gets periodically called in order to update a progress bar in the GUI. One thing you often have to deal with is thread-safety and affinity. A lot of GUIs will crash (or silently break) if you try to update them from a different thread.
Yep, that's definitely worth devoting several paragraphs to.
How do you think this would end up looking? From my experience, using a `HashMap` or any other type across the FFI boundary is normally just a case of writing bindings that handle allocating (`Box`) and destroying the object then exposing a bunch of functions that wrap the object's methods. There are a couple issues you need to deal with in terms of exception safety (catching a `panic!()`) and null pointers, but I've already published a [ffi-helpers] crate for dealing with these exact problems. [ffi-helpers]: https://docs.rs/ffi_helpers
Exposing Rust traits and structs as C++ interfaces and classes respectively. There seems to be very spotty support for this at best. The rust_swig crate initially looks spot-on, but it can’t even support ToString because it doesn’t allow returning of owned strings. This is the main justification I’ve been given for not using Rust at work. All management understands is that FFI is C, so they think we’d have to rewrite the entire codebase in Rust to use it. Because they don’t see how it could interoperate with QString, QVector, etc algorithms without copying all the data. The rust_cpp crate does an excellent job providing access to C++ code, but I’d need to do the opposite direction since Rust mostly makes sense as a callable library due to the lack of good ui support. And yes, I am aware of the qt_bindings_generator, but I’ve only seen an example of that being used with QML, not exporting QVector, QString, etc for another Qt library to call. And it looks like requires a more complex toolchain to support it. rust_to_cpp makes more sense to me than qt_bindings_generator if the types are binary-compatible with their C++ counterparts, but I haven’t put that to the test and it doesn’t seem to be maintained anymore.
What does vectorizing mean? 
Could it also be used to minimize the attack vector (for Firefox) on used crates and on crates.io?
See [this small cffi lib](https://github.com/YosaiProject/yosai_libauthz/blob/master/src/c_abi.rs) as an example. This lib is used to bridge python with rust. Why #[no_mangle]? Why is there a panic::catch_unwind( block? Why was slice::from_raw_parts used? General questions about best practices, such as should serialized data generally be used to pass information between rust and other language rather than resolving specific types? Mapping rust types to c types would help!
You could also look into a coroutine/green threads/fibers library like [May](https://crates.io/crates/may) or [Corona](https://crates.io/crates/corona) .
&gt; That sounds like a good design. In Rust I'd let Cell be Cow&lt;Vec&lt;u8&gt;, &amp;[u8]&gt; to deal with "maybe needs copying". I would not, because it invites multiple small allocations. Instead, I find it best to let the user provide its own "buffer" to write into. The user can choose to use a `Vec&lt;u8&gt;` for simplicity, or can instead use some form of arena to amortize allocations. &gt; For the stream I find the idea of an iterator yielding iterators quite nice. Hum. I had not thought about that as I was going from a `Cell` iterator at the bottom to a `Row` iterator built on top, but I really like the interface you've gotten here. Very intuitive and easy to use.
This website is probably the biggest pile of junk I’ve ever see and whoever is responsible for it probably should be fired. 
Related thing that should be mentioned: it's extremely easy to accidentally violate Rust's `Send`/`Sync` rules if a library invokes a callback on a different thread than the one that registered it.
That's a really good point! Have you got any ideas for how to approach this? As far as I know, the only real "solution" is to loudly document when a callback (or object in general) is not thread-safe.
Well, it's just a matter of setting a`Send`/`Sync` bound on the callback argument in the safe wrapper. But this is easy to forget, and rustc cannot help you there.
I would say that one of the things I find hardest is working out the ownership semantics of the C code. If it's not documented, it normally requires reading through the source of what you want to integrate. Also, if you own the C data, is it safe to deallocate with `libc::free`, or is it not guaranteed that it was created using the system allocator? Another is callbacks, something I very much struggled with. I was trying to wrap pacman (libalpm) and there were callbacks with variadic parameters (printf-like logging), which I don't think I managed to get working. I tried to do something with trampolines, but I didn't understand it sufficiently.
&gt; Because they don’t see how it could interoperate with QString, QVector, etc algorithms without copying all the data. Wouldn't you have the same issue when working with a non-Qt library anyway? That said, it should be rather straightforward to write a wrapper class that exposes the Rust library using a Qt-friendly API. Sure you may need to do an extra copy here or there, but from my experience you typically try to expose a Rust module using a high-level interface, meaning the copies are typically once-off and not a massive issue. &gt; The rust_cpp crate does an excellent job providing access to C++ code, but I’d need to do the opposite direction since Rust mostly makes sense as a callable library due to the lack of good ui support. This is the use case I'm most familiar with. At work I was trying to interface a Rust DLL (about 15kloc) with a legacy GUI application. I found it tends to be easier to write bindings manually instead of relying on some sort of binding generator. My FFI bindings ended up exposing about 20 or 30 functions in maybe 200 lines of code. I think a good rule of thumb is to try and keep things high level and expose a small API surface. As a bonus, this made things quite maintainable and uncoupled from the rest of the application.
&gt; Alternate link on Mozilla's YouTube channel: https://www.youtube.com/watch?v=Pc6ednHfsQg *(from /u/bobdernardo's [comment](https://www.reddit.com/r/rust/comments/8uuvti/footage_of_june_rust_bay_area_meetup_chalk_gui/e1isfol/))*
Holy crap this is the worst video player site I've ever seen. What the hell is mozilla doing?
Nope, I don't think it is for now. However, Tidis (https://github.com/yongman/tidis) might be useful because it provides Redis protocol API (string, list, hash, set, sorted set).