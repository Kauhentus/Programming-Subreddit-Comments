The biggest issue here is actually `step_trait`. Alacritty uses newtypes `Line` and `Column` for indexing the grid. There's a form of indexing with a range of lines: grid[start..end] I can't recall specifically why, but this needed the step_trait to accomplish.
Thanks for posting the link!
This isn't too far from working on Wayland. There's just a bit of work to get back on the Glutin main development line and also upstreaming a few features.
Thank you for sharing. It makes me happy to hear this promoted somebody's interest in Rust!
Shouldn't need to recompile; simply change it in the config file. If you have a config file in the XDG_CONFIG_DIR, this one takes priority.
If you're interested in bounded space summarization algorithms I'm always looking for contributions of new algorithms to [quantiles](https://github.com/postmates/quantiles). Each new algorithm is a separate effort to the existing implementations. The project uses randomized testing via quickcheck and there are examples in-repo, if that's something new to you. 
You can with sixel support, see [here] (http://saitoha.github.io/libsixel/) for some fancy examples. My terminal emulator which is also written in Rust supports them, with a true color extension :) With sixels and a fast enough terminal you can even [play](http://www.hnng.moe/f/Ly6) (may be NSFW if you aren't in Japan) videos inside it.
That's not my question. Let me phrase it again: Why did the author decide to license under Apache, especially since it required more effort since they had to rewrite an existing library to do it? I merely added a comment on my motivations towards my licensing choices to add some context as to why I was curious.
I just gave it a try. In fact this is the first time I've come out of lurking and actually installed Rust! You're absolutely right, it's a speed demon. I ran a `find /` and the output speed is massively smoother than that of Terminal.app. If this gets a few extra little perks like tabs, scrollback and in-app configuration, I could see myself switching to this for sure.
Is there any way to kill a child process while another thread is waiting on it? Both `wait` and `kill` take `&amp;mut self` from the `Child`, and `wait` is blocking, so it looks like even if the child was in an `Arc&lt;Mutex&lt;_&gt;&gt;` or whatever it would still be locked for the entire duration of `wait`. Are there any other options I've missed? (Edit: I guess anything like this would be fundamentally racy, because the child might finish right in the middle of `kill`, and the waiting thread might recycle its PID before the killing thread resumes?)
Excellent. Currently we don't ship with any terminal and just recommend `weston-terminal` as a terminal (even though it's not very good). Would love to package Alacritty with Way Cooler 
When you recompile it's included in the binary as the default configuration right? So it should have changed the font size.. 
Just curious, why does `Vec&lt;T&gt;` tend to panic rather than returning a `Result` in its methods?
Here's the complete main.rs: extern crate sdl2; use sdl2::event::Event; use sdl2::keyboard::Keycode; use std::collections::HashSet; use std::time::Duration; const map: [[usize; 13]; 11] = [ [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] ]; struct Point { x: f64, y: f64, } fn mag(point: Point) -&gt; f64 { let x: f64 = point.x.powf(2.0); let y: f64 = point.y.powf(2.0); return (x + y).sqrt(); } fn sub(i: Point, j: Point) -&gt; Point { let temp: Point = i; temp.x = temp.x - j.x; temp.y = temp.y - j.y; return temp; } fn sn(player: Point, m: f64, b: f64) -&gt; Point { let y: f64 = (player.y - 1.0).ceil(); let x: f64 = (y - b) / m; return Point {x: x, y: y}; } fn se(player: Point, m: f64, b: f64) -&gt; Point { let x: f64 = (player.x + 1.0).floor(); let y: f64 = m * x + b; return Point {x: x, y: y}; } fn ss(player: Point, m: f64, b: f64) -&gt; Point { let y: f64 = (player.y + 1.0).floor(); let x: f64 = (y - b) / m; return Point {x: x, y: y}; } fn sw(player: Point, m: f64, b: f64) -&gt; Point { let x: f64 = (player.x - 1.0).ceil(); let y: f64 = m * x + b; return Point {x: x, y: y}; } fn step(player: Point, slope: f64, sector: u32) -&gt; Point { let intercept: f64 = player.y - slope * player.x; // step in a cardinal direction let n: Point = sn(player, slope, intercept); let e: Point = se(player, slope, intercept); let s: Point = ss(player, slope, intercept); let w: Point = sw(player, slope, intercept); // step to the next line let mut next: Point; next = match (sector, mag(sub(e, player)) &lt; mag(sub(s, player))) { (0, true) =&gt; e, (0, false) =&gt; s, (1, true) =&gt; w, (1, false) =&gt; s, (2, true) =&gt; w, (2, false) =&gt; n, (_, true) =&gt; e, (_, false) =&gt; n, }; // begin checking the map let x: usize = next.x as usize; let y: usize = next.y as usize; // for horz lines if next.y == next.y.floor() { if map[y as usize][x as usize] || map[(y - 1) as usize][x as usize] { return next; } } // for vert lines else { if map[y as usize][x as usize] || map[y as usize][(x - 1) as usize] { return next; } } return step(next, slope, sector); } fn quadrant(radians: f64) -&gt; u32 { let x: f64 = radians.cos(); let y: f64 = radians.sin(); if x &gt;= 0.0 &amp;&amp; y &gt;= 0.0 { return 0; } if x &lt;= 0.0 &amp;&amp; y &gt;= 0.0 { return 1; } if x &lt;= 0.0 &amp;&amp; y &lt;= 0.0 { return 2; } if x &gt;= 0.0 &amp;&amp; y &lt;= 0.0 { return 3; } return -1; } 
No, I'm not really looking for a window manager, that's GUI, I'm looking for it in CLI! Following the CLI workflow I'm used to with tmux. I want a portable CLI I can use on any OS instead of i3, etc, simple and that can display real images and graphics in its panes. We now have terminals inside graphics (GUIs), but no graphics inside terminals. Thanks for your condescendence.
Out-of-bounds indexing and integer overflows in capacity calculations tend to result from bugs or malicious attacks, and don't really have a good recovery route. Out-of-bounds indexing in C and C++ will either segfault (bad) or return a pointer to memory that might be used elsewhere (really bad). At least Rust tries to catch it in a way that's somewhat easier to debug. However, there is `get()` and `get_mut()` for non-panicking indexing which return `None` in the out-of-bounds case. Integer overflows can't really be handled any better. You could use saturating arithmetic but then you have to handle the case where resizing the `Vec` may not actually make it any bigger, and that's just asking for problems. And anyway, on 64-bit systems the chance of overflowing a `usize` in a way that's *not* a bug is incredibly small. Even with x86-64, which only currently uses something like 48 bits of a pointer, that still allows an address range of ~280 TB.
I didn't realise it copied the conf file by default. It's working now.
I think it's because it needs to start the .NET virtual machine.
This isn't completely true. The Features page says that there is "experimental code generation for ARM," and "code generation for x86-64." In contrast, it says there is "*mature* code generation for x86 (32-bit)" (emphasis added).
Serde itself is just the framework, you have to pick a "backend" crate that takes a serializable type and serializes it. Supported formats and their implementing backends are listed [here](https://serde.rs/#data-formats). (In fact, there's even a backend for Python's pickling format, but you probably don't want that specifically unless you need it for Python interop.) For behavior equivalent to pickling in Python, where the encoding is a byte stream of arbitrary structure, I would recommend the [`bincode` crate](https://crates.io/crates/bincode), which can work with either Serde or `rustc-serialize`. In fact, it provides convenience functions in its submodules for either crate so you don't have to do anything yourself if you're using types that are already serializable, which is basically all the collections types and primitives in the stdlib (including `HashMap`, `String` and `[u64; 3]`). I would actually recommend using just the `rustc-serialize` feature, which compiles faster because it has fewer dependencies. In your `Cargo.toml`: [dependencies.bincode] version = "0.6" default-features = false features = ["rustc-serialize"] Then in your app: extern crate bincode; use bincode::SizeLimit; use bincode::rustc_serialize::{decode_from, encode_into}; use std::collections::HashMap; use std::io::File; // a useful shorthand type Delta = HashMap&lt;String, HashMap&lt;u8, [u64; 3]&gt;&gt;; fn load_delta() -&gt; Delta { // This will panic if the file doesn't exist. // You should probably prefer to just return a new empty `Delta` instead. let mut delta_file = File::open("delta_file").expect("Could not open file for reading"); // `SizeLimit` is mostly for dealing with reading over the network, where an attacker // could send a large amount of data to try and run your server out of memory. // Since we're reading from the local filesystem, we won't worry about that. decode_from(&amp;mut delta_file, SizeLimit::Infinite).expect("Failed to load Delta from file") } fn save_delta(delta: &amp;Delta) { // This will create the file if it doesn't exist, or truncate it if it does. let mut delta_file = File::create("delta_file").expect("Could not open file for writing"); // Again, the `SizeLimit` is likely irrelevant for your use-case. encode_into(delta, &amp;mut delta_file, SizeLimit::Infinite).expect("Failed to save Delta to file"); } Obviously, this could be a lot better with respect to error handling, it's mostly just for demonstration. In a robust app or library, you would return `Result` from both methods and then handle it at the top level, printing useful messages for each error case and exiting cleanly. 
I think you want /r/playrust
It's because `Range&lt;A&gt;` has an iterator impl only when `A: Step`, which makes sense. We can't impl iterator ourselves because of coherence. We have to create our own range type for these. Would that be acceptable? I'm trying to remove nightly features from this crate and this is the solution I'm coming up with. The step trait is one of those things that will probably take forever to stabilize. It's been around for a while with no interest in stabilization. I would not rely on it.
I think it just loads a lot of libraries - supposedly the newer versions are much faster to start.
A REPL, like the ones in Xerox and ETHZ systems, is a CLI on steroids. Not only can you do what you would expect from something like bash, you can also access all OS APIs inside the REPL, interact with running applications (e.g. change the text currently selected on any specific window). A few examples, not the best ones, but there isn't much that survived. Editing an image on Symbolics Lisp Machine REPL. https://www.youtube.com/watch?v=o4-YnLpLgtk An overview of Symbolics https://www.youtube.com/watch?v=OBfB2MJw3qg Smalltalk-80 (See the context menu on the REPL and method messages as piping mechanism) https://www.youtube.com/watch?v=8yxCJfayW-8 And if you can stretch your imagination a bit, here is the documentation for Mesa/Cedar workstation environment, https://archive.org/details/bitsavers_xeroxparcteCedarProgrammingEnvironmentAMidtermRepo_13518000 Check how the debugger, interpreter and command window interact together. 
Thanks for sharing.
Thanks! Very interesting.
Very cool project, and an excellent writeup. And I'm so happy to see how many libraries you're contributing back to the ecosystem in the process! :) You mention using OpenGL but I don't see Glium in the dependencies, can I ask what you're using instead? What are the blockers for getting this running on Windows?
I didn't realise it wrote the default to a file, thought it just used it in-memory.
fyi, xfce-terminal-devel (on Arch, available from AUR), supports true colors. It's the one I'm using.
That was the vision of [Light Table](http://lighttable.com/)
&gt; is to have Cargo treat it as a dependency that cannot be upgraded Why can Cargo not update rustc for the user? If Rustup, is able to do so, then Cargo is artificially limited. Why are we artificially limiting Cargo from being able to help us?
Awesome! I'm excited to see better built-in fuzzing support in Rust in the future, but it looks like libFuzzer is a tool for Clang, not for LLVM. Am I incorrect?
&gt; Very cool project, and an excellent writeup. And I'm so happy to see how many libraries you're contributing back to the ecosystem in the process! :) Thanks! I'm using the gl binding generator and raw OpenGL. There was a lot of unknowns when beginning this project, and I didn't want to add learning the glium API to that list. This was a mistake in hindsight. There was one VBO management bug in particular that stole way too much of my life (like 6 hours!).
Bash is a repl. Or, at least the command line is. It's a repl for the language that is bash. I feel like you're really pigeonholing the term.
Powershell has a terrible syntax, and is incredibly slow. It's a shell made by folks that don't understand shells.
I think you are wrong on both counts. The syntax is as bad if not better than bash or CMD and is faster at runtime than CMD by a fair amount. Give it a try sometime. It might surprise you. In particular, the fact that it is object instead of text based is huge. Makes it almost like a full language. That combined with the fact that it runs on .Net means it's quite powerfull
Of course it cannot be done over text...., are you serious? I've got a déjà vu, do you know ms-dos graphics mode? I've programmed in it ages ago, it was graphics in the terminal, and it was once a successful game platform. The graphics came from the same terminal that output the text, simple! Now tile that with tmux (or some more powerful mux for that), that's what I'm talking about, I mean, the idea.
Ah yeah, you know what, I goofed that. The relationship wouldn't be direct, just like staticassert says. Rust would have to use the LLVM instrumentation that libFuzzer is using. 
https://github.com/jwilm/alacritty/pull/131 Removed all nightly features except for `proc_macro`.
When running a release build of Alacritty on Linux under Valgrind's DHAT memory profiler (as described [here](https://blog.mozilla.org/nnethercote/2016/10/14/how-to-speed-up-the-rust-compiler/)), it reports that most of the memory allocations at startup come from: * my GPU driver * `QuadRenderer::new` * the `notify` crate * fontconfig *Edited to add:* I had to patch Alacritty to use the [system allocator](https://doc.rust-lang.org/book/custom-allocators.html) to make DHAT measure allocations from Rust code.
I have given you a heart
Is it too late to add Glium now? Or perhaps go directly to Vulkano? :)
How is DOS graphics mode being provided by "the same terminal emulator that outputs the text?" DOS is essentially using a terminal emulator provided by the graphics card. When it switches from VGA text mode to VGA graphics mode, the text-mode features become inaccessible (the VGA mode is a single global flag). Having the graphics card do all the text rendering in a mixed environment (text and graphics both on the screen) is pretty cool. It's not very DOS-like, though.
Or IDE support. That way it can include everything from every crate you have. Actually, maybe rustdoc can do that when it builds local documentation.
I don't know about this project, but I'm glad there exists an Apache-licensed clipboard library for Rust now. Servo (which is licensed under the MPL) had to remove clipboard support because it had accidentally started using the GPL-licensed clipboard library, and Servo is under the MPL. See [issue #12805](https://github.com/servo/servo/issues/12805). Maybe we can use this one?
Indeed not very DOS-like, because it was in graphics or in text, but still, from the same console window, I realize that, and indeed I'm talking about something more, mixed, as you said.
When you move to Rust you lose the benefit of OTP design, right? Even a statically typed language would benefit from OTP considering there are a number of errors you can get that have nothing to do with types. I found that static typing was mainly beneficial in the development process as opposed to the actual runtime. Maybe I'm not thinking clearly on that, though.
&gt; From what I've heard from distro folks, programs whose only purpose is to seemingly circumvent distro packaging are frowned upon. Following the Debian community a bit, my impression is that it is more differenciated than just "frowning" upon such tools; it's rather specific shortcomings in existing "language package manager" tooling that are detrimental to the Debian packaging effort, like: - Reliance of external resources (downloads) for the build, and no good way to work with local-only resources. - No good support for co-installing distro packaged libraries and user-installed ones. Additionally, an language-specific package manager, from a distro perspective, should make it easy to automatically or semi-automatically create high-quality distro packages from the language package format. In the case of Debian, this means the resulting Debian packages need to be Policy-conformant, which requires the language "package manager" to be flexible enough to support all the established conventions (e.g. separate -doc, -dev, -dbgsym packages, if applicable). There are also requirements like avoiding code duplication between resulting packages to make security fixes more manageable, to name just one other. This is just a few things off the top of my head expected from a "good" package manager viewed from a distro perspective. Different packaging systems meet these goals to various degrees, and some do not do that well. This might lead to a "skeptic-by-default" view on such tools (speculating here, obviously). I'm not sure how cargo fares here; it was my impression that the Debian Haskell maintainers have figured out how to sanely manage a large collection of Haskell cabal packages, so looking at how it works there might provide some insight. 
So, this clipboard library doesn't link to any GPL code, but does depend on the existence of some program that must be named `xclip` which must accept some specific arguments. I'm planning to actually implement real X clipboard support at some point, but I think this hack is suitable for now.
When I develop rustup, I run `cargo run -- -y` to install my build and then test it live. Sometimes of course this results in trashing my rustup installation. You could also run `cargo run -- -y` with CARGO_HOME and RUSTUP_HOME set so that it installs to some temporary location. I mostly lean on the test suite though and only do the above as a final gut check, or for things that can't be captured in the test suite.
More clarification, rustup.exe and rustup-init.exe are the same binary. If you wanted you could also just rename rustup-init.exe to rustup.exe and it would work.
Does it support 24-bit color?
Yes.
Awesome write up. Thanks for taking the time. 
It's a relatively minor thing, but one thing that a terminal scrollback implementation can do and that tmux can't is provide pixel-by-pixel scrolling (e.g. on a two-finger drag). I've been surprised at how much nicer this is -- seeing the incremental movement makes it easier for the eye to keep track of how much you've scrolled, and the ability to display arbitrary scrolling velocities makes it easier to control and works better with things like inertial scrolling. It seems like this is something where Alacritty's rock-solid-60-Hz-updates could really shine, actually.
You're an inspiration to us all. I just wanted to link http://codegolf.stackexchange.com/, a site in which people like us like to gather. Code is poetry.
Tabs and in-app config would require a separate toolkit. As far as I'm aware this is just a raw OpenGl context. I mean there are OpenGL toolkits... hmm... 
This reminds me of an essay I had to write in high school English class arguing what the US should do about terrorists in the middle east. I thought it was a veiled way of getting us to support the Bush administration so I looked up terrorist propaganda and wrote in my best terrorist impression about how we should join them in destroying western civilization. I'm sure the NSA loves me.
It can be worked around, but it's not pretty. [Puttycyg](https://code.google.com/archive/p/puttycyg/) for example uses an internal network socket between the cygwin shell (a /subsystem:console app) and the putty application (/subsystem:windows). The conhost dependency is still there, just wrapped up in an invisible box and stuffed away.
I'd like to say for the record that I know just enough Rust to be equal parts horrified and impressed by /u/Arandur's shenanigans, malarkey, tomfoolery and nonsense.
I really should make a throwaway account for this, for I am ashamed. I made it to keep closures in maps and such to one line, but I think it could be used to make almost anything into a one liner. pub trait Instead { fn instead&lt;T&gt;(&amp;self, item: T) -&gt; T; fn instead_with&lt;F, T&gt;(&amp;self, f: F) -&gt; T where F: FnOnce() -&gt; T; } impl &lt;A&gt; Instead for A { fn instead&lt;T&gt;(&amp;self, item: T) -&gt; T { item } fn instead_with&lt;F, T&gt;(&amp;self, f: F) -&gt; T where F: FnOnce() -&gt; T { f() } } #[cfg(test)] mod tests { use Instead; #[test] fn test_works() { assert_eq!(20, println!("Ok").instead(20)); } #[test] fn test_closure() { assert_eq!(20, println!("Ok").instead_with(||20)); } } 
Thanks for your thoughts on the README, I'll change it. Regarding a pubsub system; I have no need for it atm, maybe in the future? I'm not sure what to make of your "cryptic nix code" comment, it's hardly more scary than a configuration file like Cargo.toml. see: https://github.com/fractalide/fractalide/blob/master/nodes/msg/clone/default.nix In fact the above can be simplified even more to: { agent, crates }: agent { src = ./.; crates = with crates; [ rustfbp capnp ]; } &gt; elegant for the important stuff (message types, nodes, edges, services) I'm very keen to know exact code snippets which you consider not elegant. Having said that, I've been thinking about a different DSL, but I'm uncertain what it would look like. I'd quite like to move towards a lisp that is able to express explicit inputs and outputs but that would be solving a problem the current DSL doesn't give me, as its very suitable for its purpose of expressing flow and constructing subgraph interfaces. 
You're *painfully* close. If you want to loop over mutable references to the items in a vector (or basically any container, most of them follow the same pattern), your loop should look like this: for b in &amp;mut bar { // ... } And then when you're assigning to `b.bar` in the loop, you're moving `baz` which isn't allowed there. Remember that vectors in Rust aren't implicitly copyable like primitives, they have to be explicitly `clone()`'d. You can fix this in a few different ways: let baz = vec![10, 11, 12]; for b in &amp;mut bar { // Make an explicit shallow copy of `baz` b.val = baz.clone(); } for b in &amp;mut bar { // Create a new vector and assign it b.val = vec![10, 11, 12]; } for b in &amp;mut bar { // Overwrite the values in `b.val` with the values in `baz`, does not reallocate // However, this panics if the two are different sizes b.val.copy_from_slice(&amp;baz); } for b in &amp;mut bar { // Empty the vector and copy values from `baz` into it // Supports differing sizes, but may reallocate to accommodate additional elements. b.val.clear(); b.val.extend(&amp;baz); } 
Zero-semicolon Rust is easy. You can sequence two side-effect expressions with a function call. fn seq(_a: (), _b: ()) {} fn main() { // Print foo forever. seq(println!("foo"), main()) } You can emulate let-bindings using closures. use std::io::prelude::*; fn main() { fn seq(_a: (), _b: ()) {} // Read a line in, then echo it right back out. (|mut a|seq(stdin().read_line(&amp;mut a),println!("{}", a)))(String::new()) } 
Are there any benchmarks, even a side by side video of Alacritty and another terminal emulator doing the same task? It's hard to take the "fastest" title without so much as a single benchmark, no matter how contrived.
If I remember correctly, I stuck a `class A {};` at the top before I turned it in. Received full marks for that item. It was far and away the stupidest course I've ever taken. 
&gt; Also, how will you stop code from simply importing internal modules? The filesystem has no visibility mechanics. In Python this is not a problem because the language doesn't have any visibility mechanics to begin with. You could just make submodules private by default and require an explicit reexport to make them public. There's actually a similar concept in Python, where it is common to rexport things in `__init__.py`. 
Don't forget the redundancy between extern crate and use. I can't think of any case where I'd want to import a crate but not use it.
The render thread holds a lock on the terminal for as little time as possible while building the display list. During this time, the parser cannot operate on it. The parser _could_ continue in the background during this time. It would need to buffer up all of the state changes though until the render thread releases the lock. This isn't necessarily better because the render thread will still have to process a bunch of state changes instead of the parser doing it inline. This actually turns out to be more work overall with the addition of having to store this list somewhere. Alternatively, the terminal could be COW and they could be fully parallelized. This isn't a clear performance win due to the large malloc and copy required. It also uses more memory which many people are sensitive to. There may be an optimization here where it's double buffered so you can avoid reallocating regularly, but you will still need to copy the state at some point. There are options, but none of them are clearly performance wins. The only way to know would be to try these things and measure. I would like to actually try these things. The only real difficulty is finding time for them. By the way, I'm glad you posted this because I did think of one optimization that could be added now to improve rendering time--I may not have considered it otherwise. The render thread is actually holding the lock a bit longer than is necessary. Once the display lists are computed, the lock should be released, and then the upload and draw commands should execute. Maybe that's what you were suggesting actually. Anyway, thanks :).
[I also use a GPU-accelerated terminal emulator.](http://www.secretgeometry.com/apps/cathode/)
The thing that really sets Rust apart is the lack of mutable aliasing, and other languages "handle" it by not doing squat. In C++, Python, etc. you can mutate stuff with wild abandon, and it's on you to not write bugs. Rust encourages you to structure your code in a way where mutation bugs can be statically avoided. This often takes a lot of work, but it does bring benefits in performance and correctness.
foo[i **as usize**]
The ability to factor out common type parameters would also be nice. Writing Foo&lt;'a&gt; is ok on the struct def, but putting it twice in every impl block and every function definition is silly. (Yes, I know why it is that way, but I wish the common case was handled better)
Normally I prefer smooth scrolling, but in some situations line-based scrolling is more appropriate, when you’re visually diffing adjacent lines. Sometimes multiple lines at a time would be more desirable for similar reasons. But yeah, multiplexers are a hack and you can implement many of their features so much more nicely in the emulator. Implement scrollback and Windows support (including the API call approach to text styling that Windows uses) and I’m probably sold.
needs better borrow checker inference. I don't appreciate spurious indentations.
Neither rust nor llvm really have a concept of 'secret' data; in theory the compiler is free to copy data to the stack when it wants to, and it might decide to do so when it believes it would be more efficient. I think it would be helpful to specify exactly which types of attacks this zeroing is supposed to thwart. 
I take it there's no way to quickly change the font size with a keypress -- like if I'm showing the screen to someone with bad eyesight for just a few seconds, or if I want just one window to have larger or smaller text? Not being able to change the font size with a keyboard shortcut has so far prevented me from switching to a minimalist emulator.
The GC pauses are getting way better though and last I checked, they had sub millisecond pauses. However, sub millisecond &gt; 0, so if that's important to you, definitely do your due diligence.
Agreed, but most of the time I just throw my "spurious indentations" into a separate function or clone my way to happiness. It could definitely use some attention though.
for a terminal emulator there is ConEmu. 
Thanks, I would have missed it! 
So I'm also pretty new to rust as well and I played around with your code and as the other commenter mentioned you have to write a struct to avoid the box memory allocation. Which is kinda annoying and destroys the conposability of iterators with closures. Hopefully something like http://www.ncameron.org/blog/abstract-return-types-aka-%60impl-trait%60/ will save the day.
I rarely need a debugger in rust in contrast to other languages. But when I need to debug I use gdb and I recently found out if you use visual studio code with the rust and gdb plug-in it's a really good IDE like experience. 
Secret storage is not really something the language can provide - you can zero on drop, but what about the copy of that secret that got paged to disc? So you need to use the (platform specific) memory API to allocate a page and then lock it from being paged. Once you've done that, freeing the page zeros its contents (or, rather, the kernel zeros it before mapping it again). A library doing this to provide a SecretArena would be quite useful!
Or you just use docker or other image based solutions instead of a really niche tool. 100 machines is tiny. You can spin up a 1000 matching machines based on the same disk image in AWS at the click of a button or so.
Hey /u/troutwine in the runner program .map(|f| f64::from_str(f)) .filter(|f| f.is_ok()) .map(|f| f.unwrap()) could be replaced by .filter_map(|f| f64::from_str(f).ok())
For map_if, I'd probably just ensure that the function I'm mapping with returns the original element when necessary instead of using a higher order function that's potentially unfamiliar to others. map_at looks interesting but I'm not sure I'd ever find a use for it.
Docker and other image based solutions are not truly reproducible systems, they are "zip file" systems. Docker's content addressable store SHA resolution is at container level whereas nix's SHA resolution is at package level, which is the correct resolution. You are still faced with managing the system configuration of the contents of the image based solutions using a convergent model, which is far from ideal. Yes, you can put nix/fractalide inside a docker image if you want to thus you have a congruent system configuration model in an image based solution. But why would you do that when nix subsumes image-based-teardown-and-setup approaches? Yes you can use a convergent system configuration model when you tear down and setup a new instance. That gets the actual disk state closer to the target disk state. Again, all this fighting with divergent and convergent tools when you can just use a congruent tool which subsumes the status quo. 
Thank you for the writeup. Very interesting read. Looking forward to part 2. I have some followup questions: Can the fieldnorm be overwritten, when I want some field to be better scored? When decoding/encoding the inverted index, where do you store the bit width of each block? Have you considered using "fancier" decoding/encoding algorithms like [TurboPFor](https://github.com/powturbo/TurboPFor)? And do you have any benchmarks for us? Like, how fast can tantivy execute querys on different sized collections? 
Since it's a rather common mistake/confusion, I'd like to make sure you did compile the code with optimizations enabled (release mode) before comparing the runtime performance. If not, the comparison may be way off. https://users.rust-lang.org/t/why-does-cargo-build-not-optimise-by-default/4150
I'm trying to implement a generic function to calculate the Eukildean norm of a slice of Numbers, using the num::Num trait to define what's a valid Number. The code looks like this: extern crate num; use num::Num; fn euklid_norm&lt;T: Num&gt;(v: &amp;[T]) -&gt; f64 { let norm_sqr = v.iter().fold(num::Zero::zero(), |sum, &amp;elem| {sum + elem * elem}) as f64; norm_sqr.sqrt() } This doesn't compile, it fails on the first line when trying to cast to f64 with `error: the type of this value must be known in this context`. How do I manage to convert to `f64`? 
Whats "not nice" about it? I think it works great in swift and python 3.6.
Ah, a fellow connoisseur! I'm glad you appreciated my work. 
I was agreeing with you :P I was saying that since matches can already do it there's no good reason not to allow it here 
 if let Some(x) = y &amp;&amp; let Wrap(inner) = x { inner.call(); }
The fieldnorm cannot be overwritten. What will probably be implemented some day, is some way to boost specific term, and configuration on the query parser side, to boost a specific field. I burn one byte for the bit width of each block. If I remember correctly, the codecs in simdcomp are smarter than this. Since the maximum value is 32, you actually only need 5 or 6 bits, so grouping this information can shave off a few bits here and there. I just wanted to use the library but still have control over iterating on the different blocks, so I went for this trade-off. I did also considered TurboPFor, and also a VInt based codec actually implemented by my boss at Indeed (https://arxiv.org/abs/1503.07387). My choice was not really educated to be honest. One reason I put TurboPFor aside is that it is too complicated for me to eventually code a SIMD implementation in Rust. The VInt solution has a bunch of benefits... I may actually switch back to that. Anyway, all of these solutions are so fast, that as long as you use one of them, compression is dwarfed by all of the other stuff you are doing in your search. I am afraid I don't have any proper benchmark figures yet, that I could run against Lucene and tantivy yet. I can give a ballpark estimate over the wikipedia benchmark. I can tell you that the query barack obama, on EN-wikipedia (around 5 millions document), expanded to 4 terms like in the blog post, takes around 1.5 ms to run and score the 11080 matching documents. A query like "the" on the other hand, will match almost all of the document and will take 158ms. At the moment, Tantivy is very bad on intersections, as it does not skip anything whatsoever. (there is no skip list yet, and I do not skip blocks either)
The tl;dr is: insanity. It's the prose that makes this hilarious. No way to tl;dr that, unfortunately.
Or [this](https://github.com/rust-lang/rust/pull/37336) maybe?
ZeroMQ isn't dead, the creator died in this past year from cancer, but the project definitely lives on. 
Seems to be the case. That being said, are you then recommending ZeroMQ as the message passing library for Rust?
So it seems. Is is the best choice then?
My pleasure. I made a memory-only version first because I intent to use this in a long running server. `v0.0.2` will also include disk persistence however.
From my limited experience there is no good alternative to the big "Bus" or "MemMap" struct. You have one choice though: You can either let the CPU own that struct, or pass around a mutable reference to it in the CPU methods that need it (i.e., instruction dispatch and memory read/write instructions). I wouldn't worry too much about correctly modeling electronics hardware design. The most important thing is to keep the code understandable, which is independent of struct ownership choices if documented properly. 
This is my only qualm: &gt; Alacritty should be the fastest terminal emulator available anywhere. And then &gt; Alacritty isn’t concerned with trying to only redraw what’s necessary. The entire screen is redrawn each frame because it’s so cheap. If you want to be the fastest, you really should implement a [clipping](https://en.wikipedia.org/wiki/Clipping_(computer_graphics\)) strategy. &gt; Good clipping strategy is important in the development of video games in order to maximize the game's frame rate and visual quality. 
All I ever wanted from a terminal - simple, smooth as butter, easy to configure and made with rust :)
I understood your point. I was going further to say that powershell is probably better than bash in a lot of ways.
Huh. To each their own, I suppose. 
What is happening here? Is tig doing some trickery? Monaco 12pt, macOS Alacritty f6186b1 [Alacritty](http://i.imgur.com/cXvyP5V.png) vs [iTerm2](http://i.imgur.com/ktAeI9T.png)
Ahhhh. I see. So, between this and /u/oconnor663's answer, which is more likely to work (be implemented) for container types? ```for b in &amp;mut bar``` or ```for b in bar.iter_mut()``` ? It sounds like they (may) not map to the same thing(?). What's the difference? And thanks for the multiple options to copy ```baz``` having them all spelled out like that with explanations really helps a newbie. 
I can recommend ZeroMQ in general, I don't know how good the Rust bindings are, although from what I've seen it's mainly analogous to the underlying C library which is pretty good. I've been using it recently for a project at work (in python though) and it's very nice to use.
The former is basically just syntactic sugar for the latter, but not directly. It's just a commonly accepted pattern for the two (if both are implemented--they are on pretty much all stdlib collections, but not always on datastructures in external crates) to end up at the same iterator type, or at least have the same semantics. The same generally holds for `&amp;bar` and `bar.iter()`, which both yield immutable references, and `bar` and `bar.into_iter()`, which consume the collection and yield items by-value. The magic part is that the expression after `in` can be anything that implements [`IntoItetator`](https://doc.rust-lang.org/std/iter/trait.IntoIterator.html). It's got a generic impl for any `I: Iterator`, and it also has a bunch of implementations for specific types, namely the collections types, and one of them is `&amp;mut Vec&lt;T&gt;`. `iter_mut()` is just a regular method that returns an iterator. It's actually implemented on the slice type (`[T]`) which is then accessible through `Vec&lt;T&gt;` via `DerefMut`.
Oh thanks man for the info! 
What if you add the `ToPrimitive` bound to `T` as well and use `.to_f64()` instead of `as f64`?
For a text-based window manager with support for graphical X11 apps, check out [exwm](https://github.com/ch11ng/exwm)
You had me at &gt; The logo is so neat, you can feel it’s webscale.
Nice use of U+0305 'COMBINING OVERLINE'
Is this true? If so, I don't see it in the reference.
When this thread came up, I was just about to choose a password for a new computer, so I used your program for that. I generated 6 words (77.5 bits) which I now use. However, it's an awful lot of characters to type! What do you think about using a really large word list, so that the same security can be had with fewer words (and hence less typing)?
Thanks! 
I imagine that the shell would be responsible for that.
I just want to say "thank you" for taking the time to actually write documentation and provide examples! So many people think (not necessarily in the Rust community) think that just throwing code up on a repo is all it takes to get people to use it.
Can I fill it with 200×`' '` then?
That's what volatile operations are for.
It's definitely possible but I don't see where, the snippet seems balanced with 3 opening and 3 closing parens?
I see the submission of absurd solutions as a sort of institutional fuzzing. It's a noble service we provide. On the topic of poor homework grades, though, my SLOC counter received a grade of -14/10. The rubric was literally designed to allow for negative scores. That was the spark that ignited the fires of war. 
Thanks for pointing me in the right direction. A working example code looks like this: extern crate num; use num::Num; use num::ToPrimitive; fn euklid_norm&lt;T: Num + ToPrimitive + Copy&gt;(v: &amp;[T]) -&gt; f64 { let norm_sqr = v.iter().fold(0f64, |sum, &amp;elem| { match elem.to_f64() { Some(x) =&gt; sum + x * x, None =&gt; 0f64, } }); norm_sqr.sqrt() } Maybe error handling should still be improved by returning an Option&lt;f64&gt;!
main is calling itself?
Hmm... for performance reasons it might be better to first perform the `.fold()` with `T` (therefore the num::Num) and only prior to the `.sqrt()`perform the `.to_f64()`
There are 2 zeromq crates. The one I'm using needed a fix, will try to get a PR done soon.
There's wrappers or native libraries in a plethora of languages. And it offered epgm as a transport, which nanomsg didn't. And the socket types. Afair nanomsg didn't offer push/pull.
Looks like a fallback fonts issue.
I think it might be useful. I would like to know why the second one is much faster. If Rust tries to do zero-cost abstractions, shouldn't the imperative version also be just as fast? Say I got your second version and wanted to rewrite it into the first version so that it's more readable to those more used to imperative stuff but without the performance hit.
What sort of academic resources are there to dip my toes into affine types and affine logic? I've peaked around blogs and wikipedia, but it's rather limited on what it details.
I'm not an academic, neither do I know much of programming language theory, I'm afraid. I am, however, interested in practical applications, such as [session types](https://github.com/Munksgaard/session-types).
These things (things you define along the way to defining the full thing) are called pre-things in math (eg. preterm, presheaf). They also look like a good use-case for the [inheritance-like delegation](https://www.reddit.com/r/rust/comments/5m92s2/missing_syntactic_sugar/dc28wja/) mentioned in the syntactic sugar thread.
You've not heard of https://tessel.io/ ?
You're right, it's not. [Stuff surrounding the assignment operator is still somewhat up-in-the-air](https://github.com/rust-lang/rust/issues/28160), but nobody seems to have even brought up function arguments since 2015, and all the commentary surrounding the assignment operator seems to implicitly assume that function arguments go left-to-right, so I thought it was settled. My mistake.
It's all good! I strongly suspect this is one of those things that we're going to have to just define what rustc already does.
I thought this was a pretty legitimate question tbh
I've used nanomsg.rs in a 2-year private project. During this time there were some problems: * C library / rust wrapper version mismatch, some enums changed on C side and some functions failed. Though it's my mistake, it's clearly specified on nanomsg.rs project page what library version it expects, so you just need to pay attention during upgrades. * Change of return codes in some places in C lib: `would_block` was changed to `timeout`. * During dependency upgrade a year ago something broke, I didn't had time to debug and just rolled back the upgrade (maybe that's was the next issue in this list, I don't remember what happened well enough). * Issue I've just submitted PR for. C library added API to set max message size, and used 1MiB as default, so all my 400MB messages were dropped and after several attempts server aborted with an assertion from C code (probably another bug). That's mostly minor issues and all of them happened during C lib / rust crate upgrades. In production there were no problems. It's also worth to mention that there is a [pure rust implementation](https://github.com/blabaere/scaproust), though I've not used it. Edit: overall C lib is in maintenance mode and shouldn't change as often, and I think that's a good thing.
https://docs.rs/mitochondria/0.3.1/mitochondria/struct.OnceCell.html is a better abstraction for when you want to once-init something
Rust did not make your invariants explicit – you did! All it did was gently nudge you in the right direction. That said, I also have a hunch that those gentle nudges from the compiler lead to a clear and obvious design, and this is IMHO one of the not-really secrets to Rust's good runtime performance. For example, when writing [bytecount](https://github.com/llogiq/bytecount), we started with a pretty messy approach, with lots of unsafe code. Now we only have a single unsafe line, the code is even faster, and just recently I replaced two indexing loops with iterators on suggestion from [clippy](https://github.com/Manishearth/rust-clippy) for better readability, and – to my surprise – a modest performance improvement.
Does this mean Alacritty cannot correctly display Monaco on my system?
Ah, thanks. [This](https://is.gd/XLU9hd) compiles correctly, but renders wrong in the code listing (but correctly in the error message).
That doesn't solve the lifetime problem, since all the compiler cares about is the use of interior mutability. 
I understand. OP doesn't quite want to have those features, and that's fine—they should make this however they want. I'm just saying, those are the things I'd want. Not much more than what it already is, and certainly nowhere near the sophistication of, say, iTerm2. But if the author doesn't feel like it, I can certainly understand.
Why? Did you find the compiler messages rude? 😎
+1 on the brainfuck interpreter. It's dead simple to get working,and then you can try your hand at some obvious optimizations, then some less obvious ones. There's a bf program out there that draws the mandelbrot set in ASCII, you can use that as your test input. I'd link it but I'm on mobile. Other ideas: - Simple emulator - Game of Life, can also be as simple or complex as you want. You can use SDL or piston for this. - A program that plays/solves a game. (Snake, Rubik's, Tetris,...) - Reimplement some common cli utilities like ls, mkdir, grep, ... 
Hey asshat! You can't mutate an immutable, it's not your abomination of a face after all!
There's been lots of discussion around a possible `Carrier` trait to enable this. In the meantime, it's pretty simple to write your own `require!` macro to do the same thing.
Probably clippy yes. Clippy is not a rust feature, so there's no "stability" related to it. It's an independent tool. That said we do plan to do things that will make it be possible to run `clippy` on stable rst.
https://crates.io/crates/mdo In practice I use this crate only with complex option related code.
&gt; I would like to see more context on your errors [Here's my Stack Overflow post](http://stackoverflow.com/questions/41204134/rust-lifetime-error), but that has a simplified version of the code, so it isn't that enlightening. Probably the simplest method to replicate the exact error would be to take the previous state of the code I linked and add a RefCell. It doesn't matter which, since the error comes from losing covariance due to interior mutability. &gt; Another good solution would be to refactor the protos function to operate on a reduced parameter list of DexFile fields instead of a DexFile itself. Not only is that incredibly verbose, but it would have required duplicating and inlining the logic of all of DexFile's methods, which is even worse. 
I can't find the reference, but I saw a post a while back which suggested that the HashMap was faster (over twice as fast if I remember). In addition, the HashMap from this crate: https://github.com/sfackler/rust-phf was slightly faster than the one from the standard library (but barely).
Last I heard, the Rust standard library had three independent implementations of this for internal use. (`try_opt!`, `option_try!`, and `otry!`)
If you haven't written many macros, this one is a fairly simple one to write yourself and so might be nice practice.
I'm pretty sure that we are talking about different things here (this subreddit is about The Programming Language Rust), but I totally agree that Rust on Xbox One / PS4 would be pretty cool. You may want to have a look at /r/playrust.
Hey hey! Yeah I haven't used this crate, but it seems like exactly what you want.
In this case I would sooner expect an indexed load than a jump table, but who can tell what brilliant madness llvm will come up with? 
&gt; since the error comes from losing covariance due to interior mutability. Well, yes, but that's also because you have your lifetimes wrong. https://is.gd/fAB6y2 struct Bar&lt;'a&gt; { bar: &amp;'a str, } impl&lt;'a&gt; Bar&lt;'a&gt; { fn new&lt;'b: 'a&gt;(foo: &amp;'b Foo&lt;'a&gt;) -&gt; Bar&lt;'a&gt; { Bar{bar: foo.raw} } } pub struct Foo&lt;'a&gt; { raw: &amp;'a str, cell: Cell&lt;&amp;'a str&gt;, } impl&lt;'a&gt; Foo&lt;'a&gt; { fn get_bar&lt;'b: 'a&gt;(&amp;'b self) -&gt; Bar&lt;'a&gt; { Bar::new(&amp;self) } } You need to be careful about the lifetimes and the subtyping relationships, but there's nothing fundamentally restrictive about what you're trying to do. Variance issues in borrow checking only really crop up when there's something unsafe that you're trying to do. &gt; which is even worse. It depends on the exact case. Sometimes it's easier to have another struct, sometimes it's easier to split some logic into functions.
If you have 500 FPS it means, that user is able to see 60 frames and 440 are wasted. Maybe it makes sense to have terminal state under RWLock, write it on every change and read no more than 60 times per second?
Why can't I build a struct in a function and return it immediately? #[derive(Debug)] struct Foo { a: u32, b: u32, } fn build(a: u32, b: u32) -&gt; Foo { let bar = Foo{ a: a, b: b, }/* ; bar */ } fn main() { let bar = build(213, 135); println!("{:?}", bar); } I have to remove the comments to get it to work. And when I do, clippy will recommend that I go back to the original! Thanks!
Why update the unchanged portions of the screen buffer when only one character changed in the text buffer? Only a tiny portion of the screen buffer needs to change. 
Could you annotate that code? I want to understand, but I'm lost.
Thanks!
Thanks!
The allocation is done only once though.
0 vs 1 is a lot. I would also imagine that something like 'match' is easier to optimize (at the compiler level) given constant values. A hashmap would be harder - given that Rust's hashmap uses a runtime-random component there's no way it could be optimized to the same degree. If I had code that provided a constant to a function that matched and returned a value, I would expect the compiler to just replace the function call with the return value. I wouldn't expect that if the function used a HashMap.
There's already issues for it :)
That's a simplified example. I would have had to change the lifetimes in large parts of the code in order to make interior mutability work, and I didn't want to do that.
The answer to your final question is yes.
`a[b]` for pointers is defined to be `*(a + b)`, and `7 + p` and `p + 7` are both valid.
&gt; If you immediately turn the optional into something else, the optional allocation is removed as well. What allocation—are you saying using `Option` sometimes causes a heap allocation?
Mh I'd like a sarcastic-dissapointed compiler like &gt; use of moved value: 'val'. Again. There goes my hope you learned that by now. Serously. It's not that hard... &gt; (...) &gt; error: could not compile 'foo'. Maybe try a garbage-collected language?
I didn't mean to imply that. Option can just potentially add some overhead to whatever it is an option of (you need the flag to determine if it is empty or not). See here for an example of that: https://godbolt.org/g/Wv1qkn You'll notice that a total of 16 bytes are reserved on the stack in the case of a Some even though a `u64` takes up only 8 bytes. If you were to then use it, you would have to test whether or not the value actually exists or not (adding some more CPU overhead). These things are really pretty minimal and shouldn't prevent you from using Option. However, the compiler is smart and in some cases it is able to remove both the extra memory and the extra check if it can prove that it is always a "Some" that is returned.
It doesn't. I imagine the parent is saying that if the function is inlined into something that does a `match` (including calling one of `Option`'s combinator methods), the option may not exist at all, everything will be collapsed together so there's just the `char` match.
Yup. I was more trying to talk about the memory footprint and less about residency.
Generally with Rust, the first thing I look at when I find a new crate I might use is the docs, not the source, because the Rust ecosystem is really fantastic on both docs &amp; examples. It's the opposite of what I usually do with other langs. When I was about to publish my first crate, it didn't have docs/examples yet and I actually felt a little guilty, because I know how awesome the docs/examples have been for Rust itself and virtually every crate I've ever used, so I stopped and wrote both before publishing. I think the habits of a community matter a great deal :)
Right, my point is that there is a valid solution via RefCell or OnceCell
There is a rusty-machine gitter. Not very active recently though (the github repo on the other hand is evolving fast!)
Would anyone be able to expand on why the "one liner" might be significantly faster?
It would be nice to have a reddit forum.
You want to be looking in /r/playrust – people on that sub presumably have a better aim than the folks here.
Ah, I think you're correct. Took the actual time to test and it seems that is the correct behaviour. Thanks, nearly had an off-by-one error in my stride test, that wouldn't have been good :\
This is excellent. Congratulations!
This subreddit is for the Rust programming language, not pictures of rusty metal. Try /r/pics or something?
I think the kernel doesn't zero the physical page when freeing it. That would be too much useless work. This allows for a [cold boot attack](https://en.wikipedia.org/wiki/Cold_boot_attack) even after the key was supposed to be deleted. Or can you give the kernel some flag to really zero the page?
\*spooky campfire voice\* No one knooooowwwwws
You're right, the bound is wrong, and the code is broken. The code should just be struct Bar&lt;'a&gt; { bar: &amp;'a str, } impl&lt;'a&gt; Bar&lt;'a&gt; { fn new&lt;'b&gt;(foo: &amp;'b Foo&lt;'a&gt;) -&gt; Bar&lt;'a&gt; { Bar{bar: foo.raw} } } pub struct Foo&lt;'a&gt; { raw: &amp;'a str, cell: Cell&lt;&amp;'a str&gt;, } impl&lt;'a&gt; Foo&lt;'a&gt; { fn get_bar&lt;'b&gt;(&amp;'b self) -&gt; Bar&lt;'a&gt; { Bar::new(&amp;self) } }
Congratulations! I'm curious, what's the scope of the image library? So far the list of [supported image formats](https://github.com/PistonDevelopers/image#21-supported-image-formats) documentation includes mostly the obvious and useful raster formats: PNG, JPEG, GIF, TIFF, BMP, ICO, Webp, PPM. Will it support more "obscure" (TGA, PCX), complex (PSD, PSP, PDN), animated (ANI, MNG, APNG) and even vector (SVG, SWF, PS, PDF) image formats or are those considered out of scope? HDR (e.g. 16bit per component or floating point; DPX, EXR) images? Could a third party library or application "plug in" more formats into the framework? Consider for example writing an image viewer that's competitive with [IrfanView's supported formats](http://www.irfanview.com/main_formats.htm). Would this be possible with this library? Then there's also the [image processing functions](https://github.com/PistonDevelopers/image#5-image-processing-functions). Is it intentionally limited to only the basics or will it be expanded to all kinds of complex functions? Do they operate in a linear color space? Consider for example writing a an image processing command line tool competitive with [ImageMagick](https://www.imagemagick.org/). Would this be possible with this library?
There is this for node developers: https://github.com/Mercateo/rust-for-node-developers
&gt;Additionally, interior mutability is a pain to deal with due to the loss of covariance. Can you explain what you mean here or give an example? I assume you didn't mean OOP subtyping variance, as Rust doesn't have that anyway, and I don't _think_ you can mean functor variance in this context.
Thanks for the input!
Wait, what? How is `fn new&lt;'b: 'a&gt;(foo: &amp;'b Foo&lt;'a&gt;) ` possible? 'b outlives 'a, right? How can a reference (with 'b) outlive the referent (with shorter 'a)? Edit: Ah, so this was an example of _broken_ code?
Speaking from my own experience, CS students hear the word invariant for the first time when proving loop invariants on algorithms &amp; data structure classes, and many of them never hear about them after. This might lead to a bit narrow mental image what invariants are. I re-familiarized myself with the word here in the Rust community.
Likely. The "edit timer" is 3mn (before the star appears) so that's a fairly large window for "serial browsers". Especially since you just need to have opened the thread at that point.
fbp is interesting. I found there is another fbp in javascript. https://noflojs.org/example/
https://wiki.mozilla.org/Areweyet
Image manipulation has always been a horrible thing in C. Imagemagick has had continual vulnerabilities and several colleagues that have discussed auditing its source all ended up backing away frightened. The moment I heard about Rust, decent image management was the first thing I thought of. Great work!
Shit man, what about Lossless JPEG ('94), JPEG-LS, and JPEG-XR? Also, what about YCgCo?
Yeah, but then it's not `tokio`.
(I just noticed the source repository already contains some TGA and HDR support.)
&gt; The resulting code took a bit more work to write than the mutable approach idiomatic in other languages, but it benefits from static type checking. I would argue that the final design *is* the appropriate design, whatever the language. Somewhat-initialized objects should be consigned to the dustbins of bad design history. That is why you use the builder pattern (when fields can be initialized in any order) or an intermediate structure to produce the final, as-immutable-as-possible, complete structure.
[rawloader](https://crates.io/crates/rawloader) can be used to add support for camera raw formats. Hopefully I'll finish the last two formats soon. It also contains just enough of a lossless jpeg decoder for these formats, but that could be improved to a full decoder.
Shouldn't this be `Rust::from::&lt;Lang&gt;(knowledge)`? ;)
I meant, what type of algorithm does it use? Since Rust is not context-free, I was interested on how one might parse Rust code, since the non-context-free algorithms are not standard fare for undergrad classes.
It does support HDR (AKA Radiance) files read/write. The crate documentation is just out of sync with the actual library capabilities.
Interesting, thanks. So this is not directly related to the image library and uses its own Image type and Decoder trait. If I wanted to use both libraries I'd have to somehow abstract over them myself?
 #rust-machine-learning exists on the mozilla IRC network.
I'll link it under an extra resources page that aggregates things like this! Thanks for pointing it out
Wouldn't it be better to put loaders into separate crates?
I'd say match by a far margin.
Right now yes. I've though about doing a PR to add this to the image library but it's difficult to match the API since raw formats have mosaic images (e.g., each pixel is one of R/G/B) and other complexities. It would be simple to do a loader that just outputs a normal RGB image for simple usage as rawloader includes a simple raw processing pipeline capable of doing that. But an actual raw processing program will usually have different code paths for raw images and for normal rgb images.
So it's safe to say that you should only use a HashMap if you won't know the data until runtime. If you know the lookup data during development, just use a match.
Awesome! I love pure rust projects that do low level stuff that previously C was used for (have some of them myself). This is living proof that Rust is a systems programming language, and helps teach people that you don't need to fall back to C if you want to do "real" programming.
&gt; I think the habits of a community matter a great deal :) I can assure you, they do. I was recently having a conversation with a new production user; they were frustrated by finding tons of useful crates, but ones with no docs. Docs make a big difference!
Thanks, I think I must have skipped that chapter.
Is it possible to use the `?` operators inside closures? I'd like to use `?` inside the following `map` call. let buf: Vec&lt;char&gt; = env::args() .nth(1) .map(|ref file| { let mut buf = String::new(); File::open(file) .and_then(|mut f| f.read_to_string(&amp;mut buf)) .expect(&amp;format!("Could not read {}", file)); buf.chars().collect() }) .expect("No argument given");
And this for Rubyists: https://github.com/steveklabnik/rust_for_rubyists
Did you keep reading? &gt; However, as soon as I added the RefCell, my code would no longer borrow check, and I couldn’t figure out why.
I forgot about `unwrap_or()`. Updated :) The Mutex trick for the CSPRNG is the only way I've found to have a mutable global. I'd be surprised if that's actually the right way to go about it, however.
This was exactly what I needed! Thank you!!
Ah, OK, so let me try and get this straight. The article then goes on to say, &gt; I probably could have fixed this by adding more lifetime parameters throughout the codebase, but I wanted to avoid changing as much code as possible. It seemed like pushing a round peg through a square hole by brute force, and I wanted a cleaner approach. So, I took that to mean that `RefCell` was a "valid approach", in the sense that it would work if the lifetime parameters were fixed. Is /u/Manishearth saying that if the lifetime parameters were specified correctly initially, that RefCell would be a "valid approach" in the sense that the rest of the usages wouldn't need to be changed in a complex way at all?
I'm working on a demo using diesel. I'm going to get it up and working soon.
Holy Macaroni! Diesel.rs looks great. I also really like the guide. As a beginner it was a breeze to set up a working database connection. Seems like my next project have to be done in rust...
I understand that brevity is important, but I'm not sure I agree that the second version is an improvement. Readability is also important and the first version is very obvious what it means, while the second requires you to remember the semantics of unwrap_or() to understand it.
This was my first response too. In fact I'm finding myself turn to 'map', ' and_then' and the like for Option and Result more regularly. It makes more concise code, but is still legible, imo. 
I'd add that those problems seem to be expected for C lib wrappers. I've also extensively used sdl2 + sdl2_ttf from pre-rust-1.0 days: a lot of API changes while proper lifetimes got figured out, several panics and some segfaults from ttf part. There also were troubles with openssl wrapper: system lib was too new or old and some functions were missing. Crates with smaller API area tend to do much better, especially if they bundle C parts: rust-lzma, lz4, flate2 has just worked. Pure-rust crates tend to break the least. I've used serde, bincode, time, chrono, num, nalgebra, chan, bit-set, bit-vec, vec_map, threadpool, toml, rand to name a few. No panics, no segfaults, API changes are caught at compile time. Lifetime parameters rarely change and that usually means little to no refactoring. While I may sound negative, authors of all those packages did great work and I'm very grateful to them. Those are just observations regarding complexity and interoperation. That said, amount of code required to set up communications with nanomsg is very small. Depending on your task it may be quite easy to localize, e. g. rest of the code can be attached through channels. In this case it would be easy to switch from nanomsg to zeromq later if needed. Not sure about MPI, I don't know how it's structured.
I agree with your point, but in this case I think `.unwrap_or()` is actually more readable than the explicit `match`. Some of the functional methods do get a bit ridiculous though.
Yeah unfortunately that avoids some of the things that I would anticipate are difficult. For example a new connection to the database is established for every query (twice in `Task::toggle_with_id()`!), and if it fails, it panics.
Bound to have this corrected/expanded by others.. but in terms of the stack, you are only passing pointers around so there is no great impact on stack usage. Rust's ownership system and its borrow checker means that the compiler can determine that the original data is still valid
Is this similar to OpenCV? Also, is there literally any library that hasn't yet to be ported to Rust? I arrived a little late to the party and it seems like all the good projects are taken :T
There’s the additional overhead of tracking changes, which may cause enough of a slowdown to negate the potential gains.
You can look at nom, a parsing crate that enables zero-copy parsers (it uses slices for this). - Talk (about zero copy and implementation after 15:30) https://youtu.be/8mA5ZwWB3M0?t=928 - Introduction to nom http://hermanradtke.com/2016/08/08/introduction-to-nom-rust-parsing-combinator-framework.html
You can totally use `?` in a closure, but it'll return from the closure itself rather than from the containing function. Since you're going to `expect` the first Option anyway, it might be easier to just do it on its own line than trying to chain it with `map`. Maybe something like this? let file = env::args().nth(1).expect("No argument given!"); let mut buf = String::new(); File::open(&amp;file) .and_then(|mut f| f.read_to_string(&amp;mut buf)) .expect(&amp;format!("Could not read {}", file)); let chars: Vec&lt;char&gt; = buf.chars().collect(); If you really want to get `?` in there, then it would probably make sense to transform the Option into an io::Result straight away, to fit the error type that File::open is going to return: let buf: Vec&lt;char&gt; = env::args().nth(1) .ok_or(io::Error::new(io::ErrorKind::InvalidInput, "No argument given.")) .and_then(|ref file| { let mut buf = String::new(); File::open(file)?.read_to_string(&amp;mut buf)?; Ok(buf.chars().collect()) })?; 
What's even easier is just use a single reference, instead of multiple. Then you can reuse it as often as you want. let field_idents_: &amp;Vec&lt;Ident&gt; = &amp;fields.iter().map(|f| f.ident.clone().unwrap()).collect();
I prefer the more ergonomic `knowledge.into::&lt;Rust&gt;();` personally, because usually the compiler can infer that you want Rust.
Great! Are there any performance improvements? Either in compilation or runtime?
Funny enough, i got the same error trying to package rust nightly for nixos. Did you figure out what causes this error?
An example of setting up a simple db pool for Diesel using r2d2 and making a rocket RequestGuard for it can be seen here: https://github.com/SergioBenitez/Rocket/issues/53#issuecomment-269460216 When that is in place, any route that has an argument 'db: DB' will have a DB struct (from the example above) available and can get a connection reference with 'db.conn()' inside the route.
&gt; Thanks, /u/... wait is that /u/steveklabnik1 omg Yeah he showed up sometime ago and we haven't been able to get rid of him since. :P
Hmmm, not sure why that would happen. Is the error on the line that creates the clone, or the line inside the closure that uses the clone? BTW, I took your code, and mocked or changed all the bits that didn't compile. The result is [here](https://play.rust-lang.org/?gist=a47cfe7f441ad0e29967edd9b6d5bc64&amp;version=stable&amp;backtrace=0). This compiles OK. Is this any help? 
Isn't this weak to a dictionary attack? It recommends using just know words. Adding in just a couple random numbers and symbols on top of this decreases the likely hood of brute force to basically zero.
Huh... weird that it works for you, that's what I had essentially. I gave up and I'm trying a whole other route now but I may circle back, in which case this will definitely be helpful - thanks.
This is for image loading and manipulation, while OpenCV is more for (real-time) computer vision applications.
If you're just gonna match and panic, you might as well just use `.unwrap()` since it does the same: let mut os_csprng = match OsRng::new() { Ok(g) =&gt; g, Err(e) =&gt; panic!("{}", e), }; should just be: let mut os_csprng = OsRng::new().unwrap() 
I'm currently working on a library for parsing DICOM (supported by IrfanView), however I haven't decided whether to make it public or not.
Random guess... The program doesn't seem to do a massive amount of calculation so I would say that the performance would depend on your IO. The one liner version reads the whole file in one go with `read_to_string` while the readable version use `lines()` on the `BufReader`, which might go to the files several times...
I've been mulling over a project with a similar purpose for about a month now. If I can stop being so lazy perhaps I'll contribute here instead :)
Finally found the serialisation library I always wanted, thanks!
I was pestering you a while ago about making it storage agnostic so that it can work as a library that can be integrated into other databases. Have you thought about that?
Ah - potentially much simpler than I thought :-)
Didn't know, that this library exists. Thanks!
As a vim user myself, I just forgot that the tags for emacs are including the tags for the dependencies by a file reference, so emacs users can't just delete the old cache files without rebuilding the tags for their cargo projects.
As great as Stackoverflow is, it is very vicious to new users. I have posted valid Rust questions and have received either no answer, or very condescending comments. So, when you say "no question is dumb" it doesn't really reflect the attitude of the SO community.
Many things that were decided years ago are no longer true.
Agree, IMHO their filter functions should also be moved into a separate crate. Some formats are very complex (PSD, XCF, OpenEXR), so it may be overkill to use this library for basic png/jpeg loading for example.
As the [FlatBuffers website](http://google.github.io/flatbuffers/) states: &gt; Cap'n'Proto promises to reduce Protocol Buffers much like FlatBuffers does, though with a more complicated binary encoding and less flexibility (no optional fields to allow deprecating fields or serializing with missing fields for which defaults exist). It currently also isn't fully cross-platform portable (lack of VS support) Quoted from the [benchmarks page](http://google.github.io/flatbuffers/flatbuffers_benchmarks.html).
I'm going to nag everyone about our [Rust Regulars' Table](https://www.meetup.com/de-DE/Rust-Rhein-Main/events/236456912/) Friday next week.
Oh I see, I figured I hadn't given `?` enough info about the Result it should return in my map function (or something). I like your first solution more thought. I guess it's a better idea to separate things instead of trying to do everything in one line, at least in this case.
Two complete guesses from a non-expert: that kind of thing is easier to optimize because the sequencing is less explicit so the compiler has more freedom. Also the style is naturally amenable to using conditional operations (because the chains are already like that) rather than jumps.
I started working on [tokio support](https://github.com/polachok/pnetlink/tree/tokio) for my [netlink library](https://github.com/polachok/pnetlink).
Note that ideally you would actually use the soon to be added `kind = "static-nobundle"` (https://github.com/rust-lang/rust/pull/38426). On Windows there is a distinct difference between references to symbols from a static library and symbols from a dynamic library so the code referencing such symbols has to be generated correctly. Recently Rust finally added support for choosing whether to emit dllimport, and it is controlled by which kind you're using. To summarize: * If you're linking to a dynamic link library via an import library, use `kind = "dylib"`. * If you're linking to a static library, use `kind = "static-nobundle"` as soon as it is implemented.
If I'm right, then sublime uses vi style tags, so calling `rusty-tags vi` should work. To change the name of the tag files you have to set `vi_tags = ".tags"` inside of `~/.rusty-tags/config.toml`. 
I find that Reddit threads are better structured for Q&amp;As anyway, namely because there's clear trains of thought in the comments, allowing actual conversations for corrections or clarifications. It's also nice that you don't have to deal with questions being removed by mods for any number of arbitrary reasons. They'll remove a question for being duplicate, but nevermind that the question they link back to is five years old and the solution is now obsolete. The solution might get updated at some point, probably by you after you figured the problem out for yourself--if you can be arsed, that is. 
A 1920x1080x32bbp frame buffer is ~8MB of data. At 60fps that's nearly 500MB/s. OP is claiming ~500 fps, which is __~4GB/s__, very near the maximum of a PCI-E 3.0 4x implementation. Contrast that with updating a single 16x12x32bpp character. That's 768 bytes. Even if the clipping code took 1ms to execute (an eternity on a modern cpu), you'd double your fps and drop the bus usage to a fraction of the bandwidth it was using when pushing the whole frame buffer every time. It may seem like less code is faster code, but in reality a lot of that code is running on the GPU. It may seem cheap and nearly free but it's really pushing all the work elsewhere. 
Excellent, thank you. Would you consider a generic .tags option in future? Edit: In reflection this is probably outside the scope of the tool. 
use kafka, noob
Just finished off a Chip-8 interpreter (like everyone else). Looking for a new project now.
Perhaps something like `rusty-tags sublime` might make sense, which defaults to the `.tags` name. I know nothing about sublime, is the `.tags` name specific to a certain sublime plugin? Are there multiple different tag plugins for sublime? Is the name sublime version dependent?
Continuing on my work to use [futures/tokio in gluon](https://github.com/gluon-lang/gluon/pull/241). Currently got the http request to be read in asynchronously and should get writing the response working this week! After that I think I am unblocked on the [pretty printing/code formatter PR](https://github.com/gluon-lang/gluon/pull/205) so with some luck it might be possible to format all gluon code in existence! (Well, all ~1k of it :) )
wooooooh, got a project all ready to go for this
I switched from Cap'n Proto to flatbuffers because: - flatbuffers derserialization is free - it's just a pointer cast. Higher performance, less allocations, less copies. - Cap'n Proto (at the time) was calling panic instead of returning Result errors. - Flatbuffers has the possibility of being enhanced to support 'placement new'. It's on my todo list to enhance flatbuffers to support this for use with my shared memory IPC interface. Explanation: So I can directly create the flatbuffer object in a shared memory region with no copy. Fwiw for a shared memory IPC channel both Cap'n Proto and Flatbuffers currently must take the slow approach of constructing an object and then copy it to its destination (shared memory) during the serialization phase. 
I'm working on a Rust-only minimal AUR helper for Arch Linux, to automate search, download, installation, and update of AUR packages. The world doesn't need this, there's so many already, but I don't care. I've also got a Raspberry Pi home server which has a little administrative landing page I wrote up in Go - it's going to be really hard to fight the temptation to port it to Rocket and I imagine I'll give in by tomorrow ;) I am SO into Rust now it's not even funny.
This is the Sublime ctags plug in I use: [CTags](https://github.com/SublimeText/CTags). AFAIK it is the most popular plugin but I'm sure others are available. I've only ever used this on Sublime Text 3. By default it just uses a .tags file which is of course configurable.
thanks again to /u/carols10cents, /u/shepmaster, and the rest of the RBR team for all their work on the conference, it was really great!
&gt; flatbuffers derserialization is free - it's just a pointer cast. Higher performance, less allocations, less copies. What about when source and destination are differing endianness? It can't be free in that case, can it?
I have a small CLI "kind-of-compilerish" project written in ANSI C89, it only uses stdlib.h, stdio.h and signal.h with conditional compilation to handle POSIX signals. Been lurking and watching Rust for a while now and could make the migration, if it doesn't prove too bothersome. 1. Can one deal with C and/or POSIX signals in Rust. 2. How well can one translate C89 to Rust without redesigning data structures or other large changes. (If they are well designed in the first place.)
I'm interested in this. Mainly because I need a decent project that I can relate to so I can learn rust.
For your suffix array implementation, is there any reason why you didn't use the [`suffix`](https://crates.io/crates/suffix) crate? Did you find your implementation to be faster? &gt; So, I'm kinda stuck. It's just shocking to see that an input size of ~250 MB requires ~3 GB of RAM, and I can't improve this in any way. AIUI, even the best suffix array construction algorithms have ~5 bytes of overheard *per character* of the input. That at least puts you in the same order of magnitude as 3GB.
&gt; flatbuffers derserialization is free - it's just a pointer cast. Higher performance, less allocations, less copies. I'm fairly certain that Cap'n Proto is also zero copy. I understand there should be very little difference in performance between the two.
Ironically, I think Rust is most similar to C++, in terms of the fact that they're both systems programming languages with a focus on zero cost abstraction and high performance. And lifetimes should be familiar to C++ programmers, since it's just making explicit to the compiler what you already are doing. The main thing that is new from the point of view of C++ is the pattern matching and blocks as expressions, but that seems relatively minor. Well, that and traits obviously.
Continue translate ebook [Rust pogramming language](https://github.com/rust-vietnam/book) to Vietnamese
Please do! Any help is greatly welcomed. Right now though github has shadow banned me for no reason and so the repo doesn't exist to anyone but me on the site. Hoping to get this resolved today. EDIT: It's back up now
like your blog post. But, the only thing that irks me with the rust ecosystem is the dependency on rust-nightly. I can in no way convince my fellow teammates to use rust for anything serious, when our compiler itself is basically coming out hot from the repo. I just wish that the ecosystem doesn't depend on rust-nightly as much as it already is.
I mentioned it in the other comment but Github has shadow banned me. Until support resolves my ticket this repo and all my other work can't be seen
That's definitely a pain-point yes. However, I see it also as a good thing! It allows developers to test out new ideas without making a promise that it is going to stay the way it is right now. So in my opinion it's how you can aggressively try out new stuff without impacting stability promises. (And I'd argue that both the crates do 'new' stuff)
Depends on what you're moving. Don't move huge stack based arrays. But heap allocated things like vectors and strings are cheap to move.
Very interesting! Thanks. I never thought that there would be an implementation of suffix array elsewhere in Rust (apart from rust-bio). Oh, and mine is a lot slower than yours, apparently :)
&gt; Can you elaborate a bit more why I don't need to drop_in_place my image? I am not sure that I understand your point. My understanding is all it does is invoke the `drop` of the pointee (and whatever it contains) (without having to copy it to the local stack as e.g. `ptr::read` would, meaning it's cheaper and works for unsized objects). `Image` doesn't implement `Drop`, and it only contains non-drop values, so I believe it isn't going to do anything. It's an intrinsic and I don't know the specific details though, so I might be completely off-base, somebody working on rustc (or much dived in unsafe) would probably be able to give better information. Maybe try ping-ing people who [worked/talked on the issue](https://github.com/rust-lang/rust/issues/27908) like /u/gankro.
It's back up now! Github spam filters had tripped up.
No. Still, for my use cases I'm able to deserialize in a single pointer cast. 
Yay! I'll keep my eyes peeled for any announcements!
Plus, C++ likes to _copy_ and Rust likes to _move_. That caught me up a few times. As for _thinking in traits_ it's sufficiently different to cause puzzlement. Anybody coming from an old-fashioned OOP background is going to struggle a bit - there is actually _unlearning_ as well as learning
Here's why folks say Capn Proto is zero copy for sending data (to a socket): all of the required internal data structures can be sent 'as is' to a *file descriptor* without first copying them to some intermediate representation. I'll ignore that zero copy is still false because there will be a userspace-&gt;kernel copy. Fwiw when doing local IPC this way the overhead (perf analysis) is *enormous*. At least it was for us - we failed to meet our performance requirements and switched to shared memory and flatbuffers (Rust &lt;-&gt; C++). 
Cap'n Proto was explicitly designed to be able to transmit using shared memory with literally zero copies. You do not have to pipe it through an FD if you don't want to.
I'm working on my first project with Rust, inspired by /u/yupferris and his Rustendo64: a Game Boy emulator. I'm extensively using the same code structure as a guide. [Here's the repo](https://github.com/javierbg/RustyBoy), any suggestions are welcome.
If you (experimentally or otherwise) switch to /u/BurntSushi's `suffix` crate, could you report back on how your memory usage and performance are affected? I'm always curious to see how these things play out.
Could you provide instructions on how to reproduce your results? `rust-helix` doesn't seem to be executable by itself, and I'm not sure where the 250MB of data came from. I'm not sure that I could actually help very much with your particular problem, but if I get time, I'd like to take a look, and I'm sure that providing instructions would make it easier for others to help too, if it's possible to provide the necessary items.
Thanks for stopping by Kenton! Fyi the Rust implementation isn't there yet. I do realize you provide an example in C++ for how to do this... My comments were implicitly talking about the Rust implementation. I thought it made sense because this is /r/rust and the discussion seemed to be around the Rust implementations. Apologies for any confusion. I'll be more explicit in the future. 
So, DNA sequences are just ATCG's. You can generate something like this in python, from random import choice with open('SEQ', 'w') as fd: fd.writelines([choice('ATCG') for i in xrange(1000000)]) `helix` is a library. So, the wrapper I'd used for it is something like this: extern crate helix; use std::io::Read; let mut bytes = vec![]; let mut fd = ::std::fs::File::open("SEQ").unwrap(); let _ = fd.read_to_end(&amp;mut bytes); let _sa = ::helix::suffix_array(bytes); `/usr/bin/time -v` produces decent results on the time taken and the maximum resident size.
What specific functionality do you think is missing in capnproto-rust? As far as I know, all the necessary pieces are in place. For example, if you know your message is less than 8000 bytes, you could construct it like this: ``` let mut m = message::Builder::new(message::HeapAllocator::new().first_segment_words(1000)); ``` and then when you're done filling it in, `m.get_segments_for_output()[0]` will give you an `&amp;[Word]` containing your message, without performing any copies on the data. 
Really hope the Fluent Rust Bindings talk goes up soon. It was my favorite of the conference.
&gt; A FlatBuffer is a binary file and in-memory format consisting mostly of scalars of various sizes, all aligned to their own size. Each scalar is also always represented in little-endian format, as this corresponds to all commonly used CPUs today. FlatBuffers will also work on big-endian machines, but will be slightly slower because of additional byte-swap intrinsics. So, on x86, you're home free. On big-endian architectures, you pay the cost of a copy. Personally, rather than having one-shot deserialization, I prefer accessors: pub struct Reader&lt;'a&gt; { data: &amp;'a [u8], } impl&lt;'a&gt; Reader&lt;'a&gt; { pub fn read_x(&amp;self) { read_aligned_i32_le(self.data) } } where `read_i32` will just byte-cast on little-endian architectures and byte-swap on big-endian ones. This avoids pessimistic copies if you only need to read a couple fields: you only translate what you really access.
Sorry, we didn't record any of the workshops on Day 1. You can find the materials for it [here](https://github.com/jdm/bindings-workshop) though! We've also posted materials we've received from all speakers [on our sessions page](http://www.rust-belt-rust.com/sessions/).
Oh! Good question. /u/masklinn already noticed that it is caller-allocated. Therefore that comment is wrong.
Do a `git grep` for any calls to `unwrap`.
That's a useful link, thanks! In any case, let's continue this discussion on [the pulldown-cmark github issue](https://github.com/google/pulldown-cmark/issues/6).
&gt; Instead of marking things with Option&lt;usize&gt;, I use u32::MAX, which reduces the memory by more than half, and also because even the size of the giant human genome is less than u32::MAX :P You could instead create a new type and implement NonZero for it (unstable iirc). When constructing the type you can pass it a usize, and assert that the usize is not 0. Then you could go back to using Optional&lt;NewType&gt; without memory overhead.
I'd remove a few `unsafe` statements. Do you *really* need them?
/r/playrustlfg
I will be messaging you on [**2017-01-23 19:51:23 UTC**](http://www.wolframalpha.com/input/?i=2017-01-23 19:51:23 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/5mwl04/whats_everyone_working_on_this_week_22017/dc7kex2) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/5mwl04/whats_everyone_working_on_this_week_22017/dc7kex2]%0A%0ARemindMe! 2 weeks ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dc7kgqn) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
&gt; Rust code tends to use 1TBS What's this mean?
I'm interested! Thanks!
As far as I know the author of both ZeroMQ and nanomsg is [Martin Sústrik](/u/sustrik) - http://250bpm.com/ and I believe (and certainly hope) he's alive and well.
Not according to [wikipedia](https://en.wikipedia.org/wiki/Pieter_Hintjens). Although the [ZeroMQ](https://en.wikipedia.org/wiki/ZeroMQ) wikipedia page says that Hintjens was more of a cofounder with Sustrik.
Well, to be exact, Sergio said there will be a "simple solution", not simpler than the example above. That is not to say it won't be, but its just not what he said. It might even be built off the same premise, just abstracted out and built in to rocket so it becomes simpler to use. I have talked a bit with Sergio about it myself, but the design is not being discussed anywhere publicly, so have not yet found out what it is he is working on for this. Needless to say, I am super excitedly to see what he is working on. Until then though, lazy_static! and RequestGuards will have to do.
Would thath be wise? I imagine a zero-base fragment might be a useful concept to have around, perhaps more so than a `u32::MAX`-base fragment.
Great, thanks.
Since you asked, I'd like to see all unwrap/expect (anything that explicitly causes a panic) to be replaced with a Result. We are aware of catch_unwind() but the problem in this case is that we'd actually like to use a message library in the *main* thread. If the main thread panics because of a malformed message then we'd have to use a different message library. We could possibly (if I could ever figure out how to provide a custom allocator) use capn proto inside our worker threads - but if we had to use a different message library for the main thread then we just wouldn't do that. 
&gt; It currently also isn't fully cross-platform portable (lack of VS support) This has been false for some time (see Supported Compilers in [the installation instructions](https://capnproto.org/install.html)). It was only ever a problem in the first place because of VS's then-incomplete C++11 support, which even then was only relevant if you wanted to use the standard C++11 code generator. &gt; less flexibility This is a somewhat odd way to characterize the design decision not to have every field be implicitly optional. Not to mention that flatbuffers' requirement for this actually *increases* overhead slightly by forcing runtime indirection for every access.
So, running that code on my system, with the python script adjusted to generate 25 000 000 elements: Command being timed: "cargo run --release" User time (seconds): 22.92 System time (seconds): 213.80 Percent of CPU this job got: 99% Elapsed (wall clock) time (h:mm:ss or m:ss): 3:56.89 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 212128 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 0 Minor (reclaiming a frame) page faults: 15085 Voluntary context switches: 72 Involuntary context switches: 3206 Swaps: 0 File system inputs: 0 File system outputs: 170312 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 Memory usage seems.... really low, but it took 4 minutes on a pretty powerful machine. Any ideas? EDIT: If I used 250 000 000, it would probably get up to like ~2GB of memory, so that makes sense then, but the run time would be forever. This is on an Intel Core i7-6700HQ, which isn't a slouch of a processor.
Any panic originating from within capnproto-rust indicates a bug in the capnproto-rust. Errors due to malformed messages are propagated as `Result::Err`. This has been the case [since early 2015](https://dwrensha.github.io/capnproto-rust/2015/03/21/error-handling-revisited.html).
True. I guess I was assuming 0 isn't a valid value, that may not be the case.
Using the `suffix` crate: $ cargo install suffix $ /usr/bin/time -v suffix-array /tmp/SEQ-25MB Suffixes: 25000000 Elapsed (wall clock) time (h:mm:ss or m:ss): 0:03.79 Maximum resident set size (kbytes): 192244 $ /usr/bin/time -v suffix-array /tmp/SEQ-250MB Suffixes: 250000000 Elapsed (wall clock) time (h:mm:ss or m:ss): 0:45.91 Maximum resident set size (kbytes): 1752836
Still working on [teleborg](https://github.com/voider1/teleborg) [link to Github page]. I've made some significant progress in the last week or two. I've implemented the commands with a trait called, you guessed it, `Command`. I think it's pretty neat, because using trait objects and runtime polymorphism I can make anything into a command if it implements the `Command` trait which allows me to make very advanced commands with less effort. The library automatically implements the trait for commands which match the right signature. I can now receive updates from the server and reply to them and I'm still implementing more. Suggestions are always welcome!
o/ fellow VT rustacean :) I was just regretting that the two hour drive from Southern VT is just a bit too much for this hack night. :(
[One True Brace Style](https://en.wikipedia.org/wiki/Indent_style#K.26R_style), a K&amp;R variant where the opening brace is always at the end of the corresponding "opening" statement's line (rather than on a new line, let alone alone there as in Allman), the `else` is "cuddled" (on the same line as the preceding closing and following opening braces) and ever block is braced (though Rust doesn't actually do that one in every case, braces are often elited in single-exception match arms, OTOH it mandates braces for other statement blocks). The BSD KNF is also close, but it puts the opening brace of a function's body alone whereas Rust code generally does not (in my experience anyway).
Or you can use my [optional](https://github.com/llogiq/optional) crate, which implements the same thing with a nice `Option`-like interface.
If you need 5 bytes per character of input for suffix array construction then does that mean that FM indices are actually not as useful as they may seem because you need a large amount of memory anyway?
Are they broken? They were broken about 10 min ago because I messed up the conditional compilation of the validation function, but I fixed that. There are warnings for unused values, but as far as I know the AUR package should build successfully even with those warnings 
Thanks for reminding me, I need to check that out.
Hey, thanks for the answer. I asked you about using nanomsg or not for a new project recently over at gitter. Scaporust looks pretty good by the way, hope you make good progress on it soon. I'm still weighing all the options, but I appreciate the community giving me the info to make the right call.
Have you ever played with ARM instructions to change data access endianness? I've never had reason to do any performance eval of them, but it seems it might be pretty useful in this context.
And I'm in the Brattleboro area. I would be up for a meetup, should one be put together, despite the distances involved. Tangentially relevant, I'm also hoping to give an introductory talk at one of the Brattleboro Area Tech (BAT) meetups this winter/spring.
I have yet to use a language with a more intuitive module system than Rust, and going to other languages is always a strict downgrade. This is especially true for languages with - _shudder_ - namespaces, or modules-that-are-actually-namespaces, (looking at you, Haskell). As a newbie, the difference between `mod foo {}`, `mod foo;` and `extern crate foo;` was instantly clear, and the only thing that caught me out was the fact that the file that represents a folder is "mod.rs" and not "index.rs", like it is in JavaScript and Python. I'm sure that there's are legitimate improvements that could be made to the module system, but I don't think these will make the system easier so much as confuse newbies even more when they _do_ encounter the normally-optional syntax.
Oh yes, conemu isn't good compared to the offerings on linux/mac, but I don't get why you are comparing it to powershell when you just said powershell isn't a terminal emulator (which it isn't). They're not something you can compare!
I don't understand what a "namespace" means in the context of your post.
I was just making the point that making a competitor to ConEmu (which is what Alacritty is) is more reasonable (and needed!) than making a competitor to powershell.
Gotcha! And I didn't realize that Alacritty was a terminal emulator! How can it speed stuff up, isn't that the job of the terminal?
I'll keep you in mind for a few years from now then ;) And you should absolutely start a meetup/user group/whatever *you* want to call it! :)
So, the problem with that revision was that I was trying to optimize with serialization and bit representation. File I/O obviously takes a lot of time. But since it didn't have much effect on the memory consumed, I'm now back to using `Vec&lt;u32&gt;` everywhere. With that, I get something like this (on [`master`](https://github.com/Wafflespeanut/rust-helix/blob/cc4f99442a7ad109725244f50c1107b9f790c6fc/src/sa.rs)) $ time target/release/test_suffix ~/Desktop/SEQ_DUMP_250M Elapsed (wall clock) time (h:mm:ss or m:ss): 1:30.58 Maximum resident set size (kbytes): 1753060 $ time ./target/release/test_helix ~/Desktop/SEQ_DUMP_250M Elapsed (wall clock) time (h:mm:ss or m:ss): 1:09.29 Maximum resident set size (kbytes): 2266092 
Nice! Do you know where the perf improvements are?
I'm still working on figuring out where both our implementations diverge (Early morning, pre-brushing typing :P). I think yours is memory optimized almost entirely because of [having a mutable slice during recursion](https://github.com/BurntSushi/suffix/blob/db691a43e659455da2407b61ab25cbfb658dfaa5/src/table.rs#L451) (which is neat!), whereas I [create a new vector](https://github.com/Wafflespeanut/rust-helix/blob/cc4f99442a7ad109725244f50c1107b9f790c6fc/src/sa.rs#L232) every time. W.r.t performance, at least as far as I can see right now, you should be able to merge the [type-map building](https://github.com/BurntSushi/suffix/blob/db691a43e659455da2407b61ab25cbfb658dfaa5/src/table.rs#L544) and [finding the character frequencies](https://github.com/BurntSushi/suffix/blob/db691a43e659455da2407b61ab25cbfb658dfaa5/src/table.rs#L461), like [I did](https://github.com/Wafflespeanut/rust-helix/blob/cc4f99442a7ad109725244f50c1107b9f790c6fc/src/sa.rs#L128-L145). That should reduce an unnecessary iteration. Also, I don't think [sorting](https://github.com/BurntSushi/suffix/blob/db691a43e659455da2407b61ab25cbfb658dfaa5/src/table.rs#L641) is really necessary since we're both using vectors as counters. This won't have much effect initially, but the input to each of the recursive call is full of character indices, which are almost always unique. So, for a complex string of 250 MB, the first recursive call would have an input of ~100 MB (which is a collection of unique indices). Sorting that will be expensive, I guess?
From the website: &gt; Why is the conference taking place in the Rust Belt? For the pun opportunities, of course!! We also enjoy the opportunity to show off our region-- there are more people doing interesting things with technology here than you might have guessed! The conference took place in Pittsburgh, Pennsylvania, USA, a city in the heart of the [Rust Belt](https://en.wikipedia.org/wiki/Rust_Belt). It focuses on [Rust](https://en.wikipedia.org/wiki/Rust_(programming_language\)), so combine the two together =&gt; "Rust Belt Rust" :-) The plan is to move the conference from city to city, staying within the Rust Belt.
I think you could get rid of the race conditions using a CAS-loop style code: loop the load-update-sequence until it succeeds, and have it find the row to be updated by checking not only the ID as it currently does, but also by checking that `clicks` has the value that's expected. If someone else has concurrently updated `clicks`, it can't find the row and fails, and gets to try again.
I think that could work. That's definitely doable.
The speedup is in printing massive walls of text. Say you cat a file that's several gigabytes large -- cat will read the contents of the file, and write them to stdout. Then the terminal will copy the stdout of cat to its stdout. And finally, the terminal emulator will read the stdout of the shell and print it onto the screen. Printing onto the screen is usually the chokepoint -- to test this you can compare the time it takes to run `cat somefile` vs `cat somefile &gt;/dev/null`. The second will be much, much faster for large files. In the blog post above, the author of Alacritty lists several optimizations he made so that printing out lines from stdout will no longer be the slowdown. (And of course all this works differently on windows, I'm not familiar with the primitives.)
Hmm, no 5 years Rust experience required?
Hm. I suspect that can be optimized by pushing multiple nucleotides at once (have a function take `[T; 4]` or something) and always doing aligned pushes.
Regarding your first point, the topic to read up on if this matters to your use case is "transaction isolation levels". Most databases let you opt in to different levels, each of which implies different performance characteristics etc., too, so they're well worth knowing about.
Yeah, I know about table-level locking, row-level locking, serializable transactions etc., and should definitely study more. But actually the reason why I familiarized myself with the technique described above is that Diesel doesn't yet have full support of these.
I'm working on my first Rust project, a wrapper for the Keysight AgMD1Fundamental driver (I will also cover a separate lib for AgMD2). https://github.com/SProst/cautious-computing-machine The project is very much WIP (it doesn't represent a full coverage of AgMD1Fundamental, rather a subset particularly useful for specific digitizers) and I'm using it as an opportunity to learn more about Rust, FFI in Rust, and determine viability for switching from C# P/Invoke to Rust.
It puts a tags file at every root level of source code your cargo project or any of its direct or indirect dependecies references. For your cargo project you will get at its root level a tags file containing the tags for the project and its direct dependencies. Every direct dependency gets at its root level a tags file for its content and its direct dependencies. This is continued until the leafs in the dependey tree are reached. If you've configured your editor in a way, that it always searches upwards the directory tree for a tags file for the current source file, then you will be able - starting at a source of your project - to jump through the whole dependency tree till the leaf dependencies. I just looked up what this atom package does. It's about showing the tags of your current source file. `rusty-tags` creates tags for the complete project or dependency. I don't now if this atom package can extract the tags for one source file from a tags file.
Regarding your second point, Postgres has a [SELECT ... FOR UPDATE](https://www.postgresql.org/docs/9.6/static/sql-select.html#SQL-FOR-UPDATE-SHARE) clause.
Maybe I'm missing something but doesn't this mean you now don't have access to the `Request`? The interesting thing of the article is this single paragraph: &gt; We now setup an impl of FromRequest, a Rocket trait, for DB which is what we use in this case to get access to the pool in our routes. The from_request function returns our DB struct if successful or an error if it isn't. Cool huh? I think that deserves further explanation! Can a Rocket request handler take anything that implements `FromRequest`? How does that work? What if there are GET parameters too? What if I still want access to the `Request` object?
Oh, I mean where the modules have no hierarchy, they're just a prefix added to names that's not required to be anything unique. Like C#, where you can just add everything to the "System" namespace if you like.
I'm not knowledgable about databases but isn't something like `UPDATE ... SET count = count + 1 ...` possible? That would of course mean update first, then select.
I don't get why redshift and a screenshot program would be part of way cooler.. isn't it a WM?
To quote my fellow programmer whom I trust more than most other internet programmers: &gt; Python's http.server fails for even most trivial things &gt; It's serialised single-threaded thing, kinda works when you want to serve a single file to a single client but not for much else But also NIH.
NICE!
Sure, it’s not a good general purpose server. (Thanks for reminding me of that caveat!) But I imagine this crate being used in cases where single-threaded file serving is OK.
That's possible and should be race condition free since it's contained in the update statement. However, I'm talking from the perspective what you can (easily) do with Diesel, and I'm not sure if it supports that yet. (Couldn't find an `add` helper function from the documentation.)
Nifty! I can definitely see myself using this. The Python simple HTTP server is also nice, but great to have a Rust solution. Edit: Why didn't you name this `httplz` :D?
But isn't wlc the compositor here?
Working on level 2 for [my hacking game, hakka](https://github.com/simon-whitehead/hakka). Its coming along nicely. I have [a fully emulated LCD screen and keypad now](https://github.com/simon-whitehead/hakka/pull/19#issuecomment-270062654) and all that is left to do is add a "door" that opens once the player actually hacks the keypad.
Ah I see, wlc is a compositor library.
Such as? (Not doubting you, just curious)
Big one is this: https://github.com/hyperium/hyper/issues/950 Also https://github.com/hyperium/hyper/issues/988 and https://github.com/hyperium/hyper/issues/967
Just wanted to say it: you are doing something very cool, keep on it!
I notice the code is using `unwrap` and `expect` to handle DB errors in the routes. Is that just for expediency, or is it not possible to return `Result&lt;...&gt;` and have it properly handled by rocket?
Almost any language has something like this, nowadays. Here's an incomplete list: https://gist.github.com/willurd/5720255
Interesting! Thanks so much for the thoughts. I briefly tried removing the `sort` call, but the tests failed. I haven't understood why yet though! I'll noodle on your other suggestions. :-) You might consider adding more tests (take mine!) to your suffix array. I know I definitely had a few bugs in mine!
Nothing wrong with promoting software development in an economically afflicted part of the US.
The higher your isolation, the more performance suffers. Additionally, it's possible for a transaction to fail and roll back for no other reason then failure to serialize. It gets complicated fast.
FYI the "http" binary name is commonly taken by https://httpie.org/ on developer machines.
Quick correction, Way Cooler doesn't have the feature *yet*. Changes just landed in WLC to implement this, and support will come in the next minor version bump. 
I live here, and I'm proud of it. There's a lot more tech going on here than people realize, and people in this region deserve to have events that are easy to travel to as much as people on either coast. I doubt I'll find it restrictive.
/u/rotty81 the site isn't reachable since last few days.
Definitely agree. Thankfully Stainless and Rocket are probably just dependent on Macros 1.1 - those should by coming quite soon I believe? Not sure if it is next one or the one after. Someone will have to correct me!
Exactly! I would be surprise if the match was doing a linear search, but I also I believe this might have created some instruction cache misses.
being a compiler plugin unfortunately. We need macros 2.0 to get it on stable. Although you could use syntex to use it on stable.
I second this, /u/Bromskloss. I haven't gone to any of the rust conferences on the west coast of the US, or in the EU, purely because of the travel headaches. It's a lot more attractive to drive a couple hours, stay in a reasonably priced hotel, and then drive back, than it is to drop a whole boatload of money flying to &amp; staying in California. Maybe someday I'll have a job doing rust and my employer will help financially, but until then I enjoy having a such a high-quality event so close to me.
You want to be careful feeding user input from the Internet directly into a command, it can be very easy to exploit. If you're just streaming to `tar`'s stdin there's not a whole lot that can go wrong as long as you're using a reasonably solid implementation, but the whole concept just bothers me. Using a crate gives you more strongly typed control over the whole process, you don't have to fiddle around with different flags and such. It's likely more performant too, as process piping has overhead. As for Hyper, I don't understand what you might mean about cautionary rhetoric. Sure, it is lower level than most people might need, and it's in the middle of a migration to an asynchronous architecture that might start fragmenting the ecosystem of crates built on it (i.e. will they go async or not, or support both async and synchronous). However, it's the most solid and mature HTTP crate we've got, and a lot of other Rust web stuff is built on top of it. As for client libraries, where is [the `curl` crate](https://crates.io/crates/curl), which binds libcurl. I haven't used it myself but it's actively maintained, hopefully you find the API familiar. For pure Rust, there's [`reqwuest`](https://crates.io/crates/reqwest), providing a higher level client abstraction over Hyper and written by one of Hyper's core maintainers (and creator, I think? I forget).
Just to be clear, I don't mean that it would be restrictive to confine yourself to _this particular_ area (of which I don't really know much, not even being from the continent), just that it might be restrictive to be tied to a geographical area at all. However, I might have to change my mind, because I had the idea that this was the one and only official rust conference of the world, but maybe that is not the case.
Cool - thanks for your input! That's a good point - the tarballs are coming straight from the AUR website but the AUR doesn't make any guarantees. I'll take a look at the crate. I think all I meant was regarding this migration, but the that choice can be made on a package basis, then I see no harm in sticking with it. Reqwuest looks interesting, but as I've already got it working using plain Hyper, I don't really feel a need to change it up. Good to keep in mind for the future though. Appreciate your help!
This project also got mentioned here https://youtu.be/hAuTQdNxIZg?t=2254
It still seems crazy to me that you need that implemented in the compositor.. seems like WMs have to be more complicated than they do with X.
(Author here) Thanks! Was nice to find some example JITs in Rust. Also I intend to implement (someday) at least the Clone trait, as I saw in your crate.
Nice writeup - good to see impressions from people who are new to the language. One correction: &gt; I like that it has explicit threading support, and it is interesting that this is baked directly into the language and checked by the compiler Rust doesn't have explicit thread support - threads are in the standard library, and the compiler is unaware of 'threads' as a concept. Instead, the same memory safety constraints that keep you safe from Use After Free vulnerabilities and the like are also sufficient to prevent data races - this is the 'ownership' model. Also, as a suggestion, if you ever have questions or anything, feel free to jump into the rust IRC channel - there's a #rust-beginners channel for simple questions, so don't hesitate to ask anything.
Just FYI I am on Chrome on Windows, cleared my cache/cookies etc, still getting a blank page.
Is it possible to do it in this case? https://play.rust-lang.org/?gist=8eaa836ca4178771e2b3cb6283187f80&amp;version=stable&amp;backtrace=0
Hmmmm... This has been a sporadic issue and I haven't been able to pin down the problem unfortunately. :/ Thanks for letting me know though. I'll test it out on my windows machine later!
Thank you very much. You've helped me alot
The whole site or just the demo?
Oh, yep, will do! And, thank you for bringing up your crate. I wouldn't have otherwise known some of the magic you'd done, nor I would've realized that I should "cargo search" before running to implementing something :P That said, I'm planning to take this further to find approximate matches, so I think I don't have to entirely abandon the implementation :)
Is there possibility to match enum types without comparing inner fields?
What's the use case for this?
There is no generic documentation about BPF in it, and it's more a compilation of existing sources (uBPF docs and [commands summary](https://github.com/iovisor/bpf-docs/blob/master/eBPF.md) by the same author), but I am glad you like it. (Self promotion) In case you might be interested, I gathered some links to BPF resources [here](https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/).
For instance I've just run into problem of filtering general pool of events to pick out all the events addressed to entities of specific type. Of course receiving entities will be described as a some kind of reference
As far as `Rc&lt;RefCell&lt;Vec&lt;T&gt;&gt;&gt;` is concerned you may want to read http://manishearth.github.io/blog/2015/05/27/wrapper-types-in-rust-choosing-your-guarantees/. These things aren't that common but it's important to understand them. 
Are you sure it's a good way to handle things? Maybe your entities should filter out the events they can handle? Then you can do something like `events.map(entity.handle)`, and have `entity.handle` automatically drop the events it doesn't care about or use `if let`. You will still be matching on the event type if the entity handles multiple events, too.
For approximate matching, consider using the [`fst`](https://crates.io/crates/fst) crate. It might not fit your problem domain, since there are some [interesting requirements you must meet to use fsts](https://docs.rs/fst/0.1.35/fst/#quirks). But if you can use them, you can do super fast Levenshtein queries: https://docs.rs/fst/0.1.35/fst/struct.Levenshtein.html (Or any query that can be [formulated as a finite state machine](https://docs.rs/fst/0.1.35/fst/trait.Automaton.html).)
If it's any consolation, shows up great in my browser.
Thanks!
It's a mixed bag. On one hand fancier things (like what gnome does is) is cheaper because they are one and the same component and you get increased security. On the other hand you get usability issues like this. As time goes on and protocols stabilize however (and more frameworks come out to make window managers) this will no longer be a problem 
You're welcome!
Glad that ended up being what was needed here!
The ticket relating to to name has sadly just been closed. I also prefer `httplz`.
Try to get `update &lt;table&gt; set count = count + 1;` working with Diesel if possible, it's really much simpler than looping... You can even throw in a `returning count` in there to learn about the current count.
[A JVM](https://github.com/lolzballs/rust-jvm) because I hate myself. First rust project too!
*Shimmying intensifies*
I'd suggest just writing the actual match statement then. Or if you use in a lot of places you could impl a function matches for your enum that does the work. Alternatively you could write your own eq function for the partialeq trait but I wouldn't do that if the result isn't completely obvious.
Where does this message say that he's leaving Apple?
&gt; This recognizes the incredible effort he has already been putting into the project, and reflects a decision I’ve made to leave Apple later this month to pursue an opportunity in another space.
From what I can tell, the difference is that managed allows mutability, whereas Cow requires that reference types be converted to an owned type before they can be modified.
&gt;Something that was really strange during the reading is that Rust uses the type of the assignment to infer types. IIRC Java does this.
Maybe mention that you practically copy/pasted the lazy_static', DB struct and the RequestGuard from this thread on the issue tracker where discussion about the topic is on-going: https://github.com/SergioBenitez/Rocket/issues/53#issuecomment-269460216
Ah sorry, for some reason I didn't see that mention when I read the article the first time around.
Sadly only `&lt;Knowledge as Into&lt;Rust&gt;&gt;::into(knowledge)` would work since the generic param is not `fn into` but on the `Into` trait. This is why I tend to find `Destination::from(value)` more ergonomic when the target type _can't_ be inferred.
Ah I see. I just assumed it only passed one `FromRequest` parameter in - didn't know you can have an arbitrary number.
Allright, I asked the maintainer of Diesel. Turns out you can write `update(table).set(count.eq(count + 1))`, but you'll need to have called the macro `numeric_expr!(table::count)` for that to work.
Woah what is that about prominent rust developers now working on swift at Apple? Care to fill me in?
I believe Graydon Hoare, the creator of Rust, now works on Swift at Apple. 
Graydon, Gankro, Huon. Not a secret, they're openly committing to swift projects on github and emailing on swift mailing lists with @apple.com emails.
Oh, so you are extending the wayland protocol for this or are you using a protocol someone else defined? How is your experience defining this protocol? If I understand the specs correctly, wayland is basically a capability-based protocol? How does this factor into the design?
I think it really depends on what you intend to do. That is, IMHO MPI vs. ZMQ is an apples to oranges comparison. If you're doing a simulation of, say, some physics/chemistry/etc. phenomena and you want to parallelize it over several machines via domain decomposition, it seems to me MPI is the obvious choice. It has the kind of primitives you need for that kind of applications (e.g. highly optimized collective operations), there exists MPI libraries with backends for every exotic HPC network you can imagine, and so forth. I wouldn't worry that much about lack of full MPI 3.1 support at this point, you can get pretty far with the basic MPI 1.1 API. ZMQ/nanomsg seem more targeted at typical messaging applications, say for implementing the networking part of some high frequency trading system, or whatever.
&gt;Oh, so you are extending the wayland protocol for this or are you using a protocol someone else defined? We are going to use the same protocol defined by orbment and sway (see [here](https://github.com/SirCmpwn/sway/blob/master/protocols/gamma-control.xml)). It will require using a patched version of Redshift, at least until the change has been merged upstream. &gt; How is your experience defining this protocol? As of yet, we haven't implemented any Wayland protocols on our side. It would require using the raw bindings provided by the wayland-sys crate, as the fancier bindings are incompatible with wlc. We will begin implementing Wayland protocols during this next iteration. &gt; If I understand the specs correctly, wayland is basically a capability-based protocol? How does this factor into the design? You are correct, Wayland is really just a protocol for clients (windows) and server (compositors/wm's) to talk to each other. This design means that the window manager is generally more monolithic, as is evident with us implementing "basic" things like a background and redshift/gamma support. Programs that use a Wayland Protocol will be treated, from a design perspective at least, as clients of Way Cooler. They may not talk to us via D-Bus, but they are still going to be separate programs that extend the functionality of Way Cooler. As time goes on, and more and more protocols are stabilized (most Wayland protocols are unstable and unimplemented in most programs), we may begin deprecating certain D-Bus commands in favor of using the defined wayland protocols (e.g I'm going to add a screen shot program using D-Bus, and I know sway also uses its IPC to communicate the bytes of the image. If a screenshot protocol stabilizes however, then Way Cooler will switch to that) 
Interesting that Ayende has decided to try Rust. It could also be a good thing for Rust itself. Ayende is a talented developer and has created some amazing technologies on .NET. Glad I am not the only .NET dev that felt like they were falling into a loop and decided to branch out to Rust.
You seem surprised. Why? Both Rust and Swift are modern systems programming languages; naturally the small group of highly capable people who are active in this space can work on any of these languages, and (I imagine) might like being able to learn from an environment they have not been exposed to. Plus, it does not seem unlikely that Apple will pay more for deep Swift development than any one is being paid for Rust work right now.
Apple's not known for being cool w/ their employees talking much about their employeedom, so prob not. As a completely independent observer they all seem to be on good terms with Rust still. Speaking strictly for myself, I think Rust is the better, more interesting language in a technical sense, but working on Swift would be an amazing gig, you get to blow right past the tedious mindshare building and get your work directly in the hands of many thousands of devs working on all kinds of projects.
No; Apple doesn't take kindly to people talking about things. Still, if you're interested in systems programming with algebraic data types, Rust and Swift are pretty much your only options. Of those two, Swift is far more business-critical to Apple than Rust is to Mozilla, or to all of the companies on the Friends of Rust page combined - it's not surprising that Apple is pouring more resources into Swift (including hiring the best people they can find) than Mozilla/Rust can counter-offer.
Surprised? Well, it surely came as a surprise, but thats it. I'm just interested. Could be they had talked publicly about "seeing more of a future in swift than rust for large scale adoption" or something. I use swift and rust daily myself btw (and prefer error handling in rust 😏).
&gt; Has any of them publicly shared their reason for this? Not meaning to be sarcastic in saying it, but I have to imagine a healthy paycheck is also a fair motivation to work in Swift full time.
Yeah, I like swift almost as much as rust. The only real painpoints for me has been error handling in swift, which is better than exceptions but worse than what rust offers I think, and I still think that swift package manager and the swift toolchain is lagging for everybody not using xcode compared to rust where everybody is at equal terms.
Gankro and Huon were summer interns for Mozilla in 2015, then graduated to full-time gigs at Apple afterward. Graydon left Mozilla in 2013 to work on cryptocurrency, then later was quietly picked up by Apple. Huon is still around here all the time (username dbaupp), Gankro pops in on occasion (though less in the subreddit than on some other forums), and Graydon is as reserved as ever, though I fairly often see him retweeting prominent Rust news on Twitter.
I don't know. How does one test that?
How about the [discriminant](https://doc.rust-lang.org/nightly/std/mem/fn.discriminant.html)? It's still unstable though currently
If I were to use a Vec, I guess you could even map and collect them, but that's not the same thing. Of course in practice just using a vector is easier, but I was wondering about arrays specifically. 
Seems like he is leaving Apple to become the Vice President of Autopilot Software for Tesla. [Source](http://www.macrumors.com/2017/01/10/chris-lattner-leaving-apple/)
+1 this, although I guess if you do JIT, you leave Rust's memory safety behind. Still, Rust makes it easier to arrive with good code than C does.
Really?! And only now this gets posted?! :P Edit: I wish I could join in, but there's no way I can get a decent flight right now.
He is [going to tesla](https://www.tesla.com/blog/welcome-chris-lattner).
I've never talked to any of them about this, but it seems fairly straightforward. They're excellent PL designers, they were looking for work, Apple was hiring, Mozilla wasn't.
&gt; if you're interested in systems programming with algebraic data types, Rust and Swift are pretty much your only options. only popular options at least; off the top of my head i can think of two under active development - [ats](http://www.ats-lang.org/) (esoteric, but pretty mature) and [myrddin](http://eigenstate.org/myrddin/) (immature, but the language looks nice), and i'm sure there are others i'm unaware of.
Looks like your instincts were good, [AI on self-driving cars](https://www.tesla.com/blog/welcome-chris-lattner) is the answer!
Thanks! Should be fixed now; me notes to never reboot a container host in a hurry without an extensive checklist ;-).
Glad you like it :)
It is actually more powerful than this in Rust, the type can be inferred from how you use it later (i.e. Rust knows that you have a map of ints if you insert ints into the map at some point). This kind of type system is called [Hindley-Milner](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system) and it is an old concept very common in functional programming languages.
He says he's still going to be involved in the Swift project. That's going to mean at least occasionally contributing to LLVM upstream. /me thinks Rust would probably be more suitable for implementing autopilot in, since the language provides facilities to avoid non-deterministic behavior like allocations, but the reality is that it's probably written in C and can't change without auto regulators getting on their case. They're, rightfully, resistant to change.
I'd love to be there too!
Exactly. It was inspired by Cow to some degree, too.
Har. You mentioned a *Linux* CLI in the description. Does it work on Windows, and, if not, are there any plans?
`let array = [SomeStruct {a: [0; 10], b: 0}; 100]` should work. There have been proposals in the past for a `POD: Copy` trait that you use for types for which all bit patterns are valid and can be initialized zeroed or from a buffer.
That works if you `#[derive(Copy, Clone)]`.
Is lua really called for? In the thread, someone comments &gt; We wanted users to be able to do arbitrary things with their window manager / applications, whether at startup time or at some other time, without having to do a weird hack or make a client program but I don't see how the logic here differs at all from, say, a task bar. Moving work into a separate process--and complexity out of the project--is not a sin.
I have never looked at how `git status` works, but was just having some really annoying perf issues with it myself today.
Yeah, I should have specified that I don't necessarily want to derive `Copy` here.
I think this might require an implementation of HTTP status 206, partial content, but I'm not 100% sure on that. 
Do you know what the primary bottleneck is? If the bottleneck is "there are so many files that their stat info doesn't fit into my file system cache" or "my git repo is on a network mount," then there's really not much you can do to speed up the fundamental operation with adding some kind of caching layer of your own. Let's take the `chromium` repo---which is pretty beefy---as a test case. With a cold file cache, `git status` takes `1.16` seconds, and with a warm file cache, it takes `0.65` seconds. With a cold file cache, `git status --untracked-files=no` takes `0.64` seconds, and with a warm file cache, it takes `0.2` seconds. So it seems like whether it needs to search for untracked files or not is a big differentiator. Can you live with that? If so, you might be done. :-) Looking more closely, I generally consider GNU `find ./` to be about as fast as you can get for recursively listing a directory in a single thread. In my case, `find ./ &gt; /dev/null` from the chromium root takes `2.26` seconds on a cold file cache and `0.27` seconds on a warm file cache. To me, this means `git status` is already doing clever things, although `find` does beat plain `git status` on a warm file cache. As another landmark, `rg -uuu --files &gt; /dev/null` takes about `0.22` seconds and `rg --files &gt; /dev/null` takes about `0.25` seconds, both on warm file caches. (ripgrep has a parallel iterator, which is how it's able to beat `find`.) AIUI, people have already tried cracking this problem. It seems [Facebook has written some kind of caching layer for it.](https://bugs.chromium.org/p/chromium/issues/detail?id=535746) Some of the comments in that thread are interesting, such as increasing kernel limits that might prevent file stat info from staying in the cache.
It's not one-to-one identical, but being experience with how a compiler transforms data is not too different from how one must think in many other complex software engineering roles, be it in AI or other signal processing or big data pipelines or real-time devices. Much more broadly speaking, it's less the specific algorithms and more about being able to think like an honest-to-Knuth computational scientist rather than just thinking like an application developer. :)
Yeah `drop_in_place(x)` is semantically equivalent to `let _ = ptr::read(x)`, except it works even on unsized types (which otherwise can't be loaded onto the stack). FYI the standard terminology for "not drop, doesn't contain drop" is Plaid Old Data (POD).
&gt; The problem with moving that logic into the task bar is than now the task bar needs to implement this functionality. The task bar should be worried about the task bar, not what programs to run at startup or to dynamically change other options at runtime. I didn't propose moving that logic into the task bar, I compared moving that logic out of the core to the decision that was made to move the task bar out of the core. Separation of concerns is good. &gt; The Lua thread has a tight integration with Way Cooler, allowing us to give it special benefits that would be too powerful for client programs. Like what? &gt; It also gives the user the tools to make simple commands without having to resort to using a client program with a full blown D-Bus connection. There are other ways to solve that problem. For example, write a simple client program that just runs lua scripts with access to the D-Bus API, providing the same user experience without any design compromises. Given that (apparently a variety of) lua D-Bus libraries already exist, this may effectively already be done for you, modulo a thin convenience wrapper or something. You thereby avoid a lot of complexity inside the compositor and provide a level playing field for people to interface with the compositor using whatever tools and technology they like. &gt; I'm not looking to remove Lua from the project altogether sway it is, I guess. Shame, it'd have been nice to be running rust code.
Cant wait for it to go to async for it to be usable production-wise!
&gt; Though let me at least still make my points. Even if I don't convince you, it's a nice exercise for myself to remind myself why I'm sticking to my guns ;) Sure, I like a good architecture discussion as much as the next developer. &gt; It would lose the plus of being able to bind keybindings to Lua functions This is not a thing I have any desire to do. If I want complex behavior from a keybind, I'm going to have a much easier time producing it using a shell script (or, in extreme cases, a program written in a real language) than some lua environment. &gt; Off the top of my head, I'm not sure how we could reliably tell Way Cooler through D-Bus to run an arbitrary Lua function unless we have some specific code to retrive it The objective of the design I outlined was to allow lua to be removed entirely from the compositor. As a result, it wouldn't make sense for it to be the compositor's responsibility to execute lua code. I imagined the compositor's configuration specifying (for example) an executable to launch with the special privilege of receiving all input globally. Such a program could contain a lua environment, and trivially implement the binding of key combinations to lua functions 100% internally. Someone else could write a program that executed shell scripts instead. xbindkeys is a program designed on this principle which I'm currently using with X11. &gt; There really isn't that much complexity in terms of Lua in Way Cooler itself (it's "only" 10% of the code base in terms of lines). But that's not the point. The complexity I refer to isn't just that which arises from binding to lua, but the presence of the lua implementation itself. A programming language implementation is an awfully large thing to have in-process, especially if you're trying to be secure. It also increases the bare minimum amount of knowledge required to configure/use the compositor. &gt; When designing Way Cooler, I wanted to have a more "feature complete" approach to extensibility Being feature-complete doesn't require you to be monolithic. I'm 100% in favor of not forcing the user to use Rust to use their compositor. I don't understand why forcing the user to use lua is supposed to be any better--you might as well just dynamically link Rust code. With Wayland and D-Bus and so forth, there's finally good OS support for modular, robust IPC interfaces to provide high levels of extensibility without forcing any particular toolset on users at all. &gt; Out of curiosity, what is it about having Lua integrated that turns you off of the project? Is it purely the added complexity, or do you prefer your configuration files to not be so Turing Complete? Those are both problems. I strongly feel that independent processes communicating over a well-defined protocol is the right architecture for extensible systems. I also personally have no interest in writing lua code (it does exactly the opposite of many of the things that make Rust such a great language), and it sounds like way-cooler will give me no choice in that matter.
&gt; Why is debug mode so much slower? I get it being like 2x to 3x slower but 10x slower?? 1. Overflow checks on every single arithmetic operation. 2. Minimal inlining. 3. 1 and 2 getting in the way of what little optimization it does try to do. &gt; I was thinking about building a static lookup table with a build script but I wasn't sure what the best way to trigger a rebuild would be. Any thoughts? Incremental compilation isn't available yet, so every build is a rebuild.
&gt; That could work, though it'd be a bit hacky I'm not sure why it's hacky. I don't have the Wayland protocol loaded into my head in any detail right now, but if it's possible to encode the privileged input stream in a standard way, then such a tool could even conceivably be portable across compositors, which would be great. &gt; The user doesn't "have to use Lua" in the same way you "have to use Lua" in awesome You're right, I could just pretend really hard that lua is just yet another wacky declarative config format, and it'd be smarter to do that than to substantially duplicate development effort. The design is unlikely to stop striking me as elaborately unnecessary at the very best, but there are worse problems to have. If sway doesn't work out for me I'll definitely give way-cooler a good-faith try.
I am also saddened by this because I am one of (what I can see) about 7 regular answerers to Rust questions on StackOverflow. Do you have an example where you felt the answer or comments weren't appropriate? I have found most questions and the communication within them to be fairly friendly to be honest. I personally try to be friendly in my answers.
It seems to be an alternative implementation of the node.js APIs. It's still using V8, but all of the node stuff is written in Rust
It'd be really neat if the run schedule could be overlaid on top of the graphs. That way we could see which runs pulled in the most money :)
Thanks, I didn't think to look in the Cargo.toml. I fixed it myself now, also the reason for the white screen is that I messed up when adding the OFFSET_X and OFFSET_Y constants, I've fixed that with [this revision](https://gist.github.com/noughtmare/4d7fa5f25410814ee3bc65fb48877895/revisions#diff-6a9a437f063df1d690be66f324b6090b).
What kind of benefits would it provide? ^^^^Also ^^^^Unrelated ^^^^But ^^^^Ram ^^^^is ^^^^best ^^^^girl
I think Imma do something crazy and learn OpenGL with Rust.
Is it... an alternative implementation of node?
A tangent, but I prefer to use a script that just shows the current diffstat for staging area and working directory. The diffstat gives a clearer picture of what the state is. (It's also faster the same way because it doesn't care about untracked files.) https://gist.github.com/5c58505ba8c6e232de10dd90c6bb4bc1 STAGED parallel/Cargo.toml | 8 ++++++++ 1 file changed, 8 insertions(+) create mode 100644 parallel/Cargo.toml IN WORKING TREE src/parallel/mod.rs | 2 -- 1 file changed, 2 deletions(-) 
I have just installed `https` crate. The published version doesn't support the `-e` flag. $ http -e error: Found argument '-e' which wasn't expected, or isn't valid in this context USAGE: http [FLAGS] [OPTIONS] [DIR] For more information try --help $ http -h https 0.3.0 thecoshman &lt;thecoshman@gmail.com&gt;:nabijaczleweli &lt;nabijaczleweli@gmail.com&gt; Host These Things Please - a basic http server for hosting a folder fast and simply USAGE: http [FLAGS] [OPTIONS] [DIR] FLAGS: -w, --allow-write Allow for write operations. Default: false -s, --follow-symlinks Follow symlinks. Default: false -h, --help Prints help information -i, --no-indices Always generate dir listings even if index files are available. Default: false -V, --version Prints version information OPTIONS: -p, --port &lt;port&gt; Port to use. Default: first free port from 8000 up -t, --temp-dir &lt;temp&gt; Temporary directory. Default: $TEMP ARGS: &lt;DIR&gt; Directory to host. Default: current working directory 
I don't really understand why, and (since I'm a newbie) the linked issue doesn't really explain it either. Does anyone know why it's a breaking change?
This is awesome! Makes newtypes so much more useful. Any particular reason the Assign variants are not available or are you planning to add them?
"because `Box&lt;T&gt;` is #[fundamental]" is the short answer. This is an [example of code that would have broken](https://is.gd/7Y3t0b) if I kept the blanket impl on `Box&lt;T&gt;`. AIUI, that code normally wouldn't work for an arbitrary type constructor, but since `Box&lt;T&gt;` is special, it does work. And therefore, blanket impls can break them. I'm probably not the best person to explain this, so I'll just defer to [the RFC](https://github.com/rust-lang/rfcs/blob/master/text/1023-rebalancing-coherence.md).
Just a bug in the OpenGL drivers, then?
Also probably the winit issue that was linked. People who use OpenGL don't even realize how crappy the whole ecosystem is (both in Rust and non-Rust). 
In this case, because your structure doesn't contain any pointers, `std::mem::zeroed()` is safe. There's just not a way, currently, to statically prove that so that `zeroed()`, or more likely, a wrapper around it, can be invoked without `unsafe`. You can wrap this in a safe function if it makes you feel better: fn init_array() -&gt; [SomeStruct; 100] { // All fields of SomeStruct are valid when zeroed unsafe { ::std::mem::zeroed() } } Besides the difficulties of initializing an array of 100 non-`Copy` elements without `unsafe`, 1.4KB is kind of big to go on the stack all at once, though I'm sure most system configurations wouldn't notice the difference unless the stack was *really* deep. However, is there some reason you don't want to use `Vec&lt;SomeStruct&gt;` (heap allocation) instead? It's much more straightforward: let structs = vec![SomeStruct { a: [0u8; 10], b: 0u32 }; 100]; 
Maybe not "learn programming through Rust" but something akin to let's go through making this project that one makes in python or c or c++ in parallel with Rust so you know how to apply what you allegedly learned. I think the problems usually lie when people try to do the things they did in other languages with complex stuff once they understood the simple things in that book.
For Mercurial, Facebook built [the FSMonitor extension](https://www.mercurial-scm.org/wiki/FsMonitorExtension) which uses a watchman server to track local changes and only check those for changes.
I hope Vulkan can fix some of this, even if it just means using a GL-atop-Vulkan layer for noobies like me
Looks like init-with-rs is almost perfect. It has a limit of 32 items, but that doesn't really matter in my current situation. Thanks!
I nominated you for QotW. You should blog more. 😃
A reminder that our software can be safe and great, as long as the underlying ecosystem (OS, drivers) errs, we are not actually safe (though still safer than crap code on top).
It definitely should be possible to solve this with lifetimes, however one simple solution you could consider is to make `Element` simply have the indices of the `Node`s in question (`nodes: (usize, usize)` instead of `nodes: (&amp;Node, &amp;Node)`), as long as you can guarantee that `Structure.nodes` will only ever be appended to, never having insertions or deletions. If you're willing to build a minimal example of your problem that complains about lifetimes on the [Rust Playground](https://play.rust-lang.org) and then click "Shorten" and share the link with us, it'll be easier for us to help you with lifetime issues. Someone who is more of an expert in lifetimes may come along shortly and be able to help you regardless, I dunno.
[Why can't I store a value and a reference to that value in the same struct?](http://stackoverflow.com/questions/32300132/why-cant-i-store-a-value-and-a-reference-to-that-value-in-the-same-struct)
You're trying to have a struct which has references into itself. It's not supported by Rust. You can work around this problem in a few ways: 1. Use indices instead of references. 2. Use `Rc&lt;Node&gt;` instead of references. 3. Use some kind of graph library from crates.io. 4. Don't store `Vec&lt;Node&gt;` in `Structure`: struct Structure&lt;'a&gt; { nodes: &amp;'a [Node], elements: Vec&lt;Element&lt;'a&gt;&gt;, } fn main() { let mut nodes = vec![]; // initialize nodes let structure = Structure { nodes: &amp;nodes, elements: vec![] }; }
"Rust is new, in the sense that it has the Burrow checker" Be careful you don't disappear down that rabbit hole.
Gotta work on Friday :(
Thanks, I haven't had much use for reference counted pointers yet so this could be a good intro. Also with the lifetime in: Vec&lt;Element&lt;'a&gt;&gt; Is that saying that the element within the vector should have a lifetime &gt;= to structure or is it referring to the vector itself? 
Thanks, don't have time to look at this right now but it looks informative
Seems like [this is being changed](https://github.com/rust-lang-nursery/fmt-rfcs/issues/39) for the official style guide.
Nice! Let me know if you want help with that! The next step would be to get rid of `is_box()` entirely except for placement box situations, and add a private `DerefMove` trait that deref on box uses.
Oh, right, that's actually the most common use of Box I've seen, listed :) Why does the AST need `&amp;mut` pointers? It is immutable! Though during the expand phase IIRC much of the AST is transient so we'd have to put it into an arena in a later step. I think.
That's awesome! Any idea if you will publish to crates.io in the future?
&gt; rustc -C linker=emcc.bat --target=wasm32-unknown-emscripten hello.rs -o output.html worked for me after everything else is configured correctly.
most exciting thing.
Yeah, seems like the DNS hasn't propagated fully yet? I changed the name servers over 12 hours ago though... so not sure.
I don't see a bad cert here. It's possible that DNS hasn't reached you. It was changed last night; it started resolving for me about 10 hours ago...
Don't you have to mutate the AST for things like type inference? My toy compiler would parse, build an AST, then come back around and be like "Hey this expr looks it should be an int" *mutates* Edit: Is there a better way of doing this?
I think you mean Rem. On a more serious note probably reducing security vulnerabilities since Node is in C++ but not much else.
&gt; Seriously though, does anyone use it much? I’ve only seen it getting used for boxed DSTs (trait objects and boxed slices), which themselves are pretty rare, for sending heap types over FFI, recursive types (rare), and random special cases. Git-grepping through some of my projects, here is the number of `Box` occurrences versus the number of `Vec`s: * [A fast but limited path tracer](https://github.com/ruuda/convector): 0/313 * [An audio format decoder](https://github.com/ruuda/claxon): 1/26 — A boxed slice used as a buffer * [Another audio format decoder](https://github.com/ruuda/hound): 0/24 * [A slow path tracer with more primitives](https://github.com/ruuda/robigo-luculenta): 58/156 — Mostly trait objects for polymorphism * A private project about static program analysis: 42/30 — Recursive data types (ASTs) 
Kudos for the amazing work!
It's finally here :D Good job!
Oh this is something that I thought about doing a few times but was low-priority (unless we make it really a struct, because then that needs a newtype-friendly LLVM type computation algorithm). Will r+ your PR if you open it ;).
Well, the lifetime parameter on `Element` is because it requires a parameter – if you tried to implement it, you'd get something like that (using `'node` instead of `'a` for clarity): struct Element&lt;'node&gt; { nodes: (&amp;'node Node, &amp;'node Node) } So now, in the definition of `Structure`, where you have `Vec&lt;Element&lt;'a&gt;&gt;`, it means that you're using `Element` with `'node` = `'a`. So what's happening is that you're marking the lifetimes of these two references as the same: nodes: &amp;'a [Node] // in Structure nodes: (&amp;'a Node, &amp;'a Node) // in Element So now Rust knows that references in `Element` come from the same origin as `nodes` in `Structure`.
Name servers typically have a TTL of 24 hours or more...
I'd say that rustfmt in it's current state is effectively useless, and it cannot be configured to be much better. For functions, I prefer the following syntax: fn super_long_function(arg1, arg2, arg3.... arg5, arg6) -&gt; return type { /// actual code } Although what gets me about rustfmt is not aligning code properly. Rustfmt will not take this match action() act =&gt; do_this(), action =&gt; do_that(), actions_to_take =&gt; or_this() } and convert that into match action() act =&gt; do_this(), action =&gt; do_that(), actions_to_take =&gt; or_this() } Or notice patterns like so: let value = this; let other_value = that; let this_value = there; and convert that into let value = this; let other_value = that; let this_value = there; It's easier on the eyes when you keep everything properly aligned.
Daniel Norman has already kicked off the tokio app skeleton, check it out here: https://github.com/SDRust/tokio-chat
The documentation is impressive.
On every team I've been on this has been forbidden due to the VC noise it creates.
This was my thought too: if you want real-time tracking, you may want to spin a daemon and have it use inotify so that it always has an up-to-date list of modified files.
Announce mentions that one of the goals is "Completing a full HTTP/2 implementation". I'd like to know where is this "incomplete" implementaion? Because I have an (also incomplete) implementation of HTTP/2 https://github.com/stepancheg/grpc-rust/tree/master/http2 as part of gRPC implementation. I would really like to replace it with another implementation and participate in development of that library. Because HTTP/2 implementation is actually larger than remaining part of gRPC, and good HTTP/2 implementation is hard.
Same here. &gt; This server could not prove that it is tokio.rs; its security certificate is from jessica.wate.rs. This may be caused by a misconfiguration or an attacker intercepting your connection. Learn more.
&gt; Edit: Is there a better way of doing this? I personally prefer having *two* AST: - an Abstract Syntax Tree, which only represents the syntax, and nothing else - an Abstract Semantic Tree (?), which has the type information built-in (and can reference the former) This way, you avoid mutability.
Whoo! 🎆 I'm still a bit confused though about the async space right now. What is the difference between using `mspc::channels` vs `tokio::channels`? Where do I use `channels` and where do I use `Futures`? Are these all just a different ways to handle asynchronous code? Or are they mutually exclusive? 
We don't support externally-supplied templates as of yet, but take it up with Pirate [here](https://github.com/thecoshman/http/issues).
It means that the foundation has been laid, so people can start building stuff. Hyper has a tokio branch, it's quite usable, and has been waiting for this to land before it can be merged into master.
Is in progress: https://github.com/hyperium/hyper/tree/tokio
They're different ways of doing things. Channels don't have to do with I/O, and `mspc::channel`s are blocking unless you use the `try` variants.
^^Trash ^^Waifu And damn thats a quite a bit of requirements for deps 
I'm a huge proponent of the second choice as well. I'm not sure how helpful my opinion is, since I also use hard tabs and block comments like some kind of filthy heretic, but yeah the first style bugs me to no end.
Definitely a huge improvement over what existed before this release. I think I could actually make something with this now!
Thank you!
Good point. I was thinking it might be possible to construct such API to use Rust type system directly to produce desired result. But I'm unsure how practical that might be.
code formatting "style" has to be one of the most boring arguments on the interwobs
As the name suggests, it [uses tokio](https://github.com/lambdastackio/tokio-http2/blob/8f034b24b549b9df043f0f53c7c9b53ef2749878/Cargo.toml#L34-L37). I imagine it hasn't published a version that depends on tokio because that was only possible with this announcement: three of the tokio libraries weren't on crates.io, they had to be git dependencies.
Yeah, I find this annoying, especially because nothing explicit like `into_inner()` exists. When I wanted to get value out of `Box`, I was hugely confused.
Is there some reason not to use block comments? I take it by that you mean: /* * Comment * */ or something similar.
hopefully this is within scope for this thread... coming from a more functional background (my previous love was clojure), i prefer to limit the *sites* of mutation as much as possible (pure functions for most logic). i'm trying to apply this mentality to the design of my first real rust project but i'm not sure if it's idiomatic. so here's example code similar to what i'm playing with currently: fn main() { let mut state = State{ player_health: 10, monster_health: 10 }; loop { // get action string from stdin -&gt; command: &amp;str let change = action(command); change(state); } } struct State { player_health: u32, monster_health: u32 } fn action(command: &amp;str) -&gt; ??? { match command { "check" =&gt; |s| println!("your HP: {}, monster HP: {}", s.player_health, s.monster_health), "attack" =&gt; |s| s.monster_health -= 1 } } questions: * what type should fn `action` return? if instead of returning closures i returned pointers to named functions would that change the type? should i make a type alias for this return type and how would that work? * where does this approach lie on the "idiomatic" scale? i would prefer to do something like this with the game state so that i can process state (concurrently?), collect any changes, and then apply mutations in a single place.
Rust community standards prefer `//[ /!]` for all comments. I hate using line comments for massive documentation comments. Also, RustDoc doesn't respect Doxygen style `*` line prefixes. Block comments include every token between the opening and closing sigils. I write docs like so /*! Summary More words !*/ And "here's what I'm doing in this line" with normal line comments `// text` (two spaces).
Porting an entire operating system to Rust? That sounds like an impressive project! now, will there be any text editor in Remacs? I hear `vim` is a pretty good option, if you're looking for suggestions. ;)
Is threading optional? It seems that I could use my own task system instead of using `handle.spawn(..)`.
I also dislike the excessive rightwards drift and the needless diff noise the default settings bring. IMHO it's trying to hard to conform to some misguided ideal. I like my code terse and will usually format accordingly. This means a single line break iff the args don't fit on one line, but not one line per arg. Also I will sometimes put short `if` expressions on a single line. My rationale is that as I'm getting older, I won't be able to fit long functions in my head, but as long as I can read one function without scrolling, I'll be fine.
Might be worth poking at some of the stuff Federico has done with the librsvg port, including the auto* bits that integrate and execute cargo. It's nice to hold on to the old familiar `./configure &amp;&amp; make` workflow... until you can turn the whole beast into a crate, that is. :-)
And as for when incremental compilation potentially messes with you, you could use the build script to write the look up table to a fine and then `include_bytes!` it which, AFAIK, would trigger a rebuild of the file when it changes. 
This matches my understanding of the Tokio design. If I'm not mistaken, `spawn` is provided as a convenience because it's how many people will want to handle tasks, and not because it's essential.
You're looking for /r/playrust
Easier to reason about I guess? You'd also need a bajillion `RefCell`s to make it work safely.
Note that `Box&lt;T&gt;` can't have methods because they would get in the way of regular methods on `T`. In general, smart pointer types don't implement their own methods, and instead you would have something like `Box::into_inner(bx)`. That said, I do wish `Box::into_inner` existed because it's confusing otherwise.
One thing you can do is use the write! macro to avoid intermediate allocations: https://is.gd/griWg2
Thanks, I'll take a look. My autotools-fu is very weak.
Ah yes thanks for the question! To clarify: * `std::sync::mpsc` - these are blocking, synchronous channels. They shouldn't be used with tokio most of the time as blocking isn't typically what you want * `futures::sync::mpsc` - these are equivalent to `std::sync::mpsc`, except they're asynchronous. The channels here implement `Stream` and `Sink` and are all "futures aware" * `mio::channel` - similar to `futures::sync::mpsc`, but we'd recommend using `futures` instead. They're equivalent in the Tokio world and should suit use cases better * `tokio_core::channel` - this module is deprecated in favor of `futures::sync::mpsc` Basically, `futures::sync::mpsc` is what you want. Through that you use it like any other `Stream` and `Sink` 
You can indeed! The `futures` crate is generic over the concept of an executor, which you can [read more about](https://tokio.rs/docs/going-deeper/tasks/). Other executors can be `CpuPool`, a thread pool, the current thread via `wait`, or an event loop, for example.
After some digging I found that I should use `crate-type = ["cdylib"]` which looks like it does the right thing. It still exports the following symbols: __rust_allocate, __rust_deallocate, __rust_maybe_catch_panic, __rust_reallocate, __rust_reallocate_inplace, __rust_start_panic, __rust_usable_size Why does it do that and how do I prevent it?
Thanks for the response! I realize as dbaupp mentioned that since the code itself doesn't contain any code that concurrently attempts to `get_mut()`, there's no possibility for a race condition. But I think the overall idea was that the potential is there, say if code is later changed elsewhere and this code isn't updated, contrary to there being no possibility in the case of using an `if let Some()` construct. That's because AFAIK, the outer check of `get_mut().is_some()` causes that mut ref to "die" since `is_some()` just returns a bool, i.e. that "lock" is gone. So hypothetically if later for whatever reason code were added that potentially concurrently attempted to `get_mut()` as well, it could be that the `is_some()` check returns true, then a context switch occurs and the other code is the one that obtains a `get_mut()` because after all the `is_some()` expression didn't yield an actual mut ref (i.e. "lock"), then upon context switching back to the `is_some()` execution thread, the subsequent `get_mut().unwrap()` would panic. Yes that's all hypothetical and clearly not the case currently because the code specifically doesn't have those concurrent paths, but the point is that the possibility is there if the code is ever modified without updating this, whereas the simpler and more direct `if let Some()` construct wouldn't allow this, not to mention saves an unnecessary (?) call to `is_some()` and reduces two calls to `get_mut()` into one. Or am I misunderstanding? **EDIT**: I think I understand, because the "lock" is governed by the arc ref count, if the first call to get mut succeeds then it must be that the second one does too, since the ref count couldn't have increased since then?
You may purposely leak the original heap-allocated values and transmute them into static references, but you'll have to be the one to remember to drop the values when you're done. I do this within my Parallel application because I can guarantee that the references I'm sharing across threads will be available through the entirely of the application after they are initialized. However, there's probably a better method for your case specifically.
Jesus Christ
Hopefully this fixes emacs pinky.
`WaitEventsIterator&lt;'a&gt;` has a lifetime that comes from `self` (It's not explicitly spelled out because of lifetime elision). One option is to use [Crossbeam's scoped threads](http://aturon.github.io/crossbeam-doc/crossbeam/struct.Scope.html#method.spawn) to ensure that the thread will cease to exist before the iterator does.
bingo. *ANY* standard is better then no standard. If you have a decent formatting tool then if somewhere down the line a reformat is decided on then a single git commit can apply the new formatting...and then we can just all move on! A consistent style is a mental help, but it should just be done with tools, not people.
Yes, i'm first creating a Rust code generator for xcb-proto files.
This particular issue is a long-standing style that goes back years; it's not likely to change. https://github.com/rust-lang-nursery/fmt-rfcs in general, https://github.com/rust-lang-nursery/fmt-rfcs/issues/17 for this specifically.
Managed to implement an Rc solution here: https://is.gd/x8snls
http://spacemacs.org/
Couldn't it be made to work over an `Iterator&lt;&amp;[u8]&gt;`? A chunkable regex operation would be useful for being used inside Spidermonkey too (we were discussing replacing Firefox's regex handling).
Can someone give an ELI5 on the benefits that Tokio brings?
Which is why we should indent with tabs, right? :P
No, that's different. The add impl isn't called when you do `1 + 2`, unless it's in a generic context. The deref impl isn't called on `*bx` for a box unless it's in a generic context. There is specific code somewhere in the compiler that generates an LLVM add instruction when it comes across two integers being added, and similarly specific code that generates the equivalent of a deref operation when it comes across it. The deref impls are there to make generic code work, but are usually not what get called. OTOH the stuff mentioned in trusting trust is about things which don't have specific code in the compiler to handle them, e.g. the fact that Rust literally translates `\n` to `'\n'` and gets away with it because we already taught the compiler the ascii code for a newline.
Congratulations! An interesting concept indeed - I look forward to seeing how the roles work out! :)
I'd also like it to work over an Iterator&lt;&amp;[u8]&gt;. Iirc there was a ticket about doing this a while back and it was put on hold because capture indexes could point to non-existent memory. I submit that this is perfectly valid and workable - I would simply have to keep n previous slices around if I wanted to get something working. Currently I have built a simple sliding window implementation for &amp;[u8] that lets captures work, but it could be made to perform better with some support from the Regex library. For example, if I knew that the regex state machine had partially matched/captured something I'd know to keep x previous bytes around so when the regex library finished capturing using the next &amp;[u8] slice I could combine both parts to get the captured slice. This would save me from saving chunks in cases where the regex engine didn't find a partial match in the current chunk. 
Ruby did this way before kotlin, more than a decade before. 
Wait the `write!` macro can take a String as first argument? Wow that's the revelation of the day for me, I had totally missed that until now :s
Yes, basically the `Deref` stuff only works on generics and non-primitive types.
&gt; The main downside is that I’ve had to hard-code the use of network sockets instead of Read and Write. Of course, SSH is usually run over sockets, but this complicates testing: indeed, I was planning to run the protocol in pairs of Vec&lt;u8&gt; in the tests, and now I have to open ports. This is an interesting issue. Good practice in Tokio-using code seems to be to write high level code purely in terms of futures types, so you can substitute any suitable `Stream` or `Sink` (for example, from memory in unit tests). If anything, this becomes even easier than with the traditional `Read`/`Write` traits, because you can implement the abstraction at a much higher level and work in terms of protocol messages rather than bytes, if you want.
`cdylib` is the correct crate type to use. Those symbols being exported is unfortunately a known issue that nobody has bothered to fix yet. https://github.com/rust-lang/rust/issues/34493
Let's say I've got an enum like this: pub enum SomeLongEnumName { VariantA, VariantB(i32), //... } Is it un-idiomatic to do this in order to save horizontal space when using it: use module::SomeLongEnumName::*; my_function(var_a, var_b, VariantB(3i32)); instead of this which is much more wordy: use module::*; my_function(var_a, var_b, SomeLongEnumName::VariantB(3i32)); or is that considered okay? Edit: clarification.
It's still a leak, and valgrind will complain about the leak. You typically leak an object because you want to guarantee that the object lives for the entirety of the application. The OS will reclaim that memory after the program exits.
[removed]
https://github.com/thecoshman/http/issues/35
When writing network applications, there are a number of decision points. The first is whether to use blocking (synchronous) or non-blocking (asynchronous) I/O. The traditional way to do networked I/O is via blocking API calls and that's what the various I/O options in `std` do. The downside to blocking APIs is that they block the thread and threads are a limited resource. If your app is single threaded, blocking the thread means no progress at all is made while you're waiting on bytes over the network and you can't handle any concurrent requests. To work around this pretty much everybody starts up a bunch of threads, holds them in a thread pool, and starts concurrent requests on individual threads. This works pretty well and results in program flow matching the order of code you've written in your file, which is good and why it's traditional. There are, of course, a couple downsides. Most of the downsides involve having lots of concurrent connections. The first and easiest to solve is that your OS will only let you make a limited number of threads (threads have scheduling and bookkeeping overhead inside the kernel) so if you want to have lots of threads, you have to increase a number in your OS config and sometimes reboot the kernel. The second is that each thread has its own stack, which means that you need to allocate some memory to hold the stack. This generally isn't a large amount (I believe it's normally in the 4-8kB range) but if you have LOTS of threads, memory tends to be the main limitation. For both these reasons, most thread pool implementations will limit the number of threads they'll start up and if you run out of threads, you run out of threads. This tends to be better than running into the thread limit or running yourself out of RAM and having the OS kill the whole process. The final downside is a performance one. Switching threads involves a context switch. This means clearing out all the registers and some/all of the L1 cache, switching over to the kernel, having the kernel do whatever it does, clearing out all the registers and some/all of the L1 cache, and switching back to the next thread. This is a smaller context switch than switching processes and happens thousands of times per second so it's not that bad** and is a cost almost everything you're using is paying but it's not free. ** I've seen people argue that it is, the search keywords are data plane networking which generally involves user space networking. As the world has become more connected, these downsides have become more important. An early stab at this is the C10k problem, which was about maintaining 10,000 concurrent connections, which was influential so you'll see references to it with bigger numbers attached. One way to work around a lot of these is to move thread management into your language's runtime and make different tradeoffs than the threads your kernel makes. You'll see things like green threads, lightweight threads/processes, coroutines, etc. These are pretty neat and Rust had a green threading library back before 1.0. The reason Rust doesn't do it this way anymore is because it causes problems with C interop (C expects stacks to work a certain way) and adds runtime overhead. The other way to work around blocking limitations and the way green threading implements IO under the hood is to not block the thread. The main downside to not blocking the thread is that program flow no longer follows the code so it's harder to reason about. The other downside is that since it's not the traditional way, you tend to wind up with a mix between sync/async network stuff, which retains most of the downsides and is confusing to boot. Tokio comes into play once you've decided you want asynchronous I/O. The most important thing that Tokio does is establish The Way (TM) to build async services. Consider Rust's `Option&lt;T&gt;` where you have `Some(T)` and `None` as the possible values. You could just as easily write it `Maybe&lt;T&gt;` with `Just(T)` and `Nothing` as the values like Haskell and friends but if you did that then my `Option` and your `Maybe` would be different types describing the same thing and we'd have arguments over which is better and combinators to map between them and whatnot. Since this is obviously bad, the core team stuck `Option` in the stdlib and everybody uses that. Same thing with `Iterator`. If you look through the Tokio docs, the `Future`, `Stream`, and `Sink` traits are the async equivalents of `Option` and `Iterator`. Having everybody use the same definitions (instead of `Promise`, `Source`, `Observable`, etc) means everybody's network libraries work together. Along with trait definitions, Tokio defines a standard model for how the process of implementing a network protocol gets broken up in the form of Protocols, Codecs, Services, etc. Having defined boundaries gives obvious units of code reuse. A service could (theoretically) be written once and configured to work on top of a UDP datagram connection or over JSON RPC. Everybody could use a single LineCodec implementation, etc. Finally, Tokio provides implementations most of the the lower level stuff. The details of handling async I/O on Windows and Linux are different but you don't have to care if you're building on top of Tokio core. Even if you're using MIO (which handles that detail) there are a bunch of ways to make an event loop that don't compose together, which, again Tokio core takes care of. Hopefully all the parts are easy enough to use that people will use them by default and everybody will interoperate. Hopefully that explains things reasonably well. Tokio is like Rack in Ruby, Servlet in Java, WSGI in Python, etc though it covers more abstraction levels than anything else I know of. It's not immediately useful if you're looking for a Rails replacement but having it in place before the Rust network services ecosystem really takes off means the future Rust-on-Rails will be able to plug in any database driver without having to worry if it's compatible. It should also mean all Rust's networking stuff is async by default, which is nice because you can build green threading on top of async with good perf but you can't avoid a thread pool going the other way. Caveat Lector: I tend to work in higher level languages; I might have gotten something wrong.
It's fine, but usually done as close as possible to where the enum is used, so you can see it and don't get confused about where the variant names are coming from.
This is in fact a design goal, in my understanding.
The general rule for naming things is to keep the name's size proportional to its scope. So a global `static I = ...` isn't good, but `for i in ...` is fine. Going by that, having a `use really::long::path::Enum::*` in a restricted scope is fine, but don't do it with your entire module.
This may seem like a very dumb question, but what does the deployment process look like for a rocket application? Do you literally just "cargo run" the resultant binary?
I was afraid this was going to be another one of those overly-naive "let's rewrite all of Postgres in Rust" announcements, but the pieacemeal approach you're using looks completely reasonable. :) Glad to see you're having fun with it!
This was like reading a train wreck from beginning to end.
&gt; I think I thought it was some interior mutability behavior like how `RefCell` lets you get a mutable ref from a regular immutable ref. Yep, that's the distinction I meant to get at in my last paragraph [a few comments above](https://www.reddit.com/r/rust/comments/5nd9me/announcing_tokio_01/dcb3yp9/).
Really the only way to look at it. Some code design should never see the light of day.
Turned out more stream-of-consciousness than I intended. tl;dr: Async networking has runtime advantages but is usually not done because it's harder. Tokio looks like a reasonable foundation for async networking in Rust. Since the Rust networking space is nascent, if everybody picks Tokio then we'll be async everywhere (yay) and avoid the sync/async split that plagues more established languages. My personal excitement: * Universal, high performance async networking means we'll have well used/vetted async clients for everything. I expect these to be very attractive targets for higher level language bindings. * I haven't seen a large language (I'm bullish on Rust's chances) with a unified networking stack since Ruby and Rails. Having all us monkeys banging on the same typewriter gets lots more shakespeare written. * I think Rust's web server niche is in serving GraphQL (or Falcor, om/next, jsonapi but I think GraphQL has the most traction) and a GraphQL server in Tokio boils down to a query parser that glues together a bunch of `Service`s (one for each top level Object) and runs them on a port. The composition seems like it'd be clean and I have no immediate need for it so I've been holding off working on it until the Tokio release.
I see multiple people in the pull requests.
Whoa. Thank you for a detailed and thorough explanation.
Is the current derive mechanism too limited for something like `GeneralizedNewtypeDeriving`? I haven't kept up with the custom derive story
Sure the docs could be better, they can always be better, but at some point we will have to accept that Rust is harder to learn than most other languages and no amount of documentation will change that. For example borrowing and lifetimes are in essence simple concepts, but once you start using them in more complex situations, situations out of scope of normal examples, you will get it wrong and the only way to fix it is by reasoning about your mistake.
Some minor nitpicks on the website: - The text on the picture is hard to read. White text and bold would probably help a lot. Here are two links that might help make text on pictures legible: [7 Rules for Creating Gorgeous UI (Part 2)](https://medium.com/@erikdkennedy/7-rules-for-creating-gorgeous-ui-part-2-430de537ba96#.6nwt46nix), [Ensure High Contrast for Text Over Images](https://www.nngroup.com/articles/text-over-images/) - It should be very clear on any page of the website (like this one) that Pijul is a distributed version control system. Best in the header. I clicked on the link and had no idea what Pijul was until I switched to the home page. - "Title image from wikipedia, license CC BY-SA 4.0. ". Wikipedia with almost certainty is not the author of the picture. The author is listed when you click on the image, or in Wikimedia Commons (which would be nice to link to).
is that a '!?' or a question about writing the write! macro? 
I have some examples: // All of these Don't get formatted, they should probably be defaulted without spaces and optionally allowed/enforced #[ feature ] #[ feature( Thing ) ] fn f( x : T ) [ T; n ] // One thing I'd like #[ doc="..." ] // Option to enforce this or format (aggressively) into '///' or '//!' style There is more that I've seen but I don't have access to the code that presented problems right now. I'll file an issue about this now when I think about it.
Can be done at compile time also.
/r/playrust
&gt; tl;dr: Async networking has runtime advantages but is usually not done because it's harder. Tokio looks like a reasonable foundation for async networking in Rust. Since the Rust networking space is nascent, if everybody picks Tokio then we'll be async everywhere (yay) and avoid the sync/async split that plagues more established languages. this.
What's so hard about implementing HKT in Rust? (May be discuss about one specific example of HKT and why it is hard to implement.)
You can create the initial string buffer with `String::with_capacity(n)` where n is the number of bytes to allocate.
Passing usize/isize/u32 is the same :( In C I'm doing LOCALSIZE * LOCALSIZE * sizeof(int) and it work. However the method is supposed to pass mem:size_of&lt;type&gt; automatically EDIT:The issue may not be the two arg_loc methods. If I use a kernel without _local and I do not use arg loc I'm getting the same error.
There are a couple pain points. If you have a compilation error in a request handler, for example, the macro you put at the beginning really messes with the compiler and so you frequently don't get accurate line numbers on errors. But it's the easiest/most pleasant time I've had so far, and imo it's the future of rust web frameworks.
So, why is it not `Arc::clone(&amp;my_arc)` ?
Yeah! Though sometimes while reading through the code, my brain treats `Arc&lt;Foo&gt;` as just `Foo` and on seeing `.clone()` suddenly thinks "copied" !! Then I go back to double-check its type!
I'm trying to wrap my head around this error I'm getting: `conflicting implementations of trait TerminalSize for type std::io::Stdout` Here's my code: pub trait TerminalSize { fn size(&amp;self) -&gt; Option&lt;(u16, u16)&gt;; } impl&lt;T: AsRawFd&gt; TerminalSize for T { fn size(&amp;self) -&gt; Option&lt;(u16, u16)&gt; { size_from_fd(self.as_raw_fd()) } } impl TerminalSize for Stdout { fn size(&amp;self) -&gt; Option&lt;(u16, u16)&gt; { size_from_fd(libc::STDOUT_FILENO) } } From my understanding, `Stdout` doesn't implement `AsRawFd`, so what am I missing?
&gt; If you want the most efficient method, avoiding extra heap allocations, you'll need to implement a `numtoa` Or you can use the crate [itoa](https://github.com/dtolnay/itoa).
Alright, the reason why I decided to hardcode the use of sockets, I guess, is for a conjunction of factors not explained in my post. I'm writing them here to try and understand what could have been improved in the docs (which I'm happy to help writing if needed), or possibly in the API. I guess it's more than just docs and has to do with the process of converting existing code to tokio. My goal was to use non-blocking IO everywhere, and to avoid any undocumented assumption anything about buffer sizes (in previous versions, I was making strong assumptions over the `BufRead` I would get, like on their sizes being multiples of 8). 1. Thrussh was rewritten from a non-tokio version. 2. I wanted full control over everything, in particular how the buffers were being cleared after use, when to start timers (for things happening in constant time like authentication) and during growth/reallocation, so I decided to go with tokio-core and futures. 3. Therefore, I had to create a bunch of new types, each with at least one type parameter (often a `Stream`) implementing futures::Future. Significant portions of the existing, tested code had to be moved around, and getting everything right at the same time was non-trivial. 4. To further complicate the matter, the SSH 2 protocol needs a `BufRead` for the very first packet (to read a line), and a `Read` after that. Some things get copied into a buffer to be decrypted by crypto primitives, which expect a full message at once, and connections can live long. Hence, knowing the concrete types can help performance in this case, as one can simply get rid of the buffer once the first packet has been read, and copy things into the proper buffer directly. Thrussh 0.8.1 does not do all this yet. 
And, done. http://manishearth.github.io/blog/2017/01/11/rust-tidbits-what-is-a-lang-item/
Or more likely, you use a higher level game/domain specific engine with nicer and more appropriate api than either GL or Vulkan.
I think 4 is actually less readable. The others are OK. I'm more concerned about visual indent for function arguments.
Now imagine doing the same in C++, trying to follow the flow of templates... *shudders*
Happens to me too.
The method taken by `GeneralizedNewtypeDeriving` is to only derive for traits that have no parameters (so they could derive `Deref` but not `Mul`)
&gt; “start” is necessary to, well, start executables Have you tried `#[start]` without the lang item? AIUI, the lang item is only how libstd hooks into it.
&gt; Kudos to whoever is maintaining it! That would be /u/kibwen and I agree it's awesome.
Well, if you have ever seen the pages upon pages of error messages some nested templates can produce, you will cherish `rustc`.
Yeah, I was missing `impl Trait` in that code too. Fortunately, I didn't need closure, just `fn(EasyBuf) -&gt; Message`. But I'm refactoring it anyway... :D
Of course!
You can use it for your own functions returning Futures, as long as they are not in a trait. The thing that's not possible yet is for the `Future` traits member functions (and thus the combinator functions) to have `impl Future&lt;...&gt;` return types. So code returning futures shouldn't be hard to write, it's just that the error messages will probably not become much better for a while.
`revim` would be great.
O'course, yeah
Sorry, don't have the time to write a more constructive comment, but seeing the link in your readme under TODO I just wanted to (shamelessly) leave a few more here: [clippy](https://github.com/Manishearth/rust-clippy), [Elegant Library APIs in Rust](https://scribbles.pascalhertleif.de/elegant-apis-in-rust.html), and [Good Practices for Writing Rust Libraries](https://pascalhertleif.de/artikel/good-practices-for-writing-rust-libraries/).
[Obligatory link to The Grand C++ Error Explosion Competition](http://tgceec.tumblr.com)
&gt; Mapping: f.map(|val| some_new_value(val)). Gives you a future that executes the future f and yields the result of some_new_value(val). Regarding 2nd question. The above is quoted from https://aturon.github.io/blog/2016/08/11/futures/ . Hope it helps . Edit : Am a newbie too and the blog post is 4 months old. Hope someone else comments on the same.
Killing people is not funny to programmers. You should try /r/playrust/, maybe it will be funnier there.
I didn't know about this syntax: unsafe impl Sync for .. { } Anyway, where is the part that says not to implement `Sync` if one of the members does not implement it?
We should do such competition in Rust!
&gt; Killing people is not funny to programmers. programmers can still be gamers. We're not all crusty, serious old men. 
&gt; Tribal Knowledge shouldn’t be a thing in a programming community Awesome. These posts are excellent thank you
well 1 comment on reddit, I believe I deleted this but welp, if someone can delete this completely please do so.
&gt; but at some point we will have to accept that Rust is harder to learn than most other languages and no amount of documentation will change that. clearly the rust team disagrees with you that we are at that point. &gt; For example borrowing and lifetimes are in essence simple concepts, but once you start using them in more complex situations, situations out of scope of normal examples, you will get it wrong and the only way to fix it is by reasoning about your mistake. Right. And yet, there was no applicable example last time around. An example, even if convoluted, could've helped people grasp the concept. 
Wrong subreddit, this one is about The Programming Language Rust.
&lt;3 You're a hero!
&gt; clearly the rust team disagrees with you that we are at that point. I see you conveniently left out the first part of my reply, I'm done discussing this.
I know I usually just post the youtube upload here, but I thought I'd share the live link in advance first and post the youtube recording here afterwards. If you prefer I just post the youtube like I've been doing instead, let me know :)
I'd prefer Youtube but don't particularly mind.
Well, unless we are providing an installer, I don't see any issue here. People can check it out and build their own version and then set up an alias to execute it. But yeah, thanks for the heads up
That is the part. The semantics of `impl Trait for ..` are "implement this if all the member variables implement this, and for zero size types."
Well, this is more of an end goal rather than a library for others to build on. It's main idea is simply usage where you just want to share a folder (and maybe allow people to upload to it)
This example is the classic inheritance OOP example. I don't even think most classic OOP people consider this example useful these days. So, here is one way to implement it in Rust: https://is.gd/L1z3UO I'm sure there are many. EDIT: I didn't notice you were having mammal inherit from animal... but really, if you want to learn Rust, I recommend that you start writing code that does useful stuff. This kind of exercise teaches you about classic OOP inheritance. It isn't meant to be useful or to translate well to other abstractions. I'd love to see you try to do this in Lisp, but that would be missing the point of Lisp, arguably.
yeah, this is most relevant if you end up preferring a "brew install" or "cargo install" type command for one-line installs. most people won't be arsed to handle naming conflicts on their own.
cool... didn't know that we could have `impl Trait for Trait`. thanks a lot.
Note that you usually do not model the real world using OO. You are modeling something that represents the real world. For example, all floating-point numbers are subset of complex numbers, but we don't write `float` : `complex` in any OO language. Therefore you should look at classes in object-oriented programming as tools to represent your model. Rust may do things differently, but that does not mean your world can not be represented in it. In OO, inheritance has several uses: method re-use and dynamic dispatch. "Method reuse" would be needed if the base "Mammal" contained some helpful method that the Cat needs. "Dynamic dispatch" is the fact that you don't need to care if it is a Cat to call a method on the Mammal. In Rust, both can be achieved, but in different ways. __Method re-use__ is achieved over the composition and delegation. If you want to re-use the functionality of the Mammal, you create smaller object Mammal, include it in the Cat and delegate an action to it. It has the upside that your Cat (and maybe a Dog) does not need to extend a single main "Animal" or "Mammal" in such case. If you need the __dynamic dispatch__ (you do not need to care if it is Dog or Cat), you would use `trait objects` in Rust. For example, if you have a trait `Animal`, you can store it in the `Box&lt;Animal&gt;`. Box&lt;Animal&gt; animal = Box::new(Cat::new()); // note how cat becomes "virtual" While there is no easy way to achieve multiple inheritance in Rust, I find that these tools are quite sufficient for the majority of cases. In other cases, I am glad Rust forces to design things in a different way, because IMO multiple inheritance can be easily misused and become very messy.
I think that's kinda exactly what the author asks. What are the tools in Rust that would allow to model a similar problem/domain area? To be more specific, let's say i would like to have an array of animals (cats, dogs, etc.) and make them display their "genre". Also, let's say that some classes possess (and their descendants inherit) certain data fields. What is the best way to encode this in Rust, with as little code duplication as possible? I can imagine ways with a lot of code duplication, but i honestly don't know really good ways without code duplication (of course, this is a slightly enhanced version of what the author asks, but anyway).
This is why keyboards need to add an interrobang key, since write‽ is totally different from write!? :P
Can this be used in a rust web server for server side rendering of a single page web application (ie. javascript isomorphism also known as universal javascript)? Benefit comes from quicker initial loading of the app.
If all you want is to just receive the events non-blocking, you can use [poll_events](https://docs.rs/glutin/0.7.2/glutin/struct.Window.html#method.poll_events). Edit: Broken markup
This sounds very interesting. Do let us know when it's out!
Yeah, /u/Gankro used to say it's gone but eddy set me straight
Since the idea is to act asynchronously, it would definitely make more sense if the map-operation would start as soon as the previous future is done. But I'm no expert, so I might be wrong here.
If so, we're totally at the same page. I was just curious to know whether there was anything else I was missing.
Depends on what actual problem you want to fix. You could use a component-entity-system or trait objects though.
It shouldn't need the lang item if you use `#[start]`. The lang item is for pairing your `main` to libstd.
The standard is `int main` though, not `ssize_t` which is what `isize` is.
Yeah, the nice thing about Rust is that the error message is only about the public API -- this is just a case where we've overcomplicated the public API. Also it's a single error message, not fifty.
`int` is **a** platform-specific integer type in C and C++. When I'm programming on Arduino, for instance, `int` is 16-bit.
A question about the darcs/pijul model of version control that's not answered in the FAQ: can you meaningfully do bisection? It's a very useful tool for mid-size projects (big enough to need bisection, small enough to be in a single repository). If so, is it already implemented?
The rule is still "all member variables" for zero-sized types, and it is vacuously true if there's no fields. A ZST that contains another ZST that doesn't implement the trait won't get the defaulted `..` impl.
Sort of the same question. Anybody know **anyway to move the function body of `fn genere()` into the trait** ? Is there anyway to define the function in Mammal case, so no need to implement same again and again. Thanks. // Animal , Mammal parts are missing trait HasGenere { fn genere(&amp;self) -&gt; &amp;str; } struct Cat&lt;'a&gt; { genere: &amp;'a str } impl&lt;'a&gt; HasGenere for Cat&lt;'a&gt; { fn genere(&amp;self) -&gt; &amp;str { self.genere } } fn main() { let cat = Cat{ genere: "Cat" }; println!("{}", cat.genere()); }
Ah, thank you for clarification!
Nice!
&gt; are futures standardized in Rust, or does every future-capable library bring its own variant? Futures aren't standard in the sense that they're in the standard library yet. If libraries all depend on the `futures` crate, however, they'll all have a shared definition and all libraries will agree on the same definition of what a future is. &gt; What happens when applying a transformation to a future using `map` The transformation is delayed until when the future is polled and the underlying future completes. At that time the closure is run on the completed value. So it's always delayed until the very end, but you have to proactively pull out the result to run the closure, the closure won't be run in the background automatically or something like that.
&gt;// Look at me. &gt;// Look at me. &gt;// I'm the libcore now. &gt;\#![no_core] Captain Phillips reference approved 👌
The stdlib is free to add an impl of `AsRawFd` to `Stdout` in the future. If you have a blanket impl on `T` your code needs to be able to work regardless of how other impls change.
(fenced codeblocks don't work on reddit, you need to four-space indent)
Thanks, just settled for block quotes lol
I'm happy you posted this here. I watched the earlier sessions some time ago and would probably have been unaware you resumed working on this project. 
How would I model this data? I would make the classes enums and use a HashMap to return the strings. 
"Unlike #![no_std], libcore is a nightly-only feature that we may never stabilize2." But then you use #![feature(no_core)]. Is it the no_core feature or libcore feature? I am confused.
oh, by spec I meant the reference
It depends on which implementation of `Future` you call `map` on. For example, if you're running an event loop, it all happens on one thread via a call to `Core::run`, which *is* blocking and orchestrates all your in-flight `Future`s at once. The `Core` get an event from the OS and calls the corresponding `Future`'s `poll` method, which then immediately calls the argument to `map` and goes back to waiting for events.
[removed]
Will 2017 be the year of Rust on the Desktop?
&gt; further complicate the matter, the SSH 2 protocol needs a BufRead for the very first packet (to read a line), and a Read after that You can easily write your own generic `Future` which reads a single line from any `Io` object. Tokio's really should be similarly abstract, I'm not sure why it has those wacky constraints. &gt; knowing the concrete types can help performance in this case Rust will always monomorphize generic code. You should try to write in terms of a generic `Stream` or `Sink` when possible. Tokio 0.1 makes it a bit more difficult to be similarly generic about bytestreams like files and TCP connections, unfortunately, but you should be able work in terms of the monolithic `tokio::io::Io` until 0.2 improves on that, and switch to working in terms of `Stream`/`Sink` as soon as your application can.
Did you see https://github.com/rust-lang/rust/issues/18610 ?
Seriously. I understand Rust has a learning curve, but people usually get stuck on things like lifetimes and borrowing. If you [can't](https://doc.rust-lang.org/std/string/struct.String.html) [figure out](https://doc.rust-lang.org/book/strings.html) [how to](https://duckduckgo.com/?q=rust+string+concatenation&amp;t=ffab&amp;ia=qa) [concatenate a string](http://stackoverflow.com/questions/30154541/how-do-i-concatenate-strings), you clearly aren't giving Rust a fair shot.
Between this post and yesterday's Uncle Bob post railing against Swift and Kotlin (http://blog.cleancoder.com/uncle-bob/2017/01/11/TheDarkPath.html), I feel like we're witnessing a widening break between generations of programmers and what constitutes "modern" tooling. An interesting time to witness, if nothing else. :)
Hi all. If you'd like, you can table topics here or [here](https://users.rust-lang.org/t/rust-fosdem-2017/6632/8).
Which makes me think... I wonder if it would be useful for rustc to check the size of the type it is printing, and when above a certain size to try and find repetitions, and automatically introduce aliases for them. It's a slightly marginal case, so may be a lot of work for nothing, *and* it would only be useful if the search of repeated parts had reasonable complexity, but still. Another approach could be elision: if a generic parameter does not participate to the error message, don't show it at all. 
Where its really needed for things like `tokio::Service`, where users are expected to implement a trait. That should have an `impl Future` but instead it has an associated type. Its only actually blocked on designing ATCs and resolving the questions around them, not on implementing or stabilizing ATCs. So its not as far away as it might seem, and the prominence of use cases like this makes it a high priority.
Comparing a scripting language like Go to a scalable language like Rust is somewhat baffling. One is made to getting started quickly, while the other is made to create maintenable code bases at scale. If the former did not allow you to start more quickly, there'd be no point in using it...
Well, Go isn't exactly a scripting language. It's more like a "C, but with GC and an actual honest-to-goodness stdlib omg". Go is made to make maintainable codebases at scale. The set of kinds of codebase it works for might be reduced due to its simplicity, but it's not a scripting language for tiny programs.
Range structs are another example of things that aren't lang items but are hardcoded in the compiler. I think /u/eddyb had some ideas on how to get rid of these by doing resolution and lowering at the same time but I don't know how far-future that is.
It does get used! It only doesn't get used on concrete integer types; a generic type that resolves to an integer during monomorphization will use `Add::add`. See https://play.rust-lang.org/?gist=7c0c16ffce55a1a9c6c5f4ff711f5e09&amp;version=nightly&amp;backtrace=0 It basically has to be implemented looks-like-but-isn't-recursive-ly. There's no intrinsic for addition. You *could* implement it as a C function and call into it, but then you need to force it to be inlined. (I guess you could implement it in assembly, too, but that would also be confusing, plus annoying to make work cross-platform when LLVM does it for you) 
...wow. Uncle Bob's psychology really is alien to me. ...but then, I guess it's a matter of perspective. I've actually burned out on multiple Python projects while attempting to use unit tests to ensure Rust-esque safety guarantees (and it's a problem I've been running into for over a decade). combine that with my firsthand experience with what "just test it 'properly'" actually entails and how sneaky bugs can be without things like compiler-enforced `None`-handling checks and I can't remember the last time I felt Uncle Bob-level confidence in my own abilities. (What I aim for when I'm risking burn-out is a half-way point between 100% brach coverage and [MC/DC](https://en.wikipedia.org/wiki/Modified_Condition/Decision_Coverage).) ~~ESR's is less of a surprise though. I already knew we had vastly different views on politics and gun-ownership and the ridiculous stats on accidental gun deaths and availability of guns to the mentally ill in America make their views on guns feel very much like "Don't worry, **I** don't write bad C code."~~ **EDIT:** In hindsight, the last paragraph was not only ham-handed and needlessly controversial, it failed at its task of being a way to give my response more "reason to be here" when, still groggy from waking up, I misinterpreted /u/kibwen's comment to mean that Uncle Bob's had already been posted separately here on /r/rust and I'd somehow missed it.
If a non-conservative `impl Trait` made it out before ATCs, wouldn't that make ATCs redundant? I'm imagining it'd allow you to write, for example, an `Iterable` trait method with the following signature: `fn iter&lt;'a&gt;(&amp;'a self) -&gt; impl Iterator&lt;Item= &amp;'a Self::Item&gt; + 'a`. Edit: I should clarify-- by redundant, I mean expressible in other ways. It would still be nice to have for places where more explicit associated types are needed.
At work, I encounter C++ errors that span over a dozen screens on regular basis. GTest+GMock+Boost+creative architect...
I suggest not reading the comments there.
This is really outstanding work! After having read the "Getting Started" articles, I only have one suggestion for the API: there are a lot of places where you let a combinator return `Ok(())`, but this isn't very readable (to me at least). For example, in the [reactor](https://tokio.rs/docs/getting-started/reactor/) example, we see this code: let server = listener.incoming().for_each(|(client, client_addr)| { // process `client` by spawning a new task ... Ok(()) // keep accepting connections }); I don't understand why `Ok(())` means that we should keep accepting connections here. Couldn't there bare a type that made this clearer? And similarly in the [streams and sinks](https://tokio.rs/docs/getting-started/streams-and-sinks/) example, we see this code: let serve_one = tokio_core::io::write_all(socket, b"Hello, world!\n") .then(|_| Ok(())); Here it would be nice with a clearer indication of what `Ok(())` means as well. Since it seems to "just" be about discarding the result of the future, why force people to discard it? Can't the result just be consumed implicitly? And if it's to be explicit, maybe have a specific type for it, or make a `discard` combinator to make it more obvious what's going on :) That's my only gripe so far though; this really is an awesome piece of work you've done!
On the contrary, I suggest reading them to better understand the mindset of a broad portion of the programming community. It might not necessarily be actionable information, but it's illuminating nonetheless. :)
He correctly identifies that static guarantees are a substitute to testing. That he actually *prefers* to test for null pointer exception instead of statically disallowing them is perplexing.
[removed]
[You were right](https://www.reddit.com/r/rust/comments/5nl3fk/rust_severely_disappoints_me/)
One of the central design goals of Go was to make development on large-scale code bases (like those at Google) reasonable: https://talks.golang.org/2012/splash.article
It's been some years but if I remember correctly sml/nj had similar pretty printing of types in error msgs (?)
If you're the sensitive type, I cannot emphasize this enough. &gt;It is almost like Rust is their attempt to fix the problems they had with Ruby on Rails, but they don’t quite have what it takes. ... is where I stopped.
&gt; I think one problem here is the absence of a strong BDFL providing tasteful design direction and setting priorities. The Rust community appears to have elected to use the decentralized nature of their crate system (which undeniably has some very nice technical properties) to execute a swarm attack on the design space around the language. Which is wonderful in theory but seems to be failing in practice. This coming from the guy who wrote "The Cathedral and the Bazaar"? Also, wondering why he thinks "there are a welter of half-solutions [to the select/poll/epoll_wait problem] in third-party crates but [...] no consensus about which to adopt" when [just](https://github.com/hyperium/hyper/tree/tokio) [about](https://pijul.org/2017/01/10/first-working-pijul.html) [every](https://dwrensha.github.io/capnproto-rust/2017/01/04/rpc-futures.html) [async](https://github.com/bluejekyll/trust-dns) [project](https://github.com/stepancheg/grpc-rust) has been coalescing around [tokio](https://tokio.rs/)? Hmm. Now that I think about it, this does highlight some issues of learnability and discoverability. While those of us following Rust closely have known about Tokio for a while, there were a number of different outdated tickets in Rust and the RFCs repo about async support, where you would follow from [one closed as a duplicate](https://github.com/rust-lang/rust/issues/14961) to [another closed in favor of the RFCs repo](https://github.com/rust-lang/rust/issues/6842) to [another with a very large amount of discussion to wad through which kind of peters out](https://github.com/rust-lang/rfcs/issues/1081), and also [another about a different feature discussion about channel selection](https://github.com/rust-lang/rust/issues/27800) that also seems to have petered out. Looking through these discussions, I can see a bit of why he might think that async services aren't really a priority in the Rust world; channel selection does seem to be pretty much abandoned, and unless you read through the whole RFCs issue discussion in detail, it does look like there's a lot of discussion without progress being made. Now, as it happens, many of the issues he encountered are actually [on the roadmap for 2017](https://github.com/rust-lang/rfcs/blob/master/text/1774-roadmap-2017.md); in particular, [reducing the learning curve](https://github.com/rust-lang/rfcs/blob/master/text/1774-roadmap-2017.md#rust-should-have-a-lower-learning-curve), [providing easy access to high quality crates](https://github.com/rust-lang/rfcs/blob/master/text/1774-roadmap-2017.md#rust-should-provide-easy-access-to-high-quality-crates) (in particular, the "discoverability" issue, though it's a bit hard with Tokio as it was just released yesterday), [being well-equipped for writing scalable servers](https://github.com/rust-lang/rfcs/blob/master/text/1774-roadmap-2017.md#rust-should-be-well-equipped-for-writing-robust-high-scale-servers), and [having 1.0-level crates for essential tasks](https://github.com/rust-lang/rfcs/blob/master/text/1774-roadmap-2017.md#rust-should-have-10-level-crates-for-essential-tasks). But for someone new to the Rust community and not familiar with the RFCs process, I don't know they would find this roadmap, so it's somewhat understandable that he didn't realize that there is a "tasteful design direction and setting priorities". I think that finding information on Rust can be somewhat difficult, if you don't keep up with Reddit, internals, users, GitHub, and IRC. The website is [still fairly spartan](https://www.rust-lang.org/en-US/); there's no link to the blog from the front page, and the blog these days mostly just contains release announcements, it doesn't contain the roadmap. And of course, there's the usual discoverability issue, for crates like Tokio but also even things like regex; there doesn't even seem to be any links or discussion on the website about rust-lang or rust-lang-nursery crates and what the policies are about those. So, unless you've been following the RFC process for a while, you might not know that there are some external crates maintained by the Rust team for providing some of the batteries not in the standard library, nor what the process is for those being adopted.
I always boot up Vim to work around that horrible flaw. "+P ggVG &gt; ggVG "+y :q!
It absolutely makes sense to compare Go and Rust here. A programmer has an application they want to build. Their constraints (safety, some performance) whittle the choice down to Go and Rust, and possibly Swift/D. They should be comparing Go and Rust. Go and Rust are less comparable as general purpose languages since they're pretty different and support very different use cases. But the set of use cases intersect, and within that intersection you should be comparing things.
Do you have ideas on how to capture dependencies semantically in general? For example, in git you can estimate how many people worked in parallel on one project by how many commits were heads if you discard the newer commits (I remember reading a very interesting paper analysing this kind of 'workflow parallelism' on the Linux kernel repository).
I think the absence of the helpful suggestion is a bug. I'm not sure if we have an issue for it (on mobile right now), so perhaps open one?
Part of why I was glad to see this trending here on /r/rust. Good to consider contrary viewpoints.
&gt; a struct containing an enum. That's what inheritance compiles down to, anyway. Only if you have the entire hierarchy defined from the start. I can inherit from a class in C++ that may have been written years ago by someone else, even if I don't have the source code.
The Roadmap part was specifically addressing his objections about not having a clear direction. I think the Roadmap does demonstrate that there is a clear direction of what's being worked on, and one of those things is his exact use-case and a few more are removing a couple of the stumbling blocks that he hit, and that it's acknowledged that Rust and the ecosystem isn't quite there yet, but that the very things that blocked him are actively being worked on. Yeah, it does mean that for things like "scalable servers", you probably don't want to use Rust in critical production code right now, but if you're feeling adventurous and willing to use pre-1.0 libraries, it is at the point where you can use it for experimental projects or maybe non-critical production projects.
Yeah, in that case you use the other method. It depends. In general I've never come across a situation where I've wanted to have an "inherit from a class" in Rust, the other patterns (especially the ability to implement traits) work well for me.
Looking at the comments (which I don't necessary suggest doing, but at least this one gives more info) http://esr.ibiblio.org/?p=7294#comment-1797517 it looks like the problem is more on converting a String to an ip address. And more generally I think a difficult part when learning Rust is when all the "magic" conversions stop working and something which worked when you passed a `&amp;str` don't work anymore when you just put a `&amp;` in front of your `String`.
It's already here. We are doing resolution from lowering, we're just not plugging in lang items directly. Someone just has to go do it.
I really didn't get Uncle Bob's bit about languages (such as Rust) forcing you to consider the architecture of a system up front. (Admittedly: I'm not particularly fond of OOP/inheritance, so his point about classes being sealed by default was a bit lost on me.) In fact I find that good static analysis allows me to refactor designs *with more confidence* since Friend Compiler is trying to poke a hole in my abstraction. That being said Rust does make me carefully consider *how I use memory*, not how much I use mind you, but things like: - Where is this memory going? (stack vs heap) - Where is this memory on the stack? (lifetimes) - What/who "owns" the data? e.g: when will the destructor run / where can it be realloc'd, etc. (borrowing, smart pointers, containers) The thing is that I find these concepts to be mostly orthogonal to the architecture of my program. I don't have some grand design in my head when I start hacking on Rust code. I just sit down with a problem and start writing code to solve that problem. The great thing about Rust is that I *can* re-architect the program without fear. I can say things like "it'd be really nice if this queue were processed in parallel" and start sending things to other threads. Where Java or C++ would happily let me do just that, Rust says "hang on, you can't do that, and it's because &lt;this data&gt; violates &lt;this constraint.&gt;" So Rust shows me *exactly* where I need locks to make something safely multithreaded. Meanwhile other languages let me add the threads first, while finding where to put the locks is mostly left up to my intuition and some trial and error at runtime. I just don't understand how someone could argue *the latter* system is actually *more flexible* when it's only more flexible by way of permitting constructions that *are fundamentally insecure.*
&gt;Comparing a scripting language like Go to a scalable language like Rust is somewhat baffling. This is incorrect Go is not a scripting language, it is compiled to assembly on each platform. But Go is sometimes _used_ for writing simple scripts, which are then compiled quickly on the fly 
So this is a tradeoff between philosophy and complexity. That impl would reduce complexity. Wonderful. Rust becomes a tiny bit easier to use. That impl also introduces a cost. Adding strings will suddenly work, but with a move that consumes the second operand. Rust likes to avoid these kinds of things. Concatenation should conceptually be an append operation of a copy out of a reference to some bytes to a container. Making addition accept a second container but deallocate it might not really be nice, especially since it might encourage people to do `a + b.clone()` instead of `a + &amp;b` when they don't want the move to occur. I don't have a very strong opinion here, though. I can see an argument against it that I sort of agree with.
No that makes no sense what so ever. GO barely outperforms Java, there are plenty of faster languages. https://benchmarksgame.alioth.debian.org/u64q/go.html
Java is not a scripting language either. "Some performance" is what I said. Java might have been perfectly suitable for ntpsec's use cases too. idk.
Great news. A little complaint about the API: `Core` is such a vague name. Seems like it's a play on being in the `reactor`module, but it really tells me nothing about what it's for or what it does, just that it's supposed to be important. Maybe call it EventLoop or something instead? Because that seems to be its essential function. But overall, this looks awesome!
If we get the better error message – thanks, ESR – for this case, I don't see think that there's any tangible reason left to accept `impl Add&lt;String&gt; for String`, so just having the better error message is a win-win.
But how else will we learn about le evil SJW programmers infiltrating the Rust community? What a strange field software development has become.
Yay! 
Yeah, the fact that `TcpStream::connect(addr)` doesn't work but `TcpStream::connect(&amp;addr)` does is quite frustrating, especially when the reason is not a direct type mismatch but because of the exact way that autoderef works.
Suggested topic (or something to do afterward with some Club Mate): pairing sessions. Rust is hard to learn, so bring some code and hack on it with other people to share experiences.
Will they have Mate?
I tend to agree with you there. Ideally, Rust should be nice and convenient enough to use to be considered as a viable alternative for Java or Go. But that will probably be impossible to achieve without GC and with a "no hidden abstractions with runtime cost" philosophy. String handling is so pervasive that maybe tradeoffs should be made. If this would work... : ``` let x = "abc "; let y = x + " -&gt; " + format!("blub {}", 55); ``` I might be very alone there, but I would actually love something like `gc { ... }` blocks or `#[gc] mod x { ... }`, similar to `unsafe { ... }`, where everything (even types in fn defs) is wrapped in (A)Rc&lt;RefCell&lt;_&gt;&gt; by default, and the compiler promotes to the stack what it can. That would of course muddle up and complicate the language a lot, as you would have an embedded dialect with completely different semantics. But it would expand the scope of Rust considerably, and turn it into a real alternative to Java/Go/C# style code. 
I think that strings indeed warrant special treatment, but what makes the error message non-obvious in this particular case is that one needs to know that `String` derefs to `str` and sticking a `&amp;` in front of the `b` does the trick. Perhaps it would be nice to stick a note in for all cases where for an expected reference a value of a type that derefs to the expected type is given?
Given that he was all ready to write his own state machine, I would've pointed him at mio. It has been around much longer and provides a direct poll()-like interface.
Wow, that is a gobsmackingly stupid post. Chernobyl happened b/c they turned off all the safeties, therefore safety-oriented programming language features should not exist and you should write a bunch of tests. Nevermind that tests are just safeties you had to remember to add yourself.
The post is on the verge of trolling, at least full of unsubstantiated inconstructive criticism. At this point, placing ESR squarely in the anti-CoC crowd seems a safe assumption. Edit: yes, that is not stated in the article (I perused other sources) and /u/Manishearth is right, it should not cloud our judgement of the findings presented. That said, let's not bash him here, folks, for it would reflect badly on us. Setting aside the tone, Rust *is* hard to learn. String handling is more complex than in most unicode-ignorant languages, for better or worse (even when concatenation is a bad example of this), and we may be able to teach it better. Also the story around async *is* under heavy construction, though what's there so far looks awesome. So, perhaps Rust simply isn't the right choice for their project at this time. Let's wish them good luck and continue making the Rust ecosystem the best possible Rust ecosystem. 
Pijul and darcs work differently here: in Darcs, dependencies are recomputed, but that can be really costly. In Pijul, dependencies don't have to be recomputed, as the semantics is stored in the model. We'll explain the model in greater detail very soon, but I'd prefer to do a real release before.
I know who he is. I'd just rather ignore it in this context. 
Yes, it is really outdated. We'll update it in a few days.
To add to this (though slightly off-topic): The Chernobyl disaster happened **during a test**.
Yes, but it _isn't_ a scripting language (or is more than _just_ a scripting language). Comparing a scripting language with Rust is not usually helpful. Comparing a language that is many things among which a reasonable-replacement for scripting languages, however, is different. The "many things" may overlap with Rust. Reducing Go to a single aspect and then comparing it is not a great idea.
I had started one of these before Rust was stable. Sadly there's a lot of legwork I'd need to do to get it compiling again. (Last I remember I had finished fixing all the rust upgrade issues; but the rust-sdl2 library also had a pretty major overhaul that would upend a lot of the engine as written.) Best of luck, the DMG is a really fun little machine.
&gt; Rather, large collections of optimizers will be built around IRs like LLVM, and people will be able to create AOT and JIT compilers, as well as link-time optimizers and whatever else seems useful, simply by choosing suitable components from the toolkit. I don't think that this is true. For Jit you do other trade offs than for ahead of time compilation. Using LLVM for JIT was seen as a failed project pretty much from early on I think (is the bitcode jit executor even still part of llvm?), except for last tier optimization. And even there WebKit for instance replaced LLVM with something better optimized for JIT: https://webkit.org/blog/5852/introducing-the-b3-jit-compiler/ Some of the optimizations there are JavaScript specific which brings me to the next point: LLVM is optimized for C. For other languages you need a more high level IR like MIR for Rust or the one that Swift is using. Still in the end LLVM is extremely nice, but not the magic bullet to solve all problems.
I'd do this: match Some(0) { Some(_) =&gt; { returns_a_val(); }, None =&gt; { has_no_return(); } }
As a gun fan and rust fan I think you're overthinking/reaching here. I thought your post above was good, but that last paragraph was kind of alienating.
I would expect the compiler to give some error like this: note: ...so that the type `impl Trait` will meet its required lifetime bounds
&gt; Wrapping the offending call in `{ &lt;call&gt;; }` fixes this, but looks ugly. That is because without the semi-colon, they return values that aren't unit (`()`). Imagine this: let result = match Some(0) { Some(_) =&gt; 0, None =&gt; "None!" }; What type should `result` be here? `&amp;'static str` or `u32`? The match arms are returning a value - they have to return the same value. Adding the semi-colon makes that return value `()` - which is what functions that don't return anything return. That means both arms return `()` - which is fine. I feel like this might be a bit of an XY problem though - why are you calling a method with a return value and discarding the return value? I would say you could probably re-write your _actual_ code to not require this (at a guess).
Writing it here so that it appears in your inbox. I haven't really looked into pijul so maybe this comment might be pointless. I am wondering what information pijul siphons from user's computer. My pet peeve with git is that it's loose with private information - it doesn't really need to know email address for all use cases as well as system username under which an user is logged and some other [unneeded information](https://news.ycombinator.com/item?id=10004678). I know this doesn't bother majority of people, but some like to maintain more than one account on github or wherever and it's troublesome to maintain multiple system accounts just to force version control system to behave as it should from the start - to disclose information only when it's needed. If you were wondering, my use case is that I have an account for uni with projects that are less than presentable because they are finished as soon as they reach course requirements and I'm a lazy student so I want to keep that stuff separate from stuff I do elsewhere, but I'm sure other people might also have different use cases where they wouldn't wish their vcs to link accounts/projects unnecessarily.
In the space of emulators I don't find those fields to be unrecognizable at all. (In fact I recognized them even though I haven't looked at that CPU's specs in probably a year.) They're just the name of the registers, and they match [the documentation](http://pastraiser.com/cpu/gameboy/gameboy_opcodes.html) you'll find for that particular CPU. I'd argue that naming them anything else would actually obfuscate the code further, as it will no longer map directly to the wealth of reverse-engineering work &amp; documentation that's been done by others. In the source it looks like the author has even grouped the registers into the pairs that make up the indirect loads from memory, which is a stylistic choice I rather appreciated.
&gt; Why did the nuclear plant at Chernobyl catch fire, melt down, destroy a small city, and leave a large area uninhabitable? They overrode all the safeties. So don’t depend on safeties to prevent catastrophes. Safeties don't work if you turn them off... therefore safeties are worthless? 
After a certain age people start having an issue accepting new things. Uncle Bob's entire post seems to boil down too &gt;Yes X will solve my problem. But No True Scottsman needs protection from X, they already test for X Which if that *were* true nobody would design languages around eliminating X. 
So, firstly, this kind of stuff isn't exactly what Rust was intended to do initially (we had this stuff in the core language and _removed_ it!); "basic" depends on what you're targeting. Rust later started getting used in areas where this was necessary, and these things started becoming necessary. I don't really see many libraries being recommended. I see mio, tokio, and futures-rs. These are complementary libraries that address different layers of the stack. In particular, tokio is built on futures-rs and mio. The current situation isn't great because tokio isn't done, but it's being actively worked on with buy-in from the core team and relevant ecosystem crates. So even if there were a lot of libraries for this; that's a problem that would be solved soon.
&gt; So, perhaps Rust simply isn't the right choice for their project at this time. Yeah, I echo this -- if you sift out all the inaccuracies and other crap for his post, given his requirements -- he needs an easy-to-learn language with a good story for async IO, Go is the right language to use there. He's being hyperbolic about many things, but I would come to the same conclusion with those constraints. (It's debatable whether those constraints are actually necessary, but that's a different argument)
Do you know why the decision was made not to let `x` coerce to `&amp;x` for the purpose of function calls, as we do for method calls? Does it create nasty problems, or is it more about just being explicit? Fwiw, the `println!` macro automatically adds refs.
Why do we care what this person thinks? I for one don't see why we allow blogspam here.
Generally we want to make moving visually distinct from borrowing. There's a very clear mental model of what's happening to a variable when you see it being used without an ampersand or period (it gets moved!).
The semicolon is the idiomatic way to write it, but another option is to explicitly ignore the returned value by passing it to `drop`, which is just a function that ignores its argument: match Some(0) { Some(_) =&gt; drop(returns_a_val()), None =&gt; has_no_return() }
Ok, that makes sense. I have not used much Linux in my day apart from some basic server stuff. Next up, I don't understand how to run: $ rustc main.rs $ .\main How do I run this in the command shell? AFAIK I can only run single line commands. Running just `rustc main.rs` gets me this: error: could not exec the linker `link.exe`: The system cannot find the file specified. (os error 2) I read up on this and it seems like a building problem.. so much for one-click install? I thought this was easy?! I thought this was going to be better than the JS world?! (bit of sarcasm... apologies)
There is actually a solution to this - we could have autoref for arguments which expands (roughly) like this: foo(arg); // expands to { let tmp = foo(&amp;arg); drop(arg); tmp } 
This is two commands, and `$` is the shell prompt (as traditionally used on Unix, on Windows it'll look something like `C:\Users\blah&gt;`). The error with `rustc main.rs` is probably caused by you not having Visual C++ Build Tools installed - you can get them from the link [here](https://www.rust-lang.org/install.html).
https://www.reddit.com/r/rust/comments/5lu9gb/comment/dbymhql Called it. But yes not having asynchronous abstractions is a very legit criticism and relying on the ecosystem to take care of it seems like a terrible idea but I guess time will tell.
&gt; The reason epoll/select isn't in Rust's standard library is the same reason it's not in C's standard library. It's a Linux/BSD-specific syscall. I gotta say even though I almost never work on Windows anymore (I can't even boot up my Windows install...), I ***really*** appreciate Rust's determination in working equally well on Windows, OSX, and Unices.
You're being needlessly dismissive. He didn't say he couldn't figure it out, just that it was "unreasonably difficult". It certainly *is* harder than `"foo" + "bar"`, but you can argue [like Manish](https://www.reddit.com/r/rust/comments/5nl3fk/rust_severely_disappoints_me/dcciasv/) there's a tradeoff between philosophy and complexity, but it's not totally unfair to think that's "unreasonable". Setting up a strawman like this so you can dismiss the post out of hand serves no one. I don't see why, a priori, ESR would hate rust, and that this was just an elaborate made-up situation to serve as a platform to rant. On the contrary, given that he's talking about rewriting that project in a new language, and that he set aside some time to play with rust, I believe he gave it at least a somewhat earnest shot, and came away legitimately frustrated. So his post, while inartfully delivered, to say the least, is extremely valuable feedback to the rust community, I think. It's fortunate he has as much infamy as he does because I feel like this sort of post wouldn't have gotten much traffic on /r/rust otherwise.
This is actually something I've seen multiple people run into. It might be a good idea to change the error message to something more meaningful - and maybe even platform-specific. I don't really know who to talk to about it though. /u/steveklabnik1?
That's basically AsRef :)
I was interested, at least, since it's the followup to [this post](https://www.reddit.com/r/rust/comments/5lu9gb/getting_past_c/) on /r/rust from a bit ago.
&gt; boot up Vim It's not already running? ;) Also, never `:q!`, there's no reason to quit ViM :) Vimgolf: "+P &gt;G "+yG
I didn't check this particular example, but if `TcpStream::connect(&amp;addr)` works it's not that bad, but there are cases where it's more confusing. E.g. (the latest case where I stumbled on this) if you have a function that takes a `Read`, you can use a `&amp;[u8]` but not a `Vec&lt;u8&gt;`. Alright, so you just do `&amp;myvec` which usually works to pass the content of a `Vec&lt;T&gt;` to a function that takes `&amp;[T]`, but... in this case it doesn't work either and you have to actually use `&amp;myvec as &amp;[u8]` ([example](https://is.gd/1F5AqN)) This isn't dramatic when you know it, but during the learning phase I found it sometimes confusing. (Edit: I say that, but just by writing this example I realized it was also possible to do `&amp;*myvec`, so I guess this whole (auto)deref stuff hasn't entirely got into my head and it's *still* a bit confusing to me now :) )
Yea, you probably need to do the cast in this instance, making it even worse! I think the preferred solution for these cases btw is `&amp;myvec[..]` or `&amp;mystring[..]`, though `&amp;*` and `as` both work. Ideally you wouldn't need to do anything of this in my opinion.
When I read `f(x)`, I feel like it's much more common for `x` to be something that's `Copy`, often because it's already a reference type like `&amp;str`. So the syntax doesn't really jump out at me. Functions that take a `String` or a `Vec` by value are pretty rare, and even then they're usually methods on the type. Here's [a random example](https://github.com/oconnor663/os_pipe.rs/blob/0.4.0/src/unix.rs#L34-L39) of mine: let temp_file = unsafe { File::from_raw_fd(fd) }; let dup_result = temp_file.try_clone(); mem::forget(temp_file); dup_result.map(Stdio::from_file) There are three un-annotated function arguments in that file, but only one of them (`mem::forget`) is actually a move. I think we're more likely to notice important function names (like `drop` and `from`) than we are to notice that the `&amp;` is missing. I guess it feels weird to me that we've chosen to infer so much about autoderef (and moves into closures, and soon reference lifetimes?), but not autoref. I almost wish we had an explicit syntax for moves, and that we relied more on inference for references. I know we used to have that and got rid of it?
IMO, part of the power of rust is the fact that it has a brick wall learning curve. Rust doesn't let you get away with anything, and further it heaps on a bunch of concepts found in few (popular) languages for good measure. I think the end result is the code written in rust tends more towards being correct than code written in other languages. While you may be able to decrease the ramp up time with more tutorials, more examples, and more language refinements, the all mighty borrow checker must be appeased, which means that you have to build up the mental model of what is ok and why it is ok before you can really start being productive in rust. I would argue that rust is hard to learn but easy to master whereas languages like Go, C, JavaScript, Python are easy to learn but hard to master. Permissive and lax language make it really easy to do really bad things and not even know why what you did isn't great. Rust has a tendency to be annoying to do things that you should avoid Rc&lt;RefCell&lt;u32&gt;&gt;, that just looks nasty to deal with. On the other hand, with c, unsigned int* might not really stand out as being a problem. Nor is there really anything about that that would make a seasoned C dev balk too much. Even though it is filled with potential dragons "is it null?", "Do I need to free it?", "Who owns this?", "Is this actually an array pointer?"
As much of an idiotic troll Eric Raymond is, this isn't blog spam and I think it's important that advocates and developers of an emerging programming language listen to as much criticism as possible. 
Where did he describe the level he was looking for? I missed it.
I'm wondering if there's currently a way to have "Associated Traits". I'm wanting to get behavior similar to Associated Types, but for Traits so that I can have generic Trait bounds in my Trait that I specify more in an impl of that trait. Here's an example of what that might look like: trait Foo { trait OtherTrait; fn bar&lt;T&gt;(&amp;mut self, other: &amp;T) where T: Self::OtherTrait; } trait FooB {} impl Foo for FooType { OtherTrait = FooB; fn bar&lt;T&gt;(&amp;mut self, other: &amp;T) where T: FooB { //... } } Maybe something exists that will get me what I want, but I'm not aware of it so far. This is for a toy (at least right now) vector library that I'm working on, and I'm worried that the only way I'll be able to get what I want is with lots of redundancy or with macros. I've got an example on the playground [here](https://is.gd/4yJQgv) that should give a better example of what I'm going for. Edit: Clarification
I think it really is just that he doesn't like the extra overhead in the type system. If you say "this returns nullable String" on a method but later discover "Hey, this actually isn't nullable, the signature could be String" then you can't change that type information without making a breaking API change. On the other had, it costs you little to do the null check at the consumer level or to make the decision of whether or not the null check is necessary based on what you know about the state of the System at a given point in the code. Whether or not your assumptions are correct could be caught through testing and changes to the API that breaks those assumptions should break the tests. I can't say that I totally agree with him on this. But I think this is the thing he was getting at. Pushing smaller things into the type system makes the upfront requirement of defining and deciding an API harder to do without needing to later rewrite or make breaking changes.
Good point, thanks for the help!
Very true. I merely wanted to point out that even the best attitudes and efforts towards safety won't help if you're stepping out of line and working with things that definitely don't have your interests in mind when it comes to safety. Kind of like how even though C++ is as safe as it could be for its time, operator error combined with the fact that it's built on technology that is not looking out for you means it'll still blow up just like C does. I just do not understand how anyone can say "*I've* never had a safety problem with this unsafe thing, because *I* always make sure to take the appropriate precautions." I grew up in a woodworking shop, in the country. I'm a lifeguard and SCUBA diver. I am 100% on board with doing safety checks manually. But I've also watched people, some who didn't and some who did obsess about safety, severely injure themselves or others. *I've drowned*. Anytime I see the opportunity for safety assistance, even if it will make my life a little harder or restricted or make me break habits, you bet your ass I'll be getting on that train. No matter how good you (editorially) may be, you're only human. You *will* make a mistake, or something out of your control *will* happen. Why refuse something that can help with that.
I think he wanted tokio 1.0 and not tokio 0.1. 
&gt; At this point, placing ESR squarely in the anti-CoC crowd seems a safe assumption. I don't see how you get this from the blog post. 
&gt; why refuse something that can help As I stated above, hubris, fear of management and human errors. I'll go further: mostly it was fear of losing face, of looking stupid.
Thats just a tad ageist. 
&gt; relying on the ecosystem to take care of it seems like a terrible idea That is not what is happening. One of the main authors of tokio is a Rust core developer.
He asked for epoll, mio is (on linux) a thin wrapper around that. Tokio and futures-rs are much higher level, so as awesome as they are, he might not be interested in learning them. He could also, as others have pointed out, have made epoll calls himself directly.
Fair enough. My own opinions aside, my judgment regarding what to put together in a single post was poor and is probably hurting the comment's rank. In hindsight, I think it was an ill-considered attempt to give the post relevance beyond what I was directly replying to. That said, I don't like people who delete content in response to reactions, so I'll limit my correction to a strikethrough and an explanation.
&gt; After a certain age people start having an issue accepting new things. That's a mighty broad f'ing brush you're swinging there, I must say. We'll see what you have to say when you get older yourself. Youth is fleeting ... intellectual curiosity need not be. Edit: s/your/you're/ 
This should really be documented better, but this is called the “`std` facade”: &gt; The standard library is notably organized as a "facade": it is composed of a number of small crates whose features are all reexported through the public interface declared by std. Today, all of these inner crates (except for core) are unstable implementation details. The purpose of this facade is mostly to, through the use of the Rust crate DAG, strictly control the interdependencies between the various independent units of functionality within the facade, and thus make the individual facade crates maximally useful outside of std. Even today these facade crates have minimal, well-defined dependencies and are highly portable[.] — from https://internals.rust-lang.org/t/refactoring-std-for-ultimate-portability/4301
Also before bar() C updates x, cause bar() could read it.
Pointing to the same place is intentional, exposing the `collections::string::String` name when using `std` is basically a bug. Specifically, the `std` library is [a facade](https://cdn.rawgit.com/brson/b89639583c8ed72ee3340cb3d57740d1/raw/ec1f539e6bfe4e6b9a4ac293048c2bdffe48eaa1/std-today.svg) (A &amp;rarr; B means A depends on B) over the top of several low-level libraries, like `core` and `collections`, with `std` [re-exporting](https://doc.rust-lang.org/book/crates-and-modules.html#re-exporting-with-pub-use) all their functionality. People will opt out of `std` when writing code that can't assume all of the OS support `std` needs, and the facade allows this code to still use the pieces that do work, while also interoperating naturally if the code (if it's a library) is also used in environments where `std` works: the reexported types are entirely interchangeable&amp;mdash;the compiler knows that `std::string::String` and `collections::string::String` are the same thing. It is definitely confusing: I couldn't find an issue but [#21934](https://github.com/rust-lang/rust/issues/21934) and [#24305](https://github.com/rust-lang/rust/issues/24305) are related.
`std::string::String` is just a re-export of `collections::string::String`; for internal reasons, `std` is composed of several different crates, but re-exports a lot of the functionality from the internal crates. They are the same type. In general, it should always be referred to via the public path, `std::string::String`, but there are some places where the original path is exposed (and some, like the source link, where it's appropriate as that is where the source is).
It's better: two of the three members of the tokio core team are members of both the Rust core team and library team.
The Rust approach is to build libraries, find the pain points that occur in practice and only then solve them with language features. The evolution of `try!` to `?` is one example, as is the `impl Trait` feature (motivated by experiences with `Iterator` and similar things like `Future`). Language-level concurrency abstractions are also something people have explicitly thought about (e.g. [the RFC repo](https://github.com/rust-lang/rfcs/search?q=async+await&amp;type=Issues&amp;utf8=%E2%9C%93)), but, last time I heard, the team's goal was having concrete (zero-cost, etc.) libraries to serve as a target for language abstractions, to demonstrate that any features both solve real problems and also don't create their own problems.
While I agree with the last bits (as evidenced in the other comment) I strongly disagree with the first part of your comment. It's not fair to dismiss this as trolling, or that it's in any way related to the code of conduct. It's not very constructive criticism, but it seems like the author genuinely wanted to use Rust, and their reason for dropping Rust was not to concern-troll or otherwise "just make Rust look bad". He _has_ been against code of conducts in the past, but if his dislike of Rust was because of this I'm pretty sure he would mention CoCs somewhere in the blog post with an insinuation of blaming Rust's failures on the CoC -- that's how most concern-trolling-with-an-agenda may go. So let's be fair. We may not like him, but we shouldn't outright label him as a troll. The post is inaccurate, sure, and unfair to Rust, but we should not label it as trolling. In general, can we _please_ avoid discussing the personality behind the post over the post itself?
Can we stop this please? There are things I've written in C that I've replaced with Go programs. There are things I've written in C that I've replaced with Rust programs. There are things I've written in Go that I've replaced with Rust programs.
Your point is interesting, I do see how moving more information into the typesystem has the potential to make an API more brittle in that sense. It's just never really been a huge problem for me, and I think it's largely a matter of two things: what I program (mostly applications) and my programming style (I subscribe to the ["write the usage code first"](https://mollyrocket.com/casey/stream_0029.html) school of thought.) &gt;defining and planning a library is much harder to do without a lot of planning or a long prototyping phase Admittedly I'm an application programmer, so this will be colored by that lens, but I don't really ever sit down and plan a library. I pull libraries out of application code that already works. So at that point the API of the library has been teased out by a real application. The idea that one sits down and comes up with all the stories/usecases/behaviors a library will ever need is just really foreign to me, for the same reason Test Driven Development has never appealed to me I reckon. One can't possibly enumerate an infinite set of constraints, so putting this unsolvable problem at the *beginning* of a project just never worked for me. As a concrete example: I don't sit down and say "I want to write a Bencode parsing library." I sit down and say "I want to write a torrent tracker", and after some progress I find out I need to emit Bencode, so I write that code. I notice I have to do it in multiple places so I extract it to a module. I notice my tracker now grew several other applications, and they all need Bencode, so I move that module into a crate. In the way that I work: a library is an artifact of application code, not an end goal itself.
The reason `str: AsRef&lt;str&gt;` is that the blanket impl can't be added. We can remove the str impl if we can add the blanket impl. The blanket impl conflicts with the two reference blanket impls for AsRef, which is why it isn't included, so yes we do need specialization &amp; enhancements to it to add this impl. Its one of the primary motivating examples. More broadly, though, I don't think the solution is to tell everyone to abstract all their function arguments to `T: AsRef&lt;MyActualType&gt;` but to build this into the language to some degree.
While I'll admit that, in hindsight, it was needlessly politicizing, I want to be clear that, when I wrote that, I meant that C was a "dangerous and powerful tool to be treated with respect" in comparison to the language ecosystems with VM-managed memory that have become so popular these days.
[removed]
While you've already realized this and edited it, just dropping a comment here as a sign to others: Comments like the struck out portion of the one above should not be made on this site. Please don't bring personalities and personal views into this, unless they have too.
Depends on what you're writing. Servo written in Go? HAHAHAHHAHAHAHAAHA! NTP server written in Go? Not a bad choice.
First, I see a lot of free functions for constructing objects. fn new_sampler(...) -&gt; StickySampler { } This is fine, but the convention in rust is to implement a struct's constructor as a method. So your new_sampler function would become impl StickySampler { pub fn new(support: f64, error_tolerance: f64, failure_prob: f64) -&gt; StickySampler { // implementation here } } These are called 'Associated Functions' in rust, and are equivalent to static methods in C++. Now, instead of constructing a StickySampler like this: let mut sampler = new_sampler(0.1, 0.1, 0.01); You can construct it like so: let mut sampler = StickySampler::new(0.1, 0.1, 0.01); I find that associated functions are easier to look up than free functions, especially when they obviously belong to the type they're attached to. --- Also if you're not super tied to getopts then I prefer clap for argument parsing. With clap you get argument validation built-in (so you don't need your print_usage function, clap does it for you). extern crate clap; use clap::{App, Arg}; fn main() { let matches = App::new("countish") .arg(Arg::with_name("support") .long("support") .takes_value(true) .default_value("0.0001") .help("Base granularity. Eg. if your support is .1 you can't find content that occurs at frequency .01")) .arg(Arg::with_name("tolerance") .long("error-tolerance") .takes_value(true) .default_value("0.0001") .help("Tolerable error (eg .01 for 1%). Impls:stucky, lossy")) .arg(Arg::with_name("impl") .long("impl") .takes_value(true) .default_value("sticky") .possible_values(&amp;["lossy", "sticky", "naive"])) .get_matches(); let support = matches.value_of("support").unwrap().parse().unwrap(); ... } You can do a lot with clap (including argument validation via Arg::validator, which I think would also be useful for you), but it's still pretty easy to get started. --- And I see what you were talking about with the shenanigans you have to go through to find the keys in the HashMaps to delete, save them into a Vec, and then remove the keys afterward. Not totally sure off the top of my head how to improve that though, and as long as you're not deleting huge amounts of keys it should be fine.
Not all C programs need _that much_ control over memory, etc. Not all C programs are embedded ones. Go gives you a decent level of control. It has most of the simplicity of C syntax. You can usually tell which variables will go on the stack by looking at a function. For many kinds of software that have traditionally been written in C or C++, this is enough. ntpsec could totally be one of these. Go doesn't address all of the use cases of C, but that's not what's being discussed here.
Weird, I've tried gVim and can't stand it. I use tmux so I can have several vim instances running on my computer at once tiled as I need. When I try something like this, I just reuse an existing instance but open a new buffer: :new or :enew I also don't use tabs and use buffers instead. Anyway, interesting we have completely different workflows with the same software.
[removed]
Thank you for the first sentence. While it wasn't perfect insulation, since this was one of the situations where I read things out of order, it helped to stave off the impending bout of panic that the rest triggered. (I'm not the most socially perceptive person and my emotions and impulses sometimes get the better of me so, in order to avoid saying something unforgivable, I aim for almost robotic polite, non-confrontational, and uncontroversial behaviour (especially in text-only media). When I screw up badly enough to reach all the way outside that buffer zone, I start to panic.)
So far as I know, Rust will reload from a `*const i32`, but not from a `&amp;i32`. Same deal with `*mut _` and `&amp;mut _`. If doing so breaks `foo`, `bar`, or `main`, then the code is *wrong*, because it's using `unsafe` to violate the language's guarantees.
Okay, I'm deleting such comments now. See https://www.reddit.com/r/rust/comments/5nl3fk/rust_severely_disappoints_me/dccus7k/
Thanks a lot! Unfortunately, Rust reloads. Probably a room for optimization. Memory model is always tricky, though. https://godbolt.org/g/i0RnXm
Kudos to Brian Campbell for his patient and informative responses in the comment thread of that post.
&gt; Weird, I've tried gVim and can't stand it. I was never able to satisfactorily kick my habit of relying on things like Ctrl+Arrow for wordwise motion or features terminals can't even be reconfigured to support, like wavy-underline spell-checking. There's also something I can't pin down in my brain which says that anything more than cursory code editing must be dark-on-light, but no amount of configuration will make a dark-on-light terminal look acceptable. I have the kind of weird, nitpicky, perfectionist personality that results in someone who's a "UI/UX designer... but NOT a graphic artist" and a "polyglot programmer who can code a raw file parser from a spec... but too frontend-results-oriented to develop much low-level stuff" and "can't stand to do it in any tool less aesthetically-pleasing than Windows 95". (eg. I wrote a partial GIF parser in Python... but only because nothing else that was easy to integrate into a Python project could separate batches of static and animated GIFs quickly enough to meet my UX goals.) &gt; I also don't use tabs and use buffers instead. I've tried to use buffers, but the bugs I encounter with plugins like MiniBufExplorer are generally much less tolerable than the bugs I encounter with tabs. (And I could never get into IDEs because they're just too heavy and have too much visual clutter than can't readily auto-hide or toggle the way Vim plugins would if they weren't so buggy for me... but then I keep running into bugs where Syntastic will want to open a second or even third quickfix panel rather than reusing the one it already opened.)
&gt; However, from my understanding, there is no need creating a new version control system for this, git already contains all of the data you need, and Pijul could have been implemented as a git-merge tool. I think git does not record the kind of information pijul needs. &gt; Functionally, merging is the only thing Pijul does differently. Like darcs, it looks like pijul deals with changes, not history. Therefore it looks like pijul is based on a rather different model of revision control. &gt; If Pijul is only storing patches, would it mean there is no equivalent to git clone --depth X [darcs has lazy repos](http://darcs.net/DifferencesFromGit#TOC) so I would think pijul could get something similar in the future. EDIT: Your questions are answered in [the FAQ](https://pijul.org/faq.html) in greater detail.
Calling Go a scripting language is unjustified, and it's not clear on what basis that analogy is drawn. Anyways, ESR is right about one thing: Go is a very performant, pleasant-to-use language that allows you to get a huge amount done in a very short period of time and very little learning.
Interesting. I'm not really that nitpicky, but I didn't like the way gVim looked relative to my terminal. I like light on dark (light gray text on dark gray background for code, light blue test for terminal) and I found a decent vim theme that looked good with my semi custom terminal theme. Since I live in the terminal, this was the best fit for me. I'm a little surprised that you prefer light on dark. For me, I feel I have less eye strain with light on dark pretty much everywhere, so I use it when possible (Reddit, IDEs, etc). I guess this is likely due to my preference to work in a low light environment. My monitor is set at 0% brightness, my phone is usually 25% or lower, etc. and having a bright color palette distracts from that. I agree about IDEs, but I put up with them when the pain in avoiding them is greater than the pain in using them, and for me, that's Android, Unreal Engine and .NET development (.NET is strictly for random integration projects for work, otherwise I use primarily in Go, JS and Python at work, with Rust, C++ and Java for my personal game dev projects). I also use few plugins, only syntactic and maybe one or two others. I've given up on those project browsing plugins as I usually just open files with :vsplit or :e.
The longest compilation errors I have ever encountered (in Haskell, not Rust) were from attempting to implement [some weird lambda calculus related stuff](https://gist.github.com/sacundim/db9dbaeaff671265c8aa41ed8fdd96c7). Maybe it's possible to write the same program in Rust?
While others have discussed that this is the case for C/++ as well, the answer is probably much simpler. `isize` used to be called `int` in Rust, and was philosophically the "default" integer type (also I think literals defaulted to it too). The reason main returns an int in C/++ is probably similar. Rust later recognized that most integers don't need to be ptr-sized, and made the inference default u32 (IIRC this is a weaker default), and made the ptr-sized integers not use "int" and "uint" so that people look for other integer types instead of the "default" one they are used to from other languages.
&gt; darcs has lazy repos so I would think pijul could get something similar in the future. Thanks, I didn't know darcs has that. I've read the FAQ before writing my comment. I didn't find a counter-argument to my main point, which was not a question. &gt; I think git does not record the kind of information pijul needs. &gt; Like darcs, it looks like pijul deals with changes, not history. Therefore it looks like pijul is based on a rather different model of revision control. "Changes" or "patches" are always calculated from "snapshots". git has all snapshots and relationships between snapshots, therefore, it is always possible to calculate "changes", even if it requires some work. I believe, git history is *functionally equivalent* to storing "changes". I'm not arguing which approach is better - storing snapshots or changes, I'm arguing that these approaches are functionally equivalent. ... which leads to the following statement: Pijul could have been implemented as a git-merge ~~tool~~ strategy because git has all of the data required for the underlying merge method. Edit: I was a wrong about `merge tool`, because the tool is only used on conflicts, but the idea still holds in principle.
It was renamed from `Loop`. https://github.com/tokio-rs/tokio-core/issues/3 `EventLoop` was discarded as `EventLoopHandle` is too long. Why not `EventLoop` and `Handle`...
If you're finding the type of variables to be unclear, then it's perfectly fine to add a type declaration to make them explicit: `let addr: std::net::SocketAddr = ...;` This can also help clarify errors, because the compiler has a better idea of what you intended to do. You should also consider reporting, rather than ignoring, errors (by e.g. adding a logging statement to the body of map_err). It's not clear why you wanted to replace `and_then` with `then`. Looking at [the type signature and associated documentation](https://docs.rs/futures/0.1.8/futures/stream/trait.Stream.html#method.then), you can see that it's significantly different. The error message situation is definitely unfortunate, but it's a consequence of the zero-overhead nature of futures-rs. It should improve with time. e: Oh, wrong OP. Oh well, leaving this for posterity.
I've needed this before, too. Associated traits/bounds would be super useful, but they're not included in [the associated items RFC](https://github.com/rust-lang/rfcs/blob/master/text/0195-associated-items.md).
`impl Trait` can't come to stable soon enough imo, also using it in traits
&gt; You have to change the struct signature basically everywhere you use it. Isn't this a good thing? Your struct which previously could be tossed around indiscriminately is now tied to a scope. This is _exactly_ the kind of refactoring that has led to most of the segfaults in C++ code I've dealt with -- either someone adds an extra reference deep within a type used all over the place that doesn't live long enough, or an instance of a type containing a reference deep within it has its lifetime lengthened for some reason, and it oversteps the bounds of the borrow. Being forced to add a lifetime parameter forces you to tie each instance to a scope (after which the compiler will ensure that the scopes you are using are sound). I find that extremely useful and amazing :) Traits actually won't solve this problem, you'll still have to specify the lifetime somewhere for it to compile.
Well I'm glad I'm not the only one, haha! I would have been surprised if no one had ever wanted this before to be honest, but I couldn't really find anything on it when I did my searching (possibly related to me not knowing exactly what to call it). Do you know if this feature has ever been seriously considered/talked about? I did find [this](https://github.com/rust-lang/rfcs/pull/195#issuecomment-53005235) but that's about it.
Could possibly score based on the number of thumbs on the PR description, as some crude method of estimating the impact of the change.
I've seen it brought up in a few conversations surrounding associated type constructors, but usually by the same person (/u/glaebhoerl). I've personally wanted it for expressing bounds on entries in `HList`s (heterogeneous lists, similar to tuples). For example, working with a type that implements `HList&lt;BoundTrait=Future&lt;Item=T, Error=E&gt;&gt;` where each entry is of a different type but they all can be used as `Future`s.
Rust tells LLVM that `&amp;x` will not be mutated and `&amp;mut x` will never be read from. Currently, it only tells LLVM this at function call boundaries, though it could do more in theory (unsure if LLVM has support for this). So it's free to cache reads, and reorder both reads and writes on this assumption. It is undefined behavior to mutate behind an `&amp;x` or read from an alias to a live `&amp;mut x` (with the caveat that `x` doesn't contain `UnsafeCell`) so Rust is free to take advantage of stronger optimization guarantees in the future. IIRC C can do this too for pointers marked `restrict`, but restrict pointers are pretty rare in C codebases I've used since they're more prone to undefined behavior. In Rust the default reference type is `&amp;T` and in safe code you are prevented from triggering this undefined behavior, so Rust gets much more mileage out of this optimization. ---- Here's a quick demonstration of the reload being elided: https://play.rust-lang.org/?gist=cecedba4fad481cbbba3dae8c357734b&amp;version=nightly&amp;backtrace=0 . Be sure to run it in release mode. 
A PR to commit ratio would be good. I guess the number of lines added or deleted but that's not an objective measure as to the quality of the code added or removed.
Will macro-by-example be implemented in terms of procedural macros?
Will this be strictly for the core language, or for the core language + major crates?
It's not totally clear! I would like to have it cover at least the whole rust-lang organization.
SWIM might disagree with you and find your framing disingenuous but they'd probably pretend otherwise because they don't want to get blackballed from the industry.
All I worry is that once things fragment they're probably hard to glue back together. When I look at haskell and thing should I use pipes or conduit, I mostly end up thinking that I should use another language. It feels like too fundamental of a problem for the language to be unopinionated on to me, but I'm willing to consider that I'm scarred by haskell.
Just seeing people wonder if their opinions are against the CoC is so gross to me. But that's probably me deluding myself, the only true reason to dislike a CoC is bigotry.
A JVM for a first project? that's ballsy :)
I have received private messages today from people who agree with me but don't want to say anything publicly. The public response on this thread in contrast has been consistently negative, suggesting people who aren't you have no trouble disagreeing with me.
&gt;(I'm not the most socially perceptive person and my emotions and impulses sometimes get the better of me so, in order to avoid saying something unforgivable, I aim for almost robotic polite, non-confrontational, and uncontroversial behaviour (especially in text-only media). When I screw up badly enough to reach all the way outside that buffer zone, I start to panic.) That's funny I didn't remember you being one of my alt accounts
You're Ike the compiler: yelling at us a lot to make us better
It's especially funny because *Rust wouldn't have let Heartbleed happen*
If we killed blogspam the subreddit would be dead :p
The ATS programming language might also be relevant to your interests https://en.wikipedia.org/wiki/ATS_%28programming_language%29
I don't have an issue with the concept of binding a data-structure to a lifetime. That makes perfect sense. The problem is the level of verbosity that rusts generic syntax seems to demand when doing something simple like changing the lifetime. It makes refactoring/maintenance a major hassle. 99% of the time, you just want to have the structure use a standard normal lifetime. Ie "this reference must not outlive my structure". And all the places the type is specified will use the exact same generic signature. Many cases it's nothing more than adding &lt;'a&gt;. The problem is you have to repeatedly add it all over the place. It seems to only be some special cases, like if you have to return a struct with a different lifetime. Adding a single &amp;borrow to a structure requires the following changes: * +2 'a in the structure definition itself, once for the definition and another to bind it to the specific member variable. (It makes sense that you need this one, although an implicit definition of the lifetime from the usage would be nice). * +2 'a's for every impl line (× by every trait you implement). * +1 'a's for any constructor/factory/clone/copy fn lines. (+1 if they take in the same struct). * +1 'a's for every call site specifying the struct type (which of course can be in 3rd party crates). That's a *minimum* of 6 different locations you need to add "&lt;'a&gt;" too just to make a simple struct contain a reference. Consider going from [this](https://is.gd/ySIF1k) to [this](https://is.gd/WOhG3w). EDIT: I dun goofed on the 2nd example it was the same as the first. And this is a simple example. In my actual one I had an object containing an object containing another object. Since I needed to make the nested object a reference (because it needed to become a trait object), I had to add lifetime specifiers to the other 2 objects. That's 18 changes minimum (in-reality more like 25+ because I was implementing Debug and similar traits). Also consider if you have to add another reference or some other generic stuff. Now maybe I should have used some vastly different architecture, but having to change program architecture to avoid syntax seems to be a problem. Just being able to specify an implicit default generic signature that is used by default at any call site when no generic is specified would get rid of all of that. Just requiring you to specify it in the struct definition. You can even use Borrow&lt;&gt; to skip the added &amp;. iirk there might be a crate that does something like that via macros. In fact even nicer would be if Rust could just make an implicit lifetime when you put a &amp; in a struct of the lifetime of the struct itself, then there would be no syntax overhead. But I'm sure there are corner cases an ambiguities and so on...
That idea has been suggested in the past, in various forms. The problem is: pretty much all existing libraries are written with ownership/lifetimes in mind. So while you can fling objects around in your own code, the moment you interact with another library you'll run into the same restrictions as before.
I'm the wrong person to ask as I learn languages for fun but I'd say it is. The borrow checker can help you see the lifetimes of other variables when using other languages etc.
Also the much underappreciated [patterns](https://github.com/rust-unofficial/patterns) repo. (edit: oops, meant to reply to /u/steveklabnik1 )
We get this in scala so it seems silly not to have it and it is really killer for traits.
Would it be a breaking change to replace it with the IMHO more sensible `i32`?
The `start` lang item is unstable so no, it's fine. I'm not sure if this affects `#[start]` as well, which might be stable.
Nicely done! Since you are only ever implementing `FromHashmap&lt;#name&gt; for #name`, it may make more sense like this without a type parameter: pub trait FromHashMap { fn from_hashmap(hm: HashMap&lt;String, String&gt;) -&gt; Self; } Also if you find the long `cargo rustc ...` line tough to remember, check out [`cargo-expand`](https://github.com/dtolnay/cargo-expand) for showing the expanded code. It will also automatically run the code through rustfmt if you have it installed, which is typically more readable than what you get from the compiler.
As someone who's contributed to rustup, you should definitely include that. 
Yeah, but you don't need to factor in the cost of learning Rust, because you've already paid it.
On Haskell: we are far from that point regarding fragmentation. We still have a single package host, a single community, a single build tool (that everyone likes for once), and a single blessed library for serialization/IO/HTTP/RNG/logging. As someone who was put off by the drama in the Haskell community, this is a breath of fresh air. As for pipes vs conduit: the correct answer is to use neither. They are advanced frameworks that solve problems most applications don't have. I wrote [a server](https://github.com/lfairy/hakase) without touching pipes (or lenses) at all.
I will repeat this: git *has* all required information. The problem described on the page you linked occurs because during default merge this information is *ignored*.
If you just want the error message as long as possible, that's easy to do: let x = (); let x = (x, x); let x = (x, x); // ... let y: () = x; As part of its error message, the compiler will print the final type of `x`. This will be exponentially large.
Great initiative! Does Rust already have something like ruby-toolbox? I tried to make one for Haskell, but I ran out of weekend when I bought a fixer-upper house. As to the source.. you know I don't think anyone would've blamed you if you did it in Ruby instead ;)
Adding two strings might be a performance hazard, where someone might allocate and then later add, when adding a slice would prevent an extra allocation. But I would like something like this to work in the future: let a = "Hello, " + "world"; //adding two &amp;strs always allocates and produces a String
You may want to look in /r/playrust then.
&gt; On the other had, it costs you little That may be a matter of perspective, but I completely disagree with the idea that such a thing costs little. A check on the consumer side is O(n) in the number of usages (as opposed of the O(1) of a checked guarantee on the producer side). "What you know about the state of the System" is even worse, in that it takes a bit of the extremely valuable resource I call "brain working set while understanding the program".
Thanks for the comments! I actually wasn't afraid of non-monomorphization, and I can now write my own `Future`. All I'm trying to say is, when I first started to switch to tokio, 200 compilation errors (hardcoding all parameters) looked more manageable than 1200 (with type parameters "in the process of being fixed" in all structs). And, you guys are right, I didn't even think of re-generalizing before writing that blog post and realizing I had done that ;-)
Alright, so now imagine a world where you can use a DVCS without maintaining your own server to publish your commits, and without being forced to use someone else's server. This world is out of reach with existing tools. This is why we wrote Pijul: you can have as many accounts as you want on as many servers as you want: yours, cloud servers, and even your smartphone. Pijul exchanges exclusively patches: no need to publish more, and we all know what a patch is. (of course, a year and a half ago I knew what a patch was, but didn't know how to merge them correctly and efficiently in all cases). 
&gt; Also, wondering why he thinks "there are a welter of half-solutions [to the select/poll/epoll_wait problem] in third-party crates but [...] no consensus about which to adopt" when just about every async project has been coalescing around tokio? I'm also not sure why he thinks consensus is required, either. Find a library that does what you want, and use it. You don't need everybody else to nod their head in collective agreement. If it does the job, it does the job.
&gt;I've got a function which untars a gzipped archive simply by calling "tar" via std::process::Command. Is there any particular reason i should instead use a crate like flate2, or does it not make much of a difference? I think you should consider how your program might be used. What happens if the user doesn't have tar installed (windows user, probably)? What if it is a different / older version of tar which doesn't support particular archive format / command line options? It all depends on your use case. In general, people expect binary programs to be standalone and not "shell out" to something else.
There appears to be nothing in this link.
Nah, restrict is not enough here. foo() still can store pointer and cast to int*. Restrict can elide memory barriers between stores based on different function arguments within a function body. So void foo (int* restrict x, int* restrict y) { (*x)++; (*y)++; } Can be converted to: mov eax, *x mov ebx, *y inc eax inc ebx mov *x, eax mov *y, ebx That's usually helpful with loops unrolling. With restrict C knows stores to one array don't mess up another.
It's a bit too optimistic with regards to hyper
Ah that makes sense, thanks. Since I can't `impl AsRawFd for Stdout` I ended up making a wrapper struct around it. BTW, does anyone know why Stdout doesn't implement AsRawFd? Doesn't make much sense to me.
Run rustfmt over it. You could remove your From impls and just have an array of the types. Additionally the line where you are creating the initial board can probably be simplified and you should probably use y &lt; BOARD_SIZE / 2. 
Thank you! I recently found a repo on GitHub of another GB emulator written in Rust and had problems compiling it because of sdl2, it must have been yours, hahaha
Yay, hoped there would be one of these, I missed last year's 
My prediction is that supercompilers will become an actual thing within ten years or so. They won't have achieved even close to their potential by then, but they're going to be fast and practical enough to cover tons of currently hand-rolled optimisations at current or better compile times, while at the same time of course offering *more*. That said, people are also going to stop arguing that reducing program complexity is a semantic change that optimisers shouldn't be doing. (E.g. a common benchmark that your idea for a specific supercompiler design is sensible is that it can take a naive O(n\*m) string search implementation, a fixed string, and generate a specialised search *that uses KMP*).
The module/namespace system that C doesn't have might be related to this. In C you just have to `#include &lt;sys/epoll.h&gt;` somewhere, and then you can just `epoll()` directly. On the other hand, a namespace system like Rust's ensures that the programmer knows *where* the function comes from. In C, you can just write a program that uses epoll or select, and compile it, and it works on your machine. In Rust, though, the programmer is forced to acknowledge that epoll and select are Linux- and BSD-specific functions, by specifically importing them from a Linux- or BSD-specific crate. This goes back to what seems to be a core principle in Rust: even though you're not forced to do something about every potential problem, you're at least forced to *acknowledge* that those potential problems exist. That's why you need to explicitly destructure a Result or Option, even though `.unwrap()` is a valid way to destructure it, that's why `match` blocks need to handle every possible case explicitly, even though you can just do `_ =&gt; ()`, and so on.
I was looking on the website for a link to the repository, or something like "get involved!", but couldn't find anything. The project seems very interesting, but there is no clear way to begin contributing.
&gt; Please don't bring personalities and personal views into this, unless they have too. Could you clarify that last part? I assume it's _not_ meant to be a justification for "But muuuum, _he_ started it!" :-)
There is really no documentation about MIR's grammar and semantics other than the original RFC?
But he very much _does_ want to pick a library that will stay around for a long time. If there are multiple competing alternatives, then it's fairly likely all but one of them will die out.
&gt; Also, afaik, part of what make pijul faster than darcs (and also git) is that the information for patch commutation etc doesn't need to be computed every time you want to do it. Computing patches is only required when you perform a merge or view diffs, which is not very often and is not noticeably slow when using git. I agree that there *are* slow operations (such as git rebase) but I believe they really require a lot of work, although computing diffs is not what makes them slow.
\+ 2 `'a`s for every struct or enum from which the struct you've added to is reachable in the "contains" graph. This is a lot if you added a reference to a leaf struct.
Note that he's building his server up from a reference implementation that's on the `tokio.rs` main page. He just copied the code and then tried to build on it, discovering that minor changes could yield vague errors. His example of adding the log statement which immediately locks the type to `&amp;str` instead of `SocketAddr` is classic. What I think the compiler in this case could do to reduce confusion is not immediately bind its type on the first constraint, but instead collect constraints and then throw an error about conflicting constraints before reporting on any other problems. I.e. it would be great of rustc instead said: Line 13 expects the variable `addr` to be a &amp;str, but line 15 expects `addr` to be a `SocketAddr` Not sure if that's possible in Rusts current implementation though, this seems the kind of scenario where the greedy algorithm might be much simpler than the more robust one.
Hmm well. Personally I feel that memory safety solves an insanely vast majority of security problems in code. Vulnerabilities not involving memory safety are relatively uncommon and typically much harder to exploit, requiring sophisticated approaches rather than just lying about how much stuff you are going to send or similar. I personally don't feel that the Rust language should take responsibility for the logical security of code written by users of the language.
If you use Rust to build web application, there is a bunch of lib you must rewrite by yourself :). But this is a great opportunity to have a profound of Rust.
&gt; Wonder if the developers have plans to make a github competitor. With tokio coming stable, a Gogs-style low-overhead web application would be awesome. The Pijul team is working on a federated hosting platform called pijul nest. They wrote the rust ssh server etc, because it is a dependency for pijul nest. clipped out from the #pijul freenode irc log: &gt; [2017-01-07 10:40:27] &lt;pem_&gt; Happy new year everyone. It's starting well for Pijul: I'm starting to use it quite seriously this week. &gt; [2017-01-07 10:40:48] &lt;pem_&gt; I just finished unrecord, and stabilized the patch format today :-) &gt; [2017-01-07 10:40:57] &lt;pem_&gt; \o/ &gt; [2017-01-07 11:03:19] &lt;pointfree&gt; Yay! &gt; [2017-01-07 11:04:34] &lt;pointfree&gt; What's the story with the changes/log subcommand? &gt; [2017-01-07 15:54:55] &lt;pem_&gt; pointfree: what do you mean? &gt; [2017-01-07 15:55:46] &lt;pem_&gt; Oh, I see. It's not really functional right now, "changes" is meant to be called over ssh to list the patches in a given branch. &gt; [2017-01-07 15:56:28] &lt;pem_&gt; The idea is that nothing needs scp, so that restricted ssh servers (such as the nest's, which is already written) can still serve pijul repositories &gt; [2017-01-07 15:58:03] &lt;pointfree&gt; pem_: Interesting. So "changes" is intended to list patches in remote branches just as well? I like that. &gt; [2017-01-07 15:59:08] &lt;pem_&gt; yes, "pijul changes --branch master" gives you a really raw list of patches. &gt; [2017-01-07 15:59:13] &lt;pem_&gt; (i.e. just hashes) &gt; [2017-01-07 15:59:21] &lt;pem_&gt; not sure that one is public just yet. &gt; [2017-01-07 16:00:45] &lt;pointfree&gt; Just did a darcs pull. I don't have that subcommand yet. &gt; [2017-01-07 16:04:40] &lt;pointfree&gt; Will it be possible to do a "pijul changes" that aggregates patches from multiple local and remote branches into a single stream? ... I suppose you would have to merge things for that to work. &gt; [2017-01-07 16:05:46] &lt;pem_&gt; 1. yes, you can do anything you want with libpijul. the code for "changes" in the pijul binary i &gt; [2017-01-07 16:06:19] &lt;pem_&gt; 2. why would you want that as something separate from "pijul changes" + standard unix wizardry (cat/awk/sort/uniq and the like) &gt; ... &gt; [2017-01-13 02:58:49] &lt;pointfree&gt; pem_: regarding #2 on a multi-branch aggregating "pijul changes", what if you want to do "pijul changes -v" &gt; [2017-01-13 02:58:49] &lt;pointfree&gt; This possibility would be useful for the pijul web app, such as a feed of changes on all related forks and branches. Everything is written in rust and the pijul web app links to libpijul. I think federation should work pretty well with the fact that pijul branches are just workspaces with subsets of patches plus their dependencies regardless of whether they are local or remote.
Yeah, I would like to get involved with the pijul web app, but the team has been taking a vanguardist approach so far. Hopefully once it becomes stable and usable they will pull back the curtain. Although, by the time it's stable it will be harder to affect changes to the design because people will be using it. An older copy of the dvcs portion of the project can be cloned with: darcs get https://pijul.org 
&gt; Within its parameters, the Chernobyl reactor was as safe as the Russian technology of the time would permit Disagree, in that one of the more recent things discovered about one of the final causes of the accident was that the tips of the control rods were not just not neutron absorbers, they were made of graphite! Which was the moderator for the design, they were also short and displaced water, which is a neutron absorber in the system. So trying to slam them home initially further increased the reactivity at the worst possible moment. Maybe there's a reason they designed them that way, but I'm hard pressed to imagine how it could be possibly justified on safety grounds.
Go is actually a pretty good replacement for C for reasonably-performant network services, hence its popularity among container orchestration tools for Linux. 
Thing is, with the state of the art of guns so advanced, as you implicitly acknowledge above in reference to bridges, you only need to follow [4 rules](https://en.wikipedia.org/wiki/Jeff_Cooper#Firearms_safety), one of attitude, to avoid literally shooting yourself in the foot with one. C requires a few more rules, and having used both for 35+ years, I think it's considerably easier to follow the rules of gun safety. Then we get to C++, where I gather the first thing most groups do is implicitly or explicitly decide on a subset of it to use, so they maybe, possibly, keep the number of safety rules required to a set a mere human can follow (granted, I gave up on the language after using it heavily 1994-7 and occasionally through 2004).
C++ has something similar as well with abstract classes.
Meh, I wouldn't say "any reasonable person." Reasonable people can disagree on a lot.
I agree, and it's a topic on which I'm working. It helps that I'm in an environment with heterogeneous platforms and nobody is firmly married to either C or a specific platform type, because we're firmly married to SAFETY ÜBER ALLES. Everyone I've talked to has complained at length about all the manual work we do to prove our C can fly, but no other language can sub in for it effectively; even a pared down C++ would only work if it were pared down to being pretty much C with dot-method notation. There's no question that institutional inertia is a real dragon we'll have to slay though, and that'll take some doing.
Rust does not *guide* you to memory safety, it *enforces* it if you are not using unsafe code. That is a very big difference. You could say that C++11 guides you to memory safety, but it will never enforce it.
I'm glad we're working on this. I believe Rust is inevitably the future, but we're gonna have to spend a lot of time helping C programmers come over. 
It does not yet, but there is https://github.com/rust-lang/rfcs/pull/1824 which is sorta similar, trying to deal with discover ability.
new heading: online learning ressources In my opinion the discovery issue outweights the play favorite issue and the offline issue, at least for overview projects.
Only in the sense that, the language implementation of `select!` has issues, which is why it hasn't been stabilized. That means that in theory it could be removed, though nobody is gunning for that. There's multiple ways in which this is kind of wrong, though: 1. not in stable, in some sense, means "not in Rust yet". 2. There's no reason that this functionality _has_ to be provided by the language.
In what sense? EDIT: Just saw you posted downthread. Cool. Generally, giving more details makes for a better commit.
Can you elaborate on this spurious wakeup case or point me to where it is in the documentation? I'm familiar with a few cases where epoll_wait can wake up spuriously, but none where you wouldn't need to call recvfrom to figure out it was spurious. For example, a UDP socket in epoll set can have EPOLLIN set but recvfrom can fail with EAGAIN because kernel decided to free the page holding the packet before user space could recvfrom. My concern is the poll_read, recv_from order seems to imply you might be calling epoll_ctl (and maybe epoll_wait) before recvfrom initially which can be less than ideal. It seems to me you shouldn't call epoll_ctl until after you've tried an operation and errno is set to EAGAIN. For example, with TCP clients can include data with initial connect using sendto MSG_FASTOPEN so on the server side you want your first syscall after accept4 to be recv, not epoll_ctl. Furthering the example, you have an HTTP client using TCP Fast Open, it is reasonable for the server to conclude a transaction with the client without encountering EAGAIN.
Ok, stupid question: where did this talk about SJWs come from? Has Rust been associated in any way with such notions at some point?
I would agree with /u/killercup: Rust isn't yet a language for job opportunities. Most of my 'work/jobs' are in other languages, but my learning experience with Rust has still improved my own skills as a developer-- but that learning experience was much more than learning the language (or even the platform). I have a much better understanding of ownership, memory management, and costs that's improved my code/design in other languages. I didn't expect it to be so prominent, but I actually had some non-Rust coworkers notice the improvement. (Not that my code was bad before, but how *their* code wasn't up to par anymore). I don't really know how to explain it, but a lot of it came from reading discussions/decisions. Getting a sense of why a decision was made, how it compares (advantages/disadvantages) to other languages, and where/when improvement can be made. If you're solely learning development for a paycheck, those things may not be as useful to know-- but I'd definitely recommend Rust if you're trying to learn to be a better developer, in general. I've had three problems, after learning Rust: 1. I really miss Rust's enums-- especially the ability to associate data with it. 3. Some of my worker environments are still in the 'OOP Everything' phase. 2. I keep typing `let var = ...;` in languages that don't support it.
No matter what the landscape is for an `epoll` equivalent, it's a bit dumb to expect to find it in the standard library, since it's not cross-platform. It's not even standard C.
IIRC we didn't have access before (probably why we use hardcoded paths), and I never realized this changed :)
Right. Apologies for that. Pijul was announced by the darcs team before it was ready to be shown to anyone, even on a whiteboard. Until last week, I wasn't even sure all parts of the theory could be implemented with algorithms of reasonable complexity (I was especially worried about unrecord before I had finished writing it. Unrecord is an important part of interacting with working copies). In the first semester of 2016, I kept the Pijul repository synchronized with a clone on GitHub for a while, but have received neither pull requests nor "darcs send" patches, and the synchronization was taking me a lot of development time, which I preferred to invest in a working Pijul, and a (soon public) nest. 
[Seems to work (playground link)](https://play.rust-lang.org/?gist=328781c0452c85d354e1cd03e9bde60d&amp;version=stable&amp;backtrace=0). I think struct lifetime parameters count as output (not sure about input) lifetimes per the elision rules.
Yeah, so IIRC Rust only uses noalias on function arguments, so _right now_ we do the same optimizations. Rust has scope for more.
Just to clarify: I don't mean ESR or the any competent "old school" hackers personally are writing bad software or a software full of security holes. But the broad technical culture that I've described as an "old school", while advancing the technology at the great pace, have been using tools crude, and prone to human error, which resulted years of security issues that were easy to avoid. &gt; Really you need a major attitude adjustment because (...) Maybe. Sorry for that. I'm generally trying to be civil. I'm trying to convey my honest opinion, and might not do the best job in making sure it sounds right. I'm just disappointed at the original post, especially that it comes from someone I respect. There has been plenty of Rust critique posts on r/rust and I think this is the first time that I find it well... shallow and uninformed. As per non-ASCII characters, I just fine it relevant that while complaining about "difficulty concatenating strings" praises Go where strings are just `Vec&lt;u8&gt;` with no regards to encoding, which leads exactly to such problems. Edit: Actually, after more research it looks that my respect for ESR was misguided and uninformed. 
(Seems like you were already aware of that from further comments, but this is actually not that well known within the community. Run clippy on a codebase and IMO one of the most useful things it does is strip out elidable lifetimes. Most codebases don't elide struct lifetimes at all)
&gt; Wonder if the developers have plans to make a github competitor Very concrete plans indeed. Tokio, Thrussh, Rustls, Libpijul. I've heard the first projects include a totally asynchronous web framework, an SSH library and a patch-based version control system ;-) I don't have any plans nor any will to "compete" with GitHub. GitHub is a cool service that solves a different, git-specific problem (at a very high level, the need to publish your commits), which is unrelated to the needs of Pijul.
Specifically, we're trying not to reference too many external resources in *the book*, which is going to be printed so we'd like the code/links/etc in it to continue to work and be relevant as long as possible. We're not likely to change that stance, but /u/steveklabnik1 expressed that linking to other resources in an official place online could be discussed.
How does `&amp;self` work (i.e. why does elision work with `&amp;self`), then? Does the type of `self` equal `Struct&lt;'a&gt;`, where `'a` is defined by `impl&lt;'a&gt; Struct&lt;'a&gt;`? ([example code](https://play.rust-lang.org/?gist=be2862a275c07c9fce89f06b2ae88d51&amp;version=stable&amp;backtrace=0))
Completely agree w.r.t the book, I'm not advocating putting anything in there. But I do think there's a place for something like this *around* the book, as you mention.
It depends how you define a scripting language, I suppose. Personally, I find that Go embodies scripting languages pretty well: - Simple language - Duck-typing (in the form of automatic implementation of interfaces) - Powerful downcasting &amp; even reflection This makes it easy to write Go code, however between Duck-typing, downcasting and reflection it can pretty difficult to understand how far reaching a refactoring is: - was that interface implemented by design, or accident? - this method takes an `X` interface, but does it use down-casting/reflection to refine its behavior in some circumstances? Which is why I tend to classify it in the scripting languages: - easy to write - not much guarantees I know it's *supposed* to have been created for large-scale applications, but I find its dynamic nature runs contrary to this goal (whereas its compilation speed is a god send).
I would argue that being interpreted, JIT-ted or compiled ahead of time matters little to whether a language can be described as scripting or not. I explain here why I qualify it so: https://www.reddit.com/r/rust/comments/5nl3fk/rust_severely_disappoints_me/dcdt51v/
And I would counter by the fact that its (possibly) very dynamic nature (duck-typing, downcasting, reflection) makes "find usages" and thus "refactor" quite difficult, impeding this goal. Making a large codebase compile fast is all and good (and Go does an admirable job of it), but if it takes ages to understand who uses the piece of code you are changing because of the dynamic nature of the system, it becomes difficult to *maintain* the codebase. Easy to write, hard to maintain =&gt; scripting language. (Handling dependencies by pointing to git repositories is not the best idea either, but maybe it's changed?)
…TWIR…RFC…ABI…TDD…DRY…KISS…FCol…ISOP…SLA…SRP…SoC…MISRA-C…
I certainly would love a thicker Rustonomicon book!
&gt; I kept the Pijul repository synchronized with a clone on GitHub for a while, [..], and the synchronization was taking me a lot of development time I assume you were trying to reproduce the commit history in git? But that's really not necessary. A simple Github mirror with just a single commit representing the latest version will make it tremendously more accessible to people. (Just mention in README to do a fresh clone or `pull --rebase` every time their local copy needs to be updated, and also the commit-hash from the original darcs/pijul VCS.) Also, syncing it only once a month would be fine too. Something, anything, easily accessible would be way better than the way it is now.
At the time, it was personal preference, mostly. That said, while the code gen tool was targeting Swift output for the immediate need, we've always been planning to add more outputs to it, and we wanted the tool to be cross-platform, which is (was, at least, haven't checked recently) shaky for Swift. This goes doubly now, since new back-end development is being done in Rust. :)
Returning `Self` would indeed be better - thanks for pointing that out! Also your `cargo-expand` project looks very useful; I'll for sure give it a try.
That does sound like a nice feature! There might be a performance concern, since it's potentially significantly increasing the amount of data stored per variable, but perhaps you could only accumulate incompatible constraints, relegating any performance loss to the case where compilation is about to error out anyway.
Scripting languages (like python/ruby) deal with duck typing at runtime, Go does not (since its compiled). You can't run Go code until it passes the compiler which catches many errors that are not cached by python/ruby. And since Go was (intentionally) designed to be simple _so_ it can compile fast to native code _does not mean_ we can't compare it to other (slower) compiled languages like Rust. Comparing Go to Rust in this case is perfectly fine and fair IMO. I think you should give Go a fair chance, it was designed _to_ build scalable huge codebases from the beginning. 
You can't write a one sentence summary of what the code is trying to demonstrate? My understanding is something about the C++ standard being weird because the compiler doesn't connect the dots about a value being null when it is passed through a non-inlined/non-optimised function, and (currently non-equivalent) Rust code apparently doesn't have the same problem. --- Maybe you've made a typo, but the Rust code isn't accessing a hard-coded address: it is returning a pointer into the stack of `address`, which is dangling once the function returns. Also, optimisations aren't on, so you're not seeing the compiler try to do any reasoning about dereferences. In any case, the most spec-y document about Rust, the Reference, does explicitly [say](https://doc.rust-lang.org/reference.html#behavior-considered-undefined): &gt; Dereferencing a null/dangling raw pointer [is undefined behaviour] And, in practice, the Rust compiler behaves just like the C++ compiler: null dereferences will result in "surprising" optimisations (or maybe not surprising... I don't have enough context).
Actually most of the questions can be answered. There is a tool called `guru` that handles these sorts of queries: https://docs.google.com/document/d/1_Y9xCEMj5S-7rv2ooHpZNH15JgRT5iM742gJkw5LtmQ/edit You can also watch some of the talks by Alan Donovan (the author of Guru and one of the authors with http://www.gopl.io/ ) where he discusses how it works: https://gophervids.appspot.com/#speakers=alan-donovan The git repository still is still there though. You might be interested in the summary article from the vendoring committee about the current state of things: https://blog.gopheracademy.com/advent-2016/saga-go-dependency-management/
&gt; This is is reflected in git: when two developers diverge from a single point, they create a branching point in the commit graph. When they want to combine their changes, a merge is performed, and this is reflected in the commit graph. If you specify the commit graph in a different data structure (save difference and links between nodes instead of values and links for nodes), this isn't going to add new possibilities. In your data layout links between nodes are dependencies between patches, in git, it's parent commit(s). In darcs and pijul "spontaneous" branches are arbitrary subsets of patches + their dependencies. You can use something akin to twitter hashtags in the record (commit) messages to aggregate patches arbitrarily after the fact. darcs changes -p "issue#37" # lists all changes containing issue#37 in their message. So it's not necessarily a diverging workflow. The patches are a *partially* ordered set because sometimes there are dependencies and sometimes not. By the way, there was a [`darcs stash` subcommand](http://darcs.net/Ideas/Stash) in the works and it's similar to checkout in that it temporarily hides the effect of the other patches from the working copy. 
`&amp;self` and `&amp;mut self` have a special rule, too: https://github.com/rust-lang/rfcs/blob/master/text/0141-lifetime-elision.md#the-rules
&gt; such cases probably weren't using C in the first place You're right, Google was using C++ or Java for their services they ported to Go. &gt; I see Rust as a better tool for writing services of any kind I agree! Especially with some of the zero-copy parsing libraries like nom, we could avoid many of the security issues that plague many protocol parsers. 
I was very excited when Go was announced (probably too much), and very disappointed. It just doesn't suit my tastes (lack of generic, dynamic nature). And just because the goal was to build scalable codebases does not mean that the language actually makes it easier (than others) to build scalable codebases. I see large codebases written in Java, and they can be a pain to navigate (especially when hitting a reflection boundary...).
I agree completely; D had fantastic potential but between the GC and the Phobos/Tango split it's unfortunately hobbled, and now Rust may very well supersede it. D is a great conceptual language, and deserved a lot better than it got. For general applications-level work, it's certainly more of a peer to C++ than C# or Java, but the tangled GC does keep it out of the freestanding realm. I think Rust is the only modern language that can push C out of the freestanding space, but even in lowur-level applications D could and should have had a better shot. I'm not well versed in Go, so I don't know it's strengths and weaknesses, but I get the impression it's a more, if not niche, then at least specialized language, whereas D and Rust provide excellent general purpose strength. I do hope that we eventually get multiple libstd and compiler options (I'd be interested in a GCC front/middle end, for instance), but preferably not like D where Phobos and Tango are mutually exclusive and have significantly different features, and not like Haskell where one compiler strangles the rest (at least I think that's what's going on there). 
Imagine the following setup: - interface `Message` - interface `LoggableMessage` (function `log`) - struct `X`, currently implementing both interfaces - function `send` taking a `*Message`, but internally logging the message if it is a `LoggableMessage` (downcast) Can `guru` tell me that `log(*X)` is used, ie see through the downcast, or not? It's the kind of question I need answered to know whether `log(*X)` is unused (and clutters the code) or is actually necessary. And to be clear, I am perfectly aware than Java/C#/C++ in general cannot answers this question but (1) since they use inheritance the declaration of intention is explicit and (2) I would not call them scripting languages because they do not make writing code easy to start with...
A VCS cannot possibly automatically merge correctly under all circumstances, as doing so requires understanding the exact semantics of the data being merged and the intended effects of both changes. This is why git merges ultimately require manual resolution, and claiming that Pijul somehow never has this problem is confusing. Are you sure that's what you meant? &gt; With caching, that's an interesting remark, because that would basically amount to… using Pijul! "Pijul is git, but with slightly more caching" isn't a very compelling story.
I totally agree with this. I've been pushing for the idea of swappable and compiler-determinable collection data structures specified only by traits. In other words, depending on how you use that structure (the specific operations your code uses on it, as well as profiling information on how it is used in real life), it should be possible for the compiler to decide on a data structure implementation that fulfills the trait's contract, and insert it for you. The same could be said for algorithms that perform logically equivalent operations but with slightly different performance behavior tradeoffs: sorting, hashing, regex, etc. This is the type of optimization that makes no sense to microbenchmark writers...they are already likely to do this sort of work as part of their attempt. However, it becomes extremely useful for real world software design: specify an operational contract in your code, let the compiler take an educated guess, then profile the code in real world conditions and run it back through the compiler for an even better answer. 
Same! Excellent! Go us!
&gt; Your other remark seems to be implied by your assumption that merging cannot be formalized. This means that we agree (at least at a purely logical level), because I believe the opposite. &gt; I'm pretty sure one can formalize any patch history in terms of git merges and branches. The main difference is in terms of UX, in how patches behave like they intuitively should (i.e. according to a rock-solid algebra). I'm not saying that merging cannot be formalized. You *can* formalize merging, but 1) There will be merge conflicts, this is unavoidable. 2) it doesn't necessarily mean the result of your merge process is going to produce correct code. I strongly suspect that the rock-solid algebra you're using for patches doesn't include a specification for each programming language. &gt; you would have to wait those 27 seconds for each patch you merge, i.e. 27 times 45000 seconds. This is awfully incorrect. What I've shown is calculation of the *entire* git patch history. you don't need the entire git patch history to perform a merge, only patches from the last diverging point. In this example, I would have to wait 0.0006 seconds per commit after diverging point on each merge (and not every commit is a merge). Which I find acceptable.
That version is the same as doing `0 == 42`: you're creating a integer 0 on the stack, and dereferencing a pointer that points to it, it's correct code (now that the pointer isn't dangling), and not equivalent to the C++ code. Create a null pointer (not a pointer that points to a zero value) with `std::ptr::null()` or `0 as *const i32`.
&gt; We can try to improve on this with better documentation and examples That would be good. Went to the tutorial and it said go to the book. Went to the book and it says that main() is the entry point. I compile the example and I get a warning that main() is dead code. After compiling I can't run the example, it complains there is no binary. That's where I'm at. 
Ah, true. Dumb me on this one, I missed that, it was in my face. Fixed: https://godbolt.org/g/ig1jx1.
I would love to put together an RFC, but I feel pretty inadequate here: My proficiency in Rust is probably in the 10th percentile here, and I'm not the best document writer anyway. I do wish we had a sort of Wiki-style way of writing and voting on RFCs. I could, for example, provide a pretty comprehensive list of formally provable optimizations that could be performed given a guaranteed refinement on the acceptable range of values that a type can represent. Hell, I could probably list a dozen or two off the top of my head. 
I'm still a little confused on this. mio relies on epoll, a Linux-only construct. So does tokio-core use mio on Linux and then futures underneath for every other platform? I thought futures was supposed to be cross-platform, so is this just for performance reasons?
I've added Rust after the fact, should have checked it better. At last I learned something.
To be honest, I'd be surprised if it did with any accuracy. At the extreme, this is a Turing-Complete problem. In Java/C#/C++ IDEs cheat: instead of looking for usages of the class method, they look for the usages of the base class/interface method, showing you call sites that may never occur for your type. It's kinda okay-ish (though sometimes annoying) since you explicitly implemented the interface/extended the base class to start with. I do wonder how a Go IDE handles this. It could do the same pessimistic search, of course, but that would yield even more false positives when you accidentally match an interface you didn't care about. And filtering on the interfaces you do care about could blow in your face if you accidentally forget one that matters. --- This is to be contrasted with Rust's approach: explicit implementation, no down-casting and no reflection mean that you can have a 100% accurate answer to "where is this function used?". There are libraries, such as `query-types` which implement limited down-casting but require the caller to declare which traits its type can be down-casted to at the call site, which mean that the call-site actually documents all potential interfaces in use within the function. Which is still very tooling/maintainer friendly.
&gt;If you don't like this thing I like, it's because you're a bad human being Yeah man IDK about you but to me that sounds kinda ... bigoted
The Rust community has adopted a [code of conduct](https://www.rust-lang.org/en-US/conduct.html), which for some bizarre reason is a subject of controversy in open-source circles. The whole thing started a while back with the Opal project when a maintainer said some shitty things about trans people on Twitter and [this issue was opened](https://github.com/opal/opal/issues/941). The Opal project soon after decided to adopt a code of conduct to protect marginalized contributors, and some people got **very** upset about it. The trend propagated to a lot of other projects which has caused a pretty big rift, but our code of conduct has luckily kept most of the awful folks out of the Rust ecosystem.
&gt; mio relies on epoll, a Linux-only construct. It maps IOCP to an epoll-like model internally, if you're on Windows. Futures are used on all platforms, and don't even have anything to do with IO, strictly speaking. They're also `no_std`.
Try using `std::ptr::read_volatile`, to prevent the compiler from optimizing it out? https://godbolt.org/g/be1Nxp
This looks really interesting
I know clang does it on C++ too, so, I think this behavior may just stem from that implementation detail? If it is indeed in Rust's spec that through that API I'm safe to peer on any address without the compiler trying to rob me, then it saves the day. Otherwise it just happens that LLVM is working for that. Not what I'd like to have.
Shh don't tell them, we have the moral highground :D
Ye it can: https://gist.github.com/dgryski/31ef7c8d40f804ab1d91f0c47728e928
That is a fair analysis. Even a library to achieve the same effect would be welcome. 
Are you using cargo? You should read the cargo docs, there's a difference between a binary crate (`cargo new --bin`) and a regular one (`cargo new`). Rust files with a main functions compiled with `rustc foo.rs` will work.
Yes, _but that is completely irrelevant to this discussion_. Nobody is saying that Go completely replaces C. That's a straw man.
By default, Rust expects the `main` function to be in a file named `main.rs` in the `src` directory. We're working on [a new version of the book](http://rust-lang.github.io/book/) (that isn't finished yet) in which I think we've been clearer about files, if you have time, it would be great if you could read that version and [file issues](https://github.com/rust-lang/book/issues) if there are still parts that are unclear!
Like people who are familiar with OOP patterns might worry whether they should or shouldn't repeat those patterns with the way Rust does things. For instance, should you treat impls as objects essentially. They look and act like objects, they often have `new` methods and they carry state around using `self`. Yet there is no object inheritance, or polymorphism (you need to use traits or enums for that).
&gt; unlike git where we have a lot of similar-but-not-quite concepts What do you mean? For what I know in git we have: - pointers/labels (which in git are commits, branches and tags) - blobs (which are content of files) - trees (which are Merkle trees of blobs, these are working tree, index tree, remote tree) Which of them are "similar-but-not-quite"?
But experience isn't. I can pick up a language faster now than when I was younger because I've been exposed to more ideas and techniques compared to then.
Supposedly to be solved by C++ Concepts, the trait analogue. Although I don't actually know if they can obscure the return type quite like that...
Thanks. I got a link to a new version of the book. I really have only put an hour in so far. I'll go beta the new docs.
&gt; I would really like to see all the LLVM sanitizers available for Rust, this would help writing unsafe code tremendously. [#38699](https://github.com/rust-lang/rust/pull/38699) is work towards this.
See [RationalWiki](http://rationalwiki.org/wiki/Eric_S._Raymond) or [this article](http://www.linux-magazine.com/Online/Blogs/Off-the-Beat-Bruce-Byfield-s-Blog/The-Decline-and-Fall-of-Eric-S.-Raymond).
Oh wow I just realized you are the author of both Syn and Quote! I know your name looked familiar but I didn't know where I'd seen it until now. Thank you very much for your work on those crates; they really make the macro-writing process manageable.
Ah, that makes sense.
Testing multiple versions on Travis is [relatively easy](https://docs.travis-ci.com/user/languages/rust/): language: rust rust: - stable - 1.13.0 - beta - nightly There's not a way to directly do "last stable" in the `rust:` block, but fixing a version is another approach: guarantee compatibility back to a certain version, which you can explicitly update occasionally. The libs team [discussed](https://github.com/rust-lang/rfcs/pull/1619) this question for the crates it manages directly, but didn't come to a conclusion.
Maybe, but that would depend more on them using C the whole time and only indirectly be related to their age(since it's hard for a 20 year old to have been using C for 47 years). Anyways, this is getting a bit off topic.
So I don't remember but my quick glance over the semantic version spec I didn't see anything obvious around build requirements requiring a major bump. Hopefully somebody will be a better rules lawyer than me and tell us =). My opinion would be the use of a new API that doesn't impact the users of your library (as opposed to the folks building it) shouldn't bump major versions.
Filed! https://github.com/rust-lang/rust/issues/39044
&gt; which for some bizarre reason is a subject of controversy in open-source circles. From what I've seen, the *legitimate* concerns about CoCs are because they're often highly punitive, and have many provisions for and few checks against being used to silence valid but unpopular opinions. I'm not in favor of CoCs, but I'm also an idealist and wish people would just behave well without them; I recognize that there is a need for a standard of behavior to which we can all refer, and I recognize that enforcement is, unfortunately, at times necessary. However, the atmosphere surrounding many noteworthy CoC advocates (Contributor Covenant especially) is extremely unpleasant, and so the whole topic gets stained. I've seen plenty of CoC enthusiasts, who I recognize are not the majority of people in favor of them but are unfortunately significantly vocal and thus become the apparent face, espouse a "you have nothing to fear if you have no unpleasant behavior/tendencies/traits to hide" message, which ... IMO, is pretty horrid." There's no perfect solution, and I recognize that CoCs are often necessary or even just useful to have, but they always make me incredibly wary of speaking about anything that isn't absolutely 100% technical.
What's the point of that? Just use `concat!()` if you want that
I'm only 23, and switching from C to Rust was a struggle. I'd like to get my office to move as well, but yeah it's gonna be rough and slow.
I'd like to see rustc version requirements in the Cargo.toml file as well. rustc being a build dependency (and library) makes it a reasonable thing to track the version of. Just because every rust project would depend on it makes it a little annoying to always have to explicitly set but the dependency not filled in could just be set to imply latest stable or something.
I'd like to see the Rust community add something specific here but it has been brought up a few times without much resolution apparently [1](https://www.reddit.com/r/rust/comments/4i5l5j/crates_should_declare_a_minimum_required_rustc/).
If you, your parent, or anyone else feels this way, please open up an RFC. We have always been open to this as an option, but it requires design work. The only reason it hasn't happened is that said design work has not yet been done.
Okay, how about type inference will solve which kind of string you get then? If you NEED a String it will be a `String`, if you don't, it will be a `&amp;str`
&gt; A lot of Rustaceans don’t seem to grasp why, when the question is “where do I get feature X?” the answer “oh, there are 23 crates for that” is objectively terrifying. I have no clue where he's getting this idea from. The crates.io ecosystem seems to be doing exactly what he claims to want, from my perspective- a bunch of crates pop up and then people rally around the ones that work the best. `regex`, `serde`, `hyper`, `url`, `byteorder`, `mio`, `rayon`, etc. are all widely-recognized here. Of course there are areas where the ecosystem is less mature and hasn't really picked one solution yet, but as he himself points out, that's due to Rust's age. And we could probably do better at communicating which ones *have* become de-facto standards. But that doesn't mean the "swarm" model isn't working or that the community doesn't understand the value in picking one.
I think that's somewhat orthogonal: the question of "is it considered a breaking change to change the minimum compiler version?" still has to be answered, even if manifests are able to explicitly declare that version. Unless some heroics are done with binary compatibility, such a feature is likely to "just" result in better error messages and maybe fewer accidental breakages (if the compiler is also improved to detect when newer APIs are used). Both of these would be great, but not necessarily everything the feature sounds like it will be, on the surface.
Some possible designs have been done: - https://github.com/rust-lang/rfcs/pull/1707 - https://github.com/rust-lang/rfcs/pull/1709 
I guess I still think of the compiler as just another dependency if it can be easily specified (and so is it a breaking change to change the minimum of any dependency would answer that question) but it is a very reasonable thing to say the compiler is not "just" another dependency and want to have a different policy in place. This probably could touch on how the toolchain is assembled too. Eventually does rustup start first, gets the cargo and rustc versions required and then cargo proceeds as normal from there for a new work flow? That doesn't sound appealing to me but I don't know.
I would definitely describe the commands as "similar-but-not-quite," even if the internal model is more consistent.
Hmm... is there any listing or marking of these rust-lang crates on crates.io? If not, should there be such a feature?
Also github has stars.
I think his point is that right now, the filtering is done by the community and reputation, instead of baked into the system itself. Not every Rust user is going to check out this subreddit once in a while to figure out which crates to use. 
Part (not all) of the problem is there are multiple answers, depending on what level of abstraction you are looking for. In this case both `mio` and `tokio` are valid answers for what is (becoming) the defacto standard crate to do async io. Another part (still not all) of the problem is when phrased as "I want a select api", it's pretty reasonable for people to link to "select implemented in rust" crates, instead of "the slightly different thing we actually use, that solves the same problem".
Download counts are _a_ metric, but they don't cover everything. I recently tried finding a library with reactive streams. There are so little crates that come close, the most downloaded one was not a very good metric for quality at all.
It's not that obvious nor ubiquitous, but most of them are marked by being owned by rust-lang and/or rust-lang-nursery (e.g [regex](https://crates.io/crates/regex)) on the right hand side of a crate page. [#409](https://github.com/rust-lang/crates.io/issues/409) covers getting a listing.
If you have ideas on how to improve crate ranking, [RFC 1824](https://github.com/rust-lang/rfcs/pull/1824) may be relevant to your interests :)
Which would only help for libraries that are hosted on github.
That just shows you the oldest library, not the best one.
It shows you a combination of the two (well really most used, instead of best). Like I said, not perfect.
This is my attempt to describe the initial steps in building a rust project that targets an embedded device. Rather than relying on frameworks like Zinc, I wanted to teach readers how to think about building safe interfaces to hardware. I'm inspired in a lot of ways by /u/phil-opp 's X86-64 operating system series. I've been working on this for a little while now. I'm releasing it in the open source "release early release often" mindset - I'm sure there are things that need fixing and areas the text could be clearer. I want to evolve this post (and subsequent ones) as necessary so that the series achieves the goal of teaching real-world embedded principles.
It's up! https://branan.github.io/teensy/2017/01/12/bootup.html I've started a discussion on this subreddit as well, at https://www.reddit.com/r/rust/comments/5nufdc/rust_on_teensy_part_1_bootup_to_led/
I thought there was something open, but wasn't sure. Thanks &lt;3
Right, `mio` is a bit of a bad example since Tokio is currently in the process of stabilizing an abstraction over `mio` which, when finished, will hopefully render `mio` non-useful for anyone except `tokio-core` itself.
Do you also have any sort of blog going through this process? I'm very interested in the concept, but I just don't have the time (or attention span) to watch over a dozen 2 hour videos. It's much easier for me to break a long blog post into digestible chunks than a long video.
&gt; How many of those crates are student exercises or plain junk? How do I tell which ones are still maintained? How do I audit for quality? How do I form expectations about which will still be maintained in ten years? How do I even find all the crates that might be relevant to my interests? These are all good questions. I think the rust community realizes these are important questions, and I point to things like [this](https://users.rust-lang.org/t/help-us-understand-how-you-evaluate-crates-so-we-can-make-crates-io-better/8248) as evidence of that. &gt; the answer “oh, there are 23 crates for that” is objectively terrifying. To provide a concrete example (though admittedly picked deliberately to support my point), here's some of the results you get when you search "xml" on crates.io: * xml-rs -- An XML library in pure Rust * quick-xml -- High performance xml reader and writer * RustyXML -- A SAX-like streaming XML parser, and a DOM-like interface based on that * serde_xml -- xml support for rust-serde * xml_writer -- writes xml, not pretty, but faaast * xml5ever -- Push based streaming parser for xml * rust-xml -- {no description given} * novaxml -- DOM XML Parser People who are familiar with this space will likely all point to the same crate as the obvious first choice. New users will probably make the right guess based on the download counts, but even if they do, I bet they are still wondering the same things ESR is wondering (how to evaluate each crate) Another observation is that a lot of people have very reasonable answers to ESRs questions (especially in the previous blog post). To many, I bet those answers were obvious. It occurs to me that those answers were only obvious because those people are participating in the swarm, and ESR is not in the swarm. (By 'participating in the swarm' I mean keeping up to date on /r/reddit, {users,internals}.rust-lang.org, subscribing to interesting github issues and RFCs, etc). For the record, I think python has many of the same problems. As another concrete example, consider: $ pip search django |wc -l 5963 That's nearly 6000 python packages that exist in the python+django ecosystem, with little hints about which ones might be the best, most suitable, most well maintained, etc. If rust has a curation problem, then python definitely has a curation problem too.
I'm sure there will still be people who end up using `mio` directly for less abstraction. As such I think it's a great example of why this isn't a simple problem.
Essential reading: https://github.com/rust-lang/rfcs/blob/master/text/1242-rust-lang-crates.md &gt; A crate enters the nursery when (1) there is already a working body of code and (2) the library subteam approves a petition for inclusion. The petition is informal (not an RFC), and can take the form of a discuss post laying out the motivation and perhaps some high-level design principles, and linking to the working code. 