Thanks! I didn't even think of combining the two in the filter.
Dereferencing it would be `*query`. `&amp;query` is getting a reference to it, but otherwise yeah. In Rust references _are_ borrows, actually, or the other way around :).
Ok first the top error read's error[E0277]: the trait bound std::string::String: std::ops::FnMut&lt;(char,)&gt; is not satisfied --&gt; src/lib.rs:68:29 | 68 | .filter(|line| line.contains(query)) | ^ the trait std::ops::FnMut&lt;(char,)&gt; is not implemented for std::string::String | = note: required because of the requirements on the impl of std::str::pattern::Pattern&lt;'_&gt; for std::string::String What this is saying is the `contains` method takes a [pattern](https://doc.rust-lang.org/std/str/pattern/trait.Pattern.html) (or simple put an object the rust compiler knows how to turn into a pattern, in this case a &amp;str), to fix this, notice that `str::to_lowercase` returns a string not a str. so &amp;reference your query like so `.filter(| line | line.contains(&amp;query))`. the last error basically means "I tried to call .collect() on something that wasn't the type i expected". As with query when you call `to_lowercase` on your contents your converting them to a String, So for simplicity you should be Returning a `Vec&lt;String&gt;` instead of `Vec&lt;&amp;'a str&gt;` Edit: Formatting
As a security consultant this is one of the reasons why I started learning rust recently and am looking at retooling all the security tools I use, not just for performance, but for the safety that rust brings to the table. I believe that having safe code will push companies to use rust if there is better awareness.
Oops yeah. Coming from JavaScript so actually thinking about types and pointers can be a little confusing
Yeah, wasm is much smaller though. I have been working on a small interpreter for wasm stuff in Rust, maybe I can try using this. It's just for fun anyway.
Please use gist for this
Yes.
[removed]
That Makefile looks like a program ought to be writing it, not a human.
Note that calling `.len()` on `str` and on `[u8]` gives the same result if they physically contain the same data. That means `str::len()` returns **number of UTF-8 bytes. If you need to know number of unicode code points in `str` (which you most probably don't want even if you think you want it), you have to calculate the length by iterating the whole string.
...and Ruby, Rubinius, the BEAM ... does the fact that other stack-based virtual machines exist preclude me from making my own to better understand how it works? 
Sorry, I think you're misunderstanding me. I'm suggesting that using this crate to implement wasm would be neat. Not that you shouldn't have built it. Or maybe I'm seriously misunderstanding what "generic" means to you here.
It actually depends on situation. In the case you provided, I'd most probably omit creating `new`, because `Vector3 { x: 0, y: 1, z: 0 }` is much easier to understand than `Vector3::new(0, 1, 0)`. On the other hand, if you have something like this: struct Buffer { data: Vec&lt;u8&gt;, pos: usize, } Then it's very convenient to provide `new()` method if it's expected that it's usually initialized as empty, with zero position. My rule of thumb would be: If all fields are public, you most probably don't need/want `new()` method. If at least one field is private, you almost certainly need `new` method. Also note that `Vector3::zero()` is much more readable than `Vector3::new()`
Oh! I see. Sorry! You're welcome to give it a go :)
So if a scope knows the address to something it is borrowing it?
Yup. Borrowing is actually just a concept to help with understanding the language, as borrows are just references and have some simple but strict requirements: * you can have any number of immutable references to a value, _or_ * you can have a single mutable reference (or none at all, of course) but not both of above at the same time. So while the borrowing analogy doesn't hold quite true (you can't lend a book to five people at once), it still helps understanding those two rules.
So with modern C++ it is possible to easily gain as much memory safety as Rust. Problem is, this is mostly achieved by the likes of "defensive copies" which reduce performance compared to idiomatic C. What Rust is really bringing to the table here, is the ability to write code that has on-par performance and runtime dependencies/assumptions with idiomatic C while also having the memory safety of modern C++ (and as a bonus, superior ML-esque ergonomics to modern C++). Any of those items alone is not-an-improvement over C++ or even Go, for which reason focusing on any of those items alone (e.g. memory safety) does not seem to be a particularly good strategy for showing people why Rust's learning curve is so thoroughly worthwhile. You or I could write Go programs with no memory-related vulnerabilities. But after about the third time writing if var thing4, err4 := thing3.FooOrPhooey(); err4 != nil { return nil, err4; } else { /* indent_level++; rest of code ... */ } ... I'd probably tear my hair out and/or wonder whose bright idea it was to have a language with not even an informal concept of a monad abstraction. (Which is what Rust has. Iterator, Result, Option, Future and Stream each have methods that could be called `return` and `bind`, even though the language itself cannot represent a monad trait that those three types could implement. Option does implement IntoIterator though... so if only it were easier/more-magical to use IntoIterator then we wouldn't need most of its methods...)
Well, if you are perfectly sure about what you are doing you can mutate static variable inside `unsafe` block. This is safe if you do this at the first line of `main` function as there are no other threads at that time. Since you are calculating the path you probably want to use `Option&lt;PathBuf&gt;` initially set to `None`.
**MUCUS:** Memory Unsafe C Usually Sucks. ;)
`Box&lt;T&gt;` contains a `*const T`, which is a fat pointer when `T` is not `Sized`.
You should move github :) Also, have you thought about implementing a JIT or AOD compiler for it? I don't have too much experience with that, but I'd be happy to help.
I haven't see that one. Very helpful. Thanks!
Half of it is written by the awk script parsing `Cargo.lock`. I guess most of it can be generated by parsing `Cargo.toml` That doesn't take into account differences introduced by `build.rs` or dependencies of `*-sys` crates.
I view it similarly. I consider using Rust competitive advantage because people spend less time chasing memory bugs.
I've got plenty of code on github, but I feel slightly uncomfortable about them as a company for reasons I can't really be bothered going into here. Regarding building a JIT - I'd love to do that, but stack-vm just provides the infrastructure you need to combine your own operands with your own instructions (rust functions). To really write a JIT you need to understand the semantics of the instruction set. I see stack-vm as just part of a larger compiler pipeline where you can do code improvement steps along the way. That said, stack-vm could definitely benefit from hooks for code improvement passes.
I didn't know you could mutate static variable, that looks exactly like what I need.
&gt; proactive security is more expensive than reactive apologizing Yes, this is a huge issue sadly in many areas of computing. Why does a Bank care about someone hacking their ATMs to spit out money, they are insured. As long as they are not much less secure than the other banks, they won't have to pay higher premiums. Why does an IOT vendor care if their smart cameras are being used for DDOS-extortion. Why does the buyer of that IOT hardware care. So the incentive by these parties is not to make their systems secure, it is to have as little responsibility for it if they get hacked. In that regard, Equifax has done a really good job! They got hacked but the real victims are normal people who appear inside their databases. Sadly though often the rules of the market are against actors who put security first. E.g. your product won't be the first on the market if you take the extra time to make it super secure instead of quickly hacking shit together. This makes security an externality, and it can only be fixed by changing the rules of the market. Read regulation, in some form or another.
https://play.rust-lang.org/?gist=9f05712fb677339de24eb5aa3f8004af&amp;version=stable `Vec` implements the `Debug` trait, so you can just do a debug print instead of needing to write your own printing helper. Iterators are snazzy, so I changed the random vector generator to use those. For the insertion sort function, I mainly just removed unneeded temporaries. Wouldn't be surprised if there's some better way to do it overall, but that at least condenses things down a bit.
For fun I figured out a way to do this with no runtime checks on access: https://play.rust-lang.org/?gist=0fdca86f503828715a5fbb6efdc07308&amp;version=nightly The union is required because mem::uninitialized() isn't a const fn (yet). Using a union this way might be Undefined Behavior (I'm not the one to ask), but if not this is safe as long as you initialize the static before using it. (Edit: could also use https://docs.rs/unreachable/0.1.1/unreachable/trait.UncheckedOptionExt.html instead of the union) I'd just use lazy_static, tho.
I'm continuing to work on nickel.rs. I've run into a problem reading files with hyper-0.11/tokio. Using files with futures-cpupool is intermittently failing. Details can be found at https://github.com/seanmonstar/futures-fs/issues/4. Insights greatly appreciated.
So the struct uniquely owns a resource? In that case it might be safe.
**SHITO**: Seriously, How Is This Okay?
Baller.
Working on a little rust cmdline utility for photo organizing. It's sifting through a pile of photos in a mishmash of directories and outputs a single set of non-duplicate files in an organized set of directories. It basically works, but I'm looking at adding some logic to use exif timestamps when available instead of filesystem stamps to improve placement of files into timestamped YYYY/MM directories. Oh and also mulling if adding deconfliction logic in the (unlikely) case of a hash collision on file thumbprints is worth it.
/u/pcwalton first indicated to me why this isn't possible on twitter: turns out, the issue is that *C and C++, any version, are not type-safe.* That lack of type-safety prevents entire classes of static checks.
That's nuts. In retrospect an obvious optimization, but also nuts. Good job!
This is awesome!
Not related to the topic but, in the issue someone mentioned http://perf.rust-lang.org/index.html I have trouble to understand the graph: from the beginning of November, is rust more efficient or less efficient ? :o
this..this must be good for performance?
Y axis is % change in CPU instructions. So it looks like on average a number of programs are using 70-80% of the instructions they were before. It's faster
Those graphs are for measuring compilation time of hand-picked benchmark programs, not the performance of the generated output. They depict one of the programs taking 75% less time to compile since October, many of the programs taking 25% less time to compile, and many others that are largely unchanged though crucially they have not significantly regressed (being on guard for regressions is the reason that this site was mentioned in the comments).
After mulling this over, and considering the points I added to the OP, would it be fair to say that a slice, by definition, *is* a reference? (A reference to an unsizable type) Thus, it's actually correct to say that `&amp;[T]` and `&amp;str` are slices, and not *pointers* to slices. Does this make sense? And yes, I'll agree with you, at this point it's just terminology. :) 
Yep! It's in there for now, but I may not need all its features. At first it'll just be useful for cross platform nonblocking io, I want to make the first version compatible with the original C library Then I may make a version that is more tokio oriented which may cause some incompatibilities, not sure yet.
A couple weeks ago I bought the domain names rustreference.com and rustref.com I noticed that cppreference.com is a popular site, so thought it might be useful to have a similar domain name for rust. Right now I have them setup just as redirects to make finding documentation easier since I have a hard time remembering stuff like where to find the cookbook, or something like the ffi omnibus. If anyone has a subdomain redirect they want me to add, let me know! It just uses the redirect from google domains so some stuff like https won't work. Current redirects: rustref.com, www.rustref.com → https://doc.rust-lang.org/ book.rustref.com → https://doc.rust-lang.org/book/second-edition cargo.rustref.com → http://doc.crates.io cook.rustref.com → https://rust-lang-nursery.github.io/rust-cookbook cookbook.rustref.com → https://rust-lang-nursery.github.io/rust-cookbook ex.rustref.com → https://rustbyexample.com ffi.rustref.com → http://jakegoulding.com/rust-ffi-omnibus nomicon.rustref.com → https://doc.rust-lang.org/nomicon rfc.rustref.com → https://rust-lang.github.io/rfcs std.rustref.com → https://doc.rust-lang.org/std unstable.rustref.com → https://doc.rust-lang.org/nightly/unstable-book They will forward the path too, so some simple stuff like http://std.rustref.com/iter will work.
This is huge, it's the kind of optimization that affects all of the rust software. I would love to see (and understand) how it's implemented. Does it also work on structs, like the NonZero trait? struct StructWithABool { a: u8; b: bool; } Option&lt;StructWithABool&gt; // no memory overhead, the tag is stored inside b
Note that you can do that last part by using: my_str.chars().count() Although note that this counts the number of *unicode codepoints*, which may not be the same as your intuition as far as what counts as a character. For example, combining characters are included separately in the count.
I’m working on a tool to bulk ETL a an enormous pile of data that are stored in a particularly horrible and difficult data format, ANSI X12 837P. It’s the primary means by which healthcare providers send a list of the services they’ve rendered to insurers, so they can be reimbursed. The joys of this format include: - the use of `~` to denote newlines, and `*` for delimiters, except for when the vendor uses something different - hierarchical data in which the hierarchy is very important, but stored in a flat CSV-like (see above) format, with very minimal metadata - different types of rows (confusingly referred to as segments), with different numbers of columns (aka elements), mixed together - a single row type meaning something different (i.e. the columns change) based on the context and its location in the hierarchy - literally hundreds of implementations and multiple versions of the spec So essentially, this parser needs to read in the file, turn it into a meaningful and deeply-nested data structure, and then store that more sane version in a database (using Postgres, in this case). I wrote it in Rust, and the pattern matching functionality is perfect for this use case. I translated it over to Python as closely as I could, and the Rust version is well over an order of magnitude faster. Across roughly ten gigabytes and over a million files, this makes an enormous difference. Being able to fully process those in a couple hours rather than a couple days is fantastic. I’ve leveraged the Postgres JSONB datatype to store all the elements attached to each segment, given the variable number of columns by row type and variable nature of those columns by context, that’s hugely useful, and fast to query. I first store them in a `HashMap&lt;String, String&gt;` and then run it through `serde_json` before export. It’s been fun, and a great reason to use Rust at work!
All the layout optimizations can be found in this one function: https://github.com/rust-lang/rust/blob/master/src/librustc/ty/layout.rs#L906 The answer to your question should be "yes".
Thanks for the link! &gt; valid_range: 0..=(!0 &gt;&gt; (128 - bits)) Oh god the new inclusive range syntax is so ugly..=( (it's funny because that PR was my first contribution to rust \^\^)
So, will `Option&lt;Option&lt;bool&gt;&gt;` be optimized because it's a niche, or can it actually optimize recursive structures? Will `Result&lt;u32, Result&lt;u32, u32&gt;&gt;` be 8 bytes or 12 bytes?
`cargo rustc -- --pretty=expanded` will expand out the macros so you can at least see the code. That or use [the cargo expand tool](https://github.com/dtolnay/cargo-expand) someone wrote. I love macros a lot and use them extensively but it has it's problems, mainly debugging if something goes wrong. It's an even worse experience if this is your first time learning Rust which is unfortunate. Did you go to [nom's Gitter Chat](https://gitter.im/Geal/nom?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge)? Anyone who knows the macros well, including the creator (who's a real cool guy), would be able to help you out even more so. Hopefully this helps you out, and points you in the right direction!
There's also [lalrpop](https://github.com/nikomatsakis/lalrpop) an LR(1) parser (which I think works for lisp, it's been about a year since my SICP course) as well which is more structured towards grammars and languages
The enum discriminant is also considered a niche, so basically all the nested enums will only have one tag. (Yes, 8 bytes)
Yeah. This. It's uncertain whether the code below is part of your implementation or some test case. Could you throw up a gist with your code, your tests, what you expected to get and what you actually got? It'd go a long way to helping you out.
While I can't comment directly on what rustup does under WSL, I can say that under a normal Windows installation, a compiler and linker are included automatically with the toolchains that rustup downloads if you use the 'gnu' variant: C:\&gt;dir %HOMEDRIVE%%HOMEPATH%\.rustup\toolchains\nightly-x86_64-pc-windows-gnu\lib\rustlib\x86_64-pc-windows-gnu\bin 03/30/2017 01:26 AM 1,084,928 dlltool.exe 03/30/2017 02:03 AM 1,867,264 gcc.exe 03/30/2017 01:26 AM 1,451,008 ld.exe 03/30/2017 02:04 AM 52,736 libwinpthread-1.dll 
The one function is 700 lines long... Is that really the best way?
Well that is thoroughly unreadable...
Yes, on windows `rustup.exe` worked perfectly. But on WLS, I guess `curl sh.rustup ...` assumed I had a compiler toolchain installed already.
I noticed a comment mentioning `Option&lt;Option&lt;(&amp;U, &amp;T)&gt;&gt;` as a possibly unimplemented case?
I'm actually surprised at how easy to read it is - I expected to click the link and be completely unable to understand the content.
&gt; `str` is a type just like any other Yes, except it's an unsized type. &gt; it is *not* a slice. "Slices" would have methods from the built in `impl&lt;T&gt; [T]` &gt; `str` represents a sequence of UTF-8 bytes. Yes. `str` is an ordered collection of 0 or more bytes which are valid UTF-8. &gt; `str` is unsizable because it has no size information embedded into it, The correct term is "unsized" or "dynamically sized", or in Rust `!::std::marker::Sized`. "Unsizeable" is something different. &gt; `[T]` is also ~~unsizable,~~ ...unsized, because `[9u8]` and `[0u8, 68u8]` would be different values of the one type `[u8]` and they don't all have the same size. &gt; A *slice* is a **reference** to an unsizable type. No. A slice has slice methods like `len` and `first`, which are defined by the compiler for `[T]`. &gt; Then, by definition,`&amp;str` is a slice, since it is a "reference to the unsizable type" `str`. `str` is a newtype\* of [u8]. Since it's a newtype it has completely separate methods, and I wouldn't call it a "slice". I wish that books didn't either. (`[str]` isn't allowed, try it.) \* newtype: a `struct` with exactly one field The standard library almost could write `struct str { bytes: [u8] }` and implement almost all of the features. This would depend on a leap of faith that transmuting from `&amp;[u8]` to `&amp;str` does what you'd expect. The only other special feature related to `str` is the literal syntax. However, you *are* pretty close. Rust has several different kinds of pointers. And "pointer to a value of an unsized type" is one of them. It's a "fat" pointer, twice as big as `usize`, and you can think of it as an (address, length) pair, because it is. &gt; Then, by definition, `&amp;[T]` is also a slice, since it is a "reference to the unsizable type" `[T]`. It's another fat pointer. &gt; So `[T]` without `&amp;` in front is *not* a slice, since there are no **references** involved. How would you describe the sound of one hand clapping? Unsized types are very limited. They can't be the type of a local variable, an argument of a function, or the result of any r-value expression. They can *only* be a type parameter (the `str` in `&amp;str` is a type parameter of the type constructor `&amp;'_ _`) or the type of an l-value expression. Basically, it's not possible to handle the `[T]` slice "directly", there is always a pointer involved. Because of these restrictions, there are no `self` methods of `[T]`, only `&amp;self` and `&amp;mut self` methods. &gt; When a reference to an unsizable type is made, a fat pointer is used. A fat pointer is comprised of a pointer and length. Address and length, yes. There are a few other kinds of pointers. There are pointers to a sized type (`&amp;u8`), which always has a length of 1. There are pointers to functions (just an address to jump to, no size, size unknown) and pointers to "trait objects" (address of data, address of table of function pointers). &gt; The reason `&amp;str` exists as a separate type, and is not just another instance of `&amp;[u8]`, is to deal specificially with UTF-8 mechanics. Yes, precisely. You could write `struct WStr { words: [u16] }` to handle UTF-16 (CPU-endian) in normal Rust, no special help from the compiler, if you liked.
Shouldn't recursive structures be a union and also be optimized the same?
I wanted to implement it but then realized that the inner `None` only sets the first tuple field to null and leaves the other undetermined - for the other `Option` to use the second tuple field, the inner `None` would have to set it at something non-null. cc /u/Gankro 
I only read the first part, the rest makes more sense. I still struggle with the fact that the compiler is written in rust.
I *guess*. The problem I have with this is that `&amp;` is a pointer, full stop. I'm not a huge fan of giving it other names based on context, which might imply that sometimes `&amp;` isn't a pointer. I fear this promotes *magical thinking*, which tends to get people in trouble when it comes to understanding Rust. But that's just, like, my opinion, man. Also, I just woke up so I might be talking shellfish.
Exactly. I'm a beginner and it sort of seems like magic so I'm trying to dig up what's what. Coming from lower level languages where there is absolutely no magic.
What really cooks my shellfish is that it's arguably gotten *worse* over time. In the recent past, I've found it easier to downgrade to an older version of Rust to debug a macro issue because the current versions just *would not tell me* what was going wrong. But as for nom specifically, I actually tend to avoid using it because the compile-time errors can be... baffling, and I find it simpler to just write parsers by hand.
RIRAV - Rewriting in Rust avoids Vulnerability
But that's the thing: *there is no magic*. It's just a consequence of one thing that most other languages don't have (and by "most", I mean "I can't think of any other, but can't prove it doesn't exist somewhere"). In Rust, types can be "incomplete" at compile-time: the compiler doesn't have complete knowledge about them, in particular their size. That's `[T]`, `str`, and trait objects. The "missing information" must be known by *someone*, so it gets glued to the side of any pointers to values of that type. When you coerce from a "pointer to complete type" to "pointer to incomplete type", that's when the compiler takes the information from the complete type and adds it to the pointer to the resulting incomplete type. That's why going from `&amp;[T; 4]` to `&amp;[T]` causes the pointer to get larger: you're "throwing away" the length of the array at the type level, so it has to be retained in the pointer so that the compiler can still tell whether array accesses are valid or not. Something similar happens with trait objects, and even user-defined types. That's why I say this isn't magic. This behaviour is a consistently-applied generalisation of magical behaviours found in languages like D where `T[]` is a two-word pointer, but an `Interface` reference is one word because it just is.
I think its something they've intended on doing for a while, it was just hard to pull off. I remember a recent feature was _actually_ taking advantage of how Rust doesn't guarantee the order of struct members, and using that to optimise the order of members to avoid padding and reduce the overall size of the struct. In introducing that patch, there was a lot of internal restructuring of the compiler required to remove assumptions, and there were actually a fair few bugs in the compiler of uses of `mem::transmute` that assumed structs had a linear layout like C.
&gt; write parsers by hand I played with that thought for a brief moment, but decided that I don’t know enough yet. It‘s definitely on my todo list though
My approach is generally just to write lots of `(&amp;T) -&gt; Result&lt;(U, &amp;T), E&gt;` functions, which either return (parsed value, unused input) or fail, then glue them together. In fairness, that's *pretty much* all `nom` is doing. I've noticed people seem to sometimes be afraid of parsing, and I'm really not sure why. I actually find writing parsers relaxing. My problem isn't with what `nom` does, it's that the way its macros are written combined with Rust's macro system makes dealing with mistakes a pain in the backside, and I'd rather just deal with easier-to-debug regular functions.
I will try that cargo command, it‘s better that nothing. `cargo expand` tried to use the `-Z` flags, at which point I put it aside. Perhaps it has some options I missed 🤔 &gt; Gitter chat I was not aware of its existence until now...
It's so ugly, even the range syntax itself is sad about it. You can almost hear a thin, reedy whisper on the wind as you read it... ^^^*kill me...*
I'm also working on memory management for a hobby OS, but I'm at the opposite end of the spectrum when it comes to implementation -- a microkernel written in plain-old C, being written to such a standard of moving things to userspace that I'll be parsing binaries long before I can print to the framebuffer. (Currently, the project isn't available, but it'll be GPL3 if and when it hits userspace). It's an interesting idea to get rid of system calls. What interface are you going to use in replacement for interacting with hardware?
Welcome to Reddit. Before posting to a subreddit/forum/community, you should check to see what that subreddit is for. This includes reading the sidebar and the rules. You should also pay attention to warnings that you're posting to the wrong subreddit. Check /r/playrust. 
Basically, since the wasm runs in a vm, it should be safe to run in the kernel. I'll be loosely following the ideas that the Singularity OS project was based on--largely SIPs, or Software Isolated Processes (as opposed to Hardware Isolated Processes). So, instead of using interrupts, system calls will be directly exposes to the wasm vm as imports. As long as I count my 'T's and dot my 'I's, it should be safe enough.
As someone who would love to see the BEAM written in Rust, it does seem that it's actually a register based VM: http://erlang.org/doc/efficiency_guide/myths.html &gt; BEAM is a register-based virtual machine. It has 1024 virtual registers that are used for holding temporary values and for passing arguments when calling functions. Variables that need to survive a function call are saved to the stack. &gt; BEAM is a threaded-code interpreter. Each instruction is word pointing directly to executable C-code, making instruction dispatching very fast. Perhaps I'm misunderstanding something though?
Is this common enough to justify the extra syntax? Extra syntax not only makes the compiler more complex - it also complicates macro code and static analysis tools code. If you want to destruct a range, you can always use: let r = 0..10; use std::ops::Range; let Range { start, end } = r; for Range { start, end } in vec![r] { // Stuff }
&gt; For the insertion sort function, I mainly just removed unneeded temporaries. Wouldn't be surprised if there's some better way to do it overall, but that at least condenses things down a bit. My initial thoughts were to take a `&amp;mut [u8]` instead of a `&amp;mut Vec&lt;u8&gt;` as you don't need the features of the `Vec`. You could also invert the `if`, which I would say makes it a bit easier to read. You could also get a little more fancy, and replace the `while` with a `for` over a reversed range to get rid of the mutable index: pub fn insertion_sort(my_vec: &amp;mut [u8]) { for i in 1..my_vec.len() { for i in (1..i+1).rev() { if my_vec[i] &gt; my_vec[i-1] { break } my_vec.swap(i, i-1); } } } I tried to go full iterator, but ran into lifetime issues.
Well separated into different functions it'd probably still be awfully long. There's just so many cases to deal with and so many operations that can be performed on each if those cases.
I somehow didn't think of that, I suppose that's enough.
The problem is that ranges are *already* valid in patterns, but for a different purpose: match c { 0...127 =&gt; thing(), _ =&gt; other_thing(), } You can get most of the way there by adding a `Range::explode` method to turn a range into a tuple. At least then you don't have to repeat the range.
So messy things like `Result&lt;Option&lt;u8&gt;, (Option&lt;i16&gt;, String)&gt;` are super small now?
Just post your specs in /r/playrust
I mean you can't have Range&lt;Range&lt;_&gt;&gt; as far as I know, but I see your point.
I'm continuing to work on my Scheme interpreter this week. I spent last week fixing some bugs that I found and cleaning up the source. This week I'm planning to add support for more types such as floats and vectors. I intend to turn this into a bytecode interpreter, so I'll be thinking about that as well.
&gt; I still struggle with the fact that the compiler is written in rust. Why? Because of the bootstrapping problem? 
&gt; People would have to care about security as a primary goal of software I'm not sure this is a given. There are reasons to use memory safe languages besides security. Most code being written today is probably in a memory safe language whether it be Java or C# or Python or whatever. I don't think it's farfetched to claim that programmers generally prefer memory safety. It makes debugging much easier 
That, and the whole compiler poisoning thing. Scary stuff.
&gt; compiler poisoning I've never heard of this. Are you referring to a Trusting Trust attack?
Now that I think about it, I'm not sure recursive enums can be optimized. Consider this: https://play.rust-lang.org/?gist=0bd4f3db46905086b7663a30cffa3a73&amp;version=stable #[derive(Debug)] enum Foo { A(u32), B(u32), } #[derive(Debug)] enum Bar { X(Foo), Y(Foo), } for mut bar in vec![Bar::X(Foo::A(1)), Bar::Y(Foo::A(1))] { { let foo = match bar { Bar::X(ref mut foo) =&gt; foo, Bar::Y(ref mut foo) =&gt; foo, }; *foo = Foo::B(2); } println!("{:?}", bar); } `Foo` is obviously 8 bytes, but if `Bar` is also optimized to be 8 bytes - how will borrowing work? Most notably - how will `*foo = Foo::B(2)` write the 8 bytes that are `Foo::B(2)` and still preserve the branch of `Bar`? I can think of 3 options: 1. Only optimize for dataless branches by finding values impossible for the branch with data. 2. Only optimize when there is just one branch that has an enum. That branch will get it's natural tag values so that borrowing it will work. The other branches won't need the tag when being borrowed. This means `Result&lt;u32, Result&lt;u32, u32&gt;&gt;` can be optimized to 8 bytes but my `Bar` will have to be 12 bytes. 3. Use different bits for the different level of the enum recursion, and **always** use a mask when reading/writing the tag. Looking at the PR again, I think it's #1. #2 is doable - but the comment in the PR talks about "data-less variants" so I don't think it's it. #3 will make all enum operations slower - so I seriously doubt it'll ever be implemented.
yep
Oh, I've actually been writing a Forth VM in Rust recently. I should take a look and see if I can use this
Man, thanks for the work ! I ended up using the [simple version](https://play.rust-lang.org/?gist=0cf35d7811ac08650072cd35e6ea8004&amp;version=undefined) with the [unreachable crate](https://docs.rs/unreachable/0.1.1/unreachable/trait.UncheckedOptionExt.html) for unwrap, but your version actually taught me a few rust hacks I might use later. 
If you want to read more about this, read [Optimizing Rust Struct Size: A 6-month Compiler Development Project](http://camlorn.net/posts/April%202017/rust-struct-field-reordering.html).
You forgot to remove the newline I believe.
I believe I trim()ed it.
In the link you shared it doesn't look like you did for your 'convention' variable.
Look again.
You can't do niche-based optimizations when different payloads can have the same bit-pattern. Even `Result&lt;bool, bool&gt;` can't be optimized.
My mistake. Although, I can't figure out where to put the trim.
It doesn't really matter so long as it goes somewhere between reading from stdin and examining the value. Simplest way is to just toss in an extra `let convention = convention.trim();`.
Ah, I was missing the let. Thank you. This has been a complicated endeavor so far.
As someone who just submitted a patch to add a new repr to it with only 20 lines of code, I think it's great. (Also note that there's actually several functions declared inline)
But it doesn't matter what programmers prefer, what matters is what the people paying them want. If the employer has an existing codebase in C/C++ there is no way that they'll happily accept that the new guy wants to rewrite it in a memory safe language and they'll be paying for "nothing" for how ever many months a rewrite takes. Further, even if a company okays the rewrite, they open themselves up to litigation in the case that something happens before the rewrite is finished. It's an admission of guilt, they knew there was a flaw in their code (otherwise why touch it?) but continued to allow it to be used. If society at large starts demanding real security attempts be made, and the penalties for breaches that could have been prevented start to outweigh the cost of proactive security, then we'll see unsafe languages die off extremely quickly. It would put the waiting time from decades to years, maybe even months. Unfortunately, most of the people I talk to that aren't programmers seem to want to put the blame on the people doing the hacking. While yeah the hacking is bad and it would be nice if people didn't do that, many of the breaches wouldn't have happened if companies were following even rudimentary security practices. The public at large isn't putting the blame on the company, the public isn't putting pressure on companies to do better, the public isn't demanding that there be some sort of mandatory code/security audit, and so the companies have no reason to be better. It's literally less expensive and risky for the company to be breached and deal with the consequences when it happens than it is for them to pay people to make sure the breach never happens in the first place. Until that changes I don't see any effort to replace C/C++ succeeding on a grand scale.
Looks interesting. Given how I'm working on my own compiler and have been rather excited about LLVM, I'm already thinking of ways to abuse this to compile rather than interpret.
&gt; Result&lt;Option&lt;u8&gt;, (String, Option&lt;i16&gt;)&gt; You can try it yourself: https://play.rust-lang.org/?gist=24dab20c983834e5404211b4da258c1d&amp;version=nightly It shows 40 in both stable and nightly.
AWESOME
Hm, yeah I was one of the main champions in arguing for that syntax and it definitely didn't come out like I was hoping. I'm also not really sure what to do about that at this point.
The IRC channels are great if you need help: https://www.rust-lang.org/en-US/community.html
You have to switch to nightly. The core team decided that macro debugging is a niche feature that isn't worth enabling on stable.
Linux package systems are such a wild mess that there isn't really a good way to handle this by default reasonably that isn't going to fail on some system or another. It's also worth mentioning C compilers are only necessary if the underlying library you're compiling is using C in some way.
No, it looks as though I misunderstood :)
LLVM is pretty great. I started out trying to target that directly as well, but wound up struggling too much with rust-interop. I decided that getting to a point where I could run code was more important in the short time and once the rest of the language has settled then I can look at targeting LLVM from the compiler.
This is really neat. Any numbers on how it affects a large piece of software such as Servo? I don't know exactly what I'm looking for: anything like x% of struct definitions shrunk by at least y bytes, overall memory usage in some benchmark down x%, cpu usage (due to improved CPU cache efficiency) down x%, etc.
This flag requires nightly now.
&gt; It's also worth mentioning C compilers are only necessary if the underlying library you're compiling is using C in some way. Unfortunately, not quite. Rust's `libstd` depends on `libc` and doesn't yet have its own facility for doing the final linking step.
Oh thanks for the correction!
You could (in principle) do a time-space tradeoff though - if you flatten the above enums into a single enum, it's possible to copy into a temporary for a borrow. In the case of a mutable borrow, you'd have to copy back and adjust the tag accordingly. This only works if there isn't an UnsafeCell anywhere inside, however..
I may finally be able to implement fuzz tests within Ion now.
Wow, that is one hell of a demo. This is great work.
I don't think so. The optimization works by utilizing invalid values (0 for references, for example), and I don't see any option for invalid values in what you suggested: u8 is "valid" along the entirety of its range, so Option&lt;u8&gt; must have an added tag. Same for i16. IIRC String can have all three of its fields as zero (empty string with no allocation), and any other value is valid. Result must have a tag to differentiate.
Even without UnsafeCell, that runs into trouble with code like ```rust fn get_field_ref(x: &amp;mut Enum) -&gt; &amp;mut bool { match x { Enum::One(ref mut field) =&gt; field, _ =&gt; panic!() } } ``` But it could work as an opt-in attribute on a struct/enum that had the side effect of changing the behavior of taking references to fields of that type.
To be fair, idiomatic go elides the trailing else, so `indent_level++` isn’t entirely an accurate representation of the language, although I can’t agree more with your other complaints about its error handing. 
Using nightly (features `inclusive_range_syntax` and `slice_rotate`): pub fn insertion_sort(my_vec: &amp;mut Vec&lt;u8&gt;) { for i in 1..my_vec.len() { let m = my_vec[..i].upper_bound(&amp;my_vec[i]); &amp;mut my_vec[m..=i].rotate(i - m); } } Unfortunately `std` doesn't have an `upper_bound` yet. ;-[ IIUC it is expected to in the future, with the same interface as that of [ordslice](https://crates.io/crates/ordslice), which is what I tested with.
I would expect that many property types in Servo can now be inlined into PropertyDeclaration type rather than needing to use box. But whoever upgrading the Rust Servo uses would know exactly, since they would need to fight with our sizeof unit test :P
Care to explain what you're doing? It's all new to me!
No, it's not huge. It's smaller! :v
Thanks.
In principle, that can be resolved with a more complex return calling convention, but that starts getting very expensive (particularly when you consider that get_field_ref might be an impl invoked via a trait object). I suppose this is only really applicable if rustc can determine (by whole-program analysis) that situations like this don't come up in a non-inlineable context.
I'm not really sure what to tell you other than to link to the docs: - [`upper_bound`](https://docs.rs/ordslice/0.1.0/ordslice/trait.Ext.html#tymethod.upper_bound) - [`rotate`](https://doc.rust-lang.org/nightly/std/primitive.slice.html#method.rotate) [Adding some debugging output](https://play.rust-lang.org/?gist=911ec18e89245abf236f945f4eaab436&amp;version=nightly&amp;mode=release) should make things clear. :-]
Thanks a lot for the clarification :)
Just went there but since it's late I'll ask you since you seem knowledgeable and I don't want to start a new thread. Is Rust supported by the Hyper shell (Windows 10)? Cygwin tells me Rust is installed fine, yet Hyper tells me rustc doesn't exist.
This is pretty awesome, I only just started rust and have too thought about making a new status bar for my i3 setup. Nice work!
I don't develop on Windows but I wonder if the hyper shell can interact with Cygwin. I'd have to look into it more, sorry!
I don't develop on Windows but I wonder if the hyper shell can interact with Cygwin. I'd have to look into it more, sorry!
I know more than a few people in Aerospace who are interested in Rust. Unfortunately without GCC or GCC's target range, it will never break in.
How does this work together with unpacking pattern matching? Say match x { &amp;mut Ok(ref mut y) =&gt; do_something_with(y), where `y` also has an enum type? Previously it could just increment the pointer past the discriminant to find a complete `y` value. Now I guess it has to create a `y` on the stack somewhere, with its own discriminant, and take a reference to that. And then of course copy the changes back into `x` after the match arm has executed. Is this always an optimization? 
We specifically are not allowed to do that by the language's operational semantics, try figuring out what you'd need to do to handle `.as_ref().unwrap()`, for example. All optimizations rely on field representations being unmodified, and only *already invalid* values in those fields being reused to store information.
What kind of errors can one expect fuzzing a binary of a Rust program only using safe features?
After more troubles I gave up and used features. I guess Rust really didn't want me to do this shit.
Eh, it looks fine when the right-hand side is a number rather than an expression, or when being used in a `for` loop so that the context is obvious. Overall I think the answer is just "continue to use the normal range syntax". And even this is still better than `...`. :P
Panics on overflow
Why isn't web assembly implemented similar to [Forth](https://forth-standard.org/) / [Factor](https://factorcode.org/) (concatenative languages) but instead uses java bytecode approach?
Ah, makes sense. Thanks.
Can confirm, used cargo fuzz on one of my projects (which is libfuzzer based) and found a panic in one of my dependencies that could be triggered over the network. In theory one could also find other bugs in poorly written unsafe code.
Ok, I see, that makes sense. I overestimated what this change actually did. As long as it always keeps valid representations of all values, then there is obviously no run-time overhead involved. 
The docs for std::mem::zeroed say: &gt; There is no guarantee that an all-zero byte-pattern represents a valid value of some type T Is it possible and useful to add to the language/stdlib something that tells statically if an all-zero byte-pattern represents a valid value for the given type T?
&gt; The core team decided that macro debugging is a niche, rarely-used feature that isn't worth supporting on stable LOL. I have never seen a compiler requiring one to switch to unstable for debugging user code, and I have seen a lot of compilers. The language has macros, so the compiler should be able to print the expanded macros. What is even unstable about doing that? &gt; add [...] at the top of your crate Compiler devs hate this trick. Sound good, thank you
Awesome timing, I just decided that I'd want to setup some fuzzing.
The trophy case also lists arithmetic overflow, logic bugs, infinite loops, unwrap, utf-8 errors and "other". I don't know what those logic bugs and "other" encompass, but I think the rest of them can also occur in safe rust.
I'd point out what you've done wrong, but I already did that eight hours ago.
you're not good at reddit are you :p
You could also just send an &amp;ref to all functions as one of the parameters, depending on the complexity of your program.
I would really rethink that. What's the harm in having a mirror on Github? It helps you get exposure, as the Gitlab UI is quite off putting.
You don't need the 'let' if your variable is already mutable.
Afaik, cygwin uses a different set of env variables than the rest of windows does. You might have to look at cygwin's $PATH to check where it is searching for rust, then update windows' %PATH% so it can also find rust's binaries. That might or might not be more painful than that, and you might find it's easier to just use rust's .msi installer instead.
does it come in red? can I get fries with it?
I'm missing something, how can it work by storing the tag inside b?
Basically, if the struct has an invalid state then it cannot be Some(Struct). `b` is a bool, it can be either false (0) or true (1), so we can use all the remaining values as the tag. Then in Option&lt;S&gt;, we check the value stored at the memory position of `b`. If its 0 or 1, then the variant is Some(S), if b is for example 2, then it's None.
What about references? At least on Windows, the first 64 KiB of memory are reserved and could be used to optimize `Option&lt;Option&lt;&amp;T&gt;&gt;` to a single pointer.
Yeah, that's calculating the length by iterating.
I'm not sure what distinction you're drawing, exactly. Could you say a bit more please?
It's that the WSL is linux, not windows, so you're not using the gnu triple, but the linux one.
&gt; The language has macros, so the compiler should be able to print the expanded macros. The existing macro system is basically going to be wholesale deprecated, so investing more time in it doesn't make sense. &gt; What is even unstable about doing that? Every thing we add to stable Rust must be around *forever*. For stuff like this, that includes stable output formats, etc.
Pointers to Zero Sized Types are pointing to 0x1, so that's not a valid optimization even on Windows.
&gt; IIRC String can have all three of its fields as zero (empty string with no allocation), and any other value is valid. No, `String` and `Vec` can't have a null pointer (and neither can any safe reference/allocation in Rust, we use arbitrary non-zero integer addresses for zero-sized allocations), so `Option&lt;String&gt;` is the same size as `String` - however, `Result&lt;Option&lt;u8&gt;, (String, Option&lt;i16&gt;)&gt;` isn't optimized yet, and you could only remove `Result`'s tag.
Hm? Sometimes "&amp;" is a trait object, not a pointer. Even `*mut` can be a raw trait object, which is arguably not a (simple) pointer. Now, you could introduce terminology like "fat pointers", but suddenly, you're back at "how are things encoded"? I am also not a fan of different names in different contexts, though, which is why I strictly teach `&amp;` as "borrows". The encoding of those borrow may vary, the rules stay the same.
You might find crates `pathfinding` and `permutohedron`useful for day 24. I started writing the former precisely when writing solutions for the advent of code last year, and I was happy to find the latter.
I would say that `&amp;` is still a pointer; in `&amp;Trait`, `Trait` is the trait object type. All pointers have an "erased information" field... it's just that for sized types, that field is zero-sized since there's no erased information. Hmm? Yes, I'm familiar with the idea of Stockholm Syndrome; why do you ask?
Good job! It looks like it even allows optimizations of `enum MagicAndDreams&lt;A: u8, B: u8&gt; where A &lt; 100, B &gt;= 100 {Small(A), Big(B)}` And I only need to wait 3-5 years for it.
link to the trophy case: https://github.com/rust-fuzz/trophy-case
&gt; The existing macro system is basically going to be wholesale deprecated Point taken. However, the flag was there already. Wouldn’t a deprecation warning have sufficed for the time being? I mean, in this thread alone are multiple persons that are unhappy with the current state and one even mentioned downgrading the compiler to get the functionality back *in a reliable way*. That should be a red flag for the compiler team IMO. &gt; For stuff like this, that includes stable output formats, etc. It only needs to output Rust code, or am I oversimplifying? Because Rust code would be as stable as output can get. I also find the *it must be around forever* mentality interesting, because I think at some point you need to deprecate and remove things if you want to avoid C++-like bloat. The feature also has already been in stable, so removing it for this reason seems a bit... let’s call it counterintuitive ;) Now I don’t want to complain all day, so here is a thought I have: Would it be possible to write a function/macro similar to Common Lisp‘s `macroexpand`, just that it produces a string at compile time which one could then print out? That would be the most basic form of debugging, and it could disappear together with macros when they get thrown out (presumably in Rust 2.0?).
&gt; Wouldn’t a deprecation warning have sufficed for the time being? It doesn't. We accidentally left a number of unstable things like this stable by accident, and even with months of lead time, people were mad when we made them unstable again. &gt; It only needs to output Rust code, or am I oversimplifying? Yeah I'm speaking about several of the debugging flags more generally, not this specific one. &gt; Would it be possible I am terrible at macros so I have no idea.
I recently noticed the unstable nightly placement syntax. ```&lt;-``` What does it do and what advantages does it have over the current way of doing things?
&gt; people were mad when we made them unstable again Well you deprecated a valuable tool for a legitimate, but more philosophical reason without offering a replacement. I can see how someone would be mad about that. &gt; generally, not this specific one Which is another reason for people to get annoyed - it would have been a matter of calling it `--expand-macros` from their perspective. Anyway, it’s gone now and `std::stringify`looks like a good place to start for `macroexpand`, so I will probably look into that. Thank you for your time :)
&gt;I'm going to use Rust and make better software, and because it's better my software will overtake software written in these other languages as a virtue of the free market. If only it was this easy then we'd have only or at least mostly good software. Unfortunately that isn't the case.
Oh, from zero to (zero sized)type erasure in 1 post! Well played, sir :)!
Ah, cool. How can you remove result's tag in this case? Use string as tag?
thanks! first time using [asciinema](https://asciinema.org/), highly recommend
The behaviour you are searching for is the one that /u/NebulaJ describes. The Box grows because of its internal data. `*const T` `*mut T` and `&amp;(mut) T` are trait objects when `?Sized`. AFAIK, the nomicon doesn't cover trait objects, that would be a good addition to the data layout part.
hadn't seen ion before, cool project! and yeah [this](https://github.com/redox-os/ion/blob/f708dd671d0c1a287f496fc990a0693bf9103cf5/src/parser/statement/parse.rs#L23) might be a good candidate 👍
If one day `Cow&lt;str&gt;` will be three words like`String` (ref: https://github.com/rust-lang/rfcs/issues/1230#issuecomment-345957691 ), I wonder if we should, as an ecosystem, push towards `Cow&lt;str&gt;` a lot more than what we currently do – and possibly sugar `Cow&lt;str&gt;` more. Also, would it be possible to have an optimization that would align the pointer and length parts of the `String` and `&amp;str` variants to prevent branching when the string is used in a read-only way?
This is great, thanks! I ran this on the `rmpv::decode::value::read_value` function (with memory limit set to 4 GiB and timeout set to 4s). It quickly found hundreds of "crashes" which I could not replicate. I noticed that some of the examples were really slow though (especially in debug mode!) [and created an issue](https://github.com/3Hren/msgpack-rust/issues/151). But do you have any idea why I can't replicate the crash? Is there a way to get more details from afl about the "crashes"?
But in Rust the months are an enum. You just assign numeric values to each variant. I think things like `Vec::new()` make sense, but not in a lot of other cases. I would consider too many constructors to be a code smell.
&gt; must have discord deal-breaker
&gt; The existing macro system is basically going to be wholesale deprecated (...) I've been hearing this repeated like a mantra for almost two years now. At this point, this "pre-deprecation" seems to be little more than an excuse not to support important language feature that the entire ecosystem relies on (if only for `lazy_static`) without having to offer a replacement. Sorry, but you can't have the cake and eat it. Macros are either a fully legitimate language feature -- in which case they need proper support -- or a deprecated one that's on its way out. Trying to put them in this special limbo state is only causing grief to users when the feature inevitably starts to rot due to neglect (as several other comments pointed out) rather than being consciously phased out.
Yeah, we only do IRC here.
It's been actively worked on for that whole time, and has made a ton of progress. It's not an easy problem.
I spent ages trying to figure out a problem with some macros I was writing, so I too would like better debugging output there.
I re-purposed my A* implementation from day 13 into a crate, and have started using that. I don't think I knew we had a pathfinding crate! I have definitely implemented a few mish mashes of BFS in these challenges as well. permutohedron is one i've used before, for 2015 I think. I was going to grab that to give me the list of options, then find the minimum.
&gt; it is what it is. Well, hopefully that's not totally true and at some point it will be what it now isn't!
&gt; My approach is generally just to write lots of `(&amp;T) -&gt; Result&lt;(U, &amp;T), E&gt;` functions, which either return (parsed value, unused input) or fail, then glue them together. You are not alone!
what's memory usage like during that "2min 47s in debug mode"?
[removed]
This is putting lipstick on a pig. JSON is a bad API data format. Use protocol buffers.
&gt; My intent is to only allow WebAssembly to run Yesssssssss I've been wanting to hack this together too.
It allows you to place data at some location without copying. With release builds, many copies are elided by the compiler, but you cannot rely on this in general. So placement allows initialization of structures larger than the process stack.
If I can operate `htop` correctly, steadily increasing to a few gigabytes :) Probably some loop allocating data? (Also, 100% CPU usage during that time.)
Is there any reason to use it rather than just using .expect() directly on the option? Or is it irrelevant which one is used? 
Sweet! Feel free to give me a hand then! I'll be stuck working on the memory allocator for the next week or so, but after that, the following need to be done 1. Interrupts (for keyboard and scheduling) 2. Basic Process and Thread datatypes (no userland though) 3. wasm integration!
Thanks for your insightful post. I've drafted another summary based on your changes. One thing that still boggles my mind, and on which you've commented already, is the term slices. I've adapted my definition somewhat, and I was wondering if the points made below are technically correct now. ## Fixed-Sized Arrays - `[T; size]` - a collection of objects of the same type `T`, stored in contiguous memory - their size is known at compile time - arrays are allocated on the stack (see note on inline/outline vs stack/heap) ​ ## Unsized Array - `[T]` - an *unsized* collection of objects of the same type `T`, stored in contiguous memory - size not known at compile time - not really useful on its own ## Slices - A slice is just a view into contiguous memory space - This slice of contiguous memory space could be that of an array, a Vec, a *str*, etc. - A slice in and of itself is not useful. It does not contain any sizing information. To be really useful, slices of memory need to be accessed with pointers. Fat pointers. NOTE: Unsized types are very limited. They can't be the type of a local variable, an argument of a function, or the result of any r-value expression. They can *only* be a type parameter (the `str` in `&amp;str` is a type parameter of the type constructor `&amp;'_ _`) or the type of an l-value expression. Because of these restrictions, there are no `self` methods of `[T]`, only `&amp;self` and `&amp;mut self` methods. - Slices are represented as `[T]`. - `[T]` really means a sequence of `T` elements, like `myarray[1..10]`, where [1..10] could represent a series of 10 elements of type *u8*. - That "slice of memory", represented by `myarray[1..10]`, has no embedded sizing information. - Slices have methods from the built in `impl&lt;T&gt; [T]` ​ ## `str` - mistakenly called string slices - are not really slices - `str` is a type like any other, but is unsized. - `str` is an ordered collection of 0 or more bytes which are valid UTF-8 - `str` is similar to [u8] but with extra mechanics to deal with UTF-8 complexity - `str` is actually a newtype, a *struct* with one field, similar to `struct str { bytes: [u8] }` - `[str]` is not allowed - it's possible to get a slice of a `str` ​ ## Fat Pointers - contains an address and length pair - used by slices (slices of arrays, Vec, str) and traits - the size of a fat pointer is known at compile time ## Other Pointers - pointers to sized type (&amp;u8) which always have a length of 1 - pointers to functions (just an address to jump to, no size, size unknown) - pointers to "trait objects" (address of data, address of table of function pointers) 
Oh, doesn't `thing4` go out of scope after the if-else statement?
Use `Option`'s tag for the `Result`, and store the entire `Ok` data inside `String`'s spot?
Sadly, I've been meaning to do it for about a month, but have had no free time; I'll mostly be cheering you on from the sideline. Is there a repo available anywhere?
With a feature this big, how do you isolate it's changes when you want to move it from nightly to stable, or move other features that assume the new layout this code?
Yep! [Here](https://github.com/EuclidOS) 
&gt; people were mad when we made them unstable again. Speaking only for myself, I wouldn't have been mad if there were any replacement at the end of the deprecation period. From my perspective, the process was (1) ask if anyone is using these features, (2) ignore answers and deprecate them anyway.
We don't really "move" things from nightly to stable. The compiler follows the [train model](https://blog.rust-lang.org/2014/10/30/Stability.html), so nightly simply turns into beta which turns into stable (after fixing regressions).
More information (for the lazy): Leven is yet another static blog generator, with posts written in Markdown, but: - There’s no frontmatter to mess with. - It’s fast, and compiles your blog posts in parallel. - It’s simple, with almost zero configuration. And here's an [example website](https://quadrupleslap.github.io).
 for r in vec![r] { } This literally does nothing useful. You're packaging a single value up into a vector, then immediately unpacking it into an identifier of the same name as it originally was. Don't do this.
[Yeah, let's hope](https://imgur.com/a/W7Ke7)
I've wanted to start blogging for a while now, this looks pretty much perfect for me. Because I'm lazy, what's the typical process after `leven new my-amazing-blog`?
0. Set a theme (e.g. `leven theme sidney-pham/amazing-theme`). 1. Write your post in Markdown. 2. Save it in `content` with a human-readable title. 3. `leven build` 4. Publish the static files in `out`.
There is no "safe" way to do this. An ugly workaround could be passing `(Arc&lt;struct&gt;, Vec&lt;ComputeResult&lt;'static&gt;&gt;)`, and then changing the lifetime back.
It's an exemple of iteration over a vector of ranges. It's not meant to be useful.
In this particular case you're right, yes. 
ok, that makes more sense.
It does, but this pattern is more idiomatic: ``` thing4, err := thing3.fooOrPhooey() if err != nil { return nil, err } // do stuff w/thing4 ```
Not true. https://discord.me/rust-lang (yes, we do get rust players even with a bot who kicks you if you say you're there for the game at join time) 
That or use the pointer inside the `String`.
/u/ebfeebfe to provide a rough sketch of what /u/Wolvereness is talking about, I've put together an example here: https://play.rust-lang.org/?gist=05f412e8f902f976dba5380dcc9d4e37&amp;version=stable It doesn't change the lifetime back to what it should be, though, so keep in mind that this is dangerous stuff. `transmute` is a weapon of last resort. I think you would be better off accepting some copying until you prove that you need better performance. Simple bitcopies of structs are generally cheap, especially compared to a long computation. If you used `mpsc`, you could even collect the results as they're computed, dedicating a thread to building the `Vec` from results that it receives, potentially.
That makes sense, but do features ever get held back from moving from nightly to beta?
Why don't you do `fn long_computation(&amp;self) -&gt; Vec&lt;ComputeResult&gt;` where `ComputeResult` holds the original data through an Arc as well. You need to clone, but you only need to clone the Arc.
Yeah, with feature flags we can require an opt-in to enable something, and only nightly compilers accept the opt-in. This change doesn't look like it was done that was (though it was exhaustively tested with all the open-source rust code we have access to), but it could have been because as noted in another comment, all the changes are actually localized to one function!
You can do this using crossbeam if you [spawn the threads from within a scope](https://docs.rs/crossbeam/0.3.0/crossbeam/struct.Scope.html#method.spawn), and the data is owned by the parent thread. Crossbeam scopes allow you to have threads which contain references to their spawning threads, by guaranteeing that the spawning thread will outlive the children. The other option is to not have a `fn long_computation(&amp;'a self) -&gt; Vec&lt;ComputeResult&lt;'a&gt;&gt;`, but instead a `fn long_computation(self: Arc&lt;Struct&gt;) -&gt; Vec&lt;ComputeResult&gt;` where `ComputeResult` contains an `Arc&lt;Struct&gt;` rather than an `&amp;'a struct`. Then each result will be an owning reference, rather than a borrowed reference. I think you'll need to do this in a trait because you can't have an inherent impl on `Arc&lt;Self&gt;`.
&gt; // size 5, alignment 4 I think currently in Rust size can only be a multiple of alignment. So in this case, size of `S1` would be 8 bytes. If you'd put `#[repr(packed)]` on `S1` then it would have size=5, alignment=1. To make it possible to have size not multiple of alignment, you'd need to have two concepts of *size* – like `sizeof` and `strideof` in Swift. It would be backward incompatible to do it in Rust though.
I want to use unquoted strings in macro's, it this possible? macro!(p,q,r) generates a vec!["p","q","r"] 
Similarly, maybe write out to https://github.com/stoklund/cretonne/ IR and get AOT or JIT built in.
Mentioned this in another comment here, but you might be interested in https://github.com/stoklund/cretonne/
Is there a description somewhere of the [labels used in the Rust project](https://github.com/rust-lang/rust/labels) ? Especially the initial letter, there's a structure I don't get.
You haven't worked with commercial web services very much have you? Asking another company to change their web service format is typically ill advised and oftentimes downright refused due to business reasons. JSON is something we'll be interfacing with for a while. Best have ways to use it in Rust. 
`crossbeam::Scope` seems exactly what I was looking for, thanks. 
Oh, I've seen that a lot and was browsing it after seeing this. My one problem is that there's no documentation of the Rust API, if it even has one.
&gt; Asking another company to change their web service format is typically ill advised and oftentimes downright refused due to business reasons. This is about building json API's. Not using someone else's. &gt; JSON is something we'll be interfacing with for a while. Best have ways to use it in Rust. And we do. Serde does a fine job. 
Oops! You're right. Fixed. Not sure how we can get the memory layout optimised for S2 though without using `#[repr(packed)]` on `S1`...
Maybe my example is not the best. All I'm trying to get at is that the algorithm doesn't seem to be optimal when you have nested structs. Also, I'm not really sure how to mentally model what exactly the end result is when the memory layout is optimised.
&gt; This is about building JSON APIs True, my bad I need to read things more carefully. Still it's not implausible someone could need to build a JSON web service. &gt; Serde does a fine job. While I generally agree with that, this seems to take the concept a step further and also provide the framework for hosting and versioning the service itself.
Though at that point, you might not need the `Arc` at all. A shared reference by itself will end up with the same lifetime constraints I think.
&gt; E.g. does the layout for S1 inside S2 have to be the same as S2? Yes, it has to. The reason for that is you can obtain `&amp;mut S1` from `S2`, which has behave as a regular `&amp;mut S1`. Consider this code: fn write_s1(s1: &amp;mut S1) { s1.x = 1; s1.y = 2; } Compiler can optimize this to a single 8-byte write. So if your `S1` is inside of your `S2`, the call to `write_s1` must not destroy other `S1` fields: let mut s2 = S2 { a: S1 { ... }, b: 5, c: 6 }; write_s1(&amp;mut s2.a); // Now, if S2 layout was eg. `a a a a a c b b`, c and b fields would be overwritten
The compiler could keep track of where the `S1` came from but I realise that could get out of hand pretty quickly.
Actually, it's both. The generated data models are usable both for serialization and deserialization in a number of languages. It doesn't specify what you should do with them. Sorry for the confusion. :)
This looks really awesome, particularly because of the central repository and enforced semantic versioning. Taking this idea further, I could see API endpoints and authentication schemes being optionally defined in the `*.reproto` file, and having `reproto` generate functions to connect to those endpoints and return the parsed objects directly, taking whatever parameters are needed to communicate with that endpoint.
Is there a recursive RWLock?
What makes JSON a bad API data format? It's more space-efficient than XML, but it's also more human-readable than Protocol Buffers. Also, why would you pick protobuf over CapnProto or flatbuffers or Thrift or MsgPack? Simply saying "use protobuf" doesn't exactly make a compelling argument. Generally, I like [msgpack](https://msgpack.org/index.html) the best out of the alternatives to JSON that I've seen as a general purpose format. For specialized purposes, the others each have their advantages and disadvantages..
I don't find this a very useful way to open discourse here. Everyone dislikes one or the other approach, but this forum is mainly for showing work and implementations. If everyone goes around and just complains that projects implement something they don't like (and not much more), people will enjoy showing their projects much less. If you want to give feedback because you feel that the approach is problematic, at least make an effort to give detailed criticism.
Thank you for the answer.
So, I have a struct that needs to iterate over the characters of a string. Here's a simplified version of what I'm trying to do: use std::io; use std::io::Read; use std::str::Chars; struct Parser { s: String, s_iter: Chars, } impl Parser { fn new&lt;R: Read&gt;(mut input_stream: R) -&gt; io::Result&lt;Parser&gt; { let mut s = String::new(); input_stream.read_to_string(&amp;mut s)?; let s_iter = s.chars(); Ok(Parser { s, s_iter }) } fn next_char(&amp;mut self) -&gt; Option&lt;char&gt; { self.s_iter.next() } } This, of course, doesn't compile on its own because Chars needs a lifetime. It looks like the [rental crate](https://crates.io/crates/rental) might be what I need, but I'm wondering if there's a better way to do what I'm trying to do? I have no reason to keep the String around other than that it's borrowed by s_iter.
https://github.com/rust-lang/rust/blob/master/CONTRIBUTING.md#issue-triage
Could you add something like this to the Readme.md? It's lacking a bit of docs at the moment :)
Ah I should have written "dependencies **on** a crate" not "dependencies **of** a crate". Anyway here is another interesting graph beyond the ones in the readme: [Fraction of crates.io that depends directly on libc](https://user-images.githubusercontent.com/1940490/33086189-c371f806-ce9b-11e7-9c10-47247ba742bd.png).
What other language could it be written to mitigate the trusting trust attack?
Are indexes automatically generated?
I'm a little annoyed with statements of the kind "Rust will not break into X without tooling Y", where X is usually one of "automotive", "medical", "trains" or "aviation". Rust is barely more then 2 years old. People already taking notice is _a huge thing_ and one of our main advantages. Targets and toolchains are fixable given enough time and effort. Replacing toolchains is also possible, especially when you are targeting newly written software, not old ones. It's a huge pile of work and needs time, but it isn't as unsurmountable as people make it seem. Having a dedicated group of people with huge interest is the biggest thing you need! And no, we don't need GCCs target range, we need _the target enterprises target range_, one at a time. 
* Json is not statically typed because JS is not. Once you are over a 32bit signed integer it will start writing numbers as doubles. So you can be getting integers like you thought for some time, then everything breaks if your backend is in a statically typed language. * There is no schema. Any change to your API can break your backends extremely easily. Backwards or forwards compatibility is extremely difficult to maintain across languages. * No native binary format. * There is no schema. So there is no real spec for your API. Yes there are 10 different ways of specifiying a Json schema like this one. But this is lipstick on a pig. No one is holding your developers accountable for sticking to it. &gt; Also, why would you pick protobuf over CapnProto Not remotely as widely used or well maintained. &gt; or flatbuffers Not as much cross platform support. &gt; or Thrift It's okay. Tied to a RPC mechanism and protocol and the protocol implementations across languages is inconsistent. Only java and maybe c++ really supports everything. &gt; or MsgPack? No schema. 
This sounds cool. But one has to wonder, how far it is possible (or reasonable) to go. There are unused bits all over the place ‒ most pointers are aligned, having several unused bits in them. One could define range types (eg not u8, but 0..15 ‒ which would need only 4 bits). If there's `[Enum, 4]`, the enums could pool their tags into the same place, avoiding paddings inside. But many things would then need shifting/masking stuff around at runtime, which would probably make it slower… and letting the compiler guess if it's „hot“ data structure that is accessed a lot, or „cold“ data storage not accessed often, but in large amounts (or even having both present and converted behind the scene) is probably completely crazy.
Thanks! I've been putting some thought into how to support services, there is currently a working prototype for Java and gRPC: https://github.com/reproto/reproto/blob/master/doc/spec.md#services As mentioned in the spec, suporting arbitrary HTTP endpoints is _hard_. I'd love some feedback or inspiration on that. For now, I'll just keep punting it for more constrained solutions like gRPC.
Instruction count can not be used to measure execution speed. For example function inlining and loop unrolling both normally make a program larger and they can make it faster.
&gt; The reason for that is you can obtain `&amp;mut S1` from `S2`, which has behave as a regular `&amp;mut S1`. I would note that this is not THAT obvious, actually. Each field has to be at the same offset, and occupy the same amount of bytes, however it should in theory be possible to reuse the *padding* within `S1` to stuff bytes from `S2`. In C++, for example, it is legitimate for a Derived class to stuff fields in the trailing padding bytes of its Base class. I remember the discussion about reusing padding in Rust occurred, and there was concern that `unsafe` code may have been written with the assumption that one could `memcpy` the whole `sizeof(T)`, including padding bytes. Swift solved this issue by having `sizeof(T)` NOT include the trailing padding bytes, but as you noted this would be a breaking change too. Therefore, this is not so much that it's impossible in Rust, and more than people dread breaking `unsafe` code.
&gt; There is no schema. So there is no real spec for your API. Yes there are 10 different ways of specifiying a Json schema like this one. But this is lipstick on a pig. No one is holding your developers accountable for sticking to it. If you look closely at this project, it's more than just providing a schema, but the schema-part *is* enforced, if you're using `reproto` for your project. `reproto` generates the structs and (de)serialization for them in the language you're using. In Rust, that means you can't stuff a String into an integer field and so-forth. It is *not* lipstick on a pig, as much as you love repeating that phrase. If the schema is defined in `protobuf`, but then someone modifies the `protobuf` schema for their own project, they can generate erroneous `protobuf` messages just as easily as they can do here with `reproto`. &gt; Not remotely as widely used or well maintained. CapnProto is not well maintained? That's news to me. How widely used it is seems irrelevant here, considering that comparing **any** of these formats to how widely used JSON is will make it clear that they are all (including `protobuf`) used almost nowhere. They're very niche compared to JSON. &gt; Not as much cross platform support. `protobuf` and `flatbuffers` are both developed by Google, and they both seem to be mature implementations. What do you mean by it having less cross platform support? &gt; No schema. A schema, no matter how closely tied to the data format, still doesn't enforce that you never get bad messages, as discussed earlier.
These kinds of self-borrowing structs are not yet possible in vanilla Rust so there really is no better option.
&gt; Json is not statically typed because JS is not. Once you are over a 32bit signed integer it will start writing numbers as doubles. So you can be getting integers like you thought for some time, then everything breaks if your backend is in a statically typed language. The only safe way of using numbers is to always use strings and parse them. Doubles - which javascript numbers are based on - can represent something like -2^53 - 2^53 without a loss in precision. It is quite safe to use as long as all systems treat them equally. But you're correct in principle. One should not use them as identifiers. UUIDs or plain strings are superior alternatives. &gt; There is no schema. Well... :). &gt;&gt; or MsgPack? &gt; No schema. msgpack is one of the formats which supports the same featureset as JSON. Because I generate general structures for other frameworks it's actually already supported by reproto through these libraries: * Java (because of Jackson): https://github.com/msgpack/msgpack-java/tree/v07-develop/msgpack-jackson * Rust (because of Serde): https://github.com/3Hren/msgpack-rust * Python (operates on dicts): https://pypi.python.org/pypi/msgpack-python * Javascript (operates on objects): https://github.com/kawanet/msgpack-lite I've just not put any effort into making it convenient to integrate with them (yet). As for protobuf, it might be supported in the future. The challenges are consistently generating the numeric identifiers and building ergonomic structures/wrappers.
As mentioned by coder542 above, [rental](https://crates.io/crates/rental) will accommodate this use case. You can create a struct that will hold both the `Arc` and its resulting calculation, and that struct itself will satisfy `'static` bound and be sendable to other threads. The ergonomics aren't ideal, but it is safe.
There's an index with your `n` most recent posts, and an archive with every single one of your posts.
I landed support for inspecting trait objects in gdb. This required a change to llvm and to rustc, and is my first significant debugging patch to go in. Meanwhile I'm continuing to work on adding rust support to lldb. Most of the DWARF interpretation is done. The next step is adding some built-in formatters; and then I'll start work on expression parsing.
&gt; The core team decided that macro debugging is a niche, rarely-used feature that isn't worth supporting on stable This is not quite right, we very much want macro debugging on stable, however we decided it is lower priority than a whole bunch of other things that we also want to have.
&gt; Yes, this is a huge issue sadly in many areas of computing. Why does a Bank care about someone hacking their ATMs to spit out money, they are insured. As long as they are not much less secure than the other banks, they won't have to pay higher premiums. This realm is where theoretically the private insurance model shines. Theoretically, because neither you nor most of the involved parties noticed the other side of the coin: an atypically secure bank ought to be able to (negotiate to) pay *lesser* premiums due to its lesser expected quantity of claims per (e.g.) decade.
&gt; If you look closely at this project, it's more than just providing a schema, but the schema-part is enforced, if you're using reproto for your project. reproto generates the structs and (de)serialization for them in the language you're using. No C, C++, Go, Erlang, Ruby, Elixir, etc. If you aren't in the short list of supported languages you are on your own. Protocol buffers implementations can serialize/deserialize to Json as well. This is only playing catchup with an inferior baseline technology. &gt; CapnProto is not well maintained? It's practically a one man band and before april this year did not have a release since 2015. &gt; How widely used it is seems irrelevant here, considering that comparing any of these formats to how widely used JSON is will make it clear that all of these (including protobuf) are used almost nowhere. Protocol buffers is developed full time by a team of professional developers getting payed to do it and it's the foundation of Google's entire infrastructure. It is much better thought out and supported then all of the above. &gt; protobuf and flatbuffers are both developed by Google, and they both seem to be mature implementations. What do you mean by it having less cross platform support? There is only one flatbuffers crate that has not been updated in a year.
&gt; No C, C++, Go, Erlang, Ruby, Elixir, etc. It's a project under very early development... All I can say is "duh, of course it doesn't support every language under the sun yet."
&gt; Doubles - which javascript numbers are based on - can represent something like -253 - 253 without a loss in precision. It is quite safe to use as long as all systems treat them equally. But you're correct in principle. One should not use them as identifiers. UUIDs or plain strings are superior alternatives. You are not understanding me. Rust will serialize u64 to an integer in json ("{a : 9234556789}"). This will be happily read by JS. The reverse case however JS will happily write a f64 and break Rust deserialization. It will/might be ("{a : 9234556789.0}").
The same is possible with rayon btw.
I'd see this as pretty "magic" - and I don't think most people would want fat pointers and extra logic introduced _everywhere in their codebase_ just because one struct has a member with a different layout.
You do if `convention` is originally a String, since `trim` will give you an `&amp;str`. If `convention` is an `&amp;str` as well though, you are correct, no need to introduce a new variable binding.
Well, if we really wanted to, we could try that and do a crater run to see if any unsafe code _actually_ broke. More concerning is security. Consider this example: struct S1 { name: std::String, u8: age, email: std::String } #[repr(packed = "1")] struct S2 { u32: password_hash_or_something, S1: safe_info } If rust was allowed to put variables in the padding of substructs, it might put the u32 in the padding after the u8 on 64-bit platforms; then pointers to safe_info passed to other code would secretly have potentially-sensitive information in them.
Don't use packed casually, it's for use with ffi and exactly how it works will be changed a bit, so don't depend on it. You probably don't need it.
I'm not saying that it is necessarily a good thing to have (e.g. it might affect compile times). As mattheium pointed out, it does happen in C++ so it seems plausible that Rust might have it. My main point was - I clearly don't know enough Rust and questions like this one can arise. So what is a good source to read up on this (e.g. some particular RFCs, blog posts) instead of jumping head first into the compiler's source code.
I clearly don't know enough about it, but having a single compiler appears to be the dangerous part.
I'm not using it in practice (mentioned at the bottom of the post), just giving a hypothetical example for the sake of trying to decipher what is going on.
I just wanted to suggest this for redox as a whole.
Regardless, it was an active decision to disable what exists.
You can use the owned-chars crate in this specific case. It's just a replacement iterator that owns the string.
You'll be happy to know that any such inconsistency can be dealt with by reproto if it ever happens. That's part of the reason why wrapper classes are generated for Javascript: https://github.com/reproto/reproto/blob/master/it/test-alltypes/expected/suite/js/test.js In theory this could do all kinds of onerous things like make use of an external bignum library. Note that what you describe is not a limitation in JSON, but rather a potential effect of how numbers are represented in Javascript*. *: https://github.com/sidorares/json-bigint In practice I don't expect this to be an issues. But if it becomes one, I'll have you covered :).
Visual Studio now has preview support for the language server protocol! This means that Rust would be able to support yet another editor via the RLS. I worked closely with the individuals that made this possible and can offer guidance on how to write extensions for Visual Studio if anyone is interested in taking up the mantle of hooking up the RLS and VS. (I am unable to write the extension myself due to some legal complications).
There's a few issues with that though. * Proactive security is expensive. The lower premium would have to more than compensate for security staff, external audits, regulatory fees, etc. A doctor, for example, would have to have code that has been proven HIPAA compliant. * Proactive security is risky. By taking initiative, the entity takes on responsibility for security issues. An insurance company can't argue if you use an industry standard software, if you've rolled your own they can decide that you were at fault and they don't have to cover anything they can remotely tie to your solution. Included in "expensive" is that unless specifically designed for similarity retraining is a huge drain. There's a lot of upfront expense that *may* start making gains long term. From a business standpoint, it's MUCH safer to follow the tried and true standard and just pretend that it isn't a problem for you. That way you can be "totally surprised" when you get breached and it's not your fault and you just pay off Experian credit monitoring for a year with the insurance payout to make it go away.
Add someone not familiar with rust, I have no idea how to react this. In the linked function, are there types being defined inside the function itself? That's so foreign to me... But would be of so useful at long as it isn't passed out externally
That's a good question - I'm not sure I know of the best resources for this kind of thing besides just asking here or in the IRC channel. Someone else might have good links, I learned all I know so far from just asking questions.
If you separate out a function where the only caller is the function it was originally in, IMO it should stay local to that function
I'm not sure where else Redox OS is parsing text, but the bulk of that is definitely within the Ion shell, which is rather advanced in it's current state. Regularly find a few issues here and there over time -- nothing major, but panics due to logic errors nonetheless. Quickly fixed, but hard to find these holes in the first place.
Amazing! I'm sure the dev tools team will want to make this happen. I always forget nick's reddit name but i pinged him elsewhere.
Progress is being made on that front. There is a WIP alternative Rust compiler written in C++: https://github.com/thepowersgang/mrustc Rust is still a very young and fairly immature language. It is normal that the official compiler is the only complete implementation so far. Developing compilers takes a long time. The language itself is also still evolving quite a bit and there is no standard. It is not really practically feasible for multiple complete implementations to exist yet. That said, there are also plenty of other widely-used languages (or dialects of languages) with only one implementation and people still use them regardless.
That looks like what I need, thanks!
This is awesome news! We'd love to have Rust support in Visual Studio via the RLS. If someone wants to work on this, then I (nrc) can mentor from the RLS side. Thanks for offering to help out on the VS side! If no one picks this up, then I'll probably have time to work on it myself next year.
I saw some people were struggling with this on twitter the other day. I gave up on using the WSL and just use native windows, frankly, it works a lot better, cool as WSL is. I hear you on the cross-compile though.
Oh, is this fuzzer just for text? I was not looking into detail. Would you say Ion is ready to be used as a standard shell? 
Generally moving something to stable is a Big Thing and not something we take lightly, even if it is a small feature. We only try to stabilise features when they are a 'proper' solution or a step towards that. That's not the case for `--pretty expanded`.
Here's another approach if it is OK to hold everything in memory at once: https://play.rust-lang.org/?gist=dcd4a9b96787f27689d1319bb1530f80&amp;version=stable Another approach is to use the Bytes iterator, which unlike Chars works on stable (depending on what syntax rules you need to handle). Take a look at the [serde json parser](https://github.com/serde-rs/json/blob/master/src/de.rs) which does this. Yet another idea is to just yank the [Chars code](https://github.com/rust-lang/rust/blob/f28df200260c89b2a0bdf942510e0f888c29a70d/src/libstd/io/mod.rs#L2020-L2051) from libstd into your crate (or search on crates.io if there is something equivalent). I don't see anything unusual that would cause problems (see [27802](https://github.com/rust-lang/rust/issues/27802) for some discussion).
I've been using it as a standard shell for most of this year, so yes, it is.
maybe `...` is fine =]
Perhaps `...` was fine after all. We all read the difference between `.` and `..` all the time, so shouldn't we be able to see the difference between `..` and `...`?
It's also the first time I see a type being defined inside a function, you can see how it's useful when the file is over 2000 lines and you only use it in one place. Defining small functions is more common, using closures, like `let square = |x: u32| { return x*x; }`. As for the `valid_range = ` line above, it's easy to understand when you know that `a..=b` means `Range from a to b, inclusive`.
If you wanted this functionality you'd probably have to install all things rust on Windows so vscode can interact with it. Then you could use cargo yourself in WSL. I used to try and make WSL work but eventually gave up and just started dual booting. The inconvenience of dual booting is far offset by the developer experience in Linux. If you're new to Linux I'd recommend looking at https://system76.com/pop. It's based on Ubuntu but has a nice skin and very sane defualts.
1) String-based 2) No schema 3) Prioritize developer needs over the machine 4) Have issues with large integers (over 32 bits) 5) Hard to upgrade To be more precise it gives the developer a tiny bit more comfort during development and takes away way more in production where the developer doesn't care about it. I get why json got popular back then it had a native implementation of parsers and encoders in every browser. However, now it doesn't really matter. Now, I'm not advocating protobufs, I'm just against json. I'm even strongly against json where 99.99% requests processed by mobile devices. There is absolutely zero reason to use it besides bad habit and choosing developer comfort over performance. 
No, you not covered. You end up using string to represent numbers because javascript can't handle it like a normal language. Ran into this issue more than once.
I've just released `0.3.0` with some small changes. I'd like some feedback on handling stack limits. I'm wondering if setting the maximum stack size to an arbitrary limit and making it a compile-time option is a valid strategy or make it an additional argument to machine creation?
The linked library _replaces_ the number type to support large numbers and uses it in a custom JSON parser. Why doesn't that cover it?
You might want to update the post - `reproto build --lang rust` seems to no longer be the syntax. I replaced it with `reproto compile rust` and it worked.
One extra dependency that money patches things and required for every consumer of your API? Requires &gt;8KB of gzipped javascript to be parsed on page load? Yeah, I think it's going to be now for me. I want at least sub-second cold page load times. 
I love the tutorial - very high quality.
&gt;&gt; The reason for that is you can obtain &amp;mut S1 from S2, which has behave as a regular &amp;mut S1. &gt; &gt; I would note that this is not THAT obvious, actually. &gt; &gt; Each field has to be at the same offset, and occupy the same amount of bytes, however it should in theory be possible to reuse the padding within S1 to stuff bytes from S2. A write to that `&amp;mut S1` could clobber these padding bytes. Even if we make the compiler-generated code for `*r = x` where `r: &amp;mut S1` carefully not write to padding bytes, there’s still code like `mem::replace` that eventually calls `ptr::swap_nonoverlapping_bytes` which blindly copies `mem::size_of::&lt;S1&gt;()` bytes.
Your application either needs to support larger-than-32bit integers in JavaScript, or it doesn't. This is not `reproto`'s problem so much as it is your application's. If you want a light, snappy webpage, you have to accept the limitations of JavaScript. If you want a webpage that can work with large integers, you have to accept a few kilobytes of additional loading... which honestly is nothing compared to the megabytes of images most websites load these days. I'm not an author of `reproto`, and I just found out about the project today, but you're trying to hold the author to an impossible standard. The only way they can meet your requirements is for them to personally convince all of the major browser implementations to support 64-bit integers in JavaScript.
The concern wasn't visibility, it was the fact that mistyping between the two would produce silent otherwise impossible to catch off by one errors. That's a big footgun.
I'm hoping to see one day something like enum UnixyResult { Ok(i: i32 where i &gt;= 0), Err(errno: i32 where errno &lt; 0) }
Damn, all I said is that json is a bad for any kinds of APIs and that having extra dependencies to support i64 numbers is well...bad. 
Some comments: &gt; could be that of an array, a Vec, a str, etc. Incidentally, there's an RFC floating around out there which will allow viewing a `T: Sized` as a `[T]` with (maximum) length 1. &gt; `[str]` is not allowed Because `str` is unsized. &gt; `myarray[1..10]`, where `[1..10]` could represent a series of 10 elements of type `u8`. `myarray[1..10]` is a sequence of **9** elements. &gt; it's possible to get a slice of a str which is a `[u8]`, but not (safely) a `mut [u8]`. &gt; pointers to functions (just an address to jump to, no size, size unknown) I'm pretty sure `&amp;fn` is sized, but like `usize` vs `u64`/`u32` you can't assume its size is the same as `&amp;u8`. &gt; Fat pointers / other pointers I'm pretty sure in colloquial usage trait objects are considered fat pointers - address/length is only one kind of fat pointer. 
&gt; would it be fair to say that a slice, by definition, is a reference? Not exactly. `&amp;[T]` is properly a reference to a slice of `T` and `&amp;str` a reference to a string slice. But that’s quite long, so calling them (string) slices is a well-accepted shorthand. Most of the time it’s not ambiguous because `str` and `[T]` rarely show up by themselves. `Box&lt;[T]&gt;` and `Box&lt;str&gt;` are boxed (string) slices. Other combinations of pointers/references to dynamically-sized types like `Rc&lt;RefCell&lt;str&gt;&gt;` or `Arc&lt;Mutex&lt;SomeTrait&gt;&gt;` exist but are not necessarily convenient to use. These days dynamically-sized types exist orthogonally to what reference/pointer type like `&amp;mut _` or `Box&lt;_&gt;` they’re behind, but once upon a time `&amp;str` and `&amp;[T]` were special cases in the language that did not exist without `&amp;_`. Calling them slices is also a remnant from that time.
Yes, but how? Using any other format besides JSON requires pulling in a large external dependency in JavaScript. JSON itself doesn't have any limitations on integer size or floating point precision. The limitations under discussions are limitations of JavaScript itself. Any other format would have the exact same problems when used with JavaScript, right?
&gt; legal complications Does your employer really disallow you from working on open source in your free time or something?
Do you plan on implementing the wasm interpreter/compiler yourself, or pulling in something from one of the browsers or somewhere else?
I've been writing one chapter per day, and refining previous chapters over time, so check back often if you're interested in GTK resources!
I'm not sure. Since it has to run on bare-metal without a standard library, I'll probably write my own or modify another open-source one. If HolyJit or something like it pans out and I can modify it to work without `std`, I'll implement a jit wasm interpreter.
That and if you use the macro in like 30 different places, change one thing and cause an error then the compile time deluge of errors is terrible
You're right here. However, if you have to pull in dependencies to use JSON correctly, you might as well pull in dependencies to parse space efficient formats. 
That's unforturnate. Really? There's a ton of useful tools for debugging that are stuck behind -Z. It's frustrating -_-
No, there is no restriction on that (I'm not even sure it would be legal to). The issue is that internally I implemented the extension to help test out the feature-completeness of the LSP support. The powers that be decided the code should stay internal (something about wanting the community to own the extension and motivation issues arising from just giving them the code). There is a cool down clause that prevents us on working on other projects that would be in the same problem space as internal code within a certain time frame.
This is exactly how I do Rust development w/ WSL on windows . It is a pain, but it does work.
I can’t speak for the parent, but IP I work on is owned by my employer. I can go through a simple process for rights release should I want to work on OSS as retain my own copyright. Not all employers have such rules and not all employers subsequently have process for exclusions. See Google’s documentation: https://opensource.google.com/docs/iarc/ 
That seems incredibly problematic for someone like me. I spend a lot of my free time working on a project that isn't open source that I absolutely plan on using commercially. Fortunately it's in a different industry than my current employer.
Ah, you might have installed it through cargo? The version in cargo is 0.2.0 and is about 19 days old. I've had a hackweek at work which I spent introducing the manifest support and refining the interface. Unfortunately I'm in a similar position as [gutenberg](https://vincent.is/releasing-gutenberg-0.1.0/), where building the project is getting a bit too involved and I'm not sure how to distribute it through crates.io effectively. I might give it a stab, or I'd happily invite help to get it done. The biggest blocker right now is that the syntax themes are included as submodules and must be [manually built into packfiles](https://github.com/reproto/reproto#building-and-installing) that are then embedded with `include_bytes!`. Maybe it's possible to distribute the packs through crates.io?
&gt; motivation issues arising from just giving them the code That's ... an interesting line to take. I suspect it's more the managers not wanting to spend the time it takes to open source code at Microsoft (though I did know of stranger reasons to not do obviously good things). It's kind of shortsighted because having a decent first party example would allow for more languages to be integrated...
I've seen a thread somewhere which discussed the language integration of self-referential structs. Unfortunately, I can't find it. Could you update me on the state of your crate and the current state of supporting this feature in rust?
This is really great, good job! I'm already diving in
I realize this is more of a VSCode thing than a rls-vscode thing; it seems like lots of other, non-Rust LSP developers are running into the same thing. Still it seems like it would be possible to start the RLS (e.g., from the integrated terminal running bash) and then "attach" to it somehow in the extension, no? I don't really know how VSCode works.
I tried to use the rust gtk bindings a while back and it felt like I was just having to read the api reference and trial and error so I really think this will help you. Just out of curiosity, what are your thoughts on using rust gtk for large projects?
I do think that it is on its way. My point for GCC would only help the language. The honest truth is that there are exclusively 3 languages flying right now. Ada, C and C++. Rust has potential to be a fourth. Lots of strengths, and GCC would be a great addition. I think that ignoring GCC just keeps Rust out of the game for significantly longer. Those targets are going to be added organically to LLVM over time. You get them all in one day with GCC. 
haha I don't think you read the sidebar. You're looking for /r/playrust/
Worth looking at OpenAPI: https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.0.md It's aimed at the resftul JSON over HTTP use case and has broad support.
&gt; motivation issues arising from just giving them the code How many instances can you cite where developers got demotivated by getting example code for a problem domain they want to do work in?
Pretty sure it's a runtime *executed* instructions counter.
Two quick comments: 1. Crater runs don't reveal the existence of undefined behavior. Nothing crashes, perhaps, but this isn't evidence that all is well. 2. Please, please, please don't mistake Rust's memory safety guarantees for security guarantees. If you read out the padding bytes in `safe_info` that is currently undefined behavior, and it can report your password in the clear even if you've put it in a totally different allocation.
What does this crate provide other than a different syntax to write asserts? IOW, Why should a programmer learn yet another syntax just to write asserts differently? In a syntax that pretends to be similar to English but is sufficiently different from English that they have to spend time memorizing it explicitly..
Nice! Btw, does this also work for counting indirect dependencies?
I agree with you that it wasn't really an issue. It's just what I was told. There were also some concerns about there being an expectation for us to maintain the RLS extension. Which wasn't really in the scope of our work.
How did you specify that `cargo init` shouldn't insert your email? I don't see a way to set email to None here: http://doc.crates.io/config.html#configuration-keys
What I don't like about the proto format that its enums don't map to Rust enums :/ Someone should fork proto to have Rust-like enums, then I will use it (for gRPC)..
Does reproto support Rust-like enums?
Does all this work on Windows (8.1) / What are the steps to get this to work on Windows?
I think writing large projects with GTK-rs is very doable. It's a simple API to work with, once you have figured out how it works, and you have mastered Rust. The official documentation is just rather poor (effectively none), so it has a steep learning curve, and may seem like there is a lot of missing functionality, when it's actually just hidden behind a **IsA&lt;T&gt;**. I'm trying to address that learning curve with this tutorial series by demonstrating a few new GTK objects a time with a new GUI project, and stepping through how it's implemented. As more objects are added to the fray, these projects should become gradually more complex than the last. I will also try to make these projects around useful application ideas. For example, one idea that I have for a near-future chapter is to create a markdown editor using a GtkSourceView and a GtkWebView, and demonstrating how to convert the markdown into HTML and update the web view in real time. And I hope to revisit and enhance chapters that I have completed over time, and ensure that the state of the tutorial is always up to date with whatever breaking changes have occurred in the gtk crates as they strive for a 1.0 release. Ultimately, I'm trying to adhere to [UDL](http://www.cast.org/our-work/about-udl.html) practices with this tutorial.
It might, but I don't have any systems that run Windows, so I can't help you out.
Not yet, it only looks at direct dependencies right now. I am tracking support for indirect dependencies in [dtolnay/cargo-tally#3](https://github.com/dtolnay/cargo-tally/issues/3). I would love a PR!
Rust does not have a stable ABI. Every version of the compiler is allowed to do something different with the layout of structs, and it's just considered an internal compiler detail. Changes can happen at any time, and are considered to just be internal optimizations. So, there isn't much in the way of RFCs or blog posts about this, because it's just considered to be an optimization. Of course, these optimizations do have to preserve Rust's exposed semantics, like being able to take references to members, but since there isn't a formal spec of Rust yet, I don't think that's really written out either. The only things which do have stardard layout are those that are `#[repr(C)]`, which uses the platform's standard C ABI. The representation of Rust data types is [discussed a little in the Rustonomicon](https://doc.rust-lang.org/beta/nomicon/repr-rust.html), though that may be out of date, along with a [discussion of other reprs in Rust](https://doc.rust-lang.org/nomicon/other-reprs.html). For example, [this optimization of data structure layouts just recently landed](https://github.com/rust-lang/rust/pull/45225), which changes considerably how several types in Rust are represented. So, the best way to learn about how the compiler currently implements this may be to just play around with `size_of`, `align_of`, and doing some pointer arithmetic on references to fields in structs to see where they are in memory. [For example](https://play.rust-lang.org/?gist=f0649bae5852f737b2904909ff377943&amp;version=nightly): use std::mem::{size_of, align_of}; fn main() { struct S1 { // size 8, alignment 4 x: u32, // size 4, alignment 4 y: u8, // size 1, alignment 1 } println!("S1: {}/{} u32: {}/{} u8: {}/{}", size_of::&lt;S1&gt;(), align_of::&lt;S1&gt;(), size_of::&lt;u32&gt;(), align_of::&lt;u32&gt;(), size_of::&lt;u8&gt;(), align_of::&lt;u8&gt;()); struct S2 { a: S1, b: u16, c: u8, } let s = S2 { a: S1 { x: 1, y: 2 }, b: 3, c: 4 }; let sptr = &amp;s as *const _ as usize; println!("{}/{}", size_of::&lt;S2&gt;(), align_of::&lt;S2&gt;()); println!("s: {:?} s.a: {:?} s.a.x: {:?} s.a.y: {:?} s.b: {:?} s.c: {:?}", &amp;s as *const _ as usize - sptr, &amp;s.a as *const _ as usize - sptr, &amp;s.a.x as *const _ as usize - sptr, &amp;s.a.y as *const _ as usize - sptr, &amp;s.b as *const _ as usize - sptr, &amp;s.c as *const _ as usize - sptr, ); } You might also want to just read about [alignment in general](https://software.intel.com/en-us/articles/coding-for-performance-data-alignment-and-structures), as a lot of what applies in C applies equally well in Rust, except that because Rust doesn't guarantee an ABI, it is free to re-order struct elements and apply optimizations to enums as long as they preserve all of the stably visible Rust semantics.
This is awesome work! Can't wait to dig into it.
Oh, it's Visual Studio and not VS Code. D'Oh.
Swift is actually doing this by turning every function that returns a reference into a generator/coroutine. Rust will not do this.
Are you aware of `gtk::Application`? AFAICT that would be the more idiomatic thing to use, rather than defining a standalone window and calling `gtk::main()`.
I have no idea how hard is this task. Do you have any link for similar a similar project so I can estimate the work time needed?
Thanks for the detailed response, especially the last link and the code example. Yes, I understand the unstable ABI bit. I'm sorry if my original post wasn't clear; I am not concerned about the exact ABI itself but rather what optimization one could expect the compiler to do, possibly after giving some preprocessor directives. &gt; So, there isn't much in the way of RFCs or blog posts about this, because it's just considered to be an optimization. I don't know why the two things have to be separate? I'd expect implementing optimizations to go through an RFC process, to discuss whether the optimization is worth the costs (e.g. additional compilation time), unless there is a clear win-win situation. Regarding blogs as well, I'd love to read a blog post about "hey look, your compiler does this awesome thing you didn't even realise" such as the one linked in my post. I'm guessing more than a few people on this sub would agree with me here :). Another example: I recall watching a CppCon video about the short string optimization and I thought that was pretty rad. &gt; For example, this optimization of data structure layouts just recently landed, which changes considerably how several types in Rust are represented. Yes, I saw that (and I've mentioned it in my post :P) and I thought that was interesting. So I wrote this post asking for more juicy details about what rustc is doing under the hood. :)
I'm not sure how other people feel about it but it might be worth resubmitting - the intent is almost the opposite. Dependencies of a crate sounds like criticism (and criticism which is barely even valid in most cases) whereas dependencies on a crate is a fun kind of ego boost / legit curiosity. I avoided clicking this link at first because I don't really care how dependencies of a crate grow over time (and because I didn't notice who the submitter was). Your call, but at least one person wouldn't judge you for it.
not sure. this is just a google cloud server i ssh'd into, not sure where cargo usually pulls the email from.
I was just playing around with your example - just put a `#[repr(packed)]` on both structs. I would naively have expected the compiler to be smart and use the layout on the left, but it actually uses the one on the right. a a a a a a a a a c b b a b b c
My bad, forgot to check return values.
&gt; I guess then that's the reason for the "crashes", the calls exceed the memory limit? sounds correct to me. `afl-fuzz` (`cargo afl fuzz`) [has a crash exploration mode](https://lcamtuf.blogspot.com/2014/11/afl-fuzz-crash-exploration-mode.html) which _might_ give you more specific information about what caused the crash, but I haven't used it much, so not sure if it'd tell you directly that it's OOM also: https://github.com/rust-fuzz/trophy-case/commit/478d9493d01f0a9106bd352f20659e3d425f9850 :D
I just have a shell script that copies over into wsl, compiles and copies back
Will this system allow actors to be distributed on a cluster of machines?
As always with C libraries on windwos there's some extra work http://gtk-rs.org/docs/requirements.html Once you get the gtk libs installed, though, it should just work.
This syntax was better than the alternatives. It looks better with spaces around the operator to visually separate it from the args. valid_range: 0 ..= (!0 &gt;&gt; (128 - bits))
Not yet, but I am planing to add distributed actors. Any help is welcome.
But I have to use the MSVC rustc because I have to link to msvc-build libs..
[this thread](https://internals.rust-lang.org/t/improving-self-referential-structs/4808) on the internals board has a discussion going back several months on this topic. The short version is that rental is, I believe, the best currently possible library solution to this problem as of now, but nowhere near as good as language integration would be. The lang team mentioned in their recent AMA that they might look into this more in 2018 since it's also important for stackless coroutines.
&gt; Every thing we add to stable Rust must be around forever. forever ever?^(forever ever?)^(forever ever?) What about epochs tho?
A tangentially related question on memory usage in `struct`s: do 8 `bool` fields in a struct get represented as a single byte? 
Yeah, sorry about that. I noticed that after I had written but before I posted that you had already linked to the recent RFC. But I didn't feel like rewriting, so I posted it anyhow. Anyhow, I think that so far, the compiler hasn't done all that much clever with layout. It had some specific optimizations that could apply to things like `Option&lt;&amp;T&gt;` using one word and relying on a null pointer to represent `None` (it was a little more general than that, but not much). This refactor looks like it lays the groundwork for a lot more work on structure layout optimization. It applies also applies some fairly conservative optimizations, mostly to enums, but I think it lays the groundwork for a lot more of the kind of work you are thinking about.
gtk-rs works fine on Windows with the mingw target. But for myself I’m not interested in the mingw target. So long as you turn off the pkg-config stuff for the various libraries it needs (see the environment variables below), gtk-rs compiles fine on the msvc target until it gets to linking; that makes me hopeful that it’s just a matter of building those libraries. See https://wiki.gnome.org/Projects/GTK+/Win32/MSVCCompilationOfGTKStack for instructions on that which I haven’t followed yet but might in a couple of weeks’ time. (I don’t know of any source for prebuilt versions of them; ftp.gnome.org doesn’t have most of them, only including things for GTK+ 2 rather than GTK+ 3 and not having been updated for a few years.) To get compilation working on the msvc target, you’ll need: set GOBJECT_2.0_NO_PKG_CONFIG=1 set GLIB_2.0_NO_PKG_CONFIG=1 set GIO_2.0_NO_PKG_CONFIG=1 set CAIRO_NO_PKG_CONFIG=1 set PANGO_NO_PKG_CONFIG=1 set ATK_NO_PKG_CONFIG=1 set GDK_PIXBUF_2.0_NO_PKG_CONFIG=1 set GDK_3.0_NO_PKG_CONFIG=1 set GTK+_3.0_NO_PKG_CONFIG=1 … and to provide the linker with gtk-3.lib, gdk-3.lib, gdk-3.lib, cairo.lib, atk-1.0.lib, gdk_pixbuf-2.0.lib, gio-2.0.lib, pango-1.0.lib, gobject-2.0.lib, glib-2.0.lib and gobject-2.0.lib.
Yes, but you'll have to build the binaries yourself https://wiki.gnome.org/Projects/GTK+/Win32/MSVCCompilationOfGTKStack Then set [GTK_LIB_DIR](https://github.com/gtk-rs/sys/blob/b08fc0e16fc525dc07953d69c27511eda6bfdb14/gtk-sys/build.rs#L43) and it should work. You may be the first person to try this with Rust.
&gt; do 8 bool fields in a struct get represented as a single byte? Nope. Every bool is currently represented by a whole byte. The compact representation is a time/space tradeoff in some situations, and a pure-win in others, and Rust doesn't do anything clever here. &gt; If not, is there another way to represent bit flags? The [bitflags crate](https://crates.io/crates/bitflags) is the canonical solution for bitflags, I believe. It's in the rust-lang-nursery, so one day it might grow up and be included in `std`, but for now it exists outside the confines of `std`. But, the `bitflags` crate may not behave exactly like you're envisioning. The [bitfield crate](https://crates.io/crates/bitfield) might be closer to what you're wanting. But, how often do you have that many `bool`s all packed together? Just curious.
I think it'd be more palatable if there was an explicit stand-in. Something like `impl&lt;T: *&gt; S&lt;T&gt;` so that readers are at least *aware* that there are more constraints than are being explicitly listed. After all, there's nothing that requires `impl`s be *anywhere near* the type definition.
Random, but do you know how Cargo detects when the output isn't an interactive terminal?
terminfo, perhaps? I'm not sure. There are crates for this.
I think explicitness is good also, but what whould `&amp;c.` refer to here? Is `c` a type, or the element `c`? I get the `&amp;`, but why the `.`? Anyway thanks for taking a look at this.
It's all good. I think some people also might prefer the 'immutable' version of shadowing the variable with a new declaration, but I'm not sure if I agree with that or not. Both have advantages and disadvantages!
[*Kids these days...*](https://en.wikipedia.org/wiki/Et_cetera)
**Et cetera** Et cetera (in English; ; Latin pronunciation: [ɛt ˈkeːtɛra]), abbreviated to etc., etc, &amp;c., or &amp;c, is a Latin expression that is used in English to mean "and other similar things", or "and so forth". Et means 'and'; cētera means 'the rest'. In Latin, the expression means "and the rest (of such things)". It is a calque of the Greek καὶ τὰ ἕτερα kai ta hetera, 'and the other things'. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Oh, lol. I can't say I've ever seen et cetera written like that, usually just 'etc.'. It's similarity with rust syntax confused me.
This is the third time. Mods, can you just ban this spammer?
Please at least take a cursory glance at the sub you're posting in. You want /r/playrust
Alright, that's a good point.
I'm working on a talk about algebraic datatypes for next Monday's [Triangle Rustaceans meetup](https://meetup.com/triangle-rustaceans) in Durham, NC. Planning to talk a little bit about the theory (What makes them "algebraic?") and the practical aspects of why they make your code better.
At most, just a few. My day job is C# ecommerce, so there are a lot of flags for inventory items. It got me thinking.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cpp] [Rust landed new optimization in Option. Could it be done in std::optional?](https://www.reddit.com/r/cpp/comments/7eo6x0/rust_landed_new_optimization_in_option_could_it/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I added a few wiki pages. Is that better?
I'd guess that the best place to start would be to read the article and look at their example on Github: https://github.com/Microsoft/VSSDK-Extensibility-Samples/tree/master/LanguageServerProtocol
Basic support should be very straightforward. Getting things like prompts to install the rls for the user and display task status is more involved and requires using some Visual Studio APIs that don't have the best documentation (or any at all in some cases).
VS Code has had support for the Language Server Protocol since the protocol was first created afaik.
Check their post history: this is the third time in the last two days or so. There's no way they don't already know, they just don't care.
There is `log` that is a de-facto standard logging facade. If you logging needs are rather standard, you probably want to use it. In your binary, you need to pair it with a backend logging crate (like `envlogger`) that will actually handle all the logging messages and write or send them somewhere. There's also `slog` ecosystem which has many features that were/are missing from `log`. It's quite powerful, but it is more like "lego for logging". It supports structural, composable, contextual logging. If your logging needs are more sophisticated or "enterprise-y", you might want to spend some effort and give it a try. It comes with a lot of feature crates that implement pieces of functionality, and utility crates: eg. `sloggers` that makes basic usage much easier. There is a bunch of other logging crates: most are backends for `log`, with some selected functionality. 
Looks like struct optimizations [don't apply to `#[repr(packed)]`](https://github.com/eddyb/rust/blob/bbdaad0dc8dc64e036ccee817f90a91876b32a9d/src/librustc/ty/layout.rs#L596): // Anything with repr(C) or repr(packed) doesn't optimize. // Neither do 1-member and 2-member structs. // In addition, code in trans assume that 2-element structs can become pairs. // It's easier to just short-circuit here. let can_optimize = (fields.len() &gt; 2 || StructKind::EnumVariant == kind) &amp;&amp; !(repr.c || repr.packed || repr.linear || repr.simd); I think that `#[repr(packed)]` is mostly intended for compatibility with C's `__packed`, which means that it needs to preserve order, and it's up to the user to optimize it. One mistake that people make about `#[repr(packed)]` is thinking it means "optimize the size" and has little other effect, when it actually means that for many operations, you need to copy data out of the struct into an aligned address to work with it. See, for instance, [this pull request](https://github.com/rust-lang/rust/pull/44884) in which the compiler will soon start warning about the unsafety of referring directly to field in `#[repr(packed)]` structures, and will later turn that warning into an error. As for whether your suggested packed layout is valid for a Rust struct, I'm not sure. The usual rule, as [discussed in the Nomicon](https://doc.rust-lang.org/nomicon/repr-rust.html) is that `size_of::&lt;T&gt;` must be a multiple of `align_of::&lt;T&gt;`, so that you can lay out arrays or vecs using `size_of::&lt;T&gt;` and get proper alignment. In this sense, it would really be better to refer to `size_of::&lt;T&gt;` as the "stride" of `T` (technically, the stride of `[T]`, I guess), and have some way to refer to the actual size, without trailing padding, let's say `data_size_of::&lt;T&gt;`. Since `size_of::&lt;S1&gt;` in your example is 8, there may be code that assumes that all 8 bytes belong to it. However, if not, and you could implement `data_size_of::&lt;S1&gt;` to return 5, then it's possible that an optimization of the layout of `S2` could result in your given layout. But I don't know if it's possible to break that assumption (for non-`#[repr(packed)]` structs) without breaking code.
I was talking about [both having `#[repr(packed)]`](https://play.rust-lang.org/?gist=c4baf442058c63ead958f3e34be97336&amp;version=nightly) which does give size 5 on `S1`. So I think the key takeaway is, as you pointed out, that `repr(packed)` basically follows C's `__packed` and hence doesn't do any additional optimization even if `repr(C)` is not specified. Thanks for pointing me to the relevant issues :).
I was asking the same questions a little while ago. I wanted to write a command-line tool that could print messages to stderr, and would support command-line options like `--verbose` and `--quiet` to show more or less detailed information. I wound up using the `log` crate to provide the `warn!()`, `info!()`, `debug!()`, etc. macros, which I called at various places in my code to describe what was going on. I also used the `fern` crate to format my log messages and send them to stderr. When you set up logging with `fern`, you can tell it to only show messages of a certain level or higher, so I hooked up my `--verbose` and `--quiet` options to choose a log level and fed that in.
Yes, understood that you were talking about both being `#[repr(packed)]`. As mentioned, in that case, since the point is compat with `__packed` in C, reordering won't happen. But if it is possible to relax the restriction that `size_of::&lt;T&gt;` has to be a multiple of `align_of::&lt;T&gt;`, or if it would be possible use a `data_size_of::&lt;T&gt;` for embedding in a heterogenous structure and `size_of::&lt;T&gt;`only for homogenous structures like arrays, vecs, and slices, then I think it would be possible to fit `S1` into five bytes of `S2`, reorder `c` to be next, and have everything be properly aligned and not packed. I don't know if there are any assumptions that would violate.
Don't worry, [you are #1](https://i.imgur.com/O0a0dVK.png).
Direct reverse dependency calculation is very easy. *transitive* reverse dependencies are harder because if you want to be precise you'll have to implement a copy of cargo's resolution algorithm in reverse. It is not impossible to do, but the problem is non-trivial.
Ideally, &lt;i&gt;et cetera&lt;/i&gt; and &lt;i&gt;&amp;c.&lt;/i&gt; should be written in italics (as they are from another language; “etc.” has kinda been imported into the language enough that it shouldn’t be in italics). Unless you’re going to mandate that syntax highlighters MUST render the *&amp;c.* in italics, I don’t see how we can make this work. ☹ And when rendering to HTML, they MUST NOT use `&lt;em&gt;`, but rather `&lt;i&gt;` or `&lt;span&gt;` with some class or style attribute. (I write &lt;i&gt;&amp;c.&lt;/i&gt; all the time, and it’s fun explaining it every so often when someone hasn’t encountered it before.)
This week I'm rewriting a clunky python script in rust. I have a "quick-stop" system at work (not an "E-stop", noooooo that's much more safety-critical) that involves numerous slave IO modules where inputs are read and one master module where the combined inputs are used to toggle a "quick-stop" and "reset" output. The python script does this, but it's clunky, scans each module in sequence, and it's prone to delays and random trips if it can't reach a module. So the new version has a thread for each slave module that queries the module and sends its state over a channel (basically a FIFO queue) to a master thread. This master thread then checks this channel periodically. If there is anything queued up from the slaves it empties the channel, updating a state table of all the slaves as it does so. After the queue is emptied it then scans the updated table and sets the outputs on the master as appropriate, then sleeps for a little bit. The threads and the channel arrangement make it nicely asynchronous - which is good for response times, no more waiting on a module - and the slave threads can signal whether their module is offline preventing trips and delays when talking to slaves. Rust's paranoia about ownership makes it a lot easier to do thread work - even if you beat your head against the borrow checker occasionally you know that things are going to be thread-safe.
`..` or `...` are probably more practical than `&amp;c.` `impl&lt;T: ExtraTraits + ...&gt; S&lt;T&gt;` `impl&lt;...&gt; S&lt;T&gt;`
I'd vote against it, because I want `..`/`...` saved for variadic generics. That's why I went with `*`: it vaguely fits and I can't think of any other potential features it'd be "stealing syntax" from.
Not just idiomatic, it is *the* way to do it. A few features arent possible without it afaik. 
By the way, to answer your original question, memory layout is optimized for structs, just not in exactly the way that you originally asked about. Rust does reorder fields to waste the least space possible, while still respecting that each type has to respect the size and alignment rules. So for example, if you look at your example with just `S1` being `#[repr(packed)]`, you will see that it does only use 8 bytes of space for `S2`, though the order is still not what you would prefer, being: b b a a a a a c This matches the rule "greatest alignment first, followed by decreasing alignment", since `b` has the greatest alignment at 2, and `a` and `c` now both have alignment 1. I suppose that case could be optimized to your preferred layout if there were some notion of "preferred alignment but not required" for `#[repr(packed)]` structures, but for now, I think if you want that exact layout you'll just want to use `#[repr(packed)]` for both and order the structures by hand, and also be careful of all of the caveats about referencing data in `#[repr(packed)]` structures.
No, but interfaces are synthesized with enums in Rust: https://github.com/reproto/reproto/blob/master/doc/spec.md#interfaces For example, [this spec](https://github.com/reproto/reproto/blob/master/it/test-enum/proto/test.reproto) becomes [this](https://github.com/reproto/reproto/blob/master/it/test-enum/expected/suite/rust/test.rs)
So basically I can use either slog (with slog-stdlog) or log without backend in my library and consumer will decide what to do, right?
In libraries, it's either `slog` or `log`, yes. `slog-stdlog` is mostly for binaries. You use `slog-scope` to "catch" `log` logging messages from the libraries that your library is using when they don't support `slog`. https://docs.rs/slog-stdlog/3.0.2/slog_stdlog/#slog-scope
Hey! I've looked at OpenAPI for inspiration. My take is this: * YAML has lower signal-to-noise ratio. It can be overly [verbose](https://github.com/reproto/reproto/blob/master/README.md#openapi-previously-swagger) for things I consider core concepts. * I need the freedom to experiment with the language/spec to solve dependency management. * Development of OpenAPI is slower than it needs to be because it's a versioned spec as well (same reason but worse why c++ is moving so slowly). Breaking the spec means breaking an ecosystem of tools. I aim to make everything contained in a single project. That being said. I'd love to build an OpenAPI backend for reproto some day to leverage its tooling!
I think I still have to use `slog-stdlog` in order to redirect it to `log` backend such as `env_logger` in case consumer doesn't want to use `slog`
No, deciding to not stabilize something is not an active decision. Even if it's already stable by accident. The barrier for stabilization is high; the default state is unstable.
How the heck are variadic generics supposed to fit into Rust? Could you give an example use case?
Great work! Perhaps you should add a link to the page from the repo's README.md file?
Implementing methods on tuples. Generic constants do this with arrays, but for tuples you need varadic generics.
Package-level documentation can be a good place for simple tutorials. Examples could be be a bit more advanced, with ample comments, and serve as howtos. And you can have entirely separate markdown/other files for tutorials ([this is what I do with Cursive](https://github.com/gyscos/Cursive/blob/master/doc/tutorial_1.md)).
&gt; Swift is actually doing this by turning every function that returns a mutable reference (inout) into a generator/coroutine. !?!?!?!?!!!??!?!?????????????? …I mean, I guess it's doable if pointers aren't first-class values... But it still sounds crazy.
 impl&lt;A, ..Bs&gt; Clone for (A, ..Bs) where A: Clone, Bs: Clone { fn clone(&amp;self) -&gt; Self { let (ref a, ..ref b) = *self; (a.clone(), ..b.clone()) } } impl Clone for () { fn clone(&amp;self) -&gt; Self { () } } That implements `Clone` for all tuples of any size. `A` is always the first type, `Bs` is a tuple of the rest. Also useful for things like the `Fn*` traits.
I don't consider it much of a trophy, since it was about bug searching in a completely new crate, but here's a bug that was found by cargo fuzz. Note that it couldn't find it without seeding with the right dictionary. And then amusingly it only needs a single entry to find the bug (the entry is "abaaabaaabaaaabaa"). https://github.com/bluss/galil-seiferas/pull/1 I have test-run afl on the same vulnerability, same fuzzing target, but no hit so far, afl is a bit slower. But with a much cooler interface and being on stable Rust is *really* great.
Wait, what? how do they read structs from binary files?
Checkout log4rs which uses log but is very configurable: https://github.com/sfackler/log4rs
Thanks for the links! The cargo issue you linked to also mentions [cargo-external-doc](https://github.com/Geal/cargo-external-doc), which allows arbitrary Markdown documents to be included in the documentation directory `cargo doc` creates. It's not *super* integrated—there's no table of contents, and nothing automatically links to your documents—but you can create links yourself where relevant.
Could someone please explain what's the point in impl Trait in argument position? If it's just a sugar for generics, why introduce alternative syntax for such thing? 
Would the two actually be ambiguous? I don’t think they are. Or how about `...` for variadic generics (just as with variadic arguments) and `..` for this? There is, of course, potential for confusion if you do either of those, so using something obviously different is probably a better idea.
Amusingly, I had just glanced at this today: &lt;http://crates.io/crates/cargo-sphinx&gt;
[You can](https://github.com/rust-lang/rust/blob/master/src/test/run-pass/weird-exprs.rs#L80).
Didn't the syntax get changed to `..=` anyway due to "confusion"? Anyway, you probably *could* make it syntactically unambiguous, but I don't see any point in risking syntax or comprehension problems when there's a decent enough alternative available. For variadics, on the other hand, you've already got the precedent of `...` for C varargs, so I feel that should be maintained if at all possible.
Installing Rust on Windows turns out to be harder than expected (I'm happy with Linux and MacOS but want to check my crates for cross-platform issues). I use msys2, and I said `$ rustup-init --default-host x86_64-pc-windows-gnu` - then get the dreaded "missing key: 'url'" when trying to sync with that channel. The github issue is not enlightening.
I recently had the case where I had fn some_fn(futures: &amp;mut Vec&lt;impl Future&lt;...&gt;&gt;) { ... } where the function would fill up the vector with futures that can‘t be named. That wouldn‘t work with normal generics as they need to be inferred by the caller, which can‘t be done here. However, I‘m not sure if impl trait in argument position even solves this problem.
By parsing them! (Which you really need to do anyway) Thus actually tripped me up - somehow when I started with Windows development I got in the habit of reading and writing directly into in memory structs. And it works... until it doesn't (งツ)ว If you do this then your files gain an implicit dependency on the architecture they were written on - C struct layout is guaranteed by the architecture's ABI, but there's no guarantee that different architectures (IA32, AMD64, ARMv?, and so on) have the same struct layout or padding. And if you try to fix the layout with __attribute__((packed)) then there's no guarantee that you can *access* the members of the struct. Some architectures kill the process on unaligned memory access...
Indeed, all gtk-rs examples are using it now.
Not the first but one of the first ones for sure.
Great work! I hope one day you'll also cover the following two topics: building GUI with glade and GUI localization.
The RFC makes a very comprehensive argument for this: https://github.com/aturon/rfcs/blob/dbf6962cc05f0a5e893a29976a34cc152447e4fb/text/1951-expand-impl-trait.md#motivation-for-expanding-to-argument-position
Bookmarked! :)
Seconding.
From what I understand a library should get a slog::Logger copy which was created by the binary. So a lib should only use slog.
Great, thanks a lot !
Doesn't seem to work sadly https://play.rust-lang.org/?gist=6733df46b749fb607a8b38cb65d5ad09&amp;version=nightly (this example is using `Iterator`s, but the same would happen to `Future`s). I think the language would have to have some way of further generalizing `impl Trait` and specifying variance (something like `out impl Trait` and `in impl Trait`) for this to work. This is because right now, when `impl Trait` is used in argument position, the caller is specifying the concrete type of the `impl`, whereas when `impl Trait` is return position the function itself is specifying the type. In the case you provided the concrete type would have to be inferred from the function's body, not by the caller.
That‘s why impl Trait should just been syntactic sugar for fn some_fn&lt;T, out R&gt;(val: T, some_vec: &amp;mut Vec&lt;R&gt;) -&gt; R where R: Iterator&lt;Item = T&gt;, { ... } bleh :(
Is there a way to draw an OpenGL surface below a GTK surface? Otherwise, I sadly have to say that GTK is not usable for my case. I basically want to have my own renderer (with `glium`), but draw a GTK UI on top. QT has a method to draw to an OpenGL texture. Is there any way to integrate GTK and `glium`?
For `mem::replace` to work, the safe code needs to provide a `&amp;'static mut Foo` to replace the original one with. But safe code is not able to create a `&amp;'static mut Foo` in the first place, is it?
the how do you memory map them?
I'm struggling with this problem. I'm trying to convert: `Vec&lt;BTreeMap{"key": "key1", "value": "value1"}, BTreeMap{"key": "key2", "value": "value2"}` =&gt; `BTreeMap{"key1": "value1", "key2": "value2"}` The problem is, my `Vec&lt;stuff&gt;` can be one of two things - exactly a sequence of BTreeMaps of length 2 each with the keys "key" and "value", or anything else. Any thoughts? Ideas? Prayers?
There's an RFC (which may or may not have been merged already, I don't remember) which would allow that: ```rust type MyFut: impl Future&lt;...&gt;; fn some_fn(futures: &amp;mut Vec&lt;MyFut&gt;) { ... } ``` The actual type of `MyFut` is then inferred by the compiler. 
Relevant issue: https://github.com/gtk-rs/gdk/issues/81
Epochs weren't even thought of when this decision was made, so first of all, that :) Second, epochs aren't a license to change everything; that said, in the examples of what epochs can do, compiler flags weren't discussed at all, it was mostly from the position of the language. So, I dunno!
Consider using the MSVC target instead, it's much better, and is more "real" Windows.
Not in libstd.
&gt; What other alternatives are there to mdbook? None in my mind :) &gt; Also, mdbook's conventional directory structure overlaps with Cargo's in ways that make it awkward to keep mdbook documentation in the same repo as a Rust project. You can put it in a subdirectory, and then they won't clash. &gt; Are there any plans to support free-form Markdown files in rustdoc? Yes, by using mdbook as a library.
I hope existentials will come next. I have some trait definitions I want to convert to async that are blocked on them.
[You don't want `slot-stdlog` in your library](https://docs.rs/slog-stdlog/3.0.2/slog_stdlog/#warning): &gt; Be careful when using both methods at the same time, as a loop can be easily created: `log` -&gt; `slog` -&gt; `log` -&gt; ...
Settled for `partition` as pointed out to me on IRC.
In my misspent youth, I used MSVC, but moved onto mingw, which is a solid toolchain, and (plus) is supported by Rust. Having to download a very large MSVC dependency is not going to make the Rust install process painless for people, IHMO.
It does seem like a bug for sure, but you hit less bugs if you use MSVC. It's really the first-class target.
voting system for rust library ideas.
If I was setting up a full development environment, I would probably suck it up. But this is just a Windows 7 VM I'm using for cross-platform testing. I'll follow the rabbit hole further...
This is [RFC 2089](https://github.com/rust-lang/rfcs/pull/2089)?
do we need faster? how does it compare to gutenberg? also i made a static site generator library, its called slime. its made with serdejson and handlebars, very flexible. it would be great to get some feedback!
There is an RFC that describes exactly this (and a little bit more): [implied bounds](https://github.com/rust-lang/rfcs/blob/master/text/2089-implied-bounds.md). That RFC proposes that yes, these bounds should indeed be implied, automatically, without the need for any additional syntax. The RFC has already been merged and is waiting for someone to implement it. Anyone is welcome to help out, but from the little bit of experience I have with this part of the compiler I think this won't be an easy task. You could ask around on the [tracking issue](https://github.com/rust-lang/rust/issues/44491) or on IRC if someone's willing to mentor you.
Well, you can't. :) Either you want the file format to be cross platform compatible, in which case you need to have a common parsing format, or you are fine with being hardcoded to the current platform, in which case you can still use memroy mapping of course.
Oh.. never got back to saying thank you, but thank you, this seems to be what I was looking for!
Ups, never got back to you, but had a look and this worked great, especially since what I actually had was an iterator of T, not a Vec as shown in the example. Thank you!
&gt; The biggest blocker right now is that the syntax themes are included as submodules and must be manually built into packfiles that are then embedded with include_bytes!. Maybe it's possible to distribute the packs through crates.io? Wait what? Why are you distributing Sublime syntax and themes with the main package? Can't they be in their own, separate package?
Ah, now that you've clearly distinguished between `padded_size_of` and `data_size_of`, it's much clearer to me :)
[Last commits](https://github.com/SergioBenitez/Rocket/commits/master) were merged on Nov 17...
Yeah, sorry for not having been really clear, as I was trying to find the right terminology for concepts that don't exist in Rust as it exists, and also I was thinking through the problem as I was writing. Had I thought it all through up-front, and then started responding, I could have probably made it a bit more clear. Anyhow, I think the answer is, you're not going to get that behavior you want, of data that is both packed and aligned automatically in cases like this where it's possible, without changes to the language, and potentially ones which are breaking.
I wrote a small application with gtk-rs recently and had some issues making it work nicely with structs. Mutability was generally the issue, and the borrow checker wasn't pleased. I ended up having to use a pattern for my structs where the struct constructors had to create an `Option&lt;Rc&lt;RefCell&lt;Self&gt;&gt;&gt;` which was then used to hook up the events to the struct. Do you think there's a better way of doing it? In general, a messaging system like the one in relm seems to be a much better fit for rust.
I think really the big win would be to be able to generate a OpenAPI spec from a `.reproto` file. I like self-contained in theory, but our own experience with deploying a public API was that the people who were supposed to use it all preferred writing API requests themselves at the network layer (building the json dictionaries by hand), rather than use GRPC (which was the tooling we'd initially deployed). We ended up scrapping the entire project and rewriting it with a JSON+HTTP interface, with an OpenAPI spec, but with the understanding that none of our customers were planning to actually use it. In practice the OpenAPI spec is used to validate requests and responses to make sure they map exactly to the spec (so that people never see undocumented fields they might start to rely upon). So if this is meant to be for public APIs used by people outside an organization, you have to support the person who writes their code by hand, because that will probably be the most frequent way people use the exposed service. In practice that means strict semver and well documented, stable JSON+HTTP endpoints. The latter doesn't seem to be a goal of the project, which is too bad, because it looks pretty solid otherwise. Disclaimer: Our industry is super backwards so our experience may not be representative.
&gt; Latest commit is almost 2 months old and latest few pull requests have no comments. If you look closely, the [latest commit was authored 2 months ago, but pulled into `master` a few days ago](https://github.com/SergioBenitez/Rocket/commits/master). This means that the author is actively merging pull requests. I also wouldn't say "2 months without a commit means it's unmaintained." Writing free software is a side project for most people, and sometimes you need to take a break from it. &gt; Edit: oops, links do not work in titles? On Reddit, you can either submit a link, which is just a link to an external site, or a text post, in which there is just text (though you can include links within that text). In the case of a text post, the link on the title of the post will bring you to the comment thread; but because that's already a link, there's no way to embed another link into it. In the case of a link post, you can't attach any text. In the case of a text post, there can't be a link in the title, the link will go to the post, though there can be links in the body. You can't edit a title once submitted.
The Rocket developer has been attending events and talks while showing off Rocket. It is maintained and I definitely recommend using it. It is our best web framework imo.
Cool, did not notice. Saw the September date and freaked out. Coming from other bigger communities it looks unmaintained, I totally get the reasons, I've done the same in the past. Kind of sad that there is one maintainer instead of a group of people shouldering the responsibility.
I'm going to use it for my next personal project and see how far I can get :)
[standalone installers](https://www.rust-lang.org/en-US/other-installers.html#standalone-installers) to the rescue! . So far so good ;)
Take a look at the csv crate: https://docs.rs/csv/1.0.0-beta.5/csv/ --- It has submodules called `tutorial` and `cookbook` that export no API, but exist only to provide documentation. There's even a [simple script](https://github.com/BurntSushi/rust-csv/blob/master/scripts/copy-examples) that extracts code examples from the docs into the [examples](https://github.com/BurntSushi/rust-csv/tree/master/examples) directory so that folks can follow along and run them easily.
I'm so glad this has been done. To me, this makes Rust code vastly easier to read. 
It's pretty similar if you use [futures-await](https://github.com/alexcrichton/futures-await) (which requires nightly). On stable, the programming model is pretty different.
Well, at least this time it's not about the game! Hi OP! You've actually stumbled upon the subreddit for the Rust programming language, Reddit's number 1 place for #F E A R L E S S C O N C U R R E N C Y This post might be better suited for /r/Pareidolia, although I have to be honest with you and say that no amount of squinting can turn that into a man with a dog for me.
Is futures-await a part of the RFC for introducing the aync/await syntax?
I think the better way would be to make `..` inclusive and `..&lt;` non inclusive (I think some languages already do it that way), but that'd be changing already stable syntax of `..` i think?
There is no RFC for async/await so far AFAIK, there's an RFC for generators which is what this uses internally.
Thanks!
Many, many free software projects start out with just a single author, who transitions to being a single maintainer. Some do eventually add more maintainers, or hand off maintainership, but some continue with just a single maintainer even if they are the most successful and widely used pieces of software in the world; see, for example, the Linux kernel. I wouldn't say it's "kind of sad", it's the way a lot of people prefer to work. There are others who do prefer to spread out the load and responsibility, and on larger projects even the "single maintainers" usually have other people who are the primary maintainers of subsytems or aspects of how the process works. Rocket is a fairly young and experimental project (it depends on Rust nightly, for example), so it's not surprising that it's fully in single maintainer mode, and I wouldn't expect that to change until it matures more.
And then we need slf4rs and miriads of backends, converters between loggers and then spending weeks figuring why the app is not logging. 
They are not. They're like C++ references.
You can also find the developer of rocket on #rust channel on mozille irc network if I recall correctly.
From what I understand a library should only use `log` and let the executable chose whatever it wants for logging.
You're correct, that's not an option because it would be devastating to backwards compatibility. Otherwise I would prefer that syntax though.
I implement a sudoku solving lib for learning rust. I try out some concepts of rust in this „toy project“.
That's all well and good but re-arranged the member order of structs is a compiler optimisation gone too far IMO. What if you manually shape your struct to counter things like false sharing? The compiler is free to s**t all over that!?
I assume there is something linux specific about the code you are building? If not... I have recently been using a cargo watch from inside WSL to build source from the windows volume. I needed to set `CARGO_TARGET_DIR` to somewhere inside the linux filesystem because I run `cargo watch` from within windows also and a shared `target/` definitely didn't work. You would probably still need set it even if you were only building under linux since I believe rls is going to write to the target dir under windows. Doesn't help if you have even a single linux-only dependency of course. Something like this seems to work for me :- ``` export CARGO_TARGET_DIR=/home/jim/linux-target cd /mnt/c/Users/jim/src/tree cargo watch -x run ``` 
Agreed. I came here to rant about how sere could depend on 1600 crates, and I discovered that it was the opposite. Anyway, nice graphs. This should be embedded in crates.io for all crates :)
as /u/K900_ says, there isn't an async/await RFC. We've accepted generators as an experimental feature; this means there will need to be another RFC for them before they're stable, and then async/await is written on top of that
Why would you need to do that? Why can't you just compile it where it is?
I would really love if it were possible to compile one single set of documentation that contained the readme, examples as a kind of literate code, book-style documentation, and the API docs, into one consistent set of docs with a table of contents and searchable index of the whole thing. For many projects, just the readme plus short introductions in the package level documentation would probably be sufficient, but the same tool could scale out to larger projects that benefit from the more free-form layout of a book, and would be able to include all docs in one place along with the crate and easily searchable as a whole. In my ideal world, `cargo test` could include testing all of the examples in this unified documentation, [skeptic](https://github.com/budziq/rust-skeptic) does of READMEs, and [mdbook test](http://rust-lang-nursery.github.io/mdBook/cli/test.html) does of examples in the books. I think this might be doable by taking the approach that /u/steveklabnik1 is taking for his [rustdoc rewrite](https://github.com/steveklabnik/rustdoc) of extracting information from the Rust Language Server, and feeding that into mdbook or something that enhances or extends mdbook. For now, anyhow, I think that most projects are probably well covered by using package level documentation, and those that require more free-form structure of a book should use `mdbook` and just put it in a subdirectory of their crate repository.
Part of why i stopped using the WSL is that accessing any file inside of the WSL from anything outside of it bricks the entire WSL install. I hear this has been fixed, but uh, this is why it's still a beta.
&gt; Yes, by using mdbook as a library. Ooh. Link to tracking ticket?
&gt; The inconvenience of dual booting is far offset by the developer experience in Linux. Pure Rust projects have pretty much the same dev experience on Windows as they do on Linux. Native deps is where things get tricky, but it's not too bad, and most of the ecosystem only uses a few of them.
If I understood your first question correctly, here's how you can do it: https://play.rust-lang.org/?gist=eade66f7728e354464c10376817023d6&amp;version=stable It will build the map you want if all maps in the vector are correct, and return an error if any of them are not. If you want to simply ignore incorrect maps, you could use `filter_map` instead to remove those, and collect into `HashMap` directly, instead of a `Result`.
Sure, but couldn't you put the project outside of the WSL-specific part, and access it through /mnt/ ? The drives mounted in /mnt/ use a different file system driver, so it will play nice with win32 software.
Assuming package is crate? But yes. The themes are built into the tool. They can certainly be behind a feature flag at some point. Requiring themes to be loaded from the environment is hard. They could be... In addition if someone feels like customizing. But the tool should work by itself, and hopefully be fully installable through cargo at some point. Right now I'm working on including the binary packs as included files, which should help.
I just hated having to maintain the same tools in both windows and WSL. To each their own, I suppose.
I came here, walked the same road, hit the same wall and finally decided macros are evil and used plain old code parser instead of nom. Honestly, I'm a bit surprised that a very strict language like rust can allow macros, considering it rejected reflection and a big chunk of OOP (I'm not saying this is a bad thing, just that it's pretty audacious).
&gt; the standard library in Rust is rather small, and many things are delegated to the external libraries This is by design, and is not an issue because using external libraries in Rust is trivial thanks to cargo. &gt; During my career, I've encountered cases where several libraries used different dependencies that implement the same thing in different ways (be it futures or some other feature), and writing adapters between them was quite annoying. In Rust there is the tradition of separating API from implementation. For example, the `futures-rs` library provides the `Future` trait, and that's about it. To be able to use it you need to get implementations of that API from somewhere else. The same applies to the `log` crate. It implements a logging facade, but to use it you need to also include a concrete logger-backend (like `env_logger`). Then we have the `http` crate which implement only the `http` types for usage on library APIs; which library you end up using is up to you. Because of this, switching libraries and/or communicating between the different libraries isn't that painful in Rust. Most of this "API" crates are "official" and you can find them in the `rust-lang-nursery` github repositiory, which includes the crates maintained by the Rust team that are out of the standard library. 
That's why you have `#[repr(linear)]` and `#[repr(C)]`. Struct layout was never guaranteed, so it's your job as a programmer to use appropriate annotations. Speaking of false sharing, you can put some of your fields [inside something like this](https://github.com/crossbeam-rs/crossbeam/blob/d98fe80aacfe867c89389fa21a93917c3166a99d/src/cache_padded.rs#L16-L31).
Along this line, I just opened an issue (https://github.com/rust-lang-nursery/rls/issues/586) on RLS about the feasibility of running RLS as an HTTP server, which would make this easier/possible.
Wouldn't you need at least something to fill the ranges at the end?
 &gt; In Rust there is the tradition of separating API from implementation. For example, the futures-rs library provides the Future trait, and that's about it. To be able to use it you need to get implementations of that API from somewhere else. Off topic from the OP but I didn't realize this is the case until reading your comment. Is it standard that all implementations re-export the types or do consuming projects need to explicitly declare the, for example, `futures-rs` dependency? If so I can see that being an issue because of version mismatches. How is this typically handled?
Looks like only the examples in the *pending* branch are using it, and none in master.
Thanks to whoever included Molten in here even though I forgot to submit it!
I found this issue, also created by Steve: https://github.com/steveklabnik/rustdoc/issues/24 Last comment was in September though.
BTW congrats for your results at techempower benchmark. (Preview round 15)
WELP, I have gotten my IPFS pinning service website more or less usable, albeit still very alpha: https://md.alopex.li/ The backend is all written in Rust with Rouille, the frontend is all Elm and Hugo. The backend was honestly way less work than the frontend, but I still need to rewrite it to use proper a JSON-RPC protocol, probably using the Paritytech `jsonrpc` crate. That will be fun! But for now, back to ggez! Going to be improving OpenGL version picking and shader support (if I can remember how it works). Then it's off to mopping up some of the rough edges around window config, then rewriting the projection stuff to make it less dumb. After that we should be in pretty good shape to release 0.4 by the end of the year, after the usual documentation and clean-up passes. Hopefully I can get that all done before my vacation runs out!
Is it available on GitHub or so?
I hadn't seen that yet, got a link?
Maybe. It's been so long now I don't remember, I just know I wrecked my install.
You can use an Arc&lt;RwLock&lt;T&gt;&gt; or Arc&lt;Mutex&lt;T&gt;&gt;. Ensures that only one object has mutable access to your struct at any given point. Also lets you ship it across threads.
Yup, agreed 100%. That's defiantly what I'm aiming for with new rustdoc.
What do you think about having this list directly on rustref.com? Would be nice for discoverability.
Yes, that's the right issue. We're still working on the basics; that will come after.
Glade's development has long been stopped, and it has some serious bugs that haven't been addressed yet, so you might be waiting a while.
The thing is, the HTML DOM is now basically a general-purpose and absurdly flexible, if fairly low-level, GUI layout manager. I have to wonder what a system would look like if it was actually built to fill that role.
&gt; thing I noticed is that the standard library in Rust is rather small, and many things are delegated to the external libraries Yes, this is intended to avoid situations like Python, where bugs in the standard library are found [many years](https://github.com/vmchale/argparse-min-example) after being released. &gt;Moreover, I wonder how these adapters affect performance in performance-critical applications. I believe in Rust's impressive optimization capabilities, but being able to detect that two libraries do the same thing and optimize one of them away seems beyond realistic to me. It probably is. Rust is intended to give you (the user) low-level control, so that you can implement the optimizations that would otherwise take place in e.g. GHC. There will no doubt be some overhead from converting representations. &gt;During my career, I've encountered cases where several libraries used different dependencies that implement the same thing in different ways (be it futures or some other feature), and writing adapters between them was quite annoying. Hasn't bothered me in Rust (mainly hobby work) or Haskell (work) yet. I suspect the Rust ecosystem suffers somewhat from its youth; there will probably be fewer web frameworks for Rust in 2020.
https://www.techempower.com/benchmarks/previews/round15/#section=data-r15&amp;hw=ph&amp;test=plaintext Note that 1st and 2nd are: - higher latency - producer of 1 and 2 errors Tokio-minihttp is a killer for this bench. You set 10 threads in your CPU pool. Was it a requirement from Techempower? How did you choose this ?
Once there's some decent progress I'll make sure to share. Right now, I'm just doing the boring work of mapping CPU instructions and blabla
Related question: is there a way to integrate Vulkan surface into Vulkan GUI? I've heard it could be planned for GTK4, but that's it.
Yep.
Is this Scheme on crates.io yet?
Ah cool! I didn't write the program, so I'm not sure.
Honestly I'd take it further and argue that impl Type is the right way to do most generics, and the few remaining cases could be implemented as macros instead. But that might be something for Rust 2.0 we-don't-care-about-backwards-compat-anymore.
Thanks for the feedback. I think I will resubmit after [counting indirect dependencies](https://www.reddit.com/r/rust/comments/7eio8m/cargo_tally_draw_graphs_of_the_number_of/dq5xlub/) has been implemented.
Oh my goodness. This is the first I've seen of this RFC but it looks perfect for me. In my codebase all external systems or sufficiently complex modules are only referenced by traits they implement. This is done to make unit testing and dependency injection easier. The downside is to avoid runtime costs my code is littered with tons of generic boiler plate. I have a few helper functions where just the signature over 10 lines long. It'll be nice to clean that up and not have to keep what generic type argument maps to what trait in my head.
Precisely. It'd be quite a project to integrate the DOM into Metal, but if done well, it could be really revolutionary.
I believe this limitation is being tracked in [rust-lang/rfcs#1490](https://github.com/rust-lang/rfcs/issues/1490). Someone will need to write an RFC to propose a concrete API for handling this better.
I have the following code in a modes.rs file: ```rust use super::schema::sensors; #[derive(Queryable)] pub struct Sensor { pub id: i32, pub sensor_id: i32, pub latitude: f64, pub longitude: f64 } #[derive(Insertable)] #[table_name = "sensors"] pub struct NewSensor { pub sensor_id: i32, pub latitude: f64, pub longitude: f64 } ``` When building I get &gt; error[E0277]: the trait bound `f64: diesel::Expression` is not satisfied --&gt; src/models.rs:11:10 | 11 | #[derive(Insertable)] | ^^^^^^^^^^ the trait `diesel::Expression` is not implemented for `f64` | = note: required because of the requirements on the impl of `diesel::Expression` for `&amp;'insert f64` = note: required because of the requirements on the impl of `diesel::expression::AsExpression&lt;diesel::types::Float&gt;` for `&amp;'insert f64` 
Could you please highlight the man or a dog in this picture? Spent a while trying to figure out where both of them hiding on this pic :(
I think Rust strikes a good bridge between not requiring people to re-implement hash maps every time they use it and also not adding a ton of stuff to the standard library where you have got no idea how to deprecate it. About the standardisation issue: usually a standard emerges that most people use, at least right now in the Rust ecosystem. Generally Rust code tends to be highly modular so using one library doesn't lock you in that much compared to e.g. C++.
Is there a reason you can't do a `contains` check before you insert the value? e.g: https://play.rust-lang.org/?gist=36030d661df8de47789f5a99bac3f85e&amp;version=stable
As an aside, I like that advice, to have those four categories. Often I struggle with a Rust crate when the only documentation is Reference documentation.
It's not as simple as that, because exclusive ranges are overwhelmingly more common than inclusive ranges (e.g. Python doesn't even bother having syntax for the latter), so you want the exclusive range syntax to be lightweight. The only reason we have inclusive range syntax at all is because, unlike Python, our integers are bounded, meaning that e.g. you can't iterate over the full range of a `u8` with `0..256+1`. Exclusive ranges are rare, so it's not a problem if the syntax is wonky (and it's very good that it's not confusable with inclusive range syntax).
You would need to benchmark whether copying a few bytes (the clone way) is faster than hashing twice (the add\_if\_not\_there way).
Indeed, but the "CPU instructions" graph is only the default upon loading the page, there are other graphs as well, and they seem to corroborate each other.
Never got windows to arm-linux compiling correctly
Great! But the rust-rls extension for vscode is till broken.
I like it! Perhaps there should be a kind of template for submissions to encourage longer descriptions than the ones that are currently there. (E.g. what's wrong with current static site generators?) Also, perhaps github issues could be leveraged as a way to have a discussion room for each suggestion?
I think Rust solves this fairly cleanly by having this highly flexible trait system. So using different libraries together often just means you need to implement a few traits, and that‘s really all the adapters you need. This also has no performance impact whatsoever. I‘m currently working on a trait to allow hyper / tokio or the browser‘s http functionality to be used by some web api binding code, and it‘ll all compile away at compile time. So I think Rust already solves this nicely :)
There is an experimental RCF (eRFC) for generators that gives a proposed syntax for async/await. https://github.com/rust-lang/rfcs/blob/master/text/2033-experimental-coroutines.md#asyncawait-syntax This eRFC is a precursor to a potential normal RFC for stabilisation. 
Has this been discussed? What are the arguments for not doing it the way you suggest?
on #rocket for sure
Yes, it has been discussed quite a bit-- see the discussion on [RFC 1958](https://github.com/rust-lang/rfcs/pull/1951) and previous RFCs in the series. It's definitely an interesting question, and there are a lot of tradeoffs involved. The vast majority of the time, an argument-position type acts as an "input", rather than an "output". Desugaring argument-position `impl Trait` to generics (the approach specified in the RFC, and implemented in nightly) allows for a nicer syntax for the common case, like `fn run_my_fn(f: impl FnOnce()) { f() }`. The function described above with an argument position `Vec&lt;MyUnnameableOutParam&gt;` (`fn some_fn(futures: &amp;mut Vec&lt;impl Future&lt;...&gt;&gt;) { ... }`) is enabled instead by [RFC 2071](https://github.com/rust-lang/rfcs/pull/2071). The result looks like this: exists type MyOutFuture: Future&lt;Item = X, Error = Y&gt;; fn some_fn(futures: &amp;mut Vec&lt;MyOutFuture&gt;) { ... } N.B.: While the RFC has been merged, the final syntax for `exists`/`abstract`/etc. is still undecided.
https://github.com/LeopoldArkham/Molten/issues ;)
Are you using the right SQL type (Double) as per [these docs](http://docs.diesel.rs/diesel/types/index.html)?
That is true, and frankly I wouldn't worry about this small thing without first profiling, I was just providing a solution that the op can benchmark
Most projects require you to also depend on futures-rs, and to then just do synchronized updates of futures and the library if futures makes a server incompatible version
&gt; This is done to make unit testing and dependency injection easier. The downside is to avoid runtime costs my code is littered with tons of generic boiler plate. Damn I know this life.
I'll take this life over hand testing scripts and regressions slipping into prod though. I'm thankful for how easy rust makes zero runtime cost DI.
Consider the dark area as the man side profile looking up. And towards the bottom is a silhouette of a white dog.
Current platform *and* current build - the compiler is free to rearrange structs on each build, unless you tell it not to via a `#[repr()]` annotation :)
Thanks that did it! I was assuming "REAL" was the correct type.
"The few remaining cases" include all times the type parameter is used more than once in the signature, as well as all data structures. Macros don't allow for type-level constraints on their arguments. So that's really not a great idea.
What are you using for DI? Just by construction or through a tool?
Its just internal tooling I've written from scratch. It's nothing fancy. I'm slowly working through issues and testing things out then I plan out lifting it all out and open sourcing it when I get free time.
This is cool, but it would be nice if it was easier to vote (e.g having to fork and then open a PR is more effort than I'm willing to do most of the time). If there was a way you could use Github SSO (in order to curate the votes, for example) to do up/down votes that would be cool (but would be more involved, and would mean you no longer can just use github pages)
If I had to guess it probably grabs it from the default user `.gitconfig`
Sweet, I'd love to see a better DI story for rust.
Why no to go with WordPress?
&gt; In Rust there is the tradition of separating API from implementation. [examples provided] Yes but those aren't _standard_, they're just the current state of the community. I don't see how this refutes OP point. Simply because the current `crates.io` ecosystem is a monoculture doesn't mean it'll continue to be.
&gt; Yes but those aren't standard, they're just the current state of the community. Well they are _standard_ in the sense that most people using futures use the `Future` trait from `futures-rs`. Technically, though, nothing in Rust is _standard_ because Rust is not an ISO standard. &gt; Simply because the current crates.io ecosystem is a monoculture doesn't mean it'll continue to be. The OP implies that putting something in the `std` library prevents this, and implies that this prevention is a good thing. If you have been paying attention to these last few days on github, many crates are migrating from the `std::error::Error` trait to the `Fail` trait, and new code being written will probably prefer `Fail` to `Error`.
&gt; Technically, though, nothing in Rust is standard because Rust is not an ISO standard. Also, Rust can be used *without* the standard library...
I agree, it's a far deeper change that I made it out to be, and completely impractical in current Rust, I don't see a way of doing such a deep change. When you want to use a type parameter more than once you can either expose a way of getting the true type of an impl type (without knowing anything other than a type must exist) then you could do something like `(a: impl T, b: a::type)` which means that `b`'s type is the same as `a`'s. You could also allow a where clause to enforce this. I don't feel it's that hard to read. Macros would get a bit more complex, but to the benefit that we are using them less. Macros can return types entirely constructed within them. Since types would be a combination of structure and where it was created, calling the macro with the same params passed into the type would create the same type. You'd still need `PhantomData` to pass in PhatomTypes into structures. You can either allow Macros to do more checks after parsing of you could allow a special command to fail compilation if a compile-time assert fails. So we could have (taking a lot of freedom) macro CopyVec!(T: $type) =&gt; Type { struct { assert_where!(T: Copy); v: Vec!(T); } } IMHO the generic system from C++ is a weird mishmash of ideas that make sense on their own, but take a lot of effort to put together. I feel comfortable with the idea, but I don't think it's intuitive. Rust, and other languages, have improved on some of the worst points, but it doesn't change the weird unintitive things that can come out, at least to my opinion. So I compare something like the following: impl&lt;T: Clone&gt; Clone for Vec&lt;T&gt; vs impl Clone for Vec&lt;impl Clone&gt; The latter just feels more intuitive.
No, it's still very early in development and quite fragile. I ran afl on it last night and about 25% of inputs caused a panic.
&gt; There will no doubt be some overhead from converting representations. Which is why it is rather important to agree on *vocabulary types*. A lot of people wondered why the `http` crate did nothing but define types: that's why. If the library was parsing/connecting/etc... some people wouldn't like the trade-offs it picked and would instead make their own incompatible interface. Instead, the `http` crate is *just* types. This way, concurrent crates doing the parsing/connecting/etc... in various ways, picking various trade-offs, still use the same set of types to communicate so that (1) they are inter-operable and (2) switching from one to the other is less traumatizing. 
I feel most of the new static site generators are basically just scratching your own itch. I've used Jekyll, Hugo, Hexo and a few others (sadly not Guthenberg yet) but I still want to build my own some day.
And macro_rules! will be deprecated in favor of proc-macros? But when will proc-macros be able to do all the things that macro_rules! does now?
True, but `docs.rs` spoiled me and (I think) they don't support that yet...
Can't you just put each crate as a node in a petgraph, so that edges go from each crate to its deps and then, for each node, visit all its reachable nodes, and at each node, set the value `transitively_depends_on[krate][transitive_dep] = true;` and afterwards count the sum of `transitively_depends_on[k][krate]` for all krates k? (Assuming if A-&gt;B and A-&gt;C-&gt;B, you only want to count `A depends on B` once. Otherwise you can increase a counter instead of setting a flag.) [Similar to here.](https://github.com/rust-lang/crates.io/issues/1135)
If library exposes types from its dependency and there is no pressing requirement for interoperability with other crates which could use the same dependency, one common pattern is to reexport this dependency using `pub extern crate foo;`. This way you don't have to add this dependency to your `Cargo.toml` and it works nicely in many cases.
So in that example, Percentile would look like this? { "type": "percentile", "sample_size": 10, "sample_unit": "s", "percentile": 0.9 } Why are they not more like Rust-enums?
Not in favor of proc macros, in favor of `macro`. http://words.steveklabnik.com/an-overview-of-macros-in-rust
I'm just using this as example: https://github.com/slog-rs/example-lib
Do you mean in the reproto language? How do you propose making them more like enums?
&gt; expose a way of getting the true type of an impl type I'm not a huge fan of this because it forces you to pick one place in the signature to be the definition point of the type parameter. This makes refactoring harder, it makes scoping more tangled, and it makes everything more alien to people who are used to generics in just about any other language. &gt; You can either allow Macros to do more checks after parsing of you could allow a special command to fail compilation if a compile-time assert fails. Both of these solutions are more like C++ than Rust, where templates must be expanded before they can be typechecked. This makes error messages worse, it makes the compiler slower, and it makes trait resolution much harder if not impossible. &gt; ```impl Clone for Vec!(impl Clone)``` This requires `impl Trait` to work in type definitions where it's no longer clear whether it's an "input" or "output" type, and doesn't really seem any clearer to me than something like this: ```impl Clone for Vec&lt;T&gt; where T: Clone``` I genuinely don't see how any of this is more intuitive or better in any way. :/
I'm aware I can do a `contains`, yet my inner self cringes about that, too. The performance footprint won't show up until the sixth decimal anyway. It just bothers me.
In what way? Have you filed a bug?
Wouldn't you normally have the themes and syntax and other editor-specific stuff in their own repository, and have them installed and loaded via the editor's regular package system(in Sublime's case - https://packagecontrol.io/)
The error trait is a perfect example. The bigger the standard library, the faster things in the standard library become non-standard over time. Look at how many things in the Python or Java standard library don't in any way reflect the standard way to do things anymore, and the standard practice revolves instead around some external 3rd party dependency.
Oo, the tokio-minihttp result is great and all, but most people aren't using that for production apps. The performance of hyper in those benchmarks is very exciting however. For some reason it performed quite poorly in the previous round...
Perhaps there's room for an entry API that would allow you to look up slots with a borrowed key, and then provide an owned key on `or_insert/with`. Probably unnecessarily for most use cases, but it'd help for this particular scenario.
Got it working again, but the repo itself still says that the travis build is failing.
They are different. They may look similar with future-await, but rust’s ownership changes everything.
[removed]
At least for maps, `entry()` still requires the key *by value*. I think for OP's case, we'd want something that takes `&amp;Q` where `K: Borrow&lt;Q&gt;`.
Haha I am guessing that you are used to the pain of logging in java. Hopefully it never gets that bad...
Not according to this: https://github.com/slog-rs/example-lib
Rocket is damn good.
It's a matter of opinions. I can see the argument that people coming from C++, Java and other like languages will have an easier time since they've already wrapped their head. My argument against this is that I believe that impl types and macros will both evolve to be able to together do everything the generic system does. At that point you'd have two ways of doing everything, which would be weird. Getting rid of the generic system kind of solves the problem. &gt; Both of these solutions are more like C++ than Rust, where templates must be expanded before they can be typechecked. This makes error messages worse, it makes the compiler slower, and it makes trait resolution much harder if not impossible. You are right, Rust avoids this issue in generics. I claim that at some point I'll want to be able to declare that I want some compile assertions in my macro, and report a compilation error if they are wrong. Maybe a better way would be to expose this in the header? macro some_macro!($t: $type, $expr: $expr) where $t: SomeTrait, $expr: $type { ... I don't know if this is the best way to do it, I like it more than [the current form](https://github.com/rust-lang/rfcs/pull/1695). Still I believe that this is a problem that needs solving with or without generics. My proposal is that if it were easier to enforce post-parsing, pre-compilation guarantees (such as types, traits, etc.) you could make much better macros, and they would be able to replace generics in many (but not all) cases. &gt; This requires impl Trait to work in type definitions where it's no longer clear whether it's an "input" or "output" type, and doesn't really seem any clearer to me than something like this I am not sure what you are referring two: that we need impl types to work inside type definitions, or if the implementation of a trait now needs to know if something is an input or output abstract type. So I'm ansswering both: --- Inside type definitions (structs, enums, etc.) I actually wouldn't allow impl types inside type definitions. Type definitions need to resolve into "concrete types", which have very specific definitions about what is built, how it works, etc. You can't have abstract definitions inside the object unless you specify a way of encoding that abstraction (for example v-tables). Basically the same issue we already have with trait objects, not a new problem at all. --- Inside trait impl for type things: It's simple: impl types inside the impl trait for type expression are always input types. The real fully defined type has to satisfy all the requirements of the impl type fully. Notice that we already can do this, and it already is a compilation problem: trait A&lt;T&gt; { fn output(self) -&gt; T; } trait B&lt;T&gt; { fn input(self, T); } trait MergeInto&lt;T&gt; { type Output; fn merge_with(self, T) -&gt; Self::Output; } impl&lt;T, AT: A&lt;T&gt;, BT: B&lt;T&gt;&gt; MergeInto&lt;BT&gt; for AT { type Output = (); fn merge_with(self, b: BT) { b.input(self.output()) } } Fails to compile with the error error[E0207]: the type parameter `T` is not constrained by the impl trait, self type, or predicates --&gt; src/main.rs:14:6 | 14 | impl&lt;T, AT: A&lt;T&gt;, BT: B&lt;T&gt;&gt; MergeInto&lt;BT&gt; for AT { | ^ unconstrained type parameter error: aborting due to previous error error: Could not compile `playground`. The reason is that BT would have to be an "output" type that doesn't have an obvious to be constructed from the "input" (whatever is *after* the for) alone. The argument doesn't seem that hard, but the reality is that we need to be able to see the "real" type of `AT` and from it deduce what trait we want to implement for (which requires us knowing the real type from `BT` using `AT` alone). In a way we can think of a impl statement as a sort of function, except the input and output are flipped of how it works on almost all of rust. So impl Trait for Type Can be though of as something as Type=&gt;Trait (I use `=&gt;` to explain that this isn't a standard function). Moreover we can only know which trait implementation to call from the type alone, because having to also guess on the trait would result in output abstract values, which can lead to unsoundness. impl FromIterator&lt;Self::ItemType&gt; for Vec&lt;impl Clone&gt; I feel it's easy to explain the limitation (you can't use `impl` before the `for`) and it clearly shows the above logic. It still is a bit clunky, impl expressions are one of the few things where you put the result first and then the input, unlike most mappings in rust. This is a reality, but I do feel that the grepabbility it adds (`$ grep "impl Trait"` gives you all implementations of Trait) is not as bad. &gt; I genuinely don't see how any of this is more intuitive or better in any way. :/ That's fine, I'm mostly sharing my opinion about a bike-sheadabble things. I may not be right. The whole reason I said this is as an explanation of how we could use impl everywhere to the point that generics are only used for types. I do not know if this is the right way though. It's easy to look in retrospective and realize that things that made sense don't anymore, this is where languages start showing their age and/or break backwards compatibility. 
Yes in reproto. Basically with the same syntax as Rust, and the json repr the same as the serde_json-serialized Rust enum.
Please use https://gitter.im/slog-rs/slog for support. :) Your question should be addressed by https://docs.rs/slog-term/2.3.0/slog_term/ documentation. :)
PlainDecorator doesn't handle color, which is what OP is asking about.
Good luck! May I ask what it is?
It should be possible to have an API that makes the String from a &amp;str if needed without an additional hash. Obviously he should benchmark it for the way it currently exists as you say though.
UPDATE: I managed to make a small reproduction case and submitted the issue upstream. Updated OP with playground link. https://github.com/rust-lang/rust/issues/46197 Still no idea why the discrepency in behavior between building and just `cargo test`, or why all of my original attempts to reproduce the issue failed, but it's done now.
The Contains way will hash your key twice. That s bad two
thanks for feedback! yes, the voting system may be little annoying. How about voting on github issues with "github reactions"? I think it can be implemented with github api and static page :)
great feedback! actually your post gave me an idea to use github issue system to count votes from the issue, I will try to implement it later. Well longer descriptions are nice, but those can be updated later! But some kind of guiline would be nice. Also good idea to have a discussion in github issues :)
I am a bit confused with `?` for `Option`. As far as I understand, `Try` is now implemented for `Option` which allows it to be converted into `Result` and be used with `?`. The example functions provided have a return type of `Option`. Is there some more compiler desugaring or some `From` implementation that converts `NoneError` into `None`? Great release overall. Still waiting patiently for `impl Trait` :D 
https://docs.rs/slog-term/2.3.0/slog_term/#synchronization-via-mutex
Why is the “Wait, two versions?” in a blockquote?
 enum Suit { CLUBS = 0, DIAMONDS, HEARTS, SPADES, } struct Card { rank: u64, suit: Suit, } impl Card { fn compareTo(&amp;self, card: &amp;Card) -&gt; i64 { if(self.rank &gt; card.rank) { 1 } if(self.rank &lt; card.rank) { -1 } //Compare between suits? } } I'm making a card game using Rust, and I need to be able to compare cards for sorting reasons I'd like to be able to support cards of the same rank then by their suit, so that when a full deck is sorted the first 4 cards would be the ace of clubs, diamonds, hearts, then spades I'd like it to be as simple as self.suit &lt; card.suit, but is it?
&gt; However, this functionality is still a bit limited; you cannot yet write code that mixes results and options with ? in the same function, for example In a function that returns an option, ? only works with options. In a function that returns a result, it only works with results. There is no cross-conversion.
I felt like it was sort of a sidebar.
Not exactly. ? Doesn’t convert Options to results yet, it basically early returns an option. More conversions comes later.
Thanks for the explanation. So the `Try` trait is for this additional conversion?
Hah. I also misread the documentation.
You just need to `#[derive(PartialEq, PartialOrd)]` on the enum and then you can do that (the ` = 0` isn't strictly necessary).
Yup! And with that comes NoneError, the Err type of an Option converted to a Result via ?.
You'll want to `impl Ord for Card` (or at least `PartialOrd`). This will give you the `&lt;`, `&gt;`, `&lt;=` and `&gt;=` operators (you should also derive `PartialEq`, `Eq` so you'll get `==` and `!=`).
Converted error_chain to failure: https://github.com/llambda/nary/commit/3b4e8ae8d5de0c3b8b81cdc97abbce800f35ecb3?diff=split
Amusingly, it is actually possible to use `?` to convert between Options and Results in stable rust (under very limited circumstances) by abusing closures to get around the fact that `NoneError` is unstable: let x: Result&lt;i32, _&gt; = (|| { let val = None?; Ok(val) })(); let y: Option&lt;i32&gt; = (|| { x?; None })(); This probably Isn't useful for anything, though.
https://github.com/JonLeeCon/aws-sg-util I actually just finished up a basic AWS command line utility for listing security-groups, and adding/removing services (user defined collection of protocol + port in CSV) to a security group for the current external IP address (pulled with a DNS request to OpenDNS). It's actually my first real program in rust so there is probably a lot copying, cloning, etc that can be fine tuned. 
I'm always happy to accept PRs improving the documentation. 😀
WSL is no longer in beta. Accessing Linuxy files from Windows is unsupported, as it always has been (that is, modifying things like `%LOCALAPPDATA%\lxss\home\me\.cargo` for `/home/me/.cargo`), because the Linuxy metadata that doesn’t fit the shape of NTFS is stored in NTFS alternative data streams, and many tools will clobber that data when modifying files (e.g. create new file, put the content in, move it on top of the existing file). That’s why it was hidden away in `%LOCALAPPDATA%` in the first place. If you want to share things, put them on the Windows side and access them on the Linuxy side through `/mnt/c/`.
Nah, it’s clearly a blockquote style, semantically and visually. I’d probably do such a thing as a parenthesised paragraph, changing the first sentence to “Why two versions, you ask?” All the same, it’s kinda sad that my comment is currently the highest-voted comment in this thread…
Or github stars
Wouldn't this allow for the owned key to be different than the entry key? Depending on how the hash set is implemented, it may lead to buggy behavior if the user provides a different owned key.
So I came across something while working on a personal project today that I don't quite understand. What's worse is I don't even really know how to google this because it's hard to describe succinctly. Here's an example: https://play.rust-lang.org/?gist=73fdab774f947d58d3ff91d039add80e&amp;version=stable Basically what it boils down to is: rustc is smarter than I thought it was. Is this "feature" (I assume it's not a bug?) something that people use often? If so, what can you do with it other than what I've done here? It seems like it could be useful, but I can't think of any concrete examples.
After a bit more thought, I guess this makes sense because you can also do things like this (in the context of the above link): let node: NodeA = Node::new(2); I guess I just didn't realize that this would work across function boundaries. it makes sense now that I think about it, because the function defines the type that it expects just like the explicit type annotation above does.
Alas so often there isn't even that
[removed]
Ok. So these are reused using a library called syntect to provide syntax highlighting for the documentation generated by reproto. Sublime might not even be installed, making it difficult to use its package manager. So it's a convenience thing primarily.
I think the example for `?` for `Option` would be more clear like this: ```rust fn try_option_some() -&gt; Option&lt;u8&gt; { let val = Some(1)?; Some(val + 1) } assert_eq!(try_option_some(), Some(2)); ``` ... to show that it actually does not early return in that case.
Is there a timeline for stabilisation of conservative_impl_trait?
That would definitely be better, but it still forces the user to switch between two different interfaces (even if you went maximum convenience and added a link to the GitHub PR to link to it and still listed them on the site). I understand being adverse to having a server dedicated literally just to incrementing numbers on very specific things (not to mention the cost of doing that, even with the cheapest cloud/server hosting option...) but at the same time as the average lazy internet user it's hard enough to keep up to date with all of the site I visit without also having to switch between GitHub and the dedicated site for displaying the information. Now, this isn't _great_ but you could have the raw value in some other place that's not a server owned by you but still have it update-able from the website. There are plenty of clever hacks you can employ to achieve this (e.g I know someone who did this with a google excel-sheet, but they just read the data not sure if you can update it, not to mention data races...). Ultimately it's up to you, and I think this sort of thing is very important so good on you for trying to address it. If you're willing to do this long term, maybe contact the Rust team to see if they would be willing to officially support something in this capacity to make it easier on you?
&gt; In Rust there is the tradition of separating API from implementation. For example, the futures-rs library provides the Future trait, and that's about it. To be able to use it you need to get implementations of that API from somewhere else. This sounds awesome! I haven't even thought of it, and this approach indeed solves the problem. As I understand, the community decides what the most convenient interface is, and conflicts on this matter (where two libraries provide two incompatible sets of types, and both are popular) are expected to be rare.
You could always do `some_option.ok_or(YourError)?` (or `ok_or_else`) and `some_result.ok()?`. At least for converting `None` into a `Result&lt;_, E&gt;`, you probably often want to give some context for the error that can be automatically generated from no information at all.
As I mentioned in other comment, the idea of vocabulary libraries sounds super cool. I haven't seen this much in other languages.
&gt; Two recent compiler changes should speed up compiles in debug mode. We don’t have any specific numbers to commit to with these changes, but as always, compile times are very important to us, and we’re continuing to work on improving them. Every time that I rustup update I check my compile times and if they are lower I mentally high five you guys!!! Thank you for your hard work :)
It's out of beta now (since Fall Creators Update) and you can install Linux distributions directly from the Windows Store. If you need to edit files from Windows applications you should use /mnt since the filesystem mounted as / (lxfs) needs to set NTFS alternate data streams and NTFS extended attributes that usually unknown to Win32 applications.
[removed]
As an alternative, there is [ketos](https://crates.io/crates/ketos).
/r/playrust
You can't avoid using parts of `tokio-core` and `tokio-io` even if you decide to use `-proto` and/or `-service`. The hierarchy is approximately: * `-core`: event loop/task executor (you'll need one), bridge to low-level platform async functionality, i.e., `mio`, async networking support. * `-io`: protocol framing via `Encoder` and `Decoder` traits, which you'll need to provide, async I/O helpers. * `-proto`: framework for implementing several classes of protocols, which should follow a request/response pattern. If your protocol doesn't, `-proto` isn't a good fit. * `-service`: higher-level protocol wrapper, works well with `-proto` but doesn't strictly require it. You may use it to hide some details of request handling, like timeouts and reconnections. In the future, `-proto` is probably going to be simplified and de-emphasized in the documentation, along with several other simplifications of the whole framework, which you can read about in [this issue](https://github.com/tokio-rs/tokio-rfcs/pull/3).
I'm not super familiar with rust, and to be honest both examples are unclear to me. For Result it is pretty clear, e.g. in code let f = openFile(...)? will either return Error or assign the result to f. But what does let val = Some(1)? suppose to mean? Can Some(1) somehow fail and return None instead or am I missing something?
It unwraps the content of `Some(1)` and evaluates to `1`. This is an illustration that `?` applied onto `Some(x)` evaluates to `x`, while `?` applied onto `None` returns early with `None` as a return value.
There is some unsafe code in `extract_last_path_segment` to avoid bound checks. Would it be possible to use iterators instead, avoiding the bound checks and `unsafe`?
Thanks!
I wonder if Rust will be that interesting in aviation, is-there an objective comparison of Rust's strenghs and weaknesses in comparison to Ada?
Ah, that makes sense. Thanks!
Sadly, the code comment hints at benchmarks of different approaches existing, but the repos doesn't have them (anymore?).
Hi u/Ardenina, this is the subreddit for the Rust programming language. I think you are looking for the subreddit for the Rust game which is at r/playrust. Don't worry, it's a common enough mistake 
&gt; I feel most of the new static site generators are basically just scratching your own itch. Indeed, or just "I can't stand {NAME} anymore"
The issue is versions. If you have the following setup: crate A version 0.1.0 depends on B ^0.1.0 crate B version 0.1.0 depends on C ^0.1.0 crate B version 0.2.0 depends on D ^0.1.0 Now what will the transitive reverse dependencies of C be? It should be `B` only, but bad algorithms might also return `B` and `A`, or maybe even an empty set (if it only checks the latest versions of crates, then B would be no reverse dependency of C any more due to B version 0.2.0). For first level transitive dependencies it is very simple, you can just ignore any version that is not the latest one without any issues, but for transitive ones you can't. There is the additional issue that cargo does *unification* of dependencies, meaning that if two dependencies occur in a dependency tree, they are unified if version constraints allow it. There might be further details that I'm missing...
I'm working on a Macros 1.1 crate. It's about finished (well, the code needs a lot of refactoring). I'd like to check out the generated code to inspect it manually. Is there a compiler flag that allows me to see expanded macros like you can do with most if not all C compilers?
I'm glad `?` for `Option&lt;T&gt;` is finally stable. Been waiting for that for a while. P.S. Article has a small grammatical mistake: ` discovered a a late-breaking` has double `a`.
I can't find this feature in the docs, but [from this ticket](https://github.com/rust-lang/cargo/issues/2567) it looks like Cargo is able to update git submodules?
/r/playrust
&gt; That’s why it was hidden away in %LOCALAPPDATA% in the first place. Yeah I mean, it's not really hidden from the point of a command-line user, which is how it happened to me.
&gt; It's out of beta now Oops, thanks!
Nope. Somewhat sooner rather than later is the best I can say.
&gt; Nah I mean, you can disagree with my own inner monologue here, but that's not how this works ;) &gt; it’s clearly a blockquote style, semantically and visually. yeah, I mean markdown doesn't have syntax for `&lt;aside&gt;`, so sometimes, blockquotes get used for this kind of thing.
Thank you! https://github.com/rust-lang/blog.rust-lang.org/commit/af629919987ffe790a5e1f2513a31f0519ea5e93
&gt; ? Doesn’t convert Options to results yet I wouldn't ever expect it to be possible (at least outside of `ok_or`/`ok_or_else` that's been mentioned elsewhere, which isn't technically a conversion through `?` itself). What would be the rationale for that?
&gt; I have 2 types of errors, server internal errors that the user shouldn't see but which should get logged (jtry!()), and user input validation errors which are the opposite, not logged but which the user should see, for those I use jtry_user!() instead of jtry!(). I would add these two kinds of error as variants to your own error `enum`. Then the low level functions can just use `?` und `Result` and the higher level functions can then only log the internal server errors and report the usage errors to the user. 
? Already convers the error case, so converting the None case is consistent.
This. You should always prefer `ok_or`/`ok_or_else`.
So will we ever be able to mix the `?` operator with `bool` values?
I don't believe it's been decided, you may want to chime in on https://github.com/rust-lang/rust/issues/42327
So a fresh debug build of my current project takes 70.45s instead 86.51s now, which is a reduction of 19%. Gotta benchmark actually running my examples yet though.
No, this is actually a good thing. Rust gives you freedom and flexibility to decide what you want, using annotations on structs. In the vast majority of cases, you don't care about how a struct is going to be represented in memory, since you are just gonna be accessing it from safe Rust code anyway. In the few situations when you actually care about a specific memory layout, such as the manual shaping you talk about, or when you are going to be sending the struct to C or to some hardware device, you can annotate it with `#[repr(...)]` to specify exactly how you want it represented in memory. Really, the situations when you care about the exact memory layout are usually the exception rather than the rule (except maybe in device drivers or FFI wrappers). This means you still have full control over how your struct is represented whenever you actually care. In the vast majority of code, people don't care, so it is a good default to leave it undefined and let the compiler optimise it to make it as compact and performant as possible. It makes sense that if you don't specify that you have a special requirement, the compiler automagically chooses what it thinks is best. This allows for wide performance and memory use improvements across virtually all Rust code ever.
The defacto standard is `log`, and even if you opt for some other logging solution, you need a way to handle output from `log`-compatible dependencies so that it adds to the final logs produces by your application (and written to whatever output you wish). Like it is mentioned by /u/dpc_pw, `slog` takes a more ecosystem-like approach with a lot of small crates that you need to assemble yourself into a functioning solution. However, I'd argue that using `slog` directly isn't really logging -- it's producing a labeled event stream, i.e. something that should be handled by more specialized monitoring/metrics' libraries and not logging systems.
Hurray, my first PR actually went stable. It's the one that allows `T op= &amp;T` for primitive types. The real reason for this PR is actually not, as stated in the blog post, to fix the tiny papercut that you'd have to write `x += *y` instead of `x += y`. The real reason is that previously if you wanted to write a function that works both with `f32` and with other numeric types (complex numbers, matrices, dual numbers, etc), you want to represent that numeric type as a generic type `T`. If you want to add one `T` to another, you add the trait bound `T : AddAssign&lt;T&gt;` so you can do `x += y`. But notice that `y` is then *moved* into the `+=`. If you want to keep `y` around for later use, you have to write `x += y.clone()` instead, and cloning can be expensive (for e.g. big matrices). The better solution is to add the trait bound `T : for&lt;'a&gt; AddAssign&lt;&amp;'a T&gt;` so you can write `x += &amp;y`, avoiding the unnecessary clone. Before 1.22, if you did that then your function wouldn't work with `f32` anymore though, because `f32` didn't satisfy that trait bound. Now it does. One downside of this change is that it sometimes breaks type inference. For example `x += y.parse()` or `x += some_iter.sum()` would previously work if `x` was a `f32`, because the only thing that could appear on the right-hand side of `x +=` was a `f32`. But now `&amp;f32` is also possible there, so you have to add some type annotations, like `x += y.parse::&lt;f32&gt;()` or `x += some_iter.sum::&lt;f32&gt;()` or `let y : f32 = some_iter.sum(); x += y`, etc. This breakage caused the Rust team to reject the PR, as they take backwards compatibility very seriously. However, it was reconsidered after noticing that the inconsistency between `+` and `+=` is also pretty bad. Why should `x += y.parse()` work if `x + y.parse()` doesn't? That's just confusing and there's no good reason for it. We had to choose between letting that inconsistency exist forever, or to bite the bullet and break some code. Sincere apologies if this change broke your code, we tried as much as possible to preemptively fix it in open-source crates (big thanks to /u/Eh2406 for helping out here), but our tools may not have detected every breakage.
Sorry for misrepresenting your PR! I didn't realize. If you'd like me to change it, you can send a PR in or give me the text and I can modify things.
This (inference of generic return types) happens entirely at compile time. So there is no runtime overhead. BTW, it's the same mechanism that allows `collect()` on iterators to return a `Vec`, a `HashSet`, and other types implementing the `FromIterator` trait.
Very cool, that makes complete sense. It's really cool that this doesn't require you to write anything extra. I guess `impl Node for NodeA` is all you need because of the `-&gt; Self` on `Node::new`. Normally I would have expected to need some kind of `FromNode` trait (that somehow knows about the `Node` trait) and then to `impl FromNode for NodeA`, but I guess that behavior is implied because `Node` itself is `impl`'d for `NodeA`.
Yes, it is a boon for ndarray. Thanks for working on it.
No it's fine. I was only adding it here for those interested, but those who just want to know what's new in Rust 1.22 don't need to know all this. Also, I don't want to advertise high-performance generic numeric computations in Rust too much, because there are still a couple of things that make using Rust for this kind of code not for the faint of heart. Improvements are on their way though. The one I'm mostly waiting for is implied bounds, to deal with the otherwise annoyingly large lists of trait bounds. But other changes that will improve the situation are specialization, associated type constructors, the whole Chalk experiment which may hopefully improve the situation with orphan rules, etc etc.
&gt; Another interesting factoid about benchmarking Rust versus C in Ruby is that the amount of cache your CPU has can affect the results for Rust. More cache will improve Rust’s performance over C. This does not seem obvious to me, anyone care to explain?
That's great to hear! So far I've mostly only been hearing from people whose code I broke with this.
The Java standard library has a number of interfaces that can have different implementations, e.g. java.sql, java.xml and java.until.logging.
I'm actually not sure here. Is the article claiming that Rust's cache usage is better? That seems to be the gist of it.
Servo isn't exactly usable in that way yet.
w-which would return
Maybe they mean instruction cache rather than data cache? Languages that use templates can end up generating more code than languages that don't.
Presumably it would work the C/C++/Golang way and the false-y value would keep going and true would short-circuit return.
Another example is Go's SQL interface, which has no implementation in the standard library.
Also, I would like to note that I ask because I have some interest in either implementing new tooling in this area, or otherwise contributing to the current system in some fashion. I mean, I would like to contribute toward a more secure and featured crate management system, and wonder the best way to go about doing this. Just to summarize some general areas I believe could be improved: * Integration of cryptographic signatures on packages * webs of trust * I have no idea if scalability issues are arising, however decentralization of hosting resources could be implemented * Deprecation monitoring could signal to users when a project is using deprecated crate versions * Rating systems to judge quality of different projects at a glance * Community communication built directly into pages associated with crates to develop a sort of F.A.Q. over time I suppose cryptographic signatures could be provided by cargo itself, the primary advantage of using a standalone application comes from the ability to integrate cryptographic security into it, however it is possibly superior to continue using a web based service in a browser for crate discovery and to integrate cryptography into cargo and the crates.io interface for displaying cryptographically signed packages or so on. This would maintain the same general tooling but extend on it. 
All of these seem useless to me tbh, and GitHub issues would probably be a better place for this kind of a discussion.
Lack of cryptographic signatures on packages concentrates the security of the Rust ecosystem to the security of a centralized server from remote code execution. How hard would it be for me even to create a code that uses unsafe code toward exploiting the machine of the user who runs it, and integrating it into packages? My understanding of cargo and the crates ecosystem is that they are like a package manager and associated repository, however as far as I'm aware cargo is not using the security mechanisms of things like apt-get or google play. I think that it is useful to have these security mechanisms at least, though perhaps the other things are useless. 
I doubt that this would go anywhere. Web of trust is a useless solution to the wrong problem and people generally do not have a problem with centralization (in fact, the vast majority of people prefers that). Obviously you are free to do what you want, but I doubt there will be a large community forming around it.
Okay, I can see there isn't really any support for this idea here and agree with you that it will likely not attract much attention or be actuated. I see this as problematic regarding the security concerns, the other points I made however I hadn't really much interest in but rather added them primarily from my reading of this blog post by Eric Raymond http://esr.ibiblio.org/?p=7303
Ah good, the exact opposite of Option/Result :)
Look at https://github.com/rust-lang/crates.io/issues/75 as it describes the sanest approach I've see to opt-in signing by developers. The tricky part is not forcing someone to set up PKI to publish a 100-line package, whilst allowing maintainers of large projects to sign their own releases. Cargo definitely uses TLS for http.
What should this print then? fn foo() -&gt; Result&lt;(), bool&gt; { None? } match foo() { Ok(()) =&gt; {}, Err(b) =&gt; println!("{}", b), } 
Interesting thanks, that is exactly the sort of thing I was interested in. It should be noted I believe that crates.io already requires an API token: http://doc.crates.io/crates-io.html &gt; $ cargo login abcdefghijklmnopqrstuvwxyz012345 &gt;This command will inform Cargo of your API token and store it locally in your ~/.cargo/credentials (previously it was ~/.cargo/config). Note that this token is a secret and should not be shared with anyone else. If it leaks for any reason, you should regenerate it immediately. How difficult would it be to simply replace the API token with an ECDSA key or something and to use cryptographic systems with it rather than the web logic security that currently seems to be used. 
In my understanding, it should fail, as book doesn’t implement Try.
I guess it depends on your conversion function, i.e. your From&lt;Option&gt;.
&gt; I see this as problematic regarding the security concerns Finding a realistic trust model for package managers is a really tough topic and it's becoming ever more critical. However so far no good approaches have been found and it's likely that the solution to this issue is going to be really restrictive pinning ('shrinkwrapping') and a strong identity system which would likely be a centralized one. (eg: i only want to trust a release if it's signed by a key owned by a specific crates.io user).
Is the code public?
I'd *love* to talk to you in more depth about this space and how Rust can improve. If you're interested, shoot me an email: aturon@mozilla.com
Because a token is derived information (IIRC, you get it from logging in on the website), which means the token can be regenerated whenever lost. And only the crates.io server ever looks at it, so a rotation is invisible to people depending on your crates. Using an email address + password (and supporting password reset) as the root of the system makes it very forgiving for people. Using an ECDSA signing key is not forgiving. If you lose it you get one of the following outcomes: - All your packages are frozen forever because even cargo authenticates you through ECDSA. - You can rotate your key, but everyone who depends on your software now needs to tell their local cargo to accept the new key. These aren't fun problems to deal with for someone publishing a single cargo package. That's the nice part about TUF, it lets a publisher go from the permissive model to the restrictive one on their own schedule. Not to mention, forcing key-crypto onto people who don't understand it doesn't actually protect them. We deployed a public api that used public/private key pairs and with 3 beta users, we had 2 cases in following 2 weeks where people emailed us their private keys, defeating the whole point of using them.
cargo-external-doc was a hack I came up with, but it should really be proposed as a RFC instead
[removed]
Diff since previous round https://github.com/TechEmpower/FrameworkBenchmarks/commit/9f01d500d0e5a95e6448f228f13d8ee4dd33ae16
Yeah I used to be disappointed that rust didn't have an http library in the standard library, but I get excited with stuff like `.for_each` being added in iterators
with this release, does https://github.com/SergioBenitez/Rocket still needs nightly?
Not sure if this question is appropriate here. Feel free to remove if it's not. Some people say that Rust code is not easy to read and write. Writing/reading Rust requires high mental tax on developers. I'm feeling the same but I'm just a Rust beginner. My question is: will this impression go away when I'm more experienced? 
I think any scalability issue that crates.io runs into, npm already has a solution to. Personally, I think you'd be much better off contributing to crates.io instead of proposing a whole new system. The current system already _works_ and has a lot of inertia. 
What that really means is that the function in question ought to take a trait object instead of being generic.
Don't count on Rocket being stable until full-blown procedural macros are stable. :)
Admit it, the real reason for Rust 1.22.1 is to achieve a palindrome release!
You experience unfamilarity, and of course this will mentally tax you for a few weeks. The learning curve is steep but usually quick, thanks to the compiler. I had the same experience and once I overcame the newness of everything and learned some of the reasoning behind the design, I found a deep appreciation for why some things are that way, e.g. why we don't infer types in function signatures, why we automatically impl Send/Sync, why shadowing is acceptable in many cases, etc. In a way it's like training proper technique for archery – in the beginning you will get worse results than before, but after a while your aim will improve far more than what you were able to achieve with your prior technique. TL;DR: Yes.
I was imagining the opposite :P
What about [Stylish](https://github.com/Thinkofname/stylish)?
I'm sure.
Same. I would expect the "Win32 API" style of error handling, where `FALSE` means failure.
Oh, seems that this feature will take a long time to land.
It’ll be many more.
Sorry, must have skipped the `NoneError` thing...
Rust doesn't have null Option enum which can be None or Some value is a replacement for null, basically it's like an inline null check
(you can literally use an HTML aside tag, IIRC. You may need to add CSS to format it)
If nothing else, reflection was rejected because it inherently imposes some kind of runtime overhead, be it space or time, which can't be optimized away. If nothing else, OOP was rejected because it interacts badly with CPU caches. That's not to say those are the only reasons, but hygienic macros have neither of those problems.
Would it then make sense to add them as cases to the error_chain Error type and impl Responder for it, [similar to this](https://github.com/geeny/linux-hub-sdk/blob/release/src/errors.rs#L53-L93)?
Totally. I doubt we have the CSS and this was all last minute in a holiday, so a blockquote will have to do.
The commitment to not breaking stable Rust is a heavy commitment. It has a heavy cost to evolving the language, in particular to when the differing paths of evolution interact with each other-- and the complete vision of `impl Trait` interacts with most of Rust. There must be a path forward from `conservative_impl_trait` to the completed version, and that path can't cripple any other future feature like associated type constructors, among many others. It's a slow process.
Here's the feature list, from https://github.com/SergioBenitez/Rocket/blob/master/lib/src/lib.rs #![feature(specialization)] #![feature(conservative_impl_trait)] #![feature(const_fn)] #![feature(plugin, decl_macro)] #![feature(never_type)] #![feature(try_trait)] #![plugin(pear_codegen)]
4 posts unrelated to rust lang in just 3 days. Please stop.
You're on /r/rust, which is about the programming language. You're probably looking for /r/playrust, which is about the game. 
Oh damn... report them as spam...
thanks for response! well initially I started the project as website with rocket/diesel, but it is a lot of work. yes, it is much easier for user to vote with few clicks. the biggest problem is the maintenance of the project. I already have most of functionality implemented but struggled a lot with oauth and database auto-backup system. Maybe will try to ask someone for help to finish it. I also had some problem with my Rocket projects before (suddenly server is not responding and need to reset it every few days, maybe rocket bug?). I am currently into static websites, so I am exploring the possibility while trying to solve the voting problem! Current version of the project didnt get much tracking, so I will try something else next time :).
Nothing generates PDB files unless it's made by Microsoft, AFAIK, since that is such an opaque, undocumented format. Everyone else just sticks debug symbols inside the program itself. Debugging on Windows should work just fine. Did you try following [these instructions](http://www.brycevandyk.com/debug-rust-on-windows-with-visual-studio-code-and-the-msvc-debugger/) or others? I admit that I've never actually needed to debug Rust code on Windows, and only like once on Linux... it's not like when I would have to hunt down problems all the time in C++. But, I hear debugging works on Windows.
&gt; The Java standard library has a number of interfaces that can have different implementations, e.g. java.sql, java.xml and java.until.logging. And what trouble did that cause when the interfaces were found to be insufficient or defective... I don't really want another LayoutManager2 situation, but i suppose it's inevitable.
I've looked at those and a few others. My understanding is that with `mvsc` installed then rustup will use the VS toolchain, or `stable-x86_64-pc-windows-gnu` That part looks correct on my PC. My understanding is that 'cargo build' should tell the compiler to include debug symbols, but the build directory doesn't appear to contain anything of the sort. https://imgur.com/oecTjfX
yeah, like I said, there won't be any special files -- the symbols will be *in* the executable itself. But, I think you need to be using the MSVC toolchain if you want to use the Microsoft debugger. The GNU toolchain will likely require GDB or LLDB to debug correctly. So, you should try using the stable-x86_64-pc-windows-msvc toolchain, if you want to use Microsoft's debugger. 
Right under my nose the whole time - thanks! I was under the impression that rustup would see msvc on my box and select this toolchain automatically. But that could be a wrong impression.
Which is also what curses does. OK = 1, ERR = 0.
&gt; Nothing generates PDB files unless it's made by Microsoft, AFAIK, since that is such an opaque, undocumented format. This August, the LLVM Windows Team [announced](http://blog.llvm.org/2017/08/llvm-on-windows-now-supports-pdb-debug.html) that they'd implemented preliminary support for reading and writing PDB by building on the knowledge from a partial source dump Microsoft [released](https://github.com/Microsoft/microsoft-pdb) in response to their request.
I like it! I'm a bit busy with coursework right now, but eventually I will setup a static site with the source on github and hosted on netlify.com Netlify also has a nice way to do redirects: https://www.netlify.com/docs/redirects/ So it would be easy for someone to make a pull request to add another one :)
I'm not sure why it wouldn't detect it - I might be remembering this wrong, but I thought it asked which to install when rustup is run? In either case, there are reasons one might want to use the -gnu toolchain on windows: mainly, one might want to link to other -gnu compiled libraries.
I have no problem using the gnu toolchain if it will work without significant difficulty.
&gt; The standard library is where modules go to die. I always remember this quote when the topic comes up. It definitely has some truth with python (urllib for example).
I mean, both work completely well - the only differences I know of are: - MSVC toolchain requires visual studio C++ tools - different debuggers - different non-rust libraries you can link to
Just because nobody mentioned it if you use the msvc toolchain, rust binaries work quite well in WinDbg or Visual Studio. I suggest looking up how to load the natvis files so more stuff pretty prints properly.
If net neutrality is so important, how come the Internet has done fine in the past 20 years without it?
It hasn’t, it’s been getting worse and it’s all thanks to America. The internet belongs to Switzerland; they invented it after all.
You want /r/playrust - this subreddit is for the programming language, not the game.
Wrong place. You want /r/playrust 
Fedora 20 is not supported by its vendor for like 2 years. You may want to update it. Note that rustc isn't implemented fully in Rust, it contains a part written in C++ called LLVM.
You want [/r/rustjerk](https://www.reddit.com/r/rustjerk/)
Shoot
Things change. What once worked fine does not anymore. In the beginning the network providers were concerned with getting their nets to run and run as efficiently as possible so their customers were happy. Now they want to earn extra money by blackmailing sites. "Pay or we will reduce the amount of bandwidth your content can use on our net". There is also the case of ISPs making a cable-tv:ish thing of the internet. Putting sites in profiles and you pay more or less depending on what sites you want access too. The market doesn't work because we humans are short sighted when it comes to our personal choices. "Access to facebook is free, pay extra to access reddit? Never heard of reddit so why pay?". The few that wants access to sites outside of the big ones will have to pay extra. Making the internet into a monopoly.
It could be an unsupported dependency, but it could also be a bug in rust. I'm betting it's the former, but ICEs are always possible! (though a segfault would probably have to be a dependency error like in LLVM?) Does it segfault on all code, or only on a particular project? If it's a particular piece of code, would you mind sharing it and/or trying it in http://play.rust-lang.org/?
To add to this, I'd say that once you're over the initial learning curve, reading Rust is *easier* than most other systems languages. I read and write C code for a living, and the amount of mental state you need to hold in your head to understand even a 20-line function in C is *humongous*. Sometimes a hash map can be `NULL` to indicate zero items in it, other times it cannot. Sometimes stuff has been allocated using an arena, sometimes not. Sometimes the mutex has been taken long before your function is called, sometime you have to take it yourself. Sometimes you're inside a callback that cannot touch anything global, sometimes you're free to touch everything. Even in a semi-familiar code base, I estimate that understanding a new piece of C code can take up to a minute per line of code, on aggregate. In Rust, it's easily one tenth of that. 
https://mises.org/blog/ditch-net-neutrality-now When you use 35% of the world's bandwidth you should pay a premium.
/r/playrust
So `respond_to` is the high level function called by `Rocket` which gives you a user request and you return a response, right? Yes, then it's the right place.
The internet != The web
You're talking about the web, which is a subset of the internet.
The fact that you take mises.org seriously is already enough to discard everything you have to say.
That's an insult, not an argument. If you can't refute it then shut your facehole.
This is the *fifth time*. They are either well aware of what they're doing, or just don't care.
I understand and agree with these concerns. However the rust project maintainers and the majority of the community have deliberately decided to prefer ease-of-use and infrastructure simplicity over standard security practices that you'd see in other package infrastructure like most linux distributions and various google stores (i.e offline keys, package signatures, etc). You are unlikely to change this state of affairs without a significant amount of effort and discussion. A better more pragmatic solution would be to develop a new package system in parallel to crates.io, demonstrate that it works, and draw developers in. Client side could be as simple as a cargo plugin that verifies then adds crates in tree. If you're successful, you'll eventually replace crates.io as the primary source for rust packages relegating the obsolete system exclusively to legacy crates. Speaking for myself; If you manage to build a system that does package authentication right, I publish on your platform regardless of uptake or popularity. I also want to see the Rust's package story fixed.
I've not read the link, but I assume it is talking about YouTube. That is an extremly short sighted way to look at it. So the transfer of Google/YT content has to be payed for in some way. Google won't pay, so each ISP that want their customers to access it will have to pay instead. Since almost everyone wants access to YT it won't be some premium package, all customers will pay for it. Which is fine. That's how the net has been payed for for a long time. The problem is that this will spread to smaller sites, sites that the ISP don't want to pay for in the basic packages. The net will be split in "too big to block sites" (youtube, facebook, etc) and smaller sites. You will pay for the big sites with your connection and you pay extra for Twitch. If you never heard of it and you can't access it, or the connection is slow, will you start to pay for it? Of course not. A great way to build monopolies and the cable-tv version of the internet. No thanks. 
Surprising. I had thought the Rust creators understood the internet better than that, but I guess not. I've found a very tiny minority of people understand what BGP and peering are and why net neutrality strongly benefits Netflix monetarily but harms ISPs monetarily which offsets the costs of Netflix's infrastructure on to ISPs customers. ISP subscribers are subsidizing Netflix in this regulatory regime and ISPs can't charge Netflix for it so have to pass the cost on to the consumer, even if you aren't a Netflix customer.
Still in the progress of stabilizing [kairos](https://github.com/matthiasbeyer/kairos) and hopefully releasing beta-2 in the next few days. After that I can continue my work on `imag-habit` which is the last mayor step towards imag 0.5.0!
&gt; Rocket There's also this [tracking issue](https://github.com/SergioBenitez/Rocket/issues/19) to see what the status is on hitting stable.
It keeps happening. I told you dog! I warned you about Rust!
If it's the same user then there's a very simple way the moderators can force them to care.
&gt; Now they want to earn extra money by blackmailing sites. Maybe those sites use a disproportional amount of bandwidth? A simple email service shouldn't pay as much as a video steaming site, they have different requirements. &gt; The market doesn't work because we humans are short sighted when it comes to our personal choices. This is extremely condescending. Are *you* short sighted? *Some* people can be in *certain* choices. Consumers want the best deal, they don't want to pay more for something when they don't have to - all things being equal. I find the argument about people being short sighted is selectively brought up to construe that their opponent's disagreement is based on ignorance rather than some other valid concern. &gt; "Access to facebook is free, pay extra to access reddit? Never heard of reddit so why pay?" True, but people who never use Reddit ending up paying for those who do. There's two sides to the coin. I think it's obvious that people who only check their emails should pay **less** than myself. I use Netflix, YouTube, Reddit, and a whole host of high bandwidth sites. &gt; The few that wants access to sites outside of the big ones will have to pay extra. Possibly, it depends on a whole host of factors. Perhaps the big ones will get charged more as they have higher higher traffic. I can imagine a clear delineation between high and low bandwidth/latency - paying more for whatever you need and less for what you don't. &gt; Making the internet into a monopoly. Net Neutrality doesn't solve that issue. I've heard arguments that it hurts smaller companies who can't afford to not throttle users as they don't have the appropriate infrastructure - thus strengthening the monopoly. Big companies *can* throttle and withstand the lawsuits, starving out the smaller competition. If you impose a rule on the market that bigger companies are better equipped to handle then you end up hurting the smaller ones disproportionately. I mean have people stopped and thought why Google is for this? They're just as profit driven as Comcast and yet come down hard against repealing it. Google is perfectly able to discriminate on their side, as is Reddit, as is Facebook - as they should, they're private companies. But people lose it when Comcast should be given the same right. There are certainly valid concerns about the current state of the American ISP market, I agree it's in a bad state but I don't think net neutrality is the solution. I found the Wikipedia page on Net Neutrality quite informing on both sides of the issue.
Good catch. The former doesn't have a map, but I would still rewrite it, bc `filter` + `next` is the exact same as `find`: let interface = interfaces.into_iter().find(interface_match).unwrap();
A random nightly I tried worked on CentOS 7.
&gt; prefer ease-of-use and infrastructure simplicity over standard security practices It's not an exclusively Rust problem and a common epidemic. Not just security but also availability and reliability are ignored in favor of centralization.
&gt; Are you short sighted? Some people can be in certain choices. Of course I am. We all are. Most people are against child labour, polution etc, yet it is still big concernes because we are really good at closing our eyes when it is time to spend our money. The free markets does not fix it. &gt; I find the argument about people being short sighted is selectively brought up to construe that their opponent's disagreement is based on ignorance rather than some other valid concern. Ok. I ment that we, as consumers, don't look at the large picture when it is time to spend our money, so we will accept a "basic internet package". That package will include the big bandwidth sites, they are big because most everyone uses them, it does not make sense for an ISP to make an "email only package" - too few people would want it. So people still end up paying for stuff they don't use. &gt;&gt; Making the internet into a monopoly. &gt; Net Neutrality doesn't solve that issue. Of course not, but it does not contribute to it like the alternative.
I was rather surprised to learn this is a controversial matter, not just in the Rust community but across languages with their own package managers. I discussed this matter in an IRC channel, and learned that there are strong feelings regarding the path to take with the package manager. I wonder how it came to be, that there was substantial debate regarding this topic, with people strongly feeling one way or the other. 
A related question: As far as I understand, no part of tokio is usable with `no_std`. Is there a chance that might happen? I would love to share some code between my embedded and not embedded projects.
How do I write a function that accepts an iterator? For example, `fn walk&lt;I : Iterator&lt;String&gt;&gt;(items : I)`.
If anyone is confused: https://rust.libhunt.com/ is unrelated to https://github.com/rust-unofficial/awesome-rust
"shut your facehole" is not acceptable discourse here. Please see the rules.
Alright, y'all can't have a calm discussion about this, and this is mostly off topic anyway. Locked.
Wordpress is no static site generator (it has plugins that kind-of do that, but you will always have a bigger deploy story). It has had its share of security problems and imo will continue having because of its attitude towards security.
Does it have rss generation?
It's easier to implement a centralized index and pay for a CDN if you can afford it. This is still less reliable and available than a decentralized solution. Linux distros and Perl or Latex repositories have been hosted on public mirrors for decades and it'd be a shame to lose control and give power to a select few CDN operators and succumb to their rules and regulations. Think GitHub deleting stuff or a rogue developer removing a package, breaking CI everywhere. This traditional model can lag, but that's a feature since a critical bug that's fixed immediately won't affect everyone's hourly CI schedule but only those whose mirrors had picked up the faulty package version. The way these things work in CPAN/Linux/BSD is that packages are mirrored first and then the index with eventual collection or archival of now unreferenced versions. Not all repositories get this right, but most do and also allow you configure your mirror or rely on a geo redirector. Take this model and TUF security, and you get secure and available system that doesn't even have to use HTTPS. A local mirror can use BitTorrent or Rsync or whatever it wants and work even if half of the CDNs are down or the language org cannot affort CDN costs. &gt; I wonder how it came to be, that there was substantial debate regarding this topic, with people strongly feeling one way or the other. I believe there are many of us who are used to Linux/BSD/CPAN style decentralization of repositories and full mirroring (or on-demand caching mirroring) being built in or at least not an afterthought. If you've used Debian or FreeBSD, then you've used a public mirror to download things, likely based on proximity of your internet connection or fallback to alternative hosts if one is not accessible. A big feature of local mirroring is that it's also standard to have your private local repository too. And let's not forget that not everybody can (corporate network) or wants to (trust, speed, CI reliability, etc) access a public cdn.somelanguage.org service. I feel strongly about because every language ecosystem builds their own version which is inferior in more than one way if compared to how TexLive/CPAN or Linux/BSD are distributed. Paying for a CDN is fine for Mozilla, but at some point the CDN will be asked to delete some package or be unavailable globally or in some local network. Therefore decentralization and generic mirroring is a vital feature. 
for succ in vertex.succ.iter() is most likely moving the value that vertex holds out of the vertex variable and deinitializing it, which makes the use of the vertex variable inside the for loop a use of an uninitialized variable. 
Perhaps it is borrowing it mutably, it would if it were a &amp;mut and borrow_mut() returns something that is conceptually like a mutable reference. Essentially you would have a mutable reference in succ and vertex is a mutable reference? I'm not sure, I'm still new to Rust myself but that is my original train of thought, I can't say this definitively though. 
I have to say, for a language that prides itself on being simple, Python's `argparse` module is surprisingly horrendous.
You need fn walk&lt;I: Iterator&lt;Item = String&gt;&gt;(items: I) since `Item` is an associated type, not a type parameter. They're subtly different concepts. You might also want to use `IntoIterator` instead of a plain `Iterator`, to allow people to give you slices etc. 
Funny, I really don't agree. It's not my preferred module (I'd rather use click) but it does a rather good job. Though it is somewhat more readable than it is writeable, oddly enough (the API is quite clear but not necessarily trivial to remember if you don't use it all the time, which you won't do unless your days are spent creating CLI utilities).
`vertex` is not of type `Vertex`; it’s of type `RefMut&lt;Vertex&gt;`, which implements `Deref&lt;Output = Vertex&gt;` and `DerefMut`. In order to make this work, the compiler needs to know that you’re dealing with the same `Vertex` instance (`Deref` doesn’t guarantee it, hence this behaviour—the mutable and immutable borrows are thus on the `RefMut&lt;Vertex&gt;`, not the underlying `Vertex`). The solution is fairly straightforward in this case, since you’re only using the borrow locally: change `v.borrow_mut()` to `&amp;mut *v.borrow_mut()`.
It is far better than getopt and does everything I needed it to do. Use click if you want something simpler to use. I love structopt though. Solves my last issue with clap - using strings for argument names.
Ah now it makes sense! Thanks so much!
Nothing against your crate, but the naming is a bit unfortunate, because now there’re the crates ˋscoped-threadpoolˋ and ˋscope-threadpoolˋ.
&gt; I wonder how it came to be, that there was substantial debate regarding this topic, with people strongly feeling one way or the other. You don't only see this type of behavior when discussing package managers. Try releasing software you spend months of your life to write under the GPL and see how others react. Oddly enough, you won't get this type of reaction if you release it as closed source. Rather, you'd get polite remarks instead. People seem to have lost the ability to handle views and suggestions that don't fit with their perception of the world. I hope this is not indicative of a larger trend in humanity. Sorry for the rant and back to the topic at hand: I stand by what I said in my previous comment. I, and I'm willing to bet many others, want a better infrastructure for Rust and are willing to go the extra mile to support it. We want a package system that is properly authenticated, has peer review, and can be easily mirrored. Luckily, with cargo commands, it should be possible to have a parallel system without interfering with the current system. We are also spoiled for choice in building parts. We just need a group to commit to building it. (I feel like a hypocrite suggesting this without stepping up myself, but I have too much work on my plate and simply don't have the time) P.S.: If you or anyone else is considering implementing such a system with decentralized backing, please evaluate IPFS with three or four permanent backup nodes that automatically pinning valid packages. While I hold nothing against torrents and trackers, IPFS strikes me as a more suitable for this use case. 
ok, so I'm off by 3 months... but Rust stable still doesn't generate PDB files.
Yeah, I know :( But I had to name it what it was
Anything else would have been IMHO better, because now just mistyping the name in the ˋCargo.tomlˋ might give you the other crate.
In hindsight, I should have prefixed my message with "Good news on that front" to make it clear that I didn't mean it as "You're wrong".
There's also [gumdrop](https://crates.io/crates/gumdrop) which is a very good alternative to `structopt`.
He said rustup is crashing, didn' he?
It seems to have a very similar API, why would one use gumdrop instead of structopt (or the other way around)?
Have you tried to reinstall it from scratch or are you just updating from an older version?
I feel servo is too big of a dependency for games. Do you really want to use servo or are you just planning on making games run inside the browser? In both cases I assume you would rather use the libraries in arewegameyet.com instead of depending of CSS and servo. I think some of them can be compiled into wasm, but you would need to check that yourself.
The naive idea I had was that instead of using os window manegers and libraries to draw graphics, I thought it would be easier to me to translate 'game' logic into css animations. I hoped that I could just do let drawing_panel: Servo = Servo{800, 600}, then make a simple html for the game board and maniulate the items using a rust library. I'll take a look at the link you provided. thanks for that. 
A macro rule maybe?
ah thanks. 'ill check that out.
At least the trait libraries are separate crates from the `std` in Rust, so they are free to make a breaking change and bump their major version without breaking the whole ecosystem – making a breaking change in some less-used standard Java interface would make the whole Java standard lib backwards incompatible, whereas in Rust it typically affects only few actual users of affected trait.
Macros would be your friend there. Here's an example on how traits are implemented for many base types in Rust core. You can lift code from there. https://github.com/rust-lang/rust/blob/master/src/libcore/cmp.rs#L759-L783 There's no language feature itself that would do that and - in my opinion - that would make error reporting and detection much more complex. 
It also seems leads to bugs in the standard library - I like Rust’s approach a little better there. 
Ported some code to `structopt` this morning and I was favorably impressed (from `clap`). API was straightforward, and the examples were really good, I was able to find everything I needed in them. End result was shorter, and more readable, than the previous implementation. A++ would parse command line again.
[removed]
I don't see what's the problem with writing: #[options(help = "print help message")] instead of: #[structopt(short = "d", long = "debug", help = "Activate debug mode")] Also, `gumdrop` has no dependency vs `structopt` has many, which is a big advantage.
Given though how often the notation comes up in RFCS an such even by core members, I'm confused that the issue isn't tackled more agressively.
My only complaint about `clap-rs` is that it's quite slow (often slower than `optparse-applicative`). But other than those concerns it's my favorite way to parse commands out there. 
Sounds great, I'll have to try it. I wish the article had a more elaborate description of the problems with getopt though.. I've always found it very useful. Are there any better alternatives in C?
You can use a macro like this to achieve what you want: macro_rules! impl_foo { ($($t:ty),+) =&gt; { $(impl Foo for $t { fn foo(&amp;self) { // Implementation code here println!("{:?}", self.x); } })+ } } impl_foo!(A, B); 
I wonder if something like structopt would be possible in Python. I'm thinking it would, just by putting decorators on a data class.
`base` in Haskell is a nice example, `comonad`, `free`, and `lens` too (sort of). 
Possible? Yes. Useful? Not really. In Rust, you pretty much have to define the data-holder type, so it makes a lot of sense to annotate it with CLI meaning. In Python it's very easy for the CLI parser to generate the data-holder at runtime, so the data-holder class itself is mostly overhead, you might as well only pass the "annotations" to the CLI parser.
&gt; I don't see what's the problem with writing: I mean the `--help` flag, the gumdrop example seem to require hand-rolling its handling. &gt; Also, gumdrop has no dependency vs structopt has many, which is a big advantage. Advantage sure, bug *big* advantage? It's not like we're using C++, having dependencies is not a death knell in Rust.
Could it be based on rayon core? Would be good if there were fewer actual pools around.
Yeah it looks like it could be a good starting point! :)
The short version is that the PR ran into a design issue but was detected late, so the work had to be redone, taking a different approach. You can follow the tracking PR here: https://github.com/rust-lang/rust/pull/45918 Some work just got completed, but there's more to do. 
For the `--help` flag, it is auto-generated by calling the function `YourOptionStruct::usage()`, so that's not an issue. For the dependencies, I already had this debate and won't have it again. TLDR: it's not because it's easy to install dependencies in Rust that they don't contain any problem.
&gt; For the --help flag, it is auto-generated by calling the function YourOptionStruct::usage(), so that's not an issue. It means you have to add and handle the help flag, which you usually don't care for as it doesn't normally behave like a flag.
In case you're writing pest PEG grammar files, this might be handy. Bug reports and improvements welcome, this is my first real vim syntax highlighting plugin :) In case you don't know pest, it's a very nice PEG parser generator written in Rust: https://github.com/pest-parser/pest
`structopt` seems fine if you only get your options from the command line. If you also want to add, say, configuration files to the mix, I'm not sure it would be as helpful then. (And having to rewrite the parsing back to `clap` at this point would probably suck).
&gt; Not that your hand-rolling of them will have any less problems obviously. Maybe for you.
Writing a GTK app in Rust. It fetches data from a REST API to push to the GUI. Everything is almost fine, except for the updates. I want the data to update on an interval without any click event. I have tried `timeout_add` and `idle_add`, but both cause lag as they wait to update the GUI while making the API call + JSON parsing. I tried having the API and JSON parse on a separate thread, but the main thread still seems to hang waiting for data I have tried three things 1. Using `channel`: Causes lag waiting for the receiving signal 2. `Mutex` hangs from too much lock/unlocking (or so I guess) 3. `static mut` (or a crate implementation) which lags on reading the data (I'm guessing some sort of locking is going on behind the scenes) Anyone know of another way to solve the problem that would fix the lag issue?
I know this can be frustrating to hear, but please consider renaming it. The name is now very easily confused with another popular crate, and this seems to only be asking for problems.
I wrote a small commandline tool for saving and automatically restoring xrandr display configurations: https://crates.io/crates/quickrandr
Well, what name would you suggest?
How about “basin”? It’s short, memorable, and a synonym for “pool.”
`basin::Pool::new(1)` reads much nicer than `scope_threadpool::Pool::new()` although I suppose I could rename the function to `basin::pool(2)` and `basin::pool_with_backlog(2, 4)`.
Seriously curious: when does speed of command line parsing matter? I haven't build huge applications with `clap`, but I suspect that even parsing a huge set of flags with a huge rule set is faster than a human could notice (below a few ms). So... maybe a script executes your `clap` application very often and parsing is actually a bottleneck then? Or when would it matter?
I know about the history, it's just that its so pervasively used in code sketches for RFCs and similar. As long as we keep hitting those speed bumps (e.g. impl Trait not being allowed in method return position), we should move this feature back to experimental.
I noticed that the context closures are now replaced by simple arguments, even when they use `format!`. Is that not rather wasteful to allocate these strings, or are you counting on it being optimized away in the ok case?
You want [rayon](https://docs.rs/rayon/0.9.0/rayon/) and its [thread pool](https://docs.rs/rayon/0.9.0/rayon/struct.ThreadPool.html)
&gt; I suspect that even parsing a huge set of flags with a huge rule set is faster than a human could notice (below a few ms). It takes ~2.5ms to display help on one of my larger command-line applications. I don't know exactly how it scales but the answer seems to be "not well" and I suspect that could cause irritation in larger applications (look at `pandoc` for an example). But I was mostly just disappointed since I expected Rust to be faster. 
Oh, so rayon can do this for me anyway, that's good to hear! Looking at it, if I use a thread pool with a thread count of 'whatever rayon decides is best', how can I automatically populate all of those threads with a function?
beginner here, can someone explain me how rust can do safe printf with macros? 
The trick is that `print!` and friends all depend on `format_args!()` which is not a `macro_rules` macro but basically a procedural macro implemented in the compiler. Procedural macros allow arbitrary code to run at compile time, which in the case of `format_args` parses the format string and creates much more verbose code that can then be run through the type-checker.
Interesting; I was wondering about that as well.
I switched ripgrep from docopt to clap, and part of the motivation was performance. It is common to execute search programs with a large number of arguments, and docopt doesn't currently do well there.
&gt; eg: I only want to trust a release if it's signed by a key owned by a specific crates.io user that is at present not revoked Or by *n of N several trusted actors*? 
You can use rayon scopes for that.
I could use some help choosing if I'd want to use a parser library/combinator/??? and if so, which one. I'm parsing manually right now, but I'm not sure if that's a good option (I'm just at the beginning). I do not have a background in programming really, so bare with me wrt using the right words or only understanding really what I'm talking about. My starting point is a `Vec&lt;String&gt;` representing the lines of a file (no newlines in there). The on-disk-size of the file is up to 500MB, if that matters. I will not always need to go through the whole file. A (somewhat small) example can be found [here](http://www2.ifb.uni-stuttgart.de/fem/Tutorial8_Crash_SimpleTruck/Explicit/Truck_Front.pc) (I'll refer to that as the example). Here's roughly the structure that I need to parse: * Comment lines start with `#` or `$` * Some keywords in the beginning (up to line 15) can be ignored * After that, the file is structured into 'cards'. Each card starts with a string `KEYWO / ` where KEYWO is from a given, fixed set of keywords. * After that, it's fixed format, so e.g. a very simple card would be `NODE / 1 -1263.95 421.817 -717.38` where the first 8 bytes are the keyword, the nexe 8 bytes are a positive integer (the ID), after that the next 16 bytes are a float (the x coordinate) and so on * Cards can be multiline, too, e.g. line 21694 to 21706 in the example. Most of the format is fixed as above, though after `NAME` there's a string of variable length (but &lt;80) * Sometimes the value in a certain field of a card will change the format or the number of lines following. * Some fields have a variable number of lines following, e.g. line 23762 to 23768 encompass lines 23765 to 23768, and those could easily be more or even a lot of lines (just the 2 lines containing `END`) will be needed. The number of possible cards is somewhat large, and I'm not sure I've described all possibilities, but that should be the gist. Let me know if I should give more details. What I need is for each line number what card it is in, and what fields of that line are present, and if the entries of the fields are of the given type or within a given range. I need to be fault tolerant, so if a card isn't complete, I need to know, but the parsing should go on once the next keyword's there. I will also need to answer questions like "Given position x on line y, what field of what card are we on?" Since the number of cards is largish, I don't want to read the card structure at runtime, but have that compiled in (I think this is what happens when I use a parser library). But I need to generate the code/rules/??? of course, and it's a bit of a moving target, so having a good way to go from "example card that has the needed format" to "compile the code" would be nice. Right now, that would be "look hard at the example, hack all the match statements and the enums you're using", so anything like "run a script that reads the format and ouputs an input file for the parser generation" would probably be a win. Ok, got long enough again, if I should specify anything or give more examples let me know. I can spend some time on this question for sure, but I don't wont to start digging into e.g. nom and then realize after a lot of work that it's unsuitable for my type of problem. Thanks for any pointers!
Naw, that makes sense *if you understand Rust's static dispatch of functions*. The only strange thing about it is the fact that there's a *trait method* called `new`. Function arguments are coercion sites, meaning the compiler knows what type is required and is willing to reason backwards. `do_stuff_a` takes a `NodeA` argument. Therefore `Node::new` must return `NodeA`, therefore `Node::Self = NodeA`, therefore `Node::new` can only be dispatched to `&lt;NodeA as Node&gt;::new`. 
I've contacted OP on Steam and corrected them :)
I found this to be a good read on the subject: https://users.rust-lang.org/t/elf-processing-in-rust/10338?source_topic_id=13833
I checked, and you should be able to use `with_context` instead.
This kind of thing already exists (https://boinc.berkeley.edu/), and you don't need blockchain for it. Yall are inventing problems for solutions.
I started converting error handling in my project to use the failure crate: https://github.com/abhijat/system_snapshot_server It seems to be working okay so far. Next I'll add some information about the CPU and memory of the machine on a couple of URL endpoints. Filesystems after that. I actually did something similar in golang yesterday so I know which files in /proc to pick up data from.
I had not heard of that till now, that's cool to see.
A lot of the responses here are either half-sarcastic or just wrong. I agree that climate change is the #1 issues of our times. If you really want to impact climate change, I'd suggest you get in contact with some advocacy organizations and ask them what kind of tools they might need. The responses might surprise you or seem boring, but sometimes boring work is the most important. :/ Most of those projects probably won't be suited to Rust, but some might. In more general terms, secure software for the people (and activists). Rust's security advantages make it a key building block for infrastructure going forward -- this applies to building secure tools for activists to use so that they can continue their work, withstanding persecution from corporations, governments and other powers. This is a prerequisite for progress on climate change, because these people need to stay safe and able to do their work.
The very reason I hate the `bool` type used to signal success/failure. I've worked on codebases using opposite conventions (generally, `true` for success, but LLVM/Clang use `true` for failure...). I really much prefer an `enum`...
I've finished a writeup about my experiences with Rust (though not only Rust) while working on one of the first projects I decided to write in the language: [_gisht_](http://github.com/Xion/gisht), the downloader/executor of gists from GitHub (and other pastebins). Mostly good experiences too :) I hope someone finds it interesting. There is a copious amount of links to particular commits and code snippets which is hopefully be helpful for less experienced people. It ends with a summary of good/neutral/bad things encountered along the way.
If anyone can reproduce this problem on RHEL, please let me know! Any other Rust-on-RHEL bug reports are welcome too. Also, is the Fedora 20 problem on i686 or x86_64? I vaguely recall a glibc or binutils problem with Rust on i686, but I think that was RHEL 6.
No, that isn't the same thing at all, and you seem to have missed the point. Blockchain's proof of work hashing consumes an enormous and growing amount of energy and computing resources, while producing no work whatsoever of public good. Those resources would never be voluntarily dedicated to Folding@Home, and in effect blockchain has incentivized drawing spare resources away from that effort, a net negative on top of a net negative to the public good. If you could find a way to make blockchain's proof of work *be* something like protein folding, then you'd have an engine for good that happened to also enable the rich to get richer. The fact that distributed systems for doing tasks like protein folding exist neither matters or is in dispute, what matters is that greed will drive blockchains into sucking up compute time, so why not craft the use of that compute time into doing something of public benefit as well?
That seems to be a situation where [gumdrop](https://crates.io/crates/gumdrop) mentioned by /u/antoyo could help? Rather than take a static `default_value` keys it uses a `Default` implementation for the base, so you could pull from the environment in your `Default` impl. The parsing process is more involved (not just a `parse_args()` and you're done) but that would/could be an advantage in that context. Alternatively, you could define the relevant options (those which could come from the environment, a configuration file or the CLI) as Option and then `get_or_insert_with` them pulling from the env/config in the callback if you're on 1.20 (`get_or_insert_with` will insert the result of the callback if the subject is `None` and not do anything otherwise).
/r/playrust
Super interesting, thank you for sharing! A curiosity: do you think using structopt instead of raw clap would have been helpful at all?
I see your point, and admittedly my first response was very terse and failed to be clear. My main point is that your solution is a rube-goldberg machine that is a highly inefficient way to solve problems for which there are much better, more direct solutions. (But only some of them technical; mostly these are social solutions.) As a secondary point, I'd add that "harness greed" approaches tend to lead to negative "externalities" which outweigh the intended positive effects. (Because of the nature of greed. You know this and alluded to it in another comment. You seem to be coming at this from a harm-reduction perspective, and there's merit to that, but still, i think it would ultimately be much doings for not much result. I'd be happy to be proved wrong about that, but i think even the time spent to prove me wrong would be time lost that could be used on better, more direct and efficient solutions.)
The lack of clarity in the API is what causes me to agree with the parent comment. I've built 10+ tools using argparse and I still can't remember of the top of my head how to do submodules.
My situation is to keep the models independent - CLI/Config/Environment - then merge them before acting. Keeps things encapsulated and the exact cli framework matters less.
Could you elaborate on what your take on shadowing is? I had a colleague ask about it the other day, and it reads like you might have more insights.
It is pretty much entirely harm reduction; the key properties of blockchain make its upcoming success a no-brainer, it makes perfect sense for financial transactions, asset management, possibly even voting systems... but having a reasonably fast write throughput requires a proof of work that has also has certain properties (a one way function, relatively hard to calculate but easy to verify, can be made progressively harder), and pretty much the easiest (but least valuable to the public and most harmful to the environment) and first contender was SHA hashing. I don't think it would take that much effort to narrow down some of the NP problems to find ones that had similar properties and could provide similar value to the blockchain while also doing incidental good. Ironically, blockchain itself is just such an externality of a similar effort... someone set out to subvert the idea of money and liberate capital from the capitalists, and by accident invented an effectively perfect provenance-tracking database. I'm not suggesting anything so radical, just that people think about how we might incentivize meaningful work over meaningless work, given that work of either sort *will* be done now that the cat is out of the bag.
Not this kind of rust.
Hey, this pattern is doable (but that's not so clean I admit): #[macro_use] extern crate lazy_static; extern crate structopt; #[macro_use] extern crate structopt_derive; use structopt::StructOpt; fn env_or(env: &amp;str, default: &amp;str) -&gt; String { std::env::var(env).ok().unwrap_or_else(|| default.into()) } lazy_static! { static ref SPEED: String = env_or("SPEED", "42"); } #[derive(StructOpt, Debug)] struct Opt { #[structopt(short = "s", default_value_raw = "&amp;SPEED")] speed: f64, } fn main() { let opt = Opt::from_args(); println!("{:?}", opt); }
Not rusty enough, because the game isn't written in Rust.
I know 2 widely used libraries for 3d math: nalgebra and cgmath.
From my understanding, he said `rustup run nightly rustc` was crashing - in this, rustup just runs rustc from the nightly instillation. I... guess this could be rustup crashing, but I assumed the crash was rustc itself? It's somewhat ambiguous.
Fair enough
&gt; There must be more opportunities to use Rust custom-derive to implement DSLs for specialized serialization and deserialization problems. Coming soon to a theatre near you ;-)
If you get a minute I'd be very curious to see what your use case was so that I could see if there was a bug somewhere. `clap` is usually one of the fastest parsers, and even parsing huge CLIs with tons of complicated rules takes only a few thousand nanoseconds.
Cancerous Rust is the best/only Rust
I should probably mention, the grand goal is to move `structopt` into `clap` proper as the [`clap-derives`](https://github.com/kbknapp/clap-derives) crate. It can then get integrated as the primary way to use the results of `clap` (vice the `clap::ArgMatches` struct of today). It'll also make it easier to keep the two in sync and find/fix bug and implement features. The work has begun, I just need to finish up over the holidays. `structopt` will continue to work exactly like it does now, but with some added features like making it easy to add additional `clap` settings like ENV vars, etc. This is being done collaboratively, as the author of `structopt` is fully on board and even helping a great deal. He will remain an owner and collaborator of the `clap-derives` crate as well. The `clap-derives` crate will also offer some additional Custom Derive directives for working with enums as argument values. Once this nears completion I'll put out a blog post explaining the details and how to take advantage. If anyone is interested in finding a project to work on, feel free to contact me via the `clap` gitter and I can assist!
It _might_ have helped, as I see it does support enums to create subcommands, so perhaps it'd be powerful to enough to support the use case I was talking without additional tricks. My hunch, however, is that structopt may be a better fit for simpler apps, since clap appears to be more mature in general and appears to be a surer bet, despite the additional boilerplate involved.
I have posted it there as well my son...daughter...eh?
There's no locking with a `static mut` (unless you stick something in it which locks itself). It's hard to answer this question without some code to look at, or a more specific description of how you're moving data between threads.
structopt's derive generates clap code, so in theory you can quickly convert an app to "pure clap" using cargo-expand!
When I started out, I brought with me the conventional (Java, Python, etc.) wisdom that shadowing is bad, period. However, there are two places where in my opinion in Rust, shadowing can lead to better code: 1. If we create another binding to the same thing, but e.g. as reference (`let score = &amp;score`) or otherwise transmuted. In many cases, requiring a different name leads to naming contortions that fail to make the code remotely more readable. 2. In some cases, we can use shadowing to avoid mutation while restricting the lifetime of the shadowing value which may help the compiler to optimize better. Note that both cases are not the default. We should still avoid *needless* shadowing, but use it where it helps us.
Possibly evenwhen you chain applications together to do something, a common thing on Linux systems. If your tool would get called a thousand times, such slowness becomes a thousand times more noticeable. 
Thank you so much for this post! I just started with Rust and I spent the last 2 hours reading the Rust docs and Stackoverflow and found this by accident. The way people use the word "slice" seems to be so inconsistent, and is so confusing. I wish there were a giant "Rust syntax -&gt; 'Here is what Rust does in memory'" cheat sheet like you started below for people who know C, but have no idea about Rust concepts. 
I'm not a parser expert, but here's some thoughts. What you're doing is a bit different from how these parsers are usually used. Usually you just give it a big strong and get structured data out the other side. You can probably make it work by using a global counter for what line you're on, and append to a map line-&gt;field every time you finish parsing a field. I suppose you could create a parser that operates on individual lines, and have it output an enum based on the different line types. I don't think this would save you any effort over making a manual parser, though.
Rust isn't magic - you can still write slow code if you're not careful or profiling. Rust just makes it easier to optimize when you need to.
What's an easy way to read a binary file into a buffer (`Box&lt;[u8]&gt;` would be nice) that is aligned to 4 bytes in stable Rust?
`#[repr(align())]` should be stabilized relatively soon. Until then allocating the buffer with https://github.com/jonas-schievink/aligned_alloc.rs is probably your best bet.
How would `repr(align)` help?
Hmm, the minimum align on every mainstream platform is at least 8, so maybe you don't need to do anything at all? https://github.com/rust-lang/rust/pull/17095/files#diff-49eb27350bc2810c9cf6d430abc9ceb3R161#L153-L161
That's my experience, but I don't feel very good about it. AFAICT `Vec` is allowed to use some bizarro allocator if it wants. Maybe I should just not worry about this.
&gt; And it works... until it doesn't (งツ)ว This reminds me of parsing registry hives. Which rely on how compilers laid out data structures in memory in 1992. Never try to parse registry hives.
I appreciate your commentary about test doubles being a hassle to create in Rust - I ran into this recently myself. It would really be helpful if there were language support for using mock or fake versions of types!
You’re looking for r/playrust, this is the subreddit for a programming language called Rust.
By leveraging a browser engine to do such simple tasks you're negating any benefits you would have using rust anyway while adding a whole new layer of unecessary complexity to make your Rust program talk to Servo's inner workings, you might as well ditch rust altogether and use only html/js/css to do the job. Besides, have you ever compiled Servo? Shit takes hours to compile! You would not want to use it to build simple games. I'm pretty sure there is a way to bundle up your htmls, css's and js's into a package that can be shipped as a Chrome app that only render the app as if it was not rendering inside a browser. Rust is cool, but it's nothing more than a tool. And as such it's not always the right one for a job.
It would help if you can post what errors that you get when you try to build the packages. It's also important to specify the kind of environment you're using. Are you running things under native Windows (Command Prompt) or using some kind of MSYS/Cygwin-like shell? Or perhaps Windows Bash or something?
Writing the code more explicitly shows the real problem: If you try: use std::marker::PhantomData; // this works trait Foo { type Value; fn box_clone(&amp;self) -&gt; Box&lt;Foo&lt;Value = Self::Value&gt;&gt;; } // this works impl&lt;V&gt; Clone for Box&lt;Foo&lt;Value = V&gt;&gt; { fn clone(&amp;self) -&gt; Box&lt;Foo&lt;Value = V&gt;&gt; { self.box_clone() } } // this works #[derive(Clone)] struct Bar&lt;V&gt; { phantom: PhantomData&lt;V&gt;, } // this doesn't work impl&lt;V&gt; Foo for Bar&lt;V&gt; { type Value = V; fn box_clone(&amp;self) -&gt; Box&lt;Foo&lt;Value = V&gt;&gt; { let ref_self: &amp;Bar&lt;_&gt; = &amp;self; let cloned: Bar&lt;_&gt; = &lt;Bar&lt;_&gt; as Clone&gt;::clone(ref_self); Box::new(cloned) as Box&lt;Foo&lt;Value = _&gt;&gt; } } fn main() {} The error message is: error[E0277]: the trait bound `V: std::clone::Clone` is not satisfied --&gt; src/main.rs:29:30 | 29 | let cloned: Bar&lt;_&gt; = &lt;Bar&lt;_&gt; as Clone&gt;::clone(ref_self); | ^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::clone::Clone` is not implemented for `V` | = help: consider adding a `where V: std::clone::Clone` bound = note: required because of the requirements on the impl of `std::clone::Clone` for `Bar&lt;V&gt;` = note: required by `std::clone::Clone::clone` error: aborting due to previous error error: Could not compile `playground`. We can now see the real problem is that `#[derive(Clone)]` implemented `Clone` only when `V` is _also_ clone (this is what it does for all type parameters). So, to fix, I'd do: impl&lt;V: Clone + 'static&gt; Foo for Bar&lt;V&gt; { type Value = V; fn box_clone(&amp;self) -&gt; Box&lt;Foo&lt;Value = V&gt;&gt; { let ref_self: &amp;Bar&lt;_&gt; = &amp;self; let cloned: Bar&lt;_&gt; = &lt;Bar&lt;_&gt; as Clone&gt;::clone(ref_self); Box::new(cloned) as Box&lt;Foo&lt;Value = _&gt;&gt; } } or with removing the elaborated code: impl&lt;V: Clone + 'static&gt; Foo for Bar&lt;V&gt; { type Value = V; fn box_clone(&amp;self) -&gt; Box&lt;Foo&lt;Value = V&gt;&gt; { Box::new((*self).clone()) } }
Thanks! Rewriting the code is a good tip, I'll keep that in mind for the future. I didn't think a trait bound on `V` would be the problem since `Clone` is already implemented for `PhantomData&lt;V&gt;` regardless if `V` is `Clone` or not.
This is a major goal behind [pulling structopt into clap](https://www.reddit.com/r/rust/comments/7f6twq/in_praise_of_rusts_structopt_for_command_line/dqakkto/). It should be easy to get the best of both worlds and as seamlessly as possible access the full feature set of both.
I got it working on my machine, and commented on the linked issue: https://github.com/blas-lapack-rs/blas/issues/27#issuecomment-346915404
Yeah, that definitely catches people up a lot. I think the reasoning is that `#[derive(Clone)]` shouldn't break usages of Clone when the internals of a structure change. I guess Rust tries not to use the internals of things to infer public bounds or information. Like with how no type or lifetime inference occurs outside / between function signatures. This way, a `#[derive(Clone)]` produces an implementation which depends only on already-public information of the struct. Code using Clone on Foo won't break as long as Foo's public information doesn't change. Even with that, it is annoying at times. I've caught myself on it enough times to know that's how it works, but it's surprising to start with.
see https://github.com/rust-lang/rust/issues/26925
Lua too!
Would you mind sharing some example data? Not 500MB, but enough for a few hundred records maybe. I love making stuff like that so id be happy to help
[nalgebra](https://crates.io/crates/nalgebra) is probably what you want. It's very similar to Eigen, although it still lacks some features and performance can be a bit slower (because it does not use expression templates and explicit SIMD like Eigen). However, we already used in a somewhat large robotics project (a Visual SLAM system) and were quite happy with it. Note that nalgebra is for small stack-allocated matrices, if you need to work with large matrices you might want to check out [ndarray](https://crates.io/crates/ndarray).
You might find [d2d1test-rs](https://github.com/Connicpu/d2d1test-rs) a useful starting point. It pretty much a "hello world" that also uses direct2d for graphics rendering. There are other starting points that might be helpful, including Peter Atashian's [uitest](https://github.com/retep998/uitest). I'm having fun doing low-level Windows API programming, and expect to show off some interesting results soon.
You probably want [winapi](https://retep998.github.io/doc/winapi/) and friends, but note that it's actually broken among several packages so you'll need to have a few entries in your Cargo file.
You might also want to take a look at [winit](https://github.com/tomaka/winit)
If you're continuing development on this, I'd vote for showing the edges on the tetris grid as the next thing to add. Also, next piece preview would be great. It's good fun, though, thanks! 
How Rust handles the Windows API isn't any different to how C handles it. It's literally just binding directly to the same functions, with exact equivalents for the types and constants. In regards to callbacks: assuming you're using the correct calling convention on said callbacks, it should all work just fine. But without the code in question, I can't do more than guess.
It's hard to give beginners a general principle to work after. There's some knowledge needed to understand when shadowing is used in a good way, and when it's not. Thanks.
Tried it last night and it worked great except for the ordering of arguments. E.g. I want to supply a file argument at last and alle the flags before it. Didn’t figure out how to do it. Documentations seems to miss that one. If someone could help me out, that’d be great. 
For implementations of SE3 and SO3, [nalgebra](http://nalgebra.org) and [cgmath](https://crates.io/crates/cgmath) will both have comparable feature. cgmath however will usually be easier to use than nalgebra (as it relies much less in templates). Both nalgebra and cgmath have matrix and quaternion representations of SO3, and have combination of a matrix/quaternion and a vector for elements of SE3. If you need matrix decomposition (without having to install Lapack), I believe your only choices are [rulinalg](https://crates.io/crates/rulinalg) and nalgebra. However, rulinalg works only on heap-allocated matrices and some of its decomposition have [issues](https://github.com/AtheMathmo/rulinalg/issues/191). nalgebra works both on stack-allocated matrices (e.g. Matrix3x5) and on dynamically allocated matrices (e.g. DMatrix). If you need higher order tensors, [ndarray](https://crates.io/crates/ndarray) is your only choice. In any cases, none of those crates are optimized for very large matrix decomposition. If you need this, you can use crates based on blas/lapack binding. Some of them are [linxal](https://crates.io/crates/linxal) (using ndarray for its matrix types), [ndarray-linalg](https://crates.io/crates/ndarray-linalg)(also using ndarray for its matrix types) (also based on ndarray), and [nalgebra-lapack](https://crates.io/crates/nalgebra-lapack) (using nalgebra for its matrix types). Note that you may refer to [this page](http://www.nalgebra.org/decompositions_and_lapack/) of the user guide on nalgebra to get an idea of available decompositions. I believe all the crates mentioned here are quite popular, so your actual choice strongly depends on your application. Though if you prefer to use a single crate for both SE3/SO3 implementation and decomposition of small (stack-allocated) and medium-sized (heap-allocated) matrices (just like Eigen), I believe nalgebra is currently the only option.
Yeah, naming is hard. If `basin` is a synonym for `pool`, then `basin::pool` is quite a bit strange. If the main difference of your thread pool is the thread local state, I might have just used `scoped-threadpool-with-state` as the crates name. About the code side, I think that `Threadpool::new` is the most telling name and also kidiomatic Rust.
"batteries included" approach is a no go for systems programming language. So Rust's std library is and should stay as a set of bare minimum essentials. This way deprecation and code rot would be as rare as possible. Isn't it great? :)
To create an argument, just put a field wothout `short` or `long` annotation. There is already an issue for documentation clarrification: https://github.com/TeXitoi/structopt/issues/33 And to answer to your case exactly, try something like that: extern crate structopt; #[macro_use] extern crate structopt_derive; use structopt::StructOpt; #[derive(StructOpt, Debug)] struct Opt { #[structopt(short = "i")] i: bool, #[structopt(short = "v")] v: u64, file: String } fn main() { let opt = Opt::from_args(); println!("{:?}", opt); } 
Thank you for the example, but that wasn’t the issue. My problem was the ordering of the arguments. ./foo file -a -b was possible, ./foo -a -b file was not. Sorry if I didn’t make myself clear. 
I linked an example above, maybe you missed it: http://www2.ifb.uni-stuttgart.de/fem/Tutorial8_Crash_SimpleTruck/Explicit/Truck_Front.pc Or would you want an example for something else? Not sure right now, let me know :)
[I wrote a (slightly modified) tetris clone too, last year.](https://github.com/anthonyclays/tetris)
Yeah I figured my use case is a bit off :) Thanks for your input!
Native windows gui project source is probably a good reference: https://github.com/gabdube/native-windows-gui
* https://github.com/rust-lang/rust/blob/59bf09d4d473c803609d3ad925a0ebf13bdbb0ab/src/libcore/cmp.rs#L759-L783 This is a canonical link of the link above. So it points ever to the same section of the file. The section in the link from fgilcher can change if anybody change that file on GitHub.
More like deciding, the interface is just another library. That means that it can be updated, improved, changed... as needs arise, semantic versioning is what prevents everything from breaking. You still can run into the problem of trying to use two libraries that are using different major versions of the interface, and cannot thus interoperate, but this is something that you notice when you add a library to your project, or update the major version of another one, not something that can break behind your back.
Ok, I renamed it to [pond](https://crates.io/crates/pond) because it's one character shorter, it sounds more like "pool", and I subjectively prefer the sound of it. I kept the API exactly the same.
Oh great, I've been wanting that for a GitHub bot!
Small details: - Storing data inline is much more general than just stack allocation. We can use a `Vec&lt;[T; 3]&gt;` for example, and the array elements are inline in the array value, hence inline in the vectors's own *heap* allocated buffer. - I think nalgebra can do both small matrices with inline storage and heap allocated dynamic size ones. In particular, see its MatrixVec storage - Of course ndarray has some really nice features too, and I could answer questions about it.
I have created a small example. https://github.com/hummingly/simple-window-rs/blob/master/src/main.rs All it does, is creating a window with the title "Hello Windows!". I've added something in the message handling function, so when you click the close button it will terminate the process successful.
I just released the beta-2 yesterday, feel free to try it and report any issues you might experience. Note, though, that the syntax and maybe also some semantics of the API are not documented yet and may change (even after 0.1.0)!
Yes, it's very confusing I find. I'm not sure where the essence of the problem lies. Something to do with terminology, or overlapping concepts, or maybe just the way it's explained. After a few days of digging I have a clearer picture in my head even if I find some of the terms misleading. Glad it could help!
Yeah, I _admire_ `clap` and its ergonomic face, `structopt`, but man they are heavy-weight dependencies. The two numbers of interest are debug build times and stripped release binary sizes - so I'm getting about 1.6s and 1,2Mb (yes, that's stripped). Whereas with something dinky like `lapp` the numbers are 0.7s and 575Kb. So, although I admire these packages, I tend to use more lightweight dependencies for dinky little programs. 
Nice. It doesn't seem to compile anymore though on current nightly... ``` error[E0642]: patterns aren't allowed in methods without bodies --&gt; /home/danilo/.cargo/registry/src/github.com-1ecc6299db9ec823/rustc-serialize-0.3.19/src/serialize.rs:147:45 | 147 | &amp;f_name: &amp;str, | ^^^^^^^ ```
Ahaha. God damn moron.
i did it too! https://github.com/chinatsu/ggetris it's not great though. using ggez
Huh, strange that such a backwards-incompatible change was merged. A `cargo update` seems to update rustc-serialize to a working version though (0.3.19 -&gt; 0.3.24)
Fortunately, winapi is being consolidated into a single crate with 0.3 and its module layout will follow the Windows SDK headers.
The example I gave: texitoi@vaio:~/dev/test$ ./target/debug/test file -i Opt { i: true, v: 0, file: "file" } texitoi@vaio:~/dev/test$ ./target/debug/test -i file Opt { i: true, v: 0, file: "file" } texitoi@vaio:~/dev/test$ So I can't reproduce your problem. Please give an example with the expected behavior, else I can't help.
Backwards incompatible changes are merged if the most recent versions of all the broken crates compile.
Not yet but I planned to make it public after a bit note work.
Hmm. I'm guess I'm going to try again. I thought that it should be that simple, but I was probably doing something stupid. 
Hello, currently going through the book, I'm having trouble with the `?` operator hoping someone can help clarify My current understanding is that the `?` requires a `Result&lt;Ok(),Err()&gt;` return type on the function and will "unwrap" if `Ok()` and return the error if `Err()`. There is the following example in the book that works fine: `File::open(filename)?;` String parse looked like another method this would work, so I did: `let ip = "10.1.1.10".parse::&lt;IpAddr&gt;()?;` To my surprise this return an error "the `?` operator can only be used in a function that returns `Result` (or another type that implements `std::ops::Try`)" I initially thought it was because of the "turbofish" so I tried `let ip: IpAddr = "10.1.1.10".parse()?;` and got the same error msg. I tried printing an Ok case and Err case using `{:?}` and sure enough they are there... What am I doing wrong with the `?` operator?
Are these good libraries to use for doing 2d or 3d in rust? Seems like there's a few options...
I always use `derivative` which allows to limit the bounds for derived impls. So in this example it would be #[derive(Derivative)] #[derivative(Clone(bound = ""))] struct Bar&lt;V&gt; { phantom: PhantomData&lt;V&gt;, }
I think you want /r/playrust. /r/rust is for the programming language Rust.
You can look at this code from my crate [here](https://github.com/obv-mikhail/InputBot/blob/master/src/windows/mod.rs) which uses low level hooks to listen for keyboard events (and mouse).
This is what happens when you don't have namespaced crates. 
Any language, you mitigate the trusting trust by compiling through like twenty random languages because it's hard to make twenty different compiler hacks.
It is mostly going to be your comfortablity level with being low level. Using gl + glutin means I have to do a lot more just to get basic stuff on the screen a or to hear if an input event has occured and reading c++ opengl docs, but I also get to do a lot more. I would say they do there work pretty well, but I also don't mind putting in the extra effort.
Hi there folks, I just wanted to share the slides of a presentation that I've presented recently on TheDevConf Porto Alegre, Brazil. The target audience are people who might never heard of Rust, set some context, share some of the experience coming from JavaScript and Ruby and then showcase building a website. I've tried to put a bunch of links for other contexts, beyond webdev, otherwise it would become a massive presentation. I hope you find the content interesting, specially as it is on another language. If there are any feedbacks I would love to hear. Cheers!
And 0.3 is close to release! (At least in terms of progress, no idea about time).
I have a very similar makefile. Thinking about how to use 'cargo metadata' to remove some of the hardcoded-ness.
https://rust.godbolt.org ?
That's also what Rc&lt;RefCell&lt;T&gt;&gt; does, but RefCell is not thread-safe. This doesn't matter in GTK though. 
Nalgebra however has a user guide including reference sheet etc: http://nalgebra.org/getting_started/
Decentralisation is a principle, not a solution to capacity issues. 
There is an RFC for the entry API to make it work with borrows: https://github.com/cristicbz/rfcs/blob/entry-into-owned/text/0000-entry-into-owned.md
&gt; I hope you find the content interesting, specially as it is on another language. If there are any feedbacks I would love to hear. I must admit that for me, the "other language" kinda kills any interest simply because I cannot understand it ;P
Most of the optimization work is done in LLVM, and I don't believe it is possible to get that information out of LLVM... so I don't believe so.
I think it would be cool if you could see what the compiler was inferring your code to be, so you could automatically convert code into the more explicit version once your satisfied with it.
&gt; For example, if, in each iteration of a loop, a variable is set using an identical memory read or function call, it would be neat to see whether the compiler can figure out that it doesn't need to fetch or compute the value more than once. Loop hoisting is indeed a potential optimization. It generally rely on: - the expression evaluated being pure of any side-effects (provably), - the inputs being constants across evaluations. I do suggest however NOT relying on optimization and simply perform said hoisting manually whenever critical. It seems more reliable. &gt; Also, could one write test cases that detect when, due to a code change, a particular optimisation no longer is made? There are two potential levels of optimizations with the current architecture of rustc: - optimizations on MIR, - optimizations on LLVM IR. It seems possible to develop annotations which would check that certain optimizations are applied, or certain algorithmic complexities are met, especially for checks on MIR. LLVM IR would of course require deeper integration with the LLVM passes. However, one of the key aspects of optimizations is that they can "mangle" the code beyond recognition. Piling on inlining, loop hoisting, loop exchanges, common sub-expression elimination and constant/range propagation can really do a number on code. As such, I am unsure as to what exactly could be proven. Measuring the number of access to a function, for example, is a little more difficult when the function code has been inlined and scattered; parts of it peeled away, parts of it merged as redundant. As Chris Lattner mentions in his recommended mini-serie [What every C programmer should know about Undefined Behavior](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know_21.html), tying back code after optimization to written source code can be challenging: &gt; warning: after 3 levels of inlining (potentially across files with Link Time Optimization), some common subexpression elimination, after hoisting this thing out of a loop and proving that these 13 pointers don't alias, we found a case where you're doing something undefined. This could either be because there is a bug in your code, or because you have macros and inlining and the invalid code is dynamically unreachable but we can't prove that it is dead. I am afraid it would apply here; rendering all but high-level optimizations inscrutable.
&gt; you have macros and inlining and the invalid code is dynamically unreachable but we can't prove that it is dead. That sounds like it would count as unsafe code in Rust. Would you say so?
I believe if you hover over a variable, it'll tell you what type it is. IntelliJ puts little annotations that are visible all the time, though that doesn't use RLS.
LLVM has been adding optimization diagnostics and an opt-viewer tool. Here's some [slides](https://llvm.org/devmtg/2016-11/Slides/Nemet-Compiler-assistedPerformanceAnalysis.pdf) (PDF).
Yeah, that's sort of where I was taking the idea from. But it would be nice to have that in RLS, with the further ability to automatically expand implicit code with the previewed explicit code.
It is actually possible to get this info from LLVM! If you do rustc lib.rs --emit=llvm-ir --crate-type=lib -o lib.ll # no optimizations yet /path/to/llvm/bin/opt lib.ll -S -O3 -o lib-opt.ll -print-after-all You will get a list of the sequence of optimization steps applied by LLVM to the LLVM assembly generated by rustc.
`--emit=asm` is your friend! (though you can also use `--emit=llvm-ir`) I have a repository which does exactly this kind of analysis (on simple cases) at https://github.com/djzin/rustc-optimization. It uses `--emit=asm` and tests that the length of the generated functions is just 1 line (retq).
You're right, that seems to work. And your Tetris really is a lot of fun. Initially I thought it's gonna be way too easy, until I realized that you can get your bricks stuck for good if you're not very careful...
"we can't prove that it is dead" does not mean unsafe code. The compiler can't prove every property of all code, but it can prove some of the properties of some of the code.
&gt; "we can't prove that it is dead" does not mean unsafe code. As I understood the example, there was a case of undefined behaviour, which sounded to me like it would be an error in the context of Rust. Then again, that's probably irrelevant, since it was about C. I think I made the mistake of jumping from one to the other.
&gt; I have no idea if scalability issues are arising, however decentralization of hosting resources could be implemented 
[**English machine-translation**](https://translate.google.com/translate?hl=en&amp;sl=pt&amp;tl=en&amp;u=https%3A%2F%2Fpresentations.bltavares.com%2Fnunca-ouvi-falar-de-rust%2F)
If the constructor-like method has parameters for all the fields of the struct, and there's not any other required setup, I don't seen much benefit, but for most useful structs there are private fields and work that needs to be done to initialize them.
To be honest, this sounds more like an insane architecture in the making. Not only does Https already support client validation, [Certificate Request][Certificate Request] in TLS1.2, as well as replay resistance and confidentiality (so they're paying for crypto twice if they use tls). But also transfering microtasks such as `getQuery` from url parsing across language boundaries, moving/creating objects every time sounds more like something you would hear from someone who just associates `native` with `fast`. There probably is a case to be made for rust, the code does indeed look clean and consice compared to what one would expect from a C++ node module. But that example is either chosen unfortunate or not the result of good software engineering. Given that there were even benchmarks run, we just can't be sure really. Just my two cents. [Certificate Request]: https://tools.ietf.org/html/rfc5246#section-7.4.4
I would have enjoyed hearing if/how well rayon worked on the 128 core AWS instance.
Thank you for pointing out client validation it is indeed a better approach to solve the given problem, and yes you’re also right about the code quality, most of that code was written for demonstration purposes, and they would not fit a production environment by any means. This is barely an experiment of mine to see if it is possible, also the benchmarking was only made to demonstrate that it might not be a significant speed gain. The point of this post was not to optimize query parsing, but to demonstrate multiple ways of using the Rust language with NodeJS.
I take it you are the author of the article? Then maybe you can change the bit about ` Url::parse(&amp;url).unwrap();` which could be made to panic by a crafted, invalid url (by a still unvalidated request). I think showing proper handling with `map_err` and `?` will show off both the rich safety guarantees of rust and good programming style. 
Oh definitely. And that’s borne out (relative to Haskell at least) for me. I just worry that when it makes certain things hard, the whole idea of “write all this low-level code by hand and optimize it yourself” starts to look a lot less appealing. The less often that’s the case, the better (in my view).
Do you have a link to your use case? Because a plain Hello World in Rust will be ~440 Kb stripped (just plain `strip` nothing complicated). In my experience those ~300 Kb difference between `clap` and `lapp` are usually worth it because it's doing useful things from a user point if view. Although I haven't used `lapp` extensively so I can't really speak to all the functional differences (from a user perspective, not developer). Anyhow, if I can trim down areas beyond just using `default-features = false` (which cuts out some), I'd be interested to look! ...and I *know* there are plenty of areas I could trim :)
Thanks for posting the link! The translation has a few mistakes (cargo=charge, genderless `pessoal`=gendered `guys`), but it is still possible to understand the general idea of the presentation, from what I've seen.
The site shouldn't mess with the browser's history. I had to close and reopen a new tab because I couldn't go back here after pressing back like 10 times.
I've also wrestled with how to dependency-inject a test-double for my unit-tests, while keeping my interface simple for external callers, but the solution mentioned in this post is better than anything I'd come up with. Thanks for mentioning it! One thing I'd add: if you write a library in Rust, you should define a trait for each struct in your public API, so that other libraries can supply their own test doubles for your library.
Slide 6: "Qatas falhas" =&gt; "Quantas falhas"
I expect the presentation to be quite readable and understandable after translation. Translating tech content from English to Portuguese is a widespread usage of Google Translate in Brazil. There are mistakes, but it is often not that bad. Finding tech content, and Rust content specifically, in my native language is not really common. I find it very refreshing when I get to read Portuguese posts. If after the auto-translation you don't find the presentation too much terrible, would you mind if I ask to share it? I would love if the content reaches and motivates at least one native speaker struggling with English to join the Rust community. 
Obrigado! Corrigido já (:
It really shouldn't be worrying. It's among the current state of the art as far as I'm aware for a general purpose programming language.
Nice project! 
You're probably looking for /r/playrust
How do you use tokio without threading?
[removed]
```rust let mut window = MainWindow::new(); window.start(&amp;message_fetcher); let message_fetcher_clone = message_fetcher.clone(); let mut message_store2 = MessageStore::new(); // let tx_clone = tx.clone(); std::thread::spawn(move || { loop { let mut data = TEST.write().unwrap(); data.set_messages(message_fetcher_clone.load_messages()); // let mut data = (&amp;message_store2).clone(); // let new_messages = data.get_messages(); // data.set_messages(new_messages); println!("Data sent..."); // tx_clone.send(data).unwrap(); let five_secs = std::time::Duration::from_millis(5000); std::thread::sleep(five_secs); println!("Child loop..."); } }); let mut window_clone = window.clone(); let data = TEST.read().unwrap(); gtk::timeout_add(5000, move || { println!("GTK Loop: Begin."); // let data = TEST.read().unwrap(); // println!("Data received!"); // let rec = rx.recv().unwrap(); // window_clone.add_messages(&amp;rec); window_clone.add_messages(&amp;data); window_clone.show_all(); window_clone.scroll_to_bottom(); // println!("Receieve Data -&gt; {:?}", rec.messages[0]); println!("GTK Loop: Complete."); gtk::Continue(true) }); ```
It seems like you could avoid the "please install the correct version of ctags" depedency by just writing out the tag files yourself, although you might want to depend on ripgrep to do the recursive regex searching. ``` rg --line-number '^\s*(pub\s+)?struct' | sed -E -e 's/([^:]*):([^:]*):.*struct ([[:alpha:]][[:alnum:]]*).*/\3\t\1\t\2/' FakeError src/reqwest_mock.rs 72 FakeResponse src/reqwest_mock.rs 92 FakeClient src/reqwest_mock.rs 121 BrokenClient src/reqwest_mock.rs 167 CacheRecord src/db.rs 22 Rows src/db.rs 33 Transaction src/db.rs 52 CacheDB src/db.rs 98 GenericCache src/lib.rs 81 ```
You don't want to reassign the reference itself, you want to write to the reference (modify the refered value). So just add a dereference when assigning: *left = Box::new(Some(Binary_Tree::new(value_to_insert))) Actually, you don't need to create a new box, you can make use of the exiting one. Add one extra dereference (dereference the box), and remove `Box::new` on the right hand side: **left = Some(Binary_Tree::new(value_to_insert)) About the second part: `Option::unwrap` consumes the `Option`, but you can't do that: you don't own it, you only have a reference to it. You can use `Option::as_mut` to convert that option to `Option&lt;&amp;mut Tree&gt;`, which you can then unwrap: return (**left).as_mut().unwrap().add(value_to_insert); You need two dereferences on left: first to dereference the `&amp;mut _`, and the second to dereference the box. Box also has `as_mut` function, which is why you have to get through the box first - so that the compiler would see that you are using `Option::as_mut`.
Replacing one with another dependency doesn't help that much. Regarding the performance, `rusty-tags` has quite a bit of caching going one, so the second call should be for every project pretty much instant. I thought a few times about replacing `ctags` with a Rust AST parsing library, but then changes in the language might generate more work on my side. I think most people using `rusty-tags` might already had `ctags` installed or its an easy install for them, so it doesn't really bother me that much. 
Well, I've never had the need to install ctags before, and now I've learned there's "exuberant-ctags" and a fork named "universal-ctags", where "exuberant" is the one that Debian packages, and "universal" is the one that's actively maintained, and with all the good features. I'd much rather `cargo install rusty-tags` than convince Debian to switch upstreams, or to git-clone and build ctags myself from source all the time.
[](/disappoint) /r/playrust
This will remain my favorite clip of rust all my life.
Slowly learning how to do procedural macros (aka "macros 1.1") in order to build a somewhat reverse-bindgen for rust-WASM in JS. I was wanting to use rust with the new emscripten-less wasm target for a JS project I'm working on, but found myself spending the majority of the time writing code to convert between JS and rust types. So: writing something to automate that.
std::mem::replace and mem::swap are two very useful functions
&gt; I'd much rather cargo install rusty-tags than convince Debian to switch upstreams, or to git-clone and build ctags myself from source all the time. I don't know what you're talking here, just install the debian `ctags` package and you should be fine. Sure, everyone wants an easier life, but someone has to do the work. 
I've started using Rake for anything more complicated than a trivial Makefile. Fundamentally the same underlying technology as Make but a decent scripting language to manage it in.
I am using Makefile for both my rust and go projects. I'd like to take a look at Justfile for my rust projects in the future.
I thought rust did automatic deferencing? Is it only in some cases?