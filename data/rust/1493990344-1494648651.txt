The important page here is [the tracking issue for this feature](https://github.com/rust-lang/rust/issues/39817), which shows two outstanding issues. Also, having the feature in the compiler isn't a great indicator as to when it'll be ready; `impl Trait` has been "implemented" for a while now.
The diagrams from this Craft talk are all ascii-art that is run through a tool I made called `mon-artist`. You can see them all by looking at the [source](https://github.com/pnkfelix/presentations/tree/craftconf-2017/craftconf-2017/src) for the slide deck, e.g. the sequence titled "Sharing Data" comes from this [markdown](https://github.com/pnkfelix/presentations/blob/craftconf-2017/craftconf-2017/src/a03_sharing.md) The `mon-artist` tool itself still needs some more work. Here's its [source code](https://github.com/pnkfelix/mon-artist), but perhaps more interesting is the [PADL presentation](http://pnkfx.org/presentations/monartist-padl-2017-slides.html) I gave on `mon-artist`.
&gt; really outdated/useless package How do we decide whether a particular crate is "really useless"? Is there an objective criteria that doesn’t involve someone’s preferences? How is *that* criteria decided? This kind of thing can be really tricky. The current policy (never taking a name away from someone) avoids all of this.
It's also no guarantee it will stabilize soon either. Box syntax has been around forever.
Why'd ya have to remind me of that one? :'(
What does the trait definition look like?
https://georust.github.io/rust-geo/geo/algorithm/contains/trait.Contains.html
&gt; Saving is how they get capital. It's trivially verifiable by speaking to some small business owners; I've met quite a few who got nothing from their parents, and created their business with the money they saved from regular work. Small business owners are often not rich (imagine your local fish and chip shop, bakery, hair salon, etc.); many make less than e.g. a software engineer at Facebook. Next time you see a business ran by immigrants, ask them where they got the money to start it, you might be surprised. It is simply not true. If you're broke and what not, you can only get trivial amounts of money by saving. It's really weird that you even deny that. &gt; This has been tried, and it turns out to be really hard to plan, because you can't know what people want better than they do. It seems that you think the only form of socialism is leninism and other forms of centrally planned state socialism? Because, several other approaches exists. And saying that socialism has failed is almost cheating. Self-proclaimed socialist countries did not "fail", in the classical sense of the word, it was either corrupt from day one (see: leninism) or was destroyed from the outside (see: US imperialism). As for "successful" (outside capitalist forces has almost always destroyed these attempts) cases of these, look up Catalonia, Rojava (exists today), Paris Commune etc.. Soviet Union failed to instate socialism. It lacked democratic control of the means of production. If anything, it was just a small class of people who wanted to control everything through the state. &gt; Money is like a system where everybody has a vote; if they give it to a business (e.g. buying things), it means what the business produces is valuable to them. The extent to which they're able to vote with the money is limited by how much value they're created for others (as barring inheritance if they want money they need to do something that others' value), so their spending transitively reflects the preferences of everyone in society. There's no equivalent way to centrally gather the preferences of everyone in society, especially given peoples' preferences change over time. A dollar is a vote, yes, but that's the problem. A dollar—not a man—is a vote. The capitalist class is unelected, yet gets to decide what happens to the means of which you feed your family. There is nothing democratic about capitalism. Capital will accumulate to the hands of the few, and they will have much more power than the average worker. And, it is demonstrably false that the rich's interests represents the interest of the society as a whole. Trickle-down economics have been disproved, thousands of papers on the subject have been produced. The rich has interests distinct from the workers. The rich wants to get more money, the workers wants to be a live a life worth living, they know (maybe America is an exception, as the class consciousness is at its rock bottom) that they won't be rich. Their concerns are about keeping their job, affording food and other basic necessities, and paying their rent. &gt;There's also the matter of incentives: people have less incentive to put in the sacrifices necessary to run a business if they don't stand to benefit much from their efforts in future. As for the point of incentive, I cannot stress my disagreement enough. The whole point of socialism is proportionality: You wage shall be proportional to your productivity. It is a crude misrepresentation of socialist thought that there would be no incentive. In fact, I'd argue that socialism is all about creating incentive for people to work, start the own businesses, and letting them grow. The thing is today that a lot of people have all sorts of ideas, but simply cannot put them to life, because they lack the necessary capital to do so. Futhermore, you are _not_ paid proportionally to your work today. If you own a big business, you can retire and do virtually nothing, yet still make extreme sums of money. A CEO makes several orders of magnitude more than a Chinese sweatshop worker, etc etc. If the capitalists had no way to take surplus value, the workforce would be significantly stronger, and your hard work would be paid respectively.
One thing I find annoying in these cases is that it generates warning for both, often in opposite order (I think that having warning for `apparently_using` would be more natural. There could be an explicit separator too like this: ================= Transitively unused items: ...
&gt; but it can also make it confusing to tell the root thing which isn't being used This. I believe it should be improved, as I [already suggested](https://www.reddit.com/r/rust/comments/69bm0r/why_does_rust_warn_me_that_im_not_using_methods/dh5zhmp/).
Upon starting VSCode it tells me that RLS is not installed. I tried installing it manually via its github page but this is the error when i run: rustup update nightly C:\Users\Viking&gt;rustup update nightly info: syncing channel updates for 'nightly-x86_64-pc-windows-msvc' info: downloading component 'rustc' info: downloading component 'rust-std' info: downloading component 'cargo' info: downloading component 'rust-docs' info: installing component 'rustc' info: rolling back changes error: failed to extract package info: caused by: failed to unpack `rustc-nightly-x86_64-pc-windows-msvc/rustc/sh are/man/man1/rustdoc.1` into `C:\Users\Viking\.rustup\tmp\b_l9kfm7fpxw885u_dir\r ustc/share/man/man1/rustdoc.1` info: caused by: A rendszer nem találja a megadott elérési utat. (os error 3) Basically Path not found. Now VSCode tells me i can install RLS, but before that i need to update rustup. I click oka and nothing happens. Terminal: C:\Users\Viking&gt;rustup update info: syncing channel updates for 'stable-x86_64-pc-windows-msvc' info: checking for self-updates stable-x86_64-pc-windows-msvc unchanged - rustc 1.17.0 (56124baa9 2017-04-24) 
Both of which make it less pragmatic imo but I'm also a performance geek.
Because maybe one day we'll get it. I hope :'( We just need to make it more visible
Ah, I know they do something financey :)
Awesome!
Not trying to be rude or anything, but there are so many issues with anarcho-capitalism, and I don't have the time nor energy to discuss them. I'll sum my point up against it as this: I care about the goal, but not about the means to get there. The goal (well-being for all) should be obtained by any means necessary. I don't care about property rights or "initiation of force" or whatever, I care about people not starving, being able to enjoy life, etc., and I don't think capitalism (to even consider voluntarism!) provides any of that. Anarcho-capitalism is even worse, as it has no way of dealing with horrifying crimes against the small person without much capital. It will be a purely unrestricted form of oppression.
I'm not familiar with the codebase, but I suspect that you've introduced an ambiguity where there previously wasn't one. The problem *looks* like there used to be a single applicable `impl` for resolving that `bbox.contains` call, but with your added implementation `for Bbox&lt;T&gt;`, it now has more than one possible match. If it's got only one match, it can try coercing the type to make the call work, but with more than one the compiler might not be able to work out what it's supposed to coerce to. Maybe try writing that line out in full and see if that fixes it. Something like `Contains::&lt;Bbox&lt;T&gt;&gt;::contains(bbox, self)`. If that *does* work, then introducing a new `impl` might be a breaking change (*i.e.* you could break the code of people using this crate).
Garbage collector, so you don't have to bother about lifetime, borrow checker and that help productivity a lot. A lot more of libraries (if you add java libraries, with which scala automatically bound to, scala can't be beat on that point). They both have slow compile time though and strong type system.
Most of the time you don't need that. Just add a lot of complexity to the project for bonus you don't mind about (scala is still way faster than python/ruby/php/javascript). 
These two issues seem to differ by an order of magnitude though, and apart from bugs there don't seem to be reasons against it. But there are always more bugs to be found - finger crossed!
I managed to install the nightly like that, then i succesfully added the components to that build and set it as default toolchain by : C:\Users\Viking&gt;rustup default nightly-2017-05-01 But now VSCode freak out on autocomplete request: thread '&lt;unnamed&gt;' panicked at 'could not create cargo workspace: ChainedError { error: failed to read `d:\WorkSpace\Code\RUST\Synth_Test\Cargo.toml`, cause: A rendszer nem találja a megadott fájlt. (os error 2) }', src\libcore\result.rs:859 It can't find the file. Which is actually in Synth_Test\hello_world\
Then we have different priorities. That's fine too, I know there have been times where I just wrote something in C# because performance for it was unimportant. When I think performance is important though I turn to Rust.
We think discoverability can be solved through other means rather than just relying on the one signal of what the crate is named. See [RFC 1824](https://github.com/rust-lang/rfcs/pull/1824) for one such initiative.
&gt; as it will require to solve tricky questions and could potentially generate a negative reaction if done wrong. Also making these kinds of subjective decisions takes time that we'd all rather spend working on Rust.
The thing is, everything that undefined behaviour could cause, a logic bug or human error could also cause. So trades should ideally go through at least two separate applications (separate binaries), as the chance of the limits/failsafes in both failing at the same time is much smaller. So while Rust would eliminate some bugs, it wouldn't eliminate logic bugs (at least not until there's dependently-typed Rust), so these failsafes would still be needed. It's achievable to a relative degree of confidence; 100% confidence wouldn't be possible without writing/proving everything in Coq or the like. It costs a lot of dev time; if you've ever tried to achieve over 90% unit test coverage on a large application, imagine that kind of sluggishness. But it's still a lot less than the cost if something went seriously wrong due to insufficient failsafes. 
I am slightly concerned about how confusing the performance landscape is around all the function types. There are `fn() {name}` types which are statically dispatched, but these `fn()` types are dynamically dispatched. Of course `|x| x` is a `[closure]` type which is statically dispatched as normal but the only way to return a statically dispatched closure is still with `impl Fn()`. You can return `&amp;Fn()` instead, but rather than just using *two* indirections (lookup the vtable and then call the function), the implementation currently uses an inefficient three (lookup the vtable, *dereference* the function pointer pointer, call the function), though this may or may not be fixed some time in the future. If you want to return a function without using `impl Fn()` you want to return a custom type and `impl Fn()` for that type, which is then a static function call, but if you convert *that* to an `&amp;Fn()` it's a **single** indirection (remember `fn()` to `&amp;Fn()` has three indirections but could be two). 
I hope it won't have a breaking change. I realised that I have code that depends on the T: Copy bound from derive, and a chang would become a memory safety bug.
True, but I think with strict enough objective rules (e.g. crate not updated at least for 1-2 years, there is someone who interested in it and if crates.io team can't contact owner for say 6 months) requirement for subjective decision will rarely arise, so it will not take much time from improving Rust, while potentially it could significantly improve crates discoverability especially for new users.
Java compatibility?
Not having lifetimes might make it easier to write code, but they're still useful. Borrow checking isn't just about eliminating the need for gc, it also helps catch non-memory bugs. 
Yes but judging by my own experience of rust, lifetime is so hard to learn, I don't think it is worth it.
Are you sure you aren't creating an `&amp;&amp;Bbox&lt;T&gt;` when you do `contains(&amp;self)? It's my guess that `self` is already an `&amp;Bbox`, and thus by using the matted on `&amp;self` you're inadvertently asking for an impl for the method on `&amp;&amp;Bbox`, which means a trait impl for `&amp;Bbox` (different from a trait impl on `Bbox`.)
In my own experience, it's not hard. It takes a couple weeks to get the hang of things, but that's true of any language. The difference is that when you mess up lifetimes, you get a compile error, rather than mysterious runtime errors.
Is it possible to rollback the current one to the previous nightly, so others don't download and flip a table?
the weird thing is earlier in the code there is this: impl&lt;T&gt; Contains&lt;Point&lt;T&gt;&gt; for Polygon&lt;T&gt; where T: Float { fn contains(&amp;self, p: &amp;Point&lt;T&gt;) -&gt; bool { match get_position(p, &amp;self.exterior) { PositionPoint::OnBoundary =&gt; false, PositionPoint::Outside =&gt; false, _ =&gt; self.interiors.iter().all(|ls| get_position(p, ls) == PositionPoint::Outside), } } } impl&lt;T&gt; Contains&lt;LineString&lt;T&gt;&gt; for Polygon&lt;T&gt; where T: Float { fn contains(&amp;self, linestring: &amp;LineString&lt;T&gt;) -&gt; bool { // All points of LineString must be in the polygon ? if linestring.0.iter().all(|point| self.contains(point)) { !self.intersects(linestring) } else { false } } } which works fine. The only real difference I see is that the Bbox impl is for it's own type.
I still don't see why box syntax is actually needed. Do we really need dedicated syntax just to ensure that a particular compiler optimization happens? Why can't it be an attribute?
The real problem is the inability to name closures. There's no reason why impl Foo should be necessary to return closures.
&gt; It is licensed under the AGPL. I'd wager you'll get more feedback about this than the code itself. ;-]
Sorry for the late reply. Busy. Yeah, nothing is simple. That's why I think comparing the two at paragraph level might not be completely relevant when mashing together a few words. Anything more than that, and you are probably naming your variables wrong, so point taken. Did you mean 'camelCase' in your second paragraph? That would make more sense, I think. Maybe a freudian_slip? :-)
Do you have the same issue with `unimplemented!` or `unreachable!`?
Random thought: what if there was a distinction between "`unwrap` because I'm lazy" and "`unwrap` because it can't fail". Maybe use `unwrap` for the former, `assert_ok` for the latter. Then add a lint which detects usage of `unwrap` that is `allow` on debug builds and `warn` on release builds. That way, we can continue to use `unwrap` in simple examples without necessarily training new users to spam it everywhere, whilst keeping the more explicit `assert_ok` for when it's actually needed.
Devil's advocate: we already get lots of people complaining about code examples that don't compile in isolation. I'm unconvinced that adding considerable fuel to the fire is going to improve matters.
It really depends on the products. The easier it is to determine the "fair value" of a given product, the less variability there is between competitors, and therefore the more speed matters. The extreme is the valuation of "futures" based on the variations of their underlying, in which case the mapping is a 1-to-1. The problem is that the relationship between reaction time and profit/losses is not linear, it's a threshold game: - consistently faster? you get close to 90%/95% of the trades you want - about as fast as your competitor? even split - consistently slower? you get maybe 5%/10% of the trades you want And for futures, where speed is of the essence given the simplicity, it's literally a matter of a few nanoseconds (did you know that a 1m network cable costs 3ns in latency?). And therefore futures are a "Faster Take All" kind of market. The next in line are options: slightly more difficult to value, but [Black-Scholes](https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model) is well known, so once again everyone tends to attempt to react on the same signals at about the same speed. Thus checks are pulled out of the "reaction loop" as much as possible: compile-time, fuzzing/instrumented test runs to valid binaries, pre-computed/pre-validated stuff at run-time... Anything to shave off time. --- At the other extreme, ETFs are extremely complicated to value, and there the reaction time matters less: smarts take over. Of course, at equivalent smarts, the faster still wins.
Closures can be named, it's the type of an individual closure that can't be named.
Yes, if it's not blatant it would be difficult; I guess it becomes a matter of ethics then. Then again, putting any quote in the market remains a bet: quotes are sitting ducks, and spoofing the market relies on your ability to pull your quotes faster than your competitors can fill them, so you have to be quite confident to play that game, and it could turn on you very quickly.
&gt; Did you mean 'camelCase' in your second paragraph? That would make more sense, I think. Maybe a freudian_slip? :-) Thanks for catching that. I'm currently in the middle of trying to recover a horrendous sleep debt and it's making me a bit unreliable. (Luckily, I don't need to code right now.)
&gt; Not at all. Getting the means of production requires one thing: &gt; Capital. From your very own example, the Mexican immigrant &gt; would have no plausible way of creating a production means, &gt; regardless of what risk and abstention from consumption they &gt; put themself &gt; through. Why? Because they lack the capital to do so In the US at least, most small businesses are capitalized with personal savings and credit, not equity. And the credit is almost always collateralized, which means that it is the personal savings that are totally at risk. And the credit often comes from local banks which are capitalized with your neighbors' personal savings. The example given above is perfectly plausible; it happens every day.
Part of that is the community filing issues when they run into these cases. If a library is panicking, submit a patch to the author. If the author is unavailable, fork it. Unwraps are always going to exist in code - you should assume a library can panic at some point and build your services around this.
`unwrap` doesn't sound that dangerous. Maybe it should be called something like `ok_or_panic` or `unwrap_or_crash`?
Your doc example has a typo in the initial package import, on line 3.
I really wish i could just return results from main.
&gt; Can you point to specific unwraps in pnet that will result in runtime panics? [This unwrap](https://github.com/libpnet/libpnet/blob/36ddc62f94c1d3164d674b26ddf7cf0bbf0bd229/src/transport.rs#L186) caused me a few head scratches rather recently. I was getting the dreadful "unwrap called on Option None" type messages. &gt; Sometimes unwrap is used when earlier code has already proven that unwrap won't panic, and sometimes panic is used when continuing would make no sense at all. I'm not saying `unwrap` is evil. I use it myself, sparingly. That is, only when it's safe to do so. When it makes sense to return a `Result` instead I do so even if I'm only prototyping. &gt; But, for prototyping, unwrap makes a lot of sense, and I will not stop recommending it any time soon. That's why I put prototyping in quotes. If those unwraps are cleaned up when promoting a project from being a prototype then there is no problem with that. However, the problem with this assumption is that it's like saying it's OK to use `C` as long as you are careful. Many projects start out as prototypes but as programmers we know how often these "prototypes" end up in production. Take `pnet` for example. The author [created this issue](https://github.com/libpnet/libpnet/issues/141) in December 2015 to address those unwraps but it still hasn't been done yet. With `derive-error` for example, you can create a custom error type as simply as follows:- use std::io; #[derive(Debug, Error)] enum Error { Io(io::Error) } Then in your code you just have to use `?` instead of `unwrap()`. Even when prototyping I don't see how using `unwrap()` will end up being more productive so why not just do it right from the word go and avoid having to create an issue for cleaning up `unwraps` afterwards?
Not as much because, besides causing panics, `unwraps` can also be a nightmare to debug when they are called on `None`. When `unimplemented!` or `unreachable!` panics you know exactly what went wrong even before you dive into the source code.
Good way of putting it. Agreed.
I think you're saying the same thing.
for what it's worth, this was already discussed on this subreddit when it was released: https://www.reddit.com/r/rust/comments/62avcc/introducing_linkerdtcp_a_tcp_load_balancer/
I feel like the more generic version of your argument is, "don't create technical debt." I doubt few would disagree with that in a vacuum, alas...
But what happens if you want to assign a new value to an index? 
How's the performance?
&gt; If you run something in production, then it's your responsibility to make sure it is production ready. Open source community is not a magic pot from where a production-grade code comes for free Most non-trivial projects, once you include transitive dependencies, involve over forty libraries, at which point it becomes impractical to do a full code review. Further, there are some communities, notably Java, where there is a lot of _high quality_ open-source libraries that don't need such review. If one really needs to inspect Rust libraries to deliver a safe, non-crashing program, then Rust offers an inferior development experience to the likes of Kotlin. I agree that grepping for `.unwrap()` and `unsafe` isn't particularly difficult. However I think the author's point that writing safe code by default, regardless of project scope, is a good rule-of-thumb. 
This is correct. The English word `and` behaves backwards from the logical operator. In English, `$thing for $x and $y` expands to `($thing for $x), ($thing for $y)`, whereas in logic, it expands to `($thing for ($x and $y)`. English `and` expands the scope, logical `and` contracts it. I kinda want to write up a fuller article on this.
Like, you mean, better then the type_id-shenanigans last week? Sorry for being so unapproachable.
Shit man, I'm sorry, I was kidding. Anything HDL related is voodoo to me and I try to stay away as far as I can. I'm working with an FPGA shaman and TBH his craft scares the hell out of me.
Just to counter that. Performance is always important! If you don't need performance for solving time constraints, there is more stuff where performance matters. Say battery life. A program that has a petter performance usually tends to consume less CPU time hence less energy. If battery life does not matter – cuz its wired – you can always safe the environment! Rust is the Captain Planet of Programming! 
&gt; Do I need to keep track of bytes read to know the size of the message received, or what is the idiomatic way to deal with this? YES. Collect the return value from any fallible I/O call and inspect it to determine what actually occurred. This is equally if not more true in C. Also, &gt; read_to_end hangs probably because the socket doesn't actually close after the bytes are sent in response. You may be interested in [Read::take()](https://doc.rust-lang.org/std/io/trait.Read.html#method.take), which if you know ahead of time how many bytes you need in order to be not-an-error, you can use this to stop at that point. If possible (I don't know the socket API offhand), you should set a timeout on socket reads so that if after a while you don't receive any more data, the read call gives up and will terminate, informing you through either its return value or the length of the growable container into which it was depositing data how much was transferred.
:'((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((((( I completely sympathize though it is some wild stuff to me as well. Like with many things in this field, I found that once I actually charged headlong into that niche it started to make more sense to me. I used to think that everything below the OS' top-level API was magic, and then I had a computer engineering major that made me do embedded programming and digital logic to the point where we designed in Verilog a MIPS CPU, flashed it to an FPGA, and also wrote C freestanding programs that we then compiled to MIPS and executed on that FPGA. Shit was wild and I couldn't do it again if I tried, but it was surely educational lol ---- Now that I think about it though Rust does have some good traits for an HDL to borrow. Maybe I should do some sketches ...
Yeah I generally agree with the sentiment of this. These days I exclusively write Rust at home. During my day job though I'm a QA at a company that works pretty much exclusively with Microsoft tech so all my co-workers know C# and I'm not really in any kind of position to drive the company's tech decisions. C# is good enough for automation stuff here and being at my low position on the totem pole I'm not really particularly eager to try and convince anyone of the merits of Rust even though I know they are many. It's kind of a weird paradox in my mind I try and resolve occasionally by saying "I guess C# is ok here." I kind of want a new job but being almost exclusively self taught doesn't impress most HR departments. Even though my co-workers and peers think I'm more than capable.
Definitions vary based on programming language and mathematical background. Rust doesn't use "lambda" to officially refer to anything, and likely never will. According to Rust terms, there are only functions (which are never anonymous, capture no state, cannot be defined inline, and can recur) and closures (which might or might not be anonymous, might or might not capture state, can be defined inline, and can't recur (but maybe something something y combinator something)).
I know that feeling. I am mostly using Java at work and that is mostly because of the huge amount of code that exists. You just don't reimplement multiple multi-million-loc Java codebases to Rust – you just don't :D and there where multiple discussion of renew our tech stack ... to python, Go, Swift over many years and i was always on the position to say: "Hey Java is good enough, please don't ruin our battle proved software stack". I am myself very conservative in that regards and companies don't care about the environment ... and even this is very questionable. Choosing the right algorithm may be much more effective in that regard. But i want a Environment Tax on programming languages. If your Company uses Python as primary language your Company needs to pay more Tax – if you use Rust, safe the moneys :D – my dream scenario.
Ideally, we would include `error-chain` (or something better) on the stdlib, because it should be a widespread idiom. Well, perhaps having an interlude on the nursery first, but with a clear goal of making it standard, to reduce friction when using error types. Also, stabilize the RFC to let using `?` on main (which I don't even know if it was accepted), to not depend on the `quick_main!` hack. Then the lazy option would be to write `?` everywhere, which requires just changing `fn f(..) -&gt; X` to `fn f(..) -&gt; Result&lt;X&gt;`.
&gt; .. arguments blaming people writing Open Source code for free for not delivering the quality you need are just wrong. Make it production quality, and submit a PR. :) If I came across as trying to assign blame, I'm sorry. That definitely came out wrong. I maintain a few open source libraries for free myself (most of them are in Rust) and I have contributed to a few projects as well. I definitely know what it takes and I am very grateful to anyone who contributes their code publicly. What I'm try to do with this post is encourage those of us who write Rust code to incorporate proper error handling in their code from the first line they write because to be honest it's not much more work than just `unwrap`ing. I remember when I first created my first Rust library. I knew I didn't want to `unwrap` everywhere but I didn't quite understand how to do it properly so I ended up using `String`s for errors.
please do this! in addition isn't the scoping changing the meaning for ```spoken and``` to ```logical or```?
~~And the docs seem to support your claim, seeing as that exact `let mut file = File::open(path)?;` appears in the examples of the `File` [docs](https://doc.rust-lang.org/std/fs/struct.File.html).~~ I misread. What version of rust are you using? Can you put together a [playground](https://play.rust-lang.org/) link that causes your error, the surrounding code may be important.
Could we get a standardized compression library interface? It honestly seems like there are more than a dozen of these out there and they don't distinguish themselves enough. Ideally, this would be something that someone who wants to write a new compression algorithm could easily target and the burden on a user to slot that in would be to select the configuration options that they want to use. I don't know if this is possible. 
Fascinating. This sounds like a great idea that may get a lot of pushback from the community. I hope I'm wrong about that, and I fully support this initiative, for whatever that's worth.
`wasm` doesn't have access to WebGL last I checked, so you're stuck with compiling to JavaScript. I haven't done it, so I can't give any more direction than that, though you may want to ask over at /r/rust_gamedev.
The `?` operator does not unwrap, it gives you the success value or early-returns the error value to the caller (propagates it further). For that, you have to be inside a function that also returns a `Result`. The error tells you that you return `()` (eg. nothing) and it can't return error through that. (And yes, this answer is a bit of a simplification)
[Here](https://play.rust-lang.org/?gist=754457a7e568f2958e03c39265e0c6aa&amp;version=nightly&amp;backtrace=0) it is! I shortened the load_rom() function, but it is within there. I am also using nightly.
The problem is that the `?` operator tries to return the error if the operation fails, but you're using it in a function that returns `()`. Changing the return type of load_rom() to `std::io::Result&lt;()&gt;` would fix it ;) The error message could definitely be improved though
`unwrap` is completely fine for prototyping your _binaries_. It's absolutely unacceptable to leave potentially panicking `unwrap`s in _libraries_ you intend to release on crates.io.
`File::create` opens in write-only mode: https://doc.rust-lang.org/beta/std/fs/struct.File.html#method.create You probably want something like `OpenOptions::new().read(true).write(true).create_new(true).open(dir)?`.
Generally in surveys, freeform text fields get read by actual humans. They're super valuable for additional insight from the most dedicated survey-completers (normally you get fewer written responses than check-box responses).
There is also /r/rust_gamedev which may have interesting suggestions...
In general, Rust's constructs forces you to write better code, `unwrap` is one big exception. I agree that `unwrap` foils rust's error management philosophy. It should be removed in favor of `expect`. A lot of `expect("")` are uglier than `unwrap()`, so at least people would be more careful in using it.
I think this is a great idea (trying to get crates to use common best conventions and practices). And especially love the idea of a crate cookbook for maximum compatibly between crates and standard conventions. The only part I'm wary of is having our cake and eating it too. It's rarely that easy. If someone has issues with breaking changes in Rust proper, I'm assuming they'd also have the same or at least similar issues with a breaking changes in a primary lib/dep. This puts the lib maintainers in the same place as the Rust team *would have* been in; maintaining old versions or rarely breaking. Rust also has a fast release cycle by many languages standards, so the slow forward progress argument isn't quite as applicable as it is in some languages. Although, independent crates *can* move forward even quicker.
I think one of the problems why `unwrap()` gets used way too often in prototyping is that you still have to do it in `main()` anyway. [The RFC `?` in `main`](https://github.com/rust-lang/rfcs/pull/1937) might help if it gets adopted
Not when `panic!()` occurs in `proc_macro`, which is why I'm switching to `expect()` instead of `unwrap()`.
&gt; If someone has issues with breaking changes in Rust proper, I'm assuming they'd also have the same or at least similar issues with a breaking changes in a primary lib/dep. I think that best practices for handling upgrades in the ecosystem is a pretty big open question for the libs team right now. Hopefully this process will shed some light. 
Ya, I was more interested in if there's a goal to be able roll back for any rust nightly thing. Sometimes it's cargo, sometimes rustc, and IRC is basically "yep, it's busted, here's how to rustup the previous nightly". Would be nice if once identified as broken, we could pretend there was just no nightly published.
I mean hey your electric bill already kind of acts like that tax eh? I wonder if you can argue on behalf of electrical savings with demonstrations on power consumption. I wonder if the use of Rust actually makes a difference in the amount of power drawn.
I started prototyping a proc macro attribute to rewrite `unwrap()`s to provide accurate line info, but it's blocked on the improvements to span info in https://github.com/rust-lang/rust/pull/40939. The concept is really neat but it does feel like it would be helping cement an antipattern. Personally, I do prefer `expect()` with strings that are easy to grep for. There is something to be said for the distinction between recoverable errors (IO errors, parse errors, etc.) and unrecoverable ones (logic errors and bugs); returning error values for the latter and forcing the user to acknowledge them doesn't make for good UX.
Yeah this idea of packaging up more crates with Rust is one that some like and some strongly dislike. I kind of don't want to deal with that yet, but rather just pursue making obviously important crates as good as we can. I think the long-term picture will become clearer in time. 
&gt; Handle form parsing for multipart data (Hard) (hayaku-http) Maybe it's about time I got started on my async fork of [multipart](https://github.com/abonander/multipart).
Perfect Thanks @burkadurka exactly what I needed! I'm surprised it did give a more relevant error message like "file is READONLY" or something, but still getting used to Rust. Thanks again :)
Idea: an option to search crates.io for only 1.0 level crates?
In general, I'm happy that open source implementations of BLE for the nRF exist. I haven't looked at this one in particular.
I too would like to see how it's different from Way Cooler ;-). Time will tell, but I'm guessing that it will be like fireplace and try to incorporate Rust in the extension of the WM (thus, better bindings are needed. Which is why wlc.rs was made, why fireplace is banking on smithay, and why, presumably, this is being made). Good support for Rust as an extension language is a non-goal for Way Cooler, for various reasons. That doesn't mean there isn't good support (most of the client programs I've made are in Rust), but I think that for those that want to have full "first class" support for Rust in their window manager should definitely try to support other designs like Fireplace and Perceptia. More competition is never a bad thing :-P. 
This might be too high level for the types of libraries this effort is targeting, but I'd really like to see prioritization of non-client/server parts of HTTP from hyper released as separate 1.0-level crates: https://github.com/hyperium/hyper/issues/894 The ability for multiple potential HTTP client/server libraries to share one set of types for things like HTTP methods, status codes, and headers would be a boon for interoperability, and for libraries that need to represent these concepts without needing a full HTTP stack.
This isn't explicitly said in the guidelines right now, but a good litmus test for how heavily to weigh that guideline might be "would I want this crate to be an official Rust project"?
Couldn't agree more. There is no meaningful distinction between example and actual code.
I doubt you will get a single portion of noodles from this project to be honest.
Don't make things ugly just for the sake of them being ugly. This just leads to a language that is unpleasant to work with. Edit: and the distinction between unwrap() == is not None but compiler is too dumb to know, vs. expect() == unrecoverable, or laziness is an useful one. 
All I'm saying is that I'm pretty sure WebGL doesn't work in wasm, so either emscripten is going to build that bridge for you or, more likely, it will fail and say you need to compile to asm.js or whatever (and I'm pretty sure Rust doesn't compile to asm.js, but to "almost asm" or something like that, so it's more correct to say "javascript").
Glad that works! Rust will automatically turn &amp;(&amp;x) into &amp;x when it knows what type `x` is, but it won't do this when the method accepts a generic parameter since &amp;X and &amp;&amp;X can both have (different) implementations of a trait.
Yes, I agree. I think it's not hard to get there from here. Just stuff to be done.
&gt; Further, there are some communities, notably Java, where there is a lot of high-quality open-source libraries that don't need such review. Java has 22 years and billions of dollars worth of enterprise behind it. There's no way around it, it's just reality. &gt; Most non-trivial projects, once you include transitive dependencies, involve over forty libraries, at which point it becomes impractical to do a full code review. It is practical, and it's not an excuse not to do it. It's just cheaper/quicker not to, but then you can't blame anyone else than yourself if one of the crates turned out to be lower quality than you have exptected. For well estabilished crates, some trust could be implied, but if every company using Rust reviewed at least a couple of their dependencies, and took some responsibility for them, then most of popular community crates would have some form of business 3-rd party review by now, many times. &gt; If one really needs to inspect Rust libraries to deliver a safe, non-crashing program, then Rust offers an inferior development experience to the likes of Kotlin. You should inspect any 3rd-party bits you're pulling into your production code, no matter the language. Java ecosystem has been living for over two years with remote execution exploit https://nvd.nist.gov/vuln/detail/CVE-2015-6420 until Google finally stepped in 2017 and started fixing them http://thehackernews.com/2017/03/google-mad-gadget-flaw.html . Let me reiteratoe: for over two years, over 2600 Open Source Java projects, some "high quality" and prominten had known, documented, potentially remote execution exploit. So lets not juggle with that "hight quality" word since it can mean different things in different places. :D Having said the above (and intentionally being snarky), it might be that Java ecosystem is and will be for a while a more productive and production ready one. Nothing to be ashamed of, if you ask me.
I believe magic pocket is where they use rust the most.
Disclaimer : Experienced dev, but I'm learning rust in my free time since only a few days ago, I may be spewing nonsense because I don't know better :) Coming from a java background, ignoring unchecked exceptions is considered a **very** bad practice in libraries, but "ok" in consumer code. Checked exceptions are "You have to deal with it. That's it. The end." Not really sure how you implement the former case ("just fucking deal with the error or I won't compile"), or if it's even possible in rust. It should be a compiler warning at the very least. It seems like every single code example is using unwrap() everywhere, instead of showing the proper way to do things. I get it, result handling is not interesting. But from a beginner perspective this is bad, really really bad. If you want people to do things right, do not show the bad way as the default way to do things. 
VS code with the [rust](https://github.com/editor-rs/vscode-rust) plugin. You'll find more answers in the previous [thread](https://www.reddit.com/r/rust/comments/67pt9l/best_idetext_editor_for_rust/).
I am pretty new to rust, but my "setup" consists out of vim with the rust-vim plugin for some Color Highlighting and for code completion i use YouCompleteMe with racer support enabled and while it is not THE killer setup, it is neat :)
more like, where is your god now?
I was under the impression that cargo run file.rs would compile and run that file even without a Cargo.toml file. I guess I was wrong, probably mixed it up with the go language.
&gt; not having that sweet green threading makes the concurrency story much more complex Yeah, I was pretty sad when Rust removed it pre-1.0, but I understand why. I still wish I could have Go-style concurrency with Rust's memory safety, so I really hope something nice emerges from the community. We have several good tools already, but I think we need a bit more to have a cohesive solution.
I don't know whether this will happen as part of the Libz Blitz per se, but there's definitely work under way in exactly this direction. Stay tuned!
That sounds like it would be pretty useful, both for encouraging this year's 1.0 push, and for incentivizing library authors to reach 1.0.
I am so used to error-chain now ... I forgot how it was to handle errors properly.
Another reason why I'm not the biggest fan of macros...
In fairness, even as someone who is realitively comfortable with rust, I had a similar reaction when reading https://doc.rust-lang.org/book/error-handling.html. I don't think this is the first time I've seen this feedback for that particular code block (but I'd have to look for the other instances). 
Well, I believe we can make error reporting in macro/`proc_macro` way better, but since it is not easy, it is not implemented yet.
If the "alternative `main` signature" RFC is approved, this'll be easier to sell. It would also be nice to have `error_chain` in the stdlib to make it clear that _this_ is the preferred way to handle errors.
&gt; If you cast directly from `fn() {name}` (or a closure) to an `&amp;Fn()` it does the normal amount of indirection Awesome! ...though it's somewhat telling that even the guy ranting can't keep track of all the options ;). &gt; I agree there are a lot of types involved here but I don't know what is incidental and not fundamental complexity. I *think* it's reasonable to have all of these types. The community should just make sure to make sure the right options are the ones people are encouraged to use, whether this means using /u/Manishearth's clippy or getting /u/steveklabnik1 and co. to document the heck out of it. I don't know what's best, but I figure we should at least make the decision knowingly. I've cc'd them for comments.
That's not how I read his statement at all. It sounded to me like he runs windows, and cross-compiling for linux is a pain. And he's right. Full disclosure: in my work, numerous developers cross compile their binaries from windows for linux, but mostly just to see that it still compiles. Deployment of built binaries from windows to linux is rather more problematic, due to the permissions problem.
The original post neglected to give thanks to those who have helped so far. It's fixed now. This has been in the works for a while, with the assistance of many people. Thanks Alisha Aneja, Andrew Gallant, Brad Anderson, Charles Chamberlain, Dan Burkert, David Harris, Jan-Erik Rediger, Peter Atashian, Roman Frołow, Sean McArthur, Simon Sapin, Stephan Buys, Trent Spice.
Can you give an example of the functionality that you'd like to see? It sounds like you're downplaying the difficulty of the problem, which is to combine closures with static dispatch. An easy solution to this problem does not spring to my mind. In particular, the ability to name closures has to interact with generics somehow.
You can already desugar closures into a named struct which contains the closed over parameters. It's just massively more verbose, (and requires nightly to impl Fn*). 
I don't see how it could ever be much less verbose. Even in the best case where we introduce special new syntax to allow struct parameters to be inferred, you still have to declare a type, and you would then need to either enforce that only a single function ever returns that type, or enforce that all functions that return that type close over the exact same members, or implicitly create an enum that represents all the possible environments that pseudo-closure carries (no longer zero-cost). You'd also need to introduce new syntax to tell the compiler which type a closure should be, or provide a way to coerce a closure to a certain type with `as` (hardly a verbosity win), or extend type inference to determine when a closure should be a "specific" or "generic" closure which sounds error-prone. And now, even in the best case, we've merely managed to subject closures to the same verbose hell that iterators currently exist in.
&gt; Despite its verbosity, I actually like this approach quite a bit. You basically create one Error struct for your crate or program, implement a lot of From's for each type you need, and then finally implement Display on it so it can be printed out properly. It's a lot of boilerplate, especially if I plan on replacing my small Python scripts with Rust programs, but it's genuinely clean code and it ticks a lot of boxes with me. Well this is what I always use and the structure itself is clean and easy to use, the boilerplate is just huge but this is a common problem for Rust in general in my opinion. There is for many things a huge amount of boilerplate. If we look into the referenced code: impl fmt::Display for EsError { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { match *self { EsError::EsError(ref s) =&gt; fmt::Display::fmt(s, f), EsError::EsServerError(ref s) =&gt; fmt::Display::fmt(s, f), EsError::HttpError(ref err) =&gt; fmt::Display::fmt(err, f), EsError::IoError(ref err) =&gt; fmt::Display::fmt(err, f), EsError::JsonError(ref err) =&gt; fmt::Display::fmt(err, f) } } } There really has got to be a way to do that in three lines. 
I do have some desire to keep stdx moving. At least keep it updated on Rust's release schedule. I've had a hard time getting back to it, and am considering looking for additional maintainers. 
Still too long though. If you can match `_` why not: _(ref s) =&gt; fmt::Display::fmt(s, f)
I won't be satisfied until I have a compiler which treats readability crimes like that as syntax terrors.
Where was I rude? Sorry about that. Anyway, the problem with eschewing names and going all the way to impl Trait is that it doesn't compose well. For example, there's no way to declare that two different functions return the same type, and there's no way to store an anonymous type in a struct. You need some sort of identifier in order to be able to reference it and distinguish it wherever types appear. I guess the real question comes down to whether we are talking about "impl Trait *and* named closures" or "impl Trait *instead of* named closures". The impression I got is that people were mostly talking about the later, which I think is a really bad idea. If you consider impl Trait to be additional syntax sugar over named closures, than I agree that it would be sometimes useful. P.S. A way to go from anonymous to named types would also fix the problem. I talk about named closures, because AFAIK, closures are currently the only anonymous type in Rust, but a more general mechanism could also work. On the other hand, it's hard to see how that would interact well with Rust's "no global type inference" philosophy. Maybe it could be limited to the return types of functions.
I am of the opinion that you don't need much information on a language concurrency, since so many of the principles are cross language. So the one chapter is fine. But even more than this concurrency changes drastically between architectures. So it's impossible for rust to tell you the nitty gritty as a systems language, you need to know a certain amount yourself. This architecture issue is really the main strength of java imo, much more than most other features. Windows, Unix, arm, or x86 all of those oddities and portability issues are fixed because doug Lea already figured those things out, and he's better at concurrency than just about anyone else so on the shoulders of giants and all of that.
I have a very satisfying diff in an old project from when I migrated from hand-written error structs like that to quick-error.
I'm not sure if that compiles. Let us temporarily assume that it does. If you change your enum definition, the first one (code in my comment) will not compile and the the code in your comment may silently do the wrong thing (unintended action). So I would personally prefer the longer definition even if the shorter one worked. That said, I can see why one might prefer the less verbose option.
There's no secret, just not a working thing yet. We won't make any 1.0 without the community. We're just discussing what the requirements are, and test out concepts with the type system. When we find a combination we wouldn't be embarrassed of, we'll publish that openly!
error_chain can actually take you very far too, even just using links and kinds.
I just benchmarked the hello example with 4 threads using `wrk -t10 -c10 -d10` and it handled 87000 req/sec. A hello server with Golang's net/http handled 67000 req/sec. The performance could probably be improved, but it hasn't been a focus.
Thanks, I've fixed it.
Yeah, it would be nice to see some zero-runtime-cost solution that allows code to be written to simultaneously support asynchronous and synchronous usage.
&gt; concurrency is not a language feature. Well, the `Send` and `Sync` traits are directly related to concurrency and they are special to the compiler in that they are derived automatically, so I'm inclined to say that there is some concurrency features in the compiler.
Nope, and I'm on the latest Rust Nightly, too. That's a shame if it's unsupported, it'll be annoying importing and typing out `BigEndian` everywhere.
To add to that, it is also very possible for the author to maintain two APIs (1.x.y and 2.x.y). Which is much more difficult or cumbersome in std.
Wow, I really want to use this while exploring some code bases.
All the glium examples are *supposed* to "just work" with emscripten. There's still a main design issue in glutin though, which is that programs running with emscripten need to use a draw loop by doing something like (pseudo-code) `emscripten::set_main_loop(|| draw())` instead of `loop { draw() }`.
Currently it uses [an old version of Hoedown](https://github.com/rust-lang/hoedown). There are plans to switch to CommonMark, but as the spec is still evolving we're not ready to switch just yet. See the [internals thread](https://internals.rust-lang.org/t/what-to-do-about-pulldown-and-commonmark/5115) for more background on this issue.
Depends on what you mean. It's fine to use `"*"` before a crate is packaged, or if it's never going to be packaged (for internal test crates).
How to setup rls/racer and tools using them to provide code completion for external crates? I got glium, but so far vscode/atom/`$racer complete glium` complete nothing. VScode definitely sees the code, as if I hover over `build_glium` in `let display = glium::glutin::WindowBuilder::new().build_glium().unwrap();`, it will display function prototype and documentation. And if I ctrl-click it, it opens "$HOME/.cargo/registry/src/github.com-1ecc6299db9ec823/glium-0.16.0/src/lib.rs" However, it refuses to provide autocomplete. racer 2.0.6 cargo 0.19.0-nightly (fa7584c14 2017-04-26) rustc 1.19.0-nightly (afa1240e5 2017-04-29) ETA: I can autocomplete DisplayBuild in `use glium::DisplayBuild`, however if I go deeper - no luck
Sublime Text with Anaconda-Rust and RustAutoComplete. Not perfect, but works pretty well. Anaconda can do rustfmt formatting (and possibly listing, though I don't have that working), and RustAutoComplete is quite useful with racer. Besides that I just use ConEmu terminal on Windows and Gnome Terminal on Linux to run cargo, and a Firefox window with 3-15 doc tabs open xD.
I think nginx is written in c, so you'll need c compatibility which is a feature that scala doesn't have. Sure in this case you'd rather choose rust over scala.
I'm looking forward to Rust 2.0.
Yes but it takes even longer than a Cargo project. What's your pain point in setting them up? Should be "Cargo new" and the adding "example" to your Cargo.toml. That's not a _lot_longer than a "cargo install".
I'm not really sure it was either. That said, older Rust was very different from today's.
I have not written any production rust yet, but I don't think I would allow myself to put a single unwrap in my own production code (except in main). Would it make more sense to add more statistics to crates on crates.io? eg. the number of .unwrap()s, .expects(). etc? They could be aggregated into a single number, maybe "Number of crash sites" including links to each line? Somewhat related: I would like similar metrics for the amount of unsafe code in each crate.
I guess you're right. My issue was that I was playing around with learning the syntax and had already written a couple of files but halfway through, I wanted to add a crate 
But then one would be contributing to something that will never be used in a professional capacity. You're cutting out a large chunk of possible contributors. Agpl makes sense only of the original author(s) has the ability to drive it forward to a very advanced state.
The name of this effort is a bit confusing; it was only at the fourth paragraph that I realised that this is in no way related to the zlib compression library.
I love `error-chain` but, believe it or not, it took me a long time (longer than I would like to admit actually) to understand how to use it. Now that I understand it I'm actually embarrassed that I couldn't get it the first time. For a while I used `quick-error` when I really wanted to use `error-chain` instead. So my point is `error-chain` can be confusing for beginners too. Eventually I wrote my own [error handling boilerplate](https://github.com/rushmorem/derive-error) crate using Macros 1.1.
The Rust language team appears to at least have ties to type theory research groups. However, much of the practicality of the language is due to rapid iteration on ideas from the community. One should note that IIRC one of the goals of the RFC process was to keep the amount of change manageable.
All those people came later though; they asked about the early days.
something like this maybe? fn make_closure(x: i32) -&gt; Closure { 'Closure |y: i32| x + y } This desugars to a struct called `Closure` that implements the required `Fn` traits. You can already write this yourself, but it looks like this: struct Closure { x: i32, } impl FnOnce&lt;(i32,)&gt; for Closure { type Output = i32; extern "rust-call" fn call_once(self, (y,): (i32,)) -&gt; i32 { self.x + y } } fn make_closure(x: i32) -&gt; Closure { Closure { x: x, } } It also naturally extends to generic types: fn make_closure&lt;T&gt;(t: T) -&gt; Closure&lt;T&gt; { 'Closure || t } which desugars to struct Closure&lt;T&gt; { t: T, } impl&lt;T&gt; FnOnce&lt;()&gt; for Closure&lt;T&gt; { type Output = T; extern "rust-call" fn call_once(self, _: ()) -&gt; T { self.t } } fn make_closure&lt;T&gt;(t: T) -&gt; Closure&lt;T&gt; { Closure { t: t, } } which compiles today, but is just very verbose. edit: Also gives me an idea for a syntax: fn make_closure(x: i32) -&gt; Closure { #[derive(Copy, Clone, Debug)] 'Closure |y: i32| x + y } which applies the derivations to the generated struct in the obvious way
(about the example with `and_then`s) &gt; Nested, chained, conditional maps are not my idea of good, clean, and clear code `and_then` is monadic bind (`&gt;&gt;=` in Haskell, `flatMap` in Scala). It is a very elegant way of chaining operations that might fail. Rust doesn't provide a nice syntax for that, though there are [macros](https://github.com/TeXitoi/rust-mdo) :) However the try macro is more "idiomatic Rust"…
The error handling chapter you refer to literally walks readers through the various states of error handling, almost exactly as you laid out. :-) (With one exception: it doesn't talk about the various error crates.) The case study even does it again with a real task: https://doc.rust-lang.org/book/error-handling.html#case-study-a-program-to-read-population-data
&gt; I'm really trying hard not to be overly dismissive and critical, but this code does not make me happy and I don't think I'm alone on that. Nested, chained, conditional maps are not my idea of good, clean, and clear code. But that's exactly the point of the example! It is literally there as motivation for moving toward a cleaner solution based on try!/?. It seems weird to hold that against the example.
I feel embrassed. I will not ever skip any reading on a type documentation again.
If you don't want to handle the error, why not just propagate it? I mean instead of using `unwrap()` you simply have to stick in a `?` instead. If the approach works out, you won't have to come back and cleanup either (Which most people either forget to do afterwards or they keep deferring because then they will be busy working on other things like adding more features).
This brings up an interesting problem: AFAIK, cargo has zero provisions for multiple version lines of a crate developed in parallel (e.g. like the Linux kernel having multiple major versions that still get security updates. I think once our library ecosystem reaches some maturity, this is a use case we'll need to work out.
Thanks :)
Most compression crates do implement the writer trait for encoders/decoders, so it sort of exists already, though there's are probably extra functionality that could be added for specific types of crates.
What kinds of provisions would cargo need?
Oh yeah. The question mark and try! macro give you a lot of the benefits of do notation in say Scala and Haskell for 90% of the cases. Biggest thing is splitting borrows is not well explained. Once I understood how to redesign my structs and impls it worked like a charm.
[This is terrible](https://github.com/rust-lang/rust/issues/35946#issuecomment-244082548) and [we're working on fixing it](https://github.com/rust-lang/rfcs/pull/1859). Sorry sorry sorry :( :( :(
Fair enough: [#679](https://github.com/rust-lang/book/issues/679)
I agree with the author's side-comment about `String`/`str`: &gt; Note: at this point I have no idea when to_string() or to_owned() are used. My usually strategy is to try as_str(), to_str(), as_string(), to_string(), and to_owned(), until the compiler stops complaining. I remember that one is on the "stack" and one on the "heap", but those nouns are not things I regularly think about and I need to carefully remember which is what. And even when I remember that a "stack" lives with a "stack frame" lives with a function, I can't remember whether `String` lives in the stack or `str` lives in the stack, because the `String`/`str` names are so similar to each other. The names of the string types don't help call out their differences, you just have to memorize it... and I haven't yet. [edit] If anyone has a good mnemonic for remembering the difference between `String`/`str`, please let me know!
That's my main gripe with the article, it shows some python lines for comparison but those don't have any error handling at all.
&lt;3
It's using Rayon's ThreadPool too... nice!
Yes! Thanks for building such a great library, I hope it'll be *the* concurrency library in the ecosystem, so that projects just have a single thread pool.
This is so cool! :) I got your email a bit ago but haven't responded yet! I'm sorry!
What does "document-oriented" mean?
The database has no schema and therefore every record can be different
https://en.wikipedia.org/wiki/Document-oriented_database
Looks really promising, thank you
Right, when the type you're binding to the match arm has the same type, it works. If you changed them to different int types, you'd need different arms for each.
That's surprising because it shouldn't conflict. They're different impls. Unless I'm crazy.
Great Idea. Well done!
Oh, alright. Now it makes sense.
So... a filesystem?
The answer is up above /u/daboross figured it out.
&gt; This is a lovely, readable and powerful idiom which doesn't appear either in the old or the new books' chapters on error handling. It's in the old one, but not particularly emphasized: https://doc.rust-lang.org/book/error-handling.html#defining-your-own-error-type It's not emphasized for a reason. It looks nice in a short example like this, but writing out the `From` impls quickly becomes a lot more economical.
Just yesterday I was idly wondering how Specs avoids deadlocks. I think I've misunderstood something, because I still don't see how the ticketed locks + pulse mechanism avoids deadlocks. Are deadlocks avoided by only ever running one `System`'s `fetch` function at a time? Now that I think of it, that would make a lot of sense...
/r/playrust
thanks lol
Specs is making me want to build something. It was stagnent for ages and all of a sudden everything just burst into life. Every day I check github there's a tonne of activity!
It's not really "remove unwrap", it's more "replace unwrap with something better, more self documenting, and less hidden". If it were `.assert_no_error("description")`, `.assert_not_missing("...")`, etc. I would not be opposed. And I find it a bit unfortunate that `unwrap` and `unwrap_or` seem so similar.
Is that the *only* error you get? A live example on https://play.rust-lang.org/ would make it easier to help.
I'm 100% down with this. For most programs, it's a long time until any creative element becomes involved in error handling. The only reason I should have to expend a non-zero amount of lines for error handling (up to the top-most try-catch "print error, then exit -1" block) is if I want to do something out of the ordinary, like narrative error messages. Rust needs a way to write simple programs like this that is no more verbose on the error handling side than the equivalent python script, or people will keep using `unwrap`, or just leave.
Yes I don't get why the author is not using these variables... Also shouldn't they be the following? ``` export CARGO_HOME="~/.cache/cargo" export RUSTUP_HOME="~/.config/rustup" ```
After minimizing the code to this https://is.gd/Tph99u it works.. I think it has some to do with my imports of modules.. But since I can't post the whole code here, I will try to minimize the scope until it works again. Thanks
Thanks, I will update it
No, not exactly. A database has several advantages over a filesystem. A database is usually faster and can to handle multiple users. In addition, PaenkoDb has transactions which are important when it comes to failure. However, a record can also save a file (actually this is just a prototype and we use files as main data sources). But it doesn't really matter what format(=schema) your data has because every record can be different.
An audit of some sort, yeah. That kind of seems like what this blitz thing is about, though. 
Awesome idea, as it would also give a pretty good motivation to keep the stats low...
Probably mongodb, couchdb, etc.. kinda deal. I think IIRC postgresql have an option to do document-oriented too. 
Yeah I guess the difference is that python doesn't suffer from parametricity so I can just scrutinize the error wherever without retyping the entire program, once that becomes necessary. Edit: Oh, `Error` rolls its own downcasting. I checked whether it implied `Any` and figured that was that...
You really just described a filesytem. /u/antenore linked in the wikipedia description, that should help clarify :)
I generally try to avoid from impls where possible because I feel like that leads to too much depth of the interface - you have to start digging in to the helper libraries to understand how to key off of a specific error, and if one of those helper libraries changes, it breaks your external interface. Last but not least, it also doesn't convey the context of the error in that function. E.g. If a function opens a config file and then a resource, getting a generic Error::IOError(missing file error) doesn't help much to narrow down the issue. Whereas Error::ResourceOpenError(missing file error) is something more useful for higher order logic and error handling. As long as someone keys off Error::ResourceOpenError(_) they don't need to rewrite their code of it changes to a hyper Error or something. This is an ideal and time constraints don't always allow it, in that case I've resorted to the from impl. I still need to take the time to understand error_chain.
So is this true RAFT? e.g.: does it have ACID guarantees?
That is...inaccurate. Async I/O can buy you a lot depending on your workload characteristics. Have a lot of idle clients that post a request every so often? Or a lot of I/O (i.e. backend-request) jobs? Async I/O can help you *a lot*. It's not *necessary* however, and (this is very definitely a personal preference) I really, really dislike `Future`-based frameworks. I like green-threading solutions (a la Go) which give you the appearance of working synchronously while handling the async nature of the problem under the hood. EDIT. Oh, and just as an aside - I've worked a lot with `Future`-based frameworks: Netty, Finagle, built my own, and dabbled a touch with Tokio, so I've definitely experienced it first-hand.
It might be better to have a separate score for how closely it meets quality criteria, not necessarily tied to the version. Although you could probably automatically check for breaking external interface changes in post-1.0 crates to some extent. Several other criteria could be automatically checked and scored.
In very specific workloads, yes. BTW. If you don't like futures, `mioco` gives you API just like goroutines. I'm working (with some help) on newer, lighter version, and it even have async file io support. There's still plenty of stuff missing, but it should be quite easy to add missing bits.
This is wonderful news! I hadn't played with it in a very long time, so I'm glad to hear it's made progress. Big thanks to everybody working on it.
Thanks for keeping the updates coming.
Author needs to pm me a paypal address I gues :(
Let him know you need donate button
I disagree about `unwrap`, but that's a matter of taste. My view is that, if nothing else, it should be `.expect("")` because that empty string has an ugliness which subtly recommends never "unwrapping" without an explanatory message. (Ideally, one communicating the nature of the invariant that would have to be violated for a panic to be produced.)
The [`enum_derive` crate](https://docs.rs/enum_derive/0.1.7/enum_derive/#example) has some macros to do this.
Is there any way to bundle a custom theme with gtk on Windows? There are so many good looking gtk themes (numix, etc), but the default Windows one is horrible, and the only one I ever seem to see on Windows...
It's really cool to see the rust cookbook be integrated into the rust project so fast. I was part of a team organizing a college hackathon at UIUC back in February focused on getting students into open source and Brian Anderson and Alex Crichton made the trek out to Champaign-Urbana to mentor some students on projects focusing on rust. The rust cookbook was one of those projects. Iirc it was 4 students and Brian working on it during the hackathon and they ended up winning the staff pick prize (https://devpost.com/software/rust-cookbook) 
See if you can get the CSS from one of the April Fools days. One of the mods probably has it saved somewhere.
I do not know this Python library, but libraries like that tend to supply more detailed parse errors, including the line number.
Postgres can handle json documents, so if you just make one table with one json column in it, you basically have a document store.
I imagine wanting to replace a transitive resolved dep. But I _think_ cargo can already do that? Would be nice to see a big tree of all the libs and just select a fork/version. 
What I like about this, is that is strengthens the external lib graph, without pulling stuff into rust proper. Rust absolutely shouldn't pull libraries into a stdlib in the compiler. It will hurt Rust and it will hurt the libs. The fact that one can use a new compiler at anytime and their code still works. This zero friction to upgrades is amazing. I'd like to see more effort around codifying simple traits and structs to define interactions and data the edges of libraries. Focus on how things interact and what needs to be communicated that is invariant across how it is calculated. Rust can learn a lot from Lisp. The data structures are open. 
Do any of these help? The stack is lightweight but limited, just like `str`. `String` is a heavier-looking word, and the machinery involved in heap allocation adds weight. If you ignore capitalization, the word `str` is a slice of the word `String` that only has meaning by referencing it, just as the `str` type is a slice reference to a `String` type. (Every `str` is backed by either a `String` or a read-only `"string literal"` compiled right into the machine code.)
Not quite. I have some Python scripts I'm rewriting in Rust because Rust's monadic error handling is better than Python exceptions at helping you verify that you've handled every recoverable failure case in an appropriate way. (I've already discovered several places where I'd never noticed that the underlying POSIX API functions could return failure.)
Ah I'm on mobile just responding to comments that's why I didn't see it. Awesome! :)
levels of enlightmentment[?](https://i.imgflip.com/1okeh2.jpg)
I wrote a Tokio alternative, which can make requests sequentially in specified number of "workers". Although there still missing enough error handling, but it **can run**! At least, its usage of `join_all` should be the right way for polling at most N futures at the same time, and `oneshot` should be the right way for terminate the futures when the timeout is exceeded. You could use it as reference. &gt; [rust-concurrent-http-request](https://github.com/sybblow/rust-concurrent-http-request)
Theoretically, but it's easy to implement it and I don't want to clutter the namespace with it (it wouldn't be possible to have another `#[derive(Resource)]` from some other library anymore).
You're too kind to it. Not only is it obvious spam, it's the most incompetently titled spam I've ever seen.
Jetbrains CLion. It's not bad but autocompletion formatting and linting can be improved. Debugger works well for me. 
Mutability only lasts as long as you own the data. When you pass the Vec to `fill_vec`, you give it complete ownership of the data. You can no longer access the original Vec, and thus your requirements for it no longer hold. Since you can no longer read or use it at all, fill_vec is free to redeclare it as mutable and do whatever it wants. As far as the called of fill_vec is concerned, `vec` has disappeared into the void, never to be seen again. `fill_vec` does have to give you a Vec back too, but there's no API guarantee that it's the same vec. Just that it is a valid Vec structure. Since it's fully changing ownership again, you can now declare this new variable as mutable as well.
For Diesel or Rocket? Diesel already runs on stable, so unless they're sitting on a backwards-incompatible change with Macros 2.0, it shouldn't hold them back. Rocket is a different beast though, and I'm sure they're waiting for `hyper` to stabilize first.
I *suppose* it's possible. I never tried to do it myself.
You are right : my post was not clear. I was obviously talking about Rocket
Hasher trait isn't really general purpose. That aside, if we stabilize `associated_type_defaults` (see: https://github.com/rust-lang/rust/issues/29661) we could potentially add a `type Output = u64` and change finalize() result type to `Output` without breakage (not sure though).
I think I originally misunderstood the problem `error-chain` tries to solve. I thought it was about `chain_err` enabling me to chain multiple operations that can fail in different ways but after struggling with that for a while I ended up with far more `let`s than I expected. Now I think the point is really *conversion* of errors (the `error_chain!` macro), and `chain_err` seems more like a glorified `try!`/`expect` mixture that ends up working like exceptions; `chain_err` is not even in [the documentation on docs.rs](https://docs.rs/error-chain/0.10.0/error_chain/?search=chain_err). [Edit] This is for an executable, not a library.
By all means. The OP made this and is free to do with it as he wants. I just think it's worth pointing out that the choice of license probably limits it from reaching its full potential.
Simply curious. Why would you need such a thing?
I don't know. I've just read someone writing something like that. What I think is it could be some optimization. E.g. they need to allocate a relatively small array, so it could be on stack and then work with it generically. Maybe let compiler optimize things based on the fact that the number is compile-time-known constant.
/r/RustEvangelists would work ;)
Thank you very much for insight! Didn't know that. &gt; consistently faster? you get close to 90%/95% of the trades you want I felt like this might be the case but wasn't sure. Thank you again! &gt; did you know that a 1m network cable costs 3ns in latency? Wow, interesting! (Of course, I've known that length matters, I just didn't know the exact constant.) Is there any difference between optical and metal cable? (I think I've read somewhere that metal cable actually transmits EM, so the speed is same but the resistance of the cable is the reason optical cables exist.)
I believe the main reason is it isn't crypto hasher. That being said, if we had integer generics, I think it'd be interesting to have CryptoHasher&lt;N: usize&gt; { fn finalize(&amp;self) -&gt; [u8, N]; // ... Other methods }
I'm not *that* much of a network nerd, but I think the main difference is that optical cables have higher bandwidth. Bandwidth is not that exciting in HFT, however higher bandwidth means lower latency. 50 bytes at 10 Gb/s take 40ns to transmit. --- Note that even with so-called optical cables the signal is NOT traveling at the speed of light; which is why inter-datacenters HFT tend to use Radio signals rather than cables (that, and because Radio can get you a much straighter line as well). The [Sniper in Mahwah](https://sniperinmahwah.wordpress.com/) made a long running serie of investigating Radio Towers used in HFT; it's quite an amusing read.
I sure many a landscaper has cursed [desire paths](https://en.wikipedia.org/wiki/Desire_path), but there's only so much you can do.
you mean /r/programmingcirclejerk
&gt; the signal is NOT traveling at the speed of light Do you mean that it's slower in cable than in vacuum? Or that there is a latency when strengthening/(de)coding the signal? &gt; HFT tend to use Radio signals So much interesting stuff today! Thanks!
&gt;Rules &gt;... &gt;Only one mutable borrow at a time This is awesome! :)
I mean that it's slower than when traveling in a vacuum.
Maybe bit unrelated but is there somewhere a (popular) dumping ground for random Rust types and functions? I mean specifically the cases when someone creates some small piece of code that might be re-usable but doesn't feel like creating crate for it. E.g. a string escaping function or `fmt::Write` impl encoding with UTF16... If there isn't something like that, I'd love to start it!
So, `Hasher` wouldn't be equivalent to `Hasher&lt;Output=u64&gt;` even with the default? That's unfortunate, what's the point of that feature then?
It depends. HFT is concerned about latency, and more specifically about the difference of latency between your setup and that of your competitor. As a result, as long as all competitors use the same kind of cable, with the same length, and connect to a fair switch/matching engine, then it doesn't really matter what the latency of the cable is. However, there's another layer to this: inter-datacenter communications. The economy is global, and therefore what happens on one exchange influences the others. For example in Europe, Frankfurt is one big trading place and London is another. Getting the information that a trade occurred in Frankfurt to one of the London exchanges faster than your competitors is therefore worthwhile, and at this distance the difference between a weaving optical cable and a straight Radio line is counted in *milli*seconds. If you get the information one milli-second in advance, you could be trading in Python and still win the race; so all HFT competitors use Radio, and there's a huge gain in setting up a better radio line than your competitors.
Thanks for pointing that out. It was true several months ago; but when GitHub updated their TOS, there was uncertainty about its affects on Copyleft code. Because of this I've stopped using GitHub as a mirror until I hear otherwise.
Is there a way to add the `-Z unstable-options enable-commonmark` flag to cargo.toml or in anyway such that docs.rs will compile your docs using commonmark?
Well if that's sufficient for the use case then I'd argue that using except (rather than unwrap) would be sufficient.
Yeah what is the name of the subreddit for the game rust
For comparing Rust traits to Haskell typeclasses, there's a [FAQ answer that directly explains](https://www.rust-lang.org/en-US/faq.html#how-do-rust-traits-compare-to-haskell-typeclasses)!
This is because `Hasher` is supposed to be used by hash tables, not for cryptographic purposes. Hash tables don't need 512 bit hashes, Rust doesn't even use all 64 bits (most of the time). The reason is, if a hash table has, say, 32 buckets, then Rust can only use 5 bits out of 64 bits to determine which bucket has to be written.
It's not just you
&gt; Could you please explain these features in plain english ... Well, those *are* relatively plain English. Any explanation kind of depends on what level of familiarity you have. If it's zero, I'm not sure *any* explanation on Reddit is going to be that helpful. You also seem to be familiar enough to know what at least some of these are, so I'm not sure what you want here. It's really not conducive to writing a good explanation when the question is "please explain everything". Still, I can take a stab in the dark... * Don't pay for what you don't use, and don't pay at runtime for what you do unless that's unavoidable. * Moving values is the default, copying is the exception. * If it compiles and you didn't use `unsafe`, it's memory-safe; no segfaults, stack smashes, overruns, dangling pointers, *etc.* * Exactly what it says. * Generics are checked at definition by specifying how you want to use type parameters, rather than checking when you substitute them. * Again, what it says on the label. * Ditto. * No VM, no JIT, no GC, no monitoring environment. Rust can theoretically run on pretty much anything C can. * C↔Rust is as fast as C↔C. &gt; ... why they are better than alternatives ... Who says they are? Just because a smartphone "features" a shiny white finish doesn't mean it's better or worse than a matte white finish. But if you're looking for a phone with a shiny white finish, then hey, it's got that. If you're looking for matte, well maybe look elsewhere. Now shiny *black* finish... that's got no business existing. Unless you always wear gloves, I suppose.
/r/playrust Stick around and learn some Rust, too, though. ;)
Like this? https://github.com/cedenday/rshare/blob/d23c05850e7f94c59aa76c9d8b0a73e2df840713/src/client.rs#L150-L156
I've proposed such a trait in the past for getting the determinant out from an enum.
Someone is using WebKit2Gtk for sure. It's [antoyo](https://github.com/antoyo) on github. You should take a look at his profile (don't remember the project's name).
Thanks! It is [titanium](https://github.com/antoyo/titanium). I can see [their code](https://github.com/antoyo/titanium/blob/d9982003e29d01f9341f60eff5607b969203931b/src/webview/mod.rs) to use `webkit2gtk`, which is exactly what I was looking for =) 
This is awesome.
Good luck then. :)
I often think about mutability from a different perspective - that of embedded programming. My aim in the next year or so is to start using Rust in my personal projects, and use that as leverage to introduce it in my professional work. With many microcontrollers, there's some amount of program memory which actually *is* immutable unless you employ a specific procedure to write it. That is, a blind write to a flash address will generate a fault. It's often advantageous to have the linker place constant data there, since there is often more program memory than RAM. Additionally, it provides some degree of true safety against accidental or thoughtless modifications. So from that standpoint, it's a little disappointing to see that Rust doesn't have "true" immutability. I suppose the answer ultimately is to "be careful," which (to be fair) is a decent summary of my current language's (C) whole philosophy. I suppose it makes sense not to support more-or-less esoteric hardware features with language features, though it would be nice to see truly immutable bindings available. You could probably achieve the same effect by wrapping such data in accessor functions that only hand out immutable references. 
I just used an imageflip template. Its "exploding brain extend" or "exploding brain 2" Their UI is horrible to make these just a warning but good luck.
I find Gogs and GitHub equal in terms of UX. I remember finding GitLab difficult to use, but that was probably due to my familiarity with GitHub. I chose to use Gogs for my self-hosted instance because it uses way less resources than GitLab and I found it easier to set up.
Don't const and static cover the really immutable case?
It looks fixed now to me
Fun read! Thanks for sharing.
If you click on the image in the tweet it will enlarge, then you can right-click and view the image directly to see it even larger. The font size is still small, but I can still make out the Rust code clearly: https://pbs.twimg.com/media/C_GyS3pU0AAEEqd.jpg:large
Blind fixes, my favorite!
I'm flattered, but I believe that I misrepresented my intentions. I do not desire to make money from this project, I just want to ensure that any changes are made available for me to use. However, I withdrew some money from my savings and bought McDonalds for lunch. It was even better than noodles!
Yep.
&lt;3 Don't worry about it! I'm glad I was around and able to help, and that we don't have pagerduty set up to wake me up at 3am to take care of these sorts of thing yet ;)
&gt; Well, I think that makes sense. There is no pure capitalist area on Earth, so we can't prove whether "crony" without "capitalism" would work better than "capitalism" without "crony". So, to settle this debate, I suggest to split: anarcho-capitalists should create their own system and socialists should create theirs there should be single fairness rule: none of them may force people to stay there. Honestly, I see no reason why the problems of capitalism, which have long been documented, will disappear without a state. By Occam's razor, I'd point to capitalism being the problem (the assumptions of otherwise would be that some kind of free market magic suddenly fixes poverty etc. etc.). Futhermore, I'm not even sure if capitalism can exists without a state without either resulting in actual anarchism or fascism. It also seems that the "crony" adjective is only used when convenient. I take issue with that. You can't take all the successes and accept them as being capitalism's, yet deny all the failures as being of "crony capitalism". &gt; After some time it should be possible to determine which works better. It may be entirely possible that some people will like one and rest the other. The fairness rule would allow people to switch based on their preferences. Capitalism is not, and will never be voluntary. I truely doubt they can coexist in any way. &gt; BTW, an-caps try to do it already by building Liberland. Is there some similar movement in socialist community? Several. Every country has small-scale anarchist/socialist communities. Large areas exists too: Such as Rojava (they are one of the most important in the war against Daesh) and Kerala (pretty big economy in India, socialist to some extent). Historically, places like Catalonia, Paris Commune, and several others have existed. These all ended up being invaded. "Homage to Catalonia" by Orwell is a quite interesting book about anarchist Catalonia, which Orwell voluntarily fought for in millitias.
This gave me quite the chuckle at RustFest and I'm glad everyone involved took it all with a big smile. Now you've got a great story to tell!
&gt; I don't understand this mentality. Linux is GPLv2 and it's used everywhere. Why is this different? Linux is a standalone product, the GPLs viral nature doesn't affect software running on the kernel. Libraries and frameworks are infrastructure. As stated above I won't collaborate on infrastructure under the terms of the GPL, and lose control over my app in the bargain. How I share my projects, or don't, is a choice I want to make myself. &gt; Regardless, hayaku is pretty trivial. I don't know why a community would arise around it. I just wrote because existing frameworks felt too complex. Ok. Thanks to the license chosen, I didn't investigate close enough to rule it out as trivial.
At least some of it is from rustbuild - I can see this line https://github.com/rust-lang/rust/blob/8d19877ecea0cd22b7f5feaac5fb549f38aa3f71/src/bootstrap/sanity.rs#L43
I don't think this will work. The goal of the closures is to solve a single issue - because we have types and interfaces in this actor library, a generic library like a cache doesn't know how to send a message back to whoever queried it. Imagine I have a redis actor. In order to return a response I have one option currently - the redis actor has to know the exact type, whether it's a concrete actor or a trait actor, of who to return to. So you have something like fn get(key, actor) { value = get_value() actor.????(value) } Either every actor that want sto us this redis cache has to implement a trait for it or this basically can't work. The other option is a closure, which can capture the calling actor. The calling actor already knows how to handle the cache response. Essentially, the way to 'return' a value is provided by the caller. This opens up some nice features like short circuiting - instead of having the message return to me, the message can be returned to any actor I know the name of. It also means that underlying structures need to hold onto their own mailbox. This is something I haven't designed around yet but it isn't hard, I can automate this with the macro by injecting the field into the structure. So it isn't about asynchronicity or anything like that, it's about actors not needing to know the exact details of who called them.
Nice! I didn't realize C++ allowed this :)
&gt; My understanding is that parser combinators are just that, simpler parsers that can be combined to make more complex ones. Parser combinators are the higher-order functions that manipulate parsers. The parts are just parsers. 
It's one of those things where I've heard them before, and it made sense just fine, but I'm just now really getting to internalize it! Thanks for the explanation, that does make it more straight forward! :)
Hope the code they "used" wasn't GPL! ;-)
How is the reference counted smart pointer and vectors better than the std ones? If there are unsafe edge cases this patches over, it's possible it's less performant and/or less portable than the std ones. 
Finally Rust is production-ready for game developers!
Took me a while to get around to it, but this ended up working for me. Just wanted to comment in case any one searches for this in the future.
You forgot a word: &gt; Given a fully concrete type there definitely only one trait implementation possible.
About the issue with long where clauses: trait aliases will help with that when they're available. The RFC has been merged but they're not implemented yet. Progress is being tracked [here](https://github.com/rust-lang/rust/issues/41517).
Your Rust code is moving the original object, your C++ code isn't &amp;ndash; despite the `std::move` call, your source object is const and thus cannot be moved from (here it is silently copied instead of moved).
Wink wink
Are you responsible for this??
I might have something to do with it. I may have had some accomplices though 😆 As you can see, in the future, high tech companies are using rust!
&gt; Objects are always "mutable" Except for `&amp;'static`s. As far as I know there is no safe way to get a mutable reference to those and trying to mutate a static string via pointer cast and transmute hacks is probably undefined behaviour.
&gt; Yes it is. But the user failed to understand the limitation: you can write your own traits and implement them for other peoples types, you just cant impl other peoples traits for other peoples types. And that means that they are, at least in that regard, less flexible than type classes in for instance Haskell and Scala, where that is possible (you can make implementations of other people's type classes for other people's types, which can be very useful if the type class and type came from two different sources). But I would assume that traits in Rust either fits more into Rust in general and/or has a number of benefits, such as optimization or run-time cost.
Fair use *shrug*. This is one of the few cases where the license actually doesn't matter. (IANAL, personal opinion not legal advice)
What? You mean the C++ compiler complains at me all the time about `const` correctness in nested function calls but here it silently breaks `move` and copies instead? This is why I still haven't embraced move-semantics, 6 years after C++11 🙁 Time to learn more Rust!
Me too. I didn't see the code at first.
Thanks for the fun! :)
It's been a while since I did c++ professionally, but my understanding is that indexing beyond the end of a std::vector is undefined behaviour, rather than a well defined exception. Similar for iterator invalidation and dereferencing a null smart pointer. These all come with a performance cost, so it's unlikely to make it into the std as the default.
&gt; * zero-cost abstractions You can write `for i in 0..7` instead `for (int i = 0; i &lt; 7; i++)` or `let vals = (0..100).filter(|x| x % 3 == 0).collect::&lt;Vec&lt;_&gt;&gt;()` instead of `vector&lt;int&gt; vals; for (int i = 0; i &lt; 100; i++) { if (i % 3 == 0) { vals.push_back(i); } }` and get equally efficient code. &gt; * move semantics When you write `let y = x`, no matter what `x` is, you know it's not going to hide that there's a lot of work going on behind the scenes. &gt; * guaranteed memory safety Lots of bugs and security holes are caused by the program accessing memory that it's not supposed to when someone gives it unusual input. Safe Rust is incapable of accessing invalid memory no matter what the program's input is. The only other languages with this guarantee are all garbage collected, which prevents the "minimal runtime" bullet point. &gt; * threads without data races Rust's ownership model prevents you from modifying the same data from multiple threads without synchronization, which is another common source of hard-to-track-down bugs. &gt; * trait-based generics Stolen from Haskell, pretty much. It's an advantage compared to C++'s model, since it won't do anything stupid if you pass a `Door` to a function expecting a `File` and it tries to `open` it. &gt; * pattern matching Also about as powerful as a typical functional language's version, but completely absent from most other imperative languages. &gt; * type inference Intentionally less powerful than Haskell's and OCaml's. Inference only works within function bodies, forcing you to do what is the best practice in Haskell anyways, writing out all function signatures explicitly. &gt; * minimal runtime The code you write is the code that runs. Nothing more. No garbage collector or thread scheduler chugging along in the background, no need to install a virtual machine to run the code, no ten-second warm-up time. &gt; * efficient C bindings You can call Rust from C and C from Rust with the same efficiency that you call C from C or C from any of the billion languages capable of calling C functions. This is helped by the minimal runtime. It means you can take a big application partially or fully written in C and replace it piecemeal without killing your program's performance, and you can integrate Rust with any language that can already call C, which is most of them.
As far as I can tell, you're right, and this does only return the last float. rather than take the sum.
Rust is more of an indie games than AAA.
This is going to be one of those posts where OP never even comments on any responses or thanks anyone, even after asking for an essay to be composed on their behalf. You should do at least a simple Google before asking a question, and you should explain what you found from that search and what you actually want help with, specifically, not just "everything". You should also interact with people who take the time to comment on your post. That's just basic internet etiquette, but you've done none of that. Any time I see a post like this, it literally causes me a minute of complete frustration.
Isn't VHDL based on ADA.
Gotcha. Thanks
OK that _kinda_ makes sense. It seems unnecessarily confusing that, depending on which side of the ":" you put your `mut` or `&amp;mut` identifier, entirely different compiler checks come into play. What I'm saying is that at first I was confused that in one scenario you have the `mut` modifier on the left side `fill_vec(mut vec: Vec&lt;i32&gt;)` and here you only need to think about Rust's binding semantics. While in another scenario you have the `&amp;mut` modifier on the right side `fill_vec(vec: &amp;mut Vec&lt;i32&gt;)` and suddenly you need to start worrying about borrowing and mutability of the argument in its calling context. 
I just wanted to know why you would call a crate NUL. When I saw the post here on Reddit, I tried to find the crate so I could find out, to no avail (granted I didn't try that hard). I'm happy I finally get to know what the crate was about. Now it makes sense.
When passed a const lvalue, `std::move` will return a const rvalue reference; however `basic_string`'s move constructor strictly takes a _non_-const rvalue reference. Const can be added implicitly, but must be removed explicitly via `const_cast` (or a C-style cast). EDIT: `std::move` takes a `T&amp;&amp;`; when passed a const object, `T` will be deduced to be const as well, so in this case the actual parameter type after reference collapsing is `basic_string&lt;&gt; const&amp;`.
I thought about recommending that one but it's somewhat out-of-date now that custom derives are stable. [`enum_traits`](https://crates.io/crates/enum_traits) has a similar API but supports custom derives natively through `enum_traits_macros`. 
It depends what you index with; `std::vector` has both `operator[]` and member function `at()`. It's _there_, you just have to opt to use it.
Rather than making a macro that takes a list of filenames, and invoking it with your hardcoded list, have you tried creating a macro that takes a single filename, and invoking it multiple times (once for each file you want to test)?
Thanks for the link. On mobile the twitter website does not let you zoom in enough to read any code.
&gt; &gt; Um no it costs the entire processor state for each branch, in registers (not even L1 SRAM). &gt; Can you explain what you mean by this? I honestly can't parse what you're saying here. Well I don't really give computer architecture lessons via reddit... Look, I'm trying not to say this in an asshole way, but if you don't know what "processor state" means, or the difference between a register and an SRAM cell, maybe you don't really appreciate what the costs are and where they are incurred? &gt; the predictor will evaluate them in parallel and predict ahead Thought experiment: your chip with X registers encounters a branch. It predicts the branch goes one way. The next instruction down that path destroys part of the processor state (say, overwrites some register with a zero). Since the predictor can never be 100% certain it will be correct (even if it is almost always correct), it has to save that state that is destroyed in the speculatively chosen branch. Where is it going to put it? What if you have a chain of back-to-back branches like this, separated by a maximally-state-destructive instruction (like zeroing out some huge kilobit-size vector register)? You're sweeping all this stuff under the rug. In real life all this state has to be kept in extremely fast, extremely expensive storage (i.e. registers -- not even L1 cache), which runs out almost instantly if every single arithmetic instruction is a potential branch, and the processor simply has to stop attempting to predict branches because it has run out of close-at-hand places to stash the data needed to recover from a mispredicted branch -- even if that only happens 0.00000001% of the time. 
If I were to wildly guess, I would say put a `#[cfg(test)]` block in `build.rs`?
In a rust program dealing with this I'm sure you'd just use statics with link_name to refer to that memory, and that would be immutable. We're only talking about owned data here. That's a property of the data, not the memory location -- an owned struct can be shuffled around the stack or whatever. When you have a specific memory location that's going to be a reference, probably a static one. Not owned, not mutable. It's fine.
You can use link_name with static though
:) I didn't recognize the source, I thought it was just some play utility that the devs hacked up for the lulz.
&gt; Syntax, especially as simple as that, is rarely an issue And it's not even syntax, just convention, so you can still use camelCase if that makes you happy, though you should probably just use whatever is in the standard library so everything is consistent.
&gt; snake_case is less readable than camelCase because of how they interact with the linter's line-length setting If a few characters is what's causing you to run into linter issues, then you either need to tune your linter to accept longer lines or decrease your indentation level (i.e. break up your code into smaller pieces). Most of my code sits around 60 lines or so, which lines with text as the main ones that push the limit. &gt; because of the APIs I was working with, it could get a little ugly and akward to fit things into 80 columns I've been there as well, especially with `selenium`. `find_element_by_css_selector` is really hard to fit on one line even if your selectors are super simple or you store them in a variable. However, I don't think switching to camelCase would fix the problem completely as I'm often around 90-100 characters per line when doing browser automation.
I just want to chime in here to say that I'm really impressed that, while this question got downvoted to oblivion, the commens are on-topic and constructive. That is all :)
All I'm saying is that, for any given line length, there will always be some API that winds up at just the wrong spot. (and I remember it being easier to trip over in Python because of how certain small syntax assumptions born in the indentation-based grammar don't get relaxed when inside parens.)
Not available for Linux, :-/ 
They provide a faster, non-threadsafe reference counter pointer similar to Rust's Rc. They also provide a safer iterator, ipointer, which remains valid even if the vector storage is reallocated. The primitive type classes looks useful too for avoiding problems with size_t etc. It all comes with a slight performance cost (they mention about 30%), but that is probably acceptable for many projects. The library looks good to me and I would consider using it in a larger C++ project.
Best idea would be to lock it at 'not legal advice, I'm just a guy on the Internet' 
You mean we should answer yes, if one option is true and no if none or both are true? Seems strange to me... ;-)
I thought you meant as an asset manager :(
Concurrency is just an important example; it's also why I didn't stop the sentence where your quote ends :) Though I'm glad to have more concrete examples of other issues too :D
Is this going to be deleted since the post wasn't made as a moderator? :P
Yes, my mobile client double-posted.
Happens with the best ;)
And what would the use of that be? Rust itself looks up `nul/lib.rs` which would then also not compile.
Trying my own hand at a OpenGL accelerated GUI library with glium for the accessing GL, rather tough project and I've literally just started out, especially since some bit of rust still catch me out and I need to toy with ideas to find something that works. I'm not really a fan of immediate mode stuff, and I was hoping for a more of a "view" / "model" separation especially with the defining interfaces in some sort of markup, and curious if I can implement some sort of thing akin to data binding. But these are just pie in the sky ideas at the moment, I literally started the project last night, so amount of code and specific approaches to doing things are not even coded yet. We'll see if I get anywhere with it.
They only keep two threads pinned, and this week the pinned position is taken by the survey. Yeah, I, too, am wondering about why they don't just pin it as a thirth thread.
Because you can't, reddit only allows two threads to be pinned
How can I wrap a std::io::Cursor over a stack allocated array? use std::io::{self, Cursor}; const BLOCK_SIZE: usize = 4192; struct Block { cursor: Cursor&lt;[u8; BLOCK_SIZE]&gt; } impl Block { fn new() -&gt; Self { let buf = [0u8; BLOCK_SIZE]; let cursor = Cursor::new(buf); Block { cursor: cursor, } } fn write(&amp;mut self, b: &amp;[u8]) -&gt; io::Result&lt;()&gt; { self.cursor.write_all(b) } } The error I get is: [rustc] no method named `write_all` found for type `std::io::Cursor&lt;[u8; 4192]&gt;` in the current scope 
Maybe use an MPMC library like https://github.com/BurntSushi/chan? It's either that, or don't store the spmc::Sender in S - just the receiver and join handle. You could also do an Arc&lt;Mutex&lt;Sender&gt;&gt;`, but... I think that'd be missing the whole point.
Too bad you can't patch the game.
If you really have to play outside the rules a little, you can work with unsafe code to "cheat" the borrow checker. While frowned upon, there are some situations where it's necessary, so I don't think the community considers it a problem. Oh... you're talking about the game, not the programming language. You're probably looking for /r/playrust. ;D
`Write` is not implemented for `Cursor&lt;[u8; N]&gt;` for arbitrary `N`. But you can use a slice: use std::io::{self, Cursor, Write}; const BLOCK_SIZE: usize = 4192; struct Block { data: [u8; BLOCK_SIZE], position: u16, } impl Block { fn new() -&gt; Self { Block { data: [0u8; BLOCK_SIZE], position: 0, } } fn write(&amp;mut self, b: &amp;[u8]) -&gt; io::Result&lt;()&gt; { let mut cursor = Cursor::new(&amp;mut self.data[..]); cursor.set_position(self.position as u64); let result = cursor.write_all(b); self.position = cursor.position() as u16; result } }
Ooh, that's nice! I think I found that RFC at some point while I was looking for a solution to the long where clauses, but I'm not sure I realised it was applicable to my code. But now that I've read it more closely, yeah, this would be great for my stuff! :)
The "new" way is just the raw way where the win api has less to say compared to the underlying file system. That does not mean it's the new or preferred way. Even Windows explorer does not use that way to interface with your FS. This means that if a rust crate ever had that name you could not do much with it in windows explorer (like move it to a different location).
I'm looking into building a language like uml for describing architecture and logic flow charts. I'm not happy with how uml works, and plantuml is far too slow for me when I have larger diagrams. I definitely don't need the full features right now, I'd like something that is simple, themeable, and fast. I've mostly been putting ideas together for right now though, since I haven't had a lot of time to actually sit down and code. 
I'm working on [timely dataflow](https://github.com/frankmcsherry/timely-dataflow) and [differential dataflow](https://github.com/frankmcsherry/differential-dataflow), but in particular I am trying to think of ways to lower the barrier to entry for participation (e.g. curated "easy" issues). Any thoughts on how other "big" projects do this? It's a bit of a problem in that (i) there are some interested folks, but (ii) the barrier to entry for the system as a whole is real.
I continued my work on [relm](https://github.com/antoyo/relm), an asynchronous GUI library based on GTK+ and futures/tokio. Last week, I: * moved the model back into the struct implementing `Widget` which is convenient, but brought some challenges. * made some fixes related to mutability of methods in this trait/struct. * added the possibility to add custom method in the impl annotated by the `#[widget]` attribute, which means that inherent methods can now be updated by this attribute (updating the models will update the view). * fixed some bugs about generating `impl` for generic type. * added the support for child event, i.e. if you have a `gtk::TreeView` in your `view!`, you can connect an event to its `selection`. * added a lock so that we can circumvent circular events that would cause an infinite loop or borrow error in relm (relm should not catch this borrow mut error to show a useful explanation saying to use a lock). * relaxed the event emit function to allow recursive event emission. * made some cleanup thanks to the new gtk release. * added logging so that we can see the generated code using `RUST_LOG=warn`. (Don't worry if you don't see all these commits, they are in the [`feature/futures-glib` branch](https://github.com/antoyo/relm/commits/feature/futures-glib).) And my [`mg` crate](https://github.com/antoyo/mg) was finally completely ported to relm! I also took this opportunity to improve it and its sibbling [`mg-settings` crate](https://github.com/antoyo/mg-settings). This means `relm` is hopefully approaching alpha stability because this `mg` crate is somewhat complex. This week I'll work on the integration of network code and `futures-glib` to merge this branch in master.
Can someone explain this code a little more clearly? I understand that he's created his own local Result Type which is a Result&lt;MyConfiguration, Error&gt; but do the .map_err 's just type cast the error being returned from the IO? Additionally how does toml::from_str() know to return a MyConfiguration? Is the compiler doing type inference based on the return type of the function? 
I do not think using futures will cause any problems. I'll try to write a proof of concept and will submit a pull request... if I'm successful :)
Continuing to work on my [softrender](https://github.com/novacrazy/rust-softrender) crate, with a fully functional geometry shader and primitive clipping in the works.
Not with that attitude!
I'm more than a little disappointed in myself that I had not thought of that... I will try that out and see if it works.
&gt; todo how about do_it() ?
I've been working on a generic protobuf decoder called [pq](https://github.com/sevagh/pq) (name inspired by jq). Some of my dependencies are using serde 0.9.x so I've been attempting various pull requests to get them updated to serde 1+.
This is more of a hypothetical just thinking back to some cpp I've seen. I guess separate? Is it possible to make a crate and use it locally? Like in cargo.toml I can add myDep = "myDepFolder"? That would be pretty cool. 
It's possible to depend on a local crate [as described here](http://doc.crates.io/specifying-dependencies.html#specifying-path-dependencies). However, it still needs to be a valid crate, not just any folder. Edit: also, what's your use case for using multiple crates like that?
&gt; I imagine wanting to replace a transitive resolved dep. But I think cargo can already do that? Do you mean `[replace]` replace? Or do you mean "force a specific version"? You can specify a transitive dependency's version in your Cargo.toml to add a constraint, [I had to do this for crates.io recently](https://github.com/rust-lang/crates.io/commit/0e1b8afac8f2112287134b4362d237d6480547d5). &gt; Would be nice to see a big tree of all the libs and just select a fork/version. Could you elaborate on what you mean by "see" and "select"? For example, do you mean a cargo subcommand? Could you give an example of a project's Cargo.toml and what output you'd expect to see? By select, do you mean "manually read the output of the previous and copy into my Cargo.toml" or do you mean something more interactive? Could you perhaps put this elaboration in a bug report on cargo? :)
[Lawyers have argued that a painting containing Java code was fair use](https://motherboard.vice.com/en_us/article/why-the-very-silly-oracle-v-google-trial-actually-matters) :also shrug:
I'm trying to build a Rustic interface to the hardware on the [BeagleBone Blue](http://beagleboard.org/blue). The work is currently quite slow do to other obligations, but I hope to finish quite soon and release a preliminary create with at least the LEDs, Buttons and built-in sensors accessible. (Except for the sensors the work is very easy thanks to [rust-embedded](https://github.com/rust-embedded))
I'd never really thought about the internals of a VCS, and thinking of files as a DAG of lines was definitely eye-opening. Thanks so much for the post! And, the diagrams were really helpful (and necessary).
Nice.
The ones that will be designated for I suppose?
It's finals week so I'm pretty swamped with homework. However, I'm working on a blog post for next week and doing research on Green Threads
YAW, I hope you'll find it useful!
Can the error message for "cannot move out of borrowed content" be improved? struct X; fn main() { let v = Vec::&lt;Option&lt;X&gt;&gt;::new(); for it in v.iter() { it.unwrap(); } } Here, my error is calling `.iter()` to produce a borrowing iterator instead of iterating over `v` itself, but the compiler can't know that. Still, these three all give "cannot move out of borrowed content": it.unwrap(); *it; Option::unwrap(*it); But this is closer to what I intended: "expected type `std::option::Option&lt;_&gt;`, found type `&amp;std::option::Option&lt;X&gt;`": Option::unwrap(it); When I type `it.unwrap()`, I am told that my error is an attempt to dereference `it`. But I think my error is in calling a method that takes ownership of a value which I have only borrowed. The compiler is inserting an implicit dereference and then chastising me about it.
Ideas? Comments? PRs? I want to know!
Thanks, very interesting! Two questions though: * How is flattening a digle to a file a patch if you're not allowed to delete lines? * Your counterexample in "Deleting lines" is kinda artificial, because the patches do transform a file into two digles that are different, but would flatten to the same file. As in "Nobody does that" :D Do you have something closer to practice? Or maybe one can put a restriction on the allowed patches to remove that problem? Maybe "A patch is either a perfect merge, a flattening or a patch of files" would work.
 fn bad_deref() -&gt; !; is this even a thing? What it called?
I agree that this is not the best error message. What should probably be done here is call: it.as_ref().unwrap() Which transforms &amp;std::option::Option&lt;T&gt; into std::option::Option&lt;&amp;T&gt; and then unwraps it. 
Maybe their CI does a fetch of that text to create the new asset ;)
You're welcome! But be careful: I never said DAG (although an earlier version of my post did, because I was confused)! In fact, it's possible to construct a (somewhat artificial) sequence of merges so that the resulting digle has cycles.
`panic!()`, obviously. The function is allowed to do logging, etc before that, but at the end it must panic.
Very cool! I haven't used thrift a lot, but did use it with a Go project. Good to know there are solutions out there with Rust in case I ever need it :)
Very interesting post. This reminds me a lot of /u/raphlinus's article on CRDT for Xi: https://github.com/google/xi-editor/blob/master/doc/crdt.md It uses the same idea of a DAG, flattening and ghosts / tumbstones, which makes sense since they solve the same problem of concurrent edits.
30% seems like a lot to me...
Trying to get back to work on [ggez](http://ggez.rs/), an easy-to-use but flexible 2D game framework. We really need to get around to getting 0.3 out the door, since it has so many improvements over 0.2.x... gfx-rs rendering, rodio sound, lyon tessellation for nice (if primitive) shape drawing... Turns out there's also a *lot* of work to do to get all the fiddly bits around the edges sorted out, though. "Oh yeah, I never implemented being able to set blend modes for individual images... Oh yeah, that needs some work to add extra information to images... Oh yeah, I'm not actually sure how to best do that..."
Thanks! I'll definitely be giving examples where pijul differs from git, but in order not to inflate expectations too much, let me also give this caveat: it isn't clear to me whether pijul's improvements are a productivity game-changer (in that they will entice the masses to switch, the way everyone went from CVS and SVN to git). In order to really answer that, I think we need more experience with different workflows on large projects with complicated histories. But I'm optimistic!
AST would be really interesting. BTW there already exists [semantic merging](https://www.semanticmerge.com/) but I have no idea how good it is. I'm waiting for Linux version.
Thank you. I know of build scripts and have used them in the past, but didn't want to have to run a build script every non-test build, especially if it can fail, as any file IO is want to do.
I'm hoping to get two features of my derive actor project working, at which point I'll be publishing a crate. Specifically, generic actors, and generating code for handling return values. I'm going to mostly be away though so I may not have much time.
I honestly prefer that it isn't pinned. My eyes mostly gloss over the pinned threads and I end up not seeing them for days, though maybe that's just me. I think the ideal method for threads like these are to give them the first day in the normal pool of content then pin for the rest of the week.
Working on an unified alerting system that's written in Rust that will manage all alerts from various monitoring sources (i.e. time-series, probes, crashes, structured logging). Have most of the scaffolding working just finishing up the state machine code and config reloading logic this week.
Is it intentionally part of the example that some examples have to-do list and others to-do list: I don't see it mentioned otherwise and it was confusing me a bit when reading the examples.
Could you say what you read that restriction to be exactly? The section you quoted was meant as a general introduction to why immutability is nice without being specific to Rust, so I just want to make sure we're talking about the same thing :)
The "only owned values can mutate" one and "mutation XOR aliasing". Yeah, in general immutability is nice. Just that Rust's way of doing it doesn't exactly address concurrency safety; the concurrency works via a different but related system. Immutability is a part of that story, but not all of it.
Or just hang indeterminably, like start a `loop {};`
Totally unintentional, thanks for pointing it out! I've fixed it now.
Some examples of mixing things around (not exhaustive), you can: * Depend on a crate on the file system *outside* of your current crate. (othercrate = { path="../othercrate" }) * Have multiple sub crates *inside* your source tree that use each other. (check out cargo workspaces) * Have a mixture of library and binaries all generated from the same crate. (you can have a lib.rs *and* a main.rs, or a lib.rs and lots of things under bin/ for example. You can extern your own crate name in this example) * include!("file") files on the file system (injects them into the source of your current source file during compilation)
Missed an opportunity to call it a `NuclearOption`.
And what if no one volunteers to be designated to review crates? What if those designated to review crates don't have enough time to keep up? What if people in the community disagree with a crate review? The core team would have to spend time managing all these things, and the core team is overworked as it is :(
I hope to continue last week's progress on [xi](https://github.com/google/xi-editor). @cmyr is working on multiple plugins. I have basic multi-cursor editing working and want to finish that (including deleting the old single-cursor state). @trishume and I are working on a redesign of the CRDT engine to allow for multidevice. @rkusa is now focusing on font/style improvements.
That's why we have the RFC system and the subteams. We can write a RFC to state what should be included into a crate so it can be released as a 1.0 and create a subteam to review submissions.
Thanks!
There's still a `u8` determinant there, it's just packed into the type.
Nice, I didn't realize there was a macros 1.1 replacement already.
Very nice writeup! Wish I could give more upvotes. I am quite interested in DVCSes (contributed to Monotone way back in the day, was a pretty early adopter of Git, and was always rooting for Darcs even though I never used it heavily myself since I always felt that sets of commutable patches would be a more powerful model even though it had issues in practice), and had tried reading the original paper, and I think that I got the basic gist of it, but this explanation is a lot easier to read and understand.
base64 encoded hash prefix as a filename?
I ran into something a bit like this recently; this sort of reflection seems to be common with ECS systems. The two general-case solutions seem to be "get the type from the user" and "use macros to generate type-specific code". For the first solution, you would write a function something like fn merge_changes&lt;T&gt;(state: HashMap&lt;TypeId, Box&lt;Any&gt;&gt;, changes: HashMap&lt;TypeId, Box&lt;Any&gt;&gt;) { let id = TypeId::of::&lt;T&gt;(); let state_item = state.get(id).downcast_mut::&lt;T&gt;().expect(...); let changes_item = changes.get(id).downcast_ref::&lt;T&gt;().expect(...); merge_changes_for_specific_type(state_item, changes_item); } Then you have to call `merge_changes::&lt;MyType1&gt;(); merge_changes::&lt;MyType2&gt;();` etc for each type. (I would also make a guard check that looks for unused changes left over in your change set, and gives a warning if you might have missed any.) The macro solutions I've seen do basically the same thing, you just tell it what all your types are once at compile time and then it generates the code to do all the bookkeeping for you wherever you need bookkeeping. `calx-ecs` is a decent example of how things get done in the macro-y way, `specs` and `constellation` try to do everything at run-time but require you to tell them what types you are using quite often. It does seem like the sort of thing that better run-time reflection should be able to handle. We can check whether a value is a type we know at compile time, but we can't actually do a `downcast_ref()` for something based off of just the `TypeId`. Getting traits involved might make life a little easier in some cases but I expect you'll still bump into issues where `Any` and `TypeId` just can't do what you want entirely automatically. :-(
I think we should talk about this before doing anything. I'm only part on the doc team and I'm not interested in this at all. However it'd be a nice thing to have.
Maybe example for Rocket will help https://github.com/SergioBenitez/Rocket/issues/106#issuecomment-294298252
Of course, it could also cause infinite loop. Panic is just the most reasonable thing to do... Is it even possible to terminate the thread without panicking?
This is quite an interesting question. I wonder how rustc handles this, especially in the light of incremental compilation. So, first step, create an integrated "make" framework to help those writers of `build.rs`!
The pijul.com link at the very end is broken; it tries to be relative to the article instead of absolute.
I'll be continuing work with [Tarpaulin](https://github.com/xd009642/tarpaulin). As I predicted last week, I spent a lot of time faffing about with ptrace. Right now I fork my process, request to be traced and launch the test executable and then aim to hit all the tests... What happens is I get the "Running N test(s) test tests::test_name ..." and then a SIGTERM kills the test process for some reason... I did manage to get coverage results last week by forcefully jumping the instruction pointer to inside a test before entering __test::main but I'm trying to avoid ugly hacks and jumping around like that too much in case it borks the internal registers and messes up things like branch/condition coverage. I was fairly busy last week and didn't have any real time at the weekend to work on it so I'm hoping since this week is a lot quieter I'll be able to smash through it in my evenings.
My main gripe when viewing a diff, is when the diff viewer splits a logical block in two: the first half goes to a new unrelated block and the second half is preceded with "new" code (which happens to be very similar to first half of the previous block). It's really annoying to review :(
You should [file an issue](https://github.com/rust-lang/rust/issues/new) about this. We like to keep track of error messages that could be improved.
To me it's more about consistency. I hit a problem at my job once where `#include "Math.h"` included the standard C math.h header instead of a local file Math.h, but only on Mac. It feels kinda stupid that "path/to/file.rs" can be reached by "PaTh/To/FiLe.Rs". I mean I still prefer keeping everything lower-case and never have two files with the same name but different case, but I still want file identifiers to only have one valid spelling. 
Oh hey, I've been looking forward to seeing implementations of the Actor concurrency model in Rust - nice to see this one. Good going! Edit: Good god, that's some nice documentation.
That would be really helpful. Later maybe some basic refactoring? (renaming and moving things)
A build script can indicate which files to watch by using the `cargo:rerun-if-changed=PATH` directive, as documented [here](http://doc.crates.io/build-script.html#outputs-of-the-build-script).
This seems to be a solution to my problem. It is annoying how the tests are not as readable, but I guess that will have to be sacrificed to build on stable.
Well non lexical lifetimes should help. But you can split borrows if you structure your structs properly. 
Just make a new one, copy the code and yank down the old one. :-)
Didn't even know that's possible! I'll write a sample build.rs with this.
You probably wanted to post to /r/playrust.
/r/playrust
Thanks! A good and meaningful explanation. I know how to impl several nested traits correctly, this is why I'm really surprised that the direct implementation without `where` clause also works. If I remember correctly, this was banned a while ago.
could you expand on that second sentence?
I think he's talking about something like the Read vs Write trait split for e.g. a Stream. Logically figuring out separate function groups, if you will, and allowing a splitting and thus achieving a similar effect to "partial borrows".
&gt; If we have unrelated libraries A and B which has no knowledge of each other, and A provides a type class TC, and B provides a type T, it (assuming the type T has a meaningful implementation of type class TC) is possible for us to provide an implementation of TC for T, with the type classes in Haskell and Scala. Yes, but what I said (and I might be wrong) is that Haskell will issue a warning in that case. Many core developers of Haskell consider the allowance of orphan impls to be a bug in GHC. &gt; if you have a situation where having different implementations of the same type class-type combination would make sense, not requiring coherence is more flexible. Because you have to name the instances to select them I really don't see how this is different from just using a newtype, which Rust will gladly let you do. The 'flexibility' of incoherence is overrated.
ExitThread on windows, although it's incompatible with rust's safety guarantees.
Reddit only allows us two 'announcements' (which is what pinned threads are called nowadays) at a time.
&gt; All of this led to a single thing in the end: rust-sdl2’s 0.30 beta release (crates.io) (...) &gt; We prefer having beta-testers for this release to make sure the library is safe to use for a stable release. But per semver, 0.30 isn't a stable release to begin with. I think it's appropriate to just publish 0.30 to crates.io, and if it's really buggy perhaps yank it, then publish another version. Or, if 0.30 is supposed to be stable, rename it to 1.0 maybe.
I'm going to get a new release of rustup out, and write cookbook entries for [log](https://internals.rust-lang.org/t/crate-evaluation-for-2017-05-16-log/5185/7).
&gt; I am trying to think of ways to lower the barrier to entry for participation As someone who's been following along since the initial Naiad paper was published, I've always thought that Timely/Differential are research projects and your write ups are to organize your thoughts and get ideas from other academic-ish types. I've been following along because I find it interesting but never really put time into writing stuff with it because I don't have an immediate need for distributed/stream processing. Are you looking to turn the project into the Rust take on spark / flume / dataflow world where it's a production thing run by people who only sort of understand how it works and the support burden that entails or are you hoping more eyes on the code to generate ideas or research areas like your current dive into db benchmarks?
Trying to finish up 0.6 for Way Cooler, which has taken way longer than it should have. Part of that is me putting too much in this release, part of it is being side tracked with discussion about alternatives to wlc, and then exams took me out for a week or two. Last feature that I'm working on is tabbed / stacked tiling, which will complete the i3 features that I personally want in Way Cooler. Bit stuck on some silly rendering bug right now, but once that is fixed it should come along quickly. The next release is going to focus on better client support (eg cleaning up the dbus interface), better Lua support (giving it more things to do, plus better utilities), and better documentation (we have a [website now](https://way-cooler.org), so that would be the place it will go). When wlroots is complete, assuming it will work well with Rust, there will be a release where I just focus on that. But I'll probably be on wlc for a while, as the alternatives still aren't yet in a working state. 
Well, they use server implementation, I need the client one.
Well, it'd be impossible to implement `Deref` for it in external crates. Also I don't like mixing different types, especially dangerous and non-dangerous. As explained in docs, it has purposefully long and unique methods to avoid over-use and also to make it easy to debug. I'd be certainly against adding `Deref` impl for `Option`. I wouldn't object to including DangerousOption as a separate type in `core`, though.
Bloating crates.io is not nice...
There's actually no real answer to it. The running joke was that Graydon kept giving a different reason as to what it was called Rust, whether it be the mushroom or this. No one really knows why besides him, though I do like this answer personally.
Working on the [`thread` documentation](https://github.com/rust-lang/rust/issues/29378), hopefully all the boxes will be tickend by the end of the week. I'll also write cookbook recipes for the `log` crate as a part of the [library blitz](https://internals.rust-lang.org/t/crate-evaluation-for-2017-05-16-log/5185/15)
It's mostly that there seem to be a mix of folks interested in contributing, some because they are active in the research space (and want to try things out), and some I suspect because they would like to learn something. No particular goals for productization (hard!), but I'd love to improve it as a research platform. It hadn't occurred to me to try and engage people who might not otherwise use it (though, maybe a good idea). This was more "willing people, but looking for first steps", and me having only a limited clue how to set that up (e.g. as above, file easy issues rather than running off to fix them right away).
I actually prefer explanation in the [next comment](http://stackoverflow.com/a/16503716/1411900) of that thread. Imagine [a set of large, thick gears](http://www.featurepics.com/StockImage/20141029/heavy-gear-mechanism-stock-picture-3325328.jpg) churning away in the guts of some giant machine. Slightly rusty, but robust as hell. 
How difficult would it be re-implementing SDL in Rust using Rust's idioms and patterns? "S" in SDL means "simple"... :)
List of tokens and list of lines is essentially the same thing, the real fun starts when you define patches on trees or even graphs instead of sequences. Is the tree scenario really hard, though? Squinting at the whole thing from a completely naive POV it should be possible to nest patches. Graphs get more complicated because you get action at a distance, e.g. mentions of bindings pointing back to their definition, you would probably also want to ignore file boundaries, then. And, of course, the whole thing would need support from the language.
Oh, Hi guys, I was planning on posting this on reddit after a bit more development. I'm the developer for the project (https://keybase.io/alaingalvan)! I want to support Rust, but the language is a bit too complicated as a first language, Python is a simpler language and easier to parse. This is being built with Rust/Vulkano thanks to some experience I got working with Vulkano during some projects I was working on hooking it up to an Arduino and a raymarching visualization, in addition to working with Vulkan in C++ for my capstone project at my university. Thanks for sharing it! :) 
The answer is obvious: it's the intersection of trust and frustration.
Intetesting, thank you for explaining!
Could I suggest the examples be numbered to make it a bit easier for people to poke around without following the thing from beginning to end?
I didn't mean it in a semver way, I meant it in a "it won't explode in your hands" way. Maybe I should reword this part ?
I will be messaging you on [**2017-05-09 18:55:59 UTC**](http://www.wolframalpha.com/input/?i=2017-05-09 18:55:59 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/69qymh/i_did_a_rust_workshop_in_progressbar_hackerspace/dhb2swq) [**1 OTHERS CLICKED THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/69qymh/i_did_a_rust_workshop_in_progressbar_hackerspace/dhb2swq]%0A%0ARemindMe! 19 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dhb2tvv) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
So I've come up with this, which might not be the most optimized solution. https://is.gd/aTzrrW It would help a lot here if Rust had collecting to stack-allocated arrays, as we would not need another Vec. Alternatively, remove `to_tosql_ref` and use this: let all_params: Vec&lt;&amp;ToSql&gt; = params1.iter().map(|x| x as &amp;ToSql) .chain(params2.iter().map(|x| x as &amp;ToSql)) .chain(params3.iter().map(|x| x as &amp;ToSql)) .collect(); But I guess repeating yourself like that is exactly what you're trying to avoid.
Not my repo :P just wanted to share it with you guys
Just spitballing, how about returning a Result&lt;bool, ValidationError&gt; where ValidationError is an enum of: ` BadFormat, UnknownCountry, InvalidId ` hmm this suggestion feels weird, like it should never return false, and these Errors aren't like, really errors. What about returning a Result&lt;Iban, ValidationError&gt;, where the Iban has some useful info, like country_code. Now that feels too heavy for what it does. API design is difficult.
I think it's supposed to mean "close to the metal" (i.e. metals rust). It's a systems level language that gives you complete control* over memory management, after all. *within the constraints of its invariants
I wrote a crate specifically for this: https://crates.io/crates/from_variants
Success! Also, super trippy. Google Pixel, Android 7.1.2
This is hilariously accurate.
When you say anemic, do you mean it as a pun because it means lack of iron and therefore something that is hard to rust?
At first blush, this seems to have a few of soundness issues: * A task could easily set registers in a way that is incorrect for the hardware (Writing to a register before its associated clock gate is enabled could trigger a fault on some MCUs). I believe that this is a safety issue - it's essentially writing to unallocated memory. * Two tasks could clobber each other's use of a common hardware resource, potentially causing misbehaviors (a timer never firing when it's expected to). This isn't necessarily a strict memory safety issue by Rust's definition (I can write a trivial safe program that will cause a thread to hang using a "safe" global resource in a mutex), but it's the sort of soundness issue that I expect Rust libraries to protect me from. Coupled with the point above, a misbehaving task could possibly cause another task to hardfault by modifying hardware state. * I don't believe that your "disable interrupts" mutex is safe in multi-core Cortex-M systems. Presumably a task executing on a secondary processor could still access a shared hardware unit even if interrupts are disabled on the main core. This is also a memory safety issue, though admittedly very few real-world Cortex-M parts are multicore (this year, anyway) * Using your "safe" bindings to a DMA unit I can trash all of main memory. Even if the above hardware access were deemed "acceptable', this is clearly unsafe (I'd say any DMA access is unsafe without being very carefully wrapped in Rust's type and lifetime system) I think these automatic bindings are a great way to help jumpstart hardware access from Rust. But IMO they should be treated like the output of `bindgen` for C libraries - the unsafe building blocks that require a human to analyze the invariants and create safe, rusty APIs on top. To be clear, I think this is very valuable. "`bindgen` for hardware" is an awesome tool to have available! I wish I'd had this when I was hand-rolling structs for register blocks in my Teensy prototyping.
//! Sanity checking performed by rustbuild before actually executing anything. //! //! This module contains the implementation of ensuring that the build //! environment looks reasonable before progressing. This will verify that //! various programs like git and python exist, along with ensuring that all C //! compilers for cross-compiling are found. //! //! In theory if we get past this phase it's a bug if a build fails, but in //! practice that's likely not true! I'm not sure if it's not like that on purpose
No but I should have.
&gt; ... some architectures [...] don't have a LLVM backend ... Hence *theoretically*. There's no reason it *couldn't* run everywhere C does, it just doesn't.
https://fedoraproject.org/wiki/Licensing/MITNFA `MIT +no-false-attribs License` &gt; This license is based on the MIT license, but contains an additional section covering the removal of attributions in certain modification scenarios. It is Free and GPL-compatible. Use License: MITNFA 
Besides testing on devices, you also need to download a significant number of games on Steam (incl. all Valve games to date) and do a lot of QA testing on your own to make sure that you haven't introduced any bugs. For instance, [this bug](https://github.com/ValveSoftware/Dota-2/issues/1199) which [was fixed in SDL](https://github.com/spurious/SDL-mirror/commit/55c42e74ba6f41bf7f4c2950a8948359f7ae623d). Also, just porting SDL from C to Rust doesn't guarantee any additional bug fixes. What it *will* definitely give you is a stream of memes in /r/dota2 akin to "Source 2 will fix it" for quite a while. (Except this time they'll mostly be about SDL3, therefore Volvo is now able to count to 3, therefore HL3 confirmed)
You can take the survey [here](https://docs.google.com/forms/d/e/1FAIpQLScw5xyQCGireVaHLeb_8dQOhwvaqDZ5mF9utc0i75Z0pndhXg/viewform?c=0&amp;w=1)
I have a fairly good idea! It was named after a family of fungi. I happened to like that that family of fungi is, itself, named in a way that evokes other things; but that doesn't make it ambiguous. It was named after the fungi. Really. [We've been here before](https://www.reddit.com/r/rust/comments/27jvdt/internet_archaeology_the_definitive_endall_source/). That's the official word.
&gt;I thought Serde's code generation was more magic than I was willing to take; I'd much rather just write a simple deserializer, but that approach seems to be discouraged. Insofar as Rust *does* enable code re-use and modularity and functional programming, this is absolutely a good thing! It means all the mistakes get made once. &gt; I sort of feel like a kid who just bought a new Buzz Lightyear toy and found out that the wings don't actually spring out like it does in the movie. Rust has different use cases than python. I've definitely wanted to use it to replace some command-line tools (with success on the simpler ones), but I still do like python. And I use both it and julia for numerical stuff.
This one isn't quite as fun as previous posts, but it lays the groundwork for being able to do more complex things in the future. I was always kind of disappointed in how much unsafe I had in main in the earlier versions, and my plans for post 4 sort of forced me to clean it up anyway. There are Reddit threads for [Part 1](https://www.reddit.com/r/rust/comments/5nufdc/rust_on_teensy_part_1_bootup_to_led/) and [Part 2](https://www.reddit.com/r/rust/comments/5s3vkq/rust_on_teensy_part_2_sending_a_message/). I've also added disqus comments to the posts themselves, since Reddit will archive those comment threads in a few more months.
It's about the community, people. You can't spell "rust" without "us".
Isn't that kinda solved (at least most of the time) with patience diffs?
I'm continuing my efforts of upstreaming all my needs for my [Gattii](https://gitlab.com/susurrus/gattii) serial terminal program and its accompanying [serialport-rs](https://gitlab.com/susurrus/serialport-rs) lib. All my FFI functions are in libc for POSIX platforms, so I'm working on getting safe interfaces implemented in [nix](https://github.com/nix-rust/nix). For Windows, I'm helping with the major refactoring going on in [winapi-rs](https://github.com/retep998/winapi-rs) before the big 0.3 release.
You could try ```c = (c as u8 + 1) as char;```
Right, that's cool. Thanks! EDIT: I know I said the previous one was the "accepted answer", but the truth is you want a combination of both answers :P This works with unicode, so a huge plus 😃 *EDIT 2: See what I did there?*
This is the answer. Works flawlessly! Thanks! Though, I must follow up: Is there any "danger" with using `u8`? Will it work with unicode still?
Nope, it will not.
If I want to do a task parallel program, where do I look for?
My theory is that Rust is like adding oxygen on the metal, thus oxidating it, get it?
I'm glad you like it! I wrote it exactly for those cases you mentioned. However if you have plenty of them, maybe that is a code smell? Regarding name, I wanted to write some code using it and didn't want to wait. I named it Option because it is familiar. In Swift the same thing is called implicitly-unwrapped optional. I've even put that in keywords in Cargo.toml to make it easier to find. (It works well, BTW. :)) I felt like ImplicitlyUnwrappedOption would be way too long, especially because it's methods must be called with UFCS. Finally, I don't think Cell would be a good idea because in Rust I'd imply use of UnsafeCell underneath, which isn't true in this case. However, if someone has significantly better idea, I'm open to change it.
Or `NotReallyAnOption` :) Alternatively, you could think of it as a stronger variant of Haskell's `Maybe` (which is almost like Rust's `Option`) and so call it `Likely`.
I'm literally just experimenting, lol! Though, incrementing a character does make sense. For example a Caesar Cipher. Or converting from normal characters to regional indicators... et.c
I think that should work. AFAIK Rust stores single chars as u32
No, those are examples of mapping from one set to another. Incrementing divorced from context is dicey because the set of valid Unicode scalar values is discontinuous; the increment to get to the "next" character isn't consistent. "How do I iterate over all valid Unicode scalar values" is a different question to "how do I add 1 to a character". I bring this up largely because I've seen *way* too many people trying to work with text while suffering from [the XY problem](http://xyproblem.info/).
I didn't say `How do I iterate over all valid Unicode scalar values`... Anyways, thanks for trying to help :D
Btw, this is the typical case that triggers an exponential merge in darcs. When Alice and Bob each keep stating their own order between A and B iteratively, the darcs folks call it a "conflict fight".
I'm using ConEmu. 
Not only can casts fail in Rust they can cause unspecified results that are different every time. Some call this "undefined behaviour" though I don't think they lead to memory issues: https://is.gd/q2HY5Q Try changing the value of "_y" here, try changing the variable name. You will find that the value of x changes in this case in ways that defy reason because LLVM just gives you the last value of a random register.
Interesting, didn't think of that. But can a cast _fail_?
Define "failure"? It can't panic I think and it obviously does not return a Result type. But my problem is if you can cast floats to ints with the result being a bogus value that is different every time. I don't see that being much different than being able to cast to a character that doesn't exist. Not sure what string functions are going to do squeezing that into a UTF-8 representation. Maybe just wrap; in any case wrapping is surely less bogus than "pick the value of a random register and give me its last uninitialized value"
Or `FailureIsNotAnOption`
Cool, I understand linear types now :) I think this is a good argument against adding relevant types. 
Annoyingly partial borrows work when done directly, they just don't work through functions.
&gt; Also, if no one is using the previous crate yet How would we know this? There's already 5 downloads.
I meant other crates.
What about people using it in private? Such thing would break their builds.
Last I checked, you couldn't. The [RFC](https://github.com/rust-lang/rfcs/pull/1940) to allow it is still in the final stages.
The 5 people that probably use it, but most likely just downloaded to try it out, can manage to change the name of the crate ))
I believe you could try to open a repository on the Nest at https://nest.pijul.com, and try the following part of my answer: &gt; At the time of pushing, you decide which patches are ready, and which are not. At any time, you can unrecord a patch if no other patch depends on it, independently from when these patches were introduced. 
I like `Likely`. Does Haskell's Maybe differ in anything else than the name of it and it's variants?
That does seem like a good place to start :) And the shuffling isn't practical enough for me, because I never experience it. Or if I do experience it, I certainly don't notice it. That might be because I don't use git in scenarios where it would happen (I try not to do anything that seems exotic with git; helps keep me out of trouble I think), or I've just internalized the way git works to be how I would expect things to work. It's the same feeling I get with much of the talk about pijul in general, because I think I've either managed to stay out of git's trouble spots so far, or I've just grown a huge blind spot over it.
If you take the featureset of both languages into account, not really. The main difference is that `Maybe` is in instance of various typeclasses in Haskell (`Applicative`, `Monad`, etc.) and reaps all the benefits this entails. On the other hand, `Option` in Rust is mostly just a data type wrapper, without similar ergonomics. (Does `?` even work with `Option`?).
Almost as bad as prescribe vs proscribe.
You should send him a PR -&gt; https://github.com/Gankro/gankro.github.io/blob/master/blah/linear-rust/index.md
Whelp... better merge that RFC so I'm not wrong!
I'd be very interested in playing with this when you're ready to release it. It was on my list of potential next projects.
That makes sense, this is fascinating.
Great! When it's ready I will post it on this sub! 
&gt; But you can split borrows if you structure your structs properly. This is often not practical. You can't foresee all possible partial borrowing of your structs, and even if you could it's not possible to split your struct into sub-structs in a way that allows you to partially borrow all possible subsets of your fields.
how can we contribute to codevr?
"Isn't supported by generics" is probably an easier simplification, in which case all you need to implement is the checker, which is the easy part. The trait can be mostly hidden, and the stdlib doesn't need any work. It would probably be unpleasant to use them without the ability to store them, but I'm not an expert on how people want to use this in production.
To add an alternative to the answers already here specifically for something like the Caesar cypher you mentioned, what about using a Vec to store a rotation of characters and then increment-wrapping a usize index into the Vec? i.e., `let chars = vec!['a', 'b', 'c']; let a_index = 0; let a_encrypted = a_index.wrapping_add(CYPHER_SHIFT) % chars.len();` This way, you have a limited set of characters and avoid the "issue" others have pointed out of incrementing Unicode characters. If you needed a larger size of characters, you could use a `Vec&lt;&amp;str&gt;`. 
This is nifty! I might edit the post to include this hack...
This is awesome. Could I convince you to attack an ESP or STM board next? :D
woooooah well worth the bother of installing on my phone.
Well, sometimes it makes sense. Such as converting `a` to a regional indicator.
Hey there Rust community! Can you review the code of my little [exercise here](https://np.reddit.com/r/dailyprogrammer/comments/69y21t/20170508_challenge_314_easy_concatenated_integers/dhbngq4/)? I'm learning Rust and I decided to do these exercises. Thanks!
rustc?
Yeah `?Foo` vs a Magic `Foo` is basically the same (if/when Swift ever impls move-only types, they will probably just add a MoveOnly trait, instead of `Copy?`). The destructuring idea is a good one. If we block `mem::forget` from taking must-use types (safely), then this would possibly make &amp;uninit interesting.
What threw me off was "this type system defines three operations that a type might support". If a reader, like me, doesn't already know where you're going with this, I think it's a misunderstanding that can easily happen.
`rayon` is aimed at optimizing iterator adapters (i.e stuff like `.map(|x, y| x + y)`) and recursive functions in a parallel way. What I was looking for was threads: which I just ran into here :) http://rustbyexample.com/std_misc/threads.html
*Probably* not. My goal is to show an example of how to create rust bindings to hardware. I don't think that repeating the process for other hardware platforms would help with that, and staying focused on one platform will let me dive into more complex concepts - for example, I want to do a post on using futures.rs as an interface to the DMA engine. If there are particular things you'd like to see in future posts (or changes to past posts!) that would make it easier to apply this to other microcontrollers, please let me know what I can do
In order to write `core.debug`, Rust needs to know the type of `core`. However, `borrow` is ambiguous, so you need to explicitly document the type. This will look something like let core: &amp;Core = core_rc.borrow();
Our main target are real time systems so we require support for priorities and preemption, which RTFM supports, to fulfill deadline requirements. Futures are inherently a form of cooperative scheduling and that makes it hard to make any strong guarantee about timing constraints. That doesn't mean that futures are incompatible with this scheduler. You can run a futures-flavored event loop in the `idle` function and use it for non-critical stuff. In fact, I think that with some tweaking we can make the high level I/O API used in this post, which is totally decoupled from the scheduler and the RTFM framework, compatible with futures. (Something along the lines of `Err::WouldBlock` and `try_nb!`). But I haven't invested much time in that.
Thanks for the comment. &gt; But IMO they should be treated like the output of bindgen for C libraries - &gt; the unsafe building blocks that require a human to analyze the invariants and &gt; create safe, rusty APIs on top. That is already the case. Most of the API generated by svd2rust is `unsafe` unless this information is specified in the SVD file: - &lt;EnumeratedValues&gt; is used to enumerate all the valid bit patterns a bitfield can take, or - &lt;WriteConstraint&gt; indicates that e.g. the whole 255 values can be written to a `u8` bitfield / register. Most SVDs don't contain this information so a person would have to audit the SVD file and add these where memory safety really holds. I have done something like this for the [stm32f30x](https://github.com/japaric/stm32f30x/blob/master/STM32F30x.patch) crate. &gt; A task could easily set registers in a way that is incorrect for the hardware See above. &gt; Two tasks could clobber each other's use of a common hardware resource The svd2rust generated API doesn't do any synchronization on its own. This is the task of the next abstraction layer. &gt; I can write a trivial safe program that will cause a thread to hang using a &gt; "safe" global resource in a mutex Deadlocks are safe in Rust land. If you don't want to deadlock use something better than mutexes and threads :-). &gt; I don't believe that your "disable interrupts" mutex is safe in multi-core &gt; Cortex-M systems Possibly, but this isn't a concern of the svd2rust generated API. The next layer must take care of synchronization to make accessing the registers memory safe / date race free. So you would have to pick a concurrency framework that's suitable for multi-core systems. &gt; Using your "safe" bindings to a DMA unit These are unsafe as per my first comment.
There is no way to escape `$`, unfortunately. You'll need to choose another character. For example, the `quote` crate uses `#`.
I asked Graydon on [Twitter](https://twitter.com/Sunjay03/status/861769228076167169) about this and he said: &gt; Aspirational (be robust like rust fungi; reuse old reliable machinery), short, reasonably googlable.
And this is a bug.
&gt; I do have a few gripes about cfg, the biggest of which is that there’s no way to derive custom configurations ... You can do that in a build script. You just need to print out a message to Cargo to define the `cfg` flag you want, and off you go. For example, here's one I use for conditional compilation: println!("cargo:rustc-cfg=macro_inter_stmt_binding_visibility"); **Edit**: to be clear, this depends on the information you need being passed to the build script in environment variables, but you *should* get the information you're using in this example.
yup! Got that suggested by another person as well. It works wonderfully :D
&gt; I found that very few libraries I investigated were usable in a production quality, multi-platform game. &gt; There are more game engines written in Rust than there are games I think that this is not unexpected, and not specific to Rust. Many libraries are written by students who tell themselves "hey I like video games, let's dig into this". Then they give up when they don't have time anymore. &gt; Compile times with Rust are Not Great. This is easily my single biggest gripe about Rust right now. The build for A Snake’s Tale takes 15+ seconds, which makes iterating rather tedious. &gt; More fine grained control over compiler optimizations would be super helpful. I’d love to be able to have my hottest methods get a bit of optimization even during debug builds. I’d also like to be able to have my dependencies be compiied with optimizations during debug builds of the application. My prototype actually takes around 300 seconds (5 minutes) to build on a good machine (i7 Kaby Lake, 12 GB RAM, SSD). The reason is that I need to compile with optimizations on, otherwise runtime performance is so poor that the loading screen is much longer than the compilation time. Related issue: https://github.com/rust-lang/cargo/issues/1359 
The [`Serialize`](https://docs.serde.rs/serde/ser/trait.Serialize.html) trait in Serde is defined in a very similar way. It enforces use-exactly-once on the input serializer through a combination of ownership and the `S::Ok` associated type (which turns out to be useful for many other reasons too).
What are your thoughts on piston?
I'm not the author of this, but I thought it was a very clear overview of rust's memory management.
Oh my gosh thank you!
I used 31X7RS7YMDY665J77W2ZNHU. Thanks!
&gt; Plenty of libraries and compiler features require nightly, and I had to pass some of these up lest I get stuck on nightly Could you list these? It's worth knowing what libraries/features you needed. (and if possible I should try and fix up libraries that are not on stable) In general I've found it's not that hard to stay on stable, but sometimes takes some effort. However, this may not apply to your application. &gt; I’d love to be able to have my hottest methods get a bit of optimization even during debug builds. I believe you can mark functions as `#[cold]` and `#[hot]`
&gt;&gt; I found that very few libraries I investigated were usable in a production quality, multi-platform game. There are more game engines written in Rust than there are games &gt; I think that this is not unexpected, and not specific to Rust. Many libraries are written by students who tell themselves "hey I like video games, let's dig into this". Then they give up when they don't have time anymore. I see both claims to be plainly wrong. The reason you don't see as many games is because people keep them locally, don't publish them on `crates.io` or add to awesome rust. Libraries (that are often by-products of games) are simply more visible.
Snagged NB3D?B8D71G6Q?7?EPXCRR4, thank you!
Used A9WMKENRLX??. Thanks!
CMU has a class on Substructural Logics https://www.cs.cmu.edu/~fp/courses/15816-f16/ Up until 2012 it was just about Linear Logic IIRC.
Well; don't you think that listing Clone in the part of "Can be used any number of times" in one breath with Copy which is special arouses that? Even so, I disagree with the analysis even if we are agnostic about special-ness because it can't be used "any number of times". It can be used once. The return value of Clone is a different object of the same type. On the type level `String::to_uppercase` is the same as `String::clone` Copy may say nothing about `PartialEq` but it says a lot about equality. It guarantees that the bits that make up the sizeof are identical.
Just purchased on iOS and upvoted on Greenlight. Congrats! Look forward to playing. I love snakes :)
We're in the same boat. Looks like I'll need to be getting some money in my iTunes account so I can buy it :)
All the game-specific code was written in Rust, at least. So where do you draw the line? Can nobody say "entirely done in Rust" without 100% Rust libraries compiled by a 100% Rust compiler running on a 100% Rust OS and hardware designed by 100% Rust tools?
Fine tuning cache performance sure sounds like an optimization to me
Ah I see. In that case sounds like I need non-borrowing lifetimes too!
I think they meant code transformations like you get when you crank up the compiler's optimization levels.
Someone did not comment but used the key 3MHEHMJ3NRKA.
Hi Monacosa (and others), on the AVR (at least as I recall) the interrupt enable registers are distributed to the peripherals, meaning that we would need to poke each of these hence the order O(N) Japaric mentioned. On the Cortex M0 masks are centralised. In the original C implementation of the RTFM scheduler, we investigated that option. Notice, in order to uphold the Stack Resource Based scheduling policy (which gives bound priority inversion), we need emulate the "system ceiling", and not just preventing sources potentially conflicting w.r.t. race-conditions. On Cortex-m3 and above, we use the BASEPRI-Register in the ARM-core to accomplish this with a single write. 
Just picked it up off the Play Store to give it a try. I like the concept! The art style is simple yet consistent and the mechanics are instantly intuitive. Good thinking with flashing the Undo button if the user can't make any more moves. Maybe you can come up with a way to reward the user for completing a level without using any Undos, or with a minimum number of moves? Some games reward tokens that unlock bonus levels or things of that nature. It's all right if you want to keep things simple, of course. It runs all right up front on my Galaxy S7 but the performance seems to degrade a little bit after playing a couple levels. Killing the app and reopening it seems to help but it begins to degrade again almost immediately. I'm primarily using the game in portrait mode, on mostly full battery, and I did try killing all other running apps. On that note, a rotation lock toggle in the options wouldn't be a bad idea. The level select screen is intuitive to navigate but I may have found a bug/missing edge case in your touch handling. If I pinch-zoom the map and then leave one finger on the screen to drag it, it doesn't respond to the drag gesture. There's also a little bit of input lag, it's not a dealbreaker but maybe something to work on. The animation of the growing/shrinking circle transition is a little choppy but that might be the performance thing. Additionally, I like that the hardware Back button will exit a puzzle and return to the level select screen, but on that screen it does nothing when it should exit the app. The animation of the new circles appearing upon completing a level could be sped up a good bit. It makes sense to draw the user's attention to them for the first level they complete but after that it feels a bit gratuitous. Finally, when the snake is really long, like on the Ouroboros level, the animation of it going down the hole can take quite a while. Maybe speed that up when the snake is past a certain number of segments in length. And when the snake goes down the hole, sometimes its vertices get a little wonky (weird stretching, holes appearing in the snake, etc); I wouldn't worry about this too much, I know it can be hard to reproduce. I notice it the most when entering the hole from the left or from the top.
Can you say that anything is truly written I'm any language when there is always something one level under it? 
Congratulations on your game, this seems like a really cool project! You don't often see games that are 4,5MB in size these days. Unfortunately I'm broke at the moment ;)
That's a good question! I don't know the answer, but hopefully I will after writing the third post in this series. I suspect, though, that retrofitting that sort of thing would be harder than building it from scratch.
I am getting more and more worried that unless we somehow collectively as a community figure out how to change the language to not require huge crates as compile targets Rust will never solve this. It's impossible for Rust to ever become fast with this compilation model so we need to figure out how to not depend on it.
Can you give some examples where you'd use this concept? E.g. would you use it for parallelizing genetic algorithms? Is the main advantage that it abstracts away from a CPU like futures abstract away from threads? So you can easily parallelize across multiple computers like rayon on a cluster level?
Thanks for the notes, they are enlightening. So there isn't any way to have a function signature that gets a deep copy? If you wanted a deep copy you would have to do it within the function body (and require "Clone" as a trait of the parameter), essentially call `v1.clone()`? That seems... weird. The more expensive operation (clone) has been removed from the function signature now. Or am I misunderstanding something?
Only for English :) And that's what Rust is telling you.
&gt; meaning that we would need to poke each of these hence the order O(N) Japaric mentioned Huh, how about that. That being said, it's still a fixed number of bits you need to twiddle for a given chip (or config if you're getting fancy), so it's still O(1) (it's just more work than a simple single register write). And I guess I must be missing something. I don't see how my scheme doesn't allow for "system ceiling" of the type that could be emulated via BASEPRI.
If you only ever plan to support ascii, I suggest using `u8` instead of `char`. It's a numeric type, so you can use standard numeric operators. There's a special byte literal you can use to get u8 and arrays of u8. `b'x'` is the u8 value of "x". `b"abc"` is a slice of u8 values for each character. You can really use `c as char` to convert them back when you're printing the result. You can use the appropriate str::from_utf8 method to convert a slice of u8 back to a string. This is all really useful when you're only going to ever want to work with a certain character range. 
The sorts of things I used the makefile for were mostly packaging/release related tasks like "Take my 1024x1024 icon.png and resize it to the 20 different sizes I need for the various platforms", or "Call cargo 4 times to build each of the android targets, copy the resulting binaries into the android ant project directory, and then run `and` to build the APK". SDL2 is rather painful to build and has plenty of quirks, but it's incredibly robust and has been battle tested on probably 10s or 100s of millions of devices (SDL2 is used by the Steam client, popular indie games like FEZ, Bastion, and FTL, all Source engine games (e.g. DOTA2, CS:GO, and Portal) on Mac and Linux, and as of a few months ago, Unity replaced their own Linux platform layer with SDL2). Glutin OTOH takes almost no effort to get up and running, but I'm much less confident in its ability to Just Work everywhere. Glutin's also missing a few minor features I want, namely emscripten support and gamepad support. I think Glutin is excellent for jam games and small experiments, but I'll be sticking with SDL2 for my larger projects for the time being. I did not attempt to get A Snake's Tale running on emscripten, but I do have some smaller Rust+SDL2 prototypes running happily in the browser, and it's definitely a potential target for some of my future games.
Is the only place to get the RTFM source via pulling down the Crate? Is there a repo?
Enjoying the game, congrats on the release :)
neither of the (at least semi-functioning) games I've implemented are on crates.io, so this is at least true for me :)
&gt; Compile times with Rust are Not Great. This is easily my single biggest gripe about Rust right now. The build for A Snake’s Tale takes 15+ seconds, which makes iterating rather tedious. The current incremental compiler work also doesn’t seem to make the build for A Snake’s Tale’s codebase any faster. I'm curious about your workflow. Is this edit-build. edit-build-test, or edit-build-test-deploy? For edit-build, how well is `make check` working out for you?
How it looks like: [Imgur](http://i.imgur.com/pNP43NU.png)
O(N) in number of N or interrupt sources. For sure its doable, looking at the source code you will find that the interrupt management is done only at a few well isolated places. We choose to implement it first for the cortex-m, as the architecture is perfectly suited to this purpose (likely they designed it for easy implementation of priority ceiling protocols, like SRP that we use here). Another reason is that the cortex architecture has a substantial market share, and is a modern architecture in comparison to (e.g.,) the AVR with already good LLVM/Rust support. 
It's totally possible to make from-scratch builds fast, especially in debug mode. See D, Jai, etc. In fact, I prefer that approach in the long run as it's beneficial to more use cases, far more straightforward, and eliminates the potential to get the build system into a weird state.
Could you do something like routing every interrupt to the same handler, and then doing the job of NVIC in software? So, either preempting immediately if the priority is right, or deferring the new handler until the exit from the current ISR. That's definitely some overhead (and on chips with fmax=20MHz I can see how that would make the latency too high) but at least it would be constant.
I get an error on startup: "Error creating process: 80070032" I use following launch config, based on yours: https://gist.github.com/MSleepyPanda/74579fc1e18f7f6a76d2c5833d2dab24 Toolchain: nightly-x86_64-pc-windows-msvc (default) rustc 1.19.0-nightly (f1140a331 2017-05-08)
Does it generate an async server that uses futures? Or does it spawn a new thread for every client or for every rpc call? I kinda have to decide if we're gonna use this or grpc-rust for serving (potentially) thousands of clients.
I must admit that I don't follow the part here about the empty intersection. My problem here is exactly that. Right now: impl&lt;T, RHS : AsRef&lt;str&gt; + IntoIterator&lt;Item=T&gt;&gt; Concat&lt;RHS&gt; for String where String : Extend&lt;T&gt; Is empty. There is as far as I know no type `RHS : AsRef&lt;str&gt; + IntoIterator&lt;Item=T&gt; where String : Extend&lt;T&gt;`, but that doesn't stop me from writing the implementation already for when the type in the future _could_ occur. In fact right now the implementation just uses `AsRef&lt;str&gt;` and ignores the `IntoIterator` part and is the same as the `AsRef&lt;str&gt;` implementation. The other part of the trait constraint exists purely to communicate "If it implements both traits, go for the `AsRef&lt;str&gt;` implementation" In particular the blog says: &gt; however, specialization does not consider impl B to be a specialization of impl A, because, at the moment, there is no subset relationship between them. This seems to be false: https://is.gd/m8FaE1 It seems to consider it a specialization just fine even though the second one is empty. 
Still working on my password manager, Fortress (https://github.com/fpgaminer/fortress). Since last week I added some unit tests, improved the UI, added password generation, and did some code cleanup. It's somewhat usable now and the unit tests give me confidence that it's working as intended. I wrote a script to convert a KeePass database over to a Fortress database, so I'll be able to transition over easily from my current password manager. I'm planning out the sync backend now, so my passwords will all be backed up to a server and sync'd between computers. I think once the sync backend is in I'll package it up into a deb so I can install and start using it as my daily driver.
Maybe a library for build scripts would be in order, possibly even shipped with cargo itself. These kinds of things are trivial with cabal, but OTOH it did start out as a build script library, not command line tool... support for packages without `Setup.hs` came quite late, even if all it usually said was `import Distribution.Cabal; main = defaultMain`
I'm guessing that performance could be improved when building a Production Grade version, possibly by optimizing it for the common cases encountered in real code (rather than general logic), but I don't knew enough about the details to say for sure.
15s is the time for a `cargo build` after a trivial change. `cargo check` runs in 3 seconds, which is a lot less to complain about, but isn't particularly helpful when I'm iterating on something where I need to see the changes running in the game.
Nothing published right now. I'd love to find the time to make a small, open source game where I could include all of my packing stuff.
This was just reported as a [compiler bug](https://github.com/rust-lang/rust/issues/41865) due to the unhelpful message. Apparently the fix is to remove `use std::borrow::Borrow;` as the `borrow` method you want is on `RefCell`, not the `Borrow` trait.
Can't Spell Trust Without Rust
I am trying to wrap a cursor so I don't have to manage the position myself. struct Block&lt;'a&gt; { buffer: [u8; BLOCK_SIZE], cursor: Cursor&lt;&amp;'a mut [u8]&gt;, } impl&lt;'a&gt; Block&lt;'a&gt; { fn new() -&gt; Block&lt;'a&gt; { let buf = [0u8; BLOCK_SIZE]; Block { cursor: Cursor::new(&amp; mut buf[..]), buffer: buf, } } } But I get a lifetime error: error: Could not compile `signaldb`. Build failed, waiting for other jobs to finish... error: `buf` does not live long enough --&gt; src\lib.rs:16:39 | 16 | cursor: Cursor::new(&amp; mut buf[..]), | ^^^ does not live long enough ... 19 | } | - borrowed value only lives until here
Eat function is modifying self thus you should have ``` fn eat(&amp;mut self) { ... } ``` 
Adding `mut` to the function definition doesn't seem to change anything ... error message is exactly the same
Yep, I'm following edits, thanks. I don't want to use unsafe. Is there a way to give the struct ownership of the vector itself and also a slice of the same vector? That way, in my head, the lifetime is guaranteed to be the same? Regarding iterators: I think I tried this a while ago, and the issue I hit was that I would also like a peek() method which will tell me the next thing without advancing. Actually I've just been testing as I've been typing, and ~~you can clone() an iterator, so maybe this is what I need after all ...~~
If you want to use your original slicing method, [use an index.](https://is.gd/p7ZzLt) Keeping a self-reference in a struct is called [a rental.](https://crates.io/crates/rental/0.4.9) I don't recommend it here... but maybe possible. also, as far as the efficiency is concerned, removing from the very front or very back of a VecDeque is an [O\(1\) operation.](https://doc.rust-lang.org/std/collections/index.html#sequences) It should be about as efficient as re-slicing, as long as you're not planning to use that data again.
It depends on the ownership semantics you desire. If the `Eater` owns the list, then something that owns the values (such as a `Vec`) is what you want. If you can’t easily change the order around and only consume the items in this way, then you could work with an iterator instead too: store `items: std::vec::IntoIter&lt;T&gt;`, initialised with `items: vec.into_iter()`.
Does this overlap with the existing https://github.com/rust-unofficial/patterns repo?
It might a little bit. I'm not sure if the author of the repo knew it existed.
I write in typescript if I have to touch js. It has a solid typesystem and has things I wish rust had...
I tried iterators, and it turned into its own unpleasant little rabbit hole. Too tired to fight against it now. Rust has beaten me. Anyway your slice/index solution looks like the simplest possible solution. Thanks for the help, much appreciated.
For me, long build times such as these are about 50% of what keeps me away from Rust. The other 50% is a combination of factors - I know any IDE wont be as good as it is for other languages, libraries for game dev are not really in place and I don't want to implement them, etc. 
I was gonna say I really liked the write up style. It reminds me of an old tyme newspaper or something
should this be posted to https://users.rust-lang.org/ or https://internals.rust-lang.org/ to get more exposure ?
Keem meant to post this on /r/playrust I believe 
So? Still not relevant to the game. 
Last time I checked most people in the Rust community hate Rhino and hes barely relevant anymore. 
Ad hoc union types. Structural types. I know some of these probably can't work in rust. But really nice to use especially where JavaScript typing is a complete wreck.
nice that you mention F32 ord/partialord issues. I remember this when I tried Rust aswell; This is the problem: to prove safety at compile time, rust has to over-estimate . Of course that is the correct choice for it's mission statement .. but there are situations where code can be safe, but not provably safe on a line by line basis. Values can be guaranteed to be in safe ranges by virtue of how they were produced. The important examples in gamedev (used all over the place) are **non-NaN floats**, **non-zero floats** (pre-division), and **index data for vertex arrays**. I greatly enjoyed various rust features (nice lambdas, match etc).. it's very close to what I want, but ultimately went back to C++. I still watch whats going on here with great interest (i should try the language again). (EDIT: I think there were some suggestions r.e. vertices, for example an index buffer type that maintains the range of values held, such that they could be verified when modified (rare) and when paired with a specific vertex buffer (compare once)- this would still do some runtime checks that aren't strictly needed, but only per-object, not per -vertex.)
"The tool was created in order to enact censorship", gotcha. Review? I'd rather be sure nothing like that gets implemented again.
You can definitely make your version work! (u/coder543, no need for unsafe!). Basically, temporarily replace `self.list` with empty one to avoid moving* issues: fn eat(&amp;mut self) -&gt; Thing { let result = self.list[0].clone(); let list = std::mem::replace(&amp;mut self.list, &amp;mut []); self.list = &amp;mut list[1 ..]; result } full code: https://is.gd/DE8kai \*) I'm saying *moving* issues, not *borrowing* issues, because usually if you see a "does not live long enough error" involving `&amp;mut`, but you feel that you shouldn't ("I'm just making `self.list` point to shorter subsequence, I'm not borrowing from a temporary!"), you can try to "force a move instead of reborrow" by using `{}`: self.list = &amp;mut {self.list}[1 ..]; Now, that leads to an error "cannot move out from borrowed context". And usual solution for this error is either `std::mem::replace` or change the field type to `Option&lt;X&gt;` and use `.take()`. In the case of slice, you can use `&amp;mut []` (empty slice fits every lifetime) as a dummy value, so not need for `Option`. That leads to solution above.
None of these look very stable. When will there be a rust equivalent of WX?
Oh yeah, I always forget users.rlo exists!
What if someone made a Rust clone in Rust... which sub would it be appropriate to post it in?
Just wanted to say your game was pretty fun! https://imgur.com/Dzuon1Y I still have one more puzzle to do though. 
Thanks for the feedback. My intention is to provide a "quick start" to help people through the learning curve by providing pragmatic examples of how to get things done without being an expert on every aspect of the language from day one.
I'm not really sure, but probably within the next few years? I feel like the answer to "when" is really 1-2 years after someone starts on such a project, and works with it and the community. Right now the Rust team is still very much focusing on the language itself, and now this year core libraries - so any innovation in UI in rust is going to come from the community. A wrapper around WX itself isn't unreasonable, rust can be nice for FFI with C (c++ not so much, but wxc exists). No need to rewrite what already works, when we can instead provide a safe interface around it. I know this isn't equivalent of WX as it's not a native UI, but `conrod` is on the path to becoming a mature UI library in pure Rust - and it's relatively usable today, even if unstable.
Yeah this just goes to show how smart Keem is. Like doesn't even know the subreddit of the game he speaks so highly of and just posts this video here without even checking. What a great detective I'm sure everything in the video was thoroughly investigated!
This looks very cool. I've just started learning Rust, and the only ARM dev boards I have are [Feather M0s](https://learn.adafruit.com/adafruit-feather-m0-basic-proto/), but I'm sure this will come in handy.
Patience diff is a newer diff algorithm. Instead of void func1() { x += 1 +} + +void functhreehalves() { + x += 1.5 } void func2() { x += 2 } it produces diffs like this: void func1() { x += 1 } +void functhreehalves() { + x += 1.5 +} + void func2() { x += 2 }
I tried first with the version on Chocolatey (10.0.10586.15); afterwards I uninstalled that and tried the version that comes with the current WinSDK (10.0.15063.137). The outcome was the same for both. I also tried running VSCode as admin &amp;ndash; no effect.
Thanks for the feedback! I've submitted an [issue](https://github.com/reedz/windbg-debug/issues/1) - hopefully it's something simple that'll be resolved soon.
This collects links to articles about patterns, not patterns. The repo you mentioned is one of those links.
Yep, that's true. But I don't really wanna bother with other charsets either way :P
when you do this and turn optimizations on, do your libs get inlined and stripped of excess methods? Rather is link time optimizations run?
Thanks. Looks like [Frank McSherry](https://github.com/frankmcsherry) [beat me to it](https://github.com/Gankro/gankro.github.io/commit/e5d6fc275931b7e39eb8e97f84755d7ca1f96235). I'm surprised I missed that this is hosted on GitHub!
&gt; I can't speak to how GTK appearance is on Mac or Windows though. Bad. No one who cares about user experience would even remotely consider gtk. &gt;[`imgui-rs`] wraps [`imgui`]. I believe it's a complete wrapper, and very usable, but I haven't used it yet. This is for games or something. &gt;[`conrod`] is the pure-Rust UI library I'm most familiar with. It is an immediate-mode API similar to imgui, but with Same as above just way less mature. There is no usable cross platform rust gui framework. Nothing usable has even been started. 
Can you give some examples of good GUI toolkits for C? If there's any good ones I'd be surprised if they haven't got Rust bindings.
That's not what he means. Another crate could depend on you (or even not on you) and add a type that implements both of those traits. However without modifying the crate that defines `Widget`, no type could possibly be in the intersection from his blog post. However that point is sort of moot. We're going to add this feature someday, but only after we refactor the trait system to be more theoretically sound. Aaron starts to get into this (and the sort of open/closed issues Niko touched on in that post) in this blog post: https://aturon.github.io/blog/2017/04/24/negative-chalk/ He hasn't written a blog post about how specialization will some day work because we're still trying to solve an unsoundness issue in specialization.
[removed]
Officially it's only accessible to ISPs, but rublacklist makes it available on their site https://reestr.rublacklist.net and here's a dump on github https://github.com/Pontorez/z-i
Like /u/Quxxy said, this can't be done in regular macros. The alternative that is often good enough is to receive all your identifiers as macro arguments. Even if it makes the invocations a little repetitive, the macro itself shall save enough of the boilerplate to make the tradeoff worthwhile. Here's an example: https://github.com/Xion/rush/blob/e306f8b8235cb53a2455380452b64eaf857a8fde/crates/librush/src/eval/model/value/types.rs#L74 (macro definition just above it)
&gt; Disabling lto Isn't it disabled by default?
Is there a way to try it out without giving Google my credit card info? Maybe if I pay you directly with Bitcoin?
I think you're actually right and i just enabled and forgot it ...
Is there a question in there? :p The compiler is correct. You cannot store a borrow of something you also own.
it's awesome
What you want cannot be done. I could create a `Block&lt;'static&gt;`, get out `block.cursor`, and let `block` go out of scope (all perfectly legal). Then I would have a `Cursor&lt;&amp;'static mut [u8; BLOCK_SIZE]&gt;` that points to freed memory.
So, what's happening with [RFC 1859: extend `?` to operate over other types](https://github.com/rust-lang/rfcs/pull/1859)? I'm asking out of curiosity of the Final Comment Period process [1]. It has been in FCP since February 16, and on February 26 rfcbot declared "The final comment period is now complete." Nevertheless it has been listed as FCP in This Week in Rust, as far as I can be bothered to check, for the whole period. I see that a new FCP has [recently been initiated](https://github.com/rust-lang/rfcs/pull/1859#issuecomment-299040055). This seems atypical, usually a resolution seems to come about pretty quickly for RFCs in FCP. What's different here? :) [1]: Also, I'm looking forward to this feature. But the question is about the FCP process, I don't mean to nag about "Why can't we do this thing already dammit!?!"
I doubt we have the same definition of "looks native". Last I checked, the closest maintained option for making a Ttk app fit in on a Linux desktop was to borrow the `clearlooks` Ttk theme from [PySolFC](http://pysolfc.sourceforge.net/) (Which is what I did so my `git gui` and `gitk` don't look like they just stepped in from a mid-90s GTK+ 1.x desktop.) and I don't see any mention in the Tk 8.6 release notes that things have changed. That said, if you're going to write your UI layer in a dynamic language anyway, you might as well do as I do and use [rust-cpython](https://github.com/dgrunwald/rust-cpython) to get access to Python's much broader selection of GUI bindings. (I prefer PyQt5 because Qt's core widgets are the most "batteries included" and best documented of all of the options I've tried over the last couple of decades, so I spend less time reinventing wheels.) ...or you could use [qmlrs](https://github.com/cyndis/qmlrs).
Yup! That's what I ended up doing ;)
Hmmmm, that's a shame. I think it's just easier that I use `Cursor&lt;Vec&lt;u8&gt;&gt;` as it makes the code cleaner. But thanks for your help &lt;3!
There is barely a concept of native on linux. Either way it's by far the least important platform for gui apps.
You're talking to someone who has used Linux exclusively (aside from BSDs for running routers and the rare occasions when I boot up my Windows 3.11/98/XP retro-gaming PCs) since 2004. I think we have different priorities.
&gt; (also adds "stealing" as a **move** violent form of borrowing) I think there's a typo here.
This looks like a pretty elegant solution, I like it. I am still a little confused about what `mut` means in the context of my original declaration of `list`. Let me try to say it how I see it, tell me if any of this is wrong. `mut` makes the slice into a mutable slice with would in theory give me the ability to change the contents of an individual `Thing`. Which wasn't what I meant to do at all, I was trying to say that the member `list` can be reassigned to contain a different slice. But you did that anyway, so huh ... Empty slices, that's fine, I would have done basically what you did. Thanks.
One thing that I think Rust would greatly benefit from is relying less on llvm to output optimized code (e.g. have the frontend hand something to llvm that is already reasonable). Closing the performance difference between debug and release builds a little could help a lot of use-cases
Maybe implement a system in Rust that detects batch lookups like this and returns spoofed IP's? But anyway, I think this tool can be used for other purposes as well such as malware analysis (resolving large amounts of domains from a C&amp;C domain generating algorithm). 
Probably, my thought are "When things are rust, they are as good as new."
Everything you listed has already been discussed and isn't present either because it's not as simple as it sounds or because it takes time and effort and there are only so many experts available at any given time. For example: 1. Fencing/disallowing panics gives you a surprisingly awkward and unhelpful language, because of all the places they're used to represent OS errors you can't meaningfully handle. (How would you recover from errors in the vein of "Memory parity error detected. No ECC." with more granularity than killing and restarting the thread?) A much more reasonable solution is a lint which warns of panics outside a set of places you whitelist (typically, bits of the standard library). 2. Adding range types (the term for constraining the values a numeric type can take) ~~is non-trivial~~ does take a non-zero amount of time and people have had more pressing concerns. That's why it hasn't been done yet. As for checked math in a more generic sense, see the `checked_*`, `wrapping_*`, and `saturating_*` methods on the integer types. 3. I don't want to rehash the discussions, but this was already considered. 4. Easier said than done. That's why it hasn't been done yet. 5. Procedural macros are in development. While I agree that the documentation on the current declarative macros is terrible, they're complicated because compile-time-safe declarative metaprogramming is complicated. Your proposal is a regression in safety and expressiveness. 6. I'm honestly not sure why you're mentioning 6a, 6b, 6d, 6f, and 6g, given that they're being discussed/developed and "more time" is an unavoidable ingredient to getting them fixed. As for the others: 6c. What about them? 6e. As it was explained to someone else in my presence, even Android is "Tier 1.5" because the Rust devs don't have a Continuous Integration provider that lets them run the builds and testing on ARM hardware. Embedded, by definition, is unlikely to ever be Tier 1 for the same reason that you can't run your embedded IDE **on** the bare metal ARM/AVR/PIC/etc. chip you're coding for. 7. As with the points under 6, discussion and 3rd-party experiments are ongoing. The current approach is "Panics are thread-scoped. Detect dying threads and recover."
Lack of support for binary crates, reuse of already compiled crates between projects and incremental compilation, currently make my Rust builds way slower than the VC++ 2017 ones. Which can benefit from incremental compilation and linking, experimental C++ modules and direct use of binary libraries.
Thanks for writing this! It's great to get detailed feedback from early in the adoption phase.
The tool was created to save time in the first place. We are not Avengers here to avoid federal laws, dude. 
The theory behind Pijul could potentially be extended to syntactic patches, i.e. operating on ASTs instead of just text. That said, the most widely-used tool today (Git) is far from being based on any solid principle whatsoever, and is even not too safe to use in a security context. Pijul is a modest achievement alright, but compared to the current state of the art, the difference is not that small.
I want to serialize/deserialize a YAML file using serde. This file has a section like this: toplevel: midlevel1: .... midlevel10: Inside a section, there are 10 possible subsections, typically 2 or 3 would be there in a given file. To work with this, I have a struct with a lot of: #[serde(skip_serializing_if="Option::is_none")] pub midlevelN: Option&lt;Vec&lt;String&gt;&gt;, It works perfectly when deserializing. But serializing I am forced to do: TopLevelStruct { mid_level_1: None, mid_level_2: None, mid_level_3: Some(...), mid_level_4: None, Which is extremely verbose. Is there a better way of solving this?
Thank you for all your advice!
Self-referential structs: use Rental https://github.com/jpernst/rental jpernst has done a really good job with this. 
&gt; This seems atypical, usually a resolution seems to come about pretty quickly for RFCs in FCP. What's different here? The Final Comment Period generally arises when it seems like discussion has settled down and it's clear that the proposal has been reasonably well discussed. The idea is to give a heads up that the team will probably try to make a decision soon, whether it be to close, postpone, or merge the RFC, in case anyone had some thoughts on it that they hadn't yet contributed to the discussion. In this case, there were some comments in the first final comment period that actually did substantially change the discussion. In fact, the RFC now adopts an alternate design, and lists its original design among the "alternatives". So, based on the original FCP discussion, the RFC has been substantially rewritten; which means that now that discussion seems to have died down after the redesign, it's time for another final comment period. I think the main thing that's not clear from the formal process is when the final comment period expires (according the rfcbot), whether it's still essentially in "final comment period" and the team just hasn't made a decision on it yet, or if it's "back to the drawing board." Since that's not clear, I think that TWiR just continues to include issues in which the official FCP has expired since there is still time to make comments on them. It might be good to have a more explicit marking of "decision pending, still in FCP" or "no longer in FCP, discussion and/or design to continue."
I don't think you even need to impl for `&amp;Instant`. `in_window` already takes a `&amp;self`, so your first implementation will serve for `&amp;Instant`. And Rust will borrow `Instant` immutably automatically if you call `in_window` on it. https://is.gd/S8DJB4
(I know desiringmachines gave you a better solution so this is just in response to your question about reassigning the slice to a new one) The ability to reassign a field of a struct is only possible when the _struct_ is mutable. So in your `eat()` method, you would have had to take `self` by mutable reference, like this: fn eat(&amp;mut self) -&gt; Thing This signals that the receiver is mutable through that reference, which means that self.list = ... // new slice is now possible. `list` does _not_ have to be a mutable value to make this possible, as like you said, making `list` mutable means you can change the contents of the list.
Check out purescripts structural types, and row polymorphism is really cool too. For example, if I have a type Thing = { a :: Number, b :: Number } anything that matches that structure will be a Thing, similar to TypeScript. type Foo = { a :: Number, b :: Number } foo :: Foo -&gt; Number foo thing = thing.a and now, for the interesting one: testPoly :: forall a. { first :: String | a } -&gt; String testPoly t = t.first 
&gt; The only thing is, I've read your post like 5 times now, and I understand almost nothing you said. Don't worry. I've probably tried to fit too many information into not enough words. And it was late at night :) First of all, check out the u/desiringmachines' solution! It's probably what you need! Basically, all the complication in my solution vs theirs begins from that I didn't want to change your struct definition . You wrote: struct Eater&lt;'a&gt; { list: &amp;'a mut [ Thing ] } That `mut` means that you want a mutable access to the list's *elements*! But you probably don't want a mutable access to them. You just want to change where `list` points to. So you'd like to mutate the reference itself, not the *elements*. For that, you just need: struct Eater&lt;'a&gt; { list: &amp;'a [ Thing ] } fn eat(&amp;mut self) -&gt; Thing { ... } In Rust mutability of variables is transitive, so marking `self` as `mut` is enough to allow you to modify the `list`. Only if you want to change the `list[x]`, you should go with `&amp;'a mut [Thing]`. If you just change those `mut`s, [your original code will compile](https://is.gd/U6e0t1). (Note that u/desiringmachines' solution is more elegant, I just wanted to show you the "minimal diff" here) So basically all the things I talked about the previous post stem from the fact, that I wanted to show how to make this work if you reall want `list: &amp;'a mut[Thing]`. Why is `&amp;mut` harder than `&amp;`, you may ask? Well, you probably know about the move vs copy semantics. The thing is, `&amp;` (shared\* references) are `Copy`. So in this snippet: self.list = &amp;self.list[1 ..]; ^^^^^^^^^ The `self.list` is copied before slicing, so this field is never left empty. Also, this temporary copy has the same lifetime parameter (it points to the same slice) as `self.list`. So the `&amp;self.list[1 ..]` has a type of `&amp;'a [Thing]` and you can safely assign it to the `self.list` field. (This paragraph may be overcomplicated. You can ignore it :)). So the shared references have copy semantics. What about `&amp;mut` references? Well, they're not `Copy`, so they should have move semantics. But that's not exactly the case. Consider this snippet: impl Foo { fn bar(&amp;mut self) {} fn baz(&amp;mut self) { self.bar(); self.bar(); } } Remember that `self` has a type `&amp;mut Foo` here. Let's desugar `baz` a little: fn baz(&amp;mut self) { Foo::bar(self); Foo::bar(self); } Now, if the `&amp;mut` reference would be always moved, it would get moved in the first `Foo::bar(self)` and in the second one, you'd get "cannot use moved value `self`"!. So there's actually something more subtle going on here. By default, `&amp;mut` references are *reborrowed*. So for each call to `bar`, a new temporary `&amp;mut` reference is created (with a shorter lifetime) and that temporary reference is used. So you can call `bar` twice! Perfect! So back to your original code: self.list = &amp;mut self.list[1 ..]; Before slicing `self.list` is *reborrowed*. And because of that, the result of slicing uses some temporary lifetime (its type is something like `&amp;'temp mut[Thing]`). Because of that, you get the error you get – "...so that reference does not outlive borrowed content". The "content" is borrowed only temporarily. But you don't want a temporary borrow! You want to slice from `&amp;'a mut[Thing]` to another `&amp;'a mut[Thing]`, with the exact same lifetime! That's why you want to *force a move* (instead of reborrow). One trick to force a move is to use `{}` syntax, but a nicer way to do it is to [use the identity function as described in this blog post](https://bluss.github.io/rust/fun/2015/10/11/stuff-the-identity-function-does/). Let's try (the `{x}` is just a regular block returning `x`, which forces a move, thanks u/tomwhoiscontrary): self.list = &amp;mut {self.list}[1 ..]; No more *reborrow*! The `{self.list}` is just moved `self.list`, so it has the same lifetime (`&amp;'a mut [Thing]`). That way, Rust doesn't complain if you want to slice it and save it back as `self.list` (I mean, the "does not live enough" error is gone). Now Rust performs another check, if all `&amp;mut X` always point to valid value. And you get an error. While slicing is being done, the `self.list` contains no value! It has been moved! So `self`, which is `&amp;mut Foo` is in invalid state! That's against Rust's rules! Let's fix this. Everytime we have to move someting out a `&amp;mut` variable (in this case `&amp;mut self.list`, which has type `&amp;mut &amp;mut [Thing]`), we have to substitute something valid back. You've asked: &gt; I don't understand the relevance of Option or how that turned up. Check out the last playground from u/desiringmachines. It shows how to use the `Option`. The option has a really nice method `.take()`, that allows you to *move* a value from option and leave `None` behind. From Rust's perspective, `None` is perfectly valid value for option, so the option itself isn't moved, so the "cannot move out" error is gone. But making the field an `Option&lt;X&gt;` just to avoid the error may be a little bit annoying, so it's better to substitute a valid dummy value of type `X`. For example, you can use `Vec::new()`, `String::new()` or in general, `Default::default()`. The default dummy value for a slice is empty slice. You make it like `&amp;[]` or `&amp;mut []`. This slice doesn't point to any memory, so you never get a lifetime error if you try to use it – that's what I've meant by "fits every lifetime". But how to substitute that dummy value? That's where you use `std::mem::replace`. I consider this a really important function, and every Rustacean should know when and how to use it. Let's analyse how it's used: fn eat(&amp;mut self) -&gt; Thing { let result = self.list[0].clone(); let list = std::mem::replace(&amp;mut self.list, &amp;mut []); // here `self.list` is valid (`&amp;mut []`). self.list = &amp;mut list[1 ..]; result } `replace` takes two arguments: `&amp;mut X` and `X`. In our case, `X` is `&amp;mut [Thing]` so `&amp;mut X = &amp;mut &amp;mut[Thing]` – it's a mutable reference to the pointer to slice. The first argument is a "slot" to take a value from and substitute it with new one. That's why `slot: &amp;mut X`. `replace` is awesome function, because **the `self.list` always contains a valid value**! First it's the old value of `list`, then it's replaced by our dummy value, (and then it's replaced by a new value). All the replaces are performed "atomically" (remember, it's a single thread scenario. that's why sharing `&amp;mut` is not allowed between threads :)). PS. Using `Default::default()` instead of `&amp;mut []` would also work. --- \*) The `&amp;` and `&amp;mut` are "sometimes" called immutable and mutable reference. I really don't like this naming, because: * It's not clear what's really mutable here – the reference itself or what it points to? (answer is "what it points to") * The `&amp;T` doesn't even mean that `T` is immutable. If `T` contains a `Cell`, `Mutex`, `Atomic` or anything like that, it's definitely *mutable*. That's why I prefer *shared*/*unique* naming. Shared means that you can share a reference, and that *usually* means you can't mutate the referred element. Unique is always unique, so you can do whatever you want with it (except of moving out). Including mutation.
Regarding *"tasks like 'Add an icon to my .exe' don’t have ready-made solutions"*: I believe [winres](https://crates.io/crates/winres) exists for this purpose. I've never used it though - mayhaps you saw it and concluded it wasn't a good one. Congrats on publishing your game!
Hello Rust gods, I am looking at the code of `Iterator` and I would like to know why it is designed with an associated type and not with a type parameter like `Iterator&lt;T&gt;`; I am curious to know why as it's not obvious to me.
[Apparently cargo does this automatically](https://github.com/rust-lang/cargo/issues/1462). I think you just do something like: [dependencies.rocket_codegen] git = "path/to/rocket/repo" Cargo crawls the repo and looks for the crate in question.
Whoooa there. DISCLAIMER : I didn't read your whole post nor all the comments. But if peek was your problem: [std Peekable Iterator](https://doc.rust-lang.org/std/iter/struct.Peekable.html)
5 is more about interfacing with the compiler in a *stable manner* - we've had compiler plugins for years now, and they have to be updated every time any compiler API they use changes.
Okay, thanks, that clears things up :) I think I was expecting a clear state transition from FCP and back to the drawing board, as you say, and that this would be announced in This Week in Rust. I've been expecting this RFC to get merged _real soon_ for months now :P
&gt; 6c. lang_items These will be unstable *forever*, unless they end up a standard or something, because they're *an internal contract* between the compiler and the stdlib. Do you mean something more specific than "all lang items"? Some of them could be exposed in some stable way without making the *notion* of a "lang item" itself stable.
Is it possible to "seal" traits? I have a trait in my crate which I need to expose to the outside world but I want to ban them from implementing that trait for their own types. Essentially the trait is an implementation detail on my side but I'm forced to make it public to use it as bounds on my public interface. I found that there used to be a hack where you have a `trait Private {}` and then `pub trait Sealed : Private {}`. This allowed you to use the public trait but external crates couldn't implement it because they don't have access to private. It turns out this was an oversight by Rust and subsequently patched. Example: [playground](https://play.rust-lang.org/?gist=60324cba11d24ebf2782d34942d522b7&amp;version=stable&amp;backtrace=0).
On ranged types, they're not that difficult, they just require compile time numbers. I started a quickie implementation [here](https://github.com/paholg/ranged). At some point, when I have time, I'll flesh it out more and publish it.
From the [issue](https://github.com/rust-lang/rust/issues/34537), the solution that rustc devs promise will continue to work is to make `Private` public, but from a module that is not itself public: mod hack { pub trait Private {} } pub trait Sealed : hack::Private {} 
Why do you wan't to ban it? Can't you just mark it unstable?
Yes, and it became possible to do the best-known ones in a stable manner when Custom Derive (A.K.A. Macros 1.1) landed. Procedural Macros (A.K.A. Macros 2.0) is in development and I remember reading that, since Clippy hooks so deeply into the compiler, the plan is to bring it into the core distro, similar to how Linux kernel modules are kept with the kernel so a "Your patches can't leave other people's code in a broken state" policy can be enforced. With limited manpower and a strong stability promise, and the need to research and design before implementing that the latter entails, these things take time.
I don't think it's imperative, C is pretty terrible for writing user interfaces. C++ has Qt, which is a real killer app, but there are many, many libraries that Rust needs in order to outpace C++.
Peekable sounds like the right tool for the job. let list = vec![Thing {whatever: 2}, Thing {whatever: 3}]; let mut eater = list.iter().rev().peekable(); let _x = eater.next().clone(); let _y = eater.peek().unwrap().clone(); let _z = eater.next().clone();
&gt; And your "99% of money on consoles" can easily be refuted in the same way by using Steam Sales Yeap, this is the main reason why literally all big publishers are focused on consoles so much releasing half-baked barely working ports on PC. &gt;Windows Desktop 41.0% So 59% is POSIX. Cool.
I don't follow stackoverflow, but I know some corners of it are high quality. Is this good enough to link from the website?
"It only blocks tasks that would cause a data race. " As I understand it, that's not entirely true. e.g if there are 3 tasks and the highest and lowest priority task share a resource. When the lowest priority task raises to access the shared resource the middle priority task is blocked. But that's the only disadvantage I see compared to a proper RTOS given the many advantages for a lot of use cases.
Why does rust marks generic types with the &lt;&gt; notation - isn't Haskell approach better? 
the space is getting a bit crowded, but we have a shot at making it a great project :)
Thanks! I overlooked the issue.
Heads up on posting a bunch of links to SO. Reddit's algo might not know you're not affiliated and think its spam.
&gt;Yeap, this is the main reason why literally all big publishers are focused on consoles so much releasing half-baked barely working ports on PC. It's the publishers problem and their loss. Others instead start porting their games to PC (most of X1 exclusives now available on W10, a lot of Japanese games are coming out on PC too). The sales are certainly less than on consoles (except in a few exceptional cases), but nowhere near your `1%`. Also, again you throw some unsupported claims like "*all* big publishers are ... releasing half-baked barely working ports on PC." &gt;So 59% is POSIX. Cool. Not exactly, if you look at the link carefully, it doesn't work like that (i.e. the platforms are not exclusive). Anyway, it's certainly not some "every dev I know uses linux/macOS, so it must be like that anywhere" scenario some people a trying to push here without any further proofs/links.
Well interrupt sharing is possible, but we run on a single stack so you cannot do context switching (as in a trad. thread based os). 
Hi, indeed it block intermediate tasks (with a priory between the task running and the current preemption threshold). This is entirely intentional and allow single blocking behaviour (while allowing tasks at intermediate priority to preempt would risk so called transitive blocking). In short, the approach taken, based on Stack Resource Polity (SRP) theory, allows us to predict the response time of each task, with a minimum of priority inversion for each task. In an upcoming post we will tell more about the benefits of the underlying SRP theory, as well as the zero-overhead implementation (yes, its indeed zero overhead scheduling). It is optimal in the sense that there can be no more efficient protection mechanism (avoiding races) for the cortex-m3 and above, and that we use the NVIC hardware for the actual scheduling. /Per 
I shipped on rust-sdl2 0.29.1 (I generally keep my dependencies up to date, but I also had [a specific change](https://github.com/AngryLawyer/rust-sdl2/pull/606) that I wanted to be that up to date for) with SDL2 2.0.5. Over all, the current `sdl2` crate works very well (and has for a quite a while) for the platform layer sorts of things I use it for (windowing, input, audio, gl context creation). I haven't touched any of the 2d rendering stuff (and don't have plans to). The worst part (by far) of SDL2 is getting the dang C library compiled on every platform in the first place, which there's not a ton you can do about as a wrapper. I _did_ use SDL2_mixer on this project, which I ended up regretting. It has a pretty limited feature set, and it was a massive pain to get compiled and linked. (I'll be looking into `rodio` and the various OpenAL wrappers for my next projects.) Similarly, I don't have a huge desire to use SDL2_ttf and SDL2_image; they both have limited feature sets with awkward APIs and are troublesome to build. Even if I were working in C, I'd probably use stb_truetype and stb_image for those tasks.
A common idiom in embedded systems (e.g., telecom/datacom gear) is to log the error that triggered the panic, with metadata (e.g., file/line where it occurred). For cases where the panic occurs deep within stdlib, say, you need to log a backtrace. To handle OoM errors of course you have to pre-allocate a static log buffer for this.
Stability is only a thing in the stdlib.
Wild guess, haven't even looked at the code: Better CPU cache usage by having shorter functions because no inlining happened? Add `#[inline(never)]` to test in single crate.
&gt; An alternative / complementary solution I could see would be to add a panics {} block which returns a Result that is Err if a panic occurred within the block. Assuming this surrounded all possible panics in the function, the function would then not have the Panics marker set. [Already exists.](https://doc.rust-lang.org/stable/std/panic/fn.catch_unwind.html)
Most readable diagrams of what a browser engine does I can ever recall seeing!
Results stay the same. Also see interesting update after discussion on IRC.
The consensus on meta.stackoverflow is that Documentation may have a promising future, but it's far from it yet. There are specific issues with curation (and thus the quality of existing snippets), notably, and the lack of guidance of what is a good topic for Documentation and what isn't, which leads to a mish-mash of trivial topics (how to index into a vector) standing right next to deep conceptual/technical topics (ownership &amp; borrowing in 5 minutes), which no indication of the level/background required for any. The name might also be misleading; as I think it was more intended as a cookbook than anything. It's also very much in flux still, as far as I can see, as the devs are trying to figure out what works best (and what doesn't). --- TL;DR: for now, it's of very mixed quality with probably to-be-obsoleted content. I'd recommend not to link to it yet. (It's also unstructured, but I guess that's appropriate for a cookbook?)
Nice places to start: * [TypeScript](http://www.typescriptlang.org/) * [Dialyzer](http://erlang.org/doc/man/dialyzer.html) * [Hack](http://hacklang.org/) * [PyType](https://github.com/google/pytype) 
&gt; There is no usable cross platform ~~rust~~ gui framework. FTFY. But seriously, this is a problem for every language. The only real solution I've seen in this space that at least matches platform conventions is react-native, and that's not really a framework just glue to write platform specific components in.
If you want multithread, `rayon` is probably the best to use! Your example in rayon would look like this: let my_list = list_of_files .par_iter() .map(|p| my_function(p)) .collect() A more fleshed out and fully usable example: extern crate rayon; use std::{io, fs}; use std::path::{Path, PathBuf}; use rayon::prelude::*; fn my_function(_input: &amp;Path) -&gt; i32 { 0 } fn parallel() -&gt; io::Result&lt;Vec&lt;i32&gt;&gt; { let list_of_files = fs::read_dir("/")? .map(|entry_result| entry_result.map(|e| e.path())) .collect::&lt;io::Result&lt;Vec&lt;PathBuf&gt;&gt;&gt;()?; let my_list = list_of_files .par_iter() .map(|path| my_function(path)) .collect(); Ok(my_list) } Rayon manages its own thread pool, and uses "parallel iterators" to handle data. This is multithreading not multiprocessing, but I assume you were just using `multiprocessing` in python to get around the GIL. As for the other libraries, `crossbeam` may also be useful here, but I don't have as much experience using it. `Tokio` is definitely useful, but it's more similar to Python's `asnycio` than to multiprocessing - it can definitely do multiple threads, but where it really shines in in doing a ton of IO work. Rayon is the library that "simply works" in this case.
As @Regimardyl says in the comment, you can wrap them into a single executable file. There is no need for your users to install Tcl/Tk separately (they will be included in your executable bundle, and do not take up a lot of space). I have created a repo with a simple example of how to create a Tcl/Tk extension in Rust: https://github.com/edko99/tlc-tk-rust-example
The original stm32f103xx SVD file doesn't have &lt;enumeratedValues&gt; information so the generated device crate doesn't have the method-based API that lets you use `opm().continuous()`. You'll have to use the unsafe `bits` API: `w.opm().bits(0)`, `w.cen().bits(1)`, etc. &gt; Also how do I create a patch I modified the original stm32f30x SVD file and only commited the diff.
Interesting. LTO increases the inlining limit. Is there a log level that could give you more information?
I think it's due to some mis-optimizations which get turned off when function is in a different crate and marked with #[inline] or #[inline(always)] and with disabled lto. All other sub-functions marked with #[inline(always)], so both compress functions are absolutely plain. As far as I can tell examining resulting assembly it's indeed true, but the assembly itself for md5_compress is quite different for both cases despite the identical code.
Hi there! Maybe you could add a `PhantomData` marker to your struct? Since the `msg` slice should have the same lifetime as your `BytesMut`, the correct code might look something like [this](https://gist.github.com/torkleyy/7a60ba526ed100cb6ee92c14c6b7cd4d) (see the revisions for the difference).
So is reading the documentation on Option#unwrap and Result#unwrap, where it says Panic in big bold letters 
Sorry about that! I tried not to provide too much information and instead wanted to get directly to the issue. I'll see if I can expand on the question.
Yes, will do so.
I wish there was one good window framework, but unfortunately there are tiny differences that makes them slightly better for different applications. E.g. SDL2 has great support for may platforms, but on OSX it doesn't give you coordinates outside the window, which sucks for drawing editors. My greatest wish currently is stabilization of Gfx, so we can work more on rendering libraries. Good tutorials is hard and there are not many people who can work on this. Some people have given valuable feedback and I've wrote up some patterns. Discussion: https://github.com/PistonDevelopers/piston/issues/1160
Piston grew out of the need to make code reusable across projects, so it isn't very good at the application as I would like to, but it is good for generic libraries. I studied the problems with this trade-off closely and some of the ideas I got became the inspiration for Dyon's way of loading of modules. The way I use Piston is often as a backend engine for a scripting environment.
Hi again. I've taken a closer look on that issue and was able to reproduce. It turned out the debugger preferred starting as x86 - which in turn caused "request not supported" when attaching to x64 .exe. If you do have time and interest in this, please try updating debugger extension to the latest version (0.3.2) and try running it again. I've also added x64 tests in order to fix this problem for good (hopefully). Thanks again for the bug report.
`cat https://www.redox-os.org | httpBody` ? 
The definitions "Censorship" and "free speech" have nothing to do with the content or how different places treat the content. Blocking child porn is censorship and therefore infringing on freedom of speech, most people just thankfully agree it's more important to censor child porn than it is to have absolutely no censorship and full freedom of speech. With different things (gambling, piracy, and many others) you'll find varying level of support but any blocking is always censorship regardless of popularity. Besides, they also block plenty of content they politically don't agree with.
Hard to say since the project is early in its development, I've listed out some of the [goals of the project](https://github.com/OpenHID/code-vr/issues/1) but these aren't the kind of thing a contributor would be able to do easily. I did open a [Discord Server](https://discord.gg/zNE69uf) to discuss the project and I'm hosting a meeting on saturday, May 13th at Noon EST by voice. 
The problem, at least as I see it, is that Rust intentionally conflates the errors you're talking about and situations where the programmer would just rather not deal with error handling.
I can confirm that it works now! Thanks /u/dreedz !
Just upload the trace somewhere, say what you expect to see, and we'll take a look.
Thanks for posting. Fun read :)
&gt; strings should be shown correctly (I'm not sure all cases are covered) Unfortunately not. A trivial example: fn func(arg: String) { println!("{}", arg); } The variable `arg` isn't [decoded correctly](http://imgur.com/Pmo0CAi). Please do continue, though. It's better than I've seen so far.
And why is it you think time should be saved? Not breaking an oppressive law is one thing but voluntarily collaborating with the regime to make its enforcement more efficient (and then proudly declaring that) is another.
Is a browser engine the renderer or the component that determines what to redraw or the master component that controls the flow between all those components? I got confused reading that. 
Thank you so much for all this. I think it's going to take a while to properly absorb and I'm going to reread this a few times over the next few days to make sure it sticks. :)
It does show up if you search for `rust windows icons`.
I think this could definitely be done with a custom serialize/deserialize for the struct which loops over 1..11 and serializes the fields themselves. I'm on mobile right now, but there's some documentation at https://serde.rs/impl-serialize.html for this.
This does indeed look useful. Unfortunately I don't think I can put an Iterator as a member of a struct, so this can't be used to make an Eater class -- but, I suppose, if I have a Peekable iterator then maybe there is no need for the Eater class at all. So as far as my actual *practical* solution goes for the actual problem that caused this thread in the first place, this is probably the perfect thing for me, and I'm happy to know it exists. :)
We are forced to collaborate either way, it is not about laws and governments (we are against this oppressive law, by the way), we do not save time of oppressors, it is about simple workers doing their job: their time worth saving in my perspective. I added the story of creation just for you to know the background to understand the need and my technical desicions. I'm proud of my code and I'm proud that my work helps regular people like me. I'm NOT proud of my government's desicions.
Indeed; I should be more on-top of my game. Though depending on situation there are a few choices that might work equally.
Looks right to me :).
Prof. Lindgren (/u/PerLindgrenRTFM) - I've been wanting to broaden my understanding of scheduling algorithms for real-time systems for some time, but I'm having a hard time finding an appropriate place to break into the literature. Do you have a recommendation for a good place to start learning more about algorithms like SRP (which I'd never heard of until your below post)?
If you're not going to write code to handle it, and it happened, then the program is in a state where it cannot proceed. Isn't "the program cannot proceed" what abandonment is for?
Tried this on a 64-bit ARM CPU and I get the same speed (~350 MB/s) for either compilation, so presumably it's an x86 optimization issue.
I don't think anyone was suggesting that all instances of panic be removed, or made harder. However, given two things: 1. That it is so very easy (even ergonomic) to write panicable code. 2. That there are certain critical sections, which would benefit or require no panics.[0] Why not ensure that the compiler validate our critical sections through `#[no_panic]`? Please don't misunderstand me: Any application which requires guarantees should have extensive tests. However, any help the compiler can provide the better right? [0] Imagine implementing a database with transactions, or hardware interrupt handling, medical equipment management software (I wouldn't want my X-ray machine to panic while the blub was turned on).
Thanks, this worked perfectly! Do not even need to provide a default explicitely it seems that just deriving Default will give None which is the default I want
I didn't convince my team, but in general, you can just look at Rusts advantages (performance, safety, ..). I'd say the use case is more important though, so it would be good to give us a bit more context.
I would like to open an Alex Crichton fan-club, where do I sign ? Seriously though, why do I feel like he is both in every PR of rustc (and cargo), and maintaining lots of the non-std crates as well? Often I just skim through issues and PRs, but I always see him doing a tremendous job of guiding people through a PR or a feature from A to Z. Huge props to him, seriously. I loved your story and how you managed to discover what the problem was, what was the strategy to take in that case, but also details of the code as well! The fact that res_init links differently on lnux, OpenBSD or android was an interesting read as well. Nice article!
Hi /u/KodrAus, Thanks for the kind words! However, if you do run into any issues (and unfortunately you most likely will), feel free to ping me here or in github - I'd be glad to sort it out if at all possible.
&gt; For Some reason people who use rust really enjoy being scolded by the compiler, so much that actually opt into more of that. Qotw material there.
How do people in the Rust ecosystem define "lint"? Would transitive analysis to identify all code which depends on non-whitelisted panicking functions count or does "lint" carry an implication of being small and light enough to only require local knowledge and what the compiler is already providing?
I am the manager, it is easier ... In practice they don't really NEED it so they have not taken the time to learn it properly.
Same here, pointed out a bottleneck in our python code, scheduled time to make it faster, rewrote it in rust and wrapped it with cffi like we do with the rest of our C extensions. Noone was any the wiser til it was done, up for code review and blanketed in benchmarks showing ~1000x speedup.
As a Python developer, I believe that Rust will play a critical role in writing Python extensions. Great if Rust can interop with PyPy
(Offtopic) &gt;I only have my code cloned there for TravisCI. Did you try the [free shared runners](https://about.gitlab.com/2016/04/05/shared-runners/) of GitLab? If so, can you elaborate why you discarded them? 
Did you know [he's an AI](https://www.reddit.com/r/rust/comments/67x46l/announcing_rust_117/dgty1ay/?st=j2k4l1sn&amp;sh=ee530bec)? Also remember, he's sent from `Future`, so he doesn't actually have to create the code, he just copies it directly from his memory. Basically, he produces the documentation of his own code... What I find really amazing is how empathic he is. He didn't dump all the code at once but he's giving us time to catch up even though, it's still hard
I started doing Rust, then talked about it, and talked, and talked again. Then I started doing actual conferences about Rust and nom, and it started to look useful :)
cffi works on both CPython and PyPy. However, JITs rarely benefit from calling into native code. This is especially true for tracing JITs that end up inlining a great deal.
There is also native windows gui, https://github.com/gabdube/native-windows-gui/tree/v2 Obviously not cross platform. I think it seems quite decent, however I'm a hobbyist and my experience with programming gui's is limited.
&gt; Did I just... reinvent the wheel? To be fair, your project is more ambitious, since -according to the readme-, it aims to eventually be a cross-platform library for automated input. My library is strictly a binding to libxdo. &gt; EDIT: Wait, that you /u/CrumblingStatue ? You made Flowey's Time Machine for Undertale! Yep, that's me. I didn't know you were a Rustacean. How did you get into Rust?
Cool, however it's missing benchmarks, which makes it difficult to compare with other async solutions.
Me: "I'm writing the next project in Rust" They: *they think I'm joking* "Ok" Me: *started writing* They: "Oh. Ok"
On the surface, perhaps, but only really on the surface. In practice the fact that Rust's generics are monomorphised, break parametricity, and work on mutable value types is more fundamental. The type checking changes when you can use it more than how it works.
/r/playrust
I am the boss. If I say Rust then you use Rust. If you don't agree file a compliant and I will gladly ignore you
I'm working on implementing the upcoming IETF standard of Quic. You can find it [here](https://github.com/bjackson/quicrs) 
Ahh, cool! I've not looked at it in a while. The docs all seems to mention py2. Most of our code is text processing but there's enough numerical stuff in there that I'll need to have another look at numba. Thanks!
Phew, thought it might have been that new res_init patch.
Two of those are general Rust things and not specific to generics. Breaking parametricity maybe, but C++ is much farther than rust on that axis. Rust lets you break behavioral parametricity, but C++ lets you break the interface. C++ templates get used differently from Rust. Haskell and Rust generics get used pretty much the same way.
You've invented an entirely different language. Certainly feel free to implement it yourself, but essentially none of these are changes which Rust could do without seriously backward compatibility issues.
We should name the official Rust band the "Borrow Checkers". 
OK, so with the array values available, LLVM can collapse two `add` instructions into a single `lea` instruction. For example: add 0x4(%r10),%edx # %r10 is the base address of RC add %ecx,%edx Becomes: lea -0x173848aa(%rdi,%rax,1),%eax Now the problem is that this causes frontend stalls. `perf stat` shows: 1,946,734,091 stalled-cycles-frontend # 65.05% frontend cycles idle ( +- 15.66% ) vs. 1,062,250,896 stalled-cycles-frontend # 44.28% frontend cycles idle ( +- 21.81% ) Which is an issue in Intel CPUs since Sandy Bridge, where the three operand LEA instruction has higher latency and limited dispatch port choices, see https://software.intel.com/en-us/node/544484
Actually, it is possible to make that new language a compiler plugin! [Namedarg](https://github.com/comex/namedarg) is the canonical example.
Was there any friction working this into your build system?
This feels like it was inspired by a mix of Scala and Clojure. Am I far off? But​ I agree with icefoxen, don't let you dreams be dreams. Just do it!
Very cool. Thanks.
Well, that's amazing. Good work finding that. oO ...Also, DAMMIT, INTEL?!
 Rusty Code extension is no longer maintained. You can try https://github.com/editor-rs/vscode-rust instead.
You are on the subreddit of the Rust programming language. You are looking for /r/playrust
This crate seems to have similar goals to https://github.com/pythoneer/enigo
&gt; I don't think bitwise operation deserve an operator or keyword, they're just not common enough in code. That's a very close minded view. There is a lot of applications where bitwise operations are crucial like cryptography, networking, file format encoder/decoder, etc. The bottom line is that your processor has opcodes for those operations and you want operators for them. High level functions would either results in unoptimized code or a lot of work for the compiler spent inlining those.
I'm still in the imperfect tense rather than the past tense, but I talk about its advantages (and disadvantages! People respond better to honesty and admittance of fault; touting only one side sounds like snake oil) relative to C and C++, how we could use it with little changeover effort, and also I've written some small tools in it as a proof of concept. I'm going to try and give a short pitch next week when it's my turn for Cool Thing Of The Week, to demonstrate how Rust is cool and useful and a thing we should use.
Great story. I think this would be a good example to link from the 'contributing' section of the website to show newbies how it's done.
But can you write this? ``` fn my_func(v: VariantName) {...} ```
I couldn't parse that as anything other than "Name darg" until I clicked through. It seemed like a very strange name for a language.
&gt; We then had to modify lookup_host so that, if it fails to do a lookup, and we’re running a UNIX-y OS, we call res_init before returning. Before returning? So if the lookup fails because of a stale /etc/resolv.conf, then it still fails, but the next one might succeed? Would it be better to call res_init, then try the lookup again? In the case where the configuration is up-to-date, but lookups are failing for some other reason (because the host really doesn't exist, etc), will this lead to gratuitous reloading of resolv.conf? Is that cheap enough not to be a worry? 
&gt; In patterns the 'ref' keyword seem pretty alien. It might seem more logical to use the '@' symbol that means dereference since the variable on the other side is a reference. [This discussion goes back five years.](https://mail.mozilla.org/pipermail/rust-dev/2012-June/001943.html) [It was revisited right before 1.0.](https://github.com/rust-lang/rfcs/pull/742) It has its proponents, but "un-dereferencing" is just too clever...
Yeah, that's true. Never knew that existed :P
I hope you will like it. If you encounter any problem, please open an issue. The Windows API can be picky at times.
Thank you! :D
Yes, I'm thinking of the clunky function-like bitwise operators in LuaJIT. Compiles to practically native code sure, but it's hard to beat the terse C notation.
This is so awesome - great job on the tutorials / documentation as well. So excited!
What about TreeView? It's the main widget stopping me from leaving Qt (for a simple apps).
The treeview will be implemented someday. It's by far the most complex control [as you can see here](https://msdn.microsoft.com/en-us/library/windows/desktop/bb759988.aspx) .
&gt; Generics I like D's syntax here with the ! syntax. `Vec&lt;i32&gt;` -&gt; `Vec!i32`. If you need multiple type arguments, you wrap in parenthesis: `Result!(i32, Error)`. I think this is even unambiguous if the `!` character is preserved as a unary operator. Yes, it's used for macro expanson, but I guess you could make the argument that macro expansion is similar to generics as they're both generating code. `!(Type, Type)` is a generic, `!(val, val)` is a macro. Seems reasonably simple to me, though `#` is used in `#define` in C++ and `#[...]` in Rust, so it's already common as a compiler directive (though perhaps having it lead would make more sense, e.g. `#println(...)`. &gt; Function syntax: I completely agree with you and it also makes it easy to do the `where` clause. Now, that's another point of contention that I have (since you can define traits either before the argument list or after), but I don't have a solid proposal to make it better. &gt; Macros by example: I'm also not too familiar with Rust macros, but I've looked through the documentation before and it seems odd. I really like how D does this, as you can define a "macro" as a regular function, but use `static` constructs to ensure they get dealt with at compile time (e.g. `static if`, `static for`, etc). Anything that doesn't have `static` in it gets included in the source code for compilation. For example, you could have this: int do_stuff(bool arg) { static if (some_compile_time_setting) { if (arg) { return 1; } else { return 2; } } else { return 0; } } int val = do_stuff(true); If `some_compile_time_setting` is true, then the generated code would be: int do_stuff(bool arg) { if (arg) { return 1; } else { return 2; } } If not, it's just: int do_stuff(bool arg) { return 0; } It's called CTFE (compile time function execution) if you're interested. &gt; Exclamation point for unwrap: &gt; &gt; ... &gt; &gt; Type conversion: I agree. I think OP has some valid criticism and I hope something good comes of it.
lmao. That's been my strategy.
Strict gpl won't get much use...
I love that you showed the Google searches. Good read.
Yeah. The apache open source ecosystem is thriving. We don't live in the 90s anymore. Companies are completely willing to work and contribute to open source. 
Macros by example.
Thank you. Your example gives me a very good impression of how to create such data structrues in Rust. Unfortunately the size of 512^4 gives me an out of memory at runtime.
I tried rayon out today and was amazed! I got a fantastic speed boost using the .par_iter. Thanks so much for the info!
I actually had to scroll back in my history to find them, and was surprised at how many things I had to try to find something useful!
I'm glad! This kind of seamless transition from single-threaded to parallel code is one of the reasons I love working in rust - it just works!
I imagine it fitting somewhere in the prose of this page: https://www.rust-lang.org/en-US/contribute-compiler.html I thought there were some existing links to such experience reports that this could slot into, but I don't see anything like that. I might expect it in the context of a discussion about getting help from more experienced devs. The entire contribution section of the site has not changed at all since it was written...
Relatively new to RUST, I'm writing a simple program that uses cURL (and the excellent [curl-rust](https://github.com/alexcrichton/curl-rust) library) to POST some data to a server and parse the response. I'm having a bit of trouble extracting the data from a closure; here is what I have: extern crate curl; use curl::easy::Easy; fn try_post(arg:&amp;str) -&gt; Result&lt;&amp;str, curl::Error&gt; { let mut handle = Easy::new(); let mut response: &amp;[u8] = Default::default(); let url = "https://server"; handle.url(url)?; handle.post(true)?; handle.post_fields_copy(arg.as_bytes()); handle.write_function(|data| { ??? How do I get `data` into `response`? ??? })?; handle.perform()?; Ok(str::from_utf8(response).expect("Not valid utf8.")) } I can print the data to stdin from inside the closure, so I know the server is returning the correct response. I'm just struggling some with the lifetimes of various bindings. I want the ```try_post``` function to return a ```Result``` with the ```Ok``` value being the data sent by the server. Any ideas? Any other suggestions to make my code more like idiomatic Rust are appreciated.
Yeah sure. 
Have you tried using a hashmap yet? A 4 dimensional array is likely going to be far less memory and time efficient. You should give it a try. You can use a 4 tuple directly as the key. You don't even have to serialize it. 
&gt; instead the memory locations seem just to be reserved (but I am not sure). Yeah, `Vec` makes a distinction between how many items have been added, and how many items it has "reserved", meaning space has been allocated but data hasn't been filled in yet. (It then does its best to make it impossible to read that space without putting something in it first) As far as the operating system is concerned, that memory is used just as it would be if it actually had something in it. However, modern operating systems are clever, and know they can generate a page of zeroes from the aether if they need to. This means that if you allocate a huge amount of memory filled with zeroes, the OS won't immediately assign physical RAM to back that allocation. It will only try to do that when you try to write a value to that bit of memory. 
I never meant to give the impression that I thought it was an arbitrary rule. I just didn't understand the rule. That is my relationship with the borrow checker in general. There are no arbitrary rules in the borrow checker, just rules I don't yet understand :P I hadn't considered a rehash operation. That makes perfect sense. the "extract_deps" function has a parsing phase which requires a mutable node reference, and an edge generation phase, which requires a mutable reference to the graph table. I combined the phases because it was logically simpler in my mind. My thought was, "I just parsed a dependency from the file, I have everything I need to make a new edge, so I might as well just insert the edge at the same time." The two phases can easily be broken into separate functions, which sounds like the way to go. Adding an extra level of indirection seems far uglier. Thanks for your help :)
For whatever reason, zero-copy didn't make any performance difference on these datasets. It was +/- 4%. The difference is going to be way more significant in Bincode or MessagePack where zero-copy means it can avoid even looking at most of the bytes. JSON is forced to look at every byte anyway.
While we're gloating, let's acknowledge that the C++ way compiles about 3x faster.
see my reply to @PeaceBear0: &gt; the "extract_deps" function has a parsing phase which requires a mutable node reference, and an edge generation phase, which requires a mutable reference to the graph table. &gt; &gt; I combined the phases because it was logically simpler in my mind. My thought was, "I just parsed a dependency from the file, I have everything I need to make a new edge, so I might as well just insert the edge at the same time." I guess I should add, the reason I need root_node to be mutable is because I store the source file string and line number of the dependency in "include_defs" field on the Node struct. It's useful meta-data for me, not really required for the algorithm.
In the apples to apples comparison rapidjson was faster. No timings were provided for the sax parser so we don't know how fast it is. Serde only won were there were no equivalent timings. I feel like the title of this post does not represent the article findings.
I would argue that "doing the same thing" is not the correct comparison to make here. The correct comparison is "doing the fastest thing that you can reasonably do" with the library. In the C++ RapidJSON library, doing SAX-style parsing into structs is technically possible but absolutely not feasible. It's not like Serde where you slap some derives on things and put some structs inside one another for composition. Instead they force you to write state machines for every top-level document that you want to parse. They don't compose in any way, so you can't write one state machine to parse an inner struct and then use that inside of the state machine for the outer struct. If anyone would like to prove me wrong, PLEASE contribute C++ state machine parsers for the citm\_catalog.json and twitter.json benchmark files. [I wrote one](https://github.com/serde-rs/json-benchmark/tree/master/cpp) for the canada.json benchmark file which is only 3 structs and an enum. Extrapolating from that, the more complex files are probably going to be 10k to 30k lines of state machine.
&gt; Do you have opinions about svd2rs? I don't know what svd2rs is. (And Google does not seem to find anything about it?)
I have tried hashmaps but haven't tried using tuples as keys. When I tested my concept using maps I only tried storing it in a flat list. I'll try it with tuples. Thanks.
Only `UnsafeCell`, right? 
Hi. A popular book on the subject is Real-Time Systems and Programming Languages: Ada, Real-Time Java and C/Real-Time POSIX (4th Edition) (International Computer Science Series). It covers most of the practical scheduling policies. There are tons of academic work as well, the particular SRP paper can be found here http://www.cs.fsu.edu/~baker/papers/mstacks3.pdf, but it requires some prior exposure to scheduling to make sense. Another seminal paper is http://www.di.ens.fr/~pouzet/cours/systeme/bib/liu73.pdf, basically laying out the fundaments of scheduling theory, on which most work has been done. /Per 
svd2rs looks very useful and nice, it provides a much cleaner way to achieve what I did with my `register_block` macro. Especially the separation between read-only, write-only and read-write registers is important and missing in my macro. The API svd2rs generates seems to help to avoid subtle bugs as well, due to a separation of write and modify. For example I had a nasty bug concerning the SSP controller. It provides a register with a side effect on reads which can lead to very nasty bugs using my abstraction, because my `set` method has to perform a read first. The reason I did not use it is that I did now know about it. :)
There's also the wxWindows license which is LGPL + static linking exception. It's quite a good fit for Rust crates.
Yeah, consts are roughly like #[inline] statics in that regards, i.e. the optimizer gets the actual definition of the values, instead of just the declaration of that array. Please keep the issue open, it's something that more likely needs fixing in LLVM (if there's a way to do that properly, I'm not familiar enough with the problem at hand), but we should keep track of it nevertheless. I don't think there's a way to enforce proper codegen. I _think_ that you probably want a 2-operand `lea` and an `add`, but I'd have to look up some details and do some testing to tell for sure. 
Why not MIT?
Perhaps the presence of allocation in my case is impacts my benchmarks more. Namely, it goes from "allocate several new `String` buffers for each record" to "borrow data from an existing record" where that record's allocation is already amortized. In particular, I can go from this: #[derive(Debug, Deserialize, PartialEq)] struct MBTARowOwned { trip_id: String, arrival_time: String, departure_time: String, stop_id: String, stop_sequence: i32, stop_headsign: String, pickup_type: i32, drop_off_type: i32, timepoint: i32, } to this: #[derive(Debug, Deserialize, PartialEq)] struct MBTARowBorrowed&lt;'a&gt; { trip_id: &amp;'a str, arrival_time: &amp;'a str, departure_time: &amp;'a str, stop_id: &amp;'a str, stop_sequence: i32, stop_headsign: &amp;'a str, pickup_type: i32, drop_off_type: i32, timepoint: i32, } Which I think means Serde is doing literally zero allocation, which is a nice boost when compared to several small allocations. In the JSON case, perhaps you still need *some* allocations so the difference is less stark? e.g., For maps/arrays. Here's the relevant benchmark comparison: test count_mbta_deserialize_borrowed_str ... bench: 2,835,437 ns/iter (+/- 49,731) = 255 MB/s test count_mbta_deserialize_owned_str ... bench: 4,989,059 ns/iter (+/- 101,791) = 145 MB/s to reproduce: $ git clone -b rewrite git://github.com/BurntSushi/rust-csv $ cd rust-csv $ cargo bench
Ok, I somehow missed this at first - but you are not using `E` anywhere. How is rust supposed to know what this `E` pertains to? You can't find this generic parameter in neither the trait nor in the struct. You need to either define the trait as `Endpoint&lt;E&gt;` or, alternatively, define the struct as `Client&lt;E&gt;` - and in both cases, the E needs to appear somewhere. Sorry for the clunky explanation; I am sure somebody else might find better words. But if you use a generic parameter, it actually needs to appear somewhere.
Firstly, you can't return an `&amp;str` out of thin air. It's a borrowed reference that has to have a value to point to. So your return type for `try_post` should be `Result&lt;String, curl::Error&gt;`. What you probably want to do is use the `.transfer()` adapter so you can use captures in your `.write_function()` call. The second example for the `.write_function()` method shows you how to do this: https://docs.rs/curl/0.4.6/curl/easy/struct.Easy.html#examples-1 So you want to use a `Vec&lt;u8&gt;` for your buffer so it's growable, and then turn it into a `String` at the end. fn try_post(arg:&amp;str) -&gt; Result&lt;&amp;str, curl::Error&gt; { let mut handle = Easy::new(); let mut response = Vec::new(); let url = "https://server"; handle.url(url)?; handle.post(true)?; handle.post_fields_copy(arg.as_bytes()); // Nested scope to end the capture of `response` early { // This lets us use borrowed values in the closure passed to `write_function` let mut handle = handle.transfer(); handle.write_function(|data| { // Push the contents of `data` onto the end of `response` response.extend_from_slice(data); // Tell the library we've copied all the data Ok(data.len()) })?; handle.perform()?; } // Convert our owned `String` from our owned `Vec&lt;u8&gt;` Ok(String::from_utf8(response).expect("Not valid utf8.")) } Finally, calling `.expect()` to panic if there was an error is probably fine for prototyping or a small program, but you might want to think about better error handling there. That's a little bit down the road as you have to figure out a common error type to use. If you want to be lazy you can use `Box&lt;Error + 'static&gt;` where `Error` is `std::error::Error`; to be more robust you would create an enum wrapping all the error cases. There's crates that make this a little easier, like [error-chain](https://crates.io/crates/error-chain) and [quick-error](https://crates.io/crates/quick-error). Edit: fixed code example Edit 2: you need a nested scope to limit the lifetime of the `Transfer`
My goal was for the `E` type parameter to be used to constrain the associated types, not the impl type or the self type. In English, I want to express, "Implement `Service` for `Client` for every pair of `Request` and `Response` types that are tied together by a type implementing `Endpoint`." This is what I was concerned was not possible in current Rust.
I run a mix of Lubuntu and Kubuntu with the default Lubuntu theme and, if you ignore the font choices in urxvt and Vim, the only deviations are the PySolFC `clearlooks` Ttk theme used on `git gui` and the fallback them used in BasKet Note Pads because I've been too lazy to find a better Qt 3 theme and the KDE 4.x+ versions of BasKet freeze when I try to migrate over my data. Qt matches GTK+ 2.x via the QGtkStyle theming engine and the main deviation between GTK+ 2.x and 3.x applications is that GTK+ 3.x introduced a split between the original coloured action/places icons and some monochrome ones I haven't yet found time to track down and overwrite with the ones GTK+ 2.x uses everywhere. It is very much a unified look and feel and, when I find time to rewrite BasKet as part of a more comprehensive in-browser hypertext PIM solution I have sitting in pieces on my virtual garage floor, it'll be even more unified.
It can certainly be used to terrorize people who despise PHP, Bash, and Perl syntax. It is a very noisy and heavy-weight symbol. Not sure how much better it would be...
Seems like it. Sorry I couldn't help/didn't fully understand your problem.
Only checking whether `v[5]` is in-bounds would change the semantics of the program. At least the panic message would differ, which is why this is not optimised out. return v[5] + v[4] + v[3] + v[2] + v[1] + v[0]; is optimised just fine.
That would be a bit ambiguous semantically though. Boolean operators only operate on 'singular' boolean values, wheras bitwise operators are more like aggregate array versions of the boolean ones. Bitwise operators are really more of a generalization of boolean operators, not the other way around.
if you want to manually optimize that away, do the bound check yourself via .len() and access the elements via .get_unchecked()
Those do terrorize me, but seeing ' without a closing single quote is also equally horrifying. Was ^ used? I can do this all day. Come up with alternatives for '.
It also optimizes pretty well if you throw in `assert!(v.len() &gt; 5);` beforehand
&gt; Even if we know the Request type, the same request could belong to multiple endpoints. This made the gap in my logic clear to me. Thank you! As always, your comments are super useful.
It's not actually anything Rust does, it just comes from the fact that `assert!(condition)` basically boils down to `if !condition { panic!("condition"); }` and LLVM is smart enough to use that to eliminate all of the other branches of the bounds checks ;) I definitely feel like it should be documented somewhere though!
I enjoyed this not only for the content, but for getting to see and hear the venerable Manishearth for the first time. :D
You might also consider using the Apache license which has been vetted as compatible with the gpl licenses especially if you want to dual license. The mpl has some conceptual conflicts with some of the other protective licenses. 
Right. 👍
I still believe it is a failure of optimization. `panic` is a cold function, so LLVM could optimize this code as: if v.len() &lt;= 5 { return v.get_unchecked(0) + ... + v.get_unchecked(5); } else { return v[0] + v[1] + v[2] + v[3] + v[4] + v[5]; } Neither clang, nor gcc, not icc can optimize even simpler code, and that's super strange: https://godbolt.org/g/WywyK3 Edit: new LLVM issue: https://bugs.llvm.org/show_bug.cgi?id=33023
&gt; Neither clang, nor gcc, not icc can optimize even simpler code, and that's super strange The weirder thing is that it (clang) reorders the checks so that they *all* happen before any vector data is accessed, but then it keeps a sequence of: cmp eax, 1 je .LBB0_7 cmp eax, 2 jle .LBB0_7 cmp eax, 3 je .LBB0_7 ... even though that sequence could be reduced to just one comparison. So it doesn't seem to be any limitation of aliasing rules / "abort could have side effects", etc. It's an apparently trivial transformation that for some reason is not being done.
You also can use reference to an array as an input argument (`v: &amp;[u32; 6]`) and macro from [arrayref](https://github.com/droundy/arrayref) to convert slices to array references.
You bet it can.
You are right, but the new syntax doesn't seem to require any new tokens. *Technically* suffixed literals like `"f"c` would be a new token but can be emulated to the large extent.
Code looks good as far as I can see. One very minor thing: In Response::new(), rather than this: let h_str; // ... if str.contains(SEP) { // ... h_str = one_thing; } else { h_str = another_thing; } why not do: // ... let h_str = if str.contains(SEP) { // ... one_thing } else { another_thing } Using "let var_name;" is sometimes necessary, but it's better to avoid it if you can. Similarly at the top of create_request(), where you assign to 'body'. 
It's not designed for that. The use case that I'm going for is a queue, although that hasn't been implemented yet.
that's a terrible benchmark if so. It should be required to handle some level of dynamic content...
hyper is in both plaintext and JSON at the moment. If there are async DB libs, it'd be cool to add the query tests too (huge thanks to those who submitted the existing tests!) It's worth pointing out that the plaintext benchmark is nearly worthless. It's testing a situation that will absolutely never ever happen in real life, since all browsers and clients have stopped using pipelined requests. hyper actually specifically does not use some of the techniques that other libraries use to get faster pipeline results. The problems with those techniques are why no one uses HTTP/1.1 pipelining anymore. They start dealing with all of the requests in the pipeline immediately, even though the server might respond to close the connection. If so, those extra requests spawned a bunch of work that is dropped on the floor. It doesn't seem worth having that problem just to be higher in a misguided benchmark. The JSON benchmark does a much better job of basically showing a real plaintext request, and shows hyper's relative position. You can see that there is still work to be done. While not the easiest to find, it can be something as simple as making an extra syscall that isn't needed. Profiling will say more. Also, hyper will likely always be a little slower than minihttp. minihttp skips some important things, since the benchmarks don't exercise them. Things like checking for a request body, ensuring response bodies are the correct length, checking that the connection should be kept alive, etc.
:O how long until this lands until `xsv`? Loading a 5GB CSV ends up using 20+GiB of RAM. 
The crates do dual licensing because the Apache license is maybe not compatible with the GPL license version 2. Some people believe the licenses are compatible, others believe they are not, and there has been no decision by a high court on that question. The MIT is there to ensure that compatibility.
The MPL explicitly lists copyleft licenses it is compatible with. Maybe not a good solution but it works. The Apache license is compatible with the GPLv3, but may or may not be compatible with version 2. The FSF believes for example its not compatible, and better be safe than sorry. That's why you should dual license with the MIT license.
With GPL it's not possible to do anything without open sourcing everything that GPL code is linked to. Software companies often open source their stuff and it's fine. But when they get payed to develop something for other industries, they don't build GPL code to do that. Their clients extremely rarely would consent to open source what they are charging developers to build. Is your goal to charge people to use this library under a dual license? That's fine. But it also means you are competing with QT for a very small fraction of their functionality. In a language that is currently a very small community. Is your goal for people to use and contribute to the library? You are cutting off practically every person who would like to build something they would get payed for. Those people are a big chunk of users who will gladly contribute patches if something needs fixing for them. You are limiting yourself to the purely open source GPL software community. That is very niche (though vocal online) community who do not care about windows a whole lot. You are dooming your library to irrelevance. Are you licensing it GPL because you are afraid a company is just going to take it and contribute nothing? That is a pretty archaic way of thinking. Why would they want to maintain their own library. It just causes a bunch of additional work. If it's lacking something that you need, implementing and sending a pull request is way easier. Even easier is paying the maintainer to do it which is also quite common. That way the company is still benefiting from further development and not doing it all itself. 
3x of what? 3s vs 1s is probably fine. 30 mins vs 10 mins probably isn't.
I have my own suggestion: lift the `\` for namespacing from PHP and fix how it works. Motivation: Make namespace separators look like proper Windows paths, and make them work from the current module like you'd expect if it were a path. So `foo::bar` becomes `foo\bar` which is just a savings of one character. This isn't that exciting by itself, but there are further changes: 1. `self::foo::bar` is now `.\foo\bar` which continues the path analogy 2. `super::foo::bar` is now `..\foo\bar` which is even better 3. All namespaces are now relative to the current module so you wouldn't need `.` anyway, you'd mostly use `\std\env\args` syntax (absolute namespaces) and `..\..\foo` syntax (relative namespaces) this doesn't have the parsing ambiguity that `/` would have, but still lets you use things that look like paths 
Would it work to sort it in a small number (~10?) of chunks, then merge them? (Asking out of curiosity; I'm guessing you're way ahead of me)
I could be completely wrong. It's weird though since this and the tokio one are using Futures. Maybe /u/seanmonstar would know better as to why this isn't doing as well. I'm not as familiar with the internals of hyper, just how to use it.
Yeah, but that's an "uncomfortable hammer" problem, not a "building will fall down" problem. I'll happily use a slower compiler if it makes better software.
A clean build of serde certainly takes longer than 3s... I imagine at least 15-30 on fast PCs
That's called [external sorting](https://en.wikipedia.org/wiki/External_sorting). It's a valid approach, but it might not be high up on /u/burntsushi's list of priorities.
Let's also acknowledge that user couldn't really care less about the compile times that the developer of the app had ... but the user **will** care if the app is slow.
Depends on the domain of use. Although broadly I agree that compile times are an odd thing to complain about (if you're not using a REPL). 
Yes, that's the problem, and that's why the idea will never fly.
Templates are nice and all, but I usually go elsewhere if I want to worship my projects :P
&gt; In general most of this post seems to be about the dogma that each symbol should have exactly one purpose, which is not very well justified and makes little sense to me. In fact it was not a goal at first, but it emerged naturally from wanting to get rid of the `::&lt;&gt;`, reuse `!`, One of the goal is simplifying compiler parsing. I can't remember the count of language evolution proposals that were just not considered because of ambiguities about symbols. The `::&lt;&gt;` syntax is a good example of this kind of problem, but I remember it caused problem with lambda and lifetimes too. Legibility is subjective but, having one symbol for one purpose seem a huge gain to me. &gt; The downside of course is that you now have a proliferation of different symbols. Your post recommends bringing in @, #, and ~, none of which is common in Rust expressions today. The use of tons of different "sigils" was a major criticism leveled at Rust in the early days. And you will soon run out of symbols that are in ASCII and present on common keyboard layouts. In my opinion, it's quite the opposite : my language should be symbol lighter. `@` and `#` are just replacing other symbols, and many symbol are replaced by keywords or types. The only new symbol is `~`. I don't think there will be a lot of new concepts requiring new symbols (by the way may proposal set `^` free). New features are built upon existing syntax and having symbols with different purpose probably greater problem since ambiguities can prevent some good looking syntax.
Impressive work, might end up using this for some rust tools I intend to make.
I do think that if there is an effort to promote Rust as a language to write Python extensions, it would be a huge benefit for Rust ecosystem. Python is extremely popular and needs to write performance-critical Python extension is popular too. 
It's pretty quick. Not even long enough to make coffee. 
In case any one else is wondering: removing debug symbols doesn't make a measurable difference (at least on my machine with my unscientific tests \^_\^).
hi! I'm trying to solve a hackerrank exercise but in my computer the results are correct, but in hackerrank it says is a fail. Code is [here](https://gist.github.com/freinn/3d99211cd3a9e4b522b2e04d9db65e16). [this is the exercise](https://www.hackerrank.com/challenges/compare-the-triplets)
I don't really see the point. If you're going to return an Option&lt;T&gt; value and panic if that value is None, then why not just just return T, and panic if you can't?
&gt; This does bring up an interesting question of whether you could actually deserialize these bytes in-place, using marker bytes (eg. quotes and braces) as space to store metadata, and packing integers into the space their decimal representations took... It's not exactly the same, but ["in-situ parsing" on a `&amp;mut str`](https://github.com/serde-rs/json/issues/318) has been brought up before.
`~a` would have been a much worse choice for many of us who use non-American keyboard layouts because the tilde/backtick is the so called "dead key" that's used to produce diacritics. On my system, for example, `~` + `a` produces `Ą`, and I need `~` + Space to get the actual tilde.
I see you're running Windows. I'll give you a hint: look at your line endings.
I'm on ubuntu 16.04.2 but I will look for that and see what happens
Writing out the code closer to the way it's compiled int sum5(struct Vec* vec) { int x0, x1, x2, x3, x4, x5; if (0 &lt; vec-&gt;len) { x0 = vec-&gt;data[0]; } else { goto abort; } if (1 &lt; vec-&gt;len) { x1 = vec-&gt;data[1]; } else { goto abort; } ... return x0 + x1 + x2 + x3 + x4 + x5; abort: abort(); } gives sum5(Vec*): # @sum5(Vec*) mov eax, dword ptr [rdi] test eax, eax jle .LBB0_3 cmp eax, 6 jl .LBB0_3 mov rcx, qword ptr [rdi + 8] mov eax, dword ptr [rcx + 4] add eax, dword ptr [rcx] add eax, dword ptr [rcx + 8] add eax, dword ptr [rcx + 12] add eax, dword ptr [rcx + 16] add eax, dword ptr [rcx + 20] ret .LBB0_3: push rax call abort Doing the same thing without deduplicating `abort` with `goto` doesn't fix the problem, so one should expect this is another instance of the compiler optimization phase-ordering problem rearing its ugly head.
Strange. Maybe *they* are running Windows? Regardless, don't use [`pop`](https://doc.rust-lang.org/std/string/struct.String.html#method.pop) to strip the newlines from your [`read_line`](https://doc.rust-lang.org/std/io/struct.Stdin.html#method.read_line) results, use [`str::trim`](https://doc.rust-lang.org/std/primitive.str.html#method.trim). I've forked your gist with the version I ended up with, but I got a bit carried away with it so it's not very idiomatic Rust... :p
Nice! Waiting for next part!
many thanks, with trim the grass is green xDDDD
Thanks. I read through your whole post, but I only have enough time for shorter responses tonight. Re: checked maths, I did not know about the existing functions, and it is good to know. Re: lifetimes, I also didn't realize that different lifetimes would not change the generated code. Although now that I think about it, I suppose it makes sense, because there isn't really an action that I know of which takes place when something is unborrowed. As far as no_panic, there are some other posts that mention catch_unwind and inappropriate usage of panicking functions. The latter is probably more what I mean - if a cosmic ray flips a bit, I agree there's not much that the program can do and it makes sense to either panic or call some handler of some kind outside the normal flow. That being said, I don't think that #[no_panic] not existing and needing to be added to crates for it to be meaningful would make it worthless - that is much the same position that #[no_std] was presumably and that aspect would just mean that people would have to add it to existing crates, and maybe modify them to not panic. However, things that are inherently unrecoverable like a stack overflow or something make sense to panic - it's more the use of unwrap and except. One thing informing my opinion here was that very early on in my use of Rust I discovered that there was a crate that would panic on an incompatible file format. This was very much to my dismay since it seemed like it meant there was nothing I could do to keep my program safe short of forking the crate and removing the panic. Something such as that could become a potential DoS vector on code, even if it doesn't result in remote code execution.
It's not that odd. I'm a huge fan of Rust, and also Haskell -- I've written and maintained projects in both (professionally) -- and in both cases, compilation speeds are a burden and a reason to consider other languages. Here's a popular thread on /r/haskell lamenting about GHC compilation times: https://www.reddit.com/r/haskell/comments/45q90s/is_anything_being_done_to_remedy_the_soul/ &gt; Yes, we are aware the compiler performance has tanked a lot over recent releases. No, I don't think it's fundamentally anything about Haskell (or GHC itself necessarily) that makes it so. I think at this point it's basically our fault and a failure of our development process. &gt; I actually had extensive discussions about this with people in New York last week. I would say it felt like almost every professional Haskell programmer cornered me and brought up compiler performance. Mostly I just suck it up, but I also really envy people who code in Go or Ocaml, for this reason only.
I would personally trend towards failing to compile, or maybe have certain tools available in debug builds but not release builds. I feel like if someone is using Rust at this point, they are opting into a very security-conscious language. If there really is some justification to make it toggleable, I'd just make it configurable with preprocessor attributes like other warnings. In general, I feel like it's a giant contradiction to say "Here's a language optimized for compile-time safety that has a massive amount of effort put into preventing segmentation faults and other things that would instantly kill your program and lots of work put into error code handling...but if some joker calls these three or four functions that you have to just know by name in some obscure code branch, it could blow away your entire program." I would argue that the kind of panic based on an assert, unwrap, expect, or panic! is actually part of the contract of a function, whereas a panic that can happen at any point in the normal course of a program due to factors outside of programmer control (eg stack overflow) is a global language issue that the programmer just has to be conscious of as a consequence of programming in that language.
I'm actually really surprised by the length of the responses, and that's partly why it took me some time to respond. I would say that one of my concerns has been that it's been most effective for me to pop onto the IRC channel, ask a question, get an answer, say thanks, and then get back to coding with no record ever being made of the exchange (that I'm aware of). So it has felt like some of that information about what the blockers are isn't really being preserved. For other things (like self-referential structs) it feels like they've come up over and over, but the actual external impact has been small, because once I recognized the issue and struggled with it for a bit, I learned and worked around it every other time I encountered the issue.
Specifically these: https://github.com/tsgates/rust.ko/blob/master/src/lang.rs Right now it looks like these block both embedded and kernel modules, eg any kind of bare-metal programming, on stable. Both are really great places to apply Rust, but it doesn't appear to be possible without using nightly, which just sounds scary.
Glad to be of help
To your point about DLLs, I would question that assumption. What if you're running some kind of incomplete emulation, the support gets removed, the system is degraded somehow, etc.? If the only alternative is to check for every single Windows program ever, I agree a panic might make sense. But if it's something the developer is writing, then I think it might entail an error message and shut the program down. But a panic might be going a bit too far if the program is manually loading those DLLs and has other options besides panicking.
I wouldn't say all instances of panic should be removed, but I think any manually invokable instance should be made harder than it is now. I think you should really have to go looking for it, and maybe turn on an explicit "I know what I'm doing here" flag. Or have the ability to protect yourself from other people manually panicking (in the form of simply refusing to compile, because if you don't let them panic, there's no safe way you could compel that crate). Most people here seem to disagree with #[no_panic] and suggest to use a panic handler, without knowing more about the sort of behind-the-scenes panics that can come up, that seems like it might work for an X-ray machine example to at least dramatically cut down how much code you'd have to look at.
Knowing about unwrap or expect doesn't mean that somebody has read the documentation - it's pretty common for people to use them in code examples without a big red warning explaining what they mean. As code samples proliferate, it's going to become more common for people to encounter those functions without context or perhaps even pick up how to code without really reading the documentation. You might also be able to glean the methods on Result and Option from code hinting, and never see the big red text (I use vim, so I usually just have the documentation open myself)
Wrong sub m8, try /r/playrust
If you do bounds check, the compiler will optimise following checks.
5) That's not exactly what I meant. Take a look at this stack overflow for an example: https://unix.stackexchange.com/questions/147420/what-is-in-a-command The general idea here is that the bash you use inside the $() command uses the same syntax as outside the $() command. Another poster asserted this would not be as type-safe. 6a) In Alex Chricton's ssh2 library, he provides a session, sftp, and file objects which depend on the preceding object. So if you want to keep track of everything related to an SSH connection on a single struct, I don't think there's any way to do it safely or ergonomically. 6b) Any example with futures that goes on to use and_then. It seems like the and_then becomes a part of the return type signature of the function. The oom handler looks interesting, though I'm not 100% sure how it's intended to be used since the documentation is kind of sparse. However, I'm sure that'll get improved if it gets moved into stable. :)
There is [tokio-postgres](https://github.com/sfackler/rust-postgres) which could be used for the query tests.
I think optimizations depend heavily on the code being optimized, so..
I couldn't disagree more. I think the changes you propose would severely harm the usability of the language, and wouldn't actually solve anything. So what if array indexing returns a `Result&lt;&amp;T, OutOfBoundsError&gt;` or `Option&lt;&amp;T&gt;`? Already you use the question mark operator in your indexing example. So the error would "bubble up". What can the calling function do about bad array indexing? Probably nothing, so it *also* uses the question mark operator. Up and up we go. We end up in `main`, which also doesn't know how to recover (at this point we're probably dealing with `Box&lt;Error&gt;`, not `OutOfBoundsError`), and quit. The same with any function that performs division (`DivisionByZeroError`) or any arithmatic (`OverflowError`) or function call (`OutOfStackError`) or allocation (`OutOfMemoryError`, particularly nasty because we probably can't box this one...). Great, now we have the exact same situation as before, except that pretty much *all* functions must now return `Result&lt;T, Box&lt;Error&gt;&gt;`, and most of the errors we return can't be handled anyway. Retrying failing operations is not a reasonable option because a logic error would predictably fail no matter how many times we try (insert some wisdom about the definition of insanity here). Panics make a lot of sense for errors that the program can't reasonably recover from.
Is there a Roadmap available of the work that remains to be done to fix the current performance issues? 
Hmmm. I'm not in favor to avoid language features because the compiler fails to optimism them. These are cases where Ada use to shine (proper range types and loops) and even more with the introduction of contracts. I believe this should seriously be looked into to see if this cannot be "optimized" in the early phase of the code generation (during the generation of the bounds check) where "context" can be used. All the presented solutions here work at the "instruction" level optimization.
I'm not really particularly experienced with Rust, to the point where my lack of Rust experience probably still slows me down by a lot, but generally speaking I find it somewhat difficult to imagine meeting daily deadlines and client demands as effectively and quickly in any other language but the likes of C#, Python and JavaScript. Of course we're now talking in the domains of web backends, game development and inter-company infrastructure and tooling, all things which weren't the prime targets for Rust anyway. But in the domains I work in with these languages, the correctness of the code is just not such a huge critical point. Most of refactoring happens with IDE support (or you just pile abstractions on top of it and hope that shit doesn't break, which honestly doesn't happen quite so often as some horror stories might suggest), debugging UIs and game behaviour etc is more or less language independent, profiling is barely ever needed (and the tools I mostly run with make it trivial enough), writing unit and API tests just tends to be fairly similar between all of these, etc.. While I'm still a bit clumsy with Rust, I'd foresee my effectiveness with it to superceed my effectiveness with C++ quite soon if I just keep working on Rust. Rust's just simpler and once I've started to get somewhat used to the strictness of the compiler and the borrow-checker, it does in some ways actually make approaching complex problems a bit less mentally burdening.
Well you raised a few points that I didn't think about until now. At this point I'm honestly thinking about switching licenses. I think I care more about the adoption than forcing open source after all. 
&gt; I would say that one of my concerns has been that it's been most effective for me to pop onto the IRC channel, ask a question, get an answer, say thanks, and then get back to coding with no record ever being made of the exchange (that I'm aware of). So it has felt like some of that information about what the blockers are isn't really being preserved. *chuckle* I definitely know what you mean there. It just didn't occur to me because I tend to be good enough at googling and have spent enough time lurking here (since before Rust 1.0) that, while IRC is my first resort when googling fails, I've almost never needed to use it.
It's hard to get too specific on these things, but in my own personal experience, there are definitely a few bright productivity lines that are clear to me. The biggest is between languages that have no type system ("dynamically typed" or "unityped", e.g., Python, Lua, Javascript) and languages that do have a type system ("statically typed"). It's hard to rival the productivity of dynamically typed languages for short programs, but *without exception*, every single code base over a few thousand lines in a dynamically typed language has become hard for me to work with. It's hard to refactor. It's hard to find my way in the code. It's hard to do anything, quite frankly. Is it possible my experience doesn't generalize? Sure! Maybe all dynamically typed codebases I've worked on have sucked. I don't think that's true, but even if it is, you kind of have to ask yourself: why did they suck? (Remember, I'm speaking in generalities here. Technically, C is statically typed, so does that mean I think large C codebases are always easier to maintain than large Python codebases? Certainly not!)
I have worked extensively in Python (though it has been some years), C, and Rust. On the Python front, for anything past a very small project or script, I hate it. Little to no guarantees means that nothing can be assumed which means that the programmer has to check everything and/or keep track of everything themselves. There is a reason that Python devs tend to love TDD, if you don't test it you can't trust it. That makes it tiring and an absolute pain to refactor. I use C regularly as my job has me working on or with the Linux kernel often. If not working on the Linux kernel then I am working on some embedded system running code directly on metal. C works for me, but as everyone knows (who isn't lying to themselves) if you touch memory in C you are asking for a bug. The slight checking that the C compiler does helps, and if people don't do crazy casts and pointer arithmetic things generally go fine, but there is always some bug lurking in the background related to memory. As most of my work has been on the embedded side I can't say much about testing as that isn't done terribly much other than manual functional/systems tests. I have only been working with Rust for the past half a year, and though I still consider myself a newbie, I feel more productive. To be clear, most of my projects have been in the 2k-5k SLOC range, though I have worked on/am working on stuff for larger projects. If types and function signatures are written correctly I don't need to worry about another piece of code passing on data that I am not expecting. Large swathes of tests simply don't need to be written, the compiler practically walks you through refactoring, and testing is built in. What's not to love? Well, build times are slow once you get past a certain point which can slow down iteration cycles, though it doesn't bother me much as I am used to taking a five minute break each time I need to recompile certain C code that I work on often. Also, if you use macros, especially if they are from an external crate, have fun debugging them if something goes wrong. It normally isn't a problem, but once macros get to a certain complexity (I'm looking at you, `nom`) things go downhill rather fast.
&gt; in verbose-errors mode, the error list is now stored in a Vec instead of a box based linked list How does this work with no std? Or isn't verbose-errors supported in no-std?
We don't use it at work yet, not I've convinced a team member to try it at home (he's making good progress) and I'm trying to convince the others as well. I'm also making games as a hobby, and I've told everyone that I'll need help eventually and that the server is written in Rust, so if they want to help, they should learn it. Unfortunately, the main barrier is political. My boss (the CEO, I'm head of development) is very focused on ROI, and I can't really give a positive ROI on switching from Go to Rust for our sizeable project. He's not a fan of using a plethora of languages, so I'm just happy I convinced him to let us use Go. Had Rust been out when we needed to make that decision (right around Go 1.0 release date), we might have gone with Rust.
it did not require it in the first place. Why, did using verbose-errors solve that issue for you in the past?
I used to not think much of such libraries, that I could hand roll anything myself (NIH anyone?). But for my job I wanted to throw something together quickly, really simple regular grammar and even then `nom` blew me out of the water. Going from knowing nothing to basically done in a few hours (!). Really crazy good stuff, not going back ❤
If one's only source of method awareness is from code hinting, then they are going to run into problems. Reading the Fantastic Manual is an important practice. Rust has first-class documentation so thoroughly available that not reading it takes some effort. Copying from samples isn't learning. Copying, finding unexpected panics, and figuring out why they happened, can be. I don't expect everyone to read the entire Rust book and libstd documentation before opening an editor, but when the crash message says "tried to call unwrap() on a None", that's probably a sign to go look that up, see where it says Panics in big letters, and learn that unwrap() means "there is something here and if there isn't then the world doesn't make sense anymore"
It's really hard to produce "facts" rather than beliefs in programming, since we can't really do the same project with the same team in the same circumstances but with a different language to control for just that variable. Even truths that have citations with them are often overstating the significance of what they're citing-- see [Leprechauns of Software Engineering](https://leanpub.com/leprechauns) for a bunch of instances of this. 
If loc is a metric at all, Python code substituted by around the same amount of Rust code: https://github.com/rust-lang/rust/pull/41932/files 
&gt; This might be biased since all my projects are &lt;200 lines long, they fit imperative programming well and I usually need only built-in libraries (school projects). For a probject of this size I'd bet that a dynamic language and a static language have similar productivity, or it favors dynamic. The real benefits of a statically typed language, in my opinion, comes when you have a larger project and, in particular, when you have to make changes to it - refactors. I can compare Java and Python. Java has a relatively uninteresting type system, but it makes refactors far safer than Python. I've maintained large codebases in both, and Java is far, far better in my opinion for any large codebase where any change will have to be made.
Regarding the binary and logical operators, I like Python syntax (and/or/not for logical operators, and the symbols for the bitwise operators). &gt; Actually C and C++ support this but almost nobody uses it. Python has this, and I think nobody is unhappy about it. It's the only way in Python (and it's a good way).
So it's possible to change Rust semantics to allow such optimization?
I've pushed version 3 of `nom-test-helpers` as well. It doesn't look like there were any breaking changes to `IResult`, so the only "breaking change" in nom-test-helpers 3.0.0 is that it updates to nom 3.0.0 :) https://crates.io/crates/nom-test-helpers
To quote the `nom 2.2.1` [documentation](https://docs.rs/nom/2.2.1/nom/macro.escaped_transform.html) &gt; WARNING: if you do not use the `verbose-errors` feature, this combinator will currently fail to build because of a type inference error and I can confirm that this is true in `2.2.1`.
The other approach is to arrange the data on disk so that it is always available in a sorted order; this is often how databases work. Consider throwing the CSV into SQLite and querying that?
right, then I need to test this, and possibly update the docs :)
I'm not sure I understand. How do I use that to halt a `nom` parse? I don't care about what the identifier is, but if there isn't one, the document is malformed and parsing needs to stop. Figuring out the line, column, and maybe offset of the errors (and the good parses) is the problem I'll be having right after I solved the above :)
After working for 2 years in Rust I still find Rust to be 2x slower than development in C++. There are 2 major problems I have with Rust productivity: One: tab completion (racer) hardly works at all. This is a direct cause of lost time and frustration. (related) RLS is unusable - it takes over 12 minutes to start, and for some reason it seems to restart all the time. I have disabled it until things improve. Two: documentation isn't good enough. Doing things like passing a closure as an argument to a C program is really hard. Doing things like self-referential fields is really hard. There are lots of little details that you have to worry about with Rust that are not covered at all in the 'simplistic' Rust books/documentation - and these take hours and hours of searching to resolve. I'm still fully committed to Rust - just sharing because you asked. 
Hello! For that question we are trying to figure out how much of our community does not encessarily feel comfortable speaking in the primary language where they live, or online. It's not just English, because someone in China happily interacting with people about rust in Mandarin is probably not a problem. But if someone does feel left out then we could put more effort into trying to connect Mandarin speakers in San Francisco together.
I've made a small application with gtk-rs. In my opinion, it's absolutely useable. I developed the application on Linux, but it also runs on Windows (but you have to deliver ab bunch ob dlls, of course). Look and feel is the same (because it uses the default Adwaita Theme on both Linux and Windows). 
No there aren't, not in Rust.
Seconded. I don't write Windows stuff for work, but if I did, it would be a pretty hard "can't". Nothing prevents me from using a BSD/LGPL/whatever licensed library for work, and if I run into bugs with them I'll try to fix them and submit the fixes upstream. But I can't use GPL libraries, so I won't ever bother trying to make improvements to a GPL library on work time. GPL is fine for applications, or even great, since it helps ensure a community gets built around it. For libraries it's a hard road-block so, so often.
In the rustc sense, "lint" is well-defined by the compiler's interface that e.g. Clippy uses. It gets one crate's AST or typed HIR, and can run arbitrarily complex checks on it. Global analysis of panic safety would probably require annotations in dependencies' metadata.
...or building on the technique [cargo-safety](https://github.com/alexkehayias/cargo-safety) uses.
It's unclear what the right solution is here. At some point, we have to report an error to the application, and the application needs to decide what to do. We can't retry indefinitely. And the connect really *did* fail --- at the time when `connect` was first called, there really was no internet connection (that's when the resolver is first initialized). Us calling `res_init` thus only makes a difference if the application retries, and if the application retries, it will work with this fix.
That's another reason for the project. I'd like to make rust first class choice for c-extensions 
&gt; What if you're running some kind of incomplete emulation Then, assuming no API violations or relying on undocumented behavior, it's a bug in the emulation layer. If a Linux executable misbehaves under WSL, then you file a bug against WSL. If a Windows app misbehaves under Wine, then you file a bug against Wine. But instead of having to deal with emulation layers, why not just make your application cross platform in the first place? (which also completely eliminates the necessity for an emulation layer) &gt; the system is degraded somehow Depends on what we're talking about. If DirectSound is not installed or sound doesn't work on that specific machine, you can just not play back any sound. But if `User32.dll` is missing from a user's machine, then there's absolutely nothing you can do about it. Heck, `MessageBoxW` and `CreateWindowW` are located in `User32.dll`. If it's missing, you can't create a window or even display a message box to the user.
Author of TRust-DNS here: I have a question for this audience, what would it take to get a native Rust DNS implementation into the std-lib as at least an option to use instead of relying on the system's libc implementation? TRust-DNS is not ready for this, it needs a resolver wrapper that I'm planning to start work on in the next couple of weeks after getting some *ring* updates done, and cleaning up some key management. But, I would definitely like to build a resolver that would be able to facilitate requests by the stdlib (not actually included in the stdlib itself). I should probably start with the net2 library to see if there's a path forward there. Anyway, any feedback on this would be great.
I wonder if there's some use for a tool that publishes arbitrary github trees as crates named after the commit id, to get around that sorta restriction.
I use Haskell at work. If I had to write the code without the kind of abstraction it provides the code would be way more complex and longer. Higher Kinded Types and monads really make writing the code a breeze. It's less figuring out how to get something done and more what do I want to get done. That being said I feel the same way about many things for Rust (but it does lack HKT right now) and a lot of the pattern matching that Haskell has I can use extensively in Rust. I again feel less like how do I do this but what do I want to do. Does that make sense? It's kind of hard to put into words since it's something that's aquired from working with both languages consistently for some time now. The level of productivity you mention can be seen in many languages if you work in them enough. I feel that some languages make it easier
The names associated with people's user names on a subreddit. On rust it's the projects you work on. In this case burntsushi is known for his work on ripgrep as well as the regex and fst crates
I've heard that once in a blue moon, or when asked nicely, the moderators may exercise super-powers including (but not limited to nor necessarily including): * Poetry * Memes * Flairs * Shenanigans * Fearless concurrency * Moderation But that's probably just rumours... 
Ah nice - that sounds like an awesome project! I'll definitely have to look more deeply into the wiki article and the library.
You can use `?` if your function returns a [`Result`](https://doc.rust-lang.org/std/result/index.html) and there's a conversion using the [`From`](https://doc.rust-lang.org/std/convert/trait.From.html) trait from the original error type to the one your function may return. Essentially, `?` is syntactic sugar for checking if the result is an error, and returning a converted error from the function instead, or if you return the same error type, just returning the same error.
Fundamentally, `?` will immediately end the containing function and return `Err&lt;_&gt;` on failure, as though you'd manually written `return Err(_)`. (I don't know if using it inside an assignment like your second example will actually work because of that, since you can't put a `return` there synatically.) This requires that the function you're using it in has a return type of `Result` with appropriate types. OTOH, `unwrap` will *panic* on failure, unwinding and terminating the entire containing thread, and possibly the entire program depending on compilation settings. You should essentially never use it, unless you are absolutely certain that the value you're using it on is definitely an `Ok` or equivalent. Using it as in your first example is a bug waiting to happen unless `octet` is, e.g. a string from another part of your program that is guarenteed to contain a valid value. You should use some other construct if it's being provided by an external input, even one that you expect to always be valid. (Although which one depends on what you want to do should it not be valid) 
I think you're looking for /r/playrust
haha yeah
Would you happen to have an example? It seems like that will just do a return from the current parser function, and not end the whole parse.
This is the json search engine project Damien Katz (of CouchDB fame) has mentioned a couple times on Twitter in the past. The node bindings (and a bit more) are in the same github organisation. There's also a browser demo [here](https://try.noisesearch.org/demo/1/description) 
I just tried porting forward and it looks like this is fixed! (but there is an `alt_complete!` issue that I already made an issue on github for)
I thought /u/acrichto had a plan to stabilize the panic handling machinery, those aren't even regular lang items but "weak" ones, i.e. on a FFI import and a regular function definition they set a special symbol name instead of having the compiler use them directly. They end up used in libcore through FFI imports - libcore will fail to link unless those symbols are provided elsewhere, I believe.
As a user of a German keyboard, anything that uses the backtick is an abomination in my eyes. To get one in the default Windows config, you have to hit shift+tick (which is next to backspace), and then space. That's because the key is a deadkey for compositing by default. When I write lots of inline code snippets on StackOverflow, I actually put the backtick into the clipboard just that I can use ctrl+v to write one instead of that disaster of a key combination.
I hope not since that kinda defeats the whole purpose of releasing and versioning.
The type of self in `&amp;mut self` is `&amp;mut Self`; your problem is that that you pass an `&amp;mut &amp;mut Self` where an `&amp;mut Self` is wanted. Rust will automatically dereference an `&amp;mut &amp;mut T` to an `&amp;mut T`, which it does. However, in this case, doing this results in a lifetime issue, which may be just the borrowchecker being wrong, I'm not sure.
`&amp;mut &amp;mut Self` implicitly derefs to `&amp;mut Self`. This is because the following impl of the `Deref` trait exists: `impl&lt;'a, T&gt; Deref for &amp;'a mut T where T: ?Sized`. The second case does not work because `&amp;&amp;mut Self` can *not* deref to `&amp;mut Self` (you can't turn an immutable reference into a mutable reference). So the first case works because you're basically just returning the same reference as you got as an argument. The lifetime of the reference in the return value is 'a. The second case doesn't work because the type isn't compatible. The type here is `&amp;&amp;mut Self`, which is not compatible as I explained above. In the third case, Rust implicitly converts the value to the correct type because the `Deref` trait is implemented. However, the lifetime is still not compatible, because the newly-created `&amp;mut &amp;mut Self` reference has a lifetime *shorter* than 'a (specifically, it only lives until the end of the function body).
ARM is lower power and lower cost now. But this is still great because AVR is widespread in Arduino.
thanks for that informative link 
The newly-created `&amp;mut &amp;mut Self` has a lifetime that ends at the end of the function body, which is why you can not return it (or move the value it refers to) beyond the end of the function.
I find Rust to be more rapid to develop in than C, at least that is my general impression coming from thousands of hours of C experience and some small projects implemented in Rust with about a hundred hours spent primarily reading about it and doing simple exercises. I mean right now I haven't maxed out my programming speed with it, but my impression is that I will be more productive with it than with C, because there are more conveniences and less scaffolding primarily. On the down side there are fewer libraries. 
That makes sense. Thanks for answering.
And I'm guessing terming it "flair" came from Office Space, though I don't have a source for that.
&gt; with only one implementation But isn't *that* the impetus? I'm guessing that compiler devs don't want to try to implement a compiler for Rust without a formal specification, but I'm not 100% clear on that. I'd love to see a GCC Rust compiler, and if a specification is a blocker, then it should be a priority.
&gt; This might be biased since all my projects are &lt;200 lines long, they fit imperative programming well and I usually need only built-in libraries (school projects). I think you answered yourself there. A year of Haskell doing 'projects' no longer than a few hundred lines... Even if you've written dozens of projects in Haskell of this length of the year it's probably still no enough to really know the ins and outs of the language. Haskell is concise and expressive, and can do a hell of a lot in a short amount of code. One of the trade offs is that (at least for me) it takes a long time to learn it, coming from a background in OO style languages. Productivity depends on code size. For small projects, dynamic languages will be faster because there is cognitively less to organize and deal with. Languages with good type systems will be better for larger projects (Haskell, Rust, Ocaml, Purescript, Elm, etc) since more time will be spent refactoring code and integrating new code, and you can count on the assurances of the type system to help you there.
My understanding is that the primary concerns​ of Rust are safety, speed and control. Security implies safety because unsafe programs are generally exploitable, but safety alone is not sufficient for security. So adding additional language features for security would be nice, and should​ certainly be possible, but to my understanding is not a *primary* concern.
&gt; and if a specification is a blocker, then it should be a priority. The thing is, the compiler development is driven largely by the community, from what I've seen. If the community deems it a priority, it will happen. If you think it's a priority, you're welcome to start working on it, and I'm sure you will find support from members in the Rust community, but one person's opinion doesn't suddenly make it a priority for other people. There is a ton of work to be done on the one compiler implementation that exists right now, and not enough people to do it, so the people who are working on those things are working on the stuff they individually see as a high priority. Creating a GCC implementation simply isn't a high priority right now, or we would see a GCC implementation. Having Rust be specified would be nice, but [there is this](https://doc.rust-lang.org/book/syntax-index.html) as a starting point.
&gt; 5) Technically, it can be any types implementing the Hash+Clone. I use strings in my example because its easier to read. I personally think using usize (under constants) is a better idea. Could you not just use an enum or unit structs?
Aha, so it *was* (Deref) coercion! It's quite unfortunate that the compiler generates such a confusion error message in that (very specific) case, but I think I understand now. Also, I think you meant to refer to the `DerefMut` trait, correct? `Deref` seems to be implemented for both `&amp;'a mut T` and `&amp;'a T`, but only yield a `&amp;T`, while `DerefMut` is only implemented for `&amp;'a mut T`, but not for `&amp;'a T`, which would precisely explain the second case.
Refactoring in java is extremely well supported by IDEs (intellij etc), is that not the case for C#? 
Just giving possible suggestions
I only need part of socks 5 and I'm going to tailor it to be specific to Tor which has an extended implementation of Socks 
I had a conversation recently that you might find interesting: https://lobste.rs/s/7vqmxt/announcing_rust_1_17_rust_programming#c_zkoumk In particular: &gt; Every few years OpenBSD makes a change to ABI that results in old binaries not running. Everything must be recompiled. It’s fairly complex work just getting libc and a minimal C compiler over the bump, but the end result is a working system with a standard set of utilities like sed and awk and a C compiler and 9000 tar.gz source archives for everything in ports. Somebody types make and 3 days later there’s a pile of packages for all the stuff that can be bootstrapped from C and a pile of smoldering ash for the stuff that can’t. Some languages, those which can be bootstrapped from an older version built from C, survive. Others don’t. ... &gt; Rust does now work on openbsd (at least for amd64) but it involved a lot of heroics. Compiling some things on a linux system, copying to openbsd, running linux binaries under emulation on openbsd, compiling some more pieces, etc. I don’t think there’s any way somebody replicate without tremendous effort. &gt; The plan9 c bits of go are all included. Like luajit makes heavy use of dynasm which is itself written in lua, but luajit also includes a mini lua interpreter in the source to bootstrap. Same with ocaml. The main compiler is written in ocaml, but there’s enough of an interpreter written in C to compile itself. 
My point is more or less that it would be *more* code than Rust for a similar implementation that handles all the edge cases (and perhaps isn't much worse on performance), and you have the whole memory safety issue on top of that - rustc uses stacked arenas, for example (in type inference), which would be an endless nightmare without lifetime annotations checked by a compiler. Sure, there are legacy codebases written in C/C++ - that doesn't mean it's a good idea to add more to their count (that said, /u/burntsushi's comment is very intriguing).
I think having multiple compilers is good in that it means there are two implementations to hopefully catch bugs in the implementation of Rust. Since Rust has some hefty safety guarantees, having two implementations that both provide those guarantees sounds useful, as in bugs in one may not be present in the other and vice-versa (unless there's a bug in the specification). However, the more immediately practical use case is to have multiple options for codegen, which is a much easier goal to meet.
&gt; However, the more immediately practical use case is to have multiple options for codegen, which is a much easier goal to meet. And requires no reimplementation of most of the compiler, just writing a backend to lower MIR to whatever you need.
&gt; Out of my ass, I would say 10 years for an ISO standard. For reference it took Ruby 17 years to get an ISO standard, and it took C++ 19 years (or 15, if you count from the year "C with classes" was renamed to "C++"). C took 17 years. Pascal took 20 years. So between 15 years and 20 years would be a good guess.
Just a note, as a technical lead, I ignore anything that's GPL and think hard about LGPL (will only use it if it's vastly superior to other options), even if those options have an option for a paid license, especially with things like this where I can use GTK or QT, both of which are LGPL. You're definitely limiting the appeal of your library using the GPL and it would have to be *really* good in order for me to invest my time into something that I cannot ship in a proprietary project (why learn a library if I can only use it in open source work?). Of course, use what you want, but unless you change the license, I and many others will simply pass on it, even for open source projects. I don't like dependencies determining what license my code uses, and I typically release my code as BSD, MIT, Apache or some other liberal license.
Yes, I believe I meant `DerefMut`.
By using the `&amp;mut self` syntax in the struct initialization, OP is creating a new reference to `self`. When you create a new reference like this, its lifetime ends at the end of its scope.
That's a good point.
Refactoring within a single class is handled by refactoring tools, but re-organizing what classes you have isn't.
If it takes ten times as long to write those 200 lines, then you're not more productive.
yes, but then I'd have to define an enum. I want to keep the example as short as possible.
That's not really suitable as an introduction to the subject.
This is just to point out how easily one can utilise an asynchronous [Tokio/Futures](https://tokio.rs/) API in a blocking manner if need be.
&gt; The return value from ? will still terminate the current function rather than set a variable in the struct right? I mean, it would be of the wrong type anyway. The `TcpStream::connect(addrp)?` expression has _one_ type, always. Because, as other people explained, it expands to a match expression, which either "unwraps" the `Ok` value, or returns the `Err` value, so the type of that expression is whatever the `Ok` type is storing. (e.g. if you have a variable `x: Result&lt;u8, ()&gt;`, then the type of `x?` will be u8.) I just want to make sure you don't think there's more magic here than there is. Your example above is equivalent to: let socket_result: TcpStream::connect(addrp); let socket = socket_result?; // Return if Err, otherwise "unwrap" the Ok value. let mut con = TorCon { socket: socket };
I'm not rabble-rousing - I understand the incredible amount of work that would be involved in a specification and that we're unlikely to see one for a long time, and I'm okay with that. That being said, I wanted to chime in with a bit of a +1 here because a lot of the time when I hear people talk about specification it's about making it easy/possible to implement other Rust compilers, rather than making it easier/possible to verify the one that we have. To me, the latter is a much more compelling use case, as it opens up entire industries that are currently unavailable to Rust. So while it's in some sense true that "there's barely enough community to sustain one Rust compiler, let alone two", that's not a good argument for delaying standardization, and I'd really like to see that community keep an (eventual) standard in mind as a high-level goal.
Yes I think it is a question of how much of a focus on security is Rust going to have. Initially I was under the impression that it was specifically targeting security as a primary goal. Upon learning it to some extent and researching more about it, I see that this is the case from the perspective of someone who is not writing security software, but rather is writing software that they would like to be secure. For writing secure software I see Rust has quite a lot of features that make it compelling, but I hope that they focus on being a language for writing secure _security_ software as well, and for mission critical software, for me security had that connotation when I first started learning Rust but now I see that perhaps a more lay understanding of security oriented was intended (ie: writing secure generic software, as opposed to writing specialized security software). I just hope that the intention is actually to target security software such as Tor, GPG, OpenSSL, and so on, rather than to write generic software securely, I mean these have a huge intersection but Rust is lacking somewhat when you move into the specifically writing security software area it seems to me. Not to go on and on but in general I would like for it to focus on areas long neglected in C such as securely clearing memory and the other things I've already covered, as well as have a formal specification so the compiler can be verified and it can be used for mission critical software. 
I think it really depends on how long it will take to fix all of the common code generation bugs in the backend. As we fix issues in the AVR backend, more and more crop up. I think that once the AVR backend is a bit more stable, we can definitely look at upstreaming. 
&gt; but to my knowledge they opted to no longer do so because reproducible builds are not currently possible I haven't heard this, do you have a citation? We try to make Rust reproducible generally, but bugs happen.
&gt; though its more verbose equivalent `.expect ("more detailed panic message")` still might be better It *is* better and should be prefered over `.unwrap()`.
I don't have a citation but I heard it in an IRC channel associated with the Tor development community, related to #tor on irc.oftc.net, though the individual I heard it from is not a Tor developer he is familiar with the community and I imagine his statement to me was correct. https://users.rust-lang.org/t/testing-out-reproducible-builds/9758 Shows the current progress of reproducible builds in Rust, it isn't all the way green yet. Reproducible builds in this context means exactly bit for bit reproducible binaries that will produce the same cryptographic checksum even if built by different people on different systems. 
Thanks for the feedback and particularly for noticing I should have used .len() instead of .chars().count(). Also request.extend(dst.as_bytes()) is much nicer so thanks for teaching me that I will need to read the man pages for it but I can already tell what it is doing :). 
&gt; safety critical programming I assume by formal specification you mean actual mathematical specification via formal methods? (There are very few languages that are completely formally specified, usually folks use formally specified subsets and even those are few. E.g MISRA-C). C does not have a formal specification in this form. It does have a spec. The spec does not add to the safety of C code; it just gives certain guarantees. &gt; such as say attributes to instruct the compiler that a certain piece of memory needs to be cleared on deallocation You can achieve this by putting things on the heap and then force clearing it in a destructor. https://github.com/rust-lang/rfcs/pull/1496 is an RFC for this, and https://github.com/cesarb/clear_on_drop is a crate that makes this work on the stack, kind of. &gt; Also I've heard it isn't sufficient for cryptography really yet because some things cannot be guaranteed in constant time C can't give you this either. All CT stuff is usually written in assembly. There are alignment APIs; the problem is that you can't guarantee the optimizer won't mess things up. (If you're using the system allocator you can just call `posix_memalign` directly and wrap it in safe functions for constructing boxes and vectors. I think you can do this with jemalloc too but not sure) Note that you're conflating two different kinds of "safety critical" things here; the formal specification stuff is a completely different field of safety critical. Crypto software is not typically written in formally specified languages. Crypto software is written in good 'ol C and C++. In the same vein, critical aviation/defense code is not CT. &gt; but it hasn't got as much security oriented development in some areas as C has, the end goal is to have all of these security features and to have a formal specification right Almost everything that you said applies to C too. It doesn't have a formal specification (subsets like MISRA do). It has a spec; yes, but I mentioned why that's not really relevant here. It is conceivable that we could come up with a subset or variant of Rust that has the same properties, The two key differences here are that C does expose inline assembly on compiler releases (though it's not actually specced IIRC, these are extensions), whereas Rust has it unstable for now. The second difference is that you can get reproducible C builds with certain compilers IIRC. I've tried to get Rust inline ASM stabilized before but it involves stabilizing the assembly macro syntax. The problem is that the exact behavior isn't stable in LLVM, or in clang, but clang exposes it in releases anyway (Rust doesn't expose things that can change in releases). ----------------- To answer your questions: There's already work going on on formal verification of Rust. It will take time. No idea if this will end up with a formal spec. Reproducible builds -- not a priority but I think some folks are looking into it as a student project. A spec for Rust may take a while, because the language is new and in flux. I think the first leap in the right direction would be the stuff the unsafe semantics team is working on, since it would probably end up specifying a lot of the tricky bits of the language. Specs take forever. It will be many many years before Rust can target something like the aviation stuff where MISRA C is used. Crypto code; you can do that _now_. Multiple people have told me that [ed25519-dalek](https://github.com/isislovecruft/ed25519-dalek) might be the best ed25519 lib out there. Mostly because the optimizer output has been inspected, giving better CT guarantees.