&gt; This sounds way too complicated, am I imagining it? Yes; it's simply returning a `Tree` that has `root` set but is otherwise empty.
Specifically for build paths, please let's trip them by default. My ideal format is `&lt;lib/bin-name&gt;/&lt;relative-path&gt;`; I really don't need a 100 characters telling me that it was build in some long forgotten cache directory.
FWIW https://github.com/rust-lang/rust/pull/41508 already fixes this for debuginfo at least. idk if cargo uses it yet
After you've read through the official [Rust Book](https://doc.rust-lang.org/book/first-edition/), take a look at http://cglab.ca/~abeinges/blah/too-many-lists/book/
Hey, Congrats on the release. I just wanted to say that I just decided to take a look at Gotham and try building a simple hello world. I have to say that after 10 minutes I've just given up. The router code, although understandable with the comments, feels way too complex. I feel this is currently a very strong adoption issue. There needs to be a way to have a simple hello world in just one file and under 50 loc. Again, keep up the good work as this is promising. Just giving out my opinion out there.
I think you could achieve that by using conditional compilation. At the top of the file that represents your module, just add a `#![cfg(ignore)]` and it won't be compiled. Note that `ignore` is not a keyword, you can actually use any non-reserved word instead.
&gt; This is tricky. The exact syntax for inline asm (including supported instructions, clobbers, etc) is not stabilized in any compiler I've always been under the (probably mistaken) impression that the instructions themselves were just passed directly to the system's default assembler. You obviously need some additional work done to make sure things end up in the right registers and to unclobber registers and such, but these seem like things that are relatively easy to stabilize. What is impossible to stabilize is the actual instruction set, since the available instructions vary from CPU to CPU even within the same overall architecture, not even mentioning the impossibility of stabilizing the totality of instructions from all architectures in existence. In the past, I've worked with assembly in a standalone fashion, or not at all. Inline assembly is something I recognize the need for, but something I have personally managed to avoid needing, simply by avoiding projects that would need it, except for an occasional no-dependencies instruction like `wfi` on a microcontroller.
You've seen... sure. In general, though. You're way more likely to find clean python code than clean assembly code. The language helps raising the barrier of entry for good documentation and design.
That gets really annoying when I take the parent module back in and want to ignore all its submodules and take those back in one-by-one. Honestly, everything that moves that control away from the parent module is going to be a loss of ergonomics for me.
I wrote an npm installer in Rust; heh, no good reason why, just for my own exercise and the fun of it. Some unique things about it are it doesn't flatten the directory structure (so like npm v2) nor run scripts. It also checks tarball paths to make sure directories are relative paths only. Not sure if other tools do that, but the Rust tar package made that easy to do. It works somewhat well but is not parallelized whatsoever so it's quite a bit slower than pnpm/yarn/npm. It does cache, though. (Of course, would be interesting to compare performance if it were ever optimized to that level.) Main problems are the semver crate doesn't support all the same semvers that occur in npm though, e.g.,: Version 2 || 3 || 4 || 5 of semver didn't parse ( due to issue https://github.com/steveklabnik/semver/issues/57 ) And I didn't implement support for npm private namespaces so some packages can't install all their deps yet. 
Can't you just have these files outside of `src`, in their own directory?
I like responsiveness, but when my desires are anticipated I feel spoiled :D
Did anyone get rls to work in emacs? I created a spacemacs layer https://github.com/MaikKlein/rustrls but I get the following error &gt;error in process filter: Error parsing language server output: (error Couldn’t guess message type from json-data) [2 times]
I am not sure, but my guess would be for `git` deps, maybe you haven't used one of those in a while? Regular dependencies are not fetched from github, so putting them in a folder named so would be weird.
Your question is super unspecific! I don't know how to answer it and i don't expect anyone else does. We don't know your background or what your goals are – you're asking for the impossible here. We love to answer questions, if we're able to. I mean without being sarcastic the answer could be that you have to have at least a little knowledge about programming, how the http protocol works, how network works, at least a rough idea how Rust works ... You see – the domain of possible answers that would fit your question is to large to gain anything meaningful out of it. We love to help, but you need to be a little more specific of what you really want. 
Yeah you are right. Sorry, the question is really poorly worded. I just assumed everyone would get what I meant without putting much thought into it. I am just looking to know Rocket specific things, like what are there any gotchas or if anything different about rocket compared to the popular node frameworks like koa, express or python's flask. I will edit the question. Thanks. :D Should I add anything more?
It think it might be beneficial for rustc to support an intermediate stability mode that exposes unstable features to stable users that are unlikely to ever be stabilized (native TLS, inline ASM, ..etc) with an explicit opt-in mechanism to enable them. Something between Stable and Unstable. These unstablizable features are more akin to unabstractable implementation details (of the underlying system) than that of language features that are still under development. I believe it's a mistake to treat them both in the same way. Allowing stable users to `feature` into using these features seems like the most pragmatic way to solve these issues. (That, or shipping a C compiler with rustc and making c part of the rust language. I'm half kidding.)
This would quite useful for what I'm working on and a faster npm as a cargo plugin/command would be awesome.
Yeah, it'll be fine for a solution - just does make things initial stage a breaking change if it starts loading all source files.
Coalescing ring buffer is Single producer single consumer lock less DS so I need to impl Send Sync. KeyCell is ever being written by only one thread, so I think the borrow and set will not occur concurrently.
Yeah maybe the asm syntax isn't so problematic, it may just be the clobbers and stuff. But I'd expect llvm to try and understand the asm too. Idk.
&gt; Is relm usable on stable Rust? &gt; Yes, it is! Are you sure? `relm-attributes/src/lib.rs` contains `#![feature(proc_macro)]`, without which none of the examples seem to work. This is just me playing around for five minutes, so I may be doing something wrong.
Personally, I have three of them, and none of them are up to date. Confusingly, when I strace cargo, I see it accessing the middle one (not the most up-to-date one), but it... doesn't seem to actually update it. It seems to be directly reading pack files, so maybe it's somehow looking at the files without unpacking them? As a side note, I wish cargo would delete the caches that it doesn't need.
I think Rocket is much similar to frameworks in other languages, like spring in Java. I like Rocket, some wired names though like Rocket, ignite, fairing and it requires nightly. 
I said [here](https://www.reddit.com/r/rust/comments/6ts036/whats_new_in_relm_0100/dlnmj4v/) that the `relm-attributes` crate is only to be used when you want to use nightly. And I explain to look at the [`buttons-derive` example](https://github.com/antoyo/relm/tree/master/examples/buttons-derive) which work on stable.
&gt; Nickel […] After the Github graphs of the projects listed in http://www.arewewebyet.org/topics/frameworks/ I got pretty depressed that most of these Web framework's lifespan is only 1 to 2 years. What happend in October 2016? Motivation blackhole?
Thanks. The output was not very helpful but reinstalling rust and rls finally fixed the issue. RLS is already impressive.
Why should I not be allowed to?
I would guess so, but I have had no use for that yet, since I use domafic to build the DOM
It's not the same. C# has namespaces and an heavily integrated IDE. Rust is often used without an heavy IDE but still allows precise control over the module structure, in-code, which is quite useful when you're moving code around all the time.
Futures-rs and Tokio started going in earnest. Meant a lot of big changes to the ecosystem web frameworks sit on.
You can also put the lib in a subdirectory of src, like `src/lib` or `src/project-name`
Still working it out myself, but if you're on nightly this works https://play.rust-lang.org/?gist=210ce0420c3abd72a92110467b0cb5db&amp;version=nightly
I think you might be in the wrong subreddit, bud.
I'm not saying you shouldn't be allowed to, I'm just asking what the use cases are. 
The `..Default::default()` part was a bit confusing, I have to admit. After a while you get used to it and it will become second nature. In this case, the benefits are negligible, but for bigger structs it's super helpful and safes a lot of typing for both, the library user and the maintainer. Should have explained that in the post. May I ask why you consider `root: root` to be poor form? I thought it was pretty much the standard way to initialize a struct? 
Thanks for your all your efforts! Now supporting you on Patreon!
I don't know anything about wincred or other Windows-specific details. For information on credentials and credential helpers, please refer to: https://git-scm.com/docs/gitcredentials If you want to clone over the HTTPS protocol, it makes no sense to use `github_rsa` because SSH is not involved at all. The HTTPS protocol expects only username and password (or sometimes [personal access tokens](https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/), depending on how your GitHub account is set up).
As of Rust 1.19, Cargo no longer checks out all the files, but instead works with the git objects directly (see https://github.com/rust-lang/cargo/pull/4026). If you have a bunch of files in the "index" directory, those are probably relics from using an older version of Cargo.
/r/playrust
If that's the case, those methods should be marked unsafe
&gt; I would say that `rustgo` looks to be over the 50% mark on its way to production usability nononononononononononono D:
&gt; but if you're on nightly I'm on stable I spend some time trying to understand how to do basic things with `future-rs`, but failed beside implementing the `Future` trait for a custom type. I really appreciate your help, your awesome :)
Production usability doesn't mean that it would have every desirable feature! The work done so far *does* things, it just needs to be a little cleaner and safer! haha
No problem, I've just been trying to figure out this stuff for something I'm working on. The documentation is good, but lacking in examples.
Great stuff, just a few questions, to understand the current status of the project. How does pure rust part compares with, for example, Eigen, performance-wise? Are BLAS subroutines made with vectorization in mind? Which algorithms are used for QR and SVD? 
Great work! Btw, when would you recommend this algo compared to OPTICS and HDBSCAN?
Right now I use `rayon` and thought after reading [this](http://blog.danlew.net/2017/07/27/an-introduction-to-functional-reactive-programming/) very good blog post about FP and reactive programming (Java), that I should give `future-rs` a try.
Those docs are in a class of their own. They even explain each decomposition graphically, amazing!
Oh that's neat! Any idea what I can delete?
If you just delete `registry/index`, the next time you run cargo it will check out a fresh copy of the index, which should be about 80MB smaller. However, if you ever run an older version of Cargo, it will extract the files again. As for `registry/cache` and `registry/src`, I think those are safe to delete at any time, it will just need to re-download any dependencies it needs in the future. 
I'm actually not terribly familiar with OPTICS or HDBSCAN, but the principle difference as I understand it is that `kodama` can work with any pairwise dissimilarity (it doesn't even need to be a distance). That is, its input is a dissimilarity matrix, not a set of points. There's some good material on this page: http://scikit-learn.org/stable/modules/clustering.html
I'm getting started on Rust. Wish me good luck!
I've no idea about what hierachical clustering is or how it works, but I really like that the crate has c and go bindings. This is much better than reimplementing an algorithm for each new language.
There's a relatively small example that uses simple data that might shed a little light on what it is: https://docs.rs/kodama/0.1.0/kodama/#example :-) The [original implementation of these algorithms is in C++](http://danifold.net/fastcluster.html), but isn't really available as a standard C++ library. Instead, it's more like a combination of Python and R libraries where the ffi all bleeds together. I wrote this library so that we could more easily use the algorithms from Go at work (hopefully some day soon), and to learn more about the implementation in case we want to customize it.
Bon Boulot ! ;) As someone who tried to implement a camera calibration tool in Rust I was pleased to use nalgebra. Still I found that those matrices factorizations were lacking and that was a bit painful. This is a very welcome addition. And by the way, you have now one more supporter on patreon. 
You mean the methods of KeyCell? And will it help the error? 
Wow, congratulations and thank you for an awesome package. It has come a long way since the last time I looked. And the documentation is very impressive!
I suspect there's a good reason for you having done it the way you have, but why do handler's take `State` as a parameter. It seems to me that they could take `&amp;mut State` instead, and then the state wouldn't need to be returned?
I am planning to write more test cases for my tiny project after my struggle with unsafe code [unsafe code](https://www.reddit.com/r/rust/comments/6tt4sf/help_please_struggling_with_unsafe_code/) is over
Thanks for the feedback here. We certainly agree that the Router, if left in the current form, would be an adoption issue. The good news is that this the main focus for 0.2. We'll be addressing the issue through builders and macros. I believe we can end up getting this to be very similar to what you'd see in Rails/Phoenix. In the interim, Gotham can be used without the Router at all for something simple like a hello world. Would an example of this be of interest?
You may be able to store a tuple of `(&amp;'a Node&lt;'a&gt;, Rc&lt;usize&gt;)` rather than just the Node. I haven't really thought this through though, so maybe someone else will have a better suggestion.
Ah yeah - that'd probably be an even better solution
I'd have a look at implementations to begin with such as: https://github.com/SimonSapin/rust-forest and https://github.com/bluss/petgraph And have a look at how they handle this. Although if you go at it your own route you may discover a novel way. 
Does it work on Windows too?
If it's a small number of nodes or is highly connected, just storing the graph as a matrix of weights can work well. If there are fewer edges then maybe using a matrix format designed for sparse matrices would work well. Some graph algorithms map to matrix math in this form. If you want to use graph like data structures, then http://cglab.ca/~abeinges/blah/too-many-lists/book/ Is a good intro, even though it says linked list, the methods are mostly the same between a singularly linked list and directed acyclic graph. And a double linked list's are similar to a regular graph. If you just want to modify ref_graph I think you would change edges: UnsafeCell&lt;Vec&lt;&amp;'a Node&lt;'a&gt;&gt;&gt; to something like edges: UnsafeCell&lt;Vec&lt;(&amp;'a Node&lt;'a&gt;, f64)&gt;&gt; Probably better with an edge struct rather than a tuple. But ref_graph uses unsafe, which should be avoided until you have a fair bit of experience in rust and have read through the rustnomicon. They're are a few trivial cases of unsafe that aren't too hard to do correctly, but a graph structure is not one of those. The usage of UnsafeCell is critical for the correctness of ref_graph, and I would suggest you avoid touching it until you've at least learned enough to know why. 
Rocket does support shared mutable State: https://rocket.rs/guide/state/?q=&amp;hPP=15&amp;idx=guide&amp;p=6 https://api.rocket.rs/rocket/struct.State.html https://github.com/SergioBenitez/Rocket/tree/master/examples/state There are also many websocket libs, like ws-rs, tungstenite, tokio-tungstenite etc.
By implementing `Sync` for `CoalescingRingBuffer` you actually made it multi-producer multi-consumer, because nothing prevents me from creating 5 or more threads and use your structure in all of them simultaneously. As a library author you should try to make your API safe to use. And that means it should not be possible to cause undefined behavior by using your data structure in a safe code. Even if your user tries something stupid, like sharing your spsc data structure across 5 threads, it should not cause data races. There are 3 ways to provide such guarantee: 1) Encode the rules using types and traits. Make it so that incorrect usage of your library will cause a compilation error. For example look at mpsc channel in stdlib, its designed in such a way that only one thread can receive data, but many threads are allowed to send it. And this is all checked at compile time. 2) Check your invariants at runtime and panic (or return error) if user did something wrong. This can cause a negative impact on the performance, but sometimes is necessary because not every rule can be expressed in type system. For example converting from byte slice into String requires a runtime check to verify that it doesn't contain invalid utf-8 sequences. 3) Make your API unsafe. Unsafe blocks will be required to use your API, and now the user will be responsible for maintaining all the necessary invariants.
&gt; May I ask why you consider root: root to be poor form? I thought it was pretty much the standard way to initialize a struct? I guess this is personal preference, I have issues in Perl where people use a variable of the same name but different type, because even though it is legal it is behaving like a different variable and I like to see a different name to make that very clear. In this case I'd prefer more visual separation between the struct member and the method parameter - even if it was a single letter - just so when I go searching for that variable name I can find it declared at the top of the method. Others will have different opinions, of course, there's not just one way to do it, but if I'm tired and reading somebody else's code I like to have as explicit as possible nomenclature to prevent my own errors of interpretation.
I just published a rust-powered, cross-platform (thanks to rust!) version of `tac`, the coreutils utility that prints files in reverse order: https://github.com/neosmart/tac (`cargo install tac`) It might outperform the original, I haven't benchmarked it yet. My biggest reason was because I needed `tac` on FreeBSD to analyze a 30GiB access log. Earlier this week, I published [`rsproxy`](https://github.com/neosmart/rsproxy), composed of [`tcpproxy`](https://github.com/neosmart/tcpproxy) and [`udpproxy`](https://github.com/neosmart/udpproxy) which are configuration-free command-line TCP and UDP proxy servers. Yesterday, I updated `tcpproxy` to use tokiocore for better performance (no more spinning up threads for incoming requests). Again, haven't benchmarked it, but it should be a real screamer. This was my first time using tokiocore (it's painful!), anyone interested in a real-world example should have a look: https://github.com/neosmart/tcpproxy/blob/master/src/main.rs I hope to port `udpproxy` over to tokiocore this week as well.
It'll require all consumers realize there's a memory safety contract not imposed by the compiler. That helps find the error because then we know the issue is in unsafe code, whereas currently it could be anywhere
How to run too loops within one event-loop with futures and tokio-core? ``` fn main() { let mut core = Core::new().unwrap(); let handle = core.handle(); let loop1 = future::poll_fn(||{ println!("hello form loop 1"); match a_random_number() { 5 =&gt; Ok(Async::NotReady), _ =&gt; Ok(Async::Ready(())) } }); let loop2 = future::poll_fn(||{ println!("hello form loop 2"); match a_random_number() { 7 =&gt; Ok(Async::NotReady), _ =&gt; Ok(Async::Ready(())) } }); // now what to do? } ``` The output should print randomly `hello form loop 1` and `hello form loop 2` over and over again... but how?
On Issues, here's 2 relevant RFCs: [RFC 1624: `break` with values for `loop`](https://github.com/rust-lang/rust/issues/37339) &amp; [RFC for module redesign.](https://github.com/rust-lang/rfcs/pull/2108) Which includes implicit extern crate
I'd like to extend an existing type in the std library. Namely to do: impl std::ops::Add for Ipv4Addr { /* ... */ } impl std::ops::BitAnd for Ipv4Addr { /* ... */ } // ...etc. But I get the error *error[E0117]: only traits defined in the current crate can be implemented for arbitrary types*, which I take to mean you can only do impl {} for types that you define in your own crate. Is there any trick to work around this (e.g. I thought maybe I could alias the other type but that doesn't seem to work)? Or what is the idiomatic way to build on another type without re-implementing it? 
 trait Simulator: Sized { type Phenome: Phenome&lt;Genome = Self::Genome&gt;; type Genome: Genome; }
Thanks for having me on as a guest! It was fun :) As I said in the episode, this RFC ([link](https://github.com/rust-lang/rfcs/pull/2071)) is super important. It greatly expands the expressiveness of `impl Trait` and allows returning `impl Trait` types from traits. I'd love to get some more critical feedback so we can make sure the design is as solid as possible. If you're reading this, please take a moment and read the RFC and share your thoughts. How do you want to use `impl Trait`? Does this RFC solve your problem? Is the solution intuitive? Thanks, all!
Implicit `extern crate` is actually a separate RFC. You can find it [here](https://github.com/rust-lang/rfcs/pull/2088).
The latest `impl Trait` RFC is [here](https://github.com/rust-lang/rfcs/pull/2071). I also spoke about it on the [Request for Explanation podcast.](https://www.reddit.com/r/rust/comments/6tyeff/request_for_explanation_8_an_existential_crisis/) This is a really major addition to the language, and it hasn't been getting enough attention. If you have a chance, please read through it and let me know what you think! :)
So make `Genome` a type parameter of `Phenome` and `Simulator` rather than an associated type? My original thinking was that Phenomes aren't really generic over Genomes, at least by the traditional genetic algorithm metaphor. And my concrete implementations of Simulator already have 2 or 3 type parameters each. So I went with the associated type. But this does accomplish my immediate goal, so I'll definitely try it out and see how it feels. Thanks!
I should have said: it's a flat list of entries, so build_subcomponent_x consumes some of them (the first entry tell how many sub are ahead) and builds a list, and keeps going like that, recursively. THx
No, its still an associated type. You can specify what the associated type has to be using that syntax, as in `Iterator&lt;Item = u32&gt;`. This specifies that the Phenome's Genome must be the same type as the Simulator's Genome.
The best option you have is to use a wrapper struct: pub struct Ipv4Addr(std::net::Ipv4Addr); impl std::ops::Add for Ipv4Addr { ... } // Probably want from/into as well impl From&lt;std::net::Ipv4Addr&gt; for Ipv4Addr { ... }
`cargo run --example clock` is fine. I added `futures_glib::init();` to my `main` function and it worked.
Smaller update: Ran it by my coworkers, content was good, delivery was great, just need to cut it down for 30 minutes. I'll probably have more of the long form notes released after RustConf and a blog post about it all.
I'll give that a try. Thanks :-)
From what I understand, Windows has a pretty good story for async local-file I/O, but its API is naturally Windows-specific. POSIX does technically have an API for async I/O with files, but it is clunky and terrible. In particular, it's not the obvious "just pass the file descriptor to `poll()`" API you might expect, you have to set up a whole separate async structure, and you are notified of completion not by the readiness of a file-descriptor, but by the kernel sending you a POSIX signal¹. Since most libraries want to be at least basically cross-platform-compatible these days, and since POSIX doesn't have an async file I/O API worth mentioning, cross-platform code generally sticks to synchronous file I/O. If you really, really need to do something concurrently, stick the file I/O in a thread-pool. [Here's a blog post where a libtorrent author describes why you shouldn't use POSIX async I/O](http://blog.libtorrent.org/2012/10/asynchronous-disk-io/) ---- ¹: I can't find a citation right now, but I read once that when POSIX wanted to add an async I/O API, only one Unix vendor had anything of the sort. So the POSIX people took that API to the database vendors who were the most likely users of an async I/O API, and said "Is this API well-designed? Would you object if this became the standard?" and the database vendors said "We don't care, we're going to keep bypassing as much of the kernel as possible with `O_DIRECT` and doing the work ourselves so we know it's done right." And so the terrible API went into the standard as-is.
You can store it in a struct and pass the struct around
my understanding is that there's no support for it. spawn a thread per. I think it's really silly and arguments against support for it are as thin as they come.
Oh! Ok. I knew the syntax for specifying an associated type as a type parameter, but I never thought to use it like that. How does the compiler know that when you use `Phenome&lt;Genome&gt;` that the parameter refers to the associated type? I would expect something like this: trait Simulator { type Phenome&lt;Genome=Self::Genome&gt;; type Genome: Genome; ... } Which seems like it should work, thanks! I'm afk, so I'll look into this tomorrow. **Edit:** It works! The downside now is that implementors must add two associated types, when really if the `Phenome` is given then the `Genome` is deterministic. So I'm trading long types and bad error messages for boilerplate. I think this is OK, especially since I expect 99% of users to never need to implement `Simulator` themselves. And in theory, I think something like Chalk would be able to infer the `Genome` type, because it's deterministic, and maybe in the future the boilerplate can be elided. **Edit 2:** I see your example is exactly like mine. I think the app on my phone messed up the formatting when I saw it and got me confused.
If `fld` is a copy type, you could dereference it in the while binding, and then `iter` will no longer be borrowed for the length of the block while let Some(&amp;fld) = iter.next() { .... }
that did the trick! thanks struct Carry&lt;'a&gt; { pub iter : &amp;'a mut slice::Iter&lt;'a, Entry&lt;'a&gt;&gt;, } 
I didnt know that. thanks. Not a copy type on my case as it holds an u32 (ok) and a String (dont want to duplicate it)
A good overview on the subject is: https://www.nginx.com/blog/thread-pools-boost-performance-9x/ The thing to keep in mind is reading/writing from file handles on a non-blocking socket is basically a memcpy between you and the kernel. For file descriptors this is actually reading/writing from disk which is much slower and you're blocking socket operations waiting for disk. 
thanks for your guidance
&gt;I am a real noob in programming stuff, Then you probably should not use tokio/futures quite frankly. 
Steel?
Suppose I usually want a 404 but something custom on some routes, is that possible? This is very common where I work 
The actual code is more complex that this, it has several states, and in the ```match``` statement, it has several ```if``` statements inside, then it means the code is a bit unclear, every ```if {} else {}``` has to return a state even the state has not been changed.
Thanks for the link, I'll take a look. 
I have binaries for Windows, but I have yet to test it on an actual Windows machine since I don't have one :)
So I should not even attempt to learn shiny advanced things? :'(
I think you should be able to find answer with https://tokio.rs/ I agree with /u/frequenttlywrong that futures is not the easiest topic to tackle and you should probably not use it too soon. Try using higher level crates first to learn basics.
At this rate, the ecosystem will remain perpetually young and never have a chance to mature. Stability (even for flaws) is very, very valuable for people who want to build large systems. C remains popular for this exact reason. I thought the folks behind rust understood this when they advertised stability as a language feature. I'm not sure anymore. 
Shiny things tend to loose their luster when experienced up close. Tokio is a framework and frameworks should always be looked at with suspicion and kept at a distance.
Good luck! :)
You kind of shot yourself in the foot by calling yourself a "real noob". To interpret /u/frequentlywrong's comment charitably: it's not that you can't learn shiny advanced things, it's just that if you *are* a noob, there are so many *other* things you're going to need to learn *first*, that it could very well be counterproductive for you to start on an experimental, work-in-progress stack.
You have to be on nightly, now go build something :)
You can combine futures with one of the various combinators on [the `Future` trait](https://docs.rs/futures/0.1.14/futures/future/trait.Future.htm) and then pass it to `Core::run()`. I would recommend this: core.run(loop1.join(loop2)); However, as you've written them, your loops will only be polled until they return `Ready`, which looks like it will happen more often than not. The `.join()` combinator will poll each of them until they individually return `Ready`. Also, if you're actually returning `NotReady` and not polling a future internally, then your loops won't be called again after that, or at least not consistently; the implementation has to be notified when the future is ready to move forward. I believe you can make this work just by pre-emptively notifying the task as such: use futures::task; let loop1 = future::poll_fn(||{ task::current().unpark(); println!("hello form loop 1"); match a_random_number() { 5 =&gt; Ok(Async::NotReady), _ =&gt; Ok(Async::Ready(())) } }); let loop2 = future::poll_fn(||{ task::current().unpark(); println!("hello form loop 2"); match a_random_number() { 7 =&gt; Ok(Async::NotReady), _ =&gt; Ok(Async::Ready(())) } }); (If you're actually calling into another future then don't do this as it will waste CPU time polling futures that aren't ready to move forward.) If you want your loops to be called perpetually, though, you need to make them into a stream instead. A stream will continue to be polled if you return `Async::Ready(Some(()))`. Unfortunately, there's no stream equivalent of `poll_fn`, so you have to create your own: struct PollStreamFn(F); impl&lt;T, E, F&gt; Stream for PollStreamFn where F: FnMut() -&gt; Poll&lt;Option&lt;T&gt;, E&gt; { type Item = T; type Error = E; fn poll(&amp;mut self) -&gt; Poll&lt;Option&lt;T&gt;, E&gt; { (self.0)() } } let loop1 = PollStreamFn(||{ task::current().unpark(); println!("hello form loop 1"); match a_random_number() { 5 =&gt; Ok(Async::NotReady), _ =&gt; Ok(Async::Ready(Some(()))) } }); let loop2 = PollStreamFn(||{ task::current().unpark(); println!("hello form loop 2"); match a_random_number() { 7 =&gt; Ok(Async::NotReady), _ =&gt; Ok(Async::Ready(Some(()))) } }); Finally, the streams need to be combined into a `Future` to be executed, so we have to combine our two loops, which can be done with the combinators on [`Stream`](https://docs.rs/futures/0.1.14/futures/stream/trait.Stream.html), but we have to pick one matching the semantics we want: * `loop1.merge(loop2)` causes both streams to be polled each time it is polled, so they will always print in-order: &gt; hello from loop 1 &gt; hello from loop 2 * `loop1.zip(loop2)` will poll the streams individually until each returns `Ready`, so if one of them returns `NotReady` then it will be polled repeatedly until it yields a value. Then finally you can trivially convert them into a future and execute them by adding `.for_each(|_| ())`: core.run(loop1.zip(loop2).for_each(|_| ()))
Will it be extended to also allow generating server code?
How does the reference VS Code extension compare to the other one? Are there any plans to replace one of them?
It is, right down the individual `Route` instance. This is all controlled by the `struct` your application defines to have the Request Path or Query String extracted into and how it implements the `StaticResponseExtender` trait. We offer a default `StaticResponseExtender` implementation that can be [dervied](https://github.com/gotham-rs/gotham/blob/master/gotham_derive/src/lib.rs#L28) to ease implementation for folks. The default simply responds with 400 Bad Request. You can see our example app using the derive approach [here](https://github.com/gotham-rs/example-app/blob/master/src/controllers/challenge.rs#L11) and [here](https://github.com/gotham-rs/example-app/blob/master/src/controllers/challenge.rs#L16). Send the `count` parameter a String using curl, you'll see the 400 response. Alternatively, by implementing the [`StaticResponseExtender`](https://docs.rs/gotham/0.1.0/gotham/router/response/extender/trait.StaticResponseExtender.html) trait yourself instead of deriving it you can do whatever you need when extraction fails due to an invalid Request. For your needs that would be to respond with a 404 and perhaps some kind of default body content in most cases and something special when necessary.
I would like to see some well commented ASM
Thanks a lot! 
Apologies I missed this question the other day. You could implement [`PathExtractor`](https://docs.rs/gotham/0.1.0/gotham/router/request/path/trait.PathExtractor.html) or [`QueryStringExtractor`](https://docs.rs/gotham/0.1.0/gotham/router/request/query_string/trait.QueryStringExtractor.html) if you wanted to instead of using the derived versions that make use of `From[Path|QueryString]` and can populate into a `Vec`. If you do go down this path I'd be really interested to talk about your implementation.
It would for me and I would say probably for others too for sure! The simplest code to have a server responding to requests is good to have people want to keep digging.
Use program arguments. So your binary is run with: yourapp --libdir=/etc/myapp/ And if libdir arg is not present, use defaults.
Might want to check out this blog post by Niko (Rust language designer) http://smallcultfollowing.com/babysteps/blog/2015/04/06/modeling-graphs-in-rust-using-vector-indices/
Huh. I haven't actually had to think about how that's accomplished in other languages before, since the build/installation automation always did that for me. I don't have any cargo-specific experience, but perhaps you could use the value of `CARGO_MANIFEST_DIR` if set (so it's always guaranteed to work via `cargo run`) and fall back to one of the following: 1. Use a `build.rs` to read the value of a `PREFIX` environment variable at compile time (default to `/usr/local` if unset) and compile the path into the binary. 2. Code a fallback chain like this: 1. If successful, the result of `std::env::current_exe()?.canonicalize()?` with the last path component replaced with a distinctive directory. 2. `/usr/local` 3. `/usr`
Already on nightly because I wanted to use clippy, but I can't compile the damn thing. :(
Thanks
BLAS subroutines are made with auto-vectorization in mind (visible micro-benchmarks at least) but are not manually vectorized (and won't until SIMD intrinsic become stable in Rust). I did not write complete benchmarks including Eigen yet. I've run a few tests and nalgebra is still slightly slower (but not too far behind), especially for factorizations like LU where Eigen implements the block version of the algorithm. I'll see if it is possible to integrate Eigen in the rust_linalg_bench somehow. QR uses householder reflections to eliminate sub-diagonal entries. For the SVD we start by a bidiagonalization (using householder reflections), and then Golub-Kahan SVD steps with implicit shift until convergence. This is one of the methods presented on the Matrix Computations book (from Golub et al.), with minor improvements when a diagonal element is zero.
Thanks for your support!
Merci ! Don't hesitate to open issues if you encounter any numerical stability problems. Those decompositions have been tested on random inputs, but not on real-word data yet.
I recommend the assembly part of [JonesForth](http://git.annexia.org/?p=jonesforth.git;a=blob_plain;f=jonesforth.S;hb=66c56998125f3ac265a3a1df9821fd52cfeee8cc) (link goes to the raw assembly of the current revision)
Thanks. The auto-generated documentation with `cargo doc` still suffers a lot from the rustdoc bug [32077](https://github.com/rust-lang/rust/issues/32077) (forcing the user to click on long chains of aliases to discover what a type can actually do) so the user guide and the quick reference is a way to compensate this a bit.
Thanks!
Again, I recommend reading [JonesForth](http://git.annexia.org/?p=jonesforth.git;a=blob_plain;f=jonesforth.S;hb=66c56998125f3ac265a3a1df9821fd52cfeee8cc). Edit: And I want to revisit that point since you mention Python, I've professionally worked with a Python legacy code base that had worse than useless information. The original maintaminers felt that since the code is oh-so-readable, they didn't need to invest in useful docs. Worse, a good chunk of the standard library sets a bad example, so you often read the source and do experiments to find out how objects behave in certain edge cases. That said, it's a pity, because Python's documentation support is really awesome, with doctests that were the blueprint to Rust's implementation.
Nice! I'm wondering at a detailed level why the difference in performance, especially with size. I was also wondering if [GLAS](https://github.com/libmir/mir-glas) might be worth looking at as an inspiration, as it seems to be taking a different approach as some libraries, but successfully so. GPUs are on my mind also. But very nice overall.
Something like this (in case the callback is guaranteed to be only called once at a time, otherwise, use `Fn` instead of `FnMut`)? extern fn callback&lt;F: FnMut(c_int, …)&gt;(callback_param1: c_int, …, user_data: *mut c_void) { (*(user_data as *mut F))(callback_param1, …) } fn convert_to_c_callback&lt;F: FnMut(c_int, …)&gt;(f: F) -&gt; (fn(c_int, …, *mut c_void), *mut c_void) { (callback::&lt;F&gt;, Box::into_raw(Box::new(f)) as *mut c_void) } Untested, but you get the idea.
ok. but why not nickel?
I have personally used Iron quite a bit, so I can recommend it with a good conscience. I haven't used nickel before, but it might be good as well, so yeah - why not?
Rocket is like flask/laravel, if you know about routes it will be not so difficult to learn. Also, read about templates.
Doesn't look like it's been updated in a while, but you could try app_dirs https://docs.rs/app_dirs/1.1.1/app_dirs/ edit: you'd have to copy the configs initially either in the build script or an installer
Are there plans to support non-`Copy` scalars for the matrix elements? An example of where this would be useful is if you want arbitrary precision floating-point numbers, those are not `Copy`, only `Clone`. It seems like you're already trying to support complex numbers instead of only real numbers where possible, which is great, but the fact that I can't use nalgebra with arbitrary precision floats is unfortunately a deal-breaker for me right now.
You want to post this in /r/playrust
Is it suitable for small cases like solving system of linear equasions with 3 unknown / 3 equations ? I mean may be this library is overkill for such simple case and I better use some other crate?
I think petgraph stores the nodes in a `Vec` and uses indices instead of references.
Just so you know, the documentation link on crates.io is broken.
My code does: let config_file = File::open(format!("etc/{}.conf", config_name)).unwrap(); Where config_name is a configuration selected by the user ("staging", "production", etc in my case). It's then up to the system administrator (in my case, me) to put the config files in a directory called etc, and start the application with its working directory set to the parent of that etc directory. In practice, my layout is: app_name * bin * app.sh * libexec * app_binary * etc * prod.conf * staging.conf 
Alex Crichton gives a very good explanation of how futures and tokio crates fit together (at 10:40): https://request-for-explanation.github.io/podcast/ep6-everything-and-the-kitchen-async/index.html
Good job! The ccrc repo could use a README with the source paper name.
Zfs "avoids" those issues by throwing hardware at the problem. ZIL, Z2ARC. Surprisingly zfs isn't magic, and cow fs' don't have an easy way around this problem.
From the blog post: &gt; There are primarily 3 kinds of asynchronous disk APIs. &gt; &gt; * linux AIO (supported in the kernel) &gt; * posix AIO (supported by linux, Mac OS X, BSD, solaris, AIX etc.) &gt; * Windows’ overlapped I/O This is notably missing the fact that the BSDs also have [kqueue](https://people.eecs.berkeley.edu/~sangjin/2012/12/21/epoll-vs-kqueue.html), which is moderately complex, but well-thought-out and mature. I understand that Solaris (and presumably, its descendants) has something called event ports, which are similar. 
That blog post has 4245 words about how the nginx programmers worked around Linux's omission of asynchronous file IO, and 32 about FreeBSD: &gt;On the other hand, users of FreeBSD don’t need to worry at all. FreeBSD already has a sufficiently good asynchronous interface for reading files, which you should use instead of thread pools. 
As others have mentioned, there is no good portable standard for asynchronous file IO, but there are good interfaces on some platforms, and bad but workable interfaces, or the option of falling back to a threadpool, on others. My understanding is that [libuv](https://github.com/libuv/libuv) is the best portable abstraction over asynchronous IO which includes file IO. There is a [Rust binding](https://github.com/sorear/libuv-rs); it's a bit out of date, and quite low-level, but it's probably still your best bet. 
Well what more is there to say. On BSD use posix aio api. On windows use the windows aio api. On linux you have to use a thread pool. It spends all of the time on linux because it is the weakest platform in this regard and one you have to spend the most effort on.
Your Patreon page doesn't mention [kiss3d](http://kiss3d.org/). Is it unmaintained? (so it isn't going to upgrade to nalgebra 0.13 right?)
Ok we've gotten this done today. Here is the full [hello-world example app](https://github.com/gotham-rs/hello-world) and the single file example is [right here](https://github.com/gotham-rs/hello-world/blob/master/src/main.rs).
I suggest to include possibility of re-orthogonalization in Golub-Kahan SVD in case orthogonality is lost (or, at least check it run-time and show a warning). Also I suggest checking Lapack manual for the implementation ideas, there is a lot of know-how in there. Or, you can always write me a message, I did this kind of libraries for a living.
An AI professor i took a few undergrad courses from had a Meetup about a rust chess engine he was writing. I can't find it on his GitHub at the moment so maybe he took it offline to clean up the code (https://github.com/BartMassey?utf8=%E2%9C%93&amp;tab=repositories&amp;q=&amp;type=&amp;language=rust) but if you email him I think he'd be happy to talk with you
The exact same thing happened to me. Maybe instead of rewriting module system, put a big warning somewhere: "Read the modules manual! Really, you need to!"
That article on channels was really interesting. I missed that when it was posted. This is why I love TWIR!
I use this actually very often: * experiments - I write a new, incomplete, feature try it out, remove temporarily... * refactoring - I have trait that is implemented by several types in different modules. I need to change that trait. So I comment out everything and then fix the modules one-by one, so I can see it works sooner * notes in form of code (if there's more code than text). `.rs` turns on syntax highlighting
&gt; I'm not sure anymore. This.
Thanks for it. It would be nice to have some very easy to follow tutorial for `Futures` as well, and other examples of Tokio besides the one that the docs are giving. 
Wow, that list of blog posts is so long. I wonder whether its due to the holiday season, or because Rust has grown over time.
Here, maybe this will help: https://play.rust-lang.org/?gist=7244b3ac5bb5a1434d6c2f9a30077b8b&amp;version=stable
So, we need something like mio but for file system. AFAIK, on windows side, it should be similar to IOCP. No idea about other systems.
Possibly a bit of both but I would attribute it to rust growing over time more. There's been a decent amount of growth in the community over the last year alone.
I totally get the wish for temptingly complex and shiny new toys. If you primary goal is learning and not short-term productivity then just keep at it until you get it, as long as you enjoy the process. For every new concept you don't understand, research it, jump back, repeat.
Just because you had shitty programmers before you doesn't mean the language is shitty or anything. I've seen bad Rust code but I know it doesn't mean Rust is inherently bad.
Not a rust expert, but I would normally solve this problem with the equivalent of a lambda/closure and pass that around. The data and callback fn are thus bound together, and can be called safely.
perfect timing! thanks!
Have you checked out the other roguelike-rust code bases yet? Usually the saying goes: don't fight the borrow checker. I have a feeling there is a better way to achieve what you're after; but first what is the problem you're having with collections?
Ah I see, thanks for clearing that up :) I know in nickel the closure requires Send, and not Sync. I wonder where the difference lies, and if that would be a better solution (reworking Hyper for Send that is)
Aha that's what I was missing. Thanks!
Fair enough. It's just anecdotical evidence, but it's a data point nonetheless. And one that supports my argument that people will write great or shitty code in any language. In fact, I'd presume if you open any larger assembly project, you'd find it *surprisingly* well documented – simply because it's very hard to keep track of things otherwise.
Would love some comments on the setup, especially how to make a production build with Docker.
I agree with futures, have been trying to figure it out for a project. The lack of examples makes it a lot harder.
That's awesome. Thanks!
I've been trying to get this to work for a few days but can't seem to understand how I'm supposed to do it. I'm trying to make a simple function which, given a JSON-api url, creates a get request, parses the json and returns future containing the result. Can't seem to understand how to get it working though fn get(&amp;self, url: &amp;str) -&gt; BoxFuture&lt;serde_json::Value, ()&gt; { let mut req = Request::new(Method::Get, url.parse().unwrap()); // function which adds some needed headers Self::add_headers(&amp;mut req); self.client.request(req) .and_then(|res| { res.body().concat2().and_then(|data| { // Here final result as json value Ok(serde_json::from_slice(&amp;data).unwrap()) }) }).boxed() } I'm pretty new with futures and rust in general, as you can probably tell
For very small systems of linear equations (say, up to 4 unknowns and eqations), it should be more efficient to just compute the matrix inverse once and for all and then use it to solve the equation(s). In that case, cgmath (and perhaps euclid) will work well too and might be a bit easier to use than nalgebra. Performancewise they will all be even so the actual choice of crate will depend on your other needs.
Well, I did not mention kiss3d because I don't intend to implement new features for kiss3d. But, I will still update it for new version of nalgebra and ncollide because I use it for the testbed on nphysics. To clarify I will add kiss3d to my Patreon page and mention what I just said.
This is my approach,https://medium.com/learning-rust The ORDER of we are learning Rust It's less useful to explain about language capabilities by examples or explain about lifetimes before structs, enums ▸ Installation &amp; Hello World ▸ Cargo &amp; Crates ▸ Variable bindings , Constants &amp; Statics ▸ Comments ▸ Functions ▸ Primitive Data Types ▸ Operators ▸ Control Flows ▸ Vectors ▸ Structs ▸ Enums ▸ Generics ▸ Impls &amp; Traits ▸ Ownership▸ Borrowing▸ Lifetimes &amp; Lifetime Elision ▸ Modules ▸ Crates ▸ Workspaces ▸ Error Handling ▸ Functional programming in Rust
In case anyone's confused, /u/AoeAoe is sugg that the title should read "Announcing *My* First Successful Rust Project".
There is currently no plan to support non-Copy scalars for two reasons. The first is for clarity of the source code of nalgebra, i.e., to avoid having to add `.clone` everywhere. The second reason is that my intuition tells me that the use of non-Clone scalars implies very different implementations of the various algorithms in order to minimize the amount of allocations. But I might be wrong as I never worked with arbitrary precision floats.
Cool! I love kiss3d and I think it doesn't really need any new features.
&gt; holiday season Pardon my ignorance, but which holiday might I ask? The major holidays I see are Korean Liberation, Pakistani Independence, the Assumption of Mary and I guess the end of the Muslim year (looks like festivities start at the end of the month with the trip to Mecca). I've never thought of August as being a "holiday season", but rather the lack thereof (at least here in the US), so I'm genuinely interested in what I may be missing. I often associate November and December as the "holiday season", with pockets of other holidays throughout the year. I guess you could be referring to summer break for schools, but I've never heard it referred to as a holiday season (again, pardon me if I'm reading too much into this). 
`break rust` is a nice touch.
This link works for me. Are you sure it's the "Documentation" link on the "Link" section of the [crates.io](https://crates.io/crates/nalgebra) page which is broken?
This may be out of scope, but one thing that hasn't been addressed well is doing file I/O. The [current recommendation is to use a thread pool](https://github.com/tokio-rs/tokio/issues/10), though there are a few crates to do it on specific platforms.
I never heard of GLAS so thanks for mentioning it, I'll check it out! &gt; I'm wondering at a detailed level why the difference in performance, especially with size. Difference in performance when comparing what? For rulinalg vs. nalgebra, the difference comes from various optimizations like avoiding useless copies performing operations on slices instead of new buffers. Also some decomposition like the SVD of rulinalg are naive implementations (with allocations everywhere). For nalgebra vs. Lapack-based crates (linxal, nalgebra-lapack, etc.), I guess that the performance difference comes from the fact that Lapack sometimes implements better algorithms (using blocking) and has Blas operations optimized to the assembly level.
Thanks for the suggestion and the offered help! I agree Lapack manual provides several ideas to improve robustness and accuracy. Don't hesitate to mention any improvement that seems essential given your experience. I have created a [github issue](https://github.com/sebcrozet/nalgebra/issues/280) just for that; your inputs are very welcome. Problematic test cases would also be very helpful!
https://github.com/japaric/trust is a good, easy way to make cross-platform binary releases of rust programs.
Take a look at https://github.com/CraZySacX/ellmak It doesn't use rust for the API, but has the same concept of API, frontend, DB with docker-compose. I use docker-compose.override.yml to setup the dev environment, and docker-compose.yml for production images, and docker-compose.machine.yml for cloud deployment via docker-machine. The individual Dockerfiles in my case are at the top level also.
I think with this response, along with others to others' questions, you more or less answered my question about differences in performance. I was mainly wondering about what, algorithmically speaking, was causing the difference in performance between nalgebra and nalgebra-lapack, linxal, and rulinalg. Your comment about assembly-level stuff in lapack was something I assumed; the other stuff was less clear to me. This isn't a comment on nalgebra, but: I wish in general linear algebra libraries would provide better documentation about where they're getting their routines/algorithms from. Things like discussing the books/papers/other code they're based on and why decisions were made would be helpful. Maybe this is in the code comments but I wish it were brought "out front" more often. 
At least mine was supposed to be last week, but it was missed and folded into this one.
I think some people refer to vacations as 'holidays' like 'taking a holiday'.
Take a look at https://github.com/CraZySacX/ellmak. It doesn't use Rust for the API, but the structure is the same (API, Frontend, DB) from a docker perspective. I use docker-compose.yml to configure the prod environment, docker-compose.override.yml to configure the dev environment, and docker-compose.machine.yml to configure for deployment in AWS via docker-machine. My individual Dockerfiles are also at the top level.
I've heard that, I just didn't link it up with "holiday season", and I guess I assumed that people "taking a holiday" wouldn't be in a position to blog (e.g. traveling with or visiting family), whereas people tend to stay home on time off granted by schools, companies or the government. In any case, it doesn't really matter what the reason is, as long as we get more blog posts :)
I am pretty sure he means the vacation season. In some countries people typically use their vacation at the same time, for example 2-3 weeks of vacation in august, or 2-3 weeks in July as we do here in Sweden.
A European living in Zagreb here. Perhaps by "holiday season" /u/est31 meant "summer vacations". Almost everyone I know here (including myself) takes a vacation and goes to the seaside for a week or two. The city definitely feels empty during the summer. Some restaurants/shops/theaters/etc. even get closed for several weeks because all employees take a collective break.
That is an interesting article. I had just started prototyping some code last week using the std lib channels and had run into the similar set of issues that the article summarizes. It makes me wonder if it would be nice to arrive at a set of send/recv traits so that different implementations could be used by messaging processing code - similar to the approach of the [http crate](https://users.rust-lang.org/t/announcing-the-http-crate/12123).
That's awesome, thank you! I've been spinning up VMs prior to this.
Btw, we do a podcast about RFCs each week (http://request-for-explanation.github.io/podcast/), think these could be included too?
In British English, vacations are referred to as holidays. https://english.stackexchange.com/questions/31166/is-there-a-difference-between-holiday-and-vacation
If I'm reading your scripts correctly, you're building locally, then packaging the result up and pushing to docker hub for your production builds? Wouldn't you get an older prod version with ‘docker-compose up‘ if you didn't take that separate build/push step first? Is that the typical flow for containers? Sorry if these are dumb questions, still wrapping my head around best practices here.
What /u/stjepang said. I was calling it "holiday season" because in germany, most people take vacations in summer, and while for an individual its only a small amount of time, it still means many people have free time. I've thought this was a global phenomenon, or at least similar across the northern hemisphere, but I guess I was wrong... Now I also know that open source projects and communities live off the free time of their contributors. I have been maintaining an open source project for a time and I always saw the number of substantive pull requests spike after national/public holidays or shortly thereafter.
This needs to be included! That podcast is very, very valuable even though the audio quality is not always that good.
Yeah, regarding the audio quality we're trying to keep other stuff as low effort as possible; it already talks half an hour of my time to relisten and edit. So if folks want to help with that that would work, but it's probably going to stay that way for at least the near future.
RIP click :P Anyways, does anybody have nice resources demonstrating the JSON deserialization using structs?
 Are you hoping for something like Async I/O on Linux? I think most pure async implementations of file IO (e.g. nodejs) just defer to a thread pool under the hood. 
This came up in the Diesel Gitter recently. I'm of the opinion that a production image should be as small as possible, ideally only containing your application (and a basic init process). After a bit of discussion I learned about multi stage builds, a feature Docker gained recently. With it, you can run all the cargo commands you desire, grab those artifacts and, in the next stage, build image with just those artifacts (and without all the build tools like rustc and git). (And while certainly not necessary, I'd love to see an image based on alpine and musl!)
&gt; the use of non-Clone scalars implies very different implementations of the various algorithms in order to minimize the amount of allocations The optimal algorithms for "heavy" scalars may indeed be somewhat different from the normal algorithms, but (for me at least) it would be fine if you used the normal algorithms with just a `clone()` inserted where necessary. It wouldn't be optimal, but at least it would work. Right now, nalgebra + non-Copy scalars cannot work. I understand the concern that writing `clone()` everywhere makes the source code uglier though.
I'd add that on raw block devices, the linux aio works pretty well, if you're talking linux aio to files in a filesystem, then it becomes somewhat dependent on how well it's supported for the particular filesystem you're using.
I create two sets of images. One is &lt;image&gt;:local, and the other is &lt;image&gt;:latest. Only the images tagged latest get pushed out to docker hub. The local images are what I run on my machine for development. My typical flow including deployment is: 1. dc build (uses docker-compose and docker-compose.override) to build my local images. 2. dc up -d (runs the local images because of docker-compose.override) 3. dc down (stops local images) 4. Iterate for development (I actually rarely have to restart all of the docker images, because I have volumes pointing to source directories, and use nodemon to restart component images on changes). 5. docker build -t saizo/ellmak_nginx:latest -t saizo/ellmak_nginx:0.1.0 -f Dockerfile.nginx . (via scripts/dbuild) 6. docker build -t saizo/ellmak:latest -t saizo/ellmak:0.1.0 -f Dockerfile . (via scripts/dbuild) 7. scripts/dpush to push the latest and semver tags out to docker hub. 8. On production machine, pull latest tag to grab the production images.
I basically want an abstraction that handles all of that for me. It should use whatever is available (e.g. async i/o on Linux, e.g. [tokio-file-unix](https://crates.io/crates/tokio-file-unix)) and fall back to a thread pool. The use case would basically be handling lots of files on the filesystem concurrently, like file storage (think OwnCloud). My use case is \*nix, so `tokio-file-unix` will be the tool to use, but I'd prefer for there to be an abstraction in the same way that sockets have an async abstraction.
You mean io_ syscalls? That only really works on XFS. And it requires O_DIRECT of course.
There is https://github.com/emk/rust-musl-builder for building musl static binaries for docker.
A lot of people take vacation/holiday in the summer, but even more people do it in the winter, hence the confusion. I know that Rust has a lot of users throughout the world, so I wasn't sure if there was something I was missing. For example, most of my open source work happens from the end of November to the end of December (US Thanksgiving, Christmas and New Year) because that's time that I have off from my work and we typically stay home for those holidays (visit with family in the area). We go on our bigger trips in the summer, and that's time that I'm not near my computer. Hence my confusion. At any rate, it really doesn't matter and I was mostly curious, so no worries.
Cool! Would love to see a project that uses this to build a static binary that includes OpenSSL and libpq (and friends) :)
Yup!
I knew that, but "holiday season" in the US means the winter holidays, so I guess I assumed that the term had taken on a similar meaning elsewhere (e.g. the Muslim year ends around now, so perhaps there were a lot of posts from Rustaceans in Muslim countries). Thanks for the help though! :)
I took German in high school and my teacher basically said the same thing. Apparently a lot of companies essentially take a whole month off in the summer (e.g. use up all of the vacation time at once) instead of employees taking time off throughout the year. I was mostly confused at the terminology, but it seems that was mostly because of my US bias ("holiday season" has a specific definition here meaning the fall/winter holidays of Thanksgiving, Christmas/Hannukah/Rammadan/etc and New Year's Day).
Agree about the size, what I have now is pretty large. The multi-stage builds look promising. Would you build a separate container to run `diesel migrations run` and the like in prod, since that doesn't need to stick around afterward? I kind of like the assurance that my api_server and diesel migrations would have to match if they're packaged as one unit...
Summoning /u/burntsushi regarding this `memmap` business. I seem to remember that ripgrep has specific tricks regarding buffering files because `memmap` is not always the most efficient way depending on the platform.
&gt; does anybody have nice resources demonstrating the JSON deserialization using structs? * https://serde.rs/derive.html * https://serde.rs/json.html 
Would a syntax to say `#[ignore(mod1, mod2, mod3, ...)]` be practical for this usecase?
Yeah, I think languages should have more easter eggs.
Okay, cool, that matches up with what I thought was happening. Thanks for the insights!
I'd suggest embedding the config files in your app's binary, and then copying them to the user's configuration directory. If they are user-configurable options, maybe use `app_dirs` to find the right place to put and look for them? Otherwise it depends on what OSs you're targeting. Reading the PREFIX env var would make sense for unix-y systems, but I have no idea what the equivalent on windows is.
I'd probably use the embed_migrations macro
Whenever I see stjepang posting an article, I know I am in for a good moment :)
TL;DR is that `tac`'s usage seems fine to me. The specific place where I found memory maps to be slower, at least on Linux, was when crawling a very large directory with many (relatively) small files. At the scale, my hypothesis is that the book-keeping required for handling the memory maps leads to noticeable overhead. Less confidently, this overhead appears to get worse when run on VMs. Conversely, when searching a single large file, using a memory map on Linux appears to do better. The hypothesis there is that the overhead of managing a single memory map is nearly non-existent (relative to search time), and the overhead of many `read` syscalls and management of said intermediate buffer starts to become more noticeable. You can run your own tests with ripgrep by the way. You can force the issue with the `--mmap` and `--no-mmap` flags. All of the above assumes the file is already in memory somehow (either in page cache or ramdisk or whatever). Most of this was discussed in my ripgrep blog post. Do `^F` for the keywords: `VM` and `memory map`.
The impression I got was that the question is about how to make those defaults compatible with packaging conventions built around features like autoconf's `--prefix`. Given that the example was `/usr/local/games/`, `--libdir`probably isn't something you want to rely too heavily on.
Wow, way cool, I was needing a tool like both of these! One cool thing would be if your proxies could (optionally) delay packets. To simulate slow DB's what whatnot. And maybe option to dump the in/out to the console in different colors (this actually has been useful for me)
I could be wrong, but I got the impression that the JSON files in `data` were meant to be less about user-configuration and more the kind of "runtime configuration" that gets bundled into the application, like the moddable resource definitions in games. Unless Windows convention has changed since Windows 7, those go in the same tree of folders as the binary itself and, given how windows sets the working directory, could be handled simply by allowing the build to be configured so that `PREFIX` has some value that's resolved relative to the binary at runtime.
Thank you for the analysis :) It clarified the issue with mmap quite nicely!
Good luck, mate :)
This is probably not completely relevant to Rust, but I know at least of a few people that are interested in this blog post and I thought that I would post it here. I'll delete it if it is too offtopic.
What other languages would you have considered for the mentioned project?
There are no benchmarks, so I don't know how "high-performance" it is, but the code itself is pretty bad: - using `match` for `bool` is just wrong (L117) - you use `panic` on error, instead of `eprintln` (L53) - useless return (L60) - unneeded type specification (L134) - too much unsafe, unwrap and map_err for such a small app - you don't check `\r\n`, even throw you stated that app is *cross-platform* - there is no error message on print error (L66) - etc.
:-) Learned something new. http://docs.diesel.rs/diesel/macro.embed_migrations.html
Erlang is a language built for writing servers and implementing protocols. 
Which rust plugin for vscode is the "right" one? There are 3, and the one that looks official has the fewest downloads.
If I need to return a list of items from a method, should I return a `Vec&lt;T&gt;` or a `Box&lt;[T]&gt;`? edit: from an API standpoint
Thanks for looking, but I'm going to have to disagree with you. * match for bool is a matter of taste. It's identical to if else and I'd be surprised (and disappointed) if the compiler didn't emit the same code. * L53 is a critical failure, purposely not continuing with the remaining input. `eprintln` would continue (unless followed by an exit). * L60 is again a matter of taste. I haven't decided if I like explicit `return` or not. rust is in odd place between declarative and functional programming languages, and the fact that it allows you to do both is the problem, not my taking advantage of that freedom. * L134 uneeded type: you're right. That's from refactoring, it was initially `= something else` and now there's no need for it. Again, "bad code?" More like bad taste, but alright. * Did you even _read_ L66? It's error handling _an error to write to the console_. How do you propose I "write a message," exactly? That's not there in case the _string_ was not printable, it's there because if you pipe the output from `tac` to another process, then ctrl+c in the terminal, SIGINT is sent to the subsequent command first, which raises SIGPIPE in `tac` because the output pipe has been broken. rust's signal handling is non-existent at the moment (the signal handling crates are not tested on FreeBSD or Windows), and this is the most appropriate course of action under the circumstances. * Too much unsafe as compared to.....? I'm opening a memory mapped file and mapping that into a view as an array. That has to be unsafe by definition, you're leaving rust territory for uncharted OS grounds. * I don't check `\r\n` _because I don't have to_ and no code is the best code. A previous version of the code did check for `\r\n`, this one doesn't. You know why? Because `\r\n` will always have `\r\n` _in that order_ which means that `\n` is a split marker for _both_ `\n` and `\r\n` line endings. Surprise, I actually _did_ test this on Windows with CR line endings and it works just fine and dandy, thank you very much. I don't know why you're coming off like you have a chip on your shoulder, but, really, find someone else to pick on. "bad code" and "code that's not written the way I personally find to be in good taste" are very, very different things. Bad code is code that does something you don't expect it to, that does not handle input correctly, that has unexpected side-effects, that crashes unexpectedly, that accesses memory out of bounds, etc. Code that uses `match` instead of `if else` or explicitly states the type when type inference would have been sufficient is... something else. EDIT I've updated `tac` to write directly to stdout without using the print! macros, which eliminates the only other unsafe code in the utility.
The Problem: Needing to mutably access two values in the same HashMap (or Vector) at the same time. Which is absolutely safe, and the only reason that it's currently disallowed is that `rustc` can't tell the difference between "this mutably borrows because it reshapes the collection" and "this mutably borrows so that it can mutate an element of the collection". The former actually should lock the whole collection, the latter really can hand out every element as long as each element is only handed out once. https://play.rust-lang.org/?gist=40e8263e53d2a257117425b1d040aace&amp;version=stable So this is what I came up with. Of course, as soon as I had some people check it one person said "Why not use `HashMap&lt;K, RefCell&lt;V&gt;&gt;`?", and that _would_ be like 98% the same thing. However, I do like my version anyway :P No one has given it a close analysis yet, and I haven't had the time to put it into serious use, but I think it's pretty cool.
Thanks for the info! It's funny, because my experience with memory mapped files on Windows was the exact opposite. Many small files is fine, but heavy IO to a single, large mmap causes massive problems because Windows isn't smart enough with its paging and tends to page everything else that's running out of memory to page as much of the mmap as possible (this was circa 2011, don't know if things have changed since).
It would certainly work (it came up further down in the RFC discussion). But it is still a reduction in convenience since one has to first find out what all to put in that list, so it's a switch to the filesystem view (or shell in my case). It'd require editor support to be as convenient as commenting out a section with combined `mod` and reexporting `use` pairs.
Is the RLSL compiler written in Rust?
Yes, I should probably make that more clear.
Somewhat related, [glassful](https://github.com/kmcallister/glassful) (it compiles to GLSL though, not to SPIR-V). Unfortunately, development stalled and it doesn't build anymore (apparently due to procedural macro breakage).
**Warning**: This design will easily cause Stack-overflow when you add more elements like 100s or 1000s. You have to implement your own destructor to iteratively destruct nodes starting from the leaves (bottom up). 
There are some architectural differences - the one that evolved out of Rusty Code uses a variety of tools in the client for various kinds of fallback. The reference implementation uses only the RLS (which itself uses Rustfmt and Racer, so IMO other tools in the client are not really necessary). The consequence of this difference is that the Rusty Code is likely to work on more projects, but the reference one is more likely to work well. The reference implementation is maintained by the RLS devs, so is more likely to get new features quickly and to do the right things. I don't think there are any plans to replace either.
Small comment: you really should *only*[1] be using panics to indicate a bug in your program. Panics aren't end user facing error messages. [This line](https://github.com/neosmart/tac/blob/25a3127b59e3f06262f49e3481de0431f5601c6b/src/main.rs#L52) in particular should probably emit an error message to stderr and then quit the program gracefully if it doesn't make sense for the program to continue progress. Usually what I do in these cases is just bubble the error all the way back up to a `main`-like function, call `eprintln!` followed by `process::exit(1)`. [Example.](https://github.com/BurntSushi/ripgrep/blob/3d9acdab189006880e9d4ccdbe9ae42b164901ec/src/main.rs#L60) [1] - There are other use cases for panics, particularly if you're OK with relying on unwinding, but I don't think they're applicable here.
Any plans for a compute-only flavor? In my work-in-progress machine learning library I'm currently using OpenCL, but I'd love to switch to something that would support multiple backends simultaneously. (Mostly due to NVidia's abysmal support of OpenCL; while they can sabotage OpenCL and get away with it they can't do the same with Vulkan.) I've been toying with the idea of just using `syn` to parse Rust code and generate OpenCL code/SPIR-V/whatever from it, but having a more restricted language would obviously be a lot better.
&gt; too much unsafe If you're using memory maps, then you can't avoid the `unsafe` unfortunately.
Thanks for your work on RLS! &gt; The reference implementation is maintained by the RLS devs, so is more likely to get new features quickly and to do the right things. I see. When it was initially announced on the RLS GitHub page it looked like the extension was more like a sample to be used by other authors when implementing their extensions instead of something intended for the end users. It does sound like doing the same work twice. It might have been a good idea to join efforts with KalitaAlexey.
Compute-only probably not, but I'll definitely add compute shader support. https://github.com/KhronosGroup/SPIRV-LLVM currently should output SPIR-V that is at least compatible with OpenCL Edit: I am also interested in machine learning. I am currently watching this free course https://www.deeplearning.ai. I'll probably toy around with deep learning on the GPU in the future. 
Check out the examples in the `serde_json` documentation: https://docs.serde.rs/serde_json/index.html#parsing-json-as-strongly-typed-data-structures
Sure, once I will remember password to my github account. Meanwhile, the thing people would need most, I think is complex version of basic algorithms: LU-QR-SVD. In my experience people need to do complex stuff surprisingly often. Last, but not least, we always had separate repository with MATLAB versions of algorithms and then re-wrote those versions 1-to-1 to C++. The testing was done as follows: matlab subroutine vs plain matlab realization with only blas level operations and then, if everything checked out right, we translated it to C++. This was most time efficient way to write this kind of stuff. There is a fair share of surprising at first sight stuff in even slightly more advanced algorithms.
Requires nightly AND it's not async yet, right? At least I haven't caught any async announcement, or timeline for when it will be implemented.
Oh god thank you. I didn't realize that that was a logical proposition. I kept on reading it as a name. 
Through painstaking effort by a few people, mio can support async io using IOCP on Windows and any platform that supports epoll or kqueue. So anything that builds on that (e.g. tokio) would be able to offer an async API into files. But because of the rather large layer of abstraction required, I wouldn't expect to see something like that in the standard lib. Even on Linux, though, the semantics of epoll over files is different than epoll over sockets, so an API that abstracted over them would have to be quite opinionated. The best approach is probably Tokio Streams. So your verbs would have an open/connect, close, read, write
Just tried it. It pretty much doesn't work for me (typing a single character makes it rebuild for 10-30s, no error squiggles, no suggestions after dot, no RLS or extension error messages in the editor pane), but there are a lot of open issues. I'll test it again in a while.
I totally understand. Just make sure the mics catch people's voices so they can be heard clearly. But ultimately, this is one thing that could improve that is tiny compared to the positive things provided by the RFCs podcast. Thank you and the others involved in it for this. Keep them coming :)
https://godbolt.org/g/Jm35WT I checked that tail call optimization does not take place in this case. Notice that `drop` **calls** `drop` again. When the tree goes out of scope, a call stack is created for each node starting from root and stack will overflow. For garbage collected languages, this is not a problem as the destructor is deferred to later. 
awesooooooooome Make friends with the gfx-rs people. It would be awesome to have a good, portable open-source shading language that allows a lot of flexibility in definitions and adaptation to the target platform.
If all you need from the `give_shape` method is to call the types' respective constructors, then you wouldn't need an enum at all. The function will just need to be generic over the return type: fn give_shape&lt;T: Shape&gt;() -&gt; T { T::new() } And it can be called like so: give_shape::&lt;Square&gt;() I have modified your playground example to show the function in action, take a look: https://play.rust-lang.org/?gist=3770e566305c13885a7067d9c161f508&amp;version=stable
the big opportunity (IMO) would be for something which can get type information easily between the CPU and GPU shader code (CPU sets up typed vertex data -&gt; GPU vertex shaders sees it as typed inputs -&gt; typed vertex shader output -&gt; typed fragment shader.. As such my 'perfect language' really would have shaders as a strict subset, not just another similar-looking language.. a monolithic program just happens to run bits of itself on the GPU. 'the GPU' would be modelled as high-order functions taking function-objects for the shader pipeline stages. (i.e.the GPU happens to be hardware that runs ```fn render&lt;..&gt;(_:&amp;VertexArrays,_:&amp;VertexShader,_:&amp;FragmentShader, _:&amp;mut RenderTargets)``` .. constants get captured and set in constant buffers etc etc) e.g. imagine being able to write generic shaders generated alongside the type of the vertices you plug in, etc. on another note, I do think rusts slightly more functional syntax would be pleasing for shaders, but what about the overloaded constructors e.g. ```vec4(some_vec3,w)``` ```vec4(x,y,z,w)``` etc. I think I seem to remember ages ago some attempt to get actual rust code into compute shaders (using the do notation ) ... that looked awesome (EDIT: having said all that, as it stands rusts macros are already very useful to help interfacing CPU/GPU code)
This is very intriguing indeed, I did know about generics in Rust but I did not quite get a grasp of it. This helped me a lot, I have been struggling for hours on this particular problem, thank you very much!
&gt; e.g. imagine being able to write generic shaders which respond to what type of vertices you plug in, etc. Can you think of an example? &gt;on another note, I do think rusts slightly more functional syntax would be pleasing for shaders, but what about the overloaded constructors e.g. vec4(some_vec3,w) vec4(x,y,z,w) etc. I think Rust could get a bit more love for math code, but I never had problems with overloaded constructors. For example in my math lib I have this let v3 = Vec3::new(..); let v4 = v3.extend(1.0); // Vec4 Here is my look_at matrix where I use extend. (With a few ugly unwraps) pub fn look_at(eye: Vec3&lt;T&gt;, center: Vec3&lt;T&gt;, up: Vec3&lt;T&gt;) -&gt; Self { let z = Vec3::normalize(center - eye).unwrap(); let x = Vec3::cross(up, z).normalize().unwrap(); let y = Vec3::cross(z, x).normalize().unwrap(); Mat4::from_rows( x.extend(-x.dot(eye)), y.extend(-y.dot(eye)), z.extend(-z.dot(eye)), Vec4::new(T::zero(), T::zero(), T::zero(), T::one()), ) } 
Wow. Take it easy. You will get the same complains from `clippy`. It's not like I made them up.
https://crates.io/users/losfair Actually worse... I know rust has a "no crates will be reclaimed" policy, but how would somebody who obviously squats, like writing a bot which publishes every available name be handled?
Yeah in germany people do vacations in winter as well, but its only about one week, around christmas/new year, but not for more than that. I'm not worrying. Its always exciting to learn new stuff about the world ;).
&gt; Can you think of an example? - vertex skinning.. struct Vertex { .... bones:Array&lt;BoneIndex,N&gt; } - dual quaternion skinning vs standard skinning - animation used to be done by splitting the surface into sections with 3 bones.. 'draw call per limb',but later it was made more vertex-shader heavy by indexing, - but CPU skinning sometimes appears again.. - shape animation or not - other forms of procedural shape eg. extruded paths - (forward) lighting, generic over types of lights - surface formats: - how information is split between the texture and interpolated vertex parameters - UV projections - texture-blending trees, material channels - animations.. animated textures - decoding of compressed formats e.g. some have done 'vertex pos = indexed clustercenter + low-precision offset' - indexed normals vs normals in the vertex data - genericity between parts of the calculation/data split between shader constants and vertex shaders/per vertex data: I suppose a fair amount of 'genericity' is fudged by just concatenating fragments of shader code, and of course the ability to independently choose the vertex &amp; fragment shader. Thats not far of doing things with macros in rust CPU code, but it seems like with the whole type system, you could be more precise and elegantly express how shader code fragments can slot together. maybe even genericity between the same calculation being split between deferred shading &amp; forward rendering, imagine cutting this into pieces and expressing it as caching the output of each stage for deferred shading, versus gluing the stages together with cpu sorted lights (consider forward plus aswell)
'extend', ok thats interesting. (I was messing with the idea of 'concat' or 'append' in my current rust vector library similar). i think rather than unwrap i'd define a fudged version of normalise thats more like 'normalise_or_else..' with some inbuilt fallback I wish there was a way to turn literal 0 , 1 into generic T::zero() T::one() .. 
Heh, thanks xD. I ran it against the post body; totally forgot about the title.
Thanks you two!
Will do. I believe I found it from one of Manishearth's blogs about GC's. I'll dig it up and update it later. EDIT: Done
&gt; a monolithic program just happens to run bits of itself on the GPU This sounds a bit like [SYCL](https://www.khronos.org/sycl). &gt; on another note, I do think rusts slightly more functional syntax would be pleasing for shaders, but what about the overloaded constructors e.g. vec4(some_vec3,w) vec4(x,y,z,w) etc. `vec4!(somevec3,w)` and `vec4!(x,y,z,w)` don't look too bad. It even has a precedent on the `vec!` macro.
Any chance of registering the podcast in itunes or whatever the apple podcast hosting portal is called these days?
https://itunes.apple.com/us/podcast/id1258783754 It's on the play store too
Excellent thanks!
I've already commented this once in /r/rustjerk, but extern crate antigravity; should be a thing.
stylistic nits != bad code
&gt; I wouldn't expect to see something like that in the standard lib Oh, definitely not, but it would be nice to have a crate that abstracts over a few platform-specific crates and presents a unified interface to dealing with them. &gt; The best approach is probably Tokio Streams. So your verbs would have an open/connect, close, read, write I'll have to look into this. I'm in the early stages of a project that needs to access a large amount of files efficiently, and I've been debating whether it's easier to just stick it into a database instead.
 ah yes, kind of looks like kronos' answer to microsoft 'c++ amp'.
I'm down
oh wow
I think a good policy would be to free up any unused crates without an associated repository after three months or so.
If you really need an owned collection, return a `Vec` – it's bound to be the most useful type you *can* return here. But perhaps you can reorder your code to return an iterator over the items without needing to keep all of them in memory? Or if an iterator is too hard, you could take a closure that gets called with each item (and possibly some generic state to `fold`)? 
FWIW, arbitrary precision seems important... I imagine I'd run into similar problems pretty rapidly as well. 
It's all OSS, the quickest way to get a crate that you want is to write it :)
I'll be there.
I've looked at that a bit, but it made me a _little_ uneasy. It [downloads and runs a script](https://github.com/japaric/trust/blob/master/ci/install.sh#L19) to install [cross](https://github.com/japaric/cross). I get that japaric probably isn't a bad guy^(TM) and this is probably necessary to make cross compiling work with a minimum of headache (and that I could probably remove this if I don't care about cross compiling), but is there some other reason not to worry about this?
Then the squatter will just upload a dummy repository with a readme saying "I got you"
This could really be mitigated with namespaces! He could have all of the `losfair/` crates he ever wanted.
Thanks. I picked up rust a few years back when there wasn't much consensus on when to use what. I like your rationale for using `panic`, it's almost like`assert` in C/C++... Except rust has an `assert!` macro as well. What would you say the difference in use cases between them is? I'd presume `assert` for logical bugs (such as making sure something still has a sane value after manipulating its contents or crunching some numbers) and `panic` for unexpected runtime events/output that can't be reasonably handled?
I'm interested.
Count me in.
I suppose, but it's still slightly more work. It's harder to do from a single shell script. We could even introduce a $0.50 fee for each crate that would go to funding core Rust development. Of course that would piss off a lot of people, but fifty cents is nothing unless you're publishing 200 crates a month. We could even waive the fee forever for any contributor to core Rust projects. I'm kind of thinking of some forums that require a flat $1 membership fee just to weed out bots, or Steam Direct with their $100 fee to add a game to Steam store. Basically just a small trivial amount of real money to stop bots and 80% or so of the malicious users.
`assert` and `panic` are basically the same class of thing. In fact, `assert` is implemented with a `panic`. I guess I see an `assert` as an explicit acknowledgment of some runtime invariant or caller contract, and is useful primarily as a debugging aide. I like "unexpected" for `panic`, but even that's a little murky. For example, if you're using `expect`/`unwrap` on a `Result` or an `Option`, then they will panic if the `Result` isn't `Ok` or if the `Option` isn't `Some`, and that's entirely expected. Generally speaking, I don't actually write `panic!` literally that much. It's usually a result of something else I'm doing: `unwrap`, `expect`, `assert!`, `unimplemented!()`, `unreachable!()`, etc etc. I do think that there is one clear succinct rule that is always true: if an end user of your application sees a panic message, then your application has a bug.
Not the first squatter, won't be the last. Its a problem of public namespaces I guess...
That will probably never work well. Asking for payment is putting up *many* barriers to entry other than "I can't afford the nominal fee." As soon as you ask for payment, you wind up needing a method of payment, and those almost always come with some kind of caveat, like, for example, it being easier to pay in certain geographic regions. Or even forget about geographic regions, and just think about life circumstances. I guess I'm a bit older now, but back in my day, where I grew up, 13-year old me never would have been able to even pay the nominal $0.50 you're suggesting because my parents never would have let me use their credit card on something they didn't understand. On top of all of that, it's a solution to a problem that we don't really have. There are much easier solutions where cooler heads would prevail. If someone actually wrote a shell script that reserved some non-trivial portion of the crates.io namespace, I would hope the core team would respond in a reasonable way. :-)
Perhaps crates could add an ownership key attached to it so cargo could refuse to update with an unexamined ownership change.
I don't see anything egregious about this user's crates. If a bot were claiming a huge number of crate names, clearly programmatically, that would be a special case and would be judged on its merits.
Our current policy is that squatting like this is not a problem.
I'm not sure if you can do something similar with HashMap, but at least with Vec you get a method called split_at_mut which lets you split a Vec into two mutable slices, thereby letting you get a &amp;mut to two items at the same time.
I've already been hurt by a name having been squatted and the person in question didn't react to any of our inquries. There should be a clear mechanism to transfer ownership of a swatted crate to people who actually want to do something useful with the name. Sure, this might lead squatters to put meaningless code into their crates, but I assume less squatters will be aware of the rules and might just register crates without knowing they might be reclaimed. Also, it should be possible for the core team to decide on meaningless/useless code. Generally I'm against stricter control of crates.io though because I don't want the Code of Conduct or other political agendas or political views of members of official Rust teams to be forced upon the crates ecosystem.
How about requiring to solve a CAPTCHA for every new crate that's published, and/or rate-limiting an account to publishing, say, 2 new crates a week (and maybe a moderated process for submitting more at once)? Not a significant barrier to entry, and would discourage bot-assisted squatting as well as manually publishing large numbers of crates. 
I have a small question about the `static` keyword. In c++, the static keyword used inside of a function makes the variable stick around and only be created/evaluated once, but can only be used inside that function. [Example where this is talked about](http://www.learncpp.com/cpp-tutorial/43-static-duration-variables/). Does static do something similar inside of rust functions, or is it called something differently? Is there even a way to achieve this in rust, a function local (im)mutable var that sticks around and reappears when the function is called again?
Well perhaps a small forum where anyone that can't afford to pay the fee could present their crate idea and have it waived, in addition to the idea of waiving the fee for anyone that contributes to Rust itself. In fact, the "call for participation" every week in TWIR could be a perfect chance for people to have their fee waived. I certainly don't want to stop people from publishing crates, but squatting will become a problem as Rust becomes more popular with the more mainstream developers and communities. Cargo makes creating and publishing crates incredibly easy right now.
Yes, my thing is essentially a generalized (eventually) version of splitAtMut. Right now it's only for HashMap, but I hope to write one version for HashMap/Vector based on a Hash bound, and another for BTreeMap/Vector based on an Ord bound. Vector&lt;T&gt; can be seen as a map from usize to T, and usize is both Hash and Ord, so the two versions for the two maps will both work with Vector as well. If one version can cover all three collections at once with a careful trait and careful implementations that'd be cool, but my trait-fu is not that strong yet.
&gt; but squatting will become a problem Is this true in other ecosystems without namespaces?
I'd say so in JavaScript-land, where some libraries have crazy names partially because they needed something unique.
I had the same confusion and wrote about it last year when all these things first came out: https://www.jimmycuadra.com/posts/the-relationship-between-async-libraries-in-rust/
I'm interested.
As a rule of thumb, you can't put a trait from another crate onto an object from another crate. This is to prevent the mere existence of your code from breaking some other code. If you or someone else uses Ipv4Addr and forgets that you implemented Add, their code makes a false assumption and breaks. (Say they're using a generic method that only accepts things that implement Add) You can: * Put traits from you onto externals * Put external traits onto your structs * Put your own traits onto your structs But you can't put external onto external.
Excellent :) I'm glad to see these kinds of knowledge-sharing projects popping up.
Note that since give_shape is using generics it isn't giving the variables square/circle the same type. If you need the type of Shape to be determined at runtime you'd use a Box&lt;Shape&gt; for an owned value, or an &amp;Shape/&amp;mut Shape for borrowed values
Yes, please. I have been waiting for new shading languages to pop up since I started working with Vulkan. This looks very promising.
Not an answer, but the full answer will inevitably lead you here: https://github.com/rust-lang-nursery/lazy-static.rs
&gt; the one that looks official has the fewest downloads It's the newest (to the Marketplace).
Not what I'm looking for though. I don't want the variable to be global or mutable, just made once and stick around. Lazy static is useful though, just not what exactly the same as c++ static.
I'm fully aware of that. :-] Both `static` and `lazy_static!` can be used in function-scope. EDIT: &gt; Lazy static is useful though, just not what exactly the same as c++ static. Actually it offers _identical_ functionality to function-scoped `static` variables in C++ that are initialized with non-constant expressions (normal `static` covers the case for constant initializers).
Not to mention, some people will simply refuse out of principle. Ever since Google started requiring a $5 one-time fee to gain the ability to upload Chrome extensions to the store, it's been my policy that, If I'm writing an extension to scratch my own itch and I want to share it, I'll put it up on GitHub with instructions for a Chrome or Firefox setup that doesn't enforce signing and wash my hands of it. If I actually *care* how many other people use an extension, I'll figure out a way to shoehorn it into a Greasemonkey/Tampermonkey/etc. userscript. (That's been policy for much longer since I've always preferred Firefox but hated babysitting `maxVersion` from the XUL-era extension manifests and refused to maintain two separate extensions to support Chrome once it came on the scene.) If crates.io started to require a nominal fee, I'd simply axe my "only use things on crates.io to provide some insulation against deleted GitHub repos" policy and start using direct repo URLs with a carefully-managed stable branch for all of my creations.
&gt; I guess I'm a bit older now, but back in my day, where I grew up, 13-year old me never would have been able to even pay the nominal $0.50 you're suggesting because my parents never would have let me use their credit card on something they didn't understand. If you were 13, you couldn't legally contribute anyway.
Right, but if using lazy_static applies the same effect as c++ static within functions, what's the difference between that and `static`? I'm a bit confused.
[This 3 minute podcast](https://www.briefs.fm/3-minutes-with-kent/39) makes some good points about the downsides of scoped packages, but I'd like to see it as an option. It'd help everyone if we could voluntarily use package names of the form `project/crate` to tie together crates which all belong to some greater whole. (eg. various optional components for a web framework)
I contributed to things around that age. I even sold stuff I wrote. Laws aren't everything, and not all geographic locations have the same laws. I wouldn't *dream* of standing in the way of a youngin' from contributing, nevermind beating them over the head with a book of laws. :-)
If you were an organization that didn't want your project to have any legal liabilities that could limit the public's access you would. This is why CLAs are a thing.
We've been in contact since we started using 'ash' for Vulkan bindings. /u/MaikKlein has been really helpful and writes amazing code. I'm excited to see RLSL, and it somewhat reminds me if RON ;) We'll definitely consider supporting it in gfx-rs, especially once it matures a bit. More detailed review to follow...
People still paid for my stuff and people still used it. Shit happens. (I know what CLAs are and I know what point you're trying to make. My point is that in theory, practice and theory are the same, but in practice, they aren't. And that's OK.)
I suspect the reason this has got so few comments is a combination of exhaustion around this stuff (how many related RFCs have there been??) and also a slight shift in feeling towards this feature: I know in the last RFC I argued very strongly in favour of allowing `impl Trait` in associated types/type aliases, because I felt that I wouldn't be able to take advantage of it in return type position without fear of "boxing" myself in (sorry) wrt not being able to name or store the type without extra runtime overhead. At the time it seemed like there was a lot of opposition to that, and certainly comments from many of the core team members suggested that this wasn't the direction that they wanted to take, or at the very least would not be done with the `impl Trait` syntax. However, with the new RFC it seems to have been received much more favourably, so congratulations on being persuasive, or maybe just the incremental step was needed to allay fears and doubts. I suppose in my case, I didn't comment for fear of jinxing it now that it seemed to be headed the way I wanted all along!
Yes, initially the team was more interested in a higher-level "`impl Trait` in traits" framing. I actually wrote up a whole RFC for that purpose [here](https://github.com/cramertj/impl-trait-goals/blob/impl-trait-in-traits/0000-impl-trait-in-traits.md). However, that approach requires making a lot of decisions about tradeoffs that are hard to analyze without first getting experience with how `impl Trait` is used. In the end, we decided that it'd be better to start with the more expressive type-alias version so that we can see how people use the feature in practice. Sorry you're feeling burnt out on `impl Trait`-- it's definitely understandable. I can't tell you how much I'm looking forward to seeing this on stable. I really just wanted to make sure I reached out to the community as much as possible before we move to merge a feature this significant.
Maybe we can fix that with Redox?
For those who want to skip to the code: https://github.com/vitiral/artifact
Makes sense, but is that the one that is the most fully featured?
Unless you really like having custom commands for Cargo vs. just using `tasks.json`, I haven't notice any downsides vs. Kalita's extension.
We at gfx-rs are very interested in Rusty shader solutions that could be portable across platforms. RLSL captures our attention and imagination, thank you for working on it! If you have to understand the today's and future needs of graphics developers, I'd highly recommend analyzing the shader language section of the latest [Open Problems entry](http://openproblems.realtimerendering.com/s2017/04-Future%20Compute%20SIGGRAPH%202017.pptx) presented at SIGGRAPH. I find the "Why not Rust?" section to be least convincing in your post. You already have Rust-like syntax, you already got generics/references/etc on your future work list. All you need is a *subset* of Rust to get the following benefits: 1. Sharing structure definitions (e.g. vertex buffer, constant buffer) between Rust and shader code. 2. Piggy backing on existing tooling for Rust, like [syn](https://crates.io/crates/syn), not to mention all sorts of syntax highlighters, maybe even `racer`. 3. Get users to become instantly familiar with your language, instead of learning a new one. I assume you'd need to have something like `libgpu` instead of `libstd` as well as forbid some of the language features (e.g. dynamic dispatch). In terms of syntax/design this thing stroke me as odd: ``` #[builtin(position)] builtin position: Vec4; ``` Either have all your I/O as globals (please, not), or have all of it functional-style: as arguments of the functions and their return values. As such, vertex position is a vertex output semantics, so should be a part of the return structure. I hope you find my criticism constructive! Looking forward to see future development and maturing of RLSL, fingers crossed ;)
Oh cool, being able to implement my on traits on externals could be very useful, I'll have to think how I would use that. Thanks!
What is the idiomatic way to handle bitshifts where the rhs is &gt;= the bit width of the value? For example, the below results in a deny(exceeding_bitshifts) compilation error: let i = 100u32 &gt;&gt; 32; There are a number of cases where I just want to shift and if the rhs is greater than the width then I expect to just get zero back. Is the right thing to wrap every shift inside an if/else to check the width? (That seems overly verbose.) EDIT: I've implemented the following, it solves my problem, I'm not sure if this is the right approach long term so certainly appreciate more feedback: trait SaturatingShl&lt;RHS&gt; { type Output; fn saturating_shl(self, rhs: RHS) -&gt; Self::Output; } trait SaturatingShr&lt;RHS&gt; { type Output; fn saturating_shr(self, rhs: RHS) -&gt; Self::Output; } impl SaturatingShl&lt;u32&gt; for u64 { type Output = u64; fn saturating_shl(self, rhs: u32) -&gt; u64 { if rhs &lt; 64 { self &lt;&lt; rhs } else { 0 } } } impl SaturatingShr&lt;u32&gt; for u64 { type Output = u64; fn saturating_shr(self, rhs: u32) -&gt; u64 { if rhs &lt; 64 { self &gt;&gt; rhs } else { 0 } } }
`cross` is not strictly necessary. The older versions of trust just used lots of docker and lots of scripts, look at [v0.1.0-rc13](https://github.com/japaric/trust/tree/v0.1.0-rc13), for example. You can probably get rid of much of that as well. Don't need thumb targets so don't need xargo, etc.
Try it. I'll look into it more tomorrow, but it might work. It's not fundamentally unsafe (when limited to way Rust limits it) but there might be a rule that you can't have a static in a function. The big limitations you'll run into are that `static mut` is completely unsafe (and not recommended at all), all types must be `Sync`, and all values must be statically initialized. (So no Arc or Mutex because you'd need to call constructors.) Atomics will work. They're titchy once threads get involved, but they will at least do what they promise. Instead of bare statics, more commonly used patterns are: - lazy_static - thread_local - factoring state into an opaque `struct` The exact one depends on use-case. For example that `generateID` could be done with an `AtomicUSize`, but only because the programmer can answer the question "how do threads interact?"
You could write a `Copy` wrapper for your non-`Copy` types.
ML has been open with its advances i hope cuda gets phased out, SPIR-V gives me so much joy
I'm also interested in deep learning but don't have time to take the course right now. Can it be taken at any time later?
I believe [`.wrapping_shr()`](https://doc.rust-lang.org/nightly/std/primitive.u32.html#method.wrapping_shr) might work for this use-case. As documented, it clips the shift count at the width of the integer type. I'm not sure if it would end at 0, it probably clips one shift before 0.
Nicely written
I'm interested.
Fwiw, that image does include OpenSSL. You would have to do the libpq install by hand though.
Had to watch the vid twice, got distracted by the trap flavored hihats. Seems useful!
Hi all, I'm super excited about a project a few acquaintances of mine are working towards. `rust-vst` is a library that hopes to allow programmers to write audio plugins for DAWs (like Ableton live) in Rust. I've already made a few things with it (like white noise generators) and while it's very early it's still super cool considering JUCE has a pretty good monopoly on modern audio plugin dev. I [want to mention the original creator](https://github.com/overdrivenpotato/rust-vst2) for his awesome work (we hard forked after our PRs were stagnating for months, and we wanted to move along). This is very early and we're looking towards GUI stuff next, but I thought it was a cool enough thing to share, especially to those of you that like creating digital music. PS: There's a telegram chat for anyone interested in contributing, PM if you'd like it. 
~~OPTICS and HAD SCAN are extensions to DBSCAN which is a density based approach that unlike other clustering algorithms, allows for some points to not be in any cluster.~~ ~~In comparison, hierarchical clustering (which comes in agglomerative and division variants) is based off the spatial distance (not density) of points. It must put every point into a cluster.~~ Completely misread your question lol. In my experience this comes down to the specifics of your data, your problem donation and the scale of your data. Because they allow for points if no class classification, they're good for when you have quite noisy data that doesn't always neatly or cleanly fit into your categories. They're also very preferable if you have a general sense of your behaviour of your data and you know that you have non-blob-like (in a spatial/graphical sense) groups, or structures like rings/concentric groups etc (these can be handled with hierarchical methods using connectivity matrices, but in very high dimensions, these *can* be unwieldy). Density based methods also tend to scale very well. If I've missed anything, hopefully someone with more data science experience than me can correct me/add on.
Unfortunately wrapping_shr() doesn't achieve that, it merely masks the rhs to ensure that rhs won't be longer than the bit width. I.e. with u32::wrapping_shr(RHS) the RHS &amp;= 0b00011111.
I'm pretty stoned so I enjoyed this but I'm pretty sure sober me would just want text/image documentation. 
Namespaced packages have the downside that it can become quite hard to figure out what the canonical package is. Elm for example has this problem. Be careful what you wish for!
Also interested
We really need a solution for this. I don't know which one, but we do.
&gt; Generally I'm against stricter control of crates.io though because I don't want the Code of Conduct or other political agendas or political views of members of official Rust teams to be forced upon the crates ecosystem. That's really a wide jump. But, to be clear, the code of conduct is in place, as per: http://doc.crates.io/policies.html
Hihats are very useful! 
Yes please. Thank you.
&gt; [...] am I in the right direction with `mem::transmute(f as usize)` ? If you have to ask that question, you *should not be using transmute*. So far as I can see, the way you're doing this does not work, and cannot be made to work. You fundamentally do not understand what you're doing. You **cannot** just cast around function pointers like that. There is **no way** to pass a Rust function to C code expecting a C function. Hell, the argument types aren't even compatible! &gt; I'm in a bit over my head with some of this. This isn't a swimming pool, this is the *Mariana Trench*. Let's just pretend you haven't written any of that and start again... --- So you want to make a higher level binding? The callbacks are going to be a pain. Because the callback interface doesn't appear to have any provision for associated data to go along with the function pointer, you're going to be limited to statically defined functions. The principal issue is that you *need* to translate between the C and Rust ABIs and types. They just straight-up aren't compatible. So, there has to be a layer between the C lib and the Rust callback. Without some way of attaching state to the individual callback, you're going to need a unique translation function (to go between the C code and the Rust code) for every Rust function you want to use as a callback. The way I've handled this in the past is to have a macro that generates this translation layer automatically. For example, it might look like: yoga_measure_fn! { fn measure(node: Node, width: f32, width_mode: MeasureMode, height: f32, height_mode: MeasureMode) -&gt; Size { // do stuff } } Which would expand into something like: unsafe extern "C" fn measure(node: internal::YGNodeRef, width: f32, width_mode: internal::YGMeasureMode, height: f32, height_mode: internal::YGMeasureMode) -&gt; internal::YGSize { fn measure(node: Node, width: f32, width_mode: MeasureMode, height: f32, height_mode: MeasureMode) -&gt; Size { // do stuff } assert!(!node.is_null()); let node = Node { internal_node: node, should_free: false }; // This should be pulled out into a function or trait impl: let width_mode = match width_mode { 0 =&gt; MeasureMode::Undefined, 1 =&gt; MeasureMode::Exactly, 2 =&gt; MeasureMode::AtMode, _ =&gt; { // Abort because you MUST NOT panic through an FFI boundary. println!("error: invalid measure mode `{:?}`, aborting", width_mode); ::std::process::abort(); } }; let height_mode = match height_mode { ... }; let r = measure(node, width, width_mode, height, height_mode); r.into() } Note that I'm not using `transmute` anywhere in that. `transmute` isn't just the tool of last resort, it's the nuclear option. You need to be 110% certain of what you're doing, or *don't do it*. I've seen so many people make catastrophically terrible mistakes with `transmute` it just isn't funny any more. Anyway, that effectively redefines `measure` to be a real C callback that wraps around the Rust function. It's also where you should do any necessary input checking and validation. Remember: if *you* don't assert the invariants Rust guarantees, *no one will*. If the library gives you an iron-clad guarantee signed in blood that a given pointer will always be not-null, you can restrict the checks to debug builds. But if it doesn't, assume the C library could feed you almost any kind of potentially malformed data and that you need to check it. If you have to define a *lot* of these, it might make sense to have a general macro plus some kind of "RawToNative" trait that performs the necessary conversions and checks. But that's left as an exercise to the reader because otherwise I'm just writing your binding for you. :P
As someone with experience with the "all new projects must be approved by moderators" era of SourceForge, let me say that even no-fee pre-moderation sets up a psychological barrier. Requiring some form of pre-emptive sign-off encourages people to feel that they're consciously and explicitly committing to something, which can be demotivating even if the end result would have been the same otherwise.
Thanks! I was worried as well about the callback not giving a way to pass along associated data. I gave transmute a try because although the types are technically not the same, they are defined with the same exact data types and layouts, and with the same `repr`. But yeah I don't want to use transmute if there's another way, I realize the danger in doing that (this is not a published library and the linked code was created as a demonstration/question) I'm fine with the macro method of wrapping these functions if that's the only way, I'll give that a try next. These functions won't be used often anyway so the reduced ergonomics aren't a big deal. &gt; I've seen so many people make catastrophically terrible mistakes with transmute it just isn't funny any more. While we're on the topic, what is the worst thing you've seen happen with transmute?
The opposite would've been surprising, to be honest :p
&gt; [...] although the types are technically not the same, they are defined with the same exact data types and layouts, and with the same repr. Except they're not. I mean, you have `struct Node { n: NodeRef, free: bool }`. It doesn't matter if you put `#[repr(C)]` on it, it's physically a different size. &gt; [...] what is the worst thing you've seen happen with transmute? I don't keep track. I spent years tutoring computer science, so all the really, *really* awful abuses kinda blur together. After a while, you just start forgetting the details in a vain attempt to retrain what's left of your sanity. But transmuting function pointers between ABIs and physically incompatible types is pretty up there. I can't think off-hand of how you could have gotten that *particular* conversion more wrong... unless you'd been running on a Harvard architecture machine and had transmuted from a data pointer. But that seems *really* unlikely.
You're right, I noticed the discrepancy between `Node` and `internal::YGNodeRef` right after I posted that. Out of a sick curiosity I fixed that point and changed it so the ABIs match and now the test passes. At this point from what I can understand, the risks are that the passed `Node` could be null, and the `MeasureMode`s could be invalid values passed from the C library. What other risks are left now? I'm not satisfied with "don't ever use that". Even if I never actually do use it, I'm more interested in learning about it than blindly ignoring it.
I was at the "after" party last year. I can be there this year too.
I think I'm going with the Iterator solution, if someone needs a Vec it is easy to call collect. Thanks for answer! 
Seriously, this is the most exciting post I've seen on this subreddit so far. Doing VST development in Rust sounds like a dream - keep up the good work!
Well, there's no particular guarantee that that enums will be the same number of bits, or even necessarily encoded the same way, since you used `#[repr(u32)]` rather than `#[repr(C)]`. Also, just to re-emphasise: *not* validating the values is not an option. As an example, having a Rust enum (even one marked with `repr(C)`) which contains a value that does not correspond to *exactly* one variant is undefined behaviour. Beyond that, I can't think of anything. Of course, that doesn't mean there *aren't* any remaining problems... Also, I forgot to make sure you've seen a link to [The Rustonomicon](https://doc.rust-lang.org/nomicon/), which is the closest thing we have to an unsafe guide at the moment.
&gt; I find the "Why not Rust?" section to be least convincing in your post. The biggest reason why I started my own compiler is that I have no experience in writing compilers and it would have been hard for me to use the rust fronted directly. But I feel confident that I could make use of the Rust compiler now. &gt;Sharing structure definitions (e.g. vertex buffer, constant buffer) between Rust and shader code. I agree that would be nice, but I also have to think about other languages as well. I don't want to make it really nice for Rust users but neglect every other language. But I have to say that not using the Rust compiler starts to make less sense now. I think every feature that I envision could be expressed with existing Rust syntax. Also vertex input is a bit weird, for example you can't input custom structs. Previously I didn't map `Vec4` directly to the SPIR-V primitive and I was not able to send data from Vulkan to the shader. The same is true for GLSL, I probably have to split the struct up into primitive types under the hood. But this is mostly a backend thing. &gt;Piggy backing on existing tooling for Rust, like syn, not to mention all sorts of syntax highlighters, maybe even racer. The reason why I didn't use syn, is that I don't think that it can parse all Rust at the moment. https://docs.rs/syn/0.11.11/syn/ I wrote the parser with https://github.com/nikomatsakis/lalrpop which was relatively easy to use. (I could have extended it though) &gt;In terms of syntax/design this thing stroke me as odd: `#[builtin(position)] builtin position: Vec4;` Either have all your I/O as globals (please, not), or have all of it functional-style: as arguments of the functions and their return values. As such, vertex position is a vertex output semantics, so should be a part of the return structure. You mean like in HLSL? That was the plan, sort of. I am not sure how I would express it yet. I just temporarily implemented it this way because it maps nicely to SPIR-V. OpDecorate %position BuiltIn Position %position = OpVariable %_ptr_Output_v4float Output I could also envision that those variables are tied to the vertex entry point, similar to self in methods. `self.position = pos`. Edit: I also forgot one big point and that is optimization. For example what happens with iterators? Not optimizing them is probably not a good idea. But iterators are still pretty amazing and they would probably also have value on the GPU. Maybe I could use Rusts llvm backend and then I manually translate llvm-ir into SPIR-V. There are probably a lot of paths to take. 
You are right no timelines for async. There were some discussion in github but there is no clear direction on that yet
Alright, I've got some reading to do. Thanks for all your help!
I think for the near term people won't have problem coming up with a good unused name. It will suddenly not become a problem. When there is indication of a real problem, a solution will come up. :-)
We could simply use hashcash (find `n` where `SHA256(crate_hash || n) &lt; difficulty`. difficulty should be so low to take a average computer 1 minute to find such `n`) to deter most bots.
Bots are better at solving CAPTCHAs than humans.
What's your reason behind it?
I'll probably be there.
&gt; Because the callback interface doesn't appear to have any provision for associated data to go along with the function pointer, you're going to be limited to statically defined functions. I think it'd be possible to use trampolines, but I never tried that.
... how? I think this is not possible. For example, if a struct contains a `Vec`, it can't be `Copy`, because being `Copy` means you can clone the struct just by doing a bitwise copy, which you can't do with a `Vec` because that's a pointer to an array somewhere on the heap. I don't see how you could write a wrapper that does somehow work with bitwise copy.
You're welcome.
The problem with using trampolines in this context is that the Rust ABI is undefined. If it weren't for that, you *could* do it... but it would also be a lot of work, and wouldn't would everywhere.
Redox will hopefully have fantastic asynchronous file I/O support. But that won't do anything to fix legacy platforms like Linux.
I refuse to endorse a system I disapprove of (financially or otherwise) if at all possible. Same reason I neither pirate nor pay for DRM-only games. By doing so, I prove that their not receiving my money is *not* because I pirated their game instead and I avoid the implicit endorsement that a game is so desirable as to be pirated.
It would be interesting to try to improve on the rust level instead. I'll try when I'm home, especially if c += (condition as usize) helps.
If I had to rename it, I’d go for Viktor, as a reference with Hugo and Lektor. But that’s none of my business…
FWIW, in British English, the winter holidays are often the "festive season".
That has already been done (and is even mentioned in the original post), see my comment on lobste.rs about this: https://lobste.rs/s/xofbxo/rust_performance_finishing_job#c_i03hh5
This user isn't doing anything "really" wrong, but the contact details are on github and it looks to be a high-school student. IMO if somebody wants to use any of those crates names, it might be better to start by sending an email asking nicely about it, before kick-starting the discussion about launching nuclear missiles... Chances are that if we don't behave like dicks this user won't either.
To make a test for each impl you can use regular macros. Just write the tests in a macro, and invoke that macro for each type you want to be tested. Here is an example: https://play.rust-lang.org/?gist=b8983e55d1f65e036e85d3a21403f45f&amp;version=stable
&gt;The instructions we want to use only work on data that's aligned to a 16 byte boundary, so we need to run the slow loop a few times if haystack is not aligned (this is called "loop peeling") Can't we use unaligned load operations here? If I am not mistaken on modern CPUs `movups` and `movaps` have the same performance.
From a first glance, it looked like these would be solely namesquatting crates, but to be fair, two from 11 crates look actually ~~legit~~ used (ice_core and cervus). But claiming repositories like "alipay", "baidu", "bot", "server" in combination with "i", "y", "l", "h" makes me kinda wonder whether or not he is collecting trophies. Maybe i'm just paranoid :D Also, as /u/0b_0101_001_1010 pointed out, the github account behind it looks legit, so right now i give him/her the benefit of the doubt. Time has to show :)
And you also need to wrap `measure(...)` and `r.into()` in `catch_unwind`, right?
cool, but maybe longer Readme file? :)
&gt; You mean like in HLSL? That was the plan, sort of. I am not sure how I would express it yet. I also find these weirds. First function arguments should be inputs, and the return type should be the outputs, so to me `Input&lt;T&gt;` looks unnecessary, and as far as I could see, there isn't an `Output&lt;T&gt;` anywhere. Also, kill the globals, it makes code way harder to test. Passing the globals as function arguments and returning them as outputs might require you to restrict certain shaders to certain signatures, but that's the way it is. Maybe coalesce all the globals in a struct, and force the first argument to be that struct, and then force the return type to be a tuple, where this argument is the first element of the tuple or something like this. 
Ah, right. Totally forgot about that.
Sweet! I'll definitely be trying this out.
&gt;First function arguments should be inputs, and the return type should be the outputs, so to me Input&lt;T&gt; looks unnecessary There is also `Uniform&lt;T&gt;`and `Instance&lt;T&gt;` although instance is pretty much the same as `Input&lt;T&gt;`but I thought it would be good to differentiate them. It is all just temporary syntax. &gt;Also, kill the globals, it makes code way harder to test I know but that is currently how SPIR-V looks and it was easy to generate the code that way. I am thinking of doing something similar to HLSL with a `POSITION` "type". struct VsOutput{ position: Position, .... } vertex vs(pos: Input&lt;Vec4&gt;, m: Uniform&lt;Mat4&gt;) -&gt; VsOutput{ ... VsOutput { position: pos } } Or maybe struct VsOutput{ position: Position&lt;Vec4&gt;, .... }
&gt; I refuse to endorse a system I disapprove of (financially or otherwise) if at all possible. Yeah, I understand this concept. What I wanted to know is why would you disapprove paid publishing on crates.io.
Maybe the compiler could generate appropriate code for it.
`static` is essentially the same in Rust and C. The only difference is that Rust does not have any way to run code to initialize the variable before `main` runs. Rust's statics can therefore only be initialized to a compile-time constant, which gets placed in the binary's `.data` section. `lazy_static` solves this by running the initializer on first use instead, and setting a separate static boolean flag to indicate that the variable has been initialized. This has a slight performance penalty, since the flag has to be checked on every access, but in practise that penalty is often negligible. 
It *does*... when you write a C function that calls a Rust function. It's just that if you wanted to get the compiler to do this at runtime, you'd have to drag in most of the compiler, plus LLVM, plus the necessary metadata, *and* a platform-specific library for managing the trampoline itself.
I suspect you could. But the inner loop still needs to operate on 16 bytes at a time, so you still need at least one version of the "slow" loop before or after the inner loop.
I kind of feel that they're engaging the wrong side of the brain with this presentation approach. Ooohh, twinkly lights and music! Not sure what the text was saying. I'll check out the code link someone else posted.
I was thinking in the context of assembly, so if you've loaded data into SIMD register you can now execute operations over it. Maybe it's worth to test `asm!` solution to this problem. UPD: Also `asm!` will allow to play around instruction level parallelism a bit.
Well, I mean, there is a `_mm_loadu_si128` intrinsic that you can use, which specifically permits unaligned loads. At least, that's what I had in mind. :-) But the operations act on 16 bytes at a time, and if you need to search 17 bytes, you still need something to account for that last byte.
Perhaps better to opt out completely, e.g. just use MD5 hashes or random sequences of characters for crate names. Depends how bad it gets. It's not like you can build up an identity, e.g. always prefix with your project name (e.g. tokio) because someone could squat all those too. Seems like a race you can't win. So better just use random unique 5-character names.
I meant we can remove "slow" loop before the simd core, but of course after it you'll still have to peel.
Oh, I forgot to mention that I meant stack-based trampoline. Couldn't compiler just create some template that would be copied at appropriate place and modified to contain pointer to data?
&gt; the language should not be aware of the concept of crates Preach! I was saddened that the new modules proposal gets rid of one connection between the language and crates, but introduces another through the crate:: syntax. Oh well. I can't think of any other language lets the concept of distribution units creep into the language itself. Usually, using a library just means a load of modules/packages/namespaces just magically appear, as if they had been added to the standard library. That seems like a good design decision to me.
sure, I get you can do that, regular macros are great; what I imagine here though.. perhaps a project wide procedural macro could automatically roll them.
Well, first of all, I'm not aware of any major OS these days that even *allows* you to execute the stack. Secondly, I'm not sure it being on the *stack* is really important, since you don't want to be limited to just setting callbacks that can't outlive the current stack frame... which now that I think about it would also complicate any API that uses them. Finally, I suppose the compiler could theoretically generate an almost-but-not-quite complete function with what amounts to one or more unresolved symbols. But that would require either a new codegen backend, or to somehow convince LLVM to only... *partially* link an object file?
Np++ is one of the things I miss in Linux.
That RFC for [Ok wrapping](https://github.com/rust-lang/rfcs/pull/2107) is interesting. I would definitely really like a bit of sugar around this! I wonder if there's any way that we could start off with a macro-based implementation of this, to buy time to bikeshed the syntax before setting it in stone. There are a lot of options for the syntax, and some highly divergent opinions, and that feels like a recipe for a suboptimal decision. Whether that's possible or not, i encourage everyone to read the RFC, and the discussion, and give whatever feedback they have. This would become a feature of the language that would be in your face all day, every day, so it's worth getting right. 
I am a bit puzzled that the original article fails to mention [bytecount](https://github.com/llogiq/bytecount), which can use both SIMD and AVX extensions on nightly, is 100% Rust and probably faster than the author's C++ source (at least it outperformed D. Lemire's handcrafted C code in our benchmarks).
&gt; I'm not aware of any major OS these days that even allows you to execute the stack. AFAIK, this is configurable and can be turned on/off during application compilation. But maybe I'm wrong here - I'm not an expert on this. &gt; since you don't want to be limited to just setting callbacks that can't outlive the current stack frame... True, could be on heap as well. &gt; Finally, I suppose the compiler could theoretically generate an almost-but-not-quite complete function with what amounts to one or more unresolved symbols. But that would require either a new codegen backend, or to somehow convince LLVM to only... partially link an object file? I guess the function could live in the `.text` section normally, but not being executed. The code would simply memcpy that function and modify the address of data.
Linux has plenty of other really good text editors. I don't know what there is to miss.
why? It runs fine in Wine.
Awesome, using n++ almost daily. finally build in rust support.
We also have [mahkoh](https://crates.io/users/mahkoh), but at least IIRC he is willing to give squated names to the projects.
Kate :)
How do other repositories like pip and npm handle this problem?
&gt;Note: Making code generic over primitive types is currently pretty painful and hopefully will be fixed in the future. Could someone elaborate on this? I personally don't feel like making code generic like fn foo&lt;T&gt; (operand: &amp;mut [T]) where T: Add, Sub, PartialOrd or whatever is particularly onerous.
I run it in Wine
We need an editor written in Rust. I think I just found my first big rust project idea. 
Base it on Xi
You have a problem with constants. if operand &lt; 0 { } Does not work. [this](https://play.rust-lang.org/?gist=9d65cd2180b1bc913486be44cc321a27&amp;version=stable) is the best you can do regarding terseness. (thanks the kind people at `#rust-beginners`)
Interesting, TIL.
Oh wow, I forgot that existed. Yep. That's what I'm gonna do. 
Rewrite [CherryTree](https://github.com/giuspen/cherrytree) in Rust, and you'll be like a God among men.
The question is, though, is NP++ being rewritten in Rust?
Yeah, documentation was never my strongsuit. ☺️ I'll add some more detail as I get time this week. In fact... https://github.com/ghotiphud/rust-web-starter/issues/4
This was first requested on /r/firefox not too long ago and it was posted there yesterday as well where I saw it, figured people here might be interested as well.
Can you name some? I've looked and haven't found any that are easy to install on Linux and are as good as N++.
This was my idea until I wanted to use Qt quick. I'm currently working on a personal project that tries to have the same package control mechanism as sublime text has, and base it on modern Qt Quick. Hence I picked C++. Gtk is fine too, but I haven't done any GUI before and GTK's documentation is not really novice friendly.
You might want to consider renaming this. There is already a database engine / java library named h2, and your library exists in kinda the same niche (web-dev).
Sublime text
"The Rustonomicon" ...that name... needs an upgrade, to something less cringy.
I extended transform.now.sh to derive Serde structs from a json sample. There may be rough edges, we're happy about pull requests for bugs.
I think it's an excellent name.
Feel free to post your own thread.
I don't recall bytecount being available when I first wrote my profiling post, but I think you're right that it'd be a much better solution for this problem! 
Sorry, I should have mentioned that the video is intended for a larger audience. I'm posting here first to get feedback. Do you think having `github.com/vitiral/artifact` on the first image would be good?
Though we haven't incorporated the idea of using 32-bit counts yet. This might give us a small advantage on smaller slices. I shall make some measurements... Update: Yes, it's faster than a naive 64bit count, but still slower than bytecount for slices of more than 32 bytes (perhaps even lower, but measurement is hard 😎).
that's a good idea, I'll do that right now! I'll include images here: https://github.com/vitiral/artifact/blob/master/docs/QuickStart.md Stay tuned!
I'm using Kate and it's great. Infamous emacs and vim exist, and there is gedit, for which I don't know all the features.
The goal of the video is to get people to check out the repo link, since there is only so much I can say in a minute and a half commercial created by a complete amateur can do. You're checking out the link so... hopefully it was effective? If you have an suggestions let me know! Creating an advertisement is hard!
I've never before been so flattered as to have a "takedown" post published as a reply to my own! As with many bioinformatics applications in rust, I suspect the ideal solution here would be to use const generics (landing soooooon I hope) to statically dispatch to either a regular loop or a manually vectorized one, depending on slice size. I'm very excited for simd support to be stable to enable this, given that rust-bio is a stable-only library. I personally have a few projects that I'd love to implement in pure rust rather than linking to a simd-intrinsic-using C library. 
Just like your enemies, keep your dependencies close, but keep your frameworks _closer_.
It's really unfortunate that I wrote that perf "tutorial"/narrative so early on in the process of learning about optimizing these kinds of algorithms. It seems like great information for Rust users, but it's occasionally embarrassing how little I knew about assembly and vector ops at the time!
There's got to be some Turing test they haven't beaten yet. What about what reCaptcha's doing now with identifying objects? I doubt anyone's going to train a neural network just to squat some crates.
VSCode, Vim, Emacs, Geany, Bluepad, Qt Creator, GNOME Builder
vim and emacs aren't quite in the same space being text-only. VSCode, Qt Creator, GNOME Builder are all IDEs, which aren't comparable with Notepad++. Geany I tried, but forgot why I discarded it. But it looks like Rust support has improved since then, so I'll need to check it back out. Bluepad doesn't turn up anything, can you link to the project?
The qml crate is pretty good right now to build QML UIs with Rust backends. It just uses a macro to wrap and expose your types to the qml engine.
Ah, I see. Thank you!
[removed]
I believe the idea is that when you see that message, some dependent crates are still being built. If you allow those to finish building, they'll be *done*. You won't have to worry about building them ever again for that project, unless you update your dependencies. If you ctrl-c, then the build process for those crates which are unaffected by the error message must begin again. In your case, if you let them finish, then you shouldn't ever see that message again when running `cargo test`, but somehow you haven't ever finished a complete build of your dependencies*. So, either the processor does things now, or it does them later. Definitely no harm is caused. \* If you have a crate somewhere in your dependency chain that rebuilds itself every single time (it's in a constantly dirty state), then this message would just be annoying, but a constantly-dirty crate is a bug, in my opinion. An example of a constantly-dirty crate is one of `Gotham`'s dependencies, `borrow-bag`. [Issue is here.](https://github.com/gotham-rs/gotham/issues/18) It's being caused by a bad `build.rs` script.
I think a demo of Pathfinder might also appear sometime on http://www.pathfinder.graphics/ :)
hmm... I haven't heard about the java lib. However, "h2" is the official string that represents the HTTP 2.0 protocol when doing protocol negotiations.
https://m.youtube.com/watch?v=SKtQgFBRUvQ
&gt;[**RustConf 2016 - A Modern Editor Built in Rust by Raph Levien [36:16]**](http://youtu.be/SKtQgFBRUvQ) &gt; [*^Confreaks*](https://www.youtube.com/channel/UCWnPjmqvljcafA0z2U1fwKQ) ^in ^Science ^&amp; ^Technology &gt;*^14,246 ^views ^since ^Oct ^2016* [^bot ^info](/r/youtubefactsbot/wiki/index)
What does text-only mean? You're looking for a text editor so it's not immediately obvious, even if it were true, what the issue is. (Emacs can display images FWIW.)
You should only have one callback function. You must write it because it has to be `unsafe` and your wrapper is the designated expert on calling or being called by Yoga. This callback function would: - catch panics so they don't go into C and crash or worse - *somehow* figure out which user function to call (Rust style) This means you need to get a dispatch table into the callback-dispatch function. Yoga is slightly broken, or at least poor style for C: it doesn't give your callback a userdata argument. So the only other way to pass that information is through global state - and you must therefore think about thread safety. 
I understand. On the other hand, I think that the current mod-commenting workflow is flawed in itself: it's a work-around for only compiling a subset of a crate. What I *really* wish for would be a way to only compile the necessary dependencies for a specific unit-test binary. That is, I wish I could say `cargo test --minimal-compile xxx::yyy::zzz` and have `rustc` perform the smallest unit of compilation necessary: 1. It would reduce compilation time, 2. It would considerably ease refactoring. I am hopeful that with the work on incremental compilation, the necessary groundwork for figuring out which are the dependencies needed will be laid out.
Doesn't handle negative numbers correctly, defaults to `u64` which I believe cannot express negative numbers. Changing a literal to a `-1` didn't change it to a signed number. Doesn't handle `-1.5` correctly either. You probably want an arbitrary precision floating point number for this to avoid precision problems. Here's the representation Haskell's main JSON library uses: http://hackage.haskell.org/package/aeson-1.2.1.0/docs/Data-Aeson-Types.html#t:Value I took a look at serde_json, I think you'd want to reuse the types their `Value` type uses. [Number lives here](https://github.com/serde-rs/json/blob/master/src/number.rs#L18-L32). I'm not sure I'd use `f64` to represent fractional numbers for this kind of data but it's better than defaulting to `u64` I think.
I can't speak for /u/ssokolow but this entire concept of paid publishing seems very strange to me. Why would I pay money to give away my code? None of the other major repos work this way (npm, rubygems, maven, NuGet, etc)
Remacs! https://github.com/Wilfred/remacs
VSCode is actually a very nice general text editor, and somewhat similar to notepad++ besides the ui
Why don't you roll your own?
interesting - this did not occur to me because unlike on a successful compilation, there's no message regarding which other crates are being built. I just checked and I still got the message when only the current crate was edited, but it was quite fast, relatively. thanks!
I was mistaken. I thought that `Clone` was all that was necessary to `impl Copy`, and it would just cause the compiler to auto-clone things, but you're right; a type can never be `Copy` unless all of its members are `Copy`.
Thanks for sharing! Spotted a bug: Invalid identifiers just end up as quoted field names. I think if there's an invalid identifier in a JSON map, it should just use `Map&lt;String, Value&gt;`.
Why do you need another editor? Why do you care about its implementation? I got another big Rust project idea for you: a debugger, as existing debuggers suck.
And vim has a GUI. Though they are not really newbie-friendly, one has to relearn basic editing of text.
You could have this as an *option* but not a *requirement*. So you could have "confirmed crates" that take $0.50 to reserve a name for, and "unconfirmed crates" that are free to register names for. So, things that someone cares enough about to put a minimum amount of effort into, and things that are just people messing around. *Without* locking anyone out. I would gladly throw $1 a month into a patreon that sponsored confirmed crate names for good crates that can't otherwise meet the bill for one reason or another. I don't know if this is something we actually want, but it's an idea.
Why can't you use Eclipse/Idea/Electron on ARM?
I don't know. I guess reCaptchas are secure now but it's probably a matter of time until they stop working.
Aww missing the afters again due to scheduling conflicts =(. Have fun folks.
I agree it's strange. I'd find it reasonable to ask small fee in order to avoid spam. I'd even accept [Proof-of-burn](https://programmingblockchain.gitbooks.io/programmingblockchain/content/other_types_of_asset/proof_of_burn_and_reputation.html). So I'm curious why other people don't approve such scheme.
I was a complete novice when I learned GTK. The documentation is alright
Given people's reaction to my comments, I don't think it matters. The entire point of the tiny fee was to prove trustworthiness of the user while also funding language development and upkeep, barely. I suggested a couple ways that young, poor or anonymous users could have the fee waived by proving trustworthiness in other ways, and that was also downvoted. Apparently what people want is an ecosystem where trust doesn't matter, and the results of that can't be erased. Perhaps package namespaces would actually be a better solution. Avoid trust altogether by sandboxing users. Of course that would lead to fragmentation when a project is forked, and make searching for packages difficult when malicious users or bots publish the same name package but with malware in a build script and so forth. Looking at the download count might prevent that kind of attack from working, maybe. No solution is perfect, just relying on good behavior of its users.
Last I looked, all three required native components that weren't compiled/distributed for ARM. Are you using any of them on ARM, aarch64 specifically? Atom seems rather nice for rust dev on X86. I'm also familiar with and fond of Eclipse as an IDE too.
If it helps, we've been working on [a FFI guide](https://michael-f-bryan.github.io/rust-ffi-guide/) for people who want their Rust to co-operate with other languages. That'd probably help the OP if they need more of a step-by-step guide to doing FFI like this.
As an aside, does HTTP/2.0 offer any performance increase for RESTful services? I know it's main performance benefit is servicing static files, right?
Which OS? Seems as relevant as the architecture. 
/r/rustjerk
Thanks so much! This is the reason why I started learning Rust. It's crazy how easy it was to pick up the basics from someone like me who is more accustomed to high-level dynamically typed languages like Ruby and I'm really happy with it so far. It's just really fun to program with.
I think its a turn off for the non-hacker type of coders. Unprofessional is the word I'm looking for. Bring on the downvotes!! ;)
It's a tradeoff, really. You can get a bot to solve CAPTCHAs but it's going to be more of a pain than it's worth to squat a few crates, and anyway you're rate-limited so what's the point. The rate-limiting itself would probably be enough as long as someone doesn't bot-farm Github accounts.
Feels like Zim. http://zim-wiki.org/
Arch Linux ARM
That's a really cool article, thanks!
Wow, that's horrible. There are certainly great things about Rust, but the CoC and its enforcement are not one of them. Just waiting for the first occasion where a crate gets banned because it uses the word "stupid" in its documentation...
Notepad++ is a GUI program providing simple display of text files using a nice tabbed interface. It has some advanced features on top of that, but at its base that's what it is. vim and emacs are not comparable as they're not GUI programs. I was curious about similar programs to n++, not every programming editor out there.
How's the start-up time and does it handle single-files just fine or is it project-centric? I've thought about checking it out because it keeps coming up (along with IntelliJ) as the best full IDE for Rust. But I also need a reader for various text files I interact with that should be very fast to startup and support many languages with syntax highlighting. I loved the usability of n++ and how easy it made thing for me on Windows. My go-to on Linux is Gedit, which doesn't have as good language support (like following good tab settings and auto-indenting-on-return etc.).
I have strong feelings about the use of artificial fees as a barrier to entry for a variety of reasons. Some specific to this sort of thing (eg. I was one of those technically-skilled teenagers who couldn't ask for a parent's credit card) and some as part of a more general system of views on fees which aren't justified by proportionate costs. (eg. charging per gigabyte for Internet when the flow of bits doesn't cause wear-and-tear on the wires and a "prepaid credits"-style system just causes usage to be even *more* uneven.) At least with the Apple developer license fee, it's an obscenely marked-up version of a fee structure similar to "unlimited" web hosting plans. If you want to keep squatters out, use something any bright kid has access to, like a combination of a CAPTCHA, hashcash, and a policy that allows squatted names to be evicted.
Hmm.. the situation is worse than I thought. All three of them should be buildable from source. Maybe try that? VS Code looks like it has a pretty simple build process so it could be worth trying too.
I'm not sure this is the best place for a wasm question...
Ok, where do you think would be better for it? Although the memory dropping is Rust :/ 
Tell that to IPv4, the "solutions" that come up via that methodology tend to be crutches not fixes.
Thanks, I didn't know about that sub. That comment is now my most downvoted comment in history.
Vim mah dude
VSCode is a good text editor, but now intellij is the superior rust IDE imo. VScode can open single files, multiple random files at once, or if you open a folder it will act as a project. It starts up in a couple seconds, and has an extension for pretty much everything, and it includes basic stuff like smart tabs out of the box. I really recommend it as a n++ replacement, and if other IDEs are too heavy, it'll work as lighter replacemwnt too
Thank you for this. I've just installed it and it works well!
Can you define what you mean by GUI? Both Emacs and VIM have what I think most would call GUI's that use GTK; Emacs can even display images in buffers.
We've made it ya'll.
~~Nvim~~ Neovim with Completion Manager and RLS come pretty close to a full IDE, if you know how to use Vim's built-in tabs and folding.
This suggests enabling webrender, but my understanding is that doing this still keeps the old renderer running, so you're just extra slow? I only skimmed the article, is this not the case now?
In `from_bytes`, you call `mem::forget` on the input `Vec`. That *definitely* leaks memory since you don't reconstruct the Vec in your `drop_vec` function. To make it safe, you also need to store the original vector's capacity in your `JsVec` and call `Vec::from_raw_parts` using the original ptr, length, and capacity so that *that* can be dropped and properly clean up the `Vec` that you forgot. Your `Box`/`*mut` manipulation looks fine to me though.
indeed, but I think it's possible/probable this is where the Pathfinder2 demo, currently being worked on, could be published 
You might like Geany. I would also suggest Atom or Sublime text, but try are closer to an IDE, and may be too bloated for you if you're used to N++. 
Yes, HTTP/2.0 offers huge benefit for service type applications. For example, grpc (https://grpc.io/) is only a light layer on top of H2. When possible, it would be much better to use h2 over h1 for services.
Thanks for reply! &gt; I was one of those technically-skilled teenagers who couldn't ask for a parent's credit card Yeah, I can relate to this too. I kinda like the idea of waiving fees for people whose code is worth it. I'm not sure what's the best approach. &gt; charging per gigabyte for Internet when the flow of bits doesn't cause wear-and-tear The pricing was misunderstood aspect of economy for a long time until Subjective theory of value was discovered. The thing is that wires have limited capacity and the companies try to fit as many people as possible. If one wants higher capacity, he needs to pay more. After understanding economics well enough, it makes perfect sense to me.
Thanks a ton, I updated the gist with your suggestions. It seems to work now as when I log the subarray in JS, it becomes overwritten after I drop it.
Was a little bored, so I ported the C to Go (and implemented the Rust `i +=2` fix)... Results with Go 1.8.1 and Rust nightly on a Intel i-3550: C - primes: 664578 | time taken: 7.073 seconds RS - primes: 664578 | time taken: 7.435 seconds Go - primes: 664578 | time taken: 8.222 seconds
I think it might be actually part of his own crate, not a dependency (it is quite common for a single crate to be created by multiple runs of rustc and they sometimes run in parallel ‒ if you have a library, several binaries, several integration tests, etc). I think it waits for all of these so you could see all the error messages and fix them, not just error messages from the first one. Anyway, it should be pretty safe to halt it. I could imagine something going wrong (writing the build artifacts is probably not atomic, so something like half of the binary could be dumped instead of a whole one ‒ but the chance of that is pretty small). Anyway, the worst thing that could happen (which probably won't) is you having to run `cargo clean`.
Well, from a vim user's POV, using VSCode, Sublime, Np++, etc implies relearning all advanced editing.
&gt; The pricing was misunderstood aspect of economy for a long time until Subjective theory of value was discovered. The thing is that wires have limited capacity and the companies try to fit as many people as possible. If one wants higher capacity, he needs to pay more. After understanding economics well enough, it makes perfect sense to me. Not really. It causes traffic to bunch up at the beginning of the month and presents an avenue for corruption by distancing the expense model from the pricing model. Thankfully, when [ILEC](https://en.wikipedia.org/wiki/ILEC)s like Bell Canada tried to treat GAS-tarriffed DSL access (which is supposed to be a flat-rate virtual circuit on the government-subsidized telco infrastructure) like white-box Internet access and force smaller ISPs to axe their flat-rate options in sync with Bell Sympatico's new DSL offering of 60GiB + $2/GiB, Canadians revolted (with a single petition alone gathering the signatures of 1.1% of the country) and the conservative majority government (our republicans) got so scared that they told the CRTC (our FCC) to reverse their decision or they'd force the issue. As a result, we still have a healthy [CLEC](https://en.wikipedia.org/wiki/Competitive_local_exchange_carrier) ecosystem providing flat-rate DSL options at somewhat reasonable rates and the CRTC is under better management with Bell getting upset when their missives for back-door meetings on issues like "ISP-level targeted ads vs. Canadian privacy law" and "zero-rating of services from other BCE Inc. subsidiaries" get aired publicly by the recipients. Still, that doesn't change the fact that, in congested Toronto, the newest major highway, the 407, is a toll road that's owned by a private company for a century, when the rest of the road network is paid for by taxes.
Yeah, the thing is if you break CAPTCHA for one (more valuable) service, you can use that for breaking less valuable one too.
good post, hope the best to Zemeroth. Actually I like designing game with low resources (myself only on free time). It results in minimalist games with little set of rules and oversimple graphics.
What is the standard method to express futures that can take _multiple paths_? I.E. an early future in the chain may resolve the correct result, but later ones maybe necessary. Like say 1 future checks a cache, but future 2 does a full DB lookup if the cache check fails.
Thanks for the report, I opted for checking if the sample data is a float and then using f64, otherwise i64. I'd like to stick to types present in the stdlib and obviously, this is meant to create starting points quickly.
This is a great post that reflects a lot of things I've been thinking about myself. Especially the bits about narrowing scope and not rolling your own tech--[guilty as charged](https://github.com/mystal/midgar-engine)! I also hadn't seen the post you linked, so thank you :) Zemeroth looks pretty cool. Reminds me a lot of Hoplite, which you mention. Looking forward to trying it out! On another note... For my engine, I really want to stay on SDL2 given how widely used and supported it is. Plus, I get controller support for free! But seeing how easily you made an Android build via `glutin` and `android-rs-glue` really tempts me.
&gt; Thanks for the report, I opted for checking if the sample data is a float and then using f64, otherwise i64. &gt; Yeah that's going to lead to people losing data if their example isn't exhaustive (sometimes a scalar value is a fractional number, sometimes it's integral). Even if you're going to restrict yourself to stdlib types it's really worth putting in the effort to think hard about deserialization problems like this to avoid data loss. At a minimum, default to `f64` unconditionally for numbers.
If you really don't have any memory, then go for NeoVIM.
What's the difference between this and https://github.com/overdrivenpotato/rust-vst2 ?
&gt; At a minimum, just default to f64 unconditionally for numbers. This leads to issues with integers as IDs, which is very popular. Making integers floats has also it's own bag of issues. Numbers in JSON are hell, I give you that, but with this kind of approach, you cannot do more then guess. This is, by the way, the approach the auto-recognition of Elasticsearch takes, and that rarely leads to practical problems.
Randall was actually generous with that XKCD... Ever seen a post of that kind with the only reply being from the original poster stating only "nvm, fixed it"?
&gt; Cairo-rs calls panic!() on degenerate matrices Ugh. I'm seeing this idiom pop up enough that I think i'm going to start assuming that I have to catch panics on any and all code which deals with untrusted input to ensure it can't cause the associated PyQt GUI to vanish from under the user. I thought I was on my way to being done with `except BaseException as err:` when I started moving from Python to Rust. `panic!` is supposed to be for things that you can't foresee happening in a way that lends itself to being handled in a manner more nuanced than the last resort... "a malicious actor crafted input that triggers branches of the parser you don't expect to be reachable" is eminently foreseeable and has a clearly-defined, non-panicking way to be handled... return an `Err` that refuses the data as malformed.
That's not how this works. There's a lot of gap between what is considered bannable and what the community frowns upon. You mention enforcement but really there's been very little ban-level mod enforcement so I don't know what you're talking about. Of course, if the documentation is a personal attack that may get removed. Depends. We don't have a policy on this right now, I'd guess we won't deal with stuff off crates.io itself (like docs). Plus even then it would likely be a dialogue for getting it fixed, not a ban. 
Vim, emacs, neovim. The best universal editors with ide capabilities one could dream of. You will just need to get acquainted with them. 
Absolutely, that was [one of the very early iterations of the `Handler` type](https://github.com/gotham-rs/gotham/commit/2c41ca30d6440854f091ae4074d8553d701d57d0). It turned out that `&amp;mut State` didn't play nicely with lifetimes when doing async, so it [was changed pretty soon after](https://github.com/gotham-rs/gotham/commit/c3ec767d15b5e7c261aec85f59385ec510131089). Async `Middleware` code, and some async `Handler` code, needs access to `State` as well, but the mutable reference only exists until the handler function returns. For async `Middleware` in particular, it's unavoidable: impl Middleware for MyMiddleware { fn call&lt;Chain&gt;(self, state: State, request: Request, chain: Chain) -&gt; Box&lt;HandlerFuture&gt; where Chain: FnOnce(State, Request) -&gt; Box&lt;HandlerFuture&gt; + Send + 'static, Self: Sized, { some_async_call() // Do something returning an arbitrary future .then(|_| chain(state, req)) // Chain the request onto the rest of the pipeline / handler after it completes // ^^^^^ - state is moved into this closure .boxed() } } Another possibility I played with briefly was something like this: fn my_handler&lt;'a&gt;(state: &amp;'a mut State, req: Request) -&gt; Box&lt;HandlerFuture + 'a&gt; { // ... } I couldn't make Tokio/Hyper accept an explicit lifetime, which seems logical to me because there's nothing to base the lifetime on (Tokio services don't have a lifetime parameter on them).
That sounds reasonable. Thanks! The document is a bit vague, so I'm assuming the worst :).
How does it compare to [httpbis](https://github.com/stepancheg/rust-http2) used by [grpc-rust](https://github.com/stepancheg/grpc-rust)?
He's the original creator that I mentioned in the first comment. This project is a hard fork as many of us had bug fixes and features that the original maintainer didn't have time to get to. This new repo has multiple users with write access so hopefully we can avoid that problem. In terms of actual changes, I'm still learning much and the other contributers would have a better idea, but from what I understand several things like the audiobuffer were optimized, as well as a fix for preset loading, etc.
The honest answer is that those two libraries don't meet the level of quality that I would make me feel comfortable to use them in production. For example, in httpbis' hpack decoding, every single time a string is decoded (which is many times per request / response exchange), it calls [HuffmanDecoder::new](https://github.com/stepancheg/rust-http2/blob/aaf822c6c848e3e095f143ebad44754095663913/src/hpack/decoder.rs#L145), which in turn [allocates, loads dozens of values, then throws away a hash map](https://github.com/stepancheg/rust-http2/blob/master/src/hpack/huffman.rs#L58-L94). The equivalent in `h2` uses a [statically generated table](https://github.com/carllerche/h2/blob/master/src/hpack/huffman/mod.rs#L20-L41). That is really just the first example I hit. I ended up figuring it would be easier to write a lib from scratch.
I don't know about advanced editing besides vim, but I guess that switching your editor implies you have to relearn things, especially the advanced, specialized things, regardless of the actual editors. Nevertheless having to relearn even basic things as cursor movement, saving and quitting files etc. may be a bit of a frustrating experience.
&gt;This is, by the way, the approach the auto-recognition of Elasticsearch takes, and that rarely leads to practical problems. I've used Elasticsearch since 2011, wrote the most popular and complete Haskell Elasticsearch client, [and still maintain that extensive client](http://github.com/bitemyapp/bloodhound) for Elasticsearch and it _absolutely_ leads to problems and data loss in production. &gt;This leads to issues with integers as IDs, which is very popular. Making integers floats has also it's own bag of issues. You'll need to depend on serde-json then. That's explicitly what this is for anyway. You're telling people to do the wrong thing and not even warning them how it can go wrong.
It definitely offers performance improvements. The overhead of establishing TCP and TLS connections can be quite high, and h2 makes it so you only need to do this once. Many requests can be in-flight at the same time on that single connection.
I expected [this](https://xkcd.com/1875/) tbh
[Image](https://imgs.xkcd.com/comics/computers_vs_humans.png) [Mobile](https://m.xkcd.com/1875/) **Title:** Computers vs Humans **Title-text:** It's hard to train deep learning algorithms when most of the positive feedback they get is sarcastic\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1875#Explanation) **Stats:** This comic has been referenced 3 times, representing 0.0018% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dlrqz14)
Start by creating custom types and traits to narrow down the primitive types to better reflect your intentions.
It's hard to know exactly what's going on here. There are additional notes on that specific slide: &gt; Rust has a mindset about pervasive correctness, and beautiful, powerful idioms. &gt; Librsvg’s had code to simply bail out if it found a degenerate matrix, one that cannot be inverted. At first I thought, “no biggie, they must be a fact of life in SVG”. &gt; They turned out to be real bugs, due to uninitialized data, or all-bits-zero floats (which is not 0.0), or plainly malformed SVG files that we were not handling properly. &gt; Adding error handling for this in Rust clarified my thinking on how it should really work. Does this mean librsvg specifically doesn't panic now? I dunno.
Webrender is slower because it's poorly integrated with gecko (because gecko's design doesn't match webrender's well, and fixing it is a long process). If something is rendered by webrender, it isn't also rendered by gecko. But we do rely on gecko to render things that aren't implemented yet (e.g. SVG).
Thank you to make it clear to me, and sorry that I missed the comment where you explained it.
Got it. Thanks.
Vim has tabs. `gvim` is a "gui program".
I purchased this book and went through the available 2 chapters pretty quickly and I definitely recommend it to others. Tim's writing is clear and the way he focuses on the design motivations behind Rust first made the technical introduction much easier to read. I went on to read the Second Edition of the RPL book and found that it was much easier to focus and understand than when I tried the first time. Looking forward to the rest!
I'm generally happy with the current module system, but have to admit that I still occasionally get the relative and absolute paths mixed up (but don't mind too much as it doesn't take long to fix when the compiler complains). I'm also concerned about making significant changes to the language, especially breaking ones. But having read the RFC, especially the migration section, I'm in favour. It seems to me to be a very well and carefully thought out proposal which addresses the concerns I've had, and others have voiced, about the previous straw-man proposals.
Well anyway it would at least discourage cases like in the OP where it looks like they just ran a shell script or did it by hand. Finding and setting up a bot that can handle CAPTCHAs seems like more effort than is worth for this.
The article is very clear about WebRender being slow.
also, we have some pretty tight requirements with regards to buffering and flow control for some of our target use cases. Having a thin h2 library that addresses these concerns independently from tls, socket types, etc is extremely desirable.
Hey, looks like you are progressing a little faster than me haha. Though last night I implemented the ld r, r' and that knocked out almost 50 opcodes in one foul swoop. Since I'm coming up on it pretty soon, can I ask what you are using for graphics?
It's ok! I don't know why it doesn't say "forked from" by the name like on most forks, that would probably make it more visible.
As someone who has not started to use Rust professionally, this is really disappointing to read. I really appreciate the philosophy of the panic and exception-free code. Obviating this convention makes the entire language weaker.
&lt;3
Maybe rename it to something clever and rusty like H2O—HTTP/2 Oxidized?
There's an arbitrary precision crate out there that does serde and num. It's called bigdecimal. Fyi :)
You can import Zim files to Cherrytree.
You might want to try asking this in [the other thread](https://www.reddit.com/r/rust/comments/6tkaq2/hey_rustaceans_got_an_easy_question_ask_here/). ;)
https://h2o.examp1e.net/
I know what you are doing and I'm using Elasticsearch in about every versions since 0.9.0. I maintain several large clusters. Yes, damage is there, I still maintain that it rarely leads to problems, not that it never does.
That's great, thank you! That should be used then if `Number` in `serde-json` is somehow inappropriate.
&gt; The honest answer is that those two libraries don't meet the level of quality that I would make me feel comfortable to use them in production. That's true, full implementation of HTTP/2 is hard. I'd be happy to throw away my implementation of HTTP/2 and use h2 instead.
Unfortunately, Cairo-rs isn't the only codebase I've seen where panics are being used inside parsing code to indicate "I don't *think* it's possible to reach here". I'm expressing dismay over a trend I'm observing.
Nobody should use MD5 for anything anymore.
Agreed. If the ecosystem can't be trusted to use `panic!` responsibly, then we wind up assuming the worst of everyone to play it safe. What I'd really like to see is some kind of static tooling which can be pointed at a crate and return a report on all the ways it (and, optionally, its recursive dependencies) can panic, with an ability to whitelist away panics you know are OK so it can be integrated into a CI system. (Basically, making it as easy as possible to audit other people's crates for panics when you first choose to use them, and then automating the process of catching new panics as they're introduced.) Maybe once [Pi types](https://manishearth.github.io/blog/2017/03/04/what-are-sum-product-and-pi-types/) are available to rule out what is probably the most common source of panics (unchecked indexing), such a thing could also be integrated into crates.io. (I'd consider writing such a thing myself, but I don't even have time to give my existing projects the attention they need right now.)
The CoC already applies everywhere. You can be banned from the Rust community for things you say in unrelated social media channels, even if you aren't targeting a member of the Rust community.
Any big rust projects I can donate to?
Sounds good, though do you (or anyone else) have any particular examples you could suggest/link to? I've been starting to learn and work with Rust as well (full disclosure - I am by no means a good/great/professional programmer. I'm still learning a lot, but what bits I do know are C/Java-esque or Python) and have had a hard time building up my mental model for how to best utilize the features and capabilities which Rust provides.
The trick is, whenever feasible, to apply human smarts to pick a case-specific solution. For example, the solution I designed to keep blog spam from showing up in my mail form was to "200 OK" with a "Please make the following corrections and resubmit" message whenever it detected HTML or BBcode link markup. I get maybe one spam post a year through that form, from a bot so broken that it submits nothing but a poster name and the random string of padding like "rijfpaowj" that was supposed to precede the link markup. For another situation, which is currently 100% manual, once I start accepting submissions in a more automated fashion, I plan to cripple bots as a side-benefit of heavy validation on a form significantly different from a blog comment form and then use manual moderation for the final pass once I've winnowed things down sufficiently.
One way to assure that crate will not panic is to use fuzzing. (see e.g. [rust-fuzz](https://github.com/rust-fuzz))
I don't consider fuzzing deterministic enough to be my first line of defense.
I hope this will be mitigated somewhat by panic=abort being a thing. As the ecosystem matures, forgotten panics like this will have a higher priority for elimination than they would in a language where you can and are expected to work around it with `try`/`catch`.
Idk about emacs, but vim really is very much text-only. It can do other stuff, but that other stuff never gets in the way. 
I've improved the quickstart based on some comments here: https://github.com/vitiral/artifact/blob/master/docs/QuickStart.md
done! Here is the improved quickstart based on your comment: https://github.com/vitiral/artifact/blob/master/docs/QuickStart.md I also added that link to the top of the video description.
Hi there! It might appear that I'm going faster than you... but truthfully I'm _only_ doing what I need to do to get Tetris working :) This means I've skipped _alot_ of opcodes that Tetris hasn't used yet. As an example, I tried to run the blarggs CPU tests `01-special.gb` last night through my emulator and I couldn't get very far as it has all sorts of arithmetic instructions it uses that I don't have implemented yet. So skipping to graphics just makes it look like I'm progressing fast.. but it also makes me feel like I'm making more progress :) To answer your question, I went with Piston. I [use the image crate to build a frame](https://github.com/simon-whitehead/chemboy/blob/master/src/main.rs#L125) 60 times per second. I chose Piston because I want to eventually use [Conrod](https://github.com/PistonDevelopers/conrod) for some UI controls to control the emulator.
I doubt manual moderation will be feasible as an obligatory barrier in crate publishing. A practical solution would be to make it just difficult enough to not bother automating for the average joe/jane, like the person in the OP probably did with just a shell or Python script. If we're talking about someone who'll go to the length to find a CV library that can beat CAPTCHAs then we have a more serious issue that we'll have to deal with when the time comes (and even then, a dedicated attacker could just drop a few bucks on Mechanical Turk and defeat pretty much any spam mitigation), but right now we're not even preventing basic automation. You have to start somewhere.
Wow
Actually, my perspective has been that, if I can't set `panic=unwind` in something less trivial than a throwaway script, I'll seek out other dependencies or, if I really must, I'll split my application into a parent process and one or more child processes. As someone who's used managed languages almost exclusively (basically, exclusively except for in some University courses), giving a random dependency that much power to kill my top-level GUI is simply unacceptable.
I think you missed my point. That was a specific example of how I intend to "apply human smarts to pick a case-specific solution" for one of my projects, not a suggestion for crates.io. I know it's a feasible solution for this particular site because the site is currently operating on the even less scalable "people submit new information via the freeform contact form and I manually edit things".
&gt; giving a random dependency that much power to kill my top-level GUI is simply unacceptable. I don't know of a single language in the category you describe that doesn't have a global `abort` or `exit` function.
I assume this is some reference to the game "rust" rather then the programming language "rust", and is in the wrong subreddit.
/r/playrust
What chapter of TRPL 2E are you on? If you share some code someone might be able to help you out.
Follow-up: - not possible in Stable, initialization of an atomic needs constant function evaluation. [playground](https://play.rust-lang.org/?gist=6f4677d4ac27a2e5b8da726b11df5607&amp;version=stable) - it works in Nightly [playground](https://play.rust-lang.org/?gist=bb2f03f7445385a0b11b83342532a68f&amp;version=nightly) - and it's both threadsafe and encapsulates the static like a local variable. [playground](https://play.rust-lang.org/?gist=fda28f40a4f2b9ad5da551e1f287fb69&amp;version=nightly) Rust does bring the thread-safety issues to the forefront. The compiler warning tells you that `id_counter` is really a global variable with limited visibility - of course that's the point. You can't use normal syntax to access its value; you have to say what you're doing and what kind of interprocessor synchronization is needed. Atomics are in general a bit of an arcane footgun - the following is wrong because the location becomes unlocked between the load and store: let id = id_counter.load(Ordering::Relaxed); id_counter.store(id + 1, Ordering::Relaxed); return id; and the resulting bug won't be reliably reproduced. (In fact the generated unique IDs might be printed out of order and that's still correct behavior. They are generated in order, but that's the only guarantee.)
You could now have a look at [Gotham](https://gotham.rs), which works on Rust stable and is fully async.
TL;DR (since the summary is a bit sparse): * Deprecate forward declaration of lifetime parameters * Deprecate lower-case lifetimes-in-structs (so you can "see" where a lifetime comes from in a world with the previous point) * Deprecate total lifetime elision of lifetimes-in-structs (considered an anti-feature) * Encourage "proper" lifetime names matching their source So this: impl&lt;'a, T&gt; Iter&lt;'a, T&gt; { fn foo&lt;'b&gt;(&amp;self, data: &amp;'b u32) -&gt; &amp;'b Item&lt;'a, T&gt;; fn bar(&amp;self) -&gt; Item&lt;T&gt;; } Becomes this: impl&lt;T&gt; Iter&lt;'Iter, T&gt; { fn foo(&amp;self, data: &amp;'data u32) -&gt; &amp;'data Item&lt;'Iter, T&gt;; fn bar(&amp;self) -&gt; Item&lt;_, T&gt;; } With a possible alternative/future where lifetimes can be declared to be "whatever that argument had". fn foo(&amp;self, data: &amp;u32) -&gt; &amp;'data Item&lt;'Iter, T&gt;; Also the proposed `Item&lt;_, T&gt;` may need to become `Item&lt;'_, T&gt;` to avoid ambiguities with default type params.
True, but those languages have easy-to-use exception-based error handling and the abort/exit functions tend to be things that you need to import from some out-of-the-way place which may never get mentioned in the common tutorials at all. In Rust, I'm seeing too many situations where people decide to just `panic!` because they seriously misjudge the trade-offs.
Like C? Sure. Rust *is* procedural/functional after all. Clever type tricks are more about wiring instructions together than organizing data The standard library is a good read. Start with `std::hash` for a sense of what I'm talking about.. Crate nom is very cool and next level. &gt; Should I use for example more tuple structs? Only if it fits your data. Think about what kind of operations make sense between instances of a data type. For example, it rarely makes sense to multiply two id numbers, so `IdNumber(u32)` may be appropriate.
Do you mean neovim here?
Code obfuscation contest?
Yes, sorry. `nvim` is the executable name and I'm used to typing it.
This isn't rusty but I'm really enjoying Type Driven Development in Idris. It discusses a pattern of writing your code with types, then filling in the implementations later, then refining the types as you build the implementation. That general pattern is great with rust's unimplemented!(), lay out your types and then fill in the blanks.
I see rust source code has some negative traits. But looks like I can't use it. What is the alternative? impl&lt;T&gt; !Sync for Receiver&lt;T&gt; { }
Or how about `ripgrep` ? Can't it panic if doesn't include `panic!` ?
Panics can also be caused by unwrap, [] operators, expect and any other function call with a panic inside it. 
Those negative traits are special in that `Send` and `Sync` are automatically implemented for all types made up of other types that are already `Send`/`Sync`. This is so you don't need to `#[derive]` them. However, some types are not thread-safe (despite being made up of threadsafe types), so one needs to opt out of this.
You can donate to Mozilla for Rust and/or Servo development. Apart from that, some developers may have set up a patreon or something similar. What's the kind of development you want to see?
I just sent a PR to rust-bio.
Thanks for summarizing it. I'm a bit worried about the lifetime _ in both `Item&lt;_, T&gt;` and `Item&lt;'_, T&gt;`. I see how the other changes makes it easier, not sure if I like, weird feelings, will let it soak a bit more.
The main way to reason about types I've found is to try to make it so that your data types cannot contain incorrect data. This is something you likely already do in C, but may not realize it. Like using a u8 for representing a percentage from 0 to 100. So if you have primitive types, ask yourself if they can be "incorrect" and then try to prevent that by restricting your types and using constructors and the like. I like to think as someone who has never used my code before and look at the types and see what would happen if I tried to use the type without fully understanding it. If you just plug together things that match types, will you get an error? If you can, that connection should have been restricted by the type system if at all possible. Or by restrictions on the API otherwise.
One word of advice: Be cautious. Using a lot of types (especially with generics) can exacerbate your compile times considerably (this is going to get better once [Chalk](https://github.com/nikomatsakis/chalk) is integrated). If your primitive types correctly describe the data you want to work with, it's really all good!
Panics are somewhat excusable if the cause of the panic is clearcut and can be "easily" avoided. For example, array indexing panics if it's out of bounds, but it's very easy to create indices that are, by construction, within bounds. But it's not at all "obvious" whether a matrix is singular. To do that you have to e.g. calculate the determinant, or perform an attempt at inversion. And not to mention there's different thresholds as well due to floating-point … What if the matrix is very badly conditioned?
People making really useful things like hyper and maintaining them.
maybe add "under construction" tag to the description and readme :)
just curious, not worried about the lawsuit from DC? :P
The idiom we use at work is that no panic should ever be reachable. All our `expect`s and `panic!`s have a message that explains our thinking as to why it shouldn't be possible to reach that path and end in `qed`
Sticking to SDL also gives you the browser. https://blog.fazibear.me/definitive-guide-to-rust-sdl-2-and-emscripten-93d707b22bbb 
I do something similar, but that doesn't change the fact that it's bad form at best for code to tear down the entire process on unexpected types of malformed input.
Oh absolutely, I would say that this supports that. Even on catastrophically malformed input we still return error instead of panic.
&gt; some types are not thread-safe (despite being made up of threadsafe types), so one needs to opt out of this. But when I write `impl&lt;T&gt; !Sync for MyReceiver&lt;T&gt; { }` I get error `error: negative trait bounds are not yet fully implemented; use marker types for now (see issue #13231)` 
If you have several primitive types which together cannot logically be a certain subset of values, try combining them into an enum. For example: `deadReason: Option&lt;String&gt;` and `life: u32`. You probably shouldn't have a `deadReason` and a positive value for `life`. One could un-optionize the deadReason and create an enum: `enum LivingOrDead { Dead { deadReason: String }, Living { life: u32 }, }`. Now, if you ever want to assign a `deadReason`, you also throw away info about `life`. So, you're a step closer to not allowing inconsistent state.
How is it different from this? http://vestera.as/json_typegen/ It seems to do the same. And even allows specifying the #derives.
Personally I would like to be able to opt in to a rust that doesn't support APIs or operations that panic at all. Array indexing for one can return an Option. I'm sure it will come eventually.
Unreachable code is problematic. There are no systematic guarantees that it will stay unreachable across refactorings, that the documentation even tells the truth, or that the code actually _is_ unreachable. I've found that most code that uses unreachable can be rewritten to avoid it. Albeit sometimes through the introduction of odd errors or double checking conditions. Still preferable IMO.
Ordered *Rust in Action*, thanks.
So far it doesn't seem to be progressing past "RLS analysis: working" with the spinner icon.
I'm so jealous of y'all.
This old post had me learnt a lot: https://www.reddit.com/r/rust/comments/5r9tjc/communicating_intent/ EDIT: In addition, here is a nontrivial example of changing from procedural code to functional code: https://blogs.gentoo.org/lu_zero/2017/08/12/optimizing-rust/
Wow, that is a truckload full of work! I consider not reading the status report 5 - makes me feel lazy ;) nice work this is super interesting! 
Do you have a large project? Initial indexing can take quite a while. You can set `rust-client.showStdErr` to `true` in your settings and you should see some more info if there is a problem.
So what will happen to things like `abort()`?
I'd love contributing to Redox but sadly I cannot install the build dependencies on Arch (some dependency requires autoconf-2.64, however the repos only have \*-2.69). \* So for now, I will just happily contribute to [ion](https://github.com/redox-os/ion), as I also plan to replace bash with ion on my Linux system some time in the near future :) \* *Yeah, I probably should file a bug report but I was too lazy until now* Edit: fix formatting 
Nice post :) I noticed the links (and backlinks!) for the footnotes don't work. The first footnote links to https://durka.github.io/#fn:1 instead of https://durka.github.io/blog/2017/08/06/du-evolution.html#fn:1
Fantastic, I hope that you enjoy the read! Let me know if you have any thoughts :)
It isn't, I didn't know of it. It even now handles numbers the same :). I saw the project flying around somewhere and was like "oh, this typescript stuff looks like I could rework it for Rust Serde in 5 minutes". This is really nice! 
Just wanted to say that I really appreciate the fact that you have taken the time to post this. It really helps the motivation factor. Have invested many nights and weekends on the book already (there are 3 more chapters on the verge of release) and am so relieved that readers are responding well to the book.
give me first class actors in rust and i will never stop writing rust
I am resonating with this and I also liked the back reference at first. But I have ~~huge~~ concerns that, for a beginner, this could be interpreted as an operator like `&amp;` in C/C++ whereas in C `&amp;` gives you the address of a variable `'` gives you the lifetime (of a positional argument or any variable binding) 
Geany is pretty good - comes out of the box with Rust support. Find dialog is a thing of frustration but otherwise I'm happy. Works on MacOS and Windows as well.
Well thank you for putting in the time! I hope the book is a big success for you!
There's no pure Rust library for decompressing .xz files? Unacceptable! Someone, make one! [EDIT] While googling around, I managed to find https://github.com/meh/rust-lzma. It doesn't seem like it was ever successful and was abandoned.
Is it correct that code completion only works with explicit types? I don't seem to get suggestions on inferred ones. Does give me suggestions when typing 'x.': let x: Vec&lt;i32&gt; = (0..1).collect::&lt;Vec&lt;i32&gt;&gt;(); Doesn't: let x = (0..1).collect::&lt;Vec&lt;i32&gt;&gt;(); 
&gt; But I have huge concerns that, Why are you concerned about this? If you want the lifetime (or type) of a variable, you should be able to just ask for it. Maybe because `'` will be used for both, deducing lifetimes and introducing new ones?
Do you have a link to the cairo-rs issue?
Can't this be achieved with good library?
What do people mean by "first-class" and what are actors?
I just feel like the first time a newcomer uses lifetimes is in the back referencing way. And this could somehow teach him/her "if you use the `'` operator you can extract the lifetime out of a variable binding" in a sense that you are somehow able to do this let a = ... ; let lifetime_of_a = 'a;
Maybe one of these: http://libs.rs/scripting/
Hmm, no this worked differently. It was implemented so that you could enter it was unquoted text. I think it was using some extension whereby a macro was free to interpret any text between braces that obeyed the rule of balancing all delimiters as it wished
I'm just quoting from the slides here.
Congratulations, you got the job!
&gt; in a sense that you are somehow able to do this What I meant is that maybe it would be easier if we could be able to do this. That is, use `'binding` to get the lifetime of the variable behind the binding. 
Or integer overflow, when checking is enabled. So basically all arithmetic can panic.
Yes, it's a very good book. I think I've always had a type driven approach to programming (that's the main reason I never liked dynamically typed languages), but Idris really takes it to a new level. Not sure how applicable the same ideas are in Rust though (the Rust type system is a bit limiting for functional programming, especially with dependent types).
Is it [Lia](https://github.com/willcrichton/lia)?
I experienced the same issue on the mdBook code on Linux while the RLS seems to work okay on my project on MacOs using the vscode-rust extension. I would have to try the rust extension on my mac to compare with vscode-rust. If I find anything I will open an issue.
Yes! This is it! Thank you! I guess I was wrong about it being a single-syllable though.
* Wikipedia on [Actor model](https://en.wikipedia.org/wiki/Actor_model) * First-class usually means support from the language itself (i.e. syntactic sugar)
**Actor model** The actor model in computer science is a mathematical model of concurrent computation that treats "actors" as the universal primitives of concurrent computation. In response to a message that it receives, an actor can: make local decisions, create more actors, send more messages, and determine how to respond to the next message received. Actors may modify private state, but can only affect each other through messages (avoiding the need for any locks). The actor model originated in 1973. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
Is there any reason this extension tries compiling RLS on it's own instead of using the one provided by rustup? That always fails to compile libssh2-sys for me while vscode-rust works just fine.
&gt; On the downside, their ownership model has a higher learning curve than the design described here, their abstractions are typically very low level (great for systems programmers, but not as helpful for higher levels), and they don't provide much guidance for programmers about which abstractions to choose, how to structure an application, etc. Rust also doesn't provide an obvious model to scale into distributed applications. I find this a little... too much in one paragraph. I disagree with the level of abstractions: Rust can be _very_ high level, but still give a glimpse of their structure. I hate the characterisation of Ownership as a cliff. It is gradually learnable. It's just a hill that you _have_ to climb on the journey. Ownership/Borrowing situations in Rust are very much possible to be refactored, which enables gradual learning. The middle parts I agree with. Rust is pretty un-opinionated on the solution. Although this is the case in many other languages (such as Java) and has lead to an ecosystem of layered abstractions. The last part leaves me confused: aside from Erlang/Elixir, I wouldn't know any language where the model of building distributed applications comes out of the language.
In my experience, the old VS Code [Rust extension](https://marketplace.visualstudio.com/items?itemName=kalitaalexey.vscode-rust) works much better together with the RLS.
Or division by zero even if checking is not enabled.
No way can that be a zero cost abstraction though.
Note that pinyin "lia" is pronounced like "lya" and is a single syllable.
&gt; I find this a little... too much in one paragraph. Admittedly, the focus of the document is concurrency for swift.
I'm hoping to be able to do some tooling along those lines by using a combination of debuginfo and disassembly to find out which panics haven't been optimized out. I've started on this tool [here](https://github.com/philipc/ddbug), but haven't done much on the panic detection yet. Not sure yet how reliable this approach will be, and it's probably worth combining with a source level tool as well.
It is, but even then, if you are investigating, you should give the investigation time or keep it to the stuff you can somewhat sketch out. Also, it's a specific "Rust" section :).
&gt; I like a lot in this RFC. I'd also love being able to name lifetimes after arguments: &gt; fn two_args(arg1: &amp;Foo, arg2: &amp;Bar) -&gt; &amp;'arg2 Baz; This is what I want.
I wouldn't worry about making newcomers want to try something that wouldn't compile anyway. The compiler will teach them that it's not how it works.
Oh, so is it a palatized lateral, like as in Spanish (well, Castellaño) *llano* /ˈʎano/? Huh, I guess I was right.
Thus my talk of whitelist support in such a tool. Some people may want to just blindly trust the arithmetic, while others may want to enforce the use of explicit wrapping/saturating/checked types or even require all uses of division to pass some kind of audit.
&gt; [...] and they [the Rust docs] don't provide much guidance for programmers about which abstractions to choose, how to structure an application, etc. Still true? If so: Seems like our docs team has a bullet point more on their TODO. :)
It shouldn't, it should use rustup. Perhaps you have one of the old environment variables set which controls which rls to use? I'm on mobile right now, but I think you should look for RLS_* env vars
What kind of actor syntax do you need that can not be achieved with macros?
I just want actors on top of Tokio, leveraging futures. [Kabuki](https://github.com/carllerche/kabuki) seems to be the most promising one (and perhaps the only one so far...). [Here](https://www.reddit.com/r/rust/comments/6316jv/aktors_actor_library_in_rust/dfqo6sr/) is what the author has to say about its goals, on a thread about another actor library.
&gt; Unfortunately, Cairo-rs isn't the only codebase I've seen where panics are being used inside parsing code to indicate "I don't think it's possible to reach here". That makes sense to me, it's basically an assertion, if the assertion is broken it might be a library bug (which it seems to be for cairo) or it might be that the caller fucked up somehow (e.g. created an invalid datastructure via unsafe?). I mean if the library author believes something can't happen at all, what guarantee is there that an other method of handling the case will work any better?
Vim and emacs both have GUI front-ends, they just happen to also work in a terminal. That's an additional feature, not a drawback.
Is the qml crate capable enough for writing fully featured Qt UIs? People were saying the rust-qt crate doesn't have enough features to support developing a real application. How much more capable is the qml crate?
I am not so much talking about newcomers making up syntax i am talking more about the way how a manifestation of a concept about lifetimes could be established. Maybe i am just to worried about that – i am just trying to remember how it felt to not know about that stuff. 
Cheers!
This is my question too 
Oh that was it, thanks!
Except that well-designed parsers shy away from asserting. Instead, they discard the uncertain state and report failure to avoid potentially being responsible for a denial of service vulnerability.
Sure, that's completely fair, and I utterly missed the "inside parsing code" bit so… I completely agree that within parsing code panic'ing should be the exception rather than the rule (e.g. if you're parsing an internal IPC protocol maybe, and even then that's iffy)
That's true, I'd agree with such change. (If we found that it's not a good solution, it could be reverted.)
&gt; Also the proposed `Item&lt;_, T&gt;` may need to become `Item&lt;'_, T&gt;` to avoid ambiguities with default type params. Why not just `Item&lt;', T&gt;`? The additional `_` doesn't seem useful to me.
Probably partly my fault. I wasn't very clear that I considered Cairo-rs to be an extension of the parsing code in a case like reacting to a degenerate matrix because it's very likely that a parser will just pass through whatever it gets rather than including its own validator for what is essentially an embedded sub-format.
Nah, your original comment clearly talked about panics inside parsing code: &gt; Cairo-rs isn't the only codebase I've seen where panics are being used **inside parsing code** to indicate "I don't think it's possible to reach here". I don't think you could have been any clearer, I just completely missed it, my bad.
I think this might only be implemented well* in a library. (*where well means you have decent options when the implementations network transparency or process registry breaks down.)
I wonder if it would be possible to have a lint that disallows some panicking operations if you are writing a library, and if so, if it would be helpful at all? I feel like panicking in library code is almost always the wrong thing to do.
I prefer `unreachable!` annotations over code that papers over stuff that shouldn't actually happen – silently hiding errors, and for me that includes executing code paths that the developer didn't think about, is a great source for debugging madness. :/
As commented on the issue, I'm not convinced that deprecating the old syntax (for now) should be done. https://github.com/rust-lang/rfcs/pull/2115#issuecomment-323274893 I'd prefer the extensions to be implemented, with the possibility to start deprecating later on.
I think this is unrealistic on multiple levels. If you want to avoid your process crashing, then catching panics is your last line of defense. Wanting to avoid catching panics seems very strange to me, since not catching panics (while also wanting to avoid your process crashing) is making an assumption that your code is entirely bug free. It would be nice to be able to make that assumption, but it seems really unrealistic to me. &gt; Maybe once Pi types are available to rule out what is probably the most common source of panics (unchecked indexing), such a thing could also be integrated into crates.io. I'm skeptical that Pi types are some magical panacea that will suddenly save us from index out of bounds errors at compile time. :-) In particular, I wonder how much additional work from the programmer will be required. Moreover, even if everyone agreed that Rust should get Pi types, I don't see that happening for *many years*, so it seems useful to focus on Rust without Pi types for now! Personally, I think it's quite all right to panic inside a parser---or anywhere else for that matter---so long as that panic is treated as a bug. I don't see how the alternative strategy---turn all bugs-that-induce-panics into proper error values---is a tenable strategy. And if you acknowledge that we can't catch all of them, well, then you're back to needing to catch panics anyway.
I understand that might be useful. It could be worth the try and see if having to `clone()` is really very inconvenient. I’ve created an [issue](https://github.com/sebcrozet/nalgebra/issues/282) on github in case it gets implemented in the future. Out of curiosity, what crate do you use for arbitrary precision floats?
 &gt;[ion](https://github.com/redox-os/ion) FTFY 
Thanks, I always mix the syntax up.
If a library panics in a way that isn't documented, then yes, we should all consider it a bug. But actually removing every place in the source that could panic simply isn't tenable. It would mean turning every single index-out-of-bounds or option-unwrap into an error, *even when the presence of said error indicates the violation of a runtime invariant established by the library*. For example, let's say you're writing a library that does complex matrix transformations. You rightfully want to provide helpful errors to folks using your library, so before you begin any transformation, you always check that the matrix provided to you by the caller has the right size. If it doesn't, you bail out and return an error. All is good, right? Wrong! It turns out that your transformation code actually needs to access the data inside that matrix and, like any sensible Rust programmer, you do this using indexing syntax: `matrix[i]`. Oops. That can panic! So what do you do know? For every single index operation, you do: let value = match matrix.get(i) { None =&gt; return Err("runtime invariant violated, index out of bounds").to_string()), Some(v) =&gt; v, }; But this seems kind of silly, doesn't it? You've *already checked* that the matrix has the correct bounds, so you, the programmer, know that the error is not reachable, *unless there's a bug in your code that causes it to be reachable*. Now, if Rust had a more sophisticated type system, you might actually be able to use your earlier bounds check to construct a new type that provides a guarantee of how big `matrix` is, but that's only one side of the coin. You still need to prove something about `i` to the type system, and if your algorithm is complicated, that might turn out to be really hard or just downright impossible! Bugs are OK. They happen. The important thing is that we treat panics as bugs and endeavor to fix them. Telling people to never ever never unwrap or index or panic in a library without exception is just not tenable in my opinion. (With that said, I have seen some folks who *really* care about panicking go to great lengths to prevent it. And yes, you can go down that path. But I personally think it's a niche, and *hoping* for an entire ecosystem to adopt that strategy for every conceivable library is a waste of time.)
Np! Ion looks like a really cool project.
No, it's read like the IPA [lja], with a dipping tone (falling-rising). It's also the only word in Chinese for that syllable in any tone, so a bit of an outlier.
Oh, I see. Lateral-palatal glide clusters are hard for me to pronounce as a single syllable.
You can think of it as a non-syllabic high front vowel. The actual pronunciation depends on the speaker, but you can find recordings for *liang*, which is very similar except for the coda.
There are multiple, but the best crates providing arbitrary precision floats seem to be [this](https://crates.io/crates/ramp) and [this](https://crates.io/crates/rust-gmp). But it's not only BigFloats that one could do linear algebra on. It's also possible to do linear algebra on BigInts, BigRationals, BigDecimals, etc. But what I'm personally using it for is [dual numbers](http://jliszka.github.io/2013/10/24/exact-numeric-nth-derivatives.html). They're basically numbers that also keep track of the not only the value of the number but also its derivative(s) to a certain parameter (read the blog post that I linked to if you're interested, dual numbers are really cool). Basically, if nalgbra would work with generic types that don't need to be `Copy`, I could use the code you wrote to calculate the determinant of a matrix to instead calculate the *n*th derivative of that determinant wrt some parameter.
I write Elixir for my day job, so I _love_ actors. But I thought part of what made them so great in that ecosystem is the preemptive scheduling, which seems difficult to shoehorn on top of rust. Are you including that in "first class", or are you thinking of a system in rust that wouldn't have that? Are there examples of languages out there with actors that don't have preemption?
Ordered. Thank you!
this will sound like a trivial point but hear me out .. Rust macros are awesome, but code written with them has a very different 'feel' to inbuilt constructs; firstly 'infix-ness' , secondly 'nesting level'. e.g. compare what a C for loop looks like vs a for!{} macro in rust. 2 things that could help, - 'method macros', with a $self, e.g the ability to write ```expression.my_macro!( .... )```; 'expression' becomes a $self parameter in the macro. perhaps allow ```$self:expr``` or ```$self:ident```, obviously it couldn't handle completely arbitrary syntax. - multiple brackets and a preceding symbol as part of the macro syntax, e.g. allow pieces between ```macro_name!``` and a final brace ```{...}``` e.g. so you could write ```my_struct_def! StructName { ...}```, ```for!(...){....}``` etc (the detail to figure out, is stepping through each bracket type after ```ident!``` until you reach curly-braces a solid parsing rule)
Now that you say it, how would I limit a number to a range at compile time? Your u8-&gt; 1-100 example is not actually 1-100 but 0-255
This is _exactly_ the kind of thing I want to be informed about, and I'd love to see a Rust wrapper for this so I can use it in a language implementation or something, but I still think this is the wrong sub for it. /r/python, /r/programming, /r/lua and /r/c_programming would all appreciate this.
That's why I said "disallow *some* panicking operations"! 😉 What I meant is stuff like explicit calls to `panic!`. Otherwise I completely agree with you. I mean, if a library causes an OOM, that's panic that's close to impossible to avoid.
I think this is a valid point. It's weird to have something that looks like an expression - the application of an operator to a variable - but that doesn't produce a value you can assign to a variable. This is precisely why iterators in Nim felt weird to me. In Nim, you can say: for i in countup(1, 10): echo i But not: var c = countup(1, 10) for i in c: echo i That feels arbitrary. This risks being a bit the same.
Why do you need this to be in the language itself? 
I added it to the description. I note in a few places its a work in progress. Hopefully thats more obvious to people. Thanks for the tip.
Oh, hmm. Well, explicit calls to `panic!` don't seem much different than, say, `unwrap` or `xs[i]`. (Sorry if I misunderstood what you were saying! I guess I just wanted to be very clear since there's a lot of subtlety in this area...)
Hide behind some annotation like unsafe perhaps?
&gt; Rust also doesn't provide an obvious model to scale into distributed applications. What does this even mean? How many languages provide this? Erlang and its derivatives, and what else? It's highly debatable whether this is even something you want - language-agnostic protocols seem obviously a better option for the real world, where you're frequently tying together systems that were never intended to be tied together and were written in different languages, on different operating systems and hardware, etc.
After a pretty long time spent in development, pest 1.0 has reached a useable state: * the old macros have been replaced with a procedural macro that greatly reduces compile times and comes with a bootstrapped parser which delivers easy-to-understand error messages * the old `process!` macro has been replaced with a pair token API which implements `Iterator`, simplifying the processing step * error types have been introduced, improving error-reporting and introducing custom user errors * precedence climbing has been moved from the grammar to its own API * manual grammar definition is now possible with the innovative `Position` API * a parser testing macro has been added There are [a few issues](https://github.com/pest-parser/pest/milestone/3) left on the road to 1.0 and any little contribution would be greatly appreciated.
I sometimes end up with `Foo&lt;'&gt;` these days when I don't hit the `a` hard enough or there's a crumb under it. Not sure that could be called a use-case :)
VS Code works on ARM: https://code.headmelted.com/
Code that should never happen is a bit _smelly_. I prefer code that is never written in that case - i.e. the language has constructs to avoid having to write code that should never happen. Take https://github.com/rust-lang/rust/blob/master/src/librustdoc/html/escape.rs as an example of double-checking. Do we want the application to crash at runtime because of a programmer error. Or do we want it to not compile? Edit: this is how the example could be rewritten: https://play.rust-lang.org/?gist=a833daad709f360443b5f32dcdb10ed4&amp;version=stable
This was always one of my big sticking points when trying to learn Rust, especially pre-1.0. It was never very clear what 'idiomatic Rust' was supposed to look like, and since it's such a new language searching for examples on the internet often lead to out of date information or no information at all. I like to try to do things properly, and it wasn't very obvious what 'properly' was in this context. I think it's getting better (and I also care less these days, or maybe I'm more opinionated about structure regardless of language) but we could definitely use some pointers in the official book about how applications are put together.
&gt; but we could definitely use some pointers in the official book about how applications are put together. Does this help at all? https://doc.rust-lang.org/book/second-edition/ch12-00-an-io-project.html Or are you looking for more? If you're looking for more, could you elaborate a little?
I hear you, but I wouldn't know what idiomatic pre-1.0 code would look like :). I think this is fundamentally entangled with the mode Rust is developed: out in the open. The advantage that Swift and other languages have is that they were internal within one organisation for a long time, with no one from the outside to play with it. Even if they went through changes in style, they could simply fix it in all their libraries and you'd never notice. Rust: not so much. It very much developed in the open (and I that's what teased me back then). So finding out what "idiomatic" even _is_, was a community effort of people writing, trying and breaking things. It comes with its own set of drawbacks, but also with a lot of merits. You can trace (and actively link to) decisions as fundamental as throwing the GC out. 
Well, the parentheses in function definitions aren't expressions either. Lifetimes are just in function declarations or type declarations, or am I forgetting something?
Not the person you originally replied to, but I have a suggestion. Would it be possible to provide a style guide of sorts, kind of like Python's "Pep 8"?
I don't know, it feels like when unwraping or indexing panics, it's an "honest bug", but explicitly calling panic in a library, to me, in most cases signals "I don't know how to properly handle this situation". I don't know if that's actually true or even makes sense, though.
Wouldn't you just trade the crashes for silent data corruptions etc.? If someone can't `unwrap()` a value they "know" is safe to unwrap, they would e.g. `unwrap_or(0.0)` the value. If the author's assumption was wrong, is it better to crash or return garbage? Surely, the first option. Disallowing panics would be a reaaaaly bad thing for software reliability in practice.
*TL;DR:* &gt; Rust's approach to concurrency builds on the strengths of its ownership system to allow library-based concurrency patterns to be built on top. Rust supports message passing (through channels), but also support locks and other typical abstractions for shared mutable state. Rust's approaches are well suited for systems programmers, which are the primary target audience of Rust. &gt; &gt; On the positive side, the Rust design provides a lot of flexibility, a wide range of different concurrency primitives to choose from, and familiar abstractions for C++ programmers. &gt; &gt; On the downside, their ownership model has a higher learning curve than the design described here, their abstractions are typically very low level (great for systems programmers, but not as helpful for higher levels), and they don't provide much guidance for programmers about which abstractions to choose, how to structure an application, etc. Rust also doesn't provide an obvious model to scale into distributed applications. &gt; &gt; That said, improving synchronization for Swift systems programmers will be a goal once the basics of the Swift Ownership Model come together. When that happens, it makes sense to take another look at the Rust abstractions to see which would make sense to bring over to Swift.
Just bought the ebook :)
I expect the deprecations would "just" be warnings for a long period of time.
I believe it's to be more intuitive to novices; `_` means "inferred" in a lot of other places.
It supports Qt Quick Controls, and you can map objects into the QML namespace, and use signals and slots. You can absolutely build a real application out of it - the only problem is distribution, because the qml crates depends on a Qt dev environment being present and the Qt libraries being available for linkage at runtime (via the C QML binding library it uses). You can get a binary really easily out of it, but making sure it will work wherever you send it off to requires ensuring the linkage environment has the Qt libs available for dotherside.
The compiler already has some style lints in it, around naming items. Most of the rest of PEP8 would be covered by automated tools, e.g. [rustfmt](https://github.com/rust-lang-nursery/rustfmt) and [clippy](https://github.com/rust-lang-nursery/rust-clippy) which will ship with rust by default in the future.
It's not bad, actually - I must have missed that section last time I took a look at the new version of the book. Here's what I'm after: * Architectural guidelines for code organization. How does the community recommend structuring a project? The example in the book extracts code from `main.rs` into `lib.rs`, but it's not entirely clear why we choose to make that a crate vs. using the module system (which is how I'm currently handling similar problems - is that wrong?). I (and I assume many other people, just considering the greater enterprise landscape) come from OOP languages where the normal mapping is one object = one file, and often namespacing is mirrored in folder structure. It's not clear if it's a good idea to do one struct per file in Rust, or whether there's another paradigm that's more appropriate. I think the example is too small in scope here. * Guidelines on best practices. There's often a myriad of different ways to do something (silly example, handling `Result&lt;&gt;`s) and it's not very clear which one is best for any given situation. I think this is just a result of Rust's age and the way it's been developed - it's not a bad thing - but it's confusing for someone just jumping in and trying to create something slightly more than trivial. There's too many ways to do things that all seem (at least, superficially) completely equivalent. Unlike /u/hosford42 I don't think style is a problem - I'm perfectly happy with `rustfmt`, I think more languages should have a tool like that! Would avoid so, *so* many office arguments.
This would make going from code that copies crap to code that just borrows crap *so much easier.*
You can run the build using docker: https://github.com/redox-os/redox/blob/master/docker/README.md I am also working on an LXC based method for reproducible builds: https://github.com/system76/buildchain
&gt; it's not entirely clear why we choose to make that a crate vs. using the module system I would hope that https://doc.rust-lang.org/book/second-edition/ch12-03-improving-error-handling-and-modularity.html#separation-of-concerns-for-binary-projects explains &gt; This pattern is all about separating concerns: main.rs handles running the program, and lib.rs handles all of the logic of the task at hand. Because we can't test the main function directly, this structure lets us test all of our program's logic by moving it into functions in lib.rs. The only code that remains in main.rs will be small enough to verify its correctness by reading it.
I don't personally have a skin in this game, but I suppose it's a similar situation to the `try!` macro, which was superceded with the special `?` syntax. 
There are bits of this strewn throughout the docs; but the book is already over 400 pages; adding in even more of this is tough. (And that's modulo all the other comments about how this is still developing)
The number of times I haven't been able to install something because Arch is on the cutting edge is, um, lots. It's lots.
Yeah, I feel like that's not a good thing to do. Actors are a cool concurrency abstraction for a lot of things, but not *everything*, and I wouldn't want Rust to tie itself so tightly to one particular model.
I bet cargo extracts each test into its own temporary test crate, which is separate from your main crate, and so it has multiple crates it must compile (besides whatever dependencies you already have). It has to recompile every test every time you edit your main crate since your main crate is a dependency of the tests (and incremental compilation is still a work in progress). Why `cargo test` doesn't stop as soon as a compilation error in your main crate occurs, I am not sure.
I'm working on homework2 here: https://github.com/cis198-2016s/homework/tree/master/hw02 (not actually enrolled at the school, just doing the course to learn Rust) I've been going in cirlces with the borrow checker trying to insert a new Link: enum Link { Empty, More (Box&lt;Node&gt;) } struct Node { value:i32, left: Link, right: Link } Then one of the variations of insert I have tried is below, which currently fails for reassigning immutable variable self. Which I assume has become immutable because of how I am matching on it. if I match on &amp;mut self, I get type mismatch on the matches instead. halp. impl Link { pub fn new(value:i32) -&gt; Link { Link::More(Box::new(Node::new(value))) } pub fn insert(&amp;mut self, value:i32) { match self { &amp;mut Link::Empty =&gt; { self = &amp;mut Link::new(value); }, &amp;mut Link::More(boxed_node) =&gt; { if value &lt;= boxed_node.value { boxed_node.left.insert(value); } else { boxed_node.right.insert(value); } } } } }
Having worked on BEAM, GHC, and JVM applications in production, over time I've grown more inclined to use language agnostic infrastructure for distributed apps rather than anything runtime specific. I'll happily use runtime-specific structures _in process_, GHC Haskell affords me a lot of nice things for that, but I'm unlikely to use Cloud Haskell even if it works fine for some friends of mine.
 #[derive(Clone,Copy,Debug)] struct Percentage(u8); impl Percentage { pub new(x :u8) -&gt; Option&lt;Percentage&gt; { if 0 &lt;= x &amp;&amp; x &lt;= 100 { Some(Percentage(x)) } else { None } } pub unwrap(p: Percentage) -&gt; u8 { p.0 } // Whatever else }
Interesting point, I think I 'd accept that.
Yes, I understand that, but is it not equivalent to move the `run()` function into a different module rather than making it a crate? Admittedly I haven't delved much into Rust's testing ecosystem so I don't know if there's some kind of issue with testing a function in a module vs. testing a standalone crate. In my head I'm thinking about it as modules = 'namespaces' (or rather Rust's version of them, I understand they're not equivalent) inside the same binary, and crates = externally linked libraries. In other languages (for example, C#, which is what I write for my day job) I would never jump straight into creating a separate library for business logic in a binary project unless it was going to share logic with a second, related binary. I'd be happy to know if I'm wrong here!
The biggest difference is probably that `json_typegen` also has a "type-provider-like" interface and a CLI, and I originally considered the type provider to be the main interface (not sure if there is any "main" interface at the moment), which is why it is only for Rust (though that could change). At the moment, the actual code generation is, however, quite a bit more powerful than what is exposed / currently configurable in the website and CLI, as I have a lot of UX code to write.
I guess error handling is much more frequent than concrete concurrency model. The "macro-&gt;special syntax" approach seems good idea to me.
&gt; By using ranges and coroutines together, we unify push and pull based idioms into a consistent, functional style of programming. And that’s going to be important, I think. That's cool! Could stackless coroutines in Rust (as proposed by [this eRFC](https://github.com/rust-lang/rfcs/pull/2033)) be used to unify push and pull idioms? Or is there something else missing?
I've been using this for a while already. Suggestions work most of the time, and I've only had one crash. Huge improvement over just a few months ago.
I agree with the refactoring you made, but I disagree that it supports your general point: &gt; Code that should never happen is a bit smelly In fact, your refactoring *still has* such code: fmt.write_str(&amp;pile_o_bits[last.. i])?; And also fmt.write_str(&amp;pile_o_bits[last..])?; In particular, `pile_o_bits[s..e]` will expand to something like this: assert!(s &lt;= pile_o_bits.len() &amp;&amp; e &lt;= pile_o_bits.len()); unsafe { ... } And of course, the `assert!` expands to something like: if !condition { panic!("you violated a runtime invariant!") } The *correctness* of your code depends on this runtime invariant not being violated, so you've perfectly reasonably assumed that it is unreachable, because it if is reached, it will get tripped and make it obvious to the caller that there's a bug somewhere in the function they called. This is exactly why I'm against blanket statements like "don't write unreachable code." Because it's just not tenable. Unreachable code is abound.
I especially like to see more guidelines for best practices, I'm recently writing some non-trivial programs, I'm often having different ways to achieve it, e.g. using ```Result&lt;&gt;``` or simply using ```Option&lt;&gt;``` when wrapping a lower library, and other stuff as how to construct the state machines better etc.
I think theres a way to delegate all function cals to a member automatically, so you could also do that for the u8 but then always do %100
A library can never be as easy to use or as intuitive as a language feature
Interesting... This mirrors a common pattern we use at my work for writing business process automations in Python.
Rust could use a good non-moving GC library. Everything Mike Pall touches turns to gold. Other than that: ¯\\\_(ツ)_/¯
Ah, I was aware of those tools. Thanks!
I don't think so. Look at e.g. Go's `make` it is essentially the same thing as `T::new()` in Rust but without ability for users to define their own constructors. I find that totally unintuitive.
I'd like to try this out for a while. Do you know where I would find a decent tutorial on installation? I tried this path once and failed. I was unable to get RLS working with nvim. Something like https://fungos.github.io/blog/2017/08/12/setting-up-a-rust-environment-on-windows/ but for nvim would be excellent.
Enjoyed reading the presentation slides - liked the way the code is highlighted and explained in the speaker notes. The drawings were cute! &lt;3
&gt; crates = externally linked libraries It's better to think of crates as reusable components, or equivalently reasonably flexible and self-contained interfaces. You can think of the business logic without a front-end, so in that sense it is a compete interface. Conversely, the front-end depends on the business logic. This is just a language-level way of specifying such dependencies. You also get more accurate code coverage metrics if you separate *things you can do* from *what the user might enter*. With that said, I imagine most projects that have back-end library logic begin life as a single crate, and only separate later. If the entire program is an ultra-thin layer over command-line input, or just a sketch, there's not much point in convoluting the architecture.
Does the [entry API](https://doc.rust-lang.org/stable/std/collections/struct.HashMap.html#method.entry) work for your usecase (besides being verboser)?
"Zero cost abstractions" in the sense of Rust is "no added cost over other implementations through using language features".
https://www.patreon.com/redox_os 
&gt; After RustFest Fun &gt; &gt; We’re currently talking with our friends on the Rust team about how we can facilitate some time and space after the conference for our community members to get involved. That sounds awesome! I'm planning to be in Zürich until at least Monday afternoon, but am open to staying longer.
You can try this package for autoconf-2.64 (it used to be in the repository): https://archive.archlinux.org/packages/a/autoconf-2.64/autoconf-2.64-2.64-1-any.pkg.tar.xz
Isn't `0 &lt;= x` unnecessary with unsigned integers? 
RemindMe! 2 days Pretty interested in this
I will be messaging you on [**2017-08-20 16:16:52 UTC**](http://www.wolframalpha.com/input/?i=2017-08-20 16:16:52 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/rust/comments/6ud3zm/how_to_learn_to_take_advantage_of_type_system/dlsz7xz) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/rust/comments/6ud3zm/how_to_learn_to_take_advantage_of_type_system/dlsz7xz]%0A%0ARemindMe! 2 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dlsz8jp) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
This very proposal is about two different models - I don't see why actors would negate having async/await.
Yeah, I spent some time writing that, but I'm waiting for async/await to continue progress. I don't see any way to ever get generics working in rust without a huge blowup of generic arguments in various places, there's just no way to get this as pretty as a native language feature that I can see.
Why? Rust's type system is perfectly capable of expressing what's necessary to have actors that do not perform deep copies for message passing. We can look over at Pony and see that extremely efficient actors are possible. I believe in Pony there's a few hundred bytes (1-2) of overhead per actor and every message is an enqueue operation, something like 3 atomic ops. Pretty low cost.
That's a general rant about macros limitations. Any first-class feature with custom built-in syntax will look better than a library solution. It may also perform better - though Rust is usually smart enough(and - more importantly - knows enough and can infer enough) to optimize the library solution to be nearly - if not the same - as fast as a built-in or custom-coded solution. But a first class feature is much harder to maintain. It makes the languages syntax and semantics more complex. It gives the optimizer more scenarios it needs to address. Third-party tools(like Racer) and parsing libraries(like the ones we need to write procedural macros!) need to add cases to support the new syntax. And so on - the main problem is that adding new syntax is not as nearly as orthogonal as library solutions. So, for a feature to have first-class support it needs to: 1. Be very important and common. 2. The built-in solution should be considerably superior to any library solution. The `?` operator is a good example - error handling is very important and common, and the new syntax is much better because it the error handling is usually inside the expression, and the operator can be used to pass them up much more elegantly than the macro. So, what I'm trying to ask, is what justifies giving that treat to actors? Is special syntax really required for them? Does it make that much of a difference? Because the current library solutions look elegant enough to me. Even without macros - closures and pattern-matching are enough to implement an elegant actor models API. Do first-class actors really worth the extra complexity they'll introduce to the language?
&gt; There are zero reasons actors need to be 'first class'. Are you sure? &gt; frequently the wrong choice Oh? &gt; drunk the kool-aid I wish there were some actor kool-aid but I haven't seen it.
Yes, and you'll get a lint because of it. I literally wrote that in 5 minutes while passing by, without thinking very hard about the logic. It probably also should have a `From` implementation too.
Writing what?
I don't have any production experience with BEAM or Cloud Haskell, but I've been interested in their design for a while. Could you describe some of the issues you encountered?
Sorry, I was a bit vague. You linked to 'aktors', which is a project I wrote. I have a version of it locally using tokio, which doesn't work, and I've stopped until we get async/await syntax.
I haven't been able to get a macro approach working with generics. And my approach required nightly for proc macros. There's also going to be worse error messages around lifetimes and things like that.
So we are going to have separate http 1 and 2 implementations in Rust? (hyper and h2?)
Yeah, thats more of a 'cookbook' issue.
Thanks for those pointers. I've never heard of dual numbers but they do look neat. Now that you gave me some use-cases, I think supporting non-Copy types is definitely worth a try!
I'm excited for NLL and the other proposal on lifetimes specifed by args, which would drastically reduce that cliff.
Ohh sorry I didn't realize :) it would be great to have Aktors running on Tokio!
Is it reasonable to expect names that short to have any degree of uniqueness? It's also, among many other things, an html tag and notoriously-environmentally-unfriendly automobile...the disambiguation page on Wikipedia is quite long. It seems silly to reserve a string like that for a niche database that's more well known by its full names (Hypersonic SQL DB, hsqldb), but maybe that's just me. 
Yep, agree. Unfortunately, I haven't been able to come up with a solution that will reconcile my approach with rust's generics - at least one of the reasons why I'd personally like first class support.
&gt; This would mean that if I compile with miri: &gt; a crate "A" with available source code &gt; that dynamically links against the Rust library "B": &gt; compiled without instrumentation, and whose source code is not available, &gt; then in this case miri does still do 100% accurate detection of uninitialized memory access in the crate "A" source code, without any false positives. &gt; Unless miri does dynamic memory instrumentation of the crate "B" valgrind-style, which is extremely slow, I really don't know how this is possible. &gt; MSan does way better than valgrind (as in, 10x faster), because it doesn't need to instrument all memory. &gt; If whether memory is initialized or not would be part of Rust's types, then, ideally, we would not need to instrument crate B at all when running miri on crate A, at least if we just want to detect access to uninitialized memory. &gt; Maybe miri can already do that and I am missing how, or maybe the performance of miri is not an issue, but I really would like to run something like servo in miri, and for that, miri must be very fast. miri interprets MIR code. MIR is much more like Rust source code than like assembly. It is, in particular, fully typed. So this has none of the problems that instrumented assembly code has. miri is also hideously slow. 
Well you can write a compiler plugin...
I was planning on attempting it before posting. I would be more eager if I didn't have a hundred other projects that this one is doomed to join.
I've only looked at Cloud Haskell, I'm saying I won't use it in production because of some potentially problematic decisions (trying to make it transport agnostic) and that I generally would rather use a communication layer that works with any language.
Well obviously this needs to be Rewritten in Rust.
&gt; Type Driven Development in Idris https://www.manning.com/books/type-driven-development-with-idris 
1) Install Neovim from repo. 2) Install [vim-plug](https://github.com/junegunn/vim-plug) according to its instructions. 3) Install [nvim-completion-manager](https://github.com/roxma/nvim-completion-manager) with vim-plug (also explained in vim-plug's usage instructions). 4) Install the [Rust Language Server](https://github.com/rust-lang-nursery/rls) with rustup (explained in its README). 5) Follow the install instructions from completion manager's [Language Server Protocol's client](https://github.com/autozimu/LanguageClient-neovim), you will see RLS is even one of the examples. Hope I didn't miss anything.
I dont know the answer tho
You could use `Deref&lt;Target=u8&gt;`... but I prefer a named getter; people are more likely to keep the thing wrapped if there's a cost for unwrapping.
I appreciate the offer to help! I wish I had some actual code to show, but nothing thus far. I've only gotten to coding through ch2 so far (guessing game tutorial), but I've bounced around through the first and second edition of the book and have been lurking around this subreddit and the Rust GitHub repositories for some time. Basically, my experience with actually coding with Rust is very small! I guess my question was more about best practices/idomatic/best way to think about how to utilize the trait capabilities which Rust has. The Rust By Example book/site has been good in that respect, but finding examples in people's real-world code is another great way to better understand the powerful capabilities present in the language. An example if you're familiar with Python might be iterating over items in a custom class. The "C"-style way (at least as I know it - there's likely a better way in C or at least C++ which I'm not aware of...) might be to create an index variable then reference that index of the class's data, increment the index, and repeat that process as needed. However, a more idomatic or "Pythonic" way would be to implement the __iter__ and __next__ methods for the custom class to make it inherently iterable. The equivalent in Rust, I suppose, is to impl Iterator for a custom struct. While the above deals more with Traits rather than Types, I guess part of my lack of knowledge comes from not even knowing where the capabilities best begin! I'll certainly keep reading on TRPL, but any examples you might have would be appreciated!
Yeah. I was just addressing the explicit `unreachable!` to show that refactoring away unreachable code might be possible. That is why I would typically characterise such code as "smelly". It's not a perfect heuristic since it might not be tenable under all circumstances. But I still believe it to be an indicator of code smell.
Nice! I'll have to check those out!
I personally like to use types to express *domains* of values. That is, whenever I find myself thinking: impl Foo { fn func(&amp;self) { // Should never be called if self.x is 0 } } I know it's time to split this type. **My stretch goal is that all arguments of a function or method (including `self`) should necessarily have a value that is valid for this function.** The typical example is a `Connection` object. It does not make sense to be able to call `connect` and `disconnect` on the same object: either it's connected or it's not! Therefore, there are at least two types waiting to emerge here.
`.ok_or(ErrorKind::ThisShouldntHappen)` is an option. But I'd prefer looking at how to refactor the code to avoid it in the first place.
Totally fair, and it's how I'd structure a more complex program (or one with shared business logic) in any other language, too. My question is still sort of unanswered, though. Is there any reason to prefer doing it like in the book (`-&gt;` refers to a dependency): ``` main.rs -&gt; lib.rs (crate) -&gt; database.rs (mod), domain.rs (mod), [...] ``` vs. something like I've done in a recent project: ``` main.rs -&gt; run.rs (mod) -&gt; database.rs (mod), domain.rs (mod), [...] ``` I can see it being a helpful abstraction when you're foreseeing a structure where the `lib.rs` dependency is relatively generic and shared, like: ``` cli.rs (binary), gui.rs (binary), service.rs (binary) -&gt; lib.rs (crate) -&gt; database.rs (mod), domain.rs (mod), [...] ``` But in the other case where you're only ever planning on having a single binary entry point to the project (`main.rs` in these examples) I don't see a reason to prefer one over the other. Am I just misunderstanding how modules work? &gt; You also get more accurate code coverage metrics if you separate things you can do from what the user might enter. I think you get this just by virtue of keeping to the SRP when writing functions regardless of how you organize your code otherwise, again, unless I'm misunderstanding how tests work in Rust.
You could make a private member. I'm not sure if it would work as just being of type `()` or if you'd have to do something more like `PhantomData&lt;()&gt;`. Of course the user would always still be able to instantiate the struct themselves if they really wanted to, by using `std::mem::transmute(())`.
I thought about it, but it does not feel that clear to me. Specifically, `fn two_args(arg1: &amp;Foo, arg2: &amp;&amp;Bar) -&gt; &amp;'arg2 Baz;`: okay... which lifetime is that? The outermost? The innermost? Also, it doesn't allow for `fn both_args(a: &amp;'both Foo, b: &amp;'both Bar) -&gt; &amp;'both Baz;` (although I guess this could simply be `fn both_args(a: &amp;Foo, b: &amp;Bar) -&gt; &amp;Baz`?) In the end, I think it's better to nudge people into being explicit when elision doesn't work.
It's the first time for me. Then again, I'm running Arch only since a month or so :D However, I prefer stuff to not build because my distro is too advanced than because it is 2 decades behind (*looks at you Debian*)
&gt; Everything Mike Pall touches turns to gold. SO true.
My advice is to continue working through the trpl 2e. You can jump ahead and check out the relevant chapters, probably 5, 6, 10, and 19 if I recall correctly. The book isn't perfect, but I found it well structured, and I believe your questions are answered within.
Yeah, I tried the docker way afterwards, however I ran into a compilation error in one of redox' dependencies (in cookbook, I think). So I decided to wait for a few hours, until this is fixed. Your buildchain project looks promising :)
Yeah, I obviously disagree because you are basically saying that all such uses of `xs[i]` (where `xs` is a slice) is a code smell. Saying that slice indexing is a code smell doesn't seem reasonable in my opinion.
Oh, thanks. I'll look into it. It seems like Github's support for Jekyll blogs in subdirectories has a few holes.
Honestly, your response didn't really provide much, so I didn't have much to say. Really, you still haven't said much - you seem to be under the impression that I'm advocating 'only actors' - like we'd somehow lose access to OS threads or shared memory or async/ await. I don't really get why you think I'm advocating that. The linked RFC for swift even addresses the use cases for multiple primitives. The closest thing you have to an argument, across two posts, is that actors are overkill. This isn't actually an argument but a statement, but the rest of your two posts is just fluff "they're overkill" "you're just drinking the koolaid/ enamored" "oh I've seen other actor libraries so I'm sure of x" where x is entirely unclear - that actors don't need to be first class due to the existence of non-first class actors in other languages? OK - are those explicitly as powerful as actors that *are* first class? Can we express anything that powerful in rust, today? I've found the answer to be no. Can you say something with substance so I can respond with substance? It's still unclear what exactly you object to. 
Is this real life?
&gt; you are basically saying that all such uses of xs[i] (where xs is a slice) is a code smell No, I'm not saying that. Not sure how you came to that conclusion. Panicking because of unreachability is explicitly introduced by the coder. It can be either desirable or not without drawing parallels with panicking in general. What you talk about is important though. I do think there should be a way to write panic free code in Rust, I mention that here: https://www.reddit.com/r/rust/comments/6uckse/replacing_c_library_code_with_rust_guadec_2017/dlsdh7q/
Thanks everyone! I've given the venue the estimated attendance numbers and they'll be ready for us. If you are learning about the gathering just before it happens, you can come on down without an RSVP. I'm sure there will be room for all of us. Looking forward to spending more time with fellow Rustaceans!
They should work fine, along with futures-rs streams and that eRFC's accompanying async/await macros.
This is a buff
&gt; we know can be successfully implemented as a library As someone who has tried to implement it as a library, I don't know that this is true - I haven't been able to express actors properly (and ergonomically) in rust. So that's why I'm so curious as to why you seem to so strongly believe otherwise. Because it exists in Scala? Scala's type system is not rust's type system. The rest of your post is, again, nothing.
Rust team: Procedural macros aren't done yet, we're just stabilizing custom derive. Rust users: *DERIVE ALL THE THINGS!* Nice work! Love the logo. I wish I had something that needed parsing...
we gained ~~3~~ ~~7~~ ~~8~~ ~~13~~ ~~15~~ ~~26~~ ~~29~~ ~~32~~ ~~35~~ ~~38~~ ~~61~~ ~~65~~ ~~69~~ ~~81~~ ~~88~~ 241 new Rustaceans since the screenshot was made!
From my post: &gt; So that's why I'm so curious as to why you seem to so strongly believe otherwise.
I do understand that and I didn't want to force you.
/r/servojerk
No. I would *like* to do it. I just have no promises that it will actually get done.
Is this just fantasy?
Well done, this looks way better then the old macro version.
Link?
Agreed. I can't imagine this causing any confusion that would be a real problem. Seems like it'd just go like this, at worst: --- Alice: I'm looking for a good HTTP/2 library for Rust. Bob: Have you tried h2? Alice: You mean the database engine/Java library? Bob: No, I mean the HTTP/2 library for Rust. Alice: Oh, okay.
Caught in a landslide
Servo's logo is really Doge? I'd like to think they did that to troll the mods here on the "no memes" rule.
Escape from reality
I don't think so. For the combat code to have a wide range of possibilities you need to be able to have both the attacker and defender as mutable during the combat process. The Entry API is a really fancy way to do find and replace, but you can still only target one K,V pair in the map at a time.
Didn't even know that Servo has a logo. Edit: Tried to look for one. Neither on the website, nor on the repo.
Listen folks I'm trying to let my reverence for Freddy Mercury outweigh my antipathy for memes but you've really got to get the got-dang lyrics right!!
See the avatar at https://github.com/servo
No escape from reality
The mods we need, right here people.
Servo's doge logo may very well predate my barbaric anti-meme discrimination. :P
This parser library seems perfect for me. For the last few days, I tried my hand at writing a parser using Rust for the Java Properties file format, mostly for fun. This is a parser I already wrote in C a few months ago, and I wrote the state machine manually, then. I wanted to try a parser combinator library, so I rewrote it using nom. Nom is quite nice, and I was able to achieve my goal with it. It is difficult to debug because of the usage of macros, though. Also, now that the parser works I have no idea how to properly report parsing errors. Just reporting the line where the error happens seems like a very difficult task to me. I thought that a parser combinator may not be the best fit to parse a text format, after all. So I started rewriting it using Niko's parser generator, lalrpop. It started well, but then the regexp ambiguities started to appear, and I had no idea where to go from there. Also, making a syntax error in the .lalrpop file almost always results in a panic in the lalrpop parser, which is frustrating. And even then, reporting parsing errors seems tedious and very manual. Then I found out about pest 1.0 beta yesterday, and from the doc it appears to be the exact tool that I need. The grammar description is simple, and it allows to declare the elements of the AST directly without writing glue code in Rust. It tracks the parsing errors locations automatically, and it remembers the span of each AST element all by itself. Plus, there are facilities to deal with whitespaces and line separators. I'll rewrite my crate using pest soon, and I'll see how it goes!
Oh, there you are! Well hidden.
[Here's one](https://rustbyexample.com/fn.html), but it seems to be all examples on the site.
Why would Rust need garbage collection?
Indexing a slice contains code that will never run in correct programs, and you said that code that never runs is smelly. Maybe you are trying to make a more nuanced point, and I suspect i would agree with that nuanced point. But i don't think your initial comments carried that nuance, which could end up misleading others.
There is a difference between `&amp;mut Foo` and `mut &amp;Foo` - former is a mutable reference (the value that it points to can be mutated), and the latter is a mutable binding that is an immutable reference (you can't mutate the thing that it points to, but you can make it point to a different thing). When method parameter is `&amp;mut self`, it acts as the first one - `self` can never be reassigned, but instead it can be mutated. To do that you just do `*self = new_value` - you don't make self point to a different thing, but instead change the value that is in the location pointed to by `self`. So instead of `self = &amp;mut Link::new(value);`, you should do `*self = Link::new(value);` (also the first case does not make sense because `Link::new(value)` will be dropped at the end of the scope and `self` would become a dangling reference). In match arm `Link::More(boxed_node) =&gt;` you need to match `boxed_node` as `ref mut boxed_node` - `ref` because you can't move out, so just take a reference, and `mut` to allow mutably borrowing for recursive insertion. Also, you might find it nicer instead of match self { &amp;mut Link::Empty =&gt; { ... } &amp;mut Link::More(_) =&gt; { ... } } doing match *self { Link::Empty =&gt; { ... } Link::More(_) =&gt; { ... } } Here's a working version: https://play.rust-lang.org/?gist=6cef751f9cfb2d063d378d8432138e8a&amp;version=stable
Non-Mobile link: https://en.wikipedia.org/wiki/Actor_model#Actor_libraries_and_frameworks *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^102475
So, you linked a bunch of actor implementations for a bunch of languages not very much like rust, most of them sacrificing static typing, or utilizing language features rust doesn't have... idk, talking to you is making me cringe
It's OK, we know you only do it to resist your crippling meme addiction. Stay strong!
h2 is being built in a way that will make it good for hyper to use. As the the readme states, h2 is not going to have any socket, upgrade, handshake, etc... logic and it is being built as low level as it makes sense. I've been talking w/ sean about integrating h2 in hyper so that hyper can support both h1 &amp; 2
This sounds cool. I don't have a usecase right now, but I'm pretty sure it's because I never suspected I could want it and one will appear over time :-).
I'm sorry :-D
Seems like this is a link to the official spec https://tukaani.org/xz/format.html
I am psyched you are writing this book! The more books the better.
MdBook is also affected. It looks like it's a regression in https://github.com/integer32llc/rust-playground ping /u/shepmaster
Would you be up for having a video call on this at some point? aturon@mozilla.com if so
I'll email you, would love to chat and see if there's a way to get generics working with my approach. I'm at RustConf so not in a good place to send code around, but sometime next week should work.
thank you, perfect explanation
Which directs you to https://tukaani.org/xz/xz-file-format.txt, which I already have open. One quick question for anyone: should I try parsing by hand, or should I use nom? I used nom a little bit for a previous project and enjoy it, but I don't think the error messages it gives are good enough.
Could you be specific about why please?
Unless the language feature is not well-designed or intuitive. But how do you make sure it's well-designed and intuitive? Just let people test it out and see which approach works in practice... which is what you can do with a library. Once you add something shitty to the language you can't take it out.
RLS almost always works for a little while and then inevitably dies. Seeing "Connection to server got closed. Server will not be restarted." is really saddening. Are there any saved logs that we could pass along?
Small comment: the README (and the post above) use the term "pair token"/"token pair" but it is not clear what that is exactly without reading the API docs (the sample code does not make it clear either).
I don't think using JSON as the format is a good idea. JSON objects are unordered. Serde may be emitting the fields in the order of the struct, and will probably continue doing so considering how much sense it makes, but it still does not promise to do so - at least I haven't seen in the repository or in the docs that they promise - and the JSON specs clearly state that objects are unordered. This is usually not a problem - except when it is. Like now. If the order of the fields in the JSON `*.snap` files will change, it will cause a mess in the SCM, creating unnecessary merge conflicts. No one likes merge conflicts from automated tools... Serde supports many formats - wouldn't it be better to pick one that preserves the ordering of the fields?
Check who created that sub ;)
&gt; Maybe you are trying to make a more nuanced point, and I suspect i would agree with that nuanced point. But i don't think your initial comments carried that nuance, which could end up misleading others. Possibly. But I think you are reading too much into the word "smelly". "Code smell" is a specific concept meant to make you think twice about committing to a piece of code. It in itself has nuance and is only intended to be a guiding principle.
&gt; Specifically, fn two_args(arg1: &amp;Foo, arg2: &amp;&amp;Bar) -&gt; &amp;'arg2 Baz;: okay... which lifetime is that? The outermost? The innermost? It would be the outermost. `arg2`is a `&amp;&lt;something&gt;`, that's all that matters. &gt; Also, it doesn't allow for fn both_args(a: &amp;'both Foo, b: &amp;'both Bar) -&gt; &amp;'both Baz; (although I guess this could simply be fn both_args(a: &amp;Foo, b: &amp;Bar) -&gt; &amp;Baz?) You'd still be able to use the current syntax, and explicitly name your lifetimes if the default behavior isn't detailed enough. So your first example would work, but I guess per this RFC the second would as well.
Oooops! Sorry about that! It should be working now! We spun up a bigger Playground instance this morning in preparation for RustConf, and my written down instructions are a bit out of date, and so we didn't enable the CORS support on the new instance.
Thanks!
I'm aware of that but I couldn't find a simple way to explain it. Maybe a link to the docs would help?
Let's not exaggerate, this logo is replaced nightly. And seeing this not some stable software, I see no harm in being a bit playful. Google Doodle never made me use Bing
Note, the RFC has been substantially updated, and has a new summary: Improves the clarity, ergonomics, and learnability around explicit lifetimes, so that instead of writing fn two_args&lt;'b&gt;(arg1: &amp;Foo, arg2: &amp;'b Bar) -&gt; &amp;'b Baz fn two_lifetimes&lt;'a, 'b: 'a&gt;(arg1: &amp;'a Foo, arg2: &amp;'b Bar) -&gt; &amp;'a Quux&lt;'b&gt; you can write: fn two_args(arg1: &amp;Foo, arg2: &amp;Bar) -&gt; &amp;'arg2 Baz fn two_lifetimes(arg1: &amp;Foo, arg2: &amp;Bar) -&gt; &amp;'arg1 Quux&lt;'arg2&gt; More generally, this RFC completely removes the need for listing lifetime parameters, instead binding them "in-place" (but with absolute clarity about *when* this binding is happening): fn named_lifetime(arg: &amp;'inner Foo) -&gt; &amp;'inner Bar fn nested_lifetime(arg: &amp;&amp;'inner Foo) -&gt; &amp;'inner Bar fn outer_lifetime(arg: &amp;'outer &amp;Foo) -&gt; &amp;'outer Bar It also proposes linting against leaving off lifetime parameters in structs (like `Ref` or `Iter`), instead nudging people to use explicit lifetimes in this case (but leveraging the other improvements to make it ergonomic to do so). The changes, in summary, are: - A signature is taken to bind any lifetimes it mentions that are not already bound. - If an argument has a single elided lifetime, that lifetime is bound to the name of the argument. - You can write `'_` to explicitly elide a lifetime. - It is deprecated to: - Bind lifetimes within the generics list `&lt;&gt;` for `impl`s and `fn`s. - Implicitly elide lifetimes for non `&amp;` types. - The deprecations become errors at the next [epoch](https://github.com/rust-lang/rfcs/pull/2052). **This RFC does not introduce any breaking changes**, but does deprecate some existing forms in favor of improved styles of expression.
This is not the permanent new nightly logo. Mozilla is testing their infra for updating the logo due to the refreshed Firefox logo coming in version 57. For the past week the nightly logo has been rotated daily, and has been everything from [a fake logo based on Calvin &amp; Hobbes](https://www.reddit.com/r/firefox/comments/6t88su/anyone_else_get_this_as_their_new_firefox_nightly/) to [every historic Firefox project logo](https://www.reddit.com/r/firefox/comments/6teno8/another_new_firefox_nightly_icon/). If you want to see the *real* new nightly logo that will be settled into once all the fun is over, look here: https://github.com/mozilla/gecko-dev/blob/0e4a2a4a5234c21a023df4d5d9e4f17e4e0382c1/browser/branding/nightly/VisualElements_150.png (frankly, I love it, especially compared to the old one).
[download](https://download.servo.org/) has also the doge
You're still confused - ergonomics is just one part of this. The major part is getting generics working, that's hardly a minor detail, and in the one case where I can get it working we are talking about having a huge number of type parameters involved, growing along with the tree of actors. Or, giving up type safety, again not a minor detail - and a tradeoff that most languages make, which is why your list is really not very meaningful. I could trivially implement slow, unergonomic actors, similar to some of those languages implementations - but that's a ridiculous suggestion for rust. I don't think you know what you're talking about, and you post like a child - I thought it was clear before, but just to be explicit, I'm not interested in continued discussion, I don't see it being productive.
Cool, I'll give it a try next week. Thanks mixedCase_
Oh wow, nice. I wonder why Microsoft hasn't picked this up yet. Official support would make it a lot more attractive.
If you include the errors you're seeing, it's easier for other people to help you.
I'd say that, regardless of which format is best, Serde should provide at least opt-in ordering guarantees for JSON, if for no other reason than far too many other things insist on JSON and you want to make that play nice with SCM diffs. For example, Python's `json.dumps` lets you solve this issue via a `sort_keys=True` argument you can pass as a workaround for Python dicts being unordered.
Why the color change?
Open your eyes
Hmm. Ok. I think we have two very different interpretations of "smell." :-)
This commit shows the old logo that it's replacing: https://github.com/mozilla/gecko-dev/commit/0e4a2a4a5234c21a023df4d5d9e4f17e4e0382c1 , which was a version of the Firefox logo with the fox removed and the visible side of the "planet" shown at nighttime. I'm guessing that the new logo, which is just a pallet-swap of the refreshed Firefox logo, is blue both to provide continuity with the old logo and to be a rough inverse of the color scheme of stable Firefox. Note that this sort pf pallet-swap is also what Chrome does with its yellow Canary logo: https://play.google.com/store/apps/details?id=com.chrome.canary&amp;hl=en
Ah, I missed that it's exclusively for nightly.
Even if what you say it's true, consider these things: 1. I didn't even notice anything odd about the logo in the screenshot. It looked normal to me. 2. I didn't know what "doge" was. 3. I didn't know Servo even had a logo. I had to piece all three of those things together, and it only happened because of this thread. If I had seen that logo in another context, I wouldn't have thought anything of it. Maybe I just live under a rock, but I'm betting I'm not alone. :)
You need #![feature(optin_builtin_traits)]
All i see is a casual conversation on reddit, not some set of demands that a certain set of pet features must be implemented. Please make an effort to be more charitable in your communication style. Your comments come off as incredibly condescending.
https://servomemes.tumblr.com/
/r/rust abuse. This is the subreddit for the rust programming laguage, you want to post this on /r/playrust for the people interested in the game rust ;) 
what am I looking at is that man importing a crate
Look up to the skies and see
A struct with a non-pub field `_priv: ()` is sufficient to avoid making the constructor public. This RFC might be useful in the future though: https://github.com/rust-lang/rfcs/pull/2008
It's a tiny project. https://github.com/colemickens/chefi
That's what I've been using, but I thought we were all using it in lieu of the more proper final-ish solution with RLS? Though, since `Rust (rls) 0.2.1` extension isn't working for me, I'm going to revert to `Rusty Code 0.19.1`. Or try to figure out how to get more information about what's going on so that I can help with the RLS+VSCode effort...
(I'll try debugging a bit, if there are more steps, I'm happy to follow them to give feedback. Even after leaving open for hours, a VS Code process is eating 10-15% of a CPU.)
No problem, thanks for taking care of it!
If you are not enthusiastic about writing jni wrapper for java&lt;-&gt;rust by hands, you can try my project: https://github.com/Dushistov/rust_swig it has also android example: https://github.com/Dushistov/rust_swig/tree/master/android-example
What if you wanted to write a Lua implementation in it?
Nom will give you prettier errors if you ask with the right feature.
I'm just a poor boy, I need no sympathy
It'd probably be good to know what the team has been testing against so we can sanity check our installs before reporting things like "inferred types don't work", etc..
Awesome! This looks like it'll be super useful. Just for users who may not have used custom-derive crates before, I'd recommend including the `extern crate` declaration in the example. Besides that, maybe "Only one variant may have #[default], and it must have no value." could clarify that "no value" refers to the `#[default]` attribute, and not the variant? Without the example, it might seem that only `Bar` is viable for `#[default]`, and not `Baz` (because `Bar` has no values). Still, awesome crate! Glad to see this here. 
Just want to note that this is not PyPy's default GC.
Code completion (but not type on hover, etc) uses Racer, so we're limited by Racer's type inference. I think it can do slightly better than requiring explicit types, but I'm not sure exactly what it can and can't manage.
yes and actually its a bug cause 0%is still legit
Could you try restarting VSCode with `RUST_LOG=rls_analysis=info`? That should tell you if it is getting hung up on indexing a crate (it might be that one of the dep crates causes a lot of data to be generated). If you see anything interesting please file an issue on GH. I'll try and repro with that repo next week.
You can set `rust-client.showStdErr` to true in your vscode settings to see some logging info. Running with `RUST_LOG=rls=debug` will show more logging. It is really useful if you can supply such logs, thanks! 
I test against a lot of different crates - usually I smoke test on whichever crate was last reported with a problem. I also try to dogfood - both the rls itself and the dep crates (which are a bit smaller, so tend to work better) like rls-analysis.
I disagree, but I don't see anything downvote-worthy in your comment. Sorry about that. Reddit can take on a mind of its own sometimes.
Because I'm easy come, easy go Little high, little low
Thanks! Will do!
Will do! Thanks for the effort and troubleshooting help!
Wasn't trying to insult you or anything if you interpreted it in that way
Any way the wind blows doesn't really matter to me
FWIW I believe dogefox predates servodoge, so this logo isn't related to servo. It's inclusion in the nightly may be, though.
I currently have code that looks like this: if let StringFragment::Str(_) = fragments[0] { if let StringFragment::Str(ref mut string) = fragments[0] { string.push_str("Hi mum"); } } else { fragments.push(StringFragment::Str("Hi mum".into())); } [Playground link](https://play.rust-lang.org/?gist=129feee02d749e04b95c2b6a5dc42e20) This is obviously silly; I have `if let .. = fragments[0]` twice in a row! The second `if let` is obviously going to succeed, because it just did. But it doesn't work if I bind `ref mut string` in the first line here. Compiling playground v0.0.1 (file:///playground) error[E0499]: cannot borrow `fragments` as mutable more than once at a time --&gt; src/main.rs:14:9 | 11 | if let StringFragment::Str(ref mut string) = fragments[0] { | --------- first mutable borrow occurs here ... 14 | fragments.push(StringFragment::Str("Hi mum".into())); | ^^^^^^^^^ second mutable borrow occurs here 15 | } | - first borrow ends here The mutable borrow initiated of `ref mut string` seems to last to the end of the `else` part of the `if let` rather than just the "`then`" part. It seems trivially provable that it only needs to live through the "`then`" as it works as in the block above. I have a workaround (see the initial code block), so this isn't too immediately concerning. But this seems strange; why does the borrow last this long (seemingly longer than it should)? Is this a bug, which I should report?
&gt; That's why I said "disallow some panicking operations"! ...and why I proposed a whitelist... though mine was more about locations (eg. "Whitelist method X. I know it can panic.") than code constructs.
&gt; If you want to avoid your process crashing, then catching panics is your last line of defense. In hindsight, I was tired and what I wrote was a mess. What I *meant* was more in the vein of "I thought I was through with this being *more* than a last line of defence" but I was so tired that I didn't realize I was assuming others would magically share that aspect of my perspective. &gt; I'm skeptical that Pi types are some magical panacea that will suddenly save us from index out of bounds errors at compile time. :-) In particular, I wonder how much additional work from the programmer will be required. Moreover, even if everyone agreed that Rust should get Pi types, I don't see that happening for many years, so it seems useful to focus on Rust without Pi types for now! I was mainly using Pi types as a good "re-evaluate at this point" benchmark for the "not currently something I see as reasonable" idea of incorporating some kind of panic-use information into crates.io. &gt; Personally, I think it's quite all right to panic inside a parser---or anywhere else for that matter---so long as that panic is treated as a bug. I don't see how the alternative strategy---turn all bugs-that-induce-panics into proper error values---is a tenable strategy. And if you acknowledge that we can't catch all of them, well, then you're back to needing to catch panics anyway. My perspective could be summed up in a concrete example as "I won't blame nom for containing an unexpectedly reachable panic, but I will blame it if it intentionally produces a reachable panic as a result of the grammar I give it and I will blame a hand-rolled parser for containing an unintentionally-reachable panic."
Maybe /r/playrust would be a better pick?
To me
[removed]
I am *not* enthusiastic about that. Thank you for this.
Just be a real man and use unsafe ffs (as an additional bonus, no cycles wasted in pointless RefCell dynamic borrow checking). let mut map: HashMap&lt;&amp;str, u32&gt; = HashMap::new(); map.insert("x", 123); map.insert("y", 456); let px = map.get("x").unwrap() as *const u32 as *mut u32; let py = map.get("y").unwrap() as *const u32 as *mut u32; unsafe { *px = 42; *py = 88; } println!("px: {}, py: {}", map.get("x").unwrap(), map.get("y").unwrap()); Playground: https://play.rust-lang.org/?gist=1cee622a2a6530e13c9fb56892541fa9&amp;version=nightly
...Did you even read my playground link?
They mean you're on the wrong sub.
Oh, I see, it's not for Rust, just written in Rust. 
Momma
Oh you actually did use unsafe and not just RefCell. Points for that bro. # #unsafe #coolclub #2017
Spaghetti
Is this real? OMG!
AFAIK, if you want to debug Rust code with the Visual Studio debugger, you can only do line stepping at the moment. This change in LLVM should help us get variable inspections as well though :D
Wow, this is surprising, and a huge blow to Rust. Thanks for everything you've done, brson. Hope you return some day!
Have you seen the Rust libtcod tutorial? They use the following for vecs (https://tomassedovic.github.io/roguelike-tutorial/part-6-going-berserk.html): /// Mutably borrow two *separate* elements from the given slice. /// Panics when the indexes are equal or out of bounds. fn mut_two&lt;T&gt;(first_index: usize, second_index: usize, items: &amp;mut [T]) -&gt; (&amp;mut T, &amp;mut T) { assert!(first_index != second_index); let split_at_index = cmp::max(first_index, second_index); let (first_slice, second_slice) = items.split_at_mut(split_at_index); if first_index &lt; second_index { (&amp;mut first_slice[first_index], &amp;mut second_slice[0]) } else { (&amp;mut second_slice[0], &amp;mut first_slice[second_index]) } } 
/u/brson, Thank You, for guiding, leading and creating the Rust we know today. You've been a cornerstone of the project and community, and I wish you all the best for your future endeavours, wherever they may lead you.
@coder543 &gt; Have you considered writing a Custom Derive macro to remove even the last of that boilerplate? Not sure what is use case for `Custom Derive`? I prefer architecture where there is one crate know about java and jni and export all rust API from other crates. And "other" crates know nothing about java. Plus I prefer explicit vs implicit. So I want define conrecte part of Rust API that I would like to export via Java. The main reason to deal with java vs rust semantic in right way should human not program. Consider for example general case where you export `Boo.setFoo` and `Moo.getFoo`. `Moo.getFoo` get reference to `Foo`, and `Boo.setFoo` accept reference to `Foo`. In java this works in all cases, in `Rust` with lifetimes not in all cases. `rust_swig` may of course clone stuff to `Arc&lt;Mutex` behind the scene, but that would be not zero cost abstraction.
Found some explanations that this is because of how `if let`s is desugared to `match`: if let pattern = value { ... } else { ... } match value { pattern =&gt; { ... } _ =&gt; { ... } } making `value` live for both branches. I think this case will be fixed once non-lexical lifetimes are implemented.
You can keep off lifetimes for very long, if you have no problem of working mostly with String and Box, though. It's also the direction current teaching goes. I'm not trying to imply it's easy, but cliff gives the impression that you need it all at once, which isn't the case.
Yes, a link would help!
In the statement use std::io::{self, Read, BufReader}; What does **self** mean?
For a complicated compression format like this it might be worth considering porting the c library rather than starting from scratch. Looks like there is also a [crate](https://github.com/meh/rust-lzma) for lzma decompression already, so maybe that's a place to start. I've thought about porting liblzma and xz myself, so if you're starting a project to implement the xz format in pure rust let me know.
I just started working on Image Processing CLI, which not only is a wrapper for the PistonDevelopers/image library, but also implements few other things like histograms. The idea came from my work - I work on image recognition and I need to find similarities in lots of images, so I thought that it would be a good idea to create this CLI :) The next functions that I want to implement are: - difference of gaussian - apply operation to all files in a folder https://github.com/spejss/Image-Processing-CLI-in-Rust
The terminology for these things is "Higher-Ranked Trait Bounds". https://doc.rust-lang.org/nomicon/hrtb.html goes into them briefly. Basically, given a trait `T&lt;'a&gt;` you can make a new trait `for&lt;'a&gt; T&lt;'a&gt;`, which things only implement if they implement `T&lt;'a&gt;` for *all* `'a`. You can then use this trait as a trait object, or in a where clause. If you can understand the following code, you might just have higher-ranked trait bounds sussed out! https://play.rust-lang.org/?gist=f209c44b08897fc19439950cae7aab25&amp;version=stable 
It's called a "higher rank trait bound" (or HRTB), but the only documentation I'm aware of are [a brief mention in the 'nomicon](https://doc.rust-lang.org/nomicon/hrtb.html), and [the HRTB RFC](https://github.com/nox/rust-rfcs/blob/master/text/0387-higher-ranked-trait-bounds.md). Short version: `for&lt;'a&gt; T: Trait&lt;'a&gt;` means that `T` implements `Trait&lt;'a&gt;` for all `'a` rather than a single, specific `'a`.
&gt; Wow, this is surprising, and a huge blow to Rust. A blow, certainly. However I don't find it particularly surprising. All the software engineers I know, myself included, generally change projects after a couple years (say, 3 to 5). At some point you need a change of scenery, you wish to explore new challenges, ... Actually, at the company I used to work at, it was customary to ask programmers with 3/4 years experience in a team which team they'd like to go to. Sometimes you'd stay a little longer (wanting to finish a specific project, or waiting for an opening in a specific team), but many would hop team after this much time. And honestly it felt refreshing. Change is good for the employee, and it's also good for the team! Newcomers mean new ideas, new experiences, ... *Not to say I'm not sad to see brson leave, heart and reason rarely see eye to eye ;)*
r/playrust
Thank you
What's the motivation behind this? This seems very similar to Cow.
It means "this module" (in this case `std::io`). It would be equivalent to write use std::io; use std::io::{Read, BufReader};
Hard to spin this news as anything but a negative for rust, but of course, I join everyone else in thanking brson for all his hard work and wishing him the best in the future!
I have a linked list structure that turns into a tree at its tail during processing. Each node can either borrow or own the previous node, depending on what's currently happening. I've never actually taken a good look at `Cow`. The similarities are purely coincidental. One aspect that's different with `MixedRef` is that it enforces immutability to avoid potentially expensive cloning.
Wrong subreddit. Better try [/r/playrust](https://www.reddit.com/r/playrust/)
The origin of `for&lt;'a&gt;` is that closures were brought into using Rust's trait system instead of their own specific types. When we have a regular function we can have it connect the borrow of input with the output like this: `fn foo&lt;'a&gt;(&amp;'a Input) -&gt; &amp;'a Output`. The closure equivalent, using the trait `Fn` in this example, needed the for syntax to express it as a trait bound, with the expression of the equivalent it being `for&lt;'a&gt; Fn(&amp;'a Input) -&gt; &amp;'a Output`. Now of course there is a shorthand — `Fn(&amp;Input) -&gt; &amp;Output` is the same thing — but the language needed that `for&lt;'a&gt;` became a feature, even if it often wasn't explicitly written out.
The inverse of this is quite damaging. I call it "skill inversion." Essentially a company will feel a large motivation to keep engineers on a project to maintain continuity beyond the point where it is a challenge. Moving strong core contributors to janitorial roles. Simultaneously the B team is putting together the next project or product, with none of the input from A team. Eventually the company wakes up to the fact that the A team should have been on the B teams project, as it's a bit of a mess. So they reluctantly bring them over to get it done quickly as they are past a deadline. Now, what is the B team doing while A team is cleaning up their mess? They are are ofcourse laying the groundwork for the next project! Same as a thread running at an inverted priority, and for the same reason. Execution pressure keeps the cycle going.
People who already hate Mozilla probably don't run firefox nightly. Meanwhile, have you seen the [servo](https://github.com/servo/servo/blob/master/resources/servo.png) logo?
Frankly, I think that the fact that there's a core reason behind putting this meme in there and the fact that it's on a nightly, I think they're going to garner more positive opinions about the company. I've in the past looked at Mozilla and wondered "what the fuck are you guys doing?" but never really hated them. But seeing this little joke put in (in commemoration of the implementation of the servo engine) makes me see Mozilla as actually kind of cool. Not simply because it was a meme, but because the meme is there *for a good reason*. I can understand why someone wouldn't like this but to claim that Mozilla is hated is a huge stretch. Mozilla is and always has strived to advance the web in ways that Microsoft, Apple and especially Google aren't doing. Edit: See [here](https://www.reddit.com/r/firefox/comments/6uhkuo/ahahaha_such_new_many_logo_wow_icon/dlt934s/), [here](https://www.reddit.com/r/firefox/comments/6uhkuo/ahahaha_such_new_many_logo_wow_icon/dlsrd7w/), and [here](https://www.reddit.com/r/firefox/comments/6uhkuo/ahahaha_such_new_many_logo_wow_icon/dltlpxo/). I also happen to concur with the perception of this being a hilarity.
Great, I can see this really helping clean some things up; I like that it puts the info where you'd expect to look for it, not in an arbitrarily named function you'd need to be aware of to use.
I didn't, no worries. 
Could always grab me between talks at RustConf!
&gt; and a huge blow to Rust. Absolutely agreed. It makes me wary of Rust's future TBH. EDIT: Wow, this subreddit is vicious. Have at it!
Noooooooooooooo. It's so shocking to see brson go. :'(
Agreed. The basic lesson here is not to put all of one's eggs in one basket!
just killed a man
What are iterators, what can they do, how do you use them, and why would one want to? Thanks.
There is already variable introspection but I think it is possible because rustc uses Microsoft linker.
It's a blow, sure, but part of the great work that Brian has done is ensure that Rust's future is not contingent on the lifetime involvement of any one person. There are plenty of other folks who are helping out with Rust's future, so I wouldn't worry too much! Edit: Don't understand why people are downvoting the parent - it's an understandable response.
Very nice! I am already using it.
Is it really working in such way? As I read before about `custom derive` if your mark some `struct` with `#[derive(Custom)]` you got stream of tokens with only this item (`struct`), in other words you got only `struct Foo { data: i32 }`, you do not get any info about `impl`. And that make sense, because of `impl` for one `struct` may be in several files. So may be, I have to use attribute `#[derive(Swig)]`for `struct`, `impl` and static `fn` in your example, to get analog of `foreign_class!`?
Yes, this is very bad. You end up with top people maintaining old, poorly documented, messy projects simply because no one else will take the time to learn how or can figure it out. Your A team is stuck with a B team mess from a B team that quit long ago. (Intern projects, old student development, or misguided jr development are some examples that come to mind.)
This is pretty similar to what I'd want, but it suffers from the basic problem of split_at_mut in the first place: exactly two targets. The ideal solution would be able to use any number of targets.
No worries. Please come back if you get interested in learning to write code in Rust! :)
Yep. Having LLD emit PDB doesn't help debugging on Windows because we were already getting PDB's from the Microsoft linker. What it does allow is switching to LLD on Windows. This can enable some new things which wouldn't otherwise be possible: 1. Inlining across the C/C++ Rust boundary using Link-Time-Optimization 2. Better cross compilation to Windows from other platforms
Servo officially does not have a logo (yet). I think initially someone (I don’t remember who) made the Doge-in-Rust-gear mostly as a joke and used for the profile picture of https://twitter.com/ServoDev. Later it was added as an application icon for Servo itself and now it’s often used in place of a logo, in both cases because it’s better than nothing. I don’t think it has anything to do with this subreddit.
[Rust book has a chapter on iterators](https://doc.rust-lang.org/book/second-edition/ch13-02-iterators.html), I would recommend reading that to get started. 
&gt; My perspective could be summed up in a concrete example as "I won't blame nom for containing an unexpectedly reachable panic, but I will blame it if it intentionally produces a reachable panic as a result of the grammar I give it and I will blame a hand-rolled parser for containing an unintentionally-reachable panic." I think I agree with that, in the context of parsers. Elsewhere, I would add that it's OK to panic as long as it's clear documented, but I'm with you in that a good parser probably shouldn't have any documented panics.
This is why I use Gentoo ;). It has neither disadvantage. Pretty much bleeding edge, and everything always builds (unless you are doing funky experimental stuff with your system, which is something I am really guilty of). Mostly because the gentoo package system allows you to have multiple versions of the same thing simultaneously on your system, so you can have several versions of autotools/gcc/whatever, but also because gentoo, by definition, is designed to let you build everything from source. The disadvantage? Lots, lots, *lots* of waiting. Oh and a bit of a learning curve, but if you are using Arch anyway, it's not that much more complicated. Gentoo could really have more user-friendly default settings, though. Oh, and all the money I've spent on powerful CPUs with lots of cores :D. Gentoo can be an expensive hobby. Am soon going to buy a Threadripper for gentoo-ing. 
Just read [this](https://www.reddit.com/r/rust/comments/6ud3zm/how_to_learn_to_take_advantage_of_type_system/dlsus6z/) comment that suggests to create a struct with "new" method just to limit possible values in an unsigned int. Is this actually a good practice? Calling a function just for that would seem costly, no? Function calls aside, does wrapping primitives in custom types impose runtime cost?
Since you are saying that `uutils` are, for the most part, better than Redox's own `coreutils`, is there any reason why both should exist? Is it not better to join forces? Help improve `uutils` and just use them in Redox?
Why? There's been close to 150 contributors in the last release.
Rust shouldn't marry itself to async/await either. I'd rather rust have threads and processes, and let libraries provide actors, coroutines, futures... Whatever may come.
I have read this chapter :) still confused to be entirely honest what's different between that and a for.. in loop
Ah thanks. That had been bothering me when I had to do it, actually :-)
The overhead of function calls in Rust is tiny compared to that of managed languages. In release mode, a `new()` function should be inlined anyway. Rust's structs are purely a compile-time abstraction; they don't pose any inherent indirection or memory cost.