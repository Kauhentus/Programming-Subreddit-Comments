Neat, that worked. Are there any CLI programs that would be easy to test with this?
the other thing we had all those years ago was a separate debugger with UI, (and later IDE's integrated it), even if a program doesn't crash it was so helpful to place breakpoints and see how something got called, step through the chain of execution , watch variables (without having to debug print everything, although I definitely like how rust is better at that). I just took a look at the RLS and the animated videos of use only show the parts I already have (i've even got a hover showing arguments as you move the cursor around), not the part I'm missing : dot-autocomplete. (i should start calling it "type-based-discovery" to really emphasise what i"m missing)
Yeah, I don't disagree with any of this. But, it sounds like you are saying "if we can avoid using Rust types, capnproto is fast" which .. well Rust's types are kinda why I use Rust. I think we probably understand each other, and I shouldn't have baited /u/comex into evaluating abomonation, but I think this all started from "should one be worried about struct layouts" and I think the answer is still yes. Even though we know more about abom and capn now.
Can this proposal be made to output [RFC5424](https://tools.ietf.org/html/rfc5424.html)? It looks pretty general, but 5424 has this weird 2-layer map thing (see section 6.3). It also requires a pile of standard data, e.g. process ID, hostname. Does the log crate support a way to attach metadata to all lines?
If you want to test startup time, try this: `time out/scramjet net/uazu/scramjet/test/StdRedir &lt;mk` I get 344ms first time, 11ms after that.
Yup, that worked! Awesome.
I would really like to design the GUI outside of code in a guy designer application. I would like to load the GUI at runtime and render that GUI directly to a Vulcan buffer
&gt;this approach is fine, \*\*I have some parsers where I use a line iterator then a nom parser on its result\*\*. If you want to parse the whole thing with nom, the issue will often be with the last line. Emphasis mine. &amp;#x200B; As someone who has been pleased using nom so far, i think it's very key to note that nom parsers don't have to just be made up of nom macros, i feel like that's an impression a lot of people get. There can be rust code that does stuff, and it can be a lot nicer for some complex operations, and the combination of the smaller parser combinators in things like line iterators would be a really cool thing to see an example of imo (not sure if there is one, i checked out nom right around 4.0-beta) &amp;#x200B; I also would like to say that \`&amp;str\` not working like \`CompleteStr\` did mess me up for a bit, and i had a lot of trouble figuring out where some of my simple parsers were going wrong. I didn't fully understand the way nom supported streaming parsers and how that effected the parsers i wrote. &amp;#x200B; Rust was not my first programming language, but it was the first language where i started doing parsing stuff, and nom was tricky at first! But once i understood it i found it very nice and productive to use. I noticed you mentioned some lack of feedback in another response, so i just wanted to chime in with my experience with nom :) &amp;#x200B; Nom-trace looks really cool!
Maybe not totally relevant but I found this resource really helpful when trying to get my head around API design: [https://deterministic.space/elegant-apis-in-rust.html](https://deterministic.space/elegant-apis-in-rust.html)
&gt;Does the log crate support a way to attach metadata to all lines? This is usually provided by the logging backend/formatter, e.g. [https://docs.rs/syslog/4.0.1/syslog/struct.Formatter5424.html](https://docs.rs/syslog/4.0.1/syslog/struct.Formatter5424.html).
Nice work! One constructive criticism is that I think the code blocks are hard to read because of the font that is used. Perhaps you should consider using a monospaced font? 
Ok, thanks for your explaination. I understood I can't access nfc reader from wasm directly I would replace cordova for my app (wrote in JS), but I can't understand what is the best solution... :( &amp;#x200B; &amp;#x200B;
Thanks so much for the input! I'll push out a revision for the code block font. As far as using camel case, it's how I prefer to write things, but I will make a note to explain that standard Rust uses snake case.
&gt; I don't think this will ever be fully true, Go has its amazingly simple learning curve that Rust is no where near competing with. Yes, but to a point. Goroutines and channels, while not super difficult, are poorly implemented. If it's your first time learning something like that then it might be ok. For me, coming from an erlang background, and having spent a reasonable amount of time in Rust and also with `actix`, my progress in Go has been substantially slower than what I expect is common.
Happy to help! Thanks for a great contribution to the community! 
Would this also support nested structures? That would be especially useful for JSON output.
Probably Java, with maybe a bit of Rust if there's any need for it.
It's not "totally different", it just takes the `err` value so you can do something with it in the closure.
I know I'm being demanding here, but would it be possible to have it in ePub (or mobi)? I'm not a fan of reading from my laptop's screen. :)
sorry updated the question. Why does Result.or_else expects a closure that takes 1 argument, while Option.or_else doesn't? 
Have to agree with OP, explicitly using non-idiomatic style in a tutorial is very surprising. Also, why are you doing/copying `/usr/bin/cargo run --color=always` instead of `cargo run`? Also surprising.
Because the closure `Result::or_else` takes receives the `Err` value, and the closure `Option::or_else` doesn't need to receive the value - the only value it can possibly be called on is `None`.
Not entirely related, but I've written a crate to get `slog` to output RFC5424 (and RFC5425) to a type that implements `Write`: https://crates.io/crates/slog-syslog5424 Important to note that I have barely tested it, so probably won't want to use my crate in production... There's also currently no example of writing to the systems local rsyslog, but it should be pretty easy (just substitute the required `Write` type). The `syslog` crate has a way to write to the local rsyslog so could probably be mostly copied from their implementation. The reason I wrote another formatter was so that a generic writer could be used. I'm usually on windows, so compiling on windows is nice too. The `syslog` crate will only compile on unix systems.
Option's "unsuccessful" case is `None` -- which carries no values. Result's "unsuccessful" case is `Err(error)` -- which carries one value. Thus, Option has `or_else(|/* no values */| …)`, and Result has `or_else(|err /* one value */| …)`.
Because an option would give you a None if it hits the or_else, you know what it is. For a result you may want to know what the error type was that made you hit the or_else, so it's passed in to the closure.
&gt; on a 10 year old Linux install won't have Docker on it. 
However it seems like this [PR will allow const types](https://github.com/rust-lang/rust/pull/53645/files#diff-0c34ef03d6e1a35e7393327aed01e66b).
Sorry for the stupid questions. I think I partially got your point. Result::or_else expects closure with 1 argument, because inside the closure we can evaluate the error type and can change the functionality according to error type if needed. Am I correct?
I'll be there!
The error _value_, not the error _type_. The types are fixed by the `Result` type you're using.
Could there be a Rust-Lite that had some sort copy-by-default, something like a lightweight GC. Then someone can standup a new service and let the allocator histograms tell me where to focus the detailed ownership rules? Maybe we will see a Scheme or ML that can smoothly ride on top of Rust.
Thanks, I think I got the point :)
Got it :) 
got it, thanks :)
You mean it would not be possible to express something like above, because of the `size: N` part ? Hum.. I kind of understand, the `N` is something like a "type" more than a "value". pub struct Windows&lt;'a, const N: usize&gt; { inner: &amp;'a [T], size: N, } impl&lt;'a&gt; Iterator for Windows&lt;'a, N&gt; { type Item = &amp;[T; N]; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { unimplemented!() } }
slog crate?
Hello everyone. Today I've tried to use some interior mutability, and I have concocted something that greatly confuses me. Here's the simplified code: use std::cell::RefCell; trait Fmt { fn format(&amp;self, s: &amp;str) -&gt; String; } struct Lazy&lt;F&gt; { closure: RefCell&lt;F&gt; } impl&lt;T, F: FnMut() -&gt; T&gt; Lazy&lt;F&gt; { pub fn new(closure: F) -&gt; Self { Lazy { closure: RefCell::new(closure) } } } impl&lt;T: Fmt, F: FnMut() -&gt; T&gt; Fmt for Lazy&lt;F&gt; { fn format(&amp;self, s: &amp;str) -&gt; String { let r = self.closure.borrow_mut(); // OK let fmt = r(); // ERR fmt.format(s) } } The idea is to allow `FnMut`s to be `Fmt`s without changing the signature of `format` (`mut` or, heavens forbid, plain `self` just don't belong there), because it seems like a useful thing to have. However, when I try to actually call the closure contained in the `RefCell`, I get `cannot borrow immutable borrowed content as mutable`. I'm not sure I understand what's going on. Could anyone explain this what I'm doing wrong?
&gt; As far as using camel case, it's how I prefer to write things, but I will make a note to explain that standard Rust uses snake case. Please, don't. It's not a good idea to teach newbies to use nonstandard rust formatting. Keep the camelcase for your own personal projects.
It would support anything that `serde` supports, so yes.
I just copied the result from stdout showing what I get when I do `cargo run`
Thanks for your explanation! I think these are enough to justify removing `failure` from `ndarray-csv`. Is there a place that this wisdom is written down?
I appreciate the effort, I really do, but the writing style is way too flippant for me. And I expected a book titled “Code Artistry” to be about beautiful code, elegant solutions, and being hyper idiomatic about everything.
Thanks so much! The colour scheming is a great idea. I'm in the process of doing that and the monospaced font now. I've also reduced the non-code text size to match. It does look better that way. :)
I’d love to buy it as hardbook somewhere :)
In one project I'm involved in, we were unable to use `syslog` because every log line involved multiple allocations. Our original logger also allocated multiple `String`s, and we found that it eventually caused such severe memory fragmentation that our integration tests couldn't run. Since then, I've been unwilling to use any logging scheme that allocates for every log line. Unfortunately, your crate also has several temporary allocations per log line, and the upstream `syslog5424` has very very many. In its [`format` method](https://github.com/nocduro/syslog5424/blob/master/src/lib.rs#L223) we see the `log` variable is a `String::new()` which is repeatedly appended to. Every append is a potential allocation. At one point it calls `generate_priority`, which allocates a new String, appends it to `log`, and drops it -- two allocations and a deallocation. This is followed by multiple loops where it does the same thing. Similarly, it calls the utility function `remove_invalid` which generates a new `String` which is then dropped. It calls into slog-syslog5424 [here](https://github.com/nocduro/syslog5424/blob/master/src/lib.rs#L276), calling the [structured_data](https://github.com/nocduro/slog-syslog5424/blob/master/src/lib.rs#L91) method which constructs a `Vec::new()` and repeatedly appends to it, potentially allocating every time. It inserts the resulting vector into a hashmap. The caller pulls this apart to append it to the `log` String then drops the whole thing. I'm not saying this to be mean, but because it's hard to design a logging API that doesn't encourage this sort of code, and I want to make people aware that it's essential to think about for production-grade logging.
Well, aren't you as sweet as honey :) I have been chatting with some publishers, actually. I'll keep you posted!
Out of curiosity, what did you use/do instead? I may be running into the same issues and am looking for an alternative.
That's a good idea. I'll look into it :)
There is a simple solution for saving allocations in code like these. Just use a thread-local `String` for everything, and clear it before/after each use. These way one `String` is ever allocated per-thread, and rest of the code can stay roughly the same, without designing all the alloc-free APIs everywhere. Ping /u/Tritanium
These is an RFC to add structured logging support to the "standard logging crate" (`log`). It would help `slog` and `log` interoperability, potentially in the future.
I would just not feed it programs with errors :D 
No idea what's the real problem here, but it works if you explicitly `deref_mut` it. [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=0b445f058a6e32fe202014b441646af5)
Our types mostly have methods like ```rust pub fn write_5424&lt;W: Write&gt;(&amp;self, mut stderr: W) -&gt; io::Result&lt;()&gt; ``` and each one uses the `write!` macro to write into the `stderr` object (which is misnamed, I think right now it's actually a unix socket..). Each object reimplements the `[id field=name field=name]` syntax in the format string for `write!`, but in practice this isn't that bad of a DRY violation.
I agree with you, I made this crate quickly to try and get some structured logs into InfluxDB for my own prototype, but haven't had time to use it much and benchmark it. In the documentation it calls out it wasn't made for performance under ["Important Info"](https://docs.rs/slog-syslog5424/0.1.1/slog_syslog5424/#important-info) The number of allocations I said in that point is way off of course, not sure why I only counted those 3... It also says an optimization would be to reuse the buffer in the `slog` writer part (similar to the [thread local buffer used in `slog-json`](https://github.com/slog-rs/json/blob/master/lib.rs#L42)) and a similar method of reusing strings in the underlying `syslog5424` crate could be done as /u/dpc_pw suggests
_Well, hello there_
That's only dynamic checking though. Way weaker than static guarantees...
I wouldn't call it wisdom, it's just the opinion of a random guy from the Internet :-). Things like the build time impact are apparent once you start using the crate (you're already using `serde`, but I don't know what version of `syn` `failure` 0.1.2 is using). I've seen users confused about the API on IRC. There is some discussion about the future of the crate [here] (https://github.com/rust-lang-nursery/failure/issues/209). The rest was just my interpretation of the current status. Note that there are plans to move forward with `failure`, in one way or another.
A great example of why you shouldn't sacrifice correctness for a possible performance gain.
&gt; Could there be a Rust-Lite that had some sort copy-by-default, something like a lightweight GC? That's an excellent question! If you head over to r/programminglanguages there's a few people exploring various designs. My personal experiment is a combination of immutable values (persistent data-structures), using reference-counting and optimized copy-on-write: - Immutable value means thread-safe. - Immutable value means no cycle of references. - Optimized Copy-On-Write means bona fide arrays are possible. On paper, it looks pretty good. Theory, alas, needs to meet practice. And practice is 99.9% of the effort. For now, I'm left wondering at the kind of performance this could achieve. I would expect it to be on par with Go, which is a nice sweet spot to be, but I may have overlooked a critical issue that'll sink my dreams.
Totally agree as beginners should learn how other write code, so they are able to learn from other (code) sources.
&gt; back then almost no one used Linux Didn't plenty of people use linux around 1998?
/u/jDomantas has the right idea, but it's because `RefCell::borrow_mut()` returns a wrapper type `RefMut` which doesn't directly implement the closure traits. The error is unfortunately confusing here. What you actually want to do is deref and re-ref like this: let fmt = (&amp;mut *r)(); That applies the call operator to a type of `&amp;mut F` which the compiler can figure out.
Well, that was a nice dev session. The `either` pattern actually predates the `movfuscator`, though. It is a common technique in constant time algorithms.
I haven't read through all the code yet, but so far I have to say that this is one of the better projects I have ever seen. The code is very descriptive and easy to follow. Good commenting which is reasonable (you don't comment code which is self explanatory, which makes the code more concise). I feel like you really organized the code in a logical way. This is a great project! Reading the code of this project has been a great motivation for my own part. I think this should be linked as a more advanced project in some tutorial. This project ticks all the boxes regarding good practices in my opinion. Overall very impressed and thank you for sharing!
I find this way more visually appealing from an aesthetic perspective but the extra coloring/ fading really distracts from the point - to visualize the search. I find it harder to take actual meaning from the visuals because of this.
&gt; I mean, not like today, but still, lots of developers. In 1998? Using Linux in 1998 was more out there than OpenBSD nowadays. Not only you had to know what you were doing - all configuration was done by hand, lots of drivers simply didn't exist, many (if not most) modems outright didn't and couldn't work (were winmodems), and few people had networks at home. Moreover, if you were a developer, back then you needed to work with the Chrome of the day - IE (which didn't work on Linux), and I don't remember when Netscape first came out for Linux (they opened source in 1998). If you needed an office suite, forget Linux - Office didn't work, OpenOffice was in the future and WordPerfect was dying. And there was no Google docs or anything which would work on Linux. And if you were planning on developing for the desktop (where the majority of clients still lived) - you _had_ to use Windows, and you probably used Visual Studio, again only available on Windows. Actually, if you were working in a "pointy headed boss" place (which most companies were), and even in a few tech companies, even your back-end was probably IIS and ASP. Even most unix users back then (who were slowly moving to windows) used commercial unixen such as Solaris. No company would risk their reputation on a bunch of Open Source hippies who made up the Linux community. Back then using Linux on the desktop meant that you were a FOSS extremist (and a Micro$oft hater). This whole "If you're a developer, use Linux" really took off after 2005 or so, when Google commodotized the desktop and Ubuntu made the desktop easy to install.
&gt;Thank you for making this! I'll have to play around with this the next time I need to write something that talks to the Kubernetes API at work. It'll give me a good chance to learn more about doing networking stuff in Rust. I'm glad to hear your approve! If you have any questions/issues on using, feel free to hear them.
This is cool and I applaud the effort. Looking at the Pong example and then comparing it with how people implement Pong using Unity 2D and other engines and frameworks I think using Amerhyst appears to be a bit clunky though. Amethyst Pong example: https://github.com/amethyst/amethyst/tree/v0.8.0/examples/pong Unity 2D Pong tutorial: https://noobtuts.com/unity/2d-pong-game However, they do say the following in the announcement: &gt; A prototype contest for experimental Amethyst editors is happening to help us decide what technology is most adapted for our long term upcoming game development editor. We are currently looking for more people to create prototypes for different technologies (a prototype made using web technologies already exists). So I am hopeful that Amethyst might turn out to be able to compete in terms of ease of use down the line. A project to keep an eye on for sure :)
As someone who spent the weekend grappling with futures like a luchador trying to wrestle a kangaroo... It's nice to see that Rust isn't the only language where this is painful. :-p Also that article links to [this one](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/), which is even better.
I wonder the same, that’d be very interesting. Maybe a cargo plugin? :)
I love you guys and so I have to play devil's advocate a bit, and ask, What can I do with Amethyst now that I couldn't do, or which was really hard, a year ago? "More features" is not as interesting progress to me as "better polish" is.
For fun I also searched for Pong made with Unreal Engine 4 though I did not expect it to be a good example for something to be made with UE4 since UE4 is heavily focused on 3D not 2D as far as I know. They have a wiki page which at first surprised me by being much longer than I expected it to even though I was expecting something a little longer than the engines and frameworks mentioned earlier. However it turned out that on that page they are also dealing with implementing an AI for the opponent. Code formatting is broken at least on mobile though so the page is not pleasant to read. https://wiki.unrealengine.com/Pong_Tutorial I also came across a *really* nice looking 3d implementation of Pong made with UE4. Of course that implementation has a very different goal from what we are talking about when comparing 2d implementations that try to be as simple as possible, but I still think it was worth linking to the video. https://youtu.be/lC70J8x3ue4 And of course if we are going to look at how to implement Pong with UE4 we ought to find out what it is like to implement it using the UE4 node-based visual scripting system [Blueprints](https://docs.unrealengine.com/en-us/Engine/Blueprints). But I am on mobile now so I will have to save looking into that for later. I think it would be worthwhile for someone to do a proper in-depth comparison of implementing Pong in these and other engines and frameworks down to the exact same requirements while also following the current style guides and best practices of each engine or framework. That would be quite a lot of work though. Sort of a hello world / Todo MVC for gamedev.
&gt; Should you want to dive into LaTeX, ask away, I have experience there. I know I am not the specific recipent of this sentence, however I was wondering if you had any tips and tricks related to using latex for higher education purposes?
`Vec::reserve` eventually ends up calling [amortized_new_size](https://github.com/rust-lang/rust/blob/9f9f2c0095cd683b94adca133f2733aa1f88bb19/src/liballoc/raw_vec.rs#L432-L441) -- which (currently) doubles the capacity, unless the required capacity would be larger.
Heh, it's good to see my pointless Reddit argument had a beneficial side effect. Sorry I didn't have a chance to file a proper bug report before you went and fixed it :)
Is this a typo: titles_apr.insert(title); journals.insert(title); Should it rather be: titles_apr.insert(title); journals.insert(journal); To answer your question there is a more "rustonic" way of solving this task. We can use the method [`collect`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect) on an iterator to convert the values being iterated over directly into any type which implements [`FromIterator`](https://doc.rust-lang.org/std/iter/trait.FromIterator.html) (which `HashSet` does). This means that we can simplify the code to be: let titles: HashSet&lt;&amp;str&gt; = root1.descendants() .filter(|n| n.has_tag_name("DADOS-BASICOS-DO-ARTIGO")) // This always filters away journals without a year or with a year that // is not a number .filter_map(|journal| { journal.attribute("ANO-DO-ARTIGO") .and_then(|s| s.parse::&lt;i32&gt;().ok()) .map(|year| year &gt;= base_year) }) .filter_map(|journal| journal.attribute("TITULO-DO-ARTIGO")) // if you want to include journals without a title you could rather use //.map(|journal| journal.attribute("TITULO-DO-ARTIGO").unwrap_or("")) .collect(); If you want to get both titles and journals you could change it to first create the iterator which filters out only the entries you want, and then `clone` that iterator. That would look something like this: let iter = root1.descendants() .filter(|n| n.has_tag_name("DADOS-BASICOS-DO-ARTIGO")) // This always filters away journals without a year or with a year that // is not a number .filter_map(|journal| { journal.attribute("ANO-DO-ARTIGO") .and_then(|s| s.parse::&lt;i32&gt;().ok()) .map(|year| year &gt;= base_year) }); let titles: HashSet&lt;&amp;str&gt; = iter.clone() .filter_map(|journal| journal.attribute("TITULO-DO-ARTIGO")) .collect(); let journals: HashSet&lt;&amp;str&gt; = iter .map(|journal| /* turn journal into str */) .collect(); I have not ran this code, so I'm not sure it will work. However I hope I point you in the right direction still. 
&gt; Rust cannot do those things Sure it can, it's just not quite as pretty. Here's a little proof of concept I wrote: https://github.com/paholg/ranged/blob/master/src/lib.rs
It's not a typo, I have to insert the title into the journal set list and appraiser set list because they are used into different parts of the code. Journals will only have the journal titles, while titles_apr will have all the titles. And thanks, that helped, I gonna try the more "rustonic" way that you suggested :) 
They've added some wrappers around stuff like SimpleState which made things a bit easier, from what I can tell reading the documentation. Otherwise, I don't know. Honestly, It seems pretty polished now.
Am not OP obviously, but wanted to say thank you for taking the time to dig into this
Really enjoyed the typesetting of /u/aturon's thesis
That's a great idea!! :3 I have another question, filter_map requires that the closure returns bool. Attribute returns Option, how do I use filter_map for anything that return Some()?
When I do ``` let titles: HashSet&lt;&amp;str&gt; = iter.clone() .filter_map(|journal| journal.attribute("TITULO-DO-ARTIGO")) .collect(); ``` journal for some reason is defined to bool for some reason, that is the problem xD
azul seems to be churning along and improving. These projects would benefit from experienced maintainers who know how to manage groups of developers. The problem is that they are almost always works of lone star developers who want to do everything, but there is too much work for a single person so they fizzle out. 
Ok, now I did this way: ``` let journal_iter = root1.descendants().filter(|n| n.has_tag_name("DADOS-BASICOS-DO-ARTIGO")) // This always filters away journals without a year or with a year that is not a number .filter(|journal| journal.attribute("ANO-DO-ARTIGO").and_then(|y| y.parse::&lt;i32&gt;().ok()) .map(|year| year &gt;= base_year).unwrap_or(false)); journals = journal_iter.clone().filter_map(|journal| journal.attribute("TITULO-DO-ARTIGO")).collect(); ``` But in `journal.attribute("TITULO-DO-ARTIGO")` I still get a error saying that journal doesn't live long enough 
Ah, makes sense. I really should have read up on `borrow_mut` before using it. Thank you and sorry to be a bother.
Kotlin coroutines are quite nice.
&gt;Or do the faded colors/ many colors have meaning I'm not understanding? Yeah, they do: - Array accesses are red - Current element is green - Sorted elements are blue (I haven't implemented this already) - In quicksort green and blue are used to visualize partitions (maybe I should use other colors?) and partition bounds are red
Any links to this?
Interesting. Maybe just putting that in the readme would be helpful.
Thank you very much! BTW, I made a big mistake when I added the documentation: I wrote it after lots of functionality were added.
Assuming [this thesis](https://aturon.github.io/academic/turon-thesis.pdf) wow - that does look spiffy.
Thanks for your suggestion!
States are now much simpler to create, sprites are no longer just quad meshes but an actual "primitive" (and are much faster than before too, see https://github.com/cart/amethyst-bunnymark), it's now easier to debug thanks to the new debug lines, and probably a ton of other stuff I can't think of right now. (I'm not sure what is in 0.8 and what is only on the master branch, but 0.9 is coming out next week anyway)
Part of the problem is the `specs::System` trait, which is very clever, but awkward to use, and wired into Amethyst at a deep level. A `System` is something that does some sort of data processing in your game. A minimal `System` implementation looks like this: struct PhysicsSystem; impl&lt;'a&gt; System for PhysicsSystem { type SystemData&lt;'a&gt; = ( ReadStorage&lt;'a, Vel&gt;, WriteStorage&lt;'a, Pos&gt;, Read&lt;'a, TimeDelta&gt; ); fn run(&amp;mut self, (vels, mut poses, dt): self::SystemData) { for (pos, vel) in (&amp;mut poses, &amp;vels).join() { pos.0 += vel.0 * dt.0; } } } The idea is that your system statically declares its dependencies. A runtime system can then give your system the precise subset of dependencies it needs, and then run it with other systems in parallel. It's a cool idea. Unfortunately, it involves some scary-looking boilerplate (lifetimes! generics!) and repetition. I've tried to make some small games with amethyst and I found that the boilerplate was a place I consistently stubbed my toe; others may have a different experience. It doesn't help that pretty much *everything* in a game goes in a `System`; except when it apparently shouldn't, see below. In addition (if I understand it correctly) the scheduler is currently static, which means it can't easily cope if one system takes way longer than others running in parallel. Also, if a system is parallelized -- e.g. uses `rayon` for some iteration -- the schedular doesn't know about that by default, and will still try to schedule it with other things in parallel, which will result in fighting over cores. Common gamedev advice is to parallelize individual engine components instead of trying to run engine components in parallel, and there's a reason for that. There's also the optional `setup` trait of `System`: fn setup(&amp;mut self, res: &amp;mut shred::Resources) { ... } This function is used to initialize a new system; it takes a `shred::Resources`, which is a detail of the crate `shred`, which is an implementation detail of `specs`, which is an implementation detail of `amethyst`. `shred::Resources` has an entirely different API surface from `amethyst::World`, despite doing a broadly similar set of things. This means that you have to switch key mentally whenever you set up a `System`. Also, the function takes `&amp;mut self` instead of returning `Self`, which means that your `Systems` have to be full of `Option`s for things that are configured in `setup`. The reason that this API is so awkward is that `amethyst::System` is actually reexported from `shred`, which doesn't know the niceties that `amethyst` provides. Why this is reexported instead of wrapped in a nicer trait I don't know. This speaks to a more general problem with `amethyst` in my experience; it can be difficult to tell where the user-facing API ends and the internal implementation begins. This is partly because `amethyst` likes to use type-level stuff to provide deep configuration, but also partly just a perplexing stylistic choice. See, e.g. the [`ReadStorage`](https://docs.rs/specs/0.12.3/specs/type.ReadStorage.html) type alias: type ReadStorage&lt;'a, T&gt; = Storage&lt;'a, T, Fetch&lt;'a, MaskedStorage&lt;T&gt;&gt;&gt;; Do I need to know what `Storage`, `Fetch`, or `MaskedStorage` are? What about [`Read`](https://www.amethyst.rs/doc/master/doc/amethyst/ecs/prelude/struct.Read.html) and [`UnprotectedStorage`](https://docs.rs/specs/0.12.3/specs/storage/trait.UnprotectedStorage.html)? What's the difference between `GameState`, `World`, `Resources`, `Resource`, and `StateData`? A lot of this stuff has, uh, [succinct documentation](https://www.amethyst.rs/doc/master/doc/amethyst_assets/enum.AssetPrefab.html), which often consists of something like: &gt; `FetchResourceIdAssetMarker` is a helpful wrapper that packs a `shrev::EventSystem` into a `gorp::AssetMarker`. IMPORTANT NOTE: make sure you flush the corresponding `splurk::ContentPipe` every few frames, or else the queue will grow without bound! I still don't understand how to use this thing, and now I'm worried I'm going to damage my game somehow if I use it wrong. There are also multiple ways to do a lot of things - should I make my resource `Default`, or `TryDefault`, or initialize it in a `Bundle`, or initialize it in my GameState start function, or what? There's [a book](https://www.amethyst.rs/book/latest/intro.html), which has gotten more detailed since I last read it, but it still doesn't cover most of the subsystems for rendering etc., so you have to muddle through the perplexing rustdocs yourself. Basically, in my experience Amethyst is all hard edges. You need to have a deep understanding of how the engine works to use it, which is precisely the opposite of why I wanted an engine in the first place! To be clear, I think Amethyst is very cool; it has a lot of interesting technology built up within it, and a lot of potential to be an amazing tool. Whenever I try to use it, though, I bounce off. I think it needs some serious work on ergonomics before it's approachable enough for widespread use.
&gt;Maybe Piston Tutorials is a good place? I was more thinking like a general site like Rust by Examples o.l because it doesn't really show off the piston library but good and idiomatic practices. 
I've changed project name and description to this: &gt; **sorting-visualization** &gt; &gt; A Rust program for visualizing sorting algorithms which uses Piston for graphics. Inspired by Hopson97/Sort-Algorithm-Visualiser. (Reddit doesn't allow you to edit a link post)
I would read the blog. In any case, yeah. I kinda see what you mean. I still haven't used it yet for many of the reasons you stated, especially the render code being some smoke shrouded stuff which is actually kinda annoying when some of the documentation just says: `amethyst::render::pipe::Pipeline` Configures the rendering pipeline Well it never describes the rendering pipeline, what it is, when it's used. Nothing. After reading what you said, you're right. Some stuff does kinda rub me the wrong way, but the ECS side of things actually feels kinda intuitive (although some of the boilerplate does feel kinda ugly and clunky, but I can see its necessity)
For the examples, may I suggest each example provide a side-by-side plain Rust code equivalent, so it's easier to understand what's actually being generated.
I don't know if it's this you're searching for, but have you seen how [specs](https://github.com/slide-rs/specs) does something similar to what you describe using associated types? 
Like this: ``` pub fn attribute&lt;N&gt;(&amp;self, name: N) -&gt; Option&lt;&amp;str&gt; where N: Into&lt;ExpandedName&lt;'a&gt;&gt;, ``` 
Good ideal. :)
Thanks! It was great fun working through it.
It's a fairly old article at this point. I'd be surprised if there were many programmers who haven't seen it. That said, it's certainly worthy of rereading every once in a while and I've wanted to discuss it in more detail with regards to Rust futures. Much like Kotlin's coroutines, at least Rust's async/await lowers the cost of calling red functions and translating blue functions into red ones.
List comprehensions! I never knew I wanted them in Rust but now I realize that I really miss them.
Making a workshop for teaching Rust. Trying to use an API client to explain the basics and how everything pieces together.
Wow, nice! So with lots of macros that generate `From&lt;T&gt;`, one could also make it possible to assign a `Ranged&lt;i64, Z0, P29&gt;` to a variable of type `Ranged&lt;i64, Z0, P30&gt;`, right? I mean, it's impractical to use because of the syntactic overhead, but still, the fact that one can pretend having dependent integer types using macros and generics is really cool!
I do not understand how to solve this problem without some more context. Is this code on github? 
You should be able to do that with a single generic `From` impl.
&gt; I am wondering whether there is any will within the WebRender/Servo team(s) to start an 'officially sanctioned' webrender based UI project? This - the vibe I got from the post is that I can / should use WebRender for my Rust UIs. I cloned the repository, ran the examples, got a black screen on all of them :/
The general feature you're looking for is called *higher kinds*, and Rust is hopefully getting a version of them soon (in the form of [generic associated types](https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md), or GATs for short). Today, however, you can't write this code. :(
The workaround would be have `C` and `M` be concrete collection and map type. Then in implementation you add bounds to to ensure `C` is collection over `B` and `M` maps `A` to `C`.
I started working on [my own k8s client](https://github.com/andor44/kubeclient) in Rust a ~~couple months ago~~ more than a year ago (wow time flies). Unfortunately I haven't had time to put into it lately. When I began writing it there were no automatically generated API bindings for it so I began manually translating the APIs myself one by one as I needed them. This made it a bit more ergonomic to use it IMO, but of course makes it a never-ending arms race of trying to keep up with the k8s API.
After finishing [netstat](https://github.com/ivxvm/netstat-rs) crate for listing network sockets information, I started [proclist](https://github.com/ivxvm/proclist-rs) to do the same for processes. Mostly finished an initial version, going to publish it soon. This time I think I got some better design decisions like making an iterator API to allow going through processes without vector allocation. Surely I'm going to implement this in netstat as well.
WebRender isn't yet the production-ready crate everyone wants, but I think that it's by far the closest we have. My point is that it's more useful to fix issues in WebRender than make something new from scratch and after a year or work get to where WebRender is now and have to deal with the same problems. The issue you filed is pretty serious and I'm certain it will get addressed as soon as someone manages to reproduce it and investigate. If we can't do that we'll reach out and try to debug it with you if that's OK. &gt; I am wondering whether there is any will within the WebRender/Servo team(s) to start an 'officially sanctioned' webrender based UI project? The team has limited resources and so much to do. We can't justify investing a lot of time on something that would be cool and useful unless it is critical to Firefox. But we can mentor contributions and accept pull requests. These contributions don't necessary need to line up with Firefox or Servo's priorities as long as they don't contradict.
Well I first tried a talk but the feedback I got was they wanted to get a bit more hands on experience as the syntax and concepts were quite unfamiliar and hence not everyone kept up. (https://slides.com/maccoda/deck/) I am intending on targetting the same audience, familiar with software but only minimal to no knowledge in Rust. I am intending of writing it such that I walk them through the sections in a workshop but also leave enough information if they wanted to follow it up in their own time. Will post it up when I have it completed.
Please do. I have a plenty of time because I want to wait for students in my year to learn C++ since Rust is some sort of replacement of it. 
Thats good to know, seems a lot less bad in that case.
Doing some [clippy](https://github.com/rust-lang-nursery/rust-clippy) and [TWiR](https://this-week-in-rust.org) stuff, if time permits. Also I'll be preparing a workshop for some unnamed conference, but I don't yet know what it'll be about...
As for SO, please be aware of its specificities before asking. When asking SO, you ask a lot of people to give time to look at your question, and the focus of the community is to produce QA which will help other people later. This means that: * this isn't the right place for discussions, recommandations, open-ended questions * you must have done the necessary debug / logs before * apply fmt and maybe clippy before asking * asking is hard, takes time, and is only done after you checked the question wasn't already asked * more than in any other place, a [MCVE](https://stackoverflow.com/help/mcve) is crucial * a wall of code, or non relevant code or comments, won't be welcomed. Keep to the point, don't disgress * you must be ready to fast edit your question if asked for clarifications (don't post and then leave for an hour, stay reactive)
Thanks. I'm strongly leaning to Vulkano now, but considering my indecisiveness, it probably won't be for long.
Would you say it's better to pick up something else, like ggez or sdl2-rust instead of Amethyst, if I plan on making 2D games in Rust? Just as a hobby, for fun, nothing special...or would you say Amethyst is good enough to pick up and just have fun around in?
you could try cute https://docs.rs/cute/0.3.0/cute/ you can do the same thing with iterators, but it does tend to be a little more verbose.
This looks pretty close to `constexpr` support in C++11 (7 years ago...), although I believe it did support `?:` from the get go. When I think that there are still two months until Christmas, I wonder what const evaluation will look like under my glittering tree :)
Woah! Python in Rust! What do you think about s/sugar/python/ -&gt; python-rs ? 
&gt; Just because we've been doing it for 30+ years doesn't mean the problems are solved, just that we've discovered many new ways to make it complicated. ;-) I guess part of the problem is that users' expectations (and hardware) keeps growing, invalidating previously accepted solutions within a few years of them going mainstream.
Good suggestion. The crate by OP apparently just re-exports these macros from `cute`.
Indeed, though one annoyance is `Option?` in a `Result` context generates a `NoneError` which does not implement `Error` which is a pain in the ass for quick-but-not-quite-that-dirty CLI (e.g. `fn main() -&gt; Result&lt;(), Box&lt;Error&gt;&gt;`)
Are there any ideas of implementing `Drop` for futures, so that they are cancelled if they are not finished?
I believe you posted to the wrong sub. This has nothing to do with rust language. I suggest you try r/fortran
This sub is about the Rust programming language, a hobby I recommend ;) For the Rust game, see r/playrust
plz dislike video grandma bullying me
Have you considered she might have a point? 
 ive only got 5000 hours on rust man
Awesome! This looks really great, can't wait to read the blog post :)
GTFO
Generic Associated Types
Working on a command line tool for doing quick polarization simulations. It’s meant to quickly answer questions such as “what happens when a linearly polarized beam at this orientation passes through a polarizer at that orientation, followed by a quarter-wave plate at this other orientation”. The underlying simulations are 90% done, and the command line portion is probably 75% done. These simulations are really just multiplying 2x2 matrixes together, so in principle you could do them by hand, but it gets hairy once you have more than 2 elements. This started as a case of scratching my own itch, but I decided to flesh it out a little bit since I couldn’t find a similar tool anywhere else.
Scooping up some easy Hacktoberfest PRs in multi-language repositories, since Rust is typically far behind Python/Java in number of submissions.
Are there any resources for learning better design patterns for Rust? I’ve seen the Sea of Objects vs the Tree of Values in the Programming Rust book, and while I see the benefit I’m having trouble translating my problem to it. For example, imagine a website with user blogs. A User has a Vec&lt;Post&gt;, easy enough. But what happens when I add a Vec&lt;Comment&gt; to each Post where a Comment has a User associated with it? I don’t see a clear ownership tree here. Before I go diving off into Rc-land I wanted to make sure I wasn’t just stuck in poor design. Thanks!
For generator-like iterator comprehension, I'll throw a suggestion to look at [r4](https://docs.rs/r4/1.0.1/r4/) onto the pile.
[Here](https://youtu.be/0zOg8_B71gE)'s a presentation that may be what you're looking for. In your specific instance I would say comments should hold an &amp;User, although now you have to put a type parameter everywhere to ensure the comments don't outlive their authors.
Thanks I’ll check it out! As to &amp;User, wouldn’t that mean that I cannot add posts to a User once they have made a comment? I could put the Vec&lt;Post&gt; in a Cell but I suspect that is a mistake. 
Is the goal just for macros or also extension traits? [`boolinator`](https://docs.rs/boolinator/*/boolinator/trait.Boolinator.html) is one my favorite unused crates. I say unused because its slick enough that I want to use it but the value is just low enough that when I think to use it, the effort isn't worth it and I use a traditional `if` statement.
I see this uses `maplit` rather than [`collect_mac`](https://docs.rs/collect-mac/*/collect_mac/index.html). What are people's thoughts on the choice of one over the other? I think I prefer `collect_mac`s general approach over the less verbose approach: // maplist let map = hashmap!{"a" =&gt; 1, "b" =&gt; 2, }; // collect-mac let map: HashMap&lt;_, _&gt; = collect!["a" =&gt; 1, "b" =&gt; 2]; This also reminds me, I wish there was a way for us to identify crates that are related to each other, so if you look for `maplit` you can find `collect_mac`.
Of course, Extension trait is the another goal. Actually I implement a naive extension trait for Result. Thanks to point boolinator for me. I will check it.
Actually, I didn't know the `collect_mac` before your comment. When I creating this crate, I try the best to unify the syntax of related macros. Because there is the `vec!` in Rust, the `hashmap!` is more natural for programmer (IMH0). ```rust let v = vec![1, 2, 3]; let hm = hashmap!{"a" =&gt; 1, "b" =&gt; 2}; let hm2 = c![i =&gt; i + 1, for i in 1..4]; ``` 
That makes sense (and I'd recommend documenting that rationale / design principle somewhere). Maybe worthwhile to have both then so that you have to equivalent macros plus a catch all?
I have a library function that can potentially run for a long time. I'd like to wrap it so that it returns a value if it finishes within a second and an error if it doesn't. I've been looking at the timeout function of futures, but I don't see how I can convert a simple function call into a future. Hopefully it's not too difficult? Or maybe there's another way? Thanks in advance. 
I'll gladly answer. There's always the excuse that the OP could benefit from this, right? :) I was prepared to provide a sample of my thesis, but peeking at aturons' left me quite intimidated. The main point for me always was being able to focus on substance first and appearance later (classic argument). You just write down what you have to say, sprinkle in structural information as necessary and only begin to fix details in batches from time to time. Whenever there is a lot of repetitive stuff, use macros. `xparse` provides a great interface for doing that. And using the XeTex engine allows to use any Truetype or OpenType font. Overall, I have more specific explanations of what I chose to do than generic advice. And I am not sure I can say anything specific to higher education purposes. I am not working in academia, so I can't give advice concerning publishing journals and extended bibliographies. **Functional:** Highlight source code: \usepackage{minted} \setminted{fontsize=\footnotesize,linenos=true,stepnumber=1,breaklines} \setmintedinline{fontsize=\normalsize, breakbytokenanywhere=true} \usemintedstyle{friendly} This inserts highlighted rust inline: \DeclareDocumentCommand \rinl { O{} m }% {% %\mintinline[style=bw,#1]{rust}{#2} \mintinline[#1]{rust}{#2}% }% Same as above, but provide additional context for lexer: \DeclareDocumentCommand \structn { m }% {% %\rinl[gobble=7,style=bw]{struct #1}% \rinl[gobble=7]{struct #1}% }% **Visual:** I love using Source Sans Pro for Headings, it is clean and not one of those "I don't give a damn" default fonts. Maybe I'm being pretentious, but I think a serif font can provide refinement and seriousness. My default choice is [Vollkorn](http://vollkorn-typeface.com/), which is designed very carefully and provides a number of stylistic choices. It can seem rather strong but looks very good in print and high resolutions. As mentioned before, I use Hasklig for mono-spaced content. \setmainfont[Mapping=tex-text,Numbers=Lining,Scale=1.10]{Vollkorn} \setsansfont[Mapping=tex-text]{Source Sans Pro} \setmonofont[Scale=1.0]{Hasklig} Whenever possible, use vector graphics. If there is no other way, rasterise at 300dpi or more. If not building graphics with `tikz` (very advanced but allows for superb results), I use software like `inkscape` and export PDF in TeX mode. This breaks WYSIWYG (text in illustration becomes LaTeX code), but ensures that all typesetting is done by the TeX engine, so the font face, ligatures, sizes, weights, etc. look perfectly consistent.
Yeah, the hashmap syntax of `cute` and `maplit` is same, so I bundle them together. ```rust let hm1= hashmap!{1=&gt;2, 2=&gt;3}; let hm2 = c!{i =&gt; i + 1, for i in 1..2}; ``` maybe it's better to use `c!{}` instead of "c![]" when defining hashmap comprehension.
Yeah, I am open to the idea of having them both. Of course, the document needs to be updated. It is so simple now. :) 
Webrender may be the right library for UI, it may have the right internal architecture for that, but it was clearly built for the web and to be part of servo and not just a generic 2D library to build GUI on top. Look at its [documentation](https://doc.servo.org/webrender/index.html), most things are just not documented, no tutorials. This is in contrast to many other Rust libraries where authors usually consider it very important to have good documentation, examples, etc. Not a problem if webrender is only meant to be used in servo and gecko, but for more general usage this situation clearly needs to be improved. And then, as I said, it is tailored to the web needs, it has all those insane border styles which are not used in modern UIs but if I want to draw something simple, like a triangle with linear gradient defined by three points for my color picker then I'm out of luck as it only supports gradients defined by two points. And then of course I want to do all interpolation/blending correctly in linear color space which it likely does not support but is probably easy to fix. So, if we want a great library for GUIs, webrender may be the best thing to start from but it clearly needs some work in that direction.
Yes, I noticed they used the `{}` syntax in the cute documentation and found it much easier to parse at a glance. Is there a way to enforce that using the compiler? I honestly kind of feel like it should be a different macro. I would probably use `list!` and `map!` rather than just `c!` (which tells me nothing). I recognize that this has little to do with sugar and much more to do with the underlying libraries.
I've written a `specs` wrapper for my game that exposes an API like the one described in the ECS talk at rustconf: ``` let vels = world.lookup::&lt;Vels&gt;(); let mut poses = world.lookup::&lt;Pos&gt;(); let dt = world.resource::&lt;TimeDelta&gt;(); for (vel, pos) in (&amp;vels, &amp;mut poses).join() { vel.0 += pos.0 * dt.0; } ``` It means there's no automatic system parallelization (they all run serially), but you can throw a .par_iter() on any large iteration to quadruple its speed so it evens out :)
Reexport other crates in just one method for implement some macros in `sugar`. If we believe the new syntax is better, we can reimplement them in sugar. If you have more ideas, you can create issues in the github. Very open to discuss them. 
The panic macro is defined in std and you're using no\_std, so it's nowhere defined. Since you're using your own std you should define it there.
&gt; Also, because they share memory instead of sending messages over sockets, the communication is statically typed. Could it happen that the two processes (API and FTL) have a different opinion of the layout of the shared memory? I must admit I once worked on an application using shared memory, and the experience was incredibly frustrating. There is the obvious limitation of shared memory data being limited (no pointers, only offsets), the issue of coordinating the view of various processes (layouts must match), the issue of coordinating updates of the data (atomics/mutex), and on top of that for some reason our version of Linux (a while back) would fail to delete the named segment when the last process connected died, and then complained that it already existed when a new one sprang up. Personally, I tend to favor pipes/queues/requests/... or should I say explicit I/O, with serialization, these days. There may be some overhead, but it's more explicit and it's easier for a process to operate for a given period of time over a consistent snapshot of the data (then apply all further updates in batch at its convenience).
You’ve swapped the two ARM toolchain names, and your rustup command says `target` one too many times.
Getting back in the saddle. I'm going to be spending the next \~six months likely being self-directed, so maybe this is a good monday ritual? In any case, this week I'm going to finish up the next roadmap for xi, and then focus on adding basic language features, particularly auto-indent.
I'm no contributor so I can't say why they chose shared memory. I do agree it's a strange choice and as a newbie to Rust, it seems decided unRust on top of that. Maybe they are just so used to that since they've been doing other languages forever? Maybe someone from the rust community with more knowledge than I should weigh during the commentary period before it gets set in stone and publicly released. :)
I am making general scripting language in rust. Ground up and learning lot of stuff about languages and rust in general.
If you have something long running, that's not itself a future, you don't want to wrap it in a future. If you do, it'll block the thread it's running on, and it'll prevent other futures from making progress. The only way to call a long-running function without blocking your thread is to spawn a new thread for it to run on. The futures framework has ways to do that, but if your program isn't already using futures, it's probably simpler to just use threads from the standard library. You can use a Condvar to get the timeout behavior you need. That said, I don't know of any way to cancel the worker thread, if you decide it's been running too long. Proper cancellation support is something you get with futures, but it sounds like the function you're calling isn't returning a future.
in the line of “Don't communicate by sharing memory; share memory by communicating”.
Last week I released an internal tool written in rust at my job (query parser and linter that has been compiled to wasm). So far, my colleagues are very excited by it. Hopefully I'll have some time to add a few simple features. 
This basically boils down to the fact that Amethyst is still in a framework state: you use it without an editor, directly with code, and an ECS architecture. If you take a look at Unity for example, using their ECS without their editor is at least as complex. As mentioned in the article, we will have an official editor that will make all of this much nicer to use (especially as our paradigms are very UI-friendly, it will be very easy to have everything managed in a nice interface). There is also the barrier to entry of Rust, which makes it a bit hard for beginners with Rust, for obvious reasons. For those people, our scripting support initiative should help them take advantage of the unique features of Amethyst while using a language and paradigms they know already, and that are potentially simpler in concepts and syntax.
Exactly :)
How is `(0..10).filter(|x| x%2 == 0).map(|x| x*x)` verbose?
Oh man, idiotic. lol. thx.
I'm looking for a crate that provides simple windowing and pixel managing, I don't need more, what could I use ?
Thank you for that feedback! We really want to make the experience better for everyone so your remarks are very welcome. &gt; Common gamedev advice is to parallelize individual engine components instead of trying to run engine components in parallel, and there's a reason for that. This has only been true because writing parallel code is much harder anywhere than in an ECS paradigm, and especially when the ECS is used with Rust. Regarding your concerns on core overuse, this is actually a bit inaccurate. The dispatcher behind the scene relies on rayon, which handles parallelism with a threadpool. That means that there are as many threads as there are cores at any point in time, and jobs will just wait in the queue. If you have a parallel system running alongside other systems, the threadpool will handle scheduling the jobs so that only say 4 tasks run in parallel on your 4 cores machine, while keeping them all busy. (by the way, in some projects Blizzard are spawning dozens of OS threads while keeping professional-grade performances) Regarding documentation, as you might notice in our getting started guide, we never advice beginners to read through rustdocs. Rustdocs is an amazing tool, but it has some flaws, one of them being that it doesn't work really well with architecture-intensive crates such as Amethyst. Instead, we focus on guiding people towards reading the book, which gives them much more practical information on how to use the engine and features. As we state in that book, it is far from being complete (and we welcome anyone to help on that!), but that way we can be sure that the high level concepts are explained in an order that makes sense and only with the things that really matter. As you said, it's hard to have rustdocs separate implementation details from actual meaningful APIs, and so that's what the book is for. Rustdocs is meant for users that are now familiar with the engine after reading the book and want to get details and less frequently used features. Also, the best way to learn about stuff currently is to come and ask, because we are making so much new stuff that we unfortunately are having a hard time keeping the documentation up with the pace.
It's maybe a good thing that `NoneError` doesn't implement `Error` because otherwise if everyone just uses `?` to unwrap options, the errors you'd get would be almost useless. Main returning a boxed `NoneError` only tells you that someone somewhere had a `None` where they expected a `Some`. It's like those lovely "unwrap() on a `None` value" panics that are common (and equally useless) today. Just do `.ok_or_else(|| AppropriateErrorType::new(...))?` instead.
I am the developer of the Pi-hole API. A quick overview of the systems we have to work with: FTL is a C daemon which hosts a DNS server and generates stats about the queries it processes. In the currently released version of Pi-hole, there is a PHP and jQuery web interface which has a somewhat hacked-together API. Connecting these are some bash scripts which form the core of Pi-hole. FTL has lots of information stored in a few arrays, including client metadata, queries, upstream metadata, and time-dependent metadata (how many blocked queries made in a certain 10min time slot). These arrays and structs were fairly trivially converted to use shared memory. The problem that the API solves is talked about in the article, but the relevant piece for shared memory is making accessing the stats generated by FTL efficient and easy to work with. The version of the API in the master branch uses a socket to communicate with FTL, but this means that FTL needs to have its own internal API, which also does work that should be happening in the actual API. To add features such as pagination for queries, those features would have to be implemented in FTL instead of the API. The API would have to wait on FTL before being able to add features. To move FTL's API code to the API, and to make adding new API features easier, we found shared memory to be the best option. We make sure to handle the possible issues that can arise, including if they have different memory layouts. The shared memory library actually checks to make sure that the shared memory is a multiple of the struct we are trying to use (in the case of an array), we handle possible errors when accessing shared memory, and we lock shared memory so that FTL does not write when the API is reading (using a robust mutex, and when the API holds the lock it creates internal read locks). For the issue of having no pointers in shared memory, FTL's data already used IDs/array indices instead of pointers. The only issues were strings and one dynamically allocated array. Strings were solved by simply making a strings shared memory block (array of chars) and using a string ID/offset in the structs instead of a char pointer. The dynamic array was solved by making shared memory blocks for each client, to store the dynamic information of the client. If you read the code, it is very ergonomic and the data is easy to manipulate with iterators and other Rust patterns. With socket communication, it was not so nice and easy. If you have other questions or concerns about how it works, feel free to ask!
&gt; Depends on how you define overkill I like your view on this. Indeed it seems like I'm fooling myself with this 'optimisation'. w.r.t. the iterators, I see what you mean now, I'm going to fiddle around a bit more with that. Thanks for the example code!
Bootstrapping rust is not trivial. To be fair it is rarely trivial for any compiler but I have had my share of problems with rust in particular.
&gt; If you have something long running, that's not itself a future, you don't want to wrap it in a future. If you do, it'll block the thread it's running on, and it'll prevent other futures from making progress. I do understand that. What I was hoping for was some kind of function that would take a closure, run it asynchronously and return a future to the result of that closure. 
The ECS issues you listed (or well the complexities) are pretty much exactly my personal wish list for Specs. I would love to simplify it, but as soon as you read the source code you'll probably agreee that it's not that easy to simplify. If you have an idea though, please create an issue!
&gt; Rustdocs is an amazing tool, but it has some flaws, one of them being that it doesn't work really well with architecture-intensive crates such as Amethyst. Yeah, I've noticed this problem with e.g. Tokio as well. I find that putting architecture summaries in module-level documentation can help. (Or, write a book, which y'all are already doing :) &gt; That means that there are as many threads as there are cores at any point in time, and jobs will just wait in the queue. Right, but i don't get as much benefit from parallelizing my system if other systems are monopolizing the cores while it's running. I guess the system can expand to more cores if there aren't other systems scheduled, though.
Is there any support for file rotation/archiving yet?
panic does exist in core https://doc.rust-lang.org/core/macro.panic.html
Also a portability WG (which seems to entail both the libraries/ecosystem and Rust itself) was created earlier this year, but it seems to have a fairly limited reach (I hadn't even heard of it until I looked for it): https://github.com/rust-lang-nursery/portability-wg The embedded WG also seems to have suffered from the summer, and /u/japaric to have become way less active over the last 6 months or so.
Why does it work for other targets? What is special about this one?
From the gitlab: [Torrents.csv](https://gitlab.com/dessalines/torrents.csv) is a vetted, searchable repository of torrents, consisting of a single `torrents.csv` file. `Torrents.csv` will only store torrents with at least one seeder to keep the file small, and will be periodically purged of non-seeded torrents, and sorted by seeders descending. Its initially populated with a January 2017 backup of the pirate bay, and new torrents are periodically pulled from the top 20 pages of https://skytorrents.lol via a rust script. Other sites can be added as requested. It also comes with a simple [Torrents.csv webserver](https://torrents-csv.ml) [site image](https://i.imgur.com/qVmSVMC.png) To request more torrents, or add your own to the file, submit a pull request here. Made with [Rust](https://www.rust-lang.org), [ripgrep](https://github.com/BurntSushi/ripgrep), [Actix](https://actix.rs/), [Inferno](https://www.infernojs.org), [Typescript](https://www.typescriptlang.org/). 
Thanks for the detailed response! ---- &gt; A future check may be to version the shared memory layout to make sure that even if the memory size didn't change, we still detect a different memory layout. Having run into this before: a (cryptographic) hash of the files used to generate the memory layout, stored first, allows to reader to check at start-up that everything's alright. --- &gt; The API would have to wait on FTL before being able to add features. If I may, this is already the case, to some extent: your API cannot display data that the FTL doesn't provide. I think that the API having to wait on FTL could be an issue of *on demand querying*. Instead, another possibility would be for the API/FTL communication to move towards a subscription model: - on start-up, the API asks the FTL for a snapshot of the current state, - then, whenever the state changes, the FTL *pushes* the change to the API. This would mean that the API would maintain a copy of the state; I have no idea of the amount of data shared, so this may be a concern. On the other hand, this has one tremendous advantage: it's lock-free &amp; wait-free. This means that: - the API cannot block because the FTL is holding the writer lock for too long (big update), - the FTL cannot block because the API is holding the reader lock for too long (big query), - the two processes can actually run on different machines, which allows having the API providing number-crunching queries without disturbing the FTL. Oh, and before I forget; this hare-brained scheme of mine is also substantially more complicated. Don't let great be the enemy of good :P 
I've dug pretty deep into Specs' source, actually. I don't think the complexity is inherently a problem -- Specs is basically half a language runtime on its own, complexity is to expected! -- and I get how the pieces are all necessary. I guess my issue is just the way rustdoc shows all the components off. Maybe there should be a big flashing warning that says "read the book first" in the rustdoc? And/or architecture overviews in the module-level documentation. There is one simplification that I've found; I've written a wrapper for Specs I'm using in my game that gets rid of `System` entirely, and leaves operation scheduling up to the user. This lets me simplify the API a lot, because System / SystemData don't really exist. All my systems are just functions that run serially and take `&amp;mut World`. I haven't published the wrapper because it's not done, but also because it seems blasphemous to the spirit of Specs ;)
It's impossible to say without knowing what exact linker you're using.
No, it's not "blasphemous" 😅 Specs is intended to be unobrusive, so systems aren't necessary (I know a couple of people who use only the world without dispatcher).
I'd recommend giving `gfx-hal` a go. It should be perfectly usable for simple stuff, existing Vulkan documentation should mostly apply, and the community making it are really helpful. That said, an eventual goal is to hopefully be able to run Vulkano on top of `gfx-hal`, so I don't think you'll be bound too tightly to whichever choice you make.
: which ld /usr/bin/ld : ld -v @(#)PROGRAM:ld PROJECT:ld64-305 configured to support archs: armv6 armv7 armv7s arm64 i386 x86\_64 x86\_64h armv6m armv7k armv7m armv7em (tvOS)
Maybe I can just comment out that --as-needed switch, do you know where that is stored/configured?
How is developing with rust for android now? I remember asking one or two years back and being said rust is not good choice. Did it improve?
Creating tests for the derive macros in derive\_type\_level (I am writing all the tests in type\_level\_values ) .First by rewriting some tests for the \`TypeLevel\` derive macro because the uncommitted way I was testing it was too convoluted.
&gt; Right, but i don't get as much benefit from parallelizing my system if other systems are monopolizing the cores while it's running. I guess the system can expand to more cores if there aren't other systems scheduled, though. Why? If you're out of cores to run parallelized code on, there's nothing left you can do.
Just as an example of what is neat with something like exposing Rust types. Differential dataflow has some pretty non-trivial datastructures for managing its state. A log-structured merge .. trie, I think. The navigation of these things separates a cursor from the storage, and you can mutate a cursor holding only a reference to the storage. There is a bunch of logic in here about surfing around through these things, and it is about half the LOC in the project by volume. Because Abomonation exposes a `&amp;Storage` you can serialize the layers of the LSM to disk, memory map them back in, and use them as if they were references with the same logic. No "second copy of the 1-2kloc navigation logic", it just works (until it stops working, but .. *crosses fingers*). Anyhow, that is really cool, and very powerful from my point of view. :D
The `Chicken` example is totally valid. Yes the documentation will be the same but not for the `Declaration`. With the `cooked` feature enabled the `Chicken` will not be instantiable because of the private 'field", what do we show to the user and how ? Ok, so by default this addition to the documentation must be disabled ? Why not merging this with the current [`docs.rs`](https://docs.rs/about) "package.metadata.docs.rs" ?
Playing around with distributed hash tables, trying to make something [like IPFS but simpler](https://github.com/icefoxen/WorldDat). Also working on getting ggez devel working nicely on MacOS (the `gilrs` crate really needs help to get gamepads and joysticks working on that platform) and also iOS (there's some sticky issues with how `winit` handles events, but also the iOS backend just has been quite unloved).
Should be able to cap from the API side how many pending queries their are. Should also be able to cancel pending queries if they are taking too long and newer data has arrived. No idea as to the complexity such tracking and cancelling would incur however...
The `--as-needed` switch is part of rustc's target specification for all Linux targets: https://github.com/rust-lang/rust/blob/4f9b581f71810744069228f86242e6ba00b7d09c/src/librustc_target/spec/linux_base.rs#L24 For targeting x86_64 Android, I believe you should configure `i686-linux-android-gcc` or `i686-linux-android-clang` from the Android NDK as your linker.
Last week I published the oaidl crate (for safe conversion of to/from Rust data types for COM/OLE data structures). Been working on a rewrite that reduces the amount of generated code, and currently stuck on a way to handle the deeply nested structure of VARIANTs in a "safe" way without overwriting data. 
I don't think one is necessarily much better than the other, but they should both be pretty capable. The one bad thing about inheritance I know of is how it conflates data and behavior. "A inherits from B" means both "A contains all data B contains" and "A can do everything B can do". Furthermore, it means "Unless overridden, A's behavior doing everything B does is the same as B". For some things, this is obviously correct. For others, it can lead to accidental bugs. Rust separates data and behavior much more than other languages. Even at a syntax level, `struct X { ... }` declaring data and `impl X { ... }` declaring behavior are different top-level items. Composition, then, also keeps data and behavior separate. "X contains all data Y contains" is explicitly not the same as "X does everything Y does". In a way, composition is less convenient. If you have A containing an instance of B, you won't automatically get all of B's behavior on A. You have to manually create every method you want, and you have to manually forward each of those methods to call your inner B. With inheritance you automatically get every one of B's methods on A! But with less convenience, you get more control. You won't ever accidentally expose some behavior of B that you wanted to keep private, and you'll always think carefully about what aspects of B you really do want to expose from A.
Still poking away at my game project. More just in mode now of play testing it, and seeing where gaps are. If I'm happy with its feature set, i then need to update the tutorial, and build some start &amp; end screens. Otherwise I started a new project using actix-web. If anyone has any good resources for good practices with docker + rust for this kind of thing, let me know. Like if i should build a separate image to cache dependencies. What workflow I should have for re-compiling the source of my app as i make changes.
You are correct, I edited .cargo/config and made a new target based on the the i686 target. However now it croaks on another option. note: ld: unknown option: --sysroot=/Users/u1/NDK/x86/bin/../sysroot clang60: error: linker command failed with exit code 1 (use -v to see invocation)
That works fine.
Thank you for the detailed tips! I understand it can feel intimidating but based on your further comments I would think your thesis is beautiful aswell. Especially because you mention `tikz`. I think it's a great way of making a consistent looking document. I've been looking into several graph generators because a lot of illustrations I make are graphs. The only problem I've had with `tikz` is tha larger graphs end up not being confined within a A4 page. I think it might be because I use `graphviz` to convert a graph declaration into a `tikz` graph. 
New librsvg is broken on multiple archs in Debian: https://buildd.debian.org/status/package.php?p=librsvg&amp;suite=experimental Previous version was build able on ALL these archs. ALL. Painful regression.
I think that in this case, it's an issue of rustc really wanting some stuff to be dynamically linked, whereas alpine wants everything 100% statically linked.
&gt;&gt; emacs &gt; I implore you to simply stop shipping the -gtk variant. I doubt it is used so much and then you wouldn't have the librsvg dep. 
continuing work on assignment 2 of cs140e (https://web.stanford.edu/class/cs140e/assignments/2-fs/) I'm on the bin allocator subphase now (github.com/leshow/stanford-cs140e)
I read a blogpost (which i can't find right row) a long time ago about the pros and cons of composition vs inheritance which pretty much nailed the issue imo. The gist was: Basically, inheritance is "better" (read: needs less code) for components of a program that never or rarely changes. It's much easier to reuse those components and extend or override it's behavior. The code looks and feels cleaner because you don't repeat a lot of code. BUT inheritance leads to hard to refactor and more rigid code. Once you change the behavior of a base class you have to make sure it won't break anything in one of it's subclass (i can tell you from experience something will surely break). It can also lead to some really weird situations where you need a new parameter for some of the subclass, so you add it to the super class, but now all the other subclass has an unused parameter. Meanwhile composition leads to more code, but it's much more flexible. Every object handles only it's own data so it's much easier to change something without breaking any other part of the code. It's also much easier to read and understand the code because it's always linear. If/switch/match statements are easier to read than calling a virtual method and wondering what will happen. With complex inheritance, it can be a pain to figure what will happen if you call a virtual function from a base class. C++ has const methods which tells the compiler that the virtual function can't change the object, but other languages has no such safeguards (as far as i know). Meaning that if you call an overriden function from a base class, it can change the object's data that you are working on. It can lead to some really messy code.
What does "vetted" mean in this context? Does it assure that I don't get rick rolled?
I didn't manage to find enough info on C++ interop yet. Either that, or I didn't understand it. The easy question follows: what if I have an std::vector&lt;MyObject\*&gt; and I want a Rust dynamic library to do something with it. How do I approach that? How do I properly expose MyObject\* to Rust with all its functions and attributes? Preferably with as little overhead as possible. How would a vector of C++ made MyObjects\* look in Rust?
I've worked on another project using Actix, but the ease of making endpoints and managing state in Rocket is why we use it. We haven't run into any issues due to nightly (we pin to nightly versions and update if needed). Eventually Rocket will get out of nightly, but it's still in my opinion one of the best Rust web frameworks.
To be fair, badly architected composition can do the same, especially if the "composition" ends up being treated as "verbose inheritance where I manually forward everything" by the programmer. While there is less hard coupling even then, finding out who is really responsible for behavior and what methods do can be a right pain. It also becomes easy to miss things through the indirection and boilerplate.
&gt; for every commit loop over each word in the commit and for each word loop over the chars. Check out [the `aho-corasick` crate](https://github.com/BurntSushi/aho-corasick). It lets you search for any of a list of terms in a body of text in \*O(n)\* time. &gt; I wanted to try Rayon for this but I cannot figure out how to turn it into iter() and not a bunch of for loops. I would suggest trying to use Rayon to parallelize the processing of each commit rather than parallelizing the text searching within the commits. Switching to `aho-corasick` would eliminate some of inner loops, which might make this a bit easier to reason about.
I haven't seen specs yet, do you have some concrete place to look within the project?
Oh, you're right. I'm still getting used to the borrow checker. oconnor663's answer is much better.
This is exactly what I need thank you! Just one big bummer its outdated, how/when does it get updated? &gt;To work with the RS4 Experimental API, your first step is to make sure that your computer is on Windows 10 with the April 2018 update (builds 1803). &gt; &gt;Otherwise, to work with the official RS5 DXR API, please update to the latest public release of Windows, the October 2018 update (builds 1809) 
Looks neat, where did you get your words.txt file?
Isn't there a Rust compiler with a C backend floating around somewhere? Or am I misremembering?
I didn't know about the Vulkano &amp; gfx-hal integration. That's pretty awesome. I think I'll try out both and then decide. I'll try to generate some local gfx-hal docs, that will probably help a lot. Thank you for your advice
The following example is taken from the `README.md`, and there is a [chapter in the book](https://slide-rs.github.io/specs/05_storages.html) that explains storages. #[derive(Debug)] struct Pos(f32); impl Component for Pos { type Storage = VecStorage&lt;Self&gt;; } 
[mrustc](https://github.com/thepowersgang/mrustc), a Rust -&gt; C compiler in C++. It only supports x86 though, and only x86-64 Linux fully.
This discussion comes up like once a week. It's allowed because crates.io follows the RubyGems approach of not namespacing packages, and not enforcing a soft-limit on the number of crates a single user can register. This problem is completely solvable, but my understanding of the current view of the maintainers is that they simply don't care about squatters at all.
# Changed baked in with inheritance are harder to unbake and specialize for than when using composition
There is quite a discussion of this on the internals forum here: [https://internals.rust-lang.org/t/crates-io-squatting/8031/143](https://internals.rust-lang.org/t/crates-io-squatting/8031/143). &amp;#x200B; I think it is something a lot of people are wanting to address, but, there is a lot of debate about how and what would be best for the community.
&gt;I pop a little question regarding OOP in my OOAD class in uni. My professor said that inheritance main purpose is to save memory upon object creation since changing one thing on parent object would chain down to the childs. Many do not fully understand the benefit of inheritance. Most engineers do not figure it out. It's sadly a senior subject. Because of this confusion inheritance is discouraged. It's also discouraged because it uses a virtual table at run time which takes up the heap and isn't the fastest solution, and you have to pull up multiple different pages of code to read and understand a class that uses inheritance. Metaphorically reading multiple pages of code is like page file / virtual memory. If page file can be avoided, reading code is easier and quicker because there is only one page of code to read. Inheritance is good for creating types of classes. Just as a double is a type, sometimes there is a need to make specific types like an inches type and a centimeters types. More common it is helpful in financial programming where big number types or fixed precision decimal types are necessary, because double and float types have inaccuracy. Taking the same concept of creating a type, you can make subtypes / abstract types / types of classes. These are often used by frameworks, as the framework calls the class you write, you don't call the framework. For the framework to call someone else's code it has to be standardized. A framework will then create a few types of classes that do different things. If you write a class and inherit that type, the framework has a standardized way to work with it. It's good to create types when reasonable. If you've got 100 different classes, what kinds are there? There are utility classes. There are algorithm classes. There are patchwork classes that convert one format of code into another. There are logging classes. There are framework classes. There are specifics like networking classes, thread handling classes, configuration classes, and so on. Even if there is no inheritance involved, the second a project gets large it is necessary to abstract different classes into different mental abstract types. By categorizing code, even unconsciously, it becomes much easier to navigate through a code base, read code, and understand the underlining thought process behind it. &gt;Back to the question; if you were on my position, how do you explain what makes composition better than inheritance? Composition goes on the stack, so it can be faster. Composition is easier to read, mainly due to needing to read less files to understand a thing. Inheritance is a complicated subject that most misunderstand making composition a better choice. When you can do inheritance or composition, consider defaulting to composition unless it is 1) contract programming (where the inheritance is a pure abstract type) or 2) You've got an class type that is going to appear in multiple files, usually a minimum of three, before resorting to inheritance, and even then it often isn't a good idea.
Seems to me like the longer they wait, the more likely it is that the solution will have to involve drastic measures like revocation.
https://boats.gitlab.io/blog/post/2017-10-28-alternative-registries/
[https://doc.rust-lang.org/cargo/reference/source-replacement.html](https://doc.rust-lang.org/cargo/reference/source-replacement.html)
That adds new problems of its own, which is why so many languages don't support it. (eg. the [diamond problem](https://en.wikipedia.org/wiki/Multiple_inheritance#The_diamond_problem))
One particular issue with inheritance, especially in a large project which can have a chain of inheritance 8 or 10 classes long (not an exaggeration, that is what my day job is on, maintaining a legacy product with stuff like this.) Lets say I have a chain of classes that each implement an additional piece of functionality and relying on the parent class implementations for everything else, and we'll label them: A, B, C, D, E, F, G, H, I, J. Nice and clean and simple. But what if I add a new class K, inheriting from G? And I need to not just add a new piece of functionality, but override something G does within K? Not too bad. Still kind of clean, eh? But what if something inherits from K, say L, and we start getting this nested chain of calls and overrides between the three classes. And if I change anything in G to fix an issue in K and L, I'm potentially breaking H, I, ***and*** J! This illustrates a problem with inheritance called "fragile inheritance". It's where your later classes rely so strongly on specific functionality that you can't change that without breaking them. This ossifies code and prevents it from being easily refactored or rewritten, creating tech debt within the code base. The primary principle of software engineering is enabling the *ongoing* maintenance, expansion, and use of a piece of software. Software should be designed to allow for future work with relatively minimal costs in most cases. You can't eliminate costly future work in all cases, because requirements change, and sometimes unpredictably, so the product needs to change, sometimes in unpredictable ways. 
I googled around for way too long and found [this](https://github.com/RobertJGabriel/Google-profanity-words) repo with a long list of words. It was the most comprehensive list I found so that’s the one I ended up using. 
&gt; a simple C89 compiler is probably a weekend project. Please. You are misrepresenting the effort it takes to write a C compiler and/or forgetting how big C89 actually is. Yes, if you dismiss entire portions of the standard, disregard all error handling and focus on compiling a ***very*** simple subset of "C" (something like what the original TCC compiled: `int` variables only, a few operators, functions without types, `if`/`for`, and a few other bits); then you can "get it" in a weekend. But that gets you *nowhere close* to an actual C89 compiler. Yes, the easy parts of C that we all remember are easy; but from "C-like language" to "actual C89/C99/C11" there is a mountain of complexity. The proof is simply comparing the original TCC (less than 1000 lines) with the current one (more than 23000 lines). Or checking how long it took Torvalds to get `sparse` right.
Sweet, /u/BurntSushi really has a crate for everything. That looks exactly like what I want, I looked at maybe using regex for matching, but then I’d have two problems. I’m guessing this would eliminate the need to check for compound (swear) words as well? And I’ll try to parallelize the commit loop. 
Thanks! Looks awesome
The way you are building commands from user input seems potentially prone to command injection style vulnerabilities although I didn't look too deeply into it.
The ECS talk was great, thanks. It was a small hobby project so I was thinking about avoiding a database but I should give that a go. How does an ORM over a database match with Rusts ideas of borrowing and ownership, though? I guess I should read up on diesel...
Everyone: https://internals.rust-lang.org/t/crates-io-incident-2018-10-15/8568 Thanks.
How is this repo not just going to be DMCAed?
&gt; However, asking to define &gt; row and col &gt; in the trait, but then only provide one or the other depending on the struct implementing it, is fundamentally antithetical to what traits are. No, i need both implemented. Not matter what is the storage of a relation, it have columns and rows. The problem is how provide a view into that storage for both directions. 
&gt; Is porting a new programming language to a new architecture notoriously difficult Depends. Speaking more about "OS/arch combo when OS and arch are supported but not the combo" porting: I've done porting for FreeBSD/aarch64 for some languages (and looked at others' work in the same direction too), the difficulty was all over the place. - Pony: just worked (well, not a self-hosted language that doesn't do any unusual stuff) - Crystal: [one symlink](https://github.com/crystal-lang/crystal/pull/6373) plus cross-compiling a bootstrap compiler (amazingly, the compiler writes the linker invocation command for you!) - OCaml: [pretty easy](https://github.com/ocaml/ocaml/pull/1904) (having a bytecode interpreter is a great way to sidestep the self-hosting problem) - Mono: [not bad either](https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=229710) - LDC D: [C++ bootstrap ported easily, self-hosted ldc encounters weird ELF (?) related bugs but can be hacked to do something](https://github.com/ldc-developers/druntime/pull/146) - GHC Haskell: wasn't me who ported it, but they [didn't seem to encounter any hard problems](https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=196899) - Go: [hard](https://github.com/golang/go/issues/24715). I'll try to be polite, but… it's awful. The "main" Go implementation prefers calling syscalls directly (no libc), and this is written in [Go assembly](https://golang.org/doc/asm). Yes, that assembler that infamously spawned hacks like [c2goasm](https://github.com/minio/c2goasm)/[asm2plan9s](https://github.com/minio/asm2plan9s). Just… carefully read that project's readme to the end. And tell me with a straight face that letting people with a Plan 9 kink design an assembler is a good idea. - Rust: it's been ported (I have a 1.22 package) and it [broke in a weird way](https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=228892) :(
[mrustc](https://github.com/thepowersgang/mrustc) should help with the self-hosting (bootstrap problem). I wish it was more… official?
This should work for returning a column as a slice: fn col_slice(&amp;self, pos:usize) -&gt; &amp;[Scalar] { let start = pos * self.rows; let end = start + self.rows; &amp;self.ds[start..end] } [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=44698847507d835b6e65afe69102ae0c) However, a slice *must* be contiguous in memory, so you cannot return a row as a slice.
It's not that inheritance is *bad* per se, it's that it is a very *specific* and *specialized* abstraction. Inheritance augments the usual sort of data-type abstraction with a "tying the knot" trick, that allows you to have the *implementation* of an abstract datatype dispatch through the very same abstract interface you're defining for it, and access behaviors that it need not even be directly "aware" of (because they're actually defined in a "derived" class, and accessed through this dispatch step). *This* is why you should avoid inheritance in the typical case, and stick to composition. It's a YAGNI thing.
If you have any questions you can post them here or send me a PM.
WebRender is indeed not intended to be a nice user-facing API for building UIs. I think it can do a good job at doing the work of rendering complex UIs but an API specific to whatever it will be used for needs to be built on top of it for sure. Beyond that the graphics team indeed doesn't plan to make a living by making WebRender a product, nor have we done it for Gecko historically, but Gecko powers the Tor browser and SpiderMonkey is Gnome's JS engine for example. I'd be very happy to see people try (and succeed!) at building a modern UI rendering system from scratch. If anything WebRender's there to learn from (also possible to use, modify, contribute to and push to new places ;) ).
Oh, I miss the &amp; in self. Thanks!
I was recently thinking about writing an RFC about adding variadic generics (similar to [https://github.com/rust-lang/rfcs/issues/376](https://github.com/rust-lang/rfcs/issues/376)) to Rust. I have never filed an RFC, therefore I have a bunch of questions about it.. Is there a guide for writing RFCs? Is the missing RFC really the reason which blocks variadic generics or is there a good reason nobody writes an RFC for it? How high are the chances that such an RFC would be accepted?
Other than the comments from other people, is there a reason you're not just using `u64` instead of `usize`?
Because I have to use them to index into potentially very large `Vec&lt;u8&gt;`s. That's the only reason. If there's an easy way to do that with u64 directly, that would obviously be the solution, but my research didn't turn up any way of doing that. Thus, I decided to kludge in a "don't build on 32 bit" solution for now and find a fix later.
Please consider actual revocation for such bad-faith behavior...
The official policy is "it's totally allowed until we arbitrarily decide it's not". But this isn't about the squatting anyway. It's about the username implying these are squatted by the crates team. That kind of social engineering is unacceptable! 
If gitlab actually removes it, ill host it on a gitea instance overseas, or through a mailing list. So far tho gitlab has been really good with leaving stuff like this alone. 
That, in combination with other things you've wrote, has me hopelessly confused. Why don't you lay out some mock example code for an interface which you *would* be satisfied by and how it would be used, if the language allowed it.
The RFC repo README has advice. You should also look for the previous RFCs that were filed on this topic.
I'm as tired of the weekly squatting threads as y'all are. Please take remaining discussion to [the forums](https://internals.rust-lang.org/t/crates-io-squatting/8031) so that the people on the infra/cargo teams might actually see it.
But Rust is rock-solid on x86_64, arm64 and ppc64. Heck, we (Debian) even got it polished enough for sparc64. Am I missing something?
That’s why the new librsvg is going to be stuck in experimental for a while. Rust will hopefully work on m68k (I have a partial port ready, but the LLVM backend is not done yet), powerpcspe and x32. 32-bit MIPS is failing because of the virtual address space limited to 2 GiB on this target.
Yeah, but it should be feasible to get it working on other targets.
Is this intended to replace PhatomData?
On a bool? Not much. Just the data race case of committing the response to a `true` value while the value is `false` (read true, long task, write false, true task finishes). Imagine iterating over a vector though Read: "1,2,3" // [1,2,3,4,5] Write happens: [5,4,3,2,1] Read finishes with [1,2,3,2,1] 
If you found that you can use aho corasick then that would probably be ideal, but if you want more flexibility (like case insensitive matching) then a regex would be perfectly fine. The old "now you have two problems" love is a cautionary tale; not a commandment to always avoid regexes. :)
No, `PhantomData` is completely unrelated to this.
2 orthogonal concerns contexts - premature coupling (rusts *traits* are better at decoupling) and hazards of library updates causing field clashes - can be more efficient to break things into components (as i'm sure many replies have already explained), if you're inheriting a component you're moving behaviour into another 'place' in data, code, traversals. see 'data-oriented design'. it's sometimes better to group all the data thats handled in the same way together (i+d cache coherency). of course there are exceptions to every rule. Whilst I rant alot here about other language frustrations, I do appreciate Rust's streamlining. By having generics + traits they manage to get composable interfaces (you can still layer them) - and type-checked generics, with fewer total features. inheritance of vtables is sort of used to implement interfaces elsewhere (c++), i.e. you have an 'abstract superclass' with pure-virtuals, then you 'inherit' from it to implement the interface (and those interfaces can in turn be layered). you can do the same thing in a more 'compositional' way in Rust by making generic implementations of layered interfaces, and it's more versatile without the awkwardness of multiple-inheritance.
All of the pros you've cited are basically pros of polymorphism, not inheritance. There is no type system advantage to inheritance as far as I can tell, only advantages in avoiding the programming overhead of performing delegation.
Inheritance doesn't really have a lot to do with object memory usage as far as I understand it. Does anyone know what that's about?
Compilers assume that any reads that are not explicitly marked as being possibly modified by other threads/programs (volatile, atomic) are only affected by local writes. So it's totally allowed to "optimize" `while self.locked == true || other_condition` as `let value = self.locked; while value == true || other_condition`, and then optimize that to `if self.locked { while other_condition {} }`.
&gt; inheritance main purpose is to save memory upon object creation since changing one thing on parent object would chain down to the childs. That's gibberish. Inheritance has nothing to do with memory saving. And the sentence doesn't make sense anyway. It's all about code reusage and dynamic polymorphysm. 
I am using Diesel trying to connect to a local PostgreSQL database. No matter what commands I try to run, it always say Unable to open the database file. &amp;#x200B; \`\`\` DATABASE\_URL = postgres://localhost:5432/todo\_rust \`\`\` \`\`\`  todo   master ●  diesel database setup --database-url postgres://localhost:5432/todo\_rust Creating database: postgres://localhost:5432/todo\_rust Unable to open the database file &amp;#x200B; todo   master ●  diesel database reset --database-url postgres://localhost:5432/todo\_rust Creating database: postgres://localhost:5432/todo\_rust Unable to open the database file \`\`\` &amp;#x200B; I tried to connect to the database using CLI &amp;#x200B; \`\`\` psql todo\_rust \`\`\` And it works fine. &amp;#x200B; &amp;#x200B;
single binary docker deploys are even nicer. throw that baby in an alpine Linux container and you're really cooking with fire.
Thanks so much
Nick Cameron once said on twitter ["Using Deref for polymorphism is a hideous anti-pattern in Rust."](https://twitter.com/nick_r_cameron/status/580106932297465856), and later [elaborated what he meant in the Rust design patterns repository](https://github.com/rust-unofficial/patterns/blob/master/anti_patterns/deref.md). My impression is this is a strong consensus on the Rust community; what do you think?
Do you also object when people follow responsible disclosure and publicise vulnerabilities in hardware or software when the developer sticks their head in the hand about it? It seems to me that this is the same thing on a different level.
It sounds like this wasn't "responsible disclosure" though. They make it sound like possible DoS since there was an automated script registering so many crate names. I'm guessing the problem is well understood but there's debate over whether any action needs taken place. I'm not sure where to find more details about the status. I hate digging through GitHub comments.
I use a enum containing variants and impl From for every error, NonError could be implemented, but it doesn't seem like a good idea. It's always better to .ok_or(Error::ActualExplanation)?
The way I see it, the Rust (internals?) team doesn't have the manpower to enforce a concrete policy, and even defining a policy is huge beast. It makes sense that they don't want an official policy. And I very much doubt they'd want to introduce moderators with no real stake in Rust to enforce such policies. Handling issues like this on a case-by-case basis given enough outcry/reports seems like the best solution. That said, if so many people __really__ want namespaces, then they can build their own crates-like platform. It is technically possible.
Why would ? on Options be useful?
I'd recommend starting out plain and simple: `serde`, `serde-derive` and `toml`. The former two libraries are generic and usable with almost every serialization format, so you'll want to get to know them anyways. Here's an example usage of these crates to load your "servers" array. `serde-derive` makes it all very simple! extern crate serde; #[macro_use] extern crate serde_derive; extern crate toml; use std::{ collections::HashMap, net::IpAddr, }; #[derive(Serialize, Deserialize)] struct Configuration { servers: HashMap&lt;String, ServerConfiguration&gt;, } #[derive(Serialize, Deserialize)] struct ServerConfiguration { ip: IpAddr, dc: String, } fn main() -&gt; Result&lt;(), Box&lt;::std::error::Error&gt;&gt; { let config_str = r#" [servers.alpha] ip = "10.0.0.1" dc = "eqdc10" [servers.beta] ip = "10.0.0.2" dc = "eqdc10" "#; let config: Configuration = toml::from_str(config_str)?; for (section_name, server) in &amp;config.servers { println!("{}: {} and {}", section_name, server.ip, server.dc); } Ok(()) } Playground link: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=c5b92c06f2a68385d5d8cd8e63eb151e
I don't think the issue is memory size but excess pointer dereferencing. 
&gt; and sorted by seeders descending. This seems to just create noise in the commits without adding any new information. Can't the data be sorted by the application that uses it?
Subtype polymorphism not implemented through inheritance and duck typing, at least. Ad hoc polymorphism if you've got open modules.
Is there any codebase that does this though? Perhaps this should be taught as an async design pattern in Tokio or futures-rs docs.
There have been several bots that have done mass name squatting over the years. This one is just named "cratesio" which is impersonation, which is why the team actually cares. 
Wonder if having a Rust compiler written in an interpreted language would be an effective strategy to improve this.
To my understanding, that's always been the motivating factor. I think most people want namespaces because it's the easy solution and the "backend" (github) already supports it. I'd love a policy and a curation team, but I understand how impossible that challenge is. So I support namespaces as feasible alternative. My real preference is to have a discussion about the issue that involves the crates team that is a little more than a "What if..." "No. Go away" kind of discussion. 
In some languages, classes are themselves objects, that exist at runtime. In psuedo-Rust terms: struct SuperClass { list: [i32; 100], } With inheritance, one instance of this superclass may exist for every sub-class, and so you have one single list of 100 integers. But, with composition, this list of 100 integers is inside of every single instance of the sub-class. So it would use a lot more memory. That's the only possible thing I can think of.
&gt; There is no type system advantage to inheritance as far as I can tell, It can also be a disadvantage; in my understanding, type inference in the presence of sub-typing is undecidable. Or is it that, in theory it's fine, but in practice it gets untenable. Something like that. 
&gt; The only way for this to be a compile-time error is to wait for const-generics Just to be pedantic.. trait resolution is Turing complete and you can encode arbitrary computation in trait bounds, using logic programming (like Prolog). See this: [Rust's Type System Is Turing-Complete: Type-Level Programming in Rust](https://news.ycombinator.com/item?id=13843288). What I'm unaware of is a type-level feature that emits a custom compile-time error message, like Purescript's [custom type errors](https://github.com/purescript/documentation/blob/master/guides/Custom-Type-Errors.md). But to emit __some__ type error, just evaluate a non-terminating bound and let the compiler give up after exceeding the recursion limit. (... but yes, this is grotesque)
Sorry, I didn't understand, my code, or the crate code?
https://www.cmi.ac.in/~madhavan/courses/pl2009/lecturenotes/lecture-notes/node28.html Huh and here I thought I made up the terminology to describe the concept.
I certainly have questions, but I’m not sure what to ask exactly. Obviously I get stuff like documentation and binary size, but don’t know much about debugging, etc. Two things I could ask, I suppose, is if there are other points that you feel are selling points for Rust on its own merits. And what you mean specifivally by abstract/real world — there are a lot of ways one could mean that. 
I was thinking about your code 
I agree wholeheartedly. I'd love something as dead simple as `impl B for A with self.my_member`. It would keep everything nice and explicit, and it would allow _partial_ mappings instead of taking everything at once.
My understanding was the the Trait system and the trait bounds were a form of subtype polymorphism. Maybe I'm misunderstanding that? Or maybe decidability isn't a practical problem most times?
They are not. The only subtyping in rust is lifetime subtyping with ‘a: ‘b.
Could macros be used to accomplish this? If the manual writing of delegation is the problem, it seems like a sufficiently smart macro could just pull methods from the "super class" (potentially with an option to only pull in certain ones).
I've removed the other thread from the front page to reduce the spam; you can find it [here](https://www.reddit.com/r/rust/comments/9ogql8/name_squatting_on_cratesio_is_getting_ridiculous/) for posterity. I've locked this thread for the same reason as that one. We've hosted enough fruitless circular debates on this topic to last us for a good while. Endlessly re-litigating policies over which we have little control is tiresome; to all out there, please avoid submitting squatting-related topics in the future unless there is some actual new development worth highlighting.
Contributing to a [Mattermost API Connector](https://gitlab.com/pop-planet/maco) library currently, which will be used for a [native GTK Mattermost client](https://gitlab.com/pop-planet/silva), because people out there thought that web technology is enough for chat.
Oh, I see, I misunderstood when looking through the article on nominative sub typing and thought it was referring to type constraints as type substitution.
Wrote a tutorial on “Building command-line todo app in Rust” https://medium.com/@devashishdxt/building-a-command-line-todo-app-in-rust-a89bb7af91c3?source=linkShare-65eac5d4f15c-1539662466 I’ll be extending same project to create a full fledged command line task manager. 
It’s undecidable, you’re right. That’s why the Swift compiler is so awful at inferring types. 
It could but that’s significantly more sophisticated than some languages I’ve worked with in the past. (And yes, that’s immutable/persistent data structures) 
i am not very experimented but i'd do the simple thing. hashmap managed by a thread and queues to communicate ( [https://doc.rust-lang.org/std/sync/mpsc/](https://doc.rust-lang.org/std/sync/mpsc/) ) actix-web seems to be an actor based framework so i would put the hassmap in an actor and use the communication facilities provided by the framework.
Looking at the backtrace in that FreeBSD ticket, it looks like LLVM and/or jemalloc could be involved. This is definitely something adding to the complexity of Rust; it's depending on two other reasonably heavyweight projects as well. I wonder if it is possible to bootstrap the Rust compiler without jemalloc, to at least eliminate some of that complexity.
Seeders descending is the preferred user sort, so to do quick greps it makes sense to default to that. Also what do you mean application that uses it?
You have a `if !self.curses.contains_key(curse)` branch, but you can use the entry API to handle both branches more cleanly there. See the `or_insert` method.
&gt; virtual address space limited to 2 GiB Why is this still a thing? I thought it was fixed when compiler got split into smaller crates.
Oh, but jemalloc is the system malloc on FreeBSD, isn't it? Does Rust just use the system malloc on FreeBSD, or does it use its own copy of jemalloc?
&gt; If you aren't going to go full-on futures, you need to find some other way to cancel/timeout your operation. Threading can get your function to return early, but your operation would continue going until complete. Interesting, I've always thought that you can kill a thread so that it aborts whatever it is doing. &gt; To get true cancellation, you have to use some timeout on the underlying operation that's blocking. If you're doing a long running calculation, that means periodically checking the time and returning. Unfortunately, that's the library's code, so I can't change that. 
What is an Impl day? What is an Impl period? How is that related to or different from Impl trait?
The [delegate crate](https://crates.io/crates/delegate) is a nice attempt to solve the problem 
It’s inherent to how the future model works, since it’s poll based and not push based. You don’t need to do anything special for this to be true.
If you can afford the GC runtime and performance variance of Haskell, it'll get you a fine language to program in. If you want more performance or control, Rust gets you almost-FP niceties, great tooling, a very helpful compiler, an awesome community and more.
Ah, darn. To be sure there are ways to forcefully terminate threads, but the rust standard library does not expose any way to use those methods. Might have to do with how easy it is to leave things in a dangling state / leave shared locked memory locked permanently? There could also be other issues I don't know about with doing this. There's an unsafe `libc` function to kill a thread at https://docs.rs/libc/0.2.43/libc/fn.pthread_kill.html (with [as_pthread_t](https://doc.rust-lang.org/std/os/unix/thread/trait.JoinHandleExt.html#tymethod.as_pthread_t) to get handle) to do this on Unix systems, but I don't know of any cross-platform wrapper or safe wrapper interfaces.
After months away, I used a "pendulum swing" via haskell to get me back into Rust (the idea being time in that is most opposite to my C++ comfort zone). Now busy working on a.n.other engine (and yes I know rust has more engines than games already). Now I actually have some momentum going and I can finally focus on adding features rather than 'seeing if I can get used to rust'. (although it's a bit horrifying comparing where I am at Rust Year 5 vs C year 1 .. but to be fair I used C solidly fully time rather than dipping in, getting frustrated and quitting, and there was a motivational end point writing engines before they were saturated) Mostly spent a load of time working on elisp hacks to improve my editing experience (faking parameter assist, sorting greps using guesses of nearby types as a workaround to not having 'dot-autocomplete' .. I'm told I should try the RLS but it didn't help with what I needed last time I tried). This was actually strangely satisfying aswell (r.e. "writing more code outside of my C++ comfort zone"), and it's given me an itch to look for a embedded scripting LISP in Rust.
On top of what other people have said, both compilers and hardware are allowed to reorder your reads and writes, if it looks like that won't change their meaning within a single thread. Your lock function could get inlined, and then that read might move way up before some other operations that it's not supposed to precede. In this case it's strictly redundant, so maybe no one cares, but that's the general danger.
I ran into this while programming a little Webservice with actix. I wanted to immediately return a response and offload some work in the "background" with a future but forgot to "drive" the future somewhere and accidently dropped and thus "cancelled" it. I got a nice warning though but I don't know if it was from the future lib directly or some magic from actix.
[I'll do the usual thing and refer to Oleg](http://okmij.org/ftp/Computation/Subtyping/). The tl;dr of all that is "Whether a program obeys the Liskov Substitution Principle or not is undecidable in general". That is: You'll have to do quite some nasty proofs to make sure that your abstractions don't leak.
I see, thanks a lot! 
23000 LOC is still pretty simple, given that current TCC supports many architectures, C99, etc. For my weekend projects I put an upper bound on 5kLOC, and most end up at 1-3kLOC. You can pretty much touch every aspect of compiler design in two weekends trying to implement C (parsing, lexing, optimizations, machine code generation, etc.). 
You might want to look into the crates ndarray and nalgebra. They both support efficient storage of 2d-arrays.
If you want people to try it out, you should give instructions in your README.
I'd disagree that the selling point is FP related over C++. For me the selling point is fearless concurrency. 
&gt; But Rust is rock-solid on [...] ppc64. There are so many ppc64 bugs open that I wonder how do anything works at all for those running rust apps on ppc64. 
Unfortunately most windowing crates also have other abstractions like input events and higher level graphics APIs- I don't know of any which provide _only_ windowing and pixels. If you want low level for the sake of being low level, you can use [`glutin`](https://github.com/tomaka/glutin) with [raw openGL calls](https://github.com/brendanzab/gl-rs) but I really wouldn't recommend it. [`glutin`] with [`glium`] is a bit closer, but that's still calling into OpenGL, and it sounds like you want something higher level than that? The simplest to use I've used is [`piston_window`](https://github.com/PistonDevelopers/piston_window#piston_window---) with `piston2d_graphics`. You can just ask it for a window, and draw on the window. It comes with a whole event framework, and a bunch of other stuff, but you can ignore the other stuff if you want to. I've also heard good things about the usability of [ggez](https://github.com/ggez/ggez), though that's an even bigger framework than piston. I wish I had a "simple pixel management" crate for you, but unfortunately I don't know of any that anyone has built. It seems most people are focused on higher performance higher level crates than on building simple pixel-only APIs?
&gt; Does Rust just use the system malloc on FreeBSD, or does it use its own copy of jemalloc I think it uses its own copy of jemalloc, unless you specifically tell it otherwise.
Is `librsvg` tested on all these archs ? If not, then IMO that's the real problem here.
Speaking of Emacs &amp; Rust.. I've also been working on an engine-y game and decided to use a lisp dialect for config/resource loading and decided I wanted to be able to reload the lisp on the fly. Turns out writing a small local server that listens to emacs sending text (sexps in this case) is super easy! (~40 LOC for both the elisp &amp; rust side) So now I can just C-x C-a to comfortably execute lisp in my game from emacs :-) 
&gt; The point of writing your own C compiler isn't to have a tool to compile 100% standard compliant C to every architecture in existence, but to learn how compilers work. Sure, but you explicitly said C89 in 1 weekend, then another weekend for C99, etc. That is the problem. There is a difference between a "C" compiler and a C89/C99/... compiler. A beginner wouldn't even be done reading (and understanding) the C89 standard in several weekends. &gt; And FWIW, current TCC supports many architectures, C99, etc. and 23 kLOC is still pretty much tiny for that amount of functionality. I only counted the i386 codegen, and only the core compiler `.c` files, not even headers (trying to be as fair as possible :-). If you count the other few targets, with the `.h` files, you get 43k lines. If you include all the rest of `.c`/`.h` files (e.g. tests, examples, win32 support...) you get to 93k lines. Yeah... Almost 2 orders of magnitude between a "C" compiler and a C99 compiler. :) In any case, the point isn't the *length* of the code. The point is that those 23k lines do not get written in a handful of weekends; and specially not by a beginner (since this is, supposedly, an exercise to learn). Note that I agree with what you *intended* to say: writing a simple "C" compiler is fun and very rewarding. However, telling people that they could write a simple C89 compiler in a weekend and a C99 in two will only bring bad feelings. Beginners won't make it and will feel bad; and actual compiler writers (OSS ones specially) will feel you are not valuing their hard work throughout the years.
This is a case where you always have to update the same structure for every request and client requests are not tied to specific workers. As such I think sharing by communication doesn't really buy you much or you'd need to use a different pipeline model. But Mutexes are fairly fast especially with small critical sections. Only on microbenchmarks I'd expect significant contention, in real life most cores will be waiting or working on actual content processing. So I'd go with a simple mutex model and refactor if it becomes a bottleneck (the logic should be pretty well isolated).
Interesting! I have also been looking into dhts lately. Don't have a working prototype yet, but would be very interested in collaborating. In particular, I need a dht with mutable data, but also want to be able to tweak things like the validation of which values are to be accepted by nodes and how long they should stay alive. Maidsafes DHT goes a long way, but am not sure if its a good enough fit for me.
All web development is multithreaded in rust. So there cant be a non atomic shared resource in play. Your only option is Arc&lt;Mutex&gt;. Be careful if you ever share more than one mutex between threads you risk a deadlock. I dont believe there will be a performance difference between an integer hashed hashmap and a vector. Unless you loop over the container frequently. Then hashmap will cause lots of cache misses and be slow. Same can be said for the vector if it is sparsely populated. 
The main intent of mrustc (I believe) is the "trusting trust" attack. It supports even less architectures than the official rustc compiler.
Yeah, that’s probably a good idea. For right now: the only positional argument is a file name to read (or `-` for standard in, which is the default). The `-o` flag takes a single argument that’s a file name to write (or `-` for standard out, which is the default). Other flags can be seen with `--help`.
How would it work with queues? because each thread doesn't only need to send messages, but also to receive answers about the message they just sent. Would the hasmap thread need to have a que
it depends on your concurrency model. you can have one backfeeding channel by thread and give it as parameter in your query. you could make everything use synchronous bounded channels and it would be quite fast. i don't know if it would work for your case though.
There are lots of words there that might be banned in kid-friendly chatrooms, but don't necessarily indicate anger. The list includes `sex`, which is not only in git comments that I made today, but also it's in our source code and it's a database column.
&gt; Sure, but you explicitly said C89 in 1 weekend, then another weekend for C99, etc. That is the problem. Actually, I think the problem is that you prefer to argue about being technically correct on the internet instead of understanding what others are trying to say. Currently, a 100% standard conforming implementation of any of the C standards does not exist. So by "C89 in 1 weekend" I could not have meant that. 
You don't neef fancy stuff to enforce that returned type has type parameter that is next number to the inputs. fn foo&lt;N: Unsigned&gt;(_: T&lt;N&gt;) -&gt; T&lt;Add1&lt;N&gt;&gt; {...} 
Yeah, I haven't filtered the list but there are a bunch of words in there that shouldn't be included, like xxx. I get a whole lot of false positives for it but doubt all the developers working on Emacs use it to talk about porn. 
This is the best explanation of inheritance vs composition I've ever seen.
The common public CI environments only run Linux (and sometimes macOS/Windows). You can cross-compile (I wrote [a docker image that supports pkg installation even](https://github.com/myfreeweb/docker-freebsd-cross)) but you can't run the binaries. (Except with qemu :D) GitLab is better because you can [install your own runner on your own infrastructure](https://docs.gitlab.com/runner/install/freebsd.html) — from what I understand, any user on any GitLab instance can attach a custom runner to any project they own. 
That should be easy to fix since mrustc currently emits C code. I'm not sure how architecture specific that C could be… I should look at it.
I'm surprised custom jemalloc is used on FreeBSD, but IIRC there's some Rust debugging feature that prefers it? Either way… Rust's custom jemalloc is disabled on aarch64.
Yeah, you don't need literally an implementation of a Turing machine; I linked it just to show Rust traits are Turing complete.
[Yup.](https://pkgs.alpinelinux.org/package/edge/community/x86/darktable)
&gt; I think the criticism of inheritance stems from the way that it is used to provide polymorphism among types. I second this. One of the big pains with OO polymorphism is that all the types that fit are all tied together through an inheritance chain. You also have all the other aspects that come bolted on with inheritance. This makes large code bases very hard to change because small changes can impact a large amount of code through the inheritance tree. I've written a large amount of TypeScript which tackles the issues of object-orientation through structural typing. It's the duck typing approach used in dynamic languages where if it quacks like a duck then it's a duck, regardless of what it really is. The big difference being that it's checked at compile time. That avoids having to tie everything together. Ultimately with all the things said in this thread, it's having to tie all your code up together that is the core problem. Being able to bolt things on is what makes large systems much easier to cope with.
Most apps shouldn't care what arch they're running on.
&gt; Currently, a 100% standard conforming implementation of any of the C standards does not exist and whether it is possible at all is highly unlikely given how long people have been trying. And who has talked about a 100% standard conforming implementation? When a vendor claims their compiler is (conforming to some standard, they mean it modulo bugs, i.e. that they have done all that they (reasonably) could to achieve it. It does not mean "perfect, formally verified compiler". &gt; So by "CXY in 1 weekend" I could not have meant the impossible task of implementing "a full standard-conforming implementation of CXY". Whether you meant it 100% conformant or not, it does not matter, because neither is possible in a weekend. I am not sure why you are trying to play with semantics. &gt; I am sorry that you understood that that was what I was suggesting. No need to be sorry; but it is what you wrote, not what I understood. You were quite explicit on referencing several standards. &gt; Many students implement a reasonable subset of C89 and C99 every semester in less than two weeks. Most of them are surprised about how easy it is. Please show references to some curricula where they do such a thing. A "reasonable subset of C89" is a meaningless phrase, as explained.
hah it's not just me with that itch then, great . 
&gt; Also what do you mean application that uses it? An application could use this as a data source, just like the web server you have set up to search through it.
&gt; small changes can impact a large amount of code through the inheritance tree This is a good point; Code bases can become brittle and highly coupled.
Working on a seamless world generator in Rust for a futur "game".
I agree that this shouldn't be the case, yet in practice, it very often is. 
Oh? I've literally never encountered any issues aside from things depending on the old rust-crypto stuff that builds a C dependency only on arm/x86 and fails to link without some simple hacks.
Just started learning Rust recently and about a quarter of the way through the book. Coming from a Python background, there’s a bit of a steeper learning curve but the language is super intriguing and I can’t help but find myself constantly looking to learn more. That being said working on a simple package to consume Venmo API and write to a DB, perhaps follow it up with some AWS capabilities. I work as a Data Engineer so trying to learn Rust doing things I might encounter doing at a job.
Oh wow. Thanks so much. You went way out of your way! Very much appreciated! I actually understand almost all of the code except: 1. Why does the main function return something? I didn't know this was even possible. Who does it return anything to? 2. And I also don't quite understand why I need serde here? Doesn't the "toml" package provide all this functionality? I thought "toml" is just a parser that gets the requested items out of the file and stores it in a variable. What am I missing here?
&gt; Interesting, I've always thought that you can kill a thread so that it aborts whatever it is doing. You can't. Depending on the implementation you may find a way to ask it nicely to kill itself, but killing is not possible, for good reasons.
The divergent types can be resolved by just duplicating them in the documentation and use a visual annotation as I suggested in the Pre-RFC. Having a public type that can change relying on whether a feature is set or not either requires that kind of documentation complexity or confuses people. I guess a simple set intersection algorithm can be used there. Clearly, I think there are two features here: - Documenting the features in the manifest, which is a non-breaking change and should definitely happen. That would give us a way to add the features set in the documentation, which is also a non-breaking change. - Impacting the rest of the documentation by analyzing the consequences of feature gates on the public API, which is non-trivial.
Is there a good way to search for these types of repos? 
I've only been doing a little bit of work on [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) recently. Some minor documentation updates and tweaking the Travis CI build configuration now that Windows support is arriving.
Links to documentation: [ndarray](https://docs.rs/ndarray/0.12.0/ndarray/), [nalgebra](https://www.nalgebra.org/rustdoc/nalgebra/index.html)
&gt;Quite often, the impulse to inherit starts out as "oh hey, these two classes want to be able to do these same methods, I'll have them inherit an abstract class and pull the two methods up to one, look less duplication!" and now you've gone down a path where every time you want to share a method, you stuff it into that parent abstract class, which grows to thousands of lines and is full of methods that have nothing to do with one another. That's because languages like Java (pre 8) didn't allow multiple inheritance and also didn't allow default interface methods. If you have one of either of those, the inclination for a giant hodgepodge base class should be pretty easy to resist. When I did C++ I had a fair amount of abstract base classes with no data members. All methods were either public and final, protected and virtual, or public/protected pure virtual depending on whether it was part of the "API" of the interface, a default impl, or the implementor-needs-to-define behavior, respectively.
Are you running Rust binaries on real ppc64 hardware ? Maybe you can take a look at the rustc bugs tagget with powerpc :)
Obviously this is the wrong sub. I haven't played games for a number of years, but I must say I'm disappointed with the graphics, if this is a new game. Very obvious low poly count on the mountain ridges.
Hmmm, Not much listed at https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AO-PowerPC and it looks like mostly asm failures. I do daily rust development on ppc64 hardware and, at least not using any asm, I've never had any issues.
Rust is about 16 years old. They update every month. It literally is the only game worth playing.
It seems not all of them are properly tagged =/ One also has to search for `powerpc` and `ppc`
I personally find it a bit of a gray area. The kind of inheritance you can model via `Deref` is already limited, as you can't just pass a `&amp;Foo` where a `&amp;Bar` is expected and have `&amp;Foo` override/extend the behavior. For that, you'll have to go the trait route and then the encapsulation of `&amp;Bar` inside `&amp;Foo` becomes a type-specific implementation detail.
You are [passing](https://gitlab.com/dessalines/torrents.csv/blob/master/server/service/src/main.rs#L45) query received from user to [Pipe::new](https://docs.rs/pipers/1.0.1/src/pipers/lib.rs.html#20) which will then split it with [split_whitespace](https://doc.rust-lang.org/std/primitive.str.html#method.split_whitespace). This will allow user to submit arbitrary arguments to ripgrep. Anyway, using ripgrep just looks wrong for this. You will probably want at least some indexing to speed it up although I don't now if there is any crate which can provide it. Even if using a simple linear search, I think it is better to just directly use regex and load entire file on startup, this removes the need to separately install ripgrep and removes any potential for command line injection.
If you're going to play that game, [inheritance is just delegation that breaks encapsulation](https://dl.acm.org/citation.cfm?id=38820)
Cool! Is it hosted on GitHub or anything?
Inheritance creates stronger code dependencies, which is what we want to avoid in an clean architecture (when you inherit from a class, you have to mention the superclass directly in the inherited class, thus coupling both classes). Composition helps to mitigate those dependencies and allows to create more testeable and mockable objects since they can be created separately. 
&gt; Please show references to some curricula where they do such a thing. In John Hopkins this is part of the first two assignments in compiler construction, and people can push that in whatever direction they want for their class project.
Very interesting what they do here! Thanks!
Yes, I agree, multiple inheritance can help a lot with this and the likelihood of it causing trouble seems low. I've worked a lot with scala and never had much issue with that.
https://blog.rust-lang.org/2017/09/18/impl-future-for-rust.html
Can you compile it to wasm nodejs module?
That's why I like Debian's focus on compiling the whole archive across so many architectures. Most of them I definitely don't care about but it makes software more robust that at least a compile test is ran.
Look at that line again, whitespace is replaced. 
You can just include the pre-built binary in the package and list it in the `"bin"` section of a package.json. This won't be portable as the binary is prebuilt, but it will work. For multiple targets, I've never done this but I believe this is what [node-pre-gyp](https://github.com/mapbox/node-pre-gyp) is for. For completeness and sanity's sake, if you can extract the logic (including args parsing) out of the main function and export that as a function, then pass the exported function `process.argv` or whatever and use Neon, I think that's probably the best way to go. 
If you're playing in 4k then it's going to look like 4K. But they design these games so that a person who does not have the most up-to-date fastest GPU can still play reasonably. 
The thing about laziness is that it's all about the effort difference between doing it the/a right way and doing it the "lazy" way. If you are in e.g., Java 7, the "right" way is to define an Interface and then copy and paste code in each class that implements the Interface. In that case, the "lazy" way isn't really much worse than the right way, so I understand why it happens. If you have access to interfaces with default methods and you still just shove methods into a monster base class, that's something beyond lazy. The right way is almost the exact same amount of effort. On the other side of that, I've worked on several code bases now where code is just copy and pasted around, instead of being tied to some kind of reusable components. So lazy that even inheritance from a monster base class is too much work...
&gt; COOL which is pretty much "C with classes". Alright. I will stop answering, because if you believe Cool is "C with classes", there isn't much point in debating with you :-)
That's kind of a useless survey. On the first page I answer that I haven't written any web services in Rust, then I'm asked on the second page what my experience with different rust web frameworks is. I just told you I had none.
I'm sure the resolution of the display has no impact on the number of polygons your GPU can process.
The problem with that approach is that sometimes the ecosystem breaks because one widely used library introduces a change that breaks it on many architectures, because that library's own CI / developers are not aware of where it is used.
I agree it would be better if everyone tested on all architectures. Given that's not the world we live in, and everyone including the librsvg developers only cares about a few (if not just 1), it's nice that Debian takes up that challenge. It ultimately makes software better than those bugs and tooling issues are caught at least eventually.
IDK man, your doing programming and stuff, help us out. Fix it, yo.
&gt; What is an Impl day? An Impl day is a community organized hack day, typically surrounding a conference. &gt; What is an Impl period? An Impl period is when the rust community stops approving new RFCs in an effort to implement the ones currently approved but unfinished. &gt; How is that related to or different from Impl trait. Rust has a keyword `impl` that is used for two things, first is to implement behavior (methods) of a `struct `. The second is to indicate that an argument or return type can be anything that implements a particular trait. Since this is an often used keyword and seemingly unique to Rust, it is a fun name for rust related things. 
I want to implement a serde Serializer as a custom derive macro, something like this: #[derive(SerializeWithMoney)] struct Product { name: String, currency: Currency, price: Money } So, this way I can serialize money field according to every struct with particular currencies features. Is there any github repo that implement something similar and use serde functions?
Thanks for the clarification. Seeing "impl period" and "impl Trait" in the headlines with such vastly different meaning was very confusing.
Rust used to have a bootstrapping compiler in OCaml, what happened to it?
I bet the guys at /r/playrust are very interested in this.
Finally made it to reddit!!! Thanks guy you shouldnt have &lt;3
It doesn't host any copyrighted content technically
And both \`&lt;whatever type 42 is&gt;\` and \`String\` implement \`Display\`. \`impl Display\` means the same thing in the sense that they both implement \`Display\`, not that they are required to be the same type. Sorry I was not more explicit about that.
You missed the part about casting to other types - when you cast a pointer to D to a pointer to B, then the compiler doesn't *know* to offset any references to account for the class inheritance in the vtable. 
(experienced Haskell programmer just starting to learn Rust, here) &gt; but don’t know much about debugging, etc. I think you'll find most haskell programmers would disagree that debugging program logic is difficult in haskell or a weak point of the language. Furthermore it continues to be on the cutting edge w/r/t libraries for testing. The main tool I use for debugging is the REPL, which I'm sorely missing in Rust (I've read that there are some projects for this but I'm not sure how good they are or whether they are widely used; haven't seen any mention in the rust book yet) &gt; what you mean specifivally by abstract/real world Here's what I assume christiansakai is referring to, with some background: haskell has a very advanced type system which supports the invention/discovery of very powerful abstractions ("abstracting" as one of the fundamental acts of programming, e.g. the `map` function represents abstracting out a particular pattern of recursion into a reusable and understandable component). One of the challenges of learning haskell is not so much the language per se, but it's learning how to learn new abstractions and getting used to the mental "pain" associated with that. So anyway if you read /r/haskell you will often see discussions that are very abstract, which sometimes use the language of category theory, etc. I think many people would obviously take issue with the idea that this research is unrelated to "real world problems" (it seems to take a decade or two for one person's "abstract nonsense" to become practical real world problem-solving, as evidenced by the existence of Rust today and not in 1998 say (the year of the first haskell standard)). Here's I think a fairly objective survey of library support and language suitability if you're interested in evaluating haskell for a particular project: https://github.com/Gabriel439/post-rfc/blob/master/sotu.md
&gt;over another general-purpose functional language Rust is not a functional language, at least not in my opinion. I can elaborate on why, if you're interested. Rather, it's an imperative language with features from multiple FP languages which are used to make writing imperative code safer and more elegant. This distinction is quite important, as it has a large impact on the typical programming style and ecosystem. The primary reason to use Rust over a functional language is predictable and generally very competitive performance. Instead of garbage collection, Rust uses deterministic memory management and generally avoids unnecessary memory allocations as much as possible. This results in predictable performance without stutters, which is great for soft real-time systems such as audio/video processing, games and other interactive applications. The language itself has been designed to support zero cost abstractions - code can be sufficiently abstract and high level, but the resulting machine code can be optimized to a very high degree. It comes close to and sometimes exceeds C++ and C in performance while being significantly safer, both in terms of correctness and safety against common exploits. Despite novel features and ML-inspired syntax, Rust can still be considered a C-derived language. This potentially makes it easier to teach to a generation of programmers who've been writing C-like languages like C++ and Java for years than e.g Haskell. 
I looked into it more and this is my current status: 1. OK I didn't know you can "trick" main() into using the "?" operator. It seems a bit hacky to have main() "return" something, but I guess there's no better way to do it. Understood! 2. Now this is where I'm still having problems. I might just not be a good enough Rust programmer yet, but why can't I just do it simple and straight foward like this: let setting1 = toml::get_setting("setting1"); let username = toml::get_setting("username"); let server1_ip = toml::get_setting("server1", "ip"); etc... I think I understand what serialisation is, but why does it have to be so complicated? I just want to get a simple String out of a text file. Why do I need all this serde stuff? I thought that's what the parser does? Isn't the "toml" package a toml parser? I'm totally confused about this. I'm not sure if my problems is a Rust problem or a not-having-studied-CS problem.
You can make your hex grid into a square grid by shifting alternate lines half a cell (or shear the whole grid to make it square if you want to preserve shapes under translation). Then it becomes a problem with existing solutions to borrow from.
I started off with basing it on Kademila, but after some more research the BitTorrent DHT is a minor variation of it which does the things I want to do. So, I'm basing it off the BitTorrent spec.
[`shred` might be up your alley.](https://docs.rs/shred/0.7.0/shred/) You can also just use futures directly, although you’d be in for some boilerplate.
I honestly haven't gotten very far yet! I also had not intended to deal with mutable data in this project; it's intended to be content-addressed, which implies immutability and also kind of handles validation on it's own. If there's a good way we could share code though I'd be happy to. I'm interested in your thoughts though! Is there a particular application you're aiming for? How do you intend to handle mutable data? From what I've seen, the problem devolves to mutable naming of data, and that's hard to do robustly and efficiently...
&gt; Please report that as an Issue on the repo; that’s definitely a bug in the linkage of syn. [Done](https://github.com/pthariensflame/salmagundi/issues/1).
The example isn't important; I just mentioned it to avoid confusion about what I'm asking. If you're saying there are ways to compress a square grid, so I can compress my hex grid using them, I'm not interested. If you're saying there's a pattern to parallelize a DAG resulting from a square grid, what is it? I can't really imagine any method that would be specific to it that wouldn't work on a hex grid, except maybe something that exploits the branching by a constant 4.
I've done basic testing against a server running on localhost - Welle consistently runs faster than apache bench by \~25%. I'd be curious what others find when they run Welle on their machines and against different hosts.
Re 1: I used that trick mostly for demonstration. In real code you'll want your config managing method to return a `Result` for error handling so I did the same in main to use the `?` operator. If you don't want to do error handling you can replace `?` with `.unwrap()`. Re 2: You can definitely have `toml` treat your data as unframed and just get strings out, but it gets complicated pretty quickly. There are tons of error cases: for instance, what happens if a user has entered `servers = "a string" ` rather than a list? What if a server entry is missing `ip`? These would all have to be handled, either unwrapped or treaded as errors, independently in the code you're using to access the config. Even without a schema it wouldn't be a simple as `get_setting` because `toml` needs to know where your configuration is! There isn't just one `.toml` file- you'll need to load a specific configuration into a structure. By using `serde` and an explicit configuration structure we can have all parser and schema errors up front, and then just deal with correct data for the rest of the program. I'm not sure what you mean by toml not being a parser though? It's definitely a toml parsing crate. It parses a toml string into either a fully-formed `serde::Deserializable` structure, or into an unfromed structure. It's `serde` that handles the whole put-the-data-into-a-structured-format thing, and `toml` supports it because it's much more convenient and faster than loading unstructured data. If you want to do configuration without having structured config `struct`s, see the ["parsing toml"](https://docs.rs/toml/0.4.8/toml/#parsing-toml) example from the toml crate. --- In short, parsing data is not easy because there are tons of ways it can go wrong. Other languages might implicitly fail, or just give wrong (or `null` data- something Rust doesn't have) when that happens, but `rust` prefers forcing explicit error handling so you know when you can crash. Structured formats are nice because they allow you to do all your configuration parsing in one step then just deal with fully correct data. No need to handle `toml` errors all throughout your program whereever you access configuration. But using non-structured parsing is also always available.
So then why ask if one has written a web app at all then?
Okay, it just seemed that working from a DAG was a very complicated way to compress what's essentially a bitmap. If working with DAGs is the challenge you're interested in working on, rather than just getting the example compression job done, then no problem! (I guess you might not always be working with a hex grid, instead some irregular grid over a non-flat surface.)
ripgrep is available as a library now. Here's an example: https://github.com/BurntSushi/ripgrep/blob/master/grep/examples/simplegrep.rs I still need to publish a higher level guide, but all the pieces are there! cc /u/parentis_shotgun 
Whoa sweet! Thanks a ton. 
It helps in that sense, but LLVM is also a fairly big, complicated project, has its share of bugs, and there can be bugs in the interface between the Rust compiler and LLVM. It can make tracking down issues tricky sometimes.
This is what I've been trying to figure out lately because I don't want to create 1k+ object per epoch in my program. Like you said, maybe borrow and reference would do the trick. I need some time to test this out. Thank you!
Already posted boss: https://www.reddit.com/r/rust/comments/9op4sg/serverless_rust_with_cloudflare_workers/
Thanks for the comment everyone. Sorry I can't reply to each comment, but I read them all. To my understanding, both composition and inheritance have their own advantages, but it could be turned against us when we overdo and/or use it as one trick hammer for all problem. Use inheritance when I want to save some typing, making sure everything is uniform, painless behavior cloning, for program that its component rarely changes. As the result, the codebase would be quite rigid and hard to change. Without proper planning it would turn into mumbo jumbo hacking around just enough to make things work. Use composition when I mostly want just the data an object holds (since reimplementing all child struct method would be quite tedious), more flexible structure, and also easier to comprehend since you don't have to know everything all the way to the root object. Is this all correct? Let me know if I miss something. 
yep, that's the more general problem I'm thinking about too. 
The new [Pi-hole API](https://github.com/pi-hole/api) is written in Rust.
Pretty sure it was abandoned when Rust became self-hosting.
1. I understand the unwrap/? usage and quite like it. Even as a beginner this totally makes sense and saves me a ton of code. 2. Hehe, I'm of course aware that you need to read the toml-file first, I just left it out because I just left it out because I wanted to focus on the code for getting the actual values. But what really helped me understand this problem is this part: &gt;It parses a toml string into either a fully-formed serde::Deserializable structure, or into an unfromed structure. It's serde that handles the whole put-the-data-into-a-structured-format thing, and toml supports it because it's much more convenient and faster than loading unstructured data. So that means that the toml crate actually transforms the data from the toml-file and puts it in some sort of "serde compatible format"? Did I understand this correctly? What confused me is how would serde know how to do the correct checks. It can't just be some background "magic", but someone actually has to define what's valid and what isn't. Just like I'd have to do it if I didn't use serde. But if the toml crate has explicit serde compatibility, then that would make sense. Now the only question that remains is: How can I understand what exactly serde is doing? I googled "serialisation/deserialisation" but that just brings up lots of theoretical CS background info. What I'm trying to understand is: How does serde know what to do? How does serde know what to check? Because as you said: &gt;There are tons of error cases: for instance, what happens if a user has entered servers = "a string" rather than a list? What if a server entry is missing ip? These would all have to be handled, either unwrapped or treaded as errors, independently in the code you're using to access the config. All these errors are magically handled by serde, correct? I'd like to understand how it does this. Is there an ELI5 answer available or do I need to understand/lookup a specific CS topic first? I know I already have a working example, but it drives me absolutely insane if I don't understand what's going on in the background. Sorry! :-)
Ah ya, fair enough. Isn't there an LLVM IR interpreter that could maybe help?
I still don't understand from your explanation why is inheritance useful. Could you please give a code example. 
&gt; borrow I see what you did there...
Yeah, I kinda stopped about when I had to answer, "I prefer not to use a framework" - since I don't develop web services, that question doesn't even make sense!
The problem is that the answers you can give make no sense if you have no experience writing web apps in rust, and especially not if you don't write rust. &gt; Which Rust web frameworks are you using? None, but that's not a preference! I simply have no experience writing web apps in rust. &gt; Which (other) crates are you currently using that are specific to web services? Well, none obviously! &gt; Of the crates you listed, which areas could use the most improvement? How should I know, I have never used them. &gt; If there were any gaps in the ecosystem, what were they? What did you do about them? Again, I have no relevant experience to answer this question. &gt; Which platforms do you target? and &gt; If you have encountered any platform/target specific pains, what were they? Ah, two questions I can answer. &gt; Why did you choose Rust to develop a web service? I didn't 
Composition has one advantage over inheritance - significantly stronger isolation. With Java-style object inheritance, reasoning about behavior can become very complicated, as a function call may resolve to a superclass definition, or a subclass in the inheritance chain. Additionally, there is shared data, and a chain of initialization (and for some objects, destruction) that needs to be propagated up the inheritance chain (because supers initialize first). Engineers sometimes talk about 'abuse' of inheritance, and what they mean is that 'weakly defined' behavior is exploited. For example, if a subclass manipulates data in a superclass, it may do so in a way that violates contracts that are defined in the superclass - like the superclass maintaining an index whenever the data is modified. That index code may not even exist when the subclass is written. The superclass can be modified after the fact... Or maybe the subclass needs to tweak the index maintenance procedure to consider subclass data, so it overrides the superclass maintainIndex() method... Things can get ugly. Composition relies on fewer non-local assumptions between behavior. Non-local definition is always cleanly separated by an interface boundary, and data is always acted upon by the code that owns the data.
Since the Rust ABI is unspecified, randomizing struct layouts should be totally doable, just so long as it doesn't touch structs with `#[repr(C)]` or `#[repr(packed)]`.
Concurrency in Action :) I've removed the other link since it somehow went through AMP rather than directly going to the source.
This is pretty slick, nice work on getting this up and running! I was hoping myself to kick the tires on wasm + Cloudflare but I'm glad you beat me to the punch! You might get some better results with `--no-modules` which may be more appropriate for Cloudflare's use case. I think with [this small change](https://github.com/rustwasm/wasm-bindgen/pull/969) it should be possible to use the `--no-modules` output as-is, no modifications needed!
If the graph is known ahead of time, one pattern is to determine the in-degree of each node and process all nodes with in-degree 0. Each node completes, and send a "decrement" message (often with data) to each of its outgoing obligations. This enables me nodes to fire, and the process repeats until all with its fine (or a cycle is found). You can write something like this in differential dataflow pretty easily (at least, its examples/sequential.rs does this for graph coloring; that may not make it easy). It is a pretty heavy dependency to bring in, though. Alternately, you have all of your graph nodes shared with atomic usizes initially their count, use Rayon to schedule nodes with zero in-degree, have each decrement counts for its out-neighbors, and if any hit zero schedule them in Rayon too. 
You are awesome. Thank you for sharing that ^^.
Doing a quick search for `powerpc` or `ppc` I count less than ~50 open tickets. Searching for `windows` shows ~400 open tickets. This is just a factor of popularity, not of relative quality, of course, but it doesn't seem to me that ppc support is _terrible_.
Striped locking could also reduce the contention significantly.
I know this is going to be very hand-wavy, but I never missed such a feature in my projects. Isn't it the case of using an object-oriented programming style in Rust, where the code could be structured in a more "Rustic" way? In OOP, it is very common for one object to have behaviour A, and for another object to have behaviours A+B (inheriting/composing A and adding B). But it's often possible to have one object that does A, another object that does B, and use them more-or-less separately. I think Servo guys legitimately needed inheritance to save some cycles in DOM manipulation, but that seemed like quite a rare situation. I'm _not_ trying to suggest that your grievances aren't justified. I am genuinely interested in cases like this that may not be adequately served by Rust's features. Could you elaborate a bit, or post a link to a repo, or something?
What does this accomplish, why would I use it?
How do I deal with one library exporting parts of another? \`ggez::nalgebra::Point2\` is necessary whenever interacting with \`ggez\`, but \`nalgebra::Point2\` has a bunch of nice utility functions. It seems like I can use them interchangably if I import the correct (old) version of nalgebra, but as soon as I use a new one, cargo distinguishes them as different types.
In general you can't (nor should you) pass anything over FFI *or* shared library boundaries that isn't a C type. Passing a vector is pretty simple in theory but it's not perfect, and it does not apply for other STL containers. // C++ struct int main() { std:: return 0; } // some rust code #[repr(C)] pub struct Foo { // all of Foo's members }; pub extern fn pass_vector (ptr *mut Foo, len : usize) { } 
Only one of the symbols that split_whitespace considers to be a whitespace
&gt; In addition, the number of contributors writing HCL, a human readable language for DevOps, has more than doubled since 2017. The thing with multipliers, is that going from 1 to 2 is x2.0. Personally, I'm more impressed to see Python growing by x1.5; it's already the 3rd top language, a +50% increase in the number of contributors is just massive.
is rust really still that niche?
How is this serverless if you are uploading your code to the server? What am I missing?
No, but it's worth mentioning that "fastest growing" can be deceptive.
&gt; Interesting seeing such an opinion on the community [Self selection bias](https://en.wikipedia.org/wiki/Self-selection_bias). You'll find people extolling the virtues of templates in the C++ subreddit. 
Serverless is a years old movement led by AWS lambda. Traditional model required provisioning servers to run your code and paying them even when idle. Serverless uses servers, but loads programs dynamically and bill you for seconds your code spent on CPU cycles. Underlying infra is abstracted away. 
The questions are not mandatory, you can just skip them.
I have a best-practice question. I'm using the [ngx-rust](https://github.com/nginxinc/ngx-rust/tree/master) bindings from the nginx team to write an nginx plugin. We sometimes have trouble getting it to build, so I've done some digging into the build process for the package. The package just basically uses bindgen to create a [bindings.rs](https://bindings.rs) file. I've noticed that instead of building the bindings file inside a `CARGO_OUT` directory which would be per-build, the file is created, and the nginx source is downloaded, and `configure`'d inside the source directory for the package. This somewhat makes sense if you're the one developing the package, because you don't want to wait for the whole nginx build to happen every time you make a tiny change. As a user of the package however, I don't really like that the build of this package is dependent on some outside state that is shared between builds implicitly. Is there some middle ground that can work for everyone, or is there not a great solution to this problem?
Unfortunately this is not generally possible, as cargo treats different incompatible versions of libraries as completely different libraries. `nalgebra-0.1.0::Point2` is as different from `nalgebra-0.2.0::Point2` as `HahMap` is from `Vec`. Maybe you could find a way to convert one to another, but there's no trick to get them to be the same type unless `ggez` updates its nalgebra dependency. For conversion, maybe `Point2d::new(p[0], p[1])` could work?
You don't manage the server, or really anything about the environment. You can think of it as your own personal Software as a Service provider. You give them code, they provide it.
Sounds like shared web hosting where PHP was hosted for ages.
No. You have independent endpoints, each of which are tiny scripts and can be executed and modified on the fly. Stuff may suffer cold start delays if no requests came in a while. Wait a minute...
So rayon works well if you have a tree of dependencies. You can treat your dag as a tree if you're ok with duplicated work. If you're not ok with that, consider doing a toposort-driven split: 1. Toposort. 2. Split list at each index where you find that `arr[i - 1] &lt; arr[i]`. You now have a list of lists, where each sublist has no inter-dependencies. 3. Then use rayon on the first sublist, wait for completion, then use it on the second sublist, wait for completion, etc.
Check out Warp, it's very filter-based which might be closer to what you want.
As someone who doesn't know any of the frameworks you mentioned, I'm wondering what aspects of them you like. What advantages would your new framework give over rocket or actix-web? --- Semi-related: if those advantages are at an API level, would you consider building your framework on top of an existing one? `hyper` is a quite complete http base (by no means a framework), and `actix-web` is also quite capable.
This is a good idea, and it works for me particularly. This is because all shapes are made of smaller shapes, so I'll know what those thresholds are without computing them (compute all shapes of size 0, 1, 2, etc). Thanks 
Also, you can't use rustup on x86 alpine :( I really, really wish someone would make it so rustup would work with musl.
Not really. They take care of scaling the deployment and making sure the actual code is run close to the geographical point of the request to reduce latency. The actual name is very buzzword-shit, but it's pretty slick in terms of what it really does. Of course, it's basically without state, which severely restricts the things you can do.
Come on, how hard could it be? :D Thanks for the info about Bittorrent, I didn't know that. Know of anywhere I could read about these degenerate cases? I've played with libp2p a little bit, but despite the name it's in fact `lib point to point`, not `lib peer to peer`. There's a fairly decent Rust implementation made by Parity, IIRC. I'm currently just using QUIC for networking, which does a lot of the same things (lightweight channels, encryption, etc), though not everything (NAT holepunching, peer routing). What I'm making is about the equivalent of IPFS's `bitswap` layer, which does the actual shuffling of blocks from point A to point B. I am generally skeptical of IPFS these days, after a long period of using it, because I feel like they're making a lot of wrong engineering decisions. When a project invents a new, incompatible, inferior form of locator string instead of just using URI's, it makes me rather dubious of a lot of their other tech.
Exactly, if only 2 people use it, and another 2 pick it up, that’s a 100% increase in users.
&gt; Thanks for the info about Bittorrent, I didn't know that. Know of anywhere I could read about these degenerate cases? Nope, sorry. This info was mostly from seeing an ISP in action a few years ago, so it might as well be obsolete. I've mostly messed with cjdns from then on, which uses a heavily modified Kademlia for routing. There should be plenty of analysis of bittorrent DHT and/or Kademlia out there, though.
Huh, I always heard that mutexes were really slow. It wouldn't be better to use a CAS or something?
Oh you're saying that even though hash tables are slower because you have to hash (and use SipHash) compared to just an index lookup, because the array is likely to be sparsely populated there would be more cache-misses compared to a dense hashtable, so their performance would be pretty similar in reality?
I'm not really sure if I understand what you're saying. How would I avoid checking tokens with every handler request? It needs to check each time to see if there are any available so it knows whether or not to deny the request (and this same check also does the refilling operation).
I think you meant to reply to my comment above.
I think I hit the the button to do just that, must have missed.
I'm basically saying if you're ok with updating the token counts less frequently than on every request, you can do batch updates periodically. This would mean the rate limiting would only be precise to the period you choose to update. This is similar to how timers don't have infinite precision.
Well, in any case while I have you here.. do you know if it's possible to just ignore safe multithreading? Like, I don't care if there's a 1% chance the counter gets updated twice instead of once since it's just a silly rate-limiter, you know?
It's (hopefully) helpful for finding bugs in code that manipulates values in a low-level way. Basically, code might accidentally assume that a `struct` or `enum` is laid out in memory in a particular way, and `salmagundi` allows you to (in a controlled, reproducible way) break those assumptions on purpose to check for such things.
I'm surprised there is no mention of security on the reasons why we'd choose Rust on a web-facing application!
One of the problems outlined by the post is the incapacity of the `wasm32-unknown-unknown` to know in what environment it will be ran. A solution I see is the creation of a `wasm32-web-unknown` target, where the `std` will be based on [`web-sys`](https://rustwasm.github.io/wasm-bindgen/web-sys/index.html), but is it really feasible? Doesn't it depends on more feature-gating in the `std`, to remove `std::fs` for example? Can we already build partial `std` based on `web-sys`?
For simple integer increments I'd suggest simply using `unsafe` but still I would personally go with Atomics in that case. For anything more complex than that I wouldn't know, but perhaps RCU (look at the `crossbram` crate) or RWLocks for the base structure and Atomics or unsafe counter updates for the simple counter updates.
Lol, that reply button on my phone app is too small, I'm apparently hitting right below it. My answer is again at the parent post.
Can you explain, why? Not going to attack you here or forcing my opinion onto others. But rust pretty much replaced almost all languages I have used for several years. No, one does not need rust but it makes my life as a programmer much more easier. For years I have worked with python, Java, C++, JavaScript because they all had a particular purpose. I used python for my management, scripting, CLI tools stuff (and very small Webservers), Java mostly for webserver and JavaScript for front ends and C++ for "high-speed" stuff. As I was getting more and more familiar with rust I pretty much ditched all of them for my private programming (not at work, things don't move as fast over there) and my life is way more easier not having to work with more than 5 pretty complex ecosystems. Personally I can rust very well see as a popular language in the future if people realize how much quality of life rust can introduce if you don't need to be good at 4+ languages to be a good Allrounder in the Programming field.
It'd help if you showed what line the error is pointing to.
Does this run wasm on whatever js engine cloudflare is using for their edge services (v8 I'm guessing)?
Don't be so negative. We're tied for *4th* with PowerShell!
I'm wondering whether "fastest growing" in this case should be measured not in proportion to existing counts, but in the absolute increase of count.
cgi-bin-ng :)
It *is* pretty similar to the PHP model. However, it has the advantage of automatic load balancing over multiple servers.
I think this is the route I'l take.
Maybe? I don't know enough to say. It does a lot of io though, including to the terminal, so it seems like it wouldn't be a good fit.
I tried extracting the args parsing and got it working in a node module before I realized that [there's no good way to publish a node module that relies on Neon](https://github.com/neon-bindings/neon/issues/117). And node-pre-gyp seems to only be for c/c++. So I think I'll go the route of downloading the binary from github.
Yikes! Sorry to have misled you, and I suppose thank you for being my canary before I went ahead and tried Neon myself. I had no idea that glaring issue existed.
Do we now, when the results will be published?
https://www.reddit.com/r/rust/comments/97iavn/comment/e48rdrm?st=JNCC9K2H&amp;sh=2f29f28c
You want atomics even for simple integer increments. I don't have the URL handy but one of the posts that showed up in /r/rust/ a year or two ago went into great detail on how much optimizing compilers and superscalar CPU pipelines and caches are allowed to assume without explicit synchronization and it's a real "If you don't use something backed by the correct CPU intrinsics, you *will* get burned when a cache or out-of-order execution makes an incorrect assumption" situation.
The payment model is in fact a significant differentiator. It's like managed FaaS + Pay for what you use. Generally, that is the definition I see most often.
&gt; I can elaborate on why, if you're interested. Please! I probably will only grasp 30% of it, but I'd love your take.
I'm still waiting to hear how this is safe in the presence of speculative execution. This is built on a model that Chrome has explicitly stated is no longer safe (the isolated workers within a VM). So, very cool, but I enjoy knowing that when I use AWS there's likely isolation at a process level at minimum, and likely some degree of KVM isolation.
The problem is that it's not just "the counter gets updated twice". Dynamically reallocating data structures like hashmaps (to add or remove `user_id` mappings) can cause data corruption or even crash your program if you don't synchronize them properly and it's not just a multithreaded problem. (The case that's best known in single-threaded cases being iterator invalidation.) I recommend reading Manish Goregaokar's [The Problem with Single-threaded Shared Mutability](https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/) for more on that.
We're currently working on translating and sifting through the data. There a lot more than previous years. We're going as fast as possible!
I like Powershell, but it has some big issues imo. There are so many things implicit, then shouldn't be. For example somtimes if you return a string array with only one element it gets converted to a string and if you iterate over it gou get chars. You can turn that off by using a comma between the return and the array, but thats ugly. Finalizers are not officially supported, but of you have a method named finalize it get executed when the value is cleaned up by the gc, BUT its not guaranteed to be run and if its not run the shell crashes on close. Many things are guaranteed. And some things behave differently in classes, or don't work at all. And thats just the beginning.
Sorry, I tried both of these options but I'm still running into errors. If its not too much to ask, can you demonstrate what you mean with some code? &amp;#x200B; Thanks!
But then, I'd have to merge those lists back, right (since I do want to keep the original vec, and just modify the child's \`previous\_hash\` based on its parent)
Then you get bias the other way. Imagine a niche language exploding from 100 to 10,000 repositories, while a much more common lang grows a smaller 10% from 1,000,000 to 1,100,000. There are ten times as many new repos in the popular language, but the smaller one's growth is much more impressive.
&gt; Yep, if you need HKT then Rust won't cut it right thats sort of it. I don't *need* it, just like I dont need to get rid of header files. however I greatly enjoy having it; and it's more the fact that in work I've done (and in current and future interests) there is a split between *data transformation* which isn't interactive, but which does require experimentation , and 'runtime' , which needs the efficiency of C (or anything that can match it) and yes r.e. C FFI .. I dont ever anticipate Rust becoming a replacement standard. To C's credit , it established itself by getting the right features in early enough to become a standard. C++ followed and was too complex, but nothing else rivalled it. Rust again has too many specific ideas beyond what is needed to be that 'universal glue' . And you know, I've found myself thinking right now that going back to C sometimes would actually help me hedge my bets between the options... i.e. writing C libraries where I leverage my habits/experience , and the fact that it's still actually good enough in some roles , whilst being able to use that code quite directly from C++, Rust, and anything with an FFI
It is an additional problem. It just slows development a bit, for testing you need to juggle binaries between two systems (or emulator), and build scripts are not prepared for this well. The main problem is that LLVM only supports some architectures, like alpha, ia64, hppa and m68k (u/[cbmuser](https://www.reddit.com/user/cbmuser) is working on this one tho apparently). &amp;#x200B; making rust work on x86, riscv, ppc, ppc64 and sparc should be doable with little work. &amp;#x200B; alpha, ia64 and hppa would be major endevours. I hope to jump into alpha LLVM support, but always have no time, and my machine is offline right now, but this might trigger me to do it anyway. There was alpha port for LLVM in the past in official sources, but it was not maintained (LLVM sources constantly change APIs between versions, so you need to keep updating all ports to keep LLVM as a whole working) and thus removed. &amp;#x200B; Because LLVM is basically is crosscompiler from the start, it has benefits, i.e. you can develop, build and mostly test entire toolchain on another faster machine (like your usual multicore amd64), instead of waiting hours for build on your wimpy m68k, or old ppc machines. It even halpes with arm development. It also means that at least some compilation and runtime tests can be executed without access to a target machine, which is a big plus. As of rustc selfhosting. You have the same issue with C/C++ compilers. It is not unusual. &amp;#x200B;
Yes. LLI it is in LLVM distribution. It also includes JIT / dynamic compiler (using other LLVM parts) for some archs, when used with some flags. It could help. Especially with unit testing without access to target machine.
jemalloc works on Linux too. [http://jemalloc.net/](http://jemalloc.net/) It works fine on all 20 archs in Debian, including hurd and kfreebsd. I do not know how it compares to glibc malloc these days.
I think what Rust critically needs is an influx of high profile projects. I strongly believe Go was buoyed to the top not because of any feature, but because it rode the container ecosystem into the public eye. We are of course also working against the notion that Rust is a "systems level" language and that it has a "steep learning curve". Everyone here knows Rust is easier to learn than C++ or Java, and it's certainly suited to general purpose programming as much as anything else these days. We also need more evangelism (although that's too forward a term for what I mean). &amp;#x200B; Rust is in a good spot, but it needs to keep building momentum or I fear we'll end up in the Haskell or even worse, the D corner where we aren't \*not\* ready for production, but we aren't mainstream enough to sell to employers and OS project leaders. We also need more examples of big projects (I'm thinking Kubernetes, VS Code etc) that are thriving on Rust as an example that all these nice things that we like about Rust really do turn into great software.
I completely agree -- I think this is rust's secret weapon. Javascript popularity is based primarily on the fact that people who knew how to code for the browser were able to keep their skills and use those on the back-end. That said, for the node itself, node addons and performance critical parts you still have to use C/C++. With Rust you can go all the way from very bottom (performance critical) to backend to frontend (wasm)... and everything is super fast and doesn't fall over for weird reasons. More and more companies and developers will start realizing that and that will give rust the boost to the top. It is ok, we can wait. :-)
My favorite section is the most used emoji by language section Lolol. Ruby uses the most hearts, apparently.
making a yet another full rust frontend framework. [demo](https://awpteamoose.github.io/rage/) [repo](https://github.com/Awpteamoose/rage) if someone wants to take a look, especially looking for performance tips.
GUI programs tend to involve a lot of "B is an A with extra features"-style programming. Some people would go so far as to say that inheritance patterns are necessary here, (though I vehemently disagree with that,) it is actually a very common way to do things in some domains.
Nice one. I look forward to reading about that, if you get the time. 
Google regularly get's DMCA requests for hosting links pointing to torrent sites.... I basically assume without justification that this is equivalent.
Xi editor and Redox OS of course!
Hello r/rust first time poster and a new Rustacean, excited to learn! Bit of background, I've been programming for a bit over a year and I mostly have experience with Python and similar languages (-noun-script languages, Lua, the like...) but I am comfortable with OOP languages like Java and C#. Rust is my first dive into 'low-level' programming, and I am struggling with ownership. I understand how it's an important feature but I can't get a handle on how to work with it. I often end up with variables stuck inside a scope and I don't know how to get them out. For instance, I might declare a variable inside of an if statement or a loop and be unable to use it because it drops as soon as the brackets close. Python has very loose scoping rules (basically only global and function scope) and I don't know how to adjust my thought/design patterns to Rust. Is it just writing a lot of functions? It certainly can't be just declaring a bunch of variables at the beginning because then they would have to be mutable, which is no bueno. &amp;#x200B; In a nutshell: How do you deal with ownership? My variables keep getting stuck! 
Could you give an example of what the return type of an endpoint that did content negotiation would look like? I feel like that's a fairly common thing to do in APIs.
&gt; For instance, I might declare a variable inside of an if statement or a loop and be unable to use it because it drops as soon as the brackets close. Then why not declare it *outside* the branch or loop? &gt; It certainly can't be just declaring a bunch of variables at the beginning because then they would have to be mutable, which is no bueno. They wouldn't. You can define a variable without an initialiser, then initialise it later on. The compiler doesn't care so long as it can prove it's initialised before it's used. You can also just have values be the result of branches. let x = if a { i } else { j };
As someone interested in Rust but yet to do a project, what is the library ecosystem like? For example, I want to write a service for Raspberry Pi that can make https calls to a server, collect system stats, handle JSON and do some private / public key signing related. Is that easy to do in Rust?
Thanks - hopefully I have time soon.
Not a problem. It wasn't really obvious anywhere on there site at first glance.
Sure, here are a couple of examples: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=f401208001f0bcfa227033d4de8f156a Note that I'm writing let child = &amp;mut ... rather than let mut child = ... The first one says chat child is a **mutable reference** to something. That is, we'll use it to mutate the thing it _points to_, which is what you need here. However, we're not going to change what `child` is pointing to, so we don't need to call it `mut child`. What `mut child` means exactly can be a little confusing. If `child` is a reference, it means that we might change what it points to, by reassigning it. If `child` is an actual struct value, we might be saying we're going to reassign it to a whole new struct instance, or we might just be saying we're going to mutate some of it's fields. The key thing here is that `mut child` says that we're going to modify whatever it is that `child` _owns_. And if you own a reference to something, the only way to modify this reference that you own is to reassign it to be a reference to something else.
Curious how Microsoft seems to be at the top of all those charts all of a sudden.
HCL is a crappy json knockoff. TOML whips its ass up and down the block by basically ever practical measure. It's probably growing because people put their terraform configs up on GitHub.
And, C# seems to have a lot of thumbs down and frown faces.
Serializing complicated objects into script blocks is a royal pain in the ass too. There are \~3 ways to do parallelism, and they each have different shortcomings.
As someone who has used expressjs before, I feel at home with actix-web. It was fairly straight forward enough even when it was in early stages of development and has gotten a lot better since. I would give actix-web a go instead of rolling your own.
In fairness Rust does have a fairly steep learning curve, probably not as high as C++, but certainly higher than Java, depending on what level of proficiency you're trying to reach. Those aren't particularly easy to learn languages though. 
That's pretty awesome! Any details on how to get it up and running? And how well it performs while under Windows?
We need tabs.
Download from here [https://ci.appveyor.com/project/jwilm/alacritty](https://ci.appveyor.com/project/jwilm/alacritty) with stable rust version. Also echo %HOME% to find the alacritty.yml file to change the configuration.
&gt; Everyone here knows Rust is easier to learn than Java That's not even the majority opinion of this subreddit!
This is the subreddit for the Rust programming language. You're looking for /r/playrust
Oh, Lawl. My bad guys. Ill move it over. 
Maybe interesting to post this also into r/bashonubuntuonwindows
It was a long time coming, and an amazing feeling for it to finally land!
If you just need to increment you don't need to receive an answer.
Have a look at channels https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html or the crossbeam crate for sending data from one thread to an other. 
Does this make use of the new windows pty apis?
He mentions in the readme that alacritty strives to be simple. So no fancy features like tabbing usw. Even the scrollback functionality was previously considered to much for alacritty. For tabbing you have the option to use a wm or multiplexer like tmux or screen.
A CAS is often O(100) cycles so it is really slow too, depending on what you are doing.
They've been at the top for 2 or 3 years.
I really think that shipping rust binaries that work (well) on windows is a major milestone towards entreprise rust. If alacritty could demonstrate performance, reliability and maintenability/upgradability, then the rust workflow could soar amongst corporate users.
The thing is, these things don't exist on Windows. There are some kind of tiling wm, but they're buggy, and there is no terminal multiplexer at all. 
ConEmu?
Go's popularity was also thanks to Google supporting it. "If Google designed it then it must be good". Maybe for Rust to become a success, we also need some high-profile companies to start actively using and supporting it.
Apart from nesting.
That one is a terminal emulator, so you can't use alacritty with it. My point was that alacritty will need either tabs, either a working terminal emulator for windows to exist, to be really useful on windows (for powershell and cmd, cygwin and the WSL are a different story). All that said, I understand the philosophy of the project, and I do not expect alacritty to gain tabs, I'd prefer for a multiplexer to be created, based on the new [ConPTY](https://blogs.msdn.microsoft.com/commandline/2018/08/02/windows-command-line-introducing-the-windows-pseudo-console-conpty/) apis. 
Compiling for ARM, handling json and making https requests are very well supported and documented. Not sure about system stats and signing, I haven't touched these myself. 
Thanks!
Seriously? [https://github.com/hashicorp/hcl](https://github.com/hashicorp/hcl) &amp;#x200B;
Start tinkering! You won't retain anything if you don't put what you've already learned to use.
Can you explain to me how you’ve replaced JS with rust on the front end?
The one-per-scope can be fixed with the recently accepted RFC to allow `const _: ... = ...;` with the `_` for the identifier.
Hmmm i can't seem to open bash.exe.. How did you do it?
There is [nickel](https://github.com/nickel-org/nickel.rs) which states is inspired by Express. I'm not sure of developer commitment, since master last an update months ago.
Cmder?
Reminds me of st (suckless terminal)
Nice work! It must be nice seeing this land
&gt; usw German, presumably? :)
&gt; I'm persevering with rust partly because I set out on a quest to "learn things I'm not aware of" - although it WAS fixes to certain frustrations in C++ that got me into it - memory safety isn't one of them (it's all the other clunkiness like header files really). Same here. If C++20 gets modules, which is very likely, I don't think I will use Rust. The language is much nicer nowadays.
These are my completely arbitrary criteria for what are common and/or required properties in functional languages: * Support for [first class functions](https://en.wikipedia.org/wiki/First-class_function) and [closures](https://en.wikipedia.org/wiki/Closure_(computer_programming)) * Support for _ad hoc_ [function composition](https://en.wikipedia.org/wiki/Function_composition) and [chaining](https://en.wikibooks.org/wiki/F_Sharp_Programming/Higher_Order_Functions#The_|%3E_Operator) * [Currying](https://en.wikipedia.org/wiki/Currying) and [partial application](https://en.wikipedia.org/wiki/Partial_application) * Recursion and preferably [tail call](https://en.wikipedia.org/wiki/Tail_call) optimization * Controlled/limited/disallowed mutability, and tendency to use [persistent data structures](https://en.wikipedia.org/wiki/Persistent_data_structure) * Based on previous criteria: the viability to write code in a [point-free style](https://en.wikipedia.org/wiki/Tacit_programming) Rust supports many of those things, but arguably not to full enough extent or with a syntax that people want to use: * Rust supports first class functions and closures, and they are used quite a lot. However, they are [more complicated to use](https://stevedonovan.github.io/rustifications/2018/08/18/rust-closures-are-hard.html) than in functional (and/or garbage collected) languages. * Rust doesn't have any built-in mechanism for function composition or chaining. You can implement a `compose` function yourself (with some difficulty), but the lack of it in the standard library signals you aren't supposed to use it. * Rust doesn't have built-in support for currying or partial application. You can emulate partial application with closures, but it can get complicated because of borrow checking. * Rust does support recursion, but it's not used as much as in functional languages. LLVM performs tail call optimization, but it's not guaranteed and there's no way to do explicit tail calls. * Precisely controlled mutability is one of Rust's killer features, so in my opinion people actually use mutability more liberally in Rust than in languages where everything is mutable. Persistent data structures exist and are sometimes used, but once again they are not supplied in the standard library. * Based on previous bullet points: point-free style is possible, but generally not used because it can be more tedious to support and use than traditional imperative code. Parser combinator libraries like [nom](https://github.com/Geal/nom) get pretty close, but it's using a ton of macros to make it work.
Also check out http://exercism.io!
Doubtful. Other languages have the same advantage (C, C++, D...) yet they don't see widespread usage in some niches, typically because they are slower to write, harder to iterate on and very hard to train people on; which is something Rust suffers equally.
Nice, thanks. I'll check it out
Thanks for sharing your slides! :)
Not yet, it seems: [https://github.com/jwilm/alacritty/issues/1661](https://github.com/jwilm/alacritty/issues/1661)
I also regularly experience problems with a fullish disk due to exploded target directories. I think cargo itself could be more economical about using space, which I've proposed here: [https://github.com/rust-lang/cargo/issues/5931#issuecomment-417945478](https://github.com/rust-lang/cargo/issues/5931#issuecomment-417945478). &amp;#x200B; If you're going to write a utility for this that lives outside of cargo, for bonus points, replace matching instances of compiled artifacts across projects with hardlinks to just one of the instances. 
Y
IIRC: It's implemented, as the `const` evaluator is "just" MIRI, but it's gated so that it doesn't run.
Then it only works in statement position, not item position. That reduces its usefulness.
Could be because Python 3 is finally at critical mass? It feels like the language is finally moving forward again. The new optional typing is pretty good too.
I know the lint API exists, but it's still a way off of stabilizing. I'm more interested in ways to accomplish it in stable today, or that are small enough to realistically push into the next couple stables.
The target directory for one of my applications is 4GB. That's without running cargo build, only cargo check and release builds. I would love to see this reduced.
Fira Code (without ligatures) is not working for me. What font are you using here?
If ed25519 fits your use-case, then [ed25519-dalek](https://github.com/dalek-cryptography/ed25519-dalek) will be an excellent choice. If for some reason you need RSA, then I believe you'll have to use `ring` or OpenSSL binding.
As you said, the number of open tickets alone isn't really a good measure. The problems I've encountered with powerpc are ICEs, LLVM code generation errors, instruction selection problems, etc. These issues pretty much prevent generating binaries for powerpc. I've never encountered such issues when targeting any of the windows targets (`{x86_64,x86}-pc-windows-{msvc,gnu}`).
&gt; Rust again has too many specific ideas beyond what is needed to be that 'universal glue' . Far too many specifics, for sure. Though a few improvements could be made over C; e.g. I don't think any modern languages use null-terminated strings except for C compat. C++ header files are a big pain, and C++ has a bunch of other issues too (virtual functions not overriding a function in a parent class because you got the type signature wrong, arguments being implicitly copied unless explicitly moved, implicit conversions everywhere, lack of contracts in template programming, ...). Learning Rust is useful IMO even if the only things you take from it are an understanding of its lifetime and object/trait models.
I didn't know that we could panic inside const fn, that would work too. Initially I thought we could just evaluate an expression and then pass it as a constant to the proc macro which will panic. static_assert!(some_const_expr, "Error message");
Clean tree would be great for me, as I often have lots of little projects
No! We dont! Use tmux instead 
Not sure; it seems Python 3 users would have Python 2 users if Python 3 didn't exist. I *think* that it's got more to do with available libraries, especially in the new "hot" fields like machine learning, combined with the reputation that Python is easy to pick up.
Why does `Vec&lt;T&gt;` not implement `Response` for `T: Response`? I do not know how to return a `Vec&lt;Foo&gt;` with `Foo: Serializable + Response`.
&gt; Separate out routing via a “table of contents” approach, making it easy to see the overall app structure. I am very glad for this. What bothered me about the attribute approach that I believe Rocket uses (annotating functions with `#[get(...)]`) was that the routing table ends scattered all over the place, making it difficult to grok the layout. Another advantage of a pure Rust solution, of course, is the ability to generate part of (or all of) the routing table from a configuration file or a database at runtime. Sounds crazy? Think Django Admin: read the database schema, automatically handle CRUD operations.
On Windows?
I made xml parser in go from scratch. I was following this [tutorial](http://lisperator.net/pltut/dream) in JS. And now i decided i will write my own language in rust. I am somewhat inspired in implementation by [Rhai](https://github.com/jonathandturner/rhai) which is very simple scripting language in rust.
&gt; Another thing I've thought about before: there would be decent wins from just teaching `rustc` to read source code out of archives directly. This would work well with rustc: - There is no need to support dozens of archive formats; just settle on one. - I expect it's easy enough to intercept the "search/open" file in rustc, as the code should be relatively isolated. On the other hand, the debugging experience might plummet unless `gdb` (or `lldb`, ...) can *also* read the files directly from the archive. --- An alternative might be to keep only archives in the `.cargo` folder, as well as maintain an index of when each archive was accessed for easy clean-up (a `touch` of the `archive` might suffice). Then, in each `target` directory, unpack the archives needed, and use *that* as sources. Cleanup is then: 1. Remove `target` directory (`cargo clean`?). 2. Remove "old" crates in `.cargo` home (`cargo cache clean 30d`?), which coupled with the last-accessed date for each crate should only remove those not used for `30d`. 
Yeah you're right. Haven't thought about that. A terminal multiplexer a la tmux would be an interesting project. 
Personally, I recommend minifb. You have to manage timing yourself but you can make simple timer with std::time::Instant. Or you could use something like libretro. With libretro-backend crate you can crate a core and then use retroarch for frontend. It takes care of graphics, audio and savestates.
Had to look it up myself. https://jwilm.io/blog/announcing-alacritty/ &gt; Alacritty is a blazing fast, GPU accelerated terminal emulator. It’s written in **Rust** and uses **OpenGL** for rendering to be the fastest terminal emulator available. Alacritty is available on GitHub in source form.
&gt; On the other hand, the debugging experience might plummet [..] I think a good compromise would be to introduce a `cargo` command that makes uncompressed source code for a project available on-demand. I mean, in most cases, bugs are in *your* code, not your dependency's. Well, *hopefully.* But assuming that's the case, there's presumably far less need for the source code of dependencies. I wouldn't want sources extracted into `target` by default, because that folder is *already* absurdly huge.
Backslashes do not seem to work on a german keyboard. It seems like they keyboard layout is not respected at all or something.
Don't forget [Rust By Example](https://doc.rust-lang.org/rust-by-example/) and, when dealing with intermediate to advanced topics, the [Rustonomicon](https://doc.rust-lang.org/nomicon/) 
A lot (and I mean a lot) of cross-platform emulators use SDL. You could use a binding like [rust-sdl2](https://github.com/Rust-SDL2/rust-sdl2). It's not pure Rust, but it gets the job done. As for ensuring 60 fps, I would use `std::time::Instant` in combination with `std::thread::sleep`, as /u/Shadow0133 pointed out. The SDL timer subsystem is only millisecond accurate, which can cause inaccuracies.
+1 for minifb Its pretty easy to use and should be more than sufficient for a GB emulator.
yea im experiencing the same thing on a qwertz keyboard. nothing with alt + ctrl works, however it does work to copy a "\\" into it.
I've written a bunch of HCL configs and a bunch of TOML configs and I'll take TOML any day of the week over HCL.
I don't get this comment at all. I'd much rather use dotted names for deeply nested sections than a tangle of parens. Whatever, this is /r/rust, not /r/argueaboutconfigurationformats. I probably should've kept my snippiness about HCL off of the original comment. I just dislike writing those configs in it.
They've been driving a lot of big open source projects for a while. TypeScript is 6 years old now and that was driven to embrace open source from the start. Everything else is following suit. The other is that front end web development these days has to be open source, and Microsoft have been investing and embracing front end technologies for a long time.
so, what's stopping cargo from using a single folder with dependencies for all projects?
&gt; Then cargo wouldn't need to decompress the crate sources at all (unless it has a build script and doesn't explicitly note that it's OK with the crate staying compressed). I think a lot of tools using `cargo metadata` are also interested in the source code. So all of these tools would have to handle the compressed data.
Apparently you can [have tmux on cygwin](https://gist.github.com/zlalanne/8188248). And of course on WSL.
Is this trolling?
Hack.
If you're on Windows 10 1809 and willing to use WSL, you can run tmux and then execute `powershell.exe` within a tmux pane. I assume that this works because `lxcore.sys` or `lxss.sys` uses the ConPTY APIs now.
On the dependency thing, I know that [pnpm](pnpm.js.org) tracks all directory (workspaces) you use, and it can scan them to determine which dependency cache is useful. Which means, we don't need to wait 30 days, but simply triggering a prune will eliminate the redundant files.
Thank you for not using the word 'curated'
&gt; even if the only things you take from it are an understanding of its lifetime that stuff is nice but it doesn't each you something new - you needed a sense for it if you ever wrote a C or C++ program that allocates, deallocates regularly , passes references around, without crashing :) i DO definitely appreciate how much more elegant it is with Move semantics however! it's a better default. (now maybe i'm back on a high with it hah) &gt; (virtual functions not overriding a function in a parent class because you got the type signature wrong you're right it has a lot of corner cases like this to watch out for. I'll elaborate further: in particular I wanted UFCS to solve my big gripe - bouncing between free-function and method call syntax. (conflicting draws). so I liked Rusts idea of bolting traits on.. but then I found micro-managing the traits to also be annoying.. it's like you can't just think in terms of functions if you want polymorphism.. but at least you can *always* use the method call syntax safely. i like what i hear in the Julia language about not tying functions to one type.. but the "dot-call syntax" is a dream when combined with *dot-autocomplete* for discovery.. which we dont have reliable in Rust yet. (and this is why C++ has a conflicting draw. Overloaded free functions are my favourite default, but the methods become more useable with auto-complete. this choice is conflated unecaserily however coding for myself it isn't a problem. they're my classes, i can make them kitchen sinks if i want to ).
I published [atlas-coverage](https://github.com/samsieber/atlas-coverage) last week (got permission to open source it), a tool for traversing source maps while parsing code coverage from puppeteer to generate code coverage for the original sources when testing against minified js in the browser. I'm working on polishing it up a little - adding builds for releases (got linux working so far), an actual integration test, an example project setup using it, etc. Hopefully in the next week or two I'll open source a git synchronization tool written in rust, used to get around the manual intervention that subtrees and submodules need.
Don't forget [rustlings](https://github.com/rustlings/rustlings)!
I was wondering why enum MyEnum { One = 1 Two = 2 } is possible and enum MyEnum { One(MyType) = 1 Two(MyOtherType) = 2 } is not. Can someone explain this to me?
Still closed source underneath. Who knows which closed source backdoors are running: * In Minix directly on the Intel CPU. Closed source. * In the BIOS firmware. Closed source. * In the hardware drivers, used by Windows. Closed source. * In Windows itself. Closed source. * In any proprietary modifications to Ubuntu. Closed source. In this setup, the only thing you, the user, control is the very tip of the iceberg. Several companies and people control everything underneath.
&gt; On the other hand, the debugging experience might plummet unless gdb (or lldb, ...) can also read the files directly from the archive. They can be taught to, but GUIs/IDEs would need to know how to do it as well.
Lack of support for binary dependencies is a big pain regarding compile times and used space.
For example I only use platform languages for production code and right now Rust is not on any SDK of the platforms that our customers require me to use. 
On the latest Bjarne interview they mentioned that there was quite good progress during the additional meeting that took place at CppCon.
It is, the library is here: [polarization](https://github.com/zmitchell/polarization). The command line utility is here: [polsim](https://github.com/zmitchell/polsim). I’ll say that neither is completely ready for public consumption though, and there may be soundness issues with respect to the validity of the simulations at the moment.
I am just wondering, it would not be so hard to just allow users to determine the number associated with each tag (of the union) right? Or would that complicate things?
Neat. The default font setup looks pretty bad on my Windows 10 box. Can anyone recommend some tweaks?
For that I'd have to defer to someone with knowledge of Rust internals. I just know that the *idea* of enums of Rust are that it can be a type or a number, but not both.
It would take a decade or so to get there (real heavy-duty enterprise apps written in Rust) but it would be a helluva lot better than some hideous .Net/Java garbage that's out there nowadays.
Thanks for the response anyway! I appreciate it!
sure, it is basically based on wasm. Here is something to read (not from me) hope this helps you getting started or at least get some insides. https://rustwasm.github.io/book/introduction.html https://medium.com/@saschagrunert/a-web-application-completely-in-rust-6f6bdb6c4471 https://medium.com/@saschagrunert/lessons-learned-on-writing-web-applications-completely-in-rust-2080d0990287 https://github.com/koute/stdweb https://github.com/DenisKolodin/yew
Hooray! This is memorial number.
I feel dirty reading this. Kudos!
While there is no guarantee, my personal experience in implementing a game is that it's more accurate than `SDL_Delay`.
Is it possible to make cargo point to a private crate repository yet?
Congrats on the milestone and thank you for persisting! TWiR is one of my favorite Rust-related web resources -- I look forward to it every week.
I saw this was in TWIR but hadn't been posted here, yet.
I downloaded alacritty.exe, but when I try to open it, it just closes immediately. Is there anything else that is needed. &amp;#x200B; (tried on windows 7)
Note there are 2 artifacts, alacritty.exe and winpty-agent.exe. You need both since Windows didn't have native PTY until this month.
Yes: https://doc.rust-lang.org/cargo/reference/unstable.html#alternate-registries
&gt;crafty i ran the other one beforehand, and now it seems to work, thanks!
I've made me a nice struct `I` and implemented `Iterator` for it. I then proceeded to implement some special methods, say `warbl`. Now, I can call `warbl` on `I` of course, but the moment I use on of the fancy Iterator methods like `skip`, that won't work: Because skip produces a type `Skip`, and my fancy `warbl` isn't implemented for `Skip`. Now I could implement `warbl` for `Skip&lt;I&gt;`, but then I'd have to do that for `map`, `filter`, and the like. Is there an easier way to do this?
Hooray, we reached three digits! 😎🦀👍📈
It works for java (jar files are basically zip files with an optional `MANIFEST.MF` entry). As crates are already stored as `.crate` files, which are gzipped tar files, the format for Rust already exists, sort of.
Mutexes are slow if all your threads do is repeately locking and unlocking the same mutex. In this case, there is massive contention and you lose all parallelism. As long as threads do anything else besides locking/unlocking the same mutex, they are quite fast.
I prefer the explicit-ness of the first one, personally. Then, I'd do the final one. I wouldn't write the middle one, ever.
And I've gotten numerous books from there which have helped me a great deal. You're painting with a broad brush here. I've also gotten burned numerous times from Manning, O'reilly and Apress. That's why I always try to get it on sale. Packt sales are around $8 - $10, manning sales around $18, apress around $12. You take your lumps and you keep going. $10 isn't even 10 minutes of my billable time.
Actually, the `Ok(())` part is wrong (since, ya know, we must return a `Future`), but this code has the same outcome: extern crate futures; use futures::Future; use futures::lazy; use std::error::Error; fn foo() -&gt; impl Future&lt;Item=(), Error=Box&lt;Error&gt;&gt; { lazy(|| { Ok(()) }) } &amp;#x200B;
On Windows, it looks like both \[Rust's thread::sleep\]([https://github.com/rust-lang/rust/blob/db5476571d9b27c862b95c1e64764b0ac8980e23/src/libstd/sys/windows/thread.rs](https://github.com/rust-lang/rust/blob/db5476571d9b27c862b95c1e64764b0ac8980e23/src/libstd/sys/windows/thread.rs)) and \[SDL\_Delay\]([https://github.com/davidsiaw/SDL2/blob/b90a1cdaa54f998e759debae15f2479de610918a/src/timer/windows/SDL\_systimer.c](https://github.com/davidsiaw/SDL2/blob/b90a1cdaa54f998e759debae15f2479de610918a/src/timer/windows/SDL_systimer.c)) just call directly into the \[Sleep\]([https://docs.microsoft.com/en-us/windows/desktop/api/synchapi/nf-synchapi-sleep](https://docs.microsoft.com/en-us/windows/desktop/api/synchapi/nf-synchapi-sleep)) function from the Windows AI. On most versions of Windows, this function has the same resolution as the system timer: 15.6ms by default, or 1ms if \`timeBeginPeriod(1)\` has been called. I believe SDL calls \`timeBeginPeriod(1)\` by default. Windows 8 and later supposedly have a "tickless kernel" which could potentially improve the accuracy of \`Sleep\`... but since \`Sleep\` takes an integer number of milliseconds as its argument, you're never going to get better than 1ms resolution anyway, which isn't really good enough for displaying at exactly 60fps (16.6666...ms per frame). I believe most game engines either (1) ignore the monitor refresh rate and just use \`Sleep\` to approximate a frame limiter, with the understanding that this might lead to the occasional dropped frame or non-displayed frame, or (2) use vsync to synchronize exactly with the monitor refresh rate, by blocking when a back buffer is ready to be pushed to the swap chain.
These are good thoughts and definitely bring up some issues, so I see the trickiness. You could do a partially named enum type: \`(Miles(u32) | Kilometers(u32))\`. Although you lose some of the simplicity and ergonomics. Thanks for the response! &amp;#x200B;
To have an efficient cache you'll need to add a cache invalidation mechanism (LRU or timed). And wrap this in a lock so it will be threadsafe.
\`(Miles(u32) | Kilometers(u32))\` then leads to the question of how you otherwise refer to those names -- if you're calling a function that takes such a type, how do you construct those variants? How do you import them into another module?
I'd recommend taking advantage of [RetroArch](https://www.retroarch.com/) which is basically a generic emulator frontend which takes care of everything frontend-related for you (graphics, input, sound, etc.) so that you can focus on actually writing an emulator. &lt;shameless plug&gt; I have [a crate which allows you to trivially create a RetroArch core](https://crates.io/crates/libretro-backend). It's really simple - you just [implement a single trait](https://docs.rs/libretro-backend/0.2.1/libretro_backend/trait.Core.html) filling out the callbacks which RetroArch will call for you. You can see an example of it [here](https://github.com/koute/pinky/blob/master/pinky-libretro/src/lib.rs), which is a part of [my NES emulator I wrote in Rust](https://github.com/koute/pinky). &lt;/shameless plug&gt;
I only dabbled in trying to write a game for a few weeks, and my biggest lesson was to try and learn development styles from professional game developers before getting too deep. I started writing code how I imagined it would be represented in the game and quickly ran into lifetime and multiple borrowing issues. After that I watched the keynote talk from the Chucklefish developer and it was very enlightening. She started by showing sample code and saying "This is how an inexperienced programmer would probably try and create their game, but it just turns into a big ball of mud and will probably never get to a shippable state." My code was almost an exact duplicate of the code she showed, down to the same variable and object names. So I did some more reading on writing a game using an ECS and that style worked much better and didn't have nearly as many issues. There's also a presentation recently done by Unity devs where they cover using an ECS, and go a little more in depth on why using an ECS can make your game run much faster, at the expense of a little more memory.
This looks like a good place to start: https://crates.io/crates/lru
Why? My NES emulator [happily works in a WASM-powered canvas](https://koute.github.io/pinky-web/)... (: Although for a beginner it probably might not be that great of an idea, e.g. getting audio to work with acceptable latency *and* without stuttering is an absolute nightmare due to the fact that JS APIs for audio playback are so ridiculously horrible. (I got it *somewhat* working by using `requestAnimationFrame` for synchronization; unfortunately that breaks my emulator on machines with non 60Hz monitors, but I didn't really feel like wasting a week of my life trying random voodoo in hopes of finding another way to appease the JS gods to get sound which is neither delayed by a second nor stutters every hundred milliseconds, so, whatever ¯\\_(ツ)_/¯)
This is interesting. Could you file an issue on the repo to discuss further?
This seems to work: fn foo() -&gt; impl Future&lt;Item=(), Error=Box&lt;Error + 'static&gt;&gt; { lazy(|| { Ok(()) }) } `std::error::Error` is a Trait and sometimes you have to write `Trait + 'static` or `Trait + 'a` to specify whether or not the struct implementing that trait borrows from something or not. If that makes sense. In many cases it defaults to `Trait + 'static` but apparently here is one of the cases where it does not. 
I've looked into both of these packages and found a few features that are desirable! We've previously dabbled with Tokio but are looking into it more seriously now that we are sure we want a custom solution. Thanks for your help!
Thanks for the suggestion. I'm not sure that this is too applicable to our problem domain. That being said, I probably could've explained the desired package better in the post.
&gt; what are the use cases for garbage collectors in Rust? General graphs can have pointers (or IDs if you go that route) going every which way, so it's not clear which order things can be freed in. There's not a nice stack-like, nested hierarchy of lifetimes for nodes. For example, imagine an HTML DOM under arbitrary manipulation by Javascript, or a compiler IR under arbitrary manipulation by an optimizer. `Rc` is one solution here, but it means you have to know enough about the structure (or impose enough structure yourself) to know where to use `Weak`, or risk leaks. `Gc` means you can just treat "the graph" as one blob, like any other collection data structure, and trust that things won't be freed until you're done with them. &gt; how does this work, roughly? I haven't looked at the implementation yet, but I believe you're correct on what you describe. I suspect collection may also happen at other times, like allocation, or at least it could be done that way. The other major aspect of usage is rooting, which is automatic in languages with built-in GC like Go. `Gc`s are like shared references you can just pass around, but they are restricted by their `'root` lifetime to an explicit handle to the heap, which you have to create yourself via `letroot!`. These objects are where tracing starts from, so any `Gc`s derived from them have to go away before you can drop them.
Is there a video of this keynote around?
About 400 at a time, less during off-peak. I tried using actix, with the state being the hashmap, but I struggled greatly
Oh, nice one! I've been trying with `Error=Box&lt;Error 'a&gt;` and similar combinations (leading, of course, to syntax errors), since I've completely forgotten about the `+` construction.
I didn't go through the docs in detail, but is it thread safe, and can I loop through the cache to get all keys? The caches that I've used often lack iterators. I'll look at it in more detail over the weekend.
Can you tell me a bit more about how you're trying to access and mutate the data, and what you've already tried? Are position updates sent by the individual vehicles, or do you have one "worker" pulling in the most recent updates? Do the vehicles have integer ids? I have to admit I have no experience with actix, but I might be able to help if I know what you have and are trying to accomplish a bit better :) 
This could be incredible usefull, but I only vaguelly remember a paper about how extend unions: pub enum DataType { UTF8, Int32, Bool, None, } pub enum Dates:DataType { Date, DateTime, Time, } so you could match by Dates or DataType. The compiler just sugar the whole thing. From this, if you understand that algebraic data types are AND &amp; OR types, you wanna do SET operations on them! So: fn read_from_repo() -&gt; IOError or GitError I also think will be great if you could: pub enum Dates:DataType except [None] { Date, DateTime, Time, } and do things like union, difference, etc.In short? make the types a basic relational engine. This will fill a lot of holes for functional languages to look like OO and to reduce boilerplate. But add this to rust is probably not a good idea. I think this need to be from the start. 
You probably need https://redis.io/. Is not in-memory but incredible fast and reliable. &gt; Is a `HashMap` enough? Is, if you put a thread-safe communication channel and serialize the calls.
This is syntax and feature I'm dissappointed is missing when I'm handling errors especially. I'd love to see an RFC for this so at least we can hear "(why | whynot)".
Ooh thanks i tried running alacritty this morning couldn't get it running. But running the other program first and then Alacritty it works 
I think you don't get the point of that article. 
Correct, runs on v8.
Do I get a pass because it was my blog post? :p
Is there any practical difference, apart from pattern matching syntax, between these two enum variants? enum Foobar { Bar(), Baz, } Also, which should be preferred? 
From looking at https://crates.io/crates/libc it looks like the graph only shows the latest 5 versions and lumps anything older into "older"
The heavyweightness of .cargo is certainly a problem in certain setups, some users only have a small /home and suddenly a huge .cargo. If space is not a problem I actually prefer a .cargo per project/workspace, so it only contains the crates I ever used for a project and there is not a constant growing pollution from other projects. Reproducable builds/archival of Rust programs/projects is a must. Unfortunately redirecting ~/.cargo is currently not easy, for example the IntelliJ Rust plugin does have config options to specify a Rust toolchain in a custom directory, but has no options (yet?) to also redirect .cargo to somewhere else. Hacks with temporary symlinking .cargo have problems (https://github.com/intellij-rust/intellij-rust/issues/2466), so the only option is now to set a custom CARGO_HOME before starting IntelliJ and only work on one Rust project at a time?
[https://www.youtube.com/watch?v=aKLntZcp27M](https://www.youtube.com/watch?v=aKLntZcp27M) RustConf 2018 - Closing Keynote - Using Rust For Game Development by Catherine West
Oh, ok. Thanks!
There's a third possibility: if E1 | E2 implements all the traits that both E1 and E2 implement, then you can use them with a function that operates on those trait bounds, without the allocation cost that comes with a trait object.
why is it deeply unfortunate?
Please turn this into an RFC? I would love to see this kind of functionality.
Returning exceptions or Generic collections from functions are also fun. Powershell also requires a lot of experience and knowledge to write performant code. What other issues do you see?
And here I was hoping for a shoutout to the book from whence the name came
It's slower and more biased than extend+multiply+shift right.
So what does the proper solution look like? What should one write instead of `rand() % 100`?
I've noticed that making any changes at all to `RUSTFLAGS` causes a complete rebuild of the project, even I'm just switching back and forth between two different settings repeatedly. For example, when I'm benchmarking, I often want to do one run with `RUSTFLAGS="-C target-cpu=native"` and one run without. But each of those rebuilds the entire transitive dependency tree every time. Is it just a question of including the `RUSTFLAGS` in the hash? Or are there trickier issues here?
The problem is that you are **defining** the anonymous enum with _named_ variants and **using** it with _unnamed_ variants. If we are consistent in definition and usage, and use named variants in both, then we will be using `Miles` and `Kilometers` when constructing and destructing the values - and thus there will be no ambiguity. Another form of consistency is to use unnamed variants both in definition and in usage. In this case, the anonymous enum would be `(u32 | u32 | String)`. Seeing how ordering shouldn't matter, it's easier now to argue that `u32 | u32` is redundant - there is no meaningful difference between the first `u32` and the second one. It is now easier to argue that `(u32 | u32 | String)` should either be disallowed or collapsed to `(u32 | String)` (which I find preferable usability-wise - see [my comment](https://www.reddit.com/r/rust/comments/9ozl27/tuple_enum_types/e7y0ehr/))
&gt; Is not in-memory but incredible fast and reliable but &gt; Redis is an open source (BSD licensed), in-memory data structure store...
Ooohh, so basically if we represent heap topologically as a graph then unreachable subgraphs represent unreachable heap which obviously needs to be cleared. But then what if there are many unreachable subgraphs inside the whole heap graph? Wouldn't removing them cause memory fragmentation?
It would but that's no difference than if you allocate 10 blocks of memory then free the 5th one. The ways to get rid of fragmentation entirely are arena allocators and copying garbage collectors. You can also avoid fragmentation with a clever allocator but you can't prevent it entirely with just that. This is one area where a GC (so long as it's a copying one) does better. Of course the overhead for using a copying collector is that your program uses twice as much memory so... tradeoffs.
I didn't run your benchmarks, but I think you're paying for the initialization of the array. Even so, the numbers are surprising.
I've never seen `Variant()` used before, nor did I know that was even allowed. I'd just use `Variant` because that's what everyone else does.
Others have gotten to the main problems with that, but there's a few other things to consider. For one, if you mean using inheritance _to achieve composition_, that is indeed a valid strategy. It's pretty common in languages like Python, for example. e.g., it's basically noting that there's not *much* difference between: class MovingTowerUnit : Unit { AutoFire autoFire; Movement movement; }; and; class MovingTowerUnit : Unit, AutoFire, Movement { }; So long as your "mixin" types `AutoFire` and `Movement` don't inherit from `Unit` or each other, that works just fine. You still have problems with _slicing_, and now you'd have to deal with ambiguities, and you didn't solve any of the _other_ problems I noted that composition can solve for you, but it works. Multi-inheritance with the diamond problem is less about behaviors as Zeroth noted and more about data. If you multi-inherit a common base, you get multiple copies of its data, unless you use `virtual` inheritance. Which has to be at the top of the hierarchy, meaning you have to know that you _will_ multiply-inherit that base, meaning the "fix" is intrusive and requires modifying (potentially third-party) code. Plus, virtual inheritance implies both space and run-time overhead depending on implementation due to the need to add offset information to the vtable and for the run-time to consult that information and do dynamic offset calculations. Multiple inheritance thus can solve that _one_ problem, but it fails to solve others, and it introduces problems of its own _especially_ in a static low-level language like C++ or its ilk. It's not the solution you're looking for. :)
I've been using Microsoft products since early childhood. 2-3 years is definitely "all of a sudden" for me.
It scales much better then bat files and are more maintainable. But you still need to grog ps, and I personally think it's a mess. [Function return values](https://stackoverflow.com/questions/10286164/function-return-value-in-powershell) are funky, and parsing rules are unusual. Fx powershell will print "True" when you run this code: function Foo { return $True } function Bar { return Foo -and $False } Write-Host "Bar: $(Bar)" As a programmer, I find that pretty offensive. It's easy to fix once you [learn the quirks](https://github.com/PowerShell/PowerShell/issues/3241#issuecomment-343244816). And watch the encoding when mixing powershell with older cmd.exe utilities. Still, access to the .NET framework is awesome, and if you're into Azure (like me), it's virtually mandatory anyway so.
Rust 256?
I don't really know what "driven by Vue/React" means. Do they need some specific template format? If you just want to generate html, use any web framework and template library. My choice for that is actix-web + Askama.
The compiler can generally optimize div or mod by a constant into the faster version based on multiply and shift and such all on its own. What's wrong with `rand()%100` isn't a speed issue, it's a correctness issue (as I explained in the other reply).
Link to those top 100 crates in list format: [http://thume.ca/crates/](http://thume.ca/crates/)
I just meant that I'd be using one of those frameworks for the frontend. So the HTML that I would want to pre-render would be that produced by Vue, for example. I want to be able to use one of those frameworks but maintain the SEO benefits of server-side rendering.
A completed example of what this pattern can look like: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=2605f38f08525e8295786206df12b2fe](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=2605f38f08525e8295786206df12b2fe) &amp;#x200B; Here, we use a trait to provide a new method `iter.skip_past_bob()` for all iterators over a `Person` struct, so we can do things like `iter.map(some_closure).skip_past_bob()` for whatever iterator over `Person` you may have.
Fantoccini is a library to interact with a full browser - possibly a headless browser but a full one. This seems like a very heavyweight solution to prerender webpages though it would work in theory it is not the solution I would start with. You don't really need the rendering side of fantoccini at all so you might do better looking at a pure JS engine instead as that will be a lot lighter weight. But then you might still need to post process the assets as well. The easiest and likely most efficient solution at this stage is to make use of vue/reacts native SSR via node.js and using rust to cache/proxy the requests though this. Though if you are going down this route you could skip the proxy and just prerender the site to static assets and serve if via rust (or at this point any static web server) and then rerender pages or the whole site when the content changes (depending on how often this actually is). This is in a way what [netlify](https://www.netlify.com/) does so you might want to consider that if this is for a practical project as appose to a exploratory idea. There are a lot of static site generators out there that can be leveraged to do this including nuxt.js (vue based) and next.js (react based) that you might find more practical at this stage. I would love to see a complete web stack written in rust that can do SSR - but I do not think there is anything out there atm that is near stable on this front without being massively overkill like fantoccini (which is more geared towards testing/fully rendering pages in a headless browser). Currently the closest thing I am aware of is if [yew get ever ssr support](https://github.com/DenisKolodin/yew/issues/41).
&gt; And here I was hoping for a shoutout to the book from whence the name came There are a few https://github.com/withoutboats/shifgrethor/commit/5d714b37ad423e8f51878f4721bf2f7a482e9c9e https://github.com/withoutboats/shifgrethor/blob/master/src/lib.rs#L1
Maybe rendering was a poor choice of words, but what I meant by "rendering" simply outputting HTML. What I was thinking was having a headless browser generate the HTML that I want to serve back to the client. If (and assuming I can do this with that library) I'm doing it headless this way, would that still be a heavyweight solution? I am basing this thinking off of this article: https://developers.google.com/web/updates/2017/04/headless-chrome Which uses puppeteer to do the headless work I'm referring to. 
Just put your database on a ram disk?
I think `crossbeam` has some sort of nice concurrent hashmap.
Yes, of course changing RUSTFLAGS also may change the compiled result, so it also needs to be hashed/distinguished.
I think he meant local-in-memory (as in, the service he is writing will still need a network hop).
I did consider that, but shouldn't the initialisation cost be the same for the array regardless of the size of data going in or coming out of the buffer? So a Vec that would have to allocate more space should be slower than a fixed size array.
The problem with HashMap would be that it would only grow, as you'd need something to invalidate old entries. Possible solutions: 1) HashMap(key, value) + Vec&lt;(update_time, key)&gt; sorted by time. Lock HashMap with mutex for updates, have a thread that periodically removes older entries. Or skip that and just restart/wipe everything once a day or so. 2). Use Memcached, its perfect for this purpose, but out-of-process. 3) https://github.com/stusmall/ttl_cache. Expires old entries on insertion. What's your read and update rate per second?
Thanks! It should be fairly efficient indeed, some optimizations added across crates. It has been in production for almost a year now without issues. [MlesTalk](https://play.google.com/store/apps/details?id=io.mles.mlestalk) client is the main source of traffic.
Where performance isn't a concern, might a Gc'd heap be a 'nice' structure for various forms of application data (that might contain cycles)?
I just want to echo mdaffin on this. A co-worker of mine tried to do SSR with python for a react project, and it was a huge headache. Node is much better built for this purpose, and next.js comes with it out of the box.
Fixed!
&gt; BurntSushi &gt; BurntSushi &gt; BurntSushi &gt; BurntSushi &gt; BurntSushi
seems really good. a few typos, and early on, “let player_name = ...” should be “let mut”
So am I pretty much out of luck if I wanted to use Warp as my server, as well as have a decent SSR setup?
The bias is really only an issue if you're using 16 bit numbers or less though - with u32 you pretty much have a 1 in a billion chance of getting a biased output.
How does it impact compile times?
Thank you for the help. It looks like I probably have to get Node involved a bit more than I was originally wanting to if I want a relatively easy set up here.
/r/linuxquestions will likely be more help for you. Try putting `export PATH=$PATH:/home/hikikomareep/.cargo/bin` in your bashrc. You can learn Rust on Windows if that would be easier for you :) 
I just cast most thing before and after returning. Variables persist till you close the shell. Normally thet wouldn't be a problem, but if you change a New-Object definition there is a high change that the New-Object fails and you work with the old object. Anf if you use powershell classes you have to restart a new shell everytime you change something, if yyou dont you use the class before the changes and thats easy to forget. I hate that powershell promotes writing of ugly code. Powershell is much too lenient, to what you can do. And errors happen in ugly code. I saw many huge codebases, that hat -ErrorAtion SilentlyContinue defined globally or behind every second line. And guess what if something went wrong you have to guess where the error was.
haha, the frequency of that username was well noted in the audience q&amp;a!
What does your .bashrc look like? (Paste the whole thing to pastebin or a gist) and link it here)
I wrote a very simple Cargo subcommand, `cargo-cleanup` (`cargo-gc` is reserved but empty), which just reads a single `Cargo.lock`, notes the names and versions of all dependencies, then scans the Cargo source cache and prints all packages whose names are in the lockfile, but versions aren't. No automatic deletion yet, and quite rudimentary options. If there's interest, this could be developed further. The command is [published on crates.io](https://crates.io/crates/cargo-cleanup) and can be installed with `cargo install`.
No luck. :\~$ rustup doc bash: rustup: command not found &amp;#x200B; :\~$ bash bash: /home/hikikomareep/.bashrc: line 1: syntax error near unexpected token \`(' bash: /home/hikikomareep/.bashrc: line 1: \` # \~/.bashrc: executed by bash(1) for non-login shells.' &amp;#x200B;
Oh, it looks like somebody went down the node-pre-gyp route with a library using neon. [https://github.com/hone/heroku-cli-neon-hello-world/blob/master/binding.gyp](https://github.com/hone/heroku-cli-neon-hello-world/blob/master/binding.gyp) Thank you mentioning that in your post as well. I think between both paragraphs of your initial comment I'll be able to work something out! :)
&gt; '(E1 | E2) - (E1|)' will be equivalent to '(E2|)' only if there is no `E3` such that `(E3|): (E1|) and (E3|): (E2|)`
[https://pastebin.com/UeXTvJb4](https://pastebin.com/UeXTvJb4) Here it is as it stands now. No complaints when I run bash, but no access to rustup or other rust commands. &amp;#x200B;
Writing a Gedcom file to JSON parser :)
I'd caution against using that name in the software development space, as it's been in use for a number of years by a debugger from the Mozilla folks: - https://rr-project.org/ - https://en.wikipedia.org/wiki/Rr_(debugging) - https://github.com/mozilla/rr That having been said, I really dig the idea of a stand-alone tool that knows how to perform intelligent renames for various languages. Have you considered writing plugins for various editors/IDEs to use this once it gets far enough along? 
IMO adding/removing variants to a return type *should* be a breaking change! Why go to all the trouble of introducing exhaustive pattern matching if you're going to disable it?
Hi, I started making a crate that makes managing the `~/.cargo/` cache easier a while ago, you can check it out here: [https://github.com/matthiaskrgr/cargo-cache](https://github.com/matthiaskrgr/cargo-cache) You can automatically remove the extracted sourcecode archives and removed git repo checkouts (both can be recovered without network access) via `cargo cache --autoclean`, if you want to remove the entire cache, you can run `cargo cache --remove-dir all`, there are a couple more options documented in `--help`. Have fun! :) I'll try to get an official release out before end of this year (so far just squatting the crates.io name)
Here's another video which discusses some other ways you can organise your code: [Is there more to game architecture than ECS?](https://youtu.be/JxI3Eu5DPwE]
I have to ask: where does the name come from? It sounds like a monster from a Conan story.
You need to embed a javascript run time in order for it to work, so it won't be easy. If you really want a rust side of things, you can do a node server for rendering, use warp as your business logic backend, but that is also a more complicated architecture.
It's always possible, it's just a matter of how much overhead in runtime performance and programmer pain you're willing to endure.
How does the generic case work? fn either&lt;Left, Right&gt;() -&gt; (Left | Right); If you require `Left` and `Right` to be distinct you're introducing post-monomorhpizing errors, and if you collapse you're losing information and creating some interesting layout questions to solve.
Yeah it does seem that it will complicate things unnecessarily. Oh well. I'll just look for opportunities to let Rust handle particular services perhaps and let Node do its thing in JS-land.
Using static mut is just asking for data races. In this particular case thinking about what happens when you call has\_tokens() with the same person\_id at the same time from two different threads. Now maybe this can't ever happen based on your other code, but you unsafe boundary is still in the wrong place. If safe code can cause the function to do unsafe things then the function is unsafe regardless of whether it actually happens. This is more of an issue with bad practice than code correctness though. The only place you should put an unsafe block is when you know that the current state of your program cannot cause unsafe behaviour within that block. In this case, you need to mark the whole function unsafe and have code somewhere that ensures has\_tokens can only be called by one thread at a time, and only within that code would you use an unsafe block after having checked that only one thread was calling it. Everything between has\_tokens() and the safe wrapper should be unsafe. There's also a risk of undefined behaviour but I'm not familiar with the exact rules regarding static mut because it's best to just avoid it.
I originally marked the function as unsafe but it made me wrap the if block in unsafe which was annoying me because I have to put it at a the start of every route handler and I didn't like the repetition.
I am not an expert but this seems like what `memcached` is for.
Hello and good evening. I have a `HashMap&lt;String, Vec&lt;String&gt;&gt;` and I would like to do the following. Given a _key_ and a _value_, I would like to add a new vector `vec![value]` with key _key_ to the hashmap, if the hashmap doesn't contain the _key_. If the hashmap contains the _key_, I would like to add the _value_ to the vector with key _key_. This is the best I could come up with. It works, but surely there must be a better way how to do it in one match? fn add_to_department(company: &amp;mut HashMap&lt;String, Vec&lt;String&gt;&gt;, dept: String, name: String) { match company.get(&amp;dept) { None =&gt; { company.insert(dept, vec![name]); return; }, Some(_) =&gt; (), } match company.get_mut(&amp;dept) { None =&gt; (), Some(v) =&gt; { if !v.iter().any(|existing| existing == &amp;name) { v.push(name); } }, }; } 
This doesn't answer the question, but I'm reminded of (Pony)[https://www.ponylang.io/], a really interesting little language with a type system that lets you do this. for example: `actor Main new create(env: Env) =&gt; let a = foo() let b = bar() env.out.print(test_match(a)) env.out.print(test_match(b)) fun foo(): (String | None) =&gt; "foo" fun bar(): (String | None) =&gt; None fun test_match(baz: (String | None)): String =&gt; match baz | None =&gt; "*crickets*" | let s: String =&gt; s end`
You could just use `ggez` and create a new buffer each frame from `Image::from_rgba8()`. It's hardly the most efficient way possible, but it should be more than enough for a GB emulator.
I agree that using an external tool would make more sense that integrating any functionality into cargo or rustc. People concerned with disk usage would add one line to `.bashrc`, and a tool like fusecompress would handle all the compression/decompression.
&gt;it made me wrap the if block in unsafe which was annoying me because I have to put it at a the start of every route handler And with good reason. If the function isn't safe then you shouldn't be able to call it from a safe context until you've ensured it's safe. If you just put an unsafe block where it doesn't belong then you're throwing rust's safety guarantees out the window. Unsafe blocks are a way of telling the compiler that you know what you're doing and the thing inside is actually safe due to runtime checks even if it doesn't appear to be at compile time. If you lie to the compiler and put an unsafe block in the wrong place you haven't solved the problem. You've just hidden it.
Is there a way to blanket impl a trait for Send + Sync types, then blanket impl that same trait for non send/sync types? (Such as implementing a trait one way for *mut T vs T)
Does it result in different compiler code? I think I'm okay with it being technically bad because the repetition really annoys me.
&gt;I'd recommend running cargo install cargo-expand and then cargo expand in your project (I think it requires nightly?). This will show you all the code generated, and you can see exactly how the Deserialize implementation works. It'll replace things like ? with match statements too, but that shouldn't make it too unreadable. Ooooh I never heard about that before. I have loads of very short Rust code examples that I play around with in order to help me understand/learn Rust better and this is gonna be super helpful! But back to the actual question. I'm gonna put this in ELI5 terms. So toml parses the toml-files and hands over the data to serde in the already correct format. If there are any errors with the toml file it propagates them so i can actually catch them. But how is that a good thing? If there are errors I will still have to catch them. Let's take your example from earlier and say a user puts in a string where there should be a list. I need to handle this error either way. I need to print out something like "User, you did something wrong in your toml file -&gt; fix it!". So no matter if I use serde or not I will have to catch and handle that error. How does serde help here then? What about my thinking process is incorrect?
Oh that's interesting. Just moving the unsafe keyword from wrapping the function to wrapping its contents does that? I'm actually really curious now. Could you elaborate a bit? Sounds interesting.
It won't change the code (AFAIK), but incorrect code is incorrect regardless of where you put the unsafe blocks. There's nothing saying you can't abuse unsafe like this, but it's a terrible practice and I wouldn't trust a codebase that has it. If you want a cheap easy way to make the code safe, have a look at using [lazy\_static](https://crates.io/crates/lazy_static) with a mutex containing your table of tokens.
Apparently it's [from a book](https://en.wikipedia.org/wiki/The_Left_Hand_of_Darkness#Shifgrethor_and_communication).
I highly recommend reading [The Rustonomicon](https://doc.rust-lang.org/nomicon/) for stuff like this
I think the best way to do this is run a Rocket server to manage the database, logins etc with a REST API, and run your Vue/React as a decoupled SPA. If you're feeling extra Rusty, you could mix Rust/WASM into the SPA-side too.
Well, I'm working on learning the basics of building out an API with rust, and I'm trying to build a api for storing contact information. I'm going to be building in links between contacts, and I am going to try to figure out how to do a "graph" api with it, so you request exactly what you want then get it without over or under requesting.
Mmm... I was thinking of `E1`, `E2` and `E3` as regular, currently existing types - but you are right, I did use them in both forms through my examples so I...
So a request to mysite.com/home would be talking to the node SPA server, and any requests that involve data would hit the rust server? Won't the SPA component need to talk to the Rust server to get the data it needs in order to do SSR? If you could expand a bit on the decoupling that would be great. How would this architecture look?
The main failing at the moment is the lack of a simple way to create a `.msi` installer. Unfortunately not a simple fix.
It currently only supports opentype fonts on windows because of limitations of [RustType](https://github.com/redox-os/rusttype). There are plans to switch to font kit on all platforms.
It can run on the same machine though, the loopback interface should be more than fast enough for this application. It's of course not in your own process' memory but it would be a good first solution attempt.
Definitely collapse - the whole point of collapsing is to allow generics where anonymous enum types may overlap. The loss of information is irrelevant because when you use anonymous enums you usually want to lose that information (in the main usecase - error handling - we want to flatten the error types and avoid nested `Result` structures) and if you do need to distinct different types of the same underlying type - that's what regular enums are for! As for "layout questions" - if you are referring to the memory layout of the value, the compiler will have all the concrete types so I don't see how it's an issue. A more interesting example would be this: fn foo&lt;Left, Right&gt;(bar: (Left | Right)) { match bar { left: Left =&gt; {/*...*/}, right: Right =&gt; {/*...*/}, } } Which branch should be executed? I'm not sure if my idea is ready for an RCF yet - maybe a pre-RFC to discuss all these issues... 
Not a quick fix unfortunately, see [details here](https://github.com/jwilm/alacritty/issues/1673).
This is exactly the case the entry API was designed for: company.entry(key).or_default().push(value); The `.entry()` finds the place in the map where `key` should belong, then `.or_default()` inserts an empty `Vec&lt;String&gt;` there if it doesn't exist and returns a mutable reference to the `Vec` which, finally, we push `value` to.
It's trivial to get it right, but since \`rand\` uses rejection sampling, you end up with non-constant and theoretically unbounded runtime. That's not a failure of \`rand\`, rejection sampling is the correct way to do this. &amp;#x200B; However, for a game, it's likely that you don't mind a tiny bit of skew, but you need absolutely predictable runtime.
I think in the context of this thread "in-memory" refer to inside the thread of the aplication, not how is redis implemented :)
&gt;My last reason is that even with valid data, using a typed structure protects from typos. If you're accessing the data dynamically by name, server["ip_address"] will compile just as well as server["ip_addr"] and server["ip"]. If you have the structured data, though, only the correct server.ip will compile since ServerConfig has no ip_addr or ip_address field. Ahhhhhh that actually makes sense. And I actually see the benefit in that compared to simply parsing data with toml. Awesome! &gt;I guess the most important thing I've found it useful for is "separation of concern". Your configuration module cares about configuration formats, user errors, and everything necessary to get a fully valid configuration. Then the connection module only has to care about connecting to servers- it doesn't have to know what to do when a user configuration error occurs because it gets the data fully valid from the config module. That is exactly what I'm planning to do. I have one "module" that only handles getting/managing the data from the config file including handling any error that might appear in the process. And it appears as if serde is going to save me loads(!) of lines of code. Very nice. THANK YOU so much for explaining this to me. You went way out of your way and I appreciate it! As I already mentioned it is super important to me to know what's going on in the background. While I'd still want to know more details about serde, I have at least understood what it actually does and why that's a good thing. I'll look into it more! Thanks!!
Can this somehow be replicated with rust macros? The enum definition can probably be extracted from the function body and be given some logical symbols for itself and it's variants. Then on assignment/returns the value would be wrapped with the new enum variant that matches the type (having multiple possibilities would cause an error here). Then at the call site, you'd need another rewrite mechanism. If the type name created in the background for the enum contains all the info about the variants, it's probable that this can be implemented with macros... but the order of macro expansions would matter.
I'd see little trouble in renaming this new project `rere` :)
I'm thinking about switching to nightly to use AtomicU8, but that would still be unsafe, just less so. Why do you think the safe version would be as performant?
I try to simplify this. If I have: [1 2 3] [4 5 6] and wanna say "each [] is a row" then I can get fn row(self, pos:usize) -&gt; &amp;[i32] but also wish to have: fn col(self, pos:usize) -&gt; &amp;[i32] as have a slice into the internal data for both directions. However one direction data is contiguous and the other not (using vectors) I thinks this is not posible. So I have instead: fn row(self, pos:usize) -&gt; &amp;[i32] fn col(self, pos:usize) -&gt; Vec&lt;i32&gt; However, the thing is that if I reverse the situation, now I get: fn row(self, pos:usize) -&gt; Vec&lt;i32&gt; fn col(self, pos:usize) -&gt; &amp;[i32] This is ok, I can create a custom operators per storage, but now I can't have a generic trait. I must make both look like: fn row(self, pos:usize) -&gt; Vec&lt;i32&gt; fn col(self, pos:usize) -&gt; Vec&lt;i32&gt; So defeating the potential advantages of each storage. Using rows, allow to be better (and easy) to scan the table by row, CRUD operations, SETs operations, etc. And using columns, scan (some) column, filters, agregates, projections, etc I wish to a have a universal API to operate on relations and let each struct to deal with the internal logic in how implement it. This mean, I have a trait: pub trait Relation { fn count(&amp;self) -&gt; usize; fn row(&amp;self, pos:usize) -&gt; Row; fn col(&amp;self, pos:usize) -&gt; Column; fn cell(&amp;self, col:usize, row:usize) -&gt; &amp;Scalar; //more... } and then I wish to make things like: CityColumns JOIN CityRows ON city_id 
You... I like.
Glad to help- and I'm glad my explanation for how typed data helps makes sense!
Some thoughts on deduplication (specifically ignoring level collapsing): I think it would probably be OK to have `(T | T)` _behave_ the same as `(T | !)`. When you match using type ascription in patterns, you only can grab the one thing out, anyway: match cotuple { t: T =&gt; { .. } t: T =&gt; { .. } // unreachable } And if you have two different types, `(Left | Right)`, you can "do the right thing": match cotuple { left: Left =&gt; { .. } right: Right =&gt; { .. } } If you want to require `Left != Right`, that's unexpressable in Rust, and you're out of luck. It'd require post-monomorphization errors, which are something that we specifically want to avoid. The problematic example: fn evil&lt;A: Debug + Default, B: Debug + Default&gt;() { let bogus: (A | B) = if rand::random() { A::default() } else { B::default() }; match bogus { a: A =&gt; { println!("Got A: {:?}", a) } b: B =&gt; { println!("Got B: {:?}", b) } } } Thus, a post-monomorphization `(T | T)` would have to be represented as `(tag, union{0:T,1:T})` to "do the right thing" here. But we could still _lint_ against `(T | T)` where `T` is known. If we want to require it, though, we need to add a concept of distinctness to the type system, which is a whole other can of worms.
You can try having [generational arenas](https://crates.io/crates/generational-arena) behind a [faster mutex / rwlock](https://crates.io/crates/parking_lot).
Filed https://github.com/rust-lang/rust/issues/55170 referencing this thread.
The crate can be depended on as a regular library-only crate can, and `cargo install` will act as normal on the binaries. It's just like publishing a library and binary crate separately, except they have the same name. `cargo install` won't be necessary to install the library, and the binaries will be ignored when depending on the crate as a library.
Along with what the others are saying about the unsafety of this, I think this is also a case of premature optimization. I think you are vastly overestimating how much time something like redis would take, and in most use cases you are dealing with a database regardless. You are probably better off going with a basic way of implementing it. Then if you feel like your thing is too slow, then you can do some performance analysis, which importantly involves measuring each part of your system, and then applying optimizations to the slow parts. With code like this, measurements are the gold standard of finding what is actually slow and what you simply think will be slow.
FWIW, this is what I get with the SmallBuffer test: test small_buffer_write ... bench: 1,014,929 ns/iter (+/- 167,559) test small_buffer_write_tiny ... bench: 0 ns/iter (+/- 0) So it looks like the write_tiny case is being entirely optimized out. This happens for all sizes &lt; 38. Funnily enough, this doesn't happen if I abstract the benchmarks like the following: ``` fn do_one&lt;T: Default + Write&gt;(b: &amp;mut Bencher, payload: &amp;[u8]) { let payload = test::black_box(payload); b.iter(|| { (0..10_000).map(|_| { let mut buffer = T::default(); buffer.write(payload); }).for_each(|_| {}); }); } #[bench] fn small_buffer_write(b: &amp;mut Bencher) { do_one::&lt;SmallBuffer&gt;(b, &amp;PAYLOAD); } #[bench] fn small_buffer_write_tiny(b: &amp;mut Bencher) { do_one::&lt;SmallBuffer&gt;(b, &amp;PAYLOAD_TINY); } ``` (which makes it less repetitive to implement the benchs for the other structs ; note I added an impl Default for SmallBuffer that uses SmallBuffer::new) Checking the benchmarks under perf shows that malloc and free account for more than 40% of the time spent for SmallBufferV and SmallBufferBM. My guess is that the rest of the difference comes from the indirection (Vec and BufferMut contain pointers to their buffer, while in the Array case, there is no indirection)
The possibility of rejection and reroll is basically as small as the chance that you get the unbalanced result, so if you don't mind a tiny bit of skew then you clearly don't mind a tiny possibility of a hiccup in execution. The OS is gonna do worse to you just by it existing at all.
First, `Vec&lt;i32&gt;` is just as contiguous as `&amp;[i32]`... it just owns the data it's pointing at, so it can do a reallocate-and-copy if it needs to grow beyond the allocated space. That's why getting a slice of a `Vec` is so efficient. You're just using the borrow-checker to lock out length-changing modifications of the `Vec` for the lifetime of the slice and then taking a `pointer+length` describing some subset of it. It sounds like you want an API wrapper which exposes the functionality but hides the implementation. For example, having `row` and `col` both returns something that implements either `Iterator` or `IntoIterator`.
One big reason is that you're violating the best practice of profiling before you optimize. It's extremely likely that your code will spend most of its time waiting on the database or some other I/O source and you may never encounter a need to optimize this in the lifetime of the project.
You should go ahead and delete this post.
OCaml has this with polymorphic variants: https://blog.klipse.tech/ocaml/2018/03/16/ocaml-polymorphic-types.html
You could put a reverse proxy (nginx, haproxy) in front of your API servers and get a whole lot of features including rate limiting for much less work. Learn to be lazy :).
CONGRATULATIONS ON HITTING 8!!
But that is something [I am planning on looking into](https://github.com/rust-lang-nursery/cli-wg/issues/8)
This week in Rust 1
Yes, optimizing startup time was an explicit non-goal for Java. Effort was made to ensure their key benchmarks focused only on hotspot performance without being effected by startup time. To improve startup time, tools like Nailgun can be used so that we only have to pay the JVM startup cost once (though at the expense of having a JVM lying round hogging memory). These days, there has been some effort to trim the JVM startup time slightly.
No, but it allows someone to modify only safe code and cause undefined behavior by doing that. Code that allows someone to do that _is unsound_, and fundamentally break's rust's safety guarantees.
And once [this PR gets merged](https://github.com/rust-lang/rust/pull/55173), you'll get a slightly better error: error[E0106]: missing lifetime specifier --&gt; src/lib.rs:6:44 | 6 | fn foo() -&gt; impl Future&lt;Item=(), Error=Box&lt;Error&gt;&gt; { | ^^^^^ | | | expected lifetime parameter | help: consider giving it a 'static lifetime: `Error + 'static` | = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from
 let secret_number = rand::thread_rng().gen_range(1, 101); That's according to the guessing game tutorial in the Rust Book. https://doc.rust-lang.org/book/2018-edition/ch02-00-guessing-game-tutorial.html
 let secret_number = rand::thread_rng().gen_range(1, 101); That's according to the guessing game tutorial in the Rust Book. https://doc.rust-lang.org/book/2018-edition/ch02-00-guessing-game-tutorial.html
If you want to to in-memory and not use an external service such as redis or mecached, you can take a look at this crate [https://docs.rs/chashmap/2.2.0/chashmap/](https://docs.rs/chashmap/2.2.0/chashmap/) which implements a HashMap that conforms to the same API as Rust's hashmap but allows concurrent accesses and does fine-grained locking with reader-writer locks.
Awesome!
Thanks for pointing this out! I think I will rename the project to "refren" for refactor/rename. This name has an additional useless advantage of having a meaning in Polish (chorus, refrain). &amp;#x200B; About IDEs - I haven't thought about it yet, as I was not sure if the tool is likely to have actual users, but yeah it makes sense. I'd probably start with vim, it should be the easiest to integrate and most needed there. Actually this "refactor/rename" subtitle comes from JetBrains IDEs, which has "rename" under "refactor" in the context menu :)
The target directory of rustc is ~30gb, stage 1 only.
Removing is definitely a breaking change, but I don’t think so about adding. (Only speaking about Error Enums) Most of the time Errors are just passed through. There aren’t many errors which you are able to recover from in the first place. It is likely that you’ll end up matching on 2 or 3 Variants and have a catch all for the other variants, witch you can’t recover from. IMO adding Variants to an Error enum is not a breaking change, because it would mean something has not worked previously (correctly). So why ever the new behavior is, it won’t be worse than before. You aren’t disabling exhausting pattern matches, but forcing the user to use a catch all. With that the pattern match will be exhausted even if some variants are added.
This is a great example! However, I think the two sensible options here is to either throw a compiler warning/error: "Overlapping types", or to disallowing matching on a union type. &amp;#x200B; Here, Error1 isn't a type itself, it's just an alias, so the example is really: let error: (io::Error | ConcreteError1 | io::Error | ConcreteError2) = ..; match error { error: (io::Error | ConcreteError1) =&gt; { .. } error: (io::Error | ConcreteError2) =&gt; { .. } } } Written like this, the problem becomes more apparent than hidden behind aliases. The first key observation is that match does not (to my knowledge) support matching on multiple alternatives in the same branch today? (I.E. given `enum {A(u8), B(u8)}` you cannot match `A(x) or B(x) =&gt; ...`). If this functionality is to be added, to avoid the above problem, it must disallow/warn when options overlap across branches. And the functionality itself is not required to work effectively with union types.
A chocolatey option would be nice, then i can just add it to my chocolatey "get up to speed after a windows reinstall" script. 
Shoot. Ok, thank you. Since the functionality ggez offers is \_almost there\_, is there a way to implement std::ops::Add for ggez::nalgebra::Point2 myself? I know this violates the orphan rule at first glance. Aside from using my own trait to implement basicallyAdd() to Point2, can I do something craftier? i was trying to do the following: 1. Define trait X with function basicallyAdd 2. Implement X for Point2 3. Implement std::ops::Add for all implementors of X by calling basicallyAdd Point 3 is where I got stuck. Is there a way to do this or is it prohibited? It would solve my problem I suppose, as Point2 would implement + so long as I have X in scope.
Why would an implementation of this using atomics need *any* unsafe code? Atomics are the answer.
There isn't a way to implement `std::ops::Add` because of, as you mentioned, the orphan rules. If you were allowed to do this, another crate besides `nalgebra` could do the same and then there'd be conflicting implementations. Even with an auxiliary trait, you'll run into the same issue- two different crates could be defining `Add` in terms of different auxiliary traits. Blanket implementations like `impl&lt;T&gt; Add for T where T: X` work even when `X` is not in scope, unfortunately (though even if it required it to be in scope, you'd have the same conflict since a downstream crate could `use X` and `use Y` for a similar trait in a different crate doing the same thing and still get conflicting implementations). The only way I know of to tack on implementations like this is to make your own wrapper of `Point2`, doing something like `struct Point2WithAdd(pub Point2);` then implementing `Add` for that struct. You'd have to wrap points whenever adding and unwrap them after, though, so it's probably not worth it. The best possible thing is probably just to define a method `.add()` in an a custom trait and then just to call that method rather than using `+`.
The "Allow non-ASCII identifiers" RFC proposes that all Rust identifiers be normalised to [Normalization Form C](https://en.wikipedia.org/wiki/Unicode_equivalence#Normal_forms); that is, to prefer pre-composed characters (like U+00E9 LATIN SMALL LETTER E WITH ACUTE) over de-composed characters (like U+0065 LATIN SMALL LETTER E followed by U+0301 COMBINING ACUTE ACCENT). There are many more possible combinations of base characters and combining characters than pre-composed characters in the Unicode standard, so even text in NFC has to deal with proper combining character support. On the other hand, text in Normalization Form D always uses combining characters, so it's at least consistent. As I understand it, NFC is mostly useful to ensure text can round-trip from a legacy encoding, through Unicode, and back. Since Rust works with Unicode natively, that doesn't seem like much of an advantage. If the compiler is going to spend time and complexity on normalization anyway, why not use the non-legacy NFD?
I'm not familiar with either language, but one difference I notice is that the standard implementation of Idris uses a garbage collector, while the standard implementation of Formality doesn't.
I updated the array version to use `uninitialized` and `clone_from_slice`. Reading the source for `clone_from_slice` it just loops over the source and calling `clone_from` but I can also see from the source that this causes an optimisation using memcpy. These benchmark results are vastly improved (though there is unsafe code in there now). small_buffer_read ... bench: 209,359 ns/iter (+/- 34,729) &lt;- small_buffer_read_v ... bench: 329,211 ns/iter (+/- 59,423) small_buffer_read_bm ... bench: 380,842 ns/iter (+/- 11,747) small_buffer_read_tiny ... bench: 171,617 ns/iter (+/- 28,585) &lt;- small_buffer_read_tiny_v ... bench: 298,876 ns/iter (+/- 6,066) small_buffer_read_bm_tiny ... bench: 354,794 ns/iter (+/- 48,352) small_buffer_write ... bench: 52,604 ns/iter (+/- 2,461) &lt;- small_buffer_write_v ... bench: 195,899 ns/iter (+/- 13,910) small_buffer_write_bm ... bench: 258,277 ns/iter (+/- 41,630) small_buffer_write_tiny ... bench: 47,611 ns/iter (+/- 3,043) &lt;- small_buffer_write_tiny_v ... bench: 166,917 ns/iter (+/- 3,427) small_buffer_write_bm_tiny ... bench: 234,466 ns/iter (+/- 14,955) I am interested in how you found that most time was spent in `__memset_avx2_unaligned_erms`? Thanks for looking at it! 
That's `0b100`, not `0x100`.
&gt; I only read every few seconds, on average every 7 seconds. I write less frequently in general With such low rate it really doesn't matter what you use, anything will work. 
fastmod looks more mature and feature rich to begin with, but I also think the intended use case is slightly different. fastmod seems to have no specific code change in mind, whatever can be expressed with a regex. This is more flexible, but the specific rr's use case can't be (easily) expressed with a regex.
Alacrity seems not to read `~/.alacritty.yml`
I'm still in the early prototyping as well. The mutable data is described in the bittorrent protocol extension BEP44. Mutable or not, I think it should be possible to share a virtually identical implementation of the routing table. The mutability part really only affects the validations done in STORE and FIND_VALUE, afaict.
Honest question as someone who hardly knows Haskell and doesn't know Idris, Formality or similar languages: why are all these languages using Haskell-like syntax (or LISP even)? Is there a fundamental problem stopping us from writing a fully dependently typed language with Rust-like syntax? I mostly talk about type and function declarations (without function body, because yeah, that's probably a lot different in a fully functional language).
If the project name means something completely unrelated in any language, it's a good one!
&gt; that stuff is nice but it doesn't teach you something new - you needed a sense for it if you ever wrote a C or C++ program that allocates, deallocates regularly , passes references around, without crashing :) This is true to some extent, but for example Rust makes the relationship between containers and their iterators clearer. This can potentially be taken further (assurance that callback functions can only be used while their data is still live). &gt; bouncing between free-function and method call syntax I don't usually find that a problem — most functions intuitively belong to *some* object. Sometimes this is a bit weird (`x.min(y)`) but very often it works fine. Still, you can pretend everything is a free function with UFCS if you prefer. Dot auto-completion... potentially useful but by now I'm sufficiently used to using a less smart text editor (Kate, which has limited autocompletion) and an API reference that I don't miss it.
You hardly begin in this subject with a dependently typed language, you generally begin with a statically typed functional language, and those use Haskell/ML syntax. So a reason is that people familiar with the needed concepts (the target audience) are already familiar with this syntax. It's pretty much the same reason Rust uses C-like syntax: the audience is familiar with it.
Works and looks much better (and is shorter, too)! Thanks a lot!
Given that rust types do not have a fixed layout, what would it even mean to have a number associated with each tag? For example, all of `bool`, `Option&lt;bool&gt;`, and `Option&lt;Option&lt;bool&gt;&gt;` take up one byte, with `None` being represented by different values in two latter cases. `Some` case doesn't even have a number - when value is not the one that represents `None`, then that same byte is value contained in `Some`. And this might be different for other types contained in `Option`, like `Option&lt;&amp;T&gt;` having `None` represented by 0, while previously it was 2 or 3 (at least with the current stable compiler).
You should read about the modulo bias: https://stackoverflow.com/questions/10984974/why-do-people-say-there-is-modulo-bias-when-using-a-random-number-generator
&gt; Thanks to [Pascal Hertleif](https://users.rust-lang.org/t/twir-quote-of-the-week/328/565) for the suggestion! There seems to be an error with the QotW attribution: it looks it has been copy-pasted from last week.
The `add(a,b)` function is really weird. It matches on `a`, fine, but then that match returns a function that is immediately invoked. It's almost like JavaScript's immediately-invoked function expressions, but in this case seems completely unnecessary. And if such a simple function needs that kind of bloat, I fear that doing even mildly complex things may be really tedious.
On some level, Haskell syntax is better for these things. When your most basic operation is function application, you want that to be syntactically as light as possible. The other stuff then kinda follows.
This looks great, but it does suffer from the OpenGL problems with macOS Mojave, doesn't it? I tried the noise example and I get a window filled with random noise. But the noise is only drawn once, despite the loop seems to update the buffer.
I think despite the ECS craze, it's important to keep a cool head. Most of the games released on the market aren't using ECS, most of the great hits of the past weren't done with ECS. While it seems that it's the only way forward for games, I wouldn't count traditional OOP and inheritance out just yet.
You want /r/playrust
On steam 
A good talk but he sort of doesn't really explain an ECS at all. He sort of goes through the steps of why an ECS would be useful and then he just stops and shows how he has implemented his own rogue like. I would have liked to see a comparison and a reason why he didn't use an ECS. 
This is pretty similar to the design I've been working on (https://github.com/nicoburns/rustdi). So consider me broadly in favour of the design. I have some thoughts: 1. I don't think use of macros is a problem per se. I think the issues with Rocket are: - Nightly only - No async - As per /u/matthieum's comment, I really dislike the coupling between handlers and routes. That said, it probably does make sense to see how far we can get in "normal rust", and then fall back to macros when necessary. A key thing for me is that when a macro is used, the end-user should understand what the macro results in, and be able to write the same thing manually, even if doing so is less ergonomic and convenient. One thing I was using macros for was to allow the user to "request" an owned value, immutable ref, mutable ref, simply by using `T`, `&amp;T` or `&amp;mut T` in their function signature. Not quite how that would work with Extractors which I wasn't using, but seem like a good idea. 2. Why does (rust's type system work such that) the `Endpoint` trait requires the `Kind` parameter. I came across this when trying to implement rustdi too. In the following case: impl&lt;T, Ret&gt; Foo for T where T: Fn() -&gt; Ret { ... } and impl&lt;T, Ret, T0&gt; Foo for T where T: Fn(T0) -&gt; Ret { ... } Shouldn't rustc be able to tell that the two implementation are for disjoint sets of types? i.e. that a function/closure with one parameter can never be the same type as a function/closure with zero parameters... 3. It seems a little unfortunate that the parameters passed into the extractor trait need to be hardcoded. I wonder if there is any way to to generalise that interface such that the parameters available can be expanded by the caller, and such that different frameworks that provided different data could have some level of inter-operation. I guess this would introduce an extra level of indirection, but I am unclear on how significant an impact this would have on performance... 4. I'm really looking forward to seeing the design for middleware. I liked warp's take on that. Specifically the property that middleware could be composed and provide values to endpoint handlers, and so long as the handler happened to match the composed middleware's type signature, it would work (the disadvantage seemed to be compile times and confusing error messages, which are both a pretty big deal IMO). It would be even better if order didn't matter, and middleware provided values could be ignored by individual handlers as they saw fit. 5. I'd love to see the database example fleshed out more. What fields would a database handle have (are there internal synchronisation primitives?)? I'm assuming it would somehow enable you to get access to a future that would run on some kind of thread pool / queue? It might just be me, but I'm really struggling to work out what the best way of implementing DB access using an async web framework and a sync DB client (which is what we mostly seem to have atm, and many people seem to think should be entirely sufficient or even preferable to truely async db clients).
One question: Did you not read throught this sub before posting this? This is getting really annoying because this happens all the time. Where did you post this from? Did you go onto this subreddit and then click "submit a text post". Or did you do this from your Reddit Startpage and just assume that /r/rust must be the correct sub for your game?
Thank you for the explanation
255 -&gt; 0
&gt; but for example Rust makes the relationship between containers and their iterators clearer. Thats library design. I always wrote my own where possible in C++. I hate the C++ stdlib, but the underlying langauge engine lets me do more my way. &gt; (assurance that callback functions can only be used while their data is still live). now C++ finally has lambdas, both can do my preferred approach which is 'internal iterators' rather than 'external'. The chaining stuff in rust is extremely cool though, but for my areas of interest the other style lends itself to writing parallelizeable code better &gt; I don't usually find that a problem — most functions intuitively belong to some object. Thats not the problem. The problem - (which rust traits do fix) is the resulting **coupling**. The 'intuitive link' ends up bringing too many dependancies in, then your headers explode, your classes cease to be re-useable. ```class car { update() render() }``` // Thats the most obvious,intuitive way, but now your game car class depends on BOTH rendering and physics systems. it should be possible to extract either as a separate library (change physics, change renderer), and test in isolation . you could run your car physics in a headless application to pretrain the AI, whilst your renderer depends on some console devkit that you only have limited numbers of.. Compare to C, you just write car_update(Car*) car_render(Car*), and chop and change however you need. &gt; now I'm sufficiently used to using a less smart text editor (Kate, which has limited autocompletion) and an API reference that I don't miss it. I'll be honest.. I find this to be hell. I dread having to drag myself away from my 'internal mode' focussed on source to go and dig and read elsewhere. Contrasted to when the IDE is just showing you whats going on keypress by keypress.. it's night and day. I'm far better at 'internal logic' than 'memory/recall'. (i.e. aptitude in logical subjects maths/sciences over 'fact' based subjects.. learning vocabulary for languages etc). The purpose of computers is to assist us where we're weaker.. and an on-the-fly search is what I need to let me focus on using my strengths. 
That's how lambda calculus works. Creating and immediately invoking a function is a common operation in it. Since this language maps into a variant of lambda calculus during compilation or proofs, this is necessary to keep the implementation complexity low, which in turn means that the chance of bugs in the implementation is low and that proofs achieved using it are likely hold.
I'm having some problems with lifetimes in [this](https://gist.github.com/tcmal/b5744e22660120623502f60822ce0ff2) code. I don't understand why the sub_items var is trying to live for as long as `'f`, I'd like it to just die with the method.
Kudos to /u/PlasmaPower for the rewrite, who has done 99% of the work and handled it better than I possibly could. Also, this is the first time a project of mine is rewritten in Rust not for safety (implementation of C `malloc()` is wildly unsafe anyway), but for portability. C build systems are a bloody mess. By contrast, Cargo lets me write portable code without writing even a line of build system code.
Its both functional and OO in a sense, depending on how you want to use it.
Yes, but it seems like these functions always need a type definition. And I fear that these type definitions may get very verbose. I mean, all they did in the example was prove the commutativity of addition, which is a very simple proof as far as computer-checked proofs go. 
You probably want to take a look at [rum](https://github.com/tonsky/rum) which is a React wrapper for ClojureScript and it actually does server-side rendering in Clojure. Which means that it does server-side rendering on JVM and you don't need to manage a pool of Node.js processes to perform the rendering. Worth noting that it's a production-ready thing. Maybe you want to take a look at it for inspiration and ideas :)
“Closures are a poor man’s objects. Objects are a poor man’s closures.”
 ... Goodbye, world
Hello, I followed up on this. Smooth scroll is now deactivated in the theme options. Does this solve the problem? I can not tell, since it worked fine on my mobile phone.
It’s expression based, and it’s not OO. If you read the O’Reilly book both of these things are pointed out. 
Works fine now, great.
True: pattern matching, ADTs, and even currying, are all present in Rust. Higher level abstractions (like monads and their relatives) may not be directly available, but I don't imagine it being extremely hard to emulate them in a way.
In no small part thanks to you.
So... not functional.
Short answer: no.
There's more the functional programming than just closures. 
I never said there wasn’t.
&gt; pattern matching, ADTs, and even currying, are all present in Rust. ADTs and pattern matching a functional programming feature, just a modern language feature Rust happens to have because it was designed fairly recently. &gt; Higher level abstractions (like monads and their relatives) may not be directly available, but I don't imagine it being extremely hard to emulate them in a way. It is in fact hard to emulate monads in Rust.
I agree that it's much better to talk about specific functional concepts and rate a language on how much is each possible / encouraged rather than giving blanket "x is/isn't functional" statements. &amp;#x200B; I was a little surprised (pleasantly) how well Rust came out in that context with lambdas, iterators, etc. I use all these liberally myself, but I still tend to think of Rust mostly as imperative with a few functional bits on top.
&gt; Haskellers may argue that the same applies to bottom values in Haskell: they shouldn’t be used in general. Though I’d agree with that, unfortunately in Haskell today that’s not the case. The standard prelude, for instance, still exports functions like `head` and `readFile`. It should be noted that Rust also isn't free of this. `Vec::remove` for example will panic if the passed index doesn't exist.
&gt;It is in fact hard to emulate monads in Rust. Option is a monad. Result is a monad. Future is kinda monad with some boxing complexities. Of course it's hard to implement all FP algebra and all kinds of monads without HK types. But basic monads are there.
I consider functional/persistent data structures to be another prominent concept when surveying a language's functional-ness. For me, Rust's lack of these in the standard library is what causes the biggest gap between what I think of Rust and what I think of a "functional language". Circling back to the article's section on functions; I think Rust gets a few extra functional points for the std iterator being a mostly functional and idiomatic way to deal with many tasks.
&gt; But basic monads are there. So... you can't define a parser monad, for instance. 
&gt; Is there a fundamental problem stopping us from writing a fully dependently typed language with Rust-like syntax? Why would you? ML syntax is nice, Haskell-like syntax is nicer. 
Just write you API in rust, the node server can focus on just hosting the javascript application.
Yes - including tail calls on different branches.
You can define instances of monads, but you cannot abstract over them.
Or the index `[]` operator on slices, vectors, etc.
TCO is not guaranteed, but that doesn’t mean it never happens.
I'm actually using an opentype font. It does work with a misspelled name (falls back to the default font), but if I properly configure it to use Fira Code, it crashes on run. (shows a light blue screen for a moment, than turns off).
&gt; Is it possible to make a purely functional, performant systems programming language (networking code, operating systems, real time) ? I don't think real, pure functional code can be performant and "systems level" -- the constraint of immutability forces copying values instead of modifying memory directly (which is generally the most performant way to compute on bits). You can avoid the performance penalties by throwing a bunch of threads and memory at functional programs, which parallelize really well, but that's not "systems programming" anymore really.
I love [good faith](https://www.reddit.com/r/programmingcirclejerk/comments/9p9xg2/rust_the_choice_for_discriminating_functional/) questions.
Nowdays, the one and only functional language is Haskell. Over the last 2 decades, the term functional programming evolved to "Lazy, pure and with type inference." Rust is neither pure nor lazy. But is does have type inference. It is a pretty good language overall, but it cannot be considered a functional language by today's consensus. Haskell, being pure and lazy has its drawbacks too. It is not something completely magical and good. Some things are very ugly to write in Haskell, but are super easy to do in Rust.
For me, the central value proposition of functional programming is that it tries as hard as possible to eliminate shared mutable state. Most functional languages accomplish this by eliminating the "mutable" part, but Rust achieves it by eliminating the "shared" part. The end result is the same: a language in which you can reason confidently and precisely about how information flows through your program. For this reason, as someone who *loves* functional programming, I would say that Rust is one of my favorite functional languages because it satisfies the same need.
I would also give credit for widespread idiomatic use even if an external library. But just the existence of libraries implementing those data structures is universal to popular languages and does not in itself make them notably more functional.
But you can actually use different terminal emulators within cmder/conemu. I'm using it with mintty currently.
Not purely functional, no.
I really don't see the benefit in doing this. If you want to execute a Rust binary on a Lambda, wrap it in a small script to execute it as a child process and return it's output from the Lambda. By compiling with WASM as a target you sacrifice performance, some Crates and methods, string typed interfaces and more.
&gt; It is in fact hard to emulate monads in Rust. Hard? `Option`, `Result`, `Future`, `Box`, `Arc`, `Rc`, `Vec`, `List`, ... are all monads. It is pretty easy to implement monads in Rust. As other have mentioned what's hard is abstracting over all monads. 
Rust is not functional in the same way that Michael Jordan was not a basketball player because he could also play baseball
What do you do when E1 and E2 implement the same trait?
"Copying collectors" because they can only compact `Copy` types? 
If you don't look at the standard library or any cultural aspects of Rust at all, Rust is remarkably similar to OCaml, but with just two significant differences: * Static memory management * Traits instead of functors Is OCaml functional? Is this distinction actually useful?
&gt; the constraint of immutability forces copying values Linear and Affine types would like to have a word with you. It's perfectly fine to mutate in place if you can guarantee that nothing is referring to the old stuff, any more... which, not at all incidentally, is the reason why you can't take a `&amp;mut` at just any point in the program. It just happens that prior to rust, all systems-level languages with a functional-style type system (parametric polymorphism etc) were research prototypes.
Yes, a huge part of it is learning. I use Apache Ignite for similar caching needs, but I use it in the JVM, and I want to do better with Rust.
What's the argument against tail-call? It's apparently quite a powerful one, whatever it is… &amp;#9786;
For the most basic operation of copying to and reading from a `BytesMut`, it will be a little slower. This is because it has a couple of features that help in other situations: small-buffer-optimization, and shallow cloning and slicing. - Small Buffer Optimization: if the number of bytes needed are smaller than the size of the pointer fields of the struct, the bytes will be written in-place instead of allocating. In practice, on 64bit machines, strings under 32 bytes won't need to allocate. - Shallow cloning and slicing: the internal buffer can be reference counted, so you can cheaply pass clones without copying the entire buffer. You can also clone subslices of it. The benefits here are allowing to do a read from a socket, and then decoding some framed protocol without needing to copying portions out of the buffer.
Wow.
For the interested, here is the postponed RFC for the `become` keyword for guaranteed tail call optimization: https://github.com/DemiMarie/rfcs/blob/become/0000-proper-tail-calls.md The major blocker: &gt; An even greater drawback of proper tail calls is lack of cross-platform support: LLVM does not support proper tail calls when targeting MIPS or WebAssembly, and a compiler that generated C code would be hard-pressed to support them. While relying on sibling call optimization in the C compiler might be possible with whole-program compilation, it would still be tricky. WebAssembly does not support tail calls at all yet, so stablization of this feature will need to wait until this changes, which could take years. 
Haja. Yeah. There are a few more out there, but mostra of the research is focused on haskell extensions. In the 90s, there were like 628472 research languages. The community got together and decided to use Haskell.
I've also been learning about type inference chains and trait bounds (and running into their limitations). For example: trait Middleman { type Field; } trait ConversionForX { } impl&lt;T&gt; MiddleMan for T where T: From&lt;T&gt; { type Field: T; } impl&lt;Src,Dest&gt; ConversionForX for Src where Src: From&lt;Dest&gt;, Dest: From&lt;Src&gt;, Middleman::Field: Dest {} 
Most people would put OCaml in the functional family, yes. But OCaml feels different, it has a much greater emphasis on immutability.
 pub struct state { current: Vec&lt;u32&gt;, previous: Vec&lt;u32&gt;, } impl state { pub fn swap(&amp;mut self) { let temp = self.current; self.current = self.previous; self.current = temp; } } Hi r/rust, &amp;#x200B; how do I swap values of two struct fields in rust? I understand why the code above does not compile, and I wonder what idiomatic way to do this might be. thank you
They forgot about JavaScript, apparently.
We've found Lambda and Node really convenient for wrapping the child process. Node handles parsing the Lambda event JSON, calling any required AWS SDKs (for example, passing results back to CodePipeline) and ultimately calling the binary and handling stdout.
For that there's [`std::mem::swap`](https://doc.rust-lang.org/std/mem/fn.swap.html). pub struct state { current: Vec&lt;u32&gt;, previous: Vec&lt;u32&gt;, } impl state { pub fn swap(&amp;mut self) { std::mem::swap(&amp;mut self.current, &amp;mut self.previous); } }
This is the Rewrite in Rust commit: https://github.com/Shnatsel/libdiffuzz/commit/bfe3b92543e5c048034e5475cfe76deaf25c9623 202 additions and 384 deletions. Clearly, Rust is 1.9 times better than C :-).
If you're meaning purely functional, no. But you can FP finely in Rust because it has immutability, closures (lambdas), iterators etc. &amp;#x200B; As i see, there is focus for each paradigm (oo, functional, ...). If you want to learn functional, there is functional programming tutorial for it in official book: [https://doc.rust-lang.org/book/second-edition/ch13-00-functional-features.html](https://doc.rust-lang.org/book/second-edition/ch13-00-functional-features.html)
Thanks i didn't see that before. So does TCO need features of the codegen, rather than some sort of AST transformation?
Nor functional at all. 
No one has bothered to do anything like `do`-notation for parsers. 
Why don't you monitor reddit for replies?
&gt; Or did you mean "Guaranteed tail call recursion optimization"? Yes. Also known as "making recursion viable instead of blowing up."
This language isn't really designed for humans to write. It's really the "core" language, like MIR is for Rust, that a compiler might work with as intermediate structure. If you're familiar with Haskell, it's System F and later improvements. Everything is very explicit, with the understanding that local inference, elision rules, etc. will be possible to make writing code in it by hand much more comfortable.
thanks! &amp;#x200B; bonus question: is where a way to do it without std? or how big would the footprint be in a wasm application?
I like to think of it as the functional parts that make sense in software. I love functors as much as the next mathophile. But they do not help with programmers' problems.
Lmao rip 
I think it is reasonable to assume these discussions come with a blanket proviso: "Assuming a (mostly) decidable and reasonably efficient typechecker."
Don't they? I mean it's basically a generalization of a whole class of generic containers. Being able to use `[1,2,3] &lt;*&gt; [4,5,6]` in the exact same way as `Just 5 &lt;*&gt; Nothing` is pretty powerful.
I think a lot of the discussions on this subject are somewhat derailed by nomenclature. Anonymous [enum/sum/TAGGED union] types comes with lots of problems, which are those most commonly discussed. (How to refer to options, match syntax, how to combine). It doesn't seem like a good viable option. Union types, on the other hand, seem to be what people really want, judging by the syntax used and the expectations expressed. Unions (as in set theory) already have a lot of sensible rules, like `A|B = B|A`, `A|(B|C) = A|B|C` and `A|B` when `B = A` resolves to `A`. I think one cause of confusion is that union types are also sum types when the sets are disjoint. The tags, in the tagged unions ensure that. Another way to ensure disjoint sets would be to simply new-type each member of a union type. Viewed in that light, each member of a enum, COULD be considered it's own "new-type". Regarding "alternative matching", the compiler already warns "Unreachable...", for when the same "type" (enum-variant) appears twice. I think that could and should extend to matching on union types (aliased or not).
[Stack](https://haskellstack.org) stores snapshot dependencies in a user directory global to all projects, but stores project-specific deps (e.g. relatively pathed deps) in the project directory. There are some improvements coming down the pipe for this but it has treated me fairly well.
Trolls gonna troll.
* No guaranteed TCO
Sure. What I'm trying to say is that the 'functional flavor' arises from the standard library and the community and not the language itself. That makes me think that the whole exercise of designating these languages as "functional" and those as "not-functional" is mostly going to boil down to how each language's fans and detractors feel about it, and not so much about the actual languages themselves.
I've learned that you can make an `Option&lt;&amp;T&gt;` out of an `&amp;Option&lt;T&gt;` via `o.iter().next()`. Handy!
I've used that progress with great results so far.
Ha even better, thanks!
What a great post! It really goes in to depth on something I've had a gut feeling about for quite awhile already. Rust really took many of the great ideas from functional programming and incorporated them well, while avoiding the very painful aspects that sometime popup.
It makes the code more difficult to reason about and the optimization can disappear due to seemingly arbitrary changes if you're not familiar with what the compiler is doing in the background.
Adding methods to existing traits... sort of, by implementing a new trait for every type that implements an existing trait. Say `SomeTrait` is an existing trait in another library. pub trait MyTrait: SomeTrait { fn new_method(&amp;self) { // ... } } impl&lt;T&gt; MyTrait for T where T: SomeTrait {} Now, anywhere where `SomeTrait` is in scope, any instance of `SomeTrait` has a `new_method()` method, no `.into()` or wrapper type necessary. I discovered this from the [itertools](https://docs.rs/itertools/) crate, which [uses this](https://github.com/bluss/rust-itertools/blob/master/src/lib.rs#L1988) so you only have to have `use itertools::Itertools;` to get access to all kinds of extra iterator functionality.
So... not basketball.
I would call them monadic structures, there is no `Monad` trait due to the lack of HK types. In this sense C can probably have "monads" too.
About persistent data structure in std: http://smallcultfollowing.com/babysteps/blog/2018/02/01/in-rust-ordinary-vectors-are-values/
I don't get that impression from the project's readme at all. It says &gt; To guarantee mathematical meaningfulness, Formality is compiled to Cedille-core, a minimalist type theory which acts as a termination and consistency checker. It seems like Cedille-core is supposed to be that MIR and Formality is supposed to be the high-level language that compiles to Cedille-core. But you're saying there's supposed to be an even higher-level language that compiles to Formality?
In most cases that I saw in FP "persistent" data structures actually keep the last version only, everything else is immediately garbage collected, so persistence exist because of immutable approach, which usually does help with readability and reasoning. Rust can do it with `move`. Or even `next` that you mentioned, actually next has signature `next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;`, how about looking at it as immutable `next(self) -&gt; (Self, Option&lt;Self::Item&gt;)` and allow re-binding (some FP languages allow rebinding, e.g. Elixir)? We have perfectly functional `next`, don't we? Something like `let (vec, e) = vec.next()`?
This is great, I like how you managed to get it working without actually using JS :) a few months back when I did a [similar thing on Azure Functions](https://blog.x5ff.xyz/blog/azure-functions-wasm-rust-2/), that wasn't available, guess I have to update. I am not too familiar with Lambda, but I guess it has bindings to oder AWS services in their JS runtime. Do you think it's possible to work with those as well in pure Rust?
I think it's more and more true, but that's largely an effect of features from functional languages trickling down to the mainstream. Most people would not think of C or Pascal as functional languages. But now that pattern matching, null safety, immutability-per-default, etc are becoming more and more widespread, the lines between "imperative first" and "functional first" languages are getting blurry.
So this is basically a microservice-y architecture, right? Just to make sure I understand what you're saying, if a user sends a `GET` to the /profile page, for example, the Node server would see the request first and then send a request to the Rust server to get the data needed by the /profile endpoint, then the Node server would package this up and handle the SSR etc. Does that sound right?
Oh wow, I hadn't spotted that AWS now supports Go! This does look like a more practical way to run Rust on Lambda.
It's neat. I'm not sure it's "powerful" or even all that important. If you have some piece of logic that could "fail" in some sense, then having a combinatorial `Option` is convenient. But then, say, your system suddenly has a new requirement to recover from (let's say certain classes of) failures. It requires you restructure things in a non-mechanical way. And the beautiful substitutive nature of combinators doesn't gain you very much. And functors don't fit well with many problems either. Functors are mappings between categories. This is very useful in mathematics, where you have all sorts of categories with interesting relationships between them. (Say between topological spaces and abelian groups, or between pointed smooth manifolds and vectorspaces). But in programming, you usually only have one to work with. (If you can even call it that..... `Hask` is not a category, after all. Haskellers like to pretend it is, but it's all loose reasoning by analogy).
What does that do? An iterator of Result will give me some T and some E. How is that converted into a Vec of T *or* a single E?
Yes, but Applicative is a pretty clear counterpart of Functor, and I thought that specific example illustrated the point (math helps solve programming problems cleanly and generally) better.
With lambda functions you do often integrate with other AWS services via the AWS SDK: https://www.npmjs.com/package/aws-sdk I'm assuming that wasm-bindgen could generate bindings for these APIs in much the same way as they have been for the recently release web-sys crate that provides Web API bindings: https://rustwasm.github.io/2018/09/26/announcing-web-sys.html
What is the difference between "purely functional" and "functional at all", then, to you?
You use it in situations where you are only interested in getting the results i there are no errors at all. The single E returned is the first one encountered.
As I see it due to Rust guarantees any function of type `fn f&lt;T, U&gt;(v: &amp;mut T) -&gt; U` can be re-written as `fn f&lt;T, U&gt;(v: T) -&gt; (T, U)`, which looks perfectly functional, just a different notation. If we limit the number of versions in persistent data structure to 1, `v` here can be considered as immutable (+ "persistent"?), even if it's explicitly "mutable".
Collecting an Iterator of results into a vector will give you a vector of results. You can then inspect each one to see if it succeeded or failed. Collecting an Iterator of results into a single Result will give you all of the Ok values in a Vec if every single one succeeds or the first Err if even one of them fails. 
It can be any language which is lazy, pure and with Hindley–Milner types, also it's name has to be Haskell. Since when "lazy" is a requirement? :)
I've used both Rust and Haskell for a while, but I've never heard of currying ... would you mind to explain what currying is?
All the good stuff is in [the doc](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect) but the short version is that it stops at the first error, simply because of `Result`'s implementation of `FromIterator`.
My understanding is that TCO does not work nicely when you have "destructors" (aka Drop). One way to think of it is that the Drop trait adds an automatic drop() call at the end of the function. Your recursive call is therefore not actually in tail position at all.
With a reference cycle: A owns a RC reference to B and B owns a RC reference to A.
if I have a function that takes many arguments x and y like fn add(x : i32, y : i32) -&gt; i32 {
Rust is funny in how flexible it actually is. You can write Rust code that is fairly functional looking, or go pretty far towards OOP, or you can write it like a weird immutable-loving version of C. Personally, when I write (wrote- I haven't done any Rust in about a year) Rust it looks similar to Scala (functional + OOP).
The main issue is that, on Windows, Cargo stores its stuff on the C:/ drive. My C drive is a small (80GB) SSD that I use to store as little as possible (ideally only the OS and system files), and then I have a larger (2TB) drive that I use to store basically everything else. The larger drive is slower, but the data on it is not accessed as frequently so that's fine. The issue is that rustup and cargo store a lot of their data on the C:/ drive. There's no way to configure them not to do that.
TCO doesn't make the code more difficult to reason about because TCO is done by the compiler. If you write confusing code because you're trying to utilize TCO, that's something else. Similarly, if your TCO disappeared because you tweaked your function, is that any worse than never having had TCO at all (as today)?
For the sake of completeness, what is the result? Is it a carthesian product or a distributive concatenation? The Option example is clear, but also has the same answer due to the Nothing value. I can't predict `Just 5 &lt;*&gt; Just 3`…
`filter_map`, for unwrapping every `Some(x)` in an iterator of `Option&lt;T&gt;` if you don't care about the entries that are `None`: &amp;#x200B; let coll = vec![Some(1), Some(2), None, Some(4), None, Some(5)]; assert_eq!( coll.into_iter().filter_map(|x| x).collect::&lt;Vec&lt;_&gt;&gt;(), vec![1, 2, 4, 5] ); &amp;#x200B;
Wouldn't it just be `g = f 10` or `g x = f 10 x`, not `g x = f 10`, because then you have say `Int -&gt; Int -&gt; Int` instead of `Int -&gt; Int`, where the first Int doesn't matter, and the second one is the `y` in `f`. Note: I haven't used Haskell in awhile. Mostly OCaml because it's required for my class.
You can make both of those arguments, but neither one makes Haskell-style functors sound much less useful. I for one think pure FP's use of terms from category theory is pretty reasonable. The word "functor" already meant something different before mathematicians started using it, too, you know. And the programming versions of these things aren't just random appropriations of the words&amp;mdash;they're implementations of the mathematical concepts, often very good or even perfect ones when it's understood that you're only dealing with one category (or almost-category).
Whoops, you are correct. That's what you get for programmin in reddit comments.
I’m going to say “no,” for the following reason: I find the most useful definition of functional programming is as a paradigm that aims to ground programming on the lambda calculus and similar formalisms. Scheme, ML and Haskell are very much in that vein, languages designed to be a sort of executable lambda calculus. Rudy just doesn’t roll that way. Also, it’s very much got its own thing going with the compilation-time sharing/mutation mutex. The biggest highlight of Rust id that it’s a very novel kind of imperative language.
Yeah, but it doesn't seem as good as Haskell, for example. Or maybe even Rust. I've not delved crazy deep or anything, but I don't know why are there are several different functions for printing something. What about our single print with a Display trait/typeclass?
you could at least develop your points a bit more since you seem to be the only one answering the question with a hard "no", it would be a lot more useful to people who might agree with you but can't due to the lack of information.
If by possible you mean, "Give someone like Ed Kmett a billion dollar budget and challenge him to do it" -- then yeah it's possible. Would it be a practical choice, given the constraints of hardware? I don't think so.
Yeah. Garbage collection *doesn't* mean you no longer have to worry about memory at all, it means you have to worry about memory in a *different way*¹. The GC you're using has performance characteristics, just like malloc/free - in some ways they're more forgiving characteristics, like short-lived allocations being almost free, in some ways they're more brutal, like allocations can take wildly varying times. ¹: And less, too, because the typical GC problems are suboptimal performance or excess memory usage, not crashes.
👍
Bear in mind I'm only presenting summaried versions of my arguments. Ultimately, it was the insistence on pseudo-mathematics that pushed me away from the language. The community isn't very honest with itself on its relation to category theory, and I found that to be very frustrating. Category theory is interesting and useful. But I firmly believe it is a tool for topologists and logicians, not a tool for programmers. Programmers don't have problems which are expressible in terms of commutative diagrams. Software development is an engineering discipline. Proving formal equality is not the issue. It's modeling all of the implicit constraints. Two functions might be observationally equal. But that's not a strong enough guarantee if you have a real time constraint or a very large data set. Don't get me wrong. I think functional programming is the morally-correct way to think about any project, at least until the constraints force you to give it up. It's a million times better thought-out than the industry-born object oriented programming. I think monoids, algebraic types, and total finding are worthwhile for any computer-scientist to study. But Haskell's viewpoint on functional programming is a very particular viewpoint. And I think part of that is the influence monads had on the language in its infancy. I imagine if the language had been designed with a type and effect system, let's say, things would be very different. And my guess is it would have been viewed as a lot more practical, while maintaining all of the benefits.
Why would it have to be enforced with type classes? That would only makes sense for code that would want to be generic over all these types, but nobody has been able to actually even state what value would that code even add. Which function could be useful to write for `Future`, `Option`, `Arc`, and `Vec` ? The closest thing people have come up with is "something like iterator", but in most cases you can just implement `Iterator` and call it a day, and often, because of lifetimes, which is something that most functional languages do not have, you want to have slightly different features to get useful functionality (like `Futures`'s `Stream` instead of `Iterator`).
Making Tokio usable?
Minimising the shared part seems more like the actor model to me. To me it seems like Rust can do both, in the same program, and safely.
We need an identity function!!
That's an invalid program and a bug, and is logical error, which is solved my writing correct code, not relying on a GC to clean up your mistakes.
What you're talking about is generally called "ad-hoc polymorphism". Rust and Haskell do this with typeclasses. OCaml can accomplish it with its first-class module system. However, using modules for ad-hoc polymorphism is somewhat painful, which is why OCaml is adding "modular implicits" which will make the situation much nicer. As far as why the standard library doesn't do this, IIRC it's because it predates OCaml's first-class module support.
Ironically, this criticism is more correct of Rust's current optimizations of tail calls then of actual proper tail calls. Right now tail calls are *usually* optimized in release mode, but are not guaranteed to. Proper tail calls, on the other hand, change the semantics of the language in a way that is consistent and can be relied upon.
It's not just a matter of what you \*can\* say in a language, it's also a matter of how natural it is to say it. Things are "natural" to say if the language provides the faculties to work at that language of abstraction without dropping down into concretions. For example, in Scheme it is very easy and natural to do the following: (define (cons a b) (lambda (f) (f a b))) (define (car x) (x (lambda (a b) a))) (define (cdr x) (x (lambda (a b) b))) The equivalent Rust is probably 4 times as long, and it will be much harder to read and write, because there is something "different" about functions, and I'm immediately forced to deal with issues of concrete representation (like boxing, etc). Rust is not a functional language.
Well said! I came here to say basically this, and that this is how I ended up coming to rust from haskell. I'm really happy fpcomplete is doing this series of blog posts, writing about rust from a "high fp perspective" seems to be pretty interesting and fruitful, and this is the sort of thing that would have been extremely useful to me a few years ago.
I can quickly and concisely unwrap the inner value of an Option or Result into a local, or return early otherwise. But if I want to (a) unwrap the inner value of a completed Future into a local, switching-out until it is ready and returning early upon failure, or (b) unwrap each inner value of a container into a local, executing the remainder of the current function once per such value and collecting the results into a new instance of the same type of container ... we need an entirely new syntax for that!? Completely ridiculous.
Ah, thank you. Honestly, typeclasses make a lot more sense to me than modules, but it could be because I read a ton of Rust articles and no Ocaml articles.
I used perf (https://perf.wiki.kernel.org/index.php/Main_Page). But I was looking at the tiny runs because I got the results backwards initially.
... except in this benchmark, Vec is faster than BytesMut.
It doesn't optimize tail recursion. Seems pretty insane to call this a "functional language". You can't even do basic things with functions. 
&gt; That would only makes sense for code that would want to be generic over all monads, but in the context of Rust, nobody has actually managed to make a convincing point about why would this be useful. I want to sort a Vec using a fallible key-function, where failure is an error that I want to propagate to the caller, a la `try!(x :: Result&lt;T&gt;)`. Alice wants to sort a Vec using a key-function that is fallible in the ignorable manner of `Option::none`, and is fine with leaving those keys' values off together on one end. Bob wants to sort a Vec using a key-function that makes an asynchronous network call, and wants the rest of his (async) codebase to keep running while those network calls are in-flight (not to mention making the calls asynchronously of each other; the network is slow and there are lots of items in the Vec). Charlie has a similar task as Alice, except his key-function might actually return _multiple_ results for an item, and he'd like to produce all the possible valid orderings so that the caller can choose between them. Dave wants to sort a Vec the same way that Charlie does, but his key-lists are behind network calls like Bob's are. And some persnickity kids from Special Projects want to do each of the above but with some "persistent linked list from a CS research paper" instead of a Vec. If I have to fulfill all these requirements and we're using Rust, then I need to write and maintain **ten different variants of "sort container X by key Y"!** Whereas if we're using Haskell, I can just write a singular "sort Traversible collection by Monad key" function.
I don't see how tokio and garbage collection are related.
Hey every this is mine. This is sort of an alternative to wasm-bindgen though I doubt it gains any legs. I know ppl here likely care little for clojure but this is my first rust project and it was a blast. Thanks for reading :-)
I'm surprised because it should be [suggested](https://github.com/rust-lang/rust/pull/51100) on [current stable](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=bd2c81d6a5346f27f25664047b296072) in some cases where it's needed: error[E0308]: mismatched types --&gt; src/main.rs:5:29 | 5 | opt.map(|arg| takes_ref(arg)); | - ^^^ expected &amp;Foo, found struct `Foo` | | | help: consider using `as_ref` instead: `as_ref().` | = note: expected type `&amp;Foo` found type `Foo` If you encountered a case where it wasn't, file a ticket with a repro case so we can handle it too.
That's a very poor definition of functional programming that throws out SML, OCaml, Erlang, and other non-pure functional programming languages out. What remains is essentially Haskell, Idris, Agda, Coq, and such things. What unifies FP is functions as first class values and the focus on composition; that's basically it. Other than that, they don't share static typing, they don't share immutability, they don't share purity.
Rust even has a notion of purity now with `const fn` ;)
Unfortunately, no. Proc macros only look at syntax and they only look at small bits at a time (single items that they're manually applied to). What you want is a late-pass lint, which is complex and the API is unstable as it requires compiler internals. Lints look at entire crates at a time (although they actually have a way to specify what specific syntax nodes they're looking for, like expressions). Late-pass lints look at code after type inference and trait resolution is complete, so you can ask the compiler exactly what types the operands of an expression are so you can see when the user is doing arithmetic on the types you're looking for. Coincidentally, I had another user not too long ago ask a very similar question, so there does seem to be some demand for this kind of lint. Unfortunately, I don't recommend asking Clippy to implement it as they have a huge issue and PR backlog still. I might implement it myself at some point though. In the meantime, I suggest just not implementing the arithmetic ops for your types by-value so you force the user to use them by-reference. This will be pretty confusing though so you need to document the reasoning well (or still provide the impl and document why to avoid it). One final alternative is to log a warning when the user invokes the wrong arithmetic impls. They won't always see it but if they're looking for bottlenecks in their code later it'll be a nice flag to catch their attention.
That looks amazing! Thanks a lot, I'll definitely check it out.
Looks super nice! It's exactly the kind of library we're looking for: small, simple and to the point. Thanks! &amp;#x200B;
Thanks, I'll check it out!
Rust does not have the type system features to let you abstract over monads, which is what most people mean when they say "supports monads."
It's just lambdas all the way down.
Rust is extremely similar to Haskell in design and philosophy, just not it's functional bits so much.
It's not very meaningful to ask whether Rust is functional or not as a yes/no question. Rust has a fragment with pure functions (`const fn`). Rust has functions as first class values. Rust has a strong static ~HM type system. Rust has type classes (traits) which are essential to how the language works. Rust has algebraic data types. Rust has immutability by default. The standard library of Rust has functional elements like `and_then`, the `Iterator` stuff, and much of the naming is Haskell based. Rust has a lot of imperative control flow also, but so does Haskell (continuations, do notation for state monads). Rust doesn't have partial application / currying and function composition is not a central piece of the language. Does this make Rust functional? I guess; decide for yourself... The language is mixed, and so is Haskell, the world's finest imperative and OOP (`-XExistentialTypes`) language.
Here you go: https://doc.rust-lang.org/nightly/std/convert/fn.identity.html
`std::mem::swap` is just `core::mem::swap` reexported, so it's available without `std`
Thanks!
I wish we have soon a native Rust suppot from Lambda after we have all the options to run Rust as Python, Go or NodeJs,
Agreed. Any definition of functional language that doesn't include Lisp in all it's setf! glory is just wrong. Purity and immutability seems to be what the author wants to call functional, but that's wrong, we already have words for those things "pure" and "immutable", and pure *implies* immutable; or at least, pure functions never mutate things. --- Is Rust a pure language? Nope. Is it mostly pure? Not really. Does it encourage use of the pure subset? Sometimes, but only if it's easier to satisfy the borrow checker that way. Is GHC Haskell a pure language? Nope. Is it mostly pure? Yeah. Does it encourage use of the pure subset? Definitely, we like to pretend the impure parts don't exist and give them names like `accursedUnutterablePerformIO`. But, there's *plenty* of libraries, some of which a lauded for their pure, functional, even categorical, APIs that feel so well integrated into the language, that sneak in a little `unsafeInterleaveIO`, `unsafePerformIO` or `unsafeCoerce` deep in the bowels, or maybe they import a C or Python function as pure, when it should properly live in IO. So, no, GHC Haskell (and even Haskell 2010) are pure languages. --- I think there's a lesson in there, but I'm not sure. But, in any case *most* languages people use these days are functional -- for the real definition of functional, and not this confusion of functional with pure. Python, Javascript, Java 8 (and above), etc.
Rust is *founded* on the principle that “just don't write buggy code” is an unacceptable answer. There are lots of data structures which naturally have cyclic references. Relying on the programmer to manually break those cycles with Weak&lt;&gt; isn't necessarily the best choice.
Even in a language like Haskell, actually using tail recursion is a code smell. The abstractions Rust has over iteration are similar to the ones Haskell has over tail recursion. So this seems like a real nitpick to me.
&gt; Even in a language like Haskell, actually using tail recursion is a code smell. No....
Well, that's convincing.
&gt; The abstractions Rust has over iteration are similar to the ones Haskell has over tail recursion. So this seems like a real nitpick to me. &gt; The abstractions Rust has over iteration are similar to the ones Haskell has over tail recursion. So this seems like a real nitpick to me. The point is that things like while loops become a question of writing *functions*. Obviously imperative languages have facilities for control flow as functional languages do.
Although it is amazing in principle, it is something I keep struggling with. As collect() needs to know the type, and needs to know that you need the result extracted, I end up with intermediates like: let foo: Result&lt;Vec&lt;_&gt;,_&gt; = x.iter() .map(|..| /* some Result&lt;..&gt; */) .collect(); let foo = foo?; .. continue with foo iteration Wouldn't it make more sense to allow this pattern *in iteration*? Like: let foo = x.iter() .map(|..| { /* some Result&lt;&gt; */) .extract_error()? .. continue iteration 
That's why I call it a "post-functional" language. In the same vein as "post-punk" is not punk.
After some tweaking I found what seems like the minimal number of changes needed to get this to compile. I was going to write a longer explanation of what I think is going on, but my brain hurts at the moment, so I'll leave it at this: Line 21: replace `&amp;mut MyThing&lt;'f&gt;` with `&amp;'f mut MyThing&lt;'f&gt;`. As far as I can tell, rustc is inferring a lifetime parameter for the `&amp;mut` reference that is different from `'f`, whereas `get_child` expects both to have the same lifetime. Line 29: apply the same change from line 21 to match the trait definition. Line 30: change `MyThing::get_child(&amp;mut items);` to `MyThing::get_child(items);`. The variable `items` is already a reference; `&amp;mut items` appears to be re-borrowing it, giving the reborrow a strictly shorter lifetime than the lifetime `'f` that `items` has from line 29.
You could use the turbofish syntax to specify the return type of `collect`. ``` x.iter() .map(...) .collect::&lt;Result&lt;Vec&lt;_&gt;, _&gt;&gt;() ```
&gt; Just because you've never heard of something doesn't mean there hasn't been extensive research into it. Just because I said I'd never heard of it doesn't mean I was questioning its validity, sheesh. I even compared it to Rust. &gt; This point makes it sound like you are arguing for popularity as a measure of quality. Be mindful of that kind of thinking, of course. I'm just saying that Haskell has a niche, and whatever you'd like to replace it with, I don't think it can fill that niche. &gt; \[...] but I am putting my money on, in a hundred years, monads were just a curiosity that didn't really do much for reshaping software. They're already in, e.g., Rust and JavaScript. We just think of them as "things with an `and_then`-type interface" instead of as monads. Monads are a natural interface for representing operations as values. I like Haskell because it represents _all_ (conceptual) operations as values. So if you get rid of that part of it, I probably won't use whatever you come up with&amp;mdash;there are already lots of good enough languages without that feature.
It'd be nice if you could use np.reddit.com when linking my comments for people to laugh at. &gt; The point is that things like while loops become a question of writing *functions*. I can't remember the last time I used a while loop in Rust, and I can't remember the last time I used tail recursion in Haskell. I don't think it's very reasonable to cite features that show up so rarely in practice as a reason to designate a language as not _at all_ representing a particular paradigm.
Rust is getting there wrt. referential transparency with the advent of `const fn`. It's pretty limited right now, but we'll make it more powerful in due time. :) Re. GHC Haskell and purity, AIUI it is a type system invariant for any computation at any type to be referentially transparent; That `incrediblyUnsafeYouMayCauseBlackHolesIAmNotJokingPerformIO` may be used to break those invariants and cause UB is no different than using `unsafe { .. }` really. Do note that `IO` computations are pure; they are values describing side effects a run-time may take.
Wouldn't this be solved by adding the drop traits before the end of the function when using the become keyword, and using the old behavior with return? This would indeed restrict what you could write, but the programmer knows this as they are opting into it with become.
I believe the readme is misleading. Looking at the source code, it does not compile to cedille-core. However, I think it is meant to use same inference rules.
This is defined for an inductive data type that represents natural numbers. If you try to write 1024 in that language, you need to define 512, 256, 128, etc. or else is blows up the source code.
I don't agree with this: &gt; Currently, Rust provides no means of tail-call optimization (TCO). There is a vague way to do TCO in rust, but it can't be relied upon, namely LLVM optimizations. You will see this, when you run the example code in the blog post with release optimizations turned on (`cargo run --release`). [Example playground](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2015&amp;gist=ec769ad77eb18f93baf213fe66e50629) However, you will be at LLVM mercy for the optimizations, which are only available on some platforms and don't trigger for all froms of possible TCO (or so i've heard). If someone has an example of code that could be TCO'd but isn't with --release, i'd like to see it! **TL:DR:** You can do TCO in Rust if you're okay with being at LLVM's mercy for the optimizations.
To each their own. I personally would rather work with HCL than TOML.
I can easily write your expressions in Ruby in one line, does it make it a functional language? Scheme and Rust have different type systems, so the biggest problem for Rust is to declare types, otherwise something simple like `let cons = |a, b| |f| f(a, b);` would have worked just fine. It doesn't, because of static typing, which is not only static, but not HM too. I wonder if you can write it in Scala (which is considered very close to functional). Not every FP language should be dynamically typed or have HM types.
&gt; Rust has a fragment with pure functions (`const fn`). Which reminds me. I really need to check what kinds of lints or 3rd-party tools exist for checking how pure functions are without requiring them to be `const fn`. While completely pure functions are of limited utility, I think being able to have automatic warnings if certain portions of the codebase do impure things directly, rather than by calling other functions (or, ideally, if they grow new paths to impurity) would ease developing and maintaining a well-tested codebase (for similar reasons to what makes `unsafe` useful).
I pulled the Clippy repo this afternoon and started to take a stab at it. I found some other type-directed lints to use as a reference. The lack of documentation in the `hir` and `lint` is resulting in a lot of slow `println!` exploration. :( Current strategy: Look for binops, calculate the type of the operands using `cx.tables.expr_ty_adjusted(lhs/rhs)`, and see if there's an impl of that operator for `&amp;typeof(lhs), &amp;typeof(rhs)` (no idea how to do that yet, but hopefully there's some magic method buried in the fields of `LateContext`).
We need this kind of post weekly
Yep, I was saying exactly that, that simple reading and writing is a little slower, since there's some overhead for check for SBO. But what the benchmark doesn't show is that creating a new `BytesMut` with a small string will be far faster than a new `Vec`, and making copies of slices is much faster than the array and the vec.
It attempts to apply the right to the left. You'll need some binary function for it to work with multiple values. A couple examples: Just (+5) &lt;*&gt; Just 3 8 Just (*) &lt;*&gt; Just 5 &lt;*&gt; Just 3 15 [(++)] &lt;*&gt; ['a', 'b', 'c'] &lt;*&gt; ['1', '2', '3'] ['a1', 'a2', 'a3', 'b1', 'b2', 'b3', 'c1', 'c2', 'c3'] fmap (++) getLine &lt;*&gt; getLine That last example concatenates the result of two line inputs (the `fmap` maps a function over a Functor).
I meant to last week, but got side tracked. Gonna try and do it on Mondays. 
I misunderstood the acronym as Server Side Rust. My suggestion doesn't do server-side rendering; it's a clean way to set up websites, where you can use Rust on the front and/or backend, and the two works independently. User goes to web page. Frontend server sends a webpage that's mostly JS (Your React/view). When you need to access things in the DB (Like the user's profile, or to check their login info), it uses JS's fetch command to ask the Rust server for what it needs, and receives the results. 
np.reddit.com is pointless, don't use it. PCJ aside, I agree that tail calls are pointless. If you want a loop, write a loop. 
Technically that's just partial application, but they are intimately related. The currying is that your `add` has a type that is a function of one argument that returns another function. The `curry :: ((a, b) -&gt; c) -&gt; a -&gt; b -&gt; c` and `uncurry :: (a -&gt; b -&gt; c) -&gt; (a, b) -&gt; c` witness the isomorphism between (a function taking two argument and returning a value) and (a function taking one argument and returning (a function that take one argument and returns a value)).
It does optimize tail recursion, though? https://godbolt.org/z/Ur63q1 I've written `sum` recursively, but the assembler implements it using only jumps, and without growing the stack. That's what tail-call optimization is.
But you did question the similarity to Haskell, which calls the relevancy into question. No need to "sheesh" my point. Something with an `and_then` interface is effectively a continuation. It's not necessary to bury it in the monad formalism. Monads were invented to study algebraic structures. Meanwhile, continuations were invented to study flow control. Even if they have some abstract relation to each other, it should be clear which of those two things we are actually interested in as programmers. And since programmers have little use (and often, little understanding) of the theory of monads, why wouldn't you prefer the more concrete notion of continuation? But there's an appeal of mysticism that the Haskell community has fostered. It *sounds* so much more sophisticated when you wrap it up in that language. Surely, category theory is important to some aspects of computer science. It's important for modeling higher order logic, functor algebras are essentially the justification for algebraic data types, etc. But those are not useful tools for *programmers* per se. Consider by analogy the importance of quantum physics for an computer engineer. Clearly, it's pretty damn important for the working operation of the computer. But it's too far down in the abstraction latter to make even the slightest bit of difference to your field. I feel the same way about categorical theory and programming. Both are interesting. I think both have definite moral value in studying. But I think Haskell tries to unite them in a way which is (in my very personal view) a bit inauthentic. If you want to argue with me about these kinds of things, do know that I'm well aware I'm a heretic, as far as the community is concerned. But I'm not making claims completely baselessly. I used to drink the Haskell Koolaide, and after a lot of reflection, I came to realize I don't really care for the direction the community took the language. But when the Higher-Kinded Types RFC comes to the FCP, I'll likely be fighting it tooth and nail :P
Which netlink Python library are you talking about?
I'm not really entirely familiar, but an AST transform would take the form of a trampoline on some architectures (transpiling to C/JS, some hardware) which adds extra runtime cost and complicates the ABI significantly as callers might need to be aware of it. Or something.
If u have the function `foo` you can call it directly in a map method like `bar.map(foo)` Just never saw this before bc it wasn't in the docs
This is the correct answer for production settings. Otherwise, OP seems to have developped considerable interest for the problem and IMO it's actually a cool thing to try solving (again) and learn things along the way. Go OP!
You put the tests in a module (a good idea anyway) and then put that module in a different file. There’s no way to say “this module is made up of multiple files.”