I have the same problem. ;)
This project is super newcomer friendly. I made a couple of very simple PRs and they were extremely patient with me learning the ropes of making a good pull request.
so is there a way to know if it was computed at compile time?
From the supported features list: &gt; boolean operators (except for &amp;&amp; and || which are banned since they are short-circuiting). Why is short-circuiting problematic in a const context? Most of the other limitations I can see the rationale behind, but this one has me stumped.
The problem, if I remember it correctly (it was some time ago so my memory is a bit hazy..), was that `&amp;&amp;` and `||` didn't actually short circuit; and so stabilizing `&amp;&amp;` and `||` would have meant that the behavior of a `const fn` executed at run-time would not have short circuited, which means the behavior unlike normal `fn`s.
Do you know why short circuit boolean operators are not allowed?
If a `const fn` is called in a run-time context such as `let foo = my_const_fn();` inside a normal `fn` then it will be evaluated at run-time. In such a run-time context, there's right now no way to ensure that replacing `my_const_fn` with `my_sideeffectful_fn` will cause a compilation error. To ensure that it is executed at compile time (and thus also ensure that it cannot cause side-effects) you need to execute `my_const_fn` in a context that requires compile-time evaluation. Examples of such contexts are the size of an array, enum discriminants, `const` and `static` items, and soon also `const X: T` parameters when we have const generics (RFC 2000). We could potentially add a way to ensure this in the middle of `let` bindings in `fn`s, namely a `const { expr }` block that forces compile time evaluation of whatever `expr` is. Does that answer your question?
Yeah, by `const` expression I mean `const foo = 5.2.ceil()`, for example.
Yeah sure, assuming that `ceil` is a `const fn` that would work. (sidenote: `const foo = &lt;definition&gt;;` is an item, not an expression ^,^)
None of the upstream contributors know Rust, or show any inclination to learn (they're a conservative bunch by nature, and to be fair, why should they move away from C if they don't wish to?), so I doubt that will ever happen.
I know my lingo is off, but as long as I get my point across...I'm tired and need to sleep haha. Of course we're assuming `ceil` is a `const fn`, which it should be (not sure why it wouldn't really).
How do people have so much time...
You could use a hash table and use the row and column indices as your key. 
Hey, I am a huge fan of Tantivy, and it's great that you are building an ES type search engine on top of it :) Your project already has 150 stars, I think you can maybe get some people to help you out if you created issues (and add the [Hacktoberfest](https://hacktoberfest.digitalocean.com) tag). I would also think a few traits could improve your code organization :) and moving the tests to a separate directory. Would love to see that grow!
&gt;You could use a hash table and use the row and column indices as your key. This will make sequential scanning costly. Only help for mutation.
It seems as though the purity requirements would cause short-circuiting and non-short-circuiting interpretations of any binary expression inside a `const fn` to evaluate identically. But I suspect the exception has to be made in cases where a non-short-circuiting version would infinitely recurse. e.g. `const fn foo() -&gt; bool { false &amp;&amp; foo() }` is valid when short-circuited, but nonsensical when short-circuiting isn't present.
It seems as though the purity requirements would cause short-circuiting and non-short-circuiting interpretations of any binary expression inside a const fn to evaluate identically. But I suspect the exception has to be made in cases where a non-short-circuiting version would infinitely recurse. e.g. const fn foo() -&gt; bool { false &amp;&amp; foo() } is valid when short-circuited, but nonsensical when short-circuiting isn't present. 
[Cranelift](https://github.com/CraneStation/cranelift) is a code generator written in Rust by Mozilla for the purpose of using it for machine code translations inside SpiderMonkey, Firefox's js engine. Also, there are plans to make the Rust compiler use cranelift instead of LLVM for debug builds.
Sloooowly. I'm new to system programming so I want to make sure I understand what I read (oppose to what I usually do with high level languages; skim over pages to find what I needed and just make things work ASAP). I'm learning through Programming Rust book, currently at page 280. 
Space filling curves such as Hilbert or z-order are the compromise. But I'd be surprised if they outperform simple row/column major orders enough in enough cases to be worth it. Something to look at though.
Anyone know why scrolling is so funky on this page? It feels like the page gets stuck in some areas.
[`Indexmap`](https://docs.rs/indexmap/1.0.1/indexmap/) is designed specifically for fast iteration.
Given that "either rows or columns will be efficient but not both" extends all the way down to the CPU cache, which isn't directly controllable through software, you first have to define what exactly you mean by "efficient".
This applies to divergence in general, not just infinite recursion. The main reason for this is that purity does not imply totality and neither does totality imply purity. As long as a function always diverges when given the same arguments, it is pure. If you write `const fn foo() -&gt; bool { false &amp;&amp; panic!() }` then under short circuiting behavior it won't panic but it will otherwise. For there to be no difference, both totality and purity must apply.
I learned rust because I wanted to learn a "systems language" but had become accustomed to modern "batteries included" languages with package managers and standard build systems. Rust, being approachable, allowed me to fill in low-level knowledge gaps that in-turn made C and C++ more approachable. A++++++++++ would learn again.
Just starting the game for the 1st time this week. Havent played yet. Is a Lenovo Yoga 710 a decent enough laptop to game on with Rust do ya'll think?
&gt; &amp;&amp; and || didn't actually short circuit Is that just a limitation of the current implementation, or is that stating something fundamental about const fn's inability to make those operators short circuit? If it's the latter, then I'm afraid I don't get why that would be.
this is how I did it. type MaybeToken = Option&lt;Result&lt;Token, ScannerError&gt;&gt;; where you have Ok/Err and Err could be Scanner error. here is the source code. &gt; https://github.com/ooooak/resolve-pkg/blob/master/src/syntax/scanner.rs Alos have a look at rob pike's video from 2011 on parsing. 
A limitation in the current implementation; there's nothing fundamental here as far as I know. :)
I'm attempting to create a compile-time units of measurement system. Very similar to Diminsioned ([https://github.com/paholg/dimensioned](https://github.com/paholg/dimensioned)), but with a handful of added features. But mostly it's to help me learn Rust since I'm super noob. We don't have const generics yet. But using typenum ([https://github.com/paholg/typenum](https://github.com/paholg/typenum)) we can achieve most of what they'll provide. For example I have \`trait SIRatios { type Length: Ratio, type Mass: Ratio, type Time: Ratio }\`. Then I have \`struct SIRatiosT&lt;L,M,T&gt;\` which is a concrete struct that defines Length, Mass, and Time. I also have \`trait SIExponents { type Length: typenum::Integer ... }\` and \`struct ExponentsT\`. Then I have \`trait SIUnits&lt;R,E&gt; where R: SIRatios, E: SIExponents\` and \`struct SIUnitsT&lt;R,E&gt; ...\`. And I have \`struct QuantityT&lt;T,U&gt;\`. My final type might look something like this: \`type KilometersPerHour2 = QuantityT&lt;f32, SIUnits&lt; SIRatios&lt;Kilo, Zero, Hour&gt;, SIExponents&lt;typenum::One, typenum::Zero, typenum::Two&gt;&gt;&gt;\` It's a mouthful. But all of those types are zero size. The size of a variable of type KilometersPerHour2 would be just four bytes, the size of the f32. Math operations can be fully type safe. You can't mix up units. Those operations have to be generic. Which means I need a whole bunch of base traits to constraint them so the compiler yells at you when you do it wrong. &amp;#x200B;
I took a class at Stanford that was in rust and we had two weeks to read the book while doing assignments. It took me about two days though I will admit I found it an enjoyable read and did not feel pressured to understand everything in one pass since our professor was giving lectures on rust. 
It sounds similar to pure functions in functional programming, but less useful since it doesn't accept user input.
How does it compare performance wise?
Why just for debug builds?
In tokens method, I am just returning tokens and logging error to console. I don't want to the extra work. You can catch all the errors then you have to set the next valid point to parse your source code. for me, it was too much work.
 for source in package.source { let tokens = Scanner::new(source.source.as_str()).tokens(); deps::log_deps(&amp;tokens) }
I'm writing a simple command line todo app. Will publish a tutorial blog once its done.
I think cranelift doesn't optimize.
Correct. The thing is how switch between both ways? I can have 2 separated structs but when try to bring them together with a trait It fail apart. 
You just catch_unwind it way up the stack? This is like installing a custom global panic handler.
I'm very relieved, actually! I had never seen this page deposited asking having run a survey on CLIs with 1k responses 😅 A few days ago, oclif a CLI framework for node popped up as well, which I still have to check out fully. (Spoiler alert: I'm pretty sure structopt with Rusts stricter and enums is way more powerful than what they deliver with their typescript support. They do have some neat ideas on other aspects, though.)
LLVM is so good at optimizing code that it's actually somewhat poor at *not* optimizing code. For cases where the user wants to receive an artifact as fast as possible--willing to trade off (lots of) runtime performance for (lots of) compiler performance--an alternative code generator may be superior to LLVM.
&gt; I got a Do Not Disturb sign on my hotel door. It says Do Not Disturb. It's time to go with DON'T disturb. It's been Do Not for too long. We need to embrace the contraction. – Mitch Hedberg [Source: Mitch All Together](http://cynicsaccelerants.tumblr.com)
oclif looks pretty good but I agree that safety is not node's specialty. This article is based on the release of oclif and guided their writing of it. Heroku's cli is pretty great if you havent used it!
Frankly, all I really learned about mp3 is it's made of a sequence of fixed size header+data chunks, it involves lots of math I don't understand, and that reading minimp3 is the wrong way to learn about the actual algorithms...
Wait, what?
Your impression is well founded ;) `const fn foo() { if true {} }` will indeed refuse to compile. I think one of the next items we'll want to stabilize is destructuring and control flow in `const fn`s.
Cool! So in order to support Cranelift for debug builds, the work that would need to be done is allowing Rust to be compiled to Cranelift IR in addition to LLVM IR?
The problem is that I'm not entirely sure what you're asking when you say "So the idea is provide a simple switch in the lang to declare a relation as by-columns or rows." and include these lines in your example. fn row(&amp;self, pos:usize) -&gt; &amp;Data; //Can't, only valid for by-rows fn col(&amp;self, pos:usize) -&gt; &amp;Data; //Can't, only valid for by-columns If my guess is correct, it sounds like you might want something similar to what Hyper does to catch invalid use of the HTTP protocol at compile time. I haven't needed to do anything like that personally yet, so I don't know if you can do it with traits or whether it's limited to specific implementations of traits, but, what Hyper does is to add a type parameter to `Request`. The method for adding HTTP headers is defined on `Request&lt;()&gt;` but not on `Request&lt;Body&gt;` so you get a compile-time error if you try to add headers after you begin the request body.
Yes, though also remember why Rust uses LLVM in the first place: turning IR into machine code is something that needs to be done for every platform that you want to support, and that's a lot of work that nobody wants to do (hence why everyone uses LLVM)... and that's something that Cranelift will need to do. So in practice Cranelift will (for the foreseeable future) only be usable for a certain subset of targets--likely the exact same targets that Firefox runs on. Fortunately, even if you're cross-compiling you probably don't need *debug* builds to always generate code for your cross-compile target, so you can often still benefit from dev-time speedups as long as you're developing on a supported platform. I'm not involved with the project, but if it's being included in Firefox nightly then I uninformedly suspect that the Rust IR -&gt; Cranelift IR stage is actually somewhat well-developed, and that the Cranelift IR -&gt; machine code stage is the bigger blocker right now.
Erlang has the most powerful pattern matching I've ever seen and can also be applied to binary data pretty much as-is. Ergonomics are amazing, but I don't think throughput is going to be all that great for parts that are very heavy on low-level byte manipulation. Rust, C or Go would probably perform better.
Kind of a weird perspective. You could describe the difference between static and dynamic types like that too - after all, every Python object has a type, so what's the point of declaring variable types? Just to enforce that a variable always holds a value of one type.
They are pure functions, yes.
woult it not be better if the compiler always tried to handle functions as const fn?
Well, next time you know the user input at compile-time, call me.
Will it allow to create a static mutex? Can't wait to get rid of all lazy_statics in my code.
Time is something you take.
I've published the [rust_qt_binding_generator crate](https://crates.io/crates/rust_qt_binding_generator). Now Qt applications can be compiled with a simple `[build.rs](https://cgit.kde.org/scratch/vandenoever/mailmodel.git/tree/build.rs)`. There is an example application `mailmodel` that can be installed with `cargo install mailmodel`. I've only tested on Linux. Testing for Windows, Mac OSX and perhaps even Android and iOS would be appreciated.
Doesn't look like it because Mutex::new is not a const fn. And it can't be either, since it performs ffi to initialize the underlying native mutex.
Are you working from a single snapshot of the Emacs codebase from way back when Remacs was started? If not, how are you handling changes to these files when they occur upstream? Perhaps it's possible that the C parts of Emacs are sufficiently mature and foundational by now that they don't get touched very often...
But in C you can use PTHREAD_MUTEX_INITIALIZER constant to statically init your mutexes, you don't need to make any function calls for that.
Here I'll do it for you /r/woosh
But in C you can use PTHREAD_MUTEX_INITIALIZER constant to statically init your mutexes, you don't need to make any function calls for that.
The technical term I'd use here is "boilerplate".
I doubt that the standard library Mutex::new will ever be a const fn, since it might use many different apis underneath depending on the target platform. But it might be possible to create a mutex crate that either is limited to certain target platforms or implements a Mutex in pure Rust and has a const new().
Nice! It compiles and works on my computer, so I might as well use it :) Hopefully I'll take the time to contribute.
At this point it's relatively easy to make contributions. You can try to port small lisp functions, that don't require much knowledge of the code base.
Yes, I can see that! I'll try :)
There's so much trying to convince me to switch to Firefox, but I just struggle using it after getting used to Vivaldi and all its nice features, not the least of which is the quick command box that lets me search all of my hundreds of tabs without having to manually locate them. If I don't have the tab I'm looking for, it will instead open a search engine or the url itself. Does Firefox have anything like this? If so I would switch in a heartbeat.
The plan is to translate the AST into a list of instructions to be executed in a VM. Not sure what to call the instructions so I called it bytecode. The language I am designing is an interpreted language, so parsing into AST and then generating the code might be too slow?
If this isn't on the description page of cranelift yet, it needs to be there. This short comparison is a lot more insightful than the detailed one that was on cranelift's website when I last looked at it.
For small single/small series projects, is there any small board similar to the ESP-WROOM\* boards that is supported for Rust now in the same price range? 
&gt; He might see Rust will dethrone C in FLOSS projects soon! That's a statement that's unlikely to be true, very religious of you.
It’s probably in /dev somewhere.. I believe on linux you have /dev/input
I wouldn't worry without doing any profiling... Parsing might be the slowest part if you're not doing any fancy code optimizations, depending on the algorithm and the grammar. You can check Rust, Lua, Python, etc. for reference if you really want to, but if it's a simple language and interpreter, there might not be any noticeable problems.
Cool thanks!
Unless I am misunderstanding your request, Firefox already has this functionality in the Awesome Bar. If you begin typing in a URL or page name that is already open in an existing tab, it will show an entry in the Awesome Bar with a tiny tab icon and the text _Switch to tab_ on the right. Select it, and it will switch over to that tab. Otherwise, it will attempt to search for it or resolve it as a URL. Optionally, if you dislike the search suggestions being shown in the URL bar, you can turn them off in _Preferences_ &gt; _Search_, or perhaps uncheck _Show search suggestions ahead of browsing history in address bar results_ if you would rather Firefox prioritize your history and open tab results over search.
Author here. Feel free to ask questions via mail (mailinglist or directly to me) or here. I'm happy to answer all of your questions and of course can also mentor you for your first patches! The codebase is rather clean IMO, some parts are "old" (as in ... the code is not very idomatic because it was written over a year ago and I'm still learning - the project exists for ~3 years now btw), so there's also a bit of refactoring possible inside the codebase! But whether you want to implement new features or help with a certain task - you're welcome of course!
Shout out Wilfred (he started off the porting effort and "owns" the repo) who was a colleague at a firm in London and who patiently answered my endless Emacs questions. He is truly a brilliant guy. I didn't realize his effort to port Emacs to Rust has gained so much traction. Well done!
Yeah, as far as I can tell the only thing it does is take Cranelift IR as input and generate machine code from it.
Definitely yes, and I probably won't write another line of C ever.
That seems like the same page I looked at and couldn't figure out the answer to why anyone would want to use cranelift instead of LLVM. It looked to me like a reimplementation of LLVM with some different design choices that don't change the outcome very much. The only meaningful answer I got was that the design choices allowed cranelift to be more parallelizeable, I think.
I like this solution in that it is simple, elegant and eloquent. Unfortunately, in certain cases the input vectors are quite large, so the allocation of temporary vectors would represent too much overhead. On the other hand, isn't there a way to merge multiple iterators without having to materialize them into vectors?
Luckily our obsession with computers and logic naturally dissuades the opposite gender from taking too much of our time. Yes, luckily. 
I like this a lot! While it does contain unsafe code, under the assumption that the indices are disjoint, it should not result in UB. It certainly does not involve casting \*const to \*mut. My intention is to wrap it in a struct and some other API that ensures that all indices are disjoint.
Isn't that "style guide" a bit contentious? It seems to go against many elements of long-standing traditional style when it comes to how CLI interfaces are written (see ESR's *The Art of UNIX Programming*), and even to inappropriately conflate CLI and TUI at times. CLI apps are often accessed programmatically or from non-traditional interfaces (e.g. due to accessibility requirements), and following Heroku's style would make this a lot harder for no real benefit.
&gt; So like C++'s constexpr? Not at all. C++'s constexpr functions are not pure, e.g., constexpr auto v0 = foo(0); constexpr auto v1 = foo(0); assert(v0 == v1); // might fail
&gt; Pretty much like constexpr (but I assume there will be some differences...) C++'s constexpr functions are not required to be pure, e.g., constexpr int inc_counter() { /* impl */ } constexpr auto v0 = inc_counter(); constexpr auto v1 = inc_counter(); assert(v0 != v1); // OK 
Good question! While you could use lorikeet as a pure task runner, I would hazard that GNU Parallel would be faster for executing tasks in parallel. lorikeet is different in a number of ways: lorikeet builds a dependency graph of tests that need to execute, so if you have some setup that needs to happen (like copying a file, or getting some cookies), you can ensure that things happen in order, but they also happen as soon as possible. As an example, say you have 3 tests: `test1`, `test2`, `test3`. `test3` depends on `test2`, but both `test1` &amp; `test2` don't have any dependencies. Lorikeet will take your definitions and run `test1` &amp; `test2` in parallel, wait for both to finish, then run `test3` straight after! Also: if `test2` fails, then `test3` won't run. lorikeet step files are meant to be human-readable and easily parseable even (hopefully) for non-technical users. You need to name your steps and optionally set descriptions to feed in what the test does. lorikeet has a standard output format, and you can push your results via a webhook url, which lorikeet will post to using a standard format. In the latest release, JUnit report output is supported too! We have a mattermost chatroom that receives any alerts from our environments when things go wrong. I hope that makes sense. 
Well, you can do that by creating a `const` first, instead of using the function directly. const MY_VALUE: u64 = my_const_func(); // do stuff with MY_VALUE This way, you are forcing `my_const_func` to be `const fn` and to be evaluated at compile-time. If you tried to replace it with a non-`const fn`, you would get a compiler error. If you just use the function directly, then there is no guarantee about whether it would be evaluated at compile time or at runtime. Semantically, you should think of it as being evaluated at runtime. However, the optimizer will try to evaluate things at compile time as much as possible (regardless of whether they are `const fn` or not), so in a release build it will probably be evaluated at compile time anyway.
No. There's [`iterr`](https://crates.io/crates/iterr), but it's not particularly idiomatic.
Because "idiomatic" is the accepted way of doing things, and `iterr` has only ever been downloaded 58 times. It's like putting "Kids love the taste!" on packaging when you've asked exactly two children what they think. It's *just* a bit disingenuous.
In the other comment I am referring to some other hypothetical language where one might fetch data from the network during compilation (like one can do with a proc-macro today, but then you don't have type information...). This is meant as an example of why one might want to do IO at compile time. I am not talking about Rust allowing you to do IO in `const fn`s. If this was unclear I am sorry.
Yeah. I like the idea of compile time execution using an interpreter, so you can run *any* arbitrary code (so long as it terminates, obviously...) and have it's output integrated into the compiled output. Would be very versatile and useful!
Ah I see. Thanks!
It's at an early stage of development. Landing in Firefox Nightly (behind a pref) is an important milestone because it means it's easier for us to test, fuzz, benchmark, and so on, but there's much more to do!
Can you elaborate a bit? The CLI WG discussed the style of writing CLIs quite a bit but I'm very interested to hear what is important to you and what issues you see here. (We don't agree with everything this page says; maybe I can go into more detail when I have more time)
Yes, way better.
Probably, if it were that way from the start. But that would be one hell of a breaking change. Too late.
Indeed. This was supposed to be a tong-in-cheek comment, but I failed to write it in a way that that made my sarcasm explicit. English is hard :(
Does this mean that one has to choose between writing code that works at compile-time, and writing code that's efficient at run-time?
It's hard to prove termination where IO is involved (e.g. network requests -- at most you can specify time-outs), so instead you need to informally rely on termination being respected. Right now in Rust, you can do IO in procedural macros and build scripts; however, they cannot interface with the type system and are syntactic-only approaches.
The issue is that moving a function from const fn to normal fn is a breaking change. Let's say you implement a crate. You never intended a function in it to be const, you just happen to not currently use anything that would make it not be. Someone else depends on your crate, and uses your function in a const context. Then, you notice a bug and fix it. Only, doing so requires using one of the operations that makes a function not const. Now, the compile of the crate user fails. Function being marked const is an *interface promise* that not only is it currently const, but it will remain so in the future. 
I believe some of those operations could become `const fn`s or `const unsafe fn`s if the MIR interpreter can handle it. In other cases, we may perhaps allow you to unsafely call a normal `fn` inside `const fn` as long as you can manually prove to yourself that it doesn't break determinism invariants that `const fn` requires. This is then sort of like how you can use `unsafe { .. }` to say "trust me, I know what I'm doing" to the compiler. Still, there might be cases where you'll simply be unable to write as good code in `const fn` as you can with `fn`. I don't want to give definitive answers here because it is still too early to tell. Hopefully we can push the envelope as much as possible with interesting things that can be done with `const fn` without loosing any statically verified guarantees it entails.
Oh, snap!
Not implemented yet. At some point it will implement optimizations. Probably dynamic optimization and static optimization. I heard plans of them doing some PGO at some point.
&gt; In other cases, we may perhaps allow you to unsafely call a normal fn inside const fn as long as you can manually prove to yourself that it doesn't break determinism invariants that const fn requires. This is then sort of like how you can use unsafe { .. } to say "trust me, I know what I'm doing" to the compiler. That is hopeful. If `miri` cannot execute the normal `fn`, one would still need to be able to branch on whether the function is being executed at compile-time or run-time here.
It's a big milestone! The first of many :-). It's conplete enough to pass the wasm testsuite, but there's more to do to make it fast and stable. So it's not something for casual browser users to try out yet :-). If people are interested in getting involved, check out the [GitHub repo](https://github.com/CraneStation/cranelift)!
What about legacy bluetooth and RFCOMM? Is that supported or planned?
Procedural Macros fill that niche. I don't see how \`\`\`const fn\`\`\` supporting non-const arguments would be an improvement (or objectively different) than procedural macros.
is he still into remacs ?
For some definition of "soon" I'd think it would be highly likely unless something even better than Rust comes along for the space. I'm not sure how religion comes into it.
Sure, proc macros are the mechanism used for this in Rust. However, the main difference as compared to type providers in Idris is that procedural macros are syntactic and have no access to type information which can be limiting. I'm not saying we should do anything to change this situation, just laying out the landscape :)
You call this "cool thing", i call this "scary thing"
It made me a broadly better programmer, as someone who's just a web developer. Better understanding of static type systems (types generally), better understanding of references, moves, borrows (Rust-specific, but cool concept), broader ideas in terms of how to approach problems (Option and Result ADTs, matching, etc). It's impressive how approachable this language is.
This is very cool, we also use tcl modules on our servers / clusters. I'll give rsmodules a try. And the Readme is just wonderful, I wish more projects had such a nice Readme file!
it's all good &lt;3
&gt; which the acronym DRY (Don't repeat yourself) would describe perfectly fine. "Don't repeat yourself" is the short version of the aphorism, which is &gt; Every piece of knowledge must have a single, unambiguous, authoritative representation within a system. The repetition of `use a` etc happens because there is a single, unambiguous representation of a. This code is DRY.
So why not make it the default behavior for `fn`?
Too many of them can *potentially* bloat the binary.
That's fair. Excited for this new capability!
Instead of using the crates.io API can't you use this: https://github.com/rust-lang/crates.io-index it's the index that crates.io uses. It's also what rue compiler uses to find a crate to download.
Safely catching certain classes of bugs at runtime is very different from actually statically ensuring that such bugs \*cannot exist\* in a code fragment.
Thank you for the compliment :) The only feature that isn’t ready is the interactive modulefile creation wizard. 
Thank you for the compliment :) The only feature that isn’t ready is the interactive modulefile creation wizard. 
I thought you were talking about desirable features for Rust's constexpr, my bad.
I've been trying to make an iCalendar crate but I realized the current approach does not work and I'm working on a design document. I really don't know what "high level API" means, so if you could give some input that would be nice. I only tried the iCalendar-rs crate and tried fixing some problems but it's difficult to get it easy to use without losing access to the finer details.
The `spin` crate has a spinlock Mutex that has `const fn new`.
Are you using the rust-avr fork or are you using a full blown Linux board like the Onion Omega 2? I'm just interested cause I recently got done with a custom USB device using an ATTiny85 and the only thing I was able to write in Rust was the host side drivers. You can find that here: https://computeco.de/DyingLight I really want to program the tiny using rust though. 
I work as a web dev too (primarily backend Java dev, but also a liitle front end), and I agree.Programming in Rust has given me an appreciation for strong type systems, and has effected tge way I approach problems, even in Java.
Can you please explain? Isn't it like marking that a function exists not only in runtime, but in compile time too? How could this add to a binnary size? 
I'm excited to see work done in the BLE space in rust. I do a lot of BLE related stuff for my job and it would be nice to be able to point to rust in the future!
Hey, one goal of the project is to be extendable, so you could just write a server which is compatible to Chromecast using the existing libraries. The playback is working as follows (for streaming): After finding a track key the client will send a "next\_packet" call to the server with a certain packet id and track key. The server will save this request in the client state and returns 19200 samples (400ms), every call with the same packet id (regardless of the parameter) will yield the next sample packet. For now the request format is JSON, but my plan is actually to have a single protocol library and use webassembly. This would save a lot of transmission space and make the javascript library redundant. For Chromecast though this approach is incompatible. I don't know the protocol, but it will probably get the whole audio file over a common protocol like HTTP. If this is the case, you could invoke a "download" request and wait until ffmpeg has converted the file. Hex has a HTTP server builtin and will put the audio file in a \`data/download\` folder, so you could just pass the URL. But I haven't documented the protocol properly, so perhaps the best if to wait till I moved the protocol into its own crate :) I just took a short look at your repository and it seems that we have similar goals indeed, except that you're using FLAC instead of opus and saves the metadata to files instead of a database. I should really give Elm a try as a language, but never managed to start with it .. &amp;#x200B;
Hell, Rust made me a better _person_. 
Because they want constants to be reproducible, so only "pure functions" can be supported. The `const` is an API guarantee that you won't break this purity. I think there should be an "unsafe" version of that though where you can just call any function regardless of purity in a const context (you can do so anyway via a proc macro).
Nice logo! :) I'm trying to solve the mobility problem in a different way. There is a \`sync\` library in Hex which support probing for peers and creating a P2P overlay network. All devices should have running one. So you could either download playlists to your local copy of music (metadata is always shared but music data not) or have a single public IP which communicates between two peers behind NATs. I actually don't have much knowledge in NAT traversal but I hope that I can have my phone in the future and just play the music anywhere.
I know you're looking for technical feedback, but I recommend giving [`uom`](https://github.com/iliekturtles/uom) a look while you're working in this space.
This is primarily targeted at people running machines with `systemd` on Google Cloud Platform. In those setups one can simply start `journaldriver` and it will work out-of-the-box (provided that the instance has permission to write logs). Most log-forwarding solutions appear to be Rube-Goldberg-machines of various components to make forwarding work, which may be required if you don't control the things that generate those logs - but for 99% of use-cases simply reading from `journald` and forwarding that is all that I want. Journaldriver does this by interfacing directly with the `journald` APIs, so the classic diagram of: [ stackdriver output plugin ] | [ log forwarding agent ] | [ journald input plugin ] | [ journalctl CLI ] | [ journald API ] is replaced with [ journaldriver ] | [ journald API ] This was written for an environment running NixOS (where services will write to `journald` by default) and, as of NixOS 18.09, can be configured on any NixOS GCE instance with `services.journaldriver.enable = true` Feedback welcome! 
Seems a little weird that after I say that I have never used rust to write web apps, the next page is all questions about my experience with rust web apps and frameworks
Because then changing a bit of code inside the function changes its visibility/accessibility, which feels weird. It's like automatically making a type `Copy` if it only contains `Copy` members: it's technically possible, but means it becomes very easy to break people's code without even being aware of it, by modifying implementation details of the object.
Have you ever considered creating a screencast for imag just showing what it does? Unfortunately, I feel like I would have to be right inside your head to understand what it's for based off of the current documentation.
This looks like a neat tool. A few minor comments from poking through the code =P - You don't need to explicitly provide the path to modules when the name of the module is the same as the name of the Rust file (e.g. [here](https://github.com/fretn/rsmodules/blob/87a45f96a9bd45b86300a6027bb29855778d4f5e/src/rsmodules.rs#L35-L36)). - Instead of your custom stderr macros, the standard library provides [`eprintln!`](https://doc.rust-lang.org/stable/std/macro.eprintln.html). Probably not a huge deal, but nice to be aware of =). The thing I was actually looking for (and didn't find in a couple minutes of poking) is how you're setting environment variables in the parent shell. Is there a wrapper around the main Rust binary that I missed?
If I'm need to do some quick math Python is still my go to.
That seems like another problem, though. By my understanding, what it should really be is when `const fn`s get called, it is attempted to do this at compile time (not possible, I think, depending on context, but that's determinable). `fn`s perhaps "by default" for some loose definition of "default" would be determined dynamically. The answer to this I think is just that's already how it is depending on optimizations. I've put together [a quick example](https://godbolt.org/z/OfxDOe) in the compiler explorer which shows that normal `fn`s can be run at compile-time. The reason `fn`s aren't `const` by default is... they are. =)
[It is!](https://godbolt.org/z/OfxDOe) (given sufficient optimizations)
Good idea, thanks! Will do that as soon as I'm home!
This is more about writing code once to run once. However slow program you write it is going to execute faster than you wrote it. Unless you are doing big data.
&gt;The problem is that I'm not entirely sure what you're asking when you say Ok, the problem is that for both layouts, I \*wish\* to have efficient access (not cloning) for both rows and columns: [1,a;2,b] = col(0) = &amp;[1,2] [1,2;a,b] = col(0) = &amp;[1,2] but if I model the data for rows, I need to walk across columns, clone and return: ↓ ↓ [1,a;2,b] 
So by high-level I basically mean that I don't want to fiddle around with "component" and "property"-objects but with "Event"s, " Calendar"s and so on. When I started working on the rust-vobject crate and contributing to it, it had only the former. I added some features to have a more "high-level" view for things, but is far from convenient! I plan to continue work on rust-vobject as I have time... Maybe we can join our efforts?
Hi guys, if you'r interested in Rust and industrial software you're very welcome to our meetup :)
It looks like the mbed is a Coretex M, which should be one of the most-supported microcontrollers. I'm not 100% sure but I'd start poking around at https://github.com/rust-embedded/wg
https://news.ycombinator.com/item?id=18182742 I submitted the article to Hacker News and it made it to the homepage for a few hours, gathering some interesting comments. Sorry /u/db48x, it seems your own submission just had a bad timing :/
You could try `FnvHashMap` from [fnv crate](https://crates.io/crates/fnv). 
Alas, alack! All those internet points, lost. Thanks though :)
Agreed. &amp;#x200B; [https://crates.io/policies#squatting](https://crates.io/policies#squatting) makes it worse. It is basically allowed.
There are a few versions of CPP that may do what you want: C Partial Preprocessor: https://www.muppetlabs.com/~breadbox/software/cppp.html Coan: http://coan2.sourceforge.net/http://coan2.sourceforge.net/ Sunifdef: https://sourceforge.net/projects/sunifdef/ There is this paper (https://www.cs.cmu.edu/~ckaestne/pdf/vamos11.pdf) on how to do some conditional processing in C. 
Yup, it's insane. I'm really hoping they have plans to change their policies because it's getting silly with the number of people name squatting.
It's getting there and there are talks about using a superoptimizer for cranelift, but it's a ways off.
thx. Traits are something I don't really understand yet, I'll need to analyse your code and see how I can implement this thanks for the input, this is the reason I've posted this in this subreddit
Huh, I had no idea Rust had an "update syntax". That's kind of cool! I'll have to refactor some of my smaller projects to include that
They'll need to acknowledge it's a problem first. Somehow it wasn't enough that it was already a problem in all other ecosystems without namespaces.
I very much agree. A firmer stance is very much needed. At this point squatting is a pandemic in Cargo and something needs to be done about it. I know active moderation may require more work that could be used elsewhere but it has gotten to a point where it seems like squatting does need to take some form of priority
Would love to receive feedback on the code since it's written in Rust. It's my first "real" application in Rust. My background being everything from C/C++ to Java, some C# and everything else in between.
If you want to generate geometry for shapes, check out the `lyon` crate.
Wow. I'm so old and slow...
Someone should write abot that will take all names. Then they will have to do something about it.
What are you referring to? I can’t find what you’re talking about in the article.
I hope one day they change the policy to "&lt;username&gt;/&lt;cratename&gt;" and you can only get “&lt;cratename&gt;" once you reach sufficient downloads.
Isn't Wrap a better name?
This thread speaks of the same problem: https://www.reddit.com/r/rust/comments/9aaanw/cargo_crate_name_reservation_spam/ Check this out: https://internals.rust-lang.org/t/crates-io-package-policies/1041 TL;DR &gt; In short, we don’t think the Cargo ecosystem would be better off if Piston chose a name like bvssvni/game-engine(allowing other users to choose wycats/game-engine) instead of simply piston. 
I'm using a teensy.
Probably the story about default arguments. 
Opinions can change
That's odd, but not a huge problem as the main application is called warp-packer.
I actually like your suggestion. I wish I had thought of that before :P
Must not have been great bots.
Great writeup. Can anyone speak to how a properly reflected serialization system might work given that structs have nondeterministic ordering or even possible fuzzing. Writing structs to disk only to have them all be corrupt reading back with a program compiled with a different version of rust is a bit scary. 
`cargo-squat`!
The answer to both questions is: not yet, but it’s easy enough to add. I plan to make the repo public by mid-December. There are some unfortunate constraints on me doing it any sooner.
&gt;Someone should write a bot that will take all names All names? Like, strings of **every length**? ;-)
It's been a collaboration. A dozen or so folks occasionally having some spare time to write some code. Rust makes it easy to port one function at a time, and then link the two halves together at build time.
Every length until 64. https://github.com/rust-lang/crates.io/pull/718
Please refer to what I wrote in the previous thread on this: https://www.reddit.com/r/rust/comments/9jbnrc/why_is_squatting_on_cratesio_allowed/e6qnoi3/
Which I’m recently finding to also be Rust. Compiler guarantees are very nice when trying to write code quickly. 
I would have called that `pure fn` then
Statistically speaking, any naming clash is far more likely to happen with a non-cargo package so there is still potential for confusion. And if the other package is a cargo package, it's likely to be abandoned/unused/squatted/low-effort so nobody would notice the naming clash. 
This is the crux of the issue and what what rust/cargo just doesn't seem to understand. A common argument used to justify the current policy and a single namespace is pointing to those other package managers and the fact they work just fine. What they seem to forget is these other package managers actually care about squatting and have policies to deal with it, basically do something other than *explicitly allowing it*. They are not comparable to cargo. If i wanted to make a bot to take every single package name it could, thats explicitly allowed. Not only that but i wonder the possible ramifications of this. Current policy is "names are first come, first serve, and won't be removed for squatting". Does that mean if this theoretical bot is made and takes every available name, cargo is dead? Are they allowed to suddenly change their policy and remove all the squatted packages?
Yay, the big u8::MAX!
Still seems like the wrong default entirely: once a public function is const, it can't be de-consted without breaking the API, so whether to declare a function as const should be carefully considered and explicitly opted into.
I am very interested :). But unfortunately I'm in the wrong country for the meet up. 
I wrote Python this weekend for the first time since I picked up Rust two years ago. I only fixed about 10 lines of code in someone else's 300 line program. The program had about 5 minutes of work before it hit the code I was working on. I'd run it, wait 5 minutes, find out a float is being used for index access. Fix that, run, wait five minutes, find I'd typo'd a variable name. Run, wait five minutes, unhandled exception. It took me almost an hour to fix all the issues the Rust typesystem would have caught upfront. And the friend I was helping makes fun of me for being a Rust fanboy. I made sure she heard all of my complaints lol
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [Did learning Rust make you better than everyone else?](https://www.reddit.com/r/rustjerk/comments/9n0vxa/did_learning_rust_make_you_better_than_everyone/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Wow, great post. This articulates a vague feeling I've had for quite a while in a very fine way! (And if you do add references to papers on the topic, please let me know!)
I didn't *exactly* answer your question directly, but wrote a blog post responding to your first sentence: https://words.steveklabnik.com/borrow-checking-escape-analysis-and-the-generational-hypothesis
&gt; What would that expand to? I am not sure, to be honest. I am just debating possibilities, and did not think about the implementation. The easiest way would probably be to wrap the calling code completely (aka, not this syntax), but it's not as nice with the nesting and all which is why I'd prefer the syntax I demonstrated. Especially, wrapping in lambdas would imply moving stuff in/out, which is not trivial to automate. I am not sure what are the possibilities for plugins. Compilers hooks may be necessary to achieve it.
Thanks! Will do.
The link leads to a 404 page :( Is the project private?
This looks interesting. I'll add those collection trait
What are the use cases for `stringify!`? This is the example from the docs: let one_plus_one = stringify!(1 + 1); assert_eq!(one_plus_one, "1 + 1"); But if `stringify!` just turns its argument into a `&amp;'static str` without evaluating expressions, then when would you ever use it over simply: let one_plus_one = "1 + 1"; &amp;#x200B;
I'm always wary of Python for anything more critical than some data-processing or personal tools that don't get pummeled by users. The most thorough handling of a rare error can be made futile by a typo in a variable name. You pretty much need 100% unit test coverage to achieve what comes for free in static languages.
&gt; There was a really great compiler dev (gcc?) email about this history but I can't seem to find it anymore. So for the time-being I'll settle for Fabien Giesen's discussion on the matter. I'm really hoping someone knows what the author is talking about here and can link that email chain.
So, assuming only alphanumeric characters, this is going to be 36^64, or ~4.011991915×10⁹⁹, which is significantly more than the number of atoms in the universe. Good luck with that.
Any git repo with remote access.
I found the post rambling to be honest :/ I struggled to connect the various parts together, it felt like I was pulled in many different directions haphazardly. On the other hand, thought provoking. I had never though of the idea of static garbage collection and it makes complete sense.
The headline is striking. Why have I never seen it phrased this way before?
I agree. A bit disjointed, but generally thought provoking. A bit of polish and this could be a pretty amazing piece of work, a few references, a bit of reorganization, maybe a diagram or two. yup, awesome.
Is it basically "materialized views, but very good"?
Share video slides and code
If you have any concrete thoughts on organization, I'd like to hear them!
My time trying Firefox, I did see that feature, but I didn't know the priority could be changed. Is there anything else the Awesome Bar can do? Vivaldi allows opening settings, new windows, and pretty much any browser action from the quick commands.
I'm firmly in the restricted I/O camp, personally. I've seen very complex build setups, and they all fail tremendously. It's essentially for me that a project can be built offline, and that a build be 100% reproducible. And that's before all the security issues that unrestricted I/O affords; the recent ESLint fiasco is just a heads up. Of course, with the freedom afforded in `build.rs` that ship has sailed, somewhat, but `build.rs` is not part of the language and it's easy to check whether a project contains a `build.rs` or not. `const fn` would make it much more difficult to check whether a crate does I/O or not during compilation.
Haha, not too far off. I'd say the two big differences with traditional materialized views are: a) Noria provides _partial_ materializations where not *all* results are stored and maintained, which improves both throughput and memory use; and b) Noria's materialized views are optimized for reads — all reads can proceed concurrently with one another, and concurrently with writes, whereas existing approaches require reads to either block writes, or to implement reads *as* writes.
In C, or in POSIX? The standard library relies on the OS mutex facilities; not all OS are POSIX.
My first thought is that you have inverted details vs general concepts. You introduce generational garbage collection and progressive types then bring rust back in. Normally when you write and article/blog post you let the first paragraph (or two) cover the entire story, then tease out a larger over all, then you cover everything in detail. This is done so that if someone gets bored or stops reading they still have a general overview with specific details further down, it also allows a reader to skip paragraphs which cover specific details. (this is historically the case since it allows an editor to cut blocks of detail to shorten stories as needed without removing the over all readability/understand-ability of a story). Yet another way to see programming as like writing (or the inverse).
Yeah, that makes sense, thanks. I've always *hated* that style of writing, but it *is* effective.
&gt; I'm especially happy that they chose to ignore environment variables altogether as a form of input. Me too! When a program runs differently when launched directly and launched through a shell script (written so as to wipe the environment), it's extremely surprising... and sometimes leads to very unpleasant post-apocalyptic scenarios.
Wow! I've only heard `Rust has no garbage collection system` as one of the features, and when put this way, it does make sense. But, I'm not sure - this isn't necessarily a bad thing, right?
Probably because, as the post notes, "garbage collection" as popularly understood isn't really compatible with being "static". But I was once asked in a phone interview how one could add garbage collection to a C or C++ system; I don't remember what I said, but it turned out the interviewer was looking for me to describe reference-counted smart pointers. 
Yeah, my assertion in this post is that similar to how people say RC isn’t GC, they also say rust has no GC, but from a certain perspective, this isn’t correct. It’s not a bad thing at all.
I'm honestly not sure of all the features the Awesome Bar provides on hand, but my impression is that it is generally adequate out of the box, but perhaps less full-featured than Vivaldi's. There is [a helpful page on Mozilla Support](https://support.mozilla.org/en-US/kb/awesome-bar-search-firefox-bookmarks-history-tabs) listing the built-in features of the Awesome Bar. If the Awesome Bar's feature set seems too spartan and you happen to enjoy Vim-style keybindings, I would personally recommend [Vimium for Firefox](https://addons.mozilla.org/en-US/firefox/addon/vimium-ff/) as a more flexible keystroke-driven alternative. I simply cannot live without it day-to-day, especially pressing `F` anywhere on the page to navigate arbitrary links while rarely needing to lift my fingers off the home row.
This seems very similar to [AppImage](https://appimage.org/).
I'm honestly not sure of all the features the Awesome Bar provides on hand, but my impression is that it is generally adequate out of the box, but perhaps less full-featured than Vivaldi's. There is [a helpful page on Mozilla Support](https://support.mozilla.org/en-US/kb/awesome-bar-search-firefox-bookmarks-history-tabs) listing the built-in features of the Awesome Bar. If the Awesome Bar's feature set seems too spartan and you happen to enjoy Vim-style keybindings, I would personally recommend [Vimium for Firefox](https://addons.mozilla.org/en-US/firefox/addon/vimium-ff/) as a more flexible keystroke-driven alternative. I simply cannot live without it day-to-day, especially pressing `F` anywhere on the page to navigate arbitrary links while rarely needing to lift my fingers off the home row.
I'm going to be watching this project!
That reads, looks, and sounds great!
So it *is* possible according to language rules? Damn. We need to fix some nasty bugs.
5 jobs listed! Is that a new record?
It specifically depends on how familiar you are with the concepts Rust uses. And some of those are unique to Rust. Let me say, though, that once you understand the value each concept have, you'll be thrilled. Lots of "a-ha" moments.
Is it possible to get repr of the type in procmacro to know if layout is predefined or not?
Yeah, it doesn't match my details focused mental models either...but then...we aren't the usual types of readers I expect =-P Programmers, and by that I mean people who self identify as programmers not just people who program (even for a living), tend to be pedantic both through general personality as well as training. This leads to a different mental model, focus, and unfortunately social interactions. 
yes: https://github.com/servo/serde/blob/deserialize_from_enums8/serde_derive/src/internals/ast.rs#L165-L204
Maybe an annotation-based proc macro could work?
This is pretty awesome!
You may want to look into how numpy does it. IIRC, it supports both layouts in the backing store, (called Fortran vs. C-style) and let's the user switch, knowing which operations will be done next, and which ordering is most efficient for that. This does not support your desire for /simultaneously/ being efficient in both directions though. Another option that graphics often employ for improving cache use, is storing the pixels in tiled order instead, in squares of NxN values. This is efficient if operations on one value mostly depends on the adjacent values (in both directions).
I would not say that GC and the notion of ownership are completely exclusive. Pony has the notion of ownership and a GC. Yet, I agree that usually a language with a GC has no notion of ownership. But, I would like languages researchers to try to fit a GC can fit into a language that try to make guarantees about mutability/concurrency/ownership while retaining expressivity and ease of use. While Rust is stricter and usually leads to more correct code it is also hard to escape or weaken those restriction when needed (thus the famous articles on how to write a linked list in Rust).
Still cannot initialize array without T being Copy though :(
Oh and let's not talk about lacking mut bindings
 rg -USP 'match\s+.+\s+{\s+Ok\((\w+)\)\s+=&gt;\s+\1.*\s+Err\((\w+)\)\s+=&gt;\s+\2' I found this thing lurking in the "Introduce the Result::into_inner method." thread and realized `comacro` already almost has the power to eradicate that. I'm going to slap together a structural grep frontend so that you could do this: sg '(x:$pat) =&gt; match $_ { Ok($x) =&gt; $x, Err($y) = $y }' 
I know, I just like precision :)
It seems like the nesting is just in compiler structure and it's a bug fix for a linting error. 😞
I think the link there is incorrect cc /u/Gankro
I just realized that while `comacro` is already almost capable of being much better than regex for searching in code; it doesn't have the `hir` machinery in place for type information yet, but neither does grep, and grepping for patterns in code is a painful thing that people are doing. So I'm going to make a structural grep API and command line tool. Expect a release later this week!
Thank you, Steve - very good read. I didn't find it "rambly". GC is a very general and wide topic. When I discuss it with others, most people are very "binary": good / bad, helpful / useless, js / c. You are right in a sense that there are so many shades of gray that every reader will find one of your ramblings as a better general approach before you drop the "Rust(y) hammer" at the end. I've bookmarked it so I can refer others to your seminal work after I fail miserably at explaining Rust's memory management to a "seasoned javascript pro". P.S.: And you nailed it with unit tests in js/ruby/python/... is just a form of dynamic type checking... that you have to write yourself... for every function... many times over! IMHO, the only way you'd _want_ to use a dynamically typed language for a medium to large project is because you are not even planning to test most of it (mic drop). 
Oh wow, I didn't know this existed. Thanks! I can now log panics into my logging framework and make sure that the logs are flushed even with aborting panics!
Some are repeated from last issue.
Thanks! &gt; IMHO, the only way you'd want to use a dynamically typed language for a medium to large project is because you are not even planning to test most of it (mic drop). I wouldn't *personally* go this far. :) 
Sad face
This is a major point of terror for `Abomonation`. The idea of e.g. randomizing field order to "shake out bugs" is .. pretty much going to cause me to quit Rust if there isn't a complementary "ok, ok, we'll finally get serious about layout and serialization". I'm a bit worried that there is a group of folks fascinated by struct layout bit-twiddling, without a compensatory group observing that serialization is the main cost in most data intensive systems, and round-tripping through e.g. bincode is way expensive.
Try `[0; MAX_N];`.
&gt;\[0; MAX\_N\] Thank you, that solved my problem!
I was thinking that traits could encapsulate the behavior so different impl blocks can make the regular impl blocks less verbose essentially making it less cluttered and allows for using more files for description. I was thinking about the [RsGenetic](https://github.com/m-decoster/RsGenetic) where traits also have only a single implementation at times, but it made the code easier to get into. Personally I am happy to let the compiler worry about the single implementation traits :) 
It's useful for stuff like naming in macros - for example, if you want to do something like validation: ``` macro_rules! validate { ($name:ident, $v:expr) =&gt; { if !$v($name) { println!("{} is not valid", stringify!($name)); } } } fn main() { let foo = 123; validate!(foo, |x| x &gt; 200); // prints "foo is not valid" } ``` You can use it in errors or if you need to use a variable name as a tagging string.
&gt; the recent ESLint fiasco is just a heads up. What happened? I tried to google it with no success :(
I'm with you on this, personally. Part of a "systems language" for me is interoperation, and I'd love more attention to consistency here vs high-concept optimizations. IME, the folks in charge are sane (but occasionally err), and staying engaged is important for keeping concerns visible.
Most people that've never been exposed to an ML style type system don't/won't understand the appeal. I didn't really get it until I dabbled in ocaml and haskell. Up until then I thought rust was a harder to use C/C++ with horrible syntax.
One thing often overlooked in GC vs. "Manual" (compiler-assisted) memory management, is that the GC only manages a single resource, and a relatively cheap one; memory. Programs regularly deal with other, much more expensive, types of resources; files, windows, sockets mutexes and remote handles of various kinds. When destruction is deterministic, related resources can usually also be freed. (Such as files and held locks in Rust)
&gt; Making structs mem copyable across abi boundaries is really important to me Seeing as how rust currently has no defined ABI anyway, and that `repr(C)` exists and gives you the C ABI, which is also the one most everything else expects, whats the issue here?
I heard about the "*type-kinds*" for the first time. I'd love to see some concrete examples how an ABI might be different for different type kinds? Any links?
For me at least, that none of the Rust types are `repr(C)`. If you want to use a `String`, or a `Vec` or an `Option`, .. bad luck. Re-wrap your data in your own custom type system, and weep as your "users" head to different platform rather than do this.
When I think of “systems language” certain things I believe should be the default. I come primarily for games and consoles in particular. Needing to DMA memory in and out of specialized buffers for network, audio, and graphics is important. If i were to adopt rust and get my team onboard, it’s easiest if it feels like the language was made for our use case. For the most part I like the abstractions as they are defined, but in this area, the proposed default behavior is inverted and I’d rather not need to enforce a policy by adding a struct decorator everywhere. 
(sorry) typo: \&gt; to many programmers too many programmers
I don't have any ideas unfortunately but I imagine it's important to mention what platform you're using, and the rustup version.
I just like to see python as a better bash for scripts, anything that's too big for bash I'll do in python or a static language if python isn't sufficient 
Thanks!
https://www.uclibc.org/docs/psABI-x86_64.pdf It determines which registers things get passed in in the x64 linux ABI (SSE vs general purpose), and determines *whether* things get passed in registers in the x86 linux ABI (structs are always passed on stack, even if they only contain a single primitive int that would otherwise be passed in a register).
There are planned fixes for that in https://github.com/rust-lang/rfcs/pull/2203
Well, that would be because those types aren't C types?.. You need to use types C understands to be able to interface with C.. The C equivalent would be pointers, which do work. You can get Vec as a pointer, just make sure it lives long enough. For strings there's CStr(ing), and Option actually does work in certain FFI contexts, due to the null pointer optimization. The same way you can't go around memcopying structs using C++'s `std::vector` and you have to use `std::vector::data` to get the pointer. 
With respect to unrestricted I/O, there's some interesting research being done wrt. embedding security type systems in functional languages; for example, there's https://hackage.haskell.org/package/mac-0.1.3.0 which is a monad for restricted IO which uses information flow control. In our LangSec course at university we also investigated how you could use dependent security labels in Idris to gain more in expressiveness but retain static guarantees. An paper which I found to be an interesting read is http://ctp.di.fct.unl.pt/~luisal/resources/popl15-paper187.pdf which discusses "Dependent Information Flow Types". I think it makes sense that large organizations may need to fetch information in build scripts from files or over the network; it's not always feasible to duplicate information. However, there are the drawbacks you mention. I think it would be nice if you could as much as possible be expressive and have static guarantees -- i.e. "have your cake and eat it" language design; but of course, that is not easy.
What's the trick to get a job offer repeated like that? Are we supposed to do a new Tweet every week to signal we are still looking?
It's an implementation detail. All you'll interact with directly is the `($($pieces:tt)*)` branch when you invoke the macro. The macro then recursively calls itself using the `@start` and `@segment` prefixes to choose between different branches for the processing that needs to be done on the input. The important part is that this adds another point where a decision can be made. The `@segment` prefix has a different behavior if the segments of your path are types or expressions (strings).
I think if I would have redesigned Rust now perhaps `const fn` would have just been `fn` and `fn` would have just been `io fn` or something like that; we had that before 1.0 but it was removed... Hindsight is 20/20 ;) we can't do such changes now.
&gt; Manual memory management requires more work than garbage collected. You'll discover it's not true, the first time you debug weird issues in production caused by GC, pauses, resource leaks, or performance degradations, OOM crashes. Memory is just one of many resources. Ownership system deals with all resources. GC just with one. Therefore, it's actually easier to write code in Rust, than in typically GCed language, because the language helps you deal with all resources, not just with one type of it, ignoring all others. https://ruudvanasseldonk.com/2015/10/06/neither-necessary-nor-sufficient &gt; When and where should Rust be used or not used according to you? I write everything in Rust (when I have the say on which language is used). I plan on starting my own company in some medium-distance future: a Rust-only shop. Ownership system had a huge impact on me as a developer, and the code I'm writing. I wish I had more time to go on why Rust is so awesome, but I don't. :D
C is a predictable binary representation
like, the pyramid principle ? e.g [as explained here](https://medium.com/lessons-from-mckinsey/the-pyramid-principle-f0885dd3c5c7)
Yes, a banana is also a predictable representation, but the fact that Rust types aren't easily serialized to bananas rules it out about as much as serialization to C.
&gt; TypeScript is really, really growing in popularity. I can bet most of those guys have seen the horrors of dynamic typing at scale.
... and it so happened that there was a code like this: int foo() { static int x = 0; ++x; return x; } Debugging is fun, right?
API is the source code, ABI is the binary output. A single API scan have different ABIs. This is important for cross-language interoperability, as languages don’t undersatand source code. The ABI you’re referring to is the C ABI, but that’s not the only option. 
I really want to use Rust for the numerical work in my Ph.D. How do I convince my colleagues etc. that Rust is potential choice compared with Eigen in C++, numpy in Python, Julia etc. for projects involving (relatively) computationally intensive work (basically linear algebra)? I certainly see opportunities, but the language is still young. Anyone here with experience with scientific computing etc. in Rust? Thanks :)
&gt; This is efficient if operations on one value mostly depends on the adjacent values (in both directions). The main operations for a relational lang will be filter, project and joins. So it fit? Where I find how is a "tiled order"?
There was already a Haskell web server called Warp which was covered in the Architecture of Open Source Applications book too.
Sounds like a reasonable candidate. I will have to investigate further.
Only the KJV! Where's my Nearly Infallible Version? :P But seriously, that is one of the nicest looking Bible hubs I've ever seen, especially on mobile. I would genuinely pay for a Bible app like that, that would store the scripture offline and let me flick through as easily as yours does. I realise that's not necessarily hugely Rust-related, but just from a frontend-perspective, you've made a really pleasant and simple-to-use application.
With respect to terminology, I have to say that to me, saying "static garbage collector" is a losing battle not worth fighting. The meaning of words change over time and I think `garbage collection` today means tracing GC so prefixing with "static" is just confusing; "Automatic memory management" seems like the better term to use these days. &gt; Manual memory management requires more work than garbage collected. Its a trade off of course to be more performant or use lower resources. When and where should Rust be used or not used according to you? I think the people who say this are mostly right; to think that compared to Haskell, which is both lazy, has a GC with acyclic memory Rust doesn't have a "think about memory" burden is wishful thinking. Sure, compared to C the burden may not be great, but in Rust, you have the traits where Haskell gets away with functions. For example, you need to write `F: Fn(Foo) -&gt; Bar` instead of just being able to write `Foo -&gt; Bar` and similarly with `Iterator&lt;Item = A&gt;` it is a trait and not just a type `[a]`. But more than that, in Rust you are faced with thinking about "should I use `Box`, should I use `Rc`, should I use `Arc`?" -- in Haskell or other languages with GC, you don't have to take these decisions and thereby decision fatigue is reduced a lot. When writing Haskell, I feel a sense of liberation of not having to care about performance at all until it is needed. Of course, the downside to that and GC is performance, in particular wrt. latency. For fairness, I should note that Haskell has its own costs in having to think about side-effects. While we can reduce the ergonomic hit due to control over layout, it will never be as ergonomic as in languages with GC; I think we need to honest and admit this (not saying you've clearly stated otherwise, but I'll say it anyways...). &gt; My first clue comes from my own programming history. Some of my first programming languages were C, C++, and Java. These languages are statically typed, that is, they require you to declare the type of variables up front, and check that the type holds. I can remember the first time I came across Perl, and the concept of dynamic typing. Wow, this is so much easier! I could do anything. From then on, I pretty much focused on dynamically typed languages. I understand that this was your personal experience; but I feel obliged to say that while C/C++ and Java are indeed statically typed languages, they are also weakly typed with historically poor if any type inference. Languages like OCaml, Haskell and similar are strongly typed and without extensions like GADTs, RankNTypes and such they have the *principal type property* which means that given an expression in the language, the most general type can be derived without a single typing annotation. That is, I can write an entire Haskell program without specifying any types and then I can ask the REPL what the type of various terms are. This of course is a wholly different experience than in say Java. Nevertheless, Haskell programmers tend to write down type signatures for documentation and verification purposes even tho they don't have to. While Rust doesn't have the principal type property (afaik) and we have elected to only have local type inference, we could have allowed substantially more inference if we wanted to (and indeed we have loosened some restrictions on the globality of inference over the years...). &gt; In other words, my tests were sort of like “dynamic type checking.” Instead of being checked by a compiler at compile-time, these behaviors of my system were checked at run time, by my tests. This isn’t a novel insight; many others have stated this relationship between tests and types. While it is likely impossible to get rid of the term "dynamic typing", and you may consider what I'm about to say to be pedantry, in the way you've used the term "dynamic type checking" here, I must concur with Pierce in Types and Programming Languages where they note that "dynamic type" is a misnomer; In a language like Ruby or Python, there are no types. These languages are instead *untyped* (or unityped) languages (in the sense of the untyped lambda calculus...). There are instead run-time *tags*, but these are not types. With respect to tests replacing types and types replacing tests, while it is true that what you describe is usually what happens in practice (people writing less manual tests in Haskell and more in Python), I think thinking that either replace each other gives a false sense of security (unless you use a dependently typed language like Idris or Agda...) and it is also comparing apples and oranges (i.e. a category mistake). As Dijkstra famously put it: "Testing shows the presence, not the absence of bugs". By the Curry-Howard correspondence, type systems instead correspond to logics where you can prove things. Gary Bernhardt has given an excellent talk about this topic, https://www.destroyallsoftware.com/talks/ideology.
Neat. With respect to the enum support, what about moving the trigger into the variant? Something like: sm = match sm { Variant::InitialLocked(m) =&gt; m.transition(Push).as_enum(), Variant::Unlocked(UnlockedTrigger::Coin, m) =&gt; { coins += 1; m.transition(Push).as_enum() }, Variant::Locked(LockedTrigger::Push, m) =&gt; { if coins == 100 { break; } m.transition(Coin).as_enum() }, } If you had a state with multiple possible triggers, you could pattern match on the trigger.
In most shaders you can specify packing and layouts for structs explicitly and driver vendors must comply with this specification. Not all structs are but certain many (on the order of hundreds to thousands) are on major projects. I’m more concerned about “accidents” that can happen or unexpected behavior due to the inclusion of a member missing a qualifier. 
&gt; I have to say that to me, saying "static garbage collector" is a losing battle not worth fighting. Oh, I'm not saying that this is worth fighting for, nor am I saying we should advertise ourselves this way. It's a rhetorical device. &gt; "should I use Box, should I use Rc, should I use Arc?" Sure, I think that's part of the whole "skill buildling" bit. The answer is, of course, "almost never" :p &gt; you may consider what I'm about to say to be pedantry, Yes, I am on this team, but I wasn't interested in getting into it in this post :)
&lt;3
&gt; Longterm, stable vector-kind types should be available in the stdlib. Short-term they are unstably available in the simd crate. Small note here: we do have stable vector-kind types, but they are currently defined in platform specific modules. e.g., https://doc.rust-lang.org/core/arch/x86_64/struct.__m128i.html --- Their actual definition is however not platform specific AIUI. Eventually, I think the plan is to add platform independent vector types, e.g., `u8x16`. Among vector types, are there distinctions between integer vector types and floating point vector types in the ABI?
I think a key idea is that in C/C++/Rust you allocate on the stack when possible, i.e. when allocations follow a stack discipline. And you use the heap otherwise. (That's a simplification, but is still illuminating.) As for references about GC and memory allocation, Paul Wilson's old survey papers are the mother lode. You should be able to find copies online. - Uniprocessor Garbage Collection Techniques, 1992 - Dynamic Storage Allocation: A Survey and Critical Review, 1995 (with Johnstone, Neely, and Boles) - Locality of Reference, Patterns in Program Behavior, Memory Management, and Memory Hierarchies (rough draft)
I mean, Typescript was borne out of just that need. [This video is actually sums up why Typecript came to be](https://youtu.be/0siV7xeYSbY).
Hello! I've been slowly learning a bit of Rust from The Book and cobbling together some *very* basic programs as I go, to reinforce what I'm reading. But at times, I feel like I really have to fight the language to get relatively simple things done. Like indexing into a String, or when I wanted to sort each line of a file by length. I got both working, but it just felt unnecessarily frictional. I can't help but feel that this is just because I'm not even halfway close to scratching the surface of the language (and don't know the proper way of doing things), and it starts to make sense after a bit. Is that true? Or should I just move to something more conventional? Also, is there a convenient way to have step by step debugging with the MSVC compiler on Windows? I realised that I've no idea how to do that currently; did a bit of searching but most results talked about (I think) llvm or gdb. Thanks.
Thanks!
Cool! Do you have a repo or any details to share?
Wow. Nice works! I like it. Thanks for sharing it. I hope you add more bible version soon. French translations would be appreciated too! :)
&gt; add garbage collection to a C or C++ system I would've said `#define malloc(x) GC_malloc(x)` for C :)
I'm on a flight to Stuttgart right now for the closing weekend of the Stuttgart Oktoberfest. Wish I could make this, sounds very interesting. By industrial automation, are you doing PLC programming with Rust? Like the work that's normally ladder logic stuff?
&gt; These languages are statically typed, that is, they require you to declare the type of variables up front, and check that the type holds nitpick: static means *known* at compile time. Not necessarily declared explicitly by the user. Even C++ and Rust have (local) type inference :)
I've been finally getting into rust seriously, porting some C code that needs dynamic allocation for a struct with a dynamically sized array at the end. [Like this](https://gist.github.com/josephg/aaf7a5f2f53d50537135372a5a32a7f6) In stable rust I can now call \``std::alloc::System.alloc(...)`\` to allocate memory. But that explicitly uses the system allocator. But as I understand it, that explicitly uses the host system's allocator instead of jemalloc or whatever the application developer has configured box / vec to use. Is there any way to call the configured allocator instead?
As a side note, I think the term "garbage collection" usually implies automatic cycle detection too (at least, that's what it makes me think of)
We don't have a policy on that yet. But yes, we usually repeat them on request.
x64 linux seems to treat intx and floatx the same, but I don't think anything inherently prevents an ABI from treating them differently.
I think GCs are really overrated. They solve some problem, but introduce others. In fact, I think it's way easier to leak memory in C# by accident, than in modern C++ and it's nigh on impossible in Rust (unless you use unsafe code). I had to work on someone else's C# code and it was full of memory leaks, because they stored event listeners that captured instances of classes in static variables. The really bad thing is that i haven't seen a tutorial for a GC language which tells you what you shouldn't do to avoid memory leaks and that makes a lot of programmer not care about memory management. Which makes them a bad programmer in my humble opinion.
Rustup calls atom? Like Atom the Text Editor? I've never heard of it doing that. Are you using a third party plugin or something?
Maintaining a good latency is also part of the trade-off.
It's not too late! ;)
Are you having a bad day or something?
You betcha! I changed jobs recently and my routine has changed, but I still read the majority of the PRs and try to ensure no-one is blocked :)
Aw, thanks! I'm now trying to work out which former colleague would choose this particular handle :)
It's probably Windows Defender scanning all the docs. It's a known problem. You probably want to whitelist that folder or turn off Windows Defender while running a rustup update.
Ah, so it's actually more general than tests - you can run a number of CLI tasks with an arbitrary immutable dependency graph as soon as possible. That explains it. Thanks!
maybe. it was a good launching off point regardless.
It's true that many think this, but it's not in the definition. I do think that this is part of the whole "the words have changed over time" thing.
Nice nit, yes, thank you. 
When I have something workable I will tell you. I'm almost finished with writing down the draft for writing an iCalendar object, aldo looked also at some of your contributions. When I have everything set the coding shouldn't take this long hopefully.
Very nice!
Hopefully soon but first we need some more customers/orders.
Thanks so much for sharing your repo!
We almost do everything in rust except the web frontend (but this might change as WASM frameworks are getting better). And yes we also do the PLC programming with it.
You want to use the free function [`std::alloc::alloc()`](https://doc.rust-lang.org/nightly/std/alloc/fn.alloc.html).
Bingo. Even when I'm not caring about the GC, this post still discourages me from using Haskell and instead pushed me towards rust. If Haskell gets linear types, then things will be quite a bit different.
Are there plans to go back and constify much of the standard library? I was running into an issue with unstable `const` in some of my code (specifically [this function](https://github.com/Lucretiel/joinery/blob/4aba0c1d2fb8816663fe4117f8a50b41287b014c/src/lib.rs#L627-L644)) where, even though it's const in principle, the stdlib methods weren't const (even though they should be), so it refused to compile
I still don't understand what you mean by "efficient access" given how deeply rooted into the CPU's design the efficiency trade-off is.
I have no idea. My project works as a source-to-source local-only transformation. What the language itself allows *withiut* changing the source code is something I’m even less informed about than /u/Gankro
Huh, I ran the executable directly and it ran fine. So only happens when I run from cargo. Here is a little screencap to demo: https://www.dropbox.com/s/t5ubpe6ltfrgwbq/rust_cargo_bug.mov?dl=0 release build zip: Here: https://www.dropbox.com/s/6kad9xrwx1z8tst/release.zip?dl=0 My macbook's processor is a i7-4870HQ. 
I'm pushing the lang team to clarify the relevant RFC (which has always been ambiguous)
Also [A Unified Theory of Garbage Collection by Bacon et al](http://www.cs.virginia.edu/%7Ecs415/reading/bacon-garbage.pdf) to really drive home the duality between tracing and refcounting.
Little late to the party, but I've been working on a [distributed random crate](https://github.com/tecywiz121/distrand). The goal is to let multiple parties generate random values without needing to trust eachother. Could be useful for a decentralized card game or something. Not really sure yet. I'd love some feedback on the API and any security recommendations!
I think of "tracing garbage collection" as implying automatic cycle detection, because if you don't need cycle detection there's not much reason not to just use reference counting.
That’s fair!
The definition of weakly vs strongly typed I'm working with is whether or not values can be implicitly converted between types when they are used. "void *" and JS comparisons are the canonical examples of this. I believe this is the commonly accepted definition of those terms are used and is why ANSI Common Lisp, for example, is considered to be strongly typed despite not having a "strong" type system in the colloquial sense.
Oh, hahaha I don't know why I didn't see that! 😄👌 Perfect - much appreciated!
for me it's js using node (please don't kill me and my family)
The Melbourne one hasn't had a meetup in ages either :(
Pretty nice app. Have you looked at the sword project? It has a lot of bible translation in an open format. https://en.m.wikipedia.org/wiki/The_SWORD_Project https://www.crosswire.org/sword/modules/ModDisp.jsp?modType=Bibles
Non-Mobile link: https://en.wikipedia.org/wiki/The_SWORD_Project *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^218808
I understand the thing about keep data in caches. What I'm thinking is that you can say that by-columns is a rotated by-rows, but then how model is the challenge, if wanna have a uniform API.
If it’s any consolation, I find your ramblings much more fun and thought provoking than my grandfathers cantankerous ramblings. &lt;3
Yep! I think you explained it better than I did...
That's a super important point for me.
As someone who is still trying to learn rust in my spare time and works as a systems integrator, I'm rather intrigued. I can't make the meetup, but would love slides/vidoes. What PLCs are you programming in rust?
Ah, I googled it and the Wikipedia summary implied it was for the Cortex M, it is extremely possible that this is mistaken.
Checkout this as a way of building a fast grep with relatively little effort: https://github.com/BurntSushi/ripgrep/blob/master/grep/examples/simplegrep.rs I have a half written guide that I still need to publish, but you might be able to get by without it. In particular, if you implement the [`Matcher` trait](https://docs.rs/grep-matcher/0.1.1/grep_matcher/), then you can plug that into the rest of ripgrep's libraries to get printing and searching for free.
I think the distinguishing words should be "runtime GC", "compiletime GC" and "writetime GC". The first one is what JAVE et al uses, the second is Rust uses, and the last is C uses.
&gt; but I switched to Rust because I was not satisfied with mbed Your blog post didn't really go into why you weren't? How have you found Rust with the project so far? Has it turned out to be more satisfying or are some parts of the embedded dev not quite there with Rust yet? I would be interested in knowing more, like what parts you've been using. I am fairly new to embedded dev(been on the fence for a while), I'd like to make a little robot project myself, but am not sure how to pick a motor(seems to be a lot of options besides motor types, that I need to consider), or what components like the h-bridges are required and suitable for rust. Did you choose components with existing rust crates or write your own?(if you did, did you or have plans to release crate support in future?) 
Not using `Rc` or `Arc` or `RefCell` or `Cell` is possible. Not using `Box`, directly or indirectly, or other kinds of heap allocation, is barely possible, unless you don't even need `String`.
I have heard of the SWORD Project, but haven't researched it much. For the initial setup, I just used CSV files from someone's Github repo. I'm interested in using an open format like this as the source at some point, though I still prefer SQL to be the data store. Thanks for pointing me in that direction!
&gt; As of this writing, there are 4 type-kinds that Rust can care about: There's also one notable 'kind' that Rust [currently doesn't support](https://github.com/rust-lang-nursery/rust-bindgen/issues/778), which is unfortunate: C++ classes with non-trivial copy constructors or destructors. Unlike normal structs/unions, these are forced to be passed by reference, because C++ semantics expect an object to have a stable address. But the details can be platform-specific, so you can't just use a different declaration on the Rust side.
Thanks! There are a handful of examples I've seen elsewhere that use Actix Web, and several that use Diesel as well. They gave me some good patterns and idioms. I hope this is helpful to others that are in a similar position as me. This project has a few interesting pieces that you may not see elsewhere: * SQLite with full text search (FTS5). At some point, I may make some contributions to Diesel or create a Diesel plugin for FTS5. * HTML template rendering in Actix Web. * Minor text parsing (it's just regular expressions...real text parsing seemed a bit of an overkill and out of my league).
Sometimes I wonder if it hasn't made me a worse C/C++ programmer. https://twitter.com/MikeHommey/status/1010699922725670913
Anybody thought of changing the sub name to something else?
So you call into an API and get "integer overflow error" and then what? Tell them to do it again but pretty please without an error this time?
Eurobot looks pretty cool, bit of a bummer on that age limit though.. (over 30 and you're disqualified from reaching finals) Not everyone gets into robotics at younger ages :P Doesn't seem like a fair rule there, are there other competitions like this that you know of that don't have that?
The thing is, the C alignment is something we all “grew up with” so to speak and we rely on static and predictable layouts regardless of the compiler or compiler version. I also disagree regarding the “auto packing to improve performance” as low level game engineers know to pack frequently used data together so they occupy the same cache line. If my animation data is now allowed to drift to random offsets in the struct, I might now have some builds which perform better than other builds. Don’t get me wrong, it’s not that I don’t understand the goals of fuzzing and whatnot. It just means that in my mind, I’m not really the target customer of the language
Does Reddit ensure all links will redirect? I bookmark a lot of stuff here. (If so, then I'd suggest trying to arrange to retire and replace /r/rustlang/ which currently serves as a "you want /r/rust/" and nothing else.)
...not to mention that an ultimatum like that is a waste of time. Their attitude will almost certainly be "If you prefer Minecraft, then go play Minecraft. We have a lot of users who like things the way they are."
Maybe try https://www.reddit.com/r/Minecraft/
&gt; 1 Restructure the data This is not what I'm doing now? Have 2 structs each implement a layout and a trait to unify &gt; 2 Use an in-memory layout.. but not terrible for either How could be? The main purpose of this is to become the "default" data structure for the lang. So I'm not that much concerned about maximun performance but decent overall one. 
I was not able to reproduce the problem on my cpu with rust 1.29.1
Yes, obviously you can avoid some need for transactions that are just for denormalization, but sometimes you really do need transactions and consistentcy. Was curious if you had the design sketch for that written up anywhere, or you're waiting to implement it and get it tested out before discussing it.
Damn son, you are dense. 
Also when you have to do some networking stuff, not just processing local file, and want to use `async/await` (or the desugaring form), `Box` is basically inevitable. I have some experience on `tokio`, and I know I can avoid `Rc` et al most of the time, but `Box` is not something can be avoid. `impl Trait` eliminate many of the need, but not all. In short, `Box` is not the only way when you have to construct the return value from your function (one alternative is `vec![value;1]`, but what's the point?), but it is the preferable way.
If you know how to write linked list (or anything you need) in C then you already know how to write it in unsafe Rust. If something is not possible to write in safe Rust (or requires unnecessary overhead) - use unsafe Rust. Problem solved )
[@MikeHommey's latest tweet](https://i.imgur.com/RY6fLs4.jpg) [@MikeHommey on Twitter](https://twitter.com/MikeHommey) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
&gt; During the 32-bit era, assuming `int` was *exactly* 32 bits became so rampant that when 64-bit hardware started to show up, compiler developers were forced to define `int` to still be 32 bits, as too much software was completely busted when `int` was anything else. Fun historical fact: The 32-bit to 64-bit transition was the *second* bit-width transition for the C ecosystem; the first was the 16-bit to 32-bit transition. During the 16-bit era (when `short` hadn't been invented, `int` was 16 bits and `long` was 32 bits), assuming `long` was exactly 32 bits became so rampant that when 32-bit hardware started to show up, compiler developers were forced to define `long` to still be 32 bits, as too much software was completely busted when `long` was anything else. So on most 32-bit platforms, an "integer" is exactly the same size as a "long integer". By the time the 64-bit transition came around, there was much more code that assumed 32-bit ints than code that assumed 32-bit longs, so most 64-bit platforms have 32-bit `int`s and 64-bit `long`s ... except for Windows, where Microsoft wanted to absolutely maximize backwards compatibility, so 64-bit Windows has `int` *and*` `long` as 32-bit integers, and you need `long long` to get a 64-bit integer.
Sadly copyright law makes using translations from the 1920s and onward a bit difficult for small projects. The ESV is one of the few exceptions.
&gt; Systems programming is a broad field, and the line is somewhat fuzzy. It's not *just* kernels. Agreed, but I don't think you go far enough. Will Crichton's [What is Systems Programming, Really?](http://willcrichton.net/notes/systems-programming/) makes an excellent argument, both from the origins of the terms and from the potential for utility, that, when people say "systems programming" to talk about things like kernels and OS infrastructure, they should be saying "low-level programming" instead.
Yep. If you haven't looked at any documentation, [the rustwasm book](https://rustwasm.github.io/book/) is a good place to start.
Awesome! I was going to do a barebones freestanding tool and then look at integrating for all that printing and fs traversal goodness, but that interface looks straightforward enough to do it as a `Matcher` from the get-go.
This is just a long shot, but apparently a miscompilation (rustc generates faulty code) under some very specific circumstances is about to be fixed in 1.29.2 which is to be released today. And your bug seems to only happen in very specific circumstances (LTO + target-cpu=native + run under cargo)... Maybe you could try 1.29.2 and see if it fixes your problem?
Alternatively you could copy the contents of README.md to the frontpage of the projects website. The README-file has nice examples. * https://crates.io/crates/imag * https://imag-pim.org/
One thing to keep in mind: The binary is named `fdfind` and you probably want to add `alias fd=fdfind` to your shell config. A bit on the background story: There is a policy in debian that there can't be two packages that use the same path in /usr/bin. Sadly, /usr/bin/fd is already taken by a program called fdclone since a really long time. We are still looking for a better solution, but keep in mind that short generic names are very likely to cause these sort of problems.
&gt; What platform? Spark, say. If you spend 90% of your time serializing/deserializing data, then the value proposition of Rust as being lean and safe is just not as interesting any more. I'm pretty sure Abom needs a consistent layout, because we need to chase the pointers, and on deserialization we need the pointers to be where we expect (because the intent is to act as a `&amp;YourType`). For me at least the vexing thing is that Rust is so close to doing this well, in a way that other languages are not (e.g. having `&amp;self` signatures that let you restrict what types can do, so as to not permit mutation, and optional trait implementations so as to not implement things for `Rc`). The community may decide that packing things into fewer bytes is more exciting than having efficient data transport, though; it isn't nearly as exciting for the embedded folks, I would believe.
&gt; How would that even work? A type has to be the same everywhere, so if any user of it requests it to be repr(C) then everybody else has to be recompiled with the repr(C)-ified version of the type? It doesn't, we agree. The above isn't a list of demands, it's things that don't work. The question as I understood it was "why not use `repr(C)`, and then answer is .. well I think you understand it. On the other hand, a layout trait could be transitive, not forcing but at least only satisfied if all members satisfy the trait transitively. I'm approximately 0% of anything would implement it, but at least one could write some serialization code that is believed to work by using the constraint. 
Punctuation often changes the meaning of text. If you're missing the meaning given by punctuation, it is because you're unfamiliar with the language, not because it isn't clean.
I'd rather call it scope bound resource management, rather than static garbage collector.
ah, yes, the new version is clearer... ty
&gt; &gt; &gt; &gt; &gt; I would be interested in knowing more, like what parts you've been using. I am fairly new to embedded dev(been on the fence for a while), I'd like to make a little robot project myself, but am not sure how to pick a motor(seems to be a lot of options besides motor types, that I need to consider), or what components like the h-bridges are required and suitable for rust. Did you choose components with existing rust crates or write your own?(if you did, did you or have plans to release crate support in future?) My problem with mbed is that it tries to hide a lot things from the programmer. On the paper this is a good thing, but in practice you are so far away from the hardware that you can create bugs very easily without really knowing why. Some things works, and some things doesn't and you have to go dig inside mbed source code to understand why... Now, on using Rust in the project we are pretty happy at the moment, even if the robot is not even finished but there is still a lot things lacking in the ecosystem : * You have a very small choice of microcontroller, or you have to write your own HAL * Some APIs are still under discussion for a lot of peripherals (CAN, etc.) So I would say that while we can everything that we want to do in robotics, we are sad that we had to switch of microcontroller... I am planning on creating more blog posts which would be more like "how-tos" for robotics. For picking your motor and hardware stuff I can help you get started, just PM or email me :)
Here's my view on specific points in that guide: &gt; Topic and command names should always be a single, lowercase word without spaces, hyphens, underscores, or other word delimiters. Good for Heroku's use, but inappropriate for general use, where it's generally better to have names like `add-apt-repository` rather than `addaptrepository` in situations where there's no applicable mechanism for extending a top-level command with new subcommands or it's unfeasible for other reasons. &gt; Topic and command descriptions should be provided for all topics and commands. They should fit on 80 character width screens, begin with a lowercase character, and should not end in a period. Take out the "should not end on a period" and this is basically the existing convention. Shouldn't be controversial. &gt; Flags are preferred to args. They involve a bit more typing, but make the use of the CLI clearer. ---- &gt; Arguments are the basic way to provide input for a command. While flags are generally preferred, they are sometimes unnecessary in cases where there is only 1 argument, or the arguments are obvious and in an obvious order. This pair of sections doesn't mention the #1 case where you want positional arguments rather than flags: Commands where a common use case is to include shell globs in the argument list. Last I checked, I couldn't find any Google results for a way to use a glob like `file?` to produce something like `--from file1 --from file2 --from file3 --from file4`. &gt; Human-readable output should be grep-parseable, but not necessarily awk-parseable. *This* section is a perfect example of what a style guide should do. It covers something that may not occur to many people and provides practical examples of why it is the way it is. **Beyond that**, most of it is too specific to the use case to really be relevant for CLIs in general. 
IMO it'd be easier to implement in the compiler.
&gt; and is easier to maintain, test and develop Would you mind elaborating on this? My focus has been different enough that I'm only really familiar with tooling loadouts optimized for testing multi-page apps where you can turn off JavaScript and everything more or less keeps working. (My perspective has generally been that, if it can be reasonably implemented without client-side JavaScript, then depending on JavaScript for more than polyfills is irresponsibly fragile, likely to bog down the end-user's machine, and/or lazy while, if it truly *is* a web *application* in the sense of not really mapping to a graph of HTML+CSS pages, then, for the 99% of the time where "deployment: N/A" isn't a top requirement, it should be implemented using something lighter and more native-feeling, like Qt.)
Noobie question alert! Can someone explain some of the problems with compile time execution being so limited as far as the functionalities of the language? My noob brain would imagine that if you have pure functions and you change them to be const that there should be no big big problems compiling them separately, calling them and reading the result. If the compiler can compile "normal" code, why not compile the code required for compile time execution in a previous step and use that to get the results? Also, is there a difference why this has been done in Jai by Jonathan Blow without much trouble but not on Rust and C++? Sorry in advance if this is very basic and/or I'm missing something really obvious. Cheers!
You can't change a sub name. 
&gt; Well, okay, but that's a bit of an apples-to-oranges comparison. Certainly Spark provides a lot of goodies related to its purpose that Rust, out of the box, does not; it has plenty of drawbacks as well. But in general I don't think the cost of search-and-replace from, say, Vec to XVec (a hypothetical custom container type) would play a big role in choosing between them. The problem as I see it is that you need a reason to change, and no one needs to change from an existing platform that performs just fine if we are going to eat in this case non-trivial serialization. Maybe slower Rust is indistinguishable from Spark+Scala, in which case great I can go buy a van in NZ and run around the mountains there instead of trying to do something well.
&gt; (Again, with custom container/pointer types you could choose to use relative offsets and have zero upfront decoding time, like CapnProto. ;) I dare you to post CapnProto numbers and abomonation numbers in close proximity. ;)
This seems quite useful Just glancing over the code I would rewrite the the is_shell_supported function a bit (just to make it look nice and maybe get rid of the many pushes). I'd make the shell list a global static: static SUPPORTED_SHELLS: &amp;'static str = "tcsh,csh,bash,zsh,noshell,python,pearl"; And write the function like this. fn is_shell_supported(shell: &amp;str) -&gt; bool { let shell_list: Vec&lt;&amp;str&gt; = SUPPORTED_SHELLS.split(",").collect(); shell_list.contains(&amp;shell) } 
Rust isn't hard, actually! Did you read a book?
True :) I read through the linked PDF for the 2019 rules on your blog post, looks awesome. I'm way down in NZ though, tickets to europe are expensive, maybe another year if I end up living closer in future :) What did you make your component breakdown graphic in btw?
I've got the packages: ide-rust 0.18.3, and language-rust 0.4.12 installed. I also use the terminal inside Atom to run cargo, and have occasionally run rustup from it. It wasn't the problem though. New issue, still investigating.
C++ has had Boehm GC for ever. One just had to use them.
Your wish shall be granted! Just install the real Rust ([https://www.rust-lang.org/en-US/](https://www.rust-lang.org/en-US/)) which comes with absolutely no footguns and consequently no recoil! Much better than r/playrust!
&gt; I am planning on creating more blog posts which would be more like "how-tos" for robotics. Awesome :) I look forward to them. A great one for newbies like me would be stuff like motor control, in my case I'm looking at a robot with 4 legs(no movable joints) with wheels for feet. The toy robot that I'm trying to replicate has it's front wheels facing diagonally inwards/forwards, and the opposite for the back legs, it seems to manuevor well, but I've been suggested to use a more traditional arrangement of the wheels and consider mecanum style. Would love to hear more opinions, I'll PM you. &gt; You have a very small choice of microcontroller, or you have to write your own HAL Is that difficult / time-consuming? From what I've read as long as the MCU has an SVD file you can generate code to use it, from there you write the HAL? Or are you referring to HAL for various sensors/controllers on a board? (where each sensor needs it's own HAL, and then another HAL for mapping those sensors to the MCU or something iirc) &gt; Some APIs are still under discussion for a lot of peripherals (CAN, etc.) Ah, I guess that can take a while? In the mean-time you're still able to use those peripherals right? At a lower level and less portable/compatible way? &gt; My problem with mbed is that it tries to hide a lot things from the programmer. On the paper this is a good thing, but in practice you are so far away from the hardware that you can create bugs very easily without really knowing why. Some things works, and some things doesn't and you have to go dig inside mbed source code to understand why... I thought some of the embedded work is providing friendlier abstractions which'd cause similar issues(apart from benefits of rust helping avoid mistakes). If not, as rust on embedded further progresses, is that something that might become a problem with rust too?
Hm, maybe we used `Arc`, it's been so long I don't exactly remember. Here's one of my assignments. https://github.com/yacn/t_query/blob/master/src/main.rs In modern rust would I still need to wrap the subway object in an `Arc`?
:rofl: Yeah, like that's working.
The post is already 6 days old but apparently hasn't been posted here... It contains some interesting ideas that people more familiar with rustc development might want to take a look at :)
Works on desktop, might be your client.
&gt; maybe It was made by a friend using inkscape for a presentation at a local meetup, so I just translated it to english !
Fighting the good fight
Is there a good reason for those defaults? Ignores hidden directories and files, by default. Ignores patterns from your .gitignore, by default. Because, to be honest, if I want to find all files in all subdirectories, I'd actually not want to stumble over some random gitignore files and I'm much more likely to want to see hidden folders as well. It's always easy to see hidden folders and afterwards turn off searching hidden folders then not finding them at all (and thus not recognizing that I was missing files). I'd accept that for a more programmer oriented tool but not for a general system utility. Maybe it is only geared towards programmers, but then the name is not very good at communicating that :) 
I don't especially mind the souls that stumble into this sub unknowingly Thankfully the rust video game community isn't huge so this sub isn't too flooded with mis-posts The games going to die out eventually, anyway
Nice to hear! Unfortunately the link doen't work, has it been renamed ?
You don't have a sidebar on mobile 
&gt; I think your are mixing peripherals and sensors/controllers. A peripheral is embedded in the microcontroller Yes perhaps. The way I've understood it is that you can have a microcontroller, and sensors as individual crates, but with boards there can be an additional crate/interface to manage it better. Like if you have some sensors and a microcontroller on a breadboard and then put them all together fixed on a custom PCB, some boards you can buy have LED or sensors like IMU onboard hardwired. So now you might have `myboard::LED_01::power_on()`(I don't know what the actual method call would look like). Though I would have thought the separate HAL code for both components that worked on the breadboard would work fine here too, just it's an additional convinience HAL for the board? 
Using "John" for the Spanish translation might be confusing. I thought there were standardized abbreviations, but it seems I was wrong.
That seems to be a bug, it's still listed over here: https://tracker.debian.org/pkg/rust-fd-find
You can start your AwesomeBar query with a % to scope it to opened tabs.
My client has one. I use Boost on Android. Maybe it differs for other clients
Thanks for sharing! :)
To me this just seems to make every language ever have "garbage collection" Unless that language provides no way to free memory after use, you can make the argument "static GC lol" or "manual static GC lol" a definition so wildly broad and vague as to be completely useless. I think i'll stick with the normal definition of `"the automatic process of freeing up space in a computer's memory by removing data that is no longer required or in use."`
Did you implement the `NoRecoil` trait properly?
I assume the second line means that it *will* use patterns from your gitignore to determine what to ignore, it’s just confusingly worded. 
I don't think the headers were removed in 0.8.7. They were removed in 0.9, and that's mentioned in the changelog. As you can [see](https://docs.rs/reqwest/0.8.7/reqwest/), the 0.8.7 documentation is completely missing.
This would also depend on what you will "do the most". In [std::collections](https://doc.rust-lang.org/std/collections/index.html#sequences) there is a nice overview over the speed of the different collections. If the `u32` are sparse a `HashMap` is probably nice, but if they are quite centralized perhaps a simple `Vec&lt;Option&lt;String&gt;&gt;` would be even faster even though it would result in a larger vector.
While normally I'd agree 100% with your statement, it's worth noting that semantic versioning allows for breaking changes in minor releases when major is zero.
&gt; Diesel was also enjoyable, and fairly easy to wrap my head around. The type safety around database schemas is terrific! So, would you say you can hear the Diesels humming? Seriously though, this looks like a nice and instructive project. Thanks!
Cool. I'm learning rust, and as an emacs user, I can't stop thinking of remacs :)
Great! Please reach out if you have any questions or ideas for improving it. I haven't gotten much user feedback yet, so it would be great to hear how it goes!
Hm, why does *const T has “all” in the defined values column? I thought that pointers are required to be aligned?
Nice to see continuous progress. Although their borrow checker is very primitive compared to rls, it doesnt even handle move semantics. I wish jetbrains also offered rls as an alternative. Yet text editor is top notch, that's why i prefer clion over vscode. 
That's not how it's implemented in Cargo. The semver spec may say that, but Cargo deliberately does not use that spec.
Alternatives are only meant for packages which provide comparable functionality. The debian package fd has nothing to do with find, it's a clone of an old TUI file manager for MS-DOG systems.
The JSON approach would also give a super easy way to write bindings for other languages as well. Generating for example .NET P/Invoke interfaces based on that kind of structure would be trivial (much easier than parsing a C header to be sure!)
Fast, and usable Needs a home button so you don't have to press back 50 times
Oh, that makes sense. I had assumed fdclone had something to do with finding as well.
Also, there is a good [entry point](https://rustwasm.github.io/wasm-bindgen/whirlwind-tour/introduction.html)
Btw, I appreciate the positive vibe of the posts, and if I come off as snarky I apologize!
PyCharm often points out typos and mismatched types.
Great post! I'm surprised I hadn't come across this yet. I started down the syncronous arbiter path initially. In the end, as you can tell, I did the sub optimal thing, and performed the database operations in the HTTP handler. Refactoring to what this post suggests wouldn't be difficult though. Thank you for the suggestion!
The logo is the home button. I could make that more obvious...
Note: Your code is unreadable for anyone using old Reddit, because it doesn't support \`\`\`. If you want everyone to be able to read it, indent it by four spaces.
Only if you want to dereference it without using read/write\_unaligned; it's perfectly fine for it to be unaligned otherwise.
Except that plain reference counting tends to have much worse performance. Sure, modern reference counting is as fast as tracing, but to get there you have to make them quite similar ([paper](https://www.microsoft.com/en-us/research/publication/taking-off-the-gloves-with-reference-counting-immix/), [pdf](http://users.cecs.anu.edu.au/~steveb/downloads/pdf/rcix-oopsla-2013.pdf)
&gt; Empirically, the generational hypothesis is true. But I haven’t seen much investigation into why it is true. It's still weak, because it can vary a lot from program to program (as you also point out in the Go quote section). There is one relatively recent [paper](https://www.researchgate.net/publication/254004713_New_Scala_instanceof_Java_A_comparison_of_the_memory_behaviour_of_Java_and_Scala_programs) that compares survival rates of Java &amp; Scala. In Scala survival rate is 1-4% (4MB nursery), while for Java it's more in the 10-30% range. I agree, though, that it generally seems to have to do with call stacks and temporary objects. Programs with more long-term state and fewer temporary objects will profit less from the generational hypothesis.
Arguably file managers are for finding files :)
Sure, I said "almost" for a reason.
&gt; The program doesn't halt and consumes 100% cpu. What code is it executing when it's stuck? On linux you can: `gdb -p pid` to attach to the process and then do a `backtrace`. To get the pid you can run `pgrep p005`. If it's a really interesting deadlock kinda bug then you might need to sample this more than once.
sooo, this is a joke analogy for the [video game Rust](https://en.wikipedia.org/wiki/Rust_(video_game)), I think
I would **love** to meet you at the event. I'll be going there from Austria by train if possible. I stumbled upon your company's site some time ago and already thought of it as an interesting and sustainable undertaking.
Slide for Reddit technically has one but you have to explictly ask for it in the menu while you're browsing a subreddit. I know Boost did it that way as well. Your point pretty much still stands I'm just being technical. I know I almost never looked at the sidebar before doing anything.
I wonder if there was ever a Rust player that accidentally posted here and upon learning about Rust actually started learning/programming in Rust.
&gt; MS-DOG :)
https://rustwasm.github.io/book/ should be able to answer all your questions; if not, please file issues!
&gt; bit-width transition for the C ecosystem That's the x86 world.
Direct link to the RustSec advisory: [https://github.com/RustSec/advisory-db/pull/62](https://github.com/RustSec/advisory-db/pull/62) &amp;#x200B; All versions of trust-dns-resolver, trust-dns-server, and trust-dns are effected. This has been fixed in the current release of trust-dns-proto 0.4.3, which aligns with the trust-dns-resolver 0.9 release, as well as trust-dns (client) and trust-dns-server 0.14 series. The corresponding fix in the alpha series is trust-dns-proto 0.5.0-alpha.3, which is used in trust-dns-resolver 0.10.0-alpha, as well as trust-dns (client) and trust-dns-server 0.15.0-alpha series. &amp;#x200B; It assuming you're on a current release, cargo update should bring any effected software up-to-date and resolve the issue. Thank you to /u/oherrala for finding, reviewing, and helping with the patch.
You can set the LIB environment variable to include both `D:\PATH\TO\SFML\Libs` and `D:\PATH\TO\CSFML\Libs`.
What do you mean by "kind of static" term? #define PRIVATE_FUNC static #define STATIC_VAR static PRIVATE_FUNC int foo() { STATIC_VAR int x = 0; return x; } Like this?
I see no `goto`s in minimp3.h. I believe it's `do while` loops had been translated this way 
Can't say, but I find it *absurd* that the two layouts support different markup features.
Thank you very much! This seems to work, but I can't figure out how to divide different pathes. Tried ";" "&lt;SPACE&gt;" and ",". Is there a way to set the LIB variable to multiple pathes?
Bruh, you think a piston driven 7.62 is gonna be easy on recoil? Shit's a battle rifle homie, think again. PS: LEARN RUST!
I really like how this post tells the story of diving into a bug that looks intimidating and slowly learning a bunch of new things along the way to fixing it!
The repo is on github: https://github.com/nicoburns/rustdi I'll probably do a proper introductory post at some point, but for now if you take a look in the `rustdi_examples` crate you should be able to get a decent idea of how it works. The key idea is a `ServiceContainer` struct that wraps a TypeMap (from the typemap crate) and allows you to do things like let c = ServiceContainer::new(): c.bind_singleton_rwlock(AppState::new()); c.bind_factory(|| rusoto_s3::S3Client::new()) and then a proc_macro that transforms fn foo(a: &amp;AppState, b: &amp;mut B, c: rusoto_s3::S3Client) -&gt; Bar { /* impl */ } into (ServiceContainer impl's Resolver so that other implementation's can be substituted) fn foo&lt;R: Resolver&gt; (resolver: R) -&gt; Result&lt;Bar, ResolveError&gt; { fn orig_foo(a: &amp;AppState, b: &amp;mut B, c: rusoto_s3::S3Client) -&gt; Bar { /* impl */ } let a = resolver.resolve_immutable_ref::&lt;AppState&gt;()? let b = resolver.resolve_mutable_ref::&lt;B&gt;()? let c = resolver.resolve_owned_value::&lt;rusoto_s3::S3Client&gt;()? Ok(orig_foo(a, b, c)) } It's reasonably efficient I think. It can resolve concrete dependencies without heap allocation. I would like to be able to make that work for trait objects too (which should be possible, because you can create a concrete object and then cast it as &amp;Trait, but I don't it's possible within Rust's current type system). See the `router` example for WIP attempt at a RequestResolver that wraps a service container, but also allows request stuff to be injected.
I've not had to try, but some cursory googling suggests that it's supposed to be a semicolon.
&gt; we have no type-based alias analysis (TBAA, AKA "strict aliasing") Hm, why don't we have it? Is it not useful for Rust code?
&gt; Is getting emit-ffi into rustc a viable option in the future? Yeah… I hope so. Kind of a shame that both bindgen and cbindgen weren't built into Rust from day one.
Rust seems to take a surprising amount of syntax inspiration from JavaScript. let foo = "lalala"; let foo_object = {foo}; works too.
In this case machine-readability is more important than human readability. These days with most languages you get JSON serialization for virtually free in terms of programmer effort but for IDL and C headers you need separate parsing libraries which are much more rare than JSON support (and have to support much more complexity).
In this case machine-readability is more important than human readability. These days with most languages you get JSON serialization for virtually free in terms of programmer effort but for IDL and C headers you need separate parsing libraries which are much more rare than JSON support (and have to support much more complexity).
[MS-DOG](https://pbs.twimg.com/media/CDxjoY0UgAAz68f.png:large)
Congratulation for the really good work. The simplicity of the website is fantastic, no ads, not tracking, no unnecessary information, big up. I wonder whether you are planning to make an Android/IOS/Desktop app of this nature! Good work and thank you for letting others learn from you.
It's broken for me, too, on the new Reddit web client.
And I have no idea why so many down vote :(
&gt;you'll be writing C, but more as a fancy assembler Sometimes I wonder if people that say this (that C is just "portable assembly" or whatever) have ever written assembly...
Thanks for the update, though I have to ask, in what ways is this bug exploitable? I was under the impression that stack probes + guard pages suffice to preemptively any program that's about to blow its stack. Is there some way to get RCE or memory disclosure out of this (IOW, am I mistaken about stack probes?), or is the concern here just DoS rather than memory unsafety?
Any guidance regarding threads? https://github.com/rust-lang-nursery/rust-cookbook/issues/440#issuecomment-425974599
We do have a design sketch, but it's not quite ready for scrutiny yet :)
Great progress, but wondering when debugger is going to come?
I’ll go back and update the posts to make this clear, but the notice is related to DoS potential, mainly in the server. For the resolver and client, this would require a MITM to exploit also as a DoS. The Rustsec issue linked in the post does go into this detail. You are 100% correct though that as far as I’m aware there is no data leak, or other potential unto ward memory accesses, and does properly result in an application crash. Given that the resolver can be embedded in server side software, this has the potential to be pretty bad it it was exploited, even if it might be hard, given that it requires either a malicious resolver or a MITM of resolver responses. The server is much more susceptible, as it would be very trivial to trigger this. I’ve already reached out to people I know to be running the server before announcing the vulnerability.
Debugging rust code is already supported by using CLIon instead of IntelliJ.
I think the most intimidating part for me would be the front-end stuff. Did you roll your own styles, or use a framework?
Thanks for the clarification, I just wanted to make sure that the runtime memory safety protections were actually doing their job. :) You can never be too careful about these sorts of things...
&gt; I think it would be nice if you could as much as possible be expressive and have static guarantees -- i.e. "have your cake and eat it" language design; but of course, that is not easy. Indeed. Which is why I think a pragmatic approach is using a separate script (possibly a Rust script, possibly `build.rs`) to fetch data from external sources and commit them into source control, then have only restricted I/O during actual compilation. The commit to source control of munged data matters for reproducibility, which from my work experience is a very desirable property: stuff happened in production with version N, checkout tag N, build in Debug, and have at it. The fact that it's also much easier on MIRI not to have to care about anything else than reading/writing a file (logging?), is a bonus.
Anonymous union is desired, but is not obvious how it must behave in certain situations. For example, what is `T|U` when `T` and `U` are same? It would be great to squash it into simple `T`. On the other hand, it would be great to have distinction between the two. How will you construct a value of the type?
Essentially, someone managed to get the access token of one of the maintainers of the eslint-scope package on NPM, and published a new (compatible) version which would gather NPM credentials at install time and upload them to a server. From that point on, anyone building without a lock file and depending on eslint-scope would automatically pull in the infected version and have their credentials stolen. See https://nodesource.com/blog/a-high-level-post-mortem-of-the-eslint-scope-security-incident/ for the post mortem.
Depends. Are the arrays fixed-size, so they could be put on the stack? If so, there's no fragmentation at all. Do their lifetimes overlap? Then there could be fragmentation. If all the arrays are being created at once and then destroyed before the next batch is created, then it won't matter, since all the memory will be freed before new allocations.
A colleague asked me an interesting question today: what's the best way to find useful crates? The best answer I could give was the search functionality on crates.io and judging by description, number of downloads, and version number; and that I've found plenty by reading this subreddit. I'm not sure if there are better ways to find interesting crates, though.
&gt; In most shaders you can specify packing and layouts for structs explicitly and driver vendors must comply with this specification. For example, in Vulkan, uniform buffers at least are std140 layout period, which has a bunch of wacky nonnegotiable rules. Another example is dynamic uniform offsets, which give you arrays whose stride isn't even consistent between different hardware. Maybe you're using a differently behaved API, but what about the network and audio DMA structures? Can you specify their layout too? If you're specifying an explicit struct layout for your shaders, it sounds like keeping that specification in sync is going to be the dominant issue, anyway. You could, for example, generate layouts that match the rust-native ABI of your struct by inspecting it at compiletime, and then not need to worry about conversions or annotations at all.
/r/playrust
Nope! :-P I have enough on my plate. But I encourage you to make your own thread about it, it might get more visibility.
Stack probes and guard pages [don't exist on all platforms](https://github.com/rust-lang/rust/issues/49355). In fact, it looks like only the Tier-1 platforms can really be depended on for this.
Rust references provide a better system of aliasing guarantees than TBAA
It almost certainly would be, but that’s *very* hard to start with.
Because you very kindly try to persuade people to borrow you things?
&gt; as you also point out in the Go quote section That quote doesn't contradict the generational hypothesis. Most objects in Go are short-lived, but escape analysis allows Go to allocate all those short-lived objects on the data stack instead of on the heap.
They're my own styles...nothing particularly interesting about them other than personal preferences.
This looks awesome! I definitely might use this. Let us all know when you start working on the CMS. I have some ideas on what I need from a CMS in rust, and it might be worthwhile to chat. 
I don't want to mean this as negative comment, but more as a constructive one: the experience of using IntelliJ's plugin is too good a development experience for how poorly the debugging works. Last time I checked, it was there no way to check the contents of a Vec which is something pretty basic that I'm sure a lot of people need. I love all the hype and amazing work around type and inference; it's mind-blowingly good. I just don't see how Rust got away for so long with such a disappointing debugging story overall given it's a systems language.
I saw a talk on c2rust at RustConf this year and they mentioned that they implemented the relooper algorithm originally devised for Emscripten to handle translating gotos from C code. You can actually play with live translation on [their website](https://c2rust.com/), and one of the samples there has a bunch of gotos but translates into surprisingly simple Rust.
Nice writeup! I think a lot of what you struggled with is just the fact that there's tons of old C/C++ code out there that follows *really weird* conventions. If you hadn't read it, eevee has [a blog post](https://eev.ee/blog/2018/03/30/a-geometric-rust-adventure/) about porting some C++ code to Rust that has similar feelings. Some other random bits you might find useful: For serializing/deserializing binary data formats I love [scroll](https://docs.rs/scroll/0.9.2/scroll/). It has a custom derive that makes this stuff super pleasant to write. I recently converted my [minidump crate](https://github.com/luser/rust-minidump) to use it and it went really well. Now I just [derive some traits on my structs](https://github.com/luser/rust-minidump/blob/a688dc86d9d2f3fdf70fb41f01e492e2c18bbf33/minidump-common/src/format.rs#L442-L451) and then [call one of the pread/gread methods](https://github.com/luser/rust-minidump/blob/a688dc86d9d2f3fdf70fb41f01e492e2c18bbf33/src/minidump.rs#L1507) to read types from a slice of bytes! For writing tests of binary format parsers you might find my [test-assembler](https://docs.rs/test-assembler/0.1.5/test_assembler/) crate useful. I ported it to Rust from some C++ code Jim Blandy wrote for Google's Breakpad project a few years ago and it has worked out really well. It lets you generate data by stringing together sized fields of whatever endianness you need, including placeholders to values that are calculated later (like offsets into the data you're building).
&gt;Last time I checked, it was there no way to check the contents of a Vec which is something pretty basic that I'm sure a lot of people need. I think you might like [this PR](https://github.com/intellij-rust/intellij-rust/pull/2928).
OMG, we're getting fancy debugging! &lt;3 
I think best way to find out about some recent big-ish changes to the language or just-around-the-corner features is the [guide for the upcoming 2018 Edition of Rust](https://rust-lang-nursery.github.io/edition-guide/rust-2018/index.html). As for libraries, that’s a different story.
 I also believe I’ve heard that rustc may assume that it can optimize a #[repr(C)] item if it’s not exported, making this a potential safety issue as well. &amp;#x200B; Wow, that sounds bad. If I have unsafe code that uses a struct declared with \`repr(C)\`, that could break things, right? can anyone confirm this?
Things which first come to my mind are: [SIMD](https://github.com/rust-lang/rust/pull/49664/) and [u128](https://github.com/rust-lang/rust/pull/49101) stabilizations.
As long as you don't have too big of an overlap, it might be OK to just allocate normally - jemalloc's website says it "emphasizes fragmentation avoidance," so it might be able to handle whatever you give it.
One place is the [awesome-rust repo](https://github.com/rust-unofficial/awesome-rust).
Is there a way for me to request a code review of the examples in the rust-sfml examples? https://github.com/jeremyletang/rust-sfml/blob/master/examples/ Let's say we pick one - pong. https://github.com/jeremyletang/rust-sfml/blob/master/examples/pong.rs How rusty is it? 
Nice! Really liking the clion rust experience. Great seeing it moving forward.
Yes we started with [tokio-modbus](https://github.com/slowtec/tokio-modbus) that works for I/O systems as long as you don't need hard realtime. For more ambitious projects we'd like to publish a EtherCAT master (pure rust of course ;-)) but first we need a funding for that. And great to see that you started with ADS :) Siemens isn't on our roadmap yet but feel free to contact us if you need some help :)
Ah yes, I was not involved with async stuff that much, so it had a very limited impact for me.
Nice to hear! Just contact us if you're going to join us :)
Is there a way for me to request a code review of the examples in the rust-sfml examples? https://github.com/jeremyletang/rust-sfml/blob/master/examples/ Let's say we pick one - pong. https://github.com/jeremyletang/rust-sfml/blob/master/examples/pong.rs How rusty is it? No judgement towards the author at all, just requesting this so it can be compared to the original sfml examples. https://github.com/SFML/SFML/tree/master/examples Thanks!
That certainly could if the unsafe code makes assumptions about the layout. I have unsafe code for dealing with mapped datastructures, and I'm using repr(C) to ensure a particular layout. I haven't run into any issues but that's rather concerning. If rustc might ignore repr(C) there needs to be a way to force it not to or another way to hand control layout. Layout control can be critically important for performance sensitive code. Avoiding false sharing, and reducing the number of cache lines used when accessing a subset of structure fields. 
https://github.com/linkerd/linkerd2 is written in rust but I don't know how similar it is to what you're building.
At a high level, this looks quite a bit like pubsub protocols such as \[MQTT\]([http://mqtt.org/](http://mqtt.org/)) or \[NATS\]([https://nats.io/](https://nats.io/)) I'd strongly recommend using \[Tokio\]([https://tokio.rs/](https://tokio.rs/)) as the network IO library if you plan on building a scalable pubsub system. You might want to have a look at [https://github.com/zonyitoo/mqtt-rs](https://github.com/zonyitoo/mqtt-rs), which is probably the best example so far of using Tokio to build a pubsub system. 
Awesome! I found Appveyor really cumbersome to figure out and more or less just gave up on writing a configuration file for it, it's probably just experience but I find Travis to be really great to setup a CI. I haven't used it for anything advanced whatsoever however so I cannot comment on anything besides running `npm test` and getting coverage from that and `cargo {test,fmt,clippy}`.
It depends on the situation. When environment variables are used as they were originally intended, they are good. I certainly wouldn't want to have to write a wrapper for every command which currently references environment variables like these: * `BROWSER`, `EDITOR`, `VISUAL` and various other console precursors to the associations declared in `~/.local/share/applications/mimeapps.list` * `LANG` and the `LC_...` family of variables (Specifying the desired locale) * `SDL_VIDEO_FULLSCREEN_HEAD` and `SDL_JOYSTICK_DEVICE` (Used to override SDL's heuristic for identifying the primary/first monitor and joystick if the default behaviour is undesired.) ...not to mention the cases where it's simply most convenient to use an environment variable for use-specific overrides rather than potentially needing a wrapper which does config file virtualization trickery. (eg. I have games where I have to write wrappers to keep them from writing un-hidden crud to `$HOME` and I detest the ones which ignore `$HOME` and go straight to the `getpwnam` or `getpwuid` functions because it means either `LD_PRELOAD` hackery or a more fragile wrapper which moves/symlinks the save/config files from `~/.local/share/...` to `$HOME` before starting the game and then cleans up when it closes.)
I wasn't around at the time, but as I understand it, the predominant 16-bit platform was the PDP-11, the predominant 32-bit platform was the VAX, and 64-bit issues raised their heads with platforms like the Alpha. In all those cases x86 was a latecomer.
Other problems with Appveyor - The project is tied to the user and not the github org. I have builds for projects that I can't modify, cancel, etc - Builds are serial rather than parallel - No scheduled builds unless you get permission. This is mostly useful to do once a month or so to ensure external factors haven't killed your build. I've been meaning to look into ~~VSTS~~ Azure Pipeline since they've announced it works with github. The configuration seems to be pretty powerful. Just need to set aside time to try it out (and now Travis for Windows)
Non-Lexical Lifetimes, although it's still got a few more weeks before hitting stable.
The post link is a 404 for me
 This looks very interesting indeed. I have used nginx + lua in ways that it probably should never have been used because there wasn't a decent high-performance web server + lua environment. This would have simplified things dramatically :)
I will. I just don't yet feel comfortable enough with neither rust nor graphql :/ Getting there though :)
It does support names jobs! It’s just not documented anywhere that I could find. You can see it here for one of my (silly) projects here: https://github.com/sondr3/kah/blob/master/.travis.yml
That's not specifically an async feature. `impl Trait` basically just simplifies the declaration of generic functions. 
No idea, I haven’t looked at how you’d do custom builds but I’m just weary of having to do the exact same thing I was trying to do on Appveyor there when you now have Travis. 
&gt; The Windows build environment launches with support for Node.js, Rust, and Bash languages. Wow, I'm surprised to see Rust there. Node.js makes total sense to be a top priority with the huge ecosystem JS has, and Bash also makes sense assuming that they need good support for the build scripts anyways? But I would have assumed other languages to have way higher priority and more resources spent on them than Rust. Wonder why they decided to have it in there so early? Maybe they wanted something that builds native executables to see if it works and the Rust build system was easier than the multitude of different C/C++ stuff?
it actually makes returning closures possible with generics
`impl Trait` also allows returning closures. [https://play.rust-lang.org/?gist=90687289c4773816f8f2a638a676c5a7&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=90687289c4773816f8f2a638a676c5a7&amp;version=stable&amp;mode=debug&amp;edition=2015) &amp;#x200B;
But how will everyone know I went through all the trouble of setting up AppVeyor, if I don't have two CI badges on my repo?!
Guard pages exist on every platform AFAIK, though LLVM only has stack probe support for our tier-1 platforms. In this particular case I suspect that stack probes are unnecessary, since the particular function that's infinitely recurring looks rather modest and isn't going to need so much stack space that it would skip over the guard page.
Good point :) I guess with something like WebIDL, human readability is very important, but for this use case I suppose the programmer doesn't care what the format is as long as it works :)
Huh, looks like July 30th added them! https://docs.travis-ci.com/user/customizing-the-build/#naming-jobs-within-matrices https://github.com/travis-ci/travis-ci/issues/5898 I'll have to check how it looks in checks (no pun intended) but it's great to see!
How do the build times compare? Hmm, seeing the test section gets me thinking. It'd be interesting to take the `cargo test --message-format json` output and convert it into JUnit. Might even be worth doing that for test-compiles? That'd provide something easier to look at than log output (in theory) and if they have any analytic features, even better.
`fn&lt;T: Trait&gt;() -&gt; T` means that the call-site chooses what concrete type `T` is (`foo::&lt;Type&gt;()`). `fn() -&gt; impl Trait` means that the definition chooses the concrete type and the use site is only allowed to use it through the fact that it implementats `Trait`.
Note that that initializes all members of the array to zero which is not strictly equivalent to the c code where the values in the array are left uninitialized before you set them in main. Not that this is a problem. You should only bypass initial initialization if it's appropriate, and then only if you *really* need to skip the initial initialization.
/u/steveklabnik is working on a chapter for them in the 2018 edition of TRPL but it doesn't appear to be done yet: https://github.com/rust-lang/book/blob/master/2018-edition/src/ch19-06-macros.md
Just use https://shields.io/ and fake it! You've got Bors making sure master always builds, so what does it matter if your badges are always green, your master build is always green anyway!
r/playrust but I doubt they want it either
I've just published a [netstat](https://crates.io/crates/netstat) crate for cross-platform network sockets information retrieval. The long-term goal is to query this information in the most optimal way, but currently it's really efficient only for windows and linux, thus the version is `0.6`. On mac it still parses netstat output instead of sysctls because I don't have mac and not been able to finish proper implementation on virtual machine. If anyone has a mac and wants to contribute, you are very welcome!
How does not fulfill that definition? Unless you have a specific unique definition for "automatic"? Because I don't do any memory freeing in Rust that isn't automatic.
I prefer to be explicit about the absence of a result and use \`Option\`. I don't like trying to pile meaning onto empty collections, because it can become ambiguous. Does it mean there was a success, but no results? Or does it mean failure? Or that no processing occurred at all? 
Depends entirely on if the distinction between "I have a vector of no elements" and "I have no vector" is something that matters for a particular purpose. There's no universal rule.
Sure? I feel like a disconnect button would be a great addition to rustc
I am currently developing a (not ready for public consumption yet) crate for type-level values and function,I don't know if this qualifies. [https://crates.io/crates/type\_level\_values](https://crates.io/crates/type_level_values) &amp;#x200B;
I have prototyped a version with your suggestion. I wonder about this: &gt; What you absolutely should NOT do, is saving the data as &gt; Vec&lt;Vec&lt;Scalar&gt;&gt; &gt; . (Unless you plan on highly variable number of columns for each row). This is needlessly bad for cache-usage Vec&lt;Vec&lt;Scalar&gt;&gt; make far easier all the operations, because I can treat whole rows/columns. I was under the impression Rust put the data linearly in memory. Where I can learn about this details? How bad in the performance hit? 
Just what we need! You're 15 minutes into the compile then accidentally \^C when you meant to send it to the background instead and now you've got to start all over! :D
Another option is to create a wrapper type with a constructor fn new&lt;T&gt;(vec: Vec&lt;T&gt;) -&gt; Result&lt;Self, Error&gt; { if vec.len() == 0 { Error(/* some error here */) } else { Ok(Self { vec }) } } Or alternatively, fn new&lt;T&gt;(item: T) -&gt; Self { Self { vec: vec![item] } } The downside here is that (for a library author at least), now everyone else has to deal with your new type instead of using the standard `Vec`. You could try to help by implementing `Deref{Mut}&lt;Vec&lt;T&gt;&gt;` for the new type, but then the vector could be emptied by use of the methods for `Vec`. So to avoid that you'd instead have to write boilerplate methods that dispatch to the methods of `Vec`, *except* for those which could be used to empty the vector. For a binary author, I guess it wouldn't be such a big deal. The second case is a little nicer since it's a static check rather than a dynamic one, but still has the other issues.
I hope async/await stuff
Here's a crate I made that allows you to encode a subset of GADTs in Rust, https://docs.rs/refl/0.1.2/refl/. With GADTs, you can gain a degree of dependent typing.
Another interesting case is the https://docs.rs/indexing/0.3.2/indexing/ crate which uses lifetimes to emulate dependent typing.
Variables with static lifetime in C are initialized are initialized to 0/NULL per the spec.
My understanding is that It works, but with a template, the call-site must know the type somehow, with impl, the type can be anonymous to the outside.
I don't think Rust will have dependent types soon. There will be generics over constants which are "static dependent types": https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md Ticki had a proposal to add Pi types to Rust: https://github.com/rust-lang/rfcs/issues/1930 you might find it interesting.
different features is fine. The fact that the new features are not simply a superset of the old features? absurd.
I think the term "constant dependent types" are better, since dependent types are static already but not necessarily known at compile time.
Even without any mention of type interference, `&lt;T&gt;` says "the call site _can always choose any_ `T` which satisfies the bounds". Given `fn foo&lt;T: Fn() -&gt; u32&gt;() -&gt; T { ... }`, I am always allowed to do `foo::&lt;fn() -&gt; u32&gt;();` or `foo::&lt;MyNewType&gt;();`.
Ticki's [previous RFC](https://github.com/rust-lang/rfcs/pull/1657) called it "const-dependent". &amp;#x200B;
The Book is now in second edition and much more informative. That's probably the biggest change you'll see. Learning Rust got so much easier! Compiler error messages got a great deal more helpful, too. Some pain points with ergonomics have been alleviated, e.g. `match` statements do not devolve into a mess of arbitrary `ref`, `&amp;` and `*` anymore. `impl Trait` has landed, which makes it possible to e.g. return an iterator without boxing it. Inclusive ranges are now supported, e.g. if you want to loop over numbers from 1 to 10 inclusive you can write `1..=10`. Unsafe SIMD intrinsics are now available on stable. Lots of standard library function stabilizations. Incremental compilation has landed, which speeds up rebuilding a project. Parallel compilation has also landed and is enabled by default, but degrades speed of the generated code in some cases, so that's something to watch out for.
To the user, they mean different things. With an `vec![]: Vec&lt;_&gt;`, they know their request was processed and the result is empty. This can be your query is to restrictive. For example, `x*x==-1` have zero solution in `Real`, but if you are looking at `Complex` you get solutions. With an `None: Option&lt;Vec&lt;_&gt;&gt;`, you didn't get a result. This can be an error, or querying something that is not answerable. For example, `1/0` is not answerable. "This statement is false" does not have a truth value, etc. If talking about mutable objects, they have more differences: you will be able to insert into an `vec![]: Vec&lt;_&gt;` and not creating anything. However, you have to change a `None: Option&lt;Vec&lt;_&gt;&gt;` to `Some(vec![])` before insert, this means creating your own `Vec`.
I think `#![cfg(target_pointer_width = "64")]` in the crate root should work.
...ah. Thank you! Thinking about it, I did realize this at one point, because I now remember thinking to myself that I probably wouldn't miss `auto` as much with `impl Trait`, and indeed it works a lot more like that than it does like a template type. 
There's a book coming soon from Pragmatic Programmers called "Programming WebAssembly with Rust". Perhaps the beta of the book will be out within a couple of months. The announcement is here: https://medium.com/@KevinHoffman/programming-webassembly-with-rust-the-book-7c4a890fcf97 As an aside, if you go to the Elixir forum and use their coupon code, you can usually get around 35% off the list price for the ebook.
To me, the former means, "I know the sequence and it is empty", whereas the latter means, "I don't know the sequence." it depends on the situation and what meaning you want to communicate.
This crate is really cool! Any perf benefits to be aware of? What benefits do this approach give over both the naive approach and the simpler generational indices as seen in the OP's repo?
Make sure your player queue is implemented with a `VecDeque` so that dequeueing doesn't require reallocation or memory moves!
You will likely need some sort of mapping from the string to the type. This can either be a match or some form of lookup table.
Have a look at Joshua Yanovski's https://github.com/pythonesque/dependent_traits/ - pretty hilariously cool/scary!
Now if only there were morepeople doing Mac builds. I only use Travis for my Mac builds,and they have a terrible queue during the business day. And I have to keep a synced clone of my GitLab repo to GitHub to integrate with them. I'd love competition in this space too!
On a completely content-free note, you need a way to emphasize text that's different from block quotes.
Build times are good. The best part is no queueing...our builds start right away in every platform. Yeah, I looked into junit reporting. There are 3rd party test runners that support it and there are bugs to support something similar in cargo but nothing on stable yet.
Hmm... Maybe I was using it on Windows, or really with IntelliJ...
TravisCI macOS builds: ["Mac should be better now though, as we took significantly more machines online."](https://twitter.com/konstantinhaase/status/1050506178072113152) Other CI providers that have macOS support: [Shippable](https://www.shippable.com/ci-for-macos.html), [CircleCI](https://circleci.com/build-environments/xcode/osx/), and you could always run [GitLab CI on a MacStadium machine](https://about.gitlab.com/2017/05/15/how-to-use-macstadium-and-gitlab-ci-to-build-your-macos-or-ios-projects/). (In fact, IIRC TravisCI's Mac machines are provided by MacStadium!) The problem as I understand it is that there isn't any available Docker-like containerization for macOS, so each and every test run has to have a dedicated machine, whereas Linux builds can be containerized and done with many builds on one machine in parallel.
I mean, doing `some_usize as u64` should work perfectly fine on 32-bit systems. The opposite isn't always true, but that's easy to check for.
I've had an issue where my rocket based server sometimes becomes unresponsive and I have to restart it. Actix-web seems a little more straightforward with their auth story, so I'm thinking about porting my app over to that. Also actix doesn't require nightly which is a plus in my book. 
That compiles, but it not creating an object or map with the key `"foo"`. The curly braces creat a code block with a single expression, the var `foo`, and so the block evaluates that expression. If you print out `foo_obj`, you will get simply the string `"lalala`". It is the exact same as writing the second line as without the curly braces . 
Very interesting, good luck with that! Personally I intend on working more on piston's conrod ([https://github.com/PistonDevelopers/conrod](https://github.com/PistonDevelopers/conrod)) as I feel I can learn a bit from the overall design and my main focus for such a gui is games. &amp;#x200B; I've never worked with the Windows Direct2d API but I am looking forward to watching your plans progress :)
&gt; And it's inherently incompatible with the design of dumping standard library containers' byte representation directly onto disk. Someone doesn't know about `MAP_FIXED`... ;) The numbers for capnproto are much better than they were a year or two back when Erick did his goser benchmarking. Lemme check them out! The traditional capnproto issue is that the builder time was surprisingly large, even if once "built" things are fast. It looks like in addition to encoding you are benchmarking reading the strings from disk too, doing line parsing, allocating and de-allocating the strings, right? If you subtract that out, by how much do the ratios change? Similarly, on decode you are doing lots more work than the pointer correction by scanning all of the content bytes of the strings (which is fine, it's a thing); do the denominators of the ratios vanish if you do that? I can try and check these out myself, but just waking up and w/o the right data file (can make, once coffee in face).
&gt;Vec&lt;Vec&lt;Scalar&gt;&gt; make far easier all the operations, because I can treat whole rows/columns. I was under the impression Rust put the data linearly in memory. Where I can learn about this details? How bad in the performance hit? Vec&lt;Vec&lt;Scalar&gt;&gt; will store a contiguous vector of pointers to contiguous vectors. This makes it unlikely to find adjacent rows adjacent in memory. How big an impact it really has is hard to say, it depends a lot on your row-size, lifetime of application, and churn in your tables. If you really want to optimize, I would benchmark both alternatives. You could try using Matrix from crate nalgebra. It should be fairly efficient for these things
The problem with `Vec&lt;Vec&lt;Scalar&gt;&gt;` is that, while `Vec&lt;T&gt;`'s stores its data contiguously, the representation of `Vec&lt;T&gt;` itself is `(pointer, capacity, length)` with `pointer` being a pointer to the actual data somewhere on the heap. (Because `Vec&lt;T&gt;` must have a small, fixed size in case you assign it to a stack variable.) That means that, in C terminology, `Vec&lt;Vec&lt;T&gt;&gt;` isn't a two-dimensional array but, rather, an array of pointers to arrays. Supposed the outer `Vec` is the rows. You're guaranteed that the list of rows will be contiguous, and that each row's contents will be contiguous, but it's unlikely that row `N+1` will begin immediately after row `N` in memory.
Me too... PS: resvg author.
You could certainly implement something like `get_strip(&amp;self, pos:usize)` which returns either a row or a column, depending on which struct implements the traits. However, asking to define `row` and `col`in the trait, but then only provide one or the other depending on the struct implementing, it is fundamentally antithetical to what traits are. A trait is a promise that a certain interface will be available, so you seem to be asking "How do I define a data structure which promises both `row` and `col` methods, but then doesn't deliver on that promise. The compiler will rightly refuse to compile such code.
Fair enough, I'd glanced at the musl issue and it looked like it could be a problem, but it turns out that it was just the special handling of a segfault from the guard page, to print a nicer error message, that was disabled, not the actual guard page. Guard pages don't exist on embedded platforms; in some cases, you can arrange your layout so your stack will overflow out of the address space, but in some cases that's not possible.
No, my purpose isn't to get an `i32`. I just want the anonymous union type to be a base mechanism in `rust`, so we can do many things: 1. like we can let `generator.next().0.value` be an union type, make the status machine be build at the compile time and typesafe; 2. in `fn abc(a: impl TryInto&lt;i32&gt;)`, `u32` to `i32` is completed outside of `abc`; but in `fn abc(a: i32 | u32)`, transformation is completed in `abc`. `fn abc(a: u32) -&gt; u32 59u32` is indeed harder to read than `fn abc(a: u32) -&gt; u32 { 59u32 }`, but `fn abc(a: u32) -&gt; u32 { async!{59u32} }` has too more idents than `fn abc(a: u32) -&gt; u32 async!{59u32}` too.... Well, it seems more idents is ok.
Though you might not expect it by the name, GitLab CI also supports GitHub (though I'm not sure about reporting back to GitHub). You can just specify a Docker image, and which commands to run in it to build your project, so while it doesn't support Windows, it's very powerful.
Yeah, just like @rawler82 said, why must we construct a value of the anonymous union type? And the anonymous union type is `anonymous`, it should be normal for it to have no public construction.
For decode: I just quickly tried changing the decode benchmark to call `test::black_box` on the words rather than doing the byte sum. Interestingly, this brings abomonation down by 0.3s to 0.7s – barely any higher than not iterating through the list at all – while it seems to save less than 0.1s for capnproto. This makes sense since capnproto has to read the string data (and thus bring it into cache) to validate it as UTF-8, while abomonation can leave that region of memory untouched. But I think it's more natural to have the benchmark access the data. For encode: I admit I was more focused on the decode side of the benchmark, so this may have been somewhat unfair. If I benchmark just encoding to memory performance, without the initial file read to Vec (or the write to /dev/null, though that doesn't seem to make any significant difference), abomonation looks much nicer in comparison: for 1000 runs, 8.2s vs. 19.9s.
I've used it for authentication in a small game, worked really well for me
It wasn't a compliment. He's making fun of you. 
What do you mean lookup table?
For pub-sub you may also be interested in [Mles](http://mles.io)
My advice if you actually want to make a game is to not make your own ECS at the same time. Just use specs.
Yes. I sometimes use three. One for unit-local variables and one for function-local variables.
Anonymous product type, a.k.a. tuple we construct explicitly. Why anonymous sum type should be any different in this regard?
As rocket uses nightly and doesn't use async(afaik) I wouldn't recommend it, especially considering that I heard it can often break due to be nightly only
Both can serve the same goal, so just use what you find more attractive.
How does the compiler handle memory management in C? I didn’t downvote you but I’m guessing that’s why.
If you're asking if Rust has a clever trick for doing this, which would be something like runtime type reflection, it does not. You need to either write the mapping table by hand with entries for each name string and type or write a derive macro that generates it from your type. The macro sort of exists already in serde, so you could just make your text components be in a serde-readable format, add a bit of enum boilerplate to get the component names in the serialization as well and maybe get something like this: #[macro_use] extern crate serde_derive; extern crate serde; extern crate serde_json; use std::fmt::Debug; // Shared component trait trait Component : Debug {} // We need a wrapper enum that stores the name of the component in the serialization. // Use a macro because this is repetitive. macro_rules! component_wrapper { ($($x:ident),+) =&gt; { #[derive(Serialize, Deserialize)] enum ComponentWrapper { $($x($x),)+ } impl From&lt;ComponentWrapper&gt; for Box&lt;dyn Component&gt; { fn from(w: ComponentWrapper) -&gt; Box&lt;dyn Component&gt; { match w { $(ComponentWrapper::$x(c) =&gt; Box::new(c),)+ } } } } } // ECS example, some concrete components and listing them all to the wrapper macro. #[derive(Serialize, Deserialize, Debug)] struct Pos { x: i32, y: i32, } impl Component for Pos {} #[derive(Serialize, Deserialize, Debug)] struct Name { name: String, } impl Component for Name {} component_wrapper!(Pos, Name); fn main() { // Example textfile component data for string_entry in &amp;[ r#"{"Pos": {"x": 10, "y": 20}}"#, r#"{"Name": {"name": "xyzzy"}}"#, ] { // Deserialize using Serde, use the conversion trait on ComponentWrapper to get our // components out. let comp: Box&lt;dyn Component&gt; = serde_json::from_str::&lt;ComponentWrapper&gt;(&amp;string_entry).unwrap().into(); println!("{:?}", comp); } }
Hi reddit! Here's a post I made a post about [actix-lua](https://github.com/poga/actix-lua), a crate to integrate lua script to actix framework. Hope you find the use-case interesting. Feel free to ask any question! Also, sorry for the re-submitting. I had some issues with my previous blog host whic made the post unavailable. All should be good now!
well, this is, in principle, the same as `Option&lt;usize&gt;::None` vs `0`
Hi, I'm reading [The Little Book of Rust Macros](https://danielkeep.github.io/tlborm/book/) and I see that there are few different types of macros: * declarative macros * `proc-macro`s * compiler plugins But as far as I realized the only difference between the last two is that a compiler plugin can be invoked with a few `token-tree leaves` as arguments, not just one. If that's true what is the reason for plugins to exist at all? 
**TLDR**: [link to the playground with what I try to do](https://play.rust-lang.org/?gist=455c9873a206a3e48e7cfafa485acd02&amp;version=stable&amp;mode=debug&amp;edition=2015) I have a `struct Body`, containing one big `HashMap&lt;String, Vec&lt;String&gt;&gt;`, which is kinda like a csv. So a key is the name of the column, and the associated value is the content of the column. Now, I want to be able to index this body by a row index, and it will return a `struct Row` type which references the body, and can then be indexed by column name. The `Row` roughly has that structure: struct Row&lt;'a&gt; { idx: usize, content: &amp;'a HashMap&lt;.., ..&gt;, } impl Index&lt;usize&gt; for Body { type Output = Row; fn index(&amp;self, idx: usize) -&gt; &amp;Row { &amp;Row { idx, content: &amp;self.content, } } } Now, the problems that I see are: * the [`Index`](https://doc.rust-lang.org/std/ops/trait.Index.html) needs to return a reference, which obviously won't work * `Row` in the `Index` impl misses a lifetime, which I cannot figure out how to give it. I've tried the following, which doesn't work: &amp;#8203; impl&lt;'a&gt; Index&lt;usize&gt; for Body { type Output = Row&lt;'a&gt;; fn index(&amp;'a self, idx: usize) -&gt; &amp;Row&lt;'a&gt; { &amp;Row { idx, content: &amp;self.content, } } } It fails with the following error: error[E0207]: the lifetime parameter `'a` is not constrained by the impl trait, self type, or predicates --&gt; src\lib.rs:106:6 | 106 | impl&lt;'a&gt; Index&lt;usize&gt; for Body { | ^^ unconstrained lifetime parameter Is it possible to implement this? Or should I reach for another pattern, like a simple `Body::row(&amp;self, idx)`, which won't be as nice?
I think it's better to use the following variant: #[cfg(target_pointer_width = "64")] compile_error!("This crate can be used only on 64-bit systems.") This way users will get a good, readable error, instead of the missing items list.
Ok. Let me rephrase let x: T|U = ?; // what I should write here? Lets speak some math. Let `N(x)` is the set of all possible values of type `x`. For example `N(U)` = { U }` (where `U` is unit type), `N(u8) = {1, 2, 3...255}`. Product type `P(x, y)` has all combinations of all values of types `x` and `y`. So `|N(P(x, y))| = |N(x)| * |N(y)|`. Obviously. So it is *product* type. Now what about sum type `S(x, y)`? If we look at enums then everything makes sence. `N(Result&lt;T, E&gt;) = { all Ok(T) values, all Err(E) values }. `|N(Result&lt;T, E&gt;)| = |N(T)| + |N(E)|`. Hence it is *sum* type. Now, anonymous sum type you propose `S(x, y)` doesn't had tag to distinguish between `x` and `y`. So what is `N(S(T, T))`? Clearly *set* of values can't contain same values twice. Therefore `N(S(T, T)) = N(T)`. It is not a sum type anymore. How would match work in this case? If user try to match on `value: T|U` with branches for `T` and `U` and it all will end up with `T = U` then arms will become ambiguous.
Not till next year.
I think you meant it with a `not()`: #[cfg(not(target_pointer_width = "64"))] compile_error!("...") But yes, I'd say using `cfg` with a `compile_error` is the best possibility. 
We are using rocket in production for two projects and also use it for prototyping. We make sure to keep the rocket code as minimal as possible (e.g. extra crate, only routes that call a lib crate which compiles against stable). This way we make sure, that if rocket should break we can switch easily to something else. What I personally really like about rocket: The request guards: Writting `session: helpers::Cookie&lt;SessionId&gt;` and then just passing `session.0` to the lib and having a typed sessionId is really awesome. 
I've run into a major problem in `l3_restore_reservoir`. While moving some functions into methods, I noticed one last unsafe I hadn't caught in `mp3dec_decode_frame` that was trying to subvert the borrow checker for for a `Mp3DecScratch`. You noticed there was a problem both by the fact that you had to use unsafe, and also the fact that you noticed something fishy with the lifetimes in the function signature. What's going on here is that `Mp3DecScratch` contains a `Bs`, which itself contains a slice reference. In `l3_restore_reservoir`, you initialize the `maindata` array in `Mp3DecScratch` and then pass a reference to that to a new `Bs` which then gets stored in `Mp3DecScratch`. Long story short, `Mp3DecScratch` contains a reference to another field of itself. This might not seem like much, but it's a huge deal in Rust for several reasons. For one, since `maindata` is being borrowed by the `Bs`, that spreads to the rest of the struct, making the entire struct immutable until it dies. Since `l3_restore_reservoir` takes it by a mutable reference, the compiler doesn't know that that field is no longer being modified and instead locks down the struct entirely. There's also a separate issue in that normally, structs are allowed to be moved anywhere they please. You can move a value from the stack onto the heap and back again for instance. Since `Mp3DecScratch` contains a reference to one of its fields, a simple move like this would fail to update the reference and would instead point at the old location. The solution to this would unfortunately require heap allocation, so the array doesn't move with the struct, or the unstable Pin api, which allows you to specify that the struct isn't allowed to move at all. The big issue with that is that it requires the nightly compiler. If you want this to be available without std, then heap allocation isn't available at all without the alloc crate, which is also nightly exclusive.
Well, here are the differences: - `proc-macro` can be invoked with only one `token-tree` argument - `proc-macro`'s arg must be enclosed within `()`, `[]` or `{}` (I'm not sure about this) - compiler plugin can manipulate compiler-internal structures (`macro-rules` is a good example) - compiler plugins are unstable and unlikely to be stabilized ever. Did I missed something?
Interesting, Two questions: 1) Is there a way to add to an enum after the fact (or using macros declare variants of the enum separately that then get added into one during compiling, no matter where in the code base they are) 2) Does your suggestion take into account that the data in question isn't the actual entity but rather values I want to use when I initialize an entity of that type with each component in the data being the values for that component when the entity is requested to be initialised (I.e, populating a map with a bunch of orcs, using the template to initialise each one)
Anyone who wants a 2d library, please go to github.com/draw2d/draw2d and say what features you are looking for.
It manage all the lifetime of all the automatic variables
What is ATCs? 
Ah, yes.
That repo contains no actual code...?
Do you think that basing a library off of AGG or Cairo would make sense or do you think that Rust gfx community could do something better from scratch?
1. Can I use it to render an image to PNG? 1. Does it support software mode? 1. Does it support (system) text shaping/anti-aliasing/hinting? 1. Does it have a direct access to "pixels"? It's required for filters. PS: there are no docs, so it's hard to tell.
SDL2 is cross platform but I wouldn't advise to use it for anything more than cross-platform windowing and an interface for OpenGL/Vulkan. Sure, it's great if you want to store textures and print them over your screen at different sizes, draw simple shapes of different colors. Using sdl2-gfx you can even rotate/flip do more fancy stuff like this, and with -ttf you can even use fancy fonts. However... That stops here. If you want to start using shaders with the 2d SDL2 backend, it starts getting complicated. You have complex vector images that you would like to render with the GPU? Again, no luck on that side. At this point you'd better be using one of the more 3d complex libraries on top of SDL2 windowing, or even start using OpenGL/Vulkan for your rendering. Basically I wouldn't use the "render" part of sdl2 in Rust for anything else than a simple project/a prototype. /u/kyrenn (from Chucklefish) said they were using sdl2 for windowing/audio/input, but only to use raw OpenGL behind the scenes for 2d.
There are a lot of possible solutions here. Your first problem is that the Index op is really only designed to return a ref to a contained element. You're trying to return a reference to a short-lived Row. So that's never gonna work without some really "creative" solution. Making Row derive Copy and moving it to a method should make this overall design pattern work though. Note that you won't be able to modify the Body while a Row exists. This could be what you want, but if it were up to me I would probably design it as a newtype over usize so I can hold them over update cycles. Hope that helps. Hopefully I've understood what's going on here lol.
NPM uses Rocket??
Associated type constructors. 
Yep. The READMEs you see rendered on packages’ pages are done via a rocket micro service. I think there may be more too, but that’s the one they’ve publicly talked about.
Also known as the [data model split](https://en.wikipedia.org/wiki/64-bit_computing#64-bit_data_models). Windows works under LLP64 ("long long" and pointers are 64b) while most unices follow LP64 ("long" and pointers are 64b), but there are also older systems on ILP64 (integers and pointers are 64b) and SILP64 (shorts and pointers are 64b). And then there's Linux's x32 ABI, where you're running LL64 on a 64b systems (pointers and longs are 32b).
Very interesting
That actually leads me to another question as a Rust noob: wouldn't Rust being compiled and cargo.lock prevent things from breaking even if you used a nightly compiler?
Actix is playing a central role in one of Microsoft's major Azure IOT investments. It's a high-profile story in the making. The Rust community is benefiting by this, too, as work is open sourced. It's really great!
What's the big deal about NLLs?
The components are predefined types so you can't define new ones at runtime, the templates simply decided what components an entity will have and what values will be passed to the component when the component is initialised For the macros, is there a way to build up a list of items from separate invocations of a macro and then use that list to (again via macro invocation) build an enum? If I can do that, I can then build an enum representation of all components then match that against the string provided in the template data, then do: ``` ComponentReturnedByMatch::new(initial_values_from_template_data) ```` 
From working on Firefox layout and rendering, I have many years of experience using and creating 2D APIs, and I think it's very difficult for a single 2D API to cover most peoples' use-cases well. One important axis of differentiation: how much does your application know, statically, about what it's going to render? For many desktop applications or games you have a pretty good idea when you're writing the code what the scenes are going to be like. But "platform" applications like browsers, PDF viewers and so on know very little ahead of time about what's going to be rendered. For the former case "stateful" APIs like cairo are good; you can write code that sets some state in some kind of context object, draws a set of related objects using that shared state, then changes the state before drawing more objects. OTOH for "platform" applications that sort of API is inefficient because you don't statically know which drawing operations will share rendering state. You find yourself writing code that resets all state parameters for every draw call. For the sake of performance, you start working around the stateful API by caching to avoid redundant state-setting, dynamically analyzing and reordering draw calls to increase sharing, etc. (Then you realize that cairo is a stateful context API wrapped around a stateless backend API so you've got the worst of both worlds.) So the first thing to decide is: do you want an API that makes it easy to write code to draw a specific scene, like most "my first demo" code? Or do you want an API that will let you draw arbitrary scenes, about which you know almost nothing until runtime, efficiently but with greater complexity? cairo's probably in the former category, WebRender in the latter, and Skia somewhere in the middle.
What do you mean? A nightly compiler may have regressions, things stop working when you update the compiler. I wasn't able to use clippy until it stabilized because the nightly compiler wasn't able to compile it for months.
Yes, that would be better. With the `not()` from DebuggingPanda of course. Thank you.
I've had better luck with Gotham personally. Same issue as you when playing with Rocket. 
https://crates.io/crates/piston2d-graphics
In memory, an empty vec is a struct and an heap allocation. None can be optimized away and otherwise is a static value. Semantically, there are different ways to imbue meaning, but I would say that an empty vec can't represent all the meanings that option::none can.
Great job, getting Azure Pipelines to work with Rust. I would really like to read a blog post about the process ;)
Putting aside memory(because depending on situation you will use memory anyway), the difference is very minor and only if you put too much meaning into it. Lack of values in Vec may indication as if `Option&lt;Vec&lt;T&gt;&gt;` would None i.e. no values I would say if you're not planning to allocate eventually then use Option, otherwise Vec
I mean, can I lock the compiler at a certain version? Even if I can't, if the binary of my program compiles properly then my program won't break in the future, right?
You may still update compiler and, depending on changes there, your code would most likely not compile with your old dependencies
An empty Vec with a capacity of zero (e.g. created with \`Vec::new()\`, \`vec!\[\]\` or \`vec.clear(); vec.shrink\_to\_fit()\`) doesn't use any heap memory. It doesn't allocate if its capacity is zero until the capacity actually changes. It's just a value on the stack representing an empty vector.
That's pretty neat! Thanks for sharing :)
Thanks for linking to that, I had no idea it existed. Looks good.
Yeah, I think I'll need to skip the `Index` trait, at least with that structure. I'm interested in your newtype idea, the idea of the `Row` struct is that I can then work on a row, without copying or moving the content, and while hiding the original structure, and do things like: let last = body[body.len() - 1]; if last["Foo"] == "bar" { // do things } Which, if I'm not wrong, is not possible with your newtype. I'm not that much interested in mutating the body for now, so apart, does there is other advantages? I think I'll change the `Body::content` to a `Vec&lt;Vec&lt;String&gt;&gt;`, with a `columns: HashMap&lt;String, usize&gt;` field (or simply `Vec&lt;String&gt;`, not sure), which would allow a simple and nice `Index` impl, while keeping a lot of the features.
I think I've lost track of what you want to do. You'll need to figure out if the serde+enum approach works for your needs yourself.
Just wanted to say Actix has worked great for me in production. The microservice that my team built for this particular integration is in a very central position in the system and customers have been slowly ramping up use. Despite being a young project things have gone great and I have been monitoring continuously just in case they don't. No issues thus far.
This is the subreddit for Rust, the programming language. You want to visit /r/playrust for Rust, the game.
Do you have a link to the crate you wrote using actix-lua on the blog post?
Hey! While trying to implement [a hint I got here](https://www.reddit.com/r/rust/comments/9mdok5/hey_rustaceans_got_an_easy_question_ask_here/e7dv8sq/) I realized I did not think things through enough, and would like to ask for some help about how to arrange my data. It's probably too long (I tend to write too much), I'll try to write a tl;dr at the end. I'm writing an editor plugin, and I need to keep the full file's state in my plugin. The editor sends (linewise) updates when the user changes something. Performance-wise, the startup and first data-munching of the plugin is very important to me, while handling the updates is somewhat secondary. From the above link, I've decided to keep a `Vec&lt;&amp;[u8]&gt;` as the data structure that is run through all the parsing my plugin does (i.e. it represents the file line-wise). Each `&amp;[u8]` represents one line of the file. Initially, I read the file into a `Vec&lt;u8&gt;` and then `split` it on newlines. That already works nicely. I keep the initial `Vec&lt;u8&gt;` for the whole life of the plugin process, that's not a problem. Now, the updates arrive as `Vec&lt;String&gt;`s, together with the data that tells me what linenumbers really have changed (updates always happen on consecutive lines). I'm facing two problems: I need to keep the `String`s somewhere, and they should be freed when a line is updated for a second/third/etc. time. I also need to update my `Vec&lt;&amp;[u8]&gt;` to point to the updated lines. My first though was using a `HashMap&lt;u32, String&gt;` (`u32` to represent the line number) to keep the strings, updating it as necessary, and have `&amp;[u8]`s pointing into the values of that `HashMap`. But as far as I can see, that means the `HashMap` is borrowed basically all the time, so I can't update it. I _could_ make an update the following way: Remove all lines in the `HashMap` from `Vec&lt;&amp;[u8]&gt;` by inserting a dummy value (might make use of `Option`, of course), update the `HashMap`, and then again update the `Vec&lt;&amp;[u8]&gt;`. That however feels pretty tedious and like a lot of bookkeeping. I considered a `BTreeMap&lt;u32, String&gt;` as well, since that makes updating the structure easier, but that doesn't help the problem. I ideas how I could arrange the data for this use-case? Thanks for any pointers :) tl;dr: * Keeping `Vec&lt;&amp;[u8]&gt;` as pointers into `Vec&lt;u8&gt;` to represent lines of a file * Getting updates to the lines as `Vec&lt;String&gt;` together with the line numbers * Need to put the `String`s together with their line number somewhere * Need to update the `Vec&lt;&amp;[u8]&gt;` to point the the new `String`s on update * Need to free the `String`s when they're not needed anymore * First try: `HashMap&lt;u32, String&gt;`, but keeping pointers into the values makes changing it impossible, so it's very tedious to deal with new `Vec&lt;String&gt;`s as described above
Yeah it's at a planning stage, hence why I'm looking for insights into what potential users would like.
That looks interesting and could be one of the potential back-ends. Its support for Apple devices is shaky because it's OpenGL, and it doesn't support web targets, so I don't think it would count for the abstraction I'm talking about.
uh, ggez?
rustup allows you to lock the toolchain in a way that can be committed to SCC, see [here](https://github.com/rust-lang-nursery/rustup.rs#the-toolchain-file)
This is not quite right. The general sentiment that you can write the new std futures like the old ones is generally correct. Still, `async`/`await` is _not_ syntactic sugar, in generates different code in the back, namely [Generators](https://doc.rust-lang.org/nightly/std/ops/trait.Generator.html). This has a couple of different behaviours, most notably the ability to _borrow across `await`_. Second, std futures have a different interface: Instead of an `Output` and an `Error` associated type, they only have one `Output` type. You can imagine an old-style future like a std future that returns `Result&lt;T,E&gt;`. This is minor and there might be a compatibility API available. That being said, porting over to `async`/`await` is generally an easy task and all the concepts you learned remain the same.
Didn't know about this crate until now - this is really cool. I'd be interested in contributing - do you know of any easy/medium issues that someone new to the project could jump on?
Yes, since Rust statically compiles everything, your binary will work forever and ever, as long as the target platform maintains compatibility, that is.
I imagine you're after the `p_size as usize` syntax
`p_size as usize`
You want [type casting](https://doc.rust-lang.org/book/casting-between-types.html) with the `as` keyword: p_size as usize &amp;#x200B;
I did not know that they were using Rust ! More info?
Thanks! You could check out the embedded-hal crate and look out for other traits you could implement :)
What's that target key ? I've always used a `env: TARGET=` variable.
It's fake to express what I want not how to get it
https://travis-ci.org/rust-lang-nursery/packed_simd has been using them for a while - it looks all red when nightly breaks your code
64 bit usize works on 32 bit machine?
Thanks! What does SIMD mean here?
Oops, I wanted to talk about the changes in the `futures` API, but I got lost, while searching for the RFC describing the integration in `std` ([first attempt](https://github.com/rust-lang/rfcs/pull/2395), [second attempt](https://github.com/rust-lang/rfcs/pull/2418), both postponed for now). Also, I didn't want to go deeper on the `async`/`await` side because I'm not too knowledgeable on it, and I thought it won't answer directly the question, but you're right about them being more than simple "syntactic sugar" (if I understood well, it wouldn't have allowed references across `await`s). Now, while we're at it, am I right that the two following signature are the same on the public API side? fn impl_future() -&gt; impl Future&lt;Result&lt;(),()&gt;&gt;; async fn async_fn() -&gt; Result&lt;(), ()&gt;;
1. Are you looking for untagged or tagged unions? Untagged unions are generally unsafe to work with because you cannot know what is stored in the variable. E.g the union `u8 | u16`. There is no way of knowing if there is a `u8` or a `u16` hence reading the value would be a unsafe action. Taken from a Quora answer: &gt; All of the members of a union share overlapping storage. The manner in which they overlap is implementation defined. Storing an element to one member of a union, and reading from a different member results in undefined behavior. If you're looking for tagged unions, Rust already have enums which can do this behavior. Enums in C cannot contain a value, but in Rust you could do: ``` enum SomeName { A(i32), B(u32) } ``` Behind the scenes the enum is equal to the size of the biggest contained type + a enum discriminant. 2. The conversion is done inside `abc` when using `impl TryInto`. The conversion is done when `p.try_into()` is called. This can be seen in this example: ``` struct A; impl TryFrom&lt;u32&gt; for A { type Error = (); fn try_from(_: u32) -&gt; Result&lt;Self, Self::Error&gt; { println!("converting now"); Ok(A) } } fn abc(p: impl TryInto&lt;A&gt;) { println!("entered abc"); let a = p.try_into(); println!("exiting abc"); } fn main() { abc(1); } ``` Running this example will print: ``` entered abc converting now exiting abc ```
Yes you can, but you also lock your entire dependency tree. So the moment you need to change anything there you are most likely back to make everything work with current nightly. 
They don't use Rust for Travis, they just got a couple of very knowledgeable people there and experience with the toolchain. 
Actix is rock solid and surprisingly easy to use. It's also fast as fuck.
I think there are a lot of contenders for the larger rooms, so I hope we can at least stay in the H-building. Devrooms' turnout last year plays along in the acceptance, I suspect, so most re-organising rooms will likely have had queues outside the room or at least full rooms.
I went with actix instead, because actix is really high performance, and rust isnt even on the techempower framework benchmarks. 
https://github.com/nannou-org/nannou/ could be inspiring
https://en.m.wikipedia.org/wiki/SIMD
Ok, I've looked at this code in a bit more detail (mostly because I use a partition similar to this in my crate, and performance is a big deal). The only "safe" thing in both the C and rust code samples is the line: &gt; buffer[buffer_index] = i; It is provable to us humans that buffer_index is always &lt; 64. The rust compiler doesn't see that, and puts in a bounds check. The C++ compiler doesn't care ether way, and just lets the write go through. This is an interesting case where the rust compiler could have optimized it, but didn't. Zeroing uninitialized memory by default is not rusts fault. It's trying to prevent bugs, while giving you the tools to uninitialize memory if you need to. The C version, again, doesn't care about such details. Accessing elements[i] is also undefined behavior, because we don't know the length of the array. Rust bounds-checks that, C++ doesn't. As for the memcpy, you can get rid of that by passing in buffer to the function, again as /u/annodomi pointed out. This "buffer" isn't really a buffer, it is the result of the function.
[Cairus](https://github.com/CairusOrg/cairus) is an abandoned project from a team of my students under the direction of Cairo author Carl Worth to reimplement Cairo in Rust. It would be great to see it come alive again, and I can facilitate this if someone is interested.
[removed]
&gt; For the former case "stateful" APIs like cairo are good; you can write code that sets some state in some kind of context object I disagree with this statement. Stateful APIs are rarely good, even if you know what you're rendering; they're hard to optimize in the backend, they're hard to compose between layers of code, and they're hard to use correctly without introducing state bugs. Even when your code is structured in the "set state for X, then render all the X" kind of fashion, the actual backend graphics system can't really work that way. Especially in 2D games where draw order can be so important independent of material properties. Stateful APIs in general, graphics or otherwise, are just hard to use correctly and efficiently. Just say no to stateful APIs. :) &gt; OTOH for "platform" applications that sort of API is inefficient because you don't statically know which drawing operations will share rendering state. This is pretty true for many games, too, because the user has so much agency and the action on the screen can be quite emergent. Programming games with fixed/stateful rendering pipelines is a good way to get bad frame spikes even on relatively undemanding scenes.
I wonder if you could distill this and create a very minimal test case. Once you havea minimal test case it could probably be added very easily to rust's automated test cases.
Can't wait for TWiR 0 next week
With the impending 0.4 release of Rocket, the breakage should start slowing down as they've ported all of their compiler plugins to procedural macros, which are relatively stable. Additionally, I believe async is slated for the 0.5 release and should take less time than 0.4 to complete. Overall, you can totally run Rocket in production, but it is a pre-1.0 product, so use at your own risk. It does evolve reasonably rapidly and I find it more ergonomic than any of the other frameworks out there at the moment because of its generous use of macros.
This isn't a solution to your problem, but take a look at https://areweideyet.com/
I'm not sure if you're *really* talking about compiler plugins, but I wrote something about procedural macros a little while ago: [Introduction to Procedural Macros in Rust](https://tinkering.xyz/introduction-to-proc-macros/). It *is* slightly out of date, but I believe most of it is still correct.
One solution may be to modify the type of your vector of lines. Currently it is `Vec&lt;&amp;[u8]&gt;`, but it is possible to define it as `Vec&lt;Line&gt;` with enum Line&lt;'a&gt; { OriginalLine(&amp;'a [u8]), ChangedLine(String) } You can initialy store the original lines in the vector as Line::OriginalLine's. If you happen to change a line, use a Line::ChangedLine and the vector will own the contained String. If you change a line again, replacing its Line::ChangedLine,the first String will be dropped.
I can't say I have much success with Windows on my small project. It seems to be failing on \`proc-macro2\` [https://travis-ci.org/imeka/trk-io/jobs/440729762](https://travis-ci.org/imeka/trk-io/jobs/440729762) It's strange, I'm always working on Windows, I know it works!
Does this work for you? ``` macro_rules! look_for_nones { ($base:ident, $( $sub:ident ),* $(,)*) =&gt; { $( if $base.$sub.is_none() { println!("{} is None", stringify!($sub)); } )* } } ```
\&gt; until you have reliable 'dot-autocomplete', 'jump to def' etc, you can help with the build cycle. If links to the appropriate references appear in the error stream, you text editor will bring them in when you just step through the errors. What you're looking is a text editor/IDE with RLS (Rust Language Server) integration support to accommodate most of your rust tooling needs while programming. Once you go RLS, there is no going back ;)
Yeah, this is a strange issue. It looks like some linker error (missing / can't find a library?), you should probably minimize the error (just compile proc-macro2) and report it. https://travis-ci.community/c/windows Actually, it looks like https://travis-ci.community/t/rust-error-could-not-compile-winapi/268 is relevant.
Hi, author here. Any feedback is welcome. I wrote this tool because I was trying to gather code coverage data for the frontend code of project I work on. Unit tests can generate test data just fine, but automated browser didn't. And while I puppeteer can generate code coverage data, it only generates the coverage data on what it finds, which in my case was source maps. So I wrote this tool to transform that coverage data into coverage data that actually applies to the source files used to generate the minified js files and the accompanying map files.
Have you heard of Redox, my friend? ;)
you should'nt. there are differences in c types between different platferms. you can antotate #[cfg(target_os = "linux")] and assign to i32 and anotate another platform asignmend in simmilar way.
Not yet. It isn't finished yet and the implementation is still somewhat in flux. It will also _not_ be in the Rust 2018 release version. The futures crate will move to the new futures interface. (note, only `Future` becomes part of core and std, not the combinators, streams, etc. that the crate provides) Currently, as things are unstable, the `futures-preview` crate and the tokio async/await preview is what you have.
can anyone comment on how they use imag?
`usize` is going to be 32 bits, but `usize as u64` is a widening conversion, so it's not going to fail. As log as you don't modify the higher 32 bits, it's also not going to be wrong to go back, but that requires knowing what you're code is actually doing.
But why is usize 64 bit then on a 32 system? I tough usize is always machine dependent
Request guards are such a great feature. It's incredible that so much can be conveyed in the function signature of your HTTP handler.
You are very great genius.
Heheh, thank you. Well I'm not a genius, I learned great stuff from great friends over time, that's how I learned Rust ;)
NLL isn't specifically about removing explicit lifetimes. Non-Lexical Lifetimes means lifetimes will be determined by more intuitive means than just lexical scope. As you mentioned, it's more about allowing more kinds of borrowing behavior in cases where they wouldn't clash with safety. In my experience, this comes up when wrangling with `self` in a one-liner that borrows `self` in a way that *technically* isn't allowed by the borrow checking rules, which means you had to add in a separate `let` binding before it just to satisfy the borrow checker. I *believe* NLL allows scenarios like that, but please correct me if I'm wrong. I haven't played with it myself.
We have actix in production and soon more of it if that counts. 
&gt; it's cheaper to have the function borrow something than to let it take ownership of, say, an vector of strings. This isn't really correct. Transferring ownership of a `Vec` is perfectly fine. Cloning one is the expensive operation. However, depending on the structure of `Arguments::new`, you might be better served by it being: ``` fn new&lt;I&gt;(args: I) -&gt; Result&lt;Arguments, &amp;'static str&gt; where I: Iterator&lt;Item = &amp;'static str&gt;, { .... } ``` Then you can just call it like: ``` let args = env::args().skip(1); let arguments = Arguments::new(args).unwrap(); ``` No creation of an interstitial `Vec`. (Also, if you want to pass a borrowed value from a `Vec`, you're better off passing a `&amp;[String]`.)
iirc `noalias` has been causing Rust lots of problems because LLVM doesn't really expect it (since C/C++ is a lot more lax about these things)
usize is still 32 bits. `as` does widening and narrowing casts, not just casts of the same size.
Thank you, my doubts were based [on these answers](https://www.reddit.com/r/rust/comments/4q3nr8/newbie_question_when_should_a_function_take/) and especially [this one](https://www.reddit.com/r/rust/comments/46rii1/when_to_borrow_move_or_copy/d07bpog), which may have confused me. So there's no cloning going on in doing this `fn new(args: Vec&lt;String&gt;)` or `fn new(args: &amp;[String])` ? Where can I read more about your last point? It's not totally clear to me.
Do I have to do anything special for Windows? I'm getting linker errors: = note: LINK : fatal error LNK1181: cannot open input file 'advapi32.lib' 
Travis supports Windows. Cool. My build is failing finding Windows SDK libs. Darn. https://travis-ci.org/iliekturtles/uom/jobs/440763399#L104 Anyone know off the top of their head what needs to be done to make sure the linker can pick up the Windows SDK libs?
No cloning. Cloning in Rust only ever happens explicitly when you call the `clone` method on an entity. Cloning a Vec is expensive because not only do you have to copy the Vec struct itself (not too bad, it's about 24 bytes), you also have to allocate new memory for the cloned heap data, and then clone all of that data. When you move a value you just do the first part, and you leave all the heap stuff alone.
It looks like `vsvars.bat` or similar needs to be called, I'm not sure the exact issue from the outside. Reported to the Travis team: https://travis-ci.community/t/rust-error-could-not-compile-winapi/268 It'll probably be fixed decently quickly, but keep in mind this is still technically a preview! (And Rust is the only compile-to-native available currently so we're helping iron out these issues.)
I think you'd be interested in implementing your library using ECS with the \`specs\` crate, especially since it's a game type library. You can have each scene as an Entity pointing to different Components to create the specific windows, logos, images, with greater flexibility, inside a World which act likes an object pool container. [https://slide-rs.github.io/specs/](https://slide-rs.github.io/specs/)
Thanks for the quick response and the link to that thread. I'll keep an eye out there.
I think, sometimes these things posted on purpose
Sigh. Do you have a link to the repository? --- I couldn't style a login page if my life depended on it :-). I'd rather leave this to web people, but a `line-height: 2rem` looks best to my eyes.
I added ``` if [ $TRAVIS_OS_NAME = windows ]; then choco install windows-sdk-10.0 fi ``` to my setup script and it solved this issue
https://www.reddit.com/r/rust/comments/9ndo5k/travis_ci_now_supports_testing_windows_includes/e7nl1lj/
Thanks. Do I just stick that in my `script` section? Sorry, I've never used Travis.
While minimizing the test case I realized that even an empty project created by cargo is susceptible to it. Though it seems to take more tries to make it happen (usually at least once every 10 runs). demo: https://www.dropbox.com/s/8x6gg6u8gehppey/cargo_bug_empty_project.mov?dl=0 project: https://www.dropbox.com/s/dppsibrcw7odq2y/bug_intrinsics.zip?dl=0 
Thanks for the link, but I *really* meant compiler plugins like `macro_rules!`
Yep, as long as it happens before the build
Could you provide an example of your vimrc config file? If you are using the built-in completion system: :h ins-completion may be able to help. What plugin are you using as a client to the RLS?
I put a sync arbiter in front of Diesel. Thanks for the advice! [https://github.com/DSpeckhals/bible.rs/commit/290ca3a869bf7e5dac18098ed838c4fa6dfe36f5](https://github.com/DSpeckhals/bible.rs/commit/290ca3a869bf7e5dac18098ed838c4fa6dfe36f5)
That sounds very right to me.
Great! Might be interesting to benchmark before/after, see how it effects RPS and latency.
And we annotate the pointer field of `Vec` as non-null, so `Option&lt;Vec&lt;T&gt;&gt;` takes the same size in memory as `Vec&lt;T&gt;` (three times the size of `usize`, with the length and capacity fields), with a null representing `None`.
&gt;I disagree with this statement. Stateful APIs are rarely good, even if you know what you're rendering; they're hard to optimize in the backend, they're hard to compose between layers of code, and they're hard to use correctly without introducing state bugs. I think that whether statefullness is good or bad in a lot of cases really depends on whether the states actually reflect the reality of what is happening under the hood, at least when it comes to performance. &gt; (Then you realize that cairo is a stateful context API wrapped around a stateless backend API so you've got the worst of both worlds.) This. This layer sits between your software and the hardware, and instead of being the simplest way to solve problems in the context of a certain type of hardware, the layer grows into a complex system that (tries to) hide the underlying platform. But you can't escape the reality of what makes GPUs fast/slow. So you end up having to understand the whole stack including the complexity that that layer had to go through to hide things from you. And you see yourself carefully *working around* the library instead of really *using* it by figuring out the exact way to massage the API so that the gl commands you want get produced internally. My point is, to me this isn't fundamentally a problem of statelessnes and statefulness but rather a misplaced abstraction. I prefer thinking about by asking these questions: - What is the problem you are trying to solve? - On top of what do you build your solution? - and then what is the simplest way to fix this problem in this context. And as part of this process statefullness may or may not emerge in places and it will do for specific reasons. To me a stateless API that hides an underlying stateful platform is often just as bad as a stateful API on top of a stateless platform.
That was a Clippy suggestion. My original code was: for i3 in i2..(i2 + scale) { sum += item[i3] But neither that nor the for item in image[i2..i2+scale].iter() { Changes anything :( 
&gt; Also, in Godbolt, the generated Rust asm is very very long (~4700 lines) while the C implementation is very very short (~300 lines). (Swift: ~1500 lines) I think the reason for this is that Compiler Explorer doesn't add optimization flags by default. By manually adding `-O` to the compiler options, the resulting asm is 488 lines.
I was able to cut run time in half with this, but still not as fast as the C version: ```rust fn resize_image(image: &amp;[i64], width: usize, scale: usize) -&gt; Vec&lt;i64&gt; { let mut result = vec![unsafe { ::std::mem::uninitialized() }; image.len() / scale]; let mut pos = 0; for i in (0..image.len()).step_by(width) { for i2 in (i..(i + (width))).step_by(scale) { let mut sum = 0; for i3 in i2..i2 + scale { sum += unsafe { image.get_unchecked(i3) }; } unsafe { *result.get_unchecked_mut(pos) = sum / (scale as i64); } pos += 1; } } result } ``` Results (resize_original_rs is yours, resize_rs is with my modification): ``` &gt; time ./resize_original_rs 6400000, 1600000, 3200000 ./resize_original_rs 0.21s user 0.08s system 75% cpu 0.385 total &gt; time ./resize_rs 6400000, 1600000, 3200000 ./resize_rs 0.09s user 0.08s system 98% cpu 0.174 total &gt; time ./resize_c 6400000 1600000 3200000 ./resize_c 0.03s user 0.00s system 84% cpu 0.040 total ```
&gt; The size of this primitive is how many bytes it takes to reference any location in memory. For example, on a 32 bit target, this is 4 bytes and on a *64 bit target, this is 8 bytes*.
Wow this is really awesome! I've been using lua more since I started playing with using it inside of Redis for basic scripting, and then Nginx, and now Neovim and my own webserver backends. I had been trying to pick a good scripting language, and after reading antirez's post on scripting language choice for Redis, I was convinced that Lua is a very strong contendor. I also didn't expect the hot reloading logic to be so simple! I thought you would have to do a file watch to auto trigger it or something, but nope. I also never thought of leveraging actors for something like this, but it makes a lot of sense. You're slowly convincing me that there might be a very compelling general application stack I could build using Lua + Nginx + Rust + Redis and somehow re-use logic between them with Lua as the glue (and by extension have hot reloading). The hot reloadability of NGINX + Lua is one of the main compelling reasons to use it. I was about to put a PostgREST api on the localhost so that NGINX could do database calls, and so everything is just Lua, haha.
I already hacked a solution that just involves not spring the Bs directly. :P I already pushed that change to my fork of you want to read it.
I've actually been spending most of my time recently just fixing up this code. It gives me something to do and I don't mind.
both. It's about what item they're trading(flipping) and how to decide which item to flip. And they probably won't share their methodology easily since, well, it's a market.
By the way, your C implementation has bugs. sizeof returns the size in bytes, not in elements. Thus: https://gist.github.com/terhechte/1b7a4b1c4bc1eaa5826014379ad79c4c#file-gistfile1-c-L34 should be int64_t* array = malloc(count * sizeof(image)); and https://gist.github.com/terhechte/1b7a4b1c4bc1eaa5826014379ad79c4c#file-gistfile1-c-L37 should be for (int64_t i=0; i&lt;sizeof(image)/sizeof(int64_t); i+=1) This https://gist.github.com/terhechte/1b7a4b1c4bc1eaa5826014379ad79c4c#file-gistfile1-c-L18 is also suspicious. `pos` is number of elements, and you divide it by the size of one element?
&gt;Stateful APIs are rarely good, even if you know what you're rendering; they're hard to optimize in the backend, they're hard to compose between layers of code, and they're hard to use correctly without introducing state bugs. True. However they can at least \*appear\* more convenient to use than APIs that require you to pass a lot of parameters to every draw call ... at least in languages like C that don't have convenient ways to express default parameters. They can also, in some cases, \*apparently\* help with composability, since you can set state in the context object and pass that to other code instead of having to pass those parameters separately. There are also some potential ABI-compatibility benefits, in that adding new setter/getter functions to a context object can be ABI-compatible but adding new fields to public structs, or new parameters to functions, rarely is. I should have said "\*seem\* good". These benefits are mostly superficial. I'm not a fan of stateful APIs.
I am not sure if I correctly understood your function, but I think you can rewrite it like this: fn resize_image(image: &amp;[usize], scale: usize) -&gt; Vec&lt;usize&gt; { assert_eq!(image.len() % scale, 0); image .chunks(scale) .map(|chunk| chunk.iter().sum()) .collect() } On my PC it runs in ~0.2s. As for comparison with C, make sure that programs indeed do the same.
Since a Vec&lt;_&gt;'s internal representation can't be zero (it contains a non-null pointer), an Option&lt;Vec&lt;_&gt;&gt; will be the same size as a Vec&lt;_&gt;.
I don't think anyone's denying that.
Thank you for your reply, I completely agree. As a mechanical engineer, python works OK for most of the work. Speed is good enough, but I dislike duck typing and I feel larger projects are difficult to reason about. I guess i will use python/c++ for much of the work relying on linear algebra. But I will try to use Rust for specialized stuff, which often means operating on results from finite element analyses etc. Maybe also I will eventually get the chance to contribute to the Rust community :)
I think WebRender makes me the most sense as the basis for a library. If you don't use WebRender, you will end up recreating most of it, which is several man-years of work at this point. The one thing WebRender is missing is Bézier paths, but I plan to get around to that once we ship it. (There is already code in there to render fonts.)
/r/playrust
&gt; I think that whether statefullness is good or bad in a lot of cases really depends on whether the states actually reflect the reality of what is happening under the hood, at least when it comes to performance. Yep. And for a high-performance, GPU-based 2D API, the state as exposed by for example Cairo doesn't make a lot of sense. The state that matters the most is the *GPU program*, which is basically "what type of primitive are you drawing" (though in WebRender the brush abstraction makes it more flexible, this is still a rough approximation). The hardware doesn't care as much about transform, color, etc., because, for instance, primitives with different transforms can be batched together so long as they're all the same type of primitive. There is also the important fact that existing 2D APIs assume you draw strictly using the painter's algorithm—back to front. This is not the most efficient way to use the hardware, which features fancy hierarchical Z-culling. A theoretical high-performance immediate mode 2D API would expose the Z buffer and allow the user to render primitives out of order.
You guys really need a CoC!! ;-)
Hadn't thought of that. Sounds like a very sensible option
I would like for Pathfinder to effectively become part of WebRender and for someone to layer a simple API on top of WR to make it easy-to-use. Pathfinder is too low-level to be the go-to solution by itself. It needs a few more layers on top. WebRender goes a long way toward fulfilling that goal, but WebRender is itself a complex, powerful API because browsers need that. So I think we need an "easy mode" API on top of WR.
Very good point. I didn't call out hierarchical Z-culling specifically, but it's an excellent example of where the cairo-style stateful, painters- algorithm API design falls short. I think it's quite plausible that WebRender will end up being the best choice for back-end in a lion's share of the cases.
I'm inclined to believe you. Maybe nical or someone else representing the gfx team could clarify exactly what they expect to achieve with the draw2d effort that WebRender doesn't already do (with the understanding that there is a story for Bézier paths).
1. Yes, the same way you render any GL context to PNG. 2. Sort of, but you'll need a software GL implementation like llvmpipe. 3. No. 4. You can render to an FBO. I've looked into NanoVG, and at this point I think I would like to use a variation of its antialiasing technique for SVG in Pathfinder/WebRender. It's not the highest-quality antialiasing in the world, but it has the advantage of working on all GPU hardware imaginable, which is terribly important in the real world :) (For fonts my own antialiasing technique is fine, but SVG is a different story.)
Yeah, to be clear I'm not opposed to having other backends. For one thing, I'd never say no to a free side-by-side reference testing infrastructure for WebRender and Pathfinder :)
I think I'd almost always want the 2D API to handle reordering and batching for me rather than encouraging me to do it. Otherwise, if my scene is statically unknown, I'm going to have implement lots of WebRender-ish dynamic optimizations myself. And are you REALLY confident that the reordering and batching decisions made by users of your API would remain valid in the long term as hardware evolves? Not to mention working efficiently on non-GPU targets.
The C version gets a lot slower if you print out any of the results' contents: printf("%li %li %li\n", result1[0], result2[0], result3[0]); I think it's managing to optimize out everything most of the actual calculations, otherwise.
Well, I was thinking of a theoretical 2D API patterned after Metal or Vulkan: a relatively low-level interface to the hardware. If you want a high-level 2D API, I agree that it would be better to have a semi-retained-mode API capable of reordering and building batches itself, like WebRender does.
There's this comment in the linked thread https://github.com/rust-lang/rust/issues/54462#issuecomment-423739753 &gt; The code works with -Zmutable-noalias=no. So does 2018-05-15 (which is before the noalias PR landed), but 2018-06-01 starts failing (without the noalias flag). In between these dates releases had misc. bugs related to typesystem preventing nalgebra from building. There was a noalias PR between those dates, [searching for it](https://github.com/rust-lang/rust/pulls?utf8=%E2%9C%93&amp;q=is%3Apr+is%3Aclosed+noalias+merged%3A2018-05-15..2018-06-01+) leads to [this PR](https://github.com/rust-lang/rust/pull/50744) that enabled noalias. Which was merged in May 19 so maybe all nightlies since 2018-05-20 contains this bug (until being fixed [here](https://github.com/rust-lang/rust/pull/54640), so until 2018-09-29).
Is there any reason to use `&amp;String` instead of `&amp;str` as a function argument? 
Thank you for this analysis. &amp;#x200B; I've pushed a commit that should fix the silly \`Result&lt;x,String&gt;\` heap allocations you noticed: [https://github.com/capnproto/capnproto-rust/commit/30c31c2ce728de2bdaf353c5f4e7bf1eceb371dc](https://github.com/capnproto/capnproto-rust/commit/30c31c2ce728de2bdaf353c5f4e7bf1eceb371dc) &amp;#x200B; Another source of slowness on the capnp side is that it checks that all of the strings are valid utf-8. In my measurements, that checking accounts more approximately 25% of the running time. If this kind of usage pattern is a concern, we could consider updating capnp's API to allow such checking to be avoided.
&gt; If you plan on manipulating the string within the function That would be `&amp;mut String` then.
The builder pattern isn't too bad. It's a lot better than what you have to do in C. Rust also gives you some interesting approaches with struct extension, e.g. [https://play.rust-lang.org/?gist=2c1931b0887601f18a7fa797c6d71bb4&amp;version=stable&amp;mode=debug&amp;edition=2015](https://play.rust-lang.org/?gist=2c1931b0887601f18a7fa797c6d71bb4&amp;version=stable&amp;mode=debug&amp;edition=2015). Certainly would be nice if that was a bit cleaner.
I don't know what the use-cases would be for such a low-level 2D API when you could just use Vulkan.
If you store your entities using TOML instead of YML, then you can use [toml-rs](https://github.com/alexcrichton/toml-rs) to decode them. This could save you some time.
Ok, something odd I just noticed was if I have the macro outside of the main function, I get the error, but if I define it inside the main function, it works just fine! The only problem then is I can't access it from outside the main function, which I would like to be able to do. I'll add some more details to my initial post.
&gt;fn resize\_image(image: &amp;'a \[usize\], scale: usize) -&gt; impl Iterator&lt;Item = usize&gt; + 'a { image .chunks(scale) .map(|chunk| chunk.iter().sum()) } Try this instead.
I didn't realize that WebRender could be used for rendering outside of the web (although this seems completely obvious now that I think about it)
Could somebody tell me whether the first option (in the context of the surrounding loops) does what I think it does, and leads to an extra factor of image.len() in the asymptotic running time of the whole function?
I suspect that Vec&lt;usize&gt;'s iterator is smart enough to handle .skip and .take efficiently (versus just powering through .next calls)
[This code](https://play.rust-lang.org/?gist=040ff4ed853d329edd5ddab378bb631b&amp;version=stable&amp;mode=debug&amp;edition=2015) has the macro outside of main and it works fine. Can you provide a minimal non-working version?
Update: I finished up the initial library commit and got it published as a [new crate](https://crates.io/crates/blockly-parser). Thank you to everybody who reviewed the PR! The code reviews taught me a lot about Rust's ownership model, type system, and conventions.
There is really no need for a macro. You could just as well define a regular function and mark it as `#[inline(always)]` which is typesafe. Also, keep in mind that char in C and char in Rust are not the same thing.
`line-height: 1.75em;` Something along the lines of this please. With the current line height spacing, the inline code blocks are cutting into the words on other lines above and below it! 
 .and_then(Result::ok) .unwrap_or_else(|| "--".to_string())
Thanks for the feedback! I'm not particularly good at C. I just wanted to have a simple comparison.
You're right, I was stupid. Thanks!
Run into conflicting implementations with a bit of generics, but I can't wrap my head around what is the source of the conflict here. The code is simply: use std::borrow::Borrow; trait SomeTrait { } impl&lt;T: Borrow&lt;dyn SomeTrait&gt;&gt; SomeTrait for T { } impl&lt;T: SomeTrait, F: Fn() -&gt; T&gt; SomeTrait for F { } Any ideas as to what's going on here?
Side note: this code suggests that you’re thinking of the `char` type of an 8-bit byte, like in C. Rust’s `char` is a 32-bit Unicode scalar value. If you’re manipulating bytes, it might be better to stay with the `u8` type (`buffer.read()` takes `&amp;mut [u8]`) rather than convert to `char` and back. There is syntax like `b'q'` for byte literals of type `u8`.
How do webrender and gfx-hal relate to each other? Does webrender handle platform gpu abstraction?
A couple of nits: - I think you're ignoring the write errors; doesn't the compiler warn about ignoring the `Result` from `writeln!` and `flush`? - it's usually safer to write the new contents to a different file, then rename it, so the original doesn't get lost in case of a system crash; to be more pedantic, you also need to call `fsync` on the file, then on its parent directory (and maybe even the parent of that, I forgot). Of course, your `resolv.conf` is probably automatically generated, so it doesn't matter. - I personally prefer `structopt` for argument parsing; it's easier to use, but you could say it's overkill in this case - I don't think you need to call `to_string` on errors - your error handling introduces some rightward drift; you could probably avoid that (but it's still better than no error handling, so points for that) - your check for `#` is redundant (as the next check will fail), but you're not handling leading whitespace - you could probably drop the lifetimes on your comparison function, maybe also the `as_str` calls - you're juggling `lines_with_nameserver` a bit much, I'd probably just `clear` the thing and refill it - you could accept `-` as input and read from `stdin` (to e.g. support `cat foo | resolvloser`) Anyway, with the exception of the first one, these are all minor points.
Yeah my bad
Does the compiler have any particularly strong "selling point" that you'd want people to focus on ? Or is it just a "toy" project to test the language ? (Would be one hell of a toy project :P)
Thanks! I agree that using a temporary intermediate file, and accepting stdin input are good practices, though less interesting with the current purpose of this tool in mind. &gt; I think you're ignoring the write errors; doesn't the compiler warn about ignoring the Result from writeln! and flush? The compiler is completely fine with it. Note that there is a `let _ =` for the `flush()`. With regards to the `writeln!`, I am actually not sure why it does not complain... &gt; I don't think you need to call to_string on errors You're right! &gt; your error handling introduces some rightward drift; you could probably avoid that (but it's still better than no error handling, so points for that) This I was struggling with indeed. Any suggestions to reduce the drift? &gt; your check for # is redundant (as the next check will fail), but you're not handling leading whitespace True. I'd like to think the early `continue` is a (minor) optimization, not sure whether that is actually true. &gt; you could probably drop the lifetimes on your comparison function, maybe also the as_str calls I have been juggling with this, as I wanted to just call `sort_by(sort_v6_over_v4)` but then the compiler complains because it sees the elements in as `&amp;String` instead of `&amp;str`. But, you are right, I can lose the lifetimes and the `as_ref()`s if I keep `sort_by(|a, b| sort_v6_over_v4(a, b))`. &gt; you're juggling lines_with_nameserver a bit much, I'd probably just clear the thing and refill it You mean clear `/etc/resolv.conf`? I want to preserve the structure of the rest of the file, thus only rewriting lines that contained nameserver definitions originally. Again, thanks a lot! 
&gt; This used to be disabled due to LLVM bugs in the handling of noalias information in conjunction with unwinding. However, according to #31681 all known LLVM bugs have been fixed by LLVM 6.0, so it's probably time to reenable this optimization. It might have been too soon, obviously, but at least it allowed to detect a LLVM bug.
Thanks! People are fans of structopt apparently. I use `clap` for other things mostly, but found it overkill for this tool, but I'll look into structopt. Fair point on the logging lib (I also found that overkill in this case). &gt; Use more iterators :) Could you elaborate on this one please? &gt; Using methods like unwrap_or_else(|e| …) can help reduce the amount of match and indentation you have Great! This was something I was struggling with, going to look into that. Cheers! 
Structopt is a derive macro that uses/generates code using clap internally. &gt; found it overkill for this tool Depends on how you define overkill, I guess: Is it woo much work to set it up, or do think the added dependencies bloat up your tool? I've come to the point where I try to use the highest-comfort-level dependencies for CLIs possible, because the worst that could happen is that I wait a bit longer for the initial compile of the dependencies and my binary gets slightly larger. Both are not things I optimize for. &gt;&gt; Use more iterators :) &gt; &gt; Could you elaborate on this one please? Sure! It was more a general feeling when reading through the code, same as with the right-leaning code caused by the nested `match`es. I noticed [this block](https://github.com/DRiKE/resolvloser/blob/41ed2235dcb8e519045aac364bbfd0707a23c475/src/main.rs#L70-L85) of code, where you creat two vectors, `lines_with_nameserver`, and `nameservers`. To be honest, I have not yet understood what you are exactly doing. Copying the code to the playground and fiddling a bit with it, I come up with this: https://play.rust-lang.org/?gist=2e610212a291d736d384cb924e4e3665&amp;version=stable&amp;mode=debug&amp;edition=2015
There's a very dominant characteristic in Packt publications in that they are very poorly written and edited. Many people have been burned by this. Until Packt changes its business model, their books are not to be recommended to those you care about.
&gt; I was about to put a PostgREST api on the localhost so that NGINX could do database calls, and so everything is just Lua, haha. Pretty sure you can straight connect to Postgres from nginx, why add postgrest? Beware putting too much application stuff in nginx though, at the end of the day it’s evented and the time you spend in in-process “application” code blocks requests processing. 
&gt; Not only does Rust have native support for channels between threads You do realise that "native support" means "built into the language", do you? Because I'm fairly certain Rust doesn't have channels. &gt; The standard library of Rust is just as rich as that of go That's a lie. &gt; Once the async/await is merged into the stable release of Rust, I think we could call Rust a superior language to Go in, quite literally, every single way possible. So let's talk about Rust's amazing fitness for rapid prototyping, shall we? &gt; Further more, it’s almost bullet proof when compared side by side to literally any other programming language. Please go read the Ada programming Wikibook, there are a lot more aspects to safety than borrow checking and Rust looks really-not-great in some of them. &gt; Its simply a better language than any other for most use cases. ... &gt; But inertia is not to be trifled with, the largest roadblock for widespread Rust adoption is convincing developers to switch. Or, you know, mature tooling and mature libraries? Because that seems to be the *real* blocker at the moment. &gt; Once those developers smell the simplicity of Go in terms of networking and concurrency, coupled with the speed, abstraction power and resource management of C++, with a pinch of compile-time safety on top… &gt; SIMPLICITY OF GO That's a gross mischaracterisation of the language. If there is one thing Rust isn't known for, it's simplicity. C++ has way more powerful templates. Rust *does* have abstraction power, but it's not that of C++. This kind of propaganda is exactly what the RESF does. Stop it.
Go is not about power, it's about making a language easy to pick up for anyone without having to think about allocations, lifetimes and such, i.e. removing complexity altogether, there is not even an unsafe escape hatch.
&gt; You do realise that "native support" means "built into the language", do you? Because I'm fairly certain Rust doesn't have channels. To my knowledge the std has channels https://doc.rust-lang.org/rust-by-example/std_misc/channels.html &gt; That's a lie. Arguable. I would say they are almost the same. The big thing missing from the Rust std that is present in that of go is: * http[s/2] module and async i/o functionality, which is what the article revolves around * cryptography related functions, and I can see an argument why those shouldn't actually be part of the std &gt; Or, you know, mature tooling and mature libraries? Because that seems to be the real blocker at the moment. "Mature" doesn't necessarily mean better in terms of tools and libraries. Most C and C++ tooling for developer is very "mature" but quite lacking in spite or maybe even because of that "maturity". Something being old doesn't make it good. &gt; That's a gross mischaracterisation of the language. If there is one thing Rust isn't known for, it's simplicity. C++ has way more powerful templates. Rust does have abstraction power, but it's not that of C++. As far as arguing metaprogramming capabilities in Rust vs C++, I can concede that C++ is better in many ways. But, for 99.99% of developers, those ways aren't very relevant. A lot of the C++ TMP magic would be made irrelevant had C++ had something like Traits or Concepts. As far as Rust being simple, I'd argue it's on part with go in that it has an active online community that's helpful, dependency management tools, plenty of well documented 3rd party OS libraries, helpful compiler messages and good documentation and tutorials around the language. Whether or not Rust as a language design is simpler than go is subjective. I'd argue it is, Go is easy on the surface but buggy code, especially when managing slices, seem to be the norm. Rust is more VERBOSE than go, but, at the end of the day, it's much easier to actually write code, since data structures and all other free memory objects behave in a very intuitive way, as opposed to those in Go. 
&gt;Looking at Go from a birds eye view, it’s quite hard to understand its tremendous success. I disagree with this, it is quite easy to see why it was a success. You problem is that you compare it to C/C++ and other systems languages, which is has utterly failed to capture the interest of for all the reason you mentioned. But its targeted niche - web development - is not overly ruled by C/C++ and systems languages (with the exception of the very very large scale). It is mostly filled by interpreted languages, PHP, Python, Ruby, Javascript etc which is where it gains its popularity from as it is although it lacks some compile time checks and logic and might be slower than other systems level languages offer it has way more and is much faster than any interpreted languages which are completely run-time dependent. Go might have originally targeted C/C++ developers but even the authors admitted that they failed to capture the C/C++ market that they originally target and instead found a lot of interest among those from interpreted languages (at least what I read a few years ago - cannot find the reference now). This is where its success comes from. But I do absolutely agree with the rest of the article about its short comings to other systems languages. &gt;Rust a superior language to Go in, quite literally, every single way possible I don't think this will ever be fully true, Go has its amazingly simple learning curve that Rust is no where near competing with. But is something I am willing to live with for all the other advantages present. This causes a higher barrier to entry that means more people can or are willing to overcome and thus a larger pool of people that will pick up Go in favor of Rust despite the rest of its advantages - though lowering the barrier can and is being worked on and improves all the time. But in most other ways I would have to agree &gt;I don’t think people quite realize the amount of testing, debugging and crashes Rust saves them from up until they push their code into production. I said the same thing about Go when I first started learning it (again, when compared to interpreted languages) - but have since found quite a few run-time problems that are not possible in Rust that keep cropping up in Go (nil I am looking at you - the worst feature in Go). &gt;Once the async/await is merged into the stable release of Rust, I think we could call Rust a superior language to Go in, quite literally, every single way possible. I think there is one more hurdle to concur - the learning curve. This is I think attracts most interpreted language developers to Go and will continue to attract them to it for a while to come. Most don't really care that much about the benefits that Rust provides over Go. But I do think there will start to be an influx of C/C++ developers and a lot of work on database and storage services that can out compete the Gos counterparts. But there are also a lot less of these projects out there then random less performance critical services out there where I think Go will lead in for a lot longer due to the simplicity of its learning curve. As well as other areas that are currently dominated by C/C++ such as embedded works, gaming and possibly even the web assembly world where Go has failed to enter the market for. &amp;#x200B;
so... those are projects you would see suitable for the Go programming language ?
&gt; there is not even an unsafe escape hatch I would argue that, to some degree, all non-sandboxed languages have an unsafe escape hatch in the form of FFI.
&gt; C++ has way more powerful templates. Rust does have abstraction power, but it's not that of C++. I don't know any C++, and I'd be very interested in seeing examples of use-cases it can fulfill beyond Rust's capabilities :)
[Clearly](https://github.com/ethereum/go-ethereum/tree/master/core/vm) [some](https://golang.org/src/crypto/elliptic/elliptic.go) [people](https://github.com/sjwhitworth/golearn) [do](https://github.com/glemzurg/go-mcts).
And IIUC Go can not guarantee data race freedom, so in some aspects Go is unsafe compared to Rust.
Look up variadic templates, non-type template parameters and template template parameters (not a typo). C++'s `std::tuple` is a variadic template.
&gt; Arguable. I would say they are almost the same. I'm a fanatic rustacean and I'd be very wary of describing the strengths of the language to newcomers in this way. Go's approach to stdlib and Rust's are day and night, it's a consciously-made, well-known design choice. I feel a comparison of the form "it's basically the same except for X and Y" is a bit misleading and disingenuous. I don't have any significant Go experience, but just perusing through https://golang.org/pkg/ I can see support for data compression, random numbers, misc. data formats (json, xml, etc.), image processing, etc. Personally, I try to explain that "Rust is a lean-stdlib language, for reasons X and Y".
`println!()` is a variadic macro. Cpp macros are weak and unsafe, but it made up for them with a very powerful template mechanism. Rust has safe and powerful macros, so its generics can be much simpler than Cpp templates. They are different approaches, but equivalent in power. I defy anyone who claims that the Cpp template language is easier to learn than macros. 
This code is written in assumption that width is divisible by scale. Initially I had also `assert_eq`s to check those assumptions, but I've removed them for simplicity.
In OP's program, the result Vec contains elements that are the sum of scale"elements divided by scale. In your version, the Vec the elements are just the sum. I'm not really sure I understand your point.
Stopped reading when author counted wasting storage space and slowing down my computer AKA static compilation as plus of Gi. There's two basic errors 1. Counting static compilation as plus. 2. Not knowing that C/C++ support static compilation.
&gt; &gt; You do realise that "native support" means "built into the language", do you? Because I'm fairly certain Rust doesn't have channels. &gt; To my knowledge the std has channels https://doc.rust-lang.org/rust-by-example/std_misc/channels.html "standard library" != "built into the language". Having something in the _standard library_ means that it - or at least it's API - is implemented in the language itself. Any developer of the language could implement it if they wanted (even if they had to resort to inline assembly), but the language designers decided to bundle it with the language. Having something _built into the language_ means that the compiler itself is specifically programmed to handle that something. You couldn't get that thing from a library - at least not with the same syntax. A good example from Rust is the `try!` macro and the `?` operator. The `try!` macro is part of the standard library. It it didn't exist, you could write it yourself, and it would be used exactly the same. The `?` operator is built into the language - if it didn't exit you couldn't create it yourself and you couldn't get a crate that adds it - closest thing you could have created is the `try!` macro. Personally, I think having channels built into the language is not a virtue but a testimony to Go's weakness. They **have** to be built into the language because Go does not have generics. But be it better or worse - you still need to use the correct terms. &gt; &gt; That's a lie. &gt; Arguable. I would say they are almost the same. The big thing missing from the Rust std that is present in that of go is: &gt; * http[s/2] module and async i/o functionality, which is what the article revolves around &gt; * cryptography related functions, and I can see an argument why those shouldn't actually be part of the std And regex. And logging. And various compression algorithms. And an SQL API. And XML, JSON, and CSV. And command line arguments parsing. And... you get the idea. Rust has made a decision to keep the standard library thin and rely on Cargo to easily get these functionalities from external crates.
Not the OP, but I would personally answer yes to both, frequently. There are many niches where having explicit control over memory allocations and access patterns is critical, and Rust is perfect for those use cases. Resource-constrained embedded systems, low-level networking stacks, FFI bindings, language interpreters, real-time computer graphics, and game development are areas where these things matter a lot, and both benchmarks and real-world performance metrics reflect this accordingly. In regards to the second half of your question, if you want to safely work with data structures that are copy-on-write, make extensive use of references (e.g. writing your own iterators, futures), or utilize split borrows, being able to specify and manipulate explicit lifetimes is a necessity. You can make do without them in other languages, but you potentially sacrifice the speed and static correctness guarantees that Rust can give you. Of course, not all tasks demand the use of explicit lifetimes in Rust, as lifetime elision takes care of the vast majority of cases. But when they do, I am very glad that the option exists. Explicit lifetimes are the special sauce that makes Rust both fast and memory-safe without being constrained by only what the compiler can successfully infer. Ultimately, both Go and Rust chose different tradeoffs when designing and evolving their respective languages. Go is all about simplicity of reading/writing while keeping the language surface itself small. For example, Go infamously doesn't support user-defined generics, despite exposing multiple type-safe generic data structures, e.g. `map`, in the standard library. Contrast this to Rust, which doesn't shy away from complexity and exposes pragmatic escape hatches, like `unsafe` and explicit lifetimes, for when greater control of system resources and run-time behavior is needed. Both languages have different metrics for measuring "power," but if we define power as giving developers greater choice and control over how their applications will behave at run-time, drawing an equivalence between Rust and Go here doesn't make much sense.
Ah, yes. You are right. The snippet is edited.
I never really mentioned prototyping aspects, focusing mostly on ones ability to learn the language. But personally I feel that Rusts type system is a double edged sword when it comes to rapid prototyping - one the one hand, as you said one it compiles it *just works*, which is great for longer lived or more complex prototypes. But on the other hand it takes a bit longer to throw together something each very quickly that *probably works well enough* \- the types of projects that should not enter production but are a simple proof of concept. I think there are use cases for both approaches and rust definitely helps with the former but can slow down the latter.
I'm very sceptical about articles on programming language criticism and comparison which don't feature even a single line of code to support points given. Looks like a pure speculation to me, backed only by a single 3rd-party reference. Funnily enough, referenced article has much better analysis and backing.
&gt; Note that there is a `let _ =` for the `flush()`. I'm must be blind today, sorry :-). &gt; This I was struggling with indeed. Any suggestions to reduce the drift? Maybe some error type and using `?` more often. I'm not going to try to rewrite that. With a crate like `failure` it might be a little easier (as you can add context like a message to any error), but there are arguably good reasons to avoid it. &gt; True. I'd like to think the early `continue` is a (minor) optimization, not sure whether that is actually true. It's not. You have two `starts_with` (only one in that case) and one `is_empty` call instead of a single `starts_with`. Maybe it wasn't clear, I was saying that about the `starts_with('#')` check, not the `starts_with("nameserver")` one. &gt; But, you are right, I can lose the lifetimes and the `as_ref()`s if I keep `sort_by(|a, b| sort_v6_over_v4(a, b))`. Yeah, that was my point. &gt; You mean clear `/etc/resolv.conf`? `lines_with_nameserver`, actually, but yeah, you'd lose the other lines. Sorry I missed that.
No, you can do them in Go but you will have to fight against the language. For example Go-ethereum is forced to use a memory pool to avoid the bigint allocations slowdown. For elliptic curve crypto, the secp256k1 curve is using C/Assembly code by bitcoin and the BN256 curve is using C bindings by CloudFlare.
Thanks for your comment. Your codes is so cool! I will make it a reference.
&gt;Does the compiler have any particularly strong "selling point" that you'd want people to focus on ? Or is it just a "toy" project to test the language ? (Would be one hell of a toy project :P) This is a toy project.
I attribute Golang and its due success to it being a Goldilocks language. It makes tradeoffs where it's good enough for a lot of conveniences and practicality. [1] It's statically typed, easy to read (and learn), compiles to a binary, an order of magnitude faster than popular dynamic languages, 'most-popular-for-its-domain-batteries' included, excellent concurrency features etc. [1] Generalizing pretty heavily, obviously.
I apologise I must have read the prototyping comment somewhere else.
I think c# is getting closer and closer to the sweetspot also. It is easier to use than rust and has more features than go. If performance gets better it will be a great choice for almost all projects. It is also more Common than the other two. Dotnet core is pushing c# performance a lot right now.
You could look at https://www.quantopian.com/ - put this is based on python / pandas. I feeling is that your programs can access historical data in their cloud, but you are not allowed to download the data to your own computer.
`std::array&lt;int, 5&gt; x = { 0, 1, 2, 3, 4 };` would be an example of value templates, which Rust cannot do at the moment.
&gt;Go might have originally targeted C/C++ developers but even the authors admitted that they failed to capture the C/C++ market that they originally target and instead found a lot of interest among those from interpreted languages (at least what I read a few years ago - cannot find the reference now). I think you're referring to this quote from Rob Pike, originating from the panel [Systems Programming in 2014 and Beyond](https://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2014/Panel-Systems-Programming-Languages-in-2014-and-Beyond): &gt;When we first announced Go, we called it a systems programming language, and I slightly regret that because a lot of people assumed it was an operating systems writing language. What we should have called it is a server writing language, which is what we really thought of it as. Now I understand that what we have is a cloud infrastructure language. Another definition of systems programming is the stuff that runs in the cloud. I haven't watched the video myself, but I got the quote from a blog post: [What is Systems Programming, Really?](http://willcrichton.net/notes/systems-programming/).
&gt; I do not undertwjy go vs rust comparisons area thing. Speaking as someone who has been writing both Rust and Go daily for the past several years---and who has for the most part, enjoyed writing Go---I can try to shed some light here. Saying Go is "closer to Java" is definitely not wrong, but it's not always right either. For example, if you wanted to write a command line tool that is expected to execute quickly, you could write it in Go. [People have done it.](https://github.com/boyter/scc) [Another example.](https://github.com/svent/sift) [And another](https://github.com/monochromegane/the_platinum_searcher). [And another](https://github.com/junegunn/fzf). There are probably many more. Could you do the same for Java? Frankly, I don't have much experience with Java, but I can observe the distinct lack of command line tools that execute quickly written in Java. It may be the case that while such tools could be written, they don't become competitive until their inputs grow to a certain size. That is, what does the startup time look like for an average command line tool written in Java? I mean, just googling "java startup time" superficially confirms that. The [top hit](https://purelyfunctional.tv/article/the-legend-of-long-jvm-startup-times/) seems to confirm my fear. The absolute baseline is 100ms, and that's already too slow. Once the code starts growing, startup times appear to grow by an order of magnitude, even when AOT compiled. That's wildly unacceptable in the command line tooling space. So if all this crap about startup times is true and not easily solved, then it's IMO a pretty clear case where one _could_ use Go but not Java. And beside that point, I think at the end of the day, the performance requirements of a lot of folks are simply not that stringent. As soon as you relax that, a lot of choices will open up to you. It lets you use Go (or something else) to solve your problem, but simultaneously doesn't exclude Rust. Some folks might argue that Rust should only be used when necessary because it takes longer to write code with. I don't think those opinions are outright wrong, but I definitely disagree with them to an extent, but it's hard to know how well my experience generalizes. Certainly, I've written several tools in Rust that don't strictly need to be written in Rust simply because I actually preferred writing it in Rust over every other choice (which in some cases included the universe of all practical programming languages). (Of course, this is to say nothing at all about this specific comparison.)
I understand my problem better now. I edited the OP with more code that I didn't realize was relevant before. I should have posted all of it from the get-go, I thought I was saving people time, but ironically I just wasted more. My mistake.
No, it was not that one I was thinking about, though that is also a good read. https://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html [Ah, here it is](https://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html): &gt; I was asked a few weeks ago \[June 25, 2012\], "What was the biggest surprise you encountered rolling out Go?" I knew the answer instantly: Although we expected C++ programmers to see Go as an alternative, instead most Go programmers come from languages like Python and Ruby. Very few come from C++.
Go and rust are both good languages for clis because they are statically compiled and easy to distribute. That in turn has created libraries to build command line apps. I agree that much. But if we look at the total space goand rust have very lityle overlap at the moment. Go is used for a lot of concurrent and distributed server apps, a space rust is still weak at. On the other hand rust’s biggest success is in libraries, extension modules for dynamic languages, computer games, text processing, crypto and low level code. We might get closer to each other but I just don’t see it right now and as far as I can tell the go and rust developer communities have little overlap as well. I see more rust folk doing Python, C, C++ and JavaScript than go. Whereas many go people I know come from Java. 
&gt; Arguable. I would say they are almost the same. No, they really, truly, are not. Like, not even in the same ball park. Here is an incomplete list of things that the Go standard library has that Rust's standard library does not: * tar/zip archive support * byte string support * compression support (bzip2, flate, gzip, lzm, zlib) * some crypto support (which you mentioned), and this comes with common hashing functions like sha256 that are also useful outside of a crypto context. * relational database interface support. This is limited to a common subset of database operations, but it is used in practice and you can get a lot of mileage out of it. * Debug symbol parsing. * Various data format support: asn1, base64, csv, hex, json, xml and even functions for converting between bytes and integers. * Basic command line argument parsing. * A fairly complete suite of libraries for parsing and type-checking Go code. * Checksums. * Templating, including HTML support. * Image handling, including jpg, png and gif. * Suffix arrays. * Logging. * Big number arithmetic. * Mimetype support. Including the ability to parse mail messages. * HTTP support. (Again, you mentioned this. This is a pretty big one.) * RPC support. * SMTP support. * URL parsing. * Regular expressions. * Profiling. * Output alignment via elastic tabstops. * Fairly complete time handling. You could make all sorts of arguments about whether any of those things actually belong in a standard library, but that's beside the point: the standard libraries between the two languages differ markedly. To further drive this home, I actually find it somewhat difficult to find things in Rust's standard library that are not in Go's standard library. It kind of depends on how you look at it: * SIMD/vendor specific intrinsics. (In Go, I believe the standard way to get access to these is to write Assembly.) * Deep copying via `Clone`. (Go has no out-of-the-box way to deep copy something.) * Pluggable comparisons via `PartialEq`, `Eq`, `PartialOrd` and `Ord`. (Go supports comparisons, but they are not extensible and are instead completely defined by the language specification.) * BTrees. (Go has hash maps, but they are built into the language. Go's standard library also has linked lists, but they cannot be monomorphized.) * Iterators. (Go has no built in support for iterators, although there are some conventions.) You could probably add more to this list, but they start to blur the line between "what's in the standard library" and "what's enabled by the language." Iterators kind of straddle this line for example. From that perspective, Go's standard library is nearly a proper superset of Rust's, where the difference between them is non-trivially large. So I think when you say something like "The standard library of Rust is just as rich as that of go," then it is very very thoroughly wrong. _It's not even close._ And moreover, that's _by design_.
I don't know about LLVM's *expectations*, but I would expect the related codepaths are not well exercised (and thus tested) since C/C++ are as you noted very lax about it. So while the feature technically exists Rust is basically debugging it for non-trivial uses.
While this is true (and I touched on briefly) it does not make it hard to understand why Go is a success. It might have been surprising to them but it was never really a mystery as to why Go was successful - [rob pike even has a blog post about it in 2012](https://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html).
I would actually be really interested in some surveys on that matter.
&gt; It might have been too soon OTOH it's hard to say that in advance what with Rust being one of the rare emitters (and significant users) of this. The feature was toggled back in May in nightly, but the issue was only discovered in September.
Maybe I should finally finish my Rust bindings for [libgral](https://github.com/eyelash/libgral). It's a library that abstracts 2d graphics (and audio) on Linux, macOS and Windows. For graphics it uses Cairo and Pango on Linux, Core Graphics and Core Text on macOS and Direct2D and DirectWrite on Windows. A WASM port is planned as well.
Next step: build a prototype of an idiomatic Rust GUI library on top of it :)
With little recent experience, what little I saw of Jai was that JB wasn’t interested in writing a language for people who make mistakes or need strong guarantees about their code. Rust and C++ try to make their facilities incredibly robust and tolerant, so their development cycles are slower since they don’t just use the simplest available solution: they’re also trying for a best available solution.
Also, given that Jai somehow still hasn’t released any compiler or subset thereof, Rust and C++ have the distinct advantage of also not being vaporware.
Simple answer: n-dimensional array. The length of each dimension is a generic argument, and so there are n separate generic arguments.
Running into borrow checker issues with a simple program that I'm writing. I have a `Chain` that has a `vec` of `Block` and a hash. ``` struct Chain { blocks: Vec&lt;Block&gt;, latest_hash: String, } struct Block { parent_hash: String, ... // some other metadata } impl Block { fn calculate_hash(&amp;self) -&gt; String { // .... } } ``` My goal is to iterate through the blocks and set the `parent_hash` of each child block to be the `hash` of the parent. ``` for i in 0..(self.blocks.len() - 2) { let parent = self.blocks.get_mut(i).unwrap(); let mut child = self.blocks.get(i + 1).unwrap(); child.parent_hash = parent.calculate_hash(); } ``` But I'm getting the following error by the compiler: ``` error[E0502]: cannot borrow `self.blocks` as mutable because it is also borrowed as immutable --&gt; src/blockchain.rs:107:30 | 106 | let child = self.blocks.get(i + 1).unwrap(); | ----------- immutable borrow occurs here 107 | let mut parent = self.blocks.get_mut(i).unwrap(); | ^^^^^^^^^^^ mutable borrow occurs here ``` Any idea what's the correct way of fixing this?
For me, the thing that makes me magically more productive in Go, even though I don't particularly like the language, is the compile times. I develop with C++ professionally, and there's a crazy amount of time wasted in the "compile-runTests-updateCode-compile" cycle for large projects if you actually take time to measure it. Go requires more time spent writing boilerplate and unnecessary code, but this can often still be a lot less than the total time one spends in a day waiting for a C++ project to compile. This can be mitigated to some degree by working on separate features simultaneously in separate checkouts of a project, but the context switching here still hurts productivity. Rust in theory could compile a lot faster than C++, due to having a sensible module system, but that's not currently the case. &gt;Once the async/await is merged into the stable release of Rust, I think we could call Rust a superior language to Go in, quite literally, every single way possible. Personally (and I'm not the only one), after using goroutines/Haskell lightweight threads/Clojure core.async I can't imagine ever wanting to go back to writing explicitly async code unless for performance reasons there's no other option. It's so much nicer to write synchronous code and have the runtime/compiler figure out how to schedule it than to manually handle it myself.
It's too early for me, can someone try and explain a way to implement an n-dimensional array without Variadic macros? Or maybe a reason an alternative is better? 
Yep! It'll be my first Rust conference. Excited to meet some new folks and learn more about Rust!
I notice you're manually extracting command line arguments. You could make your code more readable and error free by using [structopt](https://github.com/TeXitoi/structopt) instead.
I did actually know Rust's char was 32-bit, but I did not know about the b'q' syntax and how I could use it for comparing bytes to chars more easily. Is there a way to use fmt syntax to print a byte as a char or would I need to typecast it as a char for that?
I’ll be there!
Very interesting project!
Doesn't monomorphization only happen for generic structs and functions (as opposed to using trait objects)? That's pretty much the same as C++ templates, just that Rust developers might be more likely to write generic code.
Does anyone know how to do conditional compilation for a specific target triple? I’m having issues with excluding x86_64-rumprun-netbsd without excluding netbsd. Thanks!
&gt; The standard library of Rust is just as rich as that of go &gt; &gt; That's a lie. Obviously Rust one is richer. Rust eg. has `max` and `min` for integers. ;)
Wait, how is this different from `let x: [i32; 5] = [0, 1, 2, 3, 4];` in Rust?
Although I guess this would *only* work for arrays in Rust, not anything else.
In a dependently typed language, instead of multiple type parameters one could have a single sequence of integers as the type parameter, which contained the lengths of each dimension. I'm not sure this would be any easier to implement or use, however. Also C++ sort of already allows multiple parameters to be treated a bit like a single parameter via parameter packs. If you want compile-time checking that only tensors of appropriate size are multiplied/added together, there's no alternative to storing the dimensions in some kind of structure at compile time.
To be fair, you can use `compat()` to get something that implements `std::error::Error`. But I agree, there are good reasons to avoid `failure` (just as there are good reasons to use it).
Why do you need n separate arguments for that? Wouldn't an array of lengths suffice?
max and min should be largest and smallest. Those functions don't define the maximum or minimum of anything.
I wonder if you could run the Java program with warmup code so that everything gets JITted, then do a full GC, then dump the heap into an executable that's ready to go.
I’ll also be there!
Interesting. I suspect the gap might widen with higher concurrency, since actix-web's probably running 8 threads to serve those 10 parallel requests anyway. Plus your queries are going to be pretty quick regardless. Note triple-backticks don't work on old.reddit or most mobile clients - prefix each line with 4 spaces instead.
I'll be there!
Ooh. If I bring my TRPL, will you and Carol have a signing booth? ;)
&gt; Then I stopped playing the video game I've had the exact same experience with another game, Factorio. I pretty stopped playing while I'm making an ideal factory ratio calculator application in Rust.
Which is really quite a surprising expectation. If C/++ folks were their target demographic, GC is a non-starter. Also, C/++ are not a dominant language in the web server space, and haven't been for quite some time.
Cool! I guess this is what we'll (hopefully, one day) get with "const generics"?
That idea is sort of picking up in the JS world: https://v8.dev/blog/custom-startup-snapshots
What are some of the Rust libraries you use?
Bummer. Thanks for clarifying this.
I'm sympathetic to this. I can't count the number of times over the years that I've accidentally used "min" when trying to specify a minimum or "max" when trying to specify a maximum. x = min(x, 0) doesn't clamp the lower bound of x to 0, it clamps the upper bound of x to 0. &amp;#x200B; This is like a common spelling error or typo. Either you make the mistake all the time or you don't. If you don't make the mistake routinely it probably sounds dumb. But as someone who does make this mistake often, I wish the standard name for these functions wasn't ambiguous.
This submission is a hair's breadth from violating our No Zealotry rule. Please strive to keep comments civil so I don't have to regret keeping it around. If you're looking for a good occasion to practice some humility, here it is.
T T
&gt; It is mostly filled by interpreted languages, PHP, Python, Ruby, Javascript etc which is where it gains its popularity from as although it lacks some compile time checks and logic and might be slower than other systems level languages offer it has way more compile time checks and is much faster than any interpreted languages which are completely run-time dependent. I disagree with this. Before Go, there is Java which also has the advantages over interpreted languages.
Hard to tell what the problem is from your description, but one thing to consider could be cache line alignment. Is the memory that you operate on assigned a fixed address ? ( For instance provided by the linker ) - if not the alignment could be random, and an operation that previously only accessed a single cacheline, could not access 2. Also keep in mind that DMA transfers can be sensitive to alignment issues. In particular some ARM chips display erratic behaviour when doing transfers to or from regions of memory that straddle a memory bank boundary.
Within Google there were apparently quite a few services written in C++, which were targets of replacement by Go. There's a talk somewhere from Brad Fitzpatrick about replacing Google's C++ - based download service with one written in Go. 
Indeed, and I think it's generally useful from a pedagogical perspective to note that Rust is far from the only language that has a way to distinguish unsafe operations from safe ones. C#: https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/unsafe Java: http://mishadoff.com/blog/java-magic-part-4-sun-dot-misc-dot-unsafe/ Rust makes a bigger deal out of it since it's intended for use closer to the hardware than most languages, but the principle is well-precedented.
There is a facility to compile your programs with a race detector. Not language-level, but there are ways to detect data races.
Java also has AOT compilation to native code, no need for that, it just gets ignored because up until Graal, it is only available on third party commercial JDKs. As for your native code cache idea, IBM supports it on their JVMs since ages, and Oracle did it on their old J/Rockit JVM as well.
Yep it would, but I don't imagine it would be much easier for compiler developers to support array template parameters and iterating through them at compile time than it would for them to support variadic templates. 
Because "std::array" is not a language builtin, and this notation can be used with custom user-defined types.
Sub-ranges, design by contract, integrity computing certified compilers, faster compilers.
Honestly I like that the top voted comment is a hard pass.
I’ll also be there!
I was wondering this as well. 
Can you give me a real world open source example so that I can investigate it myself? Otherwise, I'm not inclined to care what is "theoretically" possible because it isn't relevant to my point.
So basic design details of what I did to get to the latter portion of code. Module structure: * variant.rs * mod private * VariantAccess trait The VariantAccess trait consists of this interface: pub trait VariantAccess { // contains the vt value const VARTYPE: u32; // the type of the VARIANT union member being accessed type Field; // two hidden methods for accessing the variant union member } Example implementation: impl VariantAccess for u8 { const VARTYPE: u32 = VT_UI1; type Field = u8; fn from_var(_n1: &amp;VARIANT_n1, n3: &amp;VARIANT_n3) -&gt; Self::Field { unsafe {*n3.cVal()} } fn into_var(inner: Self::Field, _n1: &amp;mut VARIANT_n1, n3: &amp;mut VARIANT_n3) { unsafe { let n_ptr = n3.cVal_mut(); *n_ptr = inner } } } Then I have implemented the trait VariantExt as: impl&lt;A, B, C&gt; VariantExt&lt;B&gt; for A where A: self::private::VariantAccess&lt;Field=C&gt; + Conversion&lt;B, Error&gt;, B: Conversion&lt;A, Error&gt; + Conversion&lt;C, Error&gt;, C: Conversion&lt;B, Error&gt;, { fn from_variant(pvar: Ptr&lt;VARIANT&gt;) -&gt; Result&lt;Self, FromVariantError&gt; { ... } fn into_variant(value: A) -&gt; Result&lt;Ptr&lt;VARIANT&gt;, IntoVariantError&gt; { ... } } (Think of Conversion like a TryFrom trait.) This enabled me to do a single implementation, and the type system uses the correct VariantAccess implementation. The Conversion trait bounds lets the actual code do conversions between A &lt;==&gt; B &lt;==&gt; C where A is the base Rust type, B is an intermediary type (if applicable) and C is the type of the union field being accessed. The code is shorter, simpler, more generic, but requires more type information up front. 
&gt;there is Java which also has the advantages over interpreted languages. True, but it has a lot of downsides of its own and it failed to capture the same audience that interpreted languages did (or there would have never been a rise of interpreted languages) - it seems to have filled a slightly different more high-end enterprise niche than what a lot of interpreted languages filled. Go seems to have filled the needs of these developers, or gotten the right trade off of features and become more attractive to those that used to go for interpreted languages thus it has eaten mostly into the market share of interpreted languages over that of others.
Yeah, I think it was just the mindset of where the creators of it came from - high end enterprise environments primarily using C/C++. It is quite easy to overestimate the number of people in the same domain as you are and underestimate the size of the domain of others. My guess is they just assumed there were more C/C++ devs in the server world then there actually were and most of the existing C/C++ devs where in domains that Go failed to fill and never really targeted. In other words they met their target audience (people that develop web services) but were surprised to see that market was mostly filled by interpreted languages.
Java is a latecomer in the web development area, after PHP became very popular. Nowadays, the two are still the most used web dev languages. The rise of other script languages in the web dev area is mainly for all kinds of drawbacks in PHP. They rose to replace PHP, instead of Java. Before Go, if the code execution efficiency is a major consideration for a project, Java was almost the only choice. However, after Go was born, many people will choose Go instead. Although Go is flexible, but it is still not flexible as interpreted languages. If flexibility is a major consideration for a project, interpreted languages still have bigger chances to be chosen than Go. So in my opinion, Go eats more market share of Java than interpreted languages. 
Looking forward to it!
AFAIK I am the only one in the gfx team having taken part of the draw2d discussion so far. What I would like to do is something sort of games oriented with a much reduced scope compared to WebRender (no complicated clipping rule, text decoration or whatever else that is very css specific) and maybe focus on the things WebRender don't do yet like path rendering. Obviously I'm not very motivated by the idea of using my spare time to reproduce the thing I do at work, but while WebRender is great at rendering web pages and UIs, I think that there are plenty of other niches that could benefit from a different design with different goals.
&gt;race freedom Damn those racists
It does indeed seem that the article is viewed in a way more "negative/fanatic/us-vs-them" light than I had anticipated. It seem to be partially interpreted as a Go vs Rust article, when what I was trying to say is essentially: "Once Rust implements async i/o, people will switch to Rust for some of the same reasons they switched to Go". The whole language quality comparison was meant more to shine a light on why a few features in Go are very relevant to it's popularity. Alas, meaning in the mind of the reader and I can see the perspective from which most comments are coming at this. But, it's a bit to late now to change the article in order to better say what I wanted to showcase. ... I will try to penance for this apparent zealotry by complaining more about how the thread safety model doesn't allow for optimized lock-free code or resource sharing between entities sharing the same thread, or maybe contributing to some embedded C project. But, on a serious note, it's your subreddit, so if you wish to remove the article, I won't try contesting it with another mod or complain about it. I think that, overall, it has caused a very negative sentiment and that wasn't my intention, I can see why you dislike it and I can see why you would like it to not be here.
Ada has limited (as in only with literals) dependent typing. For example, quoting the wikibook on the definition of `String`: `type String is array (Positive range &lt;&gt;) of Character;`. Now you can instantiate this like `String (2 .. 5)` which means the array's valid indices are 2, 3, 4, 5. You can also write functions that return `String`, without supplying the range, and it gets inferred. (My Ada is a bit rusty, so if anyone can give a better example, please do!) Also, the (weird at first look) array indexing above in combination with Ada's VERY good number type story (and also contracts) eliminates a lot of nasty logic errors. Rust cannot do those things, but at least there are RFCs going on for both.
What board are you running on ? I have a https://www.lauterbach.com/frames.html?microtrace.html that I can do some basic profiling with (if I have the board at hand)
It is so important and why Flutter is similar.
Nothing much on the C side. C++ is probably the implicit comparison here- where "what changed" is "it got vastly more complex."
I think so! It’s the only conf we’ll both be at.
&gt; I think there is one more hurdle to concur - the learning curve. I think there's a second hurdle, distinct from the learning curve: ownership. I personally relish having fine-grained control over ownership, and feel empowered by the move and borrowing semantics of Rust. However, it does require some ceremony; I can perfectly see picking Go for its GC instead of tweaking the design to fit in Rust's mold. Yes, the final Rust design may very well be superior, but Go could get the service running without delay. 
&gt; but maybe the structure members are being re-ordered You can use `#[repr(C)]` to manually control the memory layout.
&gt; The lua code doesn't block from inside Nginx. It's not what the [lua-nginx-module](https://github.com/openresty/lua-nginx-module) readme states. What it states is that the code *can be* non-blocking *on network traffic*. As far as I know (though I could be wrong and am open to more information) non-io logic is synchronous and runs within the nginx process, and is thus blocking. It's the same issue you have with any event-driven backend, the issue here is that the same nginx is likely serving your static assets and the like, whereas in more traditional setups (e.g. a node server sitting behind nginx or whatever) CPU-bound tasks in the backend is not blocking nginx itself. &gt; And if you have a better example of using it with postgres, then by all means show me. ngx_postgres is literally the first hit when you search "nginx postgres"
Commercial compilers examples, https://www.excelsiorjet.com/ https://www.ptc.com/en/products/developer-tools/perc https://www.aicas.com/cms/en/JamaicaVM Open source ones, https://www.graalvm.org/docs/reference-manual/aot-compilation/ http://www.eclipse.org/openj9/oj9_performance.html 
&gt; there are a lot more aspects to safety than borrow checking and Rust looks really-not-great in some of them. Nothing on that sentence mentions it is only about grammar/semantic issues.
Looks like blogger wanted to attract traffic to his post. What is the point? Go and Rust take different approaches. I use Go at work and it is already very fast for our realtime use with predictable latency, because I have years of experience making C/C++ fast. Since Go is a language which allows pointers and immutability, makes life easier to tune things or people who understand what to change where. &amp;#x200B; Rust OTOH is something I enjoy because I am a systems programmer just I am afraid I do not have time teach other at work with nuisances of Rust. Hopefully this will change when I get more experience with Rust and people stop parroting Java expertise as requirement. 
Yeah exactly, I'm not doing CPU bound tasks. The reason that I would choose to use PostgREST or put my own server in there is so that it doesn't have to block because it would be using a subrequest. That's why I asked if you had used it because it seems like you are talking out of your ass.
Prototyping in Rust is actually really slow because even if you write a non-pub function you need to encode all of the type information in the signature. You might write `-&gt; String` but what you ACTUALLY want is `-&gt; T where T: From&lt;&amp;'a str&gt; + From&lt;String&gt;` where `T` is a generic parameter to your function of type `Monoid` because reasons that's probably 3 or 4 revisions of the types in your signature until you get it right whereas in Haskell it would just infer the correct type while you're prototyping and you can go back and annotate it later when you're sure you want that type
Are there any other reasons that I might want to avoid `failure` in this situation?
Fair enough. I also think the games space is the sweet spot; I'm absolutely not suggesting a library that you'd use for a web browser or PDF renderer, each of which brings a complex set of requirements.
I didn’t attend Google I/O but this all fits my understanding as well. There’s a lot of valid criticisms of Go but I think it really serves the purpose for which it was designed. It’s very much language design from an engineering perspective to solve a specific set of problems and it does that very well. 
In practice, combined with good design, I’ve found it to be sufficiently good at preventing data races. Language or type system level guarantees would be better of course. 
What about instruction cache ? The datasheet says that the ISB instruction is required when having self-modifying code. Also ARM documents say that a small instruction cache can be present on Cortex-M. Perhaps your long sequence of NOP instructions are busting the cache timing? Flushing the instruction cache (ISB) at the start would could make your timing more consistent.
Yep!
I will have to disagree here. Go is nowhere near replacing Java. Java ecosystem ecosystem is miles ahead. Lot of people complain about Java's verbosity but in comparison to Go, Java is much better. Java is much more productive than Go. Honestly from my experience Java's memory usage is not a problem in most enterprises and if you write exact same code in golang and Java then the performance will be close.
I am working on adding a new feature to [*RnR*](https://github.com/ChuckDaniels87/rnr) (*a cli tool to batch rename files using regex*) to dump operations into a file. Also, I wanted to read those dump files to repeat/undo operations. I needed to reorganize and refactor part of the code, but I really enjoyed it. I am still working on it, but it is almost ready for the next release. Any suggestion to improve the code or contributions are welcomed. :)
I didn't say it was? I'm not sure who you're replying to.
Couldn’t agree more. Main thing that stresses me out about go is the terrible package/dependency/project management. GO_HOME is just annoying. I know there is go mod now but it just doesn’t feel right. Using github as your package registry is also just not gonna cut it when I’m used to crates.io and hex.pm from elixir. Not only is a languages ease of use important but also it’s development flow, and by that I mean the meta, everything around it that doesn’t involve the code itself. I’ve always felt that go lives in a weird limbo between almost very low-level and easy to use high-levelish. To think an entire community thought a vendor folder was a good idea, I just don’t get it. yea the thing is useful but insanely over hyped and I think because most devs are on cruise by at the bare minimum mode. Don’t get me wrong, I understand, value to the business comes first and if go can do that, no matter how quick and dirty, they will use it. For me everything about go other than it’s first-class networking support feels completely archaic at best.
This is so correct. The only benefit of switching from Java to go is static executable but then you would be writing much verbose and less type safe code. Most Java people I know don't consider Go is an alternative.
&gt; Yeah exactly, I'm not doing CPU bound tasks. Which is why my original comment was a warning merely calling attention to a possible issue, not an assertion that Lua should not be used… &gt; The reason that I would choose to use PostgREST or put my own server in there is so that it doesn't have to block because it would be using a subrequest. ngx_postgres is specifically noted as compatible with non-blocking lua. &gt; That's why I asked if you had used it because it seems like you are talking out of your ass. And that's a report.
I took the liberty of setting up a repo [here](http://gitlab.com/BartMassey/resize-bench). I corrected the C code, cleaned up the C and Rust and made them as corresponding as I could. The code checksums the images at the end to ensure that they are used, and to ensure that all versions are producing the same answer. There are various branches corresponding to speedup experiments suggested here: none of them help. The C code compiled with Clang is about the same speed as the Swift. The Rust is about 2x slower. Interestingly, compiling the C code with GCC makes it run about the same speed as the Rust code. So LLVM appears to be doing something "special" here for the Swift and Clang code.
Yeah... I don't agree with that at all and my intent of my comments above wasn't to support the notion that Go isn't an alternative to Java. It definitely is. But it's just so not worth getting into the details. Some of it will be subjective and some of it will require a very in depth description of requirements.
If your failure case is "small", you should probably return `Result&lt;_, YourFail&gt;` instead of `Result&lt;_, failure::Error&gt;`. This avoids the downcast, as you know your exact failure modes, and can be easily boxed up by the user if desired. `failure::Error` is mostly intended as a failure where the best course of action is to print out the error, abort, and maybe try again. For library failure modes, returning your own concrete `Fail` implementation is ideal, as users can easily consume the error. A "small" error is one that doesn't greatly increase the size of your result.
It is very simple. Go syntax is clean. Go compilation and dependencies thingy is easy. It is harder to shoot yourself in the foot compared to C++. It is good performance and statically checked and typed, with testing infrastructure built in. This is all a huge benefit for collaborative open source projects, where people with varying expirience contribute code.
As far as rust is concerned raw pointers are just numbers and the memory model doesn't come into play until you dereference it into a rust pointer, unless I've got it wrong
The [Rust API Guidelines](https://rust-lang-nursery.github.io/api-guidelines/) are worth checking out.
&gt;I’ll be there! &amp;#x200B; Michael? Is that you? Eee-EEE-Hooo!
Yeah I think that's mostly true, AIUI. The one exception here is that there are certain pointer values themselves that are invalid. e.g., https://doc.rust-lang.org/std/primitive.pointer.html#safety-4 documents why adding an integer to a raw pointer is actually unsafe. You can use [`wrapping_add`](https://doc.rust-lang.org/std/primitive.pointer.html#method.wrapping_add) to get a safe but possibly slower alternative.
I'll be there. This will be my first ever Rust conference.
Been using that, but I don't think it has any guidance on my specific situation, that I've seen yet. 
Personally, I've never had good experiences with nom or similar parser combinators. I'd probably just write the parser by hand. 
Which brings me to my point:you can do mostly anything you can do in Go, in rust, W/O manual memory management. The cases where you do have to manage memory manually, are irrelevant to the comparison, since go is usually unsuitable for the type of problems where they crop up.
The println macro automatically adds a &amp; for you. If you passed in your own &amp;, you wind up with two, but auto-dereferencing takes care of that. The assert_eq macro behaves similarly.
Look at what I wrote, and re-reading various documents, I think my next step will be to redo this work, but do two things: Make the simple stuff (basic Rust data types) super easy to do, and then more complex stuff can be more complex. 
I am sceptical about any article on the success and failure of programming languages that doesn't take into account corporate backing.
I gave you the links to the AOT compilers, compiling an dummy Java CLI example program with such tools is relatively easy for anyone that isn't religiously against Java. 
I did a github search for it and every use on the first page of results was for tests.
There may or may not be a performance difference, but it depends on a lot of factors - how big the thing you're passing is (a reference is 8 bytes on a 64 bit machine, so if the struct is smaller than that you're technically copying more data if you pass by reference.) There's also costs for using references; indirection in the callee takes up instructions. Potentially. This can all be invalidated by inlining and optimization, and in a lot of cases the two ways of passing will end up identical, except for the important part of choosing between the two: semantics in the borrow checker. For the 1% of cases where you really need to worry about efficiency, profiling and checking the actual assembly output in Godbolt will help you; in the other 99% of the time, just follow the idioms (for non-Copy values, pass by reference almost always unless you want to destroy/take over the value; for Copy... I'm actually not sure if there's a consensus on standard methods for Copy, but just pass by reference most of the time anyway.) For your other question; `&amp;` will almost always give you a reference, except in the case of `&amp;str` and `&amp;[T]`, which give you structs that contain a reference and a length. The reference you get, however, might not be to the exact struct itself, but some internal data - see that `let x: &amp;str = &amp;String::from("foo")` works even though we'd expect `&amp;(String)` to give us a `&amp;String`.
It's possible that this will work when "non-lexical lifetimes" lands. In the meantime, you need to either 1) avoid assigning `parent` to a local variable, so that it doesn't stay borrowed past the line where you compute its hash, or 2) work with `parent` inside a curly braces block, to force the borrow to end at the end of that block.
I would recommend not to use `ws!()` since it does have unexpected side effects. I used `.trim()` on the `&amp;str` instead. #[macro_use] extern crate nom; #[derive(Debug)] pub struct Entry&lt;'a&gt; { group: &amp;'a str, name: &amp;'a str, path: Option&lt;&amp;'a str&gt;, } named!(parse_group&lt;&amp;str,&amp;str&gt;, delimited!( tag!("["), take_until!("]"), tag!("]") ) ); named!(parse_name&lt;&amp;str,&amp;str&gt;, take_until_and_consume!(":") ); named!(parse_path&lt;&amp;str,&amp;str&gt;, take_until_and_consume!("\n") ); named!(parse_entry&lt;&amp;str,Entry&gt;, do_parse!( group: call!(parse_group) &gt;&gt; name: call!(parse_name) &gt;&gt; path: call!(parse_path) &gt;&gt; ( { let path = match path.trim().len() { 0 =&gt; None, _ =&gt; Some(path.trim()) }; Entry{ group: group.trim(), name: name.trim(), path } } ) ) ); named!(parse_file&lt;&amp;str,Vec&lt;Entry&gt;&gt;, many0!(complete!(parse_entry))); fn main() { let fixture = include_str!("../ex.txt"); let d = parse_file(fixture); println!("{:#?}", d); } &amp;#x200B;
nom parsers sometimes behave differently as expected but when you get them to work or understand the quirks it's quite good actually.
If you don't mind my asking, I'd be curious to know what the appeal is to timed problems like these. (I generally prefer stuff where there's no time limit, because it means I can use each problem as a jumping-off point to research the most idiomatic solution and close runners-up, then commit that information to memory for future projects.)
I have a bit of trouble understanding go's success as a server programming language, though. I admit I'm not intimate with the language, but I don't know what it is that it offers that Java or. Net based languages don't already offer. Is the performance really much better than those two? On the other hand, I also don't understand why many keep comparing it to Rust.
I mean, most people would assume the way to force that would be `#[repr(C)]`. Why else would you mark it as that when it's not exported unless you really wanted it? Sure, ignorance, perhaps, but that's a poor reason to ignore it.
You're looking for /r/playrust.
Pest still took me a little bit to figure out, but I got it. Never wanted to put the time in to figuring out nom. Here's a syntax that works for the format op is using. WHITESPACE = _{ " " } group = { (ASCII_ALPHANUMERIC)+ } name = { (ASCII_ALPHANUMERIC)+ } path = { (ASCII_ALPHANUMERIC)+ } parser = _{"[" ~ group ~ "]" ~ name ~ ":" ~ (path)?} then the main.rs would be: extern crate pest; #[macro_use] extern crate pest_derive; use pest::Parser; #[derive(Parser)] #[grammar = "custom.pest"] pub struct CustomParser; fn main() { let parsed = CustomParser::parse(Rule::parser, "[blah] arg : yip"); println!("{:?}", parsed); }
&gt; … there is Java which also has the advantages over interpreted languages. Java is interpreted; the Java virtual machine interprets bytecode. Out of that list, JavaScript had the least to do with interpretation since V8 (used in node and Chrome) didn't have an interpreter and just compiled to machine code until last year, when they replaced their baseline compiler with a bytecode interpreter by default, and the year before that the interpreter was just used for low-memory devices (they switched to interpretation at all to save memory). The optimizing JIT compiler still emits machine code and instead of an interpreter overhead just has overhead from having to validate speculative optimizations. In contrast, Java's HotSpot uses interpretation.
&gt; Java is much more productive than Go Not by my experience. Go is much more productive than Java. &gt; Java's memory usage is not a problem in most enterprises. It is a big program, especially for container based PaaS projects. 
/r/playrust, I assume.
They [are 1-indexed](https://this-week-in-rust.org/blog/2013/06/07/this-week-in-rust-1/), so that wouldn't be a repeat.
&gt;So let's talk about Rust's amazing fitness for rapid prototyping, shall we? Sure. I've found Rust is a fantastic language for prototyping, if only for (1) its `enum` sum types which are a natural fit for modeling all kinds of problems (2) the ease of adding third-party dependencies. As one example, one time I needed to implement [Bridson's Poisson disk sampling algorithm](https://www.cct.lsu.edu /~fharhad/ganbatte/siggraph2007/CD2/content/sketches/0250.pdf) in C++. I thought I would take a first stab at it prototying in Rust. I got that done, including learning the algorithm and adding an (animated!) visualization with the `glium` crate, in a morning. Reimplementing the prototype in our C++ codebase took me a full day, mostly spent debugging errors in my translation from sum types to structs (this was pre-C++14 (actually pre-C++11), so I could not even use the decidedly lame but still useful `std::variant`).
I've been working on parsing a binary format with Nom, and the debugging is already tricky. Do you know of other parsers that support arbitrary binary (rather than text) data, but are less awkward on the debugging side?
I started by talking about CLI apps with fast startup times and made the observation that I could find no examples of Java programs that fit the mold. On the contrary, there are plenty of examples for Go and Rust that people are actually using. All you did was tell me it was theoretically possible without showing me any actual programs. At no point have I shifted any goalposts. I was initially quite specific because if I was wrong, I would truly learn something interesting. I don't need to be told it's possible. I want to be shown it so that I can update my mental model and revise my comparison between Java and other languages.
All true. However, strictly speaking, Java shouldn't be viewed as an interpreted language.
I really like your idea !
&gt;The traditional capnproto issue is that the builder time was surprisingly large, even if once "built" things are fast. A common reason for slow encoding time is use of \`message::Builder::new\_default()\`, which allocates 8 kilobytes for the first message segment. If the message is much smaller than 8 kilobytes, then this can mean a lot of wasted allocation, and if the message is much larger, it can mean unnecessary fragmentation. If you can estimate the size of your message up front, it's best to do something like \`message::Builder::new(message::HeapAllocator::new().first\_segment\_words(expected\_message\_size))\`. I've submitted a pull request to comex's benchmark repo containing such a usage: [https://github.com/comex/capnabom/pull/2/commits/126008e960d7698c8c89479e52a6b33aeddfe9bf](https://github.com/comex/capnabom/pull/2/commits/126008e960d7698c8c89479e52a6b33aeddfe9bf)
Have you tried handrolling it? It might turn out to be more pleasant than you might have expected!
&gt;However it might be in the future that Rust adds auto-referencing for function calls, in which case this would be consistent. That's how Go does it (if I understood you correctly) and I don't like it. I always have to scroll to the function definition to see what's actually happening. 
I'm glad to hear it's not so bad! I certainly could try, it's not that complex a format, mostly some standard structures and some RLE data. The [implementation I'm referencing](https://github.com/Photonsters/PhotonFileValidator/tree/master/src/photon/file/parts) uses Java DataInputStream to read from and otherwise hand rolls the parsing. I just thought maybe there was a library that would make it a little easier. I think I'll carry on with Nom for now, since it's probably a little less boilerplate, but I'll keep that thought in mind in case it gets a little hairy again. Thanks for your input.
It's both interpreted and JIT compiled; I didn't mean to imply that Java would be only interpreted, just that it relies on interpretation more than JS, which was listed among interpreted languages.
This is very useful crate. Thank you for teaching me! &amp;#x200B;
&gt; Write a `CONTRIBUTION.md` to help onboarding newcomers with your team guidelines, conventions, engineering processes, etc. This looks like a probable typo, given that there's no rationale for deviating from the `CONTRIBUTING.md` that GitHub Issues looks for. 
I agree for enterprise projects with sufficient budget, Java still has a much larger market share than Go. Go is more preferred for startup and personal projects. I ever made a Google AppEngine Java project, its development experience is very painful. The memory of smallest GAE instance is only 128M, which is too small for a general Java web project, and new deployed Java instance needs 20+ seconds to fully start up to handle client requests. For a typical Go project, 64M memory is enough, and the warm-up time is less than one second.
You are right... I misused the term monomorphization. How do you call the fact that there is one compiled version of default implementation of trait function per trait implementation?
https://imgur.com/a/21gUnC4
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/OJeYTCQ.jpg** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e7q5u8z) 
Both Go and Rust will auto-ref for `.` method calls, but I believe neither currently will auto-ref for function arguments. I've been frustrated by that in Go in the past too, mainly because I think "struct method that takes self by value" is a gigantic footgun that tends to silently drop your modifications, and yet taking self by value isn't uncommon in Go. I think Rust gets the better end of this, because methods taking self by value don't work in most non-`Copy` cases, making them pretty rare. I've never seen the same confusion come up in practice in Rust. Also note that Rust requires the `mut` annotation for any variable you're going to call an `&amp;mut self` method on, which sometimes makes the callsite a little clearer.
Wrong Reddit. r/playrust
I'll admit to having been confused by this. I'm *especially* confused by `x.max(y)`, which *really* looks like `x` is getting clamped to at most `y` (when in fact it's getting bumped to at least `y`), and so I strongly prefer to write `cmp::max(x, y)`. That said, I think a two-arg function called `max` that clamped one arg to at most the other arg would be worse, because then the order of the arguments would matter, and I think it would be too easy to forget the right order.
&gt; using Nom, mostly as an exercise in learning Rust May I just say this sounds like a terrible way of learning Rust. Whenever I use Nom I feel like I'm dealing with a whole separate language. You're essentially diving head first into Rust's macro system. Plus you got the whole parser combinator concept to wrap your head around.
That's false information. The reference implementation of the JVM is entirely open source.
Excellent post and great idea!
So first, as others noted, I missed that `Error` has a compat method. The downside still remaining is your users have to have `failure` as a dependency, pull in the extension trait, and do `read(...).compat()?;` The other main note on `failure` is that you are pulling into your public API a non-1.0 crate that other crates might also expose. If a `failure` 0.2 is created, the ecosystem of crates using it is split. They are trying to avoid breaking changes but who knows how long that will last. I think `failure` is helpful for `bin`s and prototyping. Past that, I recommend not using it for now, especially if you are on the path to 1.0.
&gt; And these days there is little point in using it over other languages if you are already in the Linux ecosystem. That doesn't seem to be necessarily true with dotnet core, though. Particularly since it provides a ready to use binary. You also do lose a lot on abstractions with Go compared to Java dotnet. Which is what baffles me the most considering a lot of programmers seem to come from friendly dynamic languages like js, ruby, php, etc. 
Is there a better to use the serialization interfaces, then? In the lean benchmarks, for example, I started from a `&amp;Vec&lt;String&gt;` and at this point you should have all of the information about the number of strings, and even their size (both Abom and Bincode can map out the required space cheaply at this point). Is there a non-builder approach where you just say "`&amp;Vec&lt;String&gt;` go!", and capnproto sorts out the sizes automatically?
If you're having troubles with nom consider giving us a heads up at https://gitter.im/Geal/nom, we're always happy to help :)
Go and Rust have quite a lot of potential overlap. Both have low resource usage, are AOT compiled so don't have noticeable startup time, both are fast, and both are (for the most part) safe languages and fairly fast to develop in. There are a lot of projects that have these requirements. Speed and resource usage are important in a lot of cases in microservice infrastructure, or for networking systems. Safety and development speed are critical business concerns. What other popular languages are there that satisfy these criteria? Go is absolutely not closer to Java. The JVM and Go's runtime are very different beasts, and Go's resource usage is closer to C/C++ than to Java. The runtimes of the MLs would be much closer to Go's than Rust or C++ as well. The actual details about a language are often not very important in language selection. Unless you're _extremely_ constrained in either resource utilization (microcontrollers) or latency (games), "runtime" vs "no runtime" is usually irrelevant, it's "speed" and "memory usage" that count, and "good enough" is good enough. This is why Go is so popular, because so many business problems don't _require_ the super high speed and super low memory utilization that Rust or C/C++ can give you; they just need it to be "fast enough", and Go is that for most web-related/service problems.
I wonder if there is not a technical problem with how rustdoc currently works. If I remember correctly, It was already suggested multiple times already, but since rustdoc is based on rustc, it was difficult to achieve. 
I wonder if there is not a technical problem with how rustdoc currently works. If I remember correctly, It was already suggested multiple times already, but since rustdoc is based on rustc, it was difficult to achieve. 
&gt; Java is a latecomer in the web development area, after PHP became very popular. Nowadays, the two are still the most used web dev languages. Java Servlets existed in Java 1.0 (end of 1996), while PHP started in the middle of 1995, while PHP3.0 (the first edition which really took off) was written in 1997. The thing was that until fairly recently, VPS were _really_ expensive, so almost if you were going to write a website, it would be on shared hosting, which didn't give you access to /etc/init.d, so you couldn't start your own server. As a result, you could only use existing servers which didn't require admin control - and that meant that you're using Apache, PHP, or CGI. So everyone used PHP (CGIs were slow and horribly ugly - you would be write a C program which would parse the `QUERY_STRING` environment tag. And you had to compile them on the server, back then almost no one used Linux, and they were slow to start. For all the hate it's getting now, PHP used to be literally the best language for web development for years). Ruby and Python really became big when VPS started to get popular, and you could run what you wanted. 
This looks very interesting. Might play around with it next weekend!
Upvoted for the handrolling suggestion. I never got parsers (or even lexers properly for that matter) till I started doing the whole thing from scratch. It's very enjoyable to boot!
Thanks for the detailed response. If I'm understanding this correctly, it won't match the final line of a file (no "\\n"). I assume I can change `parse_path` to use `!alt(take_until_and_consume!("\n") | take_until_and_consume!(EOF))`, but I have no idea how to indicate the latter. There's `Eof!` defined in Nom, but it's not meant for this as far as I can tell.
&gt; If it were 100%, we could never require you to write annotations. But with 87%, we can let you not write annotations, and most code that follows most normal coding practices never needs to write explicit lifetimes. While I agree we'll probably never hit 100%, the percentage should be getting higher soon. [PR #54687](https://github.com/rust-lang/rust/pull/54687) demonstrates getting rid of another common case.
I'll take a look at Pest, thank you.
Thanks for this. I'll spend some time digging through the docs just to get a better feel for it.
You could use `eprintln!()` and redirect stderr into a file
Fair point. Also, I just looked up rapid prototyping and it turns out that it involves a 3D printer. What I actually wanted to talk about is [rapid application development](https://de.m.wikipedia.org/wiki/Rapid_Application_Development), and I'm pretty sure that it's one of the things Rust cannot do as well as other languages.
Are there crates for doing localization? Is there a way to get system's language to do at least simple localization?
I've got a question about generics and conflicting implementations. Here's a playground example: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=6b75ec212ee91d5858c926281b96fe8a Why does this produce a conflicting implementation? I have one implementation when T,U are constrained to SomeTrait. Then I have a different implementation for the T,U are constrained to a different trait. I have two questions. One, I'm not totally sure why Rust doesn't allow this. It seems like it would work? Two, what is the idiomatic way to achieve this? I want to have a trait. If the parameters types are Foo then I want the trait implementation to do FooStuff. If the parameters are Bar then I want the implementation to do BarStuff. This seems pretty reasonable?
Would be good to also open an Internals thread about this pre-RFC. I like the idea to structure creation of documentation about features! 
please open issues on https://github.com/geal/nom I'm working on improving the experience, but comments like this one don't help
Naturally you see very few FOSS Java compiled to native code, because developers don't want to pay for their tools like other professionals do. As such only large corporations bothered with AOT compiling Java to native code, until Oracle and IBM decided to make their AOT offerings free as well. I provided you the links to AOT compilers for Java, commercial and open source, with which you are able to pick *any random Java CLI application from github* and compile it into native, thus making your own comparison. Apparently that is too much effort.
I definitely agree that this is something that needs addressing. Features always seemed like a rather hacky way of tacking conditional compilation on to Rust.
for debugging, you can take a look at this tool I released yesterday, it's already helped me a few times :) https://github.com/geal/nom-trace
`*mut T` and `*const T` can be freely cast to each other. Their distinction is only an attempt to help keep track of what pointer are valid to dereference as `&amp;mut *x` v.s. `&amp;*x`, but some have argued that the language would have been better off with only a single `*T` type. That said, when using `Arc::from_raw` you need to be very careful about correctly keeping track of reference counts to avoid use-after-free (or leaks). For example, getting multiple `Arc`s out of the pointer might look like `ManuallyDrop::new(Arc::from_raw(…)).clone()`, because `Arc::from_raw` doesn’t touch the refcount but `Arc::drop` does. Then, if you’re using also `AtomicPtr` it’s presumably because because you have multiple threads accessing that pointer. However even if pointer stores/loads and refcount increment/decrements are both atomic, they’re not synchronized *together*. For example if you ever want to drop the strong reference owned by the atomic pointer (in order to eventually drop the contents of the `Arc`) it might be tempting to do something like `drop(Arc::from_raw(atomic_ptr.swap(ptr::null_mut(), …)))` (and have other code paths check for null) but there’s a race condition: you could drop the last reference this way after another thread does an atomic pointer load but before it does a refcount increment. So to keep your algorithm leak-free and also truly lock-free you may need some sort of garbage collection, possibly in the form of "epoch-based reclamation" like in crossbeam: https://aturon.github.io/blog/2015/08/27/epoch/ Lock-free algorithms are subtly hard to get right. If you can, consider using an existing library that takes care of them and provides a safe abstraction. Maybe https://docs.rs/crossbeam/0.4.1/crossbeam/atomic/struct.ArcCell.html would work for you?
please do not handroll binary parsers. Even in Rust, this is the best way to end up with parser bugs. Even knowing the quality of the code you write, I would have doubts. Because I have seen excellent and careful developers write binary parsers full of bugs. I started nom partly because there's a lot of things to get right in binary formats, and I spent a huge amount of time providing tooling to avoid those issues. Please do not handwrite binary format parsers.
The problem is that there might be types that satisfy both traits (i.e. both `SomeTrait` and `SomeOtherTrait`. Which implementation should the compiler choose? Why do you need to use the same trait, if you're implementing different functionality? You could implement `SomeOp` for `SomeTrait` and `SomeOtherOp` for `SomeOtherTrait`. Might need to show more of your use case...
This is definitely a problem that I've hit. Two thoughts on the RFC: - is toml still the right data format, given the introduction of yet another list in the schema? - is there precedent for gathering docs data from cargo.toml? 
Probably the main question is if LLVM support NFC reader...
I ([almost](https://github.com/mratsim/bndump)) don't code directly in Rust now (I work in Nim) but I often use it as reference: - Ethereum Virtual Machine: [Parity](https://github.com/paritytech/parity-ethereum/tree/ef4a61c7696305098cac7fabb0629b22ba82586d/ethcore/evm/src) - Elliptic Curve Crypto: [signature schemes](https://github.com/lovesh/signature-schemes) and [Zcash BN curve](https://github.com/zcash-hackworks/bn) - Deep learning and tensor lib, I use Python, C, C++ and Cuda code as reference but I did check out the following: - [Leaf](https://github.com/autumnai/leaf) and its forks, [Juice](https://github.com/spearow/juice) and [Parenchyma](https://github.com/jonysy/parenchyma), I'm much farther than those lib now though. - [Matrix Multiply in Rust](http://bluss.github.io/rust/2016/03/28/a-gemmed-rabbit-hole/) was also a superb read to implement my own BLAS (for integers mainly and for fun too) - Reinforcement learning, that was how I learned Rust by doing [a go bot with Monte Carlo Tree Search](https://github.com/mratsim/rustygo). Unfortunately that was the first time I learned a low-level programming language and spent too much time trying to get a tree data structure with child and parent references compiling. Well I have know a much better idea on how to do that using Box, Rc or Cell after having done a lot of low level programming in Nim :P.
There's nothing in LLVM or the Rust compiler (or a browser, for what it's worth) that knows or cares about the NFC reader in a phone. Applications are not allowed to interact with the sensors directly, but rather ask the operating system to do that on their behalf. Because Android is so dependant on Java, the only way to access the sensors there is via its Java API. What Cordova does is bundle a bunch of Java code that can talk to the OS, then expose it to your JavaScript app. Neither Rust when compiled natively for Android, nor JS, nor WASM can talk to the sensors directly. JS and WASM can't even talk to the OS at all. So (assuming the Cordova web view can run WASM) you can: - write the application logic in Rust compiled to WASM - from WASM call out to the Cordova JS objects - the WASM host (e.g. Cordova) will then talk to the OS In theory, you could skip the middle man (Cordova) and run WASM from a Java app, but that would need some kind of WASM interpreter or JIT for Java. So yes, you can access the sensors from WASM, but only via JS and Cordova. You could also compile Rust natively, but you'd need to use Java for the UI and JNI to run the Rust code. It's probably not worth it.
C99 added restrict and VLAs IIRC, C11 added `Generic` , atomics, etc. And well, C++98 adds classes, virtual functions, inheritance, diamond inheritance, pointers to members, templates, etc. C89 is a simple language that pretty much maps 1:1 to assembly, so if you only want to target `x86`, it is probably a weekend project. In a second weekend you might be able to get C99 going. A couple of more weeks and you might get C11/C17 support. For C++98, well, even if you were to work on support for it full time for 10 years you probably wouldn't be able to implement a standards conforming compiler.
I don't think eof ever gets called in your example. If the parser completes the alphanumeric path check and has no bytes left, it halts and doesn't call eof. It will return incomplete. My stripped down code: named!(parser&lt;&amp;str, (&amp;str, &amp;str, &amp;str) &gt;, do_parse!( char!('[') &gt;&gt; group: take_until!("]") &gt;&gt; char!(']') &gt;&gt; space0 &gt;&gt; name: take_until!(":") &gt;&gt; char!(':') &gt;&gt; space0 &gt;&gt; path: alphanumeric &gt;&gt; eof &gt;&gt; (group, name, path) ) ); fn eof(input: &amp;str) -&gt; IResult&lt;&amp;str, &amp;str&gt; { println!("Never gets here"); if input.len() == 0 { Ok((input, "")) } else { Err(Err::Error(error_position!(input, ErrorKind::Eof))) } } fn main() { let file_str = "[aaaaa] bbbb : ccccc"; let d = parser(file_str); println!("{:#?}", d); // Err( //Incomplete( // Size( // 1 // ) //) ) } &amp;#x200B;
Besides the concerns about exposing an unstable crate in your API, people have also complained that the backtraces stored by `failure` slow down their apps. I don't think that's such a big concern, but I've been bothered about the increased build times; while a larger app might already be using e.g. `syn` (the same version, hopefully), for a small CLI app or crate, it might be too much. There's also some vague notion that `failure`'s API is not ideal, so it might change in the future. But it looks like there can't be any breaking changes to it, because at this point `failure` is too big to fail (pardon the pun). Also, I've seen people (including myself) getting confused by the failure documentation wrt. the `ErrorKind` pattern and the `Context` API. If you go for an `Error` enum, you still need to implement the conversion functions by hand. `failure` gives you backtraces, the context thing, and the macro for `Display`ing the error messages. Not everyone wants backtraces, and IMHO that macro should be another crate, with proper maintenance (it has some limitations right now). So, while it's not unreasonable to use it, `failure` today is probably not how Rust error handling will end up looking in a year or two. I'm sure that the compromises will be the same (wrt. backtraces, memory allocation and so on), but I think the details will be different. And if you use it today, you're writing more code that depends on a "too big to fail (or change)" crate.
Just wondering: Is it possible to detect all used `#[cfg]`s in a crate?
Is there anything stopping the timer interrupt from firing whilst the main program is accessing the framebuffer? Any time you have a mutable reference, the compiler is free to assume that is the *only* active reference to that piece of data, and may perform optimisations accordingly. I could be wrong, but it looks like in this case both the timer interrupt and the main program are constructing mutable references to the same static. As /u/diwic says, if you stick to only accessing static mut variables using raw pointers and `{read/write}_volatile` when there is any chance of overlap, then you should be fine. Alternatively, you could disable interrupts around code accessing the framebuffer, or else only access it in an atomic fashion, so that you never need a mutable reference. Final work-around would be just to separate them somehow, so that the timer and main program don't need to access the same memory (maybe the timer works somewhere else, and then does some kind of atomic swap).
I have come across https://github.com/projectfluent/fluent-rs but have never used nor do I know what their status is.
"Used" is kind of loose. If code called from an interrupt mutates global memory the reads and writes to that memory from the interrupt code do not have to be volatile (it's just normal, single threaded code, mutating some memory). However, reading the memory from code that can be interrupted should use volatile reads, since between two reads the code can be interrupted, and the memory can have changed. Depending on what this code is doing, it might also need volatile writes.
Ugh, true. I forget Rust requites the type name for struct literals. I believe that the following does what I was suggesting: struct Foo {foo: &amp;'static str}; let foo = "lalala"; let foo_object = Foo {foo}; 
the discouraging thing is that every time someone mentions nom, there's someone else that comments to say they should avoid nom. This very rarely happen for other libraries, parsers or not. I won't deny nom has been hard to use, especially in old versions, but there's been a huge amount of work to improve usability, and it is still ongoing. Also, people should not write parsers by hand. It's fine for a small test, but the confidence people get from their tests does no good when they write real software. Parsers are full of nasty edge cases, that's why we have libraries handling those. If anything, I'd recommend first building a parser combinator library (it's really easy to get started writing one), then use that for their parser.
The Cortex-M series does at least have instruction cache. Slight changes to the mainline code could change cache usage, and evict the ISR code from the cache on a regular basis. There might be a way to lock the cache lines used by the ISR.
Oh, yeah. Thanks! I’ll fix it.
I think the main issue, at least for me, is if you don't need to parse things frequently nom is like learning another language. It isn't really the fault of nom, to do what it does it needs to be somewhat complex. If I were writing a binary parser I would invest the time to learn it. For a simple text format though, I'd rather use something I can pick up quicker. I think that's why you see people recommend handrolling or pest, they're more error prone and probably not as performant, but much easier to learn. I'll give it another shot sometime, since I haven't seen the recent improvements you've made.
as a good reference, I'd recommend going through papers published at the [LangSec workshop](http://langsec.org/), where people explore issues in common parsers, formats, and look for ways to write them correctly. I have written parsers for years too, and my perspective is that the parser is the first part of the application that touches input data, and that input, especially in network applications in production, is often hostile. This is a part that must work correctly. I am aware that it is not as important in things like programming language parsers, but for binary formats, it is a big issue. People mess up stuff like TLV or integer overflow all the time. If the problem is ease of use or maintainability, for I'm curious about that other stuff
Another piece in the ndarray ecosystem, nice! :D
as a good reference, I'd recommend going through papers published at the LangSec workshop, where people explore issues in common parsers, formats, and look for ways to write them correctly. I have written parsers for years too, and my perspective is that the parser is the first part of the application that touches input data, and that input is often hostile. Especially in production network applications, but not only those. There's been a huge number of vulnerabilities caused by video formats, serialization formats like pickle, or even text config formats like yaml. The parser is a part that must work correctly. I am aware that it is not as important in things like programming language parsers, but for binary formats, it is a big issue. People mess up stuff like TLV or integer overflow regularly. If the problem is ease of use or maintainability, for new formats, it is better to use formats like capnproto or avro. We get production ready parsers very fast, the schemas are easy to maintain, and we can quickly add support in other languages. I'm curious about the other stuff you want to consider here though.
`const fn` is for functions evaluable at compile-time, that seems related more closely to *const generics* aka values as generic parameters, where `slice.window&lt;T, V:usize&gt;` would yield an iterator of `&amp;[T;usize]`.
Yes, I mean `const generics` not `const fns`. That is a mistake, thank you !
Yes, I mean `const generics` not `const fns`. That is a mistake, thank you !
No worries. And reading the issue I linked in more details, it looks like this pattern would not / could not be handled under its limited scope: it looks like the initial implementation would provide for a generic input but not a generic output (independent from the input): &gt; Note that all of this should allow `impl&lt;T, const N: usize&gt; Trait for [T; N] {…}`, but not actually passing a constant expression to a type/function, e.g. `ArrayVec&lt;T, 3&gt;`.
As /u/masklinn noticed, I made a mistake and wanted to speak about` const generics`, so the `slice.windows(2)` would not be of this form but more like `slice.windows::&lt;2&gt;()` (the `T` generic type is not restricted by the `windows` function but by the `&amp;self`/`&amp;[T]` type. It could be really cool if the Rust inferance system could detect that the slice pattern used (`[a, b]`) is of a size of 2 and therefore allow the user to not specify the size in the `windows` function call :)
 &gt; the discouraging thing is that every time someone mentions nom, there's someone else that comments to say they should avoid nom. This very rarely happen for other libraries, parsers or not. I think this is just a reflection of where nom is right now, and also a good sign: * Nom is the top-hit for "Rust parser" and has 2.4k stars, so naturally lots of people have tried it (congratulations, btw!) * Across all languages, I find parsers generally to be more difficult to use than "normal" libraries that have a fixed set of types and fewer ways to combine these; which leads to a higher "base level" of frustration * At some point there is a trade-off between usability and performance; and nom seems to be very strong on the performance side already (congratulations again!) It might just be that you successfully created the fastest, most used parser in Rust, and as a result of this particular combination you are now seeing more UX complaints than most other libs. If beyond that you are still discouraged, two ways forward that might reduce complaints: * Maybe survey where exactly your user's frustration comes from and take some time to analyze it. "If you feel negative about nom, why?", "Have you stopped using it and for what reason?", "What are the top-3 things nom would need for you to recommend it?", ... I think nom is famous enough that a Google Survey gets a decent participation. * Ultimately, if you believe your user experience can't be improved without sacrificing your other goals (assuming you don't want to do that), just be very clear about that on your site. Market and communicate your library in a way that manages these expectations, and help your potential (non-)customers figuring out when nom is best, and when another alternative might be better early in the process. Also, please don't hesitate to ask if you want help or feedback regarding any of that.
 &gt; I'm curious about the other stuff you want to consider here though. From the top of my head in random order: * performance * security * compile time * dependency-size * development time * maintenance effort * API familiarity * portability I think "creating a MP4 decoder for Firefox" and "just adding that temperature sensor to my pet project" have two very different sets of requirements. 
I wrote a few a while back, but really I don't expect anyone else to have bothered: [scramjet](http://uazu.net/scramjet/). It keeps a JVM running in the background. But really nowadays, why use Java when other things are so much better designed for CLI/TUI?
I have succeeded to get system's locale with `libc`: fn get_system_locale() -&gt; Option&lt;String&gt; { let locale = libc::setlocale( libc::LC_COLLATE, b"\0" as *const _, ) as *const _; if locale == std::ptr::null() { None } else { std::ffi::CStr::from_ptr(locale) .to_str() .ok() .map(|s| s.to_owned()) } }
Yeah, I mean, I don't really find that too compelling. If the parser is written in safe Rust, then the potential for exploits certainly dips quite a bit. All of the bugs I've had in my handwritten parsers have manifest as panics or, on occasion, actual logic errors. If we were talking about C or C++ here, then the correctness value proposition provided by a parser combinator is certainly larger from my perspective than in Rust. I maintain plenty of code that a lot of people use, and there are plenty of handwritten parsers in that code of all shapes and sizes. In my experience, I just don't spend much time squashing bugs in that code. This is kind of a cheap argument, I grant that, but to be fair, it is how I prioritize my work. That is, I choose how to spend my resources at least in part based on how much I perceive it will help lower maintenance costs going forward. Not once has switching from a handwritten parser to a parser combinator library even come close to crossing that radar for me. Maybe my code needs to be used by more people to find more bugs, and then maybe that calculus will change, but that's where I'm at right now. &gt; I'm curious about the other stuff you want to consider here though. I'm sure it's nothing you haven't heard before. Parser combinators are another layer of abstraction between me and the thing I'm parsing. It takes serious effort to learn how to use them effectively. When I handroll a parser and hit a problem, I'm very very familiar with not only the universe of potential solutions, but their costs as well, because I'm writing the parser myself in the programming language that I know very well. If I hit a problem with a parser combinator library, I'm stuck in its universe and have to squirm my way to an answer. It's been a very long time since I've used a parser combinator. The next time I come across a parsing task, I'll see if I can spare the resources to try one out again, because hey, maybe they have improved a lot and I'm wrong. There are certainly vague problems I have that make it difficult for me to actually choose a parser combinator over handrolling though, and they generally revolve around performance and error reporting. For example, take a look at regex parser errors: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=989c9560bdda6bad62b478298203a498 --- Is that something I can easily achieve in a parser combinator library? I have no freaking clue. I have this vague memory that parser combinators were absolutely terrible at error reporting, but I'm also aware that you've awesomely spent time on [improving this story for nom](https://github.com/Geal/nom/blob/master/doc/error_management.md). Reading that, it seems like what I'd want is possible, but I'd need to go figure it out. As another example, consider my [csv parser](https://github.com/BurntSushi/rust-csv/blob/master/csv-core/src/reader.rs). I have no doubt that any parser combinator library worth its salt could be used to write a lovely csv parser, but will it be as fast as possible? If I handroll the parser, then I know I have as much freedom to optimize as Rust will grant me, and I'm very very familiar with my limitations there. How much freedom do I have in a parser combinator library to do it? I'd probably have to actually try it out in order to figure it all out, and when I already don't place too much weight on the value proposition of a parser combinator library, it is very hard to go out of my way to effectively learn a whole new parsing language just for the task. Especially when I know exactly how I want to tackle it in a handrolled parser. Have I had bugs in my csv parser? Abso-freakin-lutely. But not many. I've spent _far_ more time on trying to figure out higher level concerns like Serde integration than I've spent on parser bugs. It just doesn't make sense for me from that perspective to spend my time optimizing a problem that doesn't exist. As another example, consider a [simple escape sequence parser](https://github.com/BurntSushi/ripgrep/blob/acf226c39d79264256c0295b8381f8c7f0d74d59/grep-cli/src/escape.rs#L104-L165). Is it 100% correct? I don't know. I've written a lot of parsers like that though, and there are some tests. I don't think I've ever had a bug reported against it, but that doesn't mean there aren't any. If a bug was reported, how easy would it be to fix it? My judgment is that it would be very easy. If a bug was reported, would it be exploitable? This tiny parser doesn't use any `unsafe` code, so I don't think so. Hell, neither performance nor error reporting even really matter much here in this context. So why not use parser combinators? Well, at this point, I just apply the normal calculus I use for choosing _any_ dependency: what is the value add? Writing that handrolled parser was a piece of cake, was dependency free and barely took any time at all. But if I were to use a parser combinator library, and even assuming I was already an expert user of that library, I still wouldn't use it because 1) there isn't much code and 2) the task isn't complex. So I would definitely rather avoid adding another dependency in that case. To some extent, the above concerns are a chicken-and-egg problem. That is, my lack of familiarity with Rust's parser combinator libraries is partially preventing me from using them. But this is to some extent a microcosm of a larger argument about abstraction, and isn't just about _me_ personally, but anyone reading or modifying my code (including my future self). I try hard not to prematurely abstract things, because I think unnecessary abstractions can lead to significant learning barriers. Tying the implementation of a core part of some library (like a parser) to a very large abstraction like a parser combinator library is, to me, an _enormous_ cost because I've very rigidly increased the barrier to touching that code. One not only needs to be familiar with the host language, but also the parser combinator language. You might say that a handrolled parser has similar problems since it might obscure the higher level task; that's true, but you only need to know one language to understand it. So from my subjective experience, introducing a parser combinator library has a large cost, but its value add is somewhat small. So the conclusion is fairly fixed for me: don't use parser combinators. Like I said though, it's been a while since I've evaluated parser combinator libraries in anger, so when I get the chance, I'll see about trying one again. I also have specific criticism toward nom as well, although I don't know how much they matter in practice. For example, the fact that the main API of the crate is a bunch of macros really turns me off from using it. Again, I know you've probably heard that before, and it's probably super frustrating to hear, because it's evident that you've tried to make the user experience really great despite the heavy macro use. This isn't a showstopper for me on its own, but it's a contributing factor, certainly. I've seen a lot of people extol the virtues of parser combinator libraries. That ain't for no reason. Parser combinators are a lovely thing that do actually appeal to me on some level. But I've also seen plenty of people express similar opinions and experiences as me about parser combinators, where they think they simply aren't worth it. I'd hesitate to say that there is some fundamental truth here, because it could just be that most parser combinator libraries suck, and that therefore the key is just building one that doesn't suck. In that sense, I can understand the frustration, because now you have to work against the prior experience of a lot of folks and convince them to give it another shot. But on the same token, I do think there needs to be at least some recognition about the costs of parser combinator libraries, and importantly, that folks will experience those costs very differently. Obviously, for someone like me who has written so many handrolled parsers that they've lost track, those costs are going to be experienced very differently from someone who has never written a parser and wants to learn the best way to do it. I should try to be more circumspect there when talking about the trade offs too, but I don't think there is much harm in suggesting that folks give handwritten parsers a chance, especially in a memory safe language like Rust. Then they can evaluate the trade offs for themselves.
Ah that's a neat idea! I'm not sure if users of CLI programs would put up with that, but it is cool. I did try it out to see what startup times actually looked like, but I couldn't get the JVM started: $ export JBIN=/usr/lib/jvm/java-10-openjdk/bin $ ./mk Note: net/uazu/scramjet/MsgReader.java uses or overrides a deprecated API. Note: Recompile with -Xlint:deprecation for details. $ ./out/scramjet -S *** Creating default configuration file in: /home/andrew/.scramjet/config *** Edit this file if things don't work correctly Starting JVM ... Scramjet server did not start up after 10 seconds $ out/scramjet net.uazu.scramjet.test.ConsoleTest0 Scramjet server did not start up after 10 seconds 
[Safe Haskell](https://downloads.haskell.org/~ghc/8.6.1/docs/html/users_guide/safe_haskell.html) is another good one to throw into the mix.