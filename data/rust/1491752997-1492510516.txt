Ah I see. See: https://www.reddit.com/r/rust/comments/649i80/looking_for_feedback_regarding_my_pandora_player/dg1andk/
The biggest cause of that in C++ is probably undefined behavior, not compiler bugs. It's hard to figure out why code like void do_a_thing(Thing* t) { int len = t-&gt;len; // stuff with side effects if (t) { // use t and len } } is skipping the null check and only segfaulting at the end, because the compiler moved the `t-&gt;len` access down to where it was first used, but kept it as proof that the null check was unnecessary. Rust has way less UB, so there aren't as many optimization-induced bugs.
&gt; That doesn't make any sense unless you're doing baremetal development. ... which is a major use-case for Rust.
VS Code just uses LLDB or GDB as the backend. And I'm guessing Qt Creator does the same thing. While VS Code might not expose all of this functionality in the UI, you can always use the Debug Console in VS Code to do all of this. Alternatively you might actually be able to just use Qt Creator to debug your Rust code.
[IntelliJ](https://www.jetbrains.com/idea/) + [Rust plugin](https://github.com/intellij-rust/intellij-rust) is pretty decent.
FsEvent's constructor can't take a MyType. I don't know what that type looks like, but what if you write a From/Into implementation for MyTypes that converts Event(FsEvent) into fsevent::Event? Then you can call FsEvent::new(tx.into()). Does it work if you write FsEvent::new(tx.0) ? That would get the event wrapped in your type.
Concepts are closer to traits than this exactly, but neat, regardless!
&gt; You can actually "hijack" rustup by writing a nix expression that downloads exactly those things rustup downloads. That is exactly what the Nixpkgs overlay do.
Not necessarily - it's actually often a good thing. The part that irks me more about this is that you want an implicit conversion from one type `Result&lt;_&gt;` to another type `IpAddr`, depending on the result of said compile time evaluation. I feel like this will really hurt maintainability, because it means the return type of `IpAddr::from_str` will depend on the input and whether the function can be evaluated at compile time.
That's because FromStr isn't in the prelude, it's not automatically imported. And since it's a trait to use its methods you have to import it into scope. What you might want to do is: "127.0.0.1".parse::&lt;IpAddr&gt;() Which is going to use FromStr internally. 
It is possible to have a macro parse the string and fail to compile if the provided value isn't a validly formatted IP address. `println` does this: try compiling `println!("{")`. That's currently the only way to force compile-time evaluation. Right now there is no distinction in the language between runtime and compile-time values, so there's no way to make a function with a different signature or different behavior whether it's called as `func("3")` or `func(get_input())`.
`FromStr` here is a trait that is implemented for `IpAddr`. Rust has a rule that traits must be in scope, in order to be used. The quick reasoning behind this is that you could have two traits for `IpAddr` that both have a method called `from_str` on them. If traits didn't have to be in scope, which version of `from_str` should be called? By requiring traits to be in scope, you can easaily choose which trait implementation you want to use.
I consider unwrap as a developer tool, that allows you to mockup your logical thoughts without being distracted by implementation details. But you should go back and replace them before considering the code done.
If you're happy to use something like the the error-chain crate (or roll your own), I'd suggest something like https://github.com/brson/error-chain/blob/master/examples/quickstart.rs. That is, `main()` should call your code proper, which lives in some other function (maybe `run()`) returning a `Result&lt;...&gt;`, and `main()` handles an `Err` result by printing a human readable error. Then inside your `run()` function you can use `?` or `try!`.
&gt; And I'm guessing Qt Creator does the same thing. Yep
I see, so short-circuiting the inheritance priority issue of Object Oriented language in way? Thanks.
TBH there is no must have general IDE for rust at the moment. The editors have the best support at the moment so pick up Vim, Emacs, Sublime, Atom or VScode. While you have to keep in mind that VScodes Rust plugin has some very active improvements going on, for example, the integration of the [Rust Language Server](https://github.com/rust-lang-nursery/rls) 
Cool - thanks.
As long as the compiler can figure out the type of `F` it should be okay. Since you cannot name the type of a closure, the only way I can think of is to conditionally create the option directly, using type inference, and then pass that. let cond = true; // or whatever logic let of = if cond { Some(|i| println!("{}", i)) } else { None }; foo(of); You can also use the nightly-only impl trait feature to move the creation into a function. [Playground example](https://is.gd/fmnWP1). In that case you could also have the function return just the closure and only call it when you create the `Some`.
I just realised i oversimplified this, what i actually wanted to accept was `Into&lt;F&gt;`, for which I can't find a type signature to apply to `None` to satisfy the type checker. 
Even better!
An alternative to implicit conversion would be some sort of "safe unwrap" that would result a compile failure if the compiler is not able to statically prove that the unwrapping will succeed.
I believe that would require closer collaboration between cargo and nix.
Redox OS is a microkernel based Operating System written in Rust. This release combines a large number of changes over the past 3 weeks. Let me know what you think!
Trait methods (unlike inherent methods) are namespaced under the trait, not the type. Therefore the only way to make the method available for the `object.method()` syntax is by importing the trait.
It would be a great thing. I read that someone is working on a MIR interpreter which should make it easier to eventually do more compile time evaluation in rustc. Unfortunately I don't remember where I read it, and don't take my word for it. Edit: Looks like it was this one: https://github.com/solson/miri Edit2: From the slides: &gt; Now it serves as an experimental implementation of the upcoming compile-time function evaluation feature in Rust.
&gt; Thinking that it'd be easy to not go back and fix scared me That's one of the many reasons to use Clippy! Develop without it and when you get to the point of "yeah, that's ready to push/merge" then run Clippy and fix everything it throws at you. It'll call you out on any remaining unwraps, common overlooked things, and just less-than-ideal code that is "good enough" when prototyping.
Am reading instructions about cargo new --template. Which versions of cargo have this option? cargo new myproject --template https://github.com/user/template ; cargo --version error: Unknown flag: '--template' Usage: cargo new [options] &lt;path&gt; cargo new -h | --help cargo-0.17.0-nightly (f9e5481 2017-03-03) 
binutils are substantial tools I think. Sad, they have to be installed now.
Glad to hear that! There is still a problem with memory usage. If you resize too many times you will run out of memory.
`binutils` in Redox is not `binutils` from Linux. Here is what is currently included: - `hex` - `hexdump` - `strings` It has also not been maintained regularly, so I decided to not include it by default. Here is the repo if your are interested: https://github.com/redox-os/binutils
This is a very useful idea, and there's a version of it in the [take_mut](https://crates.io/crates/take_mut) crate, with a slight change to make it panic-safe.
Very cool! I find myself doing a lot of embarrassingly parallel work on arrays and matrices, and have (independently) been interested in starting to do some my analyses in rust. This would really scratch both of those itches.
The doc link is dead: https://doc.redox-os.org/doc/binutils/
Your code is unsafe in the presence of panics: [demonstration](https://play.rust-lang.org/?gist=4658350f75e445738998f6330679ba5b). Run the code, scroll down, you can see `ns` getting dropped twice.
Sorry that I missed this discussion before. It is hard for me to add much to what has been said - there's a lot of fantastic information below (and in this parent comment) which I think conveys the situation well. I'm keen to work with /u/vitiral and others here to try and improve Rust's linear algebra ecosystem. Each library aims to solve a particular problem and it would be awesome if we could make it seamless for user's to switch between these when appropriate. To answer (loosely) the question of why rulinalg exists, and why it doesn't use ndarray for its underlying data types. I created rulinalg because I wanted to be able to write a machine learning library without dragging in a number of non-rust dependencies (BLAS/LAPACK, etc.). This was a toy project and I thought it would be neat to have something that worked purely with Rust. At the time I didn't care so much about performance and wanted it to be super easy to use (and set up). This is still largely true though performance has been a big focus recently (more on this shortly). I _could_ have built on top of ndarray but at the time things were less stable - from memory ndarray has just depreciated a large chunk of linear algebra code (I'd need to ask /u/neutralinostar to confirm). Because of this and the added complexity that is required (and justified) for ndarray to support generic n-dimensional arrays and row/column major storage I decided it would be easiest to write a new library myself. **I also wanted to give a public shoutout to /u/Andlon .** He has been a champion of rulinalg lately - helping new user's to onboard, giving fantastic code reviews whilst teaching all of us, and putting in some fantastic PRs himself. He is also responsible for an impressive sweep of performance improvements over some complicated linear algebra algorithms - really cool stuff! He has put forward what I believe is a really exciting vision for the library in the future and is working hard to help this be realised. There are some really exciting things in the pipeline and I'm looking forward to seeing these come to life. Thanks /u/Andlon!
There is a RFC about this already: https://github.com/rust-lang/rfcs/pull/1736 The basic consensus is that it can be made safe by falling back to a abort in the worst case, but its a bit of a clunky API due to that, since its hard to ensure that there is no panic in the update function.
Interesting project, although I have a hard time understanding why the keys are generated by the database on insert. How do you use such thing as a database?
Ok thanks I've read now. much the same issues raised as I remember. 
I removed it - there have not been docs for it there in a very long time.
Sure, we will do that. Releases are a snapshot of the most recent master. The cookbook that builds packages uses the most recent upstream version, unless directed not to. When the package manager supports updates, we will essentially have a rolling release.
Sounds great.
You might want to open up an issue on the wrapped2d github. It may just be a case that they have not added support for Windows yet.
Rust really needs something like Haskell do notation which is really nice for chaining option/either monads together. Scala has it too.
You can do `slice.chunks(5).flat_map(|chunk| chunk.windows(2))`.
&gt; panic-safe. I'm not sure that abort-on-panic is really “panic-safe.” I'm not sure if double-panicking is undefined behavior or if it is specified to abort. If it is specified to abort then `take_mut` isn't any more safe than just letting the double-panic happen, right?
I don't know, I prefer RustAlgebloat's syntax for this: a.assign(a + b - c + d.view(1..2, 0..3) - d.view(0..1, 0..3)); Compared to: Zip::from(&amp;mut A) .and(&amp;B) .and(&amp;C) .and(D.genrows()) .par_apply(|a, &amp;b, &amp;c, d_row| { *a += b - c + d_row[1] - d_row[0]; }); (AddAssign wasn't around when I did most of the work with RustAlgebloat, hence no `+=`) Eigen is a super-sweet C++ linear algebra library that has internal parallelization, simd, CUDA while using expression templates for nice syntax. It's strange to me that 3 years after I wrote RustAlgebloat it's still the only library that looks anything like Eigen in Rust land, despite tons of type system improvements added to Rust since then.
What does double panics have to do with it? If you abort then there is no second panic...
I have no beef with algebloat, don't know anything about it. You should document it and explain what it can do.
If you don't abort, then there might be a second panic, which would cause an abort, IIUC.
I wrote "This should be safe **except when the closure unwinds**". I guess you missed that. I'm aware of this problem.
&gt; Ensure that the code can't panic. At any time, somebody can add an `assert!()` which breaks this assumption. It's just too much of a footgun.
Thank you for this link! I've been searching for exactly that. Seems like it really is safe if unwind is handled somehow.
Thank you! This is exactly what I wanted.
Thanks for the kind words, /u/SleepyCoder123 :-)
If Rust had `no_unwind` - equivalent of `nothrow` from C++, it would be possible. Of course, it could make propagating these constraints difficult but it would still allow people to write simple, non-panicking code in `replace_with` and/or wrap the complicated code in `abort_on_panic()`. Also, `panic=abort` setting could automatically make all functions `no_unwind`. That would be pretty cool.
Yep - if I might add on to this, here are my macros to deal with errors in a more "safe" way: https://gist.github.com/sharazam/fd2de5010e160916125d252f6519ac76 I've built these macros in order to deal with Option and Result seperately, as well as printing a message to the screen for debugging, etc. The thing is that I want to minimize the amount of code that really "has to crash". For example, I have a function which I give a TypeId of type `DatabaseNode`. returns a `Vec&lt;Node&gt;` where any element in the vector is of type `DatabaseNode`. So for downcasting, I can use `unwrap()` safely because if this ever crashes in production, it means that I made a mistake. However, if the environment is not set up how the program expects it, I don't want it to crash. There are also the crates `log` and `backtrace` for tracing an error. My macros are just for handling the error in a non-fatal way. unwrapping is often the right thing to do if you know that certain actions cannot crash. The most important goal is if you encounter a possible error is to "bubble it up" to the main / error-handling thread. Crashing is perfectly safe, but it's not what you usually want to do for a trivial error like this.
Hmm, I will definitely have to try this out. According to https://blog.rust-lang.org/2016/08/18/Rust-1.11.html, Cargo has had support for `crate-type = ["cdylib"]` since 1.11 - maybe this is handled in the "Other" enum variant?
Sure. But why can't you put it in your Cargo.toml?
I've just tried out other `#[crate_type]`s and apparently, none of them are working for me.
I'm guessing cargo does override that too then. Are you sure that crate-type in Cargo.toml does not do what you want? http://doc.crates.io/manifest.html claims that cdylib is supported there, though I haven't used it
It should work as both a usual Rust binary and a dynamic library. I'm trying to compile it for Android without a custom linker.
&gt; … it would still allow people to write simple, non-panicking code in replace_with and/or wrap the complicated code in abort_on_panic(). Yes. On the other hand, it's pretty simple to write code that is correct w.r.t. current Rust semantics by using poison values, like libstd does for common APIs. &gt; Also, panic=abort setting could automatically make all functions no_unwind. That would be pretty cool. I agree the compiler should be able to optimize lots of stuff in panic=abort mode that it couldn't optimize as well in panic=unwind mode. Does panic=abort actually guarantee "no unwinding"? I think it only guarantees that attempts to recover from unwinding will fail.
Not sure how idiomatic that is, but I would probably `trim()` the input, then `split_at()` the length of the first item of `split_whitespace()`, then `trim()` again as needed. That said, the various `str` iterator types might benefit from a method to return the remainder of the original string slice a la `std::path::Iter`. Would that require an RFC?
&gt; That said, the various str iterator types might benefit from a method to return the remainder of the original string slice a la std::path::Iter. Would that require an RFC? I've run into this problem too, and this is exactly the solution I had in mind.
Would [splitn](https://doc.rust-lang.org/std/string/struct.String.html#method.splitn) be better for you? With that, you could split off one piece, and keep the remainder as a `&amp;str`.
&gt; using poison values Which are the same thing as additional enum variant in state machine. I wanted to avoid exactly this. :) &gt; Does panic=abort actually guarantee "no unwinding"? I think it only guarantees that attempts to recover from unwinding will fail. Good question. I don't know.
The problem is that `splitn` doesn't split on unicode `White_Space`, like `split_whitespace` does. So it's not a suitable replacement if you need that behavior. EDIT: Although it's fairly trivial to implement yourself what `split_whitespace` does, [as it turns out](https://github.com/rust-lang/rust/blob/22bae87f3bc86fc5fecc78def65733a1116aedbe/src/libstd_unicode/u_str.rs#L46-L58).
&gt; Heck, HOME isn't even really a thing to Windows programs, just badly ported UNIX software. Well, why does then the windows implementation of `env::home_dir()` care about it? pub fn home_dir() -&gt; Option&lt;PathBuf&gt; { ::env::var_os("HOME").or_else(|| { ::env::var_os("USERPROFILE") }).map(PathBuf::from).or_else(|| unsafe { let me = c::GetCurrentProcess(); let mut token = ptr::null_mut(); if c::OpenProcessToken(me, c::TOKEN_READ, &amp;mut token) == 0 { return None } let _handle = Handle::new(token); super::fill_utf16_buf(|buf, mut sz| { match c::GetUserProfileDirectoryW(token, buf, &amp;mut sz) { 0 if c::GetLastError() != c::ERROR_INSUFFICIENT_BUFFER =&gt; 0, 0 =&gt; sz, _ =&gt; sz - 1, // sz includes the null terminator } }, super::os2path).ok() }) } 
Dunno. It probably shouldn't. Asking what the "home dir" is on Windows arguably doesn't even make any sense; there are different directories for different purposes, not a single catch-all directory.
I wrote a similar function just yesterday. Was implementing a simple linked list: enum List&lt;T&gt; { Nil, Cons(T, Box&lt;List&lt;T&gt;&gt;) } and couldn't figure out how to implement various iterators. In the end I found `mem::replace` but it seems wrong to first replace a list with Nil only so I can take Cons apart and replace it with the remainder of the list after that. It also seems rather inefficient: replace calls swap which does 3x copy. So that's 6x copy to deconstruct a Cons. Am I missing something here?
I continued my work on [relm](https://github.com/antoyo/relm), an asynchronous GUI library based on GTK+ and futures/tokio. * I added a `#[name]` attribute that can be used to name a widget in the `view!` macro. * I started a GUI functional testing library for relm. * I made some cleanup/refactoring. I also wrote a blog post to talk about this crate and I'll publish it in the next days. This week, I'll continue the testing library and add more tests and documentation.
IIRC the servo team doesn't feel the ACID test is a very good test, they track based off some other things. There was a reddit thread a while back.
Wow, seems like I just thought too complicated. This works perfectly and was exactly what I was looking for! Thanks a lot!
What is the reason for the `sizes` argument to new?
Here's how we do it: (at the same level as Cargo.toml) Paste this into .cargo/config: [build] rustflags = ["-C", "prefer-dynamic"] In Cargo.toml: [lib] name = "our_lib" path = "src/lib.rs" crate-type = ["dylib"] 
Im confused
Last week, I split the parsing and file inclusion portions of my device tree reading [program](https://crates.io/crates/dts_viewer) off into a separate [crate](https://crates.io/crates/device_tree_source). I also rewrote most of of the file inclusion code which was a fun time all round, but it came out much better for it. At any rate, because much of the code is now exposed as a public interface, I need to do documentation. At the same time, I am going to look at making a test that tries parsing all of the device tree files in a directory and then run that with every device tree file in the linux kernel git. There are some pretty crazy device trees in there, so I figure if I can parse them I have little to worry about. In addition, there are a series of tests that the real device tree compiler runs on the parsed tree that I have not currently implemented. I need to go through these tests and figure out which ones I really need to worry about, but that might be pushed back to next week.
Thank you for the input! I figured it might have something to do with that - and yes, std depends on arc a lot nowadays (basically, entirety of sync, amongst other things), so it'd make sense. Trying that. Will report in circa 2 hours (that's the worst part of this) whether this worked. At this point, I'd really have liked to change the tools used here to Rust (what I'm going to replace is written in Lua right now. You can imagine the WTFs), but obviously, no rustc means no rust.
Working on a presentation of gluon for the Rust meetup in Stockholm in a couple of weeks https://www.meetup.com/ruststhlm/events/238207716/. Having a bit of trouble figuring out the right balance between talking about Rust vs talking about gluon but it should work out in the end. For gluon itself I am trying to figure out the right incantations to get releases published via travis https://github.com/gluon-lang/gluon/pull/272 and I am also going to make it possible to specify fixity and precedence for user defined operators https://github.com/gluon-lang/gluon/issues/3. 
Let me know if it works, I'm curious.
Same error with joerg-krause's script - missing Arc. Back to square one :-(
Thanks for sharing this. Unfortunately I need to build a dynamic library without editing any file.
What does RemindBot remind about?
Looks like it is abandoned.
I've tried to build cross-compiled stdlib with xargo, result is the same: "could not find `arc` in `alloc`"...
That commit is in no way recent. And it was removing stuff that were just toy implementations. Anything you've done has better quality.
Would you make available a custom target specification for a UEFI app or point me in the right direction, please? Also, is it possible for `rustc` to use the already existing linker installed by `rustup target add --toolchain nightly x86_64-pc-windows-gnu` or `rustup target add --toolchain nightly x86_64-unknown-linux-gnu`? I have been struggling to find information on building a UEFI app in Rust. I have ported the headers and run a very basic `Hello, world!` application (after a long time correcting the linker parameters).
I think Haskell's `repa` can achieve similar things, at least.
Much better 
I've been slowly working on my tokio based IRC client library [tokio-irc-client](https://github.com/mr-byte/tokio-irc-client) and as a part of that effort I completely rewrote the way messages to and from the server are stored and handled, with some interfaces for getting strongly typed access to tags and parameters. I've spun that work off into a library of its own called [pircolate](https://github.com/mr-byte/pircolate) which is very much a work in progress currently. It only handles the parsing and construction of a handful of IRC commands at this time and I still need to put some thought in to the API so that it could be used for constructing and parsing messages on both the client and server side. Right now it's very focused towards the way the client handles things. I'm mostly happy with the API for the IRC client library itself, but there's always room for improvement. I'd like to revisit the error story, to maybe improve the ergonomics of errors.
It requires nightly still, but it is a design constraint we use for the language, and something that overall, we take very seriously. I don't know of companies, but there are a *lot* of hobbyists using it for that.
Huh here I thought the /r/rust community had no problem being friendly. 
It's cleaner but I feel it's not as general as ndarray's. How would you handle cases with multiple output vectors? What if you want to store some intermediate values but don't want to allocate a whole 'nother array for it?
The second edition is currently under development and will replace the the first edition (second link) when done AFAIK.
AFAIK, it was a known trade off made in the initial implementation. There have been various proposals to fix this. This is the current one: https://github.com/rust-lang/rfcs/pull/1769
Sure. That's still no reason to assume that the OP is not one of the people using it in this fashion, though.
Oh, thanks for clearing that up. I did not realize that they are different editions of the same book (perhaps because they look so different content-wise).
Be careful with string escapes though ;-) I.E. `is "this two"` or three "args"
Should rustc raise a warning when a trait method and an inherent method have a name collision? What would be the legitimate use case of such colliding `impl`s ? trait Len { fn len(&amp;self) -&gt; String; fn len2(&amp;self) -&gt; String { self.len() } } impl Len for String { fn len(&amp;self) -&gt; String { "hello".to_string() } } fn main() { let x = "abc".to_string(); println!("{}", x.len()); // can anybody guess which len() "wins" ? println!("{}", x.len2()); // =&gt; hello let lenp: &amp;Len = &amp;x; println!("{}", lenp.len()); // -&gt; hello } * https://play.rust-lang.org/?gist=52ca7b6e84eb534eaf3df8590d631fd6&amp;version=stable&amp;backtrace=0
Well, the RFC got closed because the design presented had issues from what I could see, so I guess this means nobody really figured out how to do it.
&gt; Does panic=abort actually guarantee "no unwinding"? I think it only guarantees that attempts to recover from unwinding will fail. AFAIK it just aborts in place, no unwinding at all. This seems consistent with [this](https://github.com/rust-lang/rust/issues/38281), from which I gather that the whole unwind machinery is unnecessary in the `panic=abort` mode.
You give it a time and some text and it repeats that text to you when the time is reached. Nothing fancy, similar to reddit's version of the same. For instance: `@RemindBot in a month "I must reassign this issue if it's not resolved"` RemindBot is also polite to the point of obsequiousness.
This is useful primarily in generic contexts, where you can't access inherent methods: fn get_len&lt;T: Len&gt;(container: &amp;T) -&gt; String { container.len() } Inherent methods take precedent if they can be resolved in a given context, so: let x = "abc".to_string(); println!("{}", x.len()); Calls `String;:len()` (the one that returns `usize`) and not `&lt;String as Len&gt;::len()`.
Currently a server side / backend engineer working at an early stage startup. Our tech stack is mostly Ruby, Ruby on Rails, and some Elixir. It's a very big CRUD app. Been spending more and more time learning Rust to try and escape from many problems with dynamic languages that we fight on a day-to-day basis. Still waiting to find the right project and opportunity to apply Rust to our stack. I suspect that will be a long time before this happen.
1/ You may give a try but I am not sure it is a good way to start learning rust There is also `tokio-rs` to write async code in rust. 2 + 3/ You can bind in rust whatever is bound to c. Some links: https://doc.rust-lang.org/book/ffi.html https://github.com/alexcrichton/rust-ffi-examples https://github.com/manuels/cxx2rs 
It's not clear to me why the windows build is not listed on the site but I think this is the dl link (it's commented out in the html): https://download.servo.org/nightly/windows-msvc/servo-latest.msi The tracking issue seems to indicate that it's basically ready: https://github.com/servo/servo/issues/12125 
Bare metal rust seems highly exploratory at the moment. I know the Zinc project was abandoned. There's Tock, but it's definitely an academic project and I don't think we'll be seeing practical applications coming from there for a while, if ever. Tock is more interested in how Rust's safety features can be leveraged in resource-constrained devices, rather than creating a general purpose embedded environment. It's a shame too, because traits are a godsend for embedded development. The standard way to do this stuff is to either abuse macros in C, or abuse templates in C++. Neither of which produces understandable or maintainable code. I've been thinking about re-implementing the ChibiOS HAL in Rust, for at least one or two STM32 targets. I think a simple scheduler in Rust similar to FreeRTOS would be nice too.
[Playground Link](https://is.gd/H93E7k) Why the compiler can infer the return type in the first case, but not in the second, and there is any workaround? (Trying to come with a good constructor method for the ContModel type, if it can be done without providing any initialising value even better. Anyway I can pass enough information so the compiler will be able to infer the proper type without providing an initialising value? Which does not involve exchanging the associated type for a type parameter for the "DiscreteNode" trait.)
My dev code is littered wit `unwrap()`, and once I get something working, I go through and replace them with better error handling. Often it's difficult to know how best to handle errors, and it's really nice to be able to ignore them and just crash if there's a violation. That being said, I think that `unwrap()` is a bad practice *for production code*. There are lints (off by default) in `clippy` that you can use to catch these types of issues.
How do cargo subcommands work? I see some projects like cargo-audit and you can call it as "cargo audit". Also, rustfmt you can call like "cargo fmt". Just looking for some documentation on how it works or clarification. I'm interested in writing a cargo subcommand (at least experimenting with it) and haven't managed to find any good documentation
Oh hey, I *just* started looking into gtk-rs a few days ago. Might be visiting you. :) (warning: absolute gtk noob)
You could generate the second toml file from the first in a wrapper script :-D (I agree that this is just a couple steps removed from insanity but...it could work!)
If they could produce an analogue to ACID with only features that the Servo team cares about, I think that would do wonders for demonstrating progress. Casual onlookers really benefit from easily-consumed visual aids, and in the meantime it's a shame that the three ACIDs are the only conformance tests in that vein.
I wouldn't mind seeing their ACID compliance anyway along with explanations of why they think it's a poor test, which parts don't work that they intend to comply with (if any), and which parts don't work they do not intend to comply with (if any).
Why not use the gitter channel? 
Anyone know why docs.rs doesn't have anything yet?
None. I'm more on irc.mozilla.org but there is more people on irc.gimp.org.
Is it possible to create arrays of linked lists using the standard library? Or would I have to create my own implementation of linked lists to do so?
looks like the link in the readme is wrong, the correct one is https://docs.rs/mammut/
I believe it was something along the lines of it's broken anyway and some browsers have hacky fixes to get 100% anyway. CBA finding the post but it's somewhere... Unless I've imagined it lol
&gt; How do cargo subcommands work? If you type `cargo foo`, cargo checks your `$PATH` for something called `cargo-foo`, and if it exists, executes it, passing along the arguments. That's it. This means you can write them in literally anything: shell, Ruby, Rust.
Thanks! Yeah, I've been reading Philipp Oppermann's blog. I haven't used GNU EFI or TianoCore, although I did look into GNU EFI. I have been translating the provided structs in the UEFI specification (version 2.6) to Rust. I must have messed up somewhere; UEFI calls the entry-point (`_start`) but I see a blank screen if `_start` calls any function which is not inlined into itself. The [messy] code I wrote is published at https://gist.github.com/toothbrush7777777/0b2cd6f60558c76b09d7dffc78fa6f0d.
Coming straight from Python, you may struggle a lot with Rust syntax and semantics. There's just a lot to learn that doesn't exist in Python (speaking from experience). If you're just interested in just getting the job done, Python is probably you're best bet. If you're willing to be patient and want to learn a new language to become a better programmer, start learning Rust. There's a quote from Alan Perlis, "A language that doesn't affect the way you think about programming, is not worth knowing." Not that I know some great number of languages, but Rust is the first time that a _language_ has changed how I think.
&gt; I mean it is a general pattern if I, for example, say "the use jQuery indicates an outdated project or a programmer who has never learned JavaScript" in /r/programming people hate me for it but if I say the same thing in /r/webdev people agree. ...or some mixture of "need to support old browsers", "this API is the quickest, most concise way to do what I need", and "It's already a dependency for other things I use" (eg. Twitter Bootstrap).
Sure, but I doubt that the entire test is worthless. For better or worse I think ACID is still a useful, relatively accepted metric for comparing browsers. For the casual observer like me it would be handy to have a page reflecting the current ACID status coupled with what I can expect to change due to incompleteness, as well as why I can expect some things to never change, e.g. because the test is deemed bad or some technical cost the devs do not wish to pay. Bonus points for "here's a test we think is better and whether we pass it yet".
Ok i missed the livestream. Any chance to see a recoded version? I know its still running but would be cool if we could post a link here later :)
Can you come up with a version that compiles on play.rust-lang.org (or fails with the error you care about)? I'd like to answer but it'd be helpful if I could get compiler feedback.
Youtube lets you skip back through the entire stream, and later on it'll turn into a video automatically.
A couple of options: 1) Use a pair of channels for each bidirectional communication: https://is.gd/QCa7wv 2) Use a Future object that will eventually contain the result: https://is.gd/nfwQ7S (Note, don't use my crappy example implementation, use the [tokio](https://tokio.rs/) ecosystem instead)
But couldn't this also be the case with threads? If only one CPU is available, then won't the threads execute sequentially (or in an interlaced manner)?
https://hacks.mozilla.org/2017/04/hacking-contributing-to-servo-on-windows/ was published a few days ago by someone who was involved in a recent effort to get Servo working better.
I clicked on the link and sure got what I was expecting.
An* api
How do I use joystick events on windows? I found this crate https://docs.rs/joy/0.1.2/joy/index.html but the example doesn't look like it'd work on windows.
Anything on Freenode?
It seams that you have a termux 32 bits installation, that's why only armv7-linux-androideabi works. See the discussion here https://github.com/rust-lang/rust/pull/41152 The CA certificate error can be solves installing the package ca-certificates (`apt install ca-certificates`) and defining the SSL_CERT_FILE environment variable (`export SSL_CERT_FILE=/data/data/com.termux/files/usr/etc/tls/cert.pem`). Please check the command for typos. I will report a bug about rust-init failing to find the certificates.
As a C++ person myself, the impression I get from the community is that we think Rust definitely has the potential to become a mainstream systems programming language, but it's not quite there yet -- and, as long as it isn't able to perform arbitrary computations during compile-time, it'll never replace C++.
Thanks, that's good to know :)
Interesting discussion there, regarding OOM-killer vs DB transactions, etc. Thanks for digging that out.
I find [this](https://news.ycombinator.com/item?id=14082578) quite interesting: &gt; As an aside, I found a Reddit post the other day asserting that the Cyclone developers knew that it would never become mainstream but thought it was important because other languages would adopt it's ideas. It's amazing that they predicted that regions would be picked up later on by Rust. &gt; &gt; You can find it here: https://www.reddit.com/r/programming/comments/fmygi/cyclone_is_a_safe_and_functional_dialect_of_c/c1h6jkc/ The post is 6 years old: &gt; One of my undergrad professors was a guy who was in the group that started Cyclone. He readily admitted that the project was never going to see mainstream adoption, but he still thought he was doing valuable work because it could inspire somebody else to make something better.
"This video is unavailable." :-(
Thank you! I remember running into this when learning rust. These error idoims are common enough they should be included in learning material.
Yeah, :-(. It seems like Stanford doesn't leave the final video by the end. I'm trying to find if they put it elsewhere afterwards.
Only if we all clap really loud and *believe*.
&gt; On Linux due to the way virtual memory works, it may overcommit (give you memory it doesn't have) and pray you don't use it (aborting if you do use it before memory is freed up) so you will have this issue anyway because nobody ever checks for OOM on each heap access (I'm not even sure if this is possible) That seems like a rather poor design decision. Wouldn't it be better to temporarily pause the offending process while space is freed up?
Still waiting on integers as type params anywhere but arrays tho:(
I actually don't think that the *arbitrary computation* is required. In fact, (as a C++ programmer) I don't like template metaprogramming; what I like is all those constructs *implemented* with TMP, and TMP itself is quite a mess even today. C++ had a good argument to improve TMP, right, but I don't think Rust has to replicate that approach. To me the most important bits of TMP-like features for Rust are [type-level values](https://github.com/rust-lang/rfcs/issues/1038) (heck, even only integers will work) and [variadic generics](https://github.com/rust-lang/rfcs/issues/376) and anything beyond that should be done via procedural macros [1], which has been [greatly improved](https://github.com/rust-lang/rfcs/pull/1566) recently. [1] I'm not precluding the possibility of [compile-time madness](https://github.com/paholg/typenum) ;-), but I think they should not be a norm.
I added a bunch of issues on GitHub (there are others as `TODO` in the code). You can start with the ones with an `easy` tag. Just tell in the issue that you're working on it. Thanks for your future contributions :) .
It scared my cat but I think she's a believer now, too
I ended up using another thread. I figure that it can't be too bad, since it's mostly blocking. ¯\_(ツ)_/¯ - maybe if I get some time, I can try to understand fsevent and make a pull request or something, but this'll do for now. Thank you! I will definitely read up.
`Iterator` is basically an imperative re-expression of `Foldable`. After that it just comes down to the behavior of monoids.
Why Applicative as well as Functor? Iterator has `fmap` in the form of `map`, and `&gt;&gt;=` in the form of `flat_map`, but it has no equivalent to `liftA` nor `&lt;*&gt;`.
I.e. just like modern C++ with constexpr. An interprepiler. Man it would suck to write a C++ "compiler" from scratch these days.
There's no beef involved anywhere, I think ndarray is a great library. I'm just making an observation that I think Rust is capable of nicer syntax. You could imagine RustAlgebloat as constructing that Zip call via operator overloading and lots of traits, otherwise the idea is the same: the computations are done on the corresponding elements in the operands before being assigned to the destination element.
Yup! The next version is a bit of a change since it now uses tokio under the hood but once you get it set up right it's easy to use! Plus the use of native-tls is a big draw.
It kind of does, in that the first process to cause a page fault that can't be satisfied with physical memory isn't necessarily the one killed. The OOM killer uses a heuristic to choose the process to kill to free up memory.
It enables some nice optimizations. For example, you can allocate contiguous vectors you know will probably eventually be huge without using up physical RAM (or needing to realloc each time it grows). That use case in particular would probably be better served with more userspace allocator APIs that ask for virtual memory to be reserved for future allocation. These may even exist, I don't know. I can't think of anything that you can expect to exist on posix that does this (jemalloc probably has an API?). In general I guess it's a tradeoff. It makes it nicer for applications that are reckless with allocations, but this equalizes everyone and makes it impossible to be _careful_ wrt allocations. I suspect the former case is a lot more common. 
Why not bridge both IRC and Gitter to Matrix, then use both?
Unsafe Rust is harder than regular C++. Unsafe Rust strives to be perfect, where if it has a safe API that API should be able to accept anything you throw at it. Most similar C++ code does not do this, unless it's in a standard library (compare a naive vec implementation with `std::vector` or `Vec`). Unsafe Rust also has more kinds of UB. Not much more. However, if your goal is to teach unsafe Rust to show that Rust is as easy as C++, you've already failed because of this. Nor do we want to encourage unsafe to be the default thing people reach for. The reason "Rust is safe" is not just because it's written in 100% safe Rust, but also because the unsafe Rust used is quite tightly scoped. So we definitely want unsafe Rust to be treated as a big hammer. Especially because of the design patterns and XY problems. Folks coming to a new language often carry over their design patterns from other ones. They don't always work. Making unsafe Rust first class will mean that lots of folks will just continue with designing code the C way, even though a safe Rust design exists. I feel like this is a lot of effort and tradeoffs to mitigate a particular criticism of Rust. Yes, it would mean that folks would stop complaining about this, but at what cost? This isn't an actual learning block, it's more of a perception issue. Changing how we teach things to help folks learn is sensible to me, but changing how we teach things just so that folks will perceive the language differently is overkill IMO.
Gnome Builder has support for the RLS, though I'm not sure how complete the rest of the language support is.
If you want to teach an easy subset of Rust at first, I would just have people clone everything to start and slowly introduce borrowing. Unsafe isn't needed for the vast majority of things, and should be avoided when possible. Teaching it first is teaching bad habits before good ones and certainly seems backwards to me.
Great post! I didn't know `partition` before and had to 2 iterations to get both the `Oks` and the `Errs`. I wish there was a some kind of `filter_some` on `Option` iterators, I find the `filter_map(|x| x)` kind of pointless.
Can you use TiKV as a lightweight K/V store, or do you have to use it within the TiDB. Use Case: Offline storage for some app, sort of in the vein of pouchdb/couchdb or sqlite.
 let result: Result&lt;Vec&lt;_&gt;&gt; = results.collect(); Mind blow. I had no idea you could do this, this easily. This is great.
&gt; I wish there was a some kind of filter_some on Option iterators, I find the filter_map(|x| x) kind of pointless. It exists in a more general fashion in itertools, and is called [flatten](https://docs.rs/itertools/*/itertools/trait.Itertools.html#method.flatten).
Hi! We had more requests than expected so currently we are "full". Thank you very much for your interest. Should some seats become available again we will of course inform you here. 
&gt; The other two tricks (`flat_map` and `partition`) should hopefully be useful too, though! You didn't explain `flat_map` though... I mean I don't personally need an explanation, but I think you skipped over something there when writing your post \^\^
Well that's certainly how Rust works but I'm not convinced if it's a good idea to design the language in that way.
Yes, you can use TiKV as a distributed KV store. But we only have go client now. Here is an example: https://github.com/pingcap/tidb/blob/master/cmd/benchkv/main.go Java client is on the way.
Can one of the moderators un-remove the links please? I can't read the text posts as they are now 😣
I do lots of `clap`ping. You might even call me the `clap`piest :-)
If you're unfamiliar with audio processing like I am, this reads like complete gibberish. 
The pull request if anyone wants to see it https://github.com/servo/servo/pull/16198
For your particular use case, there's an [open issue](https://github.com/rust-lang/rfcs/issues/1926) for writing literal IP addresses. As noted in the comments, the new macro system should make this feature possible.
I think the progression of c++ and rust's integration with c++ will be the two deciding factors for how mainstream it could become. If rust can't interoperate with c++ then it's a non-starter in many areas because it eschews backwards compatibility. C++ will have modules in 2020, if some kind of borrow checking also drops then c++ -&gt; rust will start to look like a lot of work for minimal gain. However, if rust gets interoperability with c++ and the c++ standards committee don't move on some of rust's core improvements then incremental rewrites in rust could become quite popular.
I agree, if Rust wants to cater to all possible systems programming niches, it needs variants of box, Rc::new etc that can fail gracefully. that doesn't mean all interfaces of all containers etc should handle it nicely, but it should expose it in the same way C++ exposes an operator new that can return null, in addition to the throwing variant. Perhaps such a variant can be designed along with a placement-new variant, which is also currently missing
It actually had a small mistake. The correct version is: let result: Result&lt;Vec&lt;_&gt;, _&gt; = results.collect(); It should be updated in the post :)
Because I don't want to login to yet another chat thing.
One of the first things I wrote in rust was an assignment for a university lecture. It was to reverse an algorithm of a hackme binary, to find the input to get it to output success. First I wrote it in C and it worked on the first try. Then I ported it to Rust and it did not work because I had an off-by-one error that caused an out-of-bounds memory access. I think this experience was really important, but many people did not have an experience like that. All this reminds me a bit of the [story of Ignaz Semmelweis](http://www.npr.org/sections/health-shots/2015/01/12/375663920/the-doctor-who-championed-hand-washing-and-saved-women-s-lives) who got a lot of flak for telling doctors that they are responsible for deaths through their bad hand washing hygiene. So it probably really is just human nature.
Oh, plz go write that book. I would love to read it. (Rust for C programmers)
Maybe I don't understand, but isn't he looking for a GUI library rather than a graphics library? If that's the case, maybe glium isn't the best fit for his use case. Wouldn't something like gtk-rs be better? (Maybe using Glade)
`Peekable` gave the best solution. I was wondering if I was juggling pointers and assignment (current_value is `iter.next()`, next_value is current, therefore if you change current_value with another call to `iter.next()', you change next_value as well).
My personal experience playing with unsafe Rust: I found out how how tough it can be, specially when dealing with multi-threaded code. I got strange random SIGILL, SIGSEGV in code which appeared perfectly fine to me (sometimes the program/test executed perfectly fine and others it failed) and was almost impossible to track down using Valgrind and LLDB. That forced me to learn a bit more about how Rust works under the hood (but still do not comprehend that much!). The main lesson I got with playing with 'unsafe' is to avoid it at all costs whenever is possible, hiding it after safe abstractions (like the std lib does) and think very hard about what kind of things can go wrong using such unsafe code. This is taxing for you as you need to have a mental model about where the underlying data is being read, written and borrowed and at what times. The problem with unsafe code is the same problem you will have with C and C++ probably: you are making assumptions about how that code is being used, so once removed and safeguarding against the most obvious problems, you end up with subtle problems when the types involved fall off the use cases you have thought about initially if not enough safeguards are implemented (and that exactly what the std library safe abstractions do: implement enough safeguards while still retain performant data types). I use unsafe code occasionally, but when I do I ask the question: "is worth paying the price?", and depending on the kind of unsafe you are using the price is developing time, maintenance time and debugging time and polishing. Some unsafe is trivially easy to implement, but other can go wrong is many terrorific ways. One thing though, is that I doubt you can understand why some unsafe code is wrong without having a good grasp on how the ownership and lifetime models work in Rust; as many of the subtle behaviour depends on how the unsafe data types (those hiding data behind raw pointers) will be used in safe Rust (making it perfectly fine under certain circumstances and not so fine in others). Yes, there is value in understanding all that (a lot of value) but IMO there is a prerequisite in being able to understand it properly (and is a good grasp of the borrowchecker and lifetimes), otherwise you may just be writing C in Rust synthax, which is a very different beast. P.S: I must add that unless you are dealing with specific optimization problems which require pointer manipulation and arrays at low level most data structures can be implemented safe code, for example one usual complain are graphs. I've never had a problem implementing graphs in 100% safe code, you just need to use the smart pointers provided by the std library (which exist for all the reasons I wrote above, specifically: saving you the work of having to think about all the things that can go wrong using and referring to data hidden behind raw pointers, which is what unsafe code is in a nutshell). The same way in modern C++ you are probably using a lot of smart pointers too provided by std. Maybe then the question is: Do you understand well enough the data structure you are trying to implement so it can be done in a safe way (but this is not a problem of the language being learned)? An other question all together is: Can you do it efficiently (that will require unsafe code most likely), and that will require an advanced understanding of the language to implement it in a way that goes beyond a toy example (like an implementation of the std library would be, one that can be used safely under any or almost any circumstance and is effitient). But the answer to the second question will be the same no matter if you are using Rust, Java, C or C++. A non-naive implementation for a complex data structure will require a good understanding of the language in any circumstance, and a good understanding of Rust requires a good understanding on how safe code works (borrowchecker and lifetimes, the type system and some low level stuff like memory manipulation at low level like you would do in C).
That's quite an ambitious and interesting project! Good luck! How do you map tricesimoprimal notes into MIDI, which is strongly tied to the chromatic scale? Are you bypassing MIDI and also creating your own tone generators? As for getting started in GUIs, I don't know. I'm far from expert, and when I write (non-Rust) GUI code, I spend my time reading reams of documentation and trying a lot of stuff until something sticks. I wish I had a good tutorial (for any GUI) to point you toward.
Can't you just use your IRC client to connect to Matrix?
I was describing something similar a week ago https://www.reddit.com/r/rust/comments/63cl84/i_am_fighting_with_rust_is_it_worth_the_pain/dfu07sw/
To sum up what I see: detractors don't like the language because it is too different from what they work with. Some to levels of "it isn't in C, why did rust need it?" Promoters really love rust; primarily because it catches many programming bugs that would have been runtime exceptions in other languages. I don't know how you solve the detractors problems. Even with more/better users guides, some were complaining about closures, for example. Honestly, if you solve detractor concerns, you would end up with Dart. A java like language unused by almost everyone. People who want a new web language don't like it because it is so boring. And the people that are rust detractors wouldn't use it because it is too different from JavaScript. I hate saying there is nothing to learn here, but, yeah, there is nothing to learn here. Some people want to use COBOL, and everything that isn't COBOL is bad because it is too different.
Why don't you like TMP, exactly? If you're talking about the syntax I completely understand, as programming with templates looks and feels absolutely hideous, but, if not, what's so bad about the concept of being able to compute stuff during compile time when it makes sense? Sure, you could implement the stuff that can be done with templates in C++ as language features, but the point of templates (and TMP) is to provide a way to implement these features without extending the language. (Personally, what I like about templates, is that, unlike macros, I don't have to mess with the syntax at all for them to work) In any case, my main point was that Rust is not on par with C++ yet, but it's getting closer and it's the best contender for replacing C++ so far.
Any TL;DW for those who missed it?
Yeah, isn't filter_map(|x| x) (referenced in the article) just flat_map()?
Maybe simply adding `try_new(...) -&gt; Result&lt;Self, OOMError&gt;` method to `Box`, `Rc`, etc.?
See also [my response above](https://www.reddit.com/r/rust/comments/64n4zi/resultfreshnewmemory/dg47fgm/).
You could just allocate the whole thing using overcommit and lazily initialise it. If the user/program ever actually touches enough of the canvas to run the system out of memory _then_ you could kill the program with an out of memory error. If we want to restrict users to what is possible that can just be calculated up front. If you need 100GB of RAM and the system only has 4GB, then that check should be run up front, noone should be relying on allocation failure to tell them the system doesn't have enough resources.
A while back I tried something similar http://words.steveklabnik.com/a-new-introduction-to-rust not literally unsafe, but memory stuff first. some people really liked it, some people really hated it.
Thanks, my comment was indeed poorly thought.
Overall, I think it'd be worth a shot-- we definitely need more books and tutorials that teach in different ways to help people coming at Rust from any direction! Go for it! My first concern, though, would be that `unsafe` doesn't let you opt out of *all* the checks that Rust does-- if you use regular references in unsafe Rust, the borrow checker still checks those, for example. A carefully crafted path could defer these sorts of issues for a while, I suppose.
I think that would go a long way already 
I don't believe that's possible. You try to own and borrow a value at the same time. What is it you are trying to achieve?
As an aside, the book was never meant as a reference AFAIK. There is a separate reference [here](https://doc.rust-lang.org/reference.html).
System76 is using Rust now for automated testing and firmware flashing. I wrote these projects in rust, and I enjoy using it, can't say much about the other engineers.
I wanted to create a struct A containing a vec (A.v1) of struct B and a vec (A.v2) of struct C that contains references to struct B inside vec A.v1. The idea was that I use references (stored in A.v2) to access struct B inside a vec (A.v1) to have both fast access to the values and don't need to use reference counting. This is a better example: #[derive(Debug)] struct B { f: i32 } #[derive(Debug)] struct C&lt;'a&gt; { r: &amp;'a B } #[derive(Debug)] struct A&lt;'a&gt; { v1: Vec&lt;B&gt;, v2: Vec&lt;C&lt;'a&gt;&gt; } fn main() { let v1 = vec![B{f:1}, B{f:2}]; let v2 = vec![C{r:&amp;v1[0]}]; let t = A { v1: v1, v2: v2 }; println!("{:?}", t); } 
Well, alright, I'm just saying that "I don't want to log into yet another thing" doesn't make much sense since you would still use the same tools as you do now.
Not sure I can follow. What is it you want to achieve, in other words, what is your use-case? Do you have a less abstract code snippet?
Rocket makes it hard to right insecure code that bites a lot of users of other web frameworks. It does it via strong typing and request guards. A bunch of examples (of rocket, and of extremely common security mistakes it prevents) that I don't want to screw up. It was a good talk, which you'd need to be really familiar with content wise to reproduce here.
Definitely the best solution, thank you so much! One minor nitpick: In the future, the recommended Rust library may eventually change, so I'd specify `lib` here instead of `rlib`.
"First they ignore you, then they laugh at you, then they fight you, then you win." Well, that is one possible approach to people piling negativity on you anyway. If they're resisting fiercely, perhaps it's because you are close to success. Or maybe they have a Haskell allergy, who knows?
I read somewhere that using indexes isn't very rust-like and I'd personally avoid additional indirections. My hope was, that since both the borrow and its source were transferred to the instantiated struct, that this wouldn't violate the borrow/life time checker rules.
Language runtimes will often try a last ditch GC to free up memory rather than immediately aborting.
Take this more as a lack of motivation and a huge part of laziness.
You straight up can't do what you want to do. But you have a lot of options. You could try this crate. https://crates.io/crates/owning_ref You could use unsafe pointers. You could just use reference counting. You could just store index values into the vec.
`partition` really makes me wish that an `enum Either&lt;L,R&gt; {Left(L), Right(R)}` was in the standard library that Partition could work off of. Something like `let (oks, errs) = iter.map(Result::to_either).partition()`would have been nice...
Using indexes is fine-- check out [petgraph](https://docs.rs/petgraph/), it manages graph data structures using indices.
Well, folks, it's been a long day but I got it working. I reverted to a nightly from archives previous to when Arc was a mandatory requirement and also pre-dating cargo-building of std (really angry at the fact that Rust literally had a breaking change without proper semver, by the way), so I'm currently running on 1.13.x, which fits my needs for now. Will see if I can do some work to get the latest running later, but for now, it works. Steps: * follow joerg krause's stuff, use the following nightly: rustc 1.13.0-nightly (c772948b6 2016-09-20) * following instructions will work out of the box and patches should apply. I ran into an issue with the liblibc patch (unneeded since 1.13.x pre-dates the patch - effectively, it removes a build option for musl-based ARM builds, and I'm using glibc for now) * temporarily symlink /usr/local/bin/arm-linux-* to your toolchain (in my case, crosstools-ng-based toolchain) * compile * runs almost out of the box with proper env vars set For practical sake (and to save the sanity of my co-workers), I've also wrapped rustc and cargo to not need the envvars, but that might not be needed for most. I'll revisit this when I start wanting to run the latest Rust and a blog post will most likely follow, but for now, it's good enough to be able to build binaries for the hardware.
I made a simple web interface to sysinfo crate: [sysinfo-web](https://github.com/onur/sysinfo-web). This is my dream ~~system monitoring tool~~ process viewer. It is super lightweight thanks to rust. I am working on it to add more stuff like bandwith usage.
You could adapt [one of the implementations from the Too Many Lists book](http://cglab.ca/~abeinges/blah/too-many-lists/book/third-final.html)? The code in that library does look pretty old, though I think it's expected that there would be a lot of `clone`, because that's how you get another copy of a shared `Rc`/`Arc` pointer. (It just bumps the reference count, rather than copying the stuff on the inside.) [Edit: Are you sure it clones the data? What line are you looking at?]
Thanks for the suggestion. It seems promising! Regarding the cloning business: https://github.com/dpc/rclist-rs/blob/master/src/lib.rs#L66 contains the trait bound, without which the library doesn't compile. The calls to clone happen in line 69, 85, and 98. I think they do also clone the value of type T contained in the Node struct. The Iterator implementation also requires T : Clone, which makes even less sense to me.
u/krappie lists possible solutions of which I think indexing would be the simplest and most idiomatic. But if you really want to keep those references (or you don't control the `C` struct), you can use the [rental](https://github.com/jpernst/rental) crate, your `A` struct would look like: rental! { pub mod a { #[rental] pub struct A { v1: Vec&lt;B&gt;, v2: Vec&lt;C&lt;'v1&gt;&gt;, } } } (the *owning_ref* doesn't support this case, as it requires refernce to be just `&amp;'owner T`, not arbitrary struct, like `Vec&lt;C&lt;'owner&gt;&gt;`, as in this case)
&gt;That use case in particular would probably be better served with more userspace allocator APIs that ask for virtual memory to be reserved for future allocation. These may even exist, I don't know. I can't think of anything that you can expect to exist on posix that does this (jemalloc probably has an API?). Windows does exactly this with `VirtualAlloc`. You can explicitly reserve a huge blob of address space without committing it and then commit chunks of it it as needed. Hence why Windows doesn't have overcommit, because there's no need for it when you have a sane API for reserving address space.
I have never written any C++ (or C, or... Well, [insert language without GC here]...) so I have no idea what kind of work that would introduce, but my impression is that just kind of turning on borrow checking in any existing, un-borrow-checked project would cause all the things to explode and burn in bright, hot flames. Like, if you did that to any of the C# code I've worked on, for instance, the world would end and Cthulhu would laugh gleefully as you tried to run without dropping your pants. Do you see that as something that could be done as a compiler flag, or something that you'd need to opt into with some kind of region in the code, or... ?
Oh, I see. Sorry, I'm not really familiar with QML.
I know /r/rust isn't really for jokes, but I have to say that my very first thought in response was this: https://www.youtube.com/watch?v=d696t3yALAY
Asking in advance creates race conditions with other processes (and threads, I suppose), and ultimately you have the same issue to deal with, even if you're less likely to actually execute the code that deals with it.
Especially if the error was optimised to a null pointer internally, in many cases.
You might enjoy [this](http://web.stanford.edu/~engler/BLOC-coverity.pdf) paper I found recently while working on my thesis. It's written by some Coverity developers and they've seen some shit. There are a lot of C and C++ developers that simply do not know the language they're working in. Ignoring a linter is much easier than ignoring the Rust compiler.
It's something that'll never work, restructuring the average C/C++ code to please the borrow checker would almost require an entire rewrite. And even then, people will ignore the compiler flag because _they know what they're doing_. 
Perhaps a better approach is to say something like: &gt; Rust makes it easier to write *performant* code without worrying about safety Usually when you make something "safe", you throw in all kinds of mutexes to make sure everything is safe, whereas with Rust, you can have the compiler check whether you actually need a mutex and play around with options to eliminate sync points without worrying about safety.
Uh ... "Any sufficiently complicated news or blog article about programming contains an ad-hoc, informally-specified, bug-ridden, slow implementation of half of the '80s debates about Common Lisp"? 
Man, reading through that bug report reminded me why I'm glad Mozilla has the engineering talent it does...
A lot of high-end carrier &amp; datacenter routers run Linux with only a few gigs of RAM and no swap. These systems have thousands of features, not all of which can be enabled at once, so global and per-process memory utilization has to be tracked, often by a supervisor process that can proactively disable features and/or raises alarms if certain memory utilization thresholds are crossed. Even so, memory exhaustion can occur (example: too many routes are received from peers). At a minimum, if a process encounters OOM then a stack trace needs to be logged before the process is terminated, which means that an emergency log buffer needs to be pre-allocated. Datacom software is a perfect use case for Rust but this pattern needs to be accommodated.
awesome! I look forward to your feedback -- hopefully we can get something together that can enable rust to not just have an internal ecosystem, but also work with the external ecosystem without sacrificing the "rusty" API -- something languages like python have really benefited from.
Actually, I had Betteridge's law of headlines mixed up with Greenspun's rule of programming languages. But your version is better. 😅 # Greenspun's rule of headlines &gt; Any sufficiently complicated news or blog article about programming contains a poorly thought-out, informal reinvention of half of the 80's arguments for/against Common Lisp.
Zip is the objectification of the parallelization strategy. In that way it has to exist, even if the API would be different. I'm very interested in picking up ideas from other libraries. Blog about algebloat please, would be cool!
I worked on asyncio framework before it got included into standard library. From my perspective, tokio is very similar to low-level asyncio interface. I think to write async code in rust you need much more knowledge than for asyncio related code, especially if you use high level frameworks like aiohttp. So in general I think it is easier to reason about rust code, but that is only because you have to have deeper knowledge. 
&gt; sane API for reserving address space. mmap() with MAP_NORESERVE was available before overcommit was the default. 
I can definitely agree with the later parts; I have tried doing UI development outside the web platform (which is hard enough to do reliably already), but have always immediately stopped looking because *every* library/framework I have seen makes things really complicated. If I were to try again, I would first look at what can be done with [QML](https://www.vandenoever.info/blog/2017/02/17/a-simple-rust-gui-with-qml.html).
&gt; Making unsafe Rust first class will mean that lots of folks will just continue with designing code the C way, even though a safe Rust design exists. Why would these people bother with Rust then? What's the point of bending over backwards for a new language to write the same code you used to write in C? &gt; This isn't an actual learning block, it's more of a perception issue. I don't actually think this is fair. Rust has a learning curve like a brick wall - even most Rustaceans would tell you that, I think. It's possible (I think likely) that a lot of that comes from the fact that you can't get things mostly right. Unsafe *may* allow that to happen depending on the specific problem.
&gt; Wouldn't something like gtk-rs be better? (Maybe using Glade) Maybe. Though I don't know how to make gtk to behave the way I want.
It's true, it's the second Thursday of the month and we have another San Diego Rust meetup! Come on out and join us for a programming challenge -- and don't worry if you're not so familiar with coding or rust, we'll work in teams! Look over the starter repo, rusty-pong here: https://github.com/SDRust/rusty-pong Kindly started by Mike Welsh, https://github.com/Herschel! Thanks for giving us a kickstart!
Thanks
Is there a reasoning for aborting rather than panicking? Panicking would allow recovery within the process; to some degree.
Thanks, fafhrd91. In fact, I used aiohttp for my solution. I hate that I am the only one who can maintain it. Oh well.
&gt; Just working with pixels and then doing your own scrolling/etc keeps things simple. That's a good idea. But I worry about the perfomance: while gpu has parallel processing to make everything blazing fast, drawing on cpu should be done more carefully. 
Don't optimize too early. Slow code can be optimized later, but abandoned projects never get completed. Well, as long as your UI is reasonably separate from the rest of the program.
Related: [issue 29802](https://github.com/rust-lang/rust/issues/29802), providing some API for containers to not panic when insertions and similar operations fail. Nobody involved in the discussion seemed enthusiastic about doubling the API surface, but trying to have some sort of fallible allocator baked into the datatype doesn't seem great either. Firefox has done the latter in some cases, but nearly everything nowadays uses the former model, with separate methods that panic and return failure.
I agree that safety should not be the only pitch offered. I really liked to the "Rust is a fireflower" post (although, obviously, it takes some explanation) because of its emphasis on what Rust enabled, rather than on what Rust prevented. I also think different audiences are looking for different qualities. I think that "performance without worrying about safety" will work best with people dropping "down" to Rust from higher-level languages to get more juice, but I am not sure it would work that well with the C/C++ crowd. Rust is on par with C and C++, but it's not significantly better (performance-wise), so why convert the program? (And if you say "but it'll be safe"... you're back to arguing on safety)
Still waiting on proper array support :( *And by that I mean, I want to call `clone()` on `[T; 33]`...*
&gt; What's the point of bending over backwards for a new language to write the same code you used to write in C? The point to have some guarantees about your code. The code will not be the same as you would write it in C. &gt; It's possible (I think likely) that a lot of that comes from the fact that you can't get things mostly right. What did you try to do and couldn't get mostly right?
Modules are easy in comparison to borrow-checking I am afraid (and yet, they are still in flux). The first problem is that C++ does not have an affine type system, and neither does C. This is necessary for proper ownership-tracking. It's also insufficient. And I doubt it'll ever get there. Honestly; I sincerely doubt it'll ever happen. And given the extensive work it would take to convert a program to this paradigm... well, you might as well rewrite in another language it'd be the same cost.
Let's not get carried away. The tooling is in progress to be generous and the community is as much of mixed bag as anything.
Are you sure `chain` isn't `&lt;*&gt;`?
In general, the docs for doing this aren't great; I'd love to spruce them up, but since I don't do a ton of compiler hacking myself, I don't know all the tricks people use.
yay Carol and Nick! congrats to both of you!
That would be my least favourite option (even over the status quo). D's "two standard libraries" situation was a disaster for the language and the community around it.
&gt; [disposition: merge] extend ? to operate over other types. \o/ (I know it just means the RFC was merged, and not the feature itself, but I'm still excited to see this possibly moving forward)
Your intuition is right, but what's happening is that rust is doing "deref coercion" automatically to translate the references down to their referred values. You can read about it (and how to use the Deref trait to do great things with it) in the book [here](https://doc.rust-lang.org/book/deref-coercions.html).
Ah, too bad. Are there plans to change this, or is `as` going to remain kind of magic?
I don't know of any; `as` is really only meant for primitive types. `From`/`TryFrom` is really what you're looking for (along with their `Into`s); `i32` -&gt; `char` doesn't make a ton of sense, as `char` isn't signed. It's true that you can do that cast with `as`, but it's exactly the kind of cast `as` does, a very primitive "please convert these bits" rather than something more semantic.
That would be like teaching C backwards and showing programmers how to write safe code in C?! And we all know that would be a waste of time. On a more serious note, I think it's more important to encourage safe code. That is the point after all. As we make more examples of fantastic software in Rust, we'll get more C developers to see the light. However, I think Rust will grow more with new programmers than old neckbeards like me who are too stubborn to let go of their beloved C.
Usually if you get a pom error you can't handle it in your program anyways. At that point it's likely you can't even allocate a error or a print a stacktrace. Unless it was because you were trying to allocate a two Meg array, in which case there might be enough room left over. But normally oom is like a death rattle. Program death soon follows.
It's there because Linux buffers the shit out of everything but buffers are transient and lowest on the totem poll. So with overcommit Linux goes 'hold on a sec, let me clean house and see if I can get it'. Turning off overcommit is basically hamstringing everything.
This would actually be an excellent use-case for [`VecDeque`](https://doc.rust-lang.org/std/collections/struct.VecDeque.html) which supports fast insertions and removals at both ends, so you can use it as an efficient FIFO queue. Compare this to `Vec` which only has efficient insertions and removals at the far end. The other options have pretty bad cache locality and put more pressure on the allocator, which limits performance. 
&gt; Turning off overcommit is basically hamstringing everything. I won't deny that ensuring the memory is available does come with a cost. I won't deny that this cost is higher on Linux than on some other systems due to the way buffers/cache work (i.e. Linux is less likely to have completely unallocated ["free"] memory). I wouldn't call it hamstringing though, I would all it **fullfilling the contact of malloc()**.
No idea. Seems like it would be okay, though it may change the guarantees around unsafe code doing allocations.
I've just bought a MIDI controller (as someone with no musical background) and I have absolutely no clue what software I should be using it with, so maybe by the time I figure out what it means to have "31 notes per octave" (31??) this project will be far enough along for me to use. :)
&gt; Custom allocator APIs for the stdlib (think Vec&lt;T, FallibleHeap&gt;) that may potentially let you return Result instead have been discussed Yes, issue 29802. We are planning to implement InfallibleVec/InfallibleHashMap for Firefox because Rust's stdlib doesn't cater for this case. Which is annoying, but seemingly unavoidable.
I had made a [suggestion](https://internals.rust-lang.org/t/pre-rfc-panic-checker/4722) toward that end but it didn't gain any interest. It has a rather narrow use case so I'm not sure its worth the complexity. Best case it could be added as a lint.
At least some portion of it already appears to be C++? https://github.com/hunspell/hunspell Not sure if that's an in-progress rewrite or if it was already written in C++ and they want to update to a newer rev?
Should the information in this blog post be added to the docs?
It'd be nice if compiler hackers would get together to pool their knowledge/tricks to encourage and benefit newcomers, and have it be part of the official documentation.
&gt; having the C++ community go "Wow those rust people are so overzealous, always talking about safety"
I wouldn't like it. One reason to leave C is to avoid all the segmentation faults. Unsafe Rust would just keep them there.
https://twitter.com/carols10cents
Why donate to LLVM? Isn't Apple already taking care?
For people with no experience in C or C++, what Rust provides isn't safety, it's speed. The answer, for them, to "this borrow checker is so annoying! why can't I just do this?" is "because you don't have a garbage collector to cleanup after you". If you start with unsafe for these people, I could just as easily imagine them saying "why does my program keep crashing with memory errors? Rust is so dumb, it can't even do what it claims to do!"
My workflow is: - Edit one line - Build - Take a nap - Repeat &gt; add the bug as a new test in &lt;where should I put it?&gt; If you're testing that something should always compile and run, `src/test/run-pass`. If you're testing that it should fail, `src/test/compile-fail`. If you're testing that it should show appropriate help/errors in the CUI, use `src/test/ui` &gt; compile the stage0 compiler with ./x.py build src/libstd --stage 0 IIRC the stage 0 compiler isn't what you want, the stage 0 compiler is the snapshotted one. You want stage 1. ---- At some point I was going to expand the contributing file with tips for this, but I haven't really had the time to get back into mentoring rustc. However, #rust-internals on mozilla IRC is pretty helpful about this.
Presumably their devs have already learned C++...
Yeah but they take care for the Apple relevant stuff, OsX integration and so forth. It is still an opensource project after all, therefore it needs people to fix things/features on other platforms too. E.g. Windows support in lldb is really lacking, i remember trying to set up debugging with lldb on windows a few months ago and hit an awful lot of bugs.
This isn't " c++ developers are blah blah blah". I'm not calling those developers from those threads extremists. I'm saying that during those conversations it came up multiple times that people see rust devs as overzealous or get annoyed that people being g up safety too often. I'm bringing up a parallel issue demonstrated on HN
So Mozilla controls how and for what features the donation is spent?
&gt; really angry at the fact that Rust literally had a breaking change without proper semver, by the way [Tier-3 platforms](https://forge.rust-lang.org/platform-support.html) aren't included in the semver guarantees unfortunately. They aren't even guaranteed to work. Platforms can be moved up-tier if there is CI capacity for them and someone who can maintain them. (I'm not on the Rust team but I think that's the policy) ------- As for the path forward ARMv5 can support atomics using the [linux user helpers](https://www.kernel.org/doc/Documentation/arm/kernel_user_helpers.txt) mentioned above. Support for these can be added to libcompiler-builtins. Right now, the complier-builtins included with rustc is a thin wrapper around LLVM's compiler-rt, written in C. There's [an effort](https://github.com/rust-lang-nursery/compiler-builtins) to port this to rust, which is currently workable due to filling in the gaps using the old C implementation. [This PR](https://github.com/rust-lang-nursery/compiler-builtins/pull/115) adds support for the linux user helpers to this. To hack these changes into rustc: 1. Build a rustc cross compiler with the target definition for armv5 changed to support atomics. Edit: or use a target.json that has `max-atomic-width: 32` 2. Build a stdlib with that compiler that uses the compiler-builtins from the PR above. 3. (possibly more things) I have started making these changes to test it out: https://github.com/mattico/rust/tree/compiler-builtins Edit: Another thing-in-progress that is relevant is the effort to make std more configurable, to e.g. work without atomics or floating point. I can't find a link. I think there's an RFC or an internals thread somewhere...
I store my bicycle just straight inside my house, and so should consider a bikeshed at some point... Completely unrelatedly: &gt; https://github.com/rust-lang/rust/pull/41092 The naming of these seems surprising: the multithreaded functions (and both the single and multithreaded intrinsics themselves) are `fence`s, but this is a `barrier`. It's not incorrect, but the latter is both inconsistent with the existing functions and slightly confusing with [another type in `std`](https://doc.rust-lang.org/std/sync/struct.Barrier.html). Alternatives would be the "obvious" `compiler_fence`, or C++'s `atomic_signal_fence`, or `singlethread_fence` (or `fence_singlethread`, etc.).
Development? In all seriousness tho, IIRC they didn't really say specifically what it would go to last time when they received 30k, so I wouldn't hold my breath.
I know the answer to this question, but I don't think I can share it. It's nothing to be worried about.
I mean, I'd hope it's going toward development. With $50k, you could pay somebody to work on the library full time for ~6 months. You could also buy physical servers for performance testing. There's lots of stuff they could do with that kind of money. As somebody not involved with the project, I can't really think what their current expenses even are.
The 50k is definitely going towards development. &gt; you could pay somebody to work on the library full time for ~6 months This is unrealistic. Junior devs can easily make over 6 figures annual salary, and that doesn't include things like health insurance and other overhead. Consider that the money is going towards a very senior developer, it will not buy nearly 6 months of dev time. &gt; As somebody not involved with the project, I can't really think what their current expenses even are. Sponsoring development. That's it! This makes sense when you step back though. One of the biggest complaints in the most recent Rust survey was about holes in the library ecosystem. By giving this grant for tokio development, Mozilla is literally "throwing money at the problem". I for one am thrilled to see the continued sponsorship.
no, thanks!
Why does the borrow checker disallow mutable borrows inside a method call? It's a little complicated to explain, so I'll post some code. let mut graph = graph::new(); //add nodes a and b graph.add_edge(node_a, node_b, Edge { bar: foo(&amp;graph) }); // foo returns some calculated f32 This errors because graph is borrowed mutably, then I try to borrow it immutably with &amp;graph. However, the following works. let mut graph = graph::new(); //add nodes a and b let baz = foo(&amp;graph); // foo returns some calculated f32 graph.add_edge(node_a, node_b, Edge { bar: baz }); Should the borrow checker not recognize that in the first example, the immutable borrow ends before the add_edge method is ever called on the mutable borrow? Or are there cases where this would be unsafe if foo is known to return an non-reference-type value?
TOKYO BABY!!!
I personally haven't tried anything with server-sent events, but it looks like https://github.com/mikeycgto/esper is a project using `hyper`'s Handler to do this. Looking at it, 'esper' seems to be a very simple pub/sub service using server sent events, so I would recommend checking it out for examples on how to do this with hyper! note: I have used hyper for client side stuff, it is currently my 'go-to' http / web crate for both servers and clients - many other web crates also use it as a base.
well now they'll feel obligated to help where required
From the 5 minutes that I looked at it, it looked like they had very low level rust bindings, equivalent to the C bindings. But if you're like me and you have no idea what you're doing, you'll find that all of the documentation that you read is for the high level library functions of tensorflow that seem to only exist in python.
Why not using `u16` instead of `u32`? For `rank_straight`, have you tried comparing several masks at once using simd crate? For instance you could probably use `u16x8`?
Which makes me wonder why the heck they ever added overcommit and then made it the default.
Sounds like you might want https://github.com/BurntSushi/chan Serde or RustcSerialze for JSON Serialisation. For the Server-Sent events, you'd probably need to build something using Tokio or Hyper to handle that, there is a [library](https://github.com/kchmck/uhttp_sse.rs) you could try too. You're going to hit latency spikes with TCP that may be unavoidable. If you do decide to go down the Java path, have a look at Apache Camel installed within a Karaf container, with a ActiveMQ or [Apache Kafka](http://camel.apache.org/kafka.html). It should be able to handle the loads you're asking for easily. 
Oh this topic again, this comes up every x months in /r/node and every time, people complain only about memory usage and chrome. So i don't take it very serious u should assume a desktop has 4GB-8GB of ram nowdays and i very happy to have Discord, Slack, Atom, VScode and the simplicity of electron instead of fiddeling with Qt
Follow-up question: Is the vector `v` immutable, and does it outlive the reference? * If `v` is immutable, then you can store the `v` and the reference in separate structs. This leads to a design where you have a collection of `Vec&lt;i32&gt;`s and a separate collection of references. * If you only need to add immutable members to `v` , then I believe that you can use an `Arena`. * If you also need to remove and/or mutate elements of `v` then follow advice from other posters (indexing sounds fine)
You should check out /r/playrust
I wish AWS would step up and help with Rusoto. They haven't offered us an account to use for integration tests, either, which seemed like it would be a nice gesture given that we're basically doing their work for them.
Ob seek qwee ous ness. That should help you pronounce it!
If they are helpful, you can check out [timely dataflow](https://github.com/frankmcsherry/timely-dataflow) and [differential dataflow](https://github.com/frankmcsherry/differential-dataflow), both of which are relatively high-performance stream processors. Your choice of how to represent streams probably comes down to whether you have any design constraints. If each stream has a single consumer, probably no need for `Rc`. If you want latency over throughput, a linked list is probably better to avoid re-allocations. The timely and differential implementations go for shared queues (`Vec`, `Channel`, and a tcp implementation, for thread-local, process-local, and remote connections) of batches of data (batch: `Vec&lt;T&gt;` of bounded length). The batching amortizes the cost of data movement across multiple records. You can also just use timely dataflow to prototype your language. Depends which part you have the most fun working on, I guess!
&gt; the guest was obviously very under/misinformed about Rust In what way?
Looking at slog_scope I think it's time for me to jump into slog bandwagon :-) Very useful when you're not really into the original philosophy.
It appeared he wasn't familiar with Rust other than vaguely knowing it existed. [Here's the episode - LLVM with Morgan Wilde](https://softwareengineeringdaily.com/2017/04/10/llvm-with-morgan-wilde/)
The author gave a supposedly similar talk on Rocket at Mozilla's Rust Meetup of March 2017. Check the Mozilla Videos Site (am on mobile, sry).
Yeah, I agree. I am not 100% sure if it is the right way to help new comers and their questions, but we'll see how it works. Maybe it can help some people or not. Either way it harms no one by existing on it's own. I will add links to other specific subs, book and SO some time. 
More info: https://github.com/cmr/this-week-in-rust/issues/425#issuecomment-293505300
It's not even that. The RFC is in its final comment period, so everything might still change. But the maintainers like what they see; they have a disposition/an inclination to merge the RFC in its current form. Still, yay! :)
I'm reading the Esper source, but it looks like it might be using an older version of Hyper. In particular, its [implementation of hyper::server::Handler](https://github.com/mikeycgto/esper/blob/master/src/handler.rs#L63) has a different set of methods to this in [Handler today](https://hyper.rs/hyper/v0.10.7/hyper/server/trait.Handler.html). It's very possible that i'm confused here, though! I also can't get it to build with current or recent nightly - some problem with docopt_macros :(. Still, it's an informative read.
If the entire structure is immutable, then I believe that you can also do the following (but I never tried it... se also reply by CrystalGamma) https://www.rust-lang.org/en-US/faq.html#how-can-i-define-a-struct-that-contains-a-reference-to-one-of-its-own-fields 
Thank you! I mostly wanted to decide if I want to watch this sometimes or not. I guess I will.
Ahh sorry, I meant that adding these functions would do a lot to improve rust even if it might not solve all problems yet
Thank you! I agree.
You could either do an `Arc` with a [RwLock](https://doc.rust-lang.org/std/sync/struct.RwLock.html) which would allow you to access the same object concurrently in a read only fashion, with one Writer. Pretty much a single producer, multi consumer type fashion. Conversely, if you passed around a `String` to each consumer, as it's already allocated, you could simply use the [into_bytes()](https://doc.rust-lang.org/std/string/struct.String.html#method.into_bytes) method and get access to the raw buffer, which is a zero-copy, but will `consume` the `String` so noone else can use it. You could simply send that String straight on the wire with that method. Either way you will be allocating memory for the Socket buffer to send to the consumer at some point, so if you already have a buffer pre-allocated, it might be easier to use that. I've personally used Rust Serialize and had more luck with its relative simplicity. Serde is more powerful though, but I couldn't get [bincode](https://github.com/TyOverby/bincode) to work with it for some odd reason. Unfortunately without benchmarking I am not sure what would be faster (Pre-optimization is the root of all evil!) I'd hazard a guess that it would probably be the Arc method, but then again, the lock contention may actually slow it down. I've had great success with Camel, but you're right It's probably more suited if you're reconfiguring stuff dynamically (I.e, an ESB) as opposed to a finely tuned process which is what your Use case is aimed at. You get some cool stuff for free, like a [web interface](http://hawt.io/) for tracking exchanges, and being able to swap out consumers/producers at will. Only issue is Karaf as an OSGi container is a bitch at times.
Thanks for your comment! I sometimes look at QML for inspiration. I'll look at this `QAbstractItemModel`. I try to reduce the cost of this library. Since it is currently multi-threaded, there is some cost related to the shared context. But when I'll switch to [futures-glib](https://github.com/antoyo/futures-glib-rs) (which will make `relm` single-threaded again), most of the allocations will be gone. The only remaining allocations will be to communicate between the different relm widgets.
See https://github.com/rust-lang-nursery/rustup.rs/issues/1051 https://github.com/rust-lang-nursery/rustup.rs/issues/1055 and https://github.com/rust-lang-nursery/rustup.rs/issues/1058
&gt; But they should say that because they could attract more donations This.
&gt; This is unrealistic. Junior devs can easily make over 6 figures annual salary, and that doesn't include things like health insurance and other overhead. Not everyone lives in bay area.
Heck for that job I'd move to Romania.
Great work! I've been thinking about making something very much like this (even down to using tokio) after working with gtk-rs for a few months. I love it when I find out somebody else already did what I want. My biggest pain point with gtk has been the issue of state mutation and callback closures, just as you described. This looks like a really nice solution.
Stack Overflow has standards for what questions are appropriate, and newbie questions won't all be in the accepted format. For example, "which crate is best for X purpose right now?" will get closed as off-topic pretty quickly on SO.
Not really specific to your code, but one of the things I've been wishing for on the topic of data structures is if someone created and maintained a single repository/crate for e.g. all the different ways of implementing heaps/priority queues with roughly the same abstract interface - binomial heaps, fibonacci heaps, anything that's worth implementing somewhere. Reason being that a) the different algorithms do have things in common, they'd be able to share a fair amount of code and more importantly, just having all the code in one place means people will spot good ideas in one implementation and apply them elsewhere. Collecting up related code in one place so you can see the similarities and differences really does aid in understanding and improving it. b) there's often subtle performance tradeoffs, having all the different types of heaps in one place would make it really easy to switch between them in your application depending on which is best, and would also make it easier to benchmark and find out which is best. Oh and it'd make it a lot easier to get everyone to standardize on the same trait/public interface.
I don't think OP meant that new rust programmers should be taught to default to unsafe code, not at all - at least that is not what I would assume. Instead, using concepts in unsafe rust enables the programmer to reason about the code with a _familiar_ vocabulary. For instance, I had not dabbled with anything in the realm of functional code until I started to read about rust. Some concepts felt very alien to me, and it would have been simpler and more efficient to read how rust works at the memory level, instead of introducing high level concepts one after another and leaving the programmer to mess around with a debugger to try and learn what the program was _actually_ doing by reading the assembly. Everyone learns differently, and I don't think it is a good idea to try to hide some aspects of the language (and thus make it harder for others to learn) just in hopes of preventing others from burning their fingers. All the features in the language exist for a reason, and it makes sense to teach people to know them so that they can utilise those features when the need arises.
Thanks for the feedback! * Yes I implemented the lazy version. * I don't understand how it is unsound. It does assume that you give correct indices into the data structure (so that e.g. noone invalidates the indices you got) and panics if that is not the case. Do you mean that correct calling could cause panics? * That's one of the things I'd like to try as well. (My friend said that he wanted to implement a cache efficient binary heap and then we wanted to compare the 3 versions in benchmarks, not sure when we'll find the time)
&gt; I don't think OP meant that new rust programmers should be taught to default to unsafe code, not at all - at least that is not what I would assume. I know. But teaching these things first will lead to many folks defaulting to unsafe, especially when unsafe lets them reuse patterns from other languages which may be antipatterns in Rust. We're not hiding aspects of the language. Unsafe gets taught eventually. But we expect people to be comfortable with the rest of the language and understand the last-resort nature of unsafe. It's not about burning their fingers; it's about permanently getting ingrained with antipatterns. The features in the language exist for a reason; and that reason is some very specific use cases. Just like SFINAE exists in C++ for some very nice use cases. You do not teach SFINAE first, nor should you teach unsafe first. Nobody is arguing _not_ teaching unsafe. The question is if it should be taught first.
Learning Rust was very hard in the beginning for me. It really takes time to become productive with it. It hurt my tiny but inflated ego too. Every time I left it for feelings of inadequacy, and every time I came back for its promises and strong guarantees about quality software. The community is also praiseworthy of course. Now I finally get what ownership, borrowing, and lifetimes are. And I love the borrow-checker and compiler in general and Cargo and crates.io. I am yet to become truly productive in Rust. But I have no doubt I'll get there this year still.
&gt; I wouldn't say that it's only about the ego, you could also view it as some kind of evolutionary strategy to save energy. Absolutely. About 6 months ago my team got a demo of a tool that had the potential to bring significant new capabilities and reduce the amount of code we have to write and maintain. We have not (yet) done anything with it because the key word there is ***potential***. In order to really evaluate the value of the tool we have to sink a large amount of time and energy into it, which is time and energy we then can't put towards our current workload.
yes, that is my twitter... ?
For now all I hope if for people to join and learn from it. I actually created it when I myself heard about rust and was looking for a place to get answers for basic questions. I didn't think through about what rules I would set up or not. It was a quick reaction-based decision. Sadly I didn't have the time as I hoped to learn rust or moderate the page, if you I can make you admin too
Just to add: If anyone is interested in becoming a moderator, PM me .. I will send you an invite
When should we use &amp;str vs String? Much ink has been spent on this issue, but I still don't get it yet
Adding more build bots to https://github.com/mcandre/ios7crypt-rs so cross-platform binaries are easier ta publish
&gt;This is unrealistic. Junior devs can easily make over 6 figures annual salary, and that doesn't include things like health insurance and other overhead. In Eastern / Central Europe 50K is more than average senior earns a year.
&gt; newbie questions to stack overflow. It is designed for that purpose I'd disagree with this characterization. SO [bills itself](http://stackoverflow.com/tour) as "a question and answer site for professional and enthusiast programmers." True newbies need a lot more hand-holding than I'd think is appropriate for Stack Overflow. Namely, it's expected that [you show you've put a lot of effort in before asking a question](https://meta.stackoverflow.com/q/261592/155423). Things covered by the book or Rust by Example fall squarely into this camp. No one needs a SO question like "what's the syntax for an `if`?" &gt; and also gets us attention on programming language popularity indexes such as tiobe I'm all about silly metrics, but saying that we should funnel people asking questions to SO for the purposes of improving our ranking seems all kinds of wrong. This feels like the equivalent of SEO spamming. Let the questions come naturally, produce good content, and the popularity and true mindshare will be won.
Fair enough. I've had the same learning experience. It's a slow process, but that also means lots of eyeballs tend to look at things. Yeah I could implement this in an hour and submit a PR, but it's good to be careful with decisions lots of people will get stuck with forever.
&gt; What's the point of bending over backwards for a new language to write the same code you used to write in C? For one thing, it can in principle enable a new set of compiler optimizations. 
That seems right, so are you sure your setup is exactly as you've described it? Clearly it isn't a direct copy/paste since you'd get a different error about `#[mod_use]`. Wild guess: you have both lib.rs and main.rs, and the error actually comes from compiling main.rs?
That's a bit more optimized version of something I was just working on. Thanks so much!
&gt; why would someone ask what the syntax for an if is... ever? That material is in the book. I can't answer the *why*, I can only say that there's a higher count of questions than I'd expect that boil down to this exchange: OP: How do I do X? Me: TRPL chapters X and Y discuss that, which aspects of that are confusing? OP: Oh, I don't read the documentation. I prefer to write code first, ask questions later. "Documentation" can often be replaced with "API docs", "crates README", "other SO questions", etc. &gt; wonderful mods and teachers like yourself Flattery will get you everywhere 😊 
Since there's been a lot of interest here, I wanted to spell out in a bit more detail what's going in with funding at Mozilla. First off, the grant linked here is part of MOSS, which is run totally independently of the Mozilla Rust team, but has been very supportive of Rust. In addition to that, though, the Mozilla Rust team awards contracts, grants and internships more directly. We haven't tended to make a lot of fanfare around these in the past, but the general strategy has been to support people who have been doing amazing volunteer work so that they can do that work full time for a stretch. That's covered work from eddyb on the compiler, Integer 32 on crates.io and Rust training, dtolnay on Serde and other library work, jseyfried on the new macro system, carllerche on mio and Tokio, and withoutboats on a variety of topics -- and that's all this year! Beyond that, we have academic grants for research into Rust for HPC (really large-scale servers/clusters), and foundational work around the unsafe guidelines/formal semantics for Rust. In general we have a preference toward supporting people who are already doing great work in the ecosystem, rather than continually expanding the internal Mozilla team. We want Rust to grow and find support far beyond Mozilla, and this is one way of nudging things in that direction, while bolstering the ecosystem at the same time. While we've awarded almost all of our contracting money for this year, please feel free to reach out to me at aturon@mozilla.com if you have interest in small (~3 months) contract work to help push a piece of the Rust ecosystem (or tooling, or docs, or ...) over the finish line.
Help from AWS would be excellent. Thankfully running these integration tests don't cost too much so it's not a big deal, but it'd still be nice to have a $20 a month budget to spend on integration testing. I worked at getting a test account for Rusoto [for months before getting a rejection from AWS](https://github.com/rusoto/rusoto/issues/222).
Thanks that helps it make more sense. Another question, is it possible to use cargo as a lib? So if I was writing a cargo subcommand could I add cargo to my dependencies to access parts of it's core package etc.? EDIT: Might have been premature with asking this I think I've found it and the answer is yes https://crates.io/crates/cargo
Nicely done. Having never programmed in Elm before, this reminds me a lot of how `redux` in the javascript world does state management and GUI updates (in combination with `react`), which is also inspired by functional programming. I really like that style of GUI programming, but I wonder how bound `relm` is to `gtk`? Could I easily write other backends or use my own and just lend that nice functional modal and message logic?
This removes the Box layer: pub fn foobars(&amp;self) -&gt; Vec&lt;&amp;SomeTrait&gt; { let mut foobars: Vec&lt;&amp;SomeTrait&gt; = Vec::new(); for foo in &amp;self.foos { foobars.push(foo); } for bar in &amp;self.bars { foobars.push(bar); } foobars }
So I'd like to compile an example, but unfortunately I just don't have enough experience to do that. I've got nightly installed. What should I run to view the buttons example?
Yup! That's it. It's why Cargo is pre-1.0; there's no guarantee of stability in these APIs.
Not yet. That's one of the next priorities after MVP though
It makes sense that it is familiar, given that redux is highly inspired by the elm architecture.
The current approach would be to use WebWorkers for individual Wasm modules. As /u/ElvishJerricco already noted, [threads are a planned feature, high on the list](http://webassembly.org/docs/future-features/#threads)
Especially thanks to pcwalton, who does great work. Atleast from what a developer from the outside can see here on reddit, he did a lot of good work on rust :)
Yes, but I'm getting immutable rerference to mutable reference, so I thought I can get to mutable object after two dereferences. If I can't, then what is the difference between &amp;&amp;i32 and &amp;&amp;mut i32?
Look at Ottawa. Especially since you're bilingual. 5 years ago Alcatel-Lucent (now Nokia) was starting 3rd level support techs at $60k CAD
While trying to find the minimum setup that still causes the error, you were totally right. In main.rs, instead of `use gui;` I had `mod gui;` which the compiler didn't like. So, it really had nothing to do with the `use glium;` line, I was just re-declaring `mod gui` in the binary. Thanks for the help!
&gt; So yes, the compiler could infer lifetimes. Wouldn't this also require global analysis of the code and potentially exponential runtime when trying to determine the lifetime of function arguments? And if there are cases where there are multiple different lifetime assignments that work (which can be possible, I think), how should the compiler pick between them? The loosest? Tightest? Can these be unambiguously determined?
`relm` does not currently work on Windows: see this [issue](https://github.com/antoyo/glib-itc-rs/issues/1).
Just use the following command: cargo run --example buttons
Awesome! How does Relm know what update-function should change (in the example, it inserted `label.set_text(...)`)?
Same here. I'm thankful every day that I have `rustc` to yell at me and tell me where I'm wrong, because it means I learn habits that I keep when writing C and the compiler will let me do bad things and fail later.
I've tried to make something spiritually akin to ReduxJS, as in, a library that allows you to register 'handler' for events that you can then use to change some specific state. Everytime it is then updated you get a new 'state' of the store, allowing you to write side-effects free handlers and keeping your data management simple.... At least in theory. I have a working example: https://github.com/TheNeikos/reduxide/blob/master/examples/todo.rs state! { TodoState, [ todos: Vec&lt;Todo&gt; &gt; TodoAction &gt; todo_reducer ] } fn todo_reducer(state: &amp;mut Vec&lt;Todo&gt;, action: &amp;TodoAction) { use TodoAction::*; let max_id = state.iter().fold(0u64, |acc, x| if acc &gt; x.id { acc } else { x.id }) + 1; match *action { Add(ref st) =&gt; state.push(Todo { text: st.clone(), completed: false, id: max_id }), Delete(id) =&gt; state.retain(|x| x.id != id), Edit(id, ref st) =&gt; { for todo in state.iter_mut() { if todo.id == id { todo.text = st.clone(); } } } Complete(id) =&gt; { for todo in state.iter_mut() { if todo.id == id { todo.completed = !todo.completed; } } } CompleteAll =&gt; for todo in state.iter_mut() { todo.completed = !todo.completed }, ClearCompleted =&gt; state.retain(|x| !x.completed), } } let mut state = TodoState::new(); let mut siv = Cursive::new(); siv.set_fps(30); let sink = siv.cb_sink().clone(); let sub = state.subscribe(); let (tx, rx) = channel::&lt;TodoAction&gt;(); let tx_c = tx.clone(); let tx_d = tx.clone(); let tx_e = tx.clone(); siv.add_layer(Dialog::around(LinearLayout::vertical() .child(EditView::new() .on_submit(move |ref mut s, new_str|{ tx_c.send(TodoAction::Add(String::from(new_str))).unwrap(); let mut entry = s.find_id::&lt;EditView&gt;("todo_entry").unwrap(); entry.set_content(""); }).with_id("todo_entry")) .child(ListView::new().with_id("todo_list"))) .title("Todo List") .button("Complete All", move|ref mut s| { tx_d.send(TodoAction::CompleteAll); }) .button("Clear Completed", move|ref mut s| { tx_e.send(TodoAction::ClearCompleted); })); However, the usage in callback heavy code itself is rather cancerous, you have to clone things around all the time and the compile errors are very misdirecting. Is there a better way to achieve this?
&gt; Small nit, lifetimes are not higher-kinded. They can be higher ranked, but it's used so infrequently that while writing the chapter in the book on this topic I actually struggled to define a function where the annotation was required, and at least one member of the language team has said that they feel that should pretty much be the case. Also uh i just cut that section
Looks good, nice to see some progress in this area! I have a question: Update takes both a `&amp;mut self` and a `&amp;mut Self::Model`. Is there a technical reason to have a model at all, or is it just to encourage an MVC pattern? I mean, could one just as well have it this way: struct Win { counter_label: Label, window: Window, counter: i32, // Model is here } type Model = (); 
The unwrapping step can't compile away. Depending on what you're storing, `Option&lt;T&gt;` might have the exact same size and memory layout as `T`, but you still always have to look at it and see what it is. The queue is using `Option` to indicate whether it did or didn't have something in storage. *Maybe*, if the borrow checker is absolutely confident in how your queue is accessed, the compiler will be able to state that all calls to pop will succeed, but I wouldn't count on it. Unwrapping is cheap. I wouldn't worry about the Some/None matching here, and `.unwrap()` is essentially a statement that you're confident there will always be a Some() and you're willing to blow up in case something goes terribly awry.
AIUI, isn't `as` just a safe `mem::transmute` that may have actual work to do?
It's here: https://air.mozilla.org/rust-meetup-march-2017/#@1h23m34s
Thanks for the reply! I agree that describing the behavior directly in the signature is better, but to me right now it feels like the benefits aren't worth the costs... -- Take the following code: trait Trait1&lt;'a&gt; { type AT; } trait Trait2 { type AT; } impl&lt;'a, T&gt; Trait2 for T where T: Trait1&lt;'a&gt; { type AT = T::AT; } This doesn't compile: the impl requires `Trait2` to have an explicit lifetime as well. Some RFCs are trying to address this problem, for instance [Associated type constructors](https://github.com/rust-lang/rfcs/pull/1598). If I cannot change `Trait2` (e.g. because it belongs to `std`) I'm stuck. This situation would not be an issue (and wouldn't require extra syntax) if lifetimes were implicit. It's not an issue neither in C++ nor in high level languages. How do experienced people deal with it? -- I've noticed a few things in `std` that I believe might be at least partially due to this kind of issues with lifetimes: 1. Very few traits in `std` have an explicit lifetime. Take [`Index`](https://doc.rust-lang.org/beta/core/ops/trait.Index.html) for instance. It can only return references, not owned values. In order to be able to return anything it would have required some explicit lifetimes, and I think that they preferred a sub-ideal `Index` rather than explicit lifetimes. 2. Many items in `std` replicate a lot of code. Take for instance `Iterator` and `IntoIterator`: the standard way to define an iterator for a type requires you to define 3 different iterator types very similar to each other. That's what *every* iterator in `std` does. I've tried to implement one single generic iterator for a type, and one of the main obstacles I met was explicit lifetimes. 3. A common complain I've read about `std` is that many traits that should be there are missing. The standard answer is that they want to be sure that standard traits are done the right way. My belief is that most traits would be very easy to define if we didn't have constraints on explicit lifetimes, but due to lifetimes the decision to make is hard (again, just think of `Index`). ^(I'm absolutely not an expert of rust and have followed its development only for a short time, so I might have said something completely stupid, and if so, I'm sorry.) -- To summarize, I think that lots of traits aren't ideal (or aren't there at all) partially because of constraints on explicit lifetimes. The situation could improve a lot either using some higher-* features, or alternatively by just dropping mandatory explicit lifetimes. -- If at least part of what I said is true, would explicit lifetimes still worth it anyways?
I cannot figure out why the following will not compile: https://is.gd/0yws4n use std::cell::{RefCell, Ref}; use std::slice::Iter; struct Vector { data: RefCell&lt;Vec&lt;f64&gt;&gt;, } impl Vector { pub fn new(data: Vec&lt;f64&gt;) -&gt; Self { Vector {data: RefCell::new(data)} } pub fn get_data(&amp;self) -&gt; Ref&lt;Vec&lt;f64&gt;&gt; { self.data.borrow() } pub fn iter(&amp;self) -&gt; Iter&lt;f64&gt; { self.get_data().iter() // Fails with `self.get_data()` does not live long enough } } fn main() { } The full error is: rustc 1.16.0 (30cf806ef 2017-03-10) error: borrowed value does not live long enough --&gt; &lt;anon&gt;:18:9 | 18 | self.get_data().iter() | ^^^^^^^^^^^^^^^ does not live long enough 19 | // Fails with `self.get_data()` does not live long enough 20 | } | - temporary value only lives until here | note: borrowed value must be valid for the anonymous lifetime #1 defined on the body at 17:36... --&gt; &lt;anon&gt;:17:37 | 17 | pub fn iter(&amp;self) -&gt; Iter&lt;f64&gt; { | _____________________________________^ starting here... 18 | | self.get_data().iter() 19 | | // Fails with `self.get_data()` does not live long enough 20 | | } | |_____^ ...ending here error: aborting due to previous error
So for all practical purposes &amp;&amp;i32 and &amp;&amp;mut i32 behave the same? Then why they are separate types? Can I have function that accepts &amp;&amp;mut i32 but not &amp;&amp;i32? If so, what things it can do which one accepting &amp;&amp;i32 can't?
What? No. None of this is correct at all. If you have a reference in a struct you need explicit lifetimes. That's not wrong nor is it OOP.
&gt; Take the following code: This example wants more lifetimes, not less. That is, if lifetimes were inferred here, this *still wouldn't compile*. This is because Rust doesn't have associated type constructors. Inference doesn't mean that anything possible is accepted, it means you don't have to write things out as explicitly. &gt; It's not an issue neither in C++ nor in high level languages. I mean, languages that don't have a feature aren't gonna have issues with a feature, sure ;) It feels like a lot of this post is you suggesting not that we need to worry about implicit vs explicit here, but that lifetimes shouldn't exist at all. Maybe I'm reading you wrong, but lifetimes are needed for safety without a GC. (and even a GC would only solve memory related problems, not other ones.) It's the only way to ensure Rust's goals, given Rust's design constraints. Maybe somebody will someday come up with something different, but after years of research and work, this is the best thing we've come up with :) &gt; I think that they preferred a sub-ideal Index rather than explicit lifetimes I don't think this is true. Or rather, if it is true, it's only one part of it. Having it return references is the default behavior one would expect; or at least, many people would. Returning values _can_ make sense, but mostly for advanced shenanigans, IMHO. &gt; Take for instance Iterator and IntoIterator: the standard way to define an iterator for a type requires you to define 3 different iterator types very similar to each other. This doesn't have to do with lifetimes, it has to do with ownership and borrowing. You'll see these pairs of three in various places, but that's because these three things have differing and important semantics, and not all three of them make sense for every type. &gt; I'm absolutely not an expert of rust and have followed its development only for a short time, so I might have said something completely stupid, and if so, I'm sorry. It's all good! No worries :) &gt; I think that lots of traits aren't ideal (or aren't there at all) partially because of constraints on explicit lifetimes I think this goes back to the stuff above; this is about constraints on the power of the feature itself, not its explicitness. ATC isn't about implicitness, it's about extending the power of the type system. It's not inherently about explicitness, it's about the feature's existence in the first place. Does that make sense?
A big thank you for supporting not using nightly rust (which has become a frustrating thing when good projects depend solely on nightly). Looks nice so far!
It depends on what you want to do really. And the reason they are different types is because Rust chose to do it that way. To answer your last question: you have to think about what you are actually doing when working with references. A reference is a kind of pointer. The difference to raw pointers is that References are proven by the compiler to be always valid. In Rust we have two flavors, non-mut and mut. I'm sure you are familiar with the borrowing rules, so I'll skip that, but logically one can get a pointer to something that one *cannot* mutate, or one *can* mutate (`&amp;` and `&amp;mut` respectively). This means that if you want to actually work with the value behind the pointer you have to dereference it, this is done using the `*` operator. Now, if we have a `&amp;mut i32` and we dereference it, we have access to the underlying `i32` in a mutable way and can modify it: let i = 5i32; let a = &amp;mut i; *a = 42; Conversely, a `&amp;i32` only allows us to get a read-only pointer, which means that if we try to get a mutable pointer then the compiler will complain. Now, let's get to double references. If we have a `&amp;&amp;i32` then we have a pointer, which pointers to a piece of memory where another pointer resides! So now we have to dereference twice: `**`. That's what you did! So what happens if you have a `&amp;mut &amp;i32` ? When you try to read from it, it will work since both allow read-only access. However, if you were to try and write to the innermost `i32` you'd get an error as the second reference is read-only. If we now have a `&amp;mut &amp;mut i32` we'd be able to mutable dereference both and thus be able to change the underlying i32. However, getting a `&amp;mut &amp;i32` allows you to change to which `&amp;i32` things are pointing to, with the usual livetime constraints. Some code: https://is.gd/R5MPz8 --- As to when this would be useful? Well, I've been using Rust for some time now, and it really never came up. Due to the fact that a simple reference is all that's needed most of the time it only surfaces in situations like you have here.
&gt; With all due respect, and I promise I'm not intending to come off as an ass here, then Rust may not be the language for you. Lifetimes are the necessary price we pay for GC-lang levels of memory safety with C levels of performance. If you don't want to be this involved with memory management, which is absolutely fair and I'm not trying to be at all derisive, then you may be more interested in a GC'd language like Java or D. I don't think you'd sound like an ass even without the disclaimer :) I really really like rust for so many of its features that make it a modern language: to me Rust is so much better than C++ for not having a declare-before-use rule and having modules. It's so much better than C++, Java and D (and many others) for having traits instead of inheritance, for having everything const by default, everything moved by default etc. If I could find a language as modern as rust, but without borrow and lifetime checker, I believe I'd prefer that one for most purposes. -- Anyways with this post I was wondering whether a language that is safe (as Rust) and that has no runtime nor GC could work without explicit lifetimes. By explicit I mean "manually written by the user in the function signature". The compiler would of course need to keep track of lifetimes implicitly. I believe that a compiler should be able to infer the output lifetimes of your `g` function even if they're not explicitly written in the function signature. I believe that only unsafe functions should require lifetimes made explicit by the developer. u/steveklabnik1 pointed out why explicit lifetimes are useful, and in [my reply to his post](https://www.reddit.com/r/rust/comments/64zhjo/why_do_we_need_explicit_lifetimes/dg6d5a6/) I tried to explain why I don't like them.
&gt; WebAssembly only supports a limited number of value types 32- and 64-bit integers only? No way to represent a single byte?
I elided the rest of my structure because typing code on reddit is cancer. The actual implementation I've been building uses more lifetimes, and is capable of switching `actual_store`. I'm going from memory here, but I think I wound up with signatures like `fn switch&lt;'b: 's, 's&gt;(&amp;'s mut self, &amp;'b [u8]);` and `fn peek&lt;'s: 'b, 'b&gt;(&amp;'s self) -&gt; &amp;'b [u8];` where the lifetimes of the control structure itself, its backing store, and views into that store, are all separate. The structure can never outlive its current store, but the hypothetical lifetime can be elevated by giving it a buffer that lives longer than it might itself. You can't `switch` in a buffer that will go out of scope and leave the control struct dangling, which is a bug that can only be easily proven with lifetime markers AFAIK.
I found a solution here: http://stackoverflow.com/questions/33541492/returning-iterator-of-a-vec-in-a-refcell?noredirect=1&amp;lq=1
You can either specify a linker script to use with the [linker arguments attribute](https://doc.rust-lang.org/reference.html#ffi-attributes) or make `xargo` compile your stuff into a static library and than link this output manually with `ld`. Should both work just fine.
Thanks once again for this further clarification. Your answer makes a lot of sense, but I still have some doubts. -- &gt; This example wants more lifetimes, not less. That is, if lifetimes were inferred here, this still wouldn't compile. Uhm, what I was imagining is that the compiler could implicitly add lifetimes as needed to make everything work (as long as there's no lifetime violation). In order to make my snippet work you could just add an explicit lifetime to `Trait2` (and of course to anything that's using it), and everything will be fine. You can do this manually, except it's a lot of tedious work and you can't really modify `std` or other people's crates; but if the compiler did it automatically for you, everything would work fine. I think - not sure whether I'm missing something; I should try to refactor `Index` into `Index&lt;'a&gt;` throughout all the standard library as an exercise! This thing I just described now might be seen as a different feature from what I discussed previously, not sure, but I can't see it coexist with mandatory explicit lifetimes. -- &gt; I don't think this is true. Or rather, if it is true, it's only one part of it. Having it return references is the default behavior one would expect; or at least, many people would. Returning values can make sense, but mostly for advanced shenanigans, IMHO. Oh... Is it? Then I'm afraid it has a different semantics from the one I imagine... The `container[index]` expression is an owned value, not a reference: I thought that the only reason why `Index&lt;T&gt;::index` doesn't return an owned value is because we want it to work even on types that don't return implement `Clone` (and well, for performance reasons). I'd expect even `Range&lt;T&gt;` to implement `Index`, if it didn't need to return a reference... Of course `IndexMut` does need to return a mutable reference (until `DerefMove`/`IndexMove`/`IndexSet` are implemented). -- &gt; I mean, languages that don't have a feature aren't gonna have issues with a feature, sure ;) It feels like a lot of this post is you suggesting not that we need to worry about implicit vs explicit here, but that lifetimes shouldn't exist at all. Maybe I'm reading you wrong, but lifetimes are needed for safety without a GC. (and even a GC would only solve memory related problems, not other ones.) It's the only way to ensure Rust's goals, given Rust's design constraints. Maybe somebody will someday come up with something different, but after years of research and work, this is the best thing we've come up with :) Sorry for criticizing rust too harshly. I think it's a great language and I love so many of its features. It's weird how easy it is to mix up useful features like the borrow checker for a *bug*... I'm no longer fighting with the borrow checker, but I feel like the constraints on lifetimes are preventing me from implementing the traits I want, and I believe that there's no solution at the moment.
Don't get my hopes up telling me that miri will be arriving unless this is really the last blocker standing in its way. :P (Is it?)
&gt; Long story short, no, because the time complexity required for the compiler to do this work is horrifying. Would you know which parts of the inference process are computationally too expensive? When compiling a function the compiler can tell you whether the lifetime constraints are met or not. I would believe that finding the maximum lifetime shouldn't be too much more expensive (but I could easily be wrong - haven't ever looked into the lifetime inference algorithms). I think that inferring lifetimes for types and traits should be even easier (? I'm not quite sure about this TBH) And at that point, if finding the maximum lifetimes were doable, the rest shouldn't be a big deal: the compiler could go through a compilation (crate) and write to the compiled object files all the lifetime constraints it managed to infer. Then, when compiling another crate, it would use the precompiled lifetime information (instead of the function signatures) to resume its work. -- I had the impression that explicit lifetimes were chosen so that a change to the function's code wouldn't change the API (same reasons why function arguments need to have an explicit type), and in this case I would not fully agree with the decision.
How does it prevent OOP? You don't need mutability to have OOP. 
Thank you, that works. Didn't know cargo's --example functionality. Rather helpful actually. 
&gt; Yeah, not sure about that. I thought the complexity of inferring the output lifetimes would have been similar to checking whether the lifetimes requirements are met, but I'm not sure. I don't see why that would be the case. There are plenty of problems for which it's much harder to come up with a solution than it is to verify it.
Yeah, that's pretty awful. A group of people spends their own time creating useful tooling for a billion dollar corporation. Corporation doesn't care.
Structs can write to their borrows. You don't have lifetimes in structs because structs exist, you have them because they're necessary for any links to external objects. References are the most common form of this.
I'm not a compiler hacker. Every compiler hacker I've heard talk about this has said it's an intractible problem, especially since it's whole-program analysis and not just per-crate analysis. The way I use them even crosses the FFI barrier, where the compiler *can't* follow and I have to promise everything is correct. I think Rc and friends might get you where you want to be? No bare references, so fewer lifetime markers, and the deferred-destruction is the closest Rust comes to GC.
Well, even if this were an NP problem, I tend to believe that in most cases it would not be prohibitively expensive as the compatible input lifetimes for each output lifetimes are usually very few. In cases where the input is too large we could choose to explicit the lifetimes just to speed up the compiler.
One problem that I can see is that there might be a number of lifetime combinations that could work, not just one. So you'd have to carry all of those around and that would complicate the lifetime inference of other functions that call that function. Some lifetime combinations for function `A` might even make lifetime inference for function `B` impossible and now you have to backtrack and and eliminate those combinations and pretty soon you are playing sudoku with your compiler. I'd also argue that in some cases the lifetimes can provide vital documentation, which is the main reason I love rust's choice to make function argument types explicit rather than inferred. I'm dumb, and I like lots of clues to help me figure out what is going on.
Oh, I didn't realize the inspiration flowed that direction. I had always assumed it was the other way around.
&gt; According to Glassdoor, the average developer salary is $85,000. Is that average in the US?
Is it because the devs have a crush on C++? You can share, I won't tell anyone (except everyone on /r/rust).
Currently, `relm` is bound to `gtk-rs`, but I believe it won't take too much work to add other backend in its current form (the biggest feature would be to implement the `#[widget]` attribute for other backends). However, when `relm` will switch to use `futures-glib`, that will require a similar abstraction to spawn futures on these backends' event loop.
&gt; If yes, how would you specify the bindings between the model and the widgets' properties? As I remember it is possible describe signal connections into xml, so you can in glade_view! macros make possible to write something like "onButtonXPress" =&gt; something, and control that "onButtonXPress" exists in xml
By nested widgets, I assume you talk about a `relm` [Widget](https://docs.rs/relm/0.4.0/relm/trait.Widget.html) that is a container, i.e. a widget that can have children, right? If yes, then it is currently not supported. If you need this feature, I think it could be added easily by adding a `add_child()` method in the `Widget` trait. **Update:** that feature was added: see [the container example](https://github.com/antoyo/relm/blob/master/examples/container.rs#L91).
And whether you get success out of the effort is unknown. Putting a lot of effort towards evaluating something that isn't good is a great way to get people to look down on your team.
Sounds like a very sensible strategy. Thanks for sharing that.
I've fixed this issue. Thank you for reporting it!
That seems kind of difficult. If I'm understanding you right, I'm imagining that the objects being referenced live in some dynamic data structure, say a Vec&lt;Stuff1&gt; and Vec&lt;Stuff2&gt;, and then Container stores collections of &amp;mut Stuff1's and &amp;mut Stuff2's. But when you want to add or delete a new object, you need a &amp;mut to the backing storage, which can't be done while all those &amp;mut refs exist in the Container. Thinking on it some more, I think it's just something that rust can't do safely (without resorting to things like RefCell that have run-time costs). If the "StuffRefMut" needs to refer to an unbounded collection of objects, then the Container itself is going to have some collection to which there will potentially be many &amp;mut's within a StuffRefMut. But rust's borrowing system isn't capable of distinguishing eg &amp;mut arry[0] from &amp;mut arry[1] (let alone more complicated situations). So the whole enterprise is doomed. It seems like the next best thing to do then is to wrap the Stuff1's and Stuff2's in RefCell (and incur a run-time cost) or UnsafeCell (and use unsafe) within Container. Thanks!
Check out https://github.com/japaric/rust-cross. I can't really give any more help than that as I have not attempted it myself.
https://medium.com/snips-ai/how-we-made-tensorflow-run-on-a-raspberry-pi-using-rust-7478f7a31329
are you going to link to the benchmark results or any discussion around them? I'm curious to see that, but I don't know enough about Hyper or Tokio to say anything about that code. and when you say Tokio, do you mean the Tokio MiniHTTP thing which is incredibly barebones compared to the full featured offering of Hyper?
Tokio uses async io, and AFAIK, hyper has async io in master, but not released yet. For tests like that Async IO is the key for good performance. On top of it, the test used was extra optimized for this benchmark to the point taking a current time is cached https://github.com/tokio-rs/tokio-minihttp/blob/master/src/date.rs#L15
Would this be possible without Rust Nightly?
Hey, I was also trying to use conrod for my midi / VJ app and VST plugins.. But it became very slow with lots of midi notes. (Every midi note is a rectangle that has to have its own widget id and all the stuff that widget's have (a node in the graph etc)). So now I switched to writing a web UI, using websockets to push the GUI state updates to the client. I'm using Polymer / Web Components in the frontend and I will bundle it with Electron in the end. Btw, a few years ago I also had the urge to write a DAW with global custom / microtonal tuning (with VSTs you have to set the tuning on every VST and most don't support it natively but you can fake it with midi pitch bend etc). But then I had a lot of other work to do so I never got around to doing it.. If you have any questions about audio / midi / graphics programming feel free to hit me up or join #rust-music on irc.mozilla.org and write some stuff (the channel is not very active usually).
Which software you should use depends what you want to do with it (you could use it to make music or control lighting etc). If you want to record yourself playing melodies for making music, I'd recommend Reaper: http://www.reaper.fm/ If you are looking for Synth VSTs, here are some good ones to start with: http://www.elektrostudio.ovh.org/index.php?go=down If you want a piano, I recommend this one: http://www.yohng.com/software/piano.html
Excellent blog post and impressive work! What are your thoughts on the long term goal of how the updates to the model should update the GUI? So now macro magic inserts function calls that updates the GUI to match the model. Elm makes a big point of the view function returning data describing the GUI state. Similarly, QML produces a description in the form of the qt scene graph. And gtk seems to want to do this in the future also, with the gtk scene kit they are working on. Could relm possibly change to have a view function that returns a gtk scene graph, once gtk 4 is released? (I just thought of it now, haven't researched this at all... And I understand that you need something that works now, not dream ware)
Also, the answer is not that Tokio is super fast. Because in the list Hyper is almost at the bottom. Known for being very slow whole frameworks like Rails beats Hyper easily.
Looks neat! Shame about the GTK dependency--packaging GTK applications on Windows and OSX is incredibly painful even with only a single language in play.
That is a suspiciously low number, I agree.
Yes. That's not quite what List's Applicative instance's `&lt;*&gt;` does, though; my mistake, I expressed it poorly in my comment. `&lt;*&gt;` on Lists applies each function in the first list to every argument in the second list. So `[(\x -&gt; x * 2),(\x -&gt; x * 8)] &lt;*&gt; [4,8] =&gt; [8,16,32,64]`.
&gt; If I could find a language as modern as rust, but without borrow and lifetime checker, I believe I'd prefer that one for most purposes. Haskell? OCaml?
Yeah the very short version is that the lifetime of the iterator you're getting is tied to the lifetime of the guard returned from `borrow`. That guard has a destructor, which lets the RefCell know when you're done with it. Edit: The author runs into very similar issue in this chapter of the Too Many Lists book: http://cglab.ca/~abeinges/blah/too-many-lists/book/fourth-iteration.html
&gt; Returning values can make sense, but mostly for advanced shenanigans, IMHO. I think the biggest pain point this causes is sparse data structures like a Map that returns a default value when the key isn't present. Sadly, there is no way to return values from [], so you have to use a method instead. 
Even C doesn't really have this. You can have `char` variables but they're promoted to `int` if you want to do any ALU op on them.
I didn't know about gtk scene graph: this is definitively interesting and migth solve some other issues like having loops of widget or widgets only shown depending on some condition (not sure about it since I haven't read much about that). Thanks for your idea!
Is it possible to use the new Macros 1.1 features and Derive for the widget? Or is there too much magic involved?
Wait, if there's no nightly for 24 hours, does that mean tonight doesn't happen? What do we do about the sun? Am I going to have to set my clock forward?
Well, it is implemented using the same crates that you would use in macros 1.1 (`syn` and `quote`). The issue with custom derive is that it is only possible to use them on `struct` and `enum` which limits possibilities. But I've just had an idea. I believe it would be possible using this syntax: #[derive(Widget)] struct Test { update: update! { match msg { Clicked =&gt; model.counter += 1, } }, view: view! { gtk::Window { gtk::Box { gtk::Button { } } } }, } Is this something that you would like?
For that, you'll probably want SDL.
I'm splitting up a massive crate into ~60 smaller crate for [Rusoto](https://github.com/rusoto/rusoto). By making and publishing a crate for each AWS service we can avoid the issues of having a mega-crate, like running out of memory on TravisCI when compiling. I've [got a start by pulling out one service into a crate](https://github.com/rusoto/rusoto/pull/600). I'm not sure how to publish the complete API documentation. With the mega-crate we compile and run `cargo doc` with all our features enabled and it's all there one on doc output run. When we have lots of smaller crates I'm not sure how to collect all the docs and publish those. Any resources I can read for how to make this happen? The end state will be 60+ crates, plus the two crates used by each of those, and I'd like them all to have a single published location for all API documentation.
IIRC the stuff in `stage1/bin/rustc` is a copy of the stage 0 compiler. Or it was at some point. Maybe I have this backwards, but basically I'm not convinced from the folder name. This _really_ needs to be documented more. I used to always `make rustc-stage1`, since `make rustc-stage0` never worked.
This looks really, really well! I look forward to try it out. Thank you!
Yeah, you can define ALOT in glade. Signals, handlers, etc - guess we could use these.
… wow. With supreme effort and trial and error I *finally* managed to enter a basic URL. It won’t actually process any link clicks and text entry is useless, but it’s being built!
I've checked again. You're correct that `stage1/bin/rustc` is a copy of `stage0-rustc/&lt;target&gt;/release/rustc`. I've edited the post. Still `stage0-rustc/` is a compiled compiler, not the downloaded one. So what is actually happening is: * rustbuild downloaded the stage0 `rustc` and `cargo`, into `build/bootstrap/debug/*` * The stage0 compiler is used to build the "stage0 artifacts", placed in `build/&lt;target&gt;/stage0-&lt;component&gt;/` * These "stage0 artifacts" are copied to `build/&lt;target&gt;/stage1/`, and the result is the "stage1 compiler" * And "stage1 artifacts" are produced in `build/&lt;target&gt;/stage1-&lt;component&gt;/` etc. &gt; 3\. The stage0 `cargo` downloaded earlier is used to build the standard library and the compiler, and then these binaries are then copied to the `stage1` directory. That compiler is then used to generate the stage1 artifacts which are then copied to the stage2 directory, and then finally the stage2 artifacts are generated using that compiler. What has confused me is that in `src/bootstrap/README.md` it describes the directory structure as: # Location where the stage0 Cargo and Rust compiler are unpacked. This # directory is purely an extracted and overlaid tarball of these two (done # by the bootstrapy python script). In theory the build system does not # modify anything under this directory afterwards. stage0/ ... # These output directories are intended to be standalone working # implementations of the compiler (corresponding to each stage). The build # system will link (using hard links) output from stageN-{std,rustc} into # each of these directories. # # In theory there is no extra build output in these directories. stage1/ stage2/ stage3/ I assumed the rustc in `stage1/` contains a copy of `stage1-rustc`! But what happened exactly is: 1. `stage0/` does not exist 2. `stageN/` copies output from `stage(N-1)-&lt;component&gt;`, not `stageN-&lt;component&gt;`. (Could someone familiar with rustbuild clarify the doc or confirm?) ---- `make rustc-stage0` doesn't work because it is not defined in the generated Makefile. `make rustc-stage1` is equivalent to `x.py build --stage 1 src/libtest`. I think it will also build `--stage 1 src/libstd` and `--stage 0` everything by dependency. I always run `x.py` directly instead of the Makefile wrapper though.
I believe they fixed that in [this PR](https://github.com/servo/servo/pull/16198) but it's not build yet.
It's actually _more_ efficient to use the `let mut owned = None;` case in the case above. This is because with `let mut owned = None` we don't have to have an extra drop flag and drop flag branch at the end (just the regular `Option` drop glue, which both cases have). Though the optimizer might be smart enough to eliminate that here.
Yeah, the copies of rustc always confused me. This seems to be accurate. Might be worth checking this into tree somewhere prominent and linking to it from CONTRIBUTING.
Sees pretty obvious from this thread that explicit lifetimes are important, but I think that there should some tool that inferred lifetimes and printed out a few solutions. It would make learning them easier, as well as make a cool IDE feature in the future.
I noticed the "raw" file of these logs show Hyper performing reasonably during the primer and warmup, but then the results get weird when the bench starts. http://tfb-logs.techempower.com/round-14/preview-3/hyper/plaintext/ Edit: The latency measure breaks and the benchmarks show very close to 2 requests per count of concurrent connections. 
Drop elaboration reasons about active variants, I believe, but it might not be able to collapse the two flags. LLVM should though.
In some cases it works like a transmute, but others like `f32` -&gt; `i32` involve actual conversion logic.
ALL GLORY TO THE LLVM GODS
As with most functional things things: Haskell -&gt; Another Language -&gt; JS
I feel like you cargo should be able to tell you / override for you when a project is pinned to a specific nightly. Having to tell people to "do a `rustup update` with the contents of that custom file we change in git occasionally" isn't really great.
That is basically exactly what I wanted. I am on nightly, so using a feature flag is fine for me. Thanks a lot for the example code!
Thanks! If I ever need to switch to stable for some reason, I will be very thankful for your solution.
Where did you get the lua script? I can't find it in the repo.
So what's really the deal with prolonging the life of temporary values in Rust? In the case described in the article you need a backing variable but in [other situations](https://is.gd/euubwQ), Rust seems to be perfectly happy to extend the life of a temporary object: fn main() { let x = &amp;foo(); println!("{}", x); indirect_print(x); } fn foo() -&gt; String { "foo".to_owned() } fn indirect_print(x: &amp;String) { println!("{}", x); } This works perfectly, even if you add curly braces anywhere in the `&amp;foo()` expression (especially `{&amp;foo()}`) to force the value/reference to go through another scope. In a way, this looks even more powerful than what C++ can do with const references.
On the other hand, just replacing `let x = { &amp;foo() };` by let x = { let y = &amp;foo(); y}; makes it fail to compile, so I'm under the impression that here it only works because you are creating the temporary and returning it at the same time.
As far as I know thats a combination of a few features: - Creating a reference to a rvalue creates a temporary for the rvalue that lives as long as the expression itself. - The trailing expression of a block scopes the lifetimes of its temporaries as if they where outside the block. - The lifetimes of temporaries of a let initialization expression are scoped to the lifetime of the let itself. You can see the difference in action here: https://is.gd/hLGhz1
As if time handling wasn't *complex* enough.
very nice!
Could be solved by using cells, no?
With respect to your example, you can *almost* get there with HRTB: impl&lt;T&gt; Trait2 for T where T: for&lt;'a&gt; Trait1&lt;'a&gt; { ... but you can't access the associated type in `Trait1` through a HRTB. (IME, HRTB's are rarely used explicitly, but they are necessary for closures. Their explicit usage tends to occur when you have a trait parameterized over a lifetime---like you have here---but they can only take you so far.)
A wrong way! `match expr {...}` will keep *all* temporaries (except anything inside nested `let` initializers) alive, whereas `let` initializers won't, e.g. keep `&amp;foo()` alive in `bar(&amp;foo())` for longer than the duration of the call. We don't have `let x = expr1 in expr2;` other than `match expr1 { x =&gt; expr2 }`.
In that case, the temporary has the lifetime of the body of `main`, and never tries to leave this scope which is fine, whereas in OP's post they try to make the temporary leave the body of the if statement.
Would it be possible to do something similar to prolong a temporary inside a function that has to outlive the function's generic lifetime? I.e. if a function returns an iterator, the source for the iterator also has to be returned. 
To me, logging is the one place where I think I global makes the most sense. I'd kill for there to be `stdlog` in addition to `stdout` and `stderr`.
Non-js version: https://webcache.googleusercontent.com/search?q=cache:https%3A%2F%2Finternals.rust-lang.org%2Ft%2Fpre-rfc-provide-flavors-for-libraries-non-additive-features%2F5079
&gt; In order to avoid possible data races, Rust’s ownership model does not allow the UDP interface and RadioDriver to keep references to the networking stack simultaneously. While hardware interrupts are asynchronous, and therefore run concurrently with other kernel code, in our operating system interrupt handlers enqueue tasks to be run in the main scheduler loop, which is single-threaded. As a result, on_receive and send can never run concurrently and no data race is possible. They address this by giving things static lifetimes and using unsafe borrows. Couldn't they just use `Rc&lt;RefCell&lt;NetworkStack&gt;&gt;`?
`Rc&lt;RefCell&lt;_&gt;&gt;` has a runtime cost. Unsafe borrows should avoid that.
No, that would make functions very leaky -- your function should either return a type that owns its contents which can be iterated over, or accept storage space as a mutable borrow.
Very similar to my own project, although I use Hyper. I'm guessing that you as me are doing this because it is useful personally and a good learning exercise. https://github.com/JordiPolo/file_http_server I would get some ideas from your code, the guessmime crate is great, something I do not need to do myself, IMHO should be part of the mime-rs crate but what do I know 
Although I am not knowledgeable in embedded systems, coincidentally this [thread](https://www.reddit.com/r/rust/comments/655816/ownership_is_theft_experiences_building_an/) was created today. You may find a well composed answer :)
Any chance we could have Rocket and/or Backtalk in there? I've been meaning to learn Rust by means of making some kind of API, but I can't really land on what framework to use - knowing which was faster would help me pick :)
Cool! Never knew you could instantiate structs that way. Is it exclusive to unit structs?
Reading more, I've got a bunch of questions (I think Amit is a Rust regular; maybe he can clue me in). 1. Things like `Rc&lt;RefCell&lt;_&gt;&gt;` seem like the could be used in the network stack example. 2. The next concern is that closures need to take ownership of things they work on, &gt; For the closure to capture a variable, it must either take ownership of it, preventing the caller from accessing it, or complete before returning to the caller. I think that `Rc&lt;RefCell&lt;_&gt;&gt;` doesn't prevent the caller from accessing it. 3. This text ends the section: &gt; The second approach is to avoid compile time ownership checks and rely on run-time mechanisms. While this may work for some applications, it defeats the purpose of leveraging compile-time safety checks for an embedded operating system. It totally doesn't defeat the purpose! You still don't have data races, and you have to explicitly state what should happen if multiple people are trying to use the network stack at the same time. The claim is "this doesn't happen", so you could even go as far as assuming that it doesn't happen and just panic. You don't get the magical ponies of the week club membership, but it is way better than static mutable borrows. 4. The proposed solution are references that capture the thread id and just allow mutable borrows if the thread id is the same, which seems to prevent strictly fewer errors than borrowck. Things like iterator invalidation, or just general "i'm not you but writing to your memory lol" errors aren't structurally prevented. They acknowledge this at the end, and suggest &gt; Therefore, supporting mutable aliasing in Rust might require subtle changes to the standard library. While we believe execution contexts can, in general, be safe, we have not fully explored their implications on the wider Rust ecosystem. It feels like there has been a lot of thinking already, and it would be pretty brave of them to let the rust devs write code against their "multiply mutably borrowed" references. :) I hope I'm not too negative sounding (I'm sure I am). I am professionally a "complainer about papers", and old habits die hard.
This particular piece of logic is not added by the compiler, it is part of the standard library, which includes OS-specific functionality like backtraces. If you compile a`#![no_std]` application, it will not include the standard library.
But then I'm back to square one without a GUI, right?
Rust has [lang items](https://doc.rust-lang.org/book/lang-items.html). The standard library provides implementations for these functions. In general, you can't just remove this code and still expect your program to work. &gt; What codes does rust allways put in the target? does it put a signutare on file to show that this program is written in rust? Aside from the aforementioned "extra" code, I imagine a skilled person might be able to distinguish between a compiled Rust program and a compiled C++ program, just by looking at the generated assembly. E.g. C++'s `std::vector` is not implemented exactly the same as `std::vec::Vec`, so just scanning the compiled code for something 'vector-like' would probably sufficient to detect the source language. Then there's calling conventions, different idioms, etc. So unless you go to extreme lengths, it will be very hard, if not impossible, to hide the original programming language for any nontrivial program. &gt; Is there an option to remove these extra codes and tell the compiler just compile the codes that we written? If you use the nightly compiler you can use `![no_std]` and some other magic to ensure that you *only* get your own code in the resulting binary. &gt; What should I call these extra codes? do they have a name? Well I've already covered the lang items. I suppose there is some auto-generated stuff that happens before `fn main() { ... }` as well, but I'm not sure what it is named.
Note that this paper is pretty old, and this has turned into Tock today.
I can think of three things that the rustc compiler / standard library add to every program that links to `std`: A) First is "drop glue". When a variable goes of scope, its destructor gets implicitly called. This is injected by the compiler. Example: fn main() { let xs = vec![Box::new(0), Box::new(1)]; // `xs` "dropped" here. Each element of the vector gets dropped and then the // vector heap memory gets deallocated. } B) Second is "landing pads". These are required for unwinding. These are required for the RUST_BACKTRACE functionality. These are also injected by the compiler. You can opt-out of these via `-C panic=abort`. C) Third is the "Rust runtime". Before `main` gets executed some code is executed. You can see the full code [here](https://github.com/rust-lang/rust/blob/1.16.0/src/libstd/rt.rs#L32). I think the `catch_unwind` in there is also required for the RUST_BACKTRACE functionality. You can opt out of this runtime by not linking to `std`, i.e. writing a `no_std` program. &gt; does it put a signutare on file to show that this program is written in rust? It doesn't AFAIK. In Linux, at least, both Rust code and C code get compiled to an ELF executable and the Rust version doesn't have any extra header to distinguish it from the C one except perhaps from debug related tags (if compiled with `-g`). EDIT: Fixed code block.
There is, you just have to write it and send in a PR.
Slowly starting to get back into working on the `ggez` game library after a bit of a break... Which mostly means contributing to other projects at this point to provide functionality I want. `app_dirs` gets a patch, `gfx-rs` gets a patch (which I need to finish one of these days), `vfs` gets a patch and still needs another one... Also thinking about how to actually make game components talk to each other. Have some experiments to try there, if I ever get time...
I don't know if I'd *recommend* it. It's a lot of complexity (compile time only though). Alternatively, just used checked indexing that panics and call it a day (and pay the bound-checking cost at runtime).
has even been on this sub already: https://www.reddit.com/r/rust/comments/3nbt2d/ownership_is_theft_experiences_building_an/
Landing pads are not required for unwinding (otherwise C programs could not e.g. use glibc's `backtrace()` function). The absolute requirement is either: * DWARF tables (which result in precise unwinding); * or frame pointers plus a symbol table (which don't unwind through inline functions, unlike with DWARF).
Fixed, sorry. Jekyll does this stupid thing where it generates URL slugs based on the timezone you are currently in, even though timezone info is _right there in the post_. I am currently in Taipei, and when I published this blog I broke the URLs of all my older posts. I switched it back, but that broke the URL of _this_ post. I've pinned a timezone in the rakefile which is a decent temporary solution, but I should just patch it so that it can generate the slug based on post authoring timezone.
&gt; &gt; does it put a signutare on file to show that this program is written in rust? &gt; &gt; It doesn't AFAIK. It does: $ echo "fn main(){}" &gt;foo.rs $ rustc -O -C panic=abort foo.rs $ strings foo|grep 'rustc version' rustc version 1.17.0-nightly (0f34b532a 2017-02-21)
I'd use: 1. `reqwest` someday, but since it's synchronous, I'd use hyper master to get tokio. 2. `futures-cpupool` if there's any CPU-intensive processing 3. html5ever to do the parsing
Check out https://github.com/rust-embedded/ and tons of projects here https://github.com/japaric/
/u/frankmcsherry is exactly right. The runtime cost is a bit of a bummer, but the reason we wanted to avoid `Rc` is because it is heap allocated, which is problematic for reliability in low-memory scenarios like embedded systems.
Thanks for all the good feedback! It's cool to hear that things worked out well. :D You are totally right, `Cell` is what I should have said. I never use it because I don't understand it well, but yeah totally. Good point. Maybe I should edumacate myself. =/ Thanks for doing this stuff, by the way. It's great to get one's brain stretched by other people, and learn about what can and can't be done without having to go through the literal headache myself. ;D **Edit**: that should be "the literal headache and years of work"; it wasn't meant to sound trivializing. &lt;3
Would it make a good compile error note to suggest that change?
It will be generally obvious that the program is written in Rust. There are many strings in the executable that are very recognizable and only contained in the Rust stdlib (including `RUST_BACKTRACE`, but also things like `called Option::unwrap() on a None value`), even in a stripped static executable built with LTO. You could of course opt out of libstd with `#![no_std]`, but this is not practical for most real-world circumstances, and even if it was, a quick look at the assembly would make it quite clear that the program was built with rustc (the operations on `Option` and `Result` are very distinctive).
One other cool thing about the examples directory: they get compiled, but not run, when you run `cargo test`.
That's not enough, try running `strings` even after stripping.
Yeah, sorry. I meant Foo {} not just {}, since like you said, it works in all cases.
Exactly, it is chance to learn rust and to play around with tokio.
I'd Love to see an Ide feature that used the body to infer the lifetimes!
Correct. Landing pads are required to *stop* unwinding (or in other words recover from it).
I think Steve means that they solved their issues within the existing language, rather than solving Rust language issues. It sounds like (from Amit) they invented a few new `Cell` types, which .. maybe means there were things the language could have helped with more.
I think it's nice to have a general case. That way, you can `match something { Foo { .. } =&gt; do_stuff(), }` and then later on you're free to add more fields to `Foo` without changing this `match`.
I guess I don't consider this to be a "less-used" feature, to me it's just how variables work. :P Maybe it helps if you're used to other languages where variable declaration and initialization are already separate concepts (like C), coupled with the trust that Rust wouldn't let you do something completely stupid without an `unsafe` block. Once you realize that this works, and that Rust makes it safe, it really makes you appreciate how surprisingly smart the compiler's analysis passes sometimes are. For example, the following code obviously won't work: let foo; loop { foo = 1; // error: re-assignment of immutable variable `foo` } ...but this does! let foo; loop { foo = 1; break; } Even though `foo` is immutable, and therefore must be initialized no more than once, Rust is smart enough to understand that the loop will unconditionally break before it ever gets reassigned. And it extends to more complex cases like: while bar() { if qux() { foo = 1; break; } } (...although, in this last case, because we've swapped out the `loop` (which is obviously guaranteed to be entered at least once) for `while bar()` (which isn't), good luck convincing Rust to let you access `foo` outside the loop. :P If you put the `loop` back then accessing `foo` is just fine, even with the `if`, since that's the only `break` in sight, but if you put another code path in there with a `break` that *didn't* initialize `foo` exactly once along the way, then Rust would yell at you again. Again, it's pretty smart!)
Now try just `grep -i rust`.
Looks nice, aside from the miserable keyboard input (which I assume will be fixed in short order), most websites look *almost* the same as on chrome, but despite the minor graphical differences, they are still usable.
Nice library, it looks like a nice solution, but the author claims that it is unstable now, so I'm not sure if is production ready
Thanks, that looks like it is what I wanted, Is it guaranteed that these slices will not be new allocations? 
AFAIK, tendril is used in Servo and is one of the most production-ready libraries out there. = The readme warning you're citing is two years old. Though that's just my conjectural opinion.
If you are implementing a cryptosystem and have to worry about side channel attacks you need to understand whatever tools you choose *very well*. I hope this is not for production, or that you have access to an experienced mentor if it is. Rust sounds like a great choice for your project description *iff* you can find the libraries you need with stability guarantees you need. Do you have time to prototype out in both and pick based on which feels best? (If you do this please make a post about your decision!) You can hang out in #rust-beginners on irc.mozilla.org for questions you have during your project.
First, to answer your headline question: Rust is a definitely good choice for a networking application that uses crypto. Whether or not ncurses programming is convenient in Rust is the thing I would investigate carefully; I've never tried it myself. &gt; One problem apart from me not knowing much about rust, is that I'll have to learn secure programming in rust and the common mistakes. My main suggestion is to avoid `unsafe` whenever you realistically can. Also, to whatever extent you parse stuff, use some library and/or tool to help you; don't be parsing stuff by directly manipulating slices (arrays/vectors) of bytes or characters. &gt; I'm thinking about using Brian Smith's ring, although I wonder if I should just use libsodium for the crypto. Both *ring* and libsodium (sodiumoxide and friends) aim to help you avoid common crypto mistakes automatically. I often watch how people use *ring* and if/when I see them make a mistake, I improve the API. Also, there are other crypto options in Rust too. In general I would be a lot less concerned about crypto in Rust, and I would be more concerned about ncurses and other aspects.
One random reason maybe: we don't use `jemalloc` on Windows. I'm sure there's other things too, but I don't really hack on servo.
Well obviously it will still include some Rust components. strip does not remove the runtime, I never claimed that. I only said how to get rid of the specific producer value that you quoted above. That's the value that OP asked about in the question that has been quoted: "does it put a signutare on file to show that this program is written in rust?".
Maybe you could do something with `Drop`? In pseudo-code: { let a = element("a"); let b = element("b"); write(a); write(b); // Auto end_element on drop }
You don't actually have to *use* anything from libcore, and if you're building with LTO, no symbols from libcore will make it into the final binary. Mangled names do not appear in stripped binaries that are statically linked with every Rust object they depend on.
For ncurses, the solution I've generally seen people recommend is [Cursive](https://github.com/Gyscos/Cursive). It's basically a widget toolkit that uses box-drawing characters in a terminal rather than graphics primitives in a GUI system. (If you've ever used [urwid](http://urwid.org/) for Python, it's the same sort of thing.) It also has [switchable backends](https://github.com/gyscos/Cursive/wiki/Backends), which allows it to support Linux, macOS, Windows, and Redox. (The last one coming via termion, which is a pure Rust terminal-manipulation library.)
I've been hearing about rust being increasingly used in networking/crypto, like in [tor](https://news.ycombinator.com/item?id=11617917) and firefox for a while now. But my main concern was about a beginner in rust making mistakes, and if it is wise to brave rust in important applications. And I'm looking for more suggestions like: &gt;My main suggestion is to avoid unsafe whenever you realistically can. Also, to whatever extent you parse stuff, use some library and/or tool to help you; don't be parsing stuff by directly manipulating slices (arrays/vectors) of bytes or characters. I've read about some common mistakes in some HN threads (I think a post about alacritty had a couple), and I'm wondering if there are these kind of common mistakes documented by anyone in a blog post. &gt;Both ring and libsodium (sodiumoxide and friends) aim to help you avoid common crypto mistakes automatically. I often watch how people use ring and if/when I see them make a mistake, I improve the API. Also, there are other crypto options in Rust too. I've looked around for rust crypto, and yours looks like what I'll go with in case I decide not to go with sodiumoxide. Thanks for such a great project, I feel it'll be one of the best across languages. &gt; In general I would be a lot less concerned about crypto in Rust, and I would be more concerned about ncurses and other aspects. Yeah this is something I'll have to consider, but I'm not afraid of diving in and doing whatever I need from a library by myself. Tokio looks appealing for networking, is there anything else I'm missing out on for networking? 
Didn't mean to imply that I was the author. Just translating what was on the slide. Sorry!
What are the options I need to specify to `rustc` to output COFF object files to link as an `.exe`/`.efi`?
You are looking for [std::clone::Clone](https://doc.rust-lang.org/std/clone/index.html). Here is [example](http://play.integer32.com/?gist=f1436e9932d312dddf2c6f2c322d3ab1&amp;version=undefined).
I've got things working on a Cortex-M4 based chip (LM4F120) from TI and kinda-working on a Cortex-M0 based chip (KE06Z) from Freescale. See https://github.com/thejpster. It's fairly straightforward - you'll just have to pick a chip someone else has already done the drivers for, or really enjoy writing drivers. 
First, if struct1 contains struct2, to modify that contained value, you must have a mutable reference to struct1. If struct1 contains a reference to struct2, then struct2 cannot be modified until struct1 leaves scope. Secondly, if you don't want struct2 to be modified externally, then it must not be public. If you still need someone to modify it and you detect the modifications, you can use an intermediate struct that will remember the original, and compare to the final version (the one it owns, and gave a reference to) when the drop gets called. You create this on the fly, tie it to struct1's lifetime, and let it provide a mutable reference to a struct2.
I mean, it sounds like these people didn't really understand their own requirements going in. Sure, if you don't need high-performance, async IO, then use `std::net`. As it turns out, async IO is tricky even with good abstractions.
You could define a helper function like: fn with_element&lt;'a, S: Into&lt;Name&lt;'a&gt;&gt;, T: FnMut(&amp;mut EventWriter&lt;W&gt;), W: std::io::Write&gt;(name: S, writer: &amp;mut EventWriter&lt;W&gt;, mut cls: T) { writer.write(XmlEvent::start_element(name)); cls(writer); writer.write(XmlEvent::end_element()); } which you could then use like: with_element("foo", &amp;mut writer, |w| { with_element("bar", w, |w| { with_element("baz", w, |_| {}); }); });
what are you looking for in a language?
I'm making a small program to check an IBAN bank number, just to get better at Rust. I have written this code: let mut s = "DE44500105175407324931"; s.chars() .flat_map(|c| c.to_digit(36) .unwrap() .to_string() .chars()) .map(|d| d.to_digit(10).unwrap()) .fold(0, |acc, d| (acc * 10 + d) % 97) == 1 When I run it though, I get the following error: error: borrowed value does not live long enough --&gt; src\iban/mod.rs:42:27 | 42 | .flat_map(|c| c.to_digit(36) | ^ temporary value created here ... 45 | .chars()) | - temporary value only lives until here 46 | .map(|d| d.to_digit(10).unwrap()) 47 | .fold(0, |acc, d| (acc * 10 + d) % 97) == 1 | - temporary value needs to live until here I think this has something to do with the 'make' keyword, but I am not sure. What's happening and how can I fix it?
I'm not going to be modifying the contained struct2 value. They are kept just for bookkeeping tasks. The contained struct2 value simply should stop being updated upon calling an impl function. Struct2 is there for keeping track of coordinates. The moment a struct 1 impl function gets called, I want the struct1-contained struct2 to stop updating the coordinates.
That looks like what I need, thanks.
Summing up the comments from this thread, basically: If you want - for some reason - to obfuscate that a program was written in Rust you have the option of compiling an application with #![no_std] which means you don't have the standard library built into the executable. Furthermore you can strip the binary but you probably still won't eliminate all possible strings. Further still, if your goal really is total obfuscation of the programming language used you have to consider whom you want to hide that information from. Because as also mentioned in the answers, if that party is sophisticated enough they'll probably look at the assembly and deduce the programming language used from the code as some languages apparently exhibit certain patterns for similar constructs used. My two cents: At this point the only possible but also certainly bothersome method for total obfuscation of the original PL used I could think of would be some kind of transpiler into another language and to then compile the transpiled source. Although this most likely doesn't have the guarantee to produce logically sound or even the expected behavior in the final executable. EDIT: Formatting.
Nice library. The transformation from the `#[widget]` version to the plain version is quite a feat. You compare the approach to Elm. There are two fundamental differences from the Elm/React-Redux approach: 1. The model is not immutable; it is mutated directly in response to events. 2. The view is not a pure function of the model; it is mutated directly in response to events. The connection between the model and the view is done entirely by the macro, in the generated `update` function, aiming to keep the model and view in sync. I think this macro is bound to be very fragile, and you will have to fight many edge cases to make it sort-of work, and it will only work when you can bind directly to a property. However even if it works perfectly, the two points above still cause some irreparable damage, in the implementation, user flexibility, and in some cases, performance. I can expand on that but I've already thrown enough unsolicited criticism... I think that in order to truly make such a library work we would need: 1. Immutable/persistent data structures. I think that would be a bit hard without a GC. Maybe with lots of `Rc`. 2. Some "DOM diffing" implementation, which is the cleanest way that I know to achieve the goal with reasonable complexity and performance. Don't know if it's possible directly with GTK. Maybe with a "shadow DOM" for the GTK widgets.
is there still interest in making a looser version of rust, e.g. an --unsafe (or whatever) compiler flag that just turns off some of the checks. - It needn't pollute code in the rust community, since such projects can be clearly marked; - it will still increase mindshare, e.g. more people can write projects learning the same basic rust libraries &amp; Rust syntax, even if they write other code that doesn't feed back into the mainstream 'safe' rust community. - It's not losing anything, because those people would otherwise keep using C, C++.
https://www.reddit.com/r/rust/comments/4nvp65/nim_and_rust/ I don't know a whole lot about Nim, but maybe this will help some.
What about a compiler option which drops the Sync requirements for statics? That would allow a raw RefCell static, which alleviates some pain. (Also possible is to make a FakeSync type which adds a Sync impl to anything it wraps.)
Or you could use UPX or some other ELF compressor/obfuscator
That's because the `.chars()` iterator borrows its receiver, but the backing `String` (from `.to_string()`) can't outlive that `.flat_map()` closure. This is really unfortunate as there's no good way in the stdlib to get an owned iterator of characters. Weird oversight.
Nim also allows for manual memory management if wanted.
Thanks!
and nice macro system, and no header files. I really enjoy the fact 'everything is an expression' in rust. match is awesome. I know safety is the language's "pillar", but even without safety there's a load of other features that make it appealing 
Thank you, this all great advice!
I did a thing: https://github.com/CasualX/xwrt This is my attempt at an unstructured XML writer which is supposed to make it impossible to write syntactic invalid XML. Still requires explicit close call (due to the fact that writing the closing tag can fail, which you must handle): let rendered = xwrt::doc(Vec::new(), |doc| doc.dtd("UTF-8")? .doc.tag("note")? .tag("to")?.text("Tove")?.close()? .tag("from")?.text("Jani")?.close()? .tag("heading")?.text("Reminder")?.close()? .tag("body")?.text("Don't forget me this weekend!")?.close()? .close()?.finish() ).unwrap(); assert_eq!( rendered, &amp;b"&lt;note&gt;\ &lt;to&gt;Tove&lt;/to&gt;\ &lt;from&gt;Jani&lt;/from&gt;\ &lt;heading&gt;Reminder&lt;/heading&gt;\ &lt;body&gt;Don't forget me this weekend!&lt;/body&gt;\ &lt;/note&gt;"[..] );
I tried out Nim recently while looking for a new language before settling on Rust. I wrote a simple assembler in it and was amazed how easy it was to write in, even not knowing the language. It's probably the most intuitive language I've ever tried, even more so than Python which has its share of funkiness. Some cons of Nim are that the documentation is in a sorry state, the community is small, and its future is uncertain. The nail in the coffin for me was how poorly nim-mode worked in Emacs, though my Rust plugins also are completely broken at the moment. All in all it's a very solid language, but Rust is also fun to program with and in a weird way I think I even prefer it. I could write in Nim much faster but couldn't reason about the code in the same way I can with Rust. Also, learning Rust has been a very educational experience for me - I'm not sure what one can learn by using Nim. That's it, sorry for the rant... [My assembler](https://github.com/m-cat/nand2tetris/blob/master/project6/Assembler.nim) if you're interested in what Nim looks like.
Agreed. I mean, it isn't a terrible model to do thread/request, but is also isn't a great one. It can eat up resources like nobodies business and it relies really heavily on OS thread management in order to get high performance. With all that said, you could handle 10,000/requests per second, reasonably, with just the thread per request model (probably more, I may be off by orders of magnitude). But if you want to handle 10,000/requests per second and only do it without potentially spawning 10,000 threads (which, in standard windows threading, thread stack size = 1mb per thread. That means you would have to potentially be able to handle 10gb of memory allocation in a second to handle 10,000 requests per second). With tokio, that is entirely reasonable to do with just 8 threads or so. Less than 8mb of memory allocated to just request handling. Async is hard to do right. And at this point, I don't think rust has great high level abstractions for it. I think the foundations of what rust is building look great (tokio + futures), but that is only one step. We need more webservice libraries like rocket. More approaches to setup basic endpoints. etc.
You can use my [elementtree crate](https://docs.rs/elementtree/0.2.0/elementtree/#writing) for a nicer writing xml experience: let ns = "http://example.invalid/#myns"; let other_ns = "http://example.invalid/#otherns"; let mut root = Element::new((ns, "mydoc")); root.set_namespace_prefix(other_ns, "other"); { let mut list = root.append_new_child((ns, "list")); for x in 0..3 { list.append_new_child((ns, "item")) .set_text(format!("Item {}", x)) .set_attr((other_ns, "id"), x.to_string()); } } 
Yes, if you can figure out what is happening.
I have a very strong opinion that pretty much all of Rust's network IO is at very wrong abstraction levels. Everybody keeps trying to build these tall stacks include the kitchen sink, but rust still lacks the basic groundwork. About a year ago I wanted to work on an event loop that needed non-blocking io. It is a pattern I've down a dozen times in Java, a few in Python, a few in C++, and probably a couple I'm missing. There was no easy way to do this. All I wanted was select/epoll abstraction with related functions and of course the sockets. Mio only worked on its own event loop, tokio had abstractions I didn't want, and there was no non-blocking sockets in rust (this can't still be the case, can it?). Java seems to have done this right. C++ has it through C. Almost every other language. Python even has it a little better. A comment further down says this is difficult: No. It. Isn't. It is actually fairly simple. Get non-blocking sockets and a multiplexing abstraction then worry about all the other crap. Make it so it is easy to build the next level of abstraction, the event loop. People are too worried about in how many lines can you build a webserver. Let's just go for getting non-blocking sockets and a multiplexer first. Nothing more. Sometimes it seems like rust is already going framework crazy at such a young age. Everything is a full framework when often we just need a few functions. UPDATE: This view may be outdated. I am going to try mio again and see if things are more acceptable. If my impression has changed, I will post a review.
Look at Java NIO. non-blocking isn't difficult. Or are you letting the perfect be the enemey of the very good.
Networking in Rust is terrible. I gave up for a while.
My company's internal web server actually would cause `httparse` to panic due to there not being a space following the HTTP status code. 
Agreed, this is only tangentially related because I've just tried Piston, but it's amazing how deeply overengineered it is for being an engine that does barely anything more than SDL. It looked to me like a piece of software designed without any end use in mind, only "best practices" and making examples look neat. Eg. everything is one-to-many, everything is abstracted behind traits, everything is composable with dozens of things, and even basic functionality is split into 4 different crates. Getting anything done with it always involved fighting with abstractions, configuring countless things you don't need, figuring out how to compose crates etc. And what's worse, as OP points out those examples only look neat because of metric tons of sugar and glue that breaks *immediately* once you want to do something different, so your code will look bad unless you spend hours agonizing on how to "compress" it again. Which of course makes it unreadable for whoever works with you. I think that what Rust needs is libraries being spun off from a _real_ project with _real_ users, this hits a cord with me because these "frameworks" aren't designed with anyone's use case in mind, and that's not a good thing. 
I've been following rust's async story for a few years now and dipped my toes in the water at various points in development. I feel like what you're asking for is how the rust async developed. Yes tokio and mio are difficult but I think the problem here is that doing async io with zero overhead, portability, and safety the "rust way" is a fundamentally hard problem. Try looking at some of the [earlier attempts](https://github.com/tailhook/rotor) at rust async to get some perspective. I don't think this road is over something like `async`/`await` feels like a better end-game for rust, but there's a long way to go. But I think that tokio does over a nice set of primitives, specifically it offers exactly what you're asking for. &gt; Get non-blocking sockets This is what mio is, an abstraction over non-blocking sockets and registrations. Its a fairly thin wrapper around epoll, kqueue and a slightly thicker wrapper around IOCP. &gt; a multiplexing abstraction [tokio-io](https://github.com/tokio-rs/tokio-io) provides this as generic traits which can be glued together with [tokio-core](https://github.com/tokio-rs/tokio-core) event loops to get you a very bare-bones async stack. These pieces could be replaced at will for instance you could replace tokio core on windows with something that more natively understands IOCP. I think there are really three problems with the tokio stack. First, the documentation is really lacking in the low-level layers. Which seems to be a side effect of (2) which is all of these libraries seem to have shifting interface boundaries, tokio-io was split out of tokio-core recently(!), which make it much harder to figure out how it all fits together. And third, are definitely being written targeting a rust that doesn't quiet exist yet. Futures in particular makes it very clear in the documentation it expects `impl Trait` to be implemented and is designed with that in mind. Implementing `poll` in particular for a `Future` is really awkward with out support for `?` over non `Result` types. Self borrowing structs, more lifetime elision, and non-lexical lifetimes would also allow some of the places where the lifetimes are 'static to improve ergonomics for the average case to have more precise lifetime bounds. `join` would be improved by variadic/tuple generics, etc.
When you tried a year ago, mio probably still had it's event loop system. It's now simply just `Poll`, an abstraction over epoll/kqueue/iocp. You register some sockets, and then poll them, and that's it. Tokio is the event loop layer. That sounds like exactly what you describe, no?
Panic? If I recall, it would just return a parse error (which is technically correct according to RFC7230 :D). It's been made more lenient because specs never survive contact with the internet.
Hey Sean! I think you're right, I think I'm confusing my verbs. And yep, I recall it being per the spec as well, but also ignored by several other tools, notably `curl`. So, we loosened the reins ¯\\\_(ツ)\_/¯ 
I don't think that's the case. FWIW I find Tokio quite hard to grok, and I've written async servers in C and C++, Java (NIO and Netty), Scala (Finagle), Python (Gevent, Tornado) ... Tokio seems...well, honestly it feels very hard to use and get into.
I'm the author. It's worth mentioning that it should also work on vim8.
I don't know when you looked, but "Mio only worked on its own event loop" hasn't been true for well over a year now (and the lib is only 2.5 years old). `Poll` was introduced a long time ago as the under pinning of `EventLoop` and `EventLoop` has been deprecated for almost a year now.
So, you are saying that "Networking in Rust is terrible." and your basis for this is evaluating the state of the ecosystem when the language had *just* hit a 1.0 release? It sounds more like you have an axe to grind and I'm not why.
Leaving the same comment I left on HN: ----- The whole execution contexts thing is sort of based off an assumption that the unique-&amp;mut stuff has to do with thread safety. It doesn't. In fact, it had no bearing on thread safety in Rust for the many years before scoped threads were made possible by removing the 'static bound on Send. [This post](http://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/) details why it's necessary. The article does sort of mention this (and I have talked with the authors about this before) but IMO it underrepresents the importance of it. One thing I did discuss with one of the authors at one point was swapping around the guarantees a bit -- allowing multiple &amp;mut for cases not involving any form of runtime typing (enums and vectors are both cases of runtime typing -- in a vector the number of elements is runtime dependent). This would create a significantly different language and be incompatible with the vast majority of the ecosystem; however, it would still be safe, and has the potential to be useful. I even started hacking on a fork of the compiler that does this, but never got the chance to finish it. The idea in essence is not too hard to implement. ------ As you can see elsewhere in the thread, changing the strategy used and some library extensions was a sufficient solution. In general while I like the idea of pseudo-Rust with swapped around mutation guarantees, I am highly skeptical that there are use cases where Rust (perhaps with some extra non-std safe abstractions) won't work but pseudo-Rust will.
Nim needs a book 2.0 like what rust got. For sure.
The standard `TcpStream` and `UdpSocket` types now have `set_nonblocking` to enable non-blocking mode. There's no select abstraction, but it's trivial to call the select/poll syscalls directly using the `libc` crate. Here's a dead-simple pselect wrapper I'm using in some of my projects: https://gist.github.com/AGWA/b0931a912a8b22b2d6178a3155e171f3 This is what I recommend doing if you want to avoid higher-level abstractions.
I have no ax, but I still find Rust networking poor. I'm reading through the mio docs now, so just hold off on the indignation. Edit after reading docs: I definitely like the direction more than I used to. I'll go back to an old idea and try again.
&gt;Or even "Ok, how does kernel 2.x IRC communication performance compare to 3.x" Did you mean IRQ and not IRC? Or does IRC here not mean Internet Relay Chat?
If you put something side something you gotta take it out or put it back in. ``` let federative_unit = FederativeUnit::South( South::SantaCatarina); ```
It there any way to eye-candy it to avoid repeating South twice?
Nim has a small community and a standard library that is a bit haphazardly put together, due to it being developed by very few people. While it's an OK language, it simply has no chance of attracting any large community due to an overabundance of new languages. 
For http I would go with curl-rust because it's very solid and reliable.
Probably IPC
I think the hardest thing for me is not feeling fluent with the syntax. With the other languages I work in, reading the code feels second nature. It's really a kick to the balls for me to struggle this much. I'll give it another attempt in a few weeks (when my current projects calm down)
Excellent answer. 'C++ has C'? So does Rust. 
&gt; This was impossible in rust/mio a year ago. Entirely untrue.
IRC definitely doesn't mean Internet Relay Chat in that paragraph.
If you get stuck on the syntax or anything you should jump on the IRC to get help. I'm sure someone could help if you run in to difficulties!
You want /r/playrust. Please check before posting in a subreddit :)
Have a `From` impl so that you can do `South::Parana.into()`
You could `use` SantaCatarina.
&gt; You're right; Rust isn't for big old web apps at the moment, because if it were, people would be writing these frameworks. The only reason I'm not is that I'm waiting for hyper-tokio, and figuring out the warts that a framework would need to solve in the meantime!
How did we get from Tokio to Piston?
The IRC channel has been fantastic. The whole community has been very kind to me.
Ah, interesting. This behavior surprises me since in other places the compiler is aggressive in making the user acknowledge the constraints it's enforcing, e.g. the need to re-declare trait bounds in impl blocks: trait Bound; struct D&lt;T:Bound&gt; { t: T } impl &lt;T:Bound&gt; D&lt;T&gt; { ... } but you can't get away with just impl &lt;T&gt; D&lt;T&gt; { ... } because it's not guaranteed that `T` will conform to `Bound`. That's why I expected to have to declare the `Hash` bound explicitly.
How about `opt.unwrap_or(OK(None))`?
This is exactly my experience with Tokio too, there's just so many damn abstractions. I want to write a game in Rust, and looking into netcode of course I tried Tokio. Read the docs and it seemed fine. I wanted the code to still be readable to somebody without experience, no problem right? I figured the bloody abstractions like codecs and stuff were just bloody nonsense because it didn't sit right with my internal premature optimizer AND it feels like it created so much code duplication and confusing nonsense to handle different packet types that I just didn't bother. Ok we'll read the socket bytes directly how hard could it be? Ah you need hell to keep state through the mess of closures and indentation, after trying for half an hour and writing like 3 socket reads I went "nope" and asked on their Gitter if there was a better way. The response was "there isn't you're best off using codecs" So after staring at the codec and transport documentation for 30 minutes I still didn't have a damn clue about anything so I just gave up, deleted Tokio from my Cargo.toml and just used std sockets on their own threads and I made an echo thing in 10 minutes. 4 levels (yes, 4!) of abstraction are not always a good thing. 
I actually started a WebCralwer (it's still badly incomplete). If you want to check out :https://github.com/llde/rCrawly It is actually something I'm building as exercise to learn Rust's concurrency primitives (so I'm not using external crates about it despite the existence of libs as futures-cpupool, threadpool ecc,ecc). It is an almost direct port of a project I did in Java for a university course, so in a certain sense there are bits of code that is not idiomatic at all. I'm using: select hyper hyper_rustTLS (I used to use hyper_openssl but it was a nightmere on windows MSVC, but RustTLS doesn't work for all sites (lack of TLS 1.0 and 1.1) so I may choose hyper_native_tls)
&gt; It looked to me like a piece of software designed without any end use in mind, only "best practices" and making examples look neat. Eg. everything is one-to-many, everything is abstracted behind traits, everything is composable with dozens of things, and even basic functionality is split into 4 different crates. But how else would you swap out your back-end with an r/place renderer?
Tokio has a steep learning curve, and can be really painful once you need to get past the examples where all the logic essentially fits in a single function. I've been fighting with the borrow checker a lot when using Tokio. Because inner futures can't borrow `self` or anything from parent futures. So you end up using `Rc`, `RefCell`, `clone()`, `borrow()` and `borrow_mut()` everywhere. Or a lot of structures partially duplicating each other's content. This is painful. An alternative is to have futures get a context and return it. So you pass the context like a baton. This is also painful. Future-related functions expect different `Item` and `Error` types, so you need to add`.map()` and `.map_err()` statements everywhere This is annoying. Having to use boxes in order to return different future types is also painful, and not a zero-cost abstraction. For simple things, I am going to stick with coio: https://github.com/zonyitoo/coio-rs - Performance is good, and it's far more intuitive to use.
[rust-derivative](https://github.com/mcarton/rust-derivative) implements derives where one can override the bounds used. It's very useful, but it hasn't yet replaced the macros I used to have for this.
Sorry that was unclear on my part. Tokio is written assuming impl Trait, and ? improvements. The other features while a ways out, in particular the lifetime enhancements, could be used to build a better tokio. There are some places where it's clear that ergonomics were chosen over speed and precise lifetimes. For instance Core being 'static and your handles being thread_local by default. 
Thanks, I've never seen that crate before, it looks very useful!
Why isn't [`fn [T]::contains(&amp;self, x: &amp;T) -&gt; bool`](https://doc.rust-lang.org/std/primitive.slice.html#method.contains) generic over `S: PartialEq&lt;T&gt;` ? use std::borrow::Cow; fn main() { let ca = Cow::from("a"); println!("{}", "a" == ca); let arr = ["a", "b", "c"]; println!("{}", arr.contains(&amp;"a")); println!("{}", arr.contains(&amp;ca)); // error[E0308]: mismatched types } * https://play.rust-lang.org/?gist=0d882f3b5d8cd35d213039662c7f7aee&amp;version=stable&amp;backtrace=0
Seen [Rocket](https://github.com/SergioBenitez/Rocket/blob/master/README.md)? It's still not really a framework on the level of Rails or Play or Django, i.e. it's more suited to little app-lets. Could be a foundation for it though, and Rocket will run on hyper/tokio when that's stable. I still don't know if you'd want to write a monolith in Rust. Those things thrive on dynamic languages for productivity, and you're just never going to have that. Searching a .NET assembly for Controller subclasses and automatically building routes out of that? Never. A dependency injection container? Also never, at least not with the feature set you're used to. Rust just can't really implicitly bind anything. This is a weird place to put it, but I've been trying out Clojure a lot lately, and it solves some of these problems in ways other dynamic language web frameworks can't. You can construct arbitrary, extensible SQL queries using a simple map data structure and HoneySQL. EntityFramework/LINQ = almost completely reimplemented in less than 1000 lines of Clojure. And this can be completely customised for your purposes. In regular frameworks, trying to get model classes to map to the correct fields is a huge pain if you're inheriting a database with a different naming convention. In lisp, just make a function to generate names and use that to build queries. Your database has a weird convention? Stick a function in the middle to handle it. Who needs dependency injection when you can just `(def)` the parts you want to factor out? Who needs to have lots of complicated middleware classes, methods to override etc when you can just use function composition? If you're going to build a web framework for productivity today, there are two kinds of productivity to think about. One is the kind where your project is perfectly within the intended use case and you just sail along. Rails hit this sweet spot for a long time when web apps were simpler, HTML-template things, and 'rails g' might get you to 1.0. The other, however, is where you can build your own rails very easily. For this to work, you have to expose all the complexity in the framework to some degree, and allow composition on top of it. Using macro decorators like Rocket is the opposite: what if you want to step up a level beyond matching 'DELETE /api/resource/:id' and start building lots of very similar endpoints (i.e. CRUD)? What happens when you want to include RESTful 'hypermedia' links to related resources or actions in all your responses? You should be able to write a function that takes any resource name and id and spits out a link prefixed with the 'https://example.com/api' the client accessed it with. Your web framework should let you orchestrate all of its layers and create your own framework-like power features. Lots of web frameworks are good at abstracting away web-stuff like sessions, routing, authentication, templating and the file system, and of course databases. But almost none of them do that without killing off or seriously harming your ability to abstract over your own problems. Anyway, enough talk.
**Edited: was referring to the version of rust pinned to ubuntu LTS. Apologies.** ~~I'd also like to second your statement that networking in rust is terrible.~~ Especially in the standard library. (well, not only networking but I regress.) ~~It's become more bearable with the introduction of read timeouts on sockets (a.k.a poor man's non-blocking reads), but~~ it's still inferior to every other language I've had the pleasure and displeasure of using. The situation could be improved by exposing platform-specific functionality and including platform-specific glue in the standard library, but it seems that practicality takes a backseat to api elegance. I've said it before and I'll say it again: I wouldn't use another language over using rust if I have a choice. What benefits it provides far outweighs the negatives. However, as it currently is, rust is the language of workarounds.
F# works like this too, and it pains me ):
I think you picked up the wrong library / level of abstraction. IIRC the codec stuff is for folks implementing integrations with tokio. An application developer won't need to use that, they will need to just use whatever the tokio plumbing library is for Hyper (or whatever). The Tokio stuff is still kinda WIP so the messaging around this hasn't really been polished yet (in particular, many plumbing libs still don't exist).
Yes, that one.
The [ppipe crate](https://github.com/MichaelJWelsh/ppipe) is kind of like this for iterator chains. It's a thin wrapper around sync_channel, but handles the thread and channel creation for you.
It seems the line lengths are different. Did I spot the difference you were looking for? :-p More seriously, is there something about the code you pasted that confuses you? What is it that you wish to know, exactly?
&gt; if it is wise to brave rust in important applications I'd say it's unwise to brave some other language (e.g. C++) in an important application due to memory safety, especially if you're unfamiliar with how to write memory safe code. Once threading and networking get involved, it's *very* easy to make a mistake. Now, whether Rust is a good choice *right now* depends on your needs. I don't know how hardened crypto libraries are in Rust, so it really depends on which is more critical for you: memory safety or hardened crypto. C/C++ may give you fewer headaches than Rust with `ncurses` (or another similar library) due to available examples/help, but Rust will give you fewer headaches in dealing with memory safety, so it's really up to you which is more of a pain point. I think Rust is a fine choice here. Another good choice may be Python (depending on how CPU-heavy your CLI application is) as it's generally seen as more maintainable and easier to write. &gt; Tokio looks appealing for networking It makes the most sense if you're dealing with multiple sockets, as it removes the complexity of dealing with threads while keeping it fast. I'm using it for a game server, but I don't use it for the client I use to test my game server.
Thank you, I am not confused, just I am discovering amazing Rust Language.
The trick with streams is they're reused, so you don't need a massive amount of futures.
 let mut x = 15; let x = 9; vs let x = 15; let x = 5;
so many! I have two traits `Node` and `Functional`. Note: trait Node {fn print(&amp;self);} trait Functional : Node {fn arity(&amp;self) -&gt; u8;} struct Addition; impl Node for Addition {fn print(&amp;self) {print!("+ ( ");}} impl Functional for Addition {fn arity(&amp;self) -&gt; u8 {2u8}} use std::boxed::Box; fn main() { let mut v : Vec&lt;Box&lt;Node&gt;&gt; = vec![]; v.push(Box::new(Addition)); println!("{}", v[0].arity()); } since vector `v` is only takes in trait `Node`, the extending trait `Functional` cannot be accessed in it... What is more, I will still have another extending trait `Terminal` (i.e. `trait Terminal : Node {}`), not shown but needed as it serves a different purpose than `Functional`.
There is no difference in the two examples, because the second declaration of `x` replaces the first one entirely. It just becomes something like let x1 = 15; let x2 = 5; println!("x is: {}", x2); However, if you do let x = 15; x = 9; // note, no "let" here You'll get an error, cause you're changing the _value_ of an immutable variable. This will work though: let mut x = 15; // "mut" makes it mutable x = 9; 
&gt; I can understand the unease, but I think it is a necessity for mass adoption. This is where Haskell's mantra of "Avoid 'success at all costs'" is good for a language. Rust does not need mass adoption immediately, and I think many would agree that working from the lower-level libraries up over a few years will give a better long-term outcome than throwing complex frameworks with non-optimal abstractions at the problem until one gets a foothold.
I recently did some experiments to reduce the `Rc&lt;RefCell&lt;T&gt;&gt;` ceremony needed: https://gist.github.com/stevedonovan/7e3a6d8c8921e3eff16c4b11ab82b8d7. Not a complete solution, but the slightly evil thing is that `Deref` is defined for `Shared&lt;T&gt;`. Why is it slightly evil? Because it hides the fact that it isn't _that_ cheap to access shared references with `s.my_method()` rather than `s.borrow().my_method()`. But often the cost of the method is much more than the dynamic checking needed for shared references, so then it's cool. As for relaxing the pesky multiple-mutable-borrow condition, it turns out that then you're on your own (just like a C++ programmer) and like a C++ programmer you will spend time away from your family debugging obscure errors caused by unsafety. C++ is very much "Ok, you're the captain, let's do this" which is fine if you are captain of a row boat; but if you are the captain of a nuclear carrier it's useful having an executive officer who says "not such a good idea, sir". I don't doubt that there's an interesting potential place in programming language space for a 'relaxed' Rust, but it would not be Rust. 
Yes. It can be hard at first. To really grok the futures library, it's a good idea to first grok Iterators in Rust. The futures design is very much influenced by Rust's Iterators. 
Yeah, I was just screwing around with it the other day and made exactly zero progress after three or four hours of attempting to write an IRC client that used it. And I'm not new to rust. I've been using it since sometime in 2014, if I remember right.
C only needs a wrapper because of syntactical differences. The overhead creating that and using it is very low.
&gt;&gt;"I don't doubt that there's an interesting potential place in programming language space for a 'relaxed' Rust, but it would not be Rust." ... but when all this work has been done, and all it would take is a compile option to disable the borrow checker.. why not? call it 'rust--' or something.. just like we have 'the C compiler family' compiling distinct languages - "C++, objective-C, C, objective-C++" - strictly different languages, but with so much overlap that creating separate compilers for each would be insane. The clang compiler has a unified AST capable of holding the elements from each , which would appear to be how 'objective-C++' comes about naturally.
Ok, what is your question?
&gt; Having to use boxes in order to return different future types is also painful, and not a zero-cost abstraction. To be fair, there is no way to do that with zero cost. When you have something with a type that differs at runtime, you'll have a cost somewhere no matter what you do.
I think rustup can pin a project directory to a given version of the rust toolchain. Useful for embedded or other cross-platform builds too. Edit: `rustup override set &lt;toolchain&gt;`
&gt; zero cost You can wrap each branch in an enum variant. Which would result in a future with the same size modulo the enum tag but avoiding the heap allocation. Also if Rust had support for DST rvalues and returns behind `impl Trait` it would be zero cost depending on your feelings about `alloca` and friends. 
Absolutely. It's basically iterators+.
It doesn’t need [you to write] a wrapper. It’s just `use libc;` and you use it. And, well, by this logic every language that gives you a library that already exports a wrapper for all standard C functions on a target system can do this. It’s another story for some external libraries that aren’t Unix/Linux/POSIX syscalls – then you need to write your own wrapper (or find some 3rd-party crate), but for things like `epoll`, `select`, `kqueue` you have `libc` which pretty much is standard (Rust standard library even depends on it!).
Tokio, used directly, is mostly for library authors. Users are more likely to be using libraries that use tokio rather than use tokio itself. At least that's how I see it.
It still needs it and I'd argue it's not just syntax. It's FFI. C++ isn't FFI. The first example shoes this: https://doc.rust-lang.org/book/ffi.html C++ for the majority of code is a superset of C. Rust isn't. You can't claim rust has C too. In that case NodeJS has C too. 
Probably because Windows uses IO Completion Ports instead of epoll/select and the standard library tries to be cross platform and fairly minimal. If you want a cross platform wrapper on top of epoll/select, that's basically what `mio` is.
I need help satisfying the borrow checker. #Problem: (read the Background Info section below if you need to understand what I am writing / what this code is) Here is my code: http://codepad.org/Ns2zoDnA I get a compiler error saying that I cannot set the newly-parsed program, because `self.program` is borrowed. I don't understand what is going on and how to fix this error. I would appreciate it if someone could explain to me what is wrong with my code and help fix it. Here is the actual compiler error: http://codepad.org/EBLbUeKB #Background info: I decided to write a little emulator for a machine architecture that I made up (inspired by the SUBLEQ OISC) as a toy project, to learn Rust. I am trying to load and parse the program binary code from a file. Every instruction is one byte, containing a 2-bit opcode and two 3-bit operands (representing register numbers; there are 8 registers total: the program counter and 7 general-purpose). In Rust, I have an enum type to represent the program instructions, with the variants holding references to the operand registers.
Do you mean that WSL will be generally available (that is, out of developer preview), or that support for missing system calls will be available? The latter could pose some problems, but nothing that can't be worked around with some conditional compilation in Nix (I've been meaning to boot into windows and test things out, but I hate leaving Linux).
I think this comment typifies the problem here. Netty was built on top of nio to provide an event loop and unified and simplified view of networking. But nio had to exist for Netty and others like it to exist. It shows to nio's strength that there are so many frameworks out there. Everybody here seems to want to jump to the Netty level and ignore the basic nio level that is required if there is going to be a prosperous network ecosystem. You don't start with Netty and build up. You start with nio and then build Netty. And Java usually takes a few attempts at a library before it gets it right, but nio is one of the few there Java got the abstraction level mostly right on the first try. It is almost good enough to lift wholesale and transplant into rust.
https://github.com/rust-lang/crates.io/issues/27#issuecomment-267203383
I added this possibility: look at the [include example](https://github.com/antoyo/relm/blob/master/examples/include.rs#L76).
Is there (neo)vim-native (no Python or Lua needed) Language Server Protocol client for (Neo)Vim? I'd love to have that and use it for all languages rather than many language specific plugins.
In case you're wondering what's changed here, see aturon's comments from yesterday: &gt; I've extensively updated the issue with a lot more detail on the lang team's plans and various ideas that are currently in flight. I've tried to tag items with a lang team member where there's a clear person trying to push forward an idea. I've also called out opportunities for mentored RFCs (just search for "mentor"). &gt; Let me know what's missing! And: &gt; Added coroutines; supporting async/await notation in some way could be a very important ergonomic/learnability improvement to the extent that we're leaning on futures-based abstractions for async IO.
Thanks for your comment! For the "DOM diffing", someone mentionned [GTK+ scene graph](https://www.reddit.com/r/rust/comments/64xmkk/relm_a_gui_library_based_on_gtk_and_futures/dg6t2a4/) which I might use when it will be released. That will probably fixes some issues you mentionned. I'm still not sure to understand the limitation caused by the mutable model. In the future, the model will probably come back to be an attribute of the `Widget` and since the `update` function takes `&amp;mut self`, it will be able to mutate it. In a purely functional programming language, you would use an immutable model, but in Rust, it is frequent to use mutation. Could you please expand a bit on this?
If you're using `pkg-config`, and assuming /u/pmeunier's function allows you to pass dependencies into the crate derivations as `buildInput`s, linking should "just work". An example of what *should* work: https://github.com/alexcrichton/curl-rust/blob/090eda1cac02dd66ca517ab79fbffa8776502d87/curl-sys/build.rs#L38-L47
From my experience it is pretty old Java disease.
I somehow doubt that it would be that simple - although the great thing about open source is that people can try that out. I'd like a scripting language which looks and thinks like Rust (lily is not there yet). Personally I'd rather wait for further ergonomic progress like non-lexical lifetimes; the borrow checker is fine, it's just that it can be a bit stupid sometimes.
This entirely depends on what you consider to be FFI. If you recompile C with a C++ compiler, than your statement is accurate. If instead you only include a C header, and link against a library compiled in C, say a system library, than that linking is pretty much an identical set of overhead between Rust and C++ when working with those C libs. The only difference being that we need the external interface definitions and unsafe wrappers on the pointers and types being passed into Rust. While not free, for those of us who've decided Rust's safety is worth the mental overhead, this work doesn't feel excessive. On top of that, there are some tools (which I haven't used myself yet) which are making the header file translation an automated operation, so that overhead is going down in cost too. NodeJS has some nice FFI to C, but it's not as low overhead as Rust and C++, so I don't think that's a fair comparison. Although, b/c of nodes ease of importing C libs, it does make using Rust libs in Node really easy (never even need to write a C header file for that).
I've long held the opinion that Go's model (green threads; all operations look synchronous to the engineer) represents an excellent balance of usability and performance. It reduces cognitive burden and line noise and makes it trivial to build networking libraries, clients and servers. Futures are more general and performant, yes, but the resulting code can be much harder to deal with.
I kind of think the syntax issue is one of documentation. I was in the irc rooms daily because of it. And like you I can usually read other languages easily but even though rust is clean it isn't simple. The docs for Rust either don't cover what you want, are out of date, or are too difficult to understand probably because they were written by those who already know rust well and haven't had the beginner issues in a while.
Nice work /u/pmeunier! I would be interested in collaborating with you on this (FWIW, I'm the author of the Ruby/Bundler integration in Nixpkgs, among other things), though my Rust abilities are... rusty. I can help out with design and any Nix-specific bits, and as I get up to speed with Rust again, I can start to help out there, too. I idle in #nixos on Freenode as `cstrahan`, if you ever want to ping me.
I feel obligated to note that performance may not be the best with such a simplistic pipeline. There are a few issues: 1. transfer cost: queues require synchronization between CPUs, the more CPUs, the more expensive the potential CPU hop, 2. locality of memory: on the target CPU, you get a cache miss, and some CPU synchronization is necessary to transfer the cache lines from the current CPU to the next if you write to them, 3. workload asymmetry: in such a pipeline, the slowest stage essentially defines the whole pipeline speed. The biggest issue by far is certainly (3), unless your pipeline library allows multiple concurrent executing threads for a given stage (and a way to parameterize it). However, (1) and (2) can also be an issue if the work of a given stage can be very small, such as a check that there's nothing to do before moving to the next stage. In the end, while the idea of pipelining is elegant, you may find yourself better served by a task pool, depending on your problem. A simple pair of I/O pool + CPU pool for example.
I understand how Carl feels though. He's spent a ton of time thinking about this problem only to see a comment get gilded and 50+ points by repeating information that was outdated this time last year.
So, each `Machine` contains some `Register`s and a `ProgramMemory` which is a collection of `Instruction`s, which contain references to the `Machine`'s `Register`s. This kind of cycle is very hard to deal with in Rust -- a struct containing references into itself can't be moved, among other things. I'd recommend keeping register indices in the `Instruction`s instead of references, or not putting the program and the registers in the same struct.
Don't get me wrong! People will absolutely need to do this. But I think that overall, it's a slightly more involved task than most users. That is, for everyone who writes a protocol implementation, there are more users of that protocol than there are writers. I think this will get better and easier over time; developing for a cutting-edge library is just always going to be harder than using it.
Huh even if I don't specifically link with -l
The error means that the compiler, knowing nothing about type `D` except that it implements `Store&lt;...&gt;`, can't capture a variable of that type in a closure whose code will be executed in another context unless it knows that it doesn't contain any references -- otherwise, those references might've become dangling by the time of execution. So, the `'static` requirement basically means "no references (unless they outlive the `'static` lifetime)". Does your db handle contain non-`'static` references? If not, you can follow the suggestion in the error message and say fn host&lt;D: Store&lt;Query=Vec&lt;Bytes&gt;&gt; + 'static&gt;(db: Arc&lt;D&gt;) -&gt; io::Result&lt;()&gt; {... Another thing that can trip you up is variable capture in closures; things like `Arc&lt;...&gt;` and `Handle` generally need to be cloned and moved into the closure to make the compiler happy. So, you should use something like let mut db = db.clone(); before `spawn`ing the future. The error messages... are painful, agreed, but IME they're rarely worth analyzing in depth, since the reason is usually something close to the surface, so to say. I suppose things will get a bit better with `impl Trait` when that arrives.
For Rust it seems like a pattern though "yeah it doesn't quite work well, but when we get this next layer it will be awesome" (see the borrow checker of you need another example). Seems like rust will forever be one layer away from general usability.
I also see this in other languages too. :) That's the whole point of making new features; you want to make some sort of thing either possible, or easier. New features exist to be used!
Since it seems that your top comment has ended up in such a prominent position, and that so many people agreed with you possibly because they do are not up-to-date on the latest developments, would you mind terribly updating top comment either to "soften" it up, or to add a disclaimer that it reflects an outdated point of view? It was a good critic (although a bit of a rant, we're all guilty of being frustrated sometimes), and I feel it would be even better if it more accurately the present and maybe pointed readers to the current resources (such as the [`mio`'s frontpage](http://carllerche.github.io/mio/mio/index.html)).
Thanks. That's very informative! I might try to get the python-less version to work.
OK, you probably want to expand the question with more context from your situation then.
That was the Vec part. I'm not sure if there's a way not to allocate memory every time, but the current implementation doesn't appear to slow anything down.
I would really like to see a middle-level overview of that coio-rs library. What are the coroutines in coio-rs? How much do they "weight" in terms of stack usage and switching cost? How does the switching works? (I know `setjmp/longjmp`, `&lt;ucontext.h&gt;`, `Boost.Coroutine` and how they differ in cost and portability, but I have no idea where coio-rs fits) Who runs the coroutines? How it uses multiple processors if it does? How does it relate to green threading? To fibers? Of a particular interest to me is whether it's easy to integrate (mix and mash) the coroutine code with existing callback and thread-based solutions. I've seen some nice articles about Tokio stack but none about the emerging alternatives.
To be honest, I somehow really wish I could edit the title you picked. I am mostly surprised by how positives the replies are, considering we are talking about 4chan; but I don't see much of interest here.
I am not an expert in mio. I do quite a lot of high performance network code though. I don't call myself an expert at anything, but working at trading firms I have put in many hours on many systems.
I'm not sure but it might be in reference to this? https://github.com/rust-lang/rust/issues/41270
I read through all of the comments and found nothing that could be considered as constructive criticism except that error messages could be improved. I think this is an issue that has received a lot of attention lately with a big thanks to Jonathan Turner and everyone else who has participated. For anyone interested in helping improve error reporting system, there is a [GitHub issue](https://github.com/rust-lang/rust/issues/32777) for implementing more explanations for more errors.
You must have been in one too many debates about the differences of two approaches based on the number of characters typed ;)
&gt; It's become more bearable with the introduction of read timeouts on sockets (a.k.a poor man's non-blocking reads) Does [`set_nonblocking`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_nonblocking) help? If not, why not?
Especially `dyn Trait`
A future may wait on or compute arbitrary things, but when it's done, it's done, you get the value &amp; drop it. Streams can produce arbitrary numbers of values.
As someone who's spent more than a healthy amount of time on the chans my opinion is that Rust is well received in this thread. Most people might find 4chans way of communicating off putting but the volatility of the community is part of why it's survived so long.
It's the original title. I didn't pick it.
To be fair, shitty is one of the least offensive ways to say you have disdain for something on 4chan.
This is great. Very happy to see this.
Can someone please dumb this down for me?
Its about 'type level integers', like implementing a trait for all arrays.
How about stabilizing [step_by](https://github.com/rust-lang/rust/issues/27741)?
Imagine you want to write a function that takes an array as an argument: fn foo(array: STUFF) { what do you put for `STUFF`? Arrays have the type `[T; N]`, where `T` is the type of the elements and `N` is the length of the array. So, for a generic type `T`, here's the first step: fn foo&lt;T&gt;(array: [T; STUFF]) { ... but what about `STUFF`? it needs to be a number, but it can't be just one number, it has to be any number. In today's Rust, there's no way to write `foo`. With this feature (given /u/desiringmachines 's strawman syntax): fn foo&lt;T; const N: usize&gt;(array: [T; N]) { Now you can pass arguments of any size to `foo`.
This is something that's just always going to be true. No Starch is happy to update the book periodically, so we'll get updated versions of the print book. But it won't happen super super often, exactly. But yes, more major changes would mean it's a better idea to update. We'll see as it all goes.
Nim is an evolution of Delphi by way of Python, with a few good ideas about concurrency. It's an evolution of the standard imperative language design. Consequently it's likely much easier to learn than Rust. Rust is harder to learn. It uses a lot of ideas from the ML family of languages (so called trait/protocol orientated programming), and also has a resource tracking system -- the borrow-checker -- that you'll never have seen in any language before. I'm not sure about the library situation for Nim. Rust's is okay, though the web-serving toolkits are all a bit young and there's no good GUI toolkit that'll work on Mac and Windows (GTK really doesn't count) So why learn Rust? Well partly because all the ideas that have appeared in Rust are also appearing in Apple's Swift, and many exist already in Microsoft's F#. Learning the idioms that Rust uses is therefore a decent transferable skill, presuming you already know one other imperative OOP language. Note that I'm saying _learn_ and not _use_ here. If you have a project you want to get done, that very much depends on the project. Rust can offer deterministic memory-management, safe concurrency which I don't believe Nim can.
[removed]
You need more upvotes. &gt; Someone may have written a rustc plugin to flag obviously secret-dependent timing, or secret-dependent memory indexing, which can lead to cache timing attacks. I was on a team that made a tool just like this for C. Unfortunately it's very tied to C because we used clang and didn't really test with C++ or try to support it. We wanted to open source it but we never got the approval. I kind of wish we had done it at the level of LLVM instead because then it would work for rust. The main caveats were: * It required lots of user annotations because it didn't do any inference (on the flip side this let us avoid dealing with potentially ambiguous cases). * It was fairly conservative so in some cases it might say you have a potential problem when things are actually fine. I wonder how hard it would be to make a rust version, perhaps as a compiler plugin...
I'm not sure how it's determined that a feature is related to "ergonomics" but I will keep pushing for stabilization of `TryFrom`/`TryInto`, as it's the #1 thing keeping me on nightly Rust in most of my crates. I haven't had much luck trying to get the libs team's attention to make a decision about it. Tracking issue: https://github.com/rust-lang/rust/issues/33417
&gt; I personally like the clarity that comes with seeing that I explicitly passed something by reference in my code, that way I know I did not consume/move it. This isn't what Rust offers though. Consider: ``` f(foo, bar, baz); ``` In this example, it is possible that `foo` is passed by reference, `bar` is moved, and `baz` is copied.
Like this right? impl From&lt;South&gt; for FederativeUnit { fn from(original: South) -&gt; FederativeUnit { use self::South::*; match original { Parana =&gt; FederativeUnit::South(Parana), SantaCatarina =&gt; FederativeUnit::South(SantaCatarina), RioGrandeDoSul =&gt; FederativeUnit::South(RioGrandeDoSul), } } } fn main() { let federative_unit = South::SantaCatarina.into(); }
It's almost as though they're people who are capable of functioning and thinking on their own. /s Always irked me how people paint with such a broad brush.
Tokio is like LLVM for networking. You don't deal with LLVM when writing rust or c++ code. But you do use LLVM based compilers. The LLVM documentation won't tell you how to compile rust code, it will tell you how to use LLVM. Tokio is a layer in the stack. You don't need to know how to work with a particular layer to be able to use it.
pub(restricted) will be in the next stable release coming out in May!
https://github.com/Microsoft/BashOnWindows/issues/743 Nix wasn't working before the latest Windows update but now it does. I tried it and had no issues.
It's been blocked on some obscure issues around the `!` type. You should prod sfackler specifically :-)
Wanna pitch in on that? Libs team has been looking for someone to take it on for a while.
Yeah, many on the libs + lang teams think that the distinction is more trouble than it's worth, i.e. that the bugs being prevented here were pretty hypothetical, but it introduces friction for *everyone*, especially newcomers.
That's not correct. The first stable to ship pub(restricted) will be 1.18, the stabilisation has missed the deadline for 1.17. And 1.18 comes out on Jun 09. There is no release in may, 1.17 gets released on Apr 28.
&gt; but we should be aware that this causes pains to users. Pain enough to call the language "shitty". The people who call explicit casts shitty aren't the ones who'd appreciate Rust in the first place. The Rust compiler will stop them from doing way more stupid stuff than implicit casts. 
&gt; If my impression has changed, I will post a review. Where will you post it? I'm curious to read it if you do.
Wondering about the use of `usize` in the syntax: is it ever meaningful to have a non-`usize` value here? I can't have an `[i32; 0.5]`, nor could I always have an array that can hold `u64::MAX` values (embedded systems with limited memory, ect.). It seems that only `usize`will ever be what anyone wants, so why do we need to specify it?
Thank you very much - adding the sqlite feature it now builds :) I'm sure I will eventually want to target something at MySQL but for now I plan to have two components, one targeting sqlite and the other PostgreSQL. 
I installed with just Postgres, planning to come back to sqlite. How did you build `sqlite3.lib` from the Windows x64 distribution of `sqlite3.dll`? 
I think integer generics is the MVP, which will be expanded to support constants of any type, so it needs to be specified for forward compatibility. 
Wat. You would want async web server serving static files ten out of ten times (see how netflix does it). You still have to use sendfile(2), but unless file is in cache this call is going to be blocking, that's why FreeBSD's version has option to throw an error in this case.
Nice! Sorry I'm no help with anything windows related
Is there a video or audio recording ?
I think https://github.com/slog-rs/stdlog provides something like that, no?
References can't be stored alongside the things they refer to. Your reference will get invalidated when it gets moved out of scope.
I was trying to reconcile what you're saying with the fact that nginx is async, and yet still good at serving static files. It makes sense that you'd want async IO for the TCP end, to handle many concurrent clients, but I wasn't familiar with the problems you note on the filesystem end. Turns out that nginx does use sync IO for the filesystem (only if you configure it with `aio threads` for a threadpool to do the sync IO), but is still async for the TCP connection etc: https://www.nginx.com/blog/thread-pools-boost-performance-9x/
None, because there's no good low level HTTP library that uses Tokio or does async as of yet. If handling more than a couple of concurrent requests per process (this can be remedied with nginx, so at least you wouldn't be dropping questions), I'd suggest going with Rocket, but that's just my personal preference. Always make sure that what you're using is being actively developed, however.
I'm completely stumped, why doesn't this work fn main() { let suitable = |_| true; vec![1,2,3].into_iter().find(suitable).unwrap(); } Error message error[E0281]: type mismatch: the type `[closure@src/main.rs:2:20: 2:28]` implements the trait `std::ops::FnMut&lt;(_,)&gt;`, but the trait `for&lt;'r&gt; std::ops::FnMut&lt;(&amp;'r {integer},)&gt;` is required (expected concrete lifetime, found bound lifetime parameter ) --&gt; src/main.rs:3:29 | 3 | vec![1,2,3].into_iter().find(suitable).unwrap(); | ^^^^ error[E0271]: type mismatch resolving `for&lt;'r&gt; &lt;[closure@src/main.rs:2:20: 2:28] as std::ops::FnOnce&lt;(&amp;'r {integer},)&gt;&gt;::Output == bool` --&gt; src/main.rs:3:29 | 3 | vec![1,2,3].into_iter().find(suitable).unwrap(); | ^^^^ expected bound lifetime parameter , found concrete lifetime | = note: concrete lifetime that was found is lifetime '_#2r error: aborting due to 2 previous errors It does work if I inline the definition of `suitable` into the `find` call, or if I use a `fn` instead of a closure.
What if you `A` can't/doesn't want to provide `Vec` of outputs, just offload them to multiple workers as they're ready?
I'm the author of asyncomplete. Adding rust source has been on my todo list but I haven't started it yet. There are already sources for go, flow, typescript in pure vimscript - https://github.com/prabirshrestha/asyncomplete.vim#sources. If you are familiar with vimscript writing rust source should be very easy. 
My main problem with Iron is that it's too split up and the documentation is sparse and divided up amongst many repos that it's just not worth trying to figure out how it all works together. Contrast that with rocket which has great documentation and is easy to work with and add all the necessary stuff to deal with authentication or what not for each route. Heck even Django and Rails are all in one solutions (whether you agree with it or not). Frameworks should be opinionated, otherwise it's hard to get anything done with them.
Very cool! FWIW, there are two things I disagree with from the Rust VS Swift talk, in terms of Rust's design philosophy. First, and by far most important: ownership and borrowing is *not* just about (or even primarily about) memory management. It's about managing [all kinds of resources](http://blog.skylight.io/rust-means-never-having-to-close-a-socket/), *and which code has access to them at which points*. Seeing a function signature like `fn foo(slice: &amp;[u8]) -&gt; bool` tells you a *lot*: you know that `slice` can't possibly be mutated by the function while it runs. Moreover, if you have a `&amp;i32` in your hand, and you read it twice, you're guaranteed to get the same value both times; it's impossible for another thread to write to it for the duration. Neither of these things are primarily about memory management. They're about controlling mutation of aliased data. I wrote a [blog post](http://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html) trying to drive home this point for concurrency. Second: Rust's design also embraces progressive disclosure of complexity. For example, much of the thinking behind lifetime elision is the idea that, especially when first learning Rust, it should be possible to do a lot just with simple intuitions about borrowing, without understanding what lifetimes are or how to parameterize by them (and we want to push this further). Similarly, when working with closures, you can think of them as if they were a totally standalone concept, and only later learn that they work via the trait system. *Every* language has aspects that you have to understand right away, whether it's functions, classes, primitive types, or traits. Ownership in Rust tends to "stick out" as something you encounter immediately, but I think that's because it's an unusual feature, rather than something the design is explicitly trying to do. It is true, though, that there are certain kinds of costs or potential for bugs that Rust tries to steer you away from. But again, the philosophy isn't one of "syntactic salt" or otherwise aiming to throw complexity at you. We strive rather to make the happy path as smooth as possible -- like the fact that iterators are pleasant to use, but are also safe (no out of bounds errors) and compile well. And even in tricky cases like `OsString`, we worked really hard to make it so that you could mostly avoid thinking about it, including by adding convenience methods that assume unicode encoding. The thing I think Rust is unwilling to do is make the easy/default path sacrifice core values of speed and reliability. But we try to make the fast, robust thing as easy as we can.
Another way of putting this: the "memory safety without garbage collection", while a very important crystalization at one point in Rust's history, has ended up serving us poorly in explaining Rust's value proposition. I've been thinking lately about Rust in terms of "confident, productive systems programming" (a positive framing of the ["fearless"](http://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html) perspective). I'm hoping to write up a blog post laying all this out in more detail at some point...
Clarification: the bits about ownership being primarily about memory management are partly a response to the [raw slide nodes](https://t.co/aAwxyb9mQB).
Shameless plug: https://deterministic.space/things-to-rewrite-in-rust.html
I'm away from my computer for a day or two... &amp;nbsp; &amp;nbsp; ...and I'm back :) If you download and unpack the sqlite for windows x64 you'll find a .def and a .dll. You can generate the .lib with `lib.exe` (I used Visual Studio Community Edition 2017 but I'm sure earlier editions will work just as well): cd path/to/sqlite3 lib /machine:x64 /def:sqlite3.def /out:sqlite3.lib 
For me at least, I don't think I would benefit from or use anything on that list (except maybe the toml library). Or maybe I would and I just don't realize it? As such, I think it would help if you wrote a bit about: * Why it's important to rewrite them in Rust (does some feature of rust make it compelling? Memory safety probably being the obvious win in most cases) * Why is the suggestion on the list instead of something else that's not on the list? Kind of like asking, why is this particular library or program of interest? Like your footnote remarks, I could imagine just saying "rewrite all the things" but then reality sets in and priorities become necessary in order to be productive.
You can only use Rocket on nightly, which has become important since serde and diesel started working well on stable.
Like other people have said, do something that interests you. But some random examples are: * Game clones (e.g. Tetris, Asteroids, Pacman) * Gameboy emulator * Chess engine * Simple substitution cipher cracking program * SHA hashing implementation (SHA-1 at least is suprisingly easy) * Simple file manager or text editor * Machine learning program e.g. for playing poker * Sudoku generator/solver with GUI * Implement various sorting algorithms * Fractal generating program
How could I write this more efficiently/idiomatic? let args: Vec&lt;String&gt; = env::args().collect(); let s = match args.get(1) { Some(e) =&gt; e, None =&gt; "" }; I figured I could use `let s = args.get(1).unwrap_or("");` at first, but it fails with "expected struct std::string::String, found str". Also if I try to concatenate the expressions into one, I get an error that I don't understand in its context: let sourcefilename = match env::args().collect::&lt;String&gt;().get(1 as usize) { //... the trait `std::slice::SliceIndex&lt;str&gt;` is not implemented for `usize` note: slice indices are of type `usize` or ranges of `usize` --- On another note, what's the reasoning behind having some functions expect mut references for providing results instead of returning them? e.g. `File::read_to_string(&amp;mut self, output: &amp;mut String)` - It seems to hinder the use of a more functional programming style, or are there ways around it?
I don't know the reason, but annotating the type of the closure argument to be a reference compiles for me: let suitable = |_: &amp;_| true;
 &gt; On another note, what's the reasoning behind having some functions expect mut references for providing results instead of returning them? Performance I believe; calling it many times in a row would be faster compared to returning the new string, due to not having to allocate a new string. (I'm not sure this was the right call, given the worse ergonomics.)
&gt; the borrow checker is fine, it's just that it can be a bit stupid sometimes. The borrow checker is fantastic, for Rust's mission statement. The problem is, to guarantee safety, it must *over-estimate it*; There are programs that are still safe, but it's much harder to actually prove analytically at compile time. In 3d graphics, indexed primitives are incredibly common. The indices can be verified to be valid when an object is created (loaded or generated), and the programmer may know that those objects are then immutable - but I dont know of any way of analytically proving that. (an immutable reference for individual functions is not enough to prove that the objects haven't been changed elsewhere between invocations, and you have the scenario of streaming systems where the objects may be created and destroyed asynchronously.. ) (I've heard about dependant types but dont know the solution they offer). You could put some debug asserts in that will trip if the programmer adds code that changes the buffer or the indices (and you need to regularly use debug mode for other reasons), but thats not analytical proof. To be strictly safe, Rust's array indexing needs to be bounds-checked.. which is overkill with runtime-overhead in this context. That's just one example, there are others (as I write this I suppose you might be able to concoct some index buffer object that maintains the extents of the contained indices, but I haven't seen any consensus on such a scheme.. and it's still going to add runtime overhead. It would certainly be interesting to try) 
I planned to write a Butteraugli port in Rust, but they is literally no paper or communication about it. Hence, one need to implement it in Rust from the cpp code instead of implement it from their physical approach.
&gt; I would recommend libsodium over ring/OpenSSL/friends if you have free choice of crypto primitives. Mostly because I trust djb a lot more than NSA; also for reasons of code quality. What are some examples of libsodium code that is of higher quality than the code in *ring* that implements the same algorithm? (I'm genuinely curious about people's perceptions here.) &gt; However there are many ways for those to sneak in at the LLVM or machine code (or even hardware) level. Doesn't *ring* have a huge advantage with respect to this, considering that the vast majority of its timing-sensitive code isn't affected by any optimizer, since it is in assembly language?
If you're developing a single page app, it doesn't really matter which backend framework you use - all of the ones listed can do REST APIs.
Perhaps consider `let arg1 = env::args.nth(1).map_or(Cow::Borrowed(""), |x| Cow::from(x))`?
Then I need a way to reflect that in the function definition, maybe a channel in the argument? The problem would be the creation of a channel every step, but they can be optimized. 
yes, but it is in french https://youtu.be/XKJHHPB74v4?t=37m49s This was part of talks about Rust in Lille - France.
I've got one more question: Why can the questionmark operator not be used inside an expression, but only inside a function? Consider this (rather silly but relevant) example code for reading a file: let content = (||-&gt;Result&lt;String, std::io::Error&gt; { let mut s = String::new(); File::open("path")?.read_to_string(&amp;mut source)?; Ok(s) })().unwrap_or_else(||String::new()); Clippy complains about the IIFE, but the (arguably prettier) code it suggests does not compile - "Carrier trait not satisfied" seems to imply that the expression block is not regarded for resolving the questionmark result. let content = { let mut s = String::new(); File::open("path")?.read_to_string(&amp;mut source)?; Ok(s) }.unwrap_or_else(|e: std::io::Error| String::new()); 
/r/playrust
Oh! I expected that `Ord` was just refinement of `PartialOrd` too, it's quite surprising that it's not :(
Yes, it would be.
Yes but I've seen examples of Rust compiling to JavaScript and was wondering if any Rust frameworks did that.
My understanding from bluss is that there is an even stronger intent, that `Ord` is not just a refinement of `PartialOrd`, it is the same order (when it exists). Several parts of stdlib make this assumption and use `PartialOrd`s methods `lt`, `le`, etc as if they were always the same as `cmp`.
I hope "Implicit widening on integer types" doesn't make it. Just thinking about bringing this part of C implicitness to Rust makes my head hurt.
Right, so, ignoring my other post, I went over your code and figured out what you're doing - you're storing UI state in the `ui` object, then when the client connects, you send all that state and then the ongoing messages. Now, as far as I can tell, you don't actually need that `thread_ui_state` thread - you can just use another tokio stream. I've done that in my rewrite. I've also cleaned up a lot of the rest of the code so it's more readable - including using `forward` to send things to streams rather than your fold-and-send mechanism, and `chain` to chain your initial state to your ongoing messages and remove some code duplication. EDIT: Fixed some typos, spawned `accept_async` rather than spawning the connection only once accepted: https://gist.github.com/4c707da6cb049b3904c4416fa927b5bc Note that this *does* mean your main thread has to be futures-aware, since I've switched to using futures::sync::Sender to send to it. The alternative is to allow the websocket thread to block in some case, which is a bad idea with tokio. You can convert the futures::sync::Receiver into an iterator using `.wait()`.
Isn't that function fixable by wrapping each of them in `{}`? fn foo(&amp;'a mut self) { { self.run_inner(); // first mutable borrow } { self.run_inner(); // second mutable borrow } }
Nope - borrow ends at the end of the function even if it is wrapped in another block.
I posted on the other end of the link, but I did want to do a +1 for `PartialOrd` is actually a useful trait in its own right, independent of bug prevention. Not having such a trait would also introduce friction.
I don't think its fair to say "None". Non-async frameworks are doing fine. Iron for example, can handle few hundred thousands requests per second. 
The questionmark resolves to a match with a return. You currently can't "local return" out of a block, but there is proposed `catch` block syntax for this (`let result = catch { foo()?.bar()?.baz()? }`)
Yes, I read the bug you opened and the discussion that ensued after writing this comment. I think have a single ordering makes sense; though it should probably be clarified.
Neat.
Thanks! I can't test your code right now, I will do it when I get home. So I don't need a Mutex (and thus no Arc) because when using futures everything will run in the same thread? (does it?) You are doing rx_main_to_ui.clone() in line 14 but rx_main_to_ui.add_stream() in line 19, when should I use which? My assumption was that I should use add_stream() when I want messages to be sent to both, and clone() when I want both receivers to compete for dispatching the messages (the first one that asks for a message gets it, the other one doesn't). Is this assumption correct? If yes, shouldn't line 14 use add_stream() too, because I want all messages from the main thread to be sent to the state accumulator AND the browser. Is blocking bad in Tokio because of futures or because of an implementation detail that doesn't depend on futures? How bad is it really and what are the consequences? If I use a std Sender send() in ws_reader, will cpu usage be high again? Btw, what caused the high cpu usage in my original code?
Thanks! Glad you liked it!
Wow, that's a great trick! Does it care if the version mismatches in the local version?
What backend did you end up using? Termion looked interesting to me 
Ok, I think I know the underlying problem now. `&amp;'a mut T` is variant over `'a`, but invariant over `T`. https://doc.rust-lang.org/nomicon/subtyping.html Which means that the lifetime that's part of `T` cannot vary, which makes a mess of things. Here's the closest issue I was able to find: https://github.com/rust-lang/rust/issues/27031 Which seems to indicate that while what you're doing is sound, it isn't recognized as such by the borrow-checker.
My first thought would be: if you have to break it, break it early. Using the fact that this situation allows `Ord` and `PartialOrd` to be incoherent while the standard library expects otherwise, I would argue it is clearly unintended and qualifies as a bug fix. I would naively expect little breakage, and only in already dodgy situations: people should either derive both or none. I would also naively expect the same applies to `Eq` and `PartialEq`: both or none. --- Otherwise, would cheating be possible? That is, would specialization allow providing a blanket impl of `PartialOrd` for types that implement `Ord`? This makes me slightly queasy, but it's not like we don't already have such a situation with `Copy` and `Clone` (where `Clone` is implemented as `fn clone(&amp;self) -&gt; Self { *self }` because the type is `Copy`). It seems to me specialization should allow it. Would not help pinpointing the dodgy cases though.
That's okay. From what I've gathered, this hierarchy I've built isn't bad, *per se*, but it is a bit over-engineered for my current project. I could have easily used a "fig pudding" model and thrown all my source into a single folder to get the same effect. Now, for a related question. What about separating my toys into individual crates? I mean this as a learning exercise. Compiling each of my units (infix, prefix, calculator) into separate libraries is a bit heavy in terms of overhead. Is there an easy way to accomplish that, short of writing a cargo stub for each folder and renaming files?
I will probably flatten my project to this route when I push it to GitHub. I admit what I have is over-engineered. See above. I asked about packaging each tool into a library. A lot of overhead for this project (so I probably won't), but is there an easy way to split code into reusable (either) pre-compiled libraries or crates? I could make a crate for each source file, but I was wondering if Cargo handles nested projects that emit a series of crates that can later be assembled for deployment. Too much work, perhaps, for this project, but it might make sense in a different context.
I started out with ncurses-rs, then switched to termion to simplify dependencies. I didn't see any problem switching backends, everything went pretty smoothly.
[Workspaces?](https://github.com/rust-lang/rfcs/blob/master/text/1525-cargo-workspace.md) There's not much advantage to splitting crates apart for fun; a common idiom I see is to make a library and the executable that uses it two different crates if you're looking to practice that. That's what I did on my larger Rust project; the main work is in a library crate, and the two programs that consume it are separate.
&gt; and given that `as usize` doesn't check for overflow, it's more error-prone to boot Wait, not even when overflow checks are activated? 
This is getting a little old. Async is *not a requirement* for building web frameworks. There's no one-size-fits all. For example, if your request-response pattern is CPU bound there's no advantage to async: you're better off just churning through the request on the thread that received it and returning a response. Or, if you're streaming data from disk it's often more efficient to do it in a single thread. Where async *really does help* is if you have to service hundreds of clients where only some fraction of them are active. This can happen if you make a request to another backend service and are waiting for a response, or you're just holding connections open with the occasional keep-alive or making db calls or...you get the idea. To the OP: use whatever's simplest. You're far better off getting something working that you can play around with and explore your problem space than trying to chase performance or work with bleeding-edge undocumented code.
&gt; either "valuable explicit annotation which helps prevent bugs", or "completely redundant information you're forced to write out for no good reason at all" If it is redundant in some cases, and in some its not, then I think its worthwhile to have. About match ergonomics, to infer * and ref, I do agree actually. I don't disagree with everything in the list. &gt; you're forced to write as usize to index an array You are not. You can convert the types beforehand, e.g. when you store them inside a variable.
Alternatively, if a newline isn't desired, make sure you `fflush(stdout)` in your C code after printing. This will also make sure to actually print the buffer.
I ran into something similar a little while ago. I think you need to clone your Arc&lt;D&gt; before the for_each line. I could be wrong here, but I think t's the same error you get if you use thread::spawn from std and try to give it ownership of a reference, since you don't know when that thread will finish, the reference needs to have either a 'static lifetime or you need to use a ref counted pointer. You need to wrap it in an Arc and clone() it first.
Can anyone more familiar with rustc and LLVM internals give an overview of roughly what percentages of a typical `--release` build time we might be talking about here?
Yes, of course, Rust should be practical, and avoiding all bugs is not its goal. &gt; The price for the distinction, however, is that every person learning Rust has to learn this unusual distinction Haskell has the distinction as well, although its not as important there as float types implement both Ord and Eq. And yes, people have to learn the distinction, but at least on my university we learned what partial relations are in the first semester, so most people shouldn't be new to that concept. As for those who haven't went to university: they shouldn't be denied knowledge about this :). Of course, `#[derive(PartialOrd, Ord, PartialEq, Eq)]` is rather ugly, it could be shortened.
&gt; [...] why not have a binary notation where you literally write the significand and exponent verbatim as it will appear in memory? I don't know the exact reason, but I have a couple of possible explanations: C didn't historically have binary literals so it might have been awakard to add float-only binary notations, and C theoretically allows for non-binary floats (!) so the memory dump might not be as useful. Maybe the standard authors might have just wanted to make the exact description possible without making too many changes... &gt; [...] but IIRC, hexadecimal float literals in C still use decimal for the fractional part, not hex. hexadecimal-floating-constant: hexadecimal-prefix hexadecimal-fractional-constant binary-exponent-part floating-suffix[opt] hexadecimal-prefix hexadecimal-digit-sequence binary-exponent-part floating-suffix[opt] hexadecimal-fractional-constant: hexadecimal-digit-sequence[opt] . hexadecimal-digit-sequence hexadecimal-digit-sequence . (By the way oops, I thought hexf's syntax is compatible to C, but it had one missing case.)
I'm glad we're getting a team dedicated to this. I'm surprised we haven't before. Were all the things like homu etc. all under the tooling team or something?
There could be a simple way with sinks and streams, but I'm still figuring things out.
Rust can compile to [WebAssembly](http://webassembly.org/) (not the same as JavaScript!) but: 1. It's very early days yet, both for the WA spec and for compiling Rust to it. Neither are even close to being production-ready yet, but you can have a play around with it. 2. There's no frameworks available (that I know of) that'll allow you to make a single page app purely in Rust. I hope someone does come up with something like that once things are a little further along, though! I'd recommend checking out [Elm](http://elm-lang.org/) if you're looking to write a single page app in a strongly-typed language - it's a lot more Haskell/F# inspired than Rust, but they share a lot of concepts. *(On an unrelated note - can people please stop downvoting honest questions? Just because the answer seems obvious to you, doesn't mean it is to everyone else!)*
[In limerick form](https://twitter.com/llogiq/status/853177664496173057)
You sound as if you don't understand the cost side of the equation. Or do you just want rust to keep features that are never quite usable?
At the mid level there's [tokio](https://tokio.rs/) which is where most of Rust's async is moving towards. But it's still in beta, and can get a bit complicated. There's some planned Language features that should hopefully make it more ergonomic. The epoll abstraction typically used in Rust (and Tokio) is [mio](https://github.com/carllerche/mio)
&gt; You can convert the types beforehand, e.g. when you store them inside a variable. Sure, and then you'll run into friction and cast noise elsewhere. You haven't encountered this?
If you just want epoll, use mio. Tokio is a thicker abstraction, with its own event loop, something like what Node.JS has.
I'm not aware of such plans, and the core team has indicated they want to wait and see before making decisions. Why do you specifically want a solution from within the standard library?
My workplace would be more willing to use rust for our current projects if such functionality had std lib support. But I can understand reasons for not including it in the std lib, we would just have to use rust for different projects that don't need this functionality. 
&gt; Sure, and then you'll run into friction and cast noise elsewhere. That kind of casting is not noise for me. I don't want to get the mess back I came from inside the C/C++ world. You might think you are getting rid of seemingly superfluous noise, but it immediately negatively affects coding practice. First, you won't get an idea which integral types are involved. Second, other integral types will invade places in the codebase where usize/isize would have been better. Like [here](https://github.com/godotengine/godot/blob/df61dc4b2bd54a5a40c515493c76f5a458e5b541/core/array.cpp#L208) or [here](https://github.com/godotengine/godot/blob/df61dc4b2bd54a5a40c515493c76f5a458e5b541/core/array.cpp#L82), or [here](https://github.com/godotengine/godot/blob/df61dc4b2bd54a5a40c515493c76f5a458e5b541/core/pool_allocator.cpp#L180). Yes, you can try to prevent this by coding style guidelines and manual review, but why not force people to think about what they make usize and what other integral types by requiring casts.
Keep in mind that a big part of the Rust philosophy is to keep stdlib slim and rely on how high quality Cargo is. That's why things like [regex support](https://github.com/rust-lang/regex), which, in any other language, would be in stdlib, are instead maintained as crates owned by the same GitHub organization as the rust stdlib or by the [rust-lang-nursery](https://github.com/rust-lang-nursery/) organization. It's essentially an extension of the libstd/libcore split in the standard library that also gives them the added flexibility of being able to maintain a 1.x support branch while they innovate in 2.x (and beyond) if they discover they made a horrible mistake in the API/ABI design of 1.x that's not feasible to fix by adding `foo_function_v2` and friends.
Iron provides minimal usable set of well defined core concepts, allowing me to have good understanding of the framework and implement anything I can think of. It deasn't have anything that is not necessary and this simplicity is a feature.
You can look at [E-easy](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-easy) or [E-mentor](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AE-mentor) issues in order to get involved. One of the best ways to communicate with compiler developers is on the `#rustc` and `#rust-internals` IRC channels. Rustc is a production quality compiler with many features, so its very hard to do bigger changes to it. If that is your desire maybe something simpler is better. However, I've heard from people that it was much easier for them to contribute to rustc than say to clang. Also, the rust community is very welcoming! And even if you don't wish to contribute, the codebase is a great place to learn.
&gt; I don't want to get the mess back I came from inside the C/C++ world. I sympathize with this, but it's worth considering what the particular constraints are in C/C++ versus Rust, and what things are appropriate given those constraints, and whether or not they are the same. For instance, a whole generation of programmers has grown up to despise checked exceptions on principle based on their experience with Java, even though most of the pain is due to design mistakes in Java and not inherent to the idea of checked exceptions themselves. &gt; Second, other integral types will invade places in the codebase where usize/isize would have been better. I've had the opposite problem, where I end up making things be `usize`s out of exasperation, when a particular fixed-size type would've been more logically appropriate, just because I also use them to index an array.
I put together [a list of projects](https://github.com/whostolemyhat/learning-projects/blob/master/Readme.md) a while ago which I'm working through, so there may be something on there which takes your fancy.
And while this maybe a sound technical strategy. This philosophy is the single biggest reason Rust will take longer to gather enterprise adoption. It takes a lot to convince people/processes in these organizations to change at all. Adding hurdles to understand these intricate support stories is just a nightmare. Especially when it is for "basic" (i.e. expected) features like regex and async io. The only upside is that eventually Rust's merits will force them to adopt Rust, regardless of this flaw. But I worry the difference in timelines is in the 10s of years. 
Mozilla has an office in Paris and I think at least one of the Rust devs works there (maybe pnkfelix?), though I don't know if they're hiring for any Rust-related positions right now.
Oh I know, I go to the rust meetup in their office every month. But as far as I know, they don't hire for Rust.
I haven't had much luck finding any Rust work either, remote or otherwise. I think it'll be another couple years before we see a number of positions opening up; we're still in the early adoption phase now. You're probably better off finding off a different job and maybe finding a way to work Rust into it.
Yes, there's a large investment bank using Rust (among others) - at least in its Quant Research department. We're sitting boulevard des Italiens, Paris 9ème, not that far from Mozilla btw. Please send me a private message.
&gt; why not have a binary notation Writing out (and reading) 64 digits is much harder than 16.
&gt; So I don't need a Mutex (and thus no Arc) because when using futures everything will run in the same thread? (does it?) That's correct. &gt; You are doing rx_main_to_ui.clone() in line 14 but rx_main_to_ui.add_stream() in line 19, when should I use which? My assumption was that I should use add_stream() when I want messages to be sent to both, and clone() when I want both receivers to compete for dispatching the messages (the first one that asks for a message gets it, the other one doesn't). Is this assumption correct? If yes, shouldn't line 14 use add_stream() too, because I want all messages from the main thread to be sent to the state accumulator AND the browser. Yes, sorry, meant to use `.add_stream()`. I'm not actually super familiar with the library you're using, it looks useful. I've not tested the code I wrote, obviously. :) &gt; Is blocking bad in Tokio because of futures or because of an implementation detail that doesn't depend on futures? Blocking means to block the entire thread - tokio runs all IO in a single thread. Therefore, you're blocking all your IO when you block the thread - and even in simple tasks like yours, if e.g. you blocked while sending to the main thread for a bit, you'd find that messages *from* the main thread also don't get processed (and thus don't get sent to the client). &gt; Btw, what caused the high cpu usage in my original code? I'm honestly not sure!
/u/agwaman said it best: &gt; The standard `TcpStream` and `UdpSocket` types now have `set_nonblocking` to enable non-blocking mode. There's no select abstraction, but it's trivial to call the select/poll syscalls directly using the `libc` crate. Here's a dead-simple pselect wrapper I'm using in some of my projects: https://gist.github.com/AGWA/b0931a912a8b22b2d6178a3155e171f3 &gt; This is what I recommend doing if you want to avoid higher-level abstractions. The `libc` crate is owned and maintained by the rust-lang organisation, the same as the std library, compiler, etc. It is not a 3rd-party crate. There are zero reasons for management to reject using it. You can include it in your source tree to remove the internet dependency or pin it to an exact version and your code can never break as a result of changes to `libc`. https://github.com/rust-lang/libc
replied [here](https://www.reddit.com/r/rust/comments/65727v/is_rust_a_good_choice_for_a_terminal_based/dgarsmg/)
That was really enjoyable to read. Thanks for the writeup!
Dual_EC DRBG is one big example. A related issue is the [TLS "extended randomness"](https://sockpuppet.org/blog/2015/08/04/is-extended-random-malicious/) extension, promulgated by the NSA, which makes Dual_EC and related issues easier to exploit. Recall that the academic crypto community realized Dual_EC was a likely backdoor almost immediately, but the NSA pressured commercial vendors to implement it anyway (RSA Inc. got a fat bribe for making it the default in BSAFE). OpenSSL implemented Dual_EC and extended randomness, although not as default algorithms. The NIST elliptic curves (remember, NIST is in bed with the NSA) contain large magic numbers that are not justified by any published rationale. Bruce Schneier believes that they are backdoored and I think it's at least possible. It's not obvious from open cryptanalytic literature how such a backdoor would work, but we may find out one day. (Long ago, NSA magic numbers made DES *more* secure, but that doesn't seem to be their MO recently.) djb's Curve25519 has no magic constants. I'm pleased to learn now that it's been the default in OpenSSL for a while. So, my criticism may be ill-informed :) A third example is the NSA/NIST pushing the Digital Signature Algorithm (DSA), which fails catastrophically with any source of randomness less than perfect. I'm not that convinced it's deliberate but they might at least not be too concerned about it.
It does! Had to update to `rustfmt` 0.8.3 but it did the trick. Thanks!
Where is the code, that produce `Every attempt ends up in completely unreadable error messages` ? 
If you use MIO, it will actually be cross-platform. 
https://www.reddit.com/r/rust/comments/65727v/is_rust_a_good_choice_for_a_terminal_based/dgbar42/
We (the Servo team) care about keeping its tests green, but calling Servo "production software" is… let’s say generous :) (Small nit-pick: we use a pinned version of Nightly (now master), not Beta. So your PR being merged shortly before a new beta was not a factor.) Thank you for your great work!
One way you could work your way into Rust is to work in the domains that are being targeted by it ie environments where C/C++ are currently being used. eg In Melbourne, Australia, the domains where C/C++ are being used are in systems and embedded development. Rust is a bit slow in the embedded space atm, but there are already at least 1 company here using Rust in the systems space and should have more people working with it in a couple of years' time. MaidSafe are also looking for remote Rust Engineers (https://maidsafe.net/rust_engineer.html).
&gt; I guess I'm just a bit miffed as to why anyone would think otherwise. I can't speak for other people, but I came into rust assuming that the all the concurrency tools I would normally expect from a programming language to be either builtin the language itself, or be part of the standard library. Whether this assumption was reasonable for me to make or not, it's one that is apparently shared among many new rust programmers. After having spent a non-trivial amount time writing rust, I can understand the reasons behind the friction associated with extending the standard library; it's is a massive undertaking that is full of nuances and subtleties that can negatively impact future developments. However as a newcomer, what I see when are closed/stalled github issues for standard features that are available on other programming languages, and very opinionated dismissals. The situation also isn't helped when people get told to use a workaround when asking about missing functionality rather than receiving an explanation of the underlying reasons that prevent the sought functionality from being made available. All these are issues that might lead people to develop an idea that rust isn't feature-complete. (A side note: I'd like to thank you and everyone else who works on the standard library. It's easy to forget the hard work you folks put into it's development, and it's even easier to complain.)
All the existing job postings for Rust have been up for a while, so it's hard to tell if they've filled the position or stopped looking or what. I guess if it's been on their site and hasn't been taken down then they're still looking.
Could you elaborate on [https://github.com/servo/servo/pull/16473](https://github.com/servo/servo/pull/16473)? I'm curious how making structs smaller made some unit tests fail, and how not boxing them is the solution. Do you have tests that check the size of every struct or something?
I'm boxing everything at function boundaries. Still, when a function returns a boxed future, the error messages contain the full type, not a `BoxFuture&lt;Stream+Sink&gt;`. Still scary ;)
I didn't publish it as right now it's ~40 KB of experiments and burned ground (and there's some risk it infringes a trademark I'll have to strip before releasing the code). I'm not asking for help with my concrete code (it's crap, I know that already), I'm asking for help with the design. I didn't want my attempts so far to influence any ideas but if you insist, I'll strip it down and post it later.
The language has been *designed* to have this optimisation for many years (I suspect at least 3, at this point), e.g. https://github.com/rust-lang/rust/issues/28951, but it's taken a while for someone to do the hard work to implement it.
[removed]
The issue is that pretty much all web applications wind up hitting another server - a database, or redis, or similar. The alternatives are that you can't load-balance, or your application is somehow entirely stateless and doesn't have any interaction with the outside word. Mind, sync web frameworks (even PHP!) have done many people well for a long time, and will probably continue to do so. But on the other hand, development in this space in Rust essentially stalled as most people interested in web development in Rust are building systems which are at least *partially* IO-bound, and want async to be able to handle that nicely, even if they can throw some requests into a threadpool.
How do you do optional arguments with a default in Rust? Here is a Python example: def hello(name="Bob"): print "Hello " + name 
I'm pretty sure they are still looking.
Maybe consider using another name, "rdm" is already used by redis desktop manager 
&gt; Your processor can do unaligned loads at a performance cost, but it really likes it when data is at preferred addresses. Last time I (attempted) to check whether recent x64 processors still had a performance penalty for unaligned loads, I could not find any significant difference. Of course, in C and C++ the *languages* themselves defined unaligned pointers as Undefined Behavior, which can lead to very strange optimizations should you stray too far... *Note: I was checking the claim because [Simple Binary Encoding](https://github.com/real-logic/simple-binary-encoding) which is used in HFT requires unaligned loads on reinterpreted packets.*
 This is unrelated,`hello_world_return_pointer()` doesn’t actually return the buffer allocated by `malloc()`. It returns the string literal which is stored in static memory. You need copy the string into buffer with `strcpy()`.
Yeah I thought someone would bring up Java. 1. These projects were almost all started 6-10 years after Java 1.0; The Java ecosystem didn't know what it would need. The Rust ecosystem, is actively punting on parts it already knows other language ecosystems (like Java's) needed. Even with package mangers the expectation in 2017 for a std lib is significantly higher than it was in 1997/2007, which is perhaps unfair for Rust, but that just is the case. 2. The Java ecosystem, has Java EE. This could arguably be the Rust nursery / other projects in the Rust org, but again "nursery"/"same org" and "enterprise edition" have very different connotations while trying to get internal buy-in. Is the "Rust organization" willing to rename nursery/other crates to Rust EE, and offer support contracts? Is the "Rust organization" at least willing to state non-std libraries will be given equal priority alongside std? Finally, while Java might take a couple years to pull in good ideas, the biggest difference is that Java's mentality is to actively pull in core pieces into its std/ee offerings. There might be people in the Java community saying "smaller is better", but it doesn't come across as "we don't want X in std". eg. `@Inject/@Resource` vs Spring specific annotations. Java 8 time vs JodaTime. JAX-RS vs Apache HTTP. CompletableFuture vs ... &gt; I like Rust's small stdlib personally. FWIW, I haven't given my personal preference on this topic. *Personally*, I don't care. I validate that a crate works for me, and I use it. However, convincing juggernauts of the industry to allow me/anyone to use certain software is a different story[0]. When banks eventually migrate away from Cobol, will it be to Rust? I hope so, but I definitely feel until this unknown support story, for critical infrastructure, resolves itself, they will not be comfortable with doing so. P.S. I'm really not suggesting that we increase the scope of std, although it is one strategy to resolve this issue; But we do need *some way* to iron out the support story for critical infrastructure crates, and hopefully we do this sooner than later. [0] Have you seen the Typescript at Google talk?
I already postulated but got no answer.
I would keep a list of weak references to connections, meaning a bit more wrapping unfortunately. Somewhat cursory because I'm trying to be high-level here so it won't compile without some elaboration: let mut connections: Arc&lt;Mutex&lt;Vec&lt;Weak&lt;Mutex&lt;TcpStream&gt;&gt;&gt;&gt;&gt; = unimplemented!(); let conn = connections.clone() thread::spawn(move || { /* Wait and loop, etc. */ for connection in conn.lock().unwrap().iter().filter_map(Weak::upgrade) { connection.lock().write("Hello world"); } }); for connection in accept(/* Pseudocode */) { let connection = Arc::new(Mutex::new(connection)); connections.lock().unwrap().push(connection.clone().downgrade()); } You'll get all new connections pushed into `connections`, and if they get dropped the weak references won't keep them alive unnecessarily. Access connections by taking elements and `upgrade()`ing. Weak references may be unnecessary for your current needs, but it seems like the most appropriate solution to the general problem.
How about "rudi" -&gt; rust display. 
"Namespace conflicts don't exist" -crates.io
At this point just name it rudim, and have a logo based on something from Rodin to make the pun more clear.
GTK+ isn't a very good choice for game UIs. You can use Nuklear if you need one.
Good luck! I've had bad luck with display managers in the past, so I'll stay on the lookout for this one! I once investigated this myself a while back and found it to be a complete pit. Your README is a good representation of that. Dbus? PAM? Xauthority? Systemd? How does one even begin to figure out what actually needs to happen? If I were set on it, I'd probably go read the source of a widely used display manager and just copy what they do. Which sounds like a big task. :-) My conclusion was that the best display manager is no display manager. Or at least, a very minimal one. This is my `$HOME/.bash_profile`: if [ -z "$DISPLAY" ] &amp;&amp; [ $XDG_VTNR = 1 ]; then exec startx $HOME/.config/ag/startup/wingo-cheetah.xinitrc fi And that pretty much just works. My system boots and drops me into a tty. I login and boom, X starts. :-)
I was thinking about rudi the red nose reindeer. But Rodin may be more appropriate. 
Have you tried xmonad? I have never had a problem with it. 
/u/llogiq do you mind adding /r/learnrust in there? I created it and I think it deserves to be added to your list .. I think
xmonad is a WM, not a display manager. (And yes, I have. But there are various things I don't like about it. I spent years on the ultimate yak shaving quest by writing my own WM.)
As Josh wrote we have unit tests that use `size_of` to check that the giant enum doesn’t accidentally grow. If you add a big variant or make a small variant bigger crossing the threshold, the test will fail and tell you to box it. But also if a boxed variant becomes small enough that it can be unboxed (saving on allocation time) without making the enum bigger, the test will ask you to do that too. When I first realized (thanks to Emilio) this was because of struct reordering after seeing these tests fail in this case, I was afraid I’d have to conditionally compile something to make the tests pass in both compiler versions. (Servo uses Nightly/master, Firefox uses stable, the style crate is used in both.) But manually doing field reordering provided a nicer solution :)
Looks cool, good luck with this! I've been switching between login managers for a while and none of them seemed to work 100%. For now I just use the tty login like everybody else. Would love to get this working with Way Cooler though (just need to get the logind part working and it should work). 
&gt; My conclusion was that the best display manager is no display manager. That's what I did too. I didn't configure it to start a shell automatically however, I just [configured](https://wiki.archlinux.org/index.php/Xinit#Switching_between_desktop_environments.2Fwindow_managers) my xinitrc so after arriving in the tty I can type "xinit xfce" or "xinit gnome" and it opens the shell I want.
Good point, and thanks for pointing it out! Shouldn't this not work at all then?
Ooh, this has good timing. I was just looking through the DM options. I'll definitely look into this and see if I can find time to help out. One thing off the top of my head is that I don't think you have to worry about anything with D-Bus. The system session is already running due to systemd requiring it and the user session should be started by systemd and pam at login, IIRC.
Blind or not, I'm impressed.
I've implemented a similar server (that needs to send event messages to all connections, triggered by an incoming message to one of them, and from a periodic cleanup task). I decided to * use a dedicated thread to send events to all connections, and to push events to that thread using a `mpsc` channel (which can have any number of senders) * use `try_clone` on the socket to get two handles that can be written to (one from the request-response thread, one from the event thread) - if you can do that depends on synchronization requirements at the `socket.write` level That should allow you to get rid of explicit `Mutex`es altogether.
and then someone could make some kind of integration with Elementary OS and call it "rudimentary"
I'm not sure that the best representation always involves ordering subfields from largest to smallest alignment. Suppose that you have an enum that looks like TagA { u32; u16; u8; } | TagB { u32; } Then the best representation involves representing the tag as a single byte and fitting the u16 and u8 within the padding left by the tag representation, like so: +--+--+--+--+--+--+--+--+ |A |u8|u16 |u32 | +--+--+-----+-----------+ |B | (slop) |u32 | +--+--+--+--+--+--+--+--+ This ultimately requires an alignment other than "largest to smallest".
I believe he does mention ordering from smallest-to-largest in just this case.
Last I checked AArch64 never traps on unaligned accesses (but may be slow), while 32-bit ARM may or may not trap depending on the exact architecture. I may be wrong or out of date though!
That's a not too constructive, and possibly overbroad statement. Can you elaborate? What kind of games? Why is GTK+ a bad choice?
I'm creating an application server for a company I started with a buddy using Rocket for the backend and Elm for the front end. Navigating how to combine the two languages has been fun, and the similarities between them are interesting. 
How did you determine what the boxing size threshold should be?
Yes and with LUKS I already enter a password on boot and therefore a login screen as protection is kind of pointless. But at the moment I use a display manager with autologin as then I can switch between xmonad and Gnome quite easily.
I really enjoyed Caltech's [CS 171](http://courses.cms.caltech.edu/cs171/) course. I did it in Haskell and I know people who used OCaml, C++, or Python. So it's a language-agnostic course as long as you have OpenGL bindings, and Rust's [glium](https://github.com/tomaka/glium) is very nice for that. If you do this you will probably learn a lot more than Rust. Another fun project is the [Matasano crypto challenges](https://cryptopals.com/). Fractals are also great. Julia and Mandelbrot fractals are pretty easy, and then you can go as far as you want towards making them look cooler. Another great choice is [flame fractals](http://flam3.com/flame_draves.pdf) a la Electric Sheep. It's basically just an iterated function system with a few simple but really clever tricks to make it look astonishingly beautiful. You could make a renderer that generates random parameters, or an interactive editor. Any of these would be a great opportunity to explore parallelism and concurrency in Rust. Bottom line though, it really depends on what you're interested in. A friend of mine used Rust to make an editor for patterns for warp-faced backstrap weaving.
And which CS courses have you enjoyed most thus far?
You are leaking the buffer, but it is safe as long as you don’t call `free()` on the pointer. When working with FFI, I usually try to avoid passing owned memory to rust because it requires calling `free()` from rust or passing the memory back to C code for cleanup. In this case I would pre allocate a buffer in rust and pass a raw pointer for C code to write to.
I am genuinely surprised that C doesn't do this! I learned something today. Kudos to Rust for getting it implemented.
Yeah that's a my current test setup (I think?) but it falls back to a standard path anyway. For the screenshot it's pretty much just a background image with 2 gtk textboxes drawn on top so nothing fancy but you are right maybe I should a one to the readme.
Help is always appreciated! ;) As I said it's mostly about missing knowledge right now. At some point I was not sure whether the display manager should actually provide a D-Bus API to control it, because "all the big ones do" but I think that is optional and non-standard.
It's pretty trivial in C+ : uint32_t a = 0xFFFFFFFF, b = 0x1000; uint64_t c = a * b; `c` seem to be able to handle the result of `a * b`, but since they are both `uint32_t`, the result of the multiplication is `uint32_t`, and there is an overflow. 
The gitter hath spoken. The solution is to rewrite everything using tokio_proto [streaming support](https://tokio.rs/docs/going-deeper/streaming/). I was looking at it earlier and missed the detail that the chunks in `Frame::Body` are actually streamed. The key part: &gt; Here T will be the message head and B will be a **Stream of the body chunk type**. One unfortunate (for me) consequence is that now the protocol decoding (the part that knows if I need to stream or not) will have to happen at the Codec stage. Yay, another rewrite :D
There's a [chapter in the book about custom derive](https://doc.rust-lang.org/stable/book/procedural-macros.html). `proc_macro_attribute` is not stable yet. Only `proc_macro_derive` is stable.
I suppose you could use the ternary version of `if` to do it also
Pharmaceutical Chemistry. 
Probably Data Structures and Algorithms.
RDM is a desktop manager, wtftw is a window manager.
Any chance this could be added to the language as a literal? Pretty cool! 
Memory safety is a big one. Also, software can be more maintainable and robust because of Rust's type system and other high-level abstractions, compared to C. I do think though that a rewrite isn't worth it for many projects. After all, any rewrite costs time and will introduce new bugs, no matter how good the target language is. If you want to do it as a learning experience, go ahead. Just don't be too zealous about insisting your version is better simply because it's written in Rust (we're starting to get something of a reputation for that...). I think the more pragmatic approach is to incrementally rewrite *portions* of critical infrastructure in Rust (as *ring* is doing with BoringSSL), and also to favor Rust for *new* projects, when they provide other tangible improvements.
ASMJS is (a subset of) JavaScript.
You may have misread the docs: *Note that the timeout will be rounded up to the system clock granularity (usually 1ms), and kernel scheduling delays mean that the blocking interval may be overrun by a small amount.* Though, it's been a little while since I've worked directly with mio, I've instead been using tokio which is a better level of abstraction for my use cases. So definitely double check that. There are other wrappers available out there for epoll if what you want is something that is more specific for your use cases. I know mio has been focused on cross platform functionality, which often means limited to best supported across all platforms. I've noticed a bunch of conversations around timers etc, but I haven't taken part in them directly, so I'm not sure what the state of the world is there.
That's a great point. But, conversely, if you know that you need to pass memory back that is going to be accessed in C via pointer arithmetic or similar, then declaring that requirement at the FFI boundary could be nice. Right now I find that in FFI I follow the practice of wherever the memory was allocated, that is the system that is used to access it, and Convert higher order types as necessary between the two with getter methods from the other language.
I would concur. I would add that I'm still mostly learning Rust but I was able to use `poll` via the `libc` crate in my first project without any trouble. The `libc` crate even provides the proper types as `struct`'s already so it only really required a 5 line wrapper: fn rpoll(fds: &amp;mut [libc::pollfd], timeout: libc::c_int) -&gt; libc::c_int { unsafe { libc::poll(&amp;mut fds[0] as *mut libc::pollfd, fds.len() as libc::nfds_t, timeout) } } Then just make an array or Vec&lt;&gt; or etc. of`libc::pollfd`'s like you normally would, and then pass it to this wrapper which takes care of getting the pointer/length and passing it to `poll`. You don't really even need this wrapper but it's nice to hide the little details on how to call it. Personally I found this tons easier then `mio` and the others. I can see the advantages of `mio`, but it has a bit of a learning curve. With that, I didn't actually want non-blocking I/O, but `mio`'s TcpStream can't be used in blocking mode, and the `std::net::TcpStream` can't be easily used with `mio`. IMO, the entire thing seems like a pretty messy situation, but once I realized it was trivial to just use `poll` and such like I normally do with my C projects it was super easy to get it all working. And since `std::net::TcpStream` has a nonblocking option on it now, it would be trivial to change to nonblocking instead.
Right, and the amount of padding is chosen to make the address of the field a multiple of the alignment. For instance, 8-byte alignment ensures that an 8-byte access won't straddle cache lines.
Try `Box&lt;XmlElement&gt;`
It might be worth posting an issue on the mio GitHub and see if there's a recommendation from people there.
This is pretty much the only change you need: let mut model: DefDiscreteModel = DefDiscreteModel::default(&amp;val); The trouble is that `DiscreteModel` requires type parameters, but `N` is not involved in the parameters or return type of `DiscreteModel::default` so there's no information with which it can be inferred. But `DefDiscreteModel` has all the type parameters specified so it's clear which `default` method will be invoked. I suspect your confusion is thinking that because `DefDiscreteModel` is the return value of `default` that the type specified for its `N` is the same as the `N` causing the error, but that is not the case. The fully qualified function is `DiscreteModel::&lt;'a, N, S&gt;default(...) -&gt; DefDiscreteModel&lt;'a&gt;`. The `N` and `S` need to be known to determine how `default` gets monomorphized, but there is no dependency between those types and the return type. Imagine you were returning `i32` instead of `DefDiscreteModel&lt;'a&gt;`; you'd have the same problem where there's not enough information to determine which `default` to invoke, even if you know you're going to get an `i32` back.
There is an issue about that, linked at the end of the README.
Good luck, it would be great if this works out - the only thing that works for me is startx or Slim, but Slim is not maintained anymore.
&gt; I suspect your confusion is thinking that because DefDiscreteModel is the return value of default that the type specified for its N is the same as the N causing the error, but that is not the case. right, I though this: `let mut model: DefDiscreteModel = DiscreteModel::default(&amp;val);` was functionally equivalent to: `let mut model = DefDiscreteModel::default(&amp;val);` but it's not and from your explanation it's clear why it isn't. thanks.
Yes, they only work with custom derive right now. In the future more stuff will work, but not yet.
FWIW, you don't need the inner `Mutex`, as `TcpStream` (and `File`) can be used as a `Write` and `Read` even through a `&amp;` pointer. This can be seen by the [`impl&lt;'a&gt; Write for &amp;'a TcpStream`](https://doc.rust-lang.org/std/io/trait.Write.html), and is safe because the underlying OS APIs allow concurrent manipulation of such values.
I'm considering using QML with Rust. What are your issues with [White-Oak/qml-rust](https://github.com/White-Oak/qml-rust)?
I could pitch in on that. I'm not sure what's involved in stabilizing a feature vs writing new code
Slides from a talk Alex and I gave at QCon Beijing yesterday. Script, notes and links [here](https://github.com/brson/the-end-of-unsafety).
I remember something about using multiples of the cache line causing horrendous performance penalties because of how it interacted with the hash bucket algorithm used by at least Intel's CPUs. I can't remember if it was this case, but it's covered in the second half of this hour-long talk on how to make your code play nice with the CPU's cache and branch prediction systems: https://www.youtube.com/watch?v=WDIkqP4JbkE 
Swipe left? Or maybe tap to go to the next slide?
Tried swiping sideways, and it worked. Not super intuitive at first, but I really like the effect. May take note of it for some work I do in the future. 
&gt; Rust hosts a huge integration test suite, if another compiler could pass it for all intents and purposes it would be conforming to the standard. You should hang out with the ReactOS people, they cross compile ReactOS on mingw and Visual Studio. It's self-hosting too, so you can build ReactOS using Visual Studio running on ReactOS. They apparently found a lot of bugs in both VS and MingW. They also do fun shit like submit the automated bug reports whenever a MS product crashes on ReactOS. It reportedly drives the MS QA people nuts because they have to spend a lot of time investigating really quirky behavior before figuring out that it's a ReactOS user trolling them.
Only when Python starts losing people, will the platform mature to the point where the VM and batteries will be separated. Python is half of a two clock problem. You can't tell how well it isn't keeping time because you have nothing to compare it against. 
Possibly. It's been too long and I don't remember the details. I'd go re-watch it to refresh my memory, but all my programming-related time is currently taken up with Python- and web-related high-level stuff.
Yeah, the title is rather hyperbolic. Rust doesn't *end* unsafety, it just builds a strong, high-visibility fence around it, with warning signs on the one gate to get inside. As opposed to C's approach, which was to have a sign on the periphery reading "lol good luck".
My favorite read on the topic: [Binary Search Is a Pathological Case for Caches](https://www.pvk.ca/Blog/2012/07/30/binary-search-is-a-pathological-case-for-caches/)
This is [not](https://i.imgur.com/xCPcX1e.jpg) that [complicated](https://i.imgur.com/gw3cMin.jpg).
https://brson.github.io/the-end-of-unsafety/#/47 Is the ripgrep comparison fair? Doesn't grep check against both UTF-8 and UTF-16 at once when unspecified? Does ripgrep do the same? It just strikes me as odd when I know that prior to the whole Unicode thing, grep's performance seemed to be revered, only to change due to having to check against more, and more difficult encodings. Aside from that, nice to have another resource to show to people to explain the *why* of Rust.
If the mythical [C backend](https://github.com/draperlaboratory/llvm-cbe)[ to llvm](https://github.com/JuliaComputing/llvm-cbe) ever gets re-re-resurrected we might be able to support these folks via Rust -&gt; LLVM -&gt; C -&gt; GCC.
It is hyperbolic, but that's not a great way to look at the problem, in my opinion. Ending unsafety requires enforcing invariants in some way. One possibility is through the compiler- this is essentially a giant unsafe block as far as the target program is concerned, because it can generate any machine code. The other is through libraries like `std`, which use explicit `unsafe` blocks. Both restrict the use of unsafe primitives behind safe interfaces, and both should ideally be verified somehow. The difference is not in the level of safety provided, but in tradeoffs in maintenance difficulty, ubiquity, etc.
I assume the ripgrep numbers come from http://blog.burntsushi.net/ripgrep/#single-file-benchmarks which does give much more info about the assumptions etc. (Although it does seem like the 8 is more of an upper bound for the cases there, than a lower bound as would be more typical.)
My understanding is that GTK+ has it's own styling. When making games, you generally want a custom style for the GUI that is specific to your game. GTK+ isn't really flexible enough for this. The other problem is that embedding it in a way that it plays nicely with the rest of the graphics is difficult.
I made a demo of an IRC bot that can asynchronously get and send messages. It only uses the standard library, you don't to know how to use any fancy frameworks to use it. [gist link](https://gist.github.com/Lokathor/133eeacad79e86b0229900004ec94e53).
The are some major issues that prevent me from being productive with qml-rust. Issue #33 and #17 for example​. Through there are other things that are normal in Qt/c++ but are conceptually differently to rust. E.g. dynamic (dis)connecting of signals at runtime, the Qt object tree model, qobject events ... All this things are not accessible in all the existing bindings. Finally the main reason why I think about GTK is that the gtk guys are thinking about rust und try to make the bindings work. Reading their​ blog posts it really looks like they are even willing to change gtk itself to make it work better with rust. But even through I like their ideas I would really miss QML and would like to have a substitute for it in the gtk world that is well integrated with rust.
I guess it depends almost entirely on what, exactly, you're trying to do. I almost always have a distinct `BlahBuilder` type, because having a partially-initialised `Blah` is usually a really sketchy idea. If you do that, then the naming problem mostly disappears, since you almost never need to read the fields back. Also, if the code size is a problem, the macro system is right there (I believe there's a crate specifically for this somewhere). As for field names on the final type itself... depends. Generally, I'd go with `field`/`field_mut` returning `&amp;_`/`&amp;mut _`. If you need to react or compute stuff, `field`/`set_field`. Do you need to be able to move out of a field? Maybe you also want `into_field`. There isn't really a single best practice, because there isn't a single use-case.
I would say there's room for improvement, so feedback welcomed.
Try /r/playrust
This is the library you're talking about I think: https://docs.rs/derive_builder/0.4.4/derive_builder/
Yep! When I was doing maintenance, there was a basic rule: don't assume that the previous coder was an idiot (including yourself). There is often some obscure reason why the 'obvious' way was not taken. (The obscure reason is now forgotten because it was so obvious at the time.) So the temptation to 'simplify' should be resisted. (Sane refactoring is fine, but _test_)
Thanks! :)
&gt; integer conversion late to the party. Has integer conversion (implicit widening) been discussed before? Edit: sorry nvm, found it here - [https://internals.rust-lang.org/t/implicit-widening-polymorphic-indexing-and-similar-ideas/1141](https://internals.rust-lang.org/t/implicit-widening-polymorphic-indexing-and-similar-ideas/1141)
Looks pretty good! Only thing: mistakes made by the user (like specifying an invalid file name) should not make the program panic
Yeah... I would probably avoid saying unqualified things like "ripgrep is 8x faster than grep." /u/dbaupp is right to point out that 8x is probably somewhere around an upper bound on how much faster it is. In the *common* case, where grep and ripgrep are both used to search a simple ASCII literal or regex on a large file, ripgrep might edge out grep most of the time, but you're unlikely to get an 8x boost. Now... If you squint your eyes a bit, there are other ways that the 8x claim might be true: * "grep" means "BSD grep." But everyone knows BSD grep is slow, so that's not much of a statement. :-) * You're recursively searching a large directory. ripgrep will use parallelism and intelligently ignore some files, so you could see major wins over just a plain `grep -r`. But others would rightly say that a better comparison would be something like `find ./ -print0 | xargs -0 -P8 grep ...`. In which case, there probably isn't an 8x win (unless ripgrep ignores some monstrously large files). &gt; Is the ripgrep comparison fair? Doesn't grep check against both UTF-8 and UTF-16 at once when unspecified? Does ripgrep do the same? If you read my blog post on the topic, then I think your questions should be answered. Briefly: * GNU grep does **not** support UTF-16 at all, so I'm not sure where the idea that GNU grep will search both came from. :-) * Both ripgrep and GNU grep support UTF-8. For more complex Unicode queries, ripgrep will do quite a bit better than GNU grep even on single file search (this is probably where the 8x upper bound comes from). &gt; It just strikes me as odd when I know that prior to the whole Unicode thing, grep's performance seemed to be revered, only to change due to having to check against more, and more difficult encodings. If you do enough googling, you'll eventually find that GNU grep's performance can be significantly impacted by your system's locale settings. I know I've seen at least a few StackOverflow posts that recommend setting `LC_ALL=C` to make "GNU grep run fast," because in that case, it won't do much with Unicode and all the character classes have standard ASCII meanings instead of Unicode. But if your default locale settings are, say, `en_US.UTF-8` (which you can enable on-demand with `LC_ALL=en_US.UTF-8 grep ...`), then certain regexes can run significantly slower in GNU grep. The benchmarks in my blog post control for the Unicode differences in GNU grep. Read it. :-)
I looked into this and wasn't able to find a proper way to terminate early. System exit seemed the obvious choice, but is that the most idiomatic way? Actually saw an example that did exactly that, so hence why I did it like that.
A tip for the future: whenever you encounter one of these web slide shows on a desktop computer, always press the space bar to advance to the next slide. It works on every slideshow I've encountered, and even works on reveal.js style slideshows where the next slide might be in any of the cardinal directions.
How can I have an instance of struct in two vectors?
Even if it's possible it seems like a bad idea. Writing to the same stream from multiple threads without locking, a partial write in one of those threads will generally break whatever protocol you're using. It can be useful if you guarantee a single user through other means, or if you do reading and writing in different threads.
Press `?` for keyboard shortcuts. `s` = show speaker notes.
You fundamentally can't, at least not directly. Asking this is kinda equivalent to asking "how can I have the same value accessible from multiple places?" Having vectors doesn't change anything. You could have multiple copies of the struct, you could store the struct somewhere else and use `&amp;Struct`s, or you could use `Rc&lt;Struct&gt;` to get shared ownership. If you need the ability to mutate the structures, you could use `Rc&lt;RefCell&lt;Struct&gt;&gt;`, or `Rc&lt;Cell&lt;Struct&gt;&gt;` if it's a simpler type, or use `usize` indices into some other backing storage and just avoid pointers entirely. It depends on what problem you're actually trying to solve.
MaidSafe is still looking: https://maidsafe.net/careers.html Remote-first job, working on a decentralized (p2) internet infrastructure. Disclaimer: I am contracting with them, too.
If `Settings` is meant to be immutable, then it is fairly normal to make all the fields public and avoid the getters. This is less dangerous in rust than in other languages, because the compiler ensures that the fields will stay constant. If `Settings` is meant to be mutable, then you don't need a builder. Regarding naming, the convention seems to be `username()` and `set_username()` https://github.com/rust-lang/rfcs/blob/master/text/0344-conventions-galore.md#gettersetter-apis
Cyclone is a research programming language that Rust took many of its ideas from. I'm not sure about Singularity. Maybe they're referring to this: https://en.wikipedia.org/wiki/Singularity_(operating_system) 
`dbus-launch` opens a program within a new dbus session. What causes most people to use it is when the dbus environment variables are not getting set properly so programs act like there is no user session. There is/was probably something janky with your `pam_systemd` configuration.
Cyclone: https://cyclone.thelanguage.org Singularity: https://www.microsoft.com/en-us/research/project/singularity/ If you click the speaker notes for that slide, you can read: For months we batted around this problem of sending objects between threads without invalidating pointers, and without a garbage collector. Around this time Niko Matsakis joined the team. Niko was an actual trained type theorist, and he brought some good ideas. Niko was looking at a research project called Cyclone and wondering if we could learn from it. Cyclone was a safe dialect of C that used static analysis to track the validity of pointers. Cyclone's system was somewhat limited and did not directly solve our multithreading problem. But also at the same time we became aware of another research project at Microsoft called Singularity. It was an attempt to reimagine the operating system in .NET. There wasn't a lot of information coming out of Microsoft but what caught our eye was their approach to concurrency. In Singularity they employed a novel technique to transfer ownership of - and sole access to - entire regions of memory between threads, by only copying a pointer. (next fragment) In a real sense Rust is Cyclone plus Singularity. And the result in Rust is what we call "ownership and borrowing".
Why does Rust utilize more CPU in this case?
Pushed a whole bunch of tests to [`uom`](https://github.com/iliekturtles/uom) that I have been working on the last couple weeks. Coverage up to 99 %! This week I'm hoping to push a new version to crates.io and contribute a [metric benchmark](https://github.com/coder543/metric/tree/master/benches).
It's using multiple cores via rayon.
Nick just told me they didn't have time to come up with a come challenge for the interview because they're super busy right now, but they'll once it'll be a little easier. Let's see at this moment! :)
I've just started implementing a channel that is supposed to have the following features: * unbounded (lock-free), bounded (almost lock-free), and rendezvous (blocking) variants * supports multiple producers and multiple consumers * channel-like (Sender/Receiver) API and queue-like API (one shared Queue) * blocking (send, recv) and non-blocking (try_send, try_recv) methods * close method that wakes up blocked threads and prevents future sends/recvs * timeouts (send_timeout, recv_timeout) * select! macro I believe my design can support all of those at the same time, while still delivering great performance. We'll see within the next few weeks... I'll report about the progress.
Note that a key downside between a struct with public fields and a struct with private fields with getters is that the former requires a semver bump if you add a new field. If you are reasonably sure that `Settings` will never grow, then it seems fine though!
I continued my work on [`relm`](https://github.com/antoyo/relm), an asynchronous GUI library based on GTK+ and tokio and I wrote a [blog post](http://relm.ml/relm-intro) about it. Last week, I: * refactored some parts of the code. * added a custom derive and a macro to be able to use the nice syntax on Rust stable. * improved the documentation. * added support for using relm widgets as containers. * added support for "properties" in relm widgets. * started to port my [`mg` crate](https://github.com/antoyo/mg) to `relm` (and fixed many bugs in relm while doing so). This week, I plan to continue porting `mg` to `relm` and fix the issues I encounter in `relm`.
Ctrl-A may help
What I do is use [error-chain](https://docs.rs/error-chain/0.10.0/error_chain/) to define a custom error type, and use the `quick_main!` macro it provides to print out errors to the user. It takes 10 minutes to puzzle out the first time, but once you've used it once, Rust error-handling is pretty trivial.
I'm reading The Book (second edition) and something bother me in chapter **4.1. What is Ownership?** It it said: &gt; We’ve already seen string literals, where a string value is hardcoded into our program. String literals are convenient, but they aren’t always suitable for every situation in which you want to use text. One reason is that they’re immutable. But the following code is working: let mut s = "hi"; s = "test"; Instead of immutability shouldn't we speak of known size at compilation?
You might give *ring* a try for SHA1: https://github.com/briansmith/ring It provides architecture-specific optimized assembly versions of several algorithms, including SHA1 in your case (btw, don't use SHA1 :D)
Does Rc still leak reference cycles? That's not safe for long-running, high traffic software
I'll take a look at that, thanks. Wasn't sure which crypto library would be the best
Try using the special readable mode in Firefox. Very handy for these kind of things.
Documentation is a bit lacking for the moment, feel free to ask me if you'll have any problems.
I see, I thought the bindings were more mature. To be honest, I would sooner drop Rust than QML, since the GTK community is too focused on GNOME and its particular vision of the desktop for me to be comfortable developing applications in it. I'm also not a fan of what they've done with regards to API stability, nor of their future plans for versioning. Maybe it will change in the future if Canonical helps, but for now I guess I'll have to resign to using C++ :/ Thanks for the information!
I'm not positive that I understand the algorithm, but the python version searches [all permutations of lengths going to as many as the fields](https://github.com/rebootuser/Hashmash/blob/d06eb49cc452504cfe3375851598628c7d0f1ab3/hashmash.py#L127) and AFAICT the rust version considers only [combinations of all fields in the input](https://github.com/Svenito/hashmash/blob/bff4237266d9965a9420bf696d85f0e334d5748f/src/main.rs#L135).
i had nothing to do so i decided to remove all panics from the program i replaced the panic calls in read_file with the question mark operator moved the cli parsing in a separated function just so i can return a Result from it and in the main function i created a macro with takes a Result and a message if the Result is Err it prints the message and the error then exits https://github.com/juggle-tux/hashmash/blob/master/src/main.rs
From the description it sounds like a complicated task, so 1k LOC sounds reasonable. I'm more concerned about everything being in a single module, as that's probably the reason the line count is hurting. Personally I'd split timesheet.rs into session.rs, timesheet.rs, traits.rs, and util.rs. That's only through skimming the code structure, so you'd probably know better how to restructure it yourself. Also, I would not recommend templating html by interpolating strings. Try using one of the [great templating libraries](http://www.arewewebyet.org/topics/templating/) Rust has. I'd recommend [Maud](https://github.com/lfairy/maud) for this.
Wouldn't surprise me. :P
Ok. But how does the compiler creates the variable? How does he determine the size of s? Does it take the size of the longest string being assigned to s (here "test")? 
`"hi"` (and all other string literals) are of type `&amp;'static str`; that is, it's a pointer to some string data that lives (effectively) forever. It's not storing the contents of the string in the variable, just a pointer to it. (There's some weirdness around the exact *kind* of pointer this is, but that's not really important here.)
I didn't know about ripgrep's file parallelism, so that could end up a major boost for me, especially since even GNU grep is often CPU bound for me (using grep -ailr without LANG=C or LC_ALL=C using a plain ASCII search string). Why? I often search files I'm not intimately familiar with already - hence me searching them - and this way I can quickly remove a character and edit the command quickly to narrow down in the way I want. While grep is CPU bound for me, searches typically don't take too long. Thanks for the UTF-16 correction. I wonder why I've never had problems with that (or UCS-2?), now I feel dumb. I hope I never missed something important. (I presume your blog post was [this one](http://blog.burntsushi.net/ripgrep/).)
So when I create a string this way: let s = "test"; s is a pointer in the stack and the string "test" is created in the heap? That's strange.
No, `"test"` is baked into the executable; there's no heap allocation going on here. In general, if you have a `&amp;'static Anything` (emphasis on the `'static`), there's no heap allocation involved.
You definitely need a keyword to indicate that the normal checking rules aren't sufficient to establish safety. Exactly what the syntax looks like, to link to theorem source, is a good question to bikeshed. Maybe something like `#[unsafe(proof="doubly_linked_list.gh")]`
There are lots of things that are technically breaking changes that we generally don't treat as semver breaking changes. Bug fixes are an obvious one. Changing the size of types whose representation is hidden seems like another obvious one. There are less obvious ones though, like for example, adding new trait impls that slighty change type inference, which can cause your code to fail to compile. Of course, this policy requires a healthy dose of pragmatism.
Arguably, "structures that do not have a single owner per piece of data" are a combination of two cases: structures that can be described as having multiple "subpieces" of which each can be accessed independently while preserving the invariants involving the rest of the structure; or else, structures where all read/write accesses are going to be appropriately serialized. In either case, you'll need to make sure that the properties you care about are actually preserved; the compiler can't provide a one-size-fits-all solution as of yet.
I will be emceeing! I'm not stressing it, personally.
this is effectively the only good option if you care about more languages than Rust because they're not always able to handle structs. Libaudioverse has to deal with Windows memory allocators being different per-runtime. Which isn't a problem unless you want it to work with Python2 and only compile with VS2015 and hit the runtime mismatches. Python is not the only language where this problem can arise. So I also make it the rule that the library that allocates the memory is responsible for freeing it. This is inconvenient--remember to use Lav_free instead of free--but can usually be abstracted if the other language has destructors.
Yes, we'll do exactly this. It doesn't matter which way you sort in the struct case. In hindsight, I'm not sure why we originally decided to sort structs by descending, then special case enums. I suspect that probably I did sort structs in descending order and then we discovered the special case, and no one realized that we should just invert the sort. Maybe I should do a followup PR that cleans that up a bit.
Sure, but you confirmed my feeling that there was no straightforward way out of the problem. Went with `get` ;)
I forgot the *mut*. Yes that answered everything, thank you!
&gt; The ability to unit test each function in a file (write a small test, write the functionality to pass it, refactor) You can always do this, but you can't do it easily without also putting each test in a module. &gt; The ability to Mock out objects that are passed into constructors (see Google Mock) Mocking is a very under-explored area of Rust overall right now. I expect once we have "macros 2.0" it will be much more possible. &gt; The ability to module test things. I don't know what this is. &gt; Separate directories for tests/src (i.e. Not testing in the same file as the source code) Cargo supports a `tests` directory, however, due the the privacy rules, these _must_ be external tests, that is, they cannot test private things. This is one reason why the idiom is "unit tests in `src`, integration tests in `tests`". As long as you're not trying to test private stuff, then there's no inherent reason unit-style tests can't go here.
module == integration Do you have an example of these? Edit: These - meaning seperate directory tests for multiple pieces of functionality.
Crimea is a long way away, travel to Kiev is generally safe.
I usually doctest most public functions (with the added benefit of nice examples in the docs), also I sometimes have the following in my sources: #[cfg(test)] mod tests { // added tests here } I will also usually have a `tests` directory in my project, which Cargo searches automatically (also `benches` for benchmarks). I never use mocks, but if I needed them, I'd abstract the function under test with a trait and use a test struct to implement it. IIRC there's some crate to generate mocks. I also use [quickcheck](https://crates.io/crates/quickcheck) whenever applicable. I hear good things about cargo-fuzz, though I haven't used it yet.
Thanks :) So this isn't the nicest place in Kiev, and actually it's kind of confusing to navigate. Better not to go without a guide because it's closer to one of the more crime heavy regions. For anyone looking for a hotel I recommend something on the stations Olympiskaya, Zoloti Vorota, and Universitet.
I was expecting a presentation on how to reduce the amount of unsafe code in existing library crates. 
Hey, I also got one of the raffle tickets! I'm not concerned about any recent issues, but I am concerned about the fact I have basically zero travel experience and now need to work out how to get there.
Kyiv is safe, don't worry.^(am from Kyiv)
 fn get_last_session(&amp;self) -&gt; Option&lt;&amp;Session&gt; { match self.sessions.len() { 0 =&gt; None, n =&gt; Some(&amp;self.sessions[n - 1]), } } fn get_last_session_mut(&amp;mut self) -&gt; Option&lt;&amp;mut Session&gt; { match self.sessions.len() { 0 =&gt; None, n =&gt; Some(&amp;mut self.sessions[n - 1]), } } These are just self.sessions.last(); self.sessions.last_mut(); Strings like r#"Session running since {}. "#, should just be "Session running since {}.\n"
As I know craft.ai use Rust.
Do you actually care about the order when you use `find_first`? Since Rayon is visiting items in parallel, it has to do extra bookkeeping to track which found items were first in the original source. When it finds one match, it still has to wait to check all items before that. If you really only care about finding *some* result, `find_any` is better, as it can quit as soon as it finds something anywhere.
Is there any way to detect inside a drop whether or not the current thread is unwinding from a panic using only core?
If I understand the problem it's solving correctly, isn't this something that hashcat can do with a rule-based or [hybrid attack](https://hashcat.net/wiki/doku.php?id=hybrid_attack)? Hashcat of course is going to be the fastest for something like this since it uses your graphics card if it's available, and is extremely solid for any password combination/dictionary brute forcing. Not trying to understate the value of what you did, but from a practical standpoint, wouldn't hashcat be better at this problem?
Very probably yes. My friend was talking about this project to me, and it got me thinking that it would be a good opportunity for me to practice some Rust. 
curl is a lot more than just a CLI client. It's also a library used by a large number of projects, including cargo. And whether you are trying to replace the library or replace the CLI client, yes, a simple version that does just basic GET/POST wouldn't be hard to do, something that supported all of the options uses by other projects, whether they're shell scripts using the CLI client or projects using libcurl, is a huge undertaking. Anyhow, yes, it is possible to port things over to Rust, or do a rewrite that replicates the basic functionality. And I think it's a good idea for people to do so. But they shouldn't underestimate the amount of work it takes to do so, especially to achieve a version that is compatible with how other existing software uses it or that is compatible with the myriad strange web servers, network setups, proxy setups, and other middleboxes that might change how protocols work in subtle ways. The main point is, it's not all that constructive to say to someone "it shouldn't be hard to port that to Rust," because that downplays an awful lot of the difficulty and tedium of actually producing a viable replacement. It's a lot more compelling to say "hey, I ported this to Rust" (not sure if this has yet happened for any substantial projects or libraries, would be interesting to know) or "hey, I wrote a replacement in Rust that's better in these ways" (see ripgrep, for example) or "hey, I replaced this one module that's exposed to untrusted data and has had a lot of vulnerabilities over the years in Rust, would you mind adding Rust as a build dependency" (see the Oxidation project in Firefox).
[removed]
Even ignoring the fact that Rc cycles is just one way to leak memory in any software/language, "safe" in a Rust discussion almost always refers to memory safety, and, despite the name, memory leaks are memory safe: http://huonw.github.io/blog/2016/04/memory-leaks-are-memory-safe/
That sounds like a reasonable structure to me, thats what I'll be doing. Thanks also for the tip about maud, that is great!
Thanks for the hints! Should have looked at the docs some more, it seems.
I'm pretty busy trying to keep the actual pace so that won't be done any time soon. However, contributions are welcome. :)
An enum for each error type which has to be matched at the callsite? Seems verbose but legible and very safe.
But when panic=abort, `drop` isn't called (isn't it?) so we never ask the question in the first place.
How can I collect a variable number of positional args using [clap](https://github.com/kbknapp/clap-rs)? Essentially, I'm trying to replicate behavior like `echo`, where `echo hello world` would be just as valid as `echo "hello world"`. Essentially, I'd like to be able to collect all of such args into a `Vec` or something. I've been looking over the documentation and I can't seem to figure out if this is possible.
I'm going! I'm actually arriving at 29th and looking for people to walk around the city together. &gt;And does anyone have concerns about travelling to Ukraine given the recent issues with Russia? If you are traveling from Russia there's a non-zero chance you will be denied entry at the border, especially if you are an adult male. It's recommended to have good evidence of you traveling goals - the conference ticket, hotel booking confirmation, return tickets, etc.
This is a great idea. I might try this.
I've tried this, but editors get in my way when doing it so I usually wait until later to add these. I'll look into some of those and search for the crate for mocks. What all does Cargo search automatically?
This is honestly a pretty weak argument considering no one cries foul when those fundamental data structures are baked into a language. I assure you, putting it in the compiler does nothing for safety. Formal verification of production-quality implementations is a very immature field.
&gt; Why keep using C++? Good generics. (it frustrates me when Rust programmers think the only reason to use "C/C++" (a thing that doesn't exist) is because of inertia. No. Sometimes, C++ is the better tool for the job).
You could have one for your entire crate, one for each logical unit, one for each error type, or some combination there-of. errorchain seems to encourage one per crate-- but most bigger crates seem to have more than one type.
I'm not the original author, found this on [Twitter](https://twitter.com/meta_Lloyd/status/852006768200646656).
You should pretty much always pass the pointer back to the library to be freed. Because Windows (although it could happen other places in theory). In Windows, each module (DLL, EXE) can have a different C library (release, debug, threaded, unthreaded) and each one uses different memory heaps.
While it is true that "C/C++" is misleading, it is also really damn common, for instance, the clang front page has "C/C++/ObjC" (bonus extra language!) on it. Additionally, while we're nitpicking, / can mean "or"/"and" rather than implying the two things are the same thing. That said, there *are* a lot of similarities between C and C++, especially for things like mindset for safety, domain and tooling, and uses of "C/C++" are often in such contexts (including these slides, IMO! Although the use in that question is a little less clear), where outrage about that stylisation is unjustified. Of course, as your own comment demonstrates, there's also the publicity thing of not riling up C++ developers.
Your test file is only 5 lines long and there's quite an apparent speedup noticeable. What happens if you compare when the file is 5k, 500k, 1mn lines long?
It depends what you're actually promising not to break. Usually, you're only promising not to break your users' documentation-compatible workflows. If you actually document that a struct has a set size and interacting with that number is part of your users expected workflow, then it should probably break semver to change it. That's a fairly unusual circumstance though.
The Clang page is using "C/C++/ObjC" in a very different context than the commenter was alluding to. In context of the slides, I too think it's mostly justified, since it's talking about "same use cases" and "same performance". Often however, writing "C/C++" indicates a severe lack of understanding about the difference between the way they're programmed in, especially when considering modern C++. E.g. you're usually not passing around raw void pointers in C++ like in C, instead you use things like std::unique_ptr while bare pointers are encapsulated in RAII structures. I've seen people use this on their resumes in the form of "proficient in Java, Python, C/C++" which just tells the reader the person doesn't really know either. I've also seen job descriptions with the same, probably written by managers who have read it somewhere and just adopted it. A good C++ programmer is not automatically a good C programmer, and even less so in reverse. Things like those are most likely the reason why formulating "C and/or C++" as "C/C++" is so often frowned upon.
Hm. Correct me if I'm wrong, but it seems like you're specifically disagreeing with the one phrase of my comment about the mindset for safety being similar in C and C++. I was specifically referring to the "without compiler checking" concept you mention, so let me expand: both C and C++ are happy to take the "you're holding it wrong" approach to programming. It is definitely true that C++ has several features (including ones that were recently added) that make it easier to avoid problems, but the language also gains features that have similar "do it right or else" footguns (topically, move semantics is one), demonstrating what I mean by mindset. In any case, you've extrapolated *far* too much about what I ignore or not with Rust's history. My comment made no reference to the language, or the source of the ideas it incorporates, it was talking about C++. In any case, I'm often the first (and that's not just a turn of phrase) to tell people talking about Rust, things like "C++ did it first", "you can get something similar in C++ via ...", or even just "that's not accurate about Rust". I'd really appreciate it if you assumed a little more good faith. :)
CRT will call into an exported main symbol #[no_mangle] pub extern fn main(_argc: i32, _argv: *const *const u8) -&gt; i32 { 0 } add a #![no_main] to top
It's not berating an individual. It's berating the community. I want to be able to reach out to C++ developers, and have them start to play with Rust; stuff like this makes people not want to use Rust, because it comes off as tonedeaf.
[AtherEnergy](https://github.com/AtherEnergy) also uses Rust. I think /u/creativcoder works there.
I guessed, hence "seemingly": however, without context, the rather long screed in reply to a specific comment, along with "you" and various imperatives in it could easily be what someone would say to actually berate someone.
Yes, quite possibly. At the very least, make sure no other rls command is visible on your path.
Thanks
How do editors get in your way? Cargo will search `tests`, `examples` and `benches`, plus all tests in `src/` of course.
Awesome! :D So what changes when setting up VSCode and or IntelliJ IDEA's Rust Plugin with it?
I noticed that `rustup` does download the `rls` binary into the toolchain binary folder, but doesn't link it up to the `.cargo/bin` folder like it does for the other binaries. (At least it doesn't do it after I removed `~/.cargo/bin/rls`, removed the `rls` component in `rustup` and added the component back.) Edit: after I manually copied and renamed the rustup "facade" binary (`cp ~/.cargo/bin/cargo ~/.cargo/bin/rls` for any value of cargo :–D), and now it works.
Thanks for the link. It contains the following paragraph: &gt; Note that this convention is about getters/setters on ordinary data types, not on builder objects. The naming conventions for builder methods are still open. So I guess there is currently no consensues for builder methods (my question).
Whoa, congrats, that looks great! What kinds of libraries are you using? glutin, sdl2, piston? Anything for UI?
Template metaprogramming is one of the things still I really miss coming from C++. Luckily there's [support for const generics currently in the works](https://internals.rust-lang.org/t/lang-team-minutes-const-generics/5090), which could really open the way for some exciting TMP features. I hope variadic generics will follow some time after that! :) It's such an important tool esp. for library development.
As a rule of thumb you should never allocate memory in a dynamic library and de-allocate it outside of your dynlib. Different OS's have different rules about how memory allocated by a shared library behaves. This ranges from *a bit weird* (Windows), to *insanity* (OSX). So this can really hurt your portability. 
Oh, right, I forgot that one! Yeah, there are a bunch of cool folks doing Rust stuff there.
`rustc`, `cargo`, and `rustfmt` are a fairly standard split- most languages I've seen provide their functionality as separate tools as well. `rustup`'s functionality is also usually a separate tool, when it even exists. The functionality of `clippy` and `rls` (and `rustfmt`) is usually part of an IDE, which Rust doesn't really have yet. I can see them all being part of a single distribution when that happens, though.
Well, we have several events around the world an try to make that more. Are RustConf and Rust Belt Rust options for you?
... I know exactly what each of them do, but thank you. I'm just sad that as real problems with the ecosystem continue to get solved (which is amazing!) I as a user of the Rust ecosystem have to continue to learn more rather than than less. This is very analogous to the way the React ecosystem evolved. If you aren't aware, this caused massive amounts of friction, and was one of the largest contributors to people avoiding React. There are now multiple "starter kits", which help resolve this issue, but this fragments the ecosystem, and are a pain to keep all of these tools working together.
OP brought up a good point, there are quite a few tools and if you didn't really follow rust you wouldn't know what's there. Installing RLS requires 3 components already (rls, rust-analysis, rust-src). IMO we should have something like rustup component add standard-dev-env that gives you all the niceties the Rust team deem important enough to put under the nursery. RLS, rustfmt, clippy, fuzzer, etc...
I mean I agree, we should always strive to make things easier and better. It just irks me to hear "I want this and this and this" without any real constructive advice to offer. I get it, it's a venting of sorts, but maybe that energy could be directed towards making more concrete suggestions on what could be improved.
Okay, we're not in disagreement. I hate incidental complexity, but I just don't feel that it's present in Rust currently. In fact Rust seems to be the opposite compared to so many others, it's very quick and simple to get stuff up and running. And correct me if I'm wrong, but does [this](http://doc.crates.io/manifest.html#dependency-sections) help at all with what you're asking about cargo.toml and dependencies? Or is that a different kind of target than what you're thinking?
[`downgrade` belongs to `Arc`](https://doc.rust-lang.org/std/sync/struct.Arc.html#method.downgrade), but it's an associated function, not a method; try `connections.lock().unwrap().push(Arc::downgrade(&amp;connection));`. That said, if your code _actually does_ look like that, `connection` is going to get dropped immediately and `connections` will thus immediately be holding an empty `Weak&lt;&gt;`.
Great, thank you so much for being willing to dig into this. I agree that it's in the best interest of the ecosystem, and so do others. I don't have a link to hand, but I've discussed/heard discussion among various Rust core/sub-team members about hypothetically having a unified `rust ...` tool and similar ideas like that, for at least a year. In fact, the very announcement here is one step towards a more unified environment: `rustup` has support for core tooling, rather than having to `cargo install` with the right version of nightly etc etc. However, it's definitely slow-going... a 3 year timeskip would be nice. I suspect your first comment may be receiving downvotes because it's a bit vague, or, more likely, because of the later comment. I don't know, I think it is okay.
That is a different type of target. [This](http://doc.crates.io/manifest.html#the-metadata-table-optional) is closer to what I'd like, but not just for the metadata, but for the rustc version, the toolchain, other build dependencies, the runtime dependencies.
I'm not 100% what's set up now, but yes that we can catch regressions easier is something the infra team is looking into with tools like rls and clippy.
Fair enough, though my intention wasn't really to defend the status quo so much as just to point it out. I do think, as this sort of separation of concerns is pretty well-understood and widely regarded as a good thing in programming APIs, libraries, etc. that applying it to tools should be pretty uncontroversial. However, nothing prevents us from bundling things up if that turns out to work better- and `rustup` and `rls` are already beginning to combine components that used to be even more separated. It would help if those working toward that could be less adversarial, though ;)
Hey, I'm completely new to Rust and I think I've got a pretty basic lifetime question here: struct Foo&lt;'a&gt; { x: &amp;'a i32, } fn main() { let x; let y = &amp;5; let f = Foo { x: y }; { x = &amp;f.x; println!("{}", x); } } and I get the following errors: error: borrowed value does not live long enough --&gt; temp:13:1 | 7 | let y = &amp;5; | - temporary value created here ... 13 | } | ^ temporary value dropped here while still borrowed | = note: values in a scope are dropped in the opposite order they are created error: `f.x` does not live long enough --&gt; temp:13:1 | 10 | x = &amp;f.x; | --- borrow occurs here ... 13 | } | ^ `f.x` dropped here while still borrowed | = note: values in a scope are dropped in the opposite order they are created error: aborting due to 2 previous errors However, that doesn't make much sense to me because shouldn't all the variables be dropped at the same time?
For C++, I use (more or less) equivalents for all of these tools, except rustup. rustc -&gt; GCC/Clang cargo -&gt; CMake clippy -&gt; cppcheck/Clang analyzer rustfmt -&gt; astyle/clang-format rls -&gt; Clang code model plugin for Qt Creator 
Please don't label it as "an unpopular opinion". In my opinion: you were ranting and that is fine. Not everything has to be outright constructive. You care about our topic here and I like that :) I wish, there wasn't an "downvoting" feature... Truly evil posts can still be hidden by the mods...
intellij-idea doesn't use racer or RLS (as far as I know) so this should not affect your idea setup 
I completely disagree with you. UX is one of the considerations of a good architecture, but unlike clean separation of concern, maintainability and performance it can be fixed with a wrapper around more "cumbersome" APIs, as long as they are expressive enough It is not unreasonable to expect people to learn specialised tools. You can always make things easier by layering more UX friendly wrappers. See: Unix
When it's installed via rustup it gets autoupdated with the nightly, or that's what should be happening at least. However, it may be possible for a nightly to break RLS, in which case there won't be an RLS blob to update to until it gets fixed and the next nightly comes out. There should not be issues with stable (once RLS becomes stable). At least, this was the original plan, implementation wise it may have changed. We hope to get clippy on the same plan.
Which VSCode extension? It works for me on Windows using [vscode-rust](https://github.com/editor-rs/vscode-rust) on VSCode nightly and nightly-x86_64-pc-windows-msvc (although goto-definition for stdlib symbols has been broken for a few weeks now :-S).
There wasn't much content in that criticism. None in the first comment (it's vaguely gesturing at the existence of a problem that isn't quite elucidated), and almost none in the second. Additionally, the second echoes a very harmful kind of attitude of entitlement in open source, which has often lead to maintainer burnout and is a very real problem. /u/dbaupp's comment isn't discouraging criticism. It's discouraging the 99% of the comment that _wasn't_ criticism.
Enums with fields are amazing, I've already been using them. Though I don't understand why you can't have a wildcard match when you are already matching all other cases (E0001 - unreachable pattern). Enums don't seem to be built for extendability? Not sure. Not like I need to match all message types in every game logic system but still. mpsc is a good one, I probably need it if I want to handle seperate game systems asynchronously since the systems work by generating messages themselves. Can't mutate a Vector from multiple threads at once I assume, even if they only push and the ordering doesn't matter. Thanks!
Crimea is safer than Kiev or Ukraine in general. But for the short trip it does not matter.
/u/chtaeh You beat me to it! :) I did get the add operation to work well enough with the `zip()` function, however I found out that it didn't work without the trubofish `::&lt;Vec&lt;f64&gt;&gt;`. 52 fn vec_add(x: &amp;Vec&lt;f64&gt;, y: &amp;Vec&lt;f64&gt;) -&gt; Vec&lt;f64&gt; { 53 x into_iter().zip(y.into_iter()).map(|(a,b)| a + b ).collect::&lt;Vec&lt;f64&gt;&gt;() 54 } Is there something that I missed which prevents it from identifying the type ? I couldn't get the dot product (scalar multiplication) to work with the following code 72 fn vec_dot2(x: &amp;Vec&lt;Vec&lt;f64&gt;&gt;, y: &amp;Vec&lt;f64&gt;) { 73 let a = x.iter().map(|v| { 74 v.iter().zip(y.iter()).map(|(a,b)| a*b ).collect::&lt;Vec&lt;f64&gt;&gt;() 75 }).collect::&lt;Vec&lt;f64&gt;&gt;(); 76 println!("{:?}",a); 77 } If my understanding is correct, 74 v.iter().zip(y.iter()).map(|(a,b)| a*b ).collect::&lt;Vec&lt;f64&gt;&gt;() should loop over all the items in `v` and `y` and should be able to return an iterator on the result set which I can then collect/transform into a `Vec&lt;f64&gt;`. Shouldn't 75 }).collect::&lt;Vec&lt;f64&gt;&gt;(); do the same for the outer iterator? I get the following error when I compile. error[E0277]: the trait bound `std::vec::Vec&lt;f64&gt;: std::iter::FromIterator&lt;std::vec::Vec&lt;f64&gt;&gt;` is not satisfied --&gt; src/main.rs:75:12 | 75 | }).collect::&lt;Vec&lt;f64&gt;&gt;(); | ^^^^^^^ the trait `std::iter::FromIterator&lt;std::vec::Vec&lt;f64&gt;&gt;` is not implemented for `std::vec::Vec&lt;f64&gt;` | = note: a collection of type `std::vec::Vec&lt;f64&gt;` cannot be built from an iterator over elements of type `std::vec::Vec&lt;f64&gt;` Please correct me if my understanding is incorrect. Regards Delta 
&gt; However, it may be possible for a nightly to break RLS, in which case there won't be an RLS blob to update to until it gets fixed and the next nightly comes out. Does this mean that the user's installed RLS is in a possibly broken state when this happens? For example, if you update nightly rustc, but don't update clippy, there can be all sorts of errors, from unresolved symbols to segfaults, because clippy dynamically links against librustc. Is this also the case with RLS?