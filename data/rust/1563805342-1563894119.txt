What exactly gave you the impression I was interested in arguing about the design of an operating system that I not only do not use, but whose motivation isn't even clear yet? Until I hear otherwise, I'll be treating it as a legitimate complaint because it comes from a credible source. Some people, including me, like to do the best with what we've got. It's probably a couple orders of magnitude easier to reduce the size of the regex crate than to make Rust's dynamic linking story work well.
This is great. Definitely a good source for me to learn some things from too!
We're talking about a very high-profile project running widely in production. If you also create a high-profile project, widely used, yes people will start to care about whether your code is good or not. What do you expect? No-one wants another Heartbleed/etc (well, except the black hats). Coding in Rust will protect from a whole class of problems -- that's the purpose of Rust -- so long as you stick to safe code, or follow the rules in unsafe code. If there is an exploit, you expect a project to address that exploit. If the way they're coding could also potentially lead to exploits, that's not so severe, but it's still on the same scale. It should also be addressed if they care about their end-users. Okay, the author seems overworked, but if someone is doing most of the work for them to improve the situation, then what is there to argue about?
Right, features are additive. This is why crates use a `std` feature that is enabled by default, instead of a `no_std` feature that is disabled by default. Otherwise, when someone uses a crate with the `no_std` feature enabled, even when they themselves are okay using the standard library, they'd wind up with the `no_std` API and no recourse to remove it.
Yea, it's not exactly the point of this post, but some confusing parts are: * interaction with loops (when the compiler says something was used in a previous iteration) * borrowing parts of a struct / parts of an array (using split\_at) * manually specifying lifetimes (like a function which returns a reference to a reference) * When you should use std::mem::swap() or std::mem::replace() * How to transform code from another language into a format suitable for rust, if it has lots of pointers etc Also all the other things related to borrowing, but above I was mainly thinking about plain \`&amp;mut\` and \`&amp;\` references in this comment.
I use clap in a lot more than ripgrep. And as I said, this goes back to trying to show example code that is close to how real world code is written. Reasonable people can disagree about this. It seems like we've reached an impasse.
good server, except the admins. they cant even discern between game and language
Yeah that's not good. I filed an [issue](https://github.com/clap-rs/clap/issues/1524).
You're in the wrong sub.
You probably want to post in /r/playrust. This sub is about the programming language Rust.
I create an issue on rustfmt to track this: [https://github.com/rust-lang/rustfmt/issues/3700](https://github.com/rust-lang/rustfmt/issues/3700) As a Gopher learning Rust, I really need this feature. Typing those \`use\` make me bored and crazy!
&gt;Google’s ClusterFuzz has found around 16,000 bugs in Chrome and around 11,000 bugs in over 160 open source projects integrated with OSS-Fuzz. Holy shit that is a lot more than I would have guessed. But as a Rust beginner I need to ask: How many of those 16,000 bugs could have been prevented by using Rust?
BTW, would be great to see https://crates.io/crates/docopt in the comparison table at your pico-args repo.
That's interesting, and I'd never heard of the Otii. One small note, you might want to take a look at https://www.reddit.com/r/rust/comments/brbf6o/helppython_vs_rust_montecarlosimulation_of_craps/eoc0qpo/, even you're only doing 500 iterations.
Correct. If `T` isn't already `Sync`, then `RwLock&lt;T&gt;` can't be `Sync` either, because it's going to hand out multiple `&amp;T` references at the same time. But `Mutex&lt;T&gt;` is always `Sync`, regardless of `T`, because it guarantees that there's only ever one `&amp;T` at a time.
I feel personnaly attacked by the amount of high quality projects in your github :p
Thanks for the compliment! I should really spend some more time working on them, `forge` in particular.
There are Win32 version of all those libraries. For example instead of memcpy() use CopyMemory(), instead of memset() ZeroMemory () and so forth. Win32 exception handling (SEH) does not depend on CRT.
You're looking for /r/playrust my friend.
Well, there's a pie chart below. It's hard to tell, but leaks can occur in Rust (although it's a bit harder than in C or C++). Failed assertions sure, even more than in C++. Timeouts and running out of memory? Nothing prevents them. And of course, with unsafe code you can get the rest of them, too. Rust nudges you in the same direction, but we've seen one of the more popular Rust projects take a rather cavalier attitude towards unsafe code. So, assuming that distribution held, maybe 2/3 of them could have been avoided with Rust, which is pretty close to Microsoft's 70% figure. You should also weigh them by severity. One tab can make its content process crash? Tough luck. But it's much worse if it can end up executing arbitrary code on your computer. Finally, not all security issues are related to memory safety. I don't know about Chrome, but Firefox has all of its UI written in JavaScript, and it has a long history of bugs where web scripts were able to call APIs designed to be used by the browser UI. You can also have JavaScript JIT compiler bugs that no safe language will prevent. But these kind of bugs are harder to find by fuzzing, so they aren't included in those numbers.
That's confusing to me, haha. Mentally _(not that this is correct)_, I view Sync as a primitive to handle cross-thread safety. Arc is Sync in that it allows cross-thread reads, immutably. Mutex is Sync because it coordinates threads, ensuring that only one mutable ref is ever out at the same time. By that logic, why isn't `RwLock` also Sync? Shouldn't it be coordinating threads in the same way `Mutex` does? To me that's entirely the job of `Mutex`, `Arc` and I thought `RwLock` - to make something synchronized between threads. What good is `RwLock` if it doesn't coordinate between threads? Note that I get what it does from a mutability/read context, but to me `RwLock` and `Mutex` are functionally very similar - I thought they both wrapped `T` and made it `Sync`. Why does `RwLock` not make something `Sync`? I'm so confused :D
You’re trying to deserialize the entire array of data into a single bottle struct. Try making the type on your bottle variable: `Vec&lt;Bottle&gt;`.
Your problem is also solved by a pointless `if/else`: if true { wrap_fn(|_| path)(i) } else { wrap_fn(|_| path)(i) }
You're ignoring the error returned by your function. It fails because there's a typo in your JSON, near Yeti. Also, when possible, please try to post code that compiles. Yours is missing some `use` statements and the implementation of the getters.
One general transformation you can often make is to turn if let Some(t) = self.field1 { // logic if condition { self.field1 = value; // ERROR: self.field1 is already borrowed } } into let mut new_field1 = None; if let Some(t) = self.field1 { // logic if condition { new_field1 = Some(value); } } // self.field1 borrow ends here unless new_value also borrows it if let Some(new_value) = new_field1 { self.field1 = new_value; }
If you have a Twitter there's a large rust community there as well and I'll gladly retweet any job requesting tweet you make.
Won't work for event loops that don't return until it's time to exit.
Did you find anything on SO Jobs ? The last few times I've looked at Rust Remote jobs, there was only one, with title *"Senior Go Developer Who Loves Writing Microservices"* and paying 30k-40k...
Sorry about that, added those in and should compile now. Fixing the typo still doesn't work on my end though.
[docopt is pretty much dead.](https://github.com/docopt/docopt.rs#current-status) I don't recommend that anyone use it.
Actually I am using a linked list, the first JSON I deserialize into a single object though
no offense but if they're newer mistakes are to be expected. as well as the fact they may only be posting some of the code. Reactions like yours can be a bit disheartening for some newer programmers.
Good job boiling it down to a single related analogy. &amp;#x200B; Trying to describing borrowing in terms of a single physical item makes my head hurt, since it's hard to conceptualize "multiple-read-only use." The closest thing I've found in that is of a two-lane road: many people can use it, until the road crew shuts it down to repave it. The road analogy also anecdotally demonstrates how obtrusive modifying something is to other people.
I think you added some extra curly braces in `arr_data` in the meanwhile. Try https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=380aee852984ec65ebfbb89bbaf220cc.
You may be right, tone can be hard to communicate over the Internet. I certainly didn't intend to castigate the OP. /u/Oromei sorry if it felt that way, or if my comment was too curt.
That was it! Thank you!
For usage of flattening, I consider one circumstance by now. Some values in NBT structs can be optional, for example, the NBT compound for signed book and book with pen share common fields, but the former with a lot of additional information about the title and author. If we write Option structs for these additional fields, there could be many to consider for the user, for example having to check Option None values one by one, leading to complexity of errors and results. And yes, temporarily we can replace and hand-write flattened fields to finish all the systems which use our underlying library. I'll tried out a way for specifying array serializations. In my recent update I provided with a module that is compatible with serde-with attribute. User may add the serde-with attribute to fields to serialize in special array way, for example ByteArrayTag instead of ListTag of bytes. Actually in the implementation I declated a struct to wrap the array fields, and detect them in the serializer by the wrap struct name as token (I gave this token a very complex name by purpose in order to not be collapse with user library). The mechanism is tested okay but it's time for sleep now and I would add some details tomorrow. My project repo: http://github.com/luojia65/coruscant Docs (maybe not up-to-date): https://docs.coruscant.rs
yeah my bad. I've just had some friends drop out of working with code because of some rough reactions so I tend to take things a bit harder than most.
&gt; `#[repr(C)]` Maybe then it's not an undefined behaviour even without `#[non_exhaustive]`?
No worries, it's all good
I have a couple in my city, but I prefer SO because at least they have the Joel test and I've used that to weed out non-sincere posts before.
Anyways, it's still my choice when I need to implement a CLI.
It definitely does, yes. There are some fairly damning bugs on the issue tracker. I had to rip it out of ripgrep pretty early in ripgrep's life because it was just unsuitable on a couple different dimensions. The big ones, from what I can remember, were its performance and the fact that it doesn't handle non-UTF-8 arguments.
That's perfect! I really appreciate the link, cause it's nice to see something out there that does all I really *need* to have it do for my day-to-day. I can use that as examples in learning more about Rust, when I implement my own code for those same features. I appreciate the comment!
If it's safe to put a struct inside a `Mutex` I'm finding it hard to imagine a situation where that struct cannot be made `Send`. However, if I set that concern aside I can give an example of a constraint that can be expressed in Rust. I'm not sure it's the constraint you need, but here goes. You have a resource, such as a block of memory or I/O handle, and there are two kinds of operations that can be done with that resource: 1. Some operations must be done in the original thread. I'll call these "bound to a thread." 2. Other operations may be done in any thread. I'll call these "unbound." * But, no two operations can be done "simultaneously" by more than one thread. This means that if an operation will be done in a thread, it must "happen-after" any previous operation in any other thread. "Happen-after" is a technical term, and I mean specifically that "both memory effects and observable FFI effects happen-after." Fortunately, this restriction is the same as saying "locking is required" and I won't need to think about the memory model. The resource handle must be non-`Copy`. This prevents use-after-close and use-after-free bugs. Most likely, the `Drop` trait can be used to free the resource. Some resources need an explicit "close" operation, and the usual way that's expressed in Rust is to write a dummy `Drop` which panics or aborts if you forget to close. It's not airtight - you can still write a program with a resource leak or failure to close - but it at least makes those bugs louder and easier to find during testing. I think the easiest way to deal with those constraints is to express the resource handle as something which can be `Send`. That means: * unbound operations may be expressed by `&amp;mut self` methods. If it's safe to re-enter them in the same thread (multiple invocations on a single thread's stack) then they can be `&amp;self`. * bound operations may be expressed by `&amp;mut self` methods which check the thread-id and panic if that check fails. The advantage of this approach is that you get a handle type `H` which can be placed in an `Arc&lt;Mutex&lt;H&gt;&gt;` and you don't have to think much deeper about thread-safety and `unsafe` code beyond what's required to access the resource. The disadvantage is that you might have reduced performance from redundant thread-id checks. This can be refined by factoring out the bound-methods into a different type. This type is a pointer-to-the-handle without `Send`. Then you'd have a method, something like `Handle::within_main_thread(&amp;'while_thread_id_checked mut self) -&gt; HandleWhileIDChecked&lt;'while_thread_id_checked&gt;` which checks the thread ID. The lifetime tells the compiler to not allow other operations to happen while the bound operations are happening. That pointer-to-handle can probably be written in safe Rust, using a `&amp;mut Handle` reference to find the handle. The actual operations which access the resource will still need at least a touch `unsafe`. &amp;#x200B; &amp;#x200B; PS: Rust has multithreaded testing and that's usually a good thing. If your mock isn't `Send`, it will actually break. If you plan to require single-threaded testing, you should still design the mock to detect accidental multithreading and panic, for example with a reentrant mutex such as the one in `parking_lot`. Then you'll also need unsafe to force the compiler to ignore the thread-unsafety of `Rc` and `Cell`. But it's probably better to instantiate a new mock within each test. If this is possible, your tests will actually run properly in parallel.
I felt threatened by your genius jajaja. I hope you find a job at your level soon.
Ahh, with winit? I had the same problem. It looks like you don't use the whole of self inside the closure, so you should be able to just explode self into references to its members and move those into the closure. if let Full(w) = self.window { let layers = &amp;mut self.layers; let overlayers = &amp;mut self.overlayers; w.event_loop.run(move |e, _, c| { ... for it in overlayers .iter_mut() .rev() .chain(layers.iter_mut().rev()) ...
&gt; I view Sync as a primitive to handle cross-thread safety. I might phrase that differently. `Sync` is a descriptive property of a type (AKA a "marker trait"). If a type `T` is `Sync`, that's saying that `&amp;T` can be shared between threads without leading to data races or any other undefined behavior. Another way of putting the same thing is that `T` is `&amp;Sync` if `&amp;T` is `Send`. Libraries like `std::thread` rely on these marker traits to guarantee that data races don't happen, but by themselves the marker traits don't really "do" anything or imply any particular implementation. Note that because of the definition above, most types are naturally `Sync`, because most types don't allow any mutation at all through a `&amp;T` shared reference. If there's no mutation, there can't be any data races. For the most part, only types that allow shared mutation somehow (AKA "interior mutability") have a chance of not being `Sync`, depending on how that mutation is done. For example, `Cell` allows shared mutation without any atomic operations or locking, so it's not `Sync`. But `AtomicUsize` and `Mutex` are `Sync`, despite supporting shared mutation, because they use thread-safe operations internally. In these cases, Rust has no automatic way of knowing whether a type should be `Sync` or not, and it's `unsafe` code in the implementation that declares that those types are `Sync`. &gt; Arc is Sync in that it allows cross-thread reads, immutably. This isn't quite right. If we look at the docs for `Arc`, we see: impl&lt;T&gt; Sync for Arc&lt;T&gt; where T: Send + Sync + ?Sized That is, Arc _isn't_ `Sync` unless its contents are also `Sync`. Why is that? Because `Arc&lt;T&gt;` allows multiple threads to get ahold of `&amp;T` at the same time. In fact, that's the whole point of `Arc`. If `T` isn't `Sync`, then letting multiple threads use `&amp;T` at the same time leads to data races. (As an aside, why is the `Send` bound also there? I think that's because of the `get_mut` and `try_unwrap` methods, which expose `&amp;mut T` or move `T` as long as the `Arc` isn't shared. Without those methods, maybe `Arc` could've been `Send` unconditionally, but I'm not totally sure.) &gt; By that logic, why isn't RwLock also Sync? Shouldn't it be coordinating threads in the same way Mutex does? Sort of. `RwLock` is indeed coordinating between threads, and like `Mutex` it will guarantee that no two `&amp;mut T` mutable references can exist at the same time. That's a fundamental safety rule in Rust. But the key difference from `Mutex` (and the reason for having both types in the standard library) is that `RwLock` allows multiple readers at once. That is, just like `Arc`, `RwLock` is willing to hand out multiple `&amp;T` shared references at the same time. And again like `Arc`, that's only safe if `T` is `Sync`. `Mutex` is unique among container types, in that it's the only one I know of that guarantees that only one `&amp;T` can exist at a time. That's why `Mutex: Sync` doesn't depend on `T: Sync`.
/r/forhire might be useful too, if you haven't already posted/checked there
Compared to Mutex, RwLock is useful because it allows you to have multiple concurrent shared references to the inner value. This is precisely the reason why, unlike Mutex, an RwLock cannot be Sync if the contained value is not: If it was Sync, RwLock would allow multiple threads concurrent shared references to the inner value, which is forbidden as the inner type is not Sync. Types like Cell and Rc that are not Sync can safely allow mutation via shared references because they rely on those references not crossing thread boundaries.
Thanks. That fixes my move problem, thought it just reveals a new one. self doesn't live long enough. I don't get this problem if I move it into the clousure. So I need to partial move my struct or I need to reengineer this. Do you have a working winit 0.20 app I could look at?
We have this on the radar for quite some time, see https://github.com/rust-lang/rust-clippy/issues/2227
Ah gotcha that makes a lot of sense yeah. Your work on typed Arrays sounds great! I'd take a look at the code but unfortunately I get a 500 Server Error when I try to access the GitHub repo, I'm hoping it will fix itself so I'll try again in a few hours. I spent some time implementing homogeneous sequences but the approach I had in mind doesn't work (`TypeId::of` requires a `'static` lifetime which `serialize_element` cannot guarantee). I think I've found a new approach that *does* work but I'll have to do some more testing before I can say for sure. Whatever we end up with, it'll be a very hacky solution as serde is clearly not intended to support homogeneous sequences.
I use [runner](https://crates.io/crates/runner).
Based on the article's metrics, most of them. That matches my experience reading Chrome CVEs.
Is there have some useful tools to let you know which function has owned and which function has owned variables on coding time (not runtime) based on keyboard cursor? Frequently, I lost in this situation on my memory.
Oh, the argument to run's become `+ 'static` in winit. I'm behind :) If you move instead of borrowing, it compiles let mut overlayers = self.overlayers; let mut layers = self.layers;
Thanks! It works.
Very cool project, and I hope this is a state of mind that more Rust programmers adopt. There's nothing wrong with using dependencies—especially high-quality ones—but that doesn't mean that we shouldn't exercise judgement and discernment when choosing our dependencies.
&gt; (As an aside, why is the Send bound also there? I think that's because of the get_mut and try_unwrap methods, which expose &amp;mut T or move T as long as the Arc isn't shared. Without those methods, maybe Arc could've been Send unconditionally, but I'm not totally sure.) [This was tried](https://github.com/rust-lang/rust/issues/20257)! They realized the crossbeam-style scoped threads APIs allow you to run an arc's value's destructor on another thread without being `Send`: 1. Using the scoped APIs, send to another thread an `&amp;T where T: Sync`. In this case send an `&amp;Arc&lt;T&gt;` where `T` is `Sync` but not `Send`. 2. On the new thread, clone the`&amp;Arc&lt;T&gt;` and stash the resulting`Arc&lt;T&gt;` in a thread-local. 3. Afterwards, drop the original thread's copy of the arc so that the arc in the thread-local is the only remaining copy. 4. Then, at a later point, drop the arc stashed in the thread-local. This will run the underlying value's destructor on a different thread, effectively `Send`ing it.
Aaand the repo just loaded and I see now you've already implemented homogeneous sequences. Your implementation looks really cool, and it seems to be pretty close to the new one I came up with so at least I was on the right track lol. As far as I can see the `coruscant-nbt` crate is pretty much finished, so I guess my work here is done. The `coruscant` project as a whole sounds really promising btw, so if there's anything else I can help out with feel free to let me know! :-)
Currently the only way to do this is by using [mrustc](https://github.com/thepowersgang/mrustc), which compiles to C, and then using a C compiler to emit 6502 machine code. Note that mrustc is very limited and does not implement recent language features or borrow checking.
Just wondering but when did you start programming? Your GitHub is definitely impressive for a 22 year old
Well, crap.
You are free to do with your own one whatever you want, but from the GitHub issue it seems you have invested quiet a bit of time into the issue, while they have invested very little time into it. Are solutions proposed are a lot of work for questionable benefits, particular when the problem they have is a solved problem and the solution is called dynamic linking. They can’t tolerate a single megabyte of bloat, yet their use case is statically Linkin regex (and all other dependencies) to dozens of binaries. I’ll be following the issue to see how any regex crate improvement never solves their problem.
So if you can’t reuse goblin to solve your problem, then IMO goblin isn’t reusable enough and it has a bug with fixing.
I'd point out that there is a Rust Matrix channel, and that you can use Matrix clients to join Rust channels, and that the Rust team could easily continue supporting ALL IRC users, while having serious moderation tools, by adopting a Matrix room bridged to an IRC room.... but .... for whatever reason, Rust folks and especially people in this subreddit seem really proud of being stubborn about Matrix. Flat out refusing to learn anything about it. Insisting proprietary software is necessary. Promoting instant messaging apps with snake-oil encryption. Meanwhile, an open (but moderated) solution is available and half of the people here REFUSE to entertain the idea. Whatever.
I'm always a \*bit\* shaky on the details here, so take this with a grain of salt. My understanding is that the fundamental reason is that when you compile a crate, you say what edition it's compiled with. And then it's compiled. So, the only way to say "compile in both modes" is to compile two copies of the crate. But then, since they're different crates, you cannot use their types with each other, in other words, your "rust 2015 String" and your "rust 2018 String" won't work with each other, because they're different types in different crates. Beyond that, the standard library also implements lang items, and so having two copies of the standard library would duplicate those, which would produce an error. Okay, so you only compile one of the two; then you're back to the previous situation, but even worse: the "rust 2018 Iterator trait" is no longer a lang item, so any \`for\` loop is using the wrong iterator type, and so now none of your rust 2018 standard library implements Iterator in a useful way...
In case anyone else ventures here: this is (probably) the paper [Taming Undefined Behavior in LLVM](http://www.cs.utah.edu/%7Eregehr/papers/undef-pldi17.pdf) [*.pdf warning*]
&gt; However, "if" expects an expression. But "let y = 6" is a statement. That doesn't matter. `if` and `if let` are different forms.: if_expr : "if" no_struct_literal_expr '{' block '}' else_tail ? ; if_let_expr : "if" "let" pat '=' expr '{' block '}' The first one takes an expression, while the second one introduces a pattern. Why does `if let` exist? Because it's very useful.
&gt;For the political analogy (yes, I am bringing politics into this because it so closely tied to my message), if a Trump supporter were to post something on most places on Reddit with a legitimate concern about illegal immigrants, they'd get downvoted to hell and if they were lucky enough to get any responses clarifying what they are wrong about, I doubt it would be very constructive. This is a great way to alienate people from each other even further and make people on the other side think less of your community. How is this shit post allowed to be here, seriously?
There is also [https://crates.io/crates/cargo-play](https://crates.io/crates/cargo-play) .
You can read more in the RFC that proposed adding it: https://rust-lang.github.io/rfcs/0160-if-let.html and in the discussion of that RFC: https://github.com/rust-lang/rfcs/pull/160
How can leaks occur in safe rust?
thank god
 let b = Box::new(4); Box::leak(b); This is considered safe.
It's worth noting that the [6502 is not a particularly compiler-friendly target](http://forum.6502.org/viewtopic.php?f=1&amp;t=4314) for a variety of reasons. Even if there was a Rust compiler made for it, it'd be either low performance (as most 6502 C compilers are), or extremely limiting. Most NES games were programmed in 6502 assembly directly; you might want to look into that route.
Leaking memory is considered safe. Reference counted cycles are a fairly simple way of creating leaks in Rust.
&gt; Companies don't want to use unproven technologies and the only way to improve Rust use and adoption is to cut away at the use cases for other lower level languages by making the appropriate tools, libraries and resources available. * Several high-profile companies are using Rust at this point. * Many of the tools are already higher quality than those in C and C++ land. * People do need to understand why both C and C++ are bad, because a lot of them have various mental blocks of some kind. The ones I've seen most commonly are ego and apathy.
&gt; Apologies if this post is not permitted here, I couldn't find anything forbidding it in the rules. Apologies accepted. There are far more Rust developers that Rust jobs being posted, so I'd rather not have every single developer wanting to find a Rust job (myself included :P) post a separate thread. It would quickly drown out the actual content, I fear. Good luck on your search, in either case.
I mean, it most certainly, unquestionably happened after the first Actix incident. 1. Strong reaction to UB in Actix. 2. Community has HUGE, strong reaction. 1. Dev fixes a few of them. Community has a... pow-wow (I hate that I used that), and decides that they need to "be nicer". 3. (weeks go by) 4. Someone points out there are still plenty of unsoundness issues in Actix and are basically immediately shouted down as being overly negative, despite presenting genuine, technical concerns. 5. (months go by) 6. Someone finally writes it all up in a blog post, so much so that the hivemind can't deny it, and we rinse and repeat.
`if let` is a special keyword, it's not just an `if` statement with a `let` expression in the condition.
Yeah I know, but i don't really want to do anything serious. I mostly just want to test stuff out.
But not solved by `{ wrap_fn(|_| path)(i) }`. Urk :/
Thanks for the tip. It'd be nice to have that for channels, too.
It really depends on what you're trying to accomplish. Define "really simple".
`std::mem::forget("Hello".to_string())`
&gt; Do I have something to lose if i include many dependent crates in my toml file? Your build times go up, and some people dislike having a large number of dependencies. See for example https://www.reddit.com/r/rust/comments/cg3p5m/cargobloat_08_debloated_5x_smaller_10x_faster/ or https://iqlusion.blog/introducing-abscissa-rust-application-framework. &gt; If yes, why doesn't the rust standard library provide similar modules for the common use cases? It's an intentional decision, in order to avoid ossification of the standard library features. Python is known for a large standard library that's practically impossible to evolve. There's a saying about that: "The standard library is where modules go to die".
Trees are a special case of graphs, and there's nothing wrong with that crate, at least at the first impression. It certainly doesn't impose a specific order when building a tree as the OP feared, and it seems to offer an optional efficient storage.
2d something like pong.
About the same as in C++, but you should probably consider using (or contributing to) `ggez`, `amethyst` or `piston`.
I doubt you'd need to make an "engine" for that. Just make the game using a game development library. Amethyst has a bit of a learning curve, but it's pretty cool.
For those wondering "why on earth does the stdlib have Box::leak function": leaking memory is a totally legitimate memory management strategy, because the OS will always cleanup all of your memory for free on process shutdown anyway. So if you need to dynamically allocate some memory that will last for the rest of your runtime, you might as well just forget about ever freeing it. It's a bit of a footgun, though. Valgrind will be mad at you, so you'll have trouble finding "legit" leaks; it can be a kind of nasty thing for a library to do, since the parent application might want to tear down the library and get its resource back; and it can become a nasty latent bug if that path is suddenly used a lot and the leaks become unbounded. But at the same time, I believe some systems *have* been observed that spend huge amounts of time pointlessly freeing memory as they try to shutdown (this is folklore in my head, can't remember any examples right now), and this leaking strategy would materially improve the situation. (GC'd languages generally don't suffer from this since freeing memory has nothing to do with exiting a scope, unlike RAII languages like C++ and Rust.)
Thanks for the answer &gt; and some people dislike having a large number of dependencies. I am one of those people too, but i can't justify it. It feels wrong to me to have a large number of dependencies but i don't know why. How would one decide if he should introduce a new dependency, or reinvent the wheel in order to deal with a common problem however?
Ah I see, thanks!
You seem to have added a binary to you repository, that's usually a bad idea. I think you can usually find some test vectors (known inputs and outputs) for the various CRC algorithms, so you don't really need a different implementation to compare yours with. Also, I'm not really sure what's specific to Cortex in that code. Do ARM processors have hardware support for a CRC variant that matches these values? As for the implementation itself, it seems quite similar to this one in `bzip2`: https://github.com/jaime-olivares/bzip2/blob/master/src/CRC32.cs, with the difference that the result is not negated at the end. I know there are many CRC crates, perhaps you could see if one of them is missing this variant, but otherwise it doesn't seem to be that Cortex-specific. Finally, the code should probably be `no_std`, and you could switch to the 2018 edition.
&gt; borrow checking Could you check it with the regular Rust compiler, and then compile it with mrustc?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/lxd] [lxd-snapper - kinda like Borg, but for LXD snapshots!](https://www.reddit.com/r/LXD/comments/cggftk/lxdsnapper_kinda_like_borg_but_for_lxd_snapshots/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt; Several high-profile companies are using Rust at this point. This has only really changed in the past few months with the Microsoft announcement and Facebook with Libra. You can't just do what large companies with mounds of cash can do, how many hours and how much complexity has arisen from "but this is how Google does it!"? &gt; Many of the tools are already higher quality than those in C and C++ land. Yes, because people have been working on them! &gt; People do need to understand why both C and C++ are bad, because a lot of them have various mental blocks of some kind. The ones I've seen most commonly are ego and apathy. If C or C++ code pays the bills for your company, they are "good" for the company. Rewriting everything to use a relatively new programming language built by single company (and a lot of open source contributors) is high risk from a business point of view and uses resources which could just be used to improve the current product. Also, the C++ standards train is going full steam ahead at maximum speed to try to give companies a reasons to stay with them. Look at it from the point of view of a business. Imagine what would happen if Mozilla went belly up. Do you just throw your C or C++ programmers into Rust and see what happens? How are you going to hire for this new language? Can you company afford to lose that amount of productivity for them to get back up to speed and possibly rewrite or port internal libraries over to Rust? It is often sadly true, "better the devil you know than the devil you don't know".
Appreciate the depth! So lets say I have something mutable I want send across threads, a `Vec&lt;Foo&gt;` or w/e. I can do something like `Arc&lt;Mutex&lt;Vec&lt;Foo&gt;&gt;&gt;` and I'll have a safe, mutable reference I can pass into threads and mutate the `Vec` to my hearts content. What would be the correct way to express a similar intent as my above example, but with a `RwLock`? Previously I would have thought it was `Arc&lt;RwLock&lt;Vec&lt;Foo&gt;&gt;&gt;`, but I would have thought `Vec&lt;Foo&gt;`isn't `Sync`. That is to say, I thought `Sync` meant that the data can be mutably and/or immutably borrowed - that something is coordinating that behavior. Worst yet, I thought I've used something like `Arc&lt;RwLock&lt;Vec&lt;Foo&gt;&gt;&gt;` before, making me think `Vec&lt;Foo&gt;` *is* `Sync`... which then has me asking what _isn't_ Sync. Fundamentally I feel like I've always struggled to understand `Sync`. I get that it's a marker _(and I worded it poorly above)_, but every time I think I understand it, something like `RwLock`'s behavior makes me think I don't understand it. Right now I'm googling trying to figure out what makes something not `Sync`, in concrete terms at least. Funny, I've written thousands of lines of Rust, including parallel code with little to no trouble - and multiple times Sync is proving to be a mind struggle for me due to how everything is worded lol.
As well as the other examples, `Box::into_raw()` without a `Box::from_raw()` before the pointer goes out of scope can also leak.
It's a hard question. Is the crate a high-quality one doing something you need (`regex`, `serde`, `tokio`, `hyper`)? You should use it. Is it small and does something very specific like CRC or HTTP date parser? It's fine to use it. Do you need something related to crypto or hashing/key derivation? Use one of the existing crates. Is it a mostly a wrapper over functionality offered by other crates? You might be able to skip it. If it's not a well-known crate, you should also take a look over the code, especially at `unsafe` sections. If you're still not sure, feel free to ask the community. My personal opinion is that it's better to use existing code, and contribute to it if you find it lacking. In the end, using a crate should get you started more quickly, and you'll still be able to reimplement it in the end if you really need that. Rust is really nice here because you can even patch transitive dependencies. I don't have the source, but a long time ago I read some advice on this subject: is a library the core part of your application or service? Implement it yourself. Is it something tangential to what you're building? Use an existing library.
Use a `Vec&lt;Bottle&gt;` rather than a `LinkedList`. Linked lists are much less useful than data structure courses tend to imply and Rust in particular has many problems with doubly linked lists. From the documentation page: &gt; Almost always it is better to use Vec or VecDeque instead of LinkedList. In general, array-based containers are faster, more memory efficient and make better use of CPU cache.
You seem to have added a binary to you repository, that's usually a bad idea. &amp;#x200B; Good point. Removing. &amp;#x200B; &gt;Do ARM processors have hardware support for a CRC variant that matches these values? Yes! Although it is customizable, these are the default settings, frequently used for firmware/binary check and in protocols. Variants of the original code have been floating around: [https://github.com/stko/oobd/blob/master/tools/Cortex\_CRC32/cortex\_crc.](https://github.com/stko/oobd/blob/master/tools/Cortex_CRC32/cortex_crc.c) &gt;it doesn't help anyone to have 10 crates doing more or less the same thing. Thats true. Though one has to know which settings to use to achieve the same result with another crate... Thanks for your hints! I will probably just use an existing crate.
I don't like this kind of language evangelism too much. There isn't even an attempt to define the problem (what is unsafety again?), nor any description of the pain points you'll usually encounter when writing C or C++ (hint: for many applications, it's not unsafety). The problems with writing C/C++ is that while the language itself is fairly nice and simple, the underlying machine model is a nightmare that will throw hard-to-find/identify bugs at you and you need fuzzers, sanitizers and a whole lot of other tools to even have a remote chance of even finding half of the latent bugs your codebase will be riddled with. That said, for small state-machine-like programs (the kind you'll find in security-relevant applications such as automotive), C is a fine language to use. If your memory layout is flat &amp; known at compile time, you don't need to work with strings / dynamic sized vectors, you will find the simplicity and performance very endearing.
Ok, this really makes sense. Thanks for the replies!
&gt; Types like Cell and Rc that are not Sync can safely allow mutation via shared references because they rely on those references not crossing thread boundaries. Yea, and that makes sense to me. But.. what is Sync? `Arc&lt;T&gt;` isn't unless `T` is Sync, right? So is `Vec&lt;u8&gt;` Sync? I would have thought not, but that would mean I could not use `RwLock&lt;Vec&lt;u8&gt;&gt;`, because the Vec is not Sync.. so what, I'd have to do `RwLock&lt;Mutex&lt;Vec&lt;u8&gt;&gt;&gt;`? I'm tripping out lol. I've used all this code and thought I understood it all. Now my life is a lie :D
&gt; Thats true. Though one has to know which settings to use to achieve the same result with another crate... Which is why CRC variants are usually identified by name.
If it's IO bound as you said, I don't think the CPU matters as much. With that being said it's important to profile your application in a testing environment too.
It's hard to tell without knowing more and profiling your application. If it's IO-bound, then a faster CPU will probably not help; probably neither a higher-frequency one. You could maybe architect it differently, e.g. by batching your input and processing multiple batches at the same time. Perhaps you're doing that already. If you want an answer, you can rent some cloud VMs for an hour or so and test which one works better. If you're running Linux, you can also take a look at the [pressure-stall information](https://lwn.net/Articles/759781/) under `/proc`.
I suspect it's because a compiler is traditionally a complex, but basically non-interactive function, and functional languages clearly shine in that model; but in the "IO monad" (the real world), there's more of an impedance mismatch. Plus, language designers love designing compilers, and for a while it was mainly language designers who were enamored with functional languages.
&gt; leaking memory is a totally legitimate memory management strategy, because the OS will always cleanup all of your memory for free on process shutdown anyway You've probably heard this already, but there's a story that one of the popular compilers from the old days (Turbo Pascal, maybe?) never freed any memory because it was faster and the processes was short-lived anyway. &gt; I believe some systems have been observed that spend huge amounts of time pointlessly freeing memory as they try to shutdown (this is folklore in my head, can't remember any examples right now), and this leaking strategy would materially improve the situation. &gt; I believe some systems have been observed that spend huge amounts of time pointlessly freeing memory as they try to shutdown (this is folklore in my head, can't remember any examples right now) https://devblogs.microsoft.com/oldnewthing/?p=8683 is one example. &gt; and this leaking strategy would materially improve the situation. Please don't do this in libraries. In binaries, you should rather exit the process (as in `process::exit(0)`) rather than leak memory and run to the end. Valgrind will be less upset since the memory is still reachable at exit. Firefox does this, I think, although it still takes a long time to exit.
Depends, if writing the functionality you need would take a significant time/effort away from your main project, I would say just use the 3rd party lib. Most likely major 3rd party libs have been tested by the community and have bug fixes etc. And quite likely, in my case, the implementation would’ve been written by someone with more experience than myself in the domain.
&gt; making me think `Vec&lt;Foo&gt;` _is_ `Sync`... Correct! Like most "ordinary" types, `Vec` is `Sync` as long as its contents are `Sync`. That's because -- again like most types -- `Vec` doesn't allow you to do any mutation through a shared reference. So there's no danger in sharing `&amp;Vec` references across threads. &gt; which then has me asking what _isn't_ `Sync`. This is what I was getting at above when I brought up "interior mutability". Take a look at the relevant chapter of TRPL: https://doc.rust-lang.org/book/ch15-05-interior-mutability.html For a comprehensive like (I think?), you can look at the `Sync` docs: https://doc.rust-lang.org/std/marker/trait.Sync.html. Do a Ctrl-F in there for `!Sync`. The most recognizable examples in there are `Cell`, `RefCell`, and `Rc`. The first two are there because they let you mutate their contents through shared references without doing any synchronization. `Rc` is there even though its contents are generally immutable, because it updates its internal reference count without using atomics. The main reason those types exist is for performance optimizations: avoiding atomics and locks makes them more efficient than `Arc`/`Mutex`/`RwLock`, at the cost of being unsafe to share between threads.
&gt; Did Google buy Android initially, and not just start it from scratch? Oh, no. Android is the way it is because it was a small startup that tried to cobble together a proprietary OS out of as many non-GPL open-source components they could get their hands on, and write the rest in Java so they wouldn't have to deal with memory safety. Atrocious performance and battery life ensued. Pure Linux OSes like Sailfish are more responsive, consume way less battery and run equally well or better on cheaper hardware. The worst part is, Android cannot be fixed without losing the app ecosystem which relies on all that Java, and the app ecosystem is pretty much the only thing Android has going for it.
\+1 Thank you for the full response, much fuller than I could've ever reasonably expected from the internet. I think this is in a way what I was looking for, because I knew it wouldn't make sense to not have implicit self unless most variables weren't in-fact a property of the class itself. A lot of the Java code that I've seen generally has most methods simply manipulate internal variables, and thus an explicit self or this for that code would be highly unreasonable. But by having far more classes, most code ends up being calling other classes' code or otherwise interacting with input variables, making explicit self much more reasonable and sensible, as it's a minority.
The C standard library `malloc` just calls `HeapAlloc` IIRC. `memcpy` is probably a faster implementation than the `Rtl` one.
So I guess then, `RwLock` isn't the weird one for requiring `T: Sync`, but instead `Mutex` is the weird one for _not_ requiring it? Interesting, maybe that will help my warped sense of `Sync` :D Appreciate all the help!
Yes. That's the intended way to use mrustc
I am not aware that the specific variant used in cortex cores has such a name. Also, the parameters are hard to find online. Right now I am trying to get identical results from `crc-rs`, but have not succeeded yet.
If it's IO bound, you may want to focus on the IO side of things: network cards, memory controllers, etc...
&gt; I’ll go read the Linux man page on ptrace a few times now - we’re at that point. I don't have any advice; just wishes to say "Hang In There"!
Thanks, that actually helps enough. After the first almost full read-through I got some ideas which I'm about to rewrite the RFC to keep. More specifically I'm thinking the tracer should be able to specify a bitmask of types to track, and then the `write` call will respond with the kind activated. So you'd be able to say `write(&amp;(PTRACE_STOP_SIGNAL | PTRACE_STOP_SYSCALL));` and it would somehow respond with the value `PTRACE_STOP_SIGNAL` or `PTRACE_STOP_SYSCALL`, depending on which one activated first. I'm thinking of abusing the return value of `write`, but I may end up incorporating it with the event system (or both)
I'm going to be figuring out how to call into a third-party C library from Rust for a project.
Same as last week. [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) documentation and PR code reviews. I'm hoping to get a couple of the PRs landed -- but we'll see how much time I can find.
I do not consider this as a bug.
Why is something broken on [rust-toolstate](https://rust-lang-nursery.github.io/rust-toolstate/) almost all the time? What happened to the [Not Rocket Science Rule](https://graydon2.dreamwidth.org/1597.html)? Components like Clippy, RLS, and rustfmt are part of Rust distribution, yet nightly rustc breaks them routinely. I understand it is hard to do proper CI, version pinning, and atomic changes across multiple repos. Would it make sense to move Clippy, RLS, and rustfmt to rustc repo? It seems like a colossal waste of effort that people who are updating these components to keep up with rustc are different from those who introduce breaking changes and have all the necessary context to fix stuff right away.
Not everyone is working on such big projects. And this is 30 sec wasted, not 30 sec spent on doing something important.
&gt; but instead `Mutex` is the weird one for _not_ requiring it? 100%
cant access, get errors like this: Did Not Connect: Potential Security Issue Firefox detected a potential security threat and did not continue to hauleth.dev because this website requires a secure connection. What can you do about it? hauleth.dev has a security policy called HTTP Strict Transport Security (HSTS), which means that Firefox can only connect to it securely. You can’t add an exception to visit this site. The issue is most likely with the website, and there is nothing you can do to resolve it. If you are on a corporate network or using anti-virus software, you can reach out to the support teams for assistance. You can also notify the website’s administrator about the problem.
How is this different from something like SLURM?
Yep, this is the paper I was thinking about.
Well, just rewriting the Readme from scratch might help :)
&gt;You've probably heard this already, but there's a story that one of the popular compilers from the old days (Turbo Pascal, maybe?) never freed any memory because it was faster and the process was short-lived anyway. The compiler for D uses this strategy as well.
I always have a need for this. Thanks!
You're right, it seems to be a weirder variant, indeed. By the way, your API is strange, as CRC functions usually take byte buffers, while you have 32-bit integers. That's probably because the CRC method can access 3 bytes beyond the end of the buffer if the length is not a multiple of 4. Some other nits: - it's probably cleaner to include the generated bindings in a module - you should `#![allow(non_camel_case_types, non_upper_case_globals, non_snake_case)]` if you use the generated bindings - it's `#![no_std]`; the exclamation mark means that it applies to the outer block, not to what's following afterwards; right now it has no effect - you left an extra `hello` function in the C code - `bindgen` is actually overkill here, you can declare the two functions manually - the C code uses a static variable for the digest, so it doesn't work in multi-threaded code; the Rust test runner is multi-threaded by default, so you might end up with randomly-failing tests or other UB
It may be a good formal definition of how the borrow-checker works, but it did nothing to help me (as a programmer) *understand* the lifetimes (the opposite, in fact). And it was quite hard to read. I daresay that from a "normal" user point of view, that article is mostly useless (no pun intended ;), unless (maybe!) the reader is either deep into formal methods/math, or deep into compiler design. As I've been off both subjects for decades, this article contributed nothing but confusion for me. On the other hand, @lookmeat's explanation indeed made me understand the lifetimes better.
@aesamattki I wouldn't bother: it would be a detraction from what you're doing - unless you plan to design compilers *and* formally define how they work.
Do you have a more simplified benchmark results? Something like barcharts or simple percentages?
&gt;The benchmarks use criterion and you can view the criterion html reports from the run on my workstation here: [https://ggriffiniii.github.io/radix64/bench\_results/with\_avx2/report/index.html](https://ggriffiniii.github.io/radix64/bench_results/with_avx2/report/index.html) &gt; &gt; &gt; &gt;I've uploaded runs with and without simd enabled and the index for the results can be found here: [https://ggriffiniii.github.io/radix64/bench\_results/](https://ggriffiniii.github.io/radix64/bench_results/)
For reference, here is a trophy case of bugs found via fuzzing in Rust code: https://github.com/rust-fuzz/trophy-case Note how most of the bugs are not security vulnerabilities. Things like out-of-bounds accesses still happen aplenty, but thanks to Rust's safety guarantees are not a security issue.
&gt; lack of first-class interoperability with C++ Some form of this is definitely useful (I'm not sure what the current best way to interoperate between C++ and Rust is; anything better than manually specifying a C ABI?). But it makes me wonder: what languages do have "first-class interoperability" with C++? It's certainly not common... does C# have anything that can be described like that?
&gt;CRC functions usually take byte buffers, while you have 32-bit integers I did that because the cortex-m is 32-bit. What do you think of this method: [https://github.com/barafael/cortex\_crc-rs/blob/master/src/lib.rs#L46](https://github.com/barafael/cortex_crc-rs/blob/master/src/lib.rs#L46) Downside is that this is no longer `#![no_std]` then. With a byte slice, I would have to transmute or cast, right? &gt;bindgen is actually overkill here, you can declare the two functions manually Right, done. &amp;#x200B; &gt;the C code uses a static variable for the digest Damn! Good point. I addressed the issues. Thank you so much for your suggestions!
I think that the goal up there is that each type/class does only one thing and does it well, and that each method becomes the simplest actions. Java code would end up looking similar to what I did above, that is why I stated that the solution gives better OO code, but not the most rusty solution though. I think that in Java not having an explicit this is OK because the variable can only physically exist within the same block as the variable. It gets ugly when you have internal and non-static classes, which is why I generally avoid them. In Rust the function/method can be outside the block where the member variable was described. So when I see `foo` I assume it's defined somewhere in the same block I am (or brought over by a use). Then it's important to explicitly state we use member variables (through using `self.foo`) so it becomes obvious what the context is. It gets even more important when you need to split between methods and functions that could, otherwise, have the same name.
Code coverage... Awesome!
It sounds like you're more interested in high throughout than low latency. async usage tends to lower latency but at the expense of throughout in some situations. Async is a trade-off in several ways. You should use dstat on some more realistic hardware and figure out what real bottlenecks are likely to be on a real workload before trying to extrapolate so much based on your laptop.
Maybe this is the wrong sub for it, but I've been doing a lot of webassembly recently with the explicit intention of both sandboxing, and making a language agnostic playground. The tl;dr is that there's been a very appealing game concept to me for a while where I set up a server that handles cash, user interaction, 'hacking', puzzles etc, but there's no client. It'd all be played through code written on your own computer, including writing bots that other players could interact with Sandboxing in that format is obviously very tricky. I don't want to let people write C++, but forcing rust down here wouldn't help *that* much - people could still break people's bots and DoS the filesystem with large files Webassembly + wasi seems perfect. Nice sandboxed code, with capability based permissions. There'd only be so much you can do, and it runs at native speed as far as I can test (in my model, I transpile wasm to safe C and compile it) So, this leads to the question - with the increasing availability of a safe, sandboxable target which supports multiple languages, is there a compelling security reason for rust? Why not distribute C++ applications as a .wasm file, with an accompanying sandbox? I'm a huge fan of rust as a language so I'm not knocking it - I'm genuinely curious to hear people's thoughts on a sandboxed executable format vs a memory safe language
Hey those in this thread. I work downtown and will probably find a local meeting place to chat with anyone interested. If you are, feel free to pm me and I'll try organizing interest
AVX2 is known to [lower CPU frequencies considerably](https://gist.github.com/rygorous/32bc3ea8301dba09358fd2c64e02d774) for much longer than the AVX2 code actually runs, typically milliseconds. Your benchmarks are generally in the microsecond range. Wouldn't AVX2 be detrimental to performance, unless you're processing really large amounts of base64 data?
Rust would only hinder that.
&gt;does C# have anything that can be described like that? Sort of. There is C++/CLI which allows you to write .NET stuff in a language that is similar-but-not-quite C++: en.wikipedia.org/wiki/C%2B%2B/CLI I probably wouldn't call it first class, and AFAIK using a C API is more common.
So PTrace being _userland_ seems wrong, and you seem to skirt around the edges of why its wrong here when you comment &gt; The Design Feels Wrong PTrace is kernel level in most Unixes, notably Linux. PTrace (and debuggers in general) is one of the common arguments why you need monolithic kernels. As an example in OSX/Darwin/Mach (as kind-of-sort-of-microkernel) you need to also invoke a lot Thread-API's, and create a special runtime-VM for the traget process to execute in if you want to trace it. There is one stand out point here &gt; I think something to set as a goal with signals is to hit two birds with one stone and use them for handling the int3 instruction which is used by debuggers to set breakpoints. Debuggers don't insert an `int3` to break point an application. Compilers do. Debugger _will handle them_, but unless you compile in breakpoints, it generally doesn't. Why? It is _extremely_ challenging as most code ( _if_ ) it is position independent will requires it to have the same relative offset to a lot memory addresses (for example: `mov rbx [ 1 * (rax + rip + 0xFF)] `). When you insert an `int3` instruction, you need to adjust all offsets _greater_ then this (in the entire memory space). This maybe impossible. For the previous example `mov rbx [ 1 * (rax + rip + 0xFF)] ` will require an extra byte to encode `mov rbx [ 1 * (rax + rip + 0x100)]`, and now you have 2 bytes of offset, and it gets worse the more changes you make. Instead [`gdb` just calls `PTRACE_SINGLESTEP`, and snapshots the register file after every instruction](https://stackoverflow.com/questions/45083799/gdb-breakpoint-implementation), and _infers_ where your break point would be with [`DWARF`](https://en.wikipedia.org/wiki/DWARF) info. This is `gdb` telling the kernel, to tell the CPU to fault after _every instruction_ of the host program, and coordinating with the scheduler to keep it parked until the tracer tells the kernel to resume it. This also solve the syscall race condition you mentioned. As all signals the **tracer** receives come from the OS, while the **tracee** does not need to be aware their execution is modified.
That's it boys, we did it, **Microsoft Rust hype train** is ***online and operational***. Now it's time for Linux join the line. 🚅🚅🚅
Yes, I saw them. But they are too complex for me. I'm looking for something like "radix64 is X% faster than base64".
&gt; So PTrace being *userland* seems wrong, and you seem to skirt around the edges of why its wrong here when you comment It's not actually userland, this is a kernel scheme :) After all, user mode tracing would require running the process in a VM, no? &gt; When you insert an int3 instruction, you need to adjust all offsets greater then this (in the entire memory space). Or you just change the instruction back, revert the `rip` register and restart? Isn't this described in the awesome article [Playing with ptrace, Part II](https://www.linuxjournal.com/article/6210)? &gt; Instead gdb just calls `PTRACE_SINGLESTEP`, and snapshots the register file after every instruction, and infers where your break point would be with DWARF info. That would work for one line steps, and that ptrace call is implemented currently in Redox OS, but would be very, very slow for larger jumps. Are you absolutely sure GDB does this?
Yes, AVX2 has global implications and it may or may not be an improvement to the overall performance of your larger system. It depends on your CPU as well as the particular AVX2 instructions in use. I believe the instructions used in radix64 fall into the "regular" category of that document. I would always encourage people to benchmark for themselves using a representative workload for their system. If AVX2 turns out to be sub-optimal for your use case it can be disabled by compiling radix64 without default features, in which case I believe radix64 to still outperform any other current base64 crate (albeit by much, much less than with base64). &amp;#x200B; One additional note that benchmarking is hard and fraught with peril. Each iteration of my benchmark runs for microseconds but it runs many iterations that take about 5 seconds (much longer than the millisecond timescale the cpu power frequency changes).
Rust is just so much more intuitive than assembly. Anyway it was just a one time idea i had (about making nes homebrew), so it doesn't really matter anymore.
We already have a million alternative system utilities written in Rust, so it's somewhat operational. I don't think Linus would like to add a new language to the process of building the kernel, though :c
&gt; what languages do have "first-class interoperability" with C++? Not even C++ has first class interop with C++. There's no stable ABI, so code compiled under one compiler can't safely be used with code compiled under another compiler. Even different revisions of the same compiler can produce incompatible code You really have to compile everything from source - which makes cross language interop very tricky, because you can't safely hook into a library or DLL - there's no standard
Beyond the objective reasons stated, it's kind of natural for large corporations to sponsor an ecosystem, in an attempt to capitalize on it, steer its direction (or at least try to), and use it as an advantage against the competition. Google is sponsoring/shaping Go, the other giants need a response. I'm just surprised it's Microsoft that's on board (who already has .NET, even though the latter is in a different niche), rather than Amazon, who has a ton of infrastructure services (even more than MS) and no sponsored/curated language at all.
Okay. Did you look at the table on [docs.rs](https://docs.rs/radix64/0.2.0/radix64/#configs)? That may be the summary you were hoping for.
I think D made some attempts. The issue is that it is almost impossible to implement any sort of full integration with C++ code without also implementing almost all of C++'s semantics, which is a daunting task, to put it mildly. Something like virtual functions might be easy enough, but what are you going to do about templates? Many C++ libraries are header-focused, and basically require you to specify what instantiations of a template you want - including the standard library. Any realistic interoperability needs to stick to a very limited set of features, maybe even just some clever name mangling, and only to symbols that are already present in the compiled binary you're liking against.
Yeah... i do agree with you, however still have some (little one) hope, tho only time will tell (and Linus stubbornness)
Forget is the opposite of leaking
To be fair, this is even more true in Rust. There isn't really anything in theory that prevents C++ the language from being interoperable, but the issue is the standard library and its many implementations, most of which rely on compiler intrinsics to be conformant and performant. These intrinsics end up getting inlined. But you can definitely compile a library with Clang on Linux, and use it from another binary compiled with GCC - as long as they use the same standard library.
&gt; I did that because the cortex-m is 32-bit. x86 is 32-bit too, but you can still compute a CRC-32 over a 98 byte array. It's something more specific to the variant you have, I think. &gt; What do you think of this method: Do you mean the generic one? I don't like it and it's wrong; there's nothing preventing it from accessing data outside the buffer as mentioned before -- call it with an `[u8; 2]`, for example. In addition, bytes have checksums; objects don't. If your `T` is `String` or whatever, you'll get nonsensical outputs. But yes, I appreciate the care you took to make it work with ZSTs. &gt; Downside is that this is no longer #![no_std] then. Or maybe you meant something else.
Nice project. Thanks for sharing. If you change fn hit(&amp;self, r: &amp;Ray, t_min: f64, t_max: f64) -&gt; (Option&lt;HitRecord&gt;, Option&lt;&amp;Material&gt;); to fn hit(&amp;self, r: &amp;Ray, t_min: f64, t_max: f64) -&gt; Option&lt;(HitRecord, &amp;Material)&gt;; It makes your ray tracer 24% faster. It also makes the code in `hitable.rs` simpler. On modern cpus branches are surprisingly expensive compared to other operations. Rust code tends to be more ergonomic and less bug prone when illegal states are made unrepresentable.
You can always build the RedoxOS hype train.
&gt;Are you absolutely sure GDB does this? It depends on the hardware platform. As the approach they take is determined by the target/system resources. It is also determined by if it is a `catchpoint`, or `breakpoint`. [see wiki](https://sourceware.org/gdb/wiki/Internals/Breakpoint%20Handling). On x64 most evidence points to it using `SINGLE_STEP` mode. The approach of " _insert_ `int3` _and clear it afterwards creates_ " **a lot of problems** with not only multi-process applications, but chips (like x64) which don't have explicit instructions to flush their I-Cache, as you _may overwrite_ `int3`, but `int3` is still cached &amp; gets executed anyways.
Doesn't cargo test use debug builds?
Maybe Microsoft smells a technology edge using Rust in these new cloud marketing wars...
Thanks a lot for the explanation and links. I think it makes more sense now and I also have material to study :)
Maybe a Netflix stream, multiple people could watch it but only Netflix could change the video stream.
Its not necessary just the STL as far as I'm aware, there are further ABI issues to do with how various things are laid on different compilers out if I remember correctly
Thanks for the explanation, Indeed it's a combination of many features that have to align just right for the difference to manifest. On getting the low level output MIR is what I was thinking about too. I'll try to dig a bit more once I found some time
I see, thanks for the explanation. I guess that makes sense... Thanks for correcting me! And, thanks for the wiki link by the way, whenever I get back to trying to port GDB that will be extremely valuable :)
You do not remember correctly -- Clang works very hard to be ABI compatible with GCC on unix systems, and tries very hard to be compatible with MSVC on windows systems. Any ABI incompatibility is a bug.
Microsoft should just base the next server OS on Linux. Just use the Windows sources to improve Wine and run all the old software on it. Windows is not even good at running old software like games anymore. You can run the server stuff on Linux, it has better support for it anyway. Just running cloud tools on my Windows laptop made me want to tease my hair out.
Oh sorry, I thought you meant in the general case of MSVC/GCC/Clang compat overall. Yeah you're definitely right in that clang specifically will interop with GCC or msvc
&gt; So, this leads to the question - with the increasing availability of a safe, sandboxable target which supports multiple languages, is there a compelling security reason for rust? Why not distribute C++ applications as a .wasm file, with an accompanying sandbox? In general, or in your specific case? A couple of reasons for not using WASM: - WASM is a very recent technology; people are not going to port their legacy applications to something this new - there's a measurable performance loss versus native code (some 1.5-10x) - there's no support for threading, SIMD, there aren't many provisions for communication with the host; not sure about debuggers, CPU and memory profilers and other tooling - applications care about interacting with the OS -- they want to read files, draw pretty graphics, use a printer, access the network, communicate with USB devices or other running applications; could you make a sandbox that handles all of these? Possibly, but it's certainly not easy. And some reasons to use Rust instead of C++ for a WASM target: - with C++ you can still have undefined behavior even if you compile to WASM, as far as I can tell - you can still overrun buffers, have information leaks, maybe even data races if it gains threading support (although last time I looked it was more like multi-processing than multi-threading) - the Rust tooling is better (how do I compile Boost for WASM?), and the language is nicer
Wine runs old Windows games better, hell, half of the newer ones better too...
&gt;hauleth.dev/post/e... Works fine with my Firefox and I'm behind a somewhat restricted environment. Maybe your company is having a more restricted firewall.
I was experimenting with this: fn main() { let mut cnt = 10; let rec = fix(|rec, cnt: &amp;mut i32| { if *cnt &gt; 0 { *cnt -= 1; rec(cnt); //rec(cnt); // error here } }); rec(&amp;mut cnt); drop(rec); dbg!(cnt); } and it works, but if you remove the `drop` then it errors. Rust definitely thinks that the closure is, or might be "holding onto" that mut reference. I'm not sure why.
More alive than you are, grandpa 🤭
Write a nes emulator in rust
&gt; Some of these concerns include how to regulate the usage of the “unsafe” superset of Rust at scale Well hello there Microsoft, please consider supporting cargo-geiger ;) https://github.com/anderejd/cargo-geiger Send some PRs, open some issues and let's push this tool forward.
In some cases you could take a smaller crate and learn the code and re-implement it, or fork it -- and maybe post a better version or send a pull request in case it's just a small tweak. &amp;#x200B; I agree that navigating across the thousands of crates is indeed daunting. Usually the good ones bubble up.
I'm mostly interested in seeing what people think for wasm as a general security sandbox for executables, vs trying to make a safe language that cannot be exploited easily (memory safety). I'm not particularly on either side of the fence here, I'm genuinely curious! &gt;WASM is a very recent technology; people are not going to port their legacy applications to something this new This is definitely a good point, but its also not a plus for any other technology. Legacy is a problem whatever you do &gt;there's a measurable performance loss versus native code (some 1.5-10x) Interestingly I suspect this is more for a browser context - wasm as an assembly format isn't particularly inefficient and I can't see any reason why it would be - in my tests its as fast as native code (wasm -&gt; C transpiled, and then recompiled with an optimising compiler) &gt;there's no support for threading, SIMD, there aren't many provisions for communication with the host; not sure about debuggers, CPU and memory profilers and other tooling These are obviously big problems in the short term, though its worth noting there are spec proposals for (some of) these, its a matter of time essentially &gt;applications care about interacting with the OS -- they want to read files, draw pretty graphics, use a printer, access the network, communicate with USB devices or other running applications; could you make a sandbox that handles all of these? Possibly, but it's certainly not easy. This is an interesting point - though there's much the same problem in rust. Existing OS functionality isn't safe at all, so you need to create safe wrappers around it and then ensure that its only used safely &gt;with C++ you can still have undefined behavior even if you compile to WASM, as far as I can tell Undefined behaviour is the bane of my existence, but at least a proper sandbox means that you can't get *memory* unsafety - though you still run into incorrect application issues which could definitely lead to security flaws when your compiler exploits UB, which is presumably significantly harder/impossible to get in safe rust &gt;you can still overrun buffers, have information leaks, maybe even data races if it gains threading support (although last time I looked it was more like multi-processing than multi-threading) Buffer overruns should at least be impossible in the sandbox - the higher level code can try but your sandbox will abort/trap/etc. Data races are interesting but you're right in that it depends on the implementation - but fundamentally if you write thread unsafe C++ then you're going to end up with incorrect application semantics (which could be a security issue) &gt;the Rust tooling is better (how do I compile Boost for WASM?), and the language is nicer Yeah don't get me wrong, I like rust a lot as a language. Even asides from the *security* concerns, borrow checking as a concept is an extremely neat way to ensure application integrity Maybe really the solution is eventually to compile rust to WASM and sandbox it. It'd be pretty difficult to break out of that kind of jail - you'd need to find an exploit in the rust code, and then the sandbox itself
&gt; While researching Rust, we found some issues that gave and continue to give us pause. Some of these concerns include how to regulate the usage of the “unsafe” superset of Rust at scale Is there an idiom for asking for the safe-only version of a crate? [dependencies] somecrate = { version = "0.9", features = "no-unsafe" } ...and presumably `somecrate` would have a `[dependencies.nounsafe]` that asked for the `no-unsafe` version of its dependents?
I'm working on a stabilization of currently implemented stuff in [`heim`](https://crates.io/crates/heim) (async lib for system info fetching) - a lot of platform-specific information about users, network interfaces and CPU stats can be fetched now, and there is no `::std::mem::zeroed()` usage left anywhere. One very irritating bug with Windows implementation is still there though (related issue was re-opened three times already). On this week I'm going to design the running system processes API, since it is a one of the major goals and I still got nothing.
It's not really possible, because any meaningful program will need to rely on unsafe somewhere in its foundations; talking to the operating system is inherently unsafe.
MSVC and GCC do not interop because they don't attempt to at all, tho -- MSVC doesn't run on Unix, and GCC tries hard to not work with MSVC on Windows.
Thanks for reading my code ! I did what you said, it seems faster... but the greatest thing here is that the code is much cleaner ! Thanks !
As far as I'm aware, GCC tries to maintain a stable ABI whereas MSVC breaks it with every major release (excepting the recent ones) I think its less of a case of deliberate incompatibility, and more that just fixing it at this point is a lot of work - and very constraining for both parties. There's no standard for it, so there's not even a common goal to work towards - and from the sounds of the developers there's not that much interest either
Okay, sure, but maybe we could exempt/audit `libstd` or some other core subset of libs.
Thanks! That's what I was looking for.
There should be at least some one other arguments parser that is also based on `args_os`. It is question of correctness, not feature richness.
&gt; Interestingly I suspect this is more for a browser context - wasm as an assembly format isn't particularly inefficient and I can't see any reason why it would be - in my tests its as fast as native code (wasm -&gt; C transpiled, and then recompiled with an optimising compiler) See e.g. https://www.usenix.org/conference/atc19/presentation/jangda. I think there was a blog post submitted here (although it didn't mention Rust at all) that was over my head, but discussed how the WASM representation isn't great for compilers because they struggle to recover control flow information, or something like that. &gt; These are obviously big problems in the short term, though its worth noting there are spec proposals for (some of) these, its a matter of time essentially Sure, but that might take some a number of years (many more if you also want the tooling), which I wouldn't call short term. &gt; This is an interesting point - though there's much the same problem in rust. Existing OS functionality isn't safe at all, so you need to create safe wrappers around it and then ensure that its only used safely Of course, it was a point against WASM, not necessarily C++/WASM. Also, note that in some cases sandboxing these is very hard -- think of the graphics APIs, for example. &gt; Buffer overruns should at least be impossible in the sandbox [...] but fundamentally if you write thread unsafe C++ then you're going to end up with incorrect application semantics (which could be a security issue) Yes, something like that. Even if it doesn't end up as a security issue, your application can still malfunction. You can't overrun the sandbox memory, but there's nothing to prevent you from trampling around your allocated buffers. WASM doesn't even know what those are. &gt; Maybe really the solution is eventually to compile rust to WASM and sandbox it. It'd be pretty difficult to break out of that kind of jail - you'd need to find an exploit in the rust code, and then the sandbox itself Assuming you disallow `unsafe`, which might not be easy. &gt; Oh and thanks for replying! I'm mainly curious how we can stamp out bloody unsafety forever, the state of security in this industry is still ludicrously bad At least we're not building bridges...
I'd love to never have a release without clippy, but for now the decision was made to not require each PR to also update clippy, RLS and miri. Doing this would unduly burden the PR authors, who are not experts in clippy, miri and RLS. We keep up as well as we can, but we are volunteers, so our time budget is limited.
I wouldn't call this a bug, it's more of a design choice. When goblin parses a header, it parses all of the fields in the header and returns them. Changing this to lazily parse fields would be a major redesign.
Try /r/playrust. In the meanwhile, if you want to learn the Rust programming language, feel free to join us here.
&gt; See e.g. https://www.usenix.org/conference/atc19/presentation/jangda. I think there was a blog post submitted here (although it didn't mention Rust at all) that was over my head, but discussed how the WASM representation isn't great for compilers because they struggle to recover control flow information, or something like that. &gt; &gt; Thanks, I've only just got something that's theoretically performance testable going for wasm so I'll test it on some larger applications - its definitely possible that the structured control flow might cause some issues - but at least quite a bit of it looks like it can be optimised away post transpilation. Getting something like LLVM to work like this is on my TODO list, I might come back with results &gt;Sure, but that might take some a number of years (many more if you also want the tooling), which I wouldn't call short term. Definitely - though we've been grappling with terrible security since the birth of the industry so I'll take just a few years &gt;Of course, it was a point against WASM, not necessarily C++/WASM. Also, note that in some cases sandboxing these is very hard -- think of the graphics APIs, for example. Graphics API's are particularly depressing in my experience, there's just so many DoS style bugs in the drivers I'm not convinced that its possible to sandbox safely. I used to do a lot of OpenCL, and let me tell you that creating an unkillable application is easy, or chain crashing the driver - with perfectly compliant code. I'm not sure how this can be fixed &gt;Yes, something like that. Even if it doesn't end up as a security issue, your application can still malfunction. You can't overrun the sandbox memory, but there's nothing to prevent you from trampling around your allocated buffers. WASM doesn't even know what those are. Yep. WASM does do some interesting things with function calls actually, it should be the case that heap overruns (which don't OOB your sandbox) shouldn't cause EG arbitrary control flow or calling other functions which is an enormous improvement, though you do still run into incorrect application behaviour &gt;Assuming you disallow unsafe, which might not be easy. True true. I think the key thing with security though is to push it off into the hands of people who are experts, to try and isolate it to the minimum possible corner - which is something that rust does excellently. The problem currently is that its the responsibility of every developer to write correct safe code in every PR in C, whereas with rust, you can simply say "no, you must use this safe library" and then safe rust code is memory safe (assuming the library is safe, which is a significantly smaller security surface) &gt;At least we're not building bridges... Heh. I will never own anything smart in my home
Yes, someone finally suggested learning rust to those poor gamers 😂😂😂
I've been actually doing it for a while now, but they didn't seem interested :-). On the other hand, they're often new accounts, so I don't know what I should expect.
I don't usually like heavy-handed moderation, but I'm tempted to desire a minimum-age requirement for posting to /r/rust.
Are Rust servers so easy to set up? OP doesn't sound particularly underage to me.
I do mean account age :-P
I interpreted this more like asking how *infectious* unsafe is: Is it always possible to find a safe interface for an unsafe operation? Or do those usages "bubble up" into the caller code, infecting it with more unsafe directives? So far, the approach of containing the unsafety with no or only minimal performance / usability loss seems to work well. Let's hope this continues to be true when larger players like Microsoft explore new domains for Rust. But yeah, for larger companies, tooling that enforces how unsafe is used (e.g. by whitelisting), will also be required.
Here's a reason article on using `mrustc` to target 6502/6510: https://github.com/xTibor/rust-on-c64
Is Julia an example here: [https://github.com/JuliaInterop/Cxx.jl](https://github.com/JuliaInterop/Cxx.jl)
The decision making process supposed to be transparent. Could you please link to the analysis behind this decision? Am I correct that Clippy, RLS, and rustfmt are considired critical components of the Rust platform, and not just some nice-to-have hobby projects? If so, it's not enough to say that updating, say, Clippy burdens rustc devs. What about Clippy devs burdened by the need to keep up with rustc? You can only shift the cost around as long as it's not inflated in the process (and I suspect in this case it might be). Disclaimer: I'm neither rustc nor Clippy contributor (except for trivial patches and reports). This is just an outside perspective. I'm not trying to argue on behalf of the oppressed Clippy devs. But I think keeping changes atomic will save development effort overall (see the usual arguments for monorepos). As a second-order effect, the experience of making atomic changes could lead to additional insights on what rustc public API should eventually look like.
Good to know. In which case, Rust-C++ interop specifically targeting compatibility with Clang would be a decent solution, though not perfect.
That's probably a big reason why C++ libraries seem to use a lot of virtual interfaces, with some extern "C" methods for creation your initial instances that can create all your other objects.
I think you should just screen people’s first post to the rust subreddit.
Depending on your acceptance criteria, for certain parts of the language (usually not including full support for C++ templates): Objective C (with Objective C++), anything .NET (with C++/CLI), and Python (with Boost.Python) all require some explicit setup in a C++ (or extended C++) layer. This is far closer to first class than, say, JNI or FFI, but still limited. D, if it worked reliably, has more or less first class external support (comparable to the conceptual approach of https://github.com/mystor/rust-cpp), but the ABI thing is problematic. For any language with SWIG bindings, the C++ SWIG story is far more mature than it once was, but it can be touchy, and it requires some manual work on the C++ side. Julia, as mentioned by someone else here, has some support. I've never looked into C++ interop with Swift or golang, and if there has ever been an attempt at C++/JS interop, I don't want to know about it.
I tried to do this for one particular project in my workspace (leaving the rest to the default) to no avail. Is it an all or nothing setting?
That requires human effort... from unpaid moderators. Unless we have some *dedicated* mods... I doubt that'll work.
Mozilla is the one who took the lead here.
Technically true, but I was coming from the 'megacorp that owns a huge amount of infrastructure, and whose mere adoption of a technology is enough to significantly elevate it on that merit alone'.
This is indeed quite difficult; C++ is not a simple language, so even if there's a way to map the semantics, it's a complicated task. &gt; but what are you going to do about templates? Many C++ libraries are header-focused, and basically require you to specify what instantiations of a template you want I suppose a simple solution would be to just import the C type in Rust using a string like `"std::vector&lt;int&gt;"`, and rely on a C++ compiler (perhaps invoking clang as a library?) to determine the concrete functions corresponding to it. And ideally, a way to map between a compatible subset of templates and Rust generics (which is definitely not possible in general, but may be possible in some cases.). I'm not sure it would currently be possible to do the later without support deeply integrated in the language. Here's a quick idea, without trying to implement it or really consider prior art: ```rust #[cxx_include("vector")] #[derive(cxx_class("std::vector&lt;int&gt;"))] struct CXXVector_int; fn main() { CXXVector_int v; v.push_back(5); } ``` Not an especially good design, but I think it should be possible to create a crate doing this? Now, things get really insane if you want to be able to subclass C++ classes in Rust, and then call into from C++. Which is necessary for using many libraries. Really, depending on the meaning of "first class", this is only possible in a language explicitly designed to fit with the semantics of C++. (Like Kotlin does with Java.) Otherwise, even if you manage to jurry-rig a mechanism to define "classes" in Rust with all the possibilities of C++ classes, code doing that won't really be native idiomatic Rust. Though in that restrictive sense, you could say C++ doesn't have first-class interop with C.
Yeah, this is true. I wasn’t sure if we had some dedicated mods here
It took me some time but I finally figured out how to make useful types for my iCalendar writer crate - ics. The problem right now is that the API is stringly typed and due to this weakness the library requires actually a lot of knowledge from the user and keeping everything in mind. To test it I will try to make a tiny calendaring app.
The closure approach isn't necessarily any better than your solution, in this case. You've taken the computation and made it into a procedure, which is fine. For a short function, it's often a lot easier to type a closure into the program rather than put the code in a separate function, with all the tedious declarations, and so a closure can likewise make the code easier to read, since the function is close to its point of use and it's usually smaller. &amp;#x200B; In some cases, though, the closure will be reading local variables from the enclosing procedure, and perhaps returning results to local variables. In this case, the closure will be more general than the directly equivalent procedure function. Logically, this local variable access is equivalent to adding additional custom parameters to the function. You can provide access to local variables by passing an opaque pointer to a custom structure as an argument to your function, and filling that structure with pointers to local variables, but that is not so easily checked by the compiler, and requires boiler-plate to create this arbitrary structure. That would be how C programs do this type of extension. Is this clear at all? &amp;#x200B; All languages are Turing-complete-ish sorts of things, so differences come down to legibility, brevity, and compiler checking.
https://docs.rs/radix64/0.5.0/radix64/ for the latest version of crate's docs.
i have heard Alex Crichton has some free time ...
Writing a baseball data scraper with an accompanying article series for FanGraphs/THT. The first piece should drop tomorrow.
Wait I cannot tell if i'm getting roasted or helped.....
In many ways Rust isn't designed to scale down(the typical approach to memory management on 6502 is to statically locate just about everything - it's really a different universe), but something you could do instead to try some retro homebrew is work with a BASIC. There are plenty of those, not so much for NES, but certainly for other 8-bit computers. Atari 8-bits have many good and recently maintained ones such as [Altirra Basic](https://atariwiki.org/wiki/Wiki.jsp?page=Altirra%20Basic) and [FastBasic](https://atariwiki.org/wiki/Wiki.jsp?page=FastBasic).
There have been multiple 6502 backend attempts for LLVM and none have been successful. As others have said, it's not a great compiler target. The lack of stack-relative addressing in particular is a killer…
&gt;To be fair, this is even more true in Rust. This could be fixed if Rust could settle on a stable HIR/MIR, and then ship such binaries of such *stable intermediate representation* to users everywhere. (Or even just come up with a binary format that is slightly richer than LLVM.) **Then, compile** it to x86/arm/etc machine code *on the user's machine*. Ahead-of-time compilation is so much better, for two reasons: * **Better delivery:** You don't need to manage several different production binaries, for every support CPU architecture. You don't have test those X different binaries. Maintain and test just 1 binary. * **Better performance:** Compiling on the user's machine means that the compiler is aware exactly what processor the user is running, and can take advantage of all the special instructions it offers. Sure, there will be a slight delay for the user, *the first time* they launch the app, but the benefits are worth it. This is what Android ART is doing these day--the JVM-esque bytecode is AOT-compiled to machine code when a user install the app.
Renamed my Twitch bot project to [OxidizeBot](https://github.com/udoprog/OxidizeBot) - Twitch username availability is the limiting factor :o). And I'm working on breaking out a couple of utility crates that might be useful for other folks. Done so far: [futures-option](https://github.com/udoprog/futures-option) and [futures-cache](https://github.com/udoprog/futures-cache). I could use some help with the latter one. I'm working on implementing a more lock-free algorithm for queuing identical requests. It currently requires two uses of unsafe and a feature (`pin_into_inner`) to be "cancellation safe". It could use a review or rewrite to get rid of the `unsafe` if possible.
golang does only have support for C interop (package cgo), with restrictions on passing pointers between Go and C, because golang programs has a garbage collector. [https://golang.org/cmd/cgo/](https://golang.org/cmd/cgo/)
Could you elaborate why? I always thought async gives high through put because it minimises context switching.
Writing more tests and smoothing the edges for [nom-sparql](https://github.com/MattsSe/nom-sparql/), a parser for the sparql query language. I'm not sure whether I can use this in future projects, I was just interested in trying nom 5.0. But definitely thinking about graphs atm and diving into petgraph and a bunch of linalgebra crates this week.
Actually if the copies instead of "moves" this is no good. I need to receive updates to the vectors.
Example? You can update the vectors.
Can it help against errors that do not trigger a panic but abort instead? For example, for out-of-memory errors or - God forbid - things like segfaults?
C# can wrap native DLLs into a managed context. But it’s hazardous at best and explosive at worst. You rarely know how it’s going to act once you wrap it (hidden races, memory leaks, terrible performance, etc). At least that’s been my experience.
I'm learning myself, but I think it's about changing your way of thinking away from OO. We get frustrated because we're using new tools in old ways, like trying to use a scalpel like an axe. We need to learn to use the new tools. With rust I seem to have success when breaking things up into operations. I don't know how to explain it yet. It probably won't work with every problem type. It just comes from rewriting the same problem over and over in different ways and re-melding my brain. When you design a solution to remember the building blocks you have to work with: * traits * small structs * struct implementations * generics (like c++ templates * functions * iterators I just sit and think, or walk and think, about the best way to put those together to come up with a solution, and of course the best way to break the problem down into smaller problems. I've been self learning with [https://adventofcode.com/2018](https://adventofcode.com/2018)
I haven't been able to confirm, the the way I read it the data is copied out of self. I've posted about where to store this state, perhaps it's best to discuss this there as the solution suggested "worked"
Yeah but will it ever be able to compete on any level with linux? Maybe because it doesn't have all of the legacy baggage that linux does but maybe not because linux has a such a long head start and so much momentum behind it.
Do you mean JIT instead of AOT compilation? Rust already is ahead of time compiled, that's compiling each binary for each different platform ahead of the time it's run, same as C and C++. ART is a kind of mix between JIT and AOT, but leans more towards JIT, since the final compilation is done on the user's machine.
Actually, what Rust, C, C++, and other compiled languages do *is just called compilation*. AOT means that you compile on the user's machine **before the program starts**. JIT means you compile (on the user's machine) **while the program is running**. ART is AOT, whereas most JavaScript engines use (tracing) JIT. Historically, the way JIT worked was that, it started interpreting your code immediately (so there was no delay in your program starting), and then JIT-compiled practically everything on-the-fly. Modern JIT-compiled languages however, tend to use tracing JITs. A **tracing JIT** for instance, interprets your code initially, while creating a "trace" to determine hot spots (most executed parts of your code). It then JIT-compiles just that portion.
C# interop is actually quite similar to Rust interop. C# can do interop with C-like data structures and code fairly easily (although it certainly cannot represent everything that C can; Rust gets closer), but C# cannot do any degree of interop with that portion of C++ that is not part of C, such as templates or vtables, in any kind of ABI-stable manner
I really don't know. The Redox documentation says that Redox isn't going to replace Linux, which is kind of obvious, but I haven't seen anywhere where they state their end goal (if there even is one). Their advantage is the modern design for all parts of the system, their disadvantage is the lack of drivers for everything. What would be cool is if people start porting the Linux drivers to the microkernel interface (I have no idea if that's possible/doable) to make it possible to at least run the system on various pieces of hardware. And I also don't know if all the software for Linux works out of the box (after compilation, obviously). One place I could possibly really see it working is for servers, same way a lot of companies use OpenBSD for its safety features. But I don't know if the microkernel theoretical performance hit could become a real issue for something like games.
I never implied that it could replace Linux. That would be near impossible. The would be like trying to replace Windows in the consumer OS space. It'll never happen. But what I meant was that I could be a viable alternative or perhaps even a complement to existing linux systems in specific usage domains.
Could this be used with WASM at all? I wonder how it compares to the \[browsers base64 API\]([https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/Base64\_encoding\_and\_decoding](https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/Base64_encoding_and_decoding)), the custom alphabet support is a nice advantage too!
Linus does not have a single reason to switch. He literally said what he thinks about C++ (C++ devs are people who don't know what their code does) and I believe he thinks the same about Rust.
Kinda made me lose my mind for a second there. The Wikipedia page on AOT compilation didn't solidly support or deny your claim, and way too mant sources talked about Angular for some reason. [This Quora comment](https://qr.ae/TWnmb4) explained it in an okay enough way. &gt; "Ahead of time" compilation is basically just like normal compilation. It just means that you do all your optimization and code generation before running the program. JIT, on the other hand, can optimize the code as the process is running. &gt; **AOT is usually used to describe systems that work on bytecode that would normally be jitted.** So an AOT compiler generally takes some portable intermediate format (like JVM bytecode or Microsoft's CIL) and compiles it to native code before it's run. In the past, somehow, I used to think that AOT was just normal compilation, so that you for correcting this mistaken assumption. Even the Wikipedia page was kinda garbage, because it gives C or C++ compiler in the summary, but doesn't in an example below. Grrrrr. --- Besides your suggestion of AOT, which would be a cool thing to occur at installation time, what would also be cool would be to have a normally compiled executable, like Rust normally does, but have a bit more runtime to do JIT optimizations on the fly (Contrasting with the JVM, which has to compile in the first place, where this would only add optimizations). AOT is probably better overall, though, with fewer drawbacks except for a longer installation time. My idea is just too heavyweight, tbh.
Another way to think about this: The left-hand side of `let` already takes a pattern. For example, you can do something like ```rust let MyStruct { my_tuple: &amp;mut (a, ref b, _), ... } = expression; ``` Such patterns are "irrefutable". They have the same syntax as `math` arms but are required to match any value. `if let` then is simply a way to use "refutable" patterns with a `let` statement.
Hi!, just playing with async/await. With tokio::spawn and futures::Future, it is possible to execute multiple futures. How can I spawn multiple async fns? tokio::spawn(async fn{...}) fails with the error "the trait `futures::Future` is not implemented for `fn() -&gt; impl futures::Future {...}" I'm using tokio 0.2.0 from the git master and futures-preview 0.3.0 with async-await. Thanks for reading!
Gonna be real here, for some reason I tried a joke about Linux (would put /sarcasm) but because I'm a idiot who drank too much coffee (even with my IBS) I literally forgot. Should've edit but... Let's learn from my mistakes 🤣🤣 Besides the meme "Rewrite everything in Rust" I do believe (in my deepest core) that will be a more than validy choice in a lot well stabilished applications/kernel (well everything). Actually the article starts to "point this" probably the next one will exposure that more.
I built [cargo-run-script](https://github.com/JoshMcguigan/cargo-run-script) which is similar. It doesn't see any production use though, so it likely has some undiscovered rough edges.
The typical problem here is historical improper hijacking of the .dev TLD.
Doing the final commits on the 0.6.0 version of [abi\_stable](https://github.com/rodrimati1992/abi_stable_crates/tree/nonexhaustive),which I've been working on for over a month.This version will have a rewrite of Rust-to-Rust-ffi-safe trait objects,nonexhaustive enums with fields,and a bunch of other things I'll list in the changelog of the release.
You're talking to one of the original authors (or maybe the original author?) of clippy, btw.
Wow, exactly what has been said a million times before¡¡¡
Linus has only commented on Rust once, and it was... better than I expected https://www.quora.com/What-does-Linus-Torvalds-think-of-Rust
Features should be additive, not subtractive, so the approach you use is a default feature `unsafe`. I like to use three related features: - `std`, if useful functionality can be achieved without `std`, but you can add more by using std. - `nightly`, if benefit can be gained from optionally using nightly features; sometimes this means implementing unstable traits, sometimes it means choosing a more efficient implementation that is not yet stable, sometimes something else again. Will often depend on the `unsafe` feature. - `unsafe`, if you were choosing unsafe for performance rather than out of necessity, and can switch implementations. `std` and `unsafe` should be default features. Just remember to run all the tests on all combinations of such features, where you use them to switch between implementations.
Lol
Rust is not dependent upon Mozilla and has not been for years.
So it's just like programming in C++ normally? :-D
&gt;lack of first-class interoperability with C++ This was the biggest issue I ran into when integrating Rust in an existing C++ codebase. Certain things become awkward.
&gt;Modern JIT-compiled languages however tend to use tracing JITs. the hotspot jvm does this, and I'd hardly say it is "modern" in the sense of "new". though i don't know if this has always been the case. interestingly, the .net jit does not do this. there is no interpreter at all (though i lurk the .net core repos and an interpreter is brewing). asymptotically it doesn't matter, but for simple cli programs it can make a huge difference. profiling jit time matters a lot when a program's lifetime is a second or less.
afaik it's not supported anymore either. i shudder to think of the codegen behind it. friends don't let friends c++/cli. just pinvoke.
That's only part of the problem. What they're likely referring to is when is it or is it not ok to use unsafe blocks. I know we rustaceans like to say never but there are places where it's difficult or impossible to avoid.
That’s helpful to know! I’ve only worked with some native (C?) DLLs before, and a little bit of Windows APIs you had to import (media32? it’s been a loooong time)
Why would you want C++ interoperability? All you really need is C interop, and C FFI’s are usually great for that.
This code gets fixed with RUSTFLAGS="-Zpolonius" in nightly. For context (1 year-old article): http://smallcultfollowing.com/babysteps/blog/2018/06/15/mir-based-borrow-check-nll-status-update/#polonius
The if-let pattern-matching syntax was one of the hardest things for me to get my head around when learning rust. The normal use 'if' and 'let' just caused massive cognitive interference for me.
Is it bad to have a lot of \`.clone()\` calls in your code? Sometimes I feel like every function call is asking for a \`String\` instead of a \`&amp;str\` and so I'm constantly cloning my input. Should I consider this as indicative of a problem or am I overthinking things?
Huh. I didn't realise auto-moderator was a thing. Assuming it already has some vaguely related features (reading and posting comments, persisting state, etc.), how hard would it be to implement a workflow like this: 1. Evaluate a score for "looks like Rust-the-game", and a score for "looks like Rust-the-language" based on some really sloppy heuristic. 2. If you either get a strong signal for the former, _or lack_ a strong signal for the latter, then become suspicious. 3. When suspicious, post a comment explaining to the OP the challenge we have here, and asking the OP to reply with a specific phrase affirming that they understand what subreddit they've posted to. 4. If they don't get that reply within 10 minutes, quarantine the post. Or... quarantine the post immediately, if that still lets the OP post replies. (I'm not sure how Reddit works for moderators here?) If this is something that might fit into the scope of the AutoModerator project, I wouldn't mind helping with implementation.
Are those functions in your code or in someone else's?
The functions are my code.
Apologies. I know it's an open source project, but my understanding was that multiple core Rust members were employed by Mozilla.
I'm not 100% on this... but, I think if you are compiling the project as a dependency to another project then the lib will build with the parent project's settings. That said, if you are compiling just the project, having a '.cargo' folder in the same location as cargo.toml, then a 'config' file inside there should do the trick. [Here](https://doc.rust-lang.org/cargo/reference/config.html) is the doc page for cargo config which has a pretty good reference example (in my opinion). If you want to post or PM me more specific details, I can try to help more.
Making them default features means they might as well not exist, because they're additive. Every single crate in your dependency tree would have to disable default features for you to be able to disable them?
Hi! Sorry I'm replying so late as well. I went to the project's repo, but I didn't see a dev branch, so I can't look at it. I'm going to make an issue on your repo as well to track it better there :)
Mozilla IRC is shutting down, so there won't be official rust channels on IRC any more. There is #rust on FreeNode that is used by pretty much the same people.
&gt; tokio::spawn(async fn{...}) fails with the error "the trait futures::Future is not implemented for `fn() -&gt; impl futures::Future {...}" The problem is that you are not actually calling an async function, you are declaring an async function and trying to treat the function pointer as a future. What you intended to do is probably this: ```rust async fn foo() { /* do async work */ } fn main() { tokio::spawn(foo()); } ``` Now, this is not super interesting since it will immediately exit. What you can do instead is setup your own `Runtime` and use `block_on`: ```rust async fn foo() -&gt; u32 { /* do async work */ 42 } fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; { let mut rt = Runtime::new()?; let output = rt.block_on(foo()); // Outputs: 42 println!("{}", output); } ``` If you want to run multiple futures, you can join them: ```rust async fn foo() -&gt; u32 { /* do async work */ 1 } async fn bar() -&gt; u32 { /* do async work */ 1 } fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; { let mut rt = Runtime::new()?; let (a, b) = rt.block_on(futures::future::join(foo(), bar())); // Outputs: 1, 2 println!("{}, {}", a, b); } ``` If you want to use `tokio::spawn`, there are a couple of things you need to keep in mind: * Their output has to be `()`. * They must be `'static`, so you can't run an async function that takes a borrowed value, for example. * They must be `Send` because they are run on a threadpool and must be sent across threads. This is a bit tricky to wrap your head around, but anything that lives across an `.await` has to be `Send`. This is typical for things like lock guards. * `tokio::spawn` doesn't wait for a future to complete. It immediately returns. The future is run on "some other thread".
Is this based on [this paper](https://arxiv.org/pdf/1704.00605.pdf)?
&gt;Why would you want C++ interoperability? I'm not sure exactly what the authors of this Microsoft blog post have in mind, but there are various reasons. * You might need to use a C++ library (without C bindings). You'd have to write your own C bindings, just to call those bindings from Rust. * Or you want add some Rust to an existing code base. If it's C, you can call the C code fairly easily from Rust, and define C ABI functions in Rust; much harder in C++. * Or perhaps you want to rewrite a C++ library in Rust, but still have a C++ API; if it were C, you could do that without including any C code in your library other than headers, but with C++ you would need to have Rust code define a C ABI, then write a C++ wrapper using those functions. All of this *can* be done without any additional interoperability by using a C ABI in both C++ and Rust, but it makes everything more complicated. Enough that individuals and companies dealing with this might find it much easier to just stick with C++, rather than try using Rust.
I actually just saw you've published it to crates.io. I'll try and give it a go in my project soon!
&gt; Is it always possible to find a safe interface for an unsafe operation? Or do those usages "bubble up" into the caller code, infecting it with more unsafe directives? Properly audited `unsafe` blocks should never, ever, leak unsafety. `unsafe` annotations on functions are there for when you want to bubble unsafety upwards, the blocks are there to say "nothing to see here, don't worry, now it's safe". I'd say what they want is, to a first approximation, a tool that looks at the transitive dependency graph grabs out all the unsafe blocks and schedules them for audit, and for re-audit should things change.
As an earlier post mentioned they're already adding UTF-8 support to the Win32 APIs as a codepage that works with the old ASCII (\*A) versions of the APIs: [https://docs.microsoft.com/en-us/windows/uwp/design/globalizing/use-utf8-code-page](https://docs.microsoft.com/en-us/windows/uwp/design/globalizing/use-utf8-code-page)
I haven't read the paper but it's based on http://0x80.pl/notesen/2016-01-12-sse-base64-encoding.html and the corresponding decoding page of that site. Since the co-author of the paper is the author of the site I'm guessing there's some significant overlap.
Clion or IntelliJ for Rust development? I’m pretty comfortable with Clion, but Jetbrains IDEs are usually pretty similar in terms of structure. Which has better support?
You can already use COM APIs with Rust, in fact I just submitted (and tested) a PR to the Rust WinRT support library that tries to improve interoperability with classic COM: [https://github.com/Boddlnagg/winrt-rust/pull/1](https://github.com/Boddlnagg/winrt-rust/pull/1)
1. This will give wrong results on big endian machines, since the `idx ^ 0b0011` trick is to read big-endian bytes from a little-endian bytestream. 2. Unfortunately, `cortex_crc_sized` has undefined behavior if T has any padding bytes. In general, you can't really expose a generic api like this safely. If you want to do so, it should be an `unsafe fn`. 3. Additionally, you can get cortex_crc_sized to read out of bounds memory, if you pass it something where the length in bytes is not a multiple of 4. e.g. `cortex_crc_sized(&amp;[1u8])` will read past the end of of memory. Honestly, you should probably just have a version that takes &amp;[u8], and leave any casting up to the caller. Such a version wouldn't need unsafe either, it could be something like: ``` pub fn cortex_crc(src: &amp;[u8]) -&gt; u32 { assert_eq!(src.len() % 4, 0); // I guess let mut crc: u32 = 0xffff_ffff; for idx in 0..src.len() { let elem = if cfg!(target_endian = "little") { src[idx ^ 0b11] } else { src[idx] }; crc = (crc &lt;&lt; 8) ^ CRC_TABLE[((crc &gt;&gt; 24) as u8 ^ elem) as usize]; } crc } ``` 4. Requiring that your library link against a C implementation of the same function you just use for testing is unfortunate. You should probably not require this and just hard-code the values you test against in the tests.
One reason for the change from C++/CX to C++/WinRT was that the metaprogramming capabilities of the C++ language got more powerful in the five or so years between them. Rust has a pretty powerful macro system and, IMO, so far the Rust WinRT projection does a pretty nice job for the features it supports using code generation and macros, thanks to Patrick Reisert's great work. I'm a little worried about some of the features still left to support, especially inheritance, but we'll see. &amp;#x200B; But overall I think what's missing for an ideal Rust/WinRT (or Rust/xlang - the nascent cross-platform analog) developer experience is mostly on the WinRT (or xlang) ABI side - to my understanding, its metadata currently doesn't have any standard way of expressing non-nullable references or immutability, which limits how much of the benefit of Rust you get when making extensive use of autogenerated WinRT bindings. However, I think this could be corrected with new metadata features and tooling, and if they want to incrementally adopt Rust I think it should be.
In my view, libcurl handles more edge cases and real-world quirks of the web, so cHTTP ought to "just work" more consistently, even when talking to web servers with odd behaviors. In the same vein, it is very well tested and the chances of you running into an unknown bug is pretty unlikely. cHTTP itself is only 0.5, but libcurl does most of the work, so you're effectively using a very stable HTTP client.
You’re making a decision either way. What is most probable, and what is most useful? For one can reasonably argue also that if the features are *not* default, they might as well not exist. I suppose an argument could be made for “unsafe” being a negative, and thus having an additive feature `safe` (or if you really wanted, the double negative `no-unsafe`). But that only works if the feature only changes an implementation technique, not if it adds public members. I should mention something I neglected to mention: sometimes this `unsafe` feature may actually gate new functionality. For example, a crate dealing in some form of type conversion might implement a safe conversion which could be done in terms of something from std, or use some invariant in itself to perform the check itself more efficiently than the underlying std interface can, and then use an unsafe unchecked conversion. With the hypothetical `unsafe` feature enabled, this unchecked conversion method might be made public, as well as the normal conversion method switching to using it.
I think with some config to auto-disable AVX2 on platforms that don’t support it it should work. Maybe this is a feature request?
Wrong sub, you're looking for r/playrust
I suppose the usual way is to make stuff that isn't supported optional via opt-in feature flags in cargo.toml?
There's no "official" definition of AOT compilation, and plenty of people use it in the same way you do. It's just one of these things where everybody thinks _their_ definition is the correct one.
Jason Turner had a great presentation at CppCon 2016 called [Rich Code for Tiny Computers: A Simple Commodore 64 Game in C++17](https://www.youtube.com/watch?v=zBkNBP00wJE). The C64 used a slightly more advanced successor of the 6502 CPU, but the difference for this use case is negligible. &amp;#x200B; The way it worked is that he emitted x86 assembly (utilizing zero-cost abstractions of the language to assure the output would be as compact as possible) and then translated the assembly using his own [x86-to-6502](https://github.com/lefticus/x86-to-6502) tool. The tool comes with its set of caveats and limitations, but it might be good enough for you to explore the possibilities of writing demos using a high-level language.
CLion for its debugging support, assuming cost isn't an issue or if you have the student deal. Other than that, the experience will be essentially the same.
Thanks! I just added indicatorif to it, the one that's almost in production doesn't use it yet. On my laptop it is still waiting for data from the device, but I guess on the Pi it might be a problem. We do a lot more than 500 iterations, those 500 are only to skip over current fluctuations right after startup.
They stopped supporting Managed C++, AFAIK C++/CLI is not going anywhere. And it is able to provide a type-safe integration of C++ libraries into .NET code and vice versa.
This!
cool thanks.
Except in CLion... Which would be the most useful IMO =/
Clang at least used to do this as well.
No, it's not.
i forgot managed c++ was a thing. now I'm curious as to if there have been any updates.
Then something like `allow-unsafe-in` would be nice to have in the project `Cargo.toml`. This way one would have to whitelist all usages of `unsafe` for the whole dependency tree and someone reading the code could quickly look the `unsafe` usage up.
I like rust but the article seems to be going down a strange track. Sure, C/C++ can't guarantee the safety of external code, but neither can rust. Interacting with anything external to your application or library requires the use of unsafe blocks. Even in your applications, you're reliant on massive swathes of unsafe code in the form of the standard library. Rust is an improvement, it isn't perfect.
Yeah. Though it seems to me that the borrow checker can often be leveraged to prevent some classes of bugs. It also seems to me that the true major risk lies in custom implementations of Future, which are very difficult to get right, unless you are quite experienced with the exact semantics of the Waker pattern. So by composing existing, generic futures, we should be alright.
Calling C++ insecure compared to JavaScript.... Anyway, it's cool that you're gaining momentum. I'd push the performance point of view too, rust has the potential to be as fast as C, and it's great for server workloads.
Great, comprehensive post. Thanks!
Well, a few days ago i tried to install it (rustup as recommended) and asked for the C++ Build from MS, i dont want to do it because they are huge in size and Visual C++ is not as good as other compilers, it is there a work around? &amp;#x200B; Thanks for your time
Rust requires the msvc linker if you want to use the msvc-style toolchain. There's also a gnu style toolchain (`{i686,x86_64}-pc-windows-gnu`) but that requires mingw to be installed and available instead. Either way you need one or other of the toolchains available in order for Rust to link your code.
It's awesome at what pace new features are done for that plugin. Great work!
Recently I came to know about Sonic and Toshi, which are alternative to elastic search. Has anyone used it and how's there experience. I am a bit confused, are there also an alternative to Logstash and Kibana in Rust that can be used with Sonic/Toshi?
Ok, thanks, i has a proper toolchain setup and working but i saw the warning and let it be for the moment
I don't think the article presents unsafe as a *blocker* at all, simply that is an issue that they haven't settled on a solution for yet. I presume that the problem they are describing is not a technical one but more of an internal management/process one.
It seems the homepage doesn't explain what problem IntelliJ-RON solves, only how to use it. Can you shed some light on this?
That seems neither realistic nor desirable. For one, you introduce the requirement that users have an optimizing compiler installed on their system. This might be feasible on modern Android phones - certainly not on less capable devices. Rust (and C, and C++) code is written with the expectation of having extremely good optimizers available that can basically do infinite analysis in release builds. ART does not do that (and doesn't need to). Many of these local compilers/optimizers will be on different versions, meaning you cannot expect to be able to transfer core dumps between machines. Forget about distributing binaries without debug info and then debug core dumps using debug info stored in your CI infrastructure. Is the crash caused by your code, or due to the user using an older version of the codegen that contains an optimizer bug? Lastly, Rust code very often contains `#[cfg(...)]` attributes to do conditional compilation based on the target. If you are using platform-specific functions from the `libc` or `win32` crates, the compiler would have to always compile the whole module for all possible outcomes of each condition, and distribute those in your proposed platform-agnostic IR. You can probably write a Rust compiler that targets the ART, if you want. You can also use WebAssembly to achieve much of what you are proposing. It comes with significant drawbacks, though.
You probably would have more answers by making a new thread.
&gt; Recently I came to know about Sonic and Toshi, which are alternative to elastic search. Has anyone used it and how's there experience. I am a bit confused, are there also an alternative to Logstash and Kibana in Rust that can be used with Sonic/Toshi? Thanks! I will create a new thread
I think a large part of the "precise memory manipulation code" that exists in the wild exhibits undefined behavior. Having that power is similar to having the power of washing the windows of a skyscraper with no safety harness.
Given a trait `Foo`: use std::fmt; trait Foo {} why does implementing `Display` for `Foo` like this compile: // Version 1 impl fmt::Display for Foo { fn fmt(&amp;self, _f: &amp;mut fmt::Formatter) -&gt; fmt::Result { unimplemented!() } } when this doesn't compile: // Version 2 impl&lt;T: Foo&gt; fmt::Display for T { fn fmt(&amp;self, _f: &amp;mut fmt::Formatter) -&gt; fmt::Result { unimplemented!() } } // Playground like and compiler error down below How are the two versions different? I vaguely understand that the 2nd version has something to do with the orphan rule. Possibly related question: Is version 1 using dynamic dispatch? The type of `&amp;self` is `&amp;Foo` which afaict, is the same as `&amp;dyn Foo`. Is that how/why it's different? --- Playground: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d23a8304b4ccfa051a6e3d772ce4e0a0 Compiler error pasted: Compiling playground v0.0.1 (/playground) error[E0119]: conflicting implementations of trait `std::fmt::Display` for type `&amp;_`: --&gt; src/lib.rs:4:1 | 4 | impl&lt;T: Foo&gt; fmt::Display for T { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | = note: conflicting implementation in crate `core`: - impl&lt;T&gt; std::fmt::Display for &amp;T where T: std::fmt::Display, T: ?Sized; = note: downstream crates may implement trait `Foo` for type `&amp;_` error[E0210]: type parameter `T` must be used as the type parameter for some local type (e.g., `MyStruct&lt;T&gt;`) --&gt; src/lib.rs:4:1 | 4 | impl&lt;T: Foo&gt; fmt::Display for T { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ type parameter `T` must be used as the type parameter for some local type | = note: only traits defined in the current crate can be implemented for a type parameter error: aborting due to 2 previous errors Some errors have detailed explanations: E0119, E0210. For more information about an error, try `rustc --explain E0119`. error: Could not compile `playground`.
You sound like a proper UB generator.
I think the OP downvoted both of us :-).
Same I thought ;)
Mind sharing examples that you find elegant in C, and are there cases you are curious if possible in Rust?
I didn't downvote this because I don't understand what UB generator means.
From my memory the C++ rants was specifically for things that are mostly fixed in rust (mainly automatic complex castings, exceptions unwinding, global state clean up after exception). But there's le little portability thingy
Well, I think you might appreciate pure assembly even more :-)
Yes but as I read it not from the individual developer standpoint but rather as the company/team doing a review of the work and accepting specific usages or not and more importantly how can you **objectively** determine that. Hence the word regulate being thrown in there.
You can find the pieces, but you will need to work to get them do what you want and to combine them, and it still be very far from usability of existing solution. There is https://github.com/jedisct1/flowgger which may replace logstash. I don't know if there is anything like Kibana.
&gt;[http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html)
&gt; Is version 1 using dynamic dispatch? yes. nightly even produces a warning: warning: trait objects without an explicit `dyn` are deprecated --&gt; src/lib.rs:5:23 | 5 | impl fmt::Display for Foo { | ^^^ help: use `dyn`: `dyn Foo` | = note: #[warn(bare_trait_objects)] on by default
Thanks for the suggestion. Looks like I have to put some effort into joining these pieces :D
Thanks, now I upvoted.
Once you'd had a year or so with Rust you'd have a hard time going back to C. The miracle of having your C-like code's errors caught at compile time is just so amazing. Not having to explicitly free anything, while still getting efficient predictable memory management, is really nice. Having and building APIs that are hard to misuse because their usage is precisely specified is great. Writing code that always has the same precise meaning across platforms is fantastic. You can *read* about these things, and I can *tell* you about these things, but it's just not the same as experiencing them. Rust looks like handcuffs when you read about it. C feels like a tightrope once you've worked with Rust enough to get comfortable with the language. I still write C sometimes, but it feels like I'm slumming every time.
I agreed with what you said. Upvoted.
Dangit. I knew that was coming, but I was hoping it was farther away. Time to go back and noise up all my old code with meaningless `dyn` keywords. :-( :-( Thanks for the PSA!
I used to think that about pointers, but am now convinced otherwise. This is relevant reading: https://www.ralfj.de/blog/2018/07/24/pointers-and-bytes.html One key point for me was: it appears that we are manipulating memory directly via pointers, but that hasn't been entirely true for the last 20 years. There are levels of abstraction both during compilation and runtime which matters.
Cool, supervisor framework is very usefule, added bastion to my annotated list [https://frehberg.com/2019/06/rust-crates-frehbergs-annotated-catalogue/](https://frehberg.com/2019/06/rust-crates-frehbergs-annotated-catalogue/)
That would be [RFC 2476](https://github.com/rust-lang/rfcs/pull/2476).
I also have upvoted yours since I agreed with what you said about the SQL.
I also have upvoted yours since I agreed with what you said about the SQL.
One of. /u/Manishearth started clippy. I had a lint crate of my own and decided to join forces with Manish after learning of the project, doubling the number of lints and continuing to write many more. I actually took a step back from developing on clippy a while ago because other projects are taking up my time. I will still join in every now and then.
True, but this is not rust specific.
The C pointer _is_ elegant. So are two halves of a prompt critical sphere of plutonium. Arguably only a very small number of highly trained people _should_ handle either, and there’s a high probability anyone who _wants_ to should not be numbered among them. The odds are if you’re using pointers perfectly correctly you’re either a) duplicating boilerplate work Rust does for you, or b) doing something that _should_ be inside a visibly and obviously isolated `unsafe` block of code, ideally with compiler checks that at least provide _some_ resistance to your urge to slap those hemispheres together. Rust isn’t training wheels, it’s a containment vessel and some minimal failsafes.
These terms all get thrown around without people remembering that they are making a few important trade-offs. async has a lot of subtle ones and it's honestly sort of frustrating for me to look at most people's rust code that is needlessly obfuscated by poor tokio ergonomics etc... and actually detrimental to their desired workload characteristics, while they think they are sprinkling performance dust on their code. &amp;#x200B; Context switching really only serves to limit throughput when your cpu is being saturated by associated cache refilling latency to recover from TLB flushes etc... Unless you're building a load balancer serving "many" new connections per second without much associated CPU spending per client it's unlikely to be an issue that can be solved with scheduling tricks and may just need more hardware. Other workloads are less likely to come out much ahead on throughput because the ratio of work they are doing that actually needs time processing data on a core vs time spent recovering from cache pollution and TLB flushes is much more skewed toward costs that can not be reduced through avoiding context switches, and there are cpu costs associated with async scheduling and threadpool-related work distribution that might significantly reduce throughput compared to just using threads in a way that doesn't increase the ratio of work done scheduling to work done in userspace processing too much. &amp;#x200B; Async is primarily a latency concern for most workloads, as it might allow for a few requests to piggyback on each other's kernel scheduler core allocation. It reduces the granularity of scheduling decisions by trading some CPU work (and lots of $$$$ human work, but in mid-August this will be significantly better) for multiplexing requests. &amp;#x200B; Please, before you tell anyone to use async for performance, ask about: * latency vs throughput requirements * human time budget available * async pushes scheduling complexity onto humans and will slow your project's development time down to the extent that it imposes friction on engineers to fight tokio etc... * how much cpu is actually being used by processing each request * if this is dwarfs the latency hit of context switching, async is not likely to help * how often is a request-processing thread interrupted by another one before it hits blocking code? * if that number is not very high, async is not going to help
&gt;Traits in structs You already can, you just can't use non auto-trait in type alias and the impl syntax =) struct Test&lt;T: Display + Sized&gt; { field: T, }
I do not think that this gonna happen as it hides fact that `impl Trait` is a generic a little too much.
It's architectural. For example, I plan to write my own alternative to Goblin for distinguishing and extracting metadata from PE, LE, NE, and MZ-format EXE files. My rationale is that I've already had to report one "panics on untrusted input" bug in it, I wouldn't presume to demand that the author of goblin remove all `unsafe` and redesign it to ensure that untrusted input categorically *cannot* cause a panic, and I need so little of what goblin does that it's far more time-efficient for *me* to write something from scratch than to contribute to goblin and then play guard-dog on the codebase to ensure that nothing I patched away creeps back in to whatever version my codebase is depending on.
yes, that would be nice, but this crate also brings some instant benefits when implementing trees: you don't have to do the boring parts, it just provides them. Its a bit like Iterator in that way.
This assumes that I know the type of the field at creation of the struct.
There is an [accepted RFC](https://github.com/rust-lang/rfcs/pull/2071) that allows doing something close to it, which you can try out on nightly right now: #![feature(existential_type)] use std::fmt::Display; existential type Bar: Display; struct Foo { bar: Bar, } fn bar() -&gt; Bar { 42 } fn main() { let foo = Foo { bar: bar() }; println!("{}", foo.bar); }
Thanks! This looks exactly like the pattern I was looking for
What you said sounded like what an insurance sales person would say. But I agree if I stand on your point.
Atomically updating submodules is hard and annoying and is a pretty big burden that applies to anyone who wants to make nontrivial rustc contributions. This was deemed to be an undue burden on people wanting to contribute to rustc, something which is already hard enough to contribute to. On the other hand, the same kind of effect does not apply to Clippy having to keep up: only the maintainers of clippy have to worry about it. We have proposed disallowing toolstate breakage and instead turfing over clippy-fail PRs to the Clippy maintainers to patch up and finish, but this is also considered to be an issue because it lengthens the delay in landing things by a lot of time, and rustc already has PR queue problems. Ultimately it's _not much work_ for us to keep up with rustc, and our tooling is good enough to make most rustups straightforward. On the other hand, any kind of lockstep system impacts _everyone working on rustc_ (not just maintainers). Of course this is a matter of shifting costs around, but costs can be dealt with more efficiently by some as opposed to others. Clippy is slowly moving towards a more stable architecture, but it's not high priority and will take time. The breakage of nightlies isn't considered that big a deal -- people rarely need the exact latest nightly, just something recent. We do hope to improve rustup's experience around this, and have been discussing things around it. This has been discussed over and over again at this point, I don't think anything new will come out of relitigating it.
this is also relevant (linked from the first): https://www.ralfj.de/blog/2019/07/14/uninit.html
Wait, since when the type of an impl Trait can be unknown? Last time I checked it's just used to not write the type (like Iterator when there is 6 struct one in another), but you could if you wanted to. [playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b8e86efd94ae4bfca3231f57fb069cd6)
I’d say it sounded more like what someone trying to sell a containment vessel and failsafes would say to someone who has just asked if they can fool around with several kilos of weapons-grade plutonium, but sure, insurance is a good analogy too, assuming the person being sold to is very obviously trying to engage in highly risky if not entirely foolhardy behavior. The key point of memory safety, really, is to provide a measure of protection to your employer’s future earnings from your current level of competency having been unfortunately overrated, so yeah it’s a form of insurance.
&gt; Setting up a separate fake db just to run tests seems like an overkill. That's the only way to do it. Databases are way to complex to mock them. If your usecase is really simple, create a wrapper and mock that.
Well for the daemon part there is [https://crates.io/crates/daemonize](https://crates.io/crates/daemonize) but I perosnally found it unwieldly much code for such a simple task and just implemented it myself, cf. [https://github.com/yasammez/zoo/blob/master/src/daemon.rs](https://github.com/yasammez/zoo/blob/master/src/daemon.rs). As for the listening part I just created a Unix domain socket and spawned a thread for each connection to handle it. If you want something more async-and-fancy I'd probably look into [https://crates.io/crates/runtime](https://crates.io/crates/runtime) which handles all the tokio-shenanigans under the hood for you if you don't need much.
r/unexpectedcodereview
Also, I look at modern processor operation as a form of JIT compilation. Reordering, caching, branch prediction are things that _could_ be done at compiler time. So even if you do AOT, there's always (except on microcontrollers, etc.) another stage of optimization going on, albeit limited.
Well according to the issues when they have down time, Amazon is bash driven, so they are probably the Antirust.
Good news here, I have finished serialization support of NBT array types. Check this example out: https://github.com/luojia65/coruscant/blob/master/coruscant-nbt/examples/nbt-array.rs I need to do something with deserialization part now. Although I did wrote a deserialize library for NBT years ago without serde, I am somehow a newbie on this part with serde adapted. Have you tried out how to write for deserialize formats using serde?
See: [https://www.reddit.com/r/rust/comments/cgqqh5/beginner\_to\_be\_static\_or\_not\_to\_be/](https://www.reddit.com/r/rust/comments/cgqqh5/beginner_to_be_static_or_not_to_be/) This solution got my code to compile, but it doesn't allow the structure to be edited and then "read" back. I'm looking now for a solution that encompass both features, need not be anything like what I've started with.
Sry, I forgot a crucial detail: `lazy_static` https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5a9e8513048fc23b53faf3e1489c1652
Thanks
Microsoft spent a long time trying to adapt C# into a language that would fulfill similar goals to Rust: [http://joeduffyblog.com/2015/11/03/blogging-about-midori/](http://joeduffyblog.com/2015/11/03/blogging-about-midori/) .
This look great offhand; easy to use and a straightforward, Rustic API! I'll keep it in mind for when I next want to embed some level of scriptability into something :)
[Pipelined compilation](https://github.com/rust-lang/rust/issues/60988) is going to improve things a lot.
WinRT allows C++ components to expose APIs that can be used (relatively) idiomatically from C#, with support for some higher-level constructs like parameterized types and async methods. I've been helping with Rust support for WinRT: [https://github.com/contextfree/winrt-rust/](https://github.com/contextfree/winrt-rust/)
I understand how existential types are handy in this situation. Glad to have learned about it and a good use case, thanks.
For, Urdu/Hindi speakers: some of the meetups are streamed Live on facebook. The audio is usually not of bad quality.
Wow, awesome! Thanks
vector.dev for Logstash Kibana is frontend (mostly) so that will be very hard to do in Rust. I don't think anything like that exists yet. Could be a great use case for `yew`&gt;
I will almost certainly never support "safe" and "unsafe" modes in my crates. It'll likely introduce subtle performance bugs and make auditing certain types of code much more difficult. I'd rather focus my energy on getting the `unsafe` code I write correct, instead of trying to provide an escape hatch to avoid it altogether.
It is also possible to generate C code from llvm-ir: https://github.com/JuliaComputing/llvm-cbe
What could be these specific usage domains though? (asking genuinely)
I'm not familiar with winit. Will it accept a closure or do the underlying APIs preclude that? ...because that's the usual reason a Rust API didn't make a provision for user data.
Don't know what u mean, it takes an FnMut. Not sure how that translates into a working solution. Not this is only the alpha winit, the current stable has a poll() function you call to yield. With alpha you pass a FnMut to a run() function that doesn't return until it's time to exit.
How is that possible? Is `Foo` unsized?
&gt; Redux is just a hobby, it won't be big and professional like Linux.
`Foo` remains sized, as is `Bar`. This is because any single existential type must always have the same underlying concrete type (`i32` in this case). It's just the fact it is an i32 is hidden away, and code using Bar can only use it as some type that implements `Display`.
That's crazy. I cannot even imagine all the capacities that this feature allows.
Rough conditions: * The CFP is a blind CFP (first round is anonymous, second non-anonymous) * We guarantee 400EUR (EU) and 800 EUR (non-EU) travel reimbursement, with more if budget allows, plus hotel for you and partner. * To date, we have paid all speakers in full * All topics are interesting, especially also beginners and community experiences. * Topics should be Rust-based, though
&gt;but I haven't seen anywhere where they state their end goal (if there even is one) &amp;#x200B; To replace the Hurd?
&gt; AVX2 is known to lower CPU frequencies considerably for much longer than the AVX2 code actually runs, typically milliseconds. Your benchmarks are generally in the microsecond range. Wouldn't AVX2 be detrimental to performance, unless you're processing really large amounts of base64 data? There are also [different opinions](https://blog.cr.yp.to/20190430-vectorize.html) on that: &gt; What will happen when the most important computations are upgraded to use 512-bit vectors? Unless Intel botched their hardware design, the answer will be a performance win, despite the reduction in clock speed. As this clock-speed reduction increasingly becomes the norm, the supposed harms of upgrading other computations to use 512-bit vectors will disappear, while the performance benefits will remain.
This is the Intellij (Idea, Clion...) Plugin for RON, which is https://github.com/ron-rs/ron
I reported [one of the bugs](https://github.com/intellij-rust/intellij-rust/issues/4117) fixed in this release. I would like to highlight the great work and responsiveness of the developers of this plugin, who fixed the bug the day it was reported. Thank you !
Doesn't this still require Bar be one type, known at compile time? I think OP's goal is to be able to swap out foo.bar with different types that happen to implement the trait.
At the beginning of the video, the equation is `z = z^1 + c`, and then slowly throughout the video, 1 increases, until it hits 3 (`z = z^3 + c`). &amp;#x200B; The actual Mandelbrot set (`z = z^2 + c`) can be seen at the exact middle of the video. &amp;#x200B; If anyone is interested in a 2K 60fps version, pm me
That looks awesome and very interesting. Do you have a public repo I can take a look at?
no, but if you want to look at it, sure, I can create one!
Nice! How long did that take to render, and is the code on GitHub?
Took about 30 minutes if I recall correctly. &amp;#x200B; I will create a repo in a second
Actually I have a few variations of the code: \- For generating a single grayscale image of specified size \- For generating a single RGB image with red-ish borders of specified size \- For generating frames for a video like this I guess I will share the 2nd variation
If it takes an `FnMut`, you can use a closure. Here are several links about closures, so you can read whichever one makes the most sense to you. * [Finding Closure in Rust](https://huonw.github.io/blog/2015/05/finding-closure-in-rust/) * [Understanding Closures in Rust.](https://medium.com/swlh/understanding-closures-in-rust-21f286ed1759) * [When does a closure implement Fn, FnMut and FnOnce?](https://stackoverflow.com/questions/30177395/when-does-a-closure-implement-fn-fnmut-and-fnonce) * [Closures: Magic Functions](https://krishnasannasi.github.io/rust/syntactic/sugar/2019/01/17/Closures-Magic-Functions.html) Here's an excerpt from the top one explaining what closures are: &gt; In a sentence: a closure is a function that can directly use variables from the scope in which it is defined. This is often described as the closure closing over or capturing variables (the captures). Collectively, the variables are called the environment. &gt; &gt; Syntactically, a closure in Rust is an anonymous function0 value defined a little like Ruby, with pipes: |arguments...| body. For example, |a, b| a + b defines a closure that takes two arguments and returns their sum. It’s just like a normal function declaration, with more inference: (Closures are also how a lot of stuff is accomplished in other languages that are capable of them, such as JavaScript or Python.)
It sounds like you might try wrapping the branches in an [Either](https://docs.rs/futures/0.1.28/futures/future/enum.Either.html)
The example looks sweet! I don't really have experience with serde deserialization either, I manually implemented `Deserialize` for a type once but that's it lol. I'll look into it though, I feel like it will at least be less annoying than the serialization haha
That looks interesting. Did not knew about vector.dev, thanks. I will check it out.
Yes, but the issue is about not being able to split a struct to have part of it moved into the function. https://www.reddit.com/r/rust/comments/cgdhzb/newbie_question_how_do_i_avoid_breaking_apart_my/?utm_medium=android_app&amp;utm_source=share I chose to define my function to take a boxed trait, so that state could be self contained. Perhaps that's not necessary or good practice? My issue is ```fn run(self, thing: FnMut)``` doesn't allow thing to reference the object being called here, "self".
Unfortunately, I can't help you there. I haven't yet needed to use Rust for that kind of work and, at the moment, I don't really feel motivated to experiment on it as an intellectual challenge. I was just clarifying *why* the Rust function didn't support user data in the form you'd see more traditionally in C APIs.
That's super nice ! Love the video ! Will look at your code
As leudz says, `impl Trait` wouldn't have done anything that regular generic would do. If you want to be able to construct this, you need to use dynamic dispatch via `dyn` keyword, typically in a `Box`: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=13d3efb7c52168183fed1e2482084e8e
Is there a Super Ferrio Bros in the making? :)
Wouldn't that just be `Box&lt;dyn Trait&gt;`? The idea behind impl is that it's a static type.
&gt; interoperability with existing Microsoft tooling All I want for Christmas is first class Visual Studio support.
How are you finding the book? I've been thinking of getting it.
That's awesome! I really like the "bloom effect" you get at the start. I'm really happy to see this shared. I remember when I got mine at a presentable state, and know the feeling. I feel like I'm reliving that moment :D I actually gave a talk on it at a rust meetup recently. I can DM you a demo with some constructive feedback. I would love to try and help out by giving a code review?
Sometimes people get really attached to a particular set of languages. Part of Rust's selling point is what things it does better than other language (like safety, performance), which naturally means that Rust's existence claims that other languages are *less* safe, *less* performant, etc. If you are really attached to such languages, you can see how one might feel threatened by Rust, which seems to undermine your language of choice. So instead of admitting these things, people sometimes decide to mock it, then it into a meme, and so on in order to diffuse the tension that they don't want to face. This happens with many programming languages, and of course happens in other areas of life as well. Granted, I am not a psychologist.
The same thing happens with every new language that comes down the pipe. You get some adopters who become zealots and spread around Rustjerk material and want to re-write the world, and you get some developers who see a relatively new language making bold claims about it's features, looking at the language skeptically and asking themselves "Why exactly \*is\* this better than C++?" &amp;#x200B; The two groups eventually collide on the internet, and stupidity rises like rendered fat.
They would have no problems finding work elsewhere if they ever want to leave Mozilla.
Sure!
🤔
&gt; ...it seems rather strange to base your judgment of an entire language by referring to the minor group on the farthest left of distribution curve as the sample. That's just human nature, though. Ask someone who's not a feminist what feminism is about, ask someone who's not a conservative what conservatism is about, ask someone who's not a Muslim what Islam is about.
In the year of our lord 2019, amidst approximately three billion vicious online wars for perception and hegemony, you notice that you disagree with opinion X and your move is to go to a high-profile forum and ask, wide-eyed, "why does everybody believe opinion X? It sure seems like everybody has noticed its obvious appeal but me". I'm just floored.
Rust is initially really difficult, especially if you don't care to read up on the borrow checker, so I guess it's partially salt? I gave up and came back 2-3 times before I groked it.
Where can I read more about Amazon being bash driven?
I wrote an answer to this question a while back and I'll repeat it here. &gt;All of this is just my experience and opinion so take it with a pinch of salt. &gt; &gt;Googling Rust questions almost always tends to lead to pseudo-solutions which won't actually work for me because of the approach taken. You see this all the time on /r/rust. How many times have you heard it: "sorry, I do see how that answers my question but I can't do it this way because xyz." &gt; &gt;The Rust community is willing to help, but it definitely feels like a blind leading the blind situation. It's not fun to ask questions and get an answer back and internally be thinking "Thank you for answering, but I'm not sure you understand what you wrote". &gt; &gt;The ownership rules heavily complicate the basic structures. For example `Vec` has a ton of helper functions, and that's nice. But in my experience, unlike say C#, you *have* to memorize almost all of those helper functions because most of them are there to provide safe wrappers for unsafe code which circumvents some ownership paradox. So if the situation comes up for you and you don't know the right function to use, you probably can't compose it from the basic add/remove/get/set -- you have to either find the function or drop down into unsafe code. &gt; &gt;And I think the Rust documentation is just bad. Most of the time it's awkwardly laid out and hard to read. Occasionally it's [gobbledegook](https://doc.rust-lang.org/std/pin/index.html).
I can say firsthand by using Rust and being in this community for years that both are truly great. In fact, that’s probably why some people are hating on it currently. An [article from a couple of years ago](https://www.wired.com/2015/07/how-the-tech-press-forces-a-narrative-on-companies-it-covers) introduced me to the idea of a “narrative clock” - basically a cycle of hype and reaction to this hype. It’s helped me see situations like this in a clearer light. Rust is a fantastic tool and is growing on its own merit - however, great things like winning Most Loved Language on StackOverflow four years in a row, having phenomenal showings in benchmarks, continuing to climb over the years in popularity until its now just barely missing the Red Monk top 20 languages, and seeing increasing adoption in major projects in the industry might lead people who don’t know better to assume it is over-hyped. I don’t think trolling is ever the right thing to do or even excusable, but I do think that’s where it’s coming from. :)
I think part of it is that the 21st century is unique in that it creates a sort almost nihilistic identity crisis in us, and we tend to cling onto things/groups/boxes and sometimes novice programmers may latch onto a certain language/framework/paradigm and build a sort of pseudo-identity around it. It happened to me when I was young and an obsessed metalhead and every other kind of music "sucked", or I'd read Murakami and every other author sucked. Or whatever. It never hurts to learn a new language or tool and see if it fits your use case. At the end of the day, we're all just writing code to make a living, and weird things can happen if we make our life all about code. Or all about one certain thing. Anyway, remember to take the internet not too seriously.
&gt; stupidity rises like rendered fat LOL
AWS is mostly Java.
For the same reason people dislike vegans: because they find them stereotypically preachy and smug, whether that stereotype is really representative or not (usually it isn't).
Reasons real (not internet) people have given me: 1. They tried Rust pre-1.0, and didn't like it, and don't want to try it again. 2. Zealotry of people pushing Rust who have little professional experience. 3. The politics of some of the Rust people (they call them "SJW")
I'm learning Rust and I, uh, solved FizzBuzz 😒
If the only language you're comfortable with is C, Rust's much more complex type system might feel overwhelming at first. If you have any specific questions, feel free to ask. If not, I'd advise you to go back and read the book chapters on traits and structs - they explain everything better than one can in a single Reddit comment.
Well, when Python went popular, people were hating on it because of how different it is structurally. Seeing how Rust is different by design, I'm not surprised to see people hating on it.
&gt; Do we really need clap to take 3 values from a vector? Yes. It takes 3 values, displays help that explains how to use it, and if you pass 2 or 4 values it will provide useful message explaining the issue. Hand-written replacement is unlikely to do any of that as reliably as clap. If one of those parameters was a file program writes to, getting it wrong could lead to users loosing data or getting unexpected results. Also it does in a way that can be consistent between multiple programs, while custom parser will be ... custom. Get things right first, than worry about performance.
You can (and probably should in some use-cases) pass `--release` to `cargo test`.
"Even the possibility of existence fast language that isn't c++ can enrage some c++ programmers." I said that sentence at my job and one of my coworkers went crazy.
Rust is effectively under the custodianship of Mozilla, which is an organisation that slants quite left-wing. The most public facing members of the Rust core team also range from 'left-wing' to 'very left-wing' in stance. As a consequence, the Rust community tends to be pretty progressive / left-wing even by the standards of the tech industry. Sadly some people (mostly /g/ dwellers) are turned off by this.
The fact someone who isn't that into coding but wanted to build something ended up at Rust is fascinating. Those who are already software developers but want something with more guarantees it makes sense, but it is so easy to just go to the standards like C++ or Python or Java when you decide to learn to code. Very curious to see where this goes.
My specific question is that do I need previous knowledge about these concepts, or will the book explain them from scratch eventually?
I don't see anything that would prevent it from being used with WASM. If compiling for a target other than x86-64 it will remove all the avx2 optimizations but still leave you with a pretty optimal scalar implementation. That said I would expect the browser based implementation to be pretty good as well. My guess is that if you're already in rust code using WASM then calling this would be better than going back out to js and having the browser encode, but if you're in js then I imagine there would be enough overhead that you're better off using the browser implementation.
Really cool!
Is there any (documented) reason why rustdoc would omit explicit trait bounds from documentation? The [documentation for `Iterator::all`](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.all) indicates that the only bound is `F: FnMut(Self::Item) -&gt; bool`, but [the implementation of `Iterator::all` also requires `Self: Sized`](https://doc.rust-lang.org/1.30.0/src/core/iter/iterator.rs.html#1724): fn any&lt;F&gt;(&amp;mut self, mut f: F) -&gt; bool where Self: Sized, F: FnMut(Self::Item) -&gt; bool { ... } Not a single method on `Iterator` is documented as requiring `Self: Sized`, but virtually every method has this explicit bound. Only three methods do not: [`next`](https://doc.rust-lang.org/1.30.0/src/core/iter/iterator.rs.html#77), [`fn size_hint`](https://doc.rust-lang.org/1.30.0/src/core/iter/iterator.rs.html#149), [`nth`](https://doc.rust-lang.org/1.30.0/src/core/iter/iterator.rs.html#263)). What gives!?
The book does not assume you come from any particular background or have any particular knowledge, other than vague programming experience.
&gt;Rust is effectively under the custodianship of Mozilla This is not true; the only control Mozilla has over Rust is the ownership of the trademark for the name and logo.
I'll continue working on my Gameboy emulator ( [https://github.com/douglascorrea/gbrustemu](https://github.com/douglascorrea/gbrustemu) ), I'm building it from scratch during streaming sessions on Twitch. The nice thing here is that as I'm still learning Rust and this is my first Emulator ever, the streamings tends to be slow and be explaining (to myself) how things are being built. I'm doing it daily, which is even better to keep me doing Rust code every day even not working with it professionally yet.
Please file bugs for docs you think are bad. I don't have as much time as I used to, but we can't fix things we don't know about.
I have actually found it beneficial to myself in maintenance: it gives me two implementations to easily compare; the simple, safe one (in the sorts of cases I have in mind, a lot shorter to write), and the more complex, more dangerous, higher-performance one. Let me give a detailed example. A few months ago I wrote something to perform context-aware minimal escaping of HTML (e.g. for attribute values: leave `foobar` alone (it doesn’t need quoting or escaping), turn `foo'bar` into `"foo'bar"`, `foo"bar` into `'foo"bar'`, and `foo&amp;'"bar` into `"foo&amp;amp;'&amp;quot;bar"`), in as efficient a way as I know how. It takes a `Cow&lt;str&gt;`. Once it’s taken one pass through and decided that it does need to perform replacement (worthwhile, since the most common case is a borrowed string that doesn’t need escaping or quoting), the guts of the transformation is a one-liner for the safe version (`out.replace("&amp;", "&amp;amp;").replace($match2 as char, $replacement2).into()`), and 76 lines for the unsafe in-place-replacement version (which is faster, needing only a single pass and at most one allocation). For myself I’m always going to prefer to run the unsafe version because it’s faster, but I’m glad that the safe version is there, for code maintenance purposes, quite apart from having an answer for that strange breed of people that are allergic to unsafe code. (Another interesting side note: I will want to run all of this code in WASM eventually, and imagine that the safe version will yield smaller WASM; but then, when caring about size, I may well decide to cut most of the fancier context-aware minimal escaping. But again you see how there can be cause for different implementations for different situations.) Yes, I still wrote suitable test cases!
Probably related (I don't speak HTTP too well): https://github.com/SergioBenitez/Rocket/issues/106.
&gt; it seems rather strange to base your judgment of an entire language by referring to the minor group on the farthest left of distribution curve as the sample. It may be an extremely small number of people doing this but it is visible and noticeable and it really turns people off. I don't think these people, for the most part, care for the language, use cases or anything else, they simply care about validating their own feelings for whichever bandwagon they decided to jump on. True for everything that starts becoming popular, just human nature.
Because relying on emotions is easy, while thinking is hard. That’s how our brains are wired and it takes effort to overcome it. On top of that, I don’t know of a single country who’d properly educate their population on the scientific method and ideology, which basically teaches you to use logical reasoning and to avoid common cognitive distortion pitfalls.
&gt;This is because any single existential type must always have the same underlying concrete type (i32 in this case). I added the following to your example to see how it would fail: ``` fn baz() -&gt; Bar { 42_u32 } ``` Compiler output: ``` error: concrete type differs from previous defining existential type use | 15 | / fn baz() -&gt; Bar { 16 | | 42_u32 17 | | } | |_^ expected `i32`, got `u32` | note: previous use here --&gt; src/main.rs:11:1 | 11 | / fn bar() -&gt; Bar { 12 | | 42 13 | | } | |_^ ``` Admittedly, the compiler message is really good, but I'm having a hard time understanding the point. If an existential type can only have a single underlying concrete type, why bother with an existential type at all? Why not just put an i32 in your struct and call it a day? It feels like it's giving the impression that your struct is generic, when it isn't.
Of course Rust can! Not mentioning ffi necessarily. The point is if anyone can claim they write safe c code, they cannot claim anthing when their code is used as a c lib, in somebody's else c code.
I think a lot of C/C++ developers initially get frustrated using Rust because of the borrow checker. I think people coming to Rust from higher level languages receive it better, but often Rust isn't the right tool for that kind of work. Even when you get into memory management and the like I think learning it for the first time with Rust may be better than learning it in C then realising Rust doesn't allow you to do half the stuff C lets you do without kinda verbose unsafe code.
Overhead from js to WASM is quite minimal now afaik, nothing significant for a single call at least. I know overhead used to be bad, there was a big blog post about all the optimizations to bring that down.
So I see this answer is at the top. Just for the record, I think this answer is complete nonsense. The idea that my dislike of Rust comes from feeling threatened that it undermines C# or whatever? No. It's ridiculous.
I'd say it's probably the best background to have.
This short post was a food-for-thought kind of posts. If you go through John Reghre's youtube talk, you should get the details you want.
The book should have explained them from scratch by the point that you're at.
It's this kind of attitude that sucks and turns people off, because you're not being a proponent for something but you're putting people down. You have effectively just lumped everyone who doesn't like Rust as emotional instead of a thinker, who hasn't been educated right and can't avoid "common cognitive distortion pitfalls". I am not sure if that was your intention, but that's what it comes off as smug, patronizing and condescending.
where is hate of a tech there is an ignorance...
So where does your dislike of Rust come from?
The RFC itself gives a couple of uses for existential types. Basically, they are useful for dealing with concrete types with very long and complex signatures (e.g. Iterators) or unnamable types (e.g. closures). Existential types may also be useful for library authors who want to limit what users can do with exported types. For example, if a part of a library's API is an existential type, then the library author will be able to change the underlying concrete type without it being a breaking change.
Isn't this just higher kinded types in disguise? I'm that case, you will have to wait for generic associated types.
“It is difficult to get a man to understand something, when his salary depends on his not understanding it.”
I would probably use `.map()` for the success and `.map_err()` for the failure. You can just return a value inside the closure and it will be coerced into the proper future type. I might be able to pull your repo later and come up with a full solution.
This is weird, the [core version](https://doc.rust-lang.org/core/iter/trait.Iterator.html#method.all) does display the bound. The re-export must be the issue.
How many Rust core team members are Mozilla employees, though?
1. the core team does not make the vast majority of the decisions about the language 2. three out of nine members, total
That's good to know. I haven't played around with WASM yet. I'm definitely open to making radix64 compatible with WASM if it isn't already. If you give it a try and run into any problems feel free to open an issue in GitHub.
Especially something that sounds like it would work great as a web app. Find some Medium article that describes a Webpack/Express/Vue/some-other-thing starting point and half of the work is already done for you.