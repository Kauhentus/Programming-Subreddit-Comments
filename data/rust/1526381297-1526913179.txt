have you seen [pnet](https://crates.io/crates/pnet)?
It's very nice. thanks!
What? That's a totally different package.
Yeah i realise that. It has an impossible to remember name though, yours is somewhat better!
There are a huge number of people working on Rust, and absolutely no reason it can't be developed in multiple areas at once.
uom =&gt; **u**nits **o**f **m**easurement, it's pretty easy.
I recently \(yesterday\) started working on a tool for developers called [mock](https://github.com/inferiormartin/mock). It's an application for easily creating mockup REST APIs that you can test against. I have other Rust projects but none of them are actively developed on or popular at all. 
[removed]
I wouldn't consider myself a beginner. But I absolutely love your videos. Some of the info in your videos makes me look at the things I already know in a different perspective. And that's mighty good. Good work. üëç
&lt;unix nerd mode&gt; Just a little note: catting a file to `dotify` qualify as a "Useless use of cat". You can feed the file right into dotify like this: `dotfiy &lt; src/main.rs`, `dotify --bytes &lt; braille.txt`. &lt;/unix nerd mode&gt; ;)
I second this. I would appreciate some tutorial/guide that would show me how they are actually used in practice. However, for theory, to help you understand the model, I can recommend you read the following: - to understand Futures, which are the underlying model: read [the original blog post](http://aturon.github.io/blog/2016/08/11/futures/) - to understand how futures are currently used, without async/await syntax, read [the tokio docs](https://tokio.rs/docs/getting-started/hello-world/) - async/await is syntax sugar over futures that allows you to write code in the usual idiomatic Rust style; I don't know if there is any good resource yet to showcase it, but have a look at [the RFC for the new syntax](https://github.com/rust-lang/rfcs/pull/2394) as well as the examples in [this github repo](https://github.com/alexcrichton/futures-await), which was the original prototype implementation using macros (they will be official language keywords in the final implementation now, but the idea is the same). - to understand the mechanics behind how async/await works, read all posts titled async/await in [this blog series](https://boats.gitlab.io/blog/)
What's the difference between trait Foo&lt;Input,Output&gt; { fn next(&amp;mut self, input: Input) -&gt; Output; } and trait Foo { type Input; type Output; fn next(&amp;mut self, input: Self::Input) -&gt; Self::Output; }
Briefly looking at the code the differences seem to be that `yaiouom` works at the unit level (meter, second, ...) instead of the quantity level (length, time, ...) and requires the `unify` method to normalize units after operations. I'm not sure if `yaiouom` is zero-cost or not.
You can do: impl Foo&lt;A, B&gt; for X { .. } impl Foo&lt;C, D&gt; for X { .. } But you can't do: impl Foo for X { type Input = A; type Output = B; .. } impl Foo for X { type Input = C; type Output = D; .. } This can help the compiler with type inference; no matter what it deduces the type of `&lt;X as Foo&gt;::Output` to be, there can be only one `impl Foo for X`. On the other hand, deducing `U` for `Foo&lt;T, U&gt; for X`, might not help it work out `T`.
Ah...I see. Now I have to think about what I really need. Is there a rule of thumb in what kind of scenarios which approach might suits best?
Congratulations on a stable release of an amazing library! At Faraday, we've been using csv 1.0.0-beta.4 happily for a long time now, and we'll be upgrading to 1.0.0 soon. Your library is fast, robust, and convenient to use. It's also _just_ tolerant enough of the garbage that typically passes for CSV files that we use it as a normalization pass on just about everything we do. I just wanted to say thanks. :-)
the easiest thing to do is just to find an existing target file for the platform you're using and change what you need. what architecture are you porting to? if it's 32-bit arm then most of that should already be correct (or very close).
Still working on [subgit-rs](https://github.com/samsieber/subgit-rs) my server side git hook for republishing a subdirectory of a git repository as it's own. Think git submoudles, except it's fully synced and requires no manual intervention. I've been working on adding tests and figuring out the limits of the libgit2 library. So far I'm up to two spots where I've decided to call git externally. One of those was for convenience, but the other is because libgit2 doesn't support server side hooks (somehow - it was very surprising).
Ok, so a `Calculator` trait might be implemented for `f64` but also for `f32` and `i8` whereas a `BinaryController` trait might have `f64`,`f32`, ... as `Input` but the `Output` is always `bool`. Then I'd define it like this: trait Foo&lt;Input&gt; { type Output; fn next(&amp;mut self, input: Input) -&gt; Self::Output; } 
How are they handling AVX? I've found `#[cfg(target_feature="avx")]` to be better having an `avx-accel` cargo feature, which is unfortunately what most crates that use SIMD seem to do.
Are all target files a .json? The architecture in question is indeterminate - including 68k, ARM, MIPs, i960, PowerPC, x86, etc, since the OS has to support a lot of stuff. One lucky thing is that I'm supposed to implement a POC to start, so if I can find any one to implement this on, it should be good enough (I'm not sure how much I can legally allowed to disclose, but this should probably be fine?) The closest supported architecture I can find is arm cortex A(15,53,57,7,8,9) so I guess that's somewhere to start. 
I'd vote for "macroflect" as a portmanteau of macro and reflect :)
Well, I don't know what a `BinaryController` would do, but that sounds about right.
yes. all targets are specified in json files like the one you posted. you'll need one per architecture you're supporting. and uh, wow, that's a lot of architectures. out of curiosity, when you say you're "porting rust", do you mean you're setting up cross-compilation or actually porting `rustc`/`std`? either way, x86 or arm are probably the easiest places to get started.
Sorry, it is lowercase WebAssembly.[instantiate](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_objects/WebAssembly)
I love the irony of writing a blog about configuring CI on GitLab and then publishing the source on GitHub.
So it seems to me like the argument comes down to "the explicit generic syntax is harder to learn"? I never found the existing generics syntax to be all that confusing, although that may have to do with my background from other languages. It follows fairly straightforward logic, and seems pretty cohesive. I was never really a fan of having the separate `where` syntax, but keeping the existing simpler one, as the `where` syntax doesn't seem all that more cumbersome. It switches from "I have to learn one syntax for this that lets me do everything" to "I have to learn three syntaxes that have varying degrees of power." I definitely get that rust is a hard language to learn though, and other people's tastes/experiences are probably going to be different from mine, so I accept that `impl Trait` is probably a good teaching tool. However, the period of time between when you start reading the rust book and when you get to generics is a tiny fraction of the total time people spend using rust, so it seems better to not prioritize this small use case over getting actual work done. Making rust easier to learn is a good thing, but the language shouldn't be compromised for that goal. The main problem for me is that we now have three generic syntaxes and have to decide which one to use in a given situation. It seems a lot like `impl Trait` in argument position is pretty much obsolete once you learn about normal generics. Even if it gets used in real code, you still have the problem that transitioning between it and the other two syntaxes is cumbersome, while transitioning between `&lt;T: ...&gt;` and `&lt;T&gt; where ...` is relatively easy. If you later decide that you want any form of dependency between different arguments, you have to make that transformation. This also has still has the issue that you can't use the turbofish syntax with `impl Trait`, which seems like a pretty serious problem since allowing the types to be specified explicitly can make writing some code a lot less cumbersome, and somewhat suggests that the other syntax should be used in all cases when writing real code.
I mean, I'm implementing a POC for this OS, I don't actually need to handle all of the architecture, I can choose any one that's the easiest to work with (that is supported), and show that it works there. Uhh ... we'll see how far I get, but right now I'm starting with setting up cross-compilation (I am very new to this) 
&gt; So it seems to me like the argument comes down to "the explicit generic syntax is harder to learn"? I think the argument is more that the new syntax is more familiar when coming from other languages. &gt; I never found the existing generics syntax to be all that confusing And that's a great example of survivorship bias.
Async / await in Rust is pretty much the same model as used in C#, Python, Javascript, etc. so you can also use resources from those languages to learn the basic concepts, if you find the doc for the Rust version lacking currently. One of your questions has a really quick answer, though. The only points in the program where a context switch can happen are the "await" statements.
Nice. We're not adding new RNGs in this release (excepting HC-128), but thanks for mentioning.
&gt; And that's a great example of surviviorship bias. Fair, but I think the argument still stands that the `impl Trait` syntax is just *not as good* as the alternatives, once people get past the point of understanding how all of them work. Is `impl Trait` in argument position intended to never get used by more experienced users? Honestly, I think that a lot of rust's difficulty comes from the borrow checker rather than the generics system, which is fairly similar to C++, Haskell, or Java. I will admit that this could be surviviorship bias speaking here, but I really don't think it's a good idea to introduce a worse version of existing syntax just because it's closer to other languages.
Now it gives us: WebAssembly.instantiate(...).instance is undefined
 async function getWasm() { if (!cached_wasm) { cached_wasm = await fetch('rust.wasm') .then(res =&gt; res.arrayBuffer()) .then(async buf =&gt; { let mod = await WebAssembly.Instantiate(buf, {}) return mod.instance.exports; }) .catch(e =&gt; console.error(e)) } return cached_wasm; }
Now it says: TypeError: invalid assignment to const `rust_function_name'
what line is that coming from, maybe outside of `getWasm`? Try changing your `const` to a `let` or `var`. 
Changelog diff: https://github.com/rust-lang-nursery/rand/pull/453/files
Yes, they have made it more complicated than necessary, but they are also doing more than the title implies. The first half of the article is about setting up the GitLab runner itself, which mostly you already know if you are using self-hosted GitLab or don't need to know if you are using GitLab.com. The middle part could probably be made easier by using a pre-existing rust Docker image like https://hub.docker.com/_/rust/ instead of building their own image based on Ubuntu. The end is a little more complicated than most CI setups because they are using the CI to generate and publish a Docker image as well. So you're right that this is more complicated than necessary for getting GitLab CI up and running with rust, but they have also documented much more of their workflow than maybe you were expecting.
These are both helpful suggestions, thank you!
I understand the need to share it, but why not share a configuration for GitLab CI on GitLab itself? That way people could also see the actual testing being run and whatnot.
Might do after returning home. Just measured and it showed me two things: First, `NonZero` is still feature-gated *(I'm too fuckin' used to nightly 24/7.)*. Second, just shrinking `Needed` alone is not enough to reduce the size of the whole `IResult` type, as `Err` etc. still require tons of padding bytes, where most of the bloat originates from slices. So... with just that there is no real benefit besides the "correctness" thing.
If each AST node is the sole owner of its own input string, then sure, you can use a `String` there. I played around with lifetime stuff and it looks like you can also use a `&amp;str`, as long as none of the `Rc`s outlive the slice. [Playground example here](https://play.rust-lang.org/?gist=160886c9d76ad551c04054ea97f9337a&amp;version=stable&amp;mode=debug). Aside: I always try to use `&amp;Path` rather than `&amp;str` if these really represent paths. You can turn one into the other "free of charge" with `.as_ref()`, and it helps clarify why this field is here.
I would say it encourages a tree-like (or DAG-like) structure at the macroscopic level of abstraction... a thread stack references some data structures, which might have some nested data structures, noncircularly so you have a clear idea of when to do resource cleanup. However, at the low level of actually designing a data structure? Just do whatever, use a library or maybe some carefully selected unsafe calls. Petgraph, for example, does an excellent job of storing many kinds of graphs. There is still clear ownership and lifetimes at the macro level, across an entire application where it is harder to reason about. Btw, I think there is room for a DI framework library to construct and destroy more heterogenous graphs of objects like services.
NEVERMIND!!! :\) Got it sorted. I was trying to use a const for the inputs/outputs
There‚Äôs an entire book being written on asynchronous programming in Rust. It‚Äôll be available on the website when it‚Äôs done.
NEVERMIND!!! :\) Got it sorted. I was trying to use a const for the inputs/outputs
&gt; Despite the fact that the definition of c_void has not changed, technically the c_void from libc 0.2 and the c_void from libc 0.3 are different types. In Rust (as in C, for that matter), two structs are not interchangeable just because they look the same. I feel like this paragraph omits a critical detail, or I'm missing some critical context. How does the `EVFILT_AIO` change relate here at all? Or does it? If we'd changed the text in a comment and bumped the version from `0.2.0` to `0.3.0` would we have the same problem?
Its because the input's value is copied by value (not reference) when you assign it to a variable. input.value = 6; let v = input.value; input.value = 100; //input.value != v it is better to get the value from the dom each time the function is called. You could use the `onchange` event handler for an input instead, this would allow you to do the following. input.onchange = function(ev) { //Event.currentTarget here is the instance of your HTMLInputElement with it's current state //so we can trust the .value property let val = ev.currentTarget.value; testMe(val); } You may be able to do that on the `keydown`/`keyup` event as well but the target might be the key, I can't remember.
&gt; all RNGs now support `std::io::Read` Nice, this may be handy for some testing.
I'm not sure what exactly you're asking. How it is enabled? This is the PR: https://github.com/seanmonstar/httparse/pull/38
You are totally right, the way we have done it is what `instantiateStreaming` would do behind the scenes. This way is a little bit easier to debug since you can observe each step of the process. With `instantiateStreaming` if your `fetch` promise fails to resolve you get an error from the wasm compilation (which can be confusing). Now that you know the pipeline works, you could re-write it to use `instantiateStreaming`. The one thing I will add is that `instantiateStreaming` is not currently supported by Microsoft browsers (last I checked) while the method above is. 
An annoyance with argument-position `impl Trait` is that: fn foo(x: impl Foo) { } Now means something different to: type Bar = impl Foo; fn foo(x: Bar) { }
Fantastic. It instantiateStreaming also doesn't work in waterfox either, so this is absolutely perfect. Thank you so much for working this through with me.
&gt; If we'd changed the text in a comment and bumped the version from 0.2.0 to 0.3.0 would we have the same problem? Yup.
I'd say from purely pragmatic perspective \-\- i.e. if you want to learn a language that you can then find a job with \-\- C\+\+ today is a better bet. Hopefully Rust will be added to sites like Hackerrank soon. Go with Rust if your goal is more to enjoy the process and learn some new and future\-proof paradigms. I do hope Rust will replace C\+\+ in many applications, but it will take \(quite a long\) time. I personally would prefer not to learn C\+\+ if I can jump straight to a better language like Rust. I just don't see a lot of value in chasing segfaults and concurrency bugs when those can be avoided altogether by a good compiler and theoretically sound language constructs. It will also be easier to find a Rust job as time goes by \-\- being early on the "scene" is an advantage of sorts...
thanks!
I agree on all your points, I also wish that `impl Trait` wasn't allowed for argument types, to keep Rust orthogonal and avoid unnecessary overlap (especially considering that `impl Trait` for args is strictly less powerful than `&lt;T: Trait&gt;` syntax). Also, I don't think normal generics are harder to learn, and I was advocating for A/B testing to determine which aspects of Rust would be easier to learn with different syntax, instead of just guessing.. I never heard any Rust newbie (e.g. on IRC) be confused about the `&lt;T: Trait&gt;` syntax, usually the other aspects of Rust are what people find difficult, e.g. the borrow checker, lifetimes in references etc.
I cannot agree more! https://www.reddit.com/r/programming/comments/8jbfa7/naive_benchmark_treap_implementation_of_c_rust/
Completely relevant to this whole experience :\) [https://www.reddit.com/r/ProgrammerHumor/comments/8jcihg/stop\_trying\_to\_learn\_please/](https://www.reddit.com/r/ProgrammerHumor/comments/8jcihg/stop_trying_to_learn_please/) [https://www.reddit.com/r/ProgrammerHumor/comments/8jflo8/started\_from\_the\_bottom\_now\_were\_here/](https://www.reddit.com/r/ProgrammerHumor/comments/8jflo8/started_from_the_bottom_now_were_here/)
Getting back to work on my [RTSP 2.0](https://github.com/sgodwincs/rtsp-rs) (Real Time Streaming Protocol) implementation. I was hoping to wait until async/await got to a usable point, but I decided to just deal with it. The result is some pretty ugly [async code](https://github.com/sgodwincs/rtsp-rs/blob/master/src/protocol/protocol.rs). But I've made a lot of progress in the last couple of days and am almost done with a base protocol that I can build a client, server, and proxy off of.
Maybe [https://os.phil\-opp.com/minimal\-rust\-kernel/#target\-specification](https://os.phil-opp.com/minimal-rust-kernel/#target-specification) helps? The target specification format has no public documentation unfortunatly, but you can look at the documentation of the [`Target`](https://github.com/rust-lang/rust/blob/eca0da59850d4a9eef17c0e6c3795397102d88a3/src/librustc_target/spec/mod.rs#L377-L401) and [`TargetOptions`](https://github.com/rust-lang/rust/blob/eca0da59850d4a9eef17c0e6c3795397102d88a3/src/librustc_target/spec/mod.rs#L418-L634) structs. Cross\-compilation is pretty simple in Rust, since the Rust compiler is already a cross\-compiler and you can use LLD as linker \(at least for some targets\).
Cargo &amp; rustc consider two different versions of a crate different regardless of the contents.
Thank you!!!!!!! *jumps up and down* I'll continue improving for you!
Does this relate to [TSX-NI](https://software.intel.com/en-us/node/524022) any way?
There is precedent for this particular redundancy in Java. One can write both `void append(List&lt;Item&gt; list, Item item)` and `&lt;L extends List&lt;Item&gt;&gt; void append(L list, Item item)`. I've never seen anyone argue only the latter should exist.
Nope, this is all software\-based \(just using atomically\-handled pointers at most\).
Making this thing correct to fulfill science requirements would require writing a whole lot of more experiments of different type of loads, approaches, etc, and make the results easily reproducible (e.g. by using a common or a dedicated hardware). Look at how https://www.techempower.com/benchmarks/ implemented. We had a different idea in mind: we wanted to know where we can arrive implementing the same logic in different languages (currently, the list expanded well beyond our expectations and experience), that is performance-wise and ergonomics-wise. Thus, the state we wanted to arrive by design was suboptimal in terms of performance, that is not the ideal environment like science would like us to do.
There was a bit of discussion [here](https://github.com/rust-lang/rfcs/issues/1109) about somehow detecting that `None::&lt;NonCopyable&gt;` is still a "`Copy` value". 
I would be really curious to see you extend it for sparse matrix multiply and sparse transitive closure with boolean entries. The latter is a major workhorse for so many applications (Valiant parsing, graph algorithms...) but there are few high performance implementations.
I'd suggest opening a thread on internals.rust-lang.org. That forum is much more suited to long form discussion whereas here this post will fall off in a day or so. It would also be helpful if you could post, in as much detail as possible, how C code is compiled for the platform. Bonus points for clang.
I agree. Although I know there are some cool new features in the pipeline, and although I like some things being touched up and polished, in general I think that substantially more attention should be spent on stabilization and tuning of what already exists and that new language features should be lowered in their priority. 
Programming remains hard despite the years of effort we spent trying to making it easier. I don't think there's ever been a legitimate reason to intentionally make something hard to use or understand.
\&gt; My impression is that this is actually an example of run\-time polymorphism for an OO language, which rust is not. Java does not distinguish between run\-time and compile\-time polymorphism, so the redundancy is still there but inverted: whereas Rust has two ways of writing compile\-time polymorphism, Java has two ways of writing run\-time polymorphism. \&gt; I also was under the impression that the second example is actually static dispatch, so these two syntaxes mean completely different things, and have a reason to be separate. Java generics are type\-erased at runtime, so both syntaxes are the same and use virtual dispatch. \&gt; Another part of this is that java abstractions tend to be built on inheritance of classes \(something that is much more conducive to the first style\), whereas rust abstractions tend to be built on generics with trait bounds \(something that is much more conducive to the second style\). This is probably an antiquated view of Java. Anecdotally, I write Java professionally and don't run into class hierarchies very often, whereas interfaces are used ubiquitously. \&gt; Either way, my limited experience with java doesn't suggest that "java does it" is a good reason to do anything. My point wasn't that Rust should copy design choices made by the designers of Java \-\- it's that I've never seen Java \*users\* complain about this type of redundancy.
Done, [issue created](https://github.com/rust-lang/rust/issues/50776)
&gt; Lots of people had their hopes up about using Rust for small microcontrollers and now that support is given up so easily. Nobody, at least on the various Rust teams, is "giving up" on that. Embedded devices are actually part of this year's [roadmap](https://github.com/rust-lang/rfcs/blob/master/text/2314-roadmap-2018.md). There's [a lot of work](https://github.com/rust-lang-nursery/embedded-wg) currently happening to make using Rust on embedded devices better but there just isn't enough manpower to get it all done this year. Still, the state of Rust on embedded devices will be significantly better at the end of this year than it was last year.
&gt; So it seems to me like the argument comes down to "the explicit generic syntax is harder to learn"? Incorrect, as mentioned, the argument is that there are many things worth learning before learning the explicit kind syntax (the syntax is not only for generics, but also for life-times, consts, etc.).
Still a bit early. I'm just getting through the websocket server and learning serde for the serialize / deserialize stuff. I'm having to relearn everything from scratch; vanilla Rust included, as I'm finding it a different world than I remember. I'm just getting my toes wet with yew, but I am noticing a few things that will be hurdles: * . There doesn't appear to be any lifetime hooks, like React's 'componentDidMount', 'componentDidUnmount', so I need to figure out how or where it would appropriate to do the subscribe / unsubscribe stuff for each component. * . `yew` documentation is a spotty at best. I'm having to mull through source to figure out how to do, what I think, would be simple stuff. I don't mean that as harsh as I probably sound; its a fairly new project. * . There are examples to follow but they are extremely simple, and I'm used to larger scale SPAs. I'm a bit bamboolzed by the author's decision to name the component `struct`s as `Model`, as it appears to me to be more like a React.Component's `State`. I'm getting the sense these `Model`s are more state at a per component bases. I need to see if theres any sort of global state management like Redux in a React+Redux project would have, though I get the sense I need to make something myself. * . Mutating the "state" seems like hubris at first, but I understand why: immutable structures, and copying on change is more for a GC enabled language, so theres a different mentality here. However, having the `ShouldRender` check in the `Component::update` function seems like the question is being forced way too early. * . I guess the largest hurdle I'll need to overcome is the general mentality of the project; I'm guessing the author is more familiar with an Elm or Angular strategy, and I'm more familiar with a React strategy. What I mean is, `yew` seems to be heavily focused on being an all encompassing *framework*, whereas I would prefer a *library* without the opinions. Again, I'm just stepping past "hello world" and "increment / decrement" buttons, so I haven't had the chance to even approach these things above yet.
Thanks! That is very nice. 
I don't believe it would do much - operationally, this is much more like an Arc that can be updated. 
Rust has also been voted as the most loved language for the past 3 years (so, for every year of its existence): [2016](https://insights.stackoverflow.com/survey/2016#technology-most-loved-dreaded-and-wanted) [2017](https://insights.stackoverflow.com/survey/2017#technology-most-loved-dreaded-and-wanted-languages) [2018](https://insights.stackoverflow.com/survey/2018/#technology-most-loved-dreaded-and-wanted-languages)
&gt; I guess that's an argument in favour of abstract type Bar instead of type Bar = impl That is already the case: https://github.com/rust-lang/rfcs/pull/2071 
https://github.com/rust-lang/rust/blob/3c9442fc503fe397b8d3495d5a7f9e599ad63cf6/src/librustc_back/target/mod.rs#L70-L207 I finally think I understand (at least some of) this. My next plan is to try setting one of these up, and if it fails going back and seeing if I can figure out what I did wrong Thanks! 
There is no "Ristretto paper", but there is a comprehensive documentation on how it works: https://doc-internal.dalek.rs/curve25519_dalek/ristretto/notes/index.html The API is also thoroughly documented: https://doc-internal.dalek.rs/curve25519_dalek/ristretto/index.html
In which project is being used in MS? As fellow MS engineer, I'd like to talk to them
The subreddit logo is ready to party.
off-topic, but nice username ;-)
The publicly known things are 1. Ripgrep powering VS: Code's search 2. https://github.com/Microsoft/inno-updater
No worries. :-) I've also swapped snappy out of my personal memory. And I fully sympathize with PR backlogs on lesser-used crates! Go enjoy the wonderful spring or something, and don't waste 5 seconds stress on that PR.
I believe actix-web might also be publicly known. At the very least I saw it mentioned on the gitter page for it.
^The linked tweet was tweeted by [@rustwasm](https://twitter.com/rustwasm) on May 15, 2018 19:02:30 UTC (3 Retweets | 3 Favorites) ------------------------------------------------- This Week in Rust ü¶Ä and WebAssembly üï∏Ô∏è \#002 \#rustlang \#webassembly [https://rustwasm.github.io/2018/05/14/this-week-in-rust-wasm-002.html](https://rustwasm.github.io/2018/05/14/this-week-in-rust-wasm-002.html) ------------------------------------------------- ^^‚Ä¢ Beep boop I'm a bot ‚Ä¢ Find out more about me at /r/tweettranscriberbot/ ‚Ä¢
Sorry I disappeared ‚Äî last week was finals week, but I'm planning on getting back to those open PRs in the near future. Excited to see this release get out there!
Is that done by microsoft? I had no idea.
http://i.imgur.com/6Yv41.jpg
The patron saint of /r/rust, of course!
I primarily like OS development and Rust is one of the few languages that isn't a minefield and that I can tell that it doesn't allocate from a heap that doesn't exist. If I don't import alloc, I KNOW that my code will not use dynamic memory. I can't say the same for any other safe mainstream language.
Another good example of where to use each is `std::ops::Mul`. It has one generic parameter (the type of the right-hand-side expression), and one associated type (the output). This means that you can implement multiplying your type against as many other types as you wish (or even do so generically against a trait bound), but for each of those implementations there's only one valid output type.
&gt; Is impl Trait in argument position intended to never get used by more experienced users? I plan on using it where it makes sense, just like any other feature.
The person who works on it is a Microsoft employee and iirc he mentioned on gitter that it was being used for some new sites (possibly internal sites, I didn't ask)
:)
In [this issue](https://github.com/dalek-cryptography/curve25519-dalek/issues/76), zmanian talks about "the Ristretto paper is still private". So I assumed there was going to exist one.
Correct link: [https://github.com/Microsoft/inno\-updater](https://github.com/Microsoft/inno-updater)
ugh, thank you
I've been working on my programming language(underscore)[https://github.com/lapz/underscore]. Currently implementing monomorphisation.
Happy birthday to you. Happy birthday to you. Happy birthday dear Rust-lang. Happy birthday to you~~~.
Just to add to the others, if you compile this in release it changes the output. http://play.integer32.com/?version=stable&amp;mode=release
Man I love Rust. What a great game. Kind of toxic people though 
This technique was used successfully to bridge [**`log`**](https://docs.rs/log) 0.3 to 0.4, and will be used for [**`failure`**](https://boats.gitlab.io/blog/post/2018-02-22-failure-1.0/) 0.1 to 1.0 when that comes out.
Is there a link to the presentation anywhere?
https://www.youtube.com/watch?v=oAC9Zpo18-8
Congrats on the TrustDNS library being used for 1.1.1.1.
It did work for something. The .NET AOT compiler on Windows 8.x is the Bartok compiler from Singularity. 
The problem is not that \`impl Trait\` never makes sense. The problem is that as far as I can tell, there are no situations where the existing syntaxes do not make the same or more amount of sense. \`impl Trait\` in argument position doesn't add anything on top of them once you know how they work, so it's needless clutter.
&gt; once you know how they work, Right, but that's the whole point. You can skip the `&lt;&gt;` for a while at first.
I've just learned that Trust-dns has been successfully used in CloudFlare. What an achivement, congrats!
You can read a draft here https://aturon.github.io/apr/
Not guarantee, but improve the chances. It'll be a *long* time before the entire stack is written in a safe language and, even if everything were written in Rust, there will always be the chance that someone wrote some `unsafe` code and didn't audit it properly. Looking at that list, the three memory corruption issues are in WebKit, which isn't part of the application but, rather, part of the OS. (It's the browser engine that you're not allowed to replace in apps that are approved for the app store because Apple trusts their ability to push out timely security fixes more than yours.)
/r/lostredditors
Also unfortunately Rust can have [unsound bugs](https://github.com/rust-lang/rust/issues?q=is%3Aissue+is%3Aopen+label%3A%22I-unsound+%F0%9F%92%A5%22).
may I ask... why? I don't get the joke, sorry.
No u
Or just "roflect."
I guess: Rust -&gt; fungi -&gt; mushrooms -&gt; [mushroom trombone guy](https://www.reddit.com/r/rust/comments/62rreg/psa_tell_other_projects_about_the_good_word_on/dfoswui//). He was briefly used as part of the custom CSS last year in this subreddit, dunno whose idea was to use this picture initially.
True, but I generally consider fixable mismatches between the theoretical model and the actual execution environment (eg. compiler unsoundness, Spectre/Meltdown, etc.) to be like `panic!`-causing code paths in your dependencies which aren't supposed to be reachable from the API exposed to you or failing RAM cells on a DIMM. No matter what choices you make, they're always a hazard and you have limited ability to mitigate them.
``` fn somefunc(arg: impl Display) -&gt; impl Display {} ``` `somefunc` takes an argument that implements `Display` and returns an argument that implements `Display`. They mean the exact same thing. If you *don't know* what universal/existential types are, then you might be very confused about why you can't use them in both places. If you *do know* the distinction, then the distinction between a universal and an existential is useless here because they can't be mixed due to functions arguments being contravariant and return types being covariant. There is no ambiguity. My only complaints are that you can't do Trait /Type arithmetic in arbitrary places. I.e., `impl (Display + Debug + !Clone)` or similar for Trait objects.
The world my never know...
Not in the core, as part of the cache warming component. Still huge though!
Actually, no, we know now. ;)
Swift would have a similar benefit, right? And might be more likely to actually happen. I guess there are a fair few parts of the apple stack that swift wouldn't be appropriate for, but still... 
Maybe you could help out with the [Ion shell](https://github.com/redox-os/ion)
Not sure if this counts as an 'easy' question, but how can I do floating-point math in a `no_std` setting? Basic functions like `powf` and `sqrt` don't appear to exist. I'm not sure how relevant this is, but I'm trying to run Rust code on the GPU using [accel](https://github.com/termoshtt/accel). I have it working, more-or-less, but I need these math functions to proceed. I really don't want to try to implement them in software.
I'm not sure you're running your futures in parallel. You probably want to join them instead.
I'm not *fully* aware of the details, but there have been PRs like this: https://github.com/rust-lang/rust/pull/50593
As I understand it, Swift doesn't currently have compile-time guarantees as strong as Rust and isn't currently suitable to as wide a range of applications. Also, Rust is somewhat unique in how well-suited it is to being used to incrementally replace existing C or C++ code, as is being done in cases like Firefox and librsvg. That said, Swift is a rapidly-evolving language so who knows how suited it will be in the future.
Yep! That's the unfortunate part of the trade\-off. :\(
The first-ever time that the subreddit changed its CSS to anything stupid was an April Fools' joke where we became mushroom-themed and worshipped this amazing suit-wearing trombone-wielding mushroom hunter. Ever since, he has been inserted into every dumb CSS thing we've done here.
I'm not sure of any exercises in particular, but answering questions is always possible here. If you've already read through [Chapter 15 of the second edition book](https://doc.rust-lang.org/book/second-edition/ch15-00-smart-pointers.html), is there anything in particular you are confused about?
Just pushed 0.6.0 with `--sortable`/`-s` flags. Also added `--pty`/`--tty` for running things under a pseudo-terminal so apps don't buffer thinking they're being ran non-interactively.
Oh cool, now those job ads from 2 years ago looking for 3 years in rust are valid :)
I with chrono had DateTime::now() out of the box tho. Still nice that it compiles.
So this is where Rust's ecosystem is kinda lacking at thr moment. If precision isn't an issue, my crate `mish` does have all of the functions, albeit rather inaccurately. I do plan on doing a full `libm` port but that'll have to wait until summer for me. If you can find a `libm` implementation for your platform of choice, you can link it and use that instead.
Writing front end with rust and wasm. I already rewrote one part of my application and its working. The biggest concern is wasm file size (about 200kb) and wasm file being blocked by adblocker.
is there a way to force a crate to be compiled using `--release`, so it won't compile on debug?
Why do you want to not compile with the debug profile?
because I want integer overflow and features like that, to mimic the behaviour of a C library
If you want overflow arithmetic, you should use the `wrapping_add`, *etc.* methods, or `Wrapping` type.
ok... that should work, but I just added `opt-level = 3` to my `Cargo.toml` which seems to do what I want.
Woot, thanks to /u/Icefoxen for nominating Askama for crate of the week! 
Hi Tom!
Sorry for all the downvotes, -1 should have been good enough.
yeah, I know, but with my already liberal use of `transmute`, it's the least of my worries at the moment. I kinda just need it to work right now, and as I don't plan on distributing it, refactoring later seems like a better option.
[removed]
I fear I won't have the time and motivation to do that ‚Äí this one is very limited/research style and working with sparse matrices is likely very different to working with dense ones, so it'll be a completely different code. And I'd have to maintain the code üòá. But if you feel like trying yourself, you can contact me and I would try to come up with some ideas what/how to make it faster.
I'm not certain since I have not used ggez before. But maybe `update` is still invoked without limitation. Even though it does nothing the code calling it spins indefinitely without yielding the thread to the OS. The [timer module](https://docs.rs/ggez/0.4.2/ggez/timer/index.html) could be helpful here, in general you will have to make sure to handle the timestep appropriately in the update method anyway or you get undeterminstic game physics.
This is a particularly important date for me as stabilization marks the point in time when I started reading about Rust... the language being stable helped greatly and still does to the extent the language still is stable.
In addition to what the others said, when you compile a library that defines generic APIs, the library itself does not contain any compiled code for them. Rather, it contains a processed form of the raw source code in its metadata, so that any consumer of the library that puts actual types into the type parameters can generate the specialized copy of the code.
Note that it uses specific hardware instructions, so it is not very portable.
Time flies by so fast! Happy birthday Rust üéÇüçïüçª
As condescending as it sounds, believe me, you're going to regret that decision.
Wow, those function bodies are deeply nested... Is there a way to avoid that?
I don't quite understand why there needs to be a rand_core? I've read [some of the discussion](https://github.com/rust-lang-nursery/rand/issues/264) and I don't understand why rand can't contain everything and then use features to gate things based on the actual crates' requirements. From what I've seen closely related multi-crate mini-ecosystems tend to not be ideal ^[citation ^needed] . I'm not sure about my arguments here, just my general feeling based on some projects I've seen and a little bit of my own experience. Eg. you can't have cyclic dependencies between crates, but cyclic 'dependencies' between modules in a single crate is just fine. The trait coherence rules also make closely related multi-crate projects harder. It's these things that push me towards bigger crates based around features to enable the things you need. I also read somewhere that the std lib wants to go in this direction, using features instead of a split between std, no_std (when in reality the actual requirements are far more finegrained, eg allocation support yes or not, float support yes or not, simd support yes or not). Features seem _excellent_ to deal with these kind of inter dependent structures. (I understand features isn't panacea, but less problematic than trying to create a strict crate hierarchy). So my question is, what exactly is the purpose of rand_core that can't be solved (better) with features?
Tree structure like rctree. 
Thanks! So, after glancing over the links but only very quickly, I currently believe that: 1. The actual async+await more or less correspond to Lua's [coroutine.wrap](https://www.lua.org/manual/5.2/manual.html#pdf-coroutine.wrap)+[coroutine.yield](https://www.lua.org/manual/5.2/manual.html#pdf-coroutine.yield); 2. What is important, though omitted from most articles (presumably assumed "obvious"), is that to actually run the async functions and schedule them you need to fetch them to some "Executor" object. - This is nicely visible in the [example in the alexcrichton/futures-await repo](https://github.com/alexcrichton/futures-await/blob/941147f1bf6a2401794f47409c651874db3e5f0f/examples/echo.rs#L43) - and also explicitly mentioned at least in the [tokio docs' "Runtime model" chapter](https://tokio.rs/docs/getting-started/runtime-model/#executors). I believe the Executor is the actual scheduler, so you will be able to choose "any scheduling engine you like" from available libraries implementing the trait/model/whatever. In particular, most probably there will be some M:N scheduler implementation (i.e. "thread pool", a.k.a. "Go-like"). As mentioned by u/chrish42, a compromise taken by this model is that there will probably be no possibility of preemption, so the async code must be written with "cooperative scheduling" mindset, i.e. take care to insert explicit preemption points ("await calls") at right points (e.g. tight loops, etc.) if needed. One thing I presume may be problematic is calling to long running operations in third party libraries. This may probably split the world into async and non-async "worlds" of code. Or a convention may arise to try to write code as "async by default", plus maybe some stdlib macro converting an async function to a sync one by putting it through a "serial Executor". If possible. 3. IIUC, a [Reactor](https://tokio.rs/docs/going-deeper/building-runtime/#the-usual-components) is the third part of the puzzle, being the actual provider of actual values for the Futures. E.g. some "epoll" reactor providing values for any file i/o Futures. In other words, I think: - async functions are +/- "coroutines" - Reactors are actual "data/event providers", e.g. epoll-based - Executor is an "event loop"/"engine"/"scheduler", keeping a pool of blocked async functions, then waiting on a pool of Reactors till they emit some event, then forwarding this event to a matching async function and letting the function run, scheduling it on a thread from a pool according to some policy. And back to waiting for another event from some Reactor.
üéâüéâüéâüéâ
Do you have any insights you want to share based on these benchmarks /u/-elektro-pionir-? The fact that Rust outperforms Go in the benchmarks game does not say much in and of itself :)
That's quite odd. What OS and graphics card are you using? On my test systems (Windows+AMD, Linux+NVidia) your code uses &lt;1% CPU. Having vsync limit the framerate usually means your program yields automatically on the `graphics::present()` call. Contrary to /u/evotopid 's reasonable speculation, `ggez::event::run()` [doesn't do anything complicated](https://github.com/ggez/ggez/blob/master/src/event.rs#L195) (we tried making it smart and it just made life hard), it's basically `loop { handle_events(); state.update(); state.draw(); }`. Try throwing a `ggez::timer::yield_now()` call in to either `update()` or `draw()` and see what happens... If that doesn't help maybe try profiling your program to see where it's spending all this CPU time.
TIL!
At least they fixed all the crashing. 
It works fine if you `#[derive(Copy, Clone)]` for `Foo`.
At they are fixing all the crashing. 
Not really... Swift doesn't provide much more than C# in static safety checks... Which is incomparable to Rust IMO. Anyway, Swift would be better than bare C/C\+\+. Especially for Apple platforms .
Lower-level language outperforming higher-level one isn't surprising, IMO.
Been playing around with some game development, and my latest experiments have been around "screen" management. I have to a game screen that's always running, and then adding an inventory screen that lives for a bit, before it's removed and we're back to just the game screen again. All the while the game screen is also processing events, since it's still in the screen stack. I've found a way to make this work as I want it to, but I ended up having to use quite a bit of `Box&lt;Screen&gt;` signatures (where `Screen` is a trait`) to pass references to callbacks, and `Rc&lt;RefCell&lt;Box&lt;Screen&gt;&gt;&gt;` to store pointers to the various screens. It works, but it feels like there should be a better way to solve these things. Here's a slimmed down version of how I solved it: https://play.rust-lang.org/?gist=34290d7ded4807c822e5cced72c5ba80&amp;version=stable&amp;mode=debug I would love to get some feedback on how I solved these things. Do I to use `Rc`, `RefCell` and `Box` to make it work? Are there any spots where the new `impl Trait` could be used instead?
I've worked around it for now by using the intrinsics from the `core::intrinsics` module. It compiles, at least; I haven't verified yet that they give correct results. If that doesn't work I'll check out one of these libraries instead. Thanks!
I've been wondering the same thing myself Maybe `tower` can help? https://tower-rs.github.io/tower/tower_in_flight_limit/index.html
For some more information on the name: [Internet archaeology: the definitive, end\-all source for why Rust is named "Rust"](https://www.reddit.com/r/rust/comments/27jvdt/internet_archaeology_the_definitive_endall_source/)
I would be very suprised if there was any kind of performance difference between Rust on AMD and Intel CPUs that didn't correlate with benchmarks between those particular CPUs. IE, if Intel CPU `x` is 10% slower than AMD CPU `y` than I would expect Rust programs to perform about 10% slower on `x` than on `y`. 
Hi, you can access the version set by Cargo from env. I am doing this like that: ``` const VERSION: &amp;'static str = env!("CARGO_PKG_VERSION"); ```
I am really new to rust and want to reimplement my basic software renderer\(written in plain C\(rendering engine\) and C\+\+\(GUI\)\). Rust is a very interesting language and i want to increase my experience. Rust won against GO and D. Currently i plan my project structure and try to find any tutorials/Tips and Trick for avoiding pitfalls which based of Experience in other Languages i learned\(Java, Python, C, C\+\+, JavaScript\), Performance issues/optimization and and and....yes...we will see Happy rusting :\)
You can google around for llvm compile time and runtime performance differences between Intel and AMD. There isn't really any substantive difference in general though. 
Awesome! Thank you.
to expand on /u/kubaxvx 's answer, here's the list of env vars that cargo sets during compile time: https://doc.rust-lang.org/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-crates
Yes, that was fun to find out for me too! And thanks!
That would be really cool, though... As Steve mentions, it‚Äôs just the client. Still very fun to learn how people are making use of the library.
Thanks for sharing this. I was completely unaware of openssl-probe. Very cool.
[For those wondering...](https://github.com/rust-lang/rust/blob/master/src/libcore/str/mod.rs#L1458)
I seem to recall that an earlier WebRender/Firefox integration used both engines to render the current page, causing WebRender to feel slower than it really was. Is that still the case?
This is a common rumor but was never true.
So...would this benefit from stdsimd?
Are you getting a 4xx response to your react requests? If so, check to see if you are providing an Accept header than will accept application/json. By default, your browser includes */*, but your react request may not be. 
Ah, interesting. For others who may have heard the same rumor, [here's an explanation](https://www.reddit.com/r/rust/comments/618p54/webrenderer_landed_in_firefox_nightly_here_is_how/dfe2xal/). My modified question, then, is: have the performance issues at the boundary between Gecko and Webrender been mitigated, or are they still an issue?
I want to personally thank llogiq for being such a good mod here, and for remembering to create our weekly sticky threads every week for the past several years. :)
Could someone leave a comment explaining the relevance to /r/rust?
Now I am not getting a 4XX error. I am getting a json format error that says unexpected end of input
You use can the [num_traits](https://github.com/rust-num/num-traits/) crate.
Differences are marginal, but you'll likely get more performance per dollar with AMD. That's generally been how that goes. There used to be a huge difference between AMD and Intel in the days of Bulldozer, where Bulldozer would run rounds around Intel processors when compiling software due to the high number of cores and the total ALU count in comparison to Intel offerings, but nowadays their architectures are pretty similar.
Rust's String type *has* to be valid UTF-8 to be memory safe. Any time you're creating a String from a `[u8]`, you're going to need to validate it. Doing this quickly is helpful.
That's great to hear! I think there are still portability concerns, generators like PCG are trivial to implement, even in languages like Python.
I volonteer doing it over the summer, if I pass everything in first session.
You want something like this: fn times_three&lt;T&gt;(input_number: T) -&gt; T where T : std::ops::Mul&lt;Output=T&gt;, T: From&lt;u8&gt; { input_number * (3u8).into() } fn main() { println!("{}", times_three(5i32)); println!("{}", times_three(5f32)); println!("{}", times_three(5f64)); } Rather than an explicit conditional on T, you say that you want some type "T" that supports multiplication, and can be created from a literal 3.
Maybe it's possible to do even better by a larger restructuring / rethinking, but as a first step, I would remove all `RefCell` and replace with `Cell` or `RefCell` on whatever fields that can change (e g `exit: bool` =&gt; `exit: Cell&lt;bool&gt;`). With this change, a lot of methods can take `&amp;self` instead of `&amp;mut self`, and so you can get away with using `Rc&lt;Screen&gt;` instead of `Rc&lt;RefCell&lt;Box&lt;Screen&gt;&gt;&gt;`.
Any time I see "UTF-8 validation" I think of Rust ... which is admittedly not a very strong justification :P But if you just wanted someone to post Rust-related background information to try to foster a useful discussion then I can oblige. ------- UTF-8 is the defacto standard international text encoding. Each UTF-8 character (simplifying) is made up of one to four bytes, but not every sequence of bytes is valid and validating them [is somewhat complex](https://stackoverflow.com/a/17199164/1334732). Rust's standard string type, `str`, is guaranteed to be valid UTF-8 which helps to ensure the correctness and soundness of string processing code. To ensure this guarantee is kept, string data read from outside sources must be validated before it can be used as a `str`. In most cases, the time spent to validate strings is not significant to overall performance, but it is often brought up as one answer when someone asks questions like "why is this Rust code slower than this C++ code". Rust has a [well-optimized scalar implementation](https://github.com/rust-lang/rust/blame/master/src/libcore/str/mod.rs#L1458) of UTF-8 validation. With the impending stabilization of x86 SIMD in Rust, it would be an interesting project to speed up this implementation with SIMD techniques like those showcased in the article above.
I took a look, but the documentation wasn't particularly helpful. Is there a repository with examples of its use?
Unless implemented in C PCG is not going to be fast. If done in C and called from Python then it can be done the same way as the GitHub repo. Also PCG is not secure. Randen was designed so that it can tick all the boxes for prngs: secure, fast, small state. When something ticks all the boxes it allows for great simplifications: make it the default and then users don't have to choose, no need for securerng market trait, etc.
I think it'll be important to find a good trade-off between using cheaper ASCII validation and the cost of switching between ASCII and UTF-8 validation.
They have largely been mitigated. There's some on going work that will improve things further, but you won't run into problems for the most part.
The `Mul` trait has an associated `Output` type, which is the type of the result of the `*` operation. Here the `Mul&lt;Output=T&gt;` bound means that the type `T` must implement `Mul`, and the `Output` of that implementation must also be `T`. `From` is a generic trait, parametrized by a type. It allows conversions in a generic way. In this case, `From&lt;u8&gt;` means that a `u8` can be converted into `T`. This allows the function to take any type that * when multiplied by a value of the same type, produces another value of the same type * can be converted into from a `u8` Then we take the value `3` and convert it to our `T` type - the compiler is smart enough to figure out the `3` is an `u8`, because we know of no other types that _can_ be converted into `T` in that context. Finally, we multiply the argument by our converted `3` to produce another value of type `T`, and return that.
You can see that `Mul` has an associated type [here](https://doc.rust-lang.org/std/ops/trait.Mul.html#associated-types), and you can read all about associated types and how to use them in [the book](https://doc.rust-lang.org/book/second-edition/ch19-03-advanced-traits.html).
`from_utf8_unchecked` is a [very popular](https://github.com/search?l=Rust&amp;p=3&amp;q=from_utf8_unchecked&amp;type=Code) cause of unsafe code. If the same sibling`from_utf8` has great performance it'll certainly help convince people to not take the risk. 
Does that validation happen at compile time or runtime?
nothing in particular, I guess I just feel uncomfortable with the concept as of now. Perhaps I just need to go back to the basics and write some data structures like linked list or splay tree for practice
Yeah, I think I will try implementing it. Thanks
&gt; usermode/examples contains a few examples for WebAssembly applications running in Cervus. I cannot find the usermode directory in the repositoty.
Runtime, if you're creating a string from some byte array. To be honest, I don't know if the validation is skipped for string literals.
String literals are validated at compile-time, but strings created from byte sequences (either `Vec&lt;u8&gt;` or `&amp;[u8]`) have to be validated at runtime. I expect there are also more implicit conversions.
That comment seems wrong...
Fantastic. I haven't made it to that point in the book yet. Good to know what the term is.
I'd like to see what primitives some types from std::net are made from, and chasing the [docs.rs](https://docs.rs) \-src tabs lead me to an import called net\_imp::TcpStream, which I can't find any rust documentation for. Is there anywhere I can find documentation for this? Google was not helpful.
Hmm, if you could copy the XHR request as a a curl cmd, that may help diagnose it. If you don't know how here's a screenshot: https://imgur.com/a/TlusXSX
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/b0BtsLR.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
You might want to take a look at the structopt crate. It is very nice if you need argument parsing and it implements a version argument by default...
I've never dealt with this kind of thing but I'm curious: Is there a 'worst case scenario' string (of a given length) for validation? A 'best case scenario'?
So, this has MIT or APACHE2 license, so one can use it in commercial products too? [https://github.com/snipsco/snips\-nlu\-rs](https://github.com/snipsco/snips-nlu-rs) Wow!
Understanding the basics of both languages can be a good thing. You don't have to become fluent in both at the end of the day. Rather know a little about something than nothing about something.
Cool, thanks!
**Andrew Grove** Andrew Stephen 'Andy' Grove (born Andr√°s Istv√°n Gr√≥f; 2 September 1936 ‚Äì 21 March 2016) was a Hungarian-born American businessman, engineer, author and a pioneer in the semiconductor industry. He escaped from Communist-controlled Hungary at the age of 20 and moved to the United States where he finished his education. He was one of the founders and the CEO of Intel, helping transform the company into the world's largest manufacturer of semiconductors. As a result of his work at Intel, along with his books and professional articles, Grove had a considerable influence on electronics manufacturing industries worldwide. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
My WordPress plugin related CLI tool project. First real Rust project so we shall see how well it goes. https://github.com/rask/wppr
Welcome! Head over to #rust-beginner on irc if you ever need help. It works best if you ask with a simply example of your problem posted on https://play.rust-lang.org/ :)
Thanks! I'll do that.
&gt; To be honest, I don't know if the validation is skipped for string literals. String literals [are checked at compile-time](https://play.rust-lang.org/?gist=2bb236ad780160eec52b8321407c3569&amp;version=stable&amp;mode=debug).
there's an `s` on that, `#rust-beginners`.
Eat shit and die. jk, welcome! If you want my discord, PM me, I need more people to talk about programming with, especially Rust.
IDK whatever feels best for you. But note that you'll start requiring 1.26 when using `impl Trait`, something not all of your users might have.
I find systems programming kind of fascinating, after I found a book on the Unix operating system for like $3 at a local bookstore I decided it was something that I wanted to try for myself. I obviously don't know much quite yet, and that might change in the future or I might find that I like some other sort of programming better. But that's what drew me in.
Chasing down platform-specific ("sys") imports in the standard library is a little bit fussy, but follow all the module definitions you'll wind up here: https://github.com/rust-lang/rust/blob/1.26.0/src/libstd/sys_common/net.rs#L179 And deeper down here: https://github.com/rust-lang/rust/blob/1.26.0/src/libstd/sys/unix/net.rs#L46
Here are some example functions: https://www.reddit.com/r/rust/comments/8fkinp/function_that_takes_any_number_as_an_input/dy4c9op/
There is a rust discord, where a lot of helpful people hang around. You should be able to easily find a link to it.
No problem. To be honest [I'm still trying to understand the tradeoffs myself](https://github.com/rust-lang-nursery/rand/issues/431). We've certainly experienced incoherence of feature flag selection across crates, but frankly I think that's just a Cargo bug.
Indeed, if it really does tick all our boxes it would be a great replacement for `thread_rng()`. I suspect we'd have to fall back to some other RNG on unsupported hardware.
I know that you 'only meant this as a joke', but we're not doing this kind of foul language here. Even if OP got the 'joke', others may be put off by your choice of words. I've removed your comment for now.
There is a limited quantity, but it's impossible to tell how fast or slow they'll sell out; this is only the third year, and the conf is growing a bit, but so is the audience.
&gt; You can continue to use the syntax that you were using before if you don't want to concern yourself with this. I think there's something to be said for having a language with features that compose nicely and are orthogonal. I think rust prior to the addition of `impl Trait` in argument position fits this model very well. Even if I don't intend to use the syntax myself, I have an interest in keeping the language well designed and consistent. I *really* don't want rust to go in the direction of C++ where there are a billion random features, but most people only use a small subset of them. I'm not claiming that `impl Trait` alone is a huge problem, but it's definitely a step towards a more cluttered language. &gt; That's a feature: beginners using `impl Trait` don't know about angle brackets or turbo-fish. If they ever need that, its time for them to learn the kind syntax. There's a huge problem here though, which is that libraries exist. If somebody uses `impl Trait` in a library function, then nobody using that library will be able to use the turbo-fish syntax for those functions, and there is no equivalent for `impl Trait`. This trade-off means that library authors should *never* use `impl Trait` in argumet position since it needlessly restricts the users of the library. 
And the best performance (ignoring price, and maybe not that much better) with Intel, if you prop up your computer on a pile of gold bars and can spare one for a $2000 CPU. Intel may also offer better single core performance, but the OP is talking about compilation, which should scale pretty well to multiple cores (for large projects with many files).
For your borrowing issues, have you tried replacing your use of `as_mut()` with `take()` in order to gain ownership of it?
Yeah we're thinking around 350 tickets. They haven't immediately sold out in the past and it's not likely that this will happen this year either :) So there's quite some time if you want to consider (or wait for all the speakers to be announced)
Ah, thanks. Any workarounds so far?
Probably not. It's been broken with the rand crate for a bit now, and they announced tomorrow's nightly breaks clippy entirely. Just happens that lots of different things have hit clippy all at the same time, and they are trying to catch up. 
&gt; Rust has a well-optimized scalar implementation of UTF-8 validation. It's also built to be vectorisable, at least the ascii path is. I think there was a regression there with the move to llvm 6 too. 
Thanks Steve
I'm going to go for the first time. Looking forward to it!
any time &lt;3
I'm not sure how much help I can be but, I'm soon going to be building my personal site to which I'm going to over-engineer it on purpose. One of the things I'm doing is using [message-pack](https://msgpack.org/index.html). My point is that Message pack is basically efficiently packed JSON in a binary form, so you can do: JSON &gt; MessagePack &gt; protobuf and there is a message pack crate. Just one idea.
Thanks. I worked around with rustc 1.27.0-nightly (428ea5f6b 2018-05-06) and clippy 0.0.197 :) 
I can't report on experience of doing this, but your post is basically describing RPC without actually using the term "RPC". I believe the industry standard for this is now gRPC, which uses protobuf and has some intermediate unofficial Rust libraries. I personally begrudge gRPC, having worked with it in other languages and running into major issues, but I can't recommend anything else as I've never tried them.
Welcome! Rust is a fascinating language indeed and I think you will love it. It does have a steeper learning curve but that's not a bad thing. If you stick to it, you'll learn more than you'd learn in any other language, from low level and memory management to modern powerful type systems. As others mentioned, the rust IRC channels are a really good way to start. Hope you stick around. 
Uuuuh... I don't know yet whether I can be nearby Portland in August... Well, we'll see...
&gt; I think there's something to be said for having a language with features that compose nicely and are orthogonal. You can argue that `write!` + `format!` are orthogonal, but `println!` is not. There is a trade-off between orthogonal features and convenience, or in this case, learnability. For somebody that just wants to print something to the screen, `println!` does the right thing. Once their knowledge increases, they can learn about `write!` and `format!` and how `println!` is just a thin wrapper around that. Once that learning is done, they can choose what to use when appropriately. Knowing that `println! ` is just `write!` + `format!` does not make it useless, because for many common cases it is just more convenient than composing those two manually. `impl Trait` in argument position is just that.
It's a bit expensive especially when you add traveling and hotel :( I don't know if it's possible, but it would be nice to have a price for people who pay with their own money and people whose tickets are bought by their company.
I was running into the same - and I think restarting Visual Studio Code helped (and then I promptly switched back to SublimeText (I am not a fan of / experienced with code completion - and I like the way Rust Enhanced shows errors, warnings)
Yep. A quick google shows a couple rust rpc frameworks, both updated in the last ~2 months: * https://github.com/google/tarpc * https://github.com/paritytech/jsonrpc
Thanks for the welcome and encouragement. :)
Thank you so much for the brilliant analysis!
Just gave it a shot, that solved it. In hindsight it should've been obvious, thanks!
No. The first step is generally doing to be a mask to extract the high bits, just with a patterned field. This is where things get hard. You need a look up table the size of your register to avoid segfaults and keep things linear. But for `u128`, or `u256`, or god forbid `u512`, you just don't have memory space that large. You can branch into common prefixes, but this is just a hack that speeds things up if you're _generally_ dealing with pure ASCII, or pure 2byte code-points. Cases were you have mixed data get very branchy and slow. 
I'd made it to the [net.rs](https://net.rs) one, but the sun would have burned out before I connected the dots to that unix library. Thank you.
This is an interview I did with Jim Blandy on Rust. I'm just learning the language and it was fun to get to talk to the coauthor of Programming Rust about the unique features of the language.
I'll be there, as always.
That's very unlikely. Rust tries to have as lean a standard library as possible, relying instead on cargo, with various components maintained by the Rust team being published as separate crates so they can be versioned independently.
&gt; You can branch into common prefixes, but this is just a hack that speeds things up if you're generally dealing with pure ASCII, or pure 2byte code-points. Cases were you have mixed data get very branchy and slow. Is it slower than the scalar version? 
Something is off with the list; there are repos on there with 73 stars, but [`derive_builder`](https://github.com/colin-kiegel/rust-derive-builder) has 200 and doesn't show up. Full disclosure: I'm biased because I love derive_builder and am helping maintain it.
 trait TimesThree { fn times_three(&amp;self) -&gt; Self; } impl TimesThree for i64 { fn times_three(&amp;self) -&gt; Self { self * 3 } } impl TimesThree for f64 { fn times_three(&amp;self) -&gt; Self { self * 3.0 } } fn main() { println!("{}", 42.times_three()); println!("{}", 3.14.times_three()); } It's long-winded compared to the other solutions, but I like this one.
C is a fairly small language. Rust, like C++, is a kitchen sink language with tons of features. C will always have a place for its relative minimalism. It's just easier to implement and easier to understand, even though it's harder to write large correct programs in it.
Although Rust is just as small with the no_std feature enabled. Easier to start with that than C.
Code completion is syntactic, so it generally needs an explicit type in order to work, e.g., ``` let x: Option&lt;i32&gt;; let y = x. ``` should get you options. That's far from ideal, but at least it is quick when it does work. In the long term we want to have complete completion powered by the compiler, but that is a way off (jump to def and similar things are already powered by the compiler).
Location
You're recommending that a cryptographic component be added that appears to have very little review done so far. Like, for example, the original version Simpira permutation had to be substantially revised because an attack was found, and Randen doesn't even use Simpira v2 directly, but a modification thereof to double the permutation size to 2,048 bits. I think the word here is "premature."
Sometimes the RLS doesn't start. If you hop on IRC or discord, someone can walk you through debugging a lot of it, but to be honest, it won't be great for awhile
I might be biased because I'm coming from C, but imo rust is much harder to start with.
Even with no std, Rust is still pretty big with comparison.
"whose" is correct :}
Same here! I have great expectations.
Is u8 necessary or is it the smallest numeric type you want to support?
I'm not sure I'd be comfortable calling gRPC an "industry standard" of any kind. It is Google's tool, and it's not very well developed as an open source tool. 
Exactly. I would love to see C replaced, but right now it is the de facto ABI and FFI standard for interfacing between languages. Add to that the number of big important code bases in C and the attitudes people have about programming languages. I just don't see C going anywhere particularly quickly.
Personally I attached to nightly-2018-03-30 and 0.0.190, after that I got `clippy` crash on hyper: https://github.com/rust-lang-nursery/rust-clippy/issues/2603 and just crash on random code: https://github.com/rust-lang-nursery/rust-clippy/issues/2499
I always struggle to find a working nightly/clippy match. Any hints to do that, except brute forcing of every-day versions? I really with that rustup would have some sort of backups when doing `rustup update nightly`, because I regularly get a new nightly with broken clippy. So either I need to stick with some pinned version (but `cargo +nightly clippy` is definitely easier to type than `cargo +nightly-2018-05-06`) or.. I don't know.
True, and having great mentors is even more enabling. And this community is full of them. Thank you for the kind words.
I haven't looked too carefully, but it looks like you're trying to remove an element from a collection as you're iterating over it. The quickest fix would probably be to separate the "find element position" step from the "remove from vector" step.
Here it is curl 'http://localhost:8000/' -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0' -H 'Accept: */*' -H 'Accept-Language: en-US,en;q=0.5' --compressed -H 'Referer: http://localhost:3000/homes' -H 'origin: http://localhost:3000' -H 'Connection: keep-alive' -H 'DNT: 1' -H 'Cache-Control: max-age=0'
I _think_ it's because when you call `settings.get_distributions()`, you're taking a mutable borrow of `settings` and that borrow lasts as long as `distros` is in scope. You could try enclosing that statement in another scope with `{}` so `distros` goes out of scope and the mutable borrow is released before you call `settings.set()` [Example](https://play.rust-lang.org/?gist=1d9602ed4495128053db877ca3e6d424&amp;version=stable&amp;mode=debug)
Could you give some more details? The article explicitly has a SIMD-ised UTF-8 validator that isn't using ridiculous look-up tables; do you disagree with the article?
C as an ABI can and likely will long outlive C as a language.
It can be added without the cryptorng trait initially and eventually get the trait when the review is done.
I have a lot of public static structs like [this](https://github.com/KillTheMule/nvimpam/blob/master/src/carddata/node.rs#L22), mostly an array of [`lines`s](https://github.com/KillTheMule/nvimpam/blob/master/src/card/line.rs#L11). As you can see in the linked example, the enum contains variants called `Optional` and `Provides`. Is there a way to count the usage of those at compile time? I'd like to ensure the number of `Optional` and `Provides` elements used in an array are below a certain number (say, at most 3), and are actually the same. Is there a way to do this? I guess I could resort to using build.rs in some way, but is there something easier?
FWIW, I've recently built the rust compiler on AWS instances with 96 (!), 36, and 16 vCPUs. Both 96 and 36 vCPUs built in the same time! And the 16 vCPUs one was only 16% slower that than. So really, a beefier machine doesn't necessarily help.
There is a difference from a dual core to a quadcore though. I'm on a 13" macbook pro atm because I do not want to upgrade to the touchbar model and it's painful.
My talk about embedded got accepted, so I'll be there! Unfortunately (fortunately?) I have a friend's wedding I have to attend the next day, so I may not be able to hang around and meet too many people, but still excited!
I just got a hall pass from the wife... the past two were so much fun.
Try `let mut settings = ...`.
Needs a significant amount of '‚ù§Ô∏è's in the posts title ... for distraction. Maybe replace 'Bitter' with '‚ù§Ô∏è's altogether 
Other than fixing the exponential nesting types (or so as I remembered), what made the compiler faster?
 This is my function returning an Iterator: fn iter(&amp;self) -&gt; std::slice::Iter&lt;Player&gt; { let t_slice = &amp;self.players[0..self.no_players]; t_slice.iter() //.filter(|s| s.dead == false) } But I really want to add the commented part, return an iterator over just 'not dead' players. I cannot find a return type that makes the compiler happy for the 'filtered' iterator. My first question is my code returning the std::slice iterator 'correct'? or is there a simpler Iterator 'trait' I should be returning? The second is what type will work for the filtered iterator? 
C as an ABI is only relevant on OSes implemented in pure C. It is not relevant in mainframe OSes, some of the embedded OSes implemented in C++/Ada, Web (WebAssembly), Android (JNI), or Windows (COM/UWP).
Awesome work. The compiler has definitely gotten noticeably snappier recently, especially for regex, which is a nice quality of life enhancement. :-)
Closure types are unnameable. A filtered iterator's type includes the type of the closure. So you can't name a filter iterator that uses a closure. One way around this is to use a function, with the filter function type being something like `fn(&amp;Player) -&gt; bool`. That involves dynamic dispatch, though. You can also box up the closure and return *that* using `Box&lt;FnMut(&amp;Player) -&gt; bool&gt;`, but then you need dynamic dispatch *and* an allocation. In the most recent release of Rust, you should be able to use an anonymised type: `impl Iterator&lt;Item=Player&gt;`. This has no particular downsides provided you didn't need to do anything with the resulting iterator *other* than iterate over it, or use methods defined on the `Iterator` trait.
Lots of little improvements. Some of the ones I've done are here: https://blog.mozilla.org/nnethercote/2018/04/30/how-to-speed-up-the-rust-compiler-in-2018/. I mentioned Alex Crichton's regression fix in the post, which I think sped up some of the other benchmarks noticeably. Probably some other stuff too.
I'll try this as well because I've been meaning to get into the SIMD game. Current impl of `run_utf8_validation` is from https://github.com/rust-lang/rust/pull/30740 btw
How it differs from cargo\-tree?
cargo tree and cargo graph show the dependency tree and graph of the crates that the analyzed crate depends on. Cargo modules show the dependencies of the (sub)modules and usages in the analyzed crate.
Oops. By bad.
I do get annoying "Moz2d replay problem" panics that make it sound like there are still display items rendered with the old engine, though.
You could also have your own type that wraps an iterator, and implement the `Iterator` trait for it, deferring to the inner iterator, like I did [here](https://github.com/KillTheMule/nvimpam/blob/master/src/nocommentiter.rs#L26). I'm pretty happy with this solution, because all the methods are defined on that new type, and I can therefore be sure that I did not forget to filter the result when using the methods.
ABI stability is important to replace C.
It currently says "Updated as of: 5/16/2018, 4:19:29 PM".
Weird. It was April 22 when I asked that, and anything after April 21 didn't work.
I feel a bit bad because I'm pretty sure I've mentioned this before, but is there any long term data for compiler performance? The perf site doesn't seem to go back too far. 
When I started to do some C, I realized how spoilt I was in higher level languages, there was a lot of WTF why problems for me with C. Rust is maybe harder to start with, but I'd say I was happier with it as I had less problems with the actual code working properly and doing what I wanted. IMO C might give an illusion that it's easier, but few months of development in you might better compare the two and see Rust gave the dev a better experience. If you're already quite experienced with C, you know how to develop with it much better and avoid the issues that might catch a newbie by surprise and cause frustration similar to what might be experienced picking up Rust initially.
I also have many problems with the VSCode Rust plugin. I actually uninstalled some days ago. Sometimes it just wouldn't do anything. When it worked it was super slow. And since Rust 1.26 arrived I constantly got messages about cargo being blocked when I tried to run "cargo run", "cargo check" or really anything, because the plugin and RLS where apparently doing something in the background using cargo :(
Is there a summary on why the compiler is that slow to begin with?
Looks like `vis` is private, so just ensure that the only way to create a new `Visibility` is through methods that check the precondition, and you should have all the guarantees you need.
https://news.ycombinator.com/item?id=16960381 has some suggestions.
As I'm currently building an application that uses websockets for RPC at work (using the `ws` crate), and I don't have any experience with websockets other than that; can you elaborate on why you wouldn't recommend it? Any pitfalls/stuff to look out for? So far it is working out fine, but I'm still in the process of refactoring my code a lot in order to create a clean/idiomatic API on the Rust side, so any advice is appreciated!
Did you try https://github.com/rust-lang/rust/issues/39606
Switching from (a rather old) GCC to Clang 6.0 for building LLVM has had a suprisingly large impact on compile times for small crates: http://perf.rust-lang.org/compare.html?start=c8a3ec1ce6dc12f86de39bf5ac55fc2fa38358f8&amp;end=57dc98434eb818733dbc941405fdee59e5c3a023&amp;stat=wall-time It sounds like an easy thing to do but the complexity of cross platform CI this was quite a bit of engineering effort.
I feel like I must be reading the graphs wrong, they all look flat over the last month? 
Did you mean `cargo doc`? :-)
How does uom compare to [dimensioned](https://github.com/paholg/dimensioned), besides being actively updated? I tried using dimensioned a few months ago for a project that has a lot of calculations with obscure units (m^5/N, (Pa * s)/m^3, etc), but couldn't wrap my head around how to extend it in that way. I ended up verifying the equations with a Python script using [Pint](https://github.com/hgrecco/pint) (a very convenient library), then manually translating to Rust. I'd be a lot happier doing everything in Rust, is this sort of thing reasonable to accomplish with uom?
Why does Parity use hardware floating-points? Or is this just a general purpose feature in wasmi which is not used by Parity itself?
`impl Trait` is the preferred solution now, but just to throw something else out there: While you can't name closures, functions *do* have nameable types, and it just so happens that non-capturing closures are coercible to function types of the same arity. So you, in fact, *can* write the return type as-is, though it's a bit verbose: // the function argument is double-referenced fn iter(&amp;self) -&gt; std::iter::Filter&lt;std::slice::Iter&lt;Player&gt;, fn(&amp;&amp;Player) -&gt; bool&gt; { // ... }
&gt; One way around this is to use a function, with the filter function type being something like fn(&amp;Player) -&gt; bool. That involves dynamic dispatch, though. If the function pointer is provably constant and references a function in the same compilation unit, couldn't LLVM use static dispatch instead, or even inline the call?
They're small and the choice of scale isn't great on a lot of them, which makes it hard to see differences in the sub-20% range, which most of the improvements are.
Correct me if I'm wrong, but Rust with it's `repr(C)` should be able to use this ABI equally well
Well rust is a better choice than solidity. But there's nothing like wasting kilowatts of power for a single function call in a smart contract.
One aspect where C is far ahead I think is tooling, like static analyzers and stuff. On the other hand, Rust fixes a lot of the issues those tools address by language design (memory management, null-pointers, UB, ...)
C is more portable than Rust. We will observe more Rust ports for obscure systems like Haiku and MINIX in the future, but for now if extreme portability is a concern, then C/C++ are perhaps more desirable than Rust for now.
It *could*, but I prefer not to get into the "coulda, woulda, shoulda" of optimisers. My philosophy is that if it's not *guaranteed* by the language semantics, it's a nice bonus, but not something you can rely on.
True, precision is defined by the instruction, but you can still cause different values to be generated by changing to round up vs round down, and having precision defined by the control word allows you to increase precision without recompiling your code, since the compiled code only cares about the size when taking it back out of the FPU register stack (which a good compiler will do as little as possible). It's obvious to us that that's not worth the complexity, but I think it's a very understandable choice to make given the circumstances at the time.
I'm curious about the performance impact of NLL, since it shows a poor performance on http://perf.rust-lang.org. I know Niko Matsakis is working on an [alternative implementation of the borrow checker](http://smallcultfollowing.com/babysteps/blog/2018/04/27/an-alias-based-formulation-of-the-borrow-checker/), but he says that it is slower than the currently NLL implementation, with room for optimization. Does anyone know what is the plan for edition 2018? Optimize the current NLL borrow checker or finish/optimize the experimental datalog based checker? 
If you‚Äôre willing to jump up to the 15‚Äù, Apple still sells the pre-touchbar mbp.
That's very unexpected. What platform are you on? Would you be willing to find a regression window using [mozregression](https://mozilla.github.io/mozregression/)? You can enable webrender for mozregression using --pref "gfx.webrender.all:true"
Also, can you reliably reproduce the "Moz2d replay problem" panics?
Is it just the price? Or is there something about the touchbar itself that bugs you?
Is this a compiler bug then? It seems to me that the behavior of a function shouldn't be effected by inlining, but fp is so weird I don't really know.
As a vim user who still hits the escape key the lack of tactile feedback annoys me.
Technically it's a bug in our code to rely on the behaviour of hardware floating-point.
People focus on correctness and getting it working first. Hard to make something fast if it never runs in the first place 1. Make it Work 2. Make it Right 3. Make it Fast &lt;- Rust is starting to be here.
It's not that I wouldn't recommend it, it's that I wouldn't recommend it for general use. Websockets are intended for more persistent connections where data flows both ways, while traditional RPC will typically want a way to fire off one command with low overhead. I don't really know the performance aspect at all, but if you're just doing one off commands, I believe standard HTTP, rest-style, will be more efficient, and typically I think HTTP would be considered to have more overhead than RPC. That said, I do know gRPC is actually based on HTTP/2, so HTTP/2 might be a better candidate for RPC and maybe WebSockets work totally fine. I have not benchmarked or researched the performance aspects of any of these approaches. We use WebSockets because our RPC (which is really more like IPC between a handful of processes because it's all on the same machine) involves a lot of data flowing both ways, so a persistent socket makes sense. If you're already using WS and it's working fine, my opinion shouldn't even be on your radar. 
I think you've made a minor error, in your test code you have literals "0x7fa00000", but in the text you say "0x7fa000000" (an extra zero). The binary representations are also more than 32 digits.
A little insight that might be interesting maybe: This uses the latest master of alacritty, which is slower than the scrollback PR for scrolling. In my benchmarks alacritty is faster than both urxvt and st on the scrollback branch. The input latency is still accurate, however I still think it's not in an awful shape there. The main thing where alacritty shows serious speed-ups over terminals like st and urxvt is my experience is raw throughput, so changing every cell of the terminal (imagine watching a movie in the terminal or something like that).
https://github.com/varlink/rust
I sometimes have to work in a corporate environment and sometimes I need to share files between OSX, Windows and Linux machines. I can't assume for Python or other runtimes to be installed on those machines and sometimes I also need to share big files to many people at the same time. I needed an easy to use and cross-platform tool that would just work on everyone's machines and would solve the issues outlined above. I searched quite a bit for something like that but ultimately came up empty and so I made my own. It uses the awesome actix-web framework and of course Rust. It was really quite a pleasure to work in. Deployment is especially nice with the build resulting in a single binary for each platform.
Thank you for your reply! It seems like our use case does actually fit websockets quite well (more so than RPC) since we are also passing messages both ways over a persistent connection. The main reason I asked for your opinion was mainly that, well, in the past I've often been afraid of asking for people's opinions for fear of being told I'm doing something stupid, so I would just muddle on only to later find out the thing I was trying to achieve could have been done much easier. Only now that I'm working with Rust, and especially with the Rust community being so welcoming and friendly, do I find that I'm actually starting to have the courage to ask questions about programming at all. So thank you very much for providing your opinion anyway :)
Thank you!
I mean yeah, picking up any language comes with surprises, I understand that. I was more getting at: rust, while it lends a better dev experience, has some complicated concepts that are very defficult to explain to a newcommer to programming. C on the other hand is *extremely simple* (as a language). As it stands right now, I'd happily suggest rust as a *second language* (same tier as C++), if be hesitant to recommend it as a first though.
The problem is that indexing into an array or slice is done with an index of type `usize`, while you are providing an `u16`. Casting the result of `people[i]` to `usize` should work, i.e. doing `frequency[people[i] as usize] += 1`.
I am running clippy on CI, so this work around doesn't work for me.
Nah, UBsan is your best friend. Tool assisted C really is an easy language to use üòÅ
I don't think so. Judging by the numbers there may be more tools but not a single one of them is an integral part of the language or part of any standard. The choice of tools may be totally different depending on the OS, the platform and the compiler. There is not even a common build system like Cargo out there. 
You might be interested in this thread https://www.reddit.com/r/programming/comments/8jnb2a/rust_turns_three/dz2askq/
I have a function that takes an `Option&lt;T&gt;` with `T: Serializable`. If I want to pass `None`, I currently use `Some(1).filter(|i| i != &amp;1)`, but this feels very dirty. Is there a better way?
I've got three words for you: [vim foot pedal](https://github.com/alevchuk/vim-clutch).
You really shouldn't use the esc key. It's super far away. Consider binding caps to escape instead (or even better, ctrl when held and esc when pressed). It's a much better setup, regardless of computer.
Why can't you just pass `None`?
I've noticed an improvement even on the stable channel. One project of mine used to do a clean debug build in ~13s, now it's ~7s. Latest nightly is ~4.75s. Nice work!
Keep Rust out of smart contracts. You're going to market safety guarantees that can't be delivered. Contract design flaws can't be Rusted away. 
Currently creating the base of the client side of my game for Android using Rust. Is `ggez` worth it for this? Anything I should know before I go into doing this?
UBsan ... sounds like borrowcks less strict subling, which is happy if you ignore them. Not sure if you should listen to them.
You can just choose any type and write `None::&lt;T&gt;`. For example, `None::&lt;()&gt;` should work. 
&gt; Leave the Features: Take the Cannoli Beautiful
This looks really cool. I'm going to give it a deeper look when I have time available.
Another proud mustang here! :)
because it is not known which type a `None`would contain (but `None::&lt;()&gt;` does the job, thx /u/burkadurka)
thx, thats it!
C as an ABI is about linking, and doesn't have anything to do with OS's. The OS itself only has a syscall ABI, which is not the C ABI. C as an ABI will last for a long time, and is entirely OS agnostic. JNI use the C ABI, for example. WebAssembly might be able to interface with it at some point.
no, efforts here in the past have been very spotty, lots of lost/bad data
As a Rust fan that does C for work, you got this way wrong. C as a language is much simpler and easier to understand than Rust, including the UB's, but it has zero safety-net, so it's also extremely easy to screw up in.
The size of the language. The size includes syntax, features, etc., and can basically be measured as the length of the language specification that explains everything. Rust and C++ are massive languages, while Go and C are tiny. However, that does not mean that C is better than Rust.
Amen. Either limit your problem domain until it can be reasoned about completely, or work with some sort of proof language and only run the programs that can be reasoned about completely. Yes, this is Hard and we don't know how to do it well. I thought this was supposed to be about progress?
cool :))))
Yeah I even contributed a bit to it :) But I find the code generation part a bit difficult to grasp, and I think the API is not super intuitive. To give an example, each packet type you define creates two flavours of the type: a mutable one and a regular one. I prefer the kind of API proposed here: https://lab.whitequark.org/notes/2016-12-13/abstracting-over-mutability-in-rust/
&gt; Although the first edition of K&amp;R described most of the rules that brought C's type structure to its present form, many programs written in the older, more relaxed style persisted, and so did compilers that tolerated it. To encourage people to pay more attention to the official language rules, to detect legal but suspicious constructions, and to help find interface mismatches undetectable with simple mechanisms for separate compilation, Steve Johnson adapted his pcccompiler to produce lint [Johnson 79b], which scanned a set of files and remarked on dubious constructions. Dennis Ritchie -- https://www.bell-labs.com/usr/dmr/www/chist.html [So you think you know C?](https://hackernoon.com/so-you-think-you-know-c-8d4e2cd6f6a6) [What Every C Programmer Should Know About Undefined Behaviour](http://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html?m=1) [Teaching C](https://blog.regehr.org/archives/1393) [Proposal for a Friendly Dialect of C](https://blog.regehr.org/archives/1180) Looks are deceiving.
It is, unless you don't care about writting portable C code to start with.
&gt; ...I avoided using lifetimes (explicitly) like the plague... Hah, I know the feeling. It's often not a bad idea to do this when exploring an unknown problem domains; once you have a grip on the shape of the code you will start to see easy places to re-insert lifetimes. They're often much more innocent in function signatures than in struct's. And, Rust is relatively ~~easy~~ safe to refactor because if you screw something up it just won't compile.
does Rusts cleaner syntax/module system provide more scope for parallel compiling than C++, or are the bottlenecks still in the same places 
`ggez` on Android is... an unexplored domain. The sound library we depend on (`cpal`) does not support it, and graphics is a bit untried. Sad but we haven't had anyone with the expertise and time to change this, though we'd very much like to. See https://github.com/ggez/ggez/issues/70 for the whole story. That said, if you want to put a bit of work into getting it at least minimally working, I'd happily do some of the heavy lifting in terms of chopping out bits until the basics work, and then factoring stubs back in to expand later.
Another way to force the compiler to pick a type can be to just create a dummy bunding, like this: let my_none: Option&lt;SpecificType&gt; = None;
How do you define compiler within this context? What is the result of your compiler? The mentioned speed competitors (CPython and PyPy) are primarily *interpreters* - the *compile* capabilities aren't really special. (apart from the JIT of PyPy, which is of course part of the interpreter) 
There's a reasonable chance you want to use a BTreeMap and the Entry api to store and update frequencies if this is part of a larger project you're working on rather than an exercise to understand arrays: https://doc.rust-lang.org/std/collections/btree_map/enum.Entry.html#method.and_modify
&gt;experimental datalog-based checker So using something like Z3? That's exciting.
Your story is like mine. From https://github.com/cretz/asmble#caveats: "The JVM makes no guarantees about trailing bits being preserved on NaN floating point representations like WebAssembly does. This causes some mismatch on WebAssembly tests depending on how the JVM "feels" I just [exclude the NaN bit pattern check](https://github.com/cretz/asmble/blob/f24342959dacf84023ce1aa3b76b2f89dca34958/compiler/src/test/kotlin/asmble/SpecTestUnit.kt#L22).
At a high level `dimensioned` works mostly at the unit level (meter, second, ...) instead of the quantity level (length, time, ...) although quantities are supported through traits. Both libraries have a similar number of quantities and units defined. Quantities not explicitly defined can be used by both libraries, but it's not very ergonomic in either. `uom` only comes with SI out of the box while `dimensioned` has other systems like [`cgs`](https://github.com/paholg/dimensioned/blob/master/src/build/cgs.rs) and [`ucum`](https://github.com/paholg/dimensioned/blob/master/src/build/ucum.rs). Both libraries support `f32` and `f64` while `uom` also [supports](https://github.com/iliekturtles/uom#features) a number of different integer, ratio, and bigint types (this support isn't completely polished yet). Both libraries also expose macros to allow you to build your own system of units. Both libraries give the same out-of-the-box zero-cost dimensional analysis, but I believe the way `uom` is setup works better once you get past simple examples. `dimensioned` essentially defines `struct SI&lt;D, V&gt; {...}; type Meter = SI&lt;LengthDimension, V&gt;;` where `uom` defines `struct SI&lt;D, U, V&gt; where U: Unit {...}; type Length = SI&lt;LengthDimension, U, V&gt;;` This means that all lengths in `dimensioned` are stored as meters and to use any other unit you must define your own system which is tedious and error prone (note that conversion to/from other units is still easy, it's just storage you can't control). In `uom` the unit is essentially lifted into the struct definition. The default `Length` type uses meters, but you can [easily](https://github.com/iliekturtles/uom/blob/master/examples/base.rs) setup other type aliases. Hopefully I didn't misrepresent `dimensioned` here as I just skimmed the code again today and it's been a while since last looked at it.
Great question! Cannoli compiles Python into Rust, so the resulting artifact is a 'rs' file. It is then further compiled into a binary by rustc. On many of the very small benchmarks the overhead of the interpreters are apparent. So longer running benchmarks were designed to amortize this time. The comparison to the other implementations was included for context but not the point of this work. We were simply interested in how Cannoli compared to the other implementations. The *real* comparison is simply between Cannoli (unoptimized) and Cannoli (optimized) to determine the performance improvements of the implemented optimizations on various features of the language. The unoptimized version of Cannoli actually outputs Rust code that "kind of" behaves like an interpreter. For instance, it has to output logic that manages scope at run time since the translation from Python to Rust is not direct.
From the README: &gt; Cannoli is written in Rust and also compiles Python to Rust. The use of Rust as the intermediate representation was chosen for performance purposes and to avoid writing a garbage collector.
Wait, so this can compile python code to rust which avoids GC completely? Or have I misread it?
Yeah, Cannoli has no garbage collector! Automatic memory management is obtained via Rust's ownership rules and borrow checker. Since Cannoli compiles Python to Rust the resulting artifact is a Rust file and the memory management behaves as it would with any other Rust file.
The compiler already has a soft float library (ported from LLVM), `rustc_apfloat`. We could try to move it into the nursery and publish it on crates.io.
I don't recommend learning both. Learning one language as an undergrad is already daunting. Learning two at once seems like a great way to lose motivation and it's a less often taken path. I'd suggest learning C++, at least the basics, first. There's more material for it, more conference talks, etc. Once you have that down I'd say to at least take a look at rust. That said, if you already know C decently well, you may be in a position to just jump into rust.
Now write a Rust compiler in Python and compile it with Cannoli
The "31m" and "0m" make be think the output is including bash color escape sequences, but xdot doesn't expect them.
code: extern crate rand; use rand::prelude::*; error: error[E0433]: failed to resolve. Did you mean `apt::rand`? --&gt; src/apt.rs:2:5 | 2 | use rand::prelude::*; | ^^^^ Did you mean `apt::rand`? however if I add `#![cfg(feature="std")]` to the top of my file it works fine. why? 
My small amount of testing with LLVM‚Äôs soft float seems to imply that LLVM‚Äôs soft float library has different rounding behaviour to SSE2, and WebAssembly requires the same semantics as SSE2. Our tests fail when compiled with `-C target-feature=-sse2,+soft-float -C soft-float`.
then write a python compiler in the rust compiler that was written in python and compiled with cannoli!
Thx for your explanation. Wouldn't the *modern* term for your work be rather *transpiler*? 
What about Ctrl\+C? I find that superior \(though I do bind my Caps Lock to Ctrl, which just makes all Ctrl commands easier\).
Clickbait title, fizzbuzz has always been implementable in stable rust. It's a simple test to ensure that an applicant can do some *very* basic programming. This is a sane implementation: fn main() { for i in 1..101 { if i % 15 == 0 { println!("FizzBuzz"); } else if i % 3 == 0 { println!("Fizz"); } else if i % 5 == 0 { println!("Buzz"); } else { println!("{}", i); } } } Are there better ways of doing it? sure. The author's version compiles to a smaller binary than this version and is more generic. But it goes far beyond what FizzBuzz is meant to be. As an aside, the repo provided doesn't compile due to an extraneous `io::`.
Does FilePizza also work locally without Internet? If not, it's not really the same use case as the other tools.
So why doesn't this happen on x86_64 ?
"transpilers" have been attested to since the late 70's or early 80's... so, no, I don't think the word "transpiler" is more "modern", and a transpiler is a *type* of compiler, so compiler is still a completely accurate term.
&gt; // don't have assoc. values yet, so us a nullary function &gt; fn id() -&gt; Self; `const ID: Self;` works just fine
Funny you ask that actually, I had this same discussion with my advisor. I feel like both work. From the wiki: &gt; A compiler is computer software that transforms computer code written in one programming language into another programming language. The dictionary definition says "usually to machine code", so it just comes down to a debate over semantics. So yes you could call it a transpiler, but compiler works just as well too imo. 
Holy crap, that‚Äôs sweet. 
Could Canolli be used to teach python programmers rust?
Thanks for the fix! The thing is, FizzBuzzBazz case appears at 105, but if I want to run to 105, I'd have to give the user the ability to specify going up higher. I can't do that with `for i in 1..n+1` because it has an overflow bug
I haven't thought of that actually, but I think it could be valuable. The thesis describes the translation of Python elements into rust so I certainly think that could be a great tool in learning the nuance between languages. The only caveat is that the context is compiled code, so the translation is often not as direct as one would think. For instance, all types are encapsulated in a Rust enum, so translating '1 + 1" from Python to Rust (in this context) requires wrapping the integers and then operating on them. That being said, if one were to consider that while reading the paper, they could ignore that. tl;dr hopefully! haha, I'd love for someone to read the paper and learn more about Rust via translations from Python.
How do you handle cycles? Rust doesn't really do this out-of-the-box (without using any libraries).
IIRC, Ada does this pretty neatly. An integer of type 0..10 added with another integer of the same time, will automatically at compile time result in a value of type 0..20. Multiplication results in 0..100 and so on. Given this, valid values become explicit and automatic compile-time checks employed.
I mean, sure. It's not ANSI C. It's still a tool with tons of users that's pretty effective at catching UB. My point is \*what makes people think C is easy\* is: 1\) How simple the language is on the surface \(that's important. You don't want half your team not fully understanding esoteric syntax or features\) 2\) The robust tool ecosystem that already exists for it.
Interesting piece of work! I've read your thesis and still don't understand how you're avoiding GC. What does Cannoli do to collect circular structures, as in this [Python demo](https://gist.github.com/BartMassey/8eb2ad1faf83afd210f796f037773982)? I'm guessing that you just don't GC Rust `Rc` cycles and let them leak? It's a reasonable choice for this project, but something that production code doesn't get to do. Shouldn't Python slices just be implemented by cloning a slice of the Rust array? That's what Python does as far as I know. Why use iterators for this? Aside from the performance issue, it seems like you might get the wrong semantics.
Do you mean reference cycles, as in multiple objects referring to each other? If so, scope is managed at run time, this is done with hash maps. Types that operate as references in Python are wrapped in [`Rc`](https://doc.rust-lang.org/std/rc/struct.Rc.html) (reference counted) pointers. When those need interior mutability I also encapsulate the type in a [`RefCell`](https://doc.rust-lang.org/std/cell/struct.RefCell.html). When Cannoli scope elements are dropped (go out of scope) the reference count is decreased until the pointer is dropped completely. I'm not sure if Python can get trapped with reference cycles like Java can (e.g. nested classes), but if so then I suppose the compiled code would not free that memory either.
&gt; This is a sane implementation: It's horrible, you're running redundant modulos! Kidding, but seriously I prefer the pattern-matching version, it's just so much sexier: for i in 1..101 { match (i%3, i%5) { (0, 0) =&gt; println!("FizzBuzz"), (0, _) =&gt; println!("Fizz"), (_, 0) =&gt; println!("Buzz"), _ =&gt; println!("{}", i) }; } Look at that case analysis.
&gt; " Leave the Features: Take the Cannoli" Nice one!
Perhaps I am letting the `Rc` cycles leak, I'll have to check the code for this. It took me quite a while to feel comfortable using `Rc`/`RefCell` so it wouldn't surprise me if this was an oversight. Python slices are pretty difference from Rust slices. For instance, a Python list of 3 elements could be sliced as so `some_list[0:5000]` and Python would return you the 3 elements. That's fine, that can be mapped to correct Rust slices, the difficult part came with steps and reversing via slices. So `x[start:end:step]`, having a negative step to reverse the list or stepping multiple elements, etc. Rust's slices doesn't support this functionality as far as I know? I do remember seeing that 'step' was in nightly, but I didn't really explore that any further. I just ultimately fell back to a functional approach, rather than imperative. Although, I do include in the future work section that maybe unsafe Rust could be used here to improve performance, but I'm not entirely sure.
You're calculating the remainder *twice*? Do you have any idea how many cycles that takes?? :P
Could this be interpreted as a compiler bug? Isn't it reasonable to assume that transmuting bits should never flip the bits, and therefore the generated code in this instance is wrong?
Many conferences are well over $1,000 per ticket. I think RustConf is well priced. Hotel and flights are definitely expensive though.
I am continuing my work on SIT [Serverless Information Tracker] (https://sit.sh, https://github.com/sit-it/sit). There are some interesting challenges left at the core of it (such as pinpointing particular subsets of records, indexing/sorting, better support for reducers' external code dependencies, creating C API, etc.), as well as conventions (such as DERP for ultimate upgradeability of records) or "marketing" materials. Rust has been a great language to implement SIT and I even managed to run SIT in browser once (with a bit of fiddling during the build process) which was really amazing!
I'm having kind of a hard time coming up with a reason why you'd want floating point numbers so bad in a smart contract. I mean, I know the financial world runs on Excel, but for transaction processing systems you'd better believe everything is fixed point.
Rust defines `f32` and `f64` to be IEEE754 floating point numbers and this doesn't violate the IEEE754 spec. I don't think it's technically a bug.
Rust doesn't have switch, goto or computed goto. This makes certain kinds of CFGs more difficult to write than in C.
Rust may replace C within the realm of people writing fairly large programs, but I think what's being said is that C itself won't go away. Even if we use Rust and other languages for everything else, we'll still want C for bootstrapping new architectures and inter-language communication.
Mostly to allow more code to run unchanged on the blockchain. It's an acceptable solution to disallow floats entirely (and that's what we're doing right now) but it's a longer-term nice-to-have and it isn't so much implementation effort that it's worth ruling out entirely.
the difference is now the program will correctly EXIT printing an error message before it would overflow and silently exit
FFI question. I need to write a function that takes in a mutable pointer and puts a thing into it. How do I do that? C function signature looks like this: ``` my_bool my_get(my_tbl *t, key_t key, my_value *vp); ``` The function returns a "boolean" signalling if the operation was successful and puts the actual value into `vp`.
My program outputs Fizz Buzz and Bazz for the 7 case, it does more than your version
 let n = u32::max_value(); for i in 1..n.checked_add(1).expect("Integer overflow") { ... } exits with &gt; thread 'main' panicked at 'Integer overflow', libcore/option.rs:619:5 `checked_add` has been available since at least 1.0.0, and is what debug build does under the hood - it panics when overflow occurs. Anyway, I did enjoy the article, I just picked on it because the title was disingenuous. Keep up the good work.
Silent NaNs are and always have been a bad idea. It should be the responsibility of the programmer to avoid computations that don't produce non-numbers, and/or to handle the hardware exception properly when it comes up. This is what I wish Rust did: default floating point operators cause panic on NaN, you need to use a special NaN-handling version if you want to allow NaN results. Then we could have total order on floats and all would be right with the world. It's what Rust does with integers, after all (except it turns off the checks to get better performance in release mode, which frightens me).
There must be a pun, but I don't get it. Can someone give me a hint on this ? :)
You're right, the title is clickbait ^^
It's from The Godfather. The original quote was "Leave the gun, take the cannoli"
The transfers are peer-to-peer, but you'd need the webpage to initiate the transfer, unless you host the software yourself. I wasn't aware that you were specifically looking to send files without an Internet connection.
I don't think the floating-point specification is the issue, the issue is that I think one should reasonably be able to expect this: transmute_to_type_a(transmute_to_type_b(a_value)) == a_value
Are you sure it's never the case that the quiet version lets you vectorize better? I could see it being useful for dealing with extra values off the end when you have an array that isn't exactly divisible by 4 or 8.
Try to use C linking on z/OS, IBM i, ClearPath MCP, Mbed any many other OSes not written in C, without using the *UNIX compatibility layer*.
So the FFI equivalent of that function would be something like `extern "C" fn my_get(t: *mut my_tbl, key: *mut key_t, vp: *mut my_value) -&gt; my_bool` What you'd want to do is declare an instance of `my_value` somehow (i.e. `let mut val: my_value = 0;` assuming `my_value` is an integer value), then you'd pass `&amp;mut my_value` as the 3rd argument to the function. The `&amp;mut` reference will automatically coerce to a `*mut` pointer so you don't have to explicitly cast it.
Your code doesn't meet enterprise level quality standards. This is how you should be writing FizzBuzz: [https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition](https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition)
I was asking about this just yesterday. The answers aren't clear to me. I have avoided profiling and optimizing the current NLL implementation precisely because it's in such flux. The few answers I got to my questions suggested that this is the right thing to do. I too am worried that it will undo (or more) all the recent perf improvements.
The trend will get a little longer every time you go to sleep. 
Oh okay. So in that case your function would receive `vp: *mut my_val` as one of its arguments. You'd first want to check that `vp` is not null, then you'd dereference the pointer and assign whatever value you're supposed to assign to it (i.e. `*vp = 42` again assuming `my_value` is numerical).
Would you be interested in writing a PureScript to Rust compiler? (Or PureScript interpreter in Rust?) So that PureScript + Rust crates could become a power couple like Python + C libraries (with more type safety).
Just saying that you could use associated values today in stable if you wanted.
if I leave out the "std" cfg, I can still get it to work by prepending the use statement with the file name I'm working with: use apt::rand::prelude::*; I'm totally lost as to why though.
&gt; this is done with hash maps hmm... if you're doing this project with an eye towards performance, I'm sure you understand that HashMaps can eat up *all* the performance. Are you using a [fast hash function?](https://github.com/servo/rust-fnv) if you could avoid hashmaps altogether, I'm sure that would help a ton with performance.
It's hard to tell without seeing your `Cargo.toml` and the structure of your project. Perhaps the `rand` dependency is unconditional, but the "std" feature is not on, so when you put in the cfg you actually commented out the entire file. Since you are not at the crate root (`main.rs`/`lib.rs`), yet `use` paths always start at the root (unless you start them with `self::` or `super::`), the behavior you see makes sense. 
Where's Rayon for the fearless concurrency? *Downvoted*
While the normal method certainly works, I was kinda using this library as an excuse to find alternate / less feasible / more fun methods of implementing it. I'll see what I can come up with along that lines, however. Thanks for the response!
That seems to be exactly what I was looking for! Thanks!
Bingo ;)
Would be awesome. Could also lead to checks against division by zero and other logic errors related to "at least 1"-types.
Right now the easiest way to compile code for a custom target is with [xargo](https://github.com/japaric/xargo). It's a wrapper around `cargo` that automatically compiles and links in `core` and `compiler-builtins` based off of your target spec. There are plans to eventually integrate `xargo`'s functionality into the core tools directly, but for now this is what most custom kernel/OS projects have been doing.
Not with IEEE754 floating point numbers, you can't. C\+\+ specifies a minimum of \*strict weak ordering\* for many of the standard algorithms and ordered containers. It turns out that x87 80 bit floating point does not conform to this requirement, and default compiling on g\+\+ with operations on a std::set\&lt;double\&gt; could result in cpu spinning or double deletes, because the ordering was not stable. The lesson here? Don't use the 80 bit fp registers in an x87 \(or 32 bit on x86\_64\) hosted executable.
Yep! Our second optimization was managing scope with vectors. We then directly index those vectors, it was *much* faster. We had some interesting profiles that were showing quite a bit of performance slowdown from hashmap searching/inserting/hashing etc. If you're interested, the section "Optimizations &gt; Restricting Dynamic Code" in the thesis describes the use of vectors over maps. 
Aside from the horrifying optimized memcpy, can you give a good example of switch, goto, or computed goto that can't be easily translated? Unrestricted goto is probably the second most dangerous keyword after null. Most switches are trivially replaced with match, except for those with fallthrough. It's said that premature optimisation is the root of all evil and all three things you mentioned seem like premature optimisations.
I haven't tried that yet, but that would be pretty cool!
Hee hee, here's my version optimized for client code: use std::{ io, io::{ stdout, Write, }, }; fn print_stuff&lt;'w, 'sl, 'st, W: Write&gt;(writer: &amp;'w mut W, n: u32, modulos: &amp;'sl [(u32, &amp;'st str)]) -&gt; io::Result&lt;()&gt; { for i in 1..=n { let mut found_something = false; for (modulo, message) in modulos { if i % modulo == 0 { write!(writer, "{}", message)?; found_something = true; } } if !found_something { write!(writer, "{}", i)?; } write!(writer, " ")?; } Ok(()) } fn main() -&gt; io::Result&lt;()&gt; { let s = stdout(); let mut s = s.lock(); print_stuff(&amp;mut s, 15, &amp;[ (3, "Fizz"), (5, "Buzz"), ]) }
A simple input/output example would be really nice.
I gave an example in [this thread](https://www.reddit.com/r/rust/comments/88h93o/rust_first_impressions_from_a_c_developer/dwl7h0v/).
Legit curious, how so?
I remember seeing somewhere that Rust may be removing the `extern crate` needed. That it's silly to have it since the item is already in your `Cargo.toml` file. Did I imagine this? Is it on nightly? Do I need to enable a flag to get it?
It's a technique that compilers use to replace constant divisors, basically multiplying by their reciprocal. [https://gmplib.org/\~tege/divcnst\-pldi94.pdf](https://gmplib.org/~tege/divcnst-pldi94.pdf)
Why not? I just spent a few hours annoying a group of influential C\+\+ devs by contrasting various issues in a discussion about C\+\+ language proposals and infrastructure/ecosystem against Rust and Cargo. Not everybody heavily involved in the evolution of C\+\+ is salty about Rust. The bitterest of bitter C\+\+ devs are bitter about cruft from C and early C\+\+. Maybe a little bitter about the takeover of the programming world by GC languages, weakly typed or typeless languages, etc. Rust is viewed, for the most part, as either a curiosity, an unproven but intriguing newcomer, or an example of what C\+\+ could be if it didn't have its massive legacy \(for better or worse\). That said, subject line aside, this seems to be fairly off topic for C\+\+ 
&gt; I do remember seeing that 'step' was in nightly, but I didn't really explore that any further. I just ultimately fell back to a functional approach, rather than imperative. Although, I do include in the future work section that maybe unsafe Rust could be used here to improve performance, but I'm not entirely sure. You could always just copy-paste the [standard library implementation](https://doc.rust-lang.org/src/core/iter/mod.rs.html#680-684) into your project if you need it on stable. You'd have to remove the call to `intrinsics::likely()` because it's unstable, but that's just an optimization AFAICT. 
As someone who doesn't do a lot in C or C++, the idea of jumping directly into the middle of a loop makes my head hurt. Does it skip initializing the loop counter? In the particular example, is all it's really doing is starting one element ahead, or does it skip the loop completely?
This is great! Very good idea, I hadn't thought of this, thank you :)
That's nothing compared to: * Taking the standard output lock every iteration. * Trippling the binary size with all that formatting and function call boilerplate repeated on every branch. use std::io::stdout; use std::io::Write; let out = stdout(); let mut out = out.lock(); let mut num; for i in 1..=100 { out.write_all(match i % 15 { 0 =&gt; "FizzBuzz", 3 | 6 | 9 | 12 =&gt; "Fizz", 5 | 10 =&gt; "Buzz", _ =&gt; { num = i.to_string(); &amp;*num }, }.as_bytes()).unwrap(); out.write_all(b"\n").unwrap(); out.flush().unwrap(); } 
I think language writers tend to prefer the term "source-to-source compiler" because it has a more well-defined meaning than "transpiler". A transpiler is supposed to target a "high-level language", but there isn't all that much consensus on what that means *exactly*. Many people consider languages like C or Rust to be "low-level languages", and it's not clear that a compiler targeting them would be considered a "transpiler". OTOH, a source-to-source compiler creates human-readable text, whether that's JS, Rust, assembly, or whatever, which is much more well-defined.
From the sibling answers, it has almost as much of a GC as CPython: reference counting. Though it sounds like this doesn't have CPython's cycle collector to clean up reference cycles.
Exactly my thoughts. Always go for the simplest implementation.
Yes, it skips the initialization. Just imagine the loop desugared into a backwards goto. You can play with it [here](http://coliru.stacked-crooked.com/a/d06be765d2a0acb0).
ligatures in code fonts kind of defeat the purpose of using a monospaced font. makes the excerpts a bit harder to read
This is a great question and I was surprised it didn't happen on both since it's not like x86_64 can't use x87 instructions. Best guess: it's a compiler choice. Intel introduced SSE instructions in 1999 on the Pentium III. AMD incorporated Intel's SSE extensions in the Athlon line in 2001 for 32-bit but not all 32-bit chips support it. The AMD64 spec was released in 2000 and included extensions to Intel's SSE instructions, indicating that they had given up on 3DNOW! for a while and accepted SSE. AMD Opteron in 2003 included SSE support according to the spec and so have all Intel releases. Therefore AMD64 indicates SSE support and therefore XMM registers that can be used in place of x87 and the FPU stack. Why avoid x87 at all? Denormalized floating point numbers incur huge performance penalties on many microarchitectures (sometimes around a thousand times slower) so x87 is avoided if possible. Intel has some issues with denormal performance even with SSE, some slowdown on Core 2 and Sandybridge for certain operations but always better than x87. So there's really no reason to use x87 unless you either need the extra precision or you need far reaching backwards compatibility. For x86_64, compatibility isn't an issue so precision is the only reason. The Rust compiler uses LLVM for the backend which prioritizes compatibility over performance unless told otherwise and so I'm sure it makes that choice for the Rust frontend. I bet on a 32-bit machine with SSE support, using `-march=native` it would make the same choice. 
So when I said "soft float" I was referring to the library a compiler uses to e.g. constant-fold float operations, *not* a runtime support library for soft-float. I don't know what `-C soft-float` does but it can't be APFloat (because it's allocation-heavy; although the `rustc_apfloat` port isn't), it likely involves a completely different soft-float library. LLVM's APFloat and `rustc_apfloat` have more controls than most users need, and the latter should even work in no-std environments, but its API could use some polishing.
The 4 byte code points are not any worse than the 3 bytes. A constant value check on the first byte \(\&gt; 0xEF, \&lt; 0xF5\), a conditional check on b0 == 0xF4 for b1 \&lt; 0x90, and the usual check on the other three \(\&gt; 0x7F, \&lt; 0xC0\) and a mask check on the first two bytes \(\(\(0x07 &amp; b0\) \+ \(0x30 &amp; b1\)\) != 0\) and you're good. The headache is just as big in the 3 byte code points, thanks to UTF\-16 surrogate pairs. First byte is in the range \(\&gt; 0xDF, \&lt; 0xF0\), same mask check \(\(\(0x0F &amp; b0\) \+ \(0x20 &amp; b1\)\) != 0\) and a check when b0 == 0xED for b1 \&lt; 0xA0. In other words, if there wasn't a nasty compromise inherent in UTF\-16, UTF\-8 validation would be faster. Back when I implemented this in integer registers \(maybe fifteen years ago\), I actually used an offset\[256\] to an address of the first instruction for processing the next n entries, hard coded to the above rules. There was really no difference for a 1 byte and 4 byte code point...
FWIW, I once wrote this clone of `python -m SimpleHTTPServer` using rocket to share files over LAN because python's server was very slow: #![feature(plugin)] #![plugin(rocket_codegen)] extern crate rocket; extern crate rocket_contrib; use std::path::{Path, PathBuf}; use std::fs; use rocket::response::{NamedFile, Responder}; use rocket::response::content::Html; use rocket::{Request, Response}; use rocket::http::Status; use rocket::config::{Config, Environment}; fn list_dir&lt;P: AsRef&lt;Path&gt;&gt;(dir: P) -&gt; String { let dir = dir.as_ref(); let rows = fs::read_dir(&amp;dir).ok().map_or_else(|| "error reading dir".to_string(), |x| x.filter_map(|e| e.ok()).map(|entry| { let abs_path = entry.path(); let rel_path = abs_path.strip_prefix(dir).unwrap(); let path_str = rel_path.to_string_lossy(); let url = path_str.to_string() + if abs_path.is_dir() { "/" } else { "" }; format!(r#"&lt;li&gt;&lt;a href="{}"&gt;{}&lt;/a&gt;"#, url, url) }).collect::&lt;String&gt;()); let dir = dir.to_string_lossy(); let dir = if dir == "." { "/".into() } else { dir.replace('\\', "/") }; format!(r#" &lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN"&gt;&lt;html&gt; &lt;title&gt;Directory listing for {}&lt;/title&gt; &lt;body&gt; &lt;h2&gt;Directory listing for {}&lt;/h2&gt; &lt;hr&gt; &lt;ul&gt; {} &lt;/ul&gt; &lt;hr&gt; &lt;/body&gt; &lt;/html&gt; "#, dir, dir, rows) } #[get("/")] fn index() -&gt; Html&lt;String&gt; { Html(list_dir(".")) } enum PathResp { File(PathBuf), Dir(PathBuf) } impl Responder&lt;'static&gt; for PathResp { fn respond_to(self, req: &amp;Request) -&gt; Result&lt;Response&lt;'static&gt;, Status&gt; { match self { PathResp::File(path) =&gt; NamedFile::open(path).ok().respond_to(req), PathResp::Dir(path) =&gt; Html(list_dir(&amp;path)).respond_to(req) } } } #[get("/&lt;path..&gt;")] fn path(path: PathBuf) -&gt; PathResp { if path.is_dir() { PathResp::Dir(path) } else { PathResp::File(path) } } fn main() { let config = Config::build(Environment::Staging) .address("0.0.0.0").port(8000).finalize().unwrap(); rocket::custom(config, true).mount("/", routes![index, path]).launch(); } It works but for some reason I couldn't download large files (e.g. linux iso) because the download always got interrupted. Also due to the nature of rocket, it doesn't work for files starting with a dot, e.g. `.gitignore`. Does anyone know how to fix both issues? :)
Bit of an odd question, in my opinion. I'd say you could do without any one of these in particular and it'd still be a great language, but removing more than 2 or 3 of these and the language wouldn't really make sense or be cohesive anymore. My quick pitch about Rust is that it's one of the fastest languages out there, it can do everything that C can do, it's extremely modern-feeling, and it feels more like a scripting/functional language. Not really sure how to answer the question in a way that might satisfy you.
FEARLESS CONCURRENCY!
Very nice! Btw, does it also support `#include`s with paths, like `#include &lt;foo/bar.glsl&gt;`? If one wants to have a fast edit-run cycle, e.g. refreshing the tree every second, one would also want to prevent recompiling the shaders when they haven't changed. Of course it can be done by comparing the shader string with the previous one, but it would be nice to have this built in, e.g. with a method `refresh_render() -&gt; Option&lt;&amp;str&gt;` that works like calling `.refresh()` and `.render()` but returns `None` if the shader source hasn't changed.
Btw, this reminds me of the work that /u/phaazon_ has been doing with warmy (using the notify crate to auto-reload resources, like shaders) and cheddar (higher level shading language that has imports and compiles to GLSL). (cheddar is part of his `spectra` crate, btw.)
It does support paths! You provide a set of include directories to search for paths when constructing the tree. You can accomplish what you describe by checking the expired() method. In the tiled renderer script I link in my OP there‚Äôs a loop that uses this and only recompiles the shaders when they have changed on disk.
OK, so the loop counter isn't local and gets stored in the object. [I managed to write an implementation in Rust that does the exact same thing, but in a different way.](https://play.rust-lang.org/?gist=caadbdb586ead2a6394297757ed0d50d&amp;version=stable&amp;mode=debug) This is without generators and it came to the exact same length with or without replacing loc with an enum. Granted that's including the `#include` directives which weren't needed in the Rust version. From what I can tell, generators should work in a way closer to what you have there, but they're fairly new and I'm not familiar with them.
Ah nice. Btw, I know someone who would be interested in using selva for making gifs for the Animated GIF competition at Revision demoparty using shaders..
Big things: DNS-over-TLS support in the Resolver and upgrades to the new `tokio` libraries. Thank you!
The fact that I can use a safe and modern language in a bare metal environment.
Does this library still work properly if the string contains utf-8? Would it mismatch a utf-8 codepoint while looking for a specific ASCII?
Have you taken a look at Mark Dufour's MsC thesis http://mark.dufour.googlepages.com/shedskin.pdf Shedskin is an amazing project that does full program type inference and converts an implicitly typed Python program to C++. Don't get hung up on the C++ target, it easily could be *anything* once the type inference is done.
Go Cal Poly Dollies! 
If I do that, I get `cannot borrow 'settings' as immutable because it is also borrowed as mutable`
If you're planning to use tokio for that site, would you happen to be interested in collaborating on https://github.com/tene/tokio-serde-msgpack with me? I'm not at all confident that I've got a good general-purpose API here, just what's happened to be convenient for one little personal project so far, so I'm very interested in additional use-cases.
ML heritage with good performance 
That's one of the magic things of UTF-8: it is "self-synchronising", which means, there's no way to misinterpret substrings/offsets of a valid stream as something other than what was originally encoded. This means that, among other things, ASCII bytes don't appear within the encoded form of any non-ASCII characters: an ASCII character is encoded a single byte with the highest bit 0, and the bytes of everything else have their highest bit 1.
What is the difference with [https://github.com/TheWaWaR/simple\-http\-server](https://github.com/TheWaWaR/simple-http-server) for instance?
You can always write any CFG with only structured control flow. A general outline is to number the basic blocks and write a FSM loop { match step { basic_block_number =&gt; { // basic block goes here step = // number of the next basic block to execute continue; } ... } } but this is not code a human should write. This will be much less readable than gotos (and perhaps slower). Arguably it is even less structured than the goto: the fact that your code is a loop is not at all obvious, while the C++ used a proper `for` loop and it's not matter to change it slightly, by inserting a simple `continue` or another suspend point, while to do the same in your code would require much more work. re generators: I addressed that extensively in the thread I linked.
From what I can see: Almost no difference, except that that one actually has more features. Thanks for showing me that.
I have no clue about the performance but for my usage \(small files\) it works great.
Spot on! We [assert that none of the incoming bytes happen to be non-ASCII](https://github.com/shepmaster/jetscii/blob/a9cc1c2670803a79337f8d5082242acc805a8dcd/src/lib.rs#L269-L271), but otherwise rely on this highly useful property of UTF-8.
Thanks for the post! Since my original post to the User's Forum, I've also re-added the `Substring` type. I've [added a reply](https://users.rust-lang.org/t/jetscii-now-works-with-future-stable-rust-1-27-0/17426/4?u=shepmaster) with that documentation.
No garbage collection, no manual memory management. No leaks.
C python contains both a compiler and an interpreter
That's pretty neat, actually awesome. You mention inheritance, exceptions and parts of the stdlib aren't supported right now. Are there plans to support these? I'm also curious, as I haven't had time to read through the source yet, if annotations and third party packages are supported. 
Is the allusion the reason for the name, or is the name the reason for the allusion? I've been sitting here wondering why you'd name it Cannoli with no obvious connection to either Rust or Python.
Mostly unrelated, but what kind of black magic is `intrinsics::likely()`? It looks to me that it's taking a boolean and telling you whether that boolean is likely to be true... which seems unnecessary because you've already computed the boolean to pass it into the function? I understand the basic concept of branch prediction, but I've never done any super-low level stuff and don't get what I'm looking at.
&gt; If you parallelize, you'd have to keep per thread caches otherwise you have a high synchronization overhead Was this tested? Sure, there's some sync overhead from having a unified cache but it should still beat single-threaded latency. Recomputing everything per-thread is really bad, as the increased use of memory bandwidth will cause contention anyway, and for heavy compile jobs the extra CPU utilization will cause the package to throttle a lot earlier. This is not something that time(1) can measure easily!
Wait, why does this line work? ``` _ =&gt; { num = i.to_string(); &amp;*num }, ``` I would expect a "borrowed value does not live long enough" error on returning the reference.
Thank you :), means a lot! As far as future support, it's hard to say really. I certainly hope development will continue but Cannoli is very much a research project in its current state. Quite a bit of work would need to be done to implement inheritance and especially exceptions (since there isn't really a direct translation into Rust). However, I think Cannoli would be well suited to function like [Jython](http://www.jython.org/) and [IronPython](http://ironpython.net/) whose goal is to integrate the Java and C# environments, respectively, into a language like Python. Annotations are currently supported for classes. Annotating an object with it's respective class will yield performance improvements because optimizations were implemented for this case. Other type annotations wasn't supported due to time, but is left as future work. Third party packages are also unsupported for similar reasons.
It just returns its argument directly, and one valid implementation would be `fn likely(x: bool) -&gt; bool { x }`, but it's designed to be a hint to the optimizer suggesting that it should believe the boolean is usually going to be true, and so it should optimize for that case. One instance of what it might influence is code layout, e.g. it's good to keep commonly executing code close together for good caching properties. Imagine one has ...before... if x { ...then... } else { ...else... } ...after... It might get compiled to (in pseudo assembly): ...before... jump_if_true x, then_branch else_branch: // x is false, and execution fell through to here ...else... jump finish then_branch: ...then... finish: ...after... But this is possibly suboptimal if `x` is usually true: it might be better to have that code close to the `...before...` code, and using `if likely(x)` will help the compiler decide to flip the branches: ...before... jump_if_false x, else_branch then_branch: ...then... jump finish else_branch: ...else... finish: ...after... This particular transformation also helps the branch predictor: when predicting a branch for which there's no saved state, it will predict that a forward jump isn't taken. The jumps above are forward, so the first example will predict that the `else_branch` will execute, however this will usually be wrong, if `x` is usually `true`. However... these are very-very-micro optimizations, even without the annotation, the branch predictor will likely quickly catch on to `x` being usually true, and the `then_branch` will probably end up in cache if it's a hot piece of code. So, `likely` is almost always unnecessary and not really something one has to think about unless eking out that last little drop of performance.
&gt; It looks to me that it's taking a boolean and telling you whether that boolean is likely to be true... The opposite ‚Äì you're telling the compiler that the boolean is likely to be true. The return value is just whatever it's passed.
Yes, there's already a PureScript to C++ compiler (apart from the PureScript to JS compiler). The [PureScript to C++ compiler](https://github.com/andyarvanitis/purescript-native) generates inefficient C++ though, because it uses the Boehm GC. So there is a lot of room for improvement to eliminate garbage collection in the resulting code and most uses of GC could be eliminated. When compiling to Rust, one could probably go with no-Rc by default and use the [im](https://crates.io/crates/im) or [rpds](https://crates.io/crates/rpds) crates for structural sharing without cloning, to preserve the move semantics of PureScript without copying so much.
Really cool and informative, thanks.
That does seem to be a common pattern in software: Name it after the closest object, hah hah.
I like how it prevents me making mistakes and performs really well(memory/speed)... So uhh..Rust is supportive of my needs as a developer, I can count on Rust, I'm not paranoid or stressing about the code doing something behind my back that I don't know about :)
So does PyPy and all other common python interpreters üòâ As I said are the capabilities to compile python source to byte code nothing really special. The challenge resides on the *execution* site. 
I didn't know that; can't remember that during the late 90ies and 2000th I ever heard that term. Perhaps it had some kind of *dark age* and got rediscovered by the JS hype? Thx for your comment anyways - always good to learn something üòÉ I know that a transpiler is also a compiler, but a more specialized term for a subset of compilers. So my - obviously misunderstood / misinterpreted - question targeted the decision why to chose the common term for the title? Often it is just a personal taste, sometimes it's also a bit strategic. 
Portability. Rust can run on anything and should ultimately be the fastest and most reliable choice on every platform.
It could be good and bad :), for this thesis it was pretty harmless. If anything comes from this I hope it'll bring more awareness to the pastry itself, cannoli are damn delish and more bakeries need to make them.
Congrats Ben!
Thanks, Steve!
Guiding me to write better code through several language features.
Error handling.
This says nothing about the atomic version, of course, but [`std::collections::VecDeque`](https://doc.rust-lang.org/std/collections/struct.VecDeque.html) is already a growable ring buffer.
In case you have type annotations, wouldn't it in theory be possible to skip the encapsulation, since you know, what the type is going to be?
Yes and no. So theoretically, if every single variable/parameter/etc. was annotated and we knew that at compile-time, then encapsulation could be skipped almost entirely (although there would be a lot more logic to generate to resolve operations between types). If we take a more local approach and annotate a function, then we can unbox the values at the beginning of the function and then box the results at the end. In the "Future Work" section of the thesis paper I address something similar to this. Knowing the type of a variable via annotations would, at the very least, allow unboxing inline. Cannoli currently generates code to call Cannolib (its standard library) to handle unboxing. Further optimization could then take the aforementioned local approach and try to unbox a value for a given lifetime. This aspect of Python is very rich for analysis, we definitely considered this for the thesis but cut it for time. I'd love to see results on this though if the future work gets completed.
Thank you. This got me further. However now I have a different issue now. ``` #[no_mangle] pub extern fn my_get(t: *mut my_tbl, key: key_t, vp: *mut my_value) -&gt; my_bool { let hash = unsafe { &amp;mut *t }; match hash.get_mut(&amp;sym) { Some(val) =&gt; { unsafe { *vp = *val }; // ^^^^ cannot move out of borrowed content TRUE } None =&gt; FALSE } } ``` `hash` is a `HashMap`. I understand why this would happen when I use `hash.get`. I thought `mut` should let me consume the value but apparently not. How can I make it work?
So... it seems like you're borrowing `settings` immutably when you do `let distro = settings.get_distributions()`. You could isolate `distro` and its uses inside a block, like this: use std::error::Error; use settings::Settings; pub fn remove(name: &amp;str) -&gt; Result&lt;(), Box&lt;Error&gt;&gt; { let settings = Settings::get()?; { let distros = settings.get_distributions(); distros.iter() .position(|d| name == d.get_name()) .map(|p| distros.remove(p)); } settings.set()?; Ok(()) }
The changes to `extern crate` are not finished yet. You can look at https://github.com/rust-lang/rust/issues/44660 to follow the implementation of it. It seems like they're close to finishing it, so hopefully we can see it on nightly soon.
Types can maintain invariants without excessive locking. Similarly the semantics of references allow local reasoning about about how the state of a value changes because you're guaranteed no interference from other code.
Thank you!
Thank you, I will look into it
The variable is created (and scoped) at the loop's toplevel, so the borrow is valid until the end of the loop body as long as there's no re-binding of it.
Thanks for the detailed reply! That's a fair analysis of `dimensioned` , at least from what I can recall. After browsing the `uom` source a bit it seems feasible but a bit time consuming to port my project, as we have \~10 SI based units not currently available. I suppose we would need to fork and add them to src/si/, or maybe the `quantity!` and` system`! macros can handle that?
The fact that all of these features co-operate so beautifully 
A `cargo modules cycles` sub-command sounds like really useful potential addition to `cargo modules`! Would you mind creating an issue on Github describing the requirements you would have for such a sub-command?
I don't know if I am or not as I'm still planing it out. I would love to collaborate but to be honest my rust knowledge is still pretty basic, the most complicated thing I've built has been my [Wercker build status](https://github.com/thermatix/wercker_build_status) tool. Still if you're fine with that then I'd be happy to collab where I can.
Thank you!
You can certainly use the C ABI on all those OS's, and any OS not "written in C". The C ABI is *only* a contract between the two items being linked together. The OS is not involved at all, and strictly speaking, nor is the linker. The linker just deals with "symbols" in object files, not their calling convention.
It seems that optimizing canolib to use `FnvHashMap` would be a worthwile low-hanging fruit. The default hash function is really slow.
How can I send an UDP packet to a given interface under Linux ? Context: I have several ethernet interfaces with Link\-Local adresses and routes, so they are all 169.254.something and have the same mask, route, broadcast address. So I can't choose which one will send the packet using Rust's std `UdpSocket`.
How? I would have my compiler emit code with C calling convention, which would run absolutely unhindered. The "mainframe OS ABI" is just a kernel ABI, and in turn has nothing to do with the application-level "C ABI". The "UNIX personality" is similar to Windows' Linux emulation layer, which is about about pretending to have a different kernel ABI, and is entirely irrelevant from an application linking perspective. Any application running on any environment, including z/OS native environment, is free to implement whatever application-level ABI they want. When they wish to say hi to the kernel, they must abide by the kernel ABI. However, application-level ABI's and kernel ABI's have nothing to do with each other, and kernel ABI's are not related to C at all (at C API level, libc acts as a translation layer between the two). (Strictly speaking, C defines no ABI, and what we refer to is just the ABI that compilers generate by implicit convention when compiling C on a platform.)
Trying this solution with FizzBuzzBazz, I didn't manage to get the rightful matching order, I always end up with a few *warning: unreachable pattern*.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [What is your favorite Rust feature? Zero-cost abstractions, move semantics, guaranteed memory safety, threads without data races, trait-based generics, pattern matching, type inference, minimal runtime, or efficient C bindings?](https://www.reddit.com/r/rustjerk/comments/8kbxpj/what_is_your_favorite_rust_feature_zerocost/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I strongly disagree. There are *many* things wrong with C++, a lot of which Rust is designed to fix or improve on. There's also things wrong with Rust, Go and C, and I'm still going to use C++ for a long time to come for work, but claiming nothing is wrong with it is just flat at wrong. If you need examples, just go look up the stupidity that is exception specifications, which have no compile-time checks and just abort the program at runtime if an unspecified exception is thrown.
so you stick with random?
I see this guy in programming subreddits constantly just being an asshole. What is your motivation here?
Username checks out
The fact that it allows me to do many of the same things I can use C for, but it always forces me consider every detail that is important. Everything that I have to consider for my program to be correct, robust, and fast, is made clear and obvious by the language. This makes for a very pleasant programming experience. I can focus on thinking about how to express my ideas, rather than spending effort on making sure not to shoot myself (or future me) in the foot.
What's the problem with the accepted answer ?
What's the rationale for not having implicit integer widening?
`usize` is not guaranteed to be wider than `u16`.
What does Rocket have to do with files starting with a dot? I don't understand that one. :-)
\+
Is there any particular reason you use `(&amp;[T], &amp;[T])` as a return type in some contexts and `[&amp;[T]; 2]` in others?
You're looking for /r/playrust. Have a nice day!
Adding missing quantities/units is really easy. [Here](https://github.com/iliekturtles/uom/commit/18fa6094806d7c168cc67d3ce11f7732446952d3) is a recent change adding new units and [another](https://github.com/iliekturtles/uom/commit/1719a48acc962302e0f869470105719f1dd3a9e3) adding a quantity. Submit issues for the missing quantities/units you need or just list them here and I can submit the issues. Once they're added into `uom` everyone gets the benefit and no need to fork. You also mentioned obscure quantities. Below is an example of how to create an instance of a quantity that isn't explicitly setup. /// Gravitational constant, 6.674√ó10^‚àí11 m^3‚ãÖkg^‚àí1‚ãÖs^‚àí2 const G: uom::si::Quantity&lt;uom::si::ISQ&lt;P3, N1, N2, Z0, Z0, Z0, Z0&gt;, uom::si::SI&lt;f64&gt;, f64&gt; = Quantity { dimension: PhantomData, units: PhantomData, value: 6.674e-11, };
Well, the z/OS C and C++ compilers rather do otherwise. [z/OS Language Environment Writing Interlanguage Communication Applications](https://www-304.ibm.com/servers/resourcelink/svc00100.nsf/pages/zOSV2R3sa380684/$file/ceea400_v2r3.pdf) 
Maybe so, but I guess since the language predated the game, they couldn't have predicted the namespace conflict.
When anyone shares a new capability with an open source community, be prepared to explain why it ought to be used rather than something that already exists. 
I realized recently that not having function overloading is actually a really nice thing, it only takes five extra seconds for the writer to come up with a good name, but during reading the code it's much easier to figure out which function is actually called, especially when there are multiple function aeguments.
I've read somewhere that the x86_64 ABI requires floating point numbers to be passed via SSE registers, so maybe that's why it doesn't show up on x86_64?
If you're talking about `noexcept` then I think you're misinformed. A `noexcept` can absolutely be checked by the compiler - `noexcept(true)` will allow the compiler to omit elide any exception handling instructions the programmer may have added. The terminate behaviour is exactly what you want in this scenario. It guarantees safety by not allowing the program to continue, much like a Rust panic. You could've pick much better examples of C++'s flaws, such as uniform initialization, unless you're initializing a `vector`, or the fact that language features (such as structured bindings) rely on the stdlib.
IIRC it might well be that this behavior is specified by the platform ABI. For example, the x86_64 Itanium ABI might require floats to be passed via SSE registers, which means that the bug can't happen there. If the x86 ABI requires floats to be passed via x87 FPU registers, then you are guaranteed to get the bug on x86, and IMO Rust current behavior is unsound. You should fill an issue in the Rust repo, if the behavior is unsound Rust could insert asserts! in debug mode that check for floats "changing silently behind your feet" when passing them through a function ABI on x86 targets. An assert would have saved the OP a lot of work.
&gt; `Option::take` moved the right child of the node out of its `Option`, replacing it by `None`, and later the same right child would be overwritten by `split_pair.0`. But in that assignment, the right child has to be dropped, even though it is `None`. Huh, LLVM really should be able to optimize that drop away. Maybe look at the LLVM IR instead of the raw assembly to see what's going on?
I haven't tested this. The memory bottleneck you talk about may actually exist.
yeah, even though I don't think it is duplicated. Anyway, I managed to make it work. At first I got it to work like so: #[no_mangle] pub fn simple_arr() -&gt; *const i32 { let vec = &amp;[100, 200, 300, 400]; vec.as_ptr() as *const i32 } and somebody said that it works only accidentally. And then I changed my code to: #[no_mangle] pub fn simple_arr() -&gt; *mut i32 { let vec = Box::new([100, 200, 300, 400]); Box::into_raw(vec) as *mut i32 } which kinda makes sens. Whowever I don't understand why the first example works.
Just looked it up and you are correct that the x86_64 ABI guarantees floats to be returned in xmm0 since all x86_64 microarchitectures support SSE (didn‚Äôt check Itanium). I can‚Äôt find anything saying the x86 ABI guarantees returning floating point values with the FPU stack just that st1 to st7 must be popped for function returns under some calling conventions, leaving st0 allowed for returning floating point values. So I think if you compiled with native optimizations on a x86 chip with SSE support it would use xmm0. 
Definitely going to take a look at this. I've been working on a project with a Qt frontend and Rust backend, but things have been slow because it's the first time I've ever used C++. Being able to write more of the code in Rust would speed things up quite a bit.
The IR has plain calls to drop_in_place, and obviously chooses not to inline them, since they're still there, which is actually a sensible choice... I guess it can't or won't decide to partially inline it.
It is recursive, so cannot be inlined.
I'm glad this was highlighted as I think it is actually a compiler problem: https://www.reddit.com/r/rust/comments/8jbjku/comment/dyzvopc
For now yes, until sometime soon^^TM a feature called "non-lexical lifetimes" lands in stable. This will make the borrow-checker smarter in situations like this these.
Thank you for this! It might be very useful for me. I have a WIP Qt5 application that I was writing a long time ago, which I abandoned, because my C++ code was getting quite ugly and messy and I didn't like how the project was going. I am currently working on rewriting that project. I am now implementing most of it as a Rust backend library. Right now I am making a Terminal-based UI frontend (based on the Cursive crate) for it, which will do, although a proper GUI would be nicer. I was thinking of maybe doing something web-based, but now that I know about this project, I might consider making a GUI frontend with Qt (possibly reusing the GUI stuff from my old application)!
Obviously, I'm quite excited by the news that /u/llogiq has had success working with Criterion.rs. I did want to respond to a couple of points though: &gt; the defaults are pretty solid for running your own benchmarks, but too heavy for a CI, so I had to reduce warmup and measurement time and the number of resamples. Could you elaborate on what the use case is for actually running the benchmarks in a cloud CI environment like Travis or Appveyor (as opposed to simply compiling them with `cargo build --bench`)? Even with Criterion.rs, it's typically best to do actual benchmarking on a known machine. I might be able support the CI workflow better if I understood that use case more. &gt; Perhaps Brook should introduce a compatibility layer that allows bencher-benchmarks to run with criterion unchanged ‚Äì this would allow folks to cheaply test before switching. That is a fantastic idea, and I wish that I'd thought of it before now. Thanks!
In your linked comment, you mention that you managed to unroll the recursion into a loop, but I thought I'd try that and the borrow checker would constantly bite me. How do you do that?
I don't think the partial inlining pass is run by default.
Essentially the same trick as in https://stackoverflow.com/a/27083650 of moving the "current" borrow into a temporary before overwriting it.
Enhancing a tutorial I wrote about performing [linear regression in Python using statsmodels](https://datatofish.com/statsmodels-linear-regression/)
Easily trait-generics and Rust's sum type enums. Those two alone are reason enough for me to use Rust. 
I'm afraid I got this wrong - where do I put the RUST_TARGETPATH=$(home/documents/compiler-builtins) ? Do I just plop it in the cargo.toml? it doesn't seem to work with it as my part of the command line 
That's an intentional leak, however, as compared to forgetting to free a variable, so I think his point still stands.
I was talking about "throws", not noexcept (which has been deprecated with C++11, which took quite a long time to get full support for). It implements only a runtime check that aborts if a different exception is thrown (specifically, it calls std::unexpected, which can be overridden but defaults to std::terminate). There are many examples, most probably better‚ÄîI just pulled one out of the hat, as 1 "thing wrong" is an infinitely larger amount of things wrong than "nothing". I think there are plenty of existing sources if you are searching for a comprehensive list.
Is there anything in particular in this 300 page document that you wished to refer to that would somehow disprove that an application can use whatever ABI it sees fit? It seems to mostly concern itself with language interop through magical compiler flags and #pragma's, but I must admit that I do not feel like reading a 300 page IBM manual unless I absolutely have to.
oh nice, i didn't know there is a github mirror
Sure then. No leaks unless gun applied to foot.
+1 on trait-based generics. Rust stacks OOP-like features on top of a C-like language in the perfect way.
Ah, somehow I missed that. I've been in dynamic language land too much lately; my brain was completely okay with the missing `let`.
Will rustconf have scholarships this year? 
You can leak in GC languages too though and people still call them memory safe and managed.
Hah, that's basically what I've been working on, too, but I've been making it use vector graphics rather than in-termimal. My code is probably fairly verbose and ugly (I'm not an expert using rust by any means), but feel free to look at it to get some ideas if you want https://github.com/Oozekip/rust-games
You're very welcome; I see you've already opened an issue. Regarding CI: We mainly use it to ensure the benchmarks run at all and don't regress too much (though this is currently checked by eye, allowing a configurable threshold percentage for execution to return a failure value would be cool ‚Äì hey! Another idea! üòé).
There is still no guarantee about leaks, and while probably not as easy as in C, it's still quite possible to leak by accident.
Good point! :D
But they don't say "no leaks"
Yeah, I'm in the process of setting that up.
&gt; `let mut img: Vec&lt;u8&gt; = unsafe { Vec::from_raw_parts(buff_ptr, buff_len, buff_len) };` It is not safe to do this unless `buff_ptr` was originally allocated by `Vec`. Otherwise use `slice::from_raw_parts` instead. &gt; I konw it doesn't work cause I keep getting the [333] vector. Doesn't this mean it *is* working? Your function returns `[333]` in the `Ok` case.
sorry, I meant I was getting [331]. I have an alloc method: #[no_mangle] pub extern "C" fn alloc(size: usize) -&gt; *mut c_void { let mut buf = Vec::with_capacity(size); let ptr = buf.as_mut_ptr(); mem::forget(buf); return ptr as *mut c_void; } which I use load the arrayBuffer() into wasm's memory on the JS part.
Hey ‚Äî here is the current plan. First off, we are working currently on a less precise variant of NLL based on the current codebase. As you can see from the latest results on [perf](http://perf.rust-lang.org/), it is getting a lot faster, and we're not close to done yet. Take a look at the clap-rs "nll" measurement: it's not hard to spot, just look for the big line that recently took a steep drop. ;) https://imgur.com/a/Gi7Fedn Meanwhile, in parallel, we've been working on optimizing the new analysis. That work is proceeding quite quickly as well. For example, [my recent PR #23](https://github.com/rust-lang-nursery/polonius/pull/23) achieved a 10x speedup without changing anything else about the analysis. We have several other tweaks I expect to yield other large multipliers (e.g., using a less precise analysis as a prefilter, compressing the CFG somewhat, and an alternative datalog engine that is targeting just our particular case), so I am pretty sure the performance will be just fine. That said, two caveats: 1. I expect to land the new, more precise analysis later. By focusing on the less precise one, we can do polish on the diagnostics etc. 2. Because this new borrow checker fixes a lot of bugs, we are going to have to run a warning period for a while. This means we'll be running the old *and* the new borrow check. This can't be faster. =) But since the borrow check is not a big component of overall compilation time, I hope it won't be much slower. Finally, one last nice point: once we transition to the new, MIR-based borrow checker, it will enable a lot of refactors that should speed up earlier phases of the compiler. For example, the type checker doesn't have to track as much data about lifetimes, etc.
InfoQ added the 'al', whatever. :)
You can implement your toy C compiler with its own ABI non-conforming with ILC, but then it will only talk with itself. Just like C compilers in the old days weren't compatible with each other. Buying commercial libraries always brought the same library compiled multiple times for each major compiler. Linking a Borland .obj with a Watcom .obj and a .lib from GreenHills? Good luck.
It‚Äôs not general purpose yet. I want to do that, but at the moment it‚Äôs only useful internally to Rust projects. Also, it‚Äôs worth noting this: all this prevents is knowledge of what DNS query you‚Äôve sent. if you want full on privacy from your ISP, you‚Äôll need to use a VPN. DNS-over-TLS (or HTTPS) provides a secure and private connection to an upstream Resolver. That Resolver of course knows what you‚Äôre searching for, so you‚Äôre transferring trust from your ISP to the upstream Resolver. In addition to that, the ISP still knows what IP you will ultimately connect to. IPs may be enough to collect some data on what your doing. After that, HTTPS with SNI enabled will send the DNS name in the clear before establishing the TLS connection, meaning they can still discover the name of the site you‚Äôre using through that method. For these reasons, I will temper any extreme excitement around DNS-over-TLS. I think it‚Äôs best at the moment for guaranteeing the authenticity of the upstream Resolver and that it‚Äôs response packets haven‚Äôt been tampered with. If you want privacy, you will need a VPN. I think it would be interesting for us to define a new TLSA type record in DNS that could create privacy for the SNI portion of TLS, but that still won‚Äôt do anything about the IP address...
I think this is a really good idea. A few other projects that I think would be useful to have grouped this way: * rust-lang (libc, cargo, regex, and std if it becomes a crate available on crates.io) * rust-lang-nursery (lots of stuff which will hopefully move into rust-lang eventually; rls, clippy, rustfix, bindgen, rand, stdsimd, rayon, futures, etc) * tokio * gtk (gtk, gdk, gio, glib, etc) I think it would be good if projects would be owned, so only the owner, which could be a team, would be allowed to add crates to the project. In general, projects should consist of a group of crates all maintained by the same team with the same set of policies; you know that if something is part of a project, it is maintained in the same way as all of the other parts of the project, has the same bus factor, etc. The project could also have additional overview information for the project as a whole, leadership, policies, etc.
Thank you for sharing! I am already trying to embed it in the backend of a graph visualization software that I am making for my thesis. I would like to ask though what is the best approach to insert data that are taken from csv or json
Awesome! Do you know if the scholarships will be able to cover air travel?
Note: posts on /r/cpp have to be about C++. They do not have to be 100% C++, but if it's just a mention of C++ in passing, they are likely to get removed.
`#[repr(C)]` and `extern "C"` give you a stable ABI for a subset of the Rust language.
&gt; It's said that premature optimisation is the root of all evil and all three things you mentioned seem like premature optimisations. There are benchmarks that have demonstrated that for byte-code interpreters going from a `switch` to a computed `goto` led to significant performance gains. The reason is mostly branch prediction: - a `switch` has a single "origin", so branch prediction yields "20% X, 20% Y, 30% Z", - a computed `goto` used at the end of each case, however, has as many origins as there are cases; it occupies more space in the branch predictor, but each precision is more accurate: after X, 80% Y; after Y, 80% Z; ... Interestingly, it could be as simple as adding a code-gen attribute to `switch` to have it generate the computed `goto` equivalent and keep `switch` syntax; but no mainstream language proposes this option.
And of course, the issue with your list is that it's on a per-feature list. And Rust keeps getting new features ;)
I think that it's most useful as a single-entry thing. It would indicate ownership and being part of a common project with a common set of policies. There are already keywords available as a free-for-all, multi-valued indication of some kind of association; for instance, the [tokio keyword](https://crates.io/keywords/tokio). What is missing is a way to say "this is an official part of this overarching project."
I was thinking of it as a single-entry thing; for multi-entry we have categories. Topic vs. ownership, again.
I thought I had, but apparently not. If the goal is "officially part of this overarching project", how is that ultimately different from the Namespace/Organization ala github?
Nice to see it posted here. I've quickly added the source code to a nice todo example application. https://github.com/KDE/rust-qt-binding-generator/tree/master/examples/todos
&gt; I don't think it's x87's fault, SSE2 has a globally-writeable control word too (the MXCSR register) as do lots of other floating-point instruction sets. To be honest, I generally consider global state to be an abomination *by default*, and this certainly includes CPU control words and flags.
I'll look into this, thanks for pointing that out!
It seems like this only solves the third bullet point. It doesn't help with knowing whether a crate is run by the same people as the main project, or whether it's dead. 
I don't like this idea. Is there actually a need for this? The examples you have are similar in name only, so I don't think confusion is an issue. You don't pull in a crate without reading what it does. I can imagine it to be useful for project discovery, but most projects already have a page with related projects, and I think this system is better. 
The reality is that "transpiler" is not (and likely never will be) a common term among programming language researchers. As someone in research, the word honestly only comes up as a complaint about outsiders using the term despite it being an ill-defined and completely arbitrary distinction. So, the author _made_ the decision to use the _common_ terminology.
thank you, it makes sense now :)
typo
&gt; that the LLVM optimizer would be smart enough to insert them. I think the most likely explanation is that it's a niche usecase and there are bigger fishes to fry :)
I think it might be based on [datafrog]https://github.com/frankmcsherry/datafrog).
But it‚Äôs called editions!!!
It wasn‚Äôt when I gave it!
For some reason, rocket doesn't allow the `&lt;path..&gt;` to start with a dot. I asked Sergio on IRC and he said it's possible to handle paths starting with a dot if I don't use `&lt;path..&gt;` but implement by own replacement for it, but that was a while ago so I don't remember the details..
Since when? No more epoch?
The Epochalypse
No DNS-over-HTTP?
Indeed, the docs are pretty sparse. I'll see about improving that.
Version 0.1.x used `(&amp;[T], &amp;[T])`, I plan on switching everything to `[&amp;[T]; 2]`. The latter is nice because you can write a single function to copy a slice of slices to another slice.
True. The primary reason the non-atomic version exists is that you can push and pull multiple elements in bulk. This is a slight performance benefit, as you have to do length and resize checks only once instead of N times, and only one memory copy to insert all of them.
‚ÄúEpochs‚Äù are being changed to ‚ÄúEditions‚Äù as of Rust 2018, so it‚Äôs currently deprecated to call it that, but will be a hard error afterwards ;)
That seems to be a bug for sure; I would have expected the third and fourth `push`es to return `0`. Thanks for testing it out! Overwriting is definitely sometimes desired, but this implementation isn't _supposed_ to overwrite.
&gt; It doesn't help with knowing whether a crate is run by the same people as the main project, or whether it's dead. It does if you disallow pushing crates that claim to be associated with a project which aren't, and if the crate maintainers actually curate the projects they maintain. Having an explicit list of crates associated with a project somewhere isn't a bad idea, though. Just puts the information somewhere else other than in the `Cargo.toml`.
Wait, how does `cargo publish` evaluate the claim that my crate is associated with `gfx`? 
I think you mean DNS-over-HTTPS, and no. Is there something you see this as providing over and above DNS-over-TLS? It's the same level of security for both, though over HTTPS it adds the HTTP header overhead. The only area that I can see DNS-over-HTTPS being useful is inside a browser session, I'm not aware of TRust-DNS being used in that context...
Same way that it evaluates the claim that your crate is associated with your crates.io username when publish your crate anyway. We'd just need to add a group/project functionality to crates.io.
Crate names are immutable, project membership is not.
OK yeah, that sounds like what I was thinking, that the maintainers of the main crate would have to approve it or you'd get a different badge if they did. 
This was a great read! Thanks for writing about this. I always forget swap and drop have regular uses. The only thing I found confusing was the last two code blocks. The first one is about \(unmodified\) right node code but transitions to the second code block about \(modified\) left node code. Eventually I realized they were different code paths and not the same one lol
You can do that with `VecDeque` too, though; `extend` and `drain` are for exactly that purpose.
Editions == Epoch 2.0?
Xargo needs the source of rust in order to compile it for your target spec. I‚Äôm sure there‚Äôs a way to do it without rustup, you should check the docs.
nvm uninstalled and reinstalled - things should be fixed(question mark)
What are the pros and cons of using this instead of Conrod?
I like that description. It seems like it would fit well with what I at least want out of a system like that.
&gt; You say that you want the usage to be an DAG seems logical, but what is the issue if it isn't? Its not always possible, but I believe that a good rule of thumb for staving off "spaghetti" and the inevitable entropic collapse of our systems into incomprehensible ruins is that if you have a graph, it should be acyclic.
When will Epoch 2 start? And can we please use it to get sane integer casting (breaking change for `as`)?
Damn ok. thanks for your opinion. I will implement this. I'm gonna do some more reading on non-lexical lifetimes. 
I came from Java (not even on your list, what???) ;) though, I did want to get back into C... ie Rust.
I tried translating my errors (for creating easily human-readable strings, not "os error 2") and found this interesting trick to seperate the messages into modules (so you can put them into seperate files) and wanted to share it. TLDR: Make one module for each language and then use a macro to generate a pattern match on the error, returning `$language_module::MY_ERROR_STRING_CONSTANT`. 
Editions don‚Äôt match with anything :( editionalypse, editionarok, it all sounds lame 
delete
Is there a particular pattern or type of example that you'd like to see? We have quite a bit of code that uses tokio and futures (mostly 0.1 versions), futures-cpupool, and hyper 0.11, and I can try to throw some targeted examples in a few gists if that'd help, but it'd help to get a sense of some specific patterns or use cases you're looking for. In the meantime [here's a not-really-useful example](https://github.com/azuqua/fred.rs/blob/master/examples/http.rs) of using our redis client with hyper 0.11. That library also uses futures, tokio and tokio-proto, but proto is apparently going away, so I wouldn't put too much work into learning that. It primarily relies on passing around mpsc senders/receivers for a message passing model, and that might be worth looking into. Message passing + futures/tokio has worked well for us, especially when you have sets of event loop threads with different responsibilities, and even when you want to throw thread pools into the mix. [Here's another library we use with tokio/futures](https://github.com/azuqua/wombo.rs), which we use to manage groups of event loops that we sometimes need to interrupt and restart. As you called out though, with `impl Trait` landing and futures/tokio being in such a state of flux, there's a good chance this'll all be outdated in the near future. That being said, having a good understanding of `Fn`, `FnMut`, `FnOnce`, trait objects, what `move` does, and the future task model are hugely important regardless of where the interface goes, so I'd recommend playing with those. If you come from a background where message passing and/or the actor model are familiar, it's worth looking into the futures mpsc interfaces (especially the oneshot interface), as those are hugely helpful. That's all opinion though, as it's certainly possible to be very successful with different patterns on top of futures/tokio. From a general usability standpoint I'd also recommend taking a look at `loop_fn`, and `Either` in the futures crate as well.
I smell epochgate
\&gt; it'd help to get a sense of some specific patterns or use cases you're looking for. Yeah, when writing this question I realized I didn't actually have an accurate idea of what I was asking for. Unfortunately I'm new enough at Tokio and async programming in general that really, anything bigger than the tutorials will do. Regarding my particular use case, what I'm trying to write right now is writing a sort of web scraper that would poll several REST APIs every few seconds and pass the parsed JSON data down the pipeline for further processing, but even that's been sort of a challenge so I must definitely be missing something. I'll take a look at your links tomorrow, looks interesting, thank you!
I really hate programs that localise their error messages. Usually it's not something that can be acted upon by the user, but now it's translated it also means you can't search for a solution online! 
New edition, new rules for puns: - Extredition - ~~Expedition~~ (lame, is actually correct) - Contrediction - Repedition
It's extremely teachable. The syntax, the documentation, the clean semantics, the ergonomic tools.
What is the error variable in your failure case reporting?
Mods -- could I request that we ban this bot? 
You deserve an upvote. Rust, if anything, needs to not be propagandized.
Yes, I would recommend to use error codes for that (even English messages might change). I know that localizing error messages is a hot topic, but on a German computer with German menu descriptions and a localized UI - getting an error in English can feel very jarring and out of place, like the app designers just didn't care about errors. So while I would still recommend translating errors, I would give a unique error code for each error. Also, not every UI has copying enabled for error messages (ex. the Win32 popups have no "copy this message" button), so you'd need to manually type the error into Google - writing down and searching for an error ID is quicker and doesn't feel out of place in the UI.
Well, as you're printing them in the example, that's what I thought you wanted to use them for. For a pop-up, it might be reasonable to have a localised user-level description with an English technical description. Error codes are not easily searchable online, so that doesn't really fix the issue. 
Yes, for development tools that are only going to be used by developers that know English or for error logging - I wouldn't translate errors for that. The last time I had that experience was with Visual Studio and I absolutely hated the translated compiler errors. Error codes are usually easily searchable if you prefix the name of the app, i.e. "arcgis error 99999". 
That'll give you a bunch of results about 99897 which a lot of users seem to have, but is not your issue. The search engine thought it was similar enough. 
Hey, For now it‚Äôs very diffused. I‚Äôll take `cheddar` out of `spectra`, it should be doable now that I‚Äôve completely gotten `warmy` out of it. Though I have other concerns for now (making `warmy` asynchronous and bringing some new demos with `spectra`). It‚Äôll take some time but it‚Äôll come!
That's pretty straightforward, but it runs into problems in larger applications when you want to start splicing strings together, for example, to return numbers. Different languages can have wildly different methods of pluralization, so your method will lead to constructs like "you have 1 unread messages." Proper localization is really very hard.
How do I resolve the borrow checker's issues here? ``` pub struct channel&lt;'a&gt; { pub title: &amp;'a str, pub description: &amp;'a str, pub link: &amp;'a str, } fn from20&lt;'a&gt;(feed: &amp;Element, version: &amp;'a str) -&gt; Option&lt;feed::channel&lt;'a&gt;&gt; { [methods on feed called to set title, description, etc (type is String)] Some(feed::channel { title: &amp;title, description: &amp;description, link: &amp;link, }) } } ```
Sorry, I was missing a 9, it's [999999 (error executing function)](http://pro.arcgis.com/en/pro-app/tool-reference/tool-errors-and-warnings/999001-999999/tool-errors-and-warnings-999998-999999-999999.htm). It was a joke because in that case ArcGis can't tell what the error was so it just gives you 999999 (the default, most generic error). Which can't really happen in Rust, because of Result. It's been a while since I used ArcGis, but I actually got an autocorrect for the real error code (999999 was the first result on Google), not sure what's up with your search results. It may invalidate my point a bit because I couldn't remember the error code correctly, but then maybe it's a good idea to not have a million error codes.
I didn't actually search for your string, I assumed it was a dummy. I was explaining why error codes are not usually sufficient. 
Why ban it? It brings useful information, unlike some bots. 
Great, looking forward to it :)
**stephaneyfx** provided a nice idea as a workaround ‚Äì on IRC. [Link to the Rust Playground](https://play.rust-lang.org/?gist=d9b1fe4e2814618b9173a90a8b19e6f3&amp;version=stable&amp;mode=debug).
I think we'll have to agree to disagree there üòÇ this definitely doesn't meet my criteria for "useful information"
Funny, I was tempted to post the latest episode of cppcast to r/rust, but it seemed too off topic. It's about an effort to codify `no_std`-ish features of the C++ standard, to make it easier to write libraries for embedded environments. It reminds me of the work that the Embedded Working Group is doing this year. I'll sneak it in here: http://cppcast.com/2018/05/ben-craig/ The challenges of evolving C++ seem really profound. There are several widely used compilers, and a lot of proprietary ones, and just tons of (working, useful) code that isn't even on C++11. And the C++ community is still pushing the state of the art on several fronts. So, we might say for better AND worse. :)
You basically need to give the translator the whole formatting string (and explain what the %d means). The way Qt does it is OK to work with IMO. 
Maybe try getting more information by using `to_string()` on the error, then returning the bytes of that string from the function? If that isn't helpful either, you could also directly just do a `.clone().into_boxed_slice()` on the vec received and return it just to make sure the data rust is reading out is the data you're giving in. I have no idea what the actual problem is, but this should get you more information.
My bad I mixed up while writing...
`drain` doesn't seem to quite do what I'm looking for, unless there's an iterator-based way to copy elements into an existing slice. Even if it can, `pull(&amp;mut [T]) -&gt; usize` is a lot easier to grok and understand for this specific use-case in mind.
[You mean like this code?](https://play.rust-lang.org/?gist=7beabed38d8a9c7ec27086bb62423f6e&amp;version=stable&amp;mode=debug)
Is there anywhere one can follow the progress of the new website?
I'm also newly interested in this after accidentally casting a function as an i64 this week due to a typo, which compiled and resulted in garbage numbers. (casting to integer returns the memory address of the function, apparently).
As cool as this is, I think it's usually more useful to have translated messages appear in an external file either included at runtime or compile time? This could be really nice with, maybe, a proc macro to pull in language files - and to execute this macro once for each file.
Not at the moment. When it‚Äôs ready you‚Äôll hear more about it.
So, assuming type of `title`, `description`, and `link` in your function is `String`, they are being dropped when the function ends. Heap allocation is gone and so on. On the other hand, you're returning a struct that contains references to theae values, so this is *effectively* a return-of-reference-to-local problem. You could change your `channel` to contain `String` so that you can return your strings without dropping them. Or if your `Element` can produce `&amp;str` version of title, etc, then do that(as in `fn get_title(&amp;self) -&gt; &amp;str') and change your signature to `fn from20&lt;'a&gt;(feed: &amp;'a Element, version: &amp;str) -&gt; Option&lt;feed::channel&lt;'a&gt;&gt;`. 
Hey Steve, when is your new book coming out?
Congrats! It‚Äôs been a long time coming, and I‚Äôm excited to see it‚Äôs finally here. 
I just made a new thread about it. Can‚Äôt guarantee a day but it‚Äôs soon!
I'm someone who has a few times tried to get started with using it. Each time I've been flummoxed enough by the borrow checker to give up. I've been trying again lately and it's better now. In part because I know more, and in part because the language has improve some. When/If non-lexical-lifetimes drops, it will be easier still, however I worry it will cause compile times to get worse again. The tldnr is that non lexical lifetimes will allow more code to pass the borrow checker's checks than currently do. So you will be a bit less likely to type correct programs that the borrow checker complains about. My experience may is not totally unusual, I know others who have had the same problems I have had, some have gotten over it and figured it out, others have given up. *ignoring* the borrow checker the Rust language is excellent, it has a lot of features I love from F# without the complications of garbage collection, JITs, runtimes, and unpredictable runtime performance. So I hope that soon the borrow checker will click for me because if it does Rust will be a fine language to use for any purpose. It *may* be the case though that if performance is not a huge concern, that Go/F#/Kotlin etc might just be better overall choices. The hard question is whether Rust is innately hard, or just different enough that experienced programmers have a hard time getting used to the new paradigm. 
I think you'll need to wait for abstract type declarations ([RFC 2071](https://github.com/rust-lang/rfcs/blob/master/text/2071-impl-trait-type-alias.md)) to be implemented before you can get that to work.
The problem with overselling Rust is it turns people sour to our other incredible but true claims üòé
I agree with this in general. The one problem which constantly rears its head with lifetimes is the "viral" nature of infecting and perpetuating throughout the entire public API as you build it. "It's lifetimes all the way down." There is good news, though! A recent discussion on the internals forum is exploring some much needed ergonomics options to address this exact problem: https://internals.rust-lang.org/t/pre-rfc-encapsulating-private-lifetimes/7500 Worth a read, since it presents the context with examples, and proposes some solutions.
I'm not one to buy into cargo culting, friendo. And I'm not a fan of the RESF, to be honest. I prefer to use what's best for the job. Rust is still...immature, for my tastes. If it's common for the community to be aggressive about adoption (and it is, in the case of Rust), then I'm going to stubbornly assume that I can't rely on that kind of ecosystem.
Rust is indeed a general-purpose language. I would be using Rust for all my scripting if the compiler were faster. The type system and ability to flip a switch and get a fast binary are just so sweet.
thank you, I will try that
it seems that this is the error: operation not supported on wasm yet ref: https://stackoverflow.com/questions/50415623/cant-get-imageload-from-memory-to-work-when-compiled-to-webassembly Apparently it is not yet supported by wasm. Altough it is such a rudimentary operation. Maybe are there other ways of loading an image from memory?
Nice, it's similar to the [delegatemethod](https://crates.io/crates/delegatemethod) crate but allows giving the wrapper method a different name.
RESF is a joke, in case you missed it. The *community* is not a monolithic block, as you imply, but a multitude of groups with different interests. Those at the core are as wary as you about being aggressive regarding adoption, for the same reason I already mentioned. I'm not going to play 'no true Scotsman' here, but someone who is proficient with Rust would not ask to rewrite a project in it without at least a PR with a component rewritten &amp; integrated as a proof of concept, right? That'd be just lazy. That said, we *are* happy the community is growing, and Rust, while indeed immature for some use cases, brings a currently unique value proposition that makes it a solid choice for others. This is what we advertise, and it has won Rust most-beloved language on StackOverflow three times in a row.
I filed an issue to `clippy` to add a lint for that situation. What you are seeing is that a bar function name is the function pointer of a function, which (as it is just a number), can be converted to an integer.
I think it would be more pleasant for such ad-hoc use with a few tweaks, e.g. whole-program inference within modules, not repeating the types in impls (like haskell). I know you can't make a perfect language for both use cases though.. the primary mission is big efficient systems, not application or scripts.
Congratulations, /u/steveklabnik1!
This one took really long, our last release was in December ^^ We got a lot of new features, including animation, sprites and basic UI support. For the next release, I'd personally love a bigger demo and I'm currently working on support for scripting. And with that - a new era can begin :) Prototyping will be much easier due to scripts (which don't need to be recompiled) and we can start building an editor controlled by a REPL - see [the features page for an overview of planned features](https://github.com/amethyst/amethyst/blob/develop/docs/FEATURES.md).
If you're sitting there going... is rust the right choice for my project... hm... could just do it in javascript, but you know, rust is interesting and stuff...: then don't pick rust. If on the other hand, you have a *specific problem* that it seems like rust is a good fit for, then rust is absolutely a fine general purpose language. It's not perfect; the ecosystem isn't there yet, with many half made, abandoned crates for various things, but it's pretty good if you're prepared to whether bugs and breaking changes. The tooling isn't there yet, but with the vscode or intellij plugins, its pretty good. The debugging isn't there yet (and there's no editor integration at all for it afaik). Rust is a compelling choice for: - Writing critical safe infrastructure and services. - Implementing libraries to consume in another ecosystem (eg. js, python, ruby) that are fast and safe (instead of C/C++ for doing so.). - Writing safe high-performance projects eg. a web browser. It is **not** a compelling choice for: - A generic website or web service. - Writing games. - Prototyping or rapidly changing projects (the tooling for refactoring large code bases just isn't there). That's not to say you can't do these things in rust... but unless you *have a reason* to pick rust, I don't think you should. There is no 'one best language' to use for everything. I use rust a lot for command line applications that need to run on multiple platforms and run in a single binary, and I'm very happy with it; but there's no *specific* reason I couldn't use, say, go, for the same thing. I just prefer rust because I like it, it has cargo, and it's occasionally necessary to turn a cli application into a library with a C api to be consumed by another language, which is possible, but irritating, to do in go. What are you building?
I unfortunately don‚Äôt know any examples, but I have had success searching GitHub for the library name in TOML files.
[removed]
One hell of a release, so glad to be able so help some places. This will be a great foundation for the editor and scripting &lt;3
That's what I meant by 'a quick github search'. Lots of results, but hard to sort through the many, many results, most of which are of little interest to me (being either unrelated to what I'm looking for, or outdated, mostly). I'll have to dig a bit deeper. For those that don't know of this trick though, this is *extremely* useful.
Apparently one can also buy the book from Amazon. Is that true? Is there any reason one should buy from nostarch instead? Really looking forward to getting this in printed form :)
I'm planning to use this in a project as soon as I can. I'm currently on a big coroutine thing too in other languages, and I'd love to find a way to integrate them into a rust game engine like amethyst. Game logic is inherently very stateful, and coroutines are very, very good at encapsulating stateful logic. Once await!() lands, all the resumable tech will be there.
Sexy. I wonder how it would cope with functions. I guess HRTB will be the real hit here though.
Yes. It also looks like we took a pretty different approach to the macros, with the simpler approach in [delegatemethod](https://crates.io/crates/delegatemethod) not being able to handle a lot of edge cases in the Rust grammar. For example, [one of the last commits](https://github.com/crlf0710/delegatemethod\-rs/commit/d865dcc09c6d9f13765e3ffba0b4b4005785bd83) mentioned \`?Sized\` only works if it comes first in the list, and the README mentioned that as a tradeoff for supporting generics, the macro has to generate the whole impl block instead of just the items/functions. We took a similarly na√Øve approach in the very first version of the Helix macros. After spending way too much time with the macro system, we have learned our lessons and realized that these pattern matching rules are simply not sufficient to parse a grammar as complex as the Rust syntax. For example, while the macro system handles tracks matching `(...)`, `{...}` and `[...]` pairs for you, it does not do the same for `&lt;...&gt;`, meaning that if you want to support complex generic bounds like `&lt;T, U: SomeTrait&lt;T&gt;&gt;` you are simply out of luck. (Looks like delegatemethod only support single tokens separated by comma here.) However, with this One Weird Trick‚Ñ¢ (see the Ruby Kaigi talk/slides), you can turn the pattern-matching macro system into a full-fledged stateful parser, it can even do fancy things like back-tracking. For example, with this approach, you can map `&lt;` and `&gt;`s into corresponding `{` and `}`s which the Rust compiler _does_ know how to track correctly. You can see how it's done in [this commit](https://github.com/chancancode/rust-delegate/commit/95327e8f918e4b4c46e15cadc395904d87e7387a). (The code is slightly complicated by the compiler preferring to parse `&gt;&gt;` as a single token. As I am writing this I realized I could do [slightly better](https://github.com/chancancode/rust-delegate/commit/20e7d7e90da9bcedc797d857d472dc3a09fe32bc) there.) The Helix macros have a lot of these limitations today. I have spent a lot of time thinking about the cases that we don't support (well) today (generics, lifetime, unit testing the code generation, better error messages, etc) in my head since the RubyKaigi talk, and this project happened to be a pretty good way to proof out the ideas before going back and applying them in Helix itself.
Do you know the image format in compile time ? Could you use image::ImageBuffer::from_raw ? I did use image crate in wasm-unknown-unknown target successfully. Maybe you could take it as reference: https://github.com/unrust/unrust/blob/master/src/engine/asset/loader/image.rs
Thanks for the detailed reply. So your crate is strictly more powerful than the delegatemethod crate?
I didn‚Äôt look into delegatemethod in depth, so I am not sure if that‚Äôs true feature-wise (suggestions welcomed), but in terms of syntactic support, that seems to be the case. If anyone come across valid rust function/method syntax that doesn‚Äôt work here, I would love to hear about it and try to fix them. As I mentioned, this is a more bounded playground for me to test out some (long-overdue) refactors to the Helix macros, so any feedback there would be very helpful!
Can you tell me why Rust is not a good choice for "writing games"? I just wanna know your opinions because I believe Rust fits very well to writing games, so I am personally investing my time on Rust. If there's some problems I don't know, I'd like to consider. I think toolsets are still immature, but I think it is getting better very fast.
You are just spouting nonsense now. Calling across ABI's require a translation layer, like in the case where Go calls C through cgo, or when your C application uses libc to make syscalls. Such a translation would be necessary to link between Borland, Watcom and Greenhills, but seeing that such an ABI translation is *extremely* simple to make, it's not much of a problem. No one is interested in doing that, though, so it would be a few wasted hours. If I wrote a "toy" compiler implementing an ABI, it would be compatible with anything implementing that ABI. My point, as it has been this entire time, is that ABI's have *nothing* to do with OS's or compatibility layers, but are simply a function of the application binaries and libraries linked. Just like you now mention yourself with your Borland compiler example.
Very enlightening talk. Anyone know where I can find more info on the changes coming to modules?
I don't understand why the other poster deleted his post, while not useful to me, that might have been useful to others :( Don't do that! So here it is: the poster suggested using the github advanced search feature to locate repositories using the dependencies I'm struggling with: [example request](https://github.com/search?utf8=%E2%9C%93&amp;q=filename%3ACargo.toml+hyper+0.11+tokio-core&amp;type=Code). It's a great idea in general, but that does involve sifting through tons of repositories, of which surprinsingly few are more than a few dozen lines of rust. I've found some (surprinsingly few though) interesting things this way.
I used https://crates.io/crates/fnv to change my hashmaps to use the FNV hash, the amount of refactoring was minimal. That's another Rust gotcha. There ought to be a cheatsheet of sorts for the `std` library papercuts.
If you're really so much into the performance, you should generate the whole string at compile time using procedural macros. Doing the conversions at runtime and actually calling OS's `write` every time is a waste!
Looks interesting, but unfortunately Firefox apparently does not support the video playback and accessing the slides requires logging in... Is there any chance to get access to the slides, at least, without being submitted to the e-mail gathering tax?
&gt; The hard question is whether Rust is innately hard, or just different enough that experienced programmers have a hard time getting used to the new paradigm. I believe that, even without NLL, it's not Rust that's hard; it's pointers. Everyone goes in thinking they have a solid understanding of how pointers work, and are surprised to learn just how wrong they are. That said, there are a number of ways that Rust is harder than it needs to be. Some of that comes from missing lifetime features (NLL, self-referential structs, etc), some from incomplete tools (rustfmt, clippy, refactorings, build server integration). The great news is, the core developers are focused on addressing these problems for the 2018 edition. The other thing that can give an impression of rust being hard is the lack of stable libraries. This part of the ecosystem, in my opinion, is solved through community growth. The decision to target wasm as a tier-1 platform, in particular, should turbo-charge this growth over the next few years. Web developers are already familiar with package-centric development, and the sheer quantity of developers guarantees that, even if only a small percentage embrace Rust, the challenge we'll face is scaling package management.
&gt;I believe that, even without NLL, it's not Rust that's hard; it's pointers Maybe, but I the thing kinds of tree and graph structures that I get stuck on with Rust, I can make those work in C. The rest of the ecosystem - tools and libraries, I think are quite excellent. Better than almost all other new languages and many old ones. 
In the past I just did a binary search manually. I saw someone else recommend setting up a `.travis.yml` with many different Rust versions. That way, you just try everything and it should roughly happen in parallel.
What do you mean by "Helix macros"?
It saddens me to hear that, though I'm not part of the core team (and only part of the mod team because of the weekly announcements I do here). What exactly *is* your problem?
Hey, steveklabnik1, just a quick heads-up: **belive** is actually spelled **believe**. You can remember it by **i before e**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
I don‚Äôt believe so, those are only Oreilly books, right?
How up-to-date is the book? Does it match the code?
&lt;3
Woo!
Thank you!
All the code examples in there should be up to date. The book doesn't have many chapters but the existing ones are correct (except we missed something).
Amethyst already uses futures for asynchronous asset hot-reloading if you wanna check it out :)
It would be nice to have an overview in the introduction for when to use Amethyst instead of just combining crates for physics, networking, rendering etc. (when one doesn't need a ECS).
That's an interesting question, thanks, I'll add a ticket for it.
They have No Starch books, I looked but couldn‚Äôt find it yet
https://usehelix.com/
Nope, here is a book published by NoStarch available through Safari https://www.safaribooksonline.com/library/view/land-of-lisp/9781593272814/
&gt; Is this something the NLL will fix? I think so? Use nightly and toss a `#![feature(nll)]` on there to find out. I'd do it but you didn't provide full code, so it's not as easy.
Use mailinator.com
I think NLL should fix it - the `None` case has no lifetime constraints.
This was a very good and interesting talk!
Personally I used Rust+skia for graphics rendering on Android/PC, and Java for rest of UI (core logic was on Rust, and Java classes just use Rust "classes"). But my project was not game, thought it had complex enough graphics.
This is really great, I‚Äôm going to use this all the time! Very glad to have it not depend on nightly.
I love my types and I love the Rust error messages, but when there's too much type inference (hello there Futures) the error messages can rapidly become... less than ideal. I'm not sold on the tradeoff here. Safe+big+efficient sure sounds like an application to me!
Yup, works. And compilation doesn't even take longer... (purely empiric!)
No worries :)
I myself jumped into the amethyst hype train for the features it has, for example the newly released ArcBallCamera is something very common when you're making 3rd person 3D games, and that's the sort of features you won't get with general purpose stuff.
application code can mean something more about UIs, with heavy lifting done in other libraries.. GC simplifying development can be a good tradeoff
Thank you for SO much work that you have put into u/steveklabnik1 and u/carols10cents. 
The HRTB syntax is the one we'll use in Rust, and potentially `impl Trait` too, as sugar. The feature isn't implemented yet, it's waiting on the Chalk-related refactorings in the compiler.
Hey I have this code: #[derive(Debug, Clone, PartialEq)] struct Vector3&lt;T: Num&gt; { pub x: T, pub y: T, pub z: T, } impl&lt;T: Num + Copy&gt; Vector3&lt;T&gt; { pub fn new(x: T, y: T, z: T) -&gt; Vector3&lt;T&gt; { Vector3 { x, y, z } } } pub type Vector3i = Vector3&lt;i32&gt;; pub type Vector3u = Vector3&lt;u32&gt;; pub type Vector3f = Vector3&lt;f64&gt;; the compiler says that: `private type \`vector::Vector3&lt;u32&gt;\` in public interface` I don't want my user to have access to the template version of Vector. They should only have access of my "typedefs" so to speak. Is there a way to do this?
I like the HRTB since it‚Äôs more consistent with the Rest of the current Rust syntax, while I truly start to *hate* the `impl Trait` in contravariant position / universals (function arguments, `type`, etc.).
The book is based on Rust 1.21. We've started work on the next version, the "2018 edition", but it has only extremely minor changes yet. It'll catch up soonish. I've been working on edition-specific documentation first, then updating the book will come after.
Yeah, borrow checking is normally not the bottleneck. Glad to hear it!
watch jonathan blow's first video - he explains the need for malleability it's not bad, but it's not as good as it could be, and possibly not enough of an improvement over C++ to justify switching. (there are paradoxically some situations where C++ can seem *more* malleable, and yet C++ is burdened with un-necasery problems)
There is a lot of code. I wonder it is possible to use `syn` + `quote` crate instead? It is already supports full grammar of Rust (I suppose), so the result code may be just few lines with the same functionality? 
Amethyst works via an ECS. You're not going to get much out of it if you don't use one, ECS is the foundation on which everything else is built.
Interesting approach. Personally I used rust_swig to cooperate with Qt/C++ code. What about handling of Result (error handling), Option, Vec?
&gt; I think toolsets are still immature... This. That's it. Rust is a great language, and good for games, in general, but there is nothing even remotely like the set of libraries and engines available for it that there is for C++. If you want to mess around with it, or write *bits* of a game in rust, fair choice. ...but don't fool yourself. If you picked rust as 'the language' for your game, and it's a professional, commercial game? That'd be a stupid choice. It'd be an engineering choice, that fails to acknowledge the economic realities.
I see your point. I think that makes sense, and my goal is not an AAA title, so maybe it's gonna be okay to me.
You can also use traits with a generic method to imitate higher rank functions: http://fitzgeraldnick.com/2017/08/03/scrapmetal.html
How can I make \`cargo\` to \`save\-analysis\`? I know that I can do this with \`rustc\` by calling rustc \-Zsave\-snalysis \&lt;files...\&gt; But, I couldn't figure out for \`cargo\`. And also I like to know how I can read them back to \`rls\_analysis\` data structures.
Did you mean the [kyren from Chucklefish pseudo-AMA](https://www.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/)?
Is there a workflow/process on keeping the book updated with latest changes? I could see people opening issues once a major PR is merged like 128 bit integers. Is it mandated or done by the developer out of interest?
Inference makes large types with highly nested generics more palatable, so libraries get designed around them. It can rapidly become infeasible to write out types.
According to policy, the book has to be updated before a stabilization PR can be made. However, this was not great for various reasons. For the edition, we‚Äôre trying out a relaxed version of the rule: an issue has to be opened. Then, after it‚Äôs made stable, the docs land. Normally that happens pretty quick, by me. However, as I‚Äôm working on the edition docs, there‚Äôs some lag. I do accept smaller PRs for the book, but it‚Äôs a bit less open than the rest of our docs. There‚Äôs tons of subtleties about the style and voice and overall coherence that are much harder to do than in other docs.
For long types why not use a [type alias](https://doc.rust-lang.org/book/first-edition/type-aliases.html)?
You could, but that also gets unwieldy with a large number of types involved. You become less a programmer and more a type maintainer.
means creating more names.. more things to look up why not just have the option of full inference inside modules; the public interfaces will always have the types.. let people figure out what the best balance is internally
Yeah, I guess it's the only viable solution at this moment. Thanks!
I ordered via my Universities book store, is there any way I'll be able to get the e-book version as well or do I have to but it at full price again? I bought it via my University as it is a lot cheaper to buy it via them than to buy it for myself.
Yep, and now I feel like a goof.
In your post you mention you don't like `impl Trait` because it's always treated as a universal by the compiler. But if the compiler can infer whether it's universal or existential, would that make it more palatable to you?
Thanks :)
Right that's a good pattern. Thanks for the tip.
I haven‚Äôt received an email from No Starch. Does anyone know if the ebook will get the update soon?
Awesome! I am excited. I'm going to have to remember to bring my dead tree version with me to RBR unless I might see yinz sooner.
Cervus implements [CommonWA](https://github.com/CommonWA/cwa-spec) now and its [examples](https://github.com/CommonWA/cwa-rs/tree/master/examples) can run directly on cervus (therefore the `usermode` api crate is not needed any more before we have some platform-specific extensions, readme needs update :D).
You‚Äôd have to talk to No Starch about that, no idea.
TLDR Rust how\-to \- maybe this will help you: - In Rust every object has an owner. - If you pass an object to a function the called function becomes the owner of the object, a.k.a. the ownership is transferred from one function to another. - An object which comes out of scope, e.g. at the end of a function, is destroyed. - To prevent ownership transformation (object movement) to a function, pass a reference to it ‚Üí THIS IS THE IMPORTANT CONCEPT YOU HAVE TO UNDERSTAND :) - A reference has a lifetime, which makes sure that a reference can't outlive the owning object. This means that when the owning object comes out of scope, no reference to it is allowed to exist anymore. - You can have as many read-only references to an object as you wish **or** one read-write reference. - If you need to share an object with multiple parties it has to be wrapped into a reference-counting object [std::rc::Rc](https://doc.rust-lang.org/std/rc/struct.Rc.html). When the compiler can auto-deduct reference lifetimes, you don't have to specify them manually, but every reference has always a lifetime. The rest of Rust is to learn the syntax and methodology of how the standard-library approaches some problems, e.g. [std::convert::From](https://doc.rust-lang.org/std/convert/trait.From.html). // read-only reference to str's (a.k.a. a string slice) with a static lifetime let name: &amp;'static str = "John"; { // read-only reference to string slice in a scope let name2: &amp;str = "Banana"; } // end of scope, name2 can't be accessed any more let name3: String = String::from("Doe"); // owning object, containing a String foo(&amp;mut name3); // pass a read-write reference of name3 object to the foo function bar(name3); // move the name3 object into the bar function // name3 object is no longer available here // implicit reference lifetime fn zot(x: &amp;i32) { } // explicit reference lifetime fn zot&lt;'a&gt;(x: &amp;'a i32) { }
You are talking futures here, i guess. And yes they exist in rust, but in a slightly different way cause rust has a lot of restrictions of kinds. Take a look into https://github.com/tokio-rs/tokio and https://github.com/rayon-rs/rayon
This sounds really cool, but do you have any (practical?) applications in mind?
&gt; Is it just me or does literally every threading library in rust structure examples in a single file? This is just true for examples in general; keeping them small means that they're easier to see how stuff works. &gt; Am I expected to put the entire code for a service into main.rs so I can access the executor? Is there a particular thing you're struggling with? Nothing is tied to the module system directly.
Well, I've always thought C and Rust were incomparable in regards to pointers. In Rust you need to prove that your pointer usage is correct. As you said yourself, in C you only need to make them work. Unless you are comparing (semi?) formally proving a C program is correct (i.e. NOT just with testig), it's like comparing apples to oranges.
 if let Some(data) = self.some_map.get(&amp;a) { return Ok(data); } self.handle_awesomeness_not_found(a, b)
I've looked into both futures and tokio, both have you construct thread pools as a local variable. If I want to spawn tasks on that thread pool from another module, I can't see an easy way to share that without adding it as a function argument to literally everything that returns a future, which seems pretty bad to be honest. What I want is the ability to spawn a task on a thread and return a future without the added complexity of passing around a thread pool across a function chain. 
Does [rayon](https://github.com/rayon-rs/rayon) fit your needs? It is mainly useful for data parallelism, but it does have a default global thread pool.
$24 shipping to europe. Will stick with ebook only :(
Amazon might be cheaper?
If you pre\-order the print book through NoStarch, you also get the nicely formatted PDF ebook.
&gt; I've looked into both futures and tokio So, some context. The first thing I want to say is that all of this is under heavy development, specifically to address pain points. This also means it's kind of in a weird place; there's the older `tokio_core` and futures 1.0, but then there's `tokio`, and futures 2.0 and soon 3.0. So that's the backdrop of the specifics of this kind of library. &gt; I can't see an easy way to share that without adding it as a function argument to literally everything that returns a future, which seems pretty bad to be honest. This kind of question is more broad than just these libraries. It basically boils down to this: do you prefer explicitness here, or implicitness? Lots of people prefer the implicit aspect for various reasons, and historically, it's what I personally do. However, two things: 1. You can use `lazy_static`, or [thread local storage](https://doc.rust-lang.org/stable/std/macro.thread_local.html) to make the data more globally available. This has the upsides of being easier, but the downsides of globals. 2. In the nearish future, new versions of Tokio will be including a thread-local executor already, so the library by default will feel closer to what you want. This partially because so many people feel like you :) I hope this helps!
It's not well documented at the moment, but as of Rust 1.22, you can add directories into the `examples`, `tests`, and `benches` directories. `examples/gfx/main.rs` should Just Work as an example. See here: https://github.com/rust-lang/cargo/issues/4086
I've been using specs for non-game simulations. I'm approaching a point where it would be useful to start visualizing the simulation and maybe some interaction/gui later.. How would I go about converting from pure specs to Amethyst?
/r/playrust
Well it shouldn't be too difficult, Amethyst is mostly built as an add-on to specs. Give it a shot and let us know how it goes!
Thank you, sorry. 
Sure you can program with these specs using Rust the programming language, if you can play games ‚Üí I dunno.
This is a funny coincidence. As I'm looking at rules engines for implementing the logic of a game, I run into [Rete](https://en.wikipedia.org/wiki/Rete_algorithm), then the [expert crate](https://crates.io/crates/expert) which is a WIP Rete implementation in Rust and now this?
**Rete algorithm** The Rete algorithm ( REE-tee, RAY-tee, rarely REET, reh-TAY) is a pattern matching algorithm for implementing rule-based systems. It is used to determine which of the system's rules should fire based on its data store. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
You have access to both the `World` and the dispatcher, so it should be quite easy to port what you have currently. For how exactly you visualize things, I would recommend you read the book to get a feeling how to render something. Please just ask us [on Gitter](https://gitter.im/amethyst/general) or [Discord](https://discord.gg/GnP5Whs).
Well, it depends on whether you need to be able to take a function which can be called with *any* `FnOnce() -&gt; i32` (requires HRTB), or if you only need it to be callable with a *particular* `FnOnce() -&gt; i32` (for which named abstract types are sufficient). The reason your particular example doesn't work is because you can't assign a name to the type of `|| 42` and then just do `fn never_gonna_give_you_up&lt;F, C&gt;(f: F) -&gt; C where F: FnOnce(SomeName) -&gt; C { f(|| 42) }` where `SomeName` is an abstract type that implements `FnOnce() -&gt; i32`. Where you would need something like HRTB is if you wanted to do something like fn never_gonna_give_you_up&lt;F, C&gt;(f: F) where F: FnMut(SomeName) { f(|| 42); f(|| 37); } since the different closures wouldn't have the same type.
I think, you mean futures 0.1 :)
Gah yes
If you want, you can probably use `lazy_static` to make the pool a shared global. I'm not familiar with tokio or futures, but it seems to me that would resolve your annoyance regarding passing the thread pool from function to function.
Nah, the `match` one with the other handling of the result of the inner match. I don't like it. Personally I forget about `if let` most of the time. I don't particularly like that syntax. But thanks for mentioning it!
You have to install by date, $ rustup install nightly-YYYY-MM-DD and then use it instead of `nightly`.
It's definitely bedtime for me now. Thanks!
... but not until it‚Äôs implemented.
Forget rust the game, learn rust the language. It's fun!
What does that mean lol 
What does that mean I‚Äôm so confused 
Could you be more specific? Is ambiguity in parsing natural language (which I assume you want to use lojban for to avoid) really the limiting factor in artificial intelligence? Because lojban may be unambiguous to parse, but it does not have unambiguous meaning, because you are allowed to leave out stuff that is clear (for 'the listener probably gets it' definitions of 'clear') from the context (such as the subject of a sentence, tense, etc). So with regard to AI it seems to me that it allows you to skip only the problem of parsing ambiguity, and then still have the giant problem of actually creating artificial intelligence remaining. Lojban has been listing "possible applications in artificial intelligence" among its reasons to learn lojban since about 30 years ago, and yet I don't have the feeling it's going anywhere. And there is extremely little training data available in lojban, when compared to like every other language in existence. I think the prospects of AI are pretty exiting, but I'm just not convinced that lojban will be a step towards that goal instead of a dead end. And this is from someone who secretly dreams of writing a MUD that uses lojban as its input language :p
There is a programming language called Rust, **this** subreddit. There is also a computer game called Rust, the subreddit can be found here r/playrust.
Choosing a compression algorithm is a trade off between compression time decompression time and compression rate. On the "fast but does not compress that well" side of the spectrum, lz4-rs is working great.
utf8 is another decent compression algorithm for utf16 strings :D
Nice! Btw, I'd `#[derive(PartialEq)]` on `Location` instead of defining `Location::is_equal()`..
Up to 50% size reductions for common inputs. As I recall there is research showing that utf8 is better than utf16 on Wikipedia even for non-ascii languages.
Also, you can fix that a project to an old nightly while keeping the default as the most recent nightly by putting a `rust-toolchain` file in the project dir and writing the nightly in it, e.g. `nightly-2018-04-18`. Then when you check out the repo on a different computer, it will use the same nightly for this project.
Yep, it does! :)
Ah okay, I thought I was going crazy for a sec. I like your trait solution, I hadn't thought of the existential/universal dichotomy of trait bounds in that way.
That‚Äôs the reason why I made the blog post. I came to the realization that it‚Äôs possible to encode rank-n functions with traits. Then, if it‚Äôs possible to do this with traits, it should be possible to add the required syntactic sugar to enable them without all of this boilerplate. And I hope it‚Äôll be the HRTB syntax, because it fits nicely with the assumption ‚Äì i.e. *forall*, `for&lt;_&gt;`.
Thanks for taking a look! Turning directly into yourself seems it be a common complaint, so I‚Äôll probably not let the user do that. And good catch on pressing non arrow keys, I set the default value of a match statement to the down direction. That should definitely just default to not changing the direction at all. 
My services tend to be composed purely of handler and utility functions, I only really use structs for data. I guess it's either this or lazy_static for now though. 
Sorry I have no idea how to fix your problem, just here to point out that Reddit has interpreted some of your code as markdown. Reddit's code blocks are denoted by a blank line and 4 spaces of indentation. like this
The backticks version works\* in the new reddit layout. ^(\(\* On the discussion page at least\))
At the end of the day, it's not worth going into, and it only boils down to commonly held beliefs and opinions that many have already expressed. If you look through my post history enough you'll find plenty of information on all of that. You seem focused on making a heavy contribution and promoting the benefits of the language, and I absolutely respect that. But when leadership is too political or begins throw ideological and humanitarian beliefs into the mix, I walk away.
I've done it, it's fairly easy. We had to upgrade specs to the version amethyst uses to avoid type issues, but other than that it was pretty straight forward.
I think actix does a pretty good job of doing this. They have a struct for a System runner that wraps an tokio Core and they accept jobs through a public function. Is this what you're going for? https://github.com/actix/actix/blob/master/src/system.rs
Also add a few sample screenshots. They don't have to show anything specific, they only have to look fancy, because people are very visually oriented. For example, take a look at the [blender website](https://www.blender.org/). The section ‚ÄúEverything You Need‚Äù (which is just one page scroll down on the main page!) contains fancy screenshots and brief explanations what the software can do. They did a great job with that.
Unfortunately wanting something to be true doesn't make it true. I think it's **very difficult* to argue that you can't be more immediately productive in a language like python than you can in rust. I think it's *almost impossible* to argue that the you can't have a more productive lifetime-of-product written in Java, using the smart intellij refactoring tools to maintain your application with a large team than you can using rust. I think it's impossible to argue that the value of the 3rd party ecosystem in rust matches, or even come close to matching that in python, javascript, java or C# right now. So... if you were picking rust, to do something professionally, you would have to make a case, not for why rust is good, but why rust is **so much better** than the alternatives, that you should pick it. What's your pitch for that? ...because you can pitch it, for some specific use cases; but you can't reasonably expect to be able to make a good argument for rust for some arbitrary domain (eg. web application) where there are already highly productive, well made frameworks out there, battle tested and proven, well documented, with a large community of people to help you if you get stuck. Why **not** javascript? It works well for 100s of thousands of applications. What's so *special* about your application that javascript is a bad fit? Not your personal preference for a language... pragmatically, an *objectively better choice* than javascript. Do you need highly concurrent code? Why not java? Don't like the JVM? Well, it works fine for everyone else, it that just a *personal preference*, or a meaningful reason? Maybe you need native binaries? Sure ok, why not go? Don't like go? Well heck, lots of people don't like go and they use it anyway. Some of the most serious software on the planet is built in go. What's actually wrong with it as a choice? Maybe rust *is* the right choice for some things... but: Bluntly; rust is too new, and the ecosystem is too weak to be a first tier pick. You may like it. I like it... but it's not the right choice for people for every problem. That's ok. This 'rust first' thing is just nonsense. Pick the right tool for the job; Rust is the right tool for some jobs, but you should pick the tool that get the job done, not your favourite tool, regardless of what the job is. ..and just to be absolutely clear: Rust **isn't** the right tool for generic webservices. Flat out. Don't pick rust for that. Maybe one day, but right now? The async stuff hasn't even landed properly yet, all the frameworks will churn when it does... The ecosystem is full of holes and bugs. Even though rust is a good language, that *doesnt* mean you can magically avoid the problems from the missing 100s of thousands of man hours devoted to smoothing out other ecosystems. It's a *bad choice* for most webservices. ...unless there's a *specific* thing you need, that rust offers, and I frankly can't imagine what that would be for a web service. A very few well made constrained examples (eg. cloudflare DNS) are examples of high impact, performance critical projects where rust would be well suited. A blog... is not.
The `cpu_temp` method *isn't* conditionally compiled. Did you use the `Platform` trait? (As for how `target_os` is set, it's set by the compiler.)
Yes, I definitely wanr to add some screenshots. As I said, for the nexr release we're going to build a demo and I'm sure we can create some screenshots with it. The current examples are just no good screeenshot material.
I've updated the post with minimal repro case and compilation errors.
impl Trait is just like lifetime elision in that it is a strictly less powerful syntax with more inference.
It's because you linked to the Git source code, not the source of what's actually published. The reason `cpu_temp` doesn't exist is because *it doesn't exist.* What's on github is not what's published. You'll need to either wait for a new version to be published, or use the git version directly.
Reddit is a founding member of CommonMark so I think it is reasonable to expect for Reddit to migrate to CommonMark. They probably will freeze the old implementation and have a flag for old posts.
I see, good point. I guess I can also tell cargo to use github code when building. Just did that and it worked. Thank you so much for your help.
This is pretty cool! I believe we are close to good web dev environment.
Why can‚Äôt 443 be blocked as easily as 5353? And DNS-over-TLS can be run over 443 as well, if that‚Äôs something people want to work around, without adding the HTTP headers to the frame. Anyway, for anyone interested, it should be relatively straight forward to make the TLS implementations wrap the H2 library to offer DNS-over-HTTPS.
Of course blocking 443 is technically trivial, but it is not done in practice because people don't want to block HTTPS. It is an example of collateral freedom.
Wow! We should really tag posts like these for future reference. I know something like this is hard to fit into Rust Book or Rust by Example, but it is posts like these can make or break the developer experience. No google\-fu will help you find information like this, even if you're deliberately searching for it. Thanks a lot for taking time to document and share this!
if'n it works with systems it should only be a plist away from working with launchd
Sadly not. I was trying to add launchd support for both (server + crate) but as far as I can tell it‚Äôs black magic hidden in macos and does not actually expose a simple protocol that can be reimplemented. 
Wew!
As far as I remember, `no_builtings` was an optimization thing; it doesn't stop the compiler from generating those builtin functions. \([docs here](https://doc.rust-lang.org/reference/attributes.html)\) As for your problem, I don't see rust producing a definition for memcmp. Try running `nm -g librust.a | grep mem`. If rust has provided an implementation, one of the lines with `_memcpy` will be preceded by a `T` or `t`. If they're all preceded by `U`, that means there is no assembly code for them \- they need to be linked, which is exactly what you're trying to do. I don't know how that relates to the errors you're getting, but rust seems to be generating the lib correctly. I can't reproduce the error with some small c programs. Some [googling](https://doc.rust-lang.org/reference/attributes.html) suggests that gcc might be complaining about your custom version conflicting with the builtin version. Do you get the same error if you omit the rust part?
I just looked into the Rete algorithm because it sounds sort of related to something I'm working on right now and it seems pretty cool, but I can't help but wonder when one would need something like a Rete implementation when SQL-based systems offer the kind of selection/projection/relational algebra techniques used in Rete. Maybe I just haven't read enough about the algorithm so I don't have the full picture, but I'd be interested to know a use case for Rete where a SQL system wouldn't work as well.
Hi, I am implementing a little n body simulator. I have written a O\(n\^2\) algorithm. Now I want to make it fast. I am writing a little neighbour search algorithm, and once I find the neighbours I will add such object to the particle. Here is the code [https://play.rust\-lang.org/?gist=ca7ef98dd4abbe8ca1f86a9f08dc0005&amp;version=stable&amp;mode=debug](https://play.rust-lang.org/?gist=ca7ef98dd4abbe8ca1f86a9f08dc0005&amp;version=stable&amp;mode=debug) For some reason I don't know how to give lifetime to neighbours of Particle struct. Any help.
It *is* implemented in Rust 1.26, the current stable release. See also https://blog.rust-lang.org/2018/05/10/Rust-1.26.html
That release implements only `-&gt; impl Trait` in return function argument position, not in `let` bindings! /u/stevekabnik1 is right that this is not implemented yet :)
Fun! How much of the Javascript could be moved into the Rust? It'd be neat to move it all in there, if this is reasonable to do.
&gt; If I want to spawn tasks on that thread pool from another module, I can't see an easy way to share that without adding it as a function argument to literally everything that returns a future, which seems pretty bad to be honest. You can just define them in a global static variable :/
&gt; Also, is it possible to use the existing C allocator for heap allocations in Rust? If so, how? Rust uses the system allocator by default for `staticlib` crates, I think. I'm not sure what you'll get with `no_std`, though. [This](https://gitlab.com/BartMassey/mixy) compiles and runs for me on Linux x86.
Rate is an automated rule engine. You define facts (‚Äúplayer plays card x‚Äù, ‚Äúplayer y has 3 life‚Äù, in my case) and rules (‚Äúwhen card x is played by player x =&gt; player y loses 1 life‚Äù) and the engine iteratively applies the rules until no further deductions are possible. In my case that includes stuff like generating all legal moves, handling phases and turns, and custom card logic that builds on the basic game rules. 
Why are you using `impl Trait` in argument position?
This was the first project I attempted when learning Rust. Its ashes remain somewhere. Am excited to see a completed project 
I see, thanks!
Yay! I don't think I ever needed sockets to stay open when reloading an app in development. But for "production", I wrote [an utility](https://github.com/myfreeweb/soad) using the same protocol that *stops* the server when it's inactive to save on resources like RAM! Added a link to listenfd to that readme.
&gt; As I recall there is research showing that utf8 is better than utf16 on Wikipedia even for non-ascii languages. That's because there's a lot of HTML mark-up on Wikipedia, especially when including headers, footers, navigation on the left and special call-outs on the right, and all that mark-up is ASCII only.
Well, this is a rather specific need (having to keep sockets opened), so I am not sure the Book is the right place. On the other hand, the documentation of web-servers could mention this in their Getting Started section and automatically provide it in their start-kit example!
I don't know, isn't that a little overkill? There doesn't seem to be any reason to integrate it inside cargo, and especially when switching the versions while running cargo‚Ä¶ Something like this should just fail on the newest version that *doesn't* compile (not tested): ``` set +e for minor in `seq 26 -1 0` ; do rustup toolchain add 1.$minor.0 echo Trying version 1.$minor cargo +1.$minor.0 build done ```
You will end up with a self-referential struct if you do this, which Rust is very bad at dealing with. (Doing so almost always requires fiddling with unsafe code) If you can find some way to avoid having a sub-member of a Particle reference a different member of the same Particle, e.g. by having Neighbours store two references to Particles, and storing the set of Neighbours somewhere else away from the Particles, then writing the constructor will be much easier. If you mean how you assign lifetimes in general, then they fall out of how you write the constructor. If you have a struct that takes a reference, it's constructor might look like, `fn new( my_ref : &amp;'a Particle) -&gt; Neighbour&lt;'a&gt;` Which tells the compiler to assign the lifetime of the incoming reference as part of the Neighbour that is output. In practice, the compiler can do this matching-up for you in some cases, so you can actually write this as, `fn new( my_ref : &amp;Particle) -&gt; Neighbour` and it'll work the same.
dupe: https://www.reddit.com/r/rust/comments/8k5d2r/cannoli_a_python_compiler_written_entirely_in_rust/
Tangential question, but wouldn't the right thing to do be to make an extern volatile char [5] and tell the linker that it should be at 0xdeadbeef? I realize this is beside your point, since the pattern in your example is the first thing many would reach for.
I might be stupid or ignorant but why would I actually need to use this? I do web development with actix-web and `cargo watch` and it works just fine the way it does.
for win32 it's ctrl-c
Mark
Good job! I am looking forward to the results of the SAT Comp. :\)
Maybe try using the fno-builtin-memcmp option? https://gcc.gnu.org/bugzilla/show_bug.cgi?id=61001 https://doc.rust-lang.org/reference/linkage.html
Can also do these things directly in safe Rust, totally equivalent, although it's a bit more awkward. We know that's how std containers get implemented, anyway. Some say that C is the _canonical_ notation for unsafe pointer expressions, but that's only self-evident if you already know C :). A new Rust person could learn the power (and pitfalls) of unsafe pointer manipulation without knowing C at all.
I don't think we're there just yet. I am an embedded developer (99% C, 0.5% assembly and 0.5% python in order to test some of my code and create building scripts) who has just gotten into rust (1 month and loving it) and although it's very good, it still has some time before it can take over C, at least for embedded systems. Having said that, there is a market that would benefit from using rest in embedded systems and that is functional safety. I was a part of a team that made a certified SIL3 device (IEC61508) and I can tell you that we had to do A LOT of planning before writing any lines of code, because we had to use coding standards such as MISRA, and some other constraints that made it very hard to do everything in the safety components of the device, so we had to clearly devide what was blue code (normal C), yellow code (functional safety code, which MUST adhere to the standard) and green code (usually safety communication protocols such as failsafe over ethercat, profisafe, etc ... which consisted on regular components moving the safety related data between safety components and not mdifying it or doing anything with it). It was very tough separating the code and simplifying the safety components as much as possible (we were making a complex device, not a simple one) and it was even tougher writing it. After studying rust for short while I can see that we would've benefited a lot if we had programmed everything in rust, it would've made most parts far simpler that they were
I always admire the mad ambition of new Rust users. I think I just did a lexical scanner, since I've always needed one in my toolbox. Then did a JSON parser, which was fun, and discovered the json crate. Was very happy to throw away my attempt!
I can't answer your first question off the top of my head, but I can answer the second. While you are right that all types have a fixed, known size at compile time, recursive types are impossible to allocate without pointer redirection. Take this piece of code for example: ``` struct Test { val: u32, } ``` The size of a struct is the size of all of it's fields combined (plus padding, but that's more complicated). So the size of our friend Test here is 4 bytes (a u32). Now lets take a bit more complicated piece of code and try to find the size of that. ``` struct Test { val: u32, child: Test } ``` In this case, the size of Test is (u32 + (u32 + (u32 + (u32 + (u32.....))))) so on and so forth infinitely. It is impossible to allocate this on the stack because it is impossible to deduce the size. What we need to use here is a bit of 'pointer indirection'. We can wrap our child field in a Box&lt;&gt;, which is known to have a fixed, constant size. This makes the size of Test become (u32 + usize). The rust compiler can now statically determine the size our struct.
I can't think of any data that is purely 'on the heap' - there must always be some stack component, such as a pointer, that references is. As an example, a Vec should have a stack allocation of a pointer, length, and capacity, as well as a heap allocation pointed to by the pointer on the stack (for the elements). When moving the vector the stack component is copied, but not the data behind the pointer. When calling .clone() it is a deep copy of the data and the stack component. It is not always the case that data with a known size is allocated on the stack, it's just the default. For example, I can do let x = Box::new(4); and that will be heap allocated even though I know the size of '4' at compile time. More complicated situations, such as dynamically allocated stacks (alloca) exist as well.
&gt;I can't think of any data that is purely 'on the heap' - there must always be some stack component, such as a pointer, that references is. Oh, so the pointer itself is pushed onto the stack, and that pointer refers to the allocated data?
Oh my, you appear to be thoroughly confused! #Forget about Stack &amp; Heap. No, really. The semantics of a language are generally *not* tied to implementation details such as Stack and Heap. Or otherwise said, the rules should apply whether or not a value is currently stored on the Stack, on the Heap, or maybe in Read-Only Memory. Therefore, for now, forget about them. #Clone != Deep Copy. It is *mostly* true that a clone is a deep copy, however since `clone` ultimately runs user-code, there is no guarantee that it ends up performing a deep copy. The only guarantee about a clone is given by the signature of the method: `fn clone(&amp;self) -&gt; Self`. This means that it *reads* the current value and *somehow* produces a new value of the same type. There are actually special types, such as reference-counted pointers, which will only provide a shallow-copy. #Going further I really advise you to read the book. If this is your first exposure to ownership, borrowing and move semantics, there is a lot to grasp, and I will trust in Steve and Carol's writing to steer you right. [Chapter 4 is all about ownership](https://doc.rust-lang.org/book/second-edition/ch04-00-understanding-ownership.html).
Yeah, good point about Clone not always performing deep copies. Rc is a good example of this - it just bumps a counter up.
For another example of Clone != Deep Copy, although it uses an inherent method and not the clone trait, [fs::File::try_clone](https://doc.rust-lang.org/nightly/std/fs/struct.File.html#method.try_clone) gives you a clone of the underlying file descriptor, and does not actually clone the entire File.
Would be REALLY interested in reading a write-up about your experience writing this. I work in this kind of area (backtracking search algorithms, where you have mutable datastructures which change throughout search). I do everything in C++ at present, and I'd love to know how it was working in Rust.
Do you plan on implementing the IPASIR interface for incremental SAT solving for Varisat? It is a standardized interface to drive incremental SAT solvers and is defined here: [https://github.com/biotomas/ipasir](https://github.com/biotomas/ipasir) I wrote a RUST wrapper for it that can be found [here](https://crates.io/crates/ipasir) and it would be awesome to have a Rust-implemented SAT Solver that implements it. :)
It's misleading to talk about the value of a type as "some stack component"; there is no rule that the stack is ever involved at any point. A zero sized type is *never* on the stack, and if you wanted you could live with only static allocations plus the heap. The stack is only special insomuch as it's the default place for things to go.
Yes, that will probably come as soon as I have a library interface at all.
Awesome news!! :\]
If I wanted to see how your data structures for watching clauses (asusming you are using DPLL-style 2-watched literals), and adding learning clauses work, which files should I start reading first? Those were the two things I expected to be painful?
Yeah I am using watchlists, watching two literals per clause (just binary clauses are handled separately). Watchlists are handled in https://gitlab.com/jix/varisat/blob/master/src/unit_prop.rs That was actually an easy part, because I decided early on to use 32-bit offsets instead of pointers as clause references. That sidesteps most borrow checker problems, but my original reason was that it reduces the memory/cache pressure by making the watch lists smaller. The actual unit propagation is a really ugly routine doing a lot of unsafe pointer manipulation (fn propagate_long in that file). At some point I want to revisit it and see if it can be done nicer without being slower. To see how a learned clause is added it's probably best to start in fn conflict_step here https://gitlab.com/jix/varisat/blob/master/src/cdcl.rs#L69 Lines like `Self::backtrack(&amp;mut self.prop, &amp;mut self.vsids, analyzed.backtrack_to);` in that function are places where I wish there was partial borrowing across functions, so I could just do `self.backtrack(analyzed.backtrack_to)` instead.
Look at the crate `snap`. In rust implementation of the compression and decompression speed optimized snap algorithm.
There's also registers, which people routinely ignore when taking about stack vs heap.
The same could be said for a lot of other tools. Anything that automates an annoying common problem is awesome. Programmers have a 'special' type of lazy. We tend to spend hours creating automation for a problem which might only cost us seconds of time...but then, that automation will save *years* of human effort over everyone who uses it.
Well, while I think it is impossible to create a truly scientific benchmark of any kind, I believe that the benchmarks should be useful. For them to be useful, they should have a goal. It seems that the study had a goal to show how the languages perform in terms of speed and memory consumption. Why not? If that is what someone is searching for and they were willing to spend their time to do this work, that is fine. I would guess that they might have started with just a few new languages (e.g. Rust, Swift) and just one "classic" language for the baseline (e.g. C), but later the list significantly expanded and they also added some of the ones that they were interested in, though not exactly fit for the competition (e.g. PHP &amp; Hack and Python). This is what happened to my recent completely unscientific benchmark: https://www.reddit.com/r/programming/comments/8jbfa7/naive_benchmark_treap_implementation_of_c_rust/ (we started with Kotlin Native vs Rust just for the sake of argument with a colleague of mine, and it has over 40 "solutions" now; our goal, by the way, was to see how far an average developer can go with their initial "good enough" solution in different languages, so we initially were interested only in "naive" implementations, but there was a significant interest in highly optimized solutions as well, that is why we added another scoreboard to compare naives with naives and optimized with optimized) BTW, the results of our benchmark more or less match the results presented in this study, but only when you mix the naive implementations with highly optimized ones, which seems to be unfair to me. For example, when people talk about real optimizations for Python, they talk about Cython, JIT, or C extensions, and rarely they would optimize Python code itself (well, unless there is an obvious performance hog).
&gt; I can't think of any data that is purely 'on the heap' - there must always be some stack component, such as a pointer, that references is. Well, only if you think transitively; `Box&lt;Vec&lt;T&gt;&gt;` is gonna have vec's data on the heap, pointing elsewhere on the heap.
You almost always want `&amp;[T]` over `&amp;Vec&lt;T&gt;`. The only time you need the latter is if you're reading the vector's capacity for some reason. `&amp;Vec&lt;T&gt;` automatically Derefs to `&amp;[T]` too, so you gain flexibility and don't lose anything, it's broadly more genral. I can't answer your other questions right exactly this second, and itd be good to know what a `Path&lt;'a&gt;` is.
Why would you pass a `&amp;[&amp;Node]` instead of a `&amp;[Node]`? Both are possible, and in a way "valid", however one has one more level of indirection than the other, and unless indirection is strictly necessary it's often best to avoid it. Why do you think you need a slice of *references* to Nodes?
Without having read the full example, isn't this a perfect case for `.map(Ok).unwrap_or_else(||{ self.handle_awesomeness_not_found(a, b) })`? (And yes, I'm waiting and hoping for NLL too. Meanwhile, when the borrow-checker rejects my ideas, it often forces me to discover even better, simpler and more readable ways to express what I mean.)
&gt; I want to create nodes once and reuse them as a readonly collection I read this and think you should create a `Vec&lt;Node&gt;`, then pass it as a `&amp;[Node]`. But &gt; in multiple threads. makes this a bit more complicated. If you plan on starting the threads yourself via `std::thread::spawn`, you'll need to to make sure the slice is valid for the static lifetime; probably by moving the vector in to an `Arc&lt;Vec&lt;Node&gt;&gt;`. If you're using `rayon` or `scoped-threapool` you won't have such issues. &gt; if I pass &amp;Vec&lt;Node&gt; to make_rand and will try to access this node it will copy Node to the stack of make_rand? No; there is no copy unless you explicitly `.clone()` or call some other function that copes (except for `Copy` types, which are things like numbers, they always get copied). When you call `make_rand(&amp;nodes, rng)`, each node stays in the vector, where you put it.
It's an oversimplification, yes.
Can anyone help with a borrow checker/lifetime problem? Error is "cannot infer an appropriate lifetime for lifetime parameter in function call due to conflicting requirements" https://old.reddit.com/r/learnrust/comments/8kuyzv/cannot_infer_an_appropriate_lifetime_for_lifetime/
&gt; No; there is no copy unless you explicitly .clone() or call some other function that copes (except for Copy types, which are things like numbers, they always get copied). When you call make_rand(&amp;nodes, rng), each node stays in the vector, where you put it. Hmm. well since I want to keep original vector of nodes immutable, I need to create a new vector to shuffle it inside the function body. For that I use: let mut pool = nodes.to_vec(); rng.shuffle(&amp;mut pool); But when using &amp;[Node] to_vec() shows an error: ^^^^^^ the trait `std::clone::Clone` is not implemented for `Node` So I need to copy vector including its elements to create a new one. Or I can use [&amp;Node] instead and it will just copy references to the new vector. So this is what I did. Is there is any other way I'm missing?
Will there ever be a hardcover version? I want to one day show my proverbial children version 1 of the language that almost single-handedly pulled us out of the 50 year-long dark ages during which we tried to write vital software in unsafe languages. And it's a great book by the way, I don't think there's a language out there that offers such a complete and clear guide to the language right there on the website! Besides being a great introduction to Rust, I really like the fact that it sprinkles on plenty of generic low-level programming advice and techniques since I don't frequently use low-level languages. The step-by-step instructions on how to figure out why the compiler is angry with you are great too. I feel like this book is a meta-teacher, it teaches you how to let Rust teach you how to write safe code. This book teaches you that the compiler is your sensei and not a crazy old hobo yelling at you for no reason ("This is MY cardboard Box, you can't borrow it!"). And in my opinion writing Rust code improves your C and C++ code, because it doesn't allow you to be lazy nor ignorant. So all-by-all, this book is much more to me than just a language tutorial. Kudos to you, Carol and the other contributors and thank you for making it available for free.
Let's write out the elided lifetimes on `Game::mark_owned`: impl&lt;'a&gt; Game&lt;'a&gt; { fn mark_owned&lt;'b&gt;(&amp;'b mut self, player_idx: usize) { let player = &amp;self.players[player_idx]; self.fields[1] = Space::Marked(player); } } Now `player` has type `&amp;'b Player`, so `Space::Marked(player)` is `Space&lt;'b&gt;`, but we need it to be `Space&lt;'a&gt;`. So we need to add a condition `'b: 'a`. Or, more concisely, we can just borrow `self` for lifetime `'a`: fn mark_owned(&amp;'a mut self, player_idx: usize) { let player = &amp;self.players[player_idx]; self.fields[1] = Space::Marked(player); } However, now you have a problem that the `Game` struct is self-referential, which is gonna give you a whole lot of other problems. For starters, `mark_owned` will borrow game for its whole lifetime, which makes it kinda useless. You are going to need to rework your design to solve this.
do you by any chance have something on github I could take a quick look?
Well this is why I'm asking here :). I could make it work, but I'm very unsure if I'm doing it in the right way. This is because rust lang in itself needs getting used to and I have very OOP background. So although I understand how everything works in the lowest level it is hard for me to see if I'm doing stuff in the right way or just because I'm stuck in OOP perspective.
Can you give me some pointers on how to rework this? Should I store an index in Space::Marked, instead of a Player reference?
I‚Äôm sorry, I forgot to put that in my original post. I‚Äôm using the same nightly as you, and no dependencies. Thank you so much for your help! :)
Follow-up: More or less the same results for the `arm-unknown-linux-gnueabi`. &gt; rustc rust.rs --crate-type=staticlib --target=arm-unknown-linux-gnueabi &gt; nm -g librust.a | grep mem 00000000 T _ZN4core3mem7size_of17h101ba76bbb231763E U _ZN4core3mem7size_of17h101ba76bbb231763E U memcmp 00000000 T _ZN17compiler_builtins3mem6memcmp17h1b10bb2752b27739E 00000000 T _ZN17compiler_builtins3mem6memcpy17h768c59a2d18ac1b0E 00000000 T _ZN17compiler_builtins3mem6memset17h2e18fbbea4331177E 00000000 T _ZN17compiler_builtins3mem7memmove17h3d1f54105a01139eE 00000000 T __aeabi_memclr 00000000 T __aeabi_memclr4 00000000 T __aeabi_memclr8 00000000 T __aeabi_memcpy 00000000 T __aeabi_memcpy4 00000000 T __aeabi_memcpy8 00000000 T __aeabi_memmove 00000000 T __aeabi_memmove4 00000000 T __aeabi_memmove8 00000000 T __aeabi_memset 00000000 T __aeabi_memset4 00000000 T __aeabi_memset8 U memcmp U _ZN4core5slice6memchr6memchr17h7d114be75a53c8dbE U memcmp U memcpy U memset U memcpy U memset U memcmp U memcpy U memset U _ZN4core5slice6memchr6memchr17h7d114be75a53c8dbE U memcpy U memset U memcmp U memcpy 00000000 T _ZN4core5slice6memchr6memchr17h7d114be75a53c8dbE 00000000 T _ZN4core5slice6memchr7memrchr17h03e548bc1585ad2eE
Looks like Reddit decided to show the video preview of the oldest channel video instead of the newest video. Here's a direct link: [https://www.youtube.com/watch?v=KS14JIRZTBw](https://www.youtube.com/watch?v=KS14JIRZTBw)
Why not use `(x % n) as T` and `clamp(x, 0, n) as T`?
Another example would be immutable data structures with structural sharing.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/watchpeoplecode] [Live-coding a Rust crate for cancellable services \[x-post from r\/rust\]](https://www.reddit.com/r/WatchPeopleCode/comments/8kvjpb/livecoding_a_rust_crate_for_cancellable_services/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I don't have any other ideas. Rustc is clearly doing something _weird_, or Cargo is incorrectly configured somehow. Have you tried compiling everything manually using `rustc --crate-type=staticlib &lt;source files&gt;`? You may also need to specify your target with `--target=&lt;your target triple&gt;`. My only thought here is that Cargo might be adding stuff; I was specifically avoiding cargo to prevent that and test rustc. If that fails with the same error, try compiling my exact example and posting what you get from `nm`. That's all the help I can give; if it's not Cargo then I have no idea what could be wrong. Sorry.
Thanks a lot! This was a very useful and clear explanation.
Yes, one of the possible solutions would be to store index instead of the reference. If you don't need to modify players after creating them, you can still keep references by splitting them out of the game struct, so that the borrow wouldn't be self-referential. Something like [this](https://play.rust-lang.org/?gist=0b7f2d4a00e03ebdf7c5711377624eba&amp;version=stable&amp;mode=debug) or [this](https://play.rust-lang.org/?gist=c980eb1aa99ef92e9e82619e007273dd&amp;version=stable&amp;mode=debug).
Thanks a lot!
Consider differential compression if you're trying to do updates or transformations instead of purely distribution.
Please see https://github.com/sharkdp/bat/issues/134
In the meantime, `bat` can be used in almost all places where you would typically use `cat`: https://github.com/sharkdp/bat/issues/134
Both issues have been resolved by now.
The same problem occurs with Clippy if, like me, you target stable for development. I've been meaning to look into how to force Clippy to use a separate build artifact directory so I can add that to my justfile.
The recent nightlies hit me hard, too, because of proc macro breaking changes, and futures-await hadn't updated due to a chain of dependcies that we're still being updated. I wish there were better coordination with important crates that rely on nightly before breaking changes were made.
In general, knowledge of the stack and heap are useful for understanding the *why* of many parts of Rust, but not the *what*. Ownership and borrowing themselves are entirely separate from stack vs heap, but these are the tools by which Rust *manages the distinction* between stack and heap. Rust's type system (like all type systems) is fundamentally about specifying invariants of code, and stack allocated and heap allocated values have different invariants. A heap-allocated `Box&lt;T&gt;`, for example, has to have a single owner so that the memory is freed at most once and is never used after being freed. A reference to a stack-allocated object on the other hand can't be returned "up" to the calling function because the object will be destroyed at the end of the functions scope. You can avoid this by *moving* the value itself (creating a copy on the stack for the calling function to use), or you can put the value on the heap and move a smart pointer like `Box&lt;T&gt;` instead.
Cool, thanks!
&amp;Vec&lt;T&gt; wouldn‚Äôt let you do that anyway. &amp;mut Vec&lt;T&gt; does make sense for this reason though.
That's a much better way to do it. Although I honestly don't know what restrictions, if any, C places on `extern` objects, so I'd be hesitant to say it solves *everything*, it definitely helps with the worst parts. I think I've seen about two linker scripts before, though, and oddly enough neither of them did this for I/O addresses even though they were both for environments where that would have been useful. My experience is not exactly representative of the state of the industry, but it's not encouraging.
Yes, `snap` seems pretty solid too.
I need to invoke the gen_range(T, T) -&gt; T function of rand::Rng on a &amp;mut rand::Rng trait object, but the compiler states this is impossible. Is there any way to do what I wish? 
I think keeping general "application state" which includes possibly thread pools in a struct which is passed around is the general idiom that more complex projects follow. In the new `tokio`, you don't need a threadpool if you're using [tokio::spawn](https://docs.rs/tokio/0.1.6/tokio/executor/fn.spawn.html), but even without a threadpool you need to keep application data / resources _somewhere_. What's so bad about having a struct of things or handles you pass or clone around when needed?
No, male nipples don't have sexual characteristics. Please don't post this kind of nonsense here.
Wtf? They definitely do, many men have sensitive nipples and associate that with sexual activity. Don‚Äôt answer nonsense questions with nonsense.
/r/lostredditors
It is easier to write a game with C# and Unity.
I still don't quite get it. Why not just run the code depending on the compile directly after the compile is done? 
Please don't say "the compiler states this is impossible." Show the actual error message. Error messages often contain details that are important to understand the problem you're having. Anyway, in this case, your problem is probably down to `gen_range` being a generic method. Generics can't be called via trait objects, no way, no how. You'll have to find some other way of doing whatever it is you're doing. Maybe look into the source of the `gen_range` method to see how it's doing what it's doing.
You can set it in your cargo.toml : ``` [dependencies.image] version = "0.19.0" default-features = false features = ["png_codec", "tga", "jpeg"] ``` 
Thanks for the reply, sorry for not being specific. I ended up instead just passing a tuple of the 4 rng types through the methods are an. The error itself said "cannot invoke gen_range() on rand::Rng trait object", if that even matters anymore. 
On js side, the use of radius is not consistent. Sometimes you use it, sometimes you use \(x \- 5, 10 ...\)
Neat project! I'm guessing every get request calls some Webservice using this crate, which does one step?
You could wrap float types in an enum and impl for that enum? Probably a more idiomatic way exists.
Because that requires scripting this or manually triggering it when its done. Also you need to open the socket as reuseaddr or it can fail. 
It would be possible to provide support in listenfd by linking against system libs. But systemfd can‚Äôt pretend to be launchd. 
this reminds me of my old project https://github.com/jaroslaw-weber/beelang
&gt; The particularly cool bit here is that when the driver is done with the hardware reference, Rust will automatically `Drop` it, which will invoke our `after_peripheral_access` method. Does this maintain safety with `mem::forget`?
Very nice, thank you!
In my opinion, the principal reason such shootouts are fun, is that even though one should and does know better most of the time, one cannot nevertheless avoid entertaining the idea that the results show something useful, most especially when one's favourite language or languages are shown in a favourable light. 
Why `std::ptr::NonNull` take a `*mut` pointer ? Why we don't have a `const` alternative ?
weird, I have enabled only the futures above and it still gives me the "wasm not supported yet" error
Have you try to disable jpeg too ? [dependencies.image] version = "0.19.0" default-features = false features = ["png_codec", "tga"]
I'm trying my hand at a small math solver, first goal of being able to do `1 + 2 * 3` works, except that it doesn't take into account the BODMAS rule. I'm sure I'm doing it completely wrong but I want to figure stuff out on my own. [Github](https://github.com/VictorKoenders/math_solver)
Is there a way to implement this functionality without unsafe? If there is not, is the way i implemented it with unsafe safe? struct A { s: String } struct B { s: String } fn a_to_b(a: &amp;A) -&gt; &amp;B { unsafe { std::mem::transmute(a) } } fn b_to_a(a: &amp;A) -&gt; &amp;B { unsafe { std::mem::transmute(b) } }
FWIW (I'm the one who was looking over for your code for unsafe on Twitter) the design looked very clean with respect to the borrow checker; I haven't looked over all the code, but I might use this project in the future to show people the right way to structure code in Rust.
I‚Äôm pretty sure that this problem is over\-constrained. There is no way to solve it exactly as stated. But: &gt;I'd rather not have to add new entries for f16, f80, or f128 if they're ever created How much is this really worth worrying about today? New primitive numeric types have been added to Rust exactly once since 1.0, with `u128` and `i128` in 1.26. They took over two years to go from [a formal RFC](https://github.com/rust-lang/rfcs/pull/1504) to [being available on Stable](https://blog.rust-lang.org/2018/05/10/Rust-1.26.html#128-bit-integers). New floating points primitive types are not even an RFC yet. Maybe they‚Äôll be added eventually, maybe not. But it won‚Äôt be soon, and it won‚Äôt be often. Meanwhile, if your implement your trait for `f32` and `f64` separately and the code is identical \(or almost\), you can use a macro to de\-duplicate it. You‚Äôll still need a new version of your library to add e.g. `f128` if it ever exists, but that should be easy. In fa`ct num_tra`its itself does exactly this: [https://docs.rs/num\-traits/0.2.4/src/num\_traits/float.rs.html#1916\-1919](https://docs.rs/num-traits/0.2.4/src/num_traits/float.rs.html#1916-1919), it‚Äôs not like it would magically gain `f128` support without a new version.
Development on a program to run a reloadable text adventure game.
As in enum WrapperEnum&lt;F: Float&gt; { V(F) } impl &lt;F: Float&gt; Scalarlike for WrapperEnum&lt;F&gt; { ... } ? That seems to mean that, whenever anyone calls the mapping function(s) with `f64` as the destination type, they have to wrap the arguments and unwrap the result: // v1, v2: f64 use mumble::WrapperEnum as WE; let WE::V(result) = mumble::do_map(..., WE::V(v1), WE::V(v2), ...); ... which is a lot of syntactic overhead compared to just // v1, v2: f64 let result = mumble::do_map(..., v1, v2, ...) and I don't see a good way to hide it. :/
I'm making a 3D Engine made for webassembly, for use through webcomponents (that's gonna take me more than this week since I'm still fairly new to rust and struggling on some pretty simple stuff). This week I'll be focusing on batching Scene operations together to reduce the Rust/JS boundary traversals to a minimum. [Github](https://github.com/wtvr-engine/wtvr3d)
My current idea is to take a list of operations and have several simplification passes. `[Constant(1), Add, Constant(2), Multiply, Constant(3)]` `[Constant(1), Add, Constant(6)]` `[Constant(7)]`
I am making a tool for organizing collections of files. Things like your ~~porn~~ pictures saved from the internet, music, etc. The idea is to create a tool for tagging items \(files or directories\) that uses the filesystem alone \(no special database or metadata format or storing tags as metadata in the file format itself\). You create a tree hierarchy of tags, and the tool creates a corresponding hierarchy of directories. Then, you can tag each of your items in your collection with as many tags as you want, and the tool automatically makes symlinks in the respective tag directories, pointing to a single master copy of the item. tl;dr: a tool to manage lots and lots of symlinks in a directory hierarchy
Fantastic thanks! 
Hi! I have this struct pub struct HexData(pub Vec&lt;u8&gt;); A simple alias to Vec&lt;u8&gt; in order to use structopt. The thing that is bothering me is that I have to add .0 everywhere in order to use Vec's methods. Is there a way to not use .0 everywhere?
You can implement `Deref` and `DerefMut`, that eay all functions that take a `Vec` as `&amp;self` or `&amp;mut self` can be called on your struct directly.
But you have to differentiate between them in code. For instance let n1 = 10; let n2 = n1; println!(n1) Will print 10, and this let s1 = String::from("foo") let s2 = s1 println!(s1) will be a compile error. The difference is that s2 has taken ownership of the string so s1 is no longer usable.
Rewriting a program I made in Rust in C++, because apparently the professor didn't say "any object oriented language", although I heard it. It is interesting though, the C++ version sadly seems faster. I might or might not make a comparison blogpost :-)
What's wrong with this answer? It's not true? I thought it is.
Well, that (extract common functionality) is what i would have done, but 100% of their functionality is common, they only differ in where they are used. Its a bit like the Celsius/Fahrenheit thing, but with references.
Heuristically solving multidimensional [knapsac problems](https://en.wikipedia.org/wiki/Knapsack_problem), using a bunch of different heuristics.
**Knapsack problem** The knapsack problem or rucksack problem is a problem in combinatorial optimization: Given a set of items, each with a weight and a value, determine the number of each item to include in a collection so that the total weight is less than or equal to a given limit and the total value is as large as possible. It derives its name from the problem faced by someone who is constrained by a fixed-size knapsack and must fill it with the most valuable items. The problem often arises in resource allocation where there are financial constraints and is studied in fields such as combinatorics, computer science, complexity theory, cryptography, applied mathematics, and daily fantasy sports. The knapsack problem has been studied for more than a century, with early works dating as far back as 1897. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/rust/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
You monster. Is this seriously using a travil CI loop to push new favicons into a git repo?
I am writing an RFC for [including scope names in diagnostics](https://github.com/rust-lang/rust/pull/49898).
Meh, it seems to be working now... Thanks for getting me to try again :)
&gt; Sorry I just disagree, I've never gotten much use out of auto refactor tools. Fair enough. ...but that simply doesn't reflect reality for the majority of people and teams. The benefit of a strong type system has always been controversial, but the research broadly seems to fall on the side of 'really very important when you have a large code base' ... mostly because that allows you to automate large scale refactoring and testing. It goes hand in hand. &gt; I disagree that you can write an application in language X, but you must have some special need to use Rust... Depends if you're liable to lose your job or your investor's money if you make a bad decision. If it's just you, do whatever you like. 
The differentiation there in the model is actually not related to String using the heap; it's because 10 is one of the builtin integer types, all of which are Copy. Copy types may be used more than once, and therefore aren't subject to the same restrictions that other Rust types are. But this doesn't need to correspond to using the heap; there are plenty of examples of Rust types that are not Copy but don't use the heap (the most straightforward example is types with `&amp;mut` references in them, which are not safe to copy because that would violate the requirement that `&amp;mut` pointers cannot alias).
I can't conceive of a situation where `#[repr]` matters for one-field structs. If more fields are added then yes a defined field ordering is necessary which the Rust ABI explicitly does not provide (and last I heard, the compiler is randomizing field ordering in debug mode to eagerly break code that assumes field order is defined when it is not).
Thanks!
I‚Äôll try to sleep as much as I can at the beginning of the week in preparation for RustFest.
I finally made some progress on the thermodynamic temperature vs. temperature interval issue in [`uom`](https://github.com/iliekturtles/uom) (type-safe zero-cost dimensional analysis) this weekend and will be looking to get that complete this week.
The difference here is not that the `String` in allocated on the heap, it's that `String` isn't `Copy`, while `i32` is. See [https://play.rust-lang.org/?gist=05d02d1f10415c578bc6284c3b91e83d&amp;version=undefined&amp;mode=undefined](here) for an example. 
The NLL\-WG's Zulip Chat is both hilarious and highly educational at the same time! Frank and Niko are definitely among some of my absolute favorite Rust writers.
It personally sounds like a code smell to me. What's the exact semantic difference? The algorithms are the same but with differing constants, or they interpret the data differently?
Nice idea, do you have a Github link to your project ?
Are you sure this isn‚Äôt something made on Microsoft paint?
Thanks
Not yet. I have just started and I only have some basic code on my laptop, which sets up the master directory of items. Once I have something usable that more-or-less works, I will make a github repo for it.
You're looking for /r/playrust
It might be that `Deref` and `DerefMut` are supposed to be used for smart pointers only.
I'm looking at working through "Modern Compiler Implementation in ML". This is my first real foray into Rust (I've been lurking for years), so maybe it's an aggressive first project. But I've already gone through a good chunk of this book with OCaml. The shifting landscape with the stdlib there was enough to finally get me looking more at Rust. So far, so good. I think I started at a good time since 1.26 introduced some really nice usability improvements, particularly with match patterns. My biggest hurdle thus far is the book really likes the idea of using immutable data structures (classical functional language lists and the like) and I haven't found a good Rust equivalent. I'm not all that concerned with performance at this stage, so using a Vec for everything isn't really a goal unto itself. Maybe I just need to roll my own? So far I like what I see. The IntelliJ IDEA plugin is really handy. My biggest gripe thus far has been building a small AST by hand. Since the enum for the node types is recursive, I have to call Box::new everywhere, which really clutters the structure. With OCaml this was considerably cleaner to write. Fortunately, I don't have to build too many ASTs by hand -- mostly just for test cases.
Oh, while I'm here, does anyone know what the Rust equivalent of OCamllex would be? My brief survey of lexer generators in Rust seem to all require syntax extensions to the language itself and thus require rust nightly. I'm looking for something considerably simpler and am entirely okay with running an external application to generate the lexer.
That sounds interesting. Will you write up your findings?
I think so 
Actix is a nice library too, and later this year I believe that the proc macros that Rocket uses will be out by the 2018 edition, so maybe then it will become a stable competitor again.
Rust should be rewritten in Rust to make it on topic for this subreddit 
What do you mean by "reloadable"?
I think moves, lifetimes, borrow checking, and memory safety are all basically bound up together and the same thing. I would say my favorite features are that (the safety) and also Cargo, which isn't mentioned here, for the ease of modularizing, testing, and documenting.
That sounds like constraint handling rules.
So, I'm getting ready to publish my first set of crates, and I was wondering how should I go about publishing two crates that are in the same repository? You can see my orientation library/crates [here](https://github.com/rcarson3/mori). I've got it split up into a serial and parallel crate, so I would like to keep both in the same repository, so I can easily track and address issues/features for both of them. I guess part of the thing is I'm not too sure how to also set up my Cargo.toml file at the base directory level for this type of situation. I'm also wondering if it might just be best to move all of the serial code directories to their own folder in the directory and not have them live in the base directory. Also, I was wondering how would I go about make sure a crate only gets compiled/used for just my test directories? I'm currently have them added to the library Cargo.toml, but I really don't want them included in the compiled library if I can get away with it.
~~[RIIR](https://transitiontech.ca/random/RIIR)~~ [RRIR](https://steamcommunity.com/app/252490/discussions/4/616199347856426408/)!
All of Rust's ownership rules are based on local variables in spans of code, which means they're anchored to the stack. You can't have a non-static lifetime divorced from source code or a stackframe.
The consistency between output and input usage of the "impl" keyword is only in the syntax; as the RFC points out, there is semantic difference between the two usages; impl Trait on output is a callee-chosen type, but impl Trait on input is a caller-chosen type.
Huh, it looks like I'm moving to Rocket if Actix has pretty much the same feature-set. I don't use anything too exotic, so I'm guessing porting will be pretty painless. I was considering rewriting in Go to get my project released and stable. I'm okay with an unstable library/framework, I just don't want to be debugging a dependency as well as the nightly compiler. Also, they should make a bigger deal out of WebSocket support, because it looks like it supports it OOTB. 