&gt; Actually the compiler knows nothing about threads. The safey guarantees result from the borrowing/lifetime system :) I suppose you could argue that the compiler knows about threads because of `Send + Sync`, if we're being pedantic anyway.
Anyone that is familiar with xml-rs? I've read XML via xml-rs, stored the element-names &amp; attributes in a struct and then try to write them: ``` fn write_xml&lt;T&gt;(w: &amp;mut xml::writer::EventWriter&lt;T&gt;, elem: Element) where T: std::io::Write { use xml::writer::XmlEvent; let en = elem.name; { let mut eb = XmlEvent::start_element(en.borrow()); for attr in elem.attrs { eb = eb.attr(attr.name, &amp;attr.value); } w.write(eb); } // ... w.write(XmlEvent::EndElement { name: Some(en.borrow())}); } ``` and of course I get the: "borrowed value does not live long enough" error for the attr.name.borrow() How should one really do this?
Great! If a simple interface for a sync client is all thats needed, check out [reqwest](https://docs.rs/reqwest/0.8.6/reqwest/) as well.
This unhelpful error is an NLL diagnostics bug. There are a number of issues in the rust repo about this case and very similar ones, for example https://github.com/rust-lang/rust/issues/49397 -- and AFAICT all of the NLL diagnostics problems and bugs are being worked on as we speak. 
Correct, because lifetimes *don't have* mutability. Only *borrows* do, and borrows are held for certain lifetimes. That's why the `&amp;` syntax has both a `'a` and a `mut` in it; while a struct like `Borrower` only has a `'a`. The lifetime itself isn't "mutable" or "immutable", it just is. In fact, there can be both mutable and immutable borrows with the same lifetime, which is what happens in OP's example.
Thank you very much! I implemented it in a similar form now, but instead of the \`defer!\`, I use a handle struct containing the receiver, which sends the detach message in its \`Drop\` implementation. Works as expected.
I’ve started using https://github.com/alexcrichton/socket2-rs, basically the same authors as net2, but a cleaner API.
If you need TCP/UDP then tokio is the only way aside from sync std::net or its improved version net2 new tokio brings lot of nice stuff (e.g. Timers and simple async file system) The only problem is that it is painful to use and takes a while to get used to ugly futures and impossible to understand type errors from bunch of combinators. Well, After practice you'll get used to it
if you set this up I might be able to contribute some examples. We use mio extensively in [sozu](https://github.com/sozu-proxy/sozu)
I'll give it another try! I vaguely remember that doc so I might run into a problem but perhaps things have changed since I last looked.
&gt; That's a bit like translating assembly into Java. This is a good analogy, given that [that has been done](https://github.com/graalvm/sulong)^kind of.
Partially. In Erlang most APIs look like synchronous code and so do the implementations of your message handlers, in actix/Rust in general the lower-level asynchronicity "primitives" (such as futures) are more directly exposed to the user. I personally don't like the way futures and their combinators look/work, but there is ergonomic work being done with async/await that will alleviate some of these issues.
You should add this link to the ReadMe in the github page :)
Thank you for that! I finally understood why the keyword "dyn" was meant to be, it was pretty unclear for me until then.
I still don't really understand the rules about lifetimes. I tried for a while to get this to work: let factors: &amp;[u32] = &amp;[2, 3, 9]; let x= factors .iter() .map(|f: &amp;u32| { (1..) .map(|v| v * (*f)) .filter(|v| *v &lt; limit) }); But it said that the 'f' didn't live long enough. On the other hand, there was no problem with factors .iter() .map(|f: &amp;u32| (*f..limit).step_by(*f as usize)) Can someone give me an explanation about why there was a problem with the first but not the second, and how I should write this code in the future? Thanks
Wow that's incredible. Much respect to the Rust team, thanks for all you do!
Well, the error message is rather straightforward: | 18 | eb = eb.attr(attr.name.borrow(), &amp;attr.value); | ^^^^^^^^^ borrowed value does not live long enough 19 | } | - `attr.name` dropped here while still borrowed 20 | w.write(eb); 21 | } | - borrowed value needs to live until here `attr.name` is dropped at the end of the loop iteration, but you need it to live at least until you write the event. To do that you can iterate over `elem.attrs` by reference (`for attr in &amp;elem.attrs { ... }`), instead of consuming the vector - you don't even use it by-value in the loop anyway.
Weak is reference-counted which I'd rather have the option of avoiding.
Ran across a very compelling use for this just yesterday!
The problem is that the inner `map` closure is borrowing `f`, which ceases to exist at the end of the outer `map` closure, but the inner iterator you're creating needs to outlive it. This is because, when capturing a value for a closure, the compiler uses the least restrictive kind of capture that will work for the closure. In this case, it doesn't need any more than an immutable borrow, so that's what it does. To override this, you need to tell Rust to *move* all captured values into the closure and not take any borrows. To do this, just replace the closure with: move |v| v * (*f) Then it should work.
&gt; Also why is a foo : &amp;'foo mut Foo&lt;'a&gt; needed to access bar.foo as mutable when we already have a mutable reference to bar? It's not necessary, it's just that by default `self.foo` will deref' self and capture `foo` by value, which doesn't work here as it would move `self.foo` out of a borrow. So you can either type the result explicitly (so the compiler knows to ref' it) or explicitly reference it e.g. (`&amp;self.foo` or `&amp;mut self.foo`). https://play.rust-lang.org/?gist=6227560289b3bc7e478e30d7e0c2d653 &gt; Edit: after some inspection changing the function signature to &amp;'foo mut self from &amp;mut self does make it accept which makes some degree of sense that self actually needs to be passed with a mutable reference of that lifetime but I can't do that in my use case due to the Iterator protocol (it's a next method) any way around this? Remove the explicit lifetime: https://play.rust-lang.org/?gist=3bcc9250e630267c253112ac6901e2b0
The point is exactly that they aren't when you are not using. Their cost is almost non-existant.
The problem in the first example is that closures capture by reference by default - to the closure given to inner `map` stores a reference to `f` (so the type is `&amp;&amp;u32`), and then dereferences it once automatically when called. So the lifetime of that closure becomes bounded by lifetime of `f` - and `f` goes out of scope at the end of the closure in outer `map`, which is not long enough. You can fix this by capturing `f` by value (so that it copies the reference into the closure, instead of having a reference to a reference), by adding `move`: factors .iter() .map(|f: &amp;u32| { (1..) .map(move |v| v * (*f)) // ^ here .filter(|v| *v &lt; limit) })
I’m getting fairly close to publishing a new crate on crates.io... https://github.com/bcmyers/argonautica/blob/master/argonautica-rs/README.md It’s an implementation of the argon2 hashing algorithm for Rust that adds some features that other Rust implementations currently lack (namely hashing with secret keys, the latest argon2 variant, argon2id, and SIMD on stable). I’m also working on a Python wrapper that uses the Rust code underneath. Any thoughts on the code ashe before I publish would be very welcome...
So `dyn Trait` will exist only to make it explicit a Trait, and therefore dynamic dispatch or late binding, will happen? Seems interesting. Would it provide any help to the compiler or just the human reader of the code?
&gt; It’s worth mentioning that if `Trait` is implemented (for?) a reference then the struct definition would look a little different. What does this sentence mean?
Thanks for this. I'm going to have to think about it, but I think I'm getting the beginnings of a clue.
`dyn Trait` is exactly the same as `&amp;Trait`, and is meant to replace it outright.
One more awesome thing in the crate that I would love to stumble upon in the documentation.
So it is to meant to make code syntactically more explicit. How about my second question? Does it help the compiler do less work or provide any other advantage?
&gt; It's not necessary, it's just that by default self.foo will deref' self and capture foo by value, which doesn't work here as it would move self.foo out of a borrow. So you can either type the result explicitly (so the compiler knows to ref' it) or explicitly reference it e.g. (&amp;self.foo or &amp;mut self.foo) or use it in a way which implicitly refs it. In all these cases you're not taking a `&amp;mut foo` but a `&amp;mut &amp;foo` as in a mutable reference to the immutable reference. As a very distilled example: struct Foo&lt;'a&gt; { a : &amp;'a () } impl&lt;'a&gt; Foo&lt;'a&gt; { fn test ( &amp;mut self ) { {let _x = &amp;mut self.a;}; // works but secretly borrows a &amp;mut &amp;() {let _y : &amp;mut () = &amp;mut self.a;}; // does not work } } &gt; Remove the explicit lifetime: https://play.rust-lang.org/?gist=3bcc9250e630267c253112ac6901e2b0 I just happened to need something with a lifetime of that length. In particular this is my iteration struct: pub struct RemovedSongs&lt;'client, 'args : 'client, 'strings, Str : 'strings + AsRef&lt;str&gt;&gt; { client : &amp;'client mut Client&lt;'args&gt;, matches : Option&lt;StringMatchSongs&lt;'client, 'args&gt;&gt;, strings : &amp;'strings [Str], } There is a function `&amp;`client mut Client&lt;'args&gt; -&gt; StringMatchSongs&lt;'client, 'args&gt;` and I need to cal that inside of the iterator and put that result into the Option and replace it with a new one whenever it runs out and generate a new one based on the next item in `strings`.
Nope, although I'm going to stick Arch on an old laptop at the weekend and try to reproduce it on my own hardware cause trying to debug on Qemu is too slow to be productive. Hopefully, something good will come from that!
the title uses "Actin" instead of "Actix"? but I definitely think Actix is a great option. I wish I could recommend Rocket, but it's been ages since it first entered the scene and they still refuse to make a version that works on stable. Until then, I can't see myself recommending Rocket... and Actix is faster anyways.
no. The abstract syntax tree already has this distinction.
The other reply is good, but the simplest answer is “Tokio = mio + futures”, if that helps.
&lt;does happy dance&gt; it works! yay! I'm so happy. This was just smashing my head in the wall. Now I know the trick of removing !feature nll to check for an issue then returning it to get things running again.
I'm hitting the bleeding edge so I expect to get cut occasionally. I'm just so glad this community is here and so freaking helpful! it's amazing.
&gt; If you want it to be generic over the runtime, neither mio nor tokio are really gonna work, as they both bring their own runtime - just at different levels of abstraction. This is completely incorrect. Excuse my strong language, but I want to ensure that the misinformation is corrected. Tokio is not tied to a runtime. The `tokio` crate includes two different runtimes out of the box. However, the `tokio` crate is intended for usage by end applications. Libraries should depend on the components that they need, which work with any arbitrary runtime. For example, look at the `h2` (http://github.com/carllerche/h2) crate. It is based on Tokio yet is fully decoupled from the runtime. You can BYO runtime.
&gt; I believe futures 0.2 has AsyncRead and AsyncWrite traits you could use to be generic To clarify even further, as per the `futures` authors, 0.2 is not intended for general usage. It is a preview only release. 0.1 remains the stable release. 
This definitely deserves it's own blog post. Thank you so much for all your efforts! This is insane.
[removed]
Is there a time line for dyn Trait being legal. 
`actix-web` seems to be really performant in the rather simple benchmarks at TechEmpower. Is there any information about how actix performs with complex mixed I/O / compute workloads and how easy it is to instrument, profile and optimize actix applications? I've used a number of actor-based systems in the past but the Achilles' heel has always been unpredictable performance characteristics and poor support for discovering bottlenecks caused by dependency chains and poor CPU cache utilization.
Ten days.
[removed]
Thanks! 
I've been working on improving and adding functionality to my point process (Hawkes and Poisson processes) [library](https://github.com/ManifoldFR/point-process-rust) born out of some math coursework. Using RustGnuplot to preview simulated trajectories was a real help to check if my algorithm worked right! Next, I'll look at introducing multi-dimensional processes, parallelized algorithms and maybe importance sampling methods.
Have you heard of [Rust Editions](https://blog.rust-lang.org/2018/03/12/roadmap.html)? It's also not simply about whether someone can keep the entire language in their head or not. If you want that, Go is a good option. There are many things in C++ that are major footguns, but they'll compile just fine and look innocuous, but you have to just somehow know they're bad, otherwise you're shooting yourself in the foot. Rust has done a good job of avoiding those huge pitfalls in my opinion, and it looks like they will continue to do so.
Mixed I/o should not change actix-web performance. Base performance characteristics stays the same. I dont know about any special instrumentation/profiling system for actor based frameworks. I used usual tools, flamegraph, perf, etc. but if you care about cpu cache utilization, actix is probably is not for you.
I don't necessarily agree with the premise; I don't keep all of any language in my head while programming. For example, `{} + [] + ''` combinations in JavaScript are wild, but strong typing provided by TypeScript means I can avoid them, and avoid needing to memorize them. A more abstract feature makes language details less relevant. A Rust-specific example: new features like `impl Trait` allows complicated `Iterator&lt;Map&lt;Slice...&gt;&gt;` type chains which can now be reduced via `impl Trait`. `async fn` lets me gloss over the internals and API of Futures in order and just lets me write working asynchronous code. Not that my advice is to ignore completely how the Future primitive works; instead, given that new features are coherent with the rest of the language and built on underlying primitives, I know at any time I can dive into the source to figure out how to influence higher-level behavior. Honestly, I would happily opt into an easy Rust GC for all my code if I knew I could convert to manual memory management later on. Rust is an excellent language for navigating through layers of abstraction. I will never keep coherence, in-place boxing, or ADTs (much less GATs and HKTs) in my head at the same time. But stdlib uses them heavily, and stdlib is a very friendly and straightforward API. Let's not assume all new features means increased complexity; it often means less!
Would you recommend the book overall?
&gt; which is why C++ is so complicated today. It's half of it. The second half is: - C++ is built by accretion, so some problems are solved by a myriad of tiny features which may or may not overlap, rather than a single more generic feature, - C++ design lacks direction (design by committee issue?), which leads to features not being quite orthogonal either, and sometimes clashing violently (still haven't digested the fiasco of Uniform Initialization vs Initializer Lists). Rust editions may solve the first issue, however the second is a tough challenge, a "reward for success". It stems from: 1. Being unwilling to wait for the "full" solution or just afraid it'll never come, 2. A lack of oversight/cohesion, "Too many cooks in the kitchen". I hope that the Rust Language Team will manage to stay on top of things, but as more people get involved in the language, mistakes will be made. And note that editions are mostly about syntax, and less about semantics, so once a feature is in...
As I understand it, you can't really draw that conclusion because it's entirely possible that you're getting fooled by external forces in a preemptively multitasked system.
Why yes, I am. I'd also like to shoutout NixOS which enables distributed builds. My mind may have broken when I saw critical OS components for my laptop being built on my desktop without me doing anything different.
I'm finding this awkwardly worked. Could someone please paraphrase? &gt;&gt;&gt; If a function returns impl Trait, its body can return values of any type that implements Trait, but all return values need to be of the same type. 
Note that for small errors editions does allow for turning "a warning into a hard error". Not sure which cases it's being employed for yet.
Impl Foo can return anything that is Foo as long as all return paths of your function return the same type of Foo. If you have 3 paths that return Foo&lt;u32&gt; thats fine and if you have 3 paths that return Foo&lt;f32&gt; thats fine too. But you cant hav 2 paths return Foo&lt;u32&gt; and one Foo&lt;f32&gt;.
How? How can the abstract syntax tree know if `&amp;Foo` is dynamically or statically dispatched?
and what happens if your users calls `.collect()` on your iterator? Then you user has has a `Vec&lt;StringMatchSongs&lt;'client, 'args&gt;&gt;` all but the last of which has already been freed. That is a use after free and is not allowed. You would need a iterator like thing that returns a short lifetime ( and does not have a `.collect()` ) but Rust does not yet have sintaks that supports that. the google trem is "Streaming Iterator".
Thanks for the thorough answer. I think it's really useful to offer it as an additional "compatibility'ish" crate.
If a function returns impl Trait, its can return any type that implements Trait, but it has to pick one type and stick with it. It can't actually return a different type each time it's called. It just doesn't have to disclose the exact type in the function signature.
What's `Foo`?
I love that h2 and other tokio-io-based libraries allow me to bring my own runtime. I think that what /u/ashfordneil meant by "using Tokio" was using the `tokio` crate and its associated runtimes, whereas h2 [only uses the `tokio-io` crate](https://github.com/carllerche/h2/blob/master/Cargo.toml#L39), which is runtime-agnostic and parts of which are now included in `futures-io`.
That's not what the iterator returns. `StringMatchSongs` is itself an iterator hat returns `Song` objects and that's what `RemovedSongs` also returns except it does some extra checking and removes songs from a playlist if they are already in the playlist. The user won't ever get to see a `StringMatchSongs` object and it's in fact private to the module while `Song` is public.
currently, given `&amp;Foo` * if `Foo` is a struct, `&amp;Foo` is a ref to some instance of that struct * if `Foo` is a trait, `&amp;Foo` is a dynamically-dispatched trait object "`&amp;Foo`" is never "statically dispatched" when `Foo` is a trait. you would have to write either * `fn bar&lt;T: Foo&gt;(x: &amp;T)` - `&amp;T` is a ref to some struct which impls `Foo`; this is _statically_ dispatched and will be monomorphized * or `&amp;impl Foo`, which is _functionally_ the same thing as the above the whole _point_ of `dyn Trait` is that `&amp;Foo` (when `Foo` is a trait) becomes `&amp;dyn Foo`, making it clear that this is a _dynamically-dispatched trait object_. as an added benefit, this maintains congruence with `&amp;impl Foo`.
I saw a video of a talk where the speaker (Maybe /u/nikomatsakis) talks about the borrow checker as eating spinach, popeye style. I can't find the talk anymore. Can someone help me find it again?
a nice way to think about this is: having paths which return different types makes it impossible to monomorphize your function, since you can't statically separate the function into different pieces which always return the same type.
1. Intended 2. You can create a new trait `MyTrait&lt;T&gt;{type Output;...}`, and implement it differently for `&amp;T` and `&amp;mut T` 3. No. Let's deal with 1 first. Consider the following code: #[inline(never)] fn f&lt;T : Clone&gt;(t : &amp;T) -&gt; T{ t.clone() } fn main() { let a = vec![0; 100]; f(&amp;a); let b = "Hello".to_string(); f(&amp;b); } Then Rust monomorphizes f into two different functions, namely `f::&lt;Vec&lt;u8&gt;&gt;` and `f::&lt;String&gt;`. The last one has a very simple implementation: playground::f::&lt;String&gt;: pushq %rax callq &lt;alloc::string::String as core::clone::Clone&gt;::clone@PLT popq %rax retq Vectors, however, are cloned inline. When you execute: fn main() { let f_1 = f; 
I've been working on an API wrapper using hyper and tokio. I'm using hyper 0.11. Thought about upgrading to 0.12 but it looks like \`Authorization::Basic\` disappeared? After things are more tested I will publish on crates.io
the [lapin AMQP client](https://github.com/sozu-proxy/lapin) in Rust is built that way. The core is a state machine that does not specify any IO library, it just tells the client code if it wants to read or write, and if there's new useful data available. It can be integrated directly in a mio event loop, but it also has a tokio based wrapper with a futures API.
You have to pick a date, and public release seems to be a pretty reasonable choice to me.
I think that's what the compiler is for: reminding you when you forget common pitfalls. With regards to features, Rust is significantly simpler than, say, C\+\+, and features such as macros allow for extensions to the syntax without bolting more crap onto the core language. It's this modular\-but\-practical approach that makes Rust so unique and enjoyable to use.
it remains to be seen whether or not this will really help -- the scope of the changes you can make in an edition is very limited -- because people have to be able to continue to link old crates
The scope isn't that limited. Old crates will be compiled with old versions of the Rust frontend, basically. It all just has to get to the same intermediate language, which in this case is MIR. Drastic changes can be made to the language while still generating compatible MIR. I mean, C and Rust both produce LLVM IR and they're totally different languages.
1. Intended 2. You can create a new trait `MyTrait&lt;T&gt;{type Output;...}`, and implement it differently for `&amp;T` and `&amp;mut T` 3. No. Let's deal with 1 first. Consider the following code: #[inline(never)] fn f&lt;T : Clone&gt;(t : &amp;T) -&gt; T{ t.clone() } fn main() { let a = vec![0; 100]; f(&amp;a); let b = "Hello".to_string(); f(&amp;b); } Then Rust monomorphizes f into two different functions, namely `f::&lt;Vec&lt;u8&gt;&gt;` and `f::&lt;String&gt;`. The last one has a very simple implementation: playground::f::&lt;String&gt;: pushq %rax callq &lt;alloc::string::String as core::clone::Clone&gt;::clone@PLT popq %rax retq Vectors, however, are cloned inline. When you execute: fn main() { let a = 1; let f_1 = f; f_1(&amp;a); } Then `f_1` is not a compiler object or a function or so anymore. `f_1` is an *address*, and executing it corresponds to: main: movq 1, %rdi movq 0x864684, %rax call *rax The same applies to your function: main: movq &amp;v, %rdi callq const_::&lt;i64&gt; movq $10, %rdi callq *rax const_::&lt;i64&gt;: movq 0x864684, %rax ret Again, calling `const_` returns a 64-bit address pointing to the start of one instantiation of the function, and therefore it cannot be polymorphic. In Rust, functions are effectively either just an address or just a struct with a vtable. Every single (instantiated) function in Rust is nothing more than that. With instantiated I mean that the function `fn f(t : i64)` is a first class citizen and can be passed as argument to another function. The function `fn f&lt;T&gt;(t : T)`, however, isn't and can't, since it doesn't have a single function address. This is, effectively, a limitation of Rust, and also answers your third question if I'm right.
What are you actually trying to do? You want an owned value to only live as long as a borrow?
I’m trying to wrap a c api that looks something like this (using the same names as in the post) struct borrower *get_borrower(struct lender *lender); Where ‘struct borrower’ will have dangling pointers if ‘lender’ has been deallocated. For that reason I would like to tie the lifetime of the borrower to the lender. 
I'm not sure since I don't do a lot of stuff like that, but I *think* you want to put the lender into a RC and then use a weakref in the borrower: https://doc.rust-lang.org/std/rc/struct.Weak.html Someone else may have a better suggestion though.
 if let Some(ref rline) = x { //Need to make sure the string doesn't get deleted let alt = String::from("Pro - 107516:0,0,0,0,0"); let rline = if rline.contains("[") { &amp;alt } else { rline }; ... } 
May https://github.com/Xudong-Huang/may is a great alternative. It's way way way easier to use than the tokio ecosystem, yet its performance is excellent. 
Cool project! Just curious, did you consider using an error helper crate like "failure" and a parser library like "comp"?
Replying again since I don't know if you saw the other comment already or not: Actually, I think maybe Cell/RefCell might be more appropriate, though it depends on exactly how you want to do things. Of course, if you're doing this on multiple threads, throw everything out and look at Arcs and/or RWLock/Mutex.
Yeah I’ve been considering wrapping the c lender in a RefCell so that I can use ‘&amp;self’ instead of ‘&amp;mut self’ since it’s ok to have non-mutable borrows. That would probably work. 
It's not the longest, and I skipped a few sections. (sections on linting and benchmarking, compiler tweaking) The sections I did read were informative and I like that they standup pretty well on their own (you can skip around). It clarrified some things for me that I already suspected were the case in rust. If you have already been programming rust for years you probably know a lot of it already. That's not the person the book is for IMO. It's also not going to make you a master of concurrency or async programming. You will learn a bunch of rust specific tweaks which collectively will add up to a modest improvement in the performance of your code. You will also get an overview of concurrency in rust. For people not very familiar with the crate ecosystem it will probably a more comfortable experience being exposed to them through this than just hopping right into docs (for the crates that are covered). I've only been programming in rust for a few months. I knew some of what was presented in the book already but for me it was worth it. 
Is there a copy and paste error in the second code example on line 11? ```rust struct AlsoDisplay; impl fmt::Display for CanDisplay { fn fmt(&amp;self, f: &amp;mut fmt::Formatter) -&gt; fmt::Result { write!(f, "AlsoDisplay") } } ``` Should that be `impl fmt:;Display for AlsoDisplay`? 
It's possible, but I'm sure having a huge community to push back on unneeded features and an open RFC process will help push back against this.
That’s good to know. Sounds like I might be a good target for this book. Will likely check it out. Thanks!
I don't think the problem with c++ is 'too many features' - the problem is more like 'two sets of languages' where one is a mostly universally disliked version (raw pointers, lack of modern features) and one is a generally liked version (smart pointers, lambdas, variants, etc). Reconciling the 'modern' c++ with the old baggage seems to be the really gross part of c++, and why a lot of the modern features end up having footguns/ really weird workarounds to work with the old features. No one reasonably keeps an entire language's features in their heads anyways, it's more about how the features work together, and how the features act in isolation. I think reasoning about those in C++ is always going to be harder than in Rust.
On the standard bencher the error is the spread between min and max. It's super unintuitive.
By the way, your assistance with this last (oh so annoying) bit helped net a nice 71% speed up! Thanks again.
C++'s problem isn't the number of features, it's features that are half broken and interact with eachother badly. I don't think rust will suffer from continued growth
I see what you're trying to say but I dont even think that's the problem - you could compare the first sub-language the unsafe block of rust. it's subtle ways in which the features are half broken/ incomplete or fitting together awkwardly, IMO.
[removed]
This is cool. I'd love to see one for AsRef too (shouldn't be too hard) A small caveat - changing a parameter from a T to AsRef&lt;T&gt; (for some type T) can be a breaking change for some callees. I'm not sure if that also applies for changes from T to Into&lt;T&gt;(for some type T). That's because it can break type inference. I've only ever ran into it with Vecs and slices, but I haven't written a lot of Rust...
[removed]
&gt;That said, is this a good idea? Probably not in the general case, since implicit type coercions are a scary source of bugs, particularly for a language like Rust that errs on the side of explicitness. I'm failing to understand how this is a problem. It relies on a type having voluntarily implemented "into" (or String having implemented "from" for the type), so, you should never get something that hadn't opted in to being turned into a string, no?
Pretty much the same. For pub fn iter_rev(v: &amp;[u8]) -&gt; Option&lt;&amp;u8&gt;{ v.iter().rev().skip(1).next() } pub fn checked_then(v: &amp;[u8]) -&gt; Option&lt;&amp;u8&gt;{ v.len().checked_sub(2).and_then(|n|v.get(n)) } at `opt-level=2` you get the asm: example::iter_rev: lea rcx, [rdi + rsi] add rcx, -1 xor eax, eax cmp rcx, rdi lea rcx, [rdi + rsi - 2] cmovne rax, rcx test rsi, rsi cmove rax, rsi ret example::checked_then: mov rcx, rsi sub rcx, 2 add rdi, rcx xor eax, eax cmp rcx, rsi cmovae rdi, rax cmp rsi, 2 cmovae rax, rdi ret and both benchmark at 3ns/iter
As long as Rust's features are consistent (lower entropy), they will be easier to remember because your brain can compress the info. Also, personally I feel like I have all of Rust in my head and it doesn't take up much space, and there's still many features I'd want in Rust, e.g. const generics, HKTs, inline proofs (when Rust code becomes provable). I switched to Rust from C++ (and D) in 2014 and have been using it almost every day since then. In C++, a lot of things are hard to remember because they are high-entropy edge cases that the brain can't easily compress and they are easy to get wrong, turning into footguns. Rust is much more consistent and regular and you don't need to use any of the "design patterns" (workarounds for low abstraction capabilities), because you can just abstract the patterns away by factoring them out. In Rust, the compiler is much more your friend than in C++, it won't let you run into footguns, so you don't even have to remember a lot of stuff until you get a compiler error that reminds you of it (or teaches you if you didn't know it before). You can also afford to be more tired when writing Rust (compared to C++) because you can trust the compiler to not let you do stupid things.. It can seem overwhelming when starting to learn Rust, because some of the stuff you need to be productive is more complex than in C++ (e.g. the borrow checker) so the initial curve from zero to productive is steeper, but it soon becomes second nature and then it's smooth sailing. Whereas in C++ it's easier to get started but you'll be sailing in a stormy sea with monsters from the start, and have to spend a lot of time debugging..
Yep, you're right. It's been fixed. Thanks for that :)
There is no type information during the parse phase, which I think the question was about, so there is no way of knowing (beyond guessing) what `Foo` really is until the types have been resolved. Unless that has changed of course since I dug into those things, but it's a reason why macros don't have that I formation, for example. All it knows at that point is that it's an identifier and in which context it's used. The `dyn` keyword could give more contextual information, just like it does for humans, and communicate intent. That could perhaps be useful during later phases, but I don't know for what, beyond better error messages.
oh, AST. yeah, that makes sense. once you get type resolution you know what `&amp;Foo` means; before that you don't, like you said. there's no reason that knowing if something is a trait object would be useful in the AST pass, so, yes, even though `dyn Trait` signals a trait object at the syntax level, there's not really anything helpful there?
You're right that this strategy will never require an "invalid" coercion in the sense of trying to turn type A into type B where no such coercion exists. However, just because a coercion is possible doesn't mean it should happen, e.g. if you wanted to pass a string to a function but accidentally passed an unrelated integer, usually the type system helps catch such bugs, but here the coercion would occur silently and no compiler error would arise.
I wrote up a small comparison at [the bottom of the README](https://github.com/ryanisaacg/quicksilver#comparison-with-ggez)
But it's not just compile old crates; it's let old and new crates interoperate together. That's a much more strict rule than just compiling to the same MIR.
This part doesn't really make sense: &gt; It’s worth mentioning that if `Trait` is implemented a reference then the struct definition would look a little different. Ever since [RFC 599](http://rust-lang.github.io/rfcs/0599-default-object-bound.html), `struct A&lt;'a&gt;(&amp;'a Trait);` and `struct A&lt;'a&gt;(&amp;'a (Trait + 'a));` have been equivalent. 
[Yep, `impl Into&lt;X&gt;` instead of `X` can certainly break type inference](https://play.rust-lang.org/?gist=7234d10a429a27d2ff5f43a2c248a995&amp;version=stable&amp;mode=debug). That's sadly a problem with making stuff more generic :/
So dyn is just syntax sugar to make comparisons with impl Trait nicer? I guess that's nice because it has seemed weird to have the bare Trait since it's not passing traits around in the same way as other stuff.
"inline proofs" \- that sounds super interesting. Realizing it's pure speculation at this point, but I'm very curious: how do you envision this might look like?
I wonder why Rust does not accept simply `Trait` instead of `impl Trait`? Both, `impl` and `dyn` seem unnecessary in this situation, since `&amp;` could imply `dyn` and lack of `&amp;` could imply `impl`.
Reading that thread raises a question for me - would const generics also mean that Diesel would no longer require the 128-columns feature and associated twenty minutes to build on my laptop?
It is purely to make things more clear for humans, yes. The symmetry is a nice side effect too.
It also has (as far as I know, unfixible) soundness issues.
When you attempt full stack garbage setups you must fix....
Funny - the parser had the same question...
Could be useful for better error messages, but other than that I don't know.
Thanks /u/burkadurka! I've removed those parts from the post.
I've removed this from the post. See the comments below but TL;DR, RFC-0522 has made the syntax equivalent. Most commonly, traits are implemented for owned types: `impl Trait for i32`, but you can also implement traits for reference types `impl&lt;'a&gt; Trait for &amp;'a i32`. I was referring to traits that were implemented for reference types.
&gt; Old crates will be compiled with old versions of the Rust frontend, basically. how do I call a macro from an old crate that expands to code that is not allowed in the new edition?
will something to type raw identifiers be stabilized too? like let r#dyn = 1;
It's kinda like Scala's implicit conversions, which are convenient, but can be a bit much and maybe a bit surprising. Still, probably not *too* bad as long as you're using it only for Into's that aren't widely implemented.
Cool. I hadn't looked too much into it, so I wasn't sure if there was something subtly different to make the bare types still relevant.
I don't know much about diesel (never used it), but looking at the code it seems to me that columns are implemented via tuples, no arrays. Const generics will only fix arrays. So no.
I am not worried about too much bloat. Actually, I think that there is still many features Rust needs, not to be another C++, but to be ergonomic and expressive. Major examples that come to mind are generic associated types, const generics and generators, but I think that there's also more expressivity and flexibility needed around lifetimes, enums and trait objects. What these allow is primarily better APIs. They are tools for library authors to express intent and enforce constraints precisely. Of course, a sense of cohesion is paramount to keep when designing these features. I think that the problem with C++, besides footguns, is lack of cohesion. I also think that Rust is able to better because of: 1) the added benefit of hindsight 2) smaller design "commitee" 3) tighter leadership and cohesion around the ecosystem. I'm generally quite content about the discretion and design taste of the language team.
I am sorry for misunderstanding. Unfortunately I am still not understanding how the pieces fit together. Perhaps a larger examples, one that shows the iterator impl, and how this `RemovedSongs`fits in?
Yup! That’s even the syntax!
Ah I see. In that case perhaps you could specify the type in the comment?
Sounds like Haskell tbh \*ducks*
what would be wrong with generating part of the MIR with a different front end? it wouldn't be easy, but it also wouldn't be impossible
Is there a reason why type inference does not work here?
It's unable to guess a concrete type that satisfies `FromIterator&lt;char&gt;` and `Into&lt;String&gt;`. This is a weakness of the current implementation, not necessarily something that can't be done. [Read up on Chalk](http://smallcultfollowing.com/babysteps/blog/2017/03/25/unification-in-chalk-part-1/) for some indication of how this might be fixed in the future.
This is the plan, afaik.
It *just works*™ Rustc tracks where pieces of code come from in their "spans". The span is not only used to reconstruct macro backtraces, but also carries other information about the defining crate. This is already used to allow libstd macros to call otherwise unstable functions. The information also includes the edition of the defining crate, which can be used to [ensure everything works as expected](https://github.com/rust-lang/rust/pull/50999).
I'm not an expert in that field, but I think it could be similar to TLA+ but with Rust syntax :)
&gt; C++ is built by accretion, so some problems are solved by a myriad of tiny features which may or may not overlap, rather than a single more generic feature, &gt; Aren't we heading there with Rust in exactly the same way? I fail to see how editions perfectly solves this.
I never implied otherwise. The whole point of editions is that it *will* work. I really don't understand the vote distribution in this comment thread.
Great writeup, however there is one thing I haven't seen explained very well that is also missing in this post -- What does the *caller* to a function that returns `impl trait` see as a return value? ``` fn gives_impl_trait() -&gt; impl MyTrait { ... } fn calls_impl_trait() { // what the heck is the type of x? // It's not a trait object, so what is it? let x = gives_impl_trait(); } ```
I like the T: Into&lt;String&gt; because it lets me pass static strings into functions that require a String - and this is so, so often what I end up doing.
Thanks :) Since `impl Trait` get's turned into a concrete type by the compiler, `x` will be the concrete type. In the [tracking issue](https://github.com/rust-lang/rust/issues/34511) there is a task &gt; deferred: let x: impl Trait Which will make `let x = gives_impl_trait()` easier to work with as I believe you can then write something like `let x: impl Trait = gives_impl_trait()`
This seems well and fine, except that `impl Trait` is strictly less functional than generic syntax, which has no explicit key word either. Given that the general consensus seems to be not to use `impl Trait` from a public API (at least yet), in my mind, this is *creating* inconsistency, not ameliorating it.
The dual of Bar ;)
Editions let you remove some kinds of things.
Thanks for responding, but I don't think that's correct. Look at this in the playground: [https://play.rust-lang.org/?gist=fd2fcbe096a8cb41a5cadf095b55ad0b&amp;version=stable&amp;mode=debug](https://play.rust-lang.org/?gist=fd2fcbe096a8cb41a5cadf095b55ad0b&amp;version=stable&amp;mode=debug)
I certainly can't keep all of unsafe Rust in my head (I was on a code review the other day that ended up in a discussion of the exact semantics of LLVM's `getelementptr inbounds`, for instance). If we're already talking about reasonable subsets of Rust, I think it's fine to expect that individual projects can say "We will avoid use of this weird feature," the same way there's already implicit pushback against unnecessary use of unsafe code.
I’m not sure who is encouraging you to not use impl Trait. But also, it was discussed for an extremely long time before being stabilized. I think it was two years?
But why is the author singling out Ubuntu 18.04?
possibly of interest: https://www.ponylang.org/
It's not that Rocket refuses to make a version that works on stable. If they did target stable, a lot of the ergonomics would go by the wayside because the code generation capabilities, by definition, aren't stable. What we need is for procedural macros 2.0 to stabilize. At that point, all the codegen using the experimental compiler plugins can be rewritten reliably as procedural macros. There are a couple others features that Rocket needs to be able to target stable, but the big one is procedural macros 2.0.
/r/playrust
Can you detail the protocol a bit?
Hell yeah! Big fan of the BEAM. It’s so cool to see projects like this, Remacs, etc bring Rust to these great softwares. What a time to be alive :D
&gt; Nobody cares about Metal, at all. Which is, of course, why Unity and Unreal already support it...
For the function name, theres's a stack overflow question which may help (if the unstable feature is still there): https://stackoverflow.com/questions/38088067/equivalent-of-func-or-function-in-rust, wrt the crate name, you can use the environment variables set by cargo: https://doc.rust-lang.org/cargo/reference/environment-variables.html
I was thinking about [this discussion](https://www.reddit.com/r/rust/comments/8ik620/notes_on_impl_trait).
How did you configure them to talk to each other?
I have a feeling that Actix probably does much better, unless it boxes everything, because of Rust’s use of value types.
&gt;Each new edition will have the opportunity to remove things from the language completely, while still maintaining compatibility with old code. (really, it's true, but I'm not going to explain how they do it here.) C++ can't remove things without breaking code, and they've so far been very unwilling to break old code, which is why C++ is so complicated today. Why couldn't C++ do the same thing as Rust, the different versions already are essentially editions (C++11, C++14 etc)? Compilers would still need to support the old editions anyways so the only extra thing needed would be the ability to compile and link together C++ code that is using different editions.
I think this is only partially correct. Sure, the trait solver could find out which type satisfies both traits, but there might be multiple such types. And what then? Taking any of those types at random is a bad idea, so I would expect the compiler to print an error instead. But this now has the disadvantage that merely adding a trait implementation can break downstream crates. And this is something the Rust people really try to avoid. [This](https://play.rust-lang.org/?gist=e65f13a93297f4a2c90c5d61455a987c&amp;version=stable&amp;mode=debug) also doesn't work although there is only one type that satisfies the trait bound.
C++ doesn't (yet) have modules, so when you #include a file it is literally being copied and pasted into the current file. Many files become one, giant C++ file, basically, code from you and from every third party you depend on. It's not impossible for them to define the standard so that every single file would have to be marked individually for which edition they're using, but that would suck, and I'm certain it would still break someone's project where they were relying on the exact semantics of files being pasted together. There's more to it than that, but that's one of the fundamental issues. Rust uses a crate and module system, so it could theoretically be done at the module/file level, but it will be done at the crate level, which is a concept C++ doesn't really have. The exception to all of this is that you already can do some of this edition stuff in C++ if you structure your build system right. You just make sure everyone uses C++ancient for their header files, and then inside the class implementations you can probably use whatever you want, you just have to make sure your Makefile compiles each file correctly.
Btw, another thing I'd like to have in Rust is syntactic sugar for delegating struct methods to a member (I know there are at least 2 crates for this, but it should be part of the language IMO), and maybe to delegate whole trait impls to a member (for a better alternative to OOP-style inheritance: when you want to re-use behavior (a trait) that involves state (the member), but you want to make that behavior available for the parent struct).
I'd love to see something like Dafny 🤞
Actix does Box all messages. It is not suited for heavy computations. 
This time, with no suggestions nor votes, I selected the quote of the week (better this than nothing, I guess). Please folks give me something to work with so I don't need to go search for quotes and crates.
You're not doing anything with the string you create, so it becomes the result of the `match`. But you're not doing anything with the result of the `match`, so it becomes the result of the `for`. But a `for` can only result in `()`, which is a type mismatch, so the compiler rejects it. Just do something with the string you're creating.
Maybe Ubuntu users don't dare to follow tutorials, not explicitly written for their Ubuntu version. This is not a bad strategy, if you don't really understand what you are doing. But one would think that the overlap between people interested in rust and people who don't know at least a little about using the shell should be small...
I don't think you need to memorize {} + []. You should mostly avoid doing something like that.
I'm not a fan of Go or GCs, but which problems occur when there are two GCs in the same program (taking care of disjointly allocated memory regions / objects)?
I think you need to add some more detail. At first you said these components "run independently" but later you're still deciding whether to use threads or... something else. The basic architecture here is going to determine what kinds of communication are available. 
That worked perfectly! Thanks a lot!
Thanks! This comment and the other ones that followed was very useful. I've decided to write a sans-io API first and then later provide a futures based wrapper. 
Thanks a lot for introducing "place" categories to "Upcoming events". Before, I had to use `.filter()` with my brain, which is pretty slow. This is way better now :)
It's a concrete type generated by the compiler, even though you cannot name it. (Anonymous). Compiler generates a new type for each function having a returned imp Trait 
I set up my desktop and router to enable SSH connections and made a dedicated builder user. On my laptop, I used the `programs.ssh.extraConfig` to set my desktop's user, IP address, port, and authentication key, and then added it to `nix.buildMachines` before enabling `nix.distributedBuilds`. I'm pretty sure I've seen you with my alternate account. People like you are making it difficult to keep my accounts separate. Are you really a NixOS user?
I don't know of any such crate, but could you share your benchmarking setup? I'm unhappy with mine and want to change to criterion as well, I'd be glad for some hints :)
Yeah, I’m still working on a SIMD optimization for my internal regex engine 😅
It basically comes down to how GCs work. Each one wants to manage a directed graph of objects which it has full freedom to deallocate orphaned sub-graphs and, if it's a compacting collector, to move them. That makes it a hassle to design a comfortable API that allow performant data exchange between the two GCed regions.
I already cannot keep all of Rust in my head when programming. But I know where to look if I'm not sure whether I can or cannot do something in a better way than what I'm doing instead, or whether a feature exists that does exactly what I'm trying/wanting to do. The thing with Rust is, that most of the time features are orthogonal and KISS. As long as that's the case, I don't feat Rust becoming a second C++.
I [blogged](https://llogiq.github.io/2018/05/18/criterion.html) about that recently.
What exactly do you want to measure? Total mem? If you're on Linux, `time` may be able to answer your call, given the right arguments.
&gt; I wonder why Rust does not accept simply `Trait` instead of `impl Trait`? This *might* be done in some future, but for now backwards compatibility is much easier. Switching around the meaning like that without a deprecation phase is not possible. &gt; Both, impl and dyn seem unnecessary in this situation, since &amp; could imply dyn and lack of &amp; could imply impl. No, the `&amp;` is completely orthogonal to the `dyn`/`impl` information. You can also work with a reference to `impl Trait`, and `dyn Trait` doesn't need to be a reference. It can be handled in any form that is a pointer on the stack, for example in `Box&lt;dyn Trait&gt;`.
That is unfortunate indeed, I'd much prefer standard deviation.
You might be interested in https://github.com/rust-lang/rfcs/pull/2393 and https://github.com/rust-lang/rfcs/pull/2429 I am personally fine with writing some boilerplate, but I can see the lure.
Thanks for linking it, although I've already read it. What's missing for me though is the story of how to save results over time and how to evaluate it. I've tried saving benchmark results in files that are named after the commits they were taken on, but after some time I'm feeling that this is not the way to got. That's why I asked for the "Setup" rather then "How to use criterion" :)
[removed]
I don't know of such a crate, but you can use [memory flame graphs](http://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html) as for other languages.
I agree static dispatch should have been the default when neither dyn nor impl are specified. But it's probably too late to do that even if the editions make it possible in theory : that would be a huge change in the language, maybe in a distant future when more than 95% of the code has switched to the `dyn` syntax. The `dyn` keyword would still be necessary anyway. Dynamic dispatch always require a reference, but you often need to use references for type statically dispatched too, so you need to distinguish them.
The prost-build documentation seems missing https://docs.rs/prost-build/0.4.0/prost_build/. Is there another resource or example on how to integrate compiling proto files with cargo?
That would be awesome :) From what I read, it seems to be an issue with the newer gcc versions, so it will also affect other distros as soon as they upgrade. Unfortunately I'm not well-versed enough with compilers to be able to debug this.
Not specifically, `Send` is also relevant in a multiprocessing context and `Sync` is also relevant in a single-threaded concurrent context (e.g. coroutines) :)
&gt; C++ can't remove things without breaking code, and they've so far been very unwilling to break old code, which is why C++ is so complicated today. They did remove some features, for instance digraphs and `auto_ptr`.
Ah I apologize for being vague -- the code is @ https://gitlab.com/postmgr/postmgr/ I'm writing some software to closely monitor/manipulate postfix as a child procesis, plus a web admin interface. There's the part of the code that starts Postfix and manages the process (which ideally only holds on to the `ChildProcess` object so it can send signals to it, etc), then there's the chunk that runs the web admin (which is basically just running actix-web). These two components are separate, and they're not in their own threads *right now* because Postfix goes to the background immediately after starting -- so currently I start the Postfix component then I start the web admin which holds up the current single thread of execution and never returns. I think my question is pretty general though -- if you have two large-ish components/services/whatever in a rust application, how are they supposed to speak to each other and run possibly mutative commands? Should everything be controlled from loops in `main.rs` (or wherever the mutable references to the components were created?)?
I don't use the user forums. Is there anywhere else that suggestions can be posted? Perhaps you should have several places for it (forums, reddit, etc.) to make it accessible to more people?
This looks really nice; I might end up using this instead of \`quick\-protobuf\` :D
[removed]
&gt; what is able to target webassembly? C/C++ and Rust are easiest to port as all you need to do is to get the compiler to generate wasm code instead of native code and this is already done. Languages that need a runtime (java, go) or interpreter (js, python) would need to get the interpreter or runtime ported to wasm - this is doable, but adds significant overhead, so its less likely to be done and used in practice. I know that Go has plans to target it (it will include runtime). JS itself is poorly suited for that, but I am sure someone will do it. Some (inclomplete) list is here: https://github.com/mbasso/awesome-wasm#languages
Note for people who're only hearing about protocol buffers now: The original author is now working on [Cap'n Proto](https://capnproto.org/), which is faster and more sophisticated.
Author is here. For parsing, runtime does not do any parsing as it is not a compiler, so no chomping. For failures, i should have a look if i return back to working on this project. It is not moving since ±March. Selected crates should be compatible with possible future switch to no-std runtime, so that's a condition.
This is like linking oracle.com when there's a java project discussion.
Saw this in [an issue linked in TWiR](https://github.com/rust-lang/rust/issues/47856): struct Ok&lt;T: Clone + = ()&gt; { t: T, } So the `+` seems to be a trailing `+` in a list of trait bounds, but what does the `= ()` part mean? 
What country are you based in?
It seems they are located in Berlin, Germany. (See https://1aim.com/.)
&gt; Aren't we heading there with Rust in exactly the same way? Yes. The language and the library are evolved independently, and the core and library teams don't really know everything that is stabilized (particularly hard for library) so at the current scale a cohesive design is already pretty hard. These teams focus on the most important new features but cannot keep everything in mind.
Default type. For example, `HashMap` technically has three type arguments, but most people never use more than two, because the third has a default.
Cap'n Proto has had a lot of commit activity, but no releases for about a year (0.6.1 last June/July), anyone knows if there's one upcoming? Any idea on a 1.0? The idea of Cap'n Proto sounds awesome, BTW.
I guess that's because to actually live in US tech cities you have to earn that kind of salary. Which works well if you live remote in a cheaper city. EU is just not that expensive :)
My point was you can a get a remote job for a US company while living in Europe and get a US salary. So European tech companies are now competing with US salaries. 70k euro /year just doesn't cut it anymore when trying to attract top devs 
I've been meaning to nominate [ndarray](https://crates.io/crates/ndarray), but the following issues have been holding me back: 1. I'm wondering if it's already been crate of the week. Was this how I discovered it? But I find it difficult to find the answer to this 2. I find the user forums technologically hostile (the people are of course great), so I can't be bothered to engage there
Thanks for the info. I think nostd retirement is going to be a fun restriction! :-)
I'm trying to achieve following goal: - read file line by line - for each line send GET request - parse response using serde-xml-rs - postprocess the response - store result in the other file I want to do it as fast as possible but I also have limit of number of request per minute. I'm going to use [ratelimit_meter](https://crates.io/crates/ratelimit_meter) crate and send request using `reqwest::unstable::async::Client`. Unfortunately, I'm stuck with code that sends request and returns future. My current code looks like that: #[async] pub fn send(&amp;self) -&gt; Result&lt;Response, String&gt; { self.client .get(&amp;self.url_s()) .send() .map_err(|e| format!("{:?}", e)) .and_then(|mut res| { let body = mem::replace(res.body_mut(), Decoder::empty()); body.concat2().map_err(|e| format!("{:?}", e)) }) .and_then(|body| { let mut body = Cursor::new(body); //io::copy(&amp;mut body, &amp;mut io::stdout()).map_err(Into::into) deserialize(body).map_err(|e| format!("{:?}", e)) }) } which is mostly taken from [reqwest example](https://github.com/seanmonstar/reqwest/blob/master/examples/async.rs). But I get error: --&gt; .../client.rs:38:17 | 38 | / self.client 39 | | .get(&amp;self.url_s()) 40 | | .send() 41 | | .map_err(|e| format!("{:?}", e)) ... | 49 | | deserialize(body).map_err(|e| format!("{:?}", e)) 50 | | }) | |__________________^ expected enum `std::result::Result`, found struct `futures::AndThen` | = note: expected type `std::result::Result&lt;dto::hotel::response::Response, _&gt;` found type `futures::AndThen&lt;futures::AndThen&lt;futures::MapErr&lt;reqwest::async_impl::client::Pending, [closure@.../client.rs:41:26: 41:48]&gt;, futures::MapErr&lt;futures::stream::Concat2&lt;reqwest::unstable::async::Decoder&gt;, [closure@.../client.rs:44:44: 44:66]&gt;, [closure@.../client.rs:42:27: 45:18]&gt;, std::result::Result&lt;_, _&gt;, [closure@.../client.rs:46:27: 50:18]&gt;` Could you please help me?
Oh cool, I went through that book a few days ago too (though I haven't put my implementation up on GitHub yet). Are you going through "The Next Week" as well?
I added an implementation of [strongly connected components](https://en.wikipedia.org/wiki/Strongly_connected_component) to my [pathfinding](https://crates.io/crates/pathfinding) crate yesterday. I also used this crate to assign my 155 students to their preferred projects in my school using the [Kuhn-Munkres](https://en.wikipedia.org/wiki/Hungarian_algorithm) (a.k.a. Hungarian) algorithm.
Having been unemployed for 8 months and spending a significant amount of time trying to find these mythical remote jobs at even half that salary, they just don't exist enough for C/C++/Rust to be mentioned. I've seen _two_ relevant job postings period.
Don't worry too much about understanding every single thing about Rust, it will always be okay to ask. As long as you can write the stuff you want to write, that's great :) But I agree with you, while there are still things I don't know or understand about Rust I feel it's possible to completely know it at some point. With C++ that is just impossible. 
I'm going to call my Rust sequel [Smut](https://en.wikipedia.org/wiki/Smut_(fungus)).
It's all about connections
I would actually like to add support for this to Criterion.rs itself, but I've been busy with work and other projects lately and probably won't get around to it for a while. Therefore, my suggestion would be that you could submit a pull request to add this feature to Criterion.
No, but given the topics I generally post on (see my post history) I tend to run into a LOT of alt accounts. I do have an account meant for subreddits like this one, but it hardly ever gets used. Let’s take this to PM.
Is there anything that could be done to change that? Also, why is actix-web so fast?
[removed]
Box doesn’t mean slow. It might be even faster, because you move only pointer around.
Much less widely used, mature and supported.
I’m following Gaffer on games’ [network tutorials](https://gafferongames.com/post/virtual_connection_over_udp/). The connection happens over UDP and there is ordering and reliability implemented on top. Is this what you meant by protocol?
[removed]
Just being curious: what do you mean by technologically hostile?
I read somewhere from the maintainer that it's actively used in their main product (sandstorm.io) but they work off master branch and haven't cut a release in a while. There was talks about a release happening soon.
Top American devs, anyway. US salaries are bananas compared to most other countries. 
Nice work!
&gt; Each new edition will have the opportunity to remove things from the language completely, while still maintaining compatibility with old code. Are there any features that will be removed?
Regarding your first point: I just grepped for ndarray in the this-week-in-rust repo and it looks like it was never crate of the week so far.
I admit I'm impressed, but that means new editions can never count on the absence of a given feature -- e.g. it's okay to add feature X because it would only be unsafe if feature Y existed. I can always call a macro from an old crate that still has access to feature Y.
I share the same preoccupation. People mentioned editions have the possibility of removing features and the main issue is coherence of features (not repeating C++ design). However, I have only seem more features being added. More traits, more language items, more syntactic sugar. This isn’t bad, most additions made the language better. The question is, when will it be enough? Does Rust to have every good feature out there? Will there come a point where the added complexity will be more expansive than the added benefit of a new feature? I was told the stdlib won’t change even on new editions to keep backwards compatibility, will we end up with two Rust grammars to be able to read? I love Rust, it is very complex but, so far, in a way that makes me a better programmer all around, mostly because of its design around memory management. I worry that one day The Book will have to be 1000 pages long to explain a language packed to the brim with features and pointers and Traits for every memory use case under the sun.
I'm not aware of any plans to deprecate digraphs (and honestly, this would be tricky to do, as it's likely that some C++ programmers prefer `and` to `&amp;&amp;`)? Just to make sure, did you mean to type trigraphs?
Can highly recommend this place. The folks are 1aim are great. :)
If you're legitimately looking and 1aim isn't a fit for you, DM me with some idea of what field you're looking for. I might know some folks. :)
Perhaps someone who's got the time and is not averse to the official forum software can copy all suggestions you folks make in this thread over so we can see and vote on them there? 
I believe he did, since those definitely were removed. There have been a few other things though, like the "register" keyword, function exception specification ("throws"), and changing the "auto" keyword
[removed]
I haven't been following actix/actix-web very closely. Is there much correspondence with the Pony programming language?
I haven't done a ton of Rust (I'm certain that I haven't even encountered all of Rust yet), but I know I definitely can't keep all of it in my wetware's RAM already.
We are based in Berlin. We cannot currently offer remote work for Rust developers due to the phase at which we are at in 1aim. You are correct. Salaries in Berlin are lower than that of salaries in the US. However you must take into account, that the cost of living in Berlin is extremely reasonable for a European capital city. Germany is also a welfare state so that means that you are covered for all social insurance, including health insurance. We have many engineers working with us who relocated for their position at 1aim and they all confirmed that their quality of life and standard of living in Berlin is much higher than most other cities. Salaries at 1aim are determined at the interview stages depending on experience and technical ability. 1aim offers a competitive start up salary comparable to other start ups in Berlin. Let me know if you have any other questions. I am more than happy to help!
Yes, you are correct. We are based in Berlin!
Put out a crate for dense bitsets partly to get a feel for the tooling around publishing libraries. Mostly I'm continuing to hack on a tiny but powerful data structures package for approximate counting/frequencies/sets. I'm not yet working on this in the open, but I'm making good progress. So far I have bloom filters, count-min sketch, and I'm working on a hyper log log implementation right now. Studying some of Redis's source to better understand how some other implementations work in the wild.
I don't know if it's 100% related, but [check out loom](https://github.com/aysylu/loom) in Clojure.
If you are interested in a Rust position at 1aim, DM me and I can give you more info about 1aim, how great it is to work there and life in Berlin. At this moment in time, we cannot offer remote roles but if you would be interested in relocating to Berlin, then do get in touch! 
There is no such :). Actix is some simple abstractions on top of tokio+futures
I would imagine the `try!` macro will be one of the first things to go now that we have the `?` operator. there are also some deprecated functions in the string. I'm not aware of any language features specifically targeted for removal, but I know there is a desire to rethink the module system significantly, for instance.
&gt; Is &amp;impl Trait possible, and what does it mean? In what situation it can be usable (and has no synonymous without impl)? You can put it in argument position wherever you would write `fn foo&lt;A: Trait&gt;(a: &amp;A)`before. It also [works in return position](http://play.rust-lang.org/?gist=eb94812665d94657a17097bf8f5c775f&amp;version=stable&amp;mode=debug). &gt; I think dyn Trait must be handled by a reference or any kind of pointer (like Box), since it has unknown size. Yes, but not in all cases. Unsized `Trait` is allowed in places where e.g. `str` is allowed. &gt; Does Box&lt;dyn Trait&gt; differ from Box&lt;Trait&gt;? No, it's the same as for `&amp;Trait`/`&amp;dyn Trait`.
AFAIK know sandstorm is mostly without a team, since the company ran out of funding. /u/kentonv now works at Cloudflare.
Something like [weigh](http://hackage.haskell.org/package/weigh) but for Rust would be really cool.
I think it's safe to assume we never get two mutually exclusive features X/Y whose combination would be unsound. Or has this already happened or was proposed somewhere?
Yeah, no, you really can't... Finding such jobs is incredibly hard.
So far I'm just letting them sit in my target directory. I haven't been doing anything more with them besides reviewing them as I change thing (one change was ~ -71% to runtime! woot!). A long term plan will include automating the generation of the benchmarks using a travis setup and possibly more. not sure yet.
Hm, i think once you've had one remote jobs, you build up a network of other remote workers who you can ping for jobs and they can recommend you. After my first remote job, i never had trouble finding another one. 
Many of the 'half broken' features are there because C++ is over 20 years old. Rust has the advantage that it could learn from C++ mistakes and that from the beginning some competent people are working on it, but i bet that in 20 years there are some features/language constructs that are considered to be a mistake by then
You are right!
I'd suggest exa and loc. Maybe also gifski but I haven't had a chance to use it.
That could impede its uptake. I know that, for a while, everyone was complaining about The GIMP's name.
That does sound tempting, but I'm seeing numbers here suggesting that a very experienced engineer could be looking at as little as 50k€/year at a startup in Berlin. As bad as the cost of living and cumulative expenses might be in the Bay Area, we're still talking about 20% of prevailing pay scales here. I'm not sure how one can manage, say, taking the children for a visit with grandparents in the States at least once a year on a salary like that... is that really a representative salary? Mind, I can still see it making sense, given the rampant age discrimination in the Bay Area, along with the ridiculous cost of housing, inconsistent quality of education (effectively, a decent public school in the district will cause housing costs to skyrocket), etc...
Thanks for the heads up! I'll look into the build failure. In the meantime, the \[0.3.2 docs\]([https://docs.rs/prost\-build/0.3.2/prost\_build/](https://docs.rs/prost-build/0.3.2/prost_build/)) should be functionally the same.
Ubuntu has a new repo for the latest stable versions of dev tools, [ubuntu-make]( https://wiki.ubuntu.com/ubuntu-make), rust-lang is in there too.
And I seem to remember Google itself switched to FlatBuffers...
Take a peek at https://github.com/rust-unofficial/awesome-rust#parser and evaluate options there. I've toyed w/ nom and pest. The former is the most popular and I found the latter was a bit inflexible (by intention). So I'd probably recommend nom, but really unless you have complicated needs like nice error handling, handwritten isn't that hard. Just keep the string/bytes and a cursor and work through building structs.
One of other solutions is lalrpop.
`fd` as a faster `find` is pretty exciting, the latter was felt sluggish after experiencing the speedup from `grep` to `ripgrep`.
The kind of person to relocate for an earlier stage company is usually younger without those kinds of family obligations, so I imagine they are not the main focus. For someone like me, 25 and single, it's a decent opportunity if I was looking for a job.
You should spend some time in Berlin, pay is just one factor in quality of life and you may be surprised with how far each € goes there.
Sorry for late response, had some big holidays here ) I think the issue still persists: } else if self.compare_and_swap(a.id, a, b) { self.increment_rank(b); return true; } Here, after if check but before increment some parallel union could be fully executed, using not updated rank of b. This could lead to selection of other node with presumably bigger rank, while it should be equal and incremented. I do not know how much is it a problem in practice, nor am an expert in lock-free programming. Have you benched it? I see you are comparing correctness against single-threaded implementation, it would be interesting to see how they perform. I also wonder what kind of algorithm could use parallel union-find? Clasterization with preset distance threshold? 
My vauge understanding is that the relevant people know about the issue but have some other concerns about the bencher and would like to either resolve things all at once or ditch it entirely.
Fwiw Cloudflare uses Cap'n Proto internally.
[Gluon](https://github.com/gluon-lang/gluon) is written using LALRPOP \- their code is definitely worth looking at to see what a full language parser looks like using those tools. It's probably one of the most complete Rust programming language projects out there (excluding `rustc` itself). Also, anecdoatally, I wrote [a toy language](https://github.com/17cupsofcoffee/ein) with LALRPOP and found it quite pleasant to work with :)
Which is not well supported in Rust yet, though work has been done and is being redone: https://github.com/google/flatbuffers/pull/3894#issuecomment-379048617
Dont forget [Tantivy](https://github.com/tantivy-search/tantivy) and [Wyrm](https://github.com/maciejkula/wyrm)!
ripgrep. That's by far the Rust project I use the most even though I had to `alias ag=rg` because it's hard to forget old habits.
Hell, if it was 70k€ vs $120k, I'd probably jump. I'm in the &gt;$200k range in the SF area, but I don't like it here. In a better and more affordable area, I could take a 50% hit. But I don't really see it working with a 65-80% hit, even with a much lower cost of living. I guess it doesn't hurt to apply and see what kind of actual salary it comes out to... My wife certainly wants to get out of the States.
is shi*less: &gt; less, shiless, shishiless, etc or is it: &gt; shless, shiless, shiiless, shiiiless, etc ? (you probably want r/playrust/)
...for a few special cases. protobufs are overwhelmingly how Google servers store data and communicate with each other.
I think GrinCoin is an interesting blockchain project because its very different from other cryptocurrencies. IIRC the cryptocurrency is inflationary to avoid being used as speculation but rather as a research project. Some of the tech might make its way into Bitcoin, we will see. If you are not familiar with GrinCoin (MimbleWimble) it has an interesting backstory: https://github.com/mimblewimble/docs/wiki/A-Brief-History-of-MinbleWimble-White-Paper
Cap'n Proto looks awesome, but I don't think it's a viable replacement everywhere. One common use case for protobufs are databases of many tiny messages. I experimented with Cap'n Proto for one of these, and found that even after packing and compression, it was noticeably less space-efficient. (Sorry, I don't remember numbers, and YMMV anyway.)
I use `xsv` to do CSV analysis when I'm working with database exports and stuff. It's a CSV tool using the `csv` crate. I think the DataFusion engine is something to watch, and also the `mentat` project by Firefox which is inspired by Datomic, which is the most interesting database I've ever heard of. Additionally, I believe that Rust and Wayland will become good friends, as there are a few major window manager projects written in Rust.
Out of curiosity, are you at one of the major companies that you can freely name? Also how long have you been working in the industry. I'm asking because I was at a startup, so my salary was less than it could've been otherwise, but for my skillset I want to determine a potential range for future opportunities (I'm between jobs). I definitely agree that SF is kind of garbage. The homelessness problem and traffic gets worse each year and the price inflation is insane. I'm living in SoCal right now, and oh man it's so much more relaxing.
40% of Ethereum nodes run this (Rust) implementation: https://github.com/paritytech/parity (The other 60% mostly run the Go impl.) Parity Technologies is also doing a lot of work with WASM (https://github.com/paritytech/wasmi) to integrate it with Ethereum.
I’d say the first one
Cap'n Proto is stable and more or less complete, at least as an encoding scheme. Frequent releases aren't needed.
[Habitat](https://habitat.sh) - build/deploy/management software tool [github](https://github.com/habitat-sh/habitat)
It probably wouldn't be that hard to check if the parameters are taken by value, reference, or mutable reference and then choosing `Into` for value parameters, `AsRef` for references, and `AsMut` for mutable references.
I was having trouble figuring out how to read a file asychronously, but was lucky to get some help figuring this out at the Rust Hack &amp; Learn in Berlin. I figured it might be useful to share in case someone wants to try something similar in the future! :D
Startups and a couple of bigger companies along the way. Startups are rarely as good for salary. A lot of them try to say that the equity makes up for that. That's like saying that lotto tickets are equal to money. Particularly if the terms of the equity are such that you take all of the risk, but get none of the price protection. "Valuation at exercise" is synonymous with "expensive toilet paper". The older big companies tend to pay okay (not great) when you sign on, but don't keep up on comp. You can only get ahead by changing employers, which is a terrible state of affairs. I've gotten better comp offers from some startups than others, sometimes by a margin of $100k, but the newer/reinvented diversified giants - FB, Google, Apple - are the most generous offers. The real question is, do you want to work on those cultures? That, and I fear that age will eventually force me into less code-heavy roles.
conduit.io service mesh
[removed]
Same experience here \-\- I NEVER want to do any treading in my terminal without \`fd\` either!
We can't make changes to the stdlib like this. The module system changes are 100% backwards compatible.
Is there anything you see that I can improve, since you recently worked on the tutorials? I haven't really taken a look at it, but I think I might in the near future. Have you tried out "Next Week" yet?
would annotating functions in stdlib so that they aren't visible to newer editions not work?
I'm not sure it's the best way to do this, but I've used something like this: ``` pub struct BlockingFuture&lt;F, T, E&gt;(Option&lt;F&gt;) where F: FnOnce() -&gt; Result&lt;T, E&gt;; impl&lt;F, T, E&gt; BlockingFuture&lt;F, T, E&gt; where F: FnOnce() -&gt; Result&lt;T, E&gt;, { pub fn new(f: F) -&gt; Self { BlockingFuture::&lt;F, T, E&gt;(Some(f)) } } impl&lt;F, T, E&gt; Future for BlockingFuture&lt;F, T, E&gt; where F: FnOnce() -&gt; Result&lt;T, E&gt;, { type Item = T; type Error = E; fn poll(&amp;mut self) -&gt; Poll&lt;Self::Item, Self::Error&gt; { let f = self.0.take().expect("future already completed"); match tokio_threadpool::blocking(f) { Ok(Async::Ready(Ok(v))) =&gt; Ok(Async::Ready(v)), Ok(Async::Ready(Err(err))) =&gt; Err(err), Ok(Async::NotReady) =&gt; Ok(Async::NotReady), _ =&gt; panic!( "`blocking` annotated I/O must be called \ from the context of the Tokio runtime." ), } } } // std::fs::metadata isn't exposed by tokio-fs, but you can implement it like this pub fn metadata(path: PathBuf) -&gt; impl Future&lt;Item = Metadata, Error = io::Error&gt; { BlockingFuture::new(|| fs::metadata(path)) } ```
Shout to `amber`, quite useful when refactoring methods on projects
That said, also keep these in mind if you're considering nom: glaebhoerl: &gt; If I had a dime for each time I've seen someone report that they needed to parse, went with nom as the 'default option', and ended up complaining about macros, I'd have, uh, a dollar maybe. I wonder if there's anything we can or should do as a community about this situation? This is nothing against nom which is likely the best fit for many use cases, but the perception of it as "the Rust solution to parsing" is maybe not optimal. &gt; &gt; /u/arcoain, have you looked into combine, lalrpop, or pest maybe? (N.B. I haven't tried any of them; these are just the other options which came immediately to mind) &gt; -- https://www.reddit.com/r/rust/comments/88f69x/things_i_learned_writing_my_first_few_thousand/dwkprtu/ aidanhs: &gt; I generally recommend combine to newcomers after some hairy experiences with nom (with some profuse thanks from people who had also been having bad experiences with nom). I didn't particularly care about performance so never measured it and can't comment, but it feels like a simpler model, with better error messages and less chance of pain when going off the beaten track - sometimes you have a silly underspecified format and you just want to run a bit of code on your input sequence to figure out what to do next. &gt; &gt; As it happens, I do still use nom, but it parses the tokens combine emits (https://github.com/aidanhs/frametool/blob/master/src/lex.rs). &gt; -- https://www.reddit.com/r/rust/comments/88f69x/things_i_learned_writing_my_first_few_thousand/dwkswj1/ arcoain: &gt; Looking at the linked code, combine looks much closer to the parser combinator library in Scala. Will have to give that a try next time &gt; -- https://www.reddit.com/r/rust/comments/88f69x/things_i_learned_writing_my_first_few_thousand/dwl4s04/ ... and some [benchmarks](https://github.com/Geal/parser_benchmarks/pull/18) comparing nom and combine.
That's by design, since it's memory mapped to avoid an encoding/decoding step. From the [website](https://capnproto.org/): &gt; ***Won’t fixed-width integers, unset optional fields, and padding waste space on the wire?*** &gt; &gt; Yes. However, since all these extra bytes are zeros, when bandwidth matters, we can apply an extremely fast Cap’n-Proto-specific compression scheme to remove them. Cap’n Proto calls this “packing” the message; it achieves similar (better, even) message sizes to protobuf encoding, and it’s still faster. &gt; &gt; When bandwidth really matters, you should apply general-purpose compression, like zlib or LZ4, regardless of your encoding format.
I'm pretty new to Rust but having dealt with a lot of string manipulation issues before, you're probably better off doing a wholesale string replacement with regex than iterating over each line. https://docs.rs/regex/1.0.0/regex/struct.Regex.html#method.replace_all will help do a full replacment. The `replace` method on that same page shows a good example of what's going on (but that method only applies for the first instance). Looks like someone asked the same thing on stackoverflow here: https://stackoverflow.com/questions/34606043/how-do-i-replace-specific-characters-idiomatically-in-rust. You probably can use something very similar but making the replacement below for the regex expression and applying it to a string version of your CSV: ``` let re = Regex::new(r"[\[\]]").unwrap; ``` Again I'm fairly new to the language, so there might be a faster route that doesn't involve regex.
Wheb reading this I anticipated for some "why it's not a breaking change" section, but it didn't come. I agree that it may be a better trait overall, but I'm pretty uncomfortable with this breakage.
You're quoting something that mentions packing and compression. I wrote before: even after packing and compression, it was noticeably less space-efficient.
I think that projects such as [TRust-DNS](http://trust-dns.org/) and [rustls](https://github.com/ctz/rustls) are both interesting and important as they could have a huge positive impact on the reliability and security of the critical Internet infrastructure.
Sorry, right, I missed that part of your comment. I'd be surprised if Cap'n Proto was that much bigger than Protobuf after packing *and* compression, but it probably depends on your dataset.
&gt; exa Can't wait for this to make it to Windows.
One aspect is that in one of my experiments, I was using lmdb. It doesn't support compressing multiple entries together. (Not surprising. This seems hard to do with a btree-based database; how do you determine if a given set of entries will fit into a fixed-size page without having a lot of waste or doing a bunch of speculative compression?) And I didn't use anything like Zstd dictionaries. So the compression couldn't take advantage of knowing all values have similar prefixes or the like. I think it was still worse with RocksDB, though, which does compress many entries together. I probably have numbers somewhere but can't pull them up right now.
Sure, that’s a good idea. I’ll add it to the RFC!
I’ve already experienced enough startup culture to know that the next time I do it will only be if I started the company myself, so I agree wholeheartedly. At 25 years that salary makes sense, I’m still a newborn in comparison. I’m considering a larger company just to get a sense of how they operate, but at this point I’d rather risk freelancing and just try for my own venture. I’ve had varying degrees of success already in both avenues, and now is the time for me to really risk it I think. I’ve been programming for around 12 years and I’m a proper “jack of all trades” for any stack a typical SaaS company would use, and I can actually do production quality devops, so I feel like I can go fairly far as a team of one to keep costs/complexity down. Overall though, thank you for your input. Sage wisdom is always appreciated. 
[WebRender] and its sister project [PathFinder]. [WebRender]: github.com/servo/webrender [PathFinder]: https://github.com/pcwalton/pathfinder
In theory, yes. In practice, we aren't gonna provide two whole copies of the stdlib docs just so that a few things can be hidden.
I initially wrote "hostile", but figured that would read as if people on there are hostile. What I mean is something like "I find the user experience uncomfortable", but I find that choice of words too soft. I'd prefer not to belabour what I dislike about it, suffice to say I'm not creating a user there :)
Defense work was a mixture of incredibly intellectually challenging (advanced linear algebra before my first University class in the subject) and excruciatingly bureaucratic. The clearance interviews caused people that knew me to ask awkward questions. For a young person seeking challenge and growth, I'd recommend it. For someone older, I'd say it isn't likely to be worthwhile. A lot of the engineers in defense are the ones who avoid growth like the plague, and the industry grows and shrinks at the whim of political climate. On the other hand, it has ties to aerospace, including organizations like JPL and NASA, which tend to skim the cream, so there's that.
Oh cool Way Cooler made the list. Too bad nobody ever knows how to stylize it :( Note to self: never name a project with two words ever again.
It was certainly smaller than protobufs after packing and compression for the data profiles I tested it on, three years ago, so ymmv. The big win, though, was zero copy extraction. We ended up mmapping from distributed storage to memory most of the time, and treating the serialized form as immutable. If we had a better order of data computation, Google's flatbuffers might have been a better fit, but as it was, capn proto was great.
Google's Fuschia (ie the zircon kernel) is C++ not Rust. It does have a Rust port but I don't know the extent to which its used above zircon?
For the Rust part, I got a strong sense that the author blamed Rust for not following his preconceptions of what a language should be, didn't try to understand the rationale behind what it actually is, then grabbed a quote that superficially supported his argument. &gt; Rust suffers from one of the the Seven Deadly Sins. Pride. This manifests in one of two ways. The first is the borrow checker. The second is the approach to performance over simplicity. As compared to what? [Cyclone](https://en.wikipedia.org/wiki/Cyclone_(programming_language))? Rust is the first viable candidate for replacing C and C++ in a wide variety of applications outside his more forgiving requirements. &gt; If the language has the problem that people are fighting with the language in order to become productive with it, perhaps something is wrong with the language, and not the programmers? This statement can be just as easily applied by imperative programmers to the functional programming paradigm he loves so much. &gt; The biggest issue I have with the defaults, and the borrow checker is that places in FP where you would normally pass by copy — pass by value, in Rust instead it assumes you want to pass by reference. Therefore, you need to clone things by hand and pass the cloned versions instead. Although it has a [mechanism to do this automatically](https://doc.rust-lang.org/std/marker/trait.Copy.html), it’s far from ergonomic. &gt; &gt; The argument of pass by reference, or borrowing is that it’s more performant than cloning by default. In general, computers are getting faster, but systems are getting more complex. I see no sign that he tried to discover the "make expensive operations explicit" rationale that underlies this. &gt;&gt; Performance is not a primary concern — easy of programming and correctness &gt;&gt; are. — Joe Armstrong (http://erlang.org/pipermail/erlang-questions/2014-June/079613.html) &gt; &gt; I think Rust missed this. Again, compared to what? He sounds like he's coming from the same perspective that caused people inside Google to call Go a "C++ killer" because, for their restricted use-case (a faster alternative to Python for writing web apps), it was.
While I agree that the change is needed, this is not a regular breaking change. A regular breaking change requires some code to change before you can upgrade the breaking dependency. This change requires some code to change **together with** an upgrade of the Rust toolchain. There is no path that works in both new and old versions - not unless you give up on using the `Index` trait altogether. What could be nice is if we had associated lifetimes: pub trait Index&lt;Idx&gt; where Idx: ?Sized { type 'a = 'Self; // Not sure if we want a new keyword for this... type Output: ?Sized + 'a; fn index(&amp;Self self, index: Idx) -&gt; 'Self::a Self::Output; // Or should it be `Self::'a Self::Output`? } That way the change will not be a breaking one. 
This is a real pain point, in my experience I've wanted to return owned, but internally borrowing, types from iterators about half the times I've implemented Index manually. I hope the author and others can figure out a backwards compatible way to make it happen!
Thanks for the detailed reply! That’s about what I expected. And funnily enough I too found my greatest strength in linear systems, linear algebra, optimization, and similarly related fields while doing my EECS degree. Maybe defense is still in my future. The NSA did often tout that you can change teams every 2ish years, which is appealing. 
I think you're looking for /r/playrust. This subreddit is for the programming language of the same name.
lol I honestly didn't think of that. I, too, have been using `ag` for years now and it's hard to remember sometimes.
heh thanks
[amber is a code search and replace tool](https://github.com/dalance/amber)
People pointed out a few ways to do it, but the RFC was closed while I was editing it to integrate all the smart comments from people to make it a non-breaking change. Honestly, I don’t want to spend more time on this – and I mean, on a general note, any RFC process involved in Rust-lang. Feel free to take the text of the RFC and do whatever you want with it. I’m out.
You seem to describe ATC – Associated Type Constructors – to me.
It was closed with a completely reasonable and fair explanation of why, centered around the back-compat issues. If you’re solving that problem, the extra work induced by the closing would literally just be reopening the PR. Why such an indignant response?
Dyon uses [Piston-Meta](https://github.com/pistondevelopers/meta). You can take a look at the syntax [here](https://github.com/PistonDevelopers/dyon/blob/master/assets/syntax.txt).
My comment on Medium reposted here: &gt;Thanks for the writeup! It’s always a lot of effort to compile things like this, so I appreciate the time you’ve already taken. :) &gt; &gt;I’m a Rust user, and would like to respond to some of the points you made about it: &gt; &gt;1. I strongly disagree that the Rust community has a pride problem! I have yet to find a more pleasant and helpful community, and I’d invite you to spend some time on one of the many social media platforms the Rust community uses to discover that for yourself. The time that the community members take to teach, encourage, and learn has been inspiring to me as a developer. &gt; &gt;2. You state that the ownership model in Rust doesn’t optimize for productivity, but I would argue that it does —it’s tuned for the long\-term with larger\-scale codebases, and not necessarily the short\-term with smaller programs. &gt; &gt;It’s incredibly valuable to be able to change a large (potentially multithreaded) codebase correctly with minimal cognitive effort; this is the eventual mode of contribution to successful projects! The problems that the more strict Rust compilations make you aware of would still be present in, for example, a C\+\+ codebase — but you wouldn’t discover the issues until the code runs and you trigger the race. &gt; &gt;The vast majority of my admittedly hobby experience with Rust codebases has been that if you change code and can get it to compile again, there will generally be no “surprising” breakages. Even in small synchronous programs, I’ve found this to be a great boon for my sanity. I may unload side project details from my head between the few hours I find to work on FOSS during the week, and minimizing the time I need to take reloading those details is a big productivity booster for me. &gt; &gt;\-\-\- &gt; &gt; As for the Rust code you’ve posted: I believe there are some places the code posted here might be more brief or become much more comparable with the Reason sample you posted: &gt; &gt;\* I’m not experienced enough with the channel code to tell how it might otherwise be approached, but having written several CLI utilities I can tell you right now that you would benefit from using the `structopt` crate, which is intended to cut down immensely on the Clap struct reading boilerplate. This alone should save you roughly 100 lines of the \~460 you’ve posted here. &gt; &gt;\* You shouldn’t need to pass your `slogger` instance around after you’ve registered it. By default, the logging macros use a registered global logger, so you should be able to use a global implicitly like you do in Reason (i.e.,` Log.inf``o("message"`) =\&gt;` debug!("message"`) instead o`f debug!(logger, "message`")). &gt; &gt;\* `config` could stand to be passed as a` &amp;Confi`g (immutable reference, instead of by value with Config) in a few places. Most of them seem justified when being copied to a thread, though. I guess it’s a tossup whether it’d be better to make this a global or not in Rust, since Rust doesn’t make it convenient.
I think phaylon was wrong on this one, you are clearly looking for /r/NoAdmins not /r/playrust.
server advertisements are also offtopic for /r/playrust, they want /r/playrustservers
For simply listing all files, `fd` is much slower than `find` and uses more CPU: ``` $ time find ~ -type f |wc -l 1408706 real 0m3.906s user 0m0.952s sys 0m2.218s $ time fd -HI -t f . ~|wc -l 1408706 real 0m18.918s user 0m9.589s sys 0m34.460s ```
[removed]
Rust has good reason to be damn proud of our good friend borrowck! She always has our back when it comes to things like data races or reference invalidation, and while she might seem an aloof mistress to the uninitiated, she is actually much like a loving mother, keeping us all safe &amp; sound.
Ah, good to know. Thanks.
No problem. It's kinda silly that I know this...
Red Hat feels your pain.
That is true. Is it possible to make an actor system in Rust that *is* designed for heavy computation, or is the actor model generally unsuited to that purpose?
Personally I think `gfx-rs` is one of the cooler and more ambitious projects out there... For so long high-performance graphics has been purely the domain of platform-specific, C/C++ based API's that having a universal Rusty wrapper around everything is incredibly awesome.
What is the correct reaction when one reads an article like this? I'm sure the post will get some well-argued, well-thought out responses, but honestly, it's more than it deserves. The author hasn't bothered to properly learn Rust's strengths and weaknesses, and I rather doubt he has done the same for any of the other languages. What he has done is felt the need to broadcast his half-baked opinions to the world. &gt; If you’ve gotten this far, you’ll realize that everything is still terrible. If I want to implement anything at this layer of the system, my choices are largely still C, and Go. And this is a truly awful take.
Thanks for remembering Tantivy! For those wondering, it is a search engine.
I'm not sure if I can give feedback at the moment but I want to say that this is a useful implementation for me and some of my projects!
I like lalrpop
&gt; What is the correct reaction when one reads an article like this? IMO, take what criticism you can. There are some redeeming qualities to this article. But, ignore the rest, because the writing style makes it clear that the author doesn't think very highly of their audience.
[Pastebin](https://pastebin.com/WFUNeahq) Is my implementation of `login_handler2()` correct? The compiler doesn't complain, which is a good sign, but I worry about the `return Box::new(x)`. Is it right?
https://github.com/redox-os/relibc (plus other various projects by the Redox team)
&gt; However you must take into account, that the cost of living in Berlin is extremely reasonable for a European capital city. I'm comparing the salary to a *remote job for a US company* :) When working for a remote company you still get a US salary but likewise also have the reduced cost of living as you're in EU :) Perhaps ynfortunately, but european companies will be increasingly competing with US companies offering huge salaries who offer top european devs *remote* work :)
Party of the problem is that "systems language"has multiple definitions. By his definition, Rust is one of the worst candidates. By my definition, Rust (and possibly Nim) are the only languages he looked at that qualify, and between the 2, Rust far surpasses Nim. &gt; Computers have been getting faster and software more complex Except that computers haven't been getting much faster recently. They've become more parallel, but I don't think he looked at a single language other than Rust that prevents data races. Rust is designed for exactly the same domain as C. None of the other languages match that. If something is possible in C, it's possible in unsafe Rust, and is probably possible in safe Rust, and at no point to you need to subvert the runtime to take control.
For normal searches I was getting better results with Fd, maybe worth submitting a bug report since the difference is fairly significant in your example?
Understood. That explains your other comments mentioning that Actrix is not a tool for heavy computation
Tock OS
[Pony actually prevents data races also](https://tutorial.ponylang.org/capabilities/guarantees.html), and I have found it to be pretty fun to write, though the type system feels somewhat more cumbersome than Rust's to me. I think you're right, though, that it doesn't really occupy the same "systems language" space as Rust.
What, specifically, is it too immature or too unsupported for?
What does "heavy computations" mean here?
Yes, 100% Rust (ructe template engine, github-rs, reqwest, etc.)
The whole site is generated as static pages. It's 7000 plain HTML files. 
If I was going to cherry pick a quote in the non-pride direction, it would be this one, from the FAQ: &gt; We do not employ any particularly cutting-edge technologies. Old, established techniques are better.
I see what you mean. It could be a problem in practice because if the heights aren't actually bounded as expected then the ranks could overflow, I think. But I'm not sure that the problem you've found messes up the bound on ranks. I'll have to think about it more. Though also, in practice no one is using this code, anyway. I don't know what it's good for—it just seemed like a fun idea. Thanks again for your help!
I agree. Do you have a suggestion for an alternative design? The (S)CSS for it is here, so you can experiment: https://gitlab.com/crates.rs/style
`slog` is different than `log` -- you have to pass the `slog::Logger` instance around because it has structural state. I do agree that this author wants just `log` though.
&gt; slog is different than log -- you have to pass the slog::Logger instance around I think you can use [slog-scope](https://docs.rs/slog-scope/4.0.1/slog_scope/) with a global root logger so that you don't have to pass logger. 
Here’s a simpler version of the example: fn three_way_or(bv1: &amp;BitVec, bv2: &amp;BitVec, bv3: &amp;BitVec) -&gt; BitVec { bv1.bit_or(bv2).bit_or(bv3).to_bit_vec() } 
But at the same time, it's &gt; generally advised NOT to use slog_scopein libraries and the standard pattern is to pass it around in a structural manner. The idea is to decouple the logging structure from code structure. Again, though, this isn't a library. The OP would be better off with a global logger anyway.
How does this compare to the other persistent hashmap crates? like: [im-rs](https://github.com/bodil/im-rs) and [rpds](https://github.com/orium/rpds).
I use it with [Pikelet](https://github.com/pikelet-lang/pikelet/). I've found it quite excellent! You do have to make a custom lexer though if you want comments - but feel free to copy mine! If I ever want extensible syntax/notation I might have to switch to something else, like a custom Pratt or Early parser. That is one of the downsides of going with a parser generator approach.
Where is the modern C++ implementation? If we saying C == C++ im bailing out here.
I think the coolest is NPM, considering its massive importance on the frontend.
Thanks for the very informative release announcement! 
I'll have to get back to you on that. I just lost an afternoon to a windstorm-induced power outage and I already had plans for some pretty intensive TODO-squashing, so I'm now quite behind schedule.
If you find yourself considering [nom](https://github.com/Geal/nom) (a parser combinator crate that tends to come up), I'd also consider [combine](https://github.com/Marwes/combine) since people seem to find it to have [better ergonomics](https://www.reddit.com/r/rust/comments/88f69x/things_i_learned_writing_my_first_few_thousand/dwkprtu/). I wrote a [reply quoting the relevant bits](https://www.reddit.com/r/rust/comments/8qu1oc/advice_regarding_a_language_parser_needed/e0m84kr/?context=1) but Reddit seems to be silently hiding it unless I navigate to it from my profile.
I'm happy with rust's lifetime checker. But I'm wondering whether there's a way to turn of the borrow checker. I've never had any issues on borrowing when coding c/c++. 
When it comes to building web applications, we would be nowhere without diesel! It's a solid ORM that rarely gets in the way, and gives a lot of legitimacy to Rust's web stack.
You can’t turn it off, but with unsafe, you get access to raw pointers, which aren’t checked.
&gt; What is the correct reaction when one reads an article like this? If you find the article upsetting: take a step back and find the positive but critical replies. There are enough people in the community that provide such, and finding it helps contextualize similar articles in the future.
Wow, I did not know that about Ethereum and how they use GO and Rust nodes. Thanks for the info.
I've seen a bit of Pony and want to try it out, but the mere existence of its runtime prevents me from using it in my preferred domain: kernel development. I am interested in seeing if Actix can be made to work with no_std though.
&gt; I've never had any issues on multiple mut borrowing when coding c/c++. That you know of. The most insidious code is the code that works the way you think it does 99.999% of the time, because you're extremely unlikely to have enough test coverage to notice that it's broken, but it's going to get you eventually, probably long after you've stopped thinking about and forgot how it's even supposed to work. True peace of mind comes from knowing that certain kinds of bugs just don't compile. That being said, we're all adults here, and if you're sure you know what you're doing there's always unsafe
The problem is that bugs involving multiple mut borrowing are insidious. Your code seems fine and then, long after you've settled into the idea that it's correct, some rare condition occurs and you discover that it wasn't correct after all. This blog post does a good job of covering some of the less obvious ways people often get bitten: [The Problem With Single-threaded Shared Mutability](https://manishearth.github.io/blog/2015/05/17/the-problem-with-shared-mutability/)
I'm not deep into Tokio, but I think the last poll method won't work, since the first call to `.take()` and `match tokio_threadpool::blocking(f)` will consume the future. And when it it's not immediately ready (`Async::NotRead`) it just gets dropped. The future that is returned from `tokio_threadpool::blocking` imho needs to be stored somewhere in the Future type, so that this can be polled again on the next invocation.
Hmm, you do have a point, but can the future returned by `blocking` be `NotReady`? Maybe if there's not enough capacity to run it?
Hmm, you do have a point, but can the future returned by `blocking` be `NotReady`? Maybe if there's not enough capacity to run it?
Startup scene in Berlin is massively undercapitalized relative to SF but it has its charms and lots of engineers don't necessarily want to be in the SF scene. For example I'll probably end up moving home and taking a pay cut rather than end up in the States. That said: you're right its pricey to visit home, but you might be able to negotiate this if you have a family, but you also will have way more vacation. It's super weird at first but once you settle into it you feel like your life is breathing more. Anyways, keep in mind that a difficult move from SF might not seem so from London or Moscow. :)
The most important one is missing: Rust is used to implement a memory safe language **without** garbage collection, and such a language will be a game changer for systems programming.
It seems right-ish. I guess you can replace the boxing altogether with an "impl Trait", but this looks good. Anything that worries you in particular?
Wikipedia says: "npm is written entirely in JavaScript and was developed by Isaac Z. Schlueter as a result of having "seen module packaging done terribly" and with inspiration from the shortcomings of other similar projects such as PEAR (PHP) and CPAN (Perl).[3]", which is confirmed by a simple check of the github. It does have two tools written in rust, a "readme-client" and "shelby", which apparently counts something for production metrics.
I think Zig is the language the author might be content with.
You're welcome ;\-) Concerning the bounty: Maybe this could be coupled with the patreons mentioned in the blog post. I know that the [GoDot game engine](https://www.patreon.com/godotengine) does this quite sucessfully: People who support GoDot via Patreon can [suggest features and vote for them](https://www.patreon.com/posts/may-2018-results-19345998). Of course the lead developers have the last word.
Find one or two developers who want to implement it. There are Rust developers on Patreon who could be supported in that way.
I found the author's style of writing his criticism fairly unhelpful. Based on an implication from single quote from the manual, he is attributing a negative trait to an entire group of people. And I think he's really reading that quite in bad faith. The quote refers to the fact that much of what the borrow checker catches would actually be bugs in a language like C++. In C++, you have to perpetually run a mental borrow checker over your code, and the human brain generally just isn't as good at tracking that kind of minutiae, so it's easy to overlook real problems. Of course, the place where the borrow checker really does just get in your way are the places where it's not perfect. Non-lexical lifetimes are one example; there are a good number of cases in which the borrow checker is rejecting something that it really doesn't need to, so it does just feel like busywork to work around it. It's possible that the quote from the manual, plus some of these ergonomic issues (which are known, and being worked on, but as a newcomer he might not know that) could feel offputting. However, there is still an ergonomic issue that he brings up, that I have been bothered by a lot as well, which is that of working with things that implement `Clone`, which in many cases are that way because they're a wrapper around or an alias of an `Rc&lt;T&gt;` or `Arc&lt;T&gt;`. Many languages people are familiar with have GC, in which you just pass around references without thinking about it, and if the GC is implemented via reference counting, it will just do the clone in the appropriate place. In C++, you have copy constructors which do this for you, so you don't need to explicitly write the clones in, which of course means you need to sprinkle `std::move` annotations everywhere if you want to move instead of running the copy constructor. In Rust, it's the other way around from C++; the move is implicit, and you have to tack `.clone()` on if you want to clone the object. While this seems reasonable, to make the more expensive case the more cumbersome one, it really does seem to mean a lot of `.clone()` calls sprinkled in for APIs that make heavy use of shared ownership. For example, reading the [Vulkano docs](http://vulkano.rs/guide/image-export), it is pretty striking how stuttery it seems with all of the `.clone()`, `.unwrap()`, `.unwrap()`, `.clone()`, `.clone()`, `.unwrap()`. The `?` operator has improved the `.unwrap()` situation, though working out some details of the ecosystem around it still remains, but you still need to do all of the `.clone()` calls. The question is, can we do better? Is it really necessary to write out all of those clones explicitly? The borrow checker should be able to determine when they're necessary; any time it would complain about "use of moved value" on something that implements `Clone`, it could just insert a call to `.clone()` instead. Yes, that would make the code less explicit, and there wouldn't be as good of a way to ensure that you've moved a value away and so can't use it later on, unless you added some way to explicitly annotate a move like in C++. But given that I think this could be done at compile time in Rust, you wouldn't be forced to annotate moves in Rust for performance reasons to avoid a clone (the last consumer would always move by default, rather than cloning), you would only need to do so if you wanted to be explicit about it. I'm sure this has been discussed to death somewhere before, so if so, let me know where, or if not, would this be worth considering? Maybe this behavior would be undesirable for some `Clone` objects? One of the things I worry about is that in some debates about Rust features, some people stretch the goals of safety and explicitness to the point of adding "speedbumps" to behavior they think is undesirable, which rather than adding much in the way of safety or explicitness just make the language more cumbersome to use. While I think that the language team has mostly managed to avoid those temptations, there may be a few cases where it has slipped through. While I really think the way this blog post was phrased was off-putting, he may have been put off himself by some language that implied that some seemingly simple, fixable problems (I say seemingly because I know how much work has gone into NLL) were actually something he should just learn his way around. And while it's true that the borrow checker is generally holding your hand and guiding you away from the cliffs of UB, there are still several cases where it's overprotective and makes you take a circuitous route to your destination for no really good reason.
Done! https://github.com/sharkdp/fd/issues/304
I’ll try to take a look considering this a point of interest for me, but I’m not sure when I’ll get to it. I did read over some of it and I think it’s a very cool and practical application of Rust extensions for Neovim. Thanks for alerting me to this library and examples :)
&gt; Are there plans to include persistent data structures into the standard library? Doubtful. Rust aims to keep the standard library lean, to the point that things like `regex` and `rand` are distributed as crates and [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) includes the passage "It's the only niche collection I couldn't kill from std::collections.".
&gt; &gt; Performance is not a primary concern — easy of programming and correctness are. — Joe Armstrong Whoa, hold up.. Maybe performance is not a concern for YOU (the author), but I wouldn't be using Rust if it wasn't as fast as C/C++. Because then it wouldn't be a viable C++ replacement and would leave "space" between Rust and assembly language for another systems language that could be faster. Performance is paramount for me, and I'm glad it is also important for the Rust community! That being said, I think Rust also fulfills the other two: - Correctness? check! Well, we can't prove our Rust code correct yet, but at least our code is memory-safe and easy to reason about. Rust is certainly easier to write correct code in, than any less strict language. So Rust only has necessary strictness. - Easy of programming? Check! (Once you're used to it.) I can confidently write Rust code even when I'd be too tired to write safe C/C++ code, and even write concurrent code fearlessly.. "easy to dive into" `!=` "easy to use (after learning) and easy to refactor large projects and scale projects to MLOCs".
 arr[0..33].copy_from_slice(a); arr[33..66].copy_from_slice(b); arr[66..99].copy_from_slice(c); 
Lovely thank you! 
Thanks, I didn't know about it but just installed it, it will be very useful for refactoring :)
If you're willing to use a crate and have a different type, [`arrayvec`](https://crates.io/crates/arrayvec) can work well. let mut arr = ArrayVec::&lt;[_; 100]&gt;::new(); arr.extend(a); arr.extend(b); arr.extend(c); `arr` will then be a stack-based `ArrayVec` holding the 99 elements with 1 extra capacity. We need to use a 100-length backing array rather than 99-length because as nice as `arrayvec` is, it works via manual implementations for types, and `ArrayVec&lt;_; 99&gt;` doesn't exist. Besides that, this will be an efficient and clean inline storage for 99 elements.
Using `copy_from_slice` you can do it like [this](https://play.rust-lang.org/?gist=2070002f981014b3542d48b0e38067aa&amp;version=stable&amp;mode=debug).
I'd look for a way to replace `enumerate_pixels_mut` by a per-row memcopy.
You may be interested in Bodil's (author of `im`) talk about this at RustFest recently: https://www.youtube.com/watch?v=Gfe-JKn7G0I
The article links to a presentation (\[Go\-ing to Rust: Optimizing Storage at Dropbox\]([https://qconsf.com/sf2016/sf2016/presentation/going\-rust\-optimizing\-storage\-dropbox.html](https://qconsf.com/sf2016/sf2016/presentation/going-rust-optimizing-storage-dropbox.html))). I can't seem to find any more information than the abstract. Anyone knows if the slides or a video is available somewhere?
It is possible, but then it would look completely different from actix
The matrix has a column major memory while the image is row major so I don't think I can use any kind of memcopy.
It _seems_ to be available at [InfoQ](https://www.infoq.com/presentations/rust-dropbox), but as "a restricted presentation that can only be viewed by QCon San Francisco 2016 attendees". They do say "The public release of this presentation will be in the next month", but the presentation is from Nov 09, 2016, so that might not be entirely true.
oof, /u/jamwt, do you have a link to the slides? I'd also be happy to answer any questions y'all have about our use of Rust. (I worked on this project.) 
Why are you creating the image buffer through `DynamicImage`? Why not just do `GrayImage::new(nb_cols as u32, nb_rows as u32)`?
I haven't looked at Pony in detail. Would you say there's any way Rust can learn from Pony, regarding the type-system, e.g. for preventing data races?
I didn't know it was possible XD. Thanks for this. I don't have a strong OO background and I didn't see it on the [doc page of GrayImage](https://docs.rs/image/0.19.0/image/type.GrayImage.html) \^\^. Those docs are quite overwhelming for newcomers.
Ah, thought it was probably that. Yeah, it can be easy to miss things when there's a lot there. One thing you could do sometimes, is click the `[src]` button, and see what the function is doing. In this case, if you look at `DynamicImage::new_luma8()`, you'll see that all it really does is forward to `ImageBuffer::new()`.
Thanks for the \[src\] tip, I hadn't even noticed the thing ahah. It's nice to have this!
Does the image need to be in this orientation? Would it be a problem if the output image was rotated 90 degrees? Rotating it would make the image rows be the matrix columns, which, depending on underlying storage, might allow you to memcopy.
whenever someone asks what they should use for parsers in Rust, there's one person who complains loudly about nom's macros, compilation errors, etc. Usually I do not comment on them, because whatever I say, they already had a bad experience and I first need to fix it. But frankly, it gets tiring. We rarely hear about all the people who have been happily using nom for years, and used it in production. So I will give you this: * nom: [283 dependant crates](https://crates.io/crates/nom/reverse_dependencies) ~1200 download/day * pest: [21 dependant crates](https://crates.io/crates/pest/reverse_dependencies) ~1500 downloads/day (around 1200 of which due to one crate, [handlebars](https://crates.io/crates/handlebars)) * combine: [18 dependent crates](https://crates.io/crates/combine/reverse_dependencies) ~100 downloads/day * lalrpop: [25 dependant crates](https://crates.io/crates/lalrpop/reverse_dependencies) ~60 downloads/day If nom was so hard to use, there would not be so many projects using it, even considering nom's age. That said, I know there have been usability issues, but I feel the people criticizing nom gave up very early and never looked again at recent versions. Here are a few things that happened over the years: * [type trickery to avoid type inference issues](https://github.com/Geal/nom/blob/master/src/branch.rs#L225-L230) * using the [`compile_error`](https://doc.rust-lang.org/std/macro.compile_error.html) macro to [detect syntax errors and show a useful error message](https://github.com/Geal/nom/blob/master/src/branch.rs#L170-L179) * [rewriting most of the documentation](https://docs.rs/nom/4.0.0/nom/) * tutorials: * [making a nom parser from scratch](https://github.com/Geal/nom/blob/master/doc/making_a_new_parser_from_scratch.md) * [parsing the RADIUS protocol format, up to fuzzing the parser](https://github.com/Geal/langsec-2017-hackathon-code) * [various guides](https://github.com/Geal/nom/tree/master/doc) to help people upgrade to new nom versions, explaining the internal design There's even [a document to help you choose the right combinator with nice, small examples](https://github.com/Geal/nom/blob/master/doc/choosing_a_combinator.md). What drives people to nom is that it fits right with a process of hacking away at a problem, discovering stuff bit by bit. It's a very interactive, very rewarding process to extract meaning from data little by little. So, I get it, there's stuff in nom that sometimes make it hard to use. I'll ask you to do this: instead of complaining on reddit, [go open an issue](https://github.com/Geal/nom/issues/new). I care about giving people a good experience writing and maintaining parsers, and I care about improving nom, and it will get better with your help :)
Well, it's a transposition, not really a rotation, but more a rotation plus symmetry. But for visualization purposes, most of the time I guess it's fine to look at the transposed image. In that case, do you have pointers to methods I could use to directly copy memory?
Engineers working in start ups in Berlin can earn approximately this amount. Salaries are however not comparable with the US as health, pension, long-term care and unemployment insurances are all covered. Education in Germany is also completely free of charge, with the exception of University which usually charge a maximum 100 Euro fee for each semester (this fee depends on the Bundesland in which you are based). 
If it only says it's borrowed and not moved, you can just put a different scope around the loop so that the borrow is stopped before the macro borrows. And maybe I'm being stupid, but I don't think youe loop actually does anything: it declares a new binding `line` that shadows the one in the loop, which is dropped immediately at the next iteration.
This is an idea I had a few days ago to reduce code duplication in my own projects. Any thoughts or suggestions are appreciated!
And it’s damn good. An excellent project!
I am also from scala background and it took me a while to understand how and why rust the only language I know where mutability is actually not a problem. I was trying hard to have immutability in Rust because I figured in the past that it was hugely beneficial, but I ended up realizing that I had to unlearn my "good habits" since it doesn't apply in Rust. I would suggest to think deeply about why you want immutabilty and you still might want immutability but probably for very different reasons, mostly performance. 
Ok. This took a little longer than I expected, as NAlgebra is fairly complex. But, I finally found that your `DMatrix.data` will dereference as a `&amp;[u8]`. So you can go much better! If you dig into `ImageBuffer`, you'll see that it's generic over the backing storage, which you can see in the `GrayImage` type alias: `ImageBuffer&lt;Luma&lt;u8&gt;, Vec&lt;u8&gt;&gt;`. The `Vec&lt;u8&gt;` part is the backing storage. It doesn't have to be a `Vec&lt;u8&gt;`, it could be something else. Like a `&amp;[u8]`. So, if you don't need to modify the image, you can convert your `DMatrix` into an `ImageBuffer` with no copy at all! fn image_from_matrix(mat: &amp;DMatrix&lt;u8&gt;) -&gt; ImageBuffer&lt;Luma&lt;u8&gt;, &amp;[u8]&gt; { let (nb_rows, nb_cols) = mat.shape(); ImageBuffer::from_raw(nb_rows as u32, nb_cols as u32, mat.data.as_ref()).expect("Buffer not large enough") } Note that while this image lives, you won't be able to modify the matrix. If that's an issue, you could create a new image, and use [`copy_from_slice()`](https://doc.rust-lang.org/std/primitive.slice.html#method.copy_from_slice) to copy from the matrix to the image.
I've been making lots of improvements to Wyrm in the last couple of months, and it's now at least somewhat battle-tested. Stay tuned for a progress report! 
One thing you _could_ do is use a global flag in a closure you're passing to `filter`, like [this](http://play.rust-lang.org/?gist=fe8edf0200be640e6768b961f264d688&amp;version=stable&amp;mode=debug). A better option might be to make it an iterator adapter instead.
One thing you _could_ do is use a global flag in a closure you're passing to `filter`, like [this](http://play.rust-lang.org/?gist=fe8edf0200be640e6768b961f264d688&amp;version=stable&amp;mode=debug). A better option might be to make it an iterator adapter instead.
I sorta feel like this shouldn't be a single crate, but rather a separate crate for each shim. This would make versioning easier, as each shim could be versioned separately.
&gt; Also, personally I feel like I have all of Rust in my head How did you accomplish this? I have no idea how things like HRTBs work, since they're elided and I don't actually run into them until I get error messages like error[E0277]: the trait bound `for&lt;'r&gt; impl std::ops::FnMut&lt;(&amp;(_, _),)&gt;: std::ops::FnMut&lt;(&amp;'r &amp;(&amp;str, &amp;std::ops::Fn(i32) -&gt; bool),)&gt;` is not satisfied --&gt; &lt;anon&gt;:11:27 | 11 | let _ = tuples.iter().filter(f); | ^^^^^^ trait `for&lt;'r&gt; impl std::ops::FnMut&lt;(&amp;(_, _),)&gt;: std::ops::FnMut&lt;(&amp;'r &amp;(&amp;str, &amp;std::ops::Fn(i32) -&gt; bool),)&gt;` not satisfied error[E0277]: the trait bound `for&lt;'r&gt; impl std::ops::FnMut&lt;(&amp;(_, _),)&gt;: std::ops::FnOnce&lt;(&amp;'r &amp;(&amp;str, &amp;std::ops::Fn(i32) -&gt; bool),)&gt;` is not satisfied --&gt; &lt;anon&gt;:11:27 | 11 | let _ = tuples.iter().filter(f); | ^^^^^^ trait `for&lt;'r&gt; impl std::ops::FnMut&lt;(&amp;(_, _),)&gt;: std::ops::FnOnce&lt;(&amp;'r &amp;(&amp;str, &amp;std::ops::Fn(i32) -&gt; bool),)&gt;` not satisfied
I found that `Vec` has a `remove` method, which means you can do ``` let mut vec = // data goes here let i = vec.iter().position(|x| *x == foo); vec.remove(i); ``` But this definitely goes against the functional spirit of the iterator.. Haskell's `delete` function, actually does exactly what I need, but it relies on pattern matching to make it easier 
I think the author forgot how much time he'd spent to learn to write C programs that don't segfault when he suggested C.
I had that thought, too. However, flooding crates.io with a bunch of shims, especially ones that are only a dozen lines of code, felt a little excessive and spammy.
I would happily take a PR too merge that Chrono millisecond timestamp shim in. We already have second and nanosecond timestamp shims, and a structure for how to include them.
I've written some small programs and I don't think I've cloned a lot. I don't even remember the last time I cloned something other than Rc and Arc. The borrow checker isn't showing up frequently either. Most things just work, unlike in C they just segfault somewhere.
Also, this crate was created after I did try [proposing](https://github.com/hyperium/mime/pull/84) a `serde` feature on the `mime` crate. Some crates just don't want that integrated directly, or only provide a subset of the features people need. Everything that's already in `serde_shims` are shims I've used personally.
Rust is awesome. I choose Go
[crates.rs link](https://crates.rs/crates/serde_shims).
Thanks. I didn’t intend to discriminate :)
[https://doc.rust\-lang.org/std/iter/trait.Iterator.html#method.skip](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.skip) maybe just skip(1)
If I may ask, how would it look, and would there be a use case?
that requires the value to be at the beginning of the iterator, and if the contents are random and unsorted, then I wouldn't have any idea where the item I want removed is located
https://github.com/fuchsia-mirror/garnet/search?utf8=%E2%9C%93&amp;q=language%3ARust&amp;type=
Mutability is actually one of the key features of Rust. If you are using Rust, you might wanna embrace it, or reconcider the choice of a language. That means there is no need to include structures like this in the standard library and I would agree with this even if will include one of those libraries in every project.
Thanks ! :)
Slightly related question: is there a crate that offers an Arc without a weak count? I feel like those immutable data structure crates could gain by using a lighter variant of Arc.
My answer as well. I'm using it at work for a wireless product. Also looking to hire a Rust dev to work on it (in SF). 
So express what you want as a custom iterator adaptor! [Here is one easy way to do it.](https://play.rust-lang.org/?gist=299e0b0ac91c81ebcdf9ac59bb440d7e&amp;version=stable&amp;mode=debug)
Okay, cool. Working on that now. To be entirely honest I wasn't aware those methods existed.
Thanks for the link to TRust-DNS. I really need to update that landing page. I keep planning to replace it with a nice doc site like tokio, diesel, actix-web, or any of those many great examples of well documented projects, but it’s lower priority than features for me right now.
&gt;mostly persistence and performance. Persistence, yes. Performance? Not likely. The "im" crate author specifically mentions that in general the immutable collections do not perform as well (in most cases) as the standard non\-immutable ones (although they can in some cases avoid some amortized costs on inserts and such.
Curious why dropbox is building a storage system when a bunch of NetApp EFs or EMC systems could be used? 
&gt; If the language has the problem that people are fighting with the language in order to become productive with it, perhaps something is wrong with the language, and not the programmers? If you frame it differently, fighting with the language could be the alternative to fighting with bugs in the program. I'll take fighting with the compiler over fighting with the program any day.
If some Rust developer has tips and tricks how to better install it system wide, bootstrap with system rust, avoid compiling all the micro packages along cargo and best package them all individually please let me know!
https://tokio-rs.github.io/tokio/tokio_fs/
I was pretty interested in \`im\` after watching a talk on youtube at rustfest, but I looked at the src and found pervasive \`Arc\`s used in \`im\`. Is there's some reason it has to be Arc? It seems like it'd be nicer to allow the user to choose their guarantees and write the library as zero\-overhead.
Do I understand correctly you want something like the following? fn remove_first&lt;T, F&gt;(vec: &amp;mut Vec&lt;T&gt;, mut filter: F) where F: for&lt;'a&gt; FnMut(&amp;'a T) -&gt; bool, { let mut removed = false; vec.retain(move |item| { if removed || !filter(item) { true } else { removed = true; false } }); } It works like this: https://play.rust-lang.org/?gist=dae1c28fee036a44201739063c005326&amp;version=stable&amp;mode=debug
What distro are you running, anyway? I think many distributions can now do a system-wide installation for you, in which case I'm not sure what the problem is here.
I run #t2sde, you know this embedded, cross compile from source distribution. The problems are: the install / bootstrap is a unclean mess, second of all: installing it system wide is unnecessarily difficult I find lots of online threads of various distribution packages being not to happy with it trying to work around the rather alien compile form source procedure as use and implemented in Rust. This is unnecessarily difficult to compile from source yourself, and thus get new developers interested and contribution to Rust, too.
They used to do it, but they switched to their own infrastructure because when you have to deal with a massive amount of data like they do, this far less expensive.
I don't actually have all that much experience with Pony, so I don't really have an intuitive feel for the type system like I have with Rust. It feels to me like it's oriented around immutability and references in a way that's pretty similar to Rust but more strictly focused on the actor model in the way that Erlang/OTP is, though. You could totally implemented the reference capabilities stuff in Rust, but I feel like it'd only make sense if you were putting together an actor library for higher-level work, but I don't know that in the context of Rust it would necessarily offer any benefits over something like actix.
One thing to note: `im` is a LGPL'd, while `rpds` is Mozilla'd, if that will affect your decision. Despite what everyone else is saying, persistent data structures _are_ quite useful for certain problems, although I imagine that Rust's ergonomics around them aren't as good as a functional language's. Given the licenses, I can only really recommend using `rpds`.
\&gt; Rust is the first viable candidate for replacing C and C\+\+ in a wide variety of applications outside his more forgiving requirement What about Ada?
No, not quite.
Yes, it is quite different from your average autoconf/cmake package, but then many system language compilers are. I work on the packaging for Gentoo, so I am somewhat familiar with the issues here. It took me a while to figure it out, but in the end it's really not all bad. If you want to build from source, just download an earlier toolchain, then call `x.py build`, then call `x.py install`. Then there's a pretty simple config file you can use to customize things. Our build stuff is here, if that helps: https://github.com/gentoo/gentoo/blob/master/dev-lang/rust/rust-1.26.2.ebuild
It's handy to know what the result is so you can trace it back more easily if you accidentally do it
Interestingly, this isn't in \`itertools\` or in any crate I could find. In line with /u/K900_'s second suggestion, here's a quick\-n\-dirty extension struct/trait combo I wrote that can illustrate how you might implement this yourself: [http://play.rust\-lang.org/?gist=9b023208dab7c23a262b4d3d5b35f0d4&amp;version=stable&amp;mode=debug](http://play.rust-lang.org/?gist=9b023208dab7c23a262b4d3d5b35f0d4&amp;version=stable&amp;mode=debug)
x.py downloaded a new binary, although I had that version already installed, for so many reasons we can not really have the package source download additional, especially binary stuff. I show my current .conf (we use pure, rebate shell code) in the video, it is live here: https://svn.exactcode.de/t2/trunk/package/develop/rustc/rustc.conf Ideally we should avoid this binary upload, and then the much more important issue are this gazillion cargo packages, that are way more downloads we can not have, and ideally IMHO, cargo should only install cargo, and not 100? micro bindings, ..!
Through configuration you can point it at the binary you already have. You should really check it out.
What guarantee are you looking to drop?
I thought im changed license. Hmm...
I wouldn't call myself a rust programmer and haven't even tried compiling rust, but I guess that the process is similar to bootstrapping gcc, with the big exception that the linux kernel and all its distributions evolved around the C language and its infrastructure, support it and make it easy to use. Packaging and using any software that is based on a different language and principles in a format that wasn't made to fit them isn't easy. Other languages like Go produce software that has similar problems fitting into a structure that wasn't desinged for them.
Unfortunately I will have to further check this out the next time I have to update this. Also: How do we support other architectures with this? PowerPC, SPARC, MIPS, RISCV? AFAICS they crated such a complicated build system thing, and even a regular native build is not straightforward.
The same way as anything else: you can build on one of those hosts, or cross compile.
There is nothing in autoconf or Makefiles that was not made for Rust. Decades before people put whatever they had in there, from latex, over perl, python, to ruby. Boostraping GCC works with any reasonable C or now C++ compiler with ./configure; make; make install - for a cross compile with --target, --host, ...
Nice rant. Couple things: * AFAIK Rust development is sponsored by Mozilla to build Servo, the browser engine which is supposed to be incrementally assimilated into the existing FF engine (Gecko, I think was the name?), so Rust code being in FF makes sense. * despite what some ~~fanatics~~ people seem to think you don't need to build every single thing on your system from source by yourself, especially something as complex as a browser * "having to run RCE": you can just curl/download/view the bash script in the browser before you run it in the shell. If you're that ~~paranoid~~ overly cautious * Rust gets new (major) features somewhat regularly (being on a **stable** release cycle of six weeks), so needing a recent compiler is not unusual (not everyone can release new features only every few years/decades) * "micropackages": these are called crates, Rust's name for libraries. And many developers prefer to have a small discrete crate instead of some behemoth monolith library that does *everything*. * Thus libs have dependencies of their own, that also have to be built at least once, since crates are "distributed" in source not binary blob form * Not having those in some distro's package manager means they can be updated independently and also having the same experience on all supported platforms (not every (F)OSS dev runs Debian,Fedora or Gentoo) * "constant downloading": once they're downloaded, they're not downloaded again, unless the local build artifacts are deleted or a different version is requested. Them needing to be compiled... see previous sentence. * Also, when you build libs in any other PL, you likely have to download those as well, first searching for (the right version of) them, probably manually, have to figure out which build tool a lib/application uses, have to make different build tools play nice with each other etc. Rust has Cargo. Cargo is package/lib manager and *the* universal build tool for the Rust programming language all in one. You can even install binary crates extend cargo with subcommands. * artifacts stored in /$user/... Sorry, but duh. Building as root =&gt; stuff will be getting stored in /$user/... * needing rustc to build rustc: Rust being written in Rust means you need a Rust compiler to build the compiler... I doubt you could build the C(++) compiler without a previous version of that compiler. Anyway, have a nice day and I hope you'll come to revise your opinion as you learn more about Rust.
Link to documentation? step by step? I have some of those machines at hand, that now no longer can compile Firefox where it worked before, ...
Your other complaints aside, your objection to "remote shell code execution" is misplaced. When you download and run software, even if you build it from source, you are doing "remote code execution". There is zero difference from a security perspective of downloading source code, and running `make` on it, from piping shell commands to your terminal. Let's look at a few attack vectors: 1) The rust project itself contains malicious code. If this is true, then you're compromised however you install it. 2) Someone is able to MiTM your HTTPS connection to rust-lang.org. If this is true, you're still compromised since that is your jumping off point. 3) Someone has compromised the rust build servers. If this is true then the artefacts themselves are compromised. The only obvious improvement to security that can be made here is to prevent (2) from happening by signing the artefacts from the build server and validating them between download and execution. Users are very unlikely to do this themselves, and so the best way for this to be achieved is via their existing package manager, which will typically already do this kind of validation. However, rust cannot afford to package itself for every distribution, and so must provide a fallback way to install the software: the shell command is *as secure* as any other than does not do signature validation prior to installation.
Maybe we should suggest it to be part of the standard lib, after all it seems to have its use, and pretty much every other Haskell list function is present
Where have you looked for docs so far?
&gt; Boostraping GCC works with any reasonable C or now C++ compiler And bootstrapping `rustc` works with any reasonable Rust compiler. (I think `rustc` is the only reasonable Rust compiler today. There's also [mrustc](https://github.com/thepowersgang/mrustc) but I'm not sure of its status.) Rust isn't unusual in this way; see [https://en.wikipedia.org/wiki/Bootstrapping_(compilers)#List_of_languages_having_self-hosting_compilers](List of Languages having self-hosting compilers].
By 'choose your guarantees' I'm referring to the title a section of the first book you wrote: https://doc.rust-lang.org/book/first-edition/choosing-your-guarantees.html The data structures in std collections don't make any assumptions about what you want to use, you can pick Rc/Arc or whatever else. Is there some reason that persistent data structures require Arc? It seems like it shouldn't be a hard requirement
&gt; Rust &amp; friends are unnecessarily difficult to compile from source yourself, and thus get new developers interested and contribution to Rust, too. If you think it is awesome and easy, just post the steps needed ;-)! I assure you, it's not difficult at all; I do it many times per week: $ ./x.py build 
It is not a Rant, it is a vlog about daily IT things. I'm aware that Rust originated at Mozilla. Yes, I need to build everything on my system, because I'm the system vendor. Also how should people contribute and work, or security analyze open source if they can not even build it? Requiring a six week old require is unreadable new. They should avoid using latest and greatest features in their own compiler for a little longer than that. Imagine GCC would always have require exactly that latest GCC to build. I intentionally say micro packages, because it also applies to other web frameworks that are based on zillions of micro packages. Linux users and admins to not want to have stray, unpackages residuals in their system. Installation should go thru the packages manager, and not some third party stuff. Imagine the mess if you had to maintain several of those third party installer things. Linux would quickly become a mess like Windows or so. If an organization, university, or Linux distribution wants to build and install stuff they want it in the system, not in $user. I literally know nobody who wants stuff installed in their $user / $home directory. In a "hidden" .&lt;directory&gt;! Again, yes you can build gcc with other and much older compilers. I revise my opinion as soon as I can install it somewhat sorted into my system.
Hmmm. Maybe it’s because it’s the morning, but to me, I don’t see how else it would be done. Like, *maybe* Rc vs Arc, but other than that...
You mostly mention scripting languages here. Yes I get that Makefiles and autotools can be pretty much used for anything, but that wasn't my point. Dependency resolution like it is done with cargo didn't exist with C at the point where package manager came along. Shared libraries in elf files are designed with the C compiler in mind. And so on...
Rust has not 20 different config+build tools but ONE, Cargo. It manages everything for you, recursively building dependencies/libs with the only config lib/binary authors having to do being writing the appropriate dep's version into the project's `Cargo.toml` file.
You could take_while from the reference and then extend like [this](http://play.rust-lang.org/?gist=a814524e114c5f180f1ea3a43f531798&amp;version=stable&amp;mode=debug). But im not sure i like it.
The data type could just be T, an unboxed type. If you're storing some kind of primitive value I don't see any reason it needs an Arc and every node in the data structure. If you want to share the references among threads, you could then Arc the entire collection, just as you would with Vec. here's bodil discussing unboxed values for im: [https://github.com/bodil/im\-rs/issues/11#issuecomment\-384975133](https://github.com/bodil/im-rs/issues/11#issuecomment-384975133)
In my understanding, persistent collections inherently require multiple ownership.
I suppose that's what she's saying with 'complex' vs 'primitive' values. With T: Copy you can get away without any boxing and dramatically improve perf: [https://github.com/bodil/im\-rs/issues/12](https://github.com/bodil/im-rs/issues/12)
Yeah, makes sense. I’m excited to see where all of this goes!
In this day and age, NSA, crackers, Snowden revelations it is far form misplaced. If I download a tarball I can extract it, validate the signature and look inside it before I build it. This is a huge difference from blindly executing code on your computer, and running configure; make in a sandbox. Yes, I mention https in the video, but as I say MIM can give you a slightly mistyped URL they own to start with. And this strange new packaging promotion strategy is step one of making the life of distribution packagers harder. I do not want scripts that download plenty of other things and dependencies. I expect a Linux package manger to do that. Also Pro tip: If you use a new language for something as vital as one of the primary open source HTML engines, do not base it on way to many micro dependencies, at least focus on using the core language only. Why does Firefox need cargo and some of those dips?
It's a rant. I stopped watching at "Rust really is not packaged better. Open source programmers really should know better." From what I've seen, constructive criticism is quite welcome in this community. That doesn't mean anyone will watch a 15-minute video that starts in this way.
&gt; They should avoid using latest and greatest features in their own compiler for a little longer than that. Features are getting built into the language to be used, recently some major QoL features (`impl Trait` etc.) &gt; Imagine GCC would always have require exactly that latest GCC to build. Not really an issue since there is only a significant update for that compiler every other decade. &gt; Installation should go thru the packages manager, and not some third party stuff. Having to make individual arrangements separately for each and every distro/OS is an unreasonable effort. One-fits-all is much better.
Your `is_async` macro can be replaced with the futures macro in the lib `try_ready`, the rest looks pretty good. You’ve already struck on the state-machine based enum option for moving the poll operation through the various connection states. Also, since you’re just starting out, I’ll save you some pain. There’s a better understanding now that Futures should “do no work until polled”. I notice in your builders that you start some of your connections before polling. I did this as well, and still have a lot of code that does this, but it creates problems for downstream libraries. I recommend adding a new state like Connect, that actually initializes your sockets in its poll. I have a ton of refactoring that I’m working on now to dig myself out of the hole I’ve dug for myself in this regard.
&gt; And bootstrapping rustc works with any reasonable Rust compiler. Then why did it try to download a rust binary instead of running the one already installed on his system?
It is not a rant, even though you do not like that sentence. I do open source and Linux source distribution since 1998 (ROCK Linux), and I do not remember ever having to waste that much time to get something to work and then still not having it packaged in a useful way. Instead of calling my thoughts rant: How do I build cargo to install into a $prefix like /usr or /opt/cargo instead of $user/.cargo? How can I separate all the micro bindings out into individual packages?
I do not run a Linux distribution to have some additional package manager "manage" things for me. I want to apt-get install it and not cargo whatever something. into $user/.cargo? This is not how Linux systems work. Is this so hard to understand?
&gt; In this day and age, NSA, crackers, Snowden revelations it is far form misplaced. If I download a tarball I can extract it, validate the signature and look inside it before I build it. This is a huge difference from blindly executing code on your computer, and running configure; make in a sandbox. Yes, I mention https in the video, but as I say MIM can give you a slightly mistyped URL they own to start with. Ok, so you've compiled `rustc` in a sandbox with no network access. What's goal here? Are you going to run that executable on your computer after that? If so, that's RCE. What security did the sandbox give you if you're just going to run the code anyway? &gt; And this strange new packaging promotion strategy is step one of making the life of distribution packagers harder. I do not want scripts that download plenty of other things and dependencies. I expect a Linux package manger to do that. Which Linux package manager should our Windows and macOS users use? &gt; Also Pro tip: If you use a new language for something as vital as one of the primary open source HTML engines, do not base it on way to many micro dependencies, at least focus on using the core language only. Why does Firefox need cargo and some of those dips? Have you considered that perhaps the Firefox devs are using cargo's features and actually need those dependencies? Maybe they aren't just adding dependencies for lolz? 
https://www.reddit.com/r/rust/comments/8r231l/rust_cargo_are_really_not_packaged_all_that_linux/e0nvlsr/
&gt; How can I separate all the micro bindings out into individual packages? What do you mean by this?
&gt;They should avoid using latest and greatest features in their own compiler for a little longer than that. &gt; &gt;Features are getting built into the language to be used, recently some major QoL features (impl Trait etc.) getting used, does not need to mean immediately getting used in just the same compiler? &gt;Imagine GCC would always have require exactly that latest GCC to build. &gt; &gt;Not really an issue since there is only a significant update for that compiler every other decade. 1) not true. There where many GCC releases since 2.95 around 1998 andsignificant C and C\+\+ standard revisions the GCC compiler did not use for a decade or more. &gt;Installation should go thru the packages manager, and not some third party stuff. &gt; &gt;Having to make individual arrangements separately for each and every distro/OS is an unreasonable effort. One\-fits\-all is much better. You work against the nature of Linux distributions here, and you should know that. Or maybe you are simply no Linux users. Somehow this so far never was a problem with all the open source projects, packages and various languages. Yet somehow the Rust developer had to make this very Linux unfriendly. Maybe simple not their platform.
Me too! While we're on the topic, bodil commented just a few minutes ago saying they are removing Arc in the next major release: [https://github.com/bodil/im\-rs/issues/28#issuecomment\-397337855](https://github.com/bodil/im-rs/issues/28#issuecomment-397337855)
I think we need to start asking for 0.2 to be yanked... it’s causing a lot of confusion.
As I mentioned before, from a Linux developer and user perspective I find it unreasonable that cargo also builds and installs plenty fo other "crates" like curl, ssl, atty, etc. pp, really many dozens of those. 1) does cargo even need those? 2) a Linux distribution would want those as individual packages, like rust\-curl, rust\-openssl etc. I certainly do not want one huge cargo package that contains the whole rust/cargo/crate universe.
I didn't want to import `try_ready` since this module is behind feature. As for my futures, as you mentioned futures do nothing unless polled. So even though I create TcpStream Future, it is doing nothing unless my own future gets polled
For all the rant stone throwers: Let's start with technical things, and answer: 1) how do I configure cargo to install into the system, like /usr or /opt/cargo 2) how do I cross compile rust, so that I can bootstrap it for my powerpc, sparc, and mips systems? Thank you so much!
Ah awesome! Bodil certainly knows WAY more on this topic than me
Cool. Nice work!
&gt;I literally know nobody who wants stuff installed in their $user / $home directory. In a "hidden" .\&lt;directory\&gt;! I like it personally, but if you don't: it's configurable. You can do `sudo cargo install --root /usr &lt;package&gt;` if you want to. I'm not sure what the syntax is for `./x.py install` though, I've only used it once. &gt;I intentionally say micro packages, because it also applies to other web frameworks that are based on zillions of micro packages. Linux users and admins to not want to have stray, unpackages residuals in their system. *They don't stay on the system.* Everything gets assembled into one executable, and this single file can be packaged individually. Yes, they're *cached* so that they don't have to be recompiled, which is the 500 meg directory you see, but you wouldn't package that cache for distribution.
it is being removed in the next release. (link)[https://github.com/bodil/im-rs/issues/12#issuecomment-393122789]
Yeah I wish it was more obvious that they existed, doc updates (from anyone) are also very welcome!
&gt; You work against the nature of Linux distributions here, and you should know that. Or maybe you are simply no Linux users. Somehow this so far never was a problem with all the open source projects, packages and various languages. Yet somehow the Rust developer had to make this very Linux unfriendly. Maybe simple not their platform. There are [Debian](https://packages.debian.org/sid/rust/rustc), [Fedora](https://admin.fedoraproject.org/pkgdb/package/rpms/rust/), [openSUSE](https://software.opensuse.org/package/rust), [Arch](https://www.archlinux.org/packages/community/x86_64/rust/), and [Gentoo](https://packages.gentoo.org/packages/dev-lang/rust) Rust packages. Many (perhaps even most) of the Rust developers use Linux. Linux is arguably the best supported OS by Rust. Rust is very Linux friendly.
However, this nearly 600 MB .cargo directory includes the cargo binary and shares libraries :-/ Guess I have to see what is left in there if I rebuild on a clean system with --root /usr So how it sounds in your post means: cargo really needs this dozens (I have not counted, maybe 50 or more?) dependencies to build?
From `cargo install --help`: --root &lt;DIR&gt; Directory to install packages into From `./x.py --help`: --build BUILD build target of the stage0 compiler --host HOST host targets to build --target TARGET target targets to build ^(Insert snarky comment about reading manuals here.)
And what signature are you going to validate against? One you've just downloaded from the exact same compromised site? None of those mitigations achieve anything. &gt; We teach users not to click on each link in an email, and attachment but developers should curl website output into a shell??!!?? Yes, because the user is not *trying* to download and install new software... We teach them that so they don't *accidentally* run code they don't mean to. Here, and for developers in general, their entire goal is to download and run some code... If you can run `configure; make` in a sandbox, you can do the same thing for the shell script. The security here comes from the sandbox, not the fact that you're using `make`... Yes you need your sandbox to have internet access: that would also be true if you were using `make` since there are external dependencies that need to be downloaded. 
Yeah just look at all those npm and jar packages, what was Mozilla thinking with cargo! 
&gt; I find it unreasonable that cargo also builds and installs plenty fo other "crates" like curl, ssl, atty, etc. pp Libraries must be compiled in order to be linked into a final binary. Cargo doesn't "install" libraries in the traditional package manager sense. IE: packages are managed on a per project basis. You may have multiple versions of the same package on your computer. &gt; 1) does cargo even need those Yes &gt; 2) a Linux distribution would want those as individual packages, like rust-curl, rust-openssl etc Rust binaries are statically linked by default. What does it mean to install a library? How does your packaging system handle different versions of the same library? Different Rust applications (such as `ripgrep` and `fd`) may depend on different versions of the same library. How do you plan on handling this? 
The `clone()` issue mostly shows up with APIs that make heavy use of `Rc&lt;T&gt;` or `Arc&lt;T&gt;`, or wrappers around them, to manage its resources. You're right, it doesn't show up that often, but when it does, it can feel like a lot of pointless annotation. The borrow checker is pretty good, but there are definitely plenty of places where it complains about perfectly safe things. Niko has a good introductory page on [non-lexical lifetimes and the problems they will solve](http://smallcultfollowing.com/babysteps/blog/2016/04/27/non-lexical-lifetimes-introduction/), with the following example which fails to compile under the current borrow checker, but works with the in-progress NLL feature: fn bar() { let mut data = vec!['a', 'b', 'c']; let slice = &amp;mut data[..]; capitalize(slice); data.push('d'); data.push('e'); data.push('f'); } Right now, you have to work around this with the following: fn bar() { let mut data = vec!['a', 'b', 'c']; { let slice = &amp;mut data[..]; capitalize(slice); } data.push('d'); data.push('e'); data.push('f'); }
Yes, those deps are required. The rust ecosystem is modularized to a much larger extent than the usual C/C++ family of languages. This is really nice for developers, because common functionally is usually already available in high quality and liberally licensed "crates." I can see why it's frustrating from a packaging perspective though
&gt; despite what some fanatics people seem to think you don't need to build every single thing on your system from source by yourself, especially something as complex as a browser All good points, except this one. Being able to build something from source easily is pretty important. Not just for fanatics who just like to do it, but also for distros that need to package things themselves. Being able to verify and reproduce a package is important, which means it ideally should be as easy as possible for any open source package on anyone's system
&gt; * despite what some ~~fanatics~~ people seem to think you don't need to build every single thing on your system from source by yourself, especially something as complex as a browser This is not a helpful comment, and the "fanatics" part is a bit rude. There's nothing wrong with wanting to compile something yourself. Of course it's more complicated than downloading a binary. There's no reason the build should be unnecessarily complicated. &gt; * "having to run RCE": you can just curl/download/view the bash script in the browser before you run it in the shell. If you're that ~~paranoid~~ overly cautious Of course you can, but it's super frustrating because these scripts can do *anything* so you pretty much always need to do a full code review. And I'm not even talking about actively malicious scripts, I'm talking about some braindead installers I've seen that hardcode install locations in terrible places. Many of these are not written by people that are very familiar with linux distribution conventions. &gt; * Rust gets new (major) features somewhat regularly (being on a **stable** release cycle of six weeks), so needing a recent compiler is not unusual (not everyone can release new features only every few years/decades) But it's too bad that rustc itself needs a new compiler. For years gcc was written using pre-ansi C so that you could bootstrap it on any machine that had a working C compiler, even if it only supported the old crusty version of C. &gt; * artifacts stored in /$user/... Sorry, but duh. Building as root =&gt; stuff will be getting stored in /$user/... Why is that "duh"? The golden standard for unix utilities (for at least 40 years or so) has been to install into `/usr/local` by default. I don't think it's irrational to be surprised when something installs into `~/`. &gt; * needing rustc to build rustc: Rust being written in Rust means you need a Rust compiler to build the compiler... I doubt you could build the C(++) compiler without a previous version of that compiler. Like I said, yes you can. You need *some* C compiler, but gcc can be built with clang, or any other C compiler that has some baseline support. It doesn't have to be gcc itself and it doesn't have to be recent. I like Rust a lot, but it's installation is only ergonomic if you don't care about it. If you *do* care about the details, it's decidedly un-ergonomic (especially if you're trying to use "rustup"—it's like `curl | bash` except now it's a binary??? *Great.*).
&gt; However, this nearly 600 MB .cargo directory includes the cargo binary and shares libraries There are no ‘shared libraries’ (ie. dynamically linked libraries), they are bt default linked statically during compilation, ie. the final executable has them compiled into itself and does not need any libraries as external files (except for possible shared C dependencies, like libc or libssl, which are *not* downloaded by cargo, and should be provided by your system’s package manager). The rest of dependencies is just a cache for future compilations. &gt; So how it sounds in your post means: cargo really needs this dozens (I have not counted, maybe 50 or more?) dependencies to build? Why would it download them otherwise?
have you seen how Python has pip, Ruby has bundler, Go downloads GitHub repos directly, Java projects will use Maven... the list goes on. Programming languages other C and C++ all have their own dependency managers. How do you currently handle those? The needs of a developer compiling a program are rather different from what a user wants when they choose to install a program. Linux distros' package managers provide the user solution, but not the developer solution.
[text](https://www.rust-lang.org/en-US/other-installers.html) That has resources to answer both of your questions. These are official binaries that are updated that can be used to bootstrap any installation.
 1. Are you asking about installing `cargo` into a system directory or installing a Rust executable built with `cargo` into a system directory? 1. I believe you just need to modify [these lines](https://github.com/rust-lang/rust/blob/master/config.toml.example#L94-L103) in `config.toml`
what exactly does `extend` do?
That python ruby and perl have some package managers, doe not mean I have to use them. In fact neither of those language package's is as frustrating to package. Developers are also users, in my opinion linux distributions packagers also provide developer solutions to install -devel and language packages.
AFAIC this is the URL I visited to download the source tarball and even show in the video, and the build yourself from source instructions for Rust and Cargo are seriously lacking. Would you have a cross compile bootstrap how-to, steps link?
no, like this: let vec = vec![1, 1, 2, 3, 4, 4, 5, 6]; let res = vec.iter().remove_first(4).collect(); println!("{:?}", res); // prints [1, 1, 2, 3, 4, 5, 6] Notice how only the first occurrence of 4 is missing, not both
so much extra work...
I understand you absolutely. Maybe a small story will help you understand my point. A log time ago someone invented a nail and gave the people hammers to drive this nail into wood and people where happy. They started improving that hammer so its very easy do drive any nail into wood without much effort. But some people found flaws in that nail so they came together and from the ground up designed a screw and a scewdriver. Those people were happy and more and more people started using the screw. Now some nail people came along and tried to use the screw as well, but were unsatisfied that their hammer they were used to could not drive the screw into the wood. And complained to the screw people that they should put a spike on top of the screw to drive it into the wood even while using a hammer. If that is a good idea or not, we will see :)
Installation location really depends on intent. It's **very** common for development tools to install into a sub-directory under your user home in order to allow multiple versions to more easily co-exist and to make it easier for users to manage toolchains without constantly needing to elevate to root. Similarly it's common for transient dependencies to install into your home directory while finished artifacts are installed globally (under either /usr/ or /usr/local/). In this regard it's actually gcc that's the odd one out compared to most modern programming languages and tools, often forcing users into doing strange hacks involving juggling of environment variables and complicated chains of make files in order to utilize multiple toolchains.
&gt; Linux users and admins to not want to have stray, unpackages residuals in their system. If you build stuff from source, you get the cached intermediate build artifacts for all crate dependencies. But those are not used at runtime. Once everything is compiled, all those Rust crates are linked statically (only C dependencies are dynamically linked) so you only have one build product. 
It might be an oversight; InfoQ usually does publish QCon talks.
Not only do I show that page in the video and loaded the source tarball form there, it also does not answer any of my questions. Where would you have the cross compile bootstrap to other architectures documentation?
Sounds like a good RFC! :)
Crates are cheap and easy to use. It's not like in C++ where you have Boost which contains everything you could ever need, or Java where you have massive frameworks. On the other hand it's also not like NPM, where people make packages for the stupidest little things. And really, a lot of crates should be seen as build dependencies / header files. There are crates that only define standardized interfaces so other crates can interoperate for example, and a lot of crates that are data structures or combinators that get monomorphized and inlined by the compiler.
&gt; However, this nearly 600 MB .cargo directory includes the cargo binary and shares libraries &gt; There are no ‘shared libraries’ (ie. dynamically linked libraries), they are by default linked statically during compilation, ie. the final executable has them compiled into itself and does not need any libraries as external files (except for possible shared C dependencies, like libc or libssl, which are not downloaded by cargo, and should be provided by your system’s package manager). The rest of dependencies is just a cache for future compilations. ok, fine, that was from memory, then no shared libraries, even worse, why would I permanently waste 500MB or more, hidden away in my $home directory of cached sources and such? Maybe for normal users who just cargo install or update something once or twice a week this should be just downloaded and placed in the temporary build directory the user is building from? &gt; So how it sounds in your post means: cargo really needs this dozens (I have not counted, maybe 50 or more?) dependencies to build? &gt; Why would it download them otherwise? How should I know the whole thing looked unreasonable complex, large and cumbersome to me. This where so many deps it looked like it compiled everything. Or the most "important base" to my non Rust-eyes at least it did not look like this was just for cargo.
Those -devel packages *only* exist because Linux is built on C, and C doesn't have a dependency manager of its own, so Linux distro managers created a solution to make their own life easier. It's not because it's a better solution. It means that those -devel packages will likely be out of date, and they are packaged N+1 times for however many Linux distros exist.
&gt; This is not how Linux systems work. Is this so hard to understand? Are you here to understand Rust's design decisions and solve a problem together, or to yell at an entire community for not doing things how you'd like them to? The former is welcome. The latter isn't.
Something I haven't seen mentioned: [mrustc](https://www.reddit.com/r/rust/comments/7lu6di/mrustc_alternate_rust_compiler_in_c_now_broken/). This is a Rust compiler written in C\+\+. I don't think it's quite ready for prime\-time usage yet, but it was able to build the Rust compiler written in Rust successfully at least once, so eventually there will be another option that *you* might find more appealing.
&gt; Crates are cheap and easy to use. That you say it like advertising speak does not make it so. ,-) &gt; It's not like in C++ where you have Boost which contains everything you could ever need, or Java where you have massive frameworks. On the other hand it's also not like NPM, where people make packages for the stupidest little things. You mean like C and C++ where you have libpng, libjpeg, libz, ...? &gt; And really, a lot of crates should be seen as build dependencies / header files. There are crates that only define standardized interfaces so other crates can interoperate for example, and a lot of crates that are data structures or combinators that get monomorphized and inlined by the compiler. To me this looks really hard to scale and manage in the long term. Even for me today it does not look too comfortable just installing cargo.
Actually working compilers for Rust: rustc, the end. Having a handful of different compilers for the same language but with subtly differing feature sets is just a headache. regarding rustc etc. not being in some buried directory, my guess is it's because of rustup, so that it's able to switch out the binary between the different toolchains/targets. Also installing in $home/.cargo/bin across all OS's is consistent because it's not catering to any individual OS/distro.
This has nothing to do with c and c++ not having a decency manager, and more than Linux distributions want a centralized package manger for plenty (security, ease, system installation, security and features updates, et al.) of legitimate, and usability reasons.
Something I haven't seen mentioned: [mrustc](https://www.reddit.com/r/rust/comments/7lu6di/mrustc_alternate_rust_compiler_in_c_now_broken/). This is a Rust compiler written in C\+\+. I don't think it's quite ready for prime\-time usage yet, but it was able to build the Rust compiler written in Rust successfully at least once, so eventually there will be another option that *you* might find more appealing.
&gt; Maybe for normal users who just cargo install or update something once or twice a week this should be just downloaded and placed in the temporary build directory the user is building from? A normal user (who does not intend to hack around the project, or compile it with custom flags / for other architecture) should probably just download a binary release. That’s what rustup does for rustc and cargo. Those dependencies are needed to work with the code and compile it. If you need to compile a rust project yourself and do not want the cache later, just remove it (or event the whole `.cargo` dir) afterwards.
Ri\-i\-i\-ght. Then, why do ~~most~~ so many C\+\+ projects these days use "scons" instead of autotools?
Already working on it
I did not say auto* tools are amazing, but at least people know how to deal with them. Crates does not look better to me on the first glance. Also could have used scons then, ...
I asked already multiple times for answers, e.g. how to cross compile bootstrap rust to powerpc, sparc, mips. Also that no distribution packager I spoke too likes and knows how to properly package cargo crates is not helping either.
More like \~300€ per semester but it's still fairly low (at least at the Freie Universität Berlin).
&gt;Of course you can, but it's super frustrating because these scripts can do anything so you pretty much always need to do a full code review. And I'm not even talking about actively malicious scripts, I'm talking about some braindead installers I've seen that hardcode install locations in terrible places. Many of these are not written by people that are very familiar with linux distribution conventions. Whats your preferred format? A RPM or Deb can do anything a script can. &gt;But it's too bad that rustc itself needs a new compiler. For years gcc was written using pre-ansi C so that you could bootstrap it on any machine that had a working C compiler, even if it only supported the old crusty version of C. There's a Rust compiler written in C++ (mrustc) that you can use to bootstrap Rust.
It’s not *that* much extra work. It took me about 10 minutes total to bang that out and make the test case pass.
And I hope that you've noticed that people are willing to engage with open-minded technical questions and thoughtful suggestions. The other stuff needs to stop.
This is one of the largest storage clusters in the world (exabytes), so you generally stitch together some custom distributed systems to manage this efficiently from a cost and operations perspective. Trying to have a vendor solve it for you with SANs or whatever would be... to put it mildly, prohibitively expensive. :-) Just to give you a flavor of the kind of designs in these systems, typically you don’t even use machine-local RAID for these clusters because it’s too expensive and too limited. Instead you build in all of the replication and parity at a higher software layer, and that allows you to pursue extremely efficient storage overhead schemes and seamless failover at disk, machine, even rack level. There are some blog posts on our tech blog that go into the design of the system if you’re curious to know more.
So someone submitted a PR today that fixed this! It's been tested, merged in and now 0.6.1 is out with the fix present
Modify [these lines](https://github.com/rust-lang/rust/blob/master/config.toml.example#L94-L103) in your `config.toml` file and then run `./x.py build`
Technically, we used to use s3. Which is someone else’s version of a similar system. But since amazon doesn’t use EMC SANs or anything either, we really never (directly or indirectly) were using a storage architecture like that. 
I’ll try to find them. Unfortunately, without the video, a lot of context is missing. Not sure how useful they are in isolation.
oh! you're right. I remember sleffy was complaining at me about the license :P
Which other stuff? Also so far I only got trivia back, and links to an installation site that does not mention anymore details, ...
&gt; I only point out long term Linux user, developer and distribution packager perspective. Most developers using Rust to write code are going to use `rustup` not your distro's packages. &gt; I asked already multiple times for answers, e.g. how to cross compile bootstrap rust to powerpc, sparc, mips. As I've said multiple times now, modify [these lines](https://github.com/rust-lang/rust/blob/master/config.toml.example#L94-L103) and then run `./x.py build` to get a cross compiler. &gt; Also that no distribution packager I spoke too likes and knows how to properly package cargo crates is not helping either. Whom did you speak to? Rust packages exist for many different distros. You could try reaching out to those individuals or on the distro developer's mailing lists. Additionally, you might also try looking through [this thread](https://internals.rust-lang.org/t/perfecting-rust-packaging/2623) regarding Rust's Disto Packaging story specifically and you can also try posting on the same Internal's discussion fourm. 
I feel there is a lot of unecessary hostility here by some rustaceans feeling someone stepped on their toes. You, on the other hand, seem more frustrated. The Problem seems to be in part wording. If I, as a Linux user, want to *install* something, I expect my distro (arch) to provide a ready-made package and all dependencies having been taken care of by the maintainer and whithin the package-manager universe, all should be well. But if I *compile* an application, I need to worry about dependencies. This is a *frickin' hard* problem. How should I even know if all dependencies are available as native packages, how those packages are named and how this particular distro invokes one of its particular (apt, apt-get, aptitude, ...) package managers? If there was a single spec, akin to POSIX, for such stuff, maybe this could be done, but I doubt that spec would not get monstrous and terrible in many ways for there is such versatility and fragmentation in the ecosystem. Rust opted for the first-class experience for developers. Add a dependency, build your software, magic happens, things work, happy face. If you build from source, you are experiencing the *developer* workflow, not the user-installs-a-ready-made-package workflow. Since having many small dependencies is solved in an - IMHO - practical and sane manner, as opposed to some other languages, developers use this a lot to make their life easier. That is the reason for the high number of transitive dependencies. Just because having dependencies has sometimes been like pulling nails for decades and thus, to an extent, been avoided, does not make the new way inherently bad. If you had grown up like that, you would not bat an eye. The rust tools should behave sanely, so once you figured out the cache path, mount a tmpfs there or clean up with `rm -r` to get rid of temporary artifacts. Or build inside a container. Since rust-internal linking is static, the final binary should have not a single run-time dependency on it.
I don't understand yet the exact meaning of `mat.data.as_ref()` and why this works while `&amp;mat.data` does not but this is really nice! Am I right saying that I can't modify the image because the image buffer is borrowing the underlying vector slice? Thanks again for the explanation and example!
But cargo is not Rust, and Rustc not build by cargo, or is it? I asked about bootrapping the compiler. I tried to find docs, did not find too many good places, hidden behind the initial curl|sh remote code execution, ..!
It seems like the author didn't give rust a fair shot. There are inaccuracies in the post and he seems to have gone in with some preconceived notions. The quote they present: "Performance is not a primary concern — easy of programming and correctness are. — Joe Armstrong" seems oddly placed with Rust, considering they just complained about Rust's correctness in the previous paragraph, and praised Pony's correctness in the page before that. But also because they are evaluating a systems programming language, yet apparently performance isn't a primary concern. All in all I'm just confused and don't take much from the article.
&gt; my choices are largely still C, and Go. I can understand C++, but C?
C++ has dependency managers, they're just not very mature yet - conan and vspkg are the two big ones.
Ah.. yeah. returning "impl Trait" would solve the problem. Thanks!
Are there any gfx-rs tutorials that you would recommend?
The reason I mentioned Cyclone is that viability is about more than technical merit. Ada doesn't show any signs that it was going to reach "social viability" as a replacement for C and C++.
Doesn't gcc contain C++ code now? I thought they had finally decided to open the doors...
&gt;. It's very common for development tools to install into a sub\-directory under your user home not really, do not remember ever had any other tool doing so. Maybe a commercial Unix thing, or what are you talking about? Maybe also gives quotes and references?
You can also do this with `scan` to move the flag inside.
&gt; I'll ask you to do this: instead of complaining on reddit, go open an issue. I care about giving people a good experience writing and maintaining parsers, and I care about improving nom, and it will get better with your help :) To be honest, I don't personally have a complaint. My own parsing project is in the "researching what crate to use" phase and I was coming at it from a perspective of "give combine a fair chance too". That said, in hindsight, my over-eagerness to include quotes in the other post and my impulsive push-back against an apparent Reddit bug (in posting the second comment and linking to the first) certainly gave the impression that I had something against nom, so I apologize for that. Were it not my policy of not trying to erase my mistakes, I'd delete the longer post. Were I doing this again, I'd have written a brief post that said "If you're trying nom, you might also want to try combine. It has [comparable performance](https://github.com/Geal/parser_benchmarks/pull/18) and some people seem to prefer it."
Gradle, maven, go, stack, cabal, rvm, rustup, virtualenv, pip, cpan. I'm sure there are others, I just can't be bothered to look them up right now.
For `Rc` there is the nightly-only `strong_rc`. Adapting it to use atomic counters should be trivial though. If you don't need `?Sized` and `Arc` is not a part of the crate's public interface (or you don't care about interoptablity), rolling your own bare-bones implementation is not that hard: https://play.rust-lang.org/?gist=94eba41cdb083281e63f7a327013ed2a&amp;version=stable
Mostly, it's because that is the only way i could rank on google with something as popular as Rust. I am really loving rust and want to share that love through my blog so i wrote this article to maybe help folks searching for how to install it. 
&gt; I only point out long term Linux user, developer and distribution packager perspective. &gt; Most developers using Rust to write code are going to use rustup not your distro's packages. I do not believe that is true, in the long term few users will care about "rustup", and just expect rustc to be installed by the OS, or click on the install button in the package manager.
&gt; You mean like C and C++ where you have libpng, libjpeg, libz, ...? You really aren't hearing what I'm saying. Cargo is about build dependency management first and foremost. And most of these build dependencies have nothing to do with the rest of the system, so there is *no point* in going through all the overhead of packaging them in a million different ways for all distro's. And yes, they are small and lightweight, in the sense that they do not contain much code and there are a lot of them, and each one does not contribute much to the final binary size, it takes almost zero effort for programmers to add or upgrade a dependency, and in the case of Rust-only dependencies they can be confident that it will work the same on all systems. You can write libpng, libjpeg, etc in Rust, and people do that. In fact librsvg is moving from C to Rust under the same API, you can't even tell. It's just that you lose some API expressiveness by defining your API only using C types and wanting to support old versions as well, so it takes some extra effort which isn't really worth it at the moment for many Rust libraries. And you can use libpng, libjpeg etc from Rust, and people do that. But this brings with it the risks of incompatible library versions, because you are dealing with dynamically linked libraries now. In some cases this can be worth it, and a lot of crates have the option to use either an system library or a native Rust version of some feature. 
&gt; I feel there is a lot of unecessary hostility here by some rustaceans feeling someone stepped on their toes. You, on the other hand, seem more frustrated. Thank you for your good summary, much appreciated! My intent is not so much as "ranting" (you and I certainly have better things to do), but more pointing out the installation experience and usage problems from a long term Linux user and packager. Also I certainly do not want to spend that much time each time I update Firefox, though half of the time was probably to attribute some random JIT gcc-7 code generation incompatibility and solved by upgrading to gcc-8. How do other distributions handle this many micro package dependencies, does any of them package them or just rustc and cargo?
this is the worst Pro tip I have ever read in my life and the anti pattern per se. if you really think that solving ever problem by hand makes up better code then using libraries that do exactly one thing, but this right, you perspective is totally broken.
&gt; You really aren't hearing what I'm saying. Cargo is about build dependency management first and foremost. Why do you need to start so negative, maybe you should also try to listen? Maybe I'm more listening than you think? My point was that things worked quite well in the C/C++ world and libs that made it into thousands of open and commercial products, like zlib, libjpeg, lisping, fontconfig, ... Somehow even without creating such a fine grained dependency problem. Back to the practical problem, how should I even automate the build of Firefox now that it has such a non-standard automatically loading plenty of things from the internet build procedure? This is a huge problem, not only for us, but for every other distribution. Do you think developers as in distribution packagers like when this "magic" packaging stuff is unsupervised pulling more and more sources straight from the internet while building a package?
&gt; I don't understand yet the exact meaning of mat.data.as_ref() and why this works while &amp;mat.data does not but this is really nice! I was a little mistaken in the other post, in that the matrix storage doesn't deref to `&amp;[u8]`, but instead `&amp;Vec&lt;u8&gt;`. I did think the compiler would try to deref all the way down the chain in this case, but apparently not? Basically, what's happening when you call `mat.data.as_ref()` is that the `mat.data` is being dereferenced to a `&amp;Vec&lt;u8&gt;`, and that vector implements a trait that provides `as_ref()`, which in the case of this vector, returns a `&amp;[u8]`. Incidentally, another way you could get that is to do `&amp;**mat.data`. The first `*` dereferences into the vector, the second deferences to slice, and the `&amp;` creates the reference. But that, in my opinion, is a little less clear. &gt; Am I right saying that I can't modify the matrix because the image buffer is borrowing the underlying vector slice? Thanks again for the explanation and example! Yes, that's correct. While the `ImageBuffer` exists, you won't be able to modify the matrix as the image holds a reference to it. Fortunately, it's cheap to drop it and recreate a new image.
This comment is a little rude. While JS and Rust have embraced micro packages, there is still much debate about this in the wider programming community. Micropackges are not obviously better than the "regular" sized packages found in other language communities. 
Pip, CPAN, and gem have been around far longer than Rust has but I have yet to meet any developer who installs Perl, Python, or Ruby packages from their distro's package manager. Regardless, did you read the rest of my comment? 
Most I know use their distribution's packages. Slso, I have yet to see a regular C or C++ developer to bootstrap GCC, or Clang themselves, or build zlib, libjpeg, and such outside of their distributions packaging system. Usually people only do that to develop, improve or hunt a bug.
&gt; how do I configure cargo to install into the system, like /usr or /opt/cargo Don't. Build the executable with `cargo build --release`, then package the executable that's in `target/release/`.
UserVoice is one I recognize from Discord's use of it for this. Others are available: https://www.quora.com/What-is-the-best-alternative-to-uservoice-to-get-and-manage-customer-feedback-for-a-website
I've never heard any Rust user want to go back to Makefiles/autotools/CMake/SCons/waf/whatever. The cargo workflow is night and day better.
Because C and C++ lack a good build system with support for managing dependencies. Cargo has that. On any supported platform, you can simply `cd` into a project and then `cargo build` it. That's it. Managing Rust dependencies via a distro package manager would be much more work for the developer for no benefit. 
Beside the just a little bit default non-standard behavior of cargo, I did not say it is the biggest problem. It is the way it integrates into Unix systems, NOT. The longer I listen the various input here, the more I think maybe the dozens of micro packages are one of the bigger problems for proper Linux distribution package integration, besides the automatic, behind the back dependency loading. If your distribution wants to build package foo, it does not want to end up automatically added dependency bar, and zoo ending up in the package as well. That would be like packaging fontconfig, and also ending up with zlib and libx11 in it as well, ...
Please define "micro" and "regular"?
&gt; Back to the practical problem, how should I even automate the build of Firefox now that it has such a non-standard automatically loading plenty of things from the internet build procedure? This is a huge problem, not only for us, but for every other distribution. Mozilla had the same problem with their build servers but I don't remember the details on their solution. I think it involved adding Rust support to the `mach vendor` subcommand.
The things being fetched are deterministic and immutable by design. In theory there should be no difference between this or you downloading a big tarball with the source of Firefox and all crates it depends on. But I can totally see why this makes you nervous. I guess you could use something like https://github.com/alexcrichton/cargo-vendor to use your own local copies of crates, but in the end you are still trusting the Cargo system since that's the "source of truth" that you'd build your own local copy from. In case you're curious, the Cargo.lock file in the firefox source controls the exact version of each crate fetched. The crates.io index is a git repo containing metadata for all packages &amp; versions so the client can confirm that the metadata for a package version never changes (obviously the repository server should not allow this anyway, but it's good to make sure), and the metadata contains a sha256 checksum that Cargo uses to verify the actual crate data it downloads. By the way Mozilla was / is already doing something with vendoring, so that might conflict with what you might want to do. It really might be best to just spin up a vm, build firefox in there, and just copy out the build artifact. It's not necessary, but if you don't want to trust Cargo then I think you're going to have a hard time coming up with anything fundamentally more trustworthy. 
Installing is not cargos purpose. Building is. 
&gt;micro packages are one of the bigger problems Could you please define what you mean by "Micro Package"? It doesn't mean anything as far as I can tell. Crates are not Packages. Crates are either: 1) A Buildable/Runnable Application, 2) A Buildable library that can be used as a dependency for a 1 or a 2. If by "Micro" you mean "Granular", why is that a problem? How granular is too granular and why? You keep complaining about "Micro Packages", but, you haven't offered a useful definition of "Micro vs Not Micro". Unfortunately, that makes it come off as a meaningless rant rather than a reasonable discussion. If that is not your intent, it might be helpful to explain what you would consider better and why (after first reading the documentation and understanding things better): \* [https://doc.rust\-lang.org/cargo/guide/](https://doc.rust-lang.org/cargo/guide/) \* [https://doc.rust\-lang.org/book/first\-edition/documentation.html](https://doc.rust-lang.org/book/first-edition/documentation.html) \* [https://www.rust\-lang.org/en\-US/other\-installers.html#standalone](https://www.rust-lang.org/en-US/other-installers.html#standalone) In particular, look at the "Standalone Installer" documentation. 
I'm not sure if your story is advocating for or against something. It's the perfect fable!
I think the "I have yet to meet any **developer** who..." is the key part. Sure, I use the distro package manager to install dependencies for applications offered through the distro package manager... but, when I'm developing an application using something like Python or Node.js or Rust, I use the developer package manager (`virtualenv+pip`, `npm`, `cargo`, etc.) because it maintains a separate dependency tree for my project to prevent variations in the system packages from introducing complications when I'm trying to do things like diagnosing bugs or from causing packaging conflicts, if a common dependency doesn't properly identify incompatible versions and allow them to be installed in parallel. (ie. Similar to why Docker got popular.) I get the impression that you're misunderstanding some aspect of how cargo functions: 1. `~/.cargo/registry` is analogous to `/var/lib/apt/lists` and `/var/cache/apt/archives` on a Debian-based system. Build artifacts have no dependency on it and it exists purely as a way to minimize network traffic when multiple projects share the same dependencies. 2. `$PROJECT_ROOT/target` is all the stuff that `make clean` would remove in an autotools project. Cargo also caches *built* dependencies in here because `~/.cargo` is shared between all of the versions of `rustc` that you might have installed in parallel and Rust's intermediate artifacts don't have a stable ABI yet. 3. Cargo doesn't impose any additional packaging burden on build artifacts it produces. Everything cargo downloads and builds gets statically linked into the single binary or library you get as the final output. In fact, if a Rust binary or library doesn't use bindings to any C libraries, its only dependency will be `libc` itself... and even that will be statically linked in projects built for the targets based on musl libc, allowing binaries with the Linux kernel ABI as their only external dependency. 4. `cargo install` is Rust's answer to `npm install -g`. It's intended as a way for developers to install development utilities and new cargo subcommands. It's explicitly *not* intended to supplant the system package manager.
As the answers to your questions have been given, here are some general notes: - Consider the package manager of your distribution (and the associated source packages) as a means for providing a coherent base system to users, not as a system to provide sources/headers for building random third-party stuff. - Sofware developers should never depend on a distro's source ("-dev") packages while developing their software. Yes, this is the way C/C++ do it, but that's because it's the least terrible thing possible given that these languages lack a working dependency management tool of their own. - Rust's packaging story is baaaad. `cargo` needed some built-in `cargo publish` command that generates binary and source .deb/.rpm/.msi files since day one. - `cargo install` should only be used for additional tooling required for local development. Abusing it as a general application delivery channel is wrong and broken. - `cargo` dumping things into `.cargo` is plain wrong. There has always been a conflict between (re-)building software shipped with your distribution/packaging additional software into the base system and using a machine for development purposes. Conflating those two tasks was made easy by the no-questions-asked access to source/dev/header packages. In my opinion, development and packaging would be in a better shape today if those packages were not easily accessible by end-users/developers, and restricted to distribution developers/maintainers/packagers.
As to packaging, I can only speculate. I do not maintain any packages myself. That being said, my approach for building binary packages probably would be based on containers. A typical `ldd` output for a rust program looks like this: linux-vdso.so.1 (0x00007ffc46f62000) libdl.so.2 =&gt; /usr/lib/libdl.so.2 (0x00007f9a74348000) librt.so.1 =&gt; /usr/lib/librt.so.1 (0x00007f9a74140000) libpthread.so.0 =&gt; /usr/lib/libpthread.so.0 (0x00007f9a73f22000) libgcc_s.so.1 =&gt; /usr/lib/libgcc_s.so.1 (0x00007f9a73d0a000) libc.so.6 =&gt; /usr/lib/libc.so.6 (0x00007f9a7394e000) /lib64/ld-linux-x86-64.so.2 =&gt; /usr/lib64/ld-linux-x86-64.so.2 (0x00007f9a7479e000) So, since usually, one would distribute certain tools, such a tool would be compiled in a virtual environment with a libc matching the target system. Then, the binary could be packaged in the idiomatic way. If there are dependencies on C libraries, those must be identified and managed as package dependencies appropriately. I prefer static linking because my portability requirements shrink dramatically to the syscall interface of the linux kernel. Then, distribute one binary, done. All these crates that you insistently call "micro package dependencies" (it might help others if you used the idomatic name, "crate") are not libraries in the C sense of the word. There is no resulting `.so` or `.a` to link against. These crates are made part of the application at compile time and thus not placed in `/usr/lib` et al. Also, because these compile-time dependencies are so comfortable to use, there are many of them. And since rust links statically internally, there can even be multiple versions of the same dependency *without* running into dll hell. Developers get to choose the dependency they need and since tools are built from source with cargo everytime, all this nitty-gritty stuff is handled automatically.
what should I use for installation and what is "cargo install" doing then?
https://doc.rust-lang.org/std/iter/trait.Extend.html#tymethod.extend It pushes each element from the iterator into the collection that called `extend`
&gt; How did you accomplish this? After using Rust for a while (and having used each feature of the language and run into every compiler error) it became second nature. I've been using Rust almost every day since 2014, not sure exactly when it became second nature, but it's a gradual process, depending on which features you use the most. Consistency helps (using Rust regularly so you don't give your brain time to forget stuff). But since I haven't really used C++ since I switched to Rust, my C++ is kinda rusty now (heh), but I hope I'll never have to use C++ again anyway.. :) I remember at the beginning of learning Rust I just used the constructs that I understood and avoided e.g. lifetimes in structs until I really needed them, and then they made sense. You can still write a lot of Rust code that way, and work your way up. Another thing that really helped was joining the IRC where people were very helpful when I had a question or weird error message. I'm still active on IRC, also trying to answer people's questions, and there are many more people now than when I joined.. :) &gt; I have no idea how things like HRTBs work, since they're elided Every reference has a lifetime. If it's not written explicitly, it's an elided lifetime. Lifetimes in function args that are passed by reference have to work for ALL possible lifetimes (to let the caller determine one), so they are implicitly universally quantified. The `for&lt;'a&gt; ..` syntax is basically universal quantification (currently it's only allowed for references but hopefully also for types soon), it means the stuff after the `for&lt;'a&gt;` can be instantiated with any `'a`, e.g. in `fn f&lt;F: for&lt;'a&gt; FnOnce(&amp;'a i32)&gt;(f: F) { f(42) }` the `FnOnce(&amp;'a i32)` contains a named lifetime that's introduced at the `for&lt;'a&gt;` before it, and `'a` is universally quantified. When `'a` is omitted (`FnOnce(&amp;i32)`), it's implicitly added with universal quantification and this shows up in such errors. Maybe it would make sense if these kind of errors remove the implicitly added lifetime again before presenting the error to the user (?) So it's useful to decompose this into several concepts: [universal quantification](https://en.wikipedia.org/wiki/Universal_quantification), the fact that every reference needs to have a lifetime, and the fact that if no lifetime is specified, it's inferred.
I explain the various aspects that I did not particularly enjoy installing rustc and cargo. The term micro packages was suggested by others also in other languages context, and generally refers to very small packages (Rust's crates) that contain very little, like only a header, struct description or whatever small API binding rust developers put in there, … So that cargo alone depends on really many (50++?) of them from curl, ssl, atty, to socket and whatnot. This makes packages cargo even harder, if your Linux distribution wants to try to separate their installation and support form one huge cargo package: https://youtu.be/zNipdcUh7ZE?t=6m56s
Not sure that’s what your asking, but I have an interface for *caching*. [Here](https://crates.io/crates/any-cache) and the [the trait](https://docs.rs/any-cache/0.2.3/any_cache/trait.Cache.html) is abstract enough. Though, that would depend on what you want to do with such a KVS.
I'd like to propose this for the QotW
Maybe? It seems a little too specific to in-memory use cases for my purposes—but it could serve as inspiration at least, if I *have* to make my own.
I have seen cases where persistent collections can be used to minimize the copying of data and increase performance that way, but this is a pretty niche application.
cargo install is used to download, compile and install source of binaries from crates.io into ~/.cargo/bin usually. (try "cargo install tokei", then run tokei in a directory with source code to count the lines of source code) Pretty nifty. Only downside is that there is no built in way to update all your installed stuff, but you can easily install "cargo-update" and then use "cargo install-update --all" to update all your installed binaries in 1 go. use "cargo --list" to show all install cargo sub commands Really, cargo is one of the best language specific package managers I have ever used, and in cases where you only need to keep a few machines up to date with rust stuff, I would say its "good enough And when you have a bunch of machines, you could either just distribute the static binary or package it up in whatever package format of choice.
Thanks!
Thanks!
&gt; I prefer static linking because my portability requirements shrink dramatically to the syscall interface of the linux kernel. Then, distribute one binary, done. Your static linking preference is also orthogonal to the preference and best practice on modern Linux systems, … 
I think you'll find that the subtleties of the stores in general, especially as they interact with your front-end, preclude the useful creation for such a layer. some factors off the top of my head: Does the store provide a traversal/iteration model? If so, what's the traversal order? Is the store sharded? If so, how do you specify the sharding key? Does this affect traversal order? Are there any transaction or write order guarantees? How does this interact with the sharding setup? Can you do batched writes? etc, etc. KV stores are similar only in the most primitive sense. I recommend starting with one real k/v store and one "fake" in memory store, and building a backed for each of them. This will allow you to design the API that your program actually needs, and to consider the details in a focused way. 
I'm not trying to be an ass, but, I just don't understand what is wrong with so\-called, "Micro Packages". What does the granularity choice of particular Crates have to do with packaging? As has been mentioned previously, Rust is not currently optimized for supporting shared/dynamically linked libraries. It can do it, but, it is a use\-case that is still evolving. Crates are not shared libraries. If you want to package a particular Rust "Application" (including Rustc/cargo) you build the application using Cargo/Rustc and then the build executable is packaged (it is all statically linked generally). You would never individually "package" the dependency crates as they are statically linked and monomorphized into the application that is built. It seems that you are frustrated with the way the Rust ecosystem works and you want it to work more like the C ecosystem. It actually works similar to the C\+\+ ecosystem in that you cannot link against C\+\+ libs built with a different version of the C\+\+ compiler. The same is true for Rust. All libraries must be built with the same Rustc version in order to be linked together into an executable. By default, the Rust compiler statically links all dependencies into the executables it builds and ensures that all the dependencies of a given executable are built from the same compiler while supporting a local development cache so that builds of the same version of a crate with the same compiler version do not have to be redone for every executable built with that combination. Making things easier for packagers is definitely one of the goals that the Rust community is pursuing (to clarify, I'm nothing but a 3rd party and not really a member perse of the community beyond I have interest in it).
It's for easy access to development tools. It should never be used to install consumer binaries- that's the job of distro package managers. See crates like [cargo-deb](https://github.com/mmstick/cargo-deb) for actually packaging output for consumers.
The reason tokio can be preferable to mio is that tokio libraries have better composability. For instance, it's relatively easy to add TLS to a tokio TCP server, while it is much more complex in mio. 
Thanks for your long reply, unfortunately I run a bit of time right now. The problem is that this are really many. So to map this to actual distribution packages one would need to create quite many extremely small rust packages. And this even only to get the most basic Rust infrastructure working. I do not expect nor want Rust/Cargo to more work like C or C++. I just wish they would not "ignore" classic Unix/Linux FHS, and distribution packaging as much as they do and be at least somewhat packaging friendly. Get Rust/Cargo installed on my system was not really straight forward, and the end result is not really pretty. Right now I do not know how I should package that up to spin a new installer ISO w/ Firefox included.
Can you make a [playground](https://play.rust-lang.org/) example?
sure, this is the code with &amp;&amp;&amp;\[i32\] (to be understood :\-)) [https://play.rust\-lang.org/?gist=7543072f77b766d1b87b890009e707cf&amp;version=stable&amp;mode=debug](https://play.rust-lang.org/?gist=7543072f77b766d1b87b890009e707cf&amp;version=stable&amp;mode=debug)
Well, as I pointed out, the focus there is on deployability. `scp` and that's it. AFAIK unbeatable in regard to simplicity, reliability and speed. Also I've come to regard the term 'best practices' with some scepticism. One should never follow those because the term is applied but because one a) explicitly does not care and expects sensible defaults or b) one has understood their implications and the goals align. And preferences are ubiquitous, everyone has their own, slightly idiosyncratic set. :) Concerning security (most popular critique, "update dynamic openssl, fix all tools!"), static linking is no problem at all if the whole build-process is in-house. As long as I can integrate the upstream source (of openssl, for example) in time with their release, a build gets triggered and I ship a new binary additional to the system lib. Since cargo in particular makes this very easy, I've never run into problems there. Memory size of executable should be negligible in most use cases and statically linked code is often way more cache-friendly than pointer-chasing dynamically linked code. Also: global inlining. The longer the process runtime, the less initial loading matters, anyway. But I digress. I hope you found some useful advice in these threads and, maybe, at least you can understand the motivations behind many design decisions taken by the rust language team better. My recommendation stands, for binary distribution, build your binaries in a virtual environment. For a source-based distro, use the same mechanism to avoid useless build-time clutter on the target system you ought to use anyway (containers, overlay, chroot, whatever).
And notably, that project is good enough that it’s being officially used by Debian, so it can make good packages, not just make them.
Um no, not really. a) Because I'm a huge Rust fan and have adopted it over Pony for various reasons, and see no harm whatsoever in pointing out interesting languages and projects outside the Rust ecosystem (or should I call it a bubble?), and b) Because Pony is a struggling independent open source language (which happens to be technically but also in terms of the people involved, completely awesome), and not a massive for profit company peddling services and software for one of the most successful languages that has ever existed. Woke up on the wrong side of bed yesterday did you?
Ok. I guess hoping for a space elevator to appear is one way to jump down to the ground.
In this vein, I'd recommend reading [this](http://smallcultfollowing.com/babysteps/blog/2018/02/01/in-rust-ordinary-vectors-are-values/) blog post about persistent data structures in Rust and why they aren't as useful as in other languages
&gt; Well, as I pointed out, the focus there is on deployability. scp and that's it. AFAIK unbeatable in regard to simplicity, reliability and speed. yeah, well, see: I do not think users want to update their operating system packages (aka Linux distribution) security updates and such each day via scp. That is why thinks like rpm, and deb where invented a decade or two ago. And that exactly is what I'm talking about when I write: "creating Linux distribution packages", because we cant to apt upgrade, and not scp in the morning to get the latest updates. (although my Windows test install update works so badly, I can imagine some Windows Update users would be happy to use scp for that , … ;-)
Oh and as for relevance: Pony is an actor language with a strong type system which makes many of the same guarantees as Rust's. In other words, there is no other technology on earth I can think of off hand which would be of more interest to bring up in a conversation about Rust &amp; Erlang. For those with a inquiring and open turn of mind that is.
The reason is that each `&amp;` comes from a different place. The innermost one comes from the fact that each element of the vector is *already* an `&amp;[i32]` value. The middle one comes from the fact that you used the `.iter()` method on the vector, which iterates over *references to* the vector’s elements, making the iteration yield values of type `&amp;&amp;[i32]`. Finally, the outermost one comes from the fact that `max_by_key` has to take pass a *reference to* the iteration value to the supplied key-extraction function, or else it wouldn’t be guaranteed to be or to pass the value on to the result.
&gt; Whats your preferred format? A RPM or Deb can do anything a script can. Of course. But even poorly written packages *rarely* do anything completely stupid (see Microsoft's recent packaging screw up for a good exception). Mostly non-daemon packages just dump some junk into /usr and that's it. The built-in os package tooling takes care to look for conflicts and has much nicer than some install bash dumping things into who-knows-where. Bash based installers are typically really long and annoying to read because they try to cater to different OSes, but Debian .postinst scripts are typically 10 lines long or less (if they even exist) and do things like start up a daemon or call `update-alternatives`. They're *much* easier to vet.
&gt; Why is that? * You're iterating on a Vec&lt;T&gt; where T = &amp;[i32]. * Vec::iter is really Slice::iter, which returns an Iter&lt;T&gt; which is an Iterator&lt;Item=&amp;T&gt;, so Item = &amp;&amp;[i32]. * And max_by_key's callback is an FnMut(&amp;Item) -&gt; B: Ord, so the parameter is an &amp;&amp;&amp;[i32]. And there you are. You could remove one level of ref'ing with a `.cloned()`
To expand on this with the type signatures: You start with a `Vec&lt;&amp;[i32]&gt;`. Calling `iter` on a `Vec&lt;T&gt;` returns an iterator with `type Item = &amp;'a T`, or in this case, `type Item = &amp;&amp;[i32]` (ignoring the lifetime). Calling `max_by_key` on an iterator takes a generic function `F` where `F: FnMut(&amp;Self::Item) -&gt; B`, or in this case, `F: FnMut(&amp;&amp;&amp;[i32]) -&gt; B`.
Basically what's happening here is several distinct APIs and ownership rules are all making you take references: 1.`Vec&lt;[T]&gt;` is not allowed because `Vec` is `Vec&lt;T: Sized&gt;`, so you use `Vec&lt;&amp;[T]&gt;`. 2. `Vec::&lt;T&gt;::iter` is actually `[T]::iter`, which yields items by-reference to avoid cloning. 3. `Iterator::max_by_key` takes a `Self::Item` by-reference, so that the item with the highest key can be saved and yielded without cloning. That leaves you with a whole lot of references, which I'd assume get optimized away because the types you're passing around (`&amp;T`) are `Copy`. It doesn't matter in this case, but if you ever need to control how many layers of references happen in situations like these, you can use destructuring in your closure's arguments: fn fn_that_tages_ref_to_x(x: &amp;Foo) -&gt; impl Ord { ... } let v: Vec&lt;&amp;Foo&gt; = vec![ ... ]; v.iter().max_by_key(|&amp;&amp;x| fn_that_takes_ref_to_x(x)) In your case, though, I'd say the turbofish is cleanest, so probably use that.
I would try Iter + flat_map + collect
&gt; I'm sure this has been discussed to death somewhere before, so if so, let me know where, or if not, would this be worth considering? Maybe this behavior would be undesirable for some Clone objects? I've felt for awhile that an opt-in `AutoClone` trait for values that are logically, but not literally `Copy` like `Arc` and `Rc` would be a big boon for ergonomics. Something like, trait AutoClone: Clone {} impl&lt;T: Copy&gt; AutoClone for T {} Then change the language to auto copy through the `AutoClone` trait instead of `Copy`.
I couldn't disagree with this sentiment more. I'd much rather have a bunch of: foo-shim-serde crates than a shim-serde crate that has a bunch of shims for a bunch of different crates. I don't see how it would be spammy at all. Alternatively, name them "serde-shim-foo" for the "foo" crate, "serde-shim-bar" for the bar crate etc. But, I'd personally prefer the crate first so that the shim is more closely associated with the crate.
nebulet and redox
Yes, this was another alternative I considered, just figured my comment was long enough already. Has there been any discussion of this elsewhere?
So, here's why you have three `&amp;`'s: + `.iter()` returns an iterator over references to the elements + the elements are `&amp;[i32]` + `.max_by_key` will take each element of the iterator and pass a reference to it to the closure &amp;nbsp; What else could you do? The compiler couldn't infer only the type for `B`, so you can still omit the type of the closure: `.max_by_key::&lt;i32, _&gt;(|x| x.iter().sum())` Well, besides turbo-fishing the `sum` call.
I think way back when the ergonomics initiative was kicked off, clone ergonomics was briefly floated, but I haven't seen any concrete proposals.
Thank you all, for your excellent explanations! I am quite overwhelmed by the quality and speed of the feedback I got. As I am just beginning to dive into the language I am getting the feeling of entering a very friendly community. Thank you for that :-) 
With rust (as many compiled languages) you probably should prefer using multi-stage Dockerfiles, few examples: * https://github.com/emk/rust-musl-builder/blob/master/examples/using-diesel/Dockerfile * https://github.com/portier/portier-broker/blob/master/Dockerfile 
It's already been suggested.
Hopefully we'll get generators at some point and then you can write it as a coroutine.
Is it actually async though? I thought the IO done by `fs::File` were blocking on the kernel-side on most systems.
[Dinghy: Painless Rust tests and benches on iOS and Android](https://medium.com/snips-ai/dinghy-painless-rust-tests-and-benches-on-ios-and-android-c9f94f81d305) might be what you're looking for.
I don't think there's anything special about how Pony prevents data races vs how rust does, in terms of the type system. I think every ref type in Pony has a Rust analogue, but Rust uses std to provide them. The actor model provides a different model for mutable state that can make things easier to reason about, and no locks mean no *traditional* deadlocks (but you can still end up waiting forever).
Seems you're (mostly) right! This post from 18 months ago seems to paint a good overview https://lwn.net/Articles/671649. I like the idea of forward compatibility though / supporting it on platforms where it works :D
Just what I needed! Thanks so much!
People seem to think it's too niche for a full on adoption in std
Several comments are hidden now, but they had a tone of "you opened this in bad faith knowing it was a breaking change". Even the closing comment had a warning about "abuse of the process", which was gratuitous even with its disclaimer. It seems like the way to go if you have a new idea is definitely to make a pre-RFC because the actual RFC-PR-reading community has quite high standards. 
Somehow I was assuming that it wouldn't allocate in case the vector starts out empty. This unfortunately is not the case, and I thought the BitVec type might be a usize smaller than the [current implementation](https://github.com/Byron/git-reconstruct/blob/fbccab32ea7b393c3285b0e6f02ee3aaf7c7356d/src/find.rs#L40) , which is essentially a huge lookup table.
Oh man. That you for the resources, this is definitely the next step in building this out. Thank you. 
I don't think you can collect into a fixed size array.
Generators in what way?
How would I `move` an Arc? What are the semantics there? I'd rather not perform the Clone if it's unnecessasry, and often this is the case.
Well, what is kinda of wotsee than Rust Strike Force are "Go Reality Warpers". Trying to redefine things to fit their rationale/personal wishes.
On the one hand you are right, it is nice to know that it exists. I know. On the other hand it is not relevant in this topic :)
Functions that can `yield` values and continue executing. The same thing exists in Python, Javascript, C#, Lua, etc. if you've used them there.
You only insert clones if the source is alive afterwards. If it's dead, then you can just move out of it. Or in other words, you only insert a clone in places where the compiler would now complain about a use of a moved value (well, the place where the move the compiler is complaining about occurred).
Ah, yeah I'm familiar with yield from C#. I honestly had no idea that it also existed in JS 
I'm guessing your intention is to ignore any datagrams larger than 2 bytes, and just process the 1- and 2-byte ones. AFAIK, a UDP datagram will sit in the receive queue forever, blocking other datagrams, until recv'd. So you need to use a larger buffer for the recv operation - large enough to accommodate any datagram you might receive.
In Scala, I'd either use a recursive function or fold - Recursive - ``` @ def dropFirstOccurance[A](elem: A, list: List[A]) = { def loop(el: A, els: List[A], dropped: Boolean): List[A] = els match { case Nil =&gt; Nil case x :: xs =&gt; if (!dropped &amp;&amp; x == el) loop(el, xs, true) else x :: loop(el, xs, dropped) } loop(elem, list, false) } ``` Using foldRight - ``` @ def dropFirstOccurance2[A](elem: A, list: List[A]): List[A] = list.foldRight((List.empty[A], false)) { case (x, (list: List[A], dropped: Boolean)) =&gt; if (!dropped &amp;&amp; x == elem) (list, true) else (x :: list, dropped) }._1 ``` Not sure if there is a way to solve this problem using `fold` in Rust?
Ah, what if someone sends a datagram larger than my buffer? Is there nothing to be done? Should my buffer be the maximum size allowed then?
Just to make sure it isn't lost in the noise (one other comment pointed it out) &gt; explicitly, the compiler forces me to use `&amp;&amp;&amp;[i32]` in my function annotation. It doesn't. You can put `_` there instead. The thing it couldn't infer is the first `i32`.
Scala has that nice case structure that you can drop in in place of any lambda function, which certainly cleans the code up a bit. I have no idea if it exists in Rust though, I'm only starting here.
In principle this is doable. All crates have very uniform contents and metadata, so you don't have to write individual packages for each of them. Instead, write a program which takes a crate and creates a package for your distro containing that crate. You should then be able to use cargo's source replacement feature (https://doc.rust-lang.org/cargo/reference/source-replacement.html) to make cargo load the source from your distro package rather than from the original git repository. Note however that a program written in Rust can end up depending on different versions of the same package, so you'll need your distro package to contain a git repository rather than the most recent tarball. It's also possible that you could get away with installing a different distro package for each version of the crate. If you're automatically generating these packages then that won't be any extra work.
I've only gotten as far as adding bounding volume hierarchies (which improved performance very nicely) and adding a checkerboard texture. It's pretty fun. I'll take a look at your code if I get a chance.
First, a playground link that borrowck likes: [http://play.integer32.com/?gist=819fcb19e8488e0513bcdc03c2ff4ee2&amp;version=undefined&amp;mode=undefined](http://play.integer32.com/?gist=819fcb19e8488e0513bcdc03c2ff4ee2&amp;version=undefined&amp;mode=undefined) Now you'll ask why the trait has to have a lifetime, you only want the implementation to have one. The answer is that the trait's lifetimes are the only ones the users of the trait have to respect, so you can't return something with an non-static lifetime in an implementation when the trait said the lifetime was static. This trait restricts the callers to assuming they'll get a specific (shorter) lifetime, but implementations can return 'static lifetime-d stuff if they want: [http://play.integer32.com/?gist=22149fe6b2a822ef0a46033d74ce317f&amp;version=stable&amp;mode=debug](http://play.integer32.com/?gist=22149fe6b2a822ef0a46033d74ce317f&amp;version=stable&amp;mode=debug)
I just completed and published my first ever rust crate to crates.io! I will appreciate constructive criticism. Let me know what you guys think! Hopefully people find this useful. I think it is better than any other memoization crates out there. 
Well I played with it until the compiler crashed. :-) &lt;http://play.rust-lang.org/?gist=bab838d30f047184fea2088d52dec3c8&amp;version=nightly&amp;mode=debug&gt;
Perhaps if more shims are added I can restructure this crate into a meta crate that would reexport from individual shim crates. Best of both worlds. 
Nope, it always allocates. There isn't a reason for that other than it seemed like empty bit vectors would be a niche case. It could probably be made not to allocate for empty bit vectors if that would be especially useful. I don't understand the link to the “current implementation.” What could be a `usize` smaller than what?
You could use a `Vec&lt;u8&gt;` and double its size each time you get a 10040 error. In practice, UDP packets are generally limited by the size of the transport's packets, and most transports copy Ethernet's limit of ~1500 bytes. ("To fourteen-hundred and ninety two, Colombus configured his MTU.")
Might want to bug report that.
Thanks I think that covers what I misunderstanding. I didn't release the triat lifetime could be attached to just a function parameter I kept trying to insert a PhantomData reference to create a lifetime, which seemed wrong and wasn't working. I'll see if this works in my real code tomorrow. It's has a couple other lifetimes to wrangle with.
Can anyone who joined this tell me if that is about the programming language or the game?
I'm not trying to talk down doing something different. NetApp and EMC have some of the highest storage density platforms in the world and can do something like 1M iops, meaning one rack replaces several racks of other solutions (power and heat is a problem in the DC). That's decades of experience and stability, where it takes collaboration between vendors of OS, failover drivers, HBA, drive manufactures, and others. That takes time and experts in a lot of areas. Engineering is all tradeoffs, it sounds like Dropbox wasn't going for the iops and is willing to spend elsewhere building their own. Google's Juniper team did similar by building their own networking boxes for their data centers, and they said their solution wasn't able to match performance of network companies. The team mentioned it was because they didn't have the familiarity with building switches. Great read if you haven't read it! 'juniper rising' research paper. 
I'm also using Rocket with Docker and ELB, though I'm planning to migrate to K8s / EKS. Been an absolute pleasure to use and deploy so far.
Sweet... I didn't know about \`ArrayVec\`!
I don’t believe this is correct. If the buffer is too small, then I believe the entire packet will be lost. It maybe that you will get what was able to be stored in the buffer, but this should be ignored.
Edit: moved this up I don’t believe this is correct. If the buffer is too small, then I believe the entire packet will be lost. It maybe that you will get what was able to be stored in the buffer, but this should be ignored.
Looks like optimizer can't properly optimize out reference operations. The following code produces good results: fn or_vec_u32_3(v1: &amp;[u32], v2: &amp;[u32], v3: &amp;[u32]) -&gt; Vec&lt;u32&gt; { v1.iter().cloned().zip(v2.iter().cloned()).zip(v3.iter().cloned()) .map(|((z1, z2), z3)| z1 | z2 | z3) .collect() }
Oh wow I had no idea you could do that in a single Dockerfile! I've been using build scripts to effectively do that but with two Dockerfiles and manual container creation magic.
Worth noting that lifetimes are just types, syntax wise, so expressions like the following are valid and make sense: - `where T : Debug + 'a` - `fn something&lt;'a, 'b&gt;() where 'b : 'a` The subtyping relation for lifetimes, which is often (somewhat misleadingly) called "outlives" in the compiler error messages, means that 'b must be valid at least as long as 'a. So a longer lifetime is (usually) allowed in place of a shorter one, and `'static` is just the longest lifetime possible.
Me too! This changes everything.
Oh, interesting! Thanks. What led you to try that, in particular? It's surprising that it figures out the two-slice version fine without the `.cloned()`s, but can't figure out the three-slice version. Also, `cloned` doesn't seem to help when the elements are `bool`s: fn or_vec_bool_3(v1: &amp;[bool], v2: &amp;[bool], v3: &amp;[bool]) -&gt; Vec&lt;bool&gt; { v1.iter().cloned().zip(v2.iter().cloned()).zip(v3.iter().cloned()) .map(|((b1, b2), b3)| b1 | b2 | b3) .collect() } test vec_bool_iter ... bench: 1,165 ns/iter (+/- 95) test vec_bool_iter_fused ... bench: 6,771 ns/iter (+/- 529) Any idea why that would be?
Heh, this is pretty weird: fn bool_to_int(b: &amp;bool) -&gt; u32 { if *b {1} else {0} } fn or_vec_bool_3(v1: &amp;[bool], v2: &amp;[bool], v3: &amp;[bool]) -&gt; Vec&lt;bool&gt; { v1.iter().map(bool_to_int) .zip(v2.iter().map(bool_to_int)) .zip(v3.iter().map(bool_to_int)) .map(|((b1, b2), b3)| b1 | b2 | b3 != 0) .collect() } Now the fused version is faster: test vec_bool_iter ... bench: 1,200 ns/iter (+/- 137) test vec_bool_iter_fused ... bench: 890 ns/iter (+/- 236) 
We just started looking at using this at work. It's become quite an awesome solution!
Very cool. Right now my rocket rest api is deployed to Heroku with [the rust buildpack](https://github.com/emk/heroku-buildpack-rust). I'm really liking the ease of deployments, because it's as simple as `git push heroku master`. I think one day to give me more flexibility, docker may be in my future. Out of curiousity, I wonder what you all think are some pros and cons of using Docker with something like AWS or Kubernetes vs using Heroku?
Idea was to reduce amount of work which compiler has to do. In case of bools the straightforward loop with a small annoying dance to eliminate bound checks produces the best result: fn or_vec_bool_3(v1: &amp;[bool], v2: &amp;[bool], v3: &amp;[bool]) -&gt; Vec&lt;bool&gt; { let n = min(v1.len(), min(v2.len(), v3.len())); let mut buf = vec![false; n]; let v1 = &amp;v1[..n]; let v2 = &amp;v2[..n]; let v3 = &amp;v3[..n]; { let b = &amp;mut buf[..n]; for i in 0..n { b[i] = v1[i] | v2[i] | v3[i]; } } buf } It's hard to diagnose such problems without in-depth knowledge of LLVM (which is smart, but often not enough).
My list is quite long, but some projects that I use regularly which haven't been mentioned yet: * \[\`just\`\]([https://github.com/casey/just](https://github.com/casey/just)) - Sort of like a \`make\` replacement * \[\`tokei\`\]([https://github.com/Aaronepower/tokei](https://github.com/Aaronepower/tokei)) - Counting lines of code * \[\`mdbook\`\]([https://github.com/rust-lang-nursery/mdBook](https://github.com/rust-lang-nursery/mdBook)) - a \`gitbook\` replacement * \[\`gutenberg\`\]([https://github.com/Keats/gutenberg](https://github.com/Keats/gutenberg)) - a static site generator
Very interesting. Again, thanks! I'm going to see if I can incorporate yours insights into the library. Right now I have this: test vec_u32_adapter ... bench: 1,926 ns/iter (+/- 644) test vec_u32_iter ... bench: 204 ns/iter (+/- 10) test vec_u32_iter_cloned ... bench: 201 ns/iter (+/- 20) test vec_u32_iter_fused ... bench: 446 ns/iter (+/- 119) test vec_u32_iter_fused_cloned ... bench: 124 ns/iter (+/- 42) test vec_u32_loop ... bench: 1,638 ns/iter (+/- 396) test vec_u32_loop_fused ... bench: 821 ns/iter (+/- 165) That first line is using the abstraction, and the question is how competitive I can make it.
Agree. It ain't what you don't know that gets you into trouble, it's what you know for sure that just ain't so.
Already added a note to an appropriate-looking bug report. Thanks.
Yes, I have to use brackets or temporary variables every now and then. That doesn't annoy me very much though (especially compared to how much less bugs I get from Rust). I've been doing changes for compilers / linters for a long time in various languages.
BTW you can write a generic variant of this function, which will work with all numeric types: fn generic_or_3&lt;T&gt;(v1: &amp;[T], v2: &amp;[T], v3: &amp;[T]) -&gt; Vec&lt;T&gt; where T: Copy + BitOr&lt;Output=T&gt; + BitOrAssign { let n = min(v1.len(), min(v2.len(), v3.len())); let v1 = &amp;v1[..n]; let v2 = &amp;v2[..n]; let v3 = &amp;v3[..n]; let mut buf = v1.to_vec(); { let b = &amp;mut buf[..n]; for i in 0..n { b[i] |= v2[i] | v3[i]; } } buf } Same with iterator based code. Another thing at which it's worth to look at is auto-vectorization, which can be quite fragile. For such numeric code SIMD can result in a big difference.
Looking forward to it!
&gt; BTW you can write a generic variant of this function, which will work with all numeric types. Yes, the actual code is generic. The benchmarks aren't. &gt; For such numeric code SIMD can result in a big difference. Yeah, at some point I'm going to see if SIMD can help too. Thanks!
I’m curious. Do you use bind mounts in docker while developing to load source code, maybe even cargo watch? Or have a different setup for Dev environment?
I feel like the general idea within the Rust ecosystem is that empty collections shouldn't allocate. I'd also appreciate this change :)
I'm not deep into rust yet, but can you compare to using a basic ftok wrapped lib, and semephores for given needs?
I am new to docker and don't really know what I am looking at but people get excited about the things you've posted - could you explain what's this about? I don't want to miss a cool thing here 😀
Working on it now.
You want /r/playrust ; This is the subreddit for the Rust programming language. See also, the sidebar. It's generally a good idea to read it for subreddit rules before posting on any subreddit.
Thanks. Will clean up. Reading rules takes a long time.
Hyperledger Sawtooth! https://github.com/hyperledger/sawtooth-core It's an open-source consortium blockchain platform from Intel and the Linux Foundation. 
Comparing Rust to C and C++ for "easy to program" is missing the point. Is it easier than e.g. programming in Kotlin? Erlang (or Elixir)? Ruby and Javascript? For a lot of tasks, and a lot of people, no.
I didn't want to convince anyone of anything, but rather try to get people to understand the different viewpoints. And start to critic their own behaviour and opinion by themselves. That is what adulthood is all about :)
Super agreed. It was a really unfortunate decision to make a "checkpoint release" without upgrading critical ecosystem crates along with it.
(you do know that after 0.9 comes 0.10, not 1.0, right? there's no _real_ reason to jump from 0.1 to 0.8 instead of 0.2. that said, we like attatching meaning to numbers where there isn't any and bigger numbers in the minor version feels good.)
Very much r/playrust
I bind mounts in dev (using minikube) but for prod I bake the source into the image in CI (GitLab).
The `FixedSize` bit array uses a `Vec` as storage, which in turn is 24 bytes in size, in addition to 8 bytes for a usize to keep the amount of actual bits. To me it appears a boxed backend is only the size of a pointer, plus the size of the amount of bits totalling 16 bytes. Now that I think of it, this would half the required memory if the allocation wasn't enforced. Fortunately an `Option&lt;Box&lt;[Block]&gt;&gt;` is also just occupying 8 bytes thanks to the null pointer optimization, and None is just represented by 0*. Making the storage an `&lt;Option&lt;Box...&gt;&gt;` might have performance implications due to the additional check that must be performed to get to the data.
&gt; things worked quite well in the C/C++ world LOL! I don't think you have any real experience as a programmer / package maintainer to understand what cargo brings to the table. Ask anyone and they will tell you: compared to the hell that is C/C++ build system cargo is a god send. C++ does not even have a dependency management system. Supporting every random distro's package management system is just untenable. Especially when you can write tools which can solve this problem for you once and for all (see cargo-deb).
I think this is why Gitter is much better than Discode; Guests can read the content.
I wonder how stable it is? In the sense of things breaking with new Rust or Rocket versions are released. Does it still break compilation a lot? That's really the only thing holding me back. Not quite sure how long you've been working with Rocket, if you've just stated with it it might be hard to give a proper answer on this. 
And [done](https://github.com/tov/bv-rs/commit/8d8434bee7f179a7e8bc095a0ac9de10650efbdb#diff-9e5f98d173b62fabe9638a07ae432897L92). Thanks for the motivation! Will release as 0.8.2 later today.
It [no longer allocates when empty](https://github.com/tov/bv-rs/commit/8d8434bee7f179a7e8bc095a0ac9de10650efbdb#diff-9e5f98d173b62fabe9638a07ae432897L92). Thanks for the suggestion!
Huh, I see. Well, `bv::BitVec` is also 24 bytes: one for the pointer, one for the capacity, and one for the length. It would be hard (impossible?) to go smaller with a growable bit-vector. However, if you don't need to grow and are okay with your length being a multiple of the block size, then you can use `&amp;[u8]`, `&amp;[usize]`, etc., via the `Bits` and `BitsMuts` traits, which provide most of the same operations. &gt; Making the storage an `&lt;Option&lt;Box...&gt;&gt;` might have performance implications due to the additional check that must be performed to get to the data. Indeed. My code will never try to access the box when it's not there, because it length &gt; 0 implies that something is allocated. The question will be how to convince the optimizer of that.
You can check the list of nightly features of rocket here: [https://github.com/SergioBenitez/Rocket/issues/19](https://github.com/SergioBenitez/Rocket/issues/19) As long as it's using a single nightly feature you can and should expect regular breakages.
I think the goal is to create as small an image for the application as possible. Wee want to build the application, but we don't want to deploy the rust toolchain. So these Dockerfiles do it in two steps: first use an image that contains the rust toolchain to compile the application, then copy the compiled result into a minimal image.
Also https://whitfin.io/speeding-up-rust-docker-builds/
Maybe you should google me before insulting me line this. Your reply is highly inappropriate.
I just put it in (https://github.com/Byron/git-reconstruct/commit/02fec151d6936af6d231e318e7adb7ae78da3fba) and realized what you already knew: the size is pretty much the same as before. Maybe from that point of view, the potential performance hit and code complexity is not worth to maintain just for this particular usecase. Using my own storage is a great capability of the `bv` implementation, and in my case I could probably save quite a bit of memory at some additional complexity. Unfortunately I had to rollback my change, too, and went back to `FixedBitSet` as that implementation is faster. On my workload, that makes 2 minutes of a total (bv takes 14:30min, previously it was 12:30min).
&gt; Of course you can, but it's super frustrating because these scripts can do anything so you pretty much always need to do a full code review. There are a gazillion ways to install rust, all of them explained on the website. Fetching and running a script is the easiest one, but not the only one. The author is basically complaining that we give him a magic tool that install everything automatically, and the source code of the tool, but that the tool is to magic because he didn't bother to look at the source code. Yet it didn't try any other methods, but if it did, I am sure it would be complaining that they are too complex and not magic, requiring some manual steps. So what is it? We provide many ways, no way is perfect. Honestly, instead of complaining, the author should have just chosen a different way of installing Rust that suits it best.
Look working on C/C++ is my day job. I have been doing this for decades. So excuse me if you come here waltzing in and saying things are good in the C/C++ land, it felt like you were rubbing salt on my wounds.
&gt; Rust's packaging story is baaaad. cargo needed some built-in cargo publish command that generates binary and source .deb/.rpm/.msi files since day one. Why do these need to be built in? `cargo deb` generates `deb` files, and `cargo publish` publish to crates.io.
Look, and you still continue you negative tone. All I said was cargo does not install nicely on a Linux system, and is neither nicely package-able. Ps: I do all of this since ~1998.
This happens to be my first ever published crate. Feedback welcome. :) 
So you are running a compile from source distro, and complaining that to install things you need to compile them from source?
I do much more than that. Maybe you try to read what I write? No, I “complain” bootstrap process, about install location, sheer endless dependency downloads from the internet. Look on all the other Linux distribution who have problems with that. Who should that be packaged up for distribution?
So let's think about this for a second. Rust ships pre-compiled binaries for all of those hosts except RISCV of the current master branch _every day_. How can that happen? Is it magic? No, there are scripts that do this automatically, every day: rust-lang/rust/src/ci The scripts there cross-compile the compiler, run all tests on the target (e.g. via qemu), and then store the binaries somewhere. There are even Docker containers available with the minimum environment required to do that, so you can check which packages these Docker containers pull in.
Thank you, (for your marketing text), however this answers non of the questions.
Could it still have adoption into `itertools` though? That crate is pretty much built for niche iterator adapters.
I like how this AMA quickly turned into a TME (Teach Me Everything). That's how welcoming and highly devoted this community is! 
Pip does not install in the user directory by default. I am too lazy to check the others. The question was not, what tool can be instructed to do that. I mean, even any automake/autoconf-based C projects can be installed with setting PREFIX.
I've read what you wrote, and watched your video and honestly, you are just trolling. If you were trying to get anything done you would have filled an issue in the rustup repo, the rust-lang repo, asked on users forum or IRC for help, etc. Did you do any of that?
How am I trolling when I run a whole distribution and wasted over 8 hours go get the latest Firefox built?!? Have a little bit respect of people heavily contributing in the open source landscape, for a very long time.
Did you fill a rustup issue? Show me the link. Did you fill a rust-lang/rust issue? Show me the link. &gt; Have a little bit respect of people heavily contributing in the open source landscape, for a very long time. If you are so experienced, please, enlighten me of which open source projects use youtube as a bug/issue/feature request/q&amp;a filling system.
&gt;Because the author was installing it as root. Should it have been installed to `/root/local` ? No, `/usr/local` is the standard sane default, like I said. &gt; The source is availabe, so if you are already inspecting the source code of `curl` and `bash`, you can inspect (and change) the source code of `rustup` as well. You're missing the point—I'm not even talking about trusting that the binary is compiled from the source. Because `rustup` is a binary, even if I inspect the source I can't actually *do* anything about it since it requires rust to build. You don't know how many stupid installer bash scripts I've had to modify so that they didn't do something completely ludicrous. If I try to use the binary `rustup` I don't have that option at all. To me this means it's *objectively worse* than a plain bash installer. Luckily, the old bash `rustup` is still working. I hope it works for a long time because I have no intention of moving to the stupid binary one.
Please take a look at cargo-deb and see if you can replicate that for your distro. Cross compilation is currently not supported natively but an excellent alternative does exist, it's called xargo. You will have to do some reading up to understand how to put this all together since the way things are done in Rust is very different from how C++ projects are built and packaged. IMO packaging anything other than the basic rust compiler (and cargo) would be a waste of time since the end user can just \`cargo install\` anything else they want. Hope that helps and sorry for the insulting tone. Have a good rest of the day.
Why aren't you compiling rustup yourself then?
If this is all by design and awesome what bug should I fill? This was not a video bug report, that was a daily IT experience vlog update and general discussion. Nowhere did i claim it is a bug report.
If you are having problems cross compiling rust to system xyz, just fill an issue saying so, explaining what you have done, what you expected to happen, and what actually happened. Either people will tell you that "you are doing it wrong" and you should do xyz instead, in which case, they solved your problem, or people will say, "that's a bug, we should fix this". 
Unless I'm missing something. That is how the code /u/thiez gave you works. Changing the `main()` in that example to: fn main() { let mut vec = vec![1, 1, 2, 3, 4, 4, 5, 6]; println!("{:?}", vec); remove_first(&amp;mut vec, |&amp;r| r == 4); println!("{:?}", vec); } yields: [1, 1, 2, 3, 4, 4, 5, 6] [1, 1, 2, 3, 4, 5, 6] https://play.rust-lang.org/?gist=2d5aa6ae57f1fed3bf206f602ba61d00&amp;version=stable&amp;mode=debug
&gt;cargo install &gt; &gt; should only be used for additional tooling required for local development. Abusing it as a general application delivery channel is wrong and broken. Why / how is it broken?
it's likely, but I can't say for sure
&gt; But this now has the disadvantage that merely adding a trait implementation can break downstream crates. This is already the case. Adding an inherent method to a type, adding a trait implementation to a type, ... are all breaking changes. If a downstream user has a trait with a method named foo, and implements it for a type of an upstream crate, and the upstream crate adds a method with the same name, best case the signatures differ and the code of the downstream user will fail to compile. Worst case the signatures match, and the code of the downstream user will silently change to use the inherent method, potentially silently changing behavior. If an upstream crate adds a trait and implements it for a type on its public API, then depending on how the user was importing things from that crate it might break downstream code since now the method is ambiguous.
offtop: I wish crates.io links (well, the website to be precise) worked in mobile apps. Because you see a link, you are trying to click on it.. and good luck with that. crates.rs works fine (I love its static design), docs.rs works fine, github works fine, crates.io - does not. Is it would be helpful to run a bot that will post some properties of a linked crate? Say, repository/documentation/homepage links and a short description of it (not the whole readme). 
Looks very nice. I think the `MemoExt` type should be renamed; an `Ext` suffix makes me think of "extended", not "external". In other words, something that can hold multiple cached values, not something that looks very dangerous to use in trade for not holding the argument value internally. The whole crate reminds me more of C#'s ´Lazy´ than memoization, although the difference is small. A slight formatting hint: the code box in the crates.io readme display has space for at most 68 characters per line. You might want to limit your example to fit into this so that the box doesn't have horizontal scrolling.
&gt; I don't know if it covers exactly what you need, but since you seem to prefer trolling on youtube to filling issues or just asking when something isn't clear if it doesn't that won't probably change any time soon because the people working on it won't know about it. No ad-hominem please. If you are getting frustrated with the discussion, you can always opt not to participate. If you choose to participate, then please stay courteous.
Sorry, I should have known better than get mixed into this.
"micro" =&gt; left-pad "regular" =&gt; Boost.Algorithms (https://www.boost.org/doc/libs/1_67_0/libs/algorithm/doc/html/index.html) Why publish a library for *one* function instead of a library for the most useful functions of a *domain*. For formatting, for example: - left/center/right padding, - left/right trimming, - &lt;insert necessary algorithm here&gt;. Whether "micro" or "regular" is best is up for debate; I'd lean toward regular myself.
I am locking down this thread. The OP apparently is less interested in getting help, and more in venting their frustration, and unconstructive criticism is NOT welcome. The fact that other members of the community seem to be getting frustrated and replying in kind is NOT befitting of the community either. If you wish for a meaningful discussion of how best to package Rust for Linux distributions; please start a new thread and **mind the CoC** this time.
Don't take it too personally :) You are not the only one who got frustrated here; the whole thread is painful to read :(
&gt; So while I didn’t really do much in terms of quantity this week, I’m really excited to have done my first rust PR! **If anybody is still reading these blogs, please link me some nice rust application that uses unix sockets (preferrably tokio) so I can test them :)** I don't personally use tokio; could anyone else step in and help the OP?
If I may, instead of hardcoding a single parameter it sounds like you can just accept an `FnMut`(or one of the others) and let it store its parameters inside its closure. In Rust the way to do this kind of 'lazy evaluation' is through closures (for examples, see methods on `Option` and `Result`). 
cargo test can run test via script, you can look for example here: https://github.com/Dushistov/rust_swig/blob/master/android-example/.cargo/config https://github.com/Dushistov/rust_swig/blob/master/android-example/run-on-adroid.sh
Only if one uses SemVer.
A similar crate in this space is lazycell: https://crates.io/crates/lazycell.
If you're a functional programmer, this blog entry might be of good value in helping you think through this question: [In Rust, ordinary vectors are values](http://smallcultfollowing.com/babysteps/blog/2018/02/01/in-rust-ordinary-vectors-are-values/). Basically, as some have said in this thread, Rust is philosophically its own beast, it's a language that deals with the classic problems of imperative programming not by limiting mutation but rather by limiting aliasing of mutable memory. Generally, in Rust if some stack frame of your program is able to mutate some data structure, that means that no other frame possesses a reference that can observe that mutation. So 
As a substitute, there is [this](https://air.mozilla.org/rust-meetup-may-2017/) talk from a year ago.
Yup thats true ! To me it was just conceptual a big jump towards a stable crate but I guess "leaving room" before 1.0 doesnt really make sense if you plan on having large minor numbers
The reason why I designed this around a trait rather than closures is because if I used closures, I would need to store them somehow. This would require a trait object: `Box&lt;Fn...&gt;`, which would require allocation and dynamic dispatch. This would mean that the crate cannot be `#![no_std]`. Representing the computation using the type system avoids all of this overhead. My biggest design goal for this library is for it to be as lightweight and universally-useful as possible. This means `#![no_std]`. In particular, I can envision this crate being used to save some CPU cycles on embedded devices / microcontrollers by caching computations. 
&gt; - is_ready is equivalent to try_get().is_some(), I'm personally not a fan of too many helper methods that are trivially composed via the main API &gt; - ready() is equivalent to get() and ignoring the return value which is cheap here (it's just a reference) I disagree. I am of the opposite philosophy on this. While what you say is technically true, I believe that code should clearly communicate its intention. If a trivial helper method around a common operation makes the code clearer, it is worth defining. `try_get().is_some()` and ignoring the return value of `get()` to me feel like ugly workarounds for missing functionality, not like preferred ways of doing things.
As a learning example, I'm writing a simple rust util, that will look up my network's local bastion server - then build a command line up to then execute the full ssh command. But I seem to be getting hung up in the argument processing. [https://gist.github.com/drusellers/a9cc5feaadc5542fcbe1eacd848c8956](https://gist.github.com/drusellers/a9cc5feaadc5542fcbe1eacd848c8956) But I cannot for the life of me get it to work. \`\`\` "ssh" "-o" "ProxyCommand=\\'ssh -i &lt;key file&gt; -W &lt;target ip&gt;:22 ubuntu@&lt;bastion&gt;\\'" "-i" "&lt;key file&gt;" "ubuntu@&lt;target ip&gt;" \`\`\` With the error \`\`\` zsh:1: no such file or directory: ssh -i &lt;key file&gt; -W &lt;target ip&gt;:22 ubuntu@&lt;bastion&gt; \`\`\` I'm wondering if its the single ticks that are screwing this up some how. Thank you, \-d
&gt; The whole crate reminds me more of C#'s ´Lazy´ than memoization, although the difference is small. Hmm, I may be misunderstanding the term `memoization`, then. I thought it meant exactly what my crate does. Could you elaborate? &gt; A slight formatting hint: the code box in the crates.io readme display has space for at most 68 characters per line. You might want to limit your example to fit into this so that the box doesn't have horizontal scrolling. Yeah I noticed this after publishing. I'm not gonna make a new version just to fix the formatting in an example. I'll adjust it whenever I make the next update to the crate. &gt; Looks very nice. I think the `MemoExt` type should be renamed; an Ext suffix makes me think of "extended", not "external". In other words, something that can hold multiple cached values, not something that looks very dangerous to use in trade for not holding the argument value internally. Could you propose a better name? I agree with you that it is misleading (I think of "external", too), but I could not come up with anything better.
(disclosure: I’m an Amazon employee, but this is my personal opinion.) EKS costs ~$140/month + whatever EC2 instances you have under your cluster to operate. If that’s cost prohibitive to you, you can: - Use Kops—which is really nice!— and migrate to EKS if/when managing etcd becomes a pain or EKS becomes cheaper to operate. - Use Fargate. It’s cheaper and relies on ECS. In some ways it’s more mature, but there seems to be more interest around Kubernetes. - Consider GKE or AKE (Google/Azure Kubernetes, respectively). They’ll be less pricey than EKS, as EKS—at the moment—is targeted at customers with large pre-existing, Kubernetes clusters.
I really didn’t enjoy that thread, yeah. It proved me that spending a few hours on writing RFCs with the aim of “making Rust a better language” doesn’t pay, especially when you get responses like “the author knows this yet they opened the RFC” or “stirring up” or even having to “prove” that you act on behalf of good behavior. I mean, it’s a bit insulting being accused of acting with wrong ideals while all you want is enhancing something – and you can search the issues database, I wrote several RFCs, a few were accepted and being implemented and I’m open to comments to edit everything I wrote. My reaction to all of this is “Wait, why am I wasting my time trying to trying to improve and discuss a feature while people react by shutting the discussion down without even reading all the comments and giving a chance to the community to participate?” 
When you use a literal such as `3` rustc will magically understand that it is "some integer" of type `u8`, `i8`, `u16`, `i16`, `u32`, `i32`, `u64`, or `i64` (perhaps also `u128` and `i128` these days?). If type inference doesn't force any particular type, I *think* it just chooses `i32`, but I'm not sure. This magic for integer literals is (as far as I'm aware) unavailable for other types.
I've actually never heard of ftok but if both methods end up using shared memory, then they're essentially the same. This is fine for \*nix systems but my crate also works on Windows.
That's a shame, I really appreciated your RFCs...
Hopefully I enjoyed most of the responses from people who read it. I loved when people told me “You should consider this and edit that and here’s another lead and…”. That’s why I love writing RFCs, because smart people gather around a topic and try to make the best out of it. Anyway, all was said.
The generic function I'm writing should only work with integer types, I'm not trying to make it work with anything else. Is there a convenient way to make a generic function for integers only that allows for using integer magic?
No there's no trait like you want for primitives. Your best bet is to just make a trait like this `pub trait Integer {}` implement it only for integers then, depending on what operations you need, alongside Integer bring in any trait restrictions you need. The empty trait should solve your problem for the most part. It acts as a marker to restrict input like Send and Sync
Immutable datastructures are very nice for "snapshotting" behavior. Sometimes, you need the state of something at a point in time, transactionally. With immutable datastructures, that's basically O(1). Otherwise, it's not a very efficient way of doing things. 
I believe it's c native or stl. A wrapper class for that, and it was quite solid working w a transaction processing system. But tibco had a lib called Active Spaces Transactions, idk what it is now since tibco is like gone... But they used a Java wrapper around their C base code(used in visa edge).... All you had to do was use an @managed annotation for your class and bam, in shared mem. Though I dislike the Java crap that dances around the idea 
Why don't you use the [`tests`-dir](https://doc.rust-lang.org/book/second-edition/ch11-03-test-organization.html#Integration-Tests) for that? 
&gt; The generic function I'm writing should only work with integer types, I'm not trying to make it work with anything else. That's not really a meaningful statement. What is an "integer type"? Is `i32` an integer type? Is `std::num::Wrapping&lt;i32&gt;` an integer type? You should look at the operations that you need for your implementation, and demand a type that implements those operations.
So curious what your workflow consists of. There hasn't been much Rust Devops knowledge sharing.
Maybe everything was told but it's sad that such important topics are just being closed like that. RFCs are meant to be discussed as long as people don't reach a consensus. The discussion just started on this one and yet it got closed, it's really sad and such a situation shouldn't be possible (or at least from my point of view). Or, RFC process needs to evolve.
Just getting started. I’ll be converting over 6-7 endpoint from AWS Lambda to Rocket, so we’ll find out over then couple months what stability is like. I need to look deeper as to why Rocket requires the rust nightly build? Idk, yet. 
Holy cow!!!!!! Ok, this will be the thing I do right now! 
You might want to check out the [`num-traits` crate](https://docs.rs/num-traits/0.2.4/num_traits/).
Because then `cargo test` tries to execute the tests on the host system, which leads to errors.
All spot on as far as I know. My main motivation was flexibility. Meaning I wanted to set this built pipeline up, possibly try it out on different cloud platforms, wanted to be able to change it rapidly, tear it down and rebuild it quickly, and then yes admittedly play with and learn new cool tech. 
Awesome, very much appreciate your advice!
Oo, I wonder if this will eventually to lead to fixing the coordinate problems that all the WebRender based GUI prototypes seem to have on macOS.
How different is a ray tracer from baking textures(details of a high density mesh to a low poly mesh UV's generating a texture, eg normal map or diffuse)? I'm interested in working on a project that does the latter at some point. AFAIK, you use rays between the two meshes rather than a camera viewport and translate that info to the 2D surface(where the ray hits on the high mesh renders/writes the detail to the texture on the low mesh UV triangle that the ray was cast from). Would Accel be nicer to use vs a wrapper crate like ArrayFire?
rocksdb and leveldb have popular rust bindings. That one for instance is battle tested by tikv [https://crates.io/crates/rocksdb](https://crates.io/crates/rocksdb) (although it seems they use their own fork)
Note that future iterations will be able to take advantage of const generics to get rid of the manual array implementations.
Did you run it multiple times to rule out caching?
I've thought of the possible benefits of writing GPGPU kernels in rust and figured it's probably not worth it. The reason is that the model explicitly assumes unsafe, massively parallel indexing into the same block of memory, at virtually every step of the process. I see very little rust could deliver there (aside from syntax if one prefers it). A whole different story is of course higher level constructs like parallel for_all executed on the GPU. I'm curious to know your view of this. In my opinion, some clever abstractions could really help managing the memory, data transfers and the global state of CUDA runtime. But writing the very `__device__` code doesn't look like a good fit for rust, for me. 
I wrote https://wiki.alopex.li/LearningGfx a while back and it's still up to date for the released version of gfx-rs. Next version will change a lot, but I hope to write an updated version for it as well.
As an advice in any communication: always put the takeaways first. This way people that stop reading for whatever reason, will at least get the takeaways. :)
People have different ideas about it, that is fine :)
The example will compile with the bound on `M` changed to for&lt;'b&gt; M: Index&lt;&amp;'b str, Output = isize&gt; But you haven't given the call site, so I can't tell if this will break there (although it shouldn't in simple cases)
Still trying to figure it out, but something screwy is going on in total_weight += e.features.iter().map(|i| weights[i]).sum::&lt;isize&gt;(); borrowck seems to think that some part of that call chain borrows something that lasts outside the lifetime of the loop, even though the only data leaving the loop is an `isize`.
You can have closures own the entire environment by value (not just by reference) by using the move keyword. Further you can build abstractions that create these closures and return then by value using the impl trait syntax. Together these make closures extremely versatile and syntactic very concise.
Float literals have similar magic to infer `f32` or `f64`, defaulting to the latter.
Hey! I'm not the only person using Rust in Utah hahaha
I'm sorry it didn't work as well as you wanted. I'm still working on speeding things up. Did you try `BitVec` only, or using your own storage as well? Last night I discovered a performance problem in `BitVec`—an unnecessary double bounds check—and fixing that got a 5x speed up on my microbenchmarks for `BitVec::get_bit` and `BitVec::set_bit`. It doesn't speed up the access to your own storage via the `Bits` and `BitsMut` traits, though. I'll probably release the change later today (along with some minor API changes) as 0.9.0, but it's [on GitHub master now](https://github.com/tov/bv-rs/commit/45fcbaa106fc4c5616e7178f2fee0b4009495536).
I was also unsure what exactly the difference between laziness and memoization was, and [this](https://stackoverflow.com/questions/26322132/memoization-vs-lazy-initialization-evaluation) SO post defines them as: &gt; Memoization is saving the result of a long execution in order to not repeat it once called again. and &gt; Lazy initialization is making this long execution only when needed and not when initializing the object. This seems to suggest that the biggest difference between the two is that laziness mostly pertains to initialization, while memoization refers to the more general caching of long computations.
This site appears to block VPNs, by the way. So that's fun.
An open-source alternative: https://getfider.com/ — could be potentially integrated into crates.io somehow?
Surrounding the loop with braces changes nothing. I think because of the lifetime annotation in the where clause, the borrow-checker decides to keep the immutable reference to `self.entries` alive until end of the function. If there is a way to workaround that, I think the issue will be resolved. I `truncate()` removes elements from the end, but I want them to be removed from the beginning as the vector is expected to contain entries sorted by age, because that is the order in which elements will be pushed.
[removed]
there have been several discussions about it lately. here is the [most recent one](https://reddit.com/r/rust/comments/8qcf5t/rocket_to_actix/). I would recommend using Actix, not Rocket, even though Rocket has a very flashy website.
8pm UTC happens when this comment is 3 hours and 38 minutes old. You can find the live countdown here: https://countle.com/b208406YgD --- I'm a bot, if you want to send feedback, please comment below or send a PM.
You might be interested in a [project](https://github.com/MaikKlein/rlsl) of mine where I compile a subset of Rust to SPIR-V (logical mode). I am just about to finish implementing compute shaders and my current goal is to live code a very simple path tracer at an event at my university at the end of this month. Sadly the project is still fairly alpha and not usable right now.
Definitely not! We had a good first meetup yesterday, and the next one is coming soon! We're excited to execute on the ideas and plans we made.
I wasn't scientific about it but iirc I ran fd first so caching should have worked against it. I toyed with it for a bit and it was never slower than find in my use case.
Based on "cult" in the domain? (How many real cults would actually identify as such?)
No, I don't think it's that. While I'm using my VPN the site refuses connections. After some testing, it's only some VPN endpoints that are blocked, so it's probably just whatever hosting service the site is on blocking known VPN server IPs.
Oh, I mistook it that the VPN was blocking the site, but it's the other way. Strange.
Testing is built in to the Rust language and compiler. You can tell the compiler that any function in your code is a test by prefixing it with `#[test]`, and that function will only be compiled when you use `cargo test` to build your program. See chapter 11 of the manual: https://doc.rust-lang.org/book/second-edition/ch11-00-testing.html
As of this latest nightly, for the first time ever, running it works completely fine on the project it used to always fail for :) . The performance has also clearly come a long way!
That's great news! That's one reason I didn't use winit in xi-win, but there are a whole bunch of other details I'm running into (handling of smooth resize, etc). If those were addressed and there was no performance hit, I'd be interested in switching to winit from my hand-rolled stuff.
Okay, I also managed to speed up the `Bits` impl for `&amp;[Block]` by about 30%, and the `BitsMut` impl by a bit less. That's probably not enough, yet. Indexing `BitSlice` is faster than that, for some reason, but I'm not sure why yet.
I understand the reason that Rust thinks that this isn't valid: the compiler thinks that the `Index` instance (whose type is bound to `M`) could potentially be holding on to a `&amp;str` key given it BEYOND when `weights[i]` was run. I'm trying to figure out how to assure it that the reference is only kept in the lifetime of the desugared `*weights.index(i)` call, but I'm still getting to the point where actually resolving these problems are natural for me... :P Will keep trying to hack at this.
Use: M: for&lt;'b&gt; Index&lt;&amp;'b str, Output=isize&gt; Good luck!
Even if there were an AutoClone trait, I would definitely *not* want Rc or Arc to implement it.
There are definitely cases where people have discussed taking away previously sound features--e.g. for a while people were wondering whether we could fix Drop to take PinMut&lt;Self&gt; instead of &amp;mut Self.
Feel free to open issues for anything that's missing! I can't address things that I don't know about. One things I've been hoping to add soonish is support for macOS live resize and X11 `_NET_WM_SYNC_REQUEST`, but I haven't been able to find the equivalent for Windows.
Yeah I think the number one best thing about the safe vs. unsafe distinction is that you don't really have to remember anything most of the time. Having to track exception safety alone is a huge productivity killer.
OK, thank you. It seems like I was correct then in describing my library as addressing both. It evaluates your computation lazily when you first use it and then saves/memoizes it, returning the cached value on subsequent uses.
That works! Here's a playground of it working: [http://play.rust-lang.org/?gist=22dff657329dca2321a239f292031430&amp;version=stable&amp;mode=debug](http://play.rust-lang.org/?gist=22dff657329dca2321a239f292031430&amp;version=stable&amp;mode=debug)
Will do. Right now, my methodology is to develop close to the metal so I can experiment with confidence I'm not running into compromises from cross-platform abstractions. But once I know what it should look like, using common infrastructure would be better. I'll file some issues.
On the whole, I think you're probably right. If I were doing this path-tracer project over again, I probably would just use CUDA C, at least for the kernel. Most of the things that Rust does really well don't apply so much to kernel code. Kernels tend to operate on very simple types (eg. giant arrays of floats), generally don't manage resources and often have relatively simple logic without much branching or error handling. That said, I see no reason why Rust couldn't be at least as good as C is for writing kernels, and as you say, Rust offers a lot of advantages for the Host-side code. If nothing else, at least Rust programmers wouldn't have to switch between languages.
I'm afraid that I don't really understand your first question. ArrayFire is more of a high-level wrapper; it doesn't allow you to write custom kernel code as far as I can tell, but instead exposes a set of high-level operations that operate on arrays of values stored on the device. This is convenient, but this sort of abstraction always carries some degree of performance overhead. Accel provides much lower-level access. This is useful when you need to reduce the performance overhead (or just when you want to learn about the low-level details, like me) but requires more developer effort. It's a tradeoff, as are so many things in this field.
You could define your own trait with an index method that takes a `String` and implement this for `HashMap` and `BTreeMap`. You'd have to copy the `&amp;String` that you were previously using to index into `weights`. There may be better solutions. I think the real problem is there must be a way to indicate `M` doesn't store or otherwise require the `&amp;str` passed to `index` after `index` returns.
Sorry for the late answer. What's wrong with the `Cargo.toml`?
I'll have a look at it but they seem a bit too oversized for me.
The maximum size of a UDP datagram is only 64KiB, you might as well just allocate the whole thing up front so long as you reuse the buffer.
Someone probably tried to attack one of the sites they host from those VPN endpoints.
There are a bunch, but a good number only work on nightly. It also looks like there's a little question of whether or not Stainless is still maintained. [crates.io](https://crates.io/search?q=bdd)
I suspect dumindunuwan is looking for this particular aspect of how BDD APIs look: **Ginkgo (Go):** Context("With fewer than 300 pages", func() { It("should be a short story", func() { Expect(shortBook.CategoryByLength()).To(Equal("SHORT STORY")) }) }) **Jasmine (JS):** describe("A suite is just a function", function() { var a; it("and so is a spec", function() { a = true; expect(a).toBe(true); }); }); There's [stainless](https://crates.rs/crates/stainless) or, if a Fluent API is close enough, there's [spectral](https://github.com/cfrancia/spectral). Beyond that, check the [bdd Keyword](https://crates.io/keywords/bdd) on crates.io or the [Testing category](https://crates.rs/development-tools/testing) on crates.rs. (I prefer crates.rs, but it hasn't reached full feature-parity with crates.io yet.)
I've never used Rayon or any other alternatives, but I have used OpenMP in the past. I'd probably prefer to have OpenMP, which is familiar and often incredibly simple to use (although I can't compare this with Rayon or anything else).
I would say that the smart thing would be to define your needs/requirements, then, ask yourself, does Rayon meets those needs? Does some other Rust crate meet those needs? Will only OpenMP meet those needs? Just saying, "I'm familiar with OpenMP in C++ so I should use it in Rust" sounds to me like putting the cart before the horse.
It looks like the people behind Rayon are interested in adding features to the crate that would make it at least to me quite similar to OpenMP. Here's a link to the [specific issue](https://github.com/rayon-rs/rayon/issues/553). I've thought about this issue for quite a while, since I'm interested in expanding Rust to a lot of HPC type applications. I've had to rethink some of the ways I might approach these shared memory type problems to work with Rayon. However, I've found it works for a majority of the problems I've thought about parallelizing my computing problems. So, I guess my thoughts on this manner are that Rust crates do a good job at covering similar features of those found in OpenMP, and it's only getting better as time goes on. 
Hi there! This is the subreddit for the Rust programming language. You're looking for /r/playrust
\&gt; Specifically, I needed to modify nvptx/src/compile.rs to remove the +nightly argument to Xargo. I haven’t submitted a pull request for this because I’m unsure if that change would work for others or if it’s just an oddity of my own environment. FYI, I did not need this.
You need to specify the type of the content of the Vec, which is what is meant by a 'type argument'. Something like `Vec&lt;i32&gt;`.
I didn't see this posted here. So, I thought I'd post it myself.
Thanks for that, but I got an error now: calls in statics are limited to struct and enum constructors
Anyone have examples of where the new borrow checker correctly disallows seething that the original doesn't? I didn't expect something like that but I got the impression that it does happen from the article.
Maybe try out the `lazy_static` crate. It allows simple construction-on-first-use. The other option is to use an Option and initialize it the first time your function is called. A static can only be created by a `const`-evaluable expression. `Vec::new` is not a `const fn` (at this time, at least), so it cannot be used to initialize a static. The reason for this is that there is no time for that initialization to run before other code, as in Rust, there is no^1 code run before or after `main`. ^1 : well, ok, no _user_ code; there technically is a bit of glue before to set up panic unwinding
Perhaps you might find lazy_static fits your use case?
That's because you cannot call Vec::new in a static context. You might want to look up the lazy static crate.
I'm curious is there any reason you can't build the Vec outside the function, and then just pass in a mutable reference into the function? Then you would only need to build it once, and you could save on time. I guess since your doing this as part of a coding competition there might be some restrictions on what the input the function can take in.
You currently can't run the `::new` as part of a static initializer. What you might instead do is use a `Option&lt;Vec&lt;...&gt;&gt;` and initialize it as `None`
Last thing I did had dockerfile like this, nothing really special: FROM ekidd/rust-musl-builder:stable as builder COPY Cargo.toml Cargo.lock /home/rust/src/ COPY src /home/rust/src/src USER 0 RUN chown -R 1000:1000 Cargo.toml Cargo.lock /home/rust/src/src/ USER 1000 RUN cargo build --release FROM scratch WORKDIR / COPY --from=builder /home/rust/src/target/x86_64-unknown-linux-musl/release/myapp . CMD ["./myapp"] It was just a small app so I didn't really have much more of a workflow for that.
Yep, they call my function with a certain set of arguments. I can't change the arguments.
By "original" do you mean "today's borrow checker" or "the previous version of NLL"?
I have to say that is unfortunate. Well I hope you're able to get one of the other methods suggested to work. 
In the best case, rayon is four extra letters*, `iter` -&gt; `par_iter`, to multithread your code and light up all the cores. Not always appropriate, but when it is, it's brilliant. * imports etc notwithstanding
&gt; and it might be a bit too esoteric but looks like I cannot easily write fn clip_u8(val: N) -&gt; u8 that would take any primitive numeric type as input, do comparisons inside and return value either clipped to converted to u8. The best answer on how to do it I found was “you can’t, it’s against Rust practices”. But... why? Does Rust really not come with a tool for cases where losing the high bits of a number is not a bug but the *expressed purpose* of a function? Is there at least a generic (if clunky) way to perform "blasphemous" operations on a number type?
This also surprised me, and I'd be interested in an examples as well.
It's answered in one of the comments of the article by MoSal: A fully generic clamp to type function in case you are still interested: https://play.rust-lang.org/?gist=3a2cc2fdf22eef8602589679a5c91b1e
I believe today's borrow checker based on my Reading of the article.
Sorry for double post, on phone so editing sucks. So specifically this bit from the transition period section: During the transition period, we will issue warnings if your program used to compile with the old borrow checker but doesn’t with the new checker (because we fixed a bug in the borrow check
Here's a short example: https://github.com/intermezzOS/kernel/commit/e6508a00ec0bc9ffa417d003d81ae63eceac2cf9 With the old borrow check, this would fail to compile: #[test] fn write_a_letter() { let mut mock_memory = [0u8; ROWS * COLS * 2]; let mut vga = Vga::new(&amp;mut mock_memory[..]); vga.write_str("a").unwrap(); vga.flush(); assert_eq!(mock_memory[0], b'a'); assert_eq!(mock_memory[1], 0x02); } This is because, `mock_memory[0]` takes a reference to `mock_memory`. But, `Vga` also borrows a mutable reference to `mock_memory`. Since borrows are based on lexical scope, the mutable borrow lasts until the end of the function. The fix today is to write #[test] fn write_a_letter() { let mut mock_memory = [0u8; ROWS * COLS * 2]; { let mut vga = Vga::new(&amp;mut mock_memory[..]); vga.write_str("a").unwrap(); vga.flush(); } assert_eq!(mock_memory[0], b'a'); assert_eq!(mock_memory[1], 0x02); } Now, `vga` only exists for the inner scope, and so the mutable borrow goes away before the immutable borrow starts. The new MIR-based borrow-check/non-lexical lifetimes basically understands the code as if you wrote the `{}`s, without needing to actually write the `{}`s. The borrows are based on where the borrows are used, not on lexical scope. Make sense?
Oh, THAT bit. I’m not sure.
Yeah it's slightly worrying because it sounds like it's working around issues where the borrow checker was allowing code that it shouldn't. I suspect that it's a misunderstanding on my part but is instead just code that the new checker can't prove is correct.like the old one did so it's disallowing an otherwise valid program. 
&gt; Easy of programming? Check! (Once you're used to it.) I can confidently write Rust code even when I'd be too tired to write safe C/C++ code, and even write concurrent code fearlessly.. Yeah, `borrowck` got your back (or rather slaps it), so it's easier to get stuff done *without mistakes*, but that does not say anything about how easy it is to *get stuff done*. Example: once you get your specialised tree structure to work, it's going to be close to unbreakable, yet when someone asks "how do I make a specialised tree structure" the answer is "don't" because it's really hard to pull off.
I really like where this is going, but I have a problem with the blogpost. You didn't mention at all that it will only work with an Nvidia GPU. I know that they are the most popular GPU vendor and CUDA is popular (and right now it's the only implemented solution in rustc), but I think naming a proprietary technology as a de facto standard is not healthy for the GPGPU ecosystem.
&gt; Can I execute a .sql script from a text file in diesel? Yes, Diesel provides API for executing random sql. (I mean diesel the library, I am not sure about diesel cli). &gt; Can I change the default migration path where diesel looks for them? Yes. See help for the commands.
I think the OP was actually referring to things which the current borrow checkers allows but shouldn't (as referenced in the post) and not just NLL.
For example, the reproducer in [issue 31567](https://github.com/rust-lang/rust/issues/31567) is still accepted by default, but is correctly rejected with `#![feature(nll)]`. Probably most of these [bugs labeled unsound and fixed-by-NLL](https://github.com/rust-lang/rust/issues?utf8=%E2%9C%93&amp;q=label%3A%22I-unsound+%F0%9F%92%A5%22+label%3ANLL-fixed-by-NLL+) too. 
I actually saw that, but thank you for pointing it out :) My issue with this is that some projects, for example the one in the article, cannot or do not want to depend on external crates, and in those cases one is stuck with "I can't let you do that, Dave". For complicated problems that may be acceptable, but I don't consider it sensible for things like basic integer operations.
It’s pretty easy to write this particular trait on your own. You lose interoperability with the ecosystem, but it seems like the author is not interested in that anyway.
Hello. I'm MoSal, the one who left some comments there. 1. We are not only talking about unsigned types. So losing the high bits does not really describe what is needed. 2. Rust does have: a. A lossless facility for casting between num types (`From`). b. A lossy facility (`as`). The issue with `as` is that: 1. It's not trait-ified, that is, it's not implementable via traits. 2. It only works between known primitive types. That's why we can't use `as` with generics. And that's where `AsPrimitive` from `num-traits` helps. But `as` is not the only trait that is not trait-ified in num types. That's why `num-traits` exists. To to work around those limitations in std. The generic clamp function I shared: ``` fn clamp&lt;T, R&gt;(val: T) -&gt; R where T: From&lt;R&gt; + AsPrimitive&lt;R&gt; + PartialOrd, R: Bounded + Copy + 'static { let min = From::from(R::min_value()); let max = From::from(R::max_value()); num_traits::clamp(val, min, max).as_() } ``` 1. `From` is used to make sure the type we will clamp from can represent all the values of the type we will clamp to. 2. `min_value()` and `max_value()` are defined by `Bounded` from `num-traits`. 3. `as_()` is defined by `AsPrimitive` from `num-traits`, because we can't use `as` here.
That looks like a perfect set of examples. Thanks.
Well, *that's* certainly an unhelpful anti-blogspam solution. By the time I managed to bisect my way to figuring out what was causing the unhelpful "You're spam. Go back, check everything, and try again." message (my use of spamgourmet.com to provide revokable e-mail addresses in case they leak to spammers), it decided that it was being flooded with spam attempts and locked out comments completely. Here's what I was trying to post: &gt; But I’m looking forward to be able to use .step_by() in stable. To clarify the comment in that example, it was stabilized in nightly 13 days ago, so, barring the discovery of any catastrophic flaws that hold it back, it'll be in stable two version bumps from now. (So, 12 weeks or less.) Source: https://github.com/rust-lang/rust/pull/51320 ...though they're still working on fixing a performance edge-case: https://github.com/rust-lang/rust/issues/51557 &gt; or if it will join std in some form. Given that crates are used to distribute things that are maintained by the Rust team and, in other languages, would be part of std (eg. regex and rand), I wouldn't hold your breath for it.
Thanks for the explanation. That works.
Thank you for your answer, I learned something new today! I guess I can see why `as` isn't trait-ified, but I wonder why `std` lacks a facility similar to `num-traits`, it seems like an obvious candidate for inclusion to me.
&gt;and it might be a bit too esoteric but looks like I cannot easily write &gt; &gt;fn clip\_u8(val: N) -&gt; u8 &gt; &gt;that would take any primitive numeric type as input, do comparisons inside and return value either clipped to converted to &gt; &gt;u8 &gt; &gt;. The best answer on how to do it I found was “you can’t, it’s against Rust practices”. I don’t need it much and I care even less, so I’ll just mark it as a neutral language feature and forget about it. You could create a Trait called ClipInteger and implement that trait for all u\* and i\* types. The trait would have a method "fn clip\_u8( Self ) -&gt; u8". Then, your function that should do this clipping need only take as a parameter "T : ClipInteger" as the parameter type.
lazy\_static is definitely what you want.
[@managed's latest tweet](https://i.imgur.com/Vsap8k2.jpg) [@managed on Twitter](https://twitter.com/managed) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
No, it's disallowing something that the current borrowck allowed but should not have (a bug). The new borrowck correctly disallows it (fixes the bug).
&gt;cannot or do not want to depend on external crates I think the idea of "External Crates" when talking about crates on [crates.io](https://crates.io) is not really meaningful. [crates.io](https://crates.io) is the official place for Open Source libraries that are freely usable by the Rust ecosystem. In what way is it different than a huge standard library? Mostly it is different in that it can evolve much more organically. If there is concern about the underlying library/crate not meeting your needs in the future, simply create a new wrapper crate that provides the API you want and leverages the underlying crate. Then, you can create alternate implementation crates (or use different crates that implement semantically equivalent functionality perhaps in a different way) and choose at compile-time through feature flags which underlying crate is used.
I saw the message for the meetup. Didn’t make it. Is there any chance that the future meet ups will be somewhere further north of Lehi?
The winapi 0.3.5 crate is only 1MB. Where are you getting this 116MiB claim?
Nothing, I was just curious to see which crates you’d use. :)
The next one is even further south IIRC, but idk if there's a permanent location ironed out yet.
IIRC, the design space was too broad and there wasn't enough consensus for inclusion in Rust 1.0. It might be possible to add it in now but the community is caught up with more important things for the time being.
Congrats!
It certainly seems like you should drop the single quotes. Does it work when you try it? I think what's happening is that you end up passing the single quotes all the way through to the remote machine's shell, which interprets them as a single word and looks for a program by that name. Normally the shell on your own machine would interpret those out, but here you're using the Rust command builder instead of a shell, and quotes have no special meaning.
&gt; This is convenient, but this sort of abstraction always carries some degree of performance overhead. Accel provides much lower-level access. In my use of ArrayFire in the past, it seems to be pretty good perf for JIT kernels it creates. I ported a algorithm I did in OpenCL for Hashcat that had pretty much same perf via ArrayFire in Rust but was more easier to setup imo. I get what you're saying though. &gt; I'm afraid that I don't really understand your first question. A ray tracer is rendering a scene from a camera to an image right? Like a viewport. The kind I am referring to of baking, is to flatten a 3d mesh(like a cube into it's 6 sides) into 2D space(UV) where a texture can give information like colour or lighting information(that a ray tracer may use I guess to display in a viewport). Baking is the process of transferring information from one 3D mesh to another mesh, storing that information into a texture that maps to the target mesh. Perhaps the pictures in these links explain it better: https://blenderartists.org/t/blender-is-only-baking-to-certain-parts-of-mesh/487863 http://wiki.polycount.com/wiki/Texture_Baking
For a newbie like me: Is there anything that OpenMP provides besides managing a thread pool and dispatching workload in those threads?
"Evolve organically" means it grows with a lot less oversight wrt security and correctness than the actual standard library, which presumably is reviewed by trusted people. So that's a possible reason. Another is that you might just want the total amount of code in your project to stay comprehensible.
Do you need store anything other than a sequence of floats? Have you considered just writing the values directly to a binary file?
It can actually do quite a bit from being able to as you said create a thread pool and then tell that workload what to do. One of its newer features allows you to offload work onto Phi boards and GPGPUs. You can signal what variables are private and shared between threads. You can break up your workload such that so many cores work on a given task. If you'd like to get a better idea Lawrence Livermore has a nice [tutorial on OpenMP](https://computing.llnl.gov/tutorials/openMP/) and what you can do with it. 
Are you hoping for something in SLC or further north? Unfortunately, the next meetup is planned to be in southern Provo. If we could get a co-organizer local to the area, then expanding northward certainly could be possible.
I'd recommend the [`num-traits`](https://docs.rs/num-traits/0.2.4/num_traits/) burntsushi mentioned with the addition of `From&lt;u8&gt;` if you need to supply small regular numbers.
https://doc.rust-lang.org/book/second-edition/index.html This book explains most core concepts, including the prelude. Many other languages have elements you don't need to import, most of them don't call it a prelude though (Haskell does).
That's why you pin versions, either by vendoring or using Cargo.lock.
Rust uses jemalloc rather than the system allocator. If the library allocated the value with libc's malloc, you should use libc::free. Freeing it with a different allocator is guaranteed to go poorly.
Thanks for the info, good to know. But I'm using rustc for the library as well, it's my own library. So it should be jemalloc for both allocation and deallocation.
Oh, sorry, just skimmed before replying. Unsure then. 🤷‍♂️
Yes, that's what it is! https://doc.rust-lang.org/1.9.0/book/custom-allocators.html#default-allocator Thanks for the help!
[OpenMP is directly supported in GCC](https://gcc.gnu.org/wiki/openmp). I _think_ that similar directives could be enabled via Rust Macros, namely the [synchronization](https://computing.llnl.gov/tutorials/openMP/#Synchronization) and [parallelization](https://computing.llnl.gov/tutorials/openMP/#ParallelRegion) pragmas. I haven't used enough of Rayon and OpenMP, but Rayon doesn't look like something where one could do a mechanical port of an OpenMP program using it.
vec::new() doesn’t allocate anything on the heap, since a vec of size zero takes zero memory, which would have added confusion to your tests. You’d have to use with_capacity to get the behavior you were attempting to test.
Indeed i read it but i can’t understand it,although i will search for curiosity about the haskell prelude. But thank you for your respond.
It was great. Glad we finally got it started.
I guess the reason this also fails when passing a mutable reference to a vec is that we may be allocating for a resize when pushing on the vec, and I suppose that must be somewhat random given it still fails in a later iteration.
Yes. SLC would be great. I regret having attending last night because I missed out on representing crustaceans from further north. However, if there is not a meetup up north, I’ll still try to attend as I’m very much interested in being a strong rust programmer. 
Ahh good point, forgot that. But I'd probably end up needing to resize the vec in the library and end up in the same situation later.
As the Rust docs explain, Rust automatically inserts this into every program for you: extern crate std; use std::prelude::v1::*; That allows you to use types like `String` and `Vec` without having to write `use std::string::String` and `std::vec::Vec` in your program because the prelude did for you. If you had any Python experience in college, the prelude is equivalent to the `__builtins__` module in Python, which provides types like `str()` and `list()` without you having to explicitly `import` them.
Generally, the rule is to ensure that whatever allocated also frees it. This is especially important on Windows where you're not even guaranteed that it's safe between two different versions of the same C/C++ compiler.
If you don't like the C preprocessor, an alternative, more general purpose and neater macro processor is [m4](https://en.wikipedia.org/wiki/M4_(computer_language)), so you might like to check that out too.
Thanks for the answer. I should've stretched that I don't want to use the cli (by hand) but rather run the migrations *programmatically* (that's what I used dbmigrate-*lib* for). Diesel CLI gets the path to the database via env-variables, while there could be multiple creations at the same time withing my application (so it would setup multiple .sqlite-databases concurrently)
Now if only vulkano always used the latest version... Also unsure what will happen to my polling-strategy (game!) if that gets removed. Maybe it doesn't but in some issue it was talked about only providing one way of querying events (I guess it was "`run_forever`"). But well, I'll see. Thanks for the awesome work!
How would one do that in a Rust/RAII-like style though across the divide? I've read about requiring specific calls to free depending on the library, which doesn't seem ideal either.
vulkano-win is actually just [one small file](https://github.com/vulkano-rs/vulkano/blob/master/vulkano-win/src/lib.rs) (Vulkan and the windowing system aren't as tied together as in OpenGL), it's trivial to fork + update it to whatever version you need. A new version of winit hasn't been released yet, it's just the merged PR. I'm sure they'll update it as soon as possible. Yes there are changes regarding "EventsLoop 2.0". There are multiple issues regarding the current API design, part of which are inconsistencies between operating / windowing systems, part of which are assumptions that didn't turn out to be efficient in practice, especially for non-game applications. 
The `'static`lifetime means that a resource outlives *everything* and only get dropped when the program terminates. 
All I am saying is: I hope winit stays a viable solution for games as well ;)
I like `new_at`, it's simplest solution in my opinion. `&amp;mut unitialized` could be replaced by `&amp;out self` to make it shorter.
OK. So, only heap allocated resource only should be having 'static lifetime right? And one more thing I wanted to ask is, should I keep transforming from one type to another type when I return result from one fn to another? and all data should be stack allocated?
Maybe when we get custom allocators we can easily switch to libc malloc.
Thank you very much, sir, for your explanatory effort, I think i got the hang of it.
I'll have to punt to someone else on that one. I've dabbled in C, C++, and Rust, but I haven't yet needed to get familiar with the interactions between Rust's data structures and `dlopen`-based library-loading.
I don’t think so. The way I understand it (this might be a bit of an oversimplified explanation) is that when you have something like `const X: &amp;'static str = “Hello World”`, that string is included in the machine code, and loaded into RAM together with the actual code. When you refer to `X`, that reference points to that string within the loaded machine code. Also, I don’t quite understand what you are asking in the second question, could you add a bit more context?
Aha, yeah a lot more complicated than I'd like. Truth be told, I was only doing this dynamic library thing so I can live-reload code and get a faster dev cycle that way. So I might just force the allocators to be the same and call it a day. But if I want to make the library re-usable from python or something, I guess I'll have to do it the way you suggest or similar. I just hate having to have manual freeing, so error prone!
In the context of tokio/futures, `'static` just means that something owns all of its data. Yes, `'static` as a lifetime means it lives forever, but as a bound it just means the data will be alive as long as long as it is kept. It could live as long as necessary. Notably this does not require heap allocation! Simple data structures are also `'static` since they are not bound to any other lifetime. `i64` is `'static`. The only thing that isn't `'static` is a reference to data which lasts for a limited amount of time, like an `&amp;i64` borrowed from somewhere on the stack or heap.
It depends on the language you want to reuse in. Many of the popular ones that you'd want to extend with a compiled module have helper crates. I use rust-cpython to glue a PyQt frontend to a Rust backend and I don't have to worry about manual freeing because rust-cpython writes the boilerplate code for me. (It even comes with type-conversion implementations for common Rust types so I can just return something like `PyResult&lt;String&gt;` and rust-cpython will handle converting Rust's `String` to Python's `str()`.
I'm sorry there were technical difficulties in continuing the live stream yesterday. But i promise it will happen same time today. 🙏
You're into very dangerous and unsafe territory, because it's going to be difficult to guarantee that the `Vec&lt;f32&gt;` in your library is the same as the `Vec&lt;f32&gt;` in your main program. First, Rust has no stable ABI, so you need to compile both library and main program with the exact same compiler. Second, maybe the `Vec` struct changes between releases, but worse is that rustc is allowed to reorder fields between compilations for structs that are not `#[repr(C)]`. And there is no guarantee AFAIK that `Vec` is repr(C). Third, as already discovered, they need to be allocated by the same allocator. It's dangerous to go alone! Take [this](https://docs.rs/reffers/0.4.2/reffers/aref/struct.ARef.html). If whatever you wrap in an `ARef` is `#[repr(C)]` then that should help against most of these issues.
Alternatively, you could create a macro.
Note that MPI (distribution over machines) != OpenMP (distribution over threads).
Perhaps the [num crate](https://crates.io/crates/num) could be of use here, in specific [num-traits](https://crates.io/crates/num-traits).
&gt;`use std::prelude::v1::*;` in every module That's not a correct description. If prelude names were inserted in every module, then you'd be able to write `self::Vec` in any module, but you can't do that. In fact, prelude is inserted once in the crate root as `#[prelude_import] use std::prelude::v1::*;`. Such prelude import adds names *in scope* for all the crate, but doesn't plant them into modules. The same behavior is exhibited by `#[macro_use] extern crate foo;` in the root adding macros in scope for the whole crate. &lt;sub&gt;There are couple of very subtle differences, but they are bugs.&lt;/sub&gt;
The uninitialized (or similar) would be necessary to tell the compiler that the passed reference can not be used unless explicitly initialized. I don't see a way around that part. I like the '&amp;out self' concept, which would be fine for many/most cases. But falliable initialisation should alsof be possible imho.
I tried to do something with it, but couldn't manage to get the division /2 working ...
In that case, it'd probably be a good idea to revise/clarify this passage from the docs: &gt; On a technical level, Rust inserts &gt; &gt; extern crate std; &gt; &gt; into the crate root of every crate, and &gt; &gt; use std::prelude::v1::*; -- https://doc.rust-lang.org/std/prelude/
What does `OpenMP` allow you to do that rayon does not?
&gt; How would one do that in a Rust/RAII-like style though across the divide? You'd have to create an RAII wrapper on the consumer side: you're talking to the library through C and C has no concept of destructors/RAII/whatever. Incidentally that makes returning a Vec by value quite dangerous, they're not necessarily layout-stable (Rust doesn't have a stable ABI), so you want to return simple C types (from libc or types you control with `repr(C)`) or *pointers* to more opaque types. Usually, the library would provide both allocation and deallocation functions to ensure the same "internal" allocator is used for both sides, the user of the library would just use the library's relevant deallocation function with whatever object it got.
Isn't there a CUDA to SPIR-V compiler by AMD somewhere? They were at least working on that for Linux.
Is there a good article or docs somewhere describing it and how it works?
I actually think the point is to catch any regressions of code that *shouldn't* have problems, as soon as possible, so that when it gets flipped on for good correct code doesn't break without warning. For a long time, enabling nll triggered failures on sound code in my own repository--as I mentioned in an earlier comment, the most recent nightly is the first time that it hasn't.
This is a big step especially for the WebAssembly target! Hope we get more unified syntax and functionality now. Currently the library for async_await, futures and tokio have many inconsitencies and it is really hard to use one let alone all of them together in a project. Big thanks to all the hard working folks for making this possible! 
It's called [HIP](https://github.com/ROCm-Developer-Tools/HIP]), when targeting Nvidia GPUs, a tool converts the HIP API calls to the corresponding CUDA API calls and then it can be compiled with the CUDA comipler (so the HIP API is mostly identical to the CUDA API, just the word "CUDA" is repaced with "HIP" everywhere), and when tageting AMD GPUs, the tool calls AMD's special compiler called HCC, which is an LLVM fork with extra support for AMD specific stuff. Unfortunately SPIR-V is not involved at all, it generates PTX for Nvidia and direct GPU assembly for AMD (btw. there's an open PR for targetting AMD GPUs in the rustc repo).
I… don't understand. `rustc --explain` already outputs Markdown. What more do you want?
That it doesn't use SPIR-V is indeed unfortunate, but at least now CUDA can be used to target nvidia and amd on some platforms. 
https://imgur.com/a/T9R7yj9 I think it's more readable if terminal can render markdown syntax. 
I'm not an expert in this, but my impression from the diff is that `async fn` are generators/coroutines that yield nothing and return a `Future`. You can read about generators here: https://doc.rust-lang.org/beta/unstable-book/language-features/generators.html, and mapping from `async fn` to coroutines should be straightforward, but intricate in details.
I don't see how you could make this more readable. There's nothing to render in this screenshot!
u/Mattpiz, the following using \`num::NumCast\` should work (though this won't handle conversion errors very nicely): fn half_res&lt;T, U&gt;(mat: &amp;DMatrix&lt;T&gt;) -&gt; Option&lt;DMatrix&lt;T&gt;&gt; where T: Scalar + NumCast, U: Scalar + NumCast + Add&lt;U, Output = U&gt; + Div&lt;U, Output = U&gt;, { let (r, c) = mat.shape(); let half_r = r / 2; let half_c = c / 2; if half_r == 0 || half_c == 0 { None } else { let two: U = num::cast(2u8).unwrap(); let half_r_mat = DMatrix::&lt;T&gt;::from_fn(half_r, c, |i, j| { let a: U = num::cast(mat[(2 * i, j)]).unwrap(); let b: U = num::cast(mat[(2 * i + 1, j)]).unwrap(); num::cast((a + b) / two).unwrap() }); let half_mat = DMatrix::from_fn(half_r, half_c, |i, j| { let a: U = num::cast(half_r_mat[(i, 2 * j)]).unwrap(); let b: U = num::cast(half_r_mat[(i, 2 * j + 1)]).unwrap(); num::cast((a + b) / two).unwrap() }); Some(half_mat) } }
I'm curious as to why anyone would down-vote this comment by wanderer976? Please don't down-vote just to signal disagreement. It is intellectually lazy.
It's when your bill for shampoo comes up.
Those code blocks are wrapping with three back-ticks, right? ````
You seem to have sense of humor, how funny.
Thanks! So since OpenMP can offload to GPGPUs it has become a alternative to OpenCL and Cuda?
Check https://learning-rust.github.io/docs/d7.std_primitives_and_preludes.html and other pages in `Let's get it started` section. You will understand more about Rust library project structures, usages of `pub use` and preludes. 
\`\`\` $ cargo new --bin dep\_test $ cd ./dep\_test $ cat &lt;&lt; EOF &gt;&gt; ./Cargo.toml socket2 = "\*" EOF $ cargo vendor ./vendor $ du -hsc ./vendor/\* | sort -hr 115M total 54M ./vendor/winapi-x86\_64-pc-windows-gnu 52M ./vendor/winapi-i686-pc-windows-gnu 6.4M ./vendor/winapi 2.4M ./vendor/libc 212K ./vendor/socket2 164K ./vendor/redox\_syscall 52K ./vendor/cfg-if \`\`\`
You can try changing the PAGER PAGER=more rustc --explain E0120 This will replace `less` with `more`, so you can use whatever cli that render markdown for you
I'll be honest I'm not as familiar with the offload support to GPGPUs, since it's only started to be supported in the last year or two by compilers. However based on what I've read, it appears to transpile/compile(?) the code over to something that NVIDIA based GPGPUs can read and use. So, I guess it's acts more as a high-level wrapper of CUDA than anything else. 
Your question makes sense. It would be nice to have a CLI markdown interpreter that does syntax highlighting and displayed the source code in code. I don't know anything that does that unfortunately...
Yeah, HIP was originally developed for companies to make it easier to switch from Nvidia hardware/ecosystem. For example, Tensorflow is CUDA only, but AMD is developing a HIP version. SPIR-V was supposed to be the ultimate IR for graphics and compute, supporting every new GPU and every programming language. It turned out that SPIR-V for graphics and SPIR-V for compute is very similar, but different enough to require two separate mechanisms to run, so while SPIR-V for Vulkan is fairly popular, SPIR-V for OpenCL is almost dead, as well as OpenCL itself. Khronos wants to merge the functionality of OpenCL into Vulkan, but there are no public details. The other problem is, upstream LLVM doesn't support SPIR-V *at all*, so the various forks make it impossible to develop support properly. There was some discussion about it on the LLVM mailing list a couple of months ago, but I didn't see much change since then.
Wow. An entire week.
Maybe [c2rust](http://c2rust.com) is of interest.
The `'static` lifetime implies that the object *can* outlive any lifetime. It doesn't necessarily mean it only gets dropped when the program terminates. It just means Rust doesn't have to enforce that this object goes out of scope before any other object does. For example, a `&amp;'static str` has a `'static` lifetime, but so does an `i64`, or a `String`. This is why functions like fn take&lt;T : Clone + 'static&gt;(t : T); can have strings and integers as argument. In the context of Tokio, which is essentially a concurrency framework, this makes sense: a `'static` resource doesn't have to be destroyed before any other resource, and it can live as long as needed. On the other hand, `'a` resources do have a lifetime and must be destroyed before their parent goes out of scope. We are, however, working with concurrency. This means that we can never guarantee that something in one thread gets executed before something in another thread, so we cannot promise that an object in one thread gets destroyed before an object in another thread goes out of scope: it's always possible to park the first thread until the second thread is done computing, and the compiler itself is not smart enough to reason about locks. Therefore, in order to send an object to another thread, requiring that it can live on its own is the safest option.
On mobile, so it's awkward to find the issue, butiIt sounds likely the default will change to the system malloc once there are stable custom allocators. I'd like that. It'd avoid surprises like this. valgrind would work out of the box. Binaries would be smaller. And apparently the performance difference is kind of a wash anyway. (Some programs don't care. Some are faster with jemalloc. Some are faster with the system malloc, at least on some systems. If it's not clearly much better, the default should be simpler / no surprises.)
Consider using rust-peg (just called peg on crstes.io). It is a PEG based parser generator. IMO the most ergonomic of the bunch.
Hey everyone! Just in case you're not in the loop, we now have a Meetup group (http://meetu.ps/c/3WRyD/FYvwM/d) and have decided to make the #utah channel on http://rust-lang.slack.com. Come and say hi! :)
Just posted a reply to OP with more links if you're not already on Meetup and Slack. :)
Also, did you forget a "not"? I'm confused...
There is a little tool callet bat (written in Rust) which brings coloring to markdown. You could then do `rustc --explain | bat | less` to have it colorized and paginated
Whoops. Yeah, fixed that. 
Wondering, *why* can't you use lazy static? Or similar?
You could try passing around the array.
The situation with vulkano wrt winit updates is sorta bad, i.e. https://github.com/vulkano-rs/vulkano/pull/953 (this merged in 0.13.1, not the 0.15.0 version I mentioned there). So, you really should use your own patched version, since it's genuinely an easy thing to do. Also, if you track master I'll love you forever; not very many people do that, so I only find out about bugs *after* releases. Anyway, don't worry about games. I have that usage in mind when working on winit, since saying I'm going to use winit to make a game is the only way I'm able to rationalize my time investment. The upcoming restructuring won't result in a loss of capabilities, and if it does, that's unintentional and you should definitely complain.
No, like /u/SelfDistinction explains in the other post, it means that it **can** outlive everything. It doesn't need to.
There has been some really impressive progress in winit lately. Great work! Thanks for putting in the time. :)
Programming is hard. Learning a language &amp; ecosystem is the easiest part by far.
I was making my own VM that's conceptually similar to the BEAM a while back, hopefully I'll be picking it up soon again: https://gitlab.com/tino-platform/tino
HYYYPE
Thanks for reminding me why I should stay as far as possible from front end web dev. With some luck wasm will make all of that a distant memory some day.
I'm currently on the 10th chapter of the Rust Book and am struggling to understand the following paragraph: ``` Another way we could implement largest is for the function to return a reference to a T value in the slice. If we change the return type to &amp;T instead of T, thereby changing the body of the function to return a reference, we wouldn’t need the Clone or Copy trait bounds and we could avoid heap allocations. Try implementing these alternate solutions on your own! ``` For reference, the function in question is the following: ``` fn largest&lt;T&gt;(list: &amp;[T]) -&gt; T where T: PartialOrd + Copy { let mut largest = list[0]; for &amp;item in list.iter() { if item &gt; largest { largest = item; } } largest } ``` Can someone explain to me *why* we wouldn't need the Clone or Copy trait bounds in more detail? I'm very unfamiliar with low-level programming (self-taught dev with JS experience mainly) and I do not see how returning a reference to T absolves the function from having to make heap allocations. 
What’s your point?
I tried it by installing via brew. But there is no difference in the output 
Interesting approach. What happens if the bodies of `log` and `finish` would contain code, though? Does get run on the calling thread *and* the in-type receives the arguments?
Thanks! Works like a charm!
Erm...Is this your first time learning a programming language, or are you coming from another one?
This is part of a programming competition. I can only submit a function. I do not get to control anything outside of the function, including how it is called. I have attempted to use a crate, and I get back an error: error[E0463]error[E0463]: can't find crate for `lazy_static`: can't find crate for `lazy_static`
Because it can return a reference to the element that already exists. Otherwise, it has to make a copy of the element, which might involve heap allocations.
I'd prefer "oxidized".
Try adding \`rlib\` to the list? Alternatively, you might want to make a Rust library with the C bindings in a separate crate. See for example [https://github.com/hsivonen/encoding\_rs](https://github.com/hsivonen/encoding_rs) / [https://github.com/hsivonen/encoding\_c](https://github.com/hsivonen/encoding_c).
Thank you. Making a separate crate seems like a good idea, as it keeps the clutter out for people who don't need it. I notice your C crate doesn't specify a lib section at all, is it not necessary to do so? I'm just following along with this example and not really understanding what the settings mean.
wouldn't it be better to make it so you can use rust interactively? dyon only seems to exist because of the lack of this capability? to be fair having used it up just going by how the readme describes it.
This looks great! Question: Does Dyon have a runtime? If so which one / how does it work? I always thought Rust would make a great compile target for a higher level language with a runtime and good concurrency built in. 
Yes, it executes as normal functions does.
I hope to see some good scripting environments for Rust in the future. One problem is integration with other libraries, since Rust doesn't have a stable ABI yet. You need to use C-compatible interface, I think. Dyon was created just because I was waiting for some Gfx upgrades and got a couple of weeks. It turned to be so much fun to work on so I continued working on it!
Idiomatic means "peculiar to or characteristic of a particular language or dialect". Idiomatic Python is referred to as "pythonic", to my knowledge there is no similar term for Rust yet. 
Dyon is an entirely new language (but it's clearly inspired by Rust). It's designed to be easily embedded into a larger Program and be fed scripts to execute, similar to Lua. You can't really do that with Rust since you'd need to ship the whole compiler. Dyon also has some first-class features that require a nontrivial runtime (dynamic typing, coroutines), and features you'll never find in Rust that are clearly aimed at more niche scenarios (vector operations, HTML hex color literals).
"Compiling" (in a world where `#[deny(clippy)]` has gained some more features)
Dyon runs on the AST directly. First, Piston-Meta parses the source code and gives the "meta-data" to the AST constructor and the lifetime/type checker. This happens in parallel, so Dyon can load scripts faster. The run-time walks over the AST and executes the code. It is not as hard to make as it sounds. If you have coded any AST in Rust before for simple language, then Dyon basically does the same thing, but on a larger scale and more features. `enum` and pattern matching everywhere. One tricky thing is deriving the position of variables on the stack from the source code. Dyon has a Cargo feature flag that checks those variables when running, in case there is a bug in Dyon. You can build Dyon without this feature to make it run faster. There is no garbage collector in Dyon. To pass objects by reference (arguments with `mut` or with a lifetime), you must refer to them by name, so they live on the stack. All objects on the stack are given a lifetime which is checked before type checking. The run-time does not know about lifetimes, so if it wasn't for the lifetime checker it would be unsafe. Dyon has only a lifetime checker but no borrow semantics, so it is kind of a simpler version of Rust. People want a REPL environment for Dyon, and the way it works now isn't REPL-friendly. In the future I think a graph with expression indices might fix that problem. You need to pause execution and feed it one line at a time in a REPL, but currently Dyon can't pause once it starts executing a script.
Use a static `RefCell&lt;[u8; 1000]&gt;`
Can you use rust-gdb to help see what's going on?
Note these are the 1.9 docs, the feature is unstable, and so I wouldn’t expect any of this to work like this.
&gt; Second, maybe the Vec struct changes between releases, but worse is that rustc is allowed to reorder fields between compilations for structs that are not #[repr(C)]. And there is no guarantee AFAIK that Vec is repr(C). In practice, I imagine the field ordering is deterministic, is it not? Or are you suggesting that changing the rest of the program may result in a different field ordering? Yeah that wouldn't be great. Thanks for the pointer to `ARef`, if I ever make my library generally available I'll make sure to use that. For my case where I'm just trying to get live reloading during development, I think I'm happy to take the small risk that it messes up again if I update compilers and forget to recompile both, or somehow the compiler decides to reorder fields for `Vec` differently.
Does it really need to be a static?
Just use 'unsafe' which: Access or modify a mutable static variable https://doc.rust-lang.org/book/second-edition/ch19-01-unsafe-rust.html
Ahh, is that not describing the current behavior on rust stable though? I just tried searching for anything current about that, no luck.
My function is being repeatedly called. I have no control over what is calling the function. I am trying to make the function remember what the values were when called earlier, so it doesn't have to recalculate them each time the function is called.
The behavior is accurate, but all the code is wrong.
Nice suggestion. I just tried: use std::cell::RefCell; static s: RefCell&lt;[u8; 1000]&gt; = RefCell::new([0; 1000]); But got back: error[E0277]: `std::cell::RefCell&lt;[u8; 1000]&gt;` cannot be shared between threads safely
No, I don't have cents of humor. At best I have a cent of humor.