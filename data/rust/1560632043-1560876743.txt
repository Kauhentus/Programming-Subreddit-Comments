Support for async file system operations is probably not as good as you imagine.
Thanks for the reply, I tried cloning the repo and it seems that download speed stuck at 9-6 KB/s so I filled a report to GitHub support before I noticed this message &gt;Need help with the rust-lang/crates.io-index project? &gt; &gt;You should get in contact with @rust-lang. But I'm not sure what to write an issue about, how is the cloning speed relate to you? isn't that GitHub problem? btw for now, can I shadow clone the repo (to save time)? where should I clone it to?
I haven't tried in a couple months, but log handler I implementing for log create would should compile errors in intellij, but it compiled fine from cargo.
Counterpoint: for quite awhile it has been the case that almost every single 1.X compiler release has fixed yet another batch of (often longstanding) roadblocks/inanities/annoyances/omissions in the language and/or standard libraries; meaning it's hard to pick one particular version among them all, and, depending on the problem at hand, sticking with a sufficiently-old compiler can be an exercise in self-demention.
Learning curve. New users spend a lot of time fighting the borrow checker and learning the trait system, since they are a little different from how other languages do things. It's a problem that is helped greatly by the volume of community resources, but it's still a big problem.
For example gtk+ and Qt uses even loops for both network stuff and UI events.
&gt;and then people also complaining that it has too many features already I think it's a bit more nuanced than this. In many languages you can be productive without being familiar with too many language features, while in Rust there's relatively many things you need to understand before you can write anything non-trivial. But I also think Rust's benefits more than make up for it.
You can implement Add for &amp;T
I'll look into that later tonight. Is there an alternate vs code plugin or is it easy to point existing one to rust-analyzer? I'll Google more intensely later, but I didn't see anything on first page of "vs code rust-analyzer".
&gt; Also, as /u/etareduce will likely say, I don't have to say it now that you have... :)
These short keywords are examples of terseness more than explicitness, although I suppose they are explicit too, but no more than other languages. I personally don't like the shortening of keywords and types but ¯\\\_(ツ)\_/¯
Posts and comments related to cryptocurrencies usually get downvoted here, haha. I think it's a shame that all the speculation in the cryptocurrency world has given the subject such a bad reputation, even though some of the technology is really interesting. Maybe this will lessen over time as the technology matures.
See the README for rust-analyzer. All you do is run `cargo +stable install-code` and it compiles and installs both the RA LSP and the Code extension. You only need to remove the existing rls extension. You will need a current version of NPM to compile the code extension. I installed NVM for that.
I am the same as your friend, I write as much as I reasonably can in Rust. Sure, there is a limit; if you need to rapidly prototype at your job, then use something like Python instead, but if time is not scarce, it's better to continually use and learn the language if it is so difficult.
A newbie question. Is it uncommon in Rust to 'declare' a shorter name for some variable to access it with that name. E.g something like this "let mut last = vec.lock().unwrap().last().unwrap()" (assuming vec is Arc&lt;Mutex&lt;Vec&gt;&gt;, not sure if that is valid though) and then use 'last'? I want to know if is it non conventional or maybe impossible because of move semantics?
I think this has some truth to it, but my concern about this subsided somewhat after I converted my own C++ code into Rust. The Rust is far easier to read and understand compared to the original, although admittedly C++ is a low bar in this regard.
Zola is now officially supported and available in our static site environment.
&gt; The language's real potential still always seems one unimplemented RFC away (e.g., async, const generics, GATs, unsized rvalues, etc.) Agreed, that's an unfortunate property of Rust that I also discovered. An example is: Even if we get async/await, we can't properly use it in traits. In order to do that, we will need at least existential types for some use-cases and then also GATs for some more advanced use-cases. I think that property stems from the extremely strong type system in combination with the no-implicit-allocations/GC attribute.
Ah, interesting! Maybe it could be possible for libraries to integrate these things after all.
The structure of the crates.io repository, in that every crate name is in the same "global" namespace. There are accounts that take up as many single-word names as they can and ask you to PM if you want to use them, and I can only imagine that they are trying to make money off of that. I'd prefer a structure like the one that Docker Hub has, where each user gets their own namespace and relatively well-known projects can apply for a top-level name.
&gt; Observe that everything you are saying is true of types as well. (Because lifetimes are types.) Yes, changing the implementation could change the lifetimes—or the types—in the signature of the function. Yes, lifetimes are also types. But currently changing the implementation of a function, does not change the signature. This means that there is no chance that you are breaking downstream builds. &gt; Changing the implementation already potentially changes the lifetimes. The only difference is that now the human programmer has to figure it out instead of the compiler. If the lifetimes of the public API is annotated, the compiler will still refuse to compile incompatible implementation code just as it does now. This is false. Currently changing implementations does not change the signature of a function. &gt; if the code is correct, the (most general) signature of the function is determined by its implementation. (I suspect—haven't found a counterexample yet.) This most general signature can change depending on the implementation of a function, therefore changing implementations can break downstream builds. If you are forced to annotate the signature, you are forced to think about what api you want to expose. This is good, because you can choose to be forward compatible by choosing a more restrictive lifetime annotations. But if lifetimes are inferred, you never even think about it, if you need to change implementations later, you can't without a breaking change. &gt; What would be a problem is if the most general unifier were not unique. I have tried and failed to come up with such an example—but again, I've only started learning Rust since, what, Tuesday I think? Anyway, the point is I don't really know if lifetime inference is always possible, or if it is feasible (i.e. not exponential), or if it's even useful. Maybe requiring the programmer to work it out themselves in nearly every situation is a good thing and a better design decision. ¯\_(ツ)_/¯ I think that the largest problem is that global lifetime analysis makes keeping a stable api very hard. Because you don't have to think the lifetimes anymore, library builders will likely just forget about it. This leads to people accidentally make breaking changes because they can't or don't properly analyze the lifetimes of their api. Lifetime analysis is hard even in small programs. In large programs in becomes nigh impossible for humans to properly analyze and extrapolate it's implications. Also, because lifetime analysis is reducible to is SAT, it is also NP-complete. Meaning we likely won't have an algorithm to perfectly analyze lifetimes in less than exponential time. Current methods are not perfect, we had lexical lifetimes, then with the introduction of the 2018 edition we got nll, and we will be getting polonius. But none of these are perfect, they are just approximations that (ignoring bugs) never accept wrong programs.
Some perfectly reasonable code ends up looking really ugly. For the styles where this happens, the language has forced you to spend mental power on something other than what you care about when you're editing it. Reference counting is the best example. In Python, it saves you from having to worry about ownership issues in most places. In Rust, it adds an extra layer of complexity to every variable access - you *must* decide if this is a borrow or a clone, every single time.
Cool. That was fast!
A `serde` question: how do I deserialize multiple things from the `Deserialize::deserialize` body? I want to conditionally deserialize either type A or type B, and I don't know how to do that given that `deserialize` takes ownership of the deserializer. I'm aware of all the ways `Deserialize` can be derived for enums, but unfortunately it's not sufficient for this situation.
True, but then I need to write things like &amp;(&amp;a+&amp;b)+&amp;c
I think you have misread. I said *’it depends on the type of foo’*. About half way down.
&gt; I can confirm that the download speed is the same for cloning different github Glad to hear. I was not sure how we could be at fault. Sometimes our `libgit2` dependencies... no iday, so glad it was not Cargos problem. I hope Github support can help. &gt; maybe it's time for squashing again Indeed, thanks to your report, I was going to bring up when to squash again at the next Cargo meeting. &gt; can I shadow clone the repo (to save time)? where should I clone it to? I don't know enough about shallow cloning to say if that will work, but worth a try. My cargo made a bare repo at `~/.cargo/registry/index/github.com-1ecc6299db9ec823`. If some other host is working faster, maybe we can mirror it for you and you can try to clone it to that DIR.
This thread clearly shows that you cannot please everyone. We all want a sample language with no learning curve and lots of advanced features, that compiles instantly to blazingly fast optimized code... I know this thread is about the parts we don’t like so its all good 😊 I think we should strive to do better. Just clear that there is no pleasing everyone 🤷‍♀️
What you're describing has little relation to the iterator API, though. The same would apply of many methods in Rust which require a type to be defined. `string.parse()` is another example.
Totally normal! In fact, it's really nice with mutable references. I can't think of a case where you'd get ownership problems when you do this off the top of my head. If the compiler tells you that you can't move out of borrowed content, you probably just want a reference to begin with.
I don’t think it’s relevant where it is. You still need to know about these details when using Iterators. Which was my point.
I see a lot of people saying rust has a complexity cost to it of some kind, but I wonder how that cost is unique to rust among systems programming languages. I mean sure, in Cpp the compiler won't yell at you for not annotating your lifetimes, but now you have to manually track them yourself and make sure everything is in order. Same with memory safety. The complexity isn't removed just because you don't have to address it at compile time.
So much this. Why every rust crate needs to have rust mentioned in it's name?
Awesome!
This is better used as build metadata, rather than version number.
Right now I have a few disabled via the command-line (with a Makefile wrapping around that). This helps for the few lints I never care about, such as `clippy::new_without_default`.
Here's a recent example of some code I saw that does this: [https://godbolt.org/z/SYMUem](https://godbolt.org/z/SYMUem)
The point of a 1.0 version is that you can safely upgrade to 1.1, 1.2, etc. Prior to 1.0, any minor change is allowed to be incompatible. This means you can not upgrade confidently without going through the changelog of the dependencies you want to upgrade.
Interpreters written in Rust. Using a computed goto you can save yourself an extra branch per instruction. At least on slightly older hardware (pre Haswell if I remember correctly) this could have a noticeable performance impact. Some more info can be found here: * https://eli.thegreenplace.net/2012/07/12/computed-goto-for-efficient-dispatch-tables * https://pliniker.github.io/post/dispatchers/
For me it's the docs. They are very detailed and most crates are very well documented, but unless you know what you're looking for, they can be quite confusing. I can't think of a better way, but I think it's the way traits are documented, that can make exploring and discovering really hard.
But how would you add non-Copy types without moving them?
&gt;Then you have things like embedded devices. Nearly all of the SDKs are either C or C++. Get rust onto the esp32 properly and I would wet myself. There was a lot of interest in embedded rust in my local meetup - like LLVM can generate code for the flavor of ARM the Gameboy Advance is running, so is it up to the community to make whatever ISA esp32 uses to be properly supported, like appearing on here? https://forge.rust-lang.org/platform-support.html (I'm coming from the land of HTTP so the only 'embedded' stuff I've played with is Rust on Raspberry Pi)
You can also consider arrayvec for a stack based vector (has a fixed capacity but starts empty).
I don't understand why this is different from ==. With a==b, I compare the two objects and return a Boolean. With a+b, I make a new T representing the addition of a and b and return that. Why don't I need to write &amp;a==&amp;b every time I compare two non-copyable values, if I need to write &amp;a+&amp;b to add them?
Append `-rs` to the repository to differentiate it from other languages, but remove it in the crate name.
It doesn't really have lazy evaluation though, so strict ordering of effectful stuff is not the goal, and Monads aren't going to be that useful, it's more just the nice syntax, a la optional chaining? I'm no functional programming God, so tell me why I'm wrong :)
When I was learning I found if I wrote bog standard C I got up and running pretty quickly, ie structs with a few methods. The borrow checker didn’t fight me too much. It left me thinking if this is all Rust was it would be pretty good for small projects. Once I started writing more idiomatic Rust things started to get more complicated quickly.
You really ought to read a sub before posting to it. You're looking for /r/playrust
A question about generics with trait bounds containing the \`From\` trait: Let \`MyType\` be the generic type that implements \`From&lt;Source&gt;\` and \`Source\` be another Type. The way I interpret the error message I get in \[this\]([https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1615d62056499d308c5a32a186791f9f](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1615d62056499d308c5a32a186791f9f)) example, \`Source\` has to implement \`From&lt;MyType&gt;\` as well, in order to be able to use \`mytype.into()\`. As this doesn't make much sense I must have got the usage wrong.
Rust adds complexity where it isn't smart enough to understand that your lifetimes are ok. In C++ you can go "yeah... this is ok because X is never used after Y" or whatever. In Rust you might have to rearchitect your whole app to convince the borrow checker that it is ok. Of course, once you've done it you won't get random segfaults because you made a mistake like in C++, but it definitely adds complexity.
Yes! Busy. When you throw all these features together into one function declaration line, Rust code is very busy, a difficult to read soup of symbols.
Is this really the reason they chose \`-&gt; String\` for function types? So that programmers could use simple text searches? Well, there's precedence for many language syntax choices... that doesn't make them good decisions.
Nice!
I agree with you there, but... C++ syntax is an incredibly low bar to set. There are far more elegant languages that Rust could have emulated, rather than choosing the safe "let's keep the language familiar and not scare C/C++ devs" route.
I'm fairly new to Rust, but here's some things that have annoyed me. * No convenient way to split modules across several files. I know about re-exporting, but it's tedious, and unfortunately the most common practice in Rust seems to be to have everything in its own submodule. So you end up spending a lot of time trying to remember names of the submodules where each type/function is located and writing additional use declarations. The worst offender is the standard library itself. * The borrow checker often severely limits what you can do. You might even be forced to make unnecessary copies because of it, which in a performance oriented language is pretty bad. * No way to restrict visibility within the same module, i.e. two types in the same module can access each others private fields and methods. This encourages even more submodules. * No standardized constructors. It's not always obvious how you're supposed to initialize some object in a library that you're using. Sometimes there are "constructor" functions named in arbitrary ways, sometimes there are macros and sometimes you're supposed use the struct initialization syntax. * So many obscure yet essential traits, and the way they're all related to each other gets a little confusing. * The ability to redefine local variable bindings goes against the Rust philosophy of safety and correctness. Even C doesn't allow redefinitions. * Imho Rust is too strict about global static objects and static initialization. * Many of the macros (`print!`, `vec!`, `panic!` etc) and attributes (mainly `derive`) seem like lazy adhoc solutions to problems that should have proper language or standard library features.
It's incredibly useful when learning a new API. It would be an oversight to not think about searchability. Whether it's grepping in a terminal, or searching API documentation in a web browser.
Any reason why you do it that way rather than in the code? That way you don't need a makefile wrapper.
It's a very naive way of thinking. I know what a car is and what a chair is, but what if I want to Sit on my car? What is important isn't WHAT things are, it's what they DO.
main.rs: mod file_x; mod file_y; file_x.rs: use crate::file_y::some_function; // or, within the code crate::file_y::some_function(stuff);
&gt;Most notably missing from Debian Stable are NLL from 1.31 and impl Trait from 1.26. And the Debian before that shipped 1.14, which meant no stable custom derive.
You could decrypt to a nameless temp file that never touches the filesystem. I know Linux has good support for that now, and I think the tempfile crate can do a reasonable emulation on most other platforms.
Author here. Yes, re-reading this, I'd prefer to re-phrase it. "Item" is correct, but we don't introduce "item" in the book. "statement" was an attempt to not need to introduce a whole other set of terminology, but it can be misleading, as you've found. Sorry about that. Care to file a bug?
Thank you so much! It all works now!
The module hierarchy you've described looks like this: main mod_x mod_y There are two ways to reference modules higher up in the hierarchy. Either with `crate` or `super`. `crate` refers to the top-most module of the crate (`main` in this case). `super` refers to the parent module. Since `main` is the parent of both `mod_x` and `mod_y`, you can access the `mod_y` from `mod_x` with `super::mod_y` or `crate::mod_y`. The `crate` syntax has an older form, which looks like `::mod_y`. You probably don't want to use the older form.
&gt;Unfortunately I believe they generally prefer to be wrong and misleading instead of accurate and precise, We prefer to give you the correct \*intuition\* rather than be mechanically accurate; it's a book, not a language reference. That said, we strive to not be \*incorrect\* while doing so, though sometimes, we make mistakes. We're only human. We should fix this.
Thanks!
Thank you :3
Thanks for helping visualize it. This language is extremely different to C# and it's not very comparable to it so I would have never considered that the other modules are basically children of main. Thanks again.
&gt; I would like to know if one can say which is faster: Invoking the allocator to get X bytes, or setting all X bytes in an array to value Y. Another option would be wrapping the array in an `Option`. I don't know if it will be better, but I believe an option that is `None` Rust will leave the extra memory uninitialized. But with optimization, it's hard to say without testing what will be fastest, or if there is any difference. And overall there are probably too many considerations to give a universal answer for all possible programs.
Your bound only says that you can turn a `Vec&lt;u8&gt;` into a `T`, not that you can turn a `T` into a `Vec&lt;u8&gt;`.
Cool comparison! &amp;#x200B; For me Python "Won", but I know it was a casual/fun competition, not a rigorous benchmark ha!
Great read! Interesting how much difference there was between the two Rust teams. That Python programmer that did the project on her own and beat everyone else in every way must be very skilled.
Trying to imitate the Python inanity of making stupid cutesy names with *py* in them somewhere.
In general I'd say that function is unsuitable for use in library code, based on the note listed on that page: &gt; Note that this function may not catch all panics in Rust. A panic in Rust is not always implemented via unwinding, but can be implemented by aborting the process as well. This function only catches unwinding panics, not those that abort the process. Or at least, you can't rely on it, since the crate using yours may set `panic = "abort"`.
Did I see /u/BurntSushi doing some perf breakdown in one of these disk usage tool threads a while back? I consider 'ripgrep' best in class at what it does. I'd love to know what the other Rust tools are that are best-in-class.
She is incredibly skilled, I went to the same high school and we did programming contests together and I'd often take twice as long to solve the same problem. I'm not sure I'd say her project beats everyone else in every way though, I'm pretty sure she intentionally sacrificed code quality and that you wouldn't be able to understand her code at all.
It sure is weird. But it’s not anymore confusing than try catch exceptions to me. I actually thinks it’s easier to wrap my head around.
I believe pub(self) lets you have visibility to the rest of the current module, I'm not sure if this is what you meant you wanted though
I think what /u/burntsushi is getting at is that filesystem operations on Linux (and possibly other operating systems) can't be done asynchronously. Even if the filesystem is networked and you're literally waiting on network I/O, the only way to get properties of a directory entry (like if it's a symlink, when it was modified...) is to use the `stat` or `lstat` system call on individual files, which will block. I've seen latencies up to 1s when the system is cold. And the only way around this is with a threadpool, which is what `tokio-fs` does. Even though for slow filesystems where you really want asynchronicity, the threads spend most of their time off CPU.
I disagree with this, as a Rust beginner, it's not that hard to learn. Go punts the complexity of your projects to when they're actually large and need to be maintained. It allows you to start up quickly and then you fail late. Rust allows fail early.
Ooooo this looks useful! Thanks!
It's beautiful how it works - I just take issue with them choosing a question mark specifically because of how pervasive it is in other languages, and what it usually means.
Why the heck would you ever write asynchronous code by default? You're creating needless overhead when the data is already available. You don't need asynchronous if your'e not actually waiting for anything.
It doesn't have to "turn out," since it's already possible. The trap that people fall into with Rust is that because it *can* be **extremely** efficient with borrowing by reference, people forget that you can also do things the way normal people do, by using smart pointers and reference counting. The performance penalty for an atomic variable/`Arc` is so negligible that it's likely never going to matter for most programs. If you want to make a rough sketch, just don't think about performance for once. Use iterators. Import `itertool`. Use `Arc`. Go nuts. Then, once everything is settled, you can change your type signatures and use the compiler "screaming" at you as a guided form of refactoring. It's actually part of the reason why I like Rust (and other strongly typed languages like Haskell and Scala).
This. You can use python for years and never realize it is object oriented. You can treat C++ as "C with classes" and ignore 90% of the language specification. With Rust you do need to know most of the language already to do anything nontrivial in it.
It varies. In my experience, C++ can take way longer to compile than Rust if you really go overboard with TMP. With no TMP, Rust usually takes longer.
A lot of comments here are about the ecosystem. With respect to the language itself: * Logically and physically moving a type are conflated, which means `Copy` types cannot be consumed by a function * No implicit `self` in contructors means making immovable types requires `unsafe`, `Pin` and dynamic allocation * Local variable shadowing allows for poor coding practices and increases maintenance overhead * No "const after construction", like the `const` keyword for struct members in C++, makes intent harder to communicate * Type inference makes writing code easy, but reading harder. When reviewing code on any platform without type ascription (eg. Github) it is difficult to chase down exactly what type a variable is * Order of destruction in structs is opposite that of anywhere else. When code is refactored into a struct, the behaviour will change * Rust only cares about memory safety. Huge amounts of code is shared and not under your direct control, other safety like controlling usage of IO, unsafe, and filesystem access would give more confidence in using external libraries and also push libraries to be structured in ways that the user controls permissions. (Monads are *a* way to do this but not *the* way to do this) * It is unclear when a parameter is being taken by ref, const ref, or copy, unless a cast is required. This is a problem in C++ that should have been fixed * Rust has no support for `out` parameters. `MaybeUninit` will help but there is no `std` support for this as functions take `&amp;`. You have to zero initialize a buffer or lie to the compiler * No equivalent to `newtype` in Haskell for type safe aliases. If you want an ergonomic typed integer then you need to write a lot of boilerplate
&gt; Prior to 1.0, any minor change is allowed to be incompatible. This is technically true, but unrelated to the paren't comment's point. &gt; This means you can not upgrade confidently without going through the changelog of the dependencies you want to upgrade. This is only true if you are upgrading to a new minor version. In Rust's interpretation of semver, this is the same as upgrading from 5.0.0 to 6.0.0 or 0.0.5 to 0.0.6; the major-most (leftmost in left-to-right languages) component that is greater than zero is used as the major component for determining compatibility. For example, upgrading libc from 0.2.54 to 0.2.58 is completely safe. Cargo uses this interpretation of semver too; if you ask for version \^0.2.54, you may get 0.2.58 but never 0.3.0.
Seems to not have the same module issues anyways. So that's great. I'll need to bang on it more whenever I have more time, but seems same or better for what I've tried. Would be nice to have it packaged up in market place to increase exposure.
I guess the only thing with "replace with" is that I'm going to either require "clone" or "default", which isn't a huge restriction but one I thought I'd have a go at avoiding.
&gt; The lack of sum types and pattern matching in C++, which we used extensively and were very helpful. `std::variant` does a pretty good job, albeit it's far more verbose than pattern matching, and recursive types are kind of a pain.
Could you give some example use cases for wanting to consume `Copy` types?
It lacks nice IDEs and stable Frameworks. nearly all (but not all) crates are in 0.x.x version on crates.io. &gt; When would you use another language over Rust? I truly believe that rust can replace C but not C++.
This sucks that this is downvoted. OOP in rust is different than in other languages. its more like ECS
Thank you. What confused me was that the documentation mentioned that From implies Into.
Having read this entire thing, and the entire original post that started this all (which I did out of, I don't know, curiosity?) it makes me kind of glad I don't take part in communities that have these discussions at all, cause every side of this sounds a little insane to me. I go to work, work with cool people, some are gay, some aren't, a few are trans, we do work, put up posters for pride month, and go home. I get the point of the discussions, and "dialog is good" and all that, but sheesh -- the original post mentioned "tabs versus spaces" and that's what all this sounds like to me: a fight about whose soapbox is bigger.
It would be great if your crate were easier to use akin to faster. It still feels pretty manual. Any plans to support an iterator-based approach like faster? I feel there's an opening for that now as faster seems to be unmaintained now.
yikes
Okay, this has no place here. Someone didn't listen to you, you pestered them, and then after they still said no you're posting something here? This is not okay. I'm not even going to attempt addressing all the bad-faith arguments in your post, this kind of thing has no place here.
Amethyst, just like Rust, does not value 'freedom of speech' above all else, and we do not believe that freedom of speech is the best core on which to build a healthy community. While I am on the Amethyst team, the rest of this post does not represent the official views of the amethyst project, only my own. This entire situation is a *perfect* example of why freedom of speech is a *god awful* principle to build a healthy community around. Amethyst decided to support a cause that is important to many of its most active team members, contributors, and community members. This support was going to *at worst* make people who do not support LGBT rights feel slightly unwelcome. In this case, good, I hope they did, and I absolutely do not belive it is our duty to make those people feel just as welcome as those who are much more vulnerable and are persecuted on a common basis by pretty much every aspect of society: namely, those who were supported by our supporting Pride month. It is *absolutely* not our duty to let bigots come in and harrass our members with impunity, as allowing this is silent approval from the organization. Taking no action to stop an oppressive action is implicitly siding with the oppressor. If this happened, not only would Amethsyt be doing a wrong thing, but I believe we would lose at least half of our current team members, who would either be on the receiving end of said harassment and likely leave because taking abuse just to work on an open source project is an awful environment, or who would see that happening and not support a project/organization that would idly sit by and let it happen or even encourage it to happen. The attitude that words cannot hurt people is a blatantly privileged one and is just completely wrong and backwards. Words are probably the most powerful thing in the entire world, and they have the power to help and to hurt, both directly and indirectly. Whether you want to accept it or not, humans are not 100% completely rational beings; in fact, our subconscious and emotions are often much more in control than our rational, completely conscious brain. Alright, this is the first time I've responded to this situation and it's the last time I will be responding. If you keep your opinions as they are then I am absolutely glad to not have you in our community; whatever technical knowledge you may bring to the table will not be outweighed by the way that you would make people in our community feel not safe or unwelcome. Goodbye.
Thanks, particularly for the information about terminal colors! For now I have created an issue: [https://github.com/Byron/dua-cli/issues/13](https://github.com/Byron/dua-cli/issues/13) . &amp;#x200B; Besides, the alternate screen I definitely use, see here: [https://github.com/Byron/dua-cli/blob/952624118bf3c293f23064e21828af00df9d132c/src/main.rs#L40](https://github.com/Byron/dua-cli/blob/952624118bf3c293f23064e21828af00df9d132c/src/main.rs#L40) . Sometimes I have seen this happen, maybe it's an issue with stdout not getting flushed when the terminal is dropped? If the issue is spurious, this could be an explanation.
Thanks, for now I have added this remark as a limitation to the README. Filesystems could be compressed, blocksizes could be different, and estimating actual usage is hard enough for me to rather not try even with the fabulous crate suggested here.
Thanks, fixed with v2.0.1. Amazing that I could look at this for a week without noticing :D!
libgit doesn't expose shallow cloning for some reason. This is a limitation of git itself; you can only shallow clone from the CLI. I have no reason why. I guess nobody felt the need to add the option yet.
" The only reason I even bothered to talk to you privately is your \[we\], because there was a slight chance you were an LGBT person struggling with your own issues and were reacting poorly under stress. " wtf so the only reason they offered him a chance is the possibility they were LGBT? That sounds fucked up to me.
Why not release the source? The binary in the repo only works on specific UNIX systems.
Is there a concise way to read a file through bufreader, locate a line with something like "starts_with()", and just delete that line in place?
Done, will be with 2.1.0 .
&gt; I believe that someone like Edward Kmett could write the same compiler in substantially fewer lines of Haskell, in that my friend’s team didn’t use a lot of fancy super advanced abstractions, and weren’t allowed to use fancy combinator libraries like lens. Not allowing folks to use `lens` when writing a compiler feels like doing it with an arm tied behind your back. I hope they at least got to use state monads... I would never want to write a type checker or code generator without state monads... =)
I definitely don't disagree. But it's hard to say exactly what the overall impact is. It certainly makes it harder in Rust than in C++ to write code that compiles, but just compiling code isn't generally one's goal. Debugging segfaults is probably harder than fixing Rust compile errors. And as far as learning and complexity, the craziness you get with undefined behavior is certainly not a small thing to learn if you're entirely unfamiliar with it. Given this, I'm honestly not sure which is easier to learn and then develop useful software in.
True, the implementation is ugly, but it’s still async from the caller’s perspective. You can do work while waiting for operations to complete, or read several files in parallel. Of course, you can also accomplish that by manually spawning threads and using traditional synchronization primitives, so it largely comes down to which style is more ergonomic.
It's a shell script, it is the source.
Needs more examples in src form. Could be a useful building block.
it's getting to be more and more like c++
Cryptography is a somewhat esoteric subject for laypeople, so I don't think it's that surprising. It's no worse than what amounts to mysticism surrounding "AI" for any ML technology.
Their stupid naming conventions for one. Why not just call things what they are instead of "crates" why not a "package" ...
what about performance benchmarks, how long does it take to run all the tests and how much memory do they use? Seems the 2nd rust implementation, not using strings, would be faster?
No they still had to output assembly strings, there was just an extra step with a bunch of allocation in between. I didn’t do performance comparisons and they wouldn’t be very informative since the algorithms are all different.
&gt; they wouldn’t be very informative since the algorithms are all different. That sounds like the interesting part to me, though. We'd get another dimension in which to measure the effects of the differing design decisions.
I think once the hype of "blockchain all the things" dissipates and the reality of verified ledger trust systems comes to be less about get rich quick and more about "best tool for the job," the views on the topics will change. I also find the tech super interesting from an academic perspective. I hope we see more advancements due to it.
I agree, types that implement `Copy` often represent a raw value with no unique ownership, meaning "moving" or "consuming" the value makes no sense.
Precisely. I was sort of disappointed to see that only code size was considered (and it was no surprise that Python was the tersest of them all). I would have liked to see some performance benchmarks as well, especially considering that for real-world compilers, it's not so much the size of the compiler that's important as the performance/size of the *generated* code.
Why does Rust not have reflection? Is it because of the ability to break type safety etc?
I also had an easy time learning rust! However that's largely due to the other languages I used before that introduced me to many of the ideas that Rust has, like C++ for the template syntax and ownership model, and haskell for sum types and typeclasses. Meanwhile, I have seen coworkers struggle to learn Rust. They came from different backgrounds and have to learn all of those concepts. Even worse, since they don't know where those concepts come from, they don't see how Rust improved on them or why they are at all necessary. I'm happy you're having a good time learning Rust, but unfortunately we can't take the experience of one person and assume it'll be the same for everyone else.
&gt; we're probably still several years or editions away from a good dynamic linking/plugin story To be fair, the only language that really has a good dynamic linking story is C, isnt it?
&gt; Prior to 1.0, any minor change is allowed to be incompatible. "Fortunately", most implementations of semver elect to ignore that little bit of the spec, the leftmost non-zero version is used for compatibility. That is to say, `0.1.0` and `0.1.1` are considered as compatible as `1.0.0` and `1.0.1` or `1.1.0`
Presumably because they're not zero-cost.
Python is well known for having a huge standard library and a somewhat ridiculous number of language features, but it doesn't take any time at all to get up and running in Python. Especially for anybody with even minimal prior programming experience. It's not about features. More features does not equal a steeper learning curve.
After some Googling, I've found some Linux syscalls called `AIO` that, from what I can tell, are supposed to provide asynchronous file operations. Does anyone here know about these and can provide more info?
&gt; but it definitely adds complexity. It also removes complexity. A lot of complexity, IMO. The net result being far less complex than C++, in my experience, especially with NLL lifetimes fixing "this is ok because X is never used after Y"-type issues
This is more of a broad annoyance, but the fact that people seem to hold C++ const-generics up as the "standard to live up to", despite the fact that D's implementation of const generics is objectively superior / more advanced in every conceivable way. Daily reminder folks that you literally **cannot directly use floating pointer numbers or any kind of string literal** in C++ const generics, at all. You **can** do this in D. With no issues. It's just a totally normal thing, as it should be.
I'm impressed with just how much the engine provides for the programmer, but nearly all of it can be swapped out if necessary. This is definitely something to keep an eye on. It seems to try to reduce boilerplate as much as absolutely possible.
So that you don't need to repeat it for every crate
Linux certainly has async I/O support in the kernel, but it does not have async filesystem access. The filesystem is not the same as I/O (note that we have `std::fs` _and_ `std::io`). Where the filesystem knows about things like file creation time and symbolic links, I/O just describes reads and writes to a file descriptor, which could refer to a socket instead of a file.
I believe you can read the file a piece at a time until you find what you want, seek the the position in where that section starts and write over it. However of you want to delete the line you're going to have to read in the rest of the file and write it back out without that line. This can be done with a buffered writer in pieces but that's ultimately what you're going to have to do. I may be faster to just read the entire file, fine the line, remove it, and write the entire file back out again assuming you can have enough memory.
Awesome article, interesting read! I'm also a UW cs student taking 240, 241, 251 rn. I was interested in taking 444 eventually, which courses did you take before it which you found helped best prepare you?
That was the original idea but all `transaction` related create names are already reserved. Might play around atomic-ops or something similar, we'll see.
I may have worded that poorly. I meant private members like C++ or Java have. Rust only has "private to module", no "private to type".
There's still the slight problem that since filesystem operations block the calling thread, a set of filesystem operations can be completed faster by spawning way more than one thread per cpu. This property would probably surprise users who encounter `tokio-fs` without already knowing that the Linux filesystem interface is entirely synchronous.
Monads are a lot more general than a nice API for structuring stateful computations in a pure manner. [For example.](http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html?m=1) Among other things, this gives you user-definable generalized optional chaining for free.
Eg: [https://www.schneier.com/blog/archives/2016/12/giving\_up\_on\_pg.html](https://www.schneier.com/blog/archives/2016/12/giving_up_on_pg.html)
`create_instance` already takes `instance: &amp;ash::Instance`, so you don't need to pass a reference again. `khr::XlibSurface::new(&amp;entry, instance)` should work.
&gt; it's a book, not a language reference This is a good point; I probably shouldn't be so harsh in light of this. I think the Reference isn't as looked-after as the Book unfortunately, unless something has changed recently.
Scala is eagerly evaluated, but the monad is still ubiquitous.
Python isn’t that terse when you get down to it: it’s a primarily OOP, imperative language that borrowed list comprehensions from the functional folks. From what I’ve seen, particularly with folks using type hints, it’s about as verbose as Kotlin. As an example, pattern matching and destructuring in Rust translates into a massive if-elif-else chain with mutable assignments in Python. I think the programmer in question is just particularly adept at writing code, though perhaps only code that machines can read.
Great article, and really interesting to see the variation across several languages. The Python size difference isn’t that surprising, considering the complete disposal of type safety and the expressivity — if not comprehensibility — gains of metaprogramming. That said I am really curious about just how egregious the abandonment of code quality is. In Python it’s _painfully_ easy to write _terrible_ quality code that is entirely unmaintainable but nevertheless works perfectly and passes all the tests. I wonder how far removed form “Pythonic” it is, and just how much longer it would be if written to a sensible standard of quality. I’d be curious to know what score it gets when `pylint` is run on it (after `black` cleans up the trivial issues).
That's a well known caveat and would be listed in docs, which I assume, are made for reading, I suppose.
Probably better for TUI apps than CLI apps.
This is actually how most of the file operations work. E.g. see the `OpenFuture` [source code][1]. They use a `blocking_io` function, which is just a wrapper around `tokio_threadpool::blocking`. [1]: https://docs.rs/tokio-fs/0.1.6/src/tokio_fs/file/open.rs.html#25-38
Why would you compare the performance between rust and python? What do you stand to learn by doing that here?
An interesting case where you might want to reach for async in a “CLI” program is cancellation. If you do a blocking read call, the only way to interrupt it is by sending a signal. I wish there were an API for cancelling blocking calls!
For me: - Futures errors are crazy - Higher types stuff is missing - Importing macros is confusing - RLS is buggy - Compile times very long for big projects
Fully agree. Also, using a parser combinator instead of a parser generator might have drastically reduced code size as well.
&gt; If, like me, you understand that the only acceptable way to install software is from your OS's package repository and the only OS with acceptable stability guarantees is Debian Stable, you're trying to build stuff with rustc 1.24 Is this just personal preference? Or is there something else driving this requirement? Compilers that old aren't supported by upstream, so for example, you won't necessarily get security patches unless you upgrade your Rust compiler version.
Which is leaps and bounds better than first class support for monads and all the inscrutable library APIs that come with it.
Again provide some link other than "its considered to be this" and who on Earth is upvoting these plainly incorrect comments? From the literal semver website: &gt; Given a version number MAJOR.MINOR.PATCH, increment the: &gt; MAJOR version when you make incompatible API changes, &gt; MINOR version when you add functionality in a backwards-compatible manner, and &gt; PATCH version when you make backwards-compatible bug fixes. Can you pretty please with a cherry on top provide evidence of why I am wrong and you are right?
The stretch (flexbox) UI looks super interesting! Could be a very useful standalone crate for other engines as well.
Unfortunately std::variant still compiles to something much slower to dynamic subtyping even if all variants are noexcept because compilers do not optimize it as much as they might yet. Also, before C++18 that introduced lambdas with template parameters, pattern matching on it is an absolute pain for sure.
Interesting &amp; cheap approach. Just hide each rust file ones from the compiler and see if the \`cargo check\` say the project is OK :D
I was already using a Makefile, mostly so I don't have to remember all `cargo` commands I use. An example can be found [here](https://gitlab.com/inko-lang/inko/blob/23f2e7fb77318a38779cbd49bb48b75a357cc214/vm/Makefile).
My understanding was that AIO was separate from epoll and was a Linux specific interface that didn't have bindings in glib.
To me that makes her sound like an even better programmer. She thought about the trade offs and chose the way that was best for this particular set of requirements.
I was addressing the "verbose" comment. Being explicit is a different point that I didn't supply examples of.
What's your proposed syntax?
Why can't is_empty be inferred from len (like Python does) ?
AFAIK AIO is still just file/stream operations, not file*system* operations.
In serious C++ projects you need to compile, run your tests, then run them with valgrind (which degrades performance), then launch sanitizers (I counted 8 in GCC, which can't be run together). All of that takes time and it still doesn't guarantee you caught all memory and thread bugs because of insufficient coverage. You can still ship a broken binary , people do that all the time and then have to deal with crashes from the field. In Rust, you just need to compile, run your tests - and you're done. The compiler catches all memory and thread safety issues at much earlier stage and helps you dodge the bullet in production. You can't ship something that doesn't compile.
LLVM should have 100% tail recursion figured out (at least with release)
Thank you! I have definitely struggled with some of the described issues and decided not to use GPG for communications. I also have no friends and acquaintances who would bother with a proper set up, so there's that. I would ask you to refrain from a "GPG is bad and no one should use it" phrasing, because people will scoff it off, instead of thinking of it's real problems, like here in this thread.
I think it generally depends on how you tell if you want `A` or `B`? If you know by the time `deserialize` is called, you should be able to just call `A::deserialize(deserializer)` or `B::deserialize(deserializer)`. If you want to try both, I think the only way is to first deserialize into some value-type (like `serde_json::Value`, or a custom-built one) which can handle both values, then to use that value type as a reusable deserializer for the two types. This is how `#[serde(untagged)]` on enums works (it uses a private value type supporting almost all kinds of data). The reason this is required is that serde's deserializer interface doesn't really include "retracing" things. It allows code to be much more efficient (deserializers don't need to keep much state, and can be close to pure streaming), but at the cost of making it more difficult to retry things / deserialize into multiple values.
Yikes, I was not nearly this good in my fourth year O.O
I typed it in my console but copy-pasted the result to reddit :) A br would break my command line that I would see, if I understand you correctly. &gt; I meant operating system account, you can make more than one on MacOS. That would help pinpoint your issue, since if it works then it's either your installation or your user settings. I see but I did install rust as "sudo". Is it really possible to break the cargo functionality that way via some hidden user settings that would be totally unrelated as I haven't used it ever before.
&gt; echo $CARGO_FLAGS Empty response to that.
The last price for CA Inc. (Nasdaq: CA) was **$44.44** (as of 05:12 AM EST on Jun 16, 2019) The 52 week high is **$44.49** and 52 week low is **$31.97** Price action (weekly and monthly): **Weekly:** CA made a weekly high of **$44.47** and a low of **$44.02** (for the week ending on Jun 14, 2019) **Monthly:** CA made a monthly high of **$44.40** and a low of **$41.04** (for the month of May 2019) ^^I ^^am ^^a ^^new ^^bot ^^and ^^I'm ^^still ^^improving, ^^you ^^can ^^provide ^^feedback ^^by ^^DMing ^^me ^^your ^^suggestions!
It is to add a dimension to the test. Because as it stands the only compared factor really is code size (and correctness to some degree). If you write a program your requirement is rarely "use as few lines as possible".
rustasync/runtime: [Integration with GUI event loop #21](1https://github.com/rustasync/runtime/issues/21) gtk-rs/examples: GIO using await syntax https://github.com/gtk-rs/examples/blob/pending/src/bin/gio_futures_await.rs
rustasync/runtime: [Integration with GUI event loop #21](https://github.com/rustasync/runtime/issues/21) gtk-rs/examples: [GIO using await syntax](https://github.com/gtk-rs/examples/blob/pending/src/bin/gio_futures_await.rs)
Yeah, CLion plus the Rust plugin is shockingly good. Like, better than IntelliJ with Java in some respects — it ships with a perfectly solid perf integration that produces flame graphs! It’s very impressive, and my daily driver as well.
Yes but that is not maintainable in the long run. Hacks are useful for quick fixes but your overall program ought to be reasonable and based on some type system and transformations along with a safe execution context. I am all for hacks when it is not the main Target of your program but eventually one has to revisit them.
How so?
Using actix (0.7.10) how would I write a type like: Vec&lt;Box&lt;Addr&lt;dyn Handler&lt;MessageType&gt;&gt;&gt;&gt; That gives the error: `the value of the associated types Context (from the trait ...::actix::Actor), Result (from the trait ...::actix::Handler) must be specified`
Okay but let me say first that I don’t want to blame the language team or start any flame war. I will make a few examples but it’s just my personal opinion. I also know that things are getting better, and I like rust anyway. And sorry about my English, it’s kind of hard to explain for me. &amp;#x200B; So my first example would be Strings. Strings are such an important data type that you need very often. But anyway a static string is the default, so you always need to write "foo".to\_string() or format!("foo"). This leads to what I would call visual noise. Why not to make "foo" a normal String and &amp;"foo" a static string reference? This would make the code much cleaner in my opinion. &amp;#x200B; My next example would be lifetimes. I saw already a lot of people asking why do we need to repeat them when implementing a trait? Me included. I think it should not be needed to bring them into the scope first. impl&lt;'a, 'b&gt; Foo&lt;'a, 'b&gt; … or impl Foo&lt;'a, 'b&gt; has the same amount of information. I think that the compiler should infer that 'a and 'b needs to be in the scope first. This would also reduce the visual noise. &amp;#x200B; There is more to lifetimes, where I think that the compiler should infer them and only force me to write them out when it is really necessary or when I need to specify an edge case. And if it's ambiguous, then just guess it for god sake. 90% of the time it would be correct anyway. &amp;#x200B; My last example would be trait bounds that you need to repeat again and again. But I know there is a solution on the horizon. &amp;#x200B; I do find that such things make rust very verbose. And in-between you have the ?-operator, implicit returns and the new await syntax that are hard to spot. And for people with dyslexia like me it is hard to read. That it.
Can one see the code somewhere? Not only python, but the other ones as well if available.
Thanks! And yes, it should be feasible. The \`ui::core\` and \`ui::widget\` modules aren't relying on Coffee much. The hardest part would be decoupling the different input events.
Thank you! &amp;#x200B; \&gt; It seems to try to reduce boilerplate as much as absolutely possible. &amp;#x200B; Simplicity is one of the main goals of the engine. I always try to make the APIs deal with familar concepts for the users of the engine. I think the fact that I am also quite a beginner in gamedev helps. The lack of boilerplate might be a side-effect of that!
Thanks for the explanation. I think that some of those still fall under "explicit" vs. "verbose", but that's a matter of opinion and I appreciate you sharing yours. I also have dyslexia and it's interesting to learn how it affects people differently.
Agree completely. But in this case it sounds like it was an actual throwaway project. For something that has even a slight chance of turning into a permanent solution a minimum of maintainability is important,
This happens in a workspace
1.0 isn’t a stability guarantee. I’ve seen many crates releasing 1.0, and a 2.0 version the same day.
This is incorrect. Upgrading from 0.1.0 to 0.1.1 is a backwards incompatible change.
Jesus, what a dick you are. Dude literally says that he's not the most skilled at this stuff and you decide do put him down? Wow.
What if you wrap the Item in a Box&lt;T&gt;. Also, in rust the equivalent of void is the unit type - ().
Shamelessly stolen from [Dowwie on HN](https://news.ycombinator.com/item?id=20104631) &gt; The architecture of actix-web 1.0 is very different from that of 0.7. In many respects, it was a rewrite that began last Summer. The architecture is no longer based on an actor paradigm but rather one of Services, largely inspired by [Eriksen et al's finagle work](https://monkey.org/~marius/funsrv.pdf) adopted at Twitter. This service architecture is accessible through a library known as actix-net. Essentially, actix-web is a web-based actix-net server. If actix-web were bitcoin, actix-net would be its blockchain. Because of this, actix-net may be even more significant to the broader Rust community. The actor models can still be imported and used but no longer act as the default mechanisms driving the server.
i would like to make it work with iterators, though im not entirely sure how. if anyone wants to collaborate on it let me know
The thing about temporary solutions is that they will turn into permanent solutions. Unmaintainable code is shit code, always.
Please note that `libgit2` is not built within the `git` project, despite the name. I know that GH hates shallow clones, especially for package registries such as ours, they had asked cocoapods to move from shallow clones to full clones at some point. The reasons, as far as I understood, were: * worse caching * a high chance that deltas for any already cloned registry are smaller than a shallow clone The other option would be having a resolver API like bundler has it, avoiding cloning the registry, but also harming offline use.
Great Post! Youl could improve your site by https
It has! There were two contributors who really started taking care of it last year. They’ve stopped, but the lang tram intends to step up this year too. It’s already started to happen a bit.
Async is usually mostly important to keep things responsive for interactive usage. A CLI app is usually just invoke and forget, no interactivity. Blocking on file access or whatever is mostly fine, unless it's a bottleneck for performance. A TUI app is, by definition, interactive, so you don't want to block on operations because you have to stay responsive to user input.
In the pre-1.0 days, \`greppability\` was a word you heard thrown around in discussions a lot.
U. Waterloo CS seems to produce hugely competent graduates. The person would have been the best student in my uni cohort by a country mile, and he is ostensibly not even exceptional amongst his U. Waterloo peers. Everyone in his team had interned at Jane Street 😳
The official book is pretty good. I've seen recommendations to read it as well as the O' Reilly book, but it is completely fine as a standalone starting point.
The O'Reilly book is very likely completely out of date, since the language is evolving so quickly right now. The official one is quite good, I even used it for my Rust course, because I saw no point in writing my own guide when I read through it.
Just a heads up in case you don't know about it, but \`cloc\` is made specifically to count lines of code (hence the name). It filters out stuff like comments and empty lines automatically and makes for a slightly better metric than \`wc -l\`.
Is there any speed advantage over ncdu on slow laptop HDD (not SSD)?
Beautiful
Both are varying degrees of old; programming Rust is 1.17, the book is 1.21. That said, backwards compatibility means that neither are *incorrect*, you just may not hear about new features. The 2018 edition changes are the big one that both are missing.
&gt; I know that GH hates shallow clones It was slightly more nuanced than that, with a mix of misuse &amp; edge cases: https://github.com/CocoaPods/CocoaPods/issues/4989#issuecomment-193772935 &gt; most of the initial clones are shallow, meaning that not the whole history is fetched, but just the top commit. But then subsequent fetches don't use the --depth=1 option. Ironically, this practice can be much more expensive than full fetches/clones, especially over the long term. -- &gt; Moreover, you seem to be hitting an edge case in Git's shallow fetch support, which is causing a significant fraction of your users' fetches to consume disproportionate CPU time (i.e., 100+ seconds each) on our servers. When this happens, the shallow clones are being converted into nearly-full clones, in a way that is much more expensive than doing a full clone from the start. And the last bit was a repository layout issue: &gt; Finally, the layout of the repo itself doesn't help. Specifically, the Specs directory, which contains 16k+ subdirectories, causes some Git operations to be unexpectedly expensive, further driving up CPU usage. Though of course: &gt; We think Git's handling of shallow clones can be improved, but this might take a while. If the Git client needs to be changed, it wouldn't help until the new client is in the hands of the majority of your users.
Thank you very much Author, I feel honored to get a response from you and I love your work. I will file a bug immediately for you sir, thank you.
Thanks so much, on all accounts!
Small correction, unit type is just zero sized. Void (and unstable never) type is uninhabitable, meaning you can't create instance of it.
You are probably looking for /r/playrust
Python gets a lot of its "terseness" from how it dispenses with ceremony (as all dynamic languages do), from how easy it is to manipulate standard collections, and from the batteries included philosophy. You can get a lot of mileage out of that in the right applications and with the right coding style. Of course, you don't always have the right application nor can afford that coding style, but for one-person projects you often can get pretty far with that. Otherwise, if you structure your Python code like you would Java then all Python gives you is freedom from curly braces.
Or tokei, which is a great rust lines of code programme
Complexity Some Rust codes are really dense and hard to understand sometimes. I see this like a price you have to pay for the safety, power and performance that Rust promises you (a trade-off). Usually this makes it hard for the developer to focus on business problems. At a more critical level, if you don't care about it and plant a lot of clever and complex gotchas all around your code, you can easily end up with a project really hard to maintain and reason about. I also can't use Rust at work (a Java oriented organization) because of it. if your project doesn't have really strong requirements for security and performance, the complexity constraint just doesn't fit the productivity that organizations demands. The cost to write new software and to port it to other teams and also the cost for them to understand it need to be minimal to fit the release schedule. I can't convince my organization and my team mates to take a long learning curve and write complex software if their project is totally ok with a garbage collector for performance.
Phrases like "optional chaining" are a lazy and superficial way to refer to what you actually want, which is a sane way to compose together behaviors. The short-circuiting that you get from optional is only one such example.
What terminal are you using ? Is that a wm terminal ?
Most of your reasoning is defeasible: &gt; No convenient way to split modules across several files. Have you tried `include!("file.rs")`? &gt; No way to restrict visibility within the same module, [...] This encourages even more submodules. But in Rust, nested modules is the orthogonal concept to restrict visibility. You don't need to introduce additional concepts like `friend` from C++. &gt; The borrow checker often severely limits what you can do. Because the deep darkness outside of what the borrow checker allows leads in all but simple cases to an extreme complexity. Try `Rc` and `RefCell` to get around `unsafe`. Or use integers instead of pointers. If stuff inside a hot loop is not fast enough, use `unsafe` or assembler code called from the `extern "C"` ABI. Some kind of theorem prover (advanced type system) is needed to solve these kind of issues, which turn out to be difficult problems. An algorithm that cannot be validated even with a theorem verifier must contain some very deep odd complexity. With such smartness a life on the edge is mastered. &gt; No standardized constructors. Because not every type has a canonical constructor. A type may have two or more different constructors. Therefore a constructor should be nothing more than an ordinary function. &gt; So many obscure yet essential traits, [...] Because traits are essential for specifying abstract interfaces, they sharpen thought and lead to tidier code. &gt; The ability to redefine local variable bindings goes against the Rust philosophy of safety and correctness. That might be true to some extend, but I appreciate that for ergonomics. See a `let` statement as the introduction of a new block with local variables which shadow the outer block. One could tackle this sloppiness with a pedantic clippy lint, which is satisfying enough to me. &gt; Imho Rust is too strict about global static objects and static initialization. This was designed with concurrency in mind. Besides that, global objects lead to implicitness and thus to inscrutability. But sometimes you absolutely want to have them, for example a global pointer to some runtime environment. There is some effort to enable safe usage of global variables, see `lazy_static` and `thread_local`. &gt; Many of the macros (`print!`, `vec!`, `panic!` etc) and attributes (mainly derive) seem like lazy adhoc solutions to problems that should have proper language or standard library features. Syntax tree transformations are far easier to understand than interactions with the type system. Implementation of `vec` is theoretically easy, as only a variadic function is needed. But how would you achieve an implementation of `print`? It would have been (and is) possible to state a trait `Print`, then a variadic function could take arguments of type `dyn Print`. But then you lose compile time optimized formatting. The formatting macros a safe, easy to use and look more pleasent than old C's `printf`, that's most important to me.
Sorry, but despite the discussion in the article, lines of code is still a pretty rubbish metric, in absence of any other information. &gt;the amount of code provides a decent approximation of how much effort each project took, and how much there would be to maintain if it was a longer term project Really? Maybe if there was a massive difference in lines. But vastly more important for maintenance is the expressiveness of the code, general code quality, and amount and style of tests. And as for time taken - it often takes more time to write less lines of quality code!
Personally I love how productive I am in Python, there is absolutely no comparison to any other language. But when you need to really crunch a good amount of data its lack of speed at runtime becomes an annoyance very quickly, even during development.
I if wanted to build a server for a multiplayer game where the server controls the game state and clients connect to it over TCP, would I then be looking for `actix`, `actix-net` or something else?
Sorry, that came out overly negative - it was still a really interesting experiment overall!
Could you give some idea how much slower the Python implementation was compared to the others? I'd expect it to be a different ballpark from the others, like at least 5-10x slower.
In a nutshell, because it's just this massive curiosity driven, change by RFC cesspool that is still somewhat young and still in flux, the ecosystem is allover the place in terms of design decisions, shit get's deprecated left and right, and like for weirder stuff there are a lot of crates out there very few are actively maintained. Another issue that really pisses me off is that like when I do more involved library programming where stack overflow isn't going to cut it, I usually code search on github for something similar to the relevant component, or look for more involved usage of a certain dependency, and sort of go from there, i whenever I do that in rust I see a clone of these giant monorepo archives. &amp;#x200B; The other problem is just little engineering decisions, the way the module system works initially made me waste a lot of time thinking of what to name something. &amp;#x200B; As for the async story, it's not that bad unless you want to implement a more complicated protocol from scratch, or are overly generic (say you want to abstract over transports + connector logic, executors), when you do that like you basically have to waste a shit load of time going through internals, another thing is that some futures or streams have odd behavior that will shoot up errors i.e using future Result more than once won't work, at a certain point it just made me say fuck it and I implemented a bunch of utility functions on top of futures, like Ivars so I don't have to go through the boiler plate of custom futures all the time. The Trait system tends to be abused by a lot of people, so you wind up in recursive typeclass and where clause hell, like you need to book mark that shit. Honestly for me a lot of these issues with Rust stemmed from trying to library program while assuming just because the ecosystem is big, doesn't mean I don't have to reinvent the wheel a bit. The ownership system isn't all that restrictive, the only times where I have problems is when I'm dealing with odd lifetime restrictions or the API of something I'm using forces me to do some weird voodoo. These issues are from using it for fancy library programming, rather than just writing more straight forward stuff where I can generally just macros or helper functions to get around the boiler plate, and it's generally pretty pleasant, fast, and easy to test.
Yes but you're basically, "Yeah but what if the requirements weren't there real requirements!?" This was a class. The requirements were, in fact, clear and explicit and did not include maintenance. She made the right choice and basically every single metric OP considered agrees.
Waterloo is world renowned. Google has an office there basically just to retain Waterloo grads.
Agreed although in this case I think it was obviously the way to go. She worked alone and knew she would be writing everything. She knew the project want going to last more than a few months. She knew all of the requirements entirely and in advance. She knew python very well. She knew that she would not have to explain anything to anyone else or deal with interfacing with coffee other people had written. You cannot find a better example of "retreat to your cave and come back in 8 weeks with a proof of concept." She even implemented more features than everyone else. Would she still be able to maintain that velocity and correctness after two years? No one cares, that's not why the code was written.
Maybe try to find a mirror for the index? Not sure if there are any though.
I without really like to see you try it in Go and compare to your classmates. Specifically to hear about the conspicuous lack of any good types and many language features and whether that made any material difference.
Oh you're right, I somehow remembered that the default was private to type
The python person seemed pretty skilled at meta programming. Some of the visitor stuff seems like it's be pretty suitable for rust macro implementations - were those considered? And if so, why was it ruled out? (e.g. implemwntations weren't uniform enough, team familiarity, compile tine impact, etc.)
You are looking for r/playrust. Although you are welcome to stay here and speak of the Rust programming language.
I think Python is pretty good for small projects; I wouldn't want to do large scale projects (both in size and time) in a dynamic language though. Navigation is much easier with static typing.
/r/playrust
You might be able to to take inspiration from faster or rayon for the automatic SIMD based on iterator.
My understanding is that the SemVer spec doesn't guarantee anything, but that most projects in practice treat pre-1.0 patch bumps as equivalent to post-1.0 minor bumps. There might be an ongoing project to expand the standard around that idea, but I forget.
I was wondering whether there is a nice way to write something that, in Lisp, I would write with `cond`? In the case of several conditions that may not be mutually exclusive, I don't really know what to write and sometimes I wish for a `match`\-like `cond`, but perhaps something like that already exists or there might be another way of writing it that would be more pleasant. To illustrate what I mean: if p1() { do_something() } else { if p2() { do_something_else() } else { if p3() { do_something_else_else() } } } (Where the `pn` are predicates of which several may return `true` at the same moment) The above does not look pleasant, but (because the predicates may not be mutually exclusive) the below is impossible - I only want to execute a single `do_*`: if p1() { do_something() } if p2() { do_something_else } if p3() { do_something_else_else } And because the predicates might not test the same thing, I could not write it as a `match` . This makes me want to write it as a `cond`: cond { p1() =&gt; do_something(), p2() =&gt; do_something_else(), p3() =&gt; do_something_else_else(), } But perhaps I'm too used to Lisp-like languages to see another elegant way of writing this.
for prompts
Almost forgot: you also have hardlinks to take into account. Rust builds use these quite a bit: -% du -hd0 # actual usage 115M . -% du -Ahd0 # apparent usage 209M . -% dua | tail -1 267.12 MB total This means keeping track of inode numbers for files with link counts &gt; 1 and keeping track of them until you've seen them all so you don't count them more than once.
coming from elixir, to me the biggest downside is the lack of a good REPL
I think one of the killer use cases for Rust will be WebAssembly, which I expect to get very popular and important, and Rust right now is arguably the language with best support for that.
Ah, yeah, I forgot to mention that I wanted to decide to decode either `A` or `B` based on some value in the JSON. That makes a lot of sense! I assumed that deserializing consumes the deserializer because storing the state is needlessly expensive if you're not going to use it – I just didn't know how `#[serde(untagged)]` was implemented. Thanks a lot!
As someone who hasn't done any GUI programming before, is this just for game UIs or for any UIs (competing with Azul)?
&gt;Here we are declaring another lifetime ‘a that allows us to state that the child bar will last at least as long as the structure that holds it. Is this correct? I thought it was saying that the struct lives at least as long as the child. If it really means that the child lives at least as long as the struct, then that means the struct could be dropped while the child isn't? Wouldn't that be a dangling reference?
Never apologize for who you are u/ranty_mc_rant_face
It's not feature complete (yet?), and it works out of the box (when it does).
Didn’t imply that it was, I’m just curious how much different the size metrics would be if the code quality was at the same bar as the competing implementations. Or conversely how much smaller the other languages could get if you similarly abandoned good practice. Apples to apples, as it were.
I decided to build some command line tools for my work with Rust instead of C++, skimmed [https://rust-lang-nursery.github.io/cli-wg/](https://rust-lang-nursery.github.io/cli-wg/) as well as the Rust book, [https://doc.rust-lang.org/book/](https://doc.rust-lang.org/book/), working well for me. The O'Reilly book looks quite good, skimming it on Safari right now and it looks like it's definitely worth going over. Overall, looks like they cover pretty similar material? I would just go with the free book personally but no harm in using both.
Rust allows `else if`, without the extra layer of braces, so your first example can be written as if p1() { do_something() } else if p2() { do_something_else() } else if p3() { do_something_else_else() } avoiding the deep nesting. Less idiomatically, you can write an ad-hoc `cond` using `match` and guard expressions: match () { _ if p1() =&gt; do_something(), _ if p2() =&gt; do_something_else(), _ if p3() =&gt; do_something_else_else(), _ =&gt; () // No predicate matched }
While the slides are compelling, I don't think rust `libstd` is very practical (yes `no_std` is still a good alternative) for os level development. `libstd` assumes thread local storage (TLS) is supported, and TLS is provided by system libc (such as `glibc`, not `libc` crate)'s threading library. So there is no standard how TLS is implemented; this pretty much make `libstd` a non-starter (for os level code). Unfortunately `no_std` provides much less features (less crates, etc..), the benefits over C/C++ as a low level system programming language becomes deminished.
Thanks for that cli link. Did you go about the book and the cli resource in a particular order or read both simultaneously?
It would be super interesting to compare the compile times of all the implementations
I agree, especially less lines of code don't mean you're more productive if you wrote 20 lines in Java in 5 minutes but contemplated over that smart haskell one-liner for half an hour ;).
ive looked at fasters code but didn’t understand it. i may try again. there are some things that are fundamentally problematic though, like say you have a shuffle instruction and then just 2 elements left at the end of your array, what to do? any default choice will be wrong for some people.
I'm usually pretty chaotic when I learn something new, jumping around, copying code from examples and playing with it, putting it down and then picking it up later. I've never really been successful at just sitting down and reading through a programming book, unless it's like the CLI book where it's really short and just gives you a basic program at the end. So yeah, basically that's what I did, I copied the CLI book to get a template program, then cut out the stuff I didn't need. I would open up the Rust book to understand the more complicated topics like ownership and how generics work in Rust.
Precisely. Though, most of the sanity-providing FP features don't end up meaning much to Scala since it is chained to Java and its billion-dollar mistake.
What do you think is a problem for which a blockchain is the best solution? I've yet to find one besides transactions that can (with a fair bit of effort) escape law enforcement scrutiny.
I followed the same approach as yours while learning Golang and it worked out pretty well for me but Rust has been giving me a hard time.. I have already given up on it once before so I was thinking about sitting through a book this time. Well anyway thanks so much for your detailed answers.
Everyone seems to go too much into details. So I will try to put it short: Rust is just harder to write a general enterprise/web app then in GCed languages. What can be improved? Aside of features already in development - not much. It a conscious choice to go a level lower for performance reasons and one should take the consequences. Now if you compare it to C++, it must be or should eventually become just better. I want to believe it but I'm not C expert.
Are you sure they can't make a special exception in this case? Otherwise I think your only option would be reading /dev/urandom, but that can be tricky to bring it down to a certain range, say you want numbers between 0 and 5.
You could hash some constant - `DefaultHasher` should be seeded based on the system clock. Alternatively, just hash the system clock.
Yes, this is what I mean.
Those look quite nice, thank you very much! I see how the second one is less idiomatic, I'll keep it for when the clarity lost through the `match ()` and `_ if pn()` is compensated by the clarity won through the nice outlining of the conditions
Yeah, I also thought about something like taking system time modulo some number, but there is another problem: the they have only rust 1.2 available! std::time was introduced in 1.3 and DefaultHasher in 1.13. Sigh... Guess I need to continue sending them angry letters
There's `std::hash::SipHasher` or something like that in the older versions.
Oh, that looks interesting
What commands are you running, in which directory, and what is the output you are receiving?
&gt;Thank you for your work on this project and for this essay! You inspired me to actively show public support in one of the communities I run even though I knew that it would unfortunately be a bit controversial. Thank you for posting this; it makes me personally, and I suspect a lot of others, feel a bit better about the world. PM if you need/want to talk about dealing with the responses you may be getting or the feelings they may be causing. The backlash can be extreme and it is important to take care of your own emotional state.
It apparently can have a (pretty small) performance improvement as well: [https://gitlab.redox-os.org/redox-os/ion/merge\_requests/278](https://gitlab.redox-os.org/redox-os/ion/merge_requests/278) Some newer/embedded/more obscure targets may not have unwinding support, so Rust might be stuck with panics.
&gt;should be seeded based on the system clock No, `std` [uses](https://github.com/rust-lang/rust/blob/master/src/libstd/sys/unix/rand.rs) system randomness source.
I stand corrected. That submodule should be public, too, unless I'm missing something.
Doesn't this work? fn foo&lt;'a: 'c, 'b: 'c, 'c&gt;(xs: &amp;'a [u8], ys: &amp;'b [u8]) -&gt; impl Iterator&lt;Item=(u8,u8)&gt; + 'c { xs.iter().cloned().zip(ys.iter().cloned()) }
To add to all the other stuff mentioned, Rust is probably not outstandingly designed for IDE support and this goes together with code bases being harder to understand. Some of that are necessary tradeoffs, some are not. I remember this video https://www.youtube.com/watch?v=lubc8udiP_8 IIRC some poster claimed that Rust does quite poor. Some more syntax nitpicks: fn main() { let x = "Annoying to read and it probably makes independent tools harder to build."; let x = 41; let x = addone(x); println!("{}", x); } fn addone(x: i32) -&gt; i32 { // This might be cool for a terse query/command language, but not for Rust. x + 1 }
You could reimplement [PCG](http://www.pcg-random.org/download.html) PRNG. It's very small, and quite fast. It's also used by default in rand crate for SmallRng.
It's the built-in VS Code terminal, using fish and oh-my-fish :) Can't say I recommend it (fish is POSIX incompatible), but it works for me most of the time.
IMHO, any GUI library must start with a text rendering. You using rusttype, which is meh... You should at least use HarfBuzz.
chew
Just curious: are coordinates of entities and vertices and such stored in 32 bit floating point? How large of a game world does it allow without having precision related issues? If it's 32 bit floats, is it easy to switch necessary parts to 64 bits if a bigger game world requires it? Or does the engine come with some sort of world origin rebasing system that re-centers the world around the player camera so that the range of the world can be greater?
It is not clear from description how "rust object notation " and rust compiler cooperates? Is layout, widget description checked during compilation or in runtime?
We considered a procedural macro for our visitor pattern, but Rust procedural macros are a way bigger pain than Python metaprogramming. In Python you just loop over the attributes at runtime and call things. In Rust you need to use a library to parse a token stream and emit a token stream that contains code to recurse on all the attributes. I figured it would take me longer to figure out the procedural macro than the hour or two it took to write the repetitive 500 lines of Visitor boilerplate.
My first useful Rust project. I'd love feedback :)
I am doing the official rust tutorials. Why does this produce an error the second type I type in a number: let mut guess = String::new(); loop { io::stdin().read_line(&amp;mut guess) .expect("Failed to read line"); let guess: u32 = guess.trim().parse() .expect("Please type a number!"); } The let mut guess = String::new(); is supposed to go inside the loop. Then everything works fine.
If you have some code that uses, for example, reqwest in synchronous mode and try to wrap it in blocking, you'll find that it [doesn't work](https://github.com/seanmonstar/reqwest/issues/541). Futures are not composable. Secondly, look at the silly amount of boilerplate to actually necessary to use `blocking`: `spawn` `lazy` `poll_fn` `blocking`. Some of them need `move`, and then there'll be more work figuring out which if your objects need to be in an `Arc` to get it working.
Could someone help me understand why these two things that I understand as idiomatically the same the rust compiler sees as different? I have a struct called PassageController, and it has two methods we care about, retrieve_passage and set_action, both of which take a mutable reference to self. For these two snippets, the first would be more elegant, but rust sees the first one as invalid (cannot borrow `passage_controller` as mutable more than once at a time: first mutable borrow occurs here), but the second one does the same thing. What's the difference? // Invalid, borrowing twice passage_controller.set_action( game::play_game( passage_controller.retrieve_passage(), stats, debug_enabled ) ); vs. // Valid, but does the same thing let action = game::play_game( passage_controller.retrieve_passage(), stats, debug_enabled ); passage_controller.set_action(action);
Interesting. I have the same setup in my code. On one of my terminals it wasn't getting flushed. I haven't had the same issue with my code. Perhaps you're doing more with stdout than I am? Will take a look later.
Depends on your learning style. *Programming Rust* teaches more from a systems programming perspective I believe. On the other hand, while the official book teaches systems programming concepts (as Rust is a systems programming language after all), it's approach is more "neutral" and beginner-friendly in my opinion.
You contradicted me without contradicting me. I'm *sure* await will make futures *less* painful, but I don't think it'll fix a number of fundamental usability issues. One of which I've touched on [elsewhere in this thiread](https://old.reddit.com/r/rust/comments/c0xwjd/all_i_hear_about_is_how_great_rust_is_what_isnt/erc4oko/), sometimes I just want to opt out of futures entirely and use threads (maybe because my workload is so IO heavy that spawning a thread from the get-go is more efficient), but once you let futures into your program, they get everywhere and you just start getting weird bugs.
How does this compare to druid ?
AFAIK it's private and not exposed anywhere. But where is proposal to do it eventually, see: https://github.com/rust-random/getrandom/issues/21
wow, this is great!
As of now, you can only use it with Coffee. As a game engine it focuses on game features, but you could use it to build another kind of application. Also, the UI runtime is decoupled enough that it could be split into its own crate and used in different engines/frameworks to build different kinds of applications. I will probably work on splitting it soon. I will probably call it `iced`. That said, the runtime is quite simple right now and it's missing many features and optimizations. It would probably need to mature quite a bit before actually being usable to build the UIs you probably have in mind. If anyone is interested in contributing, don't hesitate to contact me!
(someone correct me if I'm wrong) but \[I believe you can target either depending on what you want using the Float type\]( [https://docs.amethyst.rs/stable/amethyst\_core/struct.Float.html](https://docs.amethyst.rs/stable/amethyst_core/struct.Float.html) ).
Xorshift is trivial to write, even libcore does this: https://github.com/rust-lang/rust/blob/37b6a5e5e82497caf5353d9d856e4eb5d14cbe06/src/libcore/slice/sort.rs#L488
Yeah but I would totally use a parser generator if I had to do my compilers course all over again. The code-size generated by it isn't important when the generator can automatically tell you about shift/reduce + reduce/reduce conflicts and whatnot. And besides, when using [`bnfc`](http://bnfc.digitalgrammars.com/) you can also get out an AST that is a *functor* which allows you to bake type information from inference directly into it.
&gt; As of now, you can only use it with Coffee I can only use Coffee with Coffee?
&gt; `position_from_screen` You have no idea how excited this one function makes me.
Right, and I want to call the GUI crate \`iced\`, so you should get some ice too.
The issue is you can't `Box&lt;dyn T&gt;` because T is Sized+Clone here. As I understand it, `Box&lt;dyn T&gt;` is actually `T` + `VTable` of some unknown size, which makes `clone(&amp;self) -&gt; Self` ambiguous (is `Self` is the size of T or the size of `T`+`VTable`?)
lol, nice, but you lost me with "you can only use Coffee with Coffee". What does that mean?
No windows support in the pipe?
Sorry. I meant that the UI can only be used with Coffee, which is a 2D game engine. Will edit to make things clear.
Ah gotcha, thanks!
Linux AIO works in some cases, silently falls back to blocking the thread in others (sensitive to e.g. what filesystem you're using), and iirc it either does not implement metadata operations or they practically always block. \`io\_uring\` may be more promising.
Oh, good thinking 👍
From what I've heard, you run into problems with f32 when doing planet-scale or galaxy-scale rendering.
Any reason this isn't just a cookie? You *can* have an instance of any type in Rockets state collection but you can trust that encrypted cookie exp stamps can't be tampered with.
&gt; Unmaintainable code is shit code, always. No it isn't. Over-engineering is bad engineering, always.
You can Box everything lol, did you try it?
You'll run into issues much closer. In Unreal Engine 4 you'll have problems at around 10 kilometers (one float = one centimeter scale). The issues manifest as skeletal meshes jittering and vertices bouncing around a bit when you move the camera.
I've never used Rust on Windows - it should work completely fine, nothing is OS specific. The problem is more the ecosystem - except for bundling everything I'm not sure how to ship it. You currently need to have the rg and other binaries in your PATH, which is fine on Linux but maybe not on Windows.
&gt;You can Box everything lol, did you try it? You can't and I did, otherwise I wouldn't have made this thread, see `rustc --explain E0038`. You can't Box Sized traits for the reason I explained above. https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0ccc9c1e30370509ab243818f5471684
Is there a way to get cargo to copy important files for the compiled executable to run to the destination folder when running `cargo build` or `cargo build --release`? For example I have a font in an `assets/` folder and the program panics if it's not found. Manually copying it to distribute the executable is already annoying and I've only done it once. I tried specifying an "include" section in the `Cargo.toml` file but that didn't seem to do it.
When it's outside of the loop you're appending to the string each time you read; try `guess.clear()` at the end of the loop (you'll have to pick another name for your `guess: u32` variable). That will let you reuse the allocation. If you're intending to append to the string, keep in mind that `.trim()` won't strip the line separator that's now between the two numbers in the string, which is why `parse() ` is failing.
If you don't reset the guess after each one, you're just appending the newly read data after the old data, which probably means it fails to parse into a u32 because there are extra control characters.
It would help if your comment provided reasoning rather than providing non constructive criticism.
&gt; You currently need to have the rg and other binaries in your PATH, which is fine on Linux but maybe not on Windows. You'd need rg on your path to run it anyway. But if you want to ship a binary package, bundling is probably the better / simpler option [short of libripgrep being finalised](https://github.com/BurntSushi/ripgrep/issues/1009).
Float has precision issues at practically any scale. If you’re doing an open world or streaming world game you want forget the concept of “world space”. There’s no such thing. No universal coordinate frame. All positions are relative to some local space. And those local spaces come and go.
Seems like some serious overkill to me.
When running `cargo build --release` from the root directory(where the workspace Cargo.toml is) output is warning: /home/doc/Code/Rust/fetch/fetch/Cargo.toml: unused manifest key: dependencies.lib_fetch.feature warning: /home/doc/Code/Rust/fetch/fetch/Cargo.toml: unused manifest key: dependencies.lib_fetch.lib_fetch Updating crates.io index Compiling fetch v0.1.0 (/home/doc/Code/Rust/fetch/fetch) Compiling lib_fetch v0.1.0 (/home/doc/Code/Rust/fetch/lib_fetch) error[E0463]: can't find crate for `lib_fetch` --&gt; fetch/src/main.rs:1:1 | 1 | extern crate lib_fetch; | ^^^^^^^^^^^^^^^^^^^^^^^ can't find crate error: aborting due to previous error For more information about this error, try `rustc --explain E0463`. error: Could not compile `fetch`. warning: build failed, waiting for other jobs to finish... error: build failed When running `cargo test --features arch test_pac` warning: /home/doc/Code/Rust/fetch/fetch/Cargo.toml: unused manifest key: dependencies.lib_fetch.feature warning: /home/doc/Code/Rust/fetch/fetch/Cargo.toml: unused manifest key: dependencies.lib_fetch.lib_fetch Compiling fetch v0.1.0 (/home/doc/Code/Rust/fetch/fetch) warning: c/linux.c: In function ‘get_loadavg’: warning: c/linux.c:62:12: warning: ‘avg’ is used uninitialized in this function [-Wuninitialized] warning: return avg; warning: ^~~ warning: c/linux.c: In function ‘get_mem_info’: warning: c/linux.c:76:12: warning: ‘info’ is used uninitialized in this function [-Wuninitialized] warning: return info; warning: ^~~~ Compiling lib_fetch v0.1.0 (/home/doc/Code/Rust/fetch/lib_fetch) error[E0463]: can't find crate for `lib_fetch` --&gt; fetch/src/main.rs:1:1 | 1 | extern crate lib_fetch; | ^^^^^^^^^^^^^^^^^^^^^^^ can't find crate error: aborting due to previous error For more information about this error, try `rustc --explain E0463`. error: Could not compile `fetch`.
I've always been curious why people use float at all for these use cases. Integers would give you fixed precision and have understood, concrete limits to exceeding that precision. Having predictable gameplay _seems_ better than supporting a wider range of values, but having cascading issues the farther out you get. Is there a reason why they use floats? Disclaimer: Not a game dev, though I've been slowly learning a bit of it.
Maybe it could warn just once if it needs an external binary which is not available? Getting a warning for each PDF on my machine because I forgot to install poppler / pdftotext is not super useful.
Good idea.. Wouldn't be that easy though because the preprocessing binary is called separately for each file, and they don't communicate with each other. Also, then a user could miss the first warning and wonder why it's not finding anything..
Everyone learns differently. What approach did you prefer while learning the other languages?
It's not just ripgrep, but also the other tools it needs for specific file types (pandoc, pdftotext, etc). I'll look into bundling everything.
Rust macros to the rescue \^\^! With them, you abstract over the match. [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=b9cd04992c95aee1e4c9c0820fe78f72). Should be relatively readable as well.
&gt; It's not just ripgrep, but also the other tools it needs for specific file types (pandoc, pdftotext, etc). I'll look into bundling everything. Oh yeah that's a harder sell then.
Why *not* embedded? A lot of embedded is waiting and acting on signals sent from the outside. It's not network I/O, but it is I/O.
&gt; Regarding panic log, yeah I currently write maybe too many messages to stderr that are only shown when extraction fails. It's mostly just that I guess the result of the filer / expander / whatever was straight unwrapped, so there's no nice message. No real biggie but a bit surprising.
The phrase "Futures are not composable" is an oxymoron. Composing them is the whole idea. If you want to run a future inside a future, it's probably best to just compose them directly using `and_then` and friends. If you *must* compose a future inside a future with a synchronous layer in between, you can start a thread and send the result. Below is an example that uses synchronous reqwest to fetch the rust home page inside a future. let future = lazy(|| { let (send, receive) = oneshot::channel(); std::thread::spawn(move || { let body = reqwest::get("https://www.rust-lang.org").unwrap() .text().unwrap(); let _ = send.send(body); }); receive }); // Then you can use the futures inside another future. // We will just run it and print the body. tokio::run( future .map(|body| println!("{}", body)) .map_err(|err| println!("Failed: {}", err)) ); As for the boilerplate, you only need `poll_fn` and `blocking` to use `blocking`. Using `lazy` in that example is a mistake, and the `spawn` is only because they're not inside a future: if you need to use `blocking`, you're going to be inside a future.
Maybe read from /dev/random if you're using unix-like systems
&gt; What is the easiest way to generate a random number in this case? Read from /dev/urandom and down-convert to the range you need? Especially if you have a recent Rust with all the `from_be_bytes` / `from_ne_bytes` goodness.
You could collect all the warnings and then emit them at the end somehow.
Unfortunately, the compiler is not GPU accelerated right now. Seriously though, you're looking for /r/playrust.
One reason is that GPUs are built to handle single precision floats the best. And converting from int to float every time you want to send data to the gpu is a pretty big pain
Not a gamedev, but how would you model animations with ints? If the scale is too big the animations become very jittery and not fluid. If you make the scale very small, the world/models can't become very large, since it will overflow too quickly. On the other hand floats allow you to indicate both larger and smaller numbers.
Ah yeah shit sorry
No.
Make sure you have `Expand declarative macros: Expand with experimental engine` enabled in `Languages &amp; Frameworks -&gt; Rust` enabled. It works quite well for me - e.g. properly expands types in the [ocl](https://docs.rs/ocl/0.19.2/ocl/) crate and few others.
&gt; that can be tricky to bring it down to a certain range, say you want numbers between 0 and 5. It's not *that* difficult: * if you really don't care about uniformity, just modulo * if you care a bit, convert to float, scale appropriately, convert to int (using banker's rounding) * if you care a lot, re-roll until you get a result which is in-bounds * if you care a lot and would like your process to terminate, only reroll on the "excess modulo" e.g. if you want [0 8[ from [0 255[ (a byte from /dev/urandom), reroll on n &gt;= 253, otherwise use n%7 There's probably an even more efficient version of the last one.
I searched long for a crate doing exactly this ILY (nohomo)
Oh, I noticed it's actually "rusty object notation". It's just instead of JSON. You might still see some mentions of JSON in the docs. Have a look at [https://github.com/ron-rs/ron.](https://github.com/ron-rs/ron.) It's all done at runtime, which is why there is no need to recompile.
If you want better versions, [xoroshiro](https://en.wikipedia.org/wiki/Xorshift#xoroshiro128**)[128|256]** is barely more complex and has much better behaviours. [PCG](https://en.wikipedia.org/wiki/Permuted_congruential_generator#Example_code) is also quite simple.
I think I googled rust TrueType rendering when I started out around.... 6 months ago? I'll have to check out HarfBuzz then. What are the main differences?
Nit: **u**random, `/dev/random` will block for no reason.
I’m authenticating with an Azure AD. As opposed to having the users sending the personal auth tokens to the server that then uses it, I would rather just have the users send the ID token to the server that will then retrieve the server auth token to use on the MS graph API. The retrieved server tokens only live for 3600 seconds if I remember correctly
C++ allows some quite neat syntax (for example initializers), that Rust avoided on purpose to be more explicit. I.e. I asked once, why Rust can't use a simple initialize syntax like: std::vector&lt;std::string&gt; foo = {"a", "b", "c"}; And the answer was - more explicit control. In the above, constructors are called implicitly.
Not sure. My main features are no recompiling, and the provider "pattern" which sort of creates an API for the front-end to use. I'll get back to you when I've checked out druid. I started this project in C++ a bit less than a year ago, then scrapped it and rewrote it in rust, so I haven't made a bunch of research about other libraries or frameworks yet.
`rustype` limitations are described in the repo's README.
`rusttype` renders glyphs, not text. It doesn't do any kind of shaping. Try rendering some Arabic text.
&gt; Composing them is the whole idea. But you have to compose them through their api. Like I said, if someone wrote a library that doesn't expose a futures api, then it all collapses. &gt; If you must compose a future inside a future with a synchronous layer in between, you can start a thread and send the result. So now I have to start a thread from the thread that I started, and there's no way to know that I need to do this until runtime (or checking the source code of something like reqwest to know that it uses futures) because, as I said, futures aren't composable. &gt; Using `lazy` in that example is a mistake So even the authors of tokio library can't get it right?
Heads up, your link is including the period at the end of the sentence resulting in a 404.
I skim through the basic syntax then write some trivial code in that language. Then I take up a small project like a cli or a rest api and do that. Then I try to make my code as idiomatic as possible. Thats what I did while learning go but rust has been giving me a hard time.
Thanks, fixed it!
What does that entail? Logging every time you do a dangerous operation (or any operation)? How do you make that so you’re not dumping out unmanageable gigabytes of logs every time you start a run?
Yeah, that is something I'm aware of. The font I have actually just includes a subset of ASCII, and is generated at startup as a sprite sheet. A more robust text rendering solution is definitely required. However, I think that is something I will focus on later. As-is there are a lot of issues to take care of and features to implement, and rendering only ASCII before 1.0 is something I'm okay with. I'll make sure to highlight the need for UTF8 text rendering for 1.0.
Look, calling blocking code from any sort of asynchronous code is always going to be unfortunate design, and will always require having some thread dedicated to performing the blocking operation. There is _fundamentally_ no way around this, and if you want the performance advantages of futures, you have to write asynchronous code. The `tokio_threadpool::blocking` method is more efficient than `thread::spawn` because the thread will often already be spawned, but it still works by monopolizing an entire thread for the entire duration of the operation. There's a reason futures are designed the way they are. That said, I agree it's unfortunate that you can't detect which of the two synchronous-inside-future strategies you need to use at compile time, but if in doubt, the `thread::spawn` one always works.
I might be interpreting what you are trying to do here wrong, but all MS services use Oauth2 authorization flow in the browser and issue refresh tokens with their access tokens to get around the 3600 sec lifespan. All the other code grant flows don't make sense or work with web services. Unless you are talking about having a client side webassembly / js application doing the application grant flow independent of the server but that kind of program is wholly independent of Rocket, it would be written into the JS / webasm modules you send from said server. Because with authorization code grant the client never has the access token - you register your app, send the client to MS to authorize, get back the authorization code in the redirect endpoint, use that code to request the access token from MS, and get back a refreshable access token you can keep using.
Thanks!
Let's hope that by that time we will have a proper solution, like a harfbuzz port to rust and/or [skribo](https://github.com/linebender/skribo).
Well, I just mean that floats are not magic. The reason they work with both large and small numbers is because they throw data away. For example, at work I do most of my "float math" on integers. This ensures I have a certain amount of precision _(I work a lot with numeric data)_. Using ints eliminates rounding errors and makes everything explicit. You can represent massive numbers or insanely tiny numbers. However, you have to choose basically at compile time how big or small your numbers can be. This safety for my work is massively important and allows us to guarantee accuracy in the numbers we produce. What I'm confused by is why this level of explicitness is not desired among game development. If I had to guess I'd say it's simply not needed for most projects. Floats simplify life, like a dynamic language does. However, like a dynamic language, they are also imprecise. So it's a game of tradeoffs I'm sure.
Is it more efficient than vec! macro?
either way you want to move the world through the origin rather than the origin through the world. then you are fine.
Not sure about efficiency, but vec! macro is a syntactic workaround for that. I was asking more, why it was needed to begin with, and why it can't use simpler syntax.
After finishing "Chapter 18: Input and Output" of Programming Rust (specifically the part "Collecting Lines"), I was able to answer my own question and come up with a better solution. I'm posting it here in case someone finds this thread later. Since the trait `FromIterator` is implement for `Result` ([link](https://doc.rust-lang.org/std/result/enum.Result.html#impl-FromIterator%3CResult%3CA%2C%20E%3E%3E)) you can collect an `Iterator` of `Result&lt;T, E&gt;` to a `Result&lt;collection&lt;T&gt;, E&gt;`. If one of the Results in the iterator is an error the whole thing returns an error. This means that my solution above could instead be written like: fn load_data(filename: &amp;str) -&gt; io::Result&lt;HashMap&lt;String, String&gt;&gt; { let file = File::open(&amp;filename)?; io::BufReader::new(file) .lines() .map(|result| { result.map(|line| { let mut iter = line.split(','); (iter.next().unwrap().to_string(), iter.next().unwrap().to_string()) }) }) .collect() } Using the Itertools crate you can make it even cleaner and avoid the nested map-methods, by using [.map\_results](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.map_results): fn load_data(filename: &amp;str) -&gt; io::Result&lt;HashMap&lt;String, String&gt;&gt; { let file = File::open(&amp;filename)?; io::BufReader::new(file) .lines() .map_results(|line| { let mut iter = line.split(','); (iter.next().unwrap().to_string(), iter.next().unwrap().to_string()) }) .collect() }
If I may be a bit frank, I often find there's a lot of people (co-workers included) that only know how and prefer to just hack things together. It's an education problem and one of the reason a lot other engineers call people who write software "not engineers". Forcing people to fix bad habits via learning Rust is a good thing.
Yea, you have to learn to crawl before you can even walk
I remember when I tried out \`piston\_window\` a long time ago that I got fonts to work via the \`find\_folder\` crate. Distributing the executable automatically will require scripts no matter what. There are probably hacky ways to get the assets into the executable itself through the \`include\_bytes!\` macro from the standard library.
Not enough context to answer your question. If I had to guess it involves taking two mutable references to the same thing, which is forbidden, instead of just taking one mutable reference. The problem is, I need to see both structs and functions in question and to see what you mean by "take a mutable reference to self". Also, include the compiler output.
That's why it has world composition to reset the origin
I think you misunderstand. If I call `blocking` then by definition I'm in a new thread. But that thread isn't allowed to use futures in a blocking manner. That's the problem. Now if I know I need threads, I call `blocking`, yet I must spawn *another* thread with `thread::spawn` in order to do blocking operations and communicate between the two threads, simply because the thread spawned by `blocking` is already "infected" with a runtime, which is logically unnecessary and stems from the deficiency in futures.
The most interesting cryptocurrency idea I've seen is middleman free brokerage. Essentially a buyer and seller put a deposit (plus payment) into a pot that either party can destroy. Both parties are motivated to resolve disputes to retrieve their deposit. I'm doubtful of it's practical usefulness but it's an interesting to mull over.
I can highly recommend Programming Rust. It's very well written and has some great illustrations to explain the concepts. That said it definitely assumes that you are an experienced programmer preferably with a background in C++. Even if you haven't used C++ it's still a great read, I haven't ever programmed in C++ (or any other systems programming language) and I still enjoyed it. It's written for Rust 1.17 but all code still compiles because the newer Rust versions are backwards compatible. After reading that book I would probably recommend reading the [The Rust 2018 Edition Guide](https://doc.rust-lang.org/edition-guide/rust-2018/) to get up to speed on the new features and changes of the languages (impl trait, dyn trait, default match bindings etc.)
I was going to jokingly ask if it can search my jpgs, but apparently it does that too.
Or we can help add missing features to rusttype
&gt; It's all done at runtime, which is why there is no need to recompile. Oh, this is sad. Users of Rust obviously prefer type checking, and part of program without compile time checking looks not good. Is property exists, is layout include real widget and so on things. What the reason to use Rust instead of JavaScript/Python if you get the same guarantee?
`rusttype` positions itself as a FreeType alternative. And FreeType is also only a glyph renderer.
This REPL uses rust version 1.31.0 (2018 edition), but the results are the same as on my computer which uses Rust 2018 edition, version 1.35.0 &amp;#x200B; [https://repl.it/repls/HelplessAmusedServers](https://repl.it/repls/HelplessAmusedServers)
Nice! I think this is probably the first specifically const-generics-based crate I've seen. One thing: it might be good to provide a directly runnable "binary" example somewhere in the repo.
Well fair enough. As far as I know, the reason `blocking` is “poisoned” like this is because futures currently rely on thread-globals to pass around notification information, and `blocking` actually stays in the same thread. In the new api coming with the async fn feature, the thread-global state is moved into a [context parameter](https://doc.rust-lang.org/std/future/trait.Future.html), so I'd the poisoning disappears when it is released. It's probably also possible to unset and set and thread-globals to make it work now.
There are two parts to the app. A front end (HTML/JS) and a backend (Rust). &amp;#x200B; When our employees sign into the app, they do so through a SSO handled by Azure (OAuth). Currently, I am issuing access\_tokens to the users when they sign in. Some times, the server is required to send an email on behalf of the signed in user that includes generated content by the server. (A sales invoice FWIW.) So I am currently using the access token issued to the browser to make the request through the server. &amp;#x200B; What I am trying to transition to is when an employee signs in, only issuing them an id\_token and having the server request its own access\_token using the registered app flow. (requesting via a client secret). &amp;#x200B; When I request the token from the oauth2/v2.0/token endpoint, it responds with the token but also expires in 3600 seconds. So what I am ultimately trying to do is include the API token in the routes where I need to call the MS Graph API, but also do maintenance such as refreshing the token if needed within the same state/guard. After thinking about it for a day, I think what I am going to end up doing is use \`State&lt;Mutex&lt;ApiKey&gt;&gt;\` and just make the token check using a getter on the struct. (i.e., \`api\_key.get\_token()\` returns a \`Result&lt;String, Error&gt;\` and will do the correct validation checks before returning the result. The error would be for if the token couldn't be refreshed for whatever reason.
Because the things you can specify in RON will be deserialized into `struct`s/`enum`s that you specified before you hit compile. The only things you can really change are values, not their types.
Welcome to the club of people making Rust GUI's!
Nice blog. A little bit empty though. By the way, once hediet's blog is out, its well designed awesomeness will outshine your fearless concurrency in ways you cannot express with barcharts however nice they look.
It would be pretty simple to write a build script to check you can deserialize all your RON when building.
An installer (.msi) is the most idiomatic approach. There's a tool called `cargo wix` which provides a slightly simpler way of creating them. IIRC still requires a Windows machine.
I think this function got deleted in https://github.com/amethyst/amethyst/commit/d24a5884c6a6c81825f58b4597f59a13b9d8a974 :(
I recognize this and have run into this issue myself before, most commonly when trying to do some operation on a \`Vec\` and using \`.len()\` as a nested argument. See \[this\]( [https://github.com/rust-lang/rfcs/issues/811](https://github.com/rust-lang/rfcs/issues/811) ) for historical stuff, and \[this\]( [https://github.com/rust-lang/rust/issues/43234](https://github.com/rust-lang/rust/issues/43234) ) for current progress. Apparently, there is still a lot of NLL work to be finished.
I'm not sure I agree. It is true that since `libstd` requires functionality from an underlying operating system that it basically by definition can't be used to implement an operating system. However, I don't think that detracts from the benefits of using Rust to write operating system code. You still have lots of nice features like algebraic data types, closures, and bounds checking by default and you also shouldn't underestimate the number of libraries that do work in a `no_std` setting. For me, the biggest downside to using Rust for such low level code (if you can even consider it a downside since the alternatives is a language where everything is unsafe) is that it is quite hard to avoid either having a lot of the code base be unsafe or having to lie about the safety of functions that that manipulate page tables, device memory, traps and so forth.
You might be looking for r/playRust. This is a programming sub.
Regarding: ```rust let arr: [Vec&lt;usize&gt;; 1000] = [Vec::new(); 1000]; ``` Once `Vec::new` becomes a `const fn` and https://github.com/rust-lang/rust/issues/49147 is implemented, you can just write the thing above and it should compile.
Just open a 'static popup' at the end of the window which shows each error type once.
When dealing with extremely large worlds, even moving to f64 won't save you. A hierarchical co-ordinate system will. E.g. player character's current "parent entity" might be the Earth, and so its position etc. is expressed relative to the Earth. Earth's parent is the sun, and so on. To compute the relative transform between any two entities in the universe you can walk up the tree to the closest "ancestor" entity, and back down again. I'm sure there are other approaches, but this one worked well for me. Now that Amethyst with Rendy is out, I'm hoping to find some time to port the basics of this approach into a crate that can be used easily with Amethyst.
Hey, thanks! Know of any others?
I feel like I should get used to these, but I was really confused by this post.
I love it when it's not a me issue :D Thanks
There exists JSON validation, and I even had it at one point before moving over to RON. Someone might make something like it for RON. The library handles everything for you; the only thing you need to do is to give it the layout, and it'll basically deserialize it. Have a look at the .gui.ron file in the repo and I'm sure it'll be clear how it works. Another goal of the library is to output helpful error messages, so it's supposed to be easy to fix any syntax errors. I, too, love statically typed languages, but to avoid recompilation it has to be dynamically loaded. Loading and building takes just a few milliseconds anyway.
32-bit float works with basically every game ever. It’s the standard. 32-bit int micrometers would give about 4km of precision. That wouldn’t be enough for global world space for many games. I’m not sure I’d want to go lower precision than micrometer. 64-bit int would give millions of miles. That enough! But 64-bits is a lot and you will pay a hefty performance fee. To be honest I’ve always wanted to try it. But people I’ve talked to who have tried always run back screaming to floats. I’m not entirely sure why. I don’t know what the gpu side of things looks like at all.
I’ve solved hundreds of problems in programming competitions. None of that code has turned into a “permanent solution”.
&gt; What I'm confused by is why this level of explicitness is not desired among game development. Because even if you're throwing away actual noticeable precision, if the player never notices and it doesn't hurt fairness, who cares?
It would be interesting to create a cargo command or simple CLI application which just runs the deserializion. Then it could be built into a CI pipeline or a build step. I should put that on the pile. Ruey does more than just deserializing, so just checking the syntax unfortunately wouldn't be enough. For instance, text alignment is written as "align: "top\|left"", and a "type" property is required for all elements.
Deserializing != checking syntax. I meant actually deserializing into the appropriate structs.
Well they do notice it, hence the discussion of how far you can go out in the world before jittering issues pop up and whatnot. I guess I just mean, I struggle to understand why I'd _choose_ to write an engine that fails the user in buggy behavior. I'd rather perfectly support gameplay up to X units, and prevent gameplay beyond X units. If that makes sense. It's clear floats _(and ints)_ have limits. However floats can pretend they don't have limits for far far longer, causing odd user experiences for some games. Programming this way seems odd to me. Especially when using ints is surprisingly easy. Anyway, to be clear *this is not a judgy comment*. I am *not* a game dev, though perhaps an aspiring one at best. My comments are desires for understanding, not any high horse or anything :) We are after all on a subreddit for developers of a fully safe language. Some of us *(aka Me)* are bound to be a little dumb when it comes to understanding the benefits of more dynamic approaches :)
Oo good point too, GPU might be an interesting beast here. Granted, I know *absolutely nothing* about GPU dev haha. Definitely not something I considered.
I am currently looking at Babylon.js and Filament to display some glTF scenes on the web and do some limited interactions. Would Amethyst on WASM be too heavy for such a use case?
I am not begging for your money, in fact I left the image un-watermarked so you can use it elsewhere, but I just saw the lack of actually neat designs for Rust, and programming in general, on T-Shirts. I found this website while looking for a good programming T-Shirt, but came up empty-handed and decided to make my own. Spare me!
Yes, sorry, I'm using the terms too interchangeably... I just meant there is some validation to be done and rules to abide by other than just the RON syntax.
The pandoc integration is really neat. I like this approach.
As someone who's making a commercial game in an engine that uses floats for everything, let me assure you that nobody notices. Never in years of development have we had a single floating point precision bug, even bugs that designers notice but players don't. So let me assure you that no, players do not notice unless you're doing very extreme things that the average game doesn't do.
`query_interface` has a `dynamic` feature that does approximately this (albeit via a custom Any trait).
&gt; i give a shit on grammar 🤔
&gt; • ⁠if you really don't care about uniformity, just modulo Note that even if you care about uniformity, if the input range is very big (say, 64 bits) and the output range small (say, 0 to 5), the bias is *exponentially small* (like 2^-61 or so for this example). So for non-demanding applications taking the modulo of a random `u64` might work. (And taking the modulo of n + 128 bits can be cryptographic-grade.) &gt; • ⁠if you care a bit, convert to float, scale appropriately, convert to int (using banker's rounding) This is trickier than it sounds. Floating point is complicated. &gt; • ⁠if you care a lot, re-roll until you get a result which is in-bounds No, this is likely to be pointlessly slow. First figure out the smallest power of 2 that’s bigger than the size of your range (e.g., 2^3 = 8), and chop the big random numbers to that many bits. That way each loop iteration has a better than even chance of termination. &gt; • ⁠if you care a lot and would like your process to terminate, only reroll on the "excess modulo" e.g. if you want [0 8[ from [0 255[ (a byte from /dev/urandom), reroll on n &gt;= 253, otherwise use n%7 Ah, that’s clever.
By passing `self` the method takes ownership of the object meaning it will be dropped by the end of the call. 99% of the time this is not what you want since you won’t be able to use the object after calling a method that takes `self` and not `&amp;self`. By convention and for usability, you should always prefer `&amp;self`. There is a workaround, and you can implement (or derive I think) `Copy` on your struct, however I have never once found a need for this and always just use `&amp;self`.
Cool that you ask it. I have the idea for a online live Rust conference (with local viewing party’s) in my head for quite some time. But I hope RustConf can have a live-stream, however if there is someone interested in organizing a online conference then DM me.
[https://areweguiyet.com/](https://areweguiyet.com/)
Of course. In addition to the ones listed on [areweguiyet](https://areweguiyet.com/), there's [makepad](https://github.com/makepad/makepad) and [carnelian](https://fuchsia.googlesource.com/fuchsia/+/refs/heads/master/garnet/public/rust/carnelian/), both of which are more specialized rather than trying to be general GUI toolkits, but have interesting properties. I also know of [moxie](https://github.com/anp/moxie), which will have a [RustConf talk](https://rustconf.com/speakers/#adam-perry) this fall, and at least a couple of game engines have enough GUI capabilities they could be used primarily for that. It's an exciting time in Rust GUI land.
Hi, thanks for the reply. I know of the difference between `self`and `&amp;(mut) self`, but my question was more specifically about choosing between: * Using `self` in a trait and implementing on `&amp;mut T`, or * Using `&amp;mut self` in a trait and implementing on `T`. Semantically it's pretty much the same thing but the second version seems to be making some things more difficult (as seen in the examples posted above), which is a bit disappointing because it also seems more straightforward.
Thanks, that worked.
I've been tinkering on [Alchemy](https://github.com/ryanmcgrath/alchemy), although there's a local branch I need to find time to finish and push that makes it actually usable.
Probably, yeah. Rendy alone might even suffice for such a thing, though keep in mind WASM support hasn’t been fully implemented yet.
oh really? my assumption was it would be too much memory usage for such a small thing
Cool! Thanks for the info!
No problems! :) I'm also very biased since `bnfc` is courtesy of my university :D
You're right, I could probably have been more nuanced. I guess I was coming at it from my security mindset; in the security community, it is almost universally acknowledged that GPG offers terrible UX and has insecure defaults to boot.
Hmm, well, if the struct lived less than the reference, it would just deallocate with no impact to the referenced data structure. But if the child reference had smaller lifetime, it would deallocate, but the struct would still exist and the child could potentially be misused. I tend to imagine a static variable being referenced in a struct.
 error[E0515]: cannot return value referencing temporary value --&gt; vkwayland/ash-tray/src/lib.rs:78:41 | 78 | Backend::Xlib { .. } =&gt; Ok([khr::Surface::name(), khr::XlibSurface::name()].into_iter()), | ^^^------------------------------------------------^^^^^^^^^^^^^ | | | | | temporary value created here | returns a value referencing data owned by the current function error[E0515]: cannot return value referencing temporary value I get this error, trying to build and return a slice::IntoIter. [https://github.com/cheako/smithay/blob/d17a144b7a344e2480bc837f8a2c57567d1660f1/vkwayland/ash-tray/src/lib.rs#L76](https://github.com/cheako/smithay/blob/d17a144b7a344e2480bc837f8a2c57567d1660f1/vkwayland/ash-tray/src/lib.rs#L76)
Only log what you need to log. Use different logging levels and filters. `fern` affords a lot of flexibility in how you configure logging requirements. You can print logs that originate from specific files, modules, crates; or print logs that meet a certain logging level: trace, debug, warn, info. In production, you can have a minimal level of logging necessary to have a good idea as to what real world inputs caused what area to malfunction. Enable more logging when testing your software in staging and development.
Ah I see. I would still suggest the second version as it is more flexible and common practice.
Umm... did that commit delete the *entire* rendering code or something?
Ah, makes sense. Thanks!
`amethyst_renderer` was renamed to `amethyst_rendy`.
Related, my [mopa](https://crates.io/crates/mopa) crate, which lets you mix `Any` functionality into your own trait.
Of course, you would need to be mindful of your system's capabilities, but Rust gives enough control that it's probably possible to keep the memory and CPU usage down even when using async code. On more complex embedded boards like RaspberryPi, this is less of an issue. In the end, it comes down to how Rust lets you be more mindful of how your code is running compared to higher level languages, while still taking advantage of abstractions not available in lower level ones.
Rust setup with \`use-package\` at the end of the [init file](https://github.com/lerouxrgd/dotfiles/blob/master/emacs.d/init.el#L737).
Note that State&lt;T&gt; is a singleton instance of a type. You want a collection of Tokens / Keys I imagine. This kind of stuff usually goes in a db. Also you can have a request guard for such tokens where you can check &amp; refresh them and guarantee routes are only called with valid tokens. Just impl FromRequest on the type behind which you can either have a threadsafe collection, db, etc backing it.
Nice catch. It was simply missed in a (very large) refactor, A bug is open here: [https://github.com/amethyst/amethyst/issues/1725](https://github.com/amethyst/amethyst/issues/1725) &amp;#x200B; Jaynus brought up on Discord: &gt;the math itself is basically the same, just the data has moved. Something to the effect of &gt; &gt;`camera_transform.translation() * camera.projection().as_matrix().try_inverse() * screen_point`
Tell the competition managers that Rust expects access to crates outside the standard library and that `std` is intentionally minimalistic. Even play.rust-lang.org doesn't expect you to work with just `std`. It provides the top 100 crates, specified [here](https://github.com/integer32llc/rust-playground/blob/master/compiler/base/Cargo.toml). There's also [the nursery](https://github.com/rust-lang-nursery) which can be thought of as an extended standard library. The nursery contains the [Rust Cookbook](https://rust-lang-nursery.github.io/rust-cookbook/). The very first guide is for random numbers and it says to import the `rand` crate. In total, 16 of the links use `std`, *everything else* for common operations it recommends the use of external crates. The fact that many competitions limit third party (and second party) libraries is something I'm not overly fond of. It unfairly penalizes languages like Rust that rely on their package manager to keep code *out* of the standard library.
HA! Well I had to nuke my project/.idea folder, the global idea settings in my homedir and re-import the project to get them to display but now they do. That is so good, thanks!
This is simply not true when it comes to problems such as deterministic physics, and of course for when it comes to large relative scales. Floats are like if you took a normal number line and instead of adding points on every whole number you add points on a quadratic curve, so they are more densely packed closer to zero, and less so the further you are from it. So while it may be true that a floating point number can represent a very large value, those very large values will often be relatively far more truncated. This is numerically a problem when your origin in a "world space" isn't shifting with where fidelity is most required, as a world space will hve many relationships and relative spaces to handle and compute, with the observer's camera being only one. There is also a big problem in determinism for floats, which while mathematically are deterministic (you should always end up truncating additional information in values the same way, just as you would when rounding to whole numbers), but then in practice FPU's will often introduce nondeterminism if not interacted with particularly carefully. &amp;#x200B; &gt; I don’t know what the gpu side of things looks like at all. &amp;#x200B; The GPU side of things is basically the sum of the reason why f32's are the dominant numeric type in video games since f64's are essentially nonexistent on GPU's unless you have one that was manufactured for \~SCIENCE\~ and while I couldn't speak to testing the performance of integers on GPU's (there are probably big pitfalls, just like integer performance on the CPU vs floating point), the numerical properties of floats are definitely far more useful for rendering since the relative space is always from the observer, and so things that are far away will have less observable fidelity loss, and fidelity is required far more as you get closer to the origin of your relative space, a property that integers don't have. And of course as u/termhn said, nobody likes numerically converting a boatload of projection matrices/translations for every single render. There are optimizations one can do to offload some of these costs, but they're still just that, costs that have been offloaded someplace else.
I think the deciding question is: will anyone implementing your trait want to implement it for a value type (not for `&amp;(mut) T`)? The reason `serde::Serialize` uses `self` and implementing for `&amp;mut T` is that _not everyone implements for `&amp;mut T`_. This lets some serializers become invalid when finished - some _do_ want to be taken by value. Then this can represent things like `json` documents which really should only contain 1 top-level item. If the trait declared `&amp;mut self` in methods, then representing things that need to be taken by value becomes impossible. Serde did originally have methods taking `&amp;mut self` in traits, but changed away in 0.9.0. The [release notes for serde 0.9.0](https://github.com/serde-rs/serde/releases/tag/v0.9.0) lay out some nice reasoning for this change, and the benefits of using `self`. --- For your own crate, if you think no one will ever implement the trait for a value type - and will always implement it for `&amp;(mut) T`, then I'd recommend just having the methods take `&amp;(mut) T` directly. It's simpler, and represents the guarantee that "anyone implementing this trait must allow calling this method more than once". If you think anyone will want to implement it for value types, then having methods take `self` is probably worth the tradeoff of complexity.
&gt; This is simply not true What isn’t true?
&gt;32-bit float works with basically every game ever. It’s the standard.
What games use integer coordinate systems? I’m not aware of any significant ones. Unity3D and UnrealEngine4 both use 32-bit floats.
Looks cool! There is certainly room for a high quality gui framework for rust. Fast iteration is also something desirable in a language not spoiled by such.
Rust has rudimentary reflection in [std::any](https://doc.rust-lang.org/std/any/index.html), although it's not as deep as reflection in java for example.
&gt;I’m not aware of any significant ones. Yes, because video games aren't developed where everybody may see their source code :) A very large number of android games use fixed point to avoid floating point emulation costs. Floating point was exclusively emulated on the DS so fixed point was required. Also, many networked games requiring deterministic properties use fixed point in order to help deal with platform differences as well as FPU pitfalls. There was some writeup on Gaffer about this but his blog is currently down.
Patiently awaiting a tutorial on creating a voxel generator using Amethyst. This looks amazing.
Unfortunately, this is not the community for the rust game (rather, for the rust programming language). Might I recommend /r/playrust?
I would contact steam about the stolen account?
When you typed "rust" into the subreddit field to make this post, it said "The Rust programming language. For the Rust video game, see /r/playrust" underneath. Why did you choose to post anyway?
Definitely `-sys` crates of the kind that bundle the entire sources of C libraries and attempt to invoke a C compiler to build them, for several reasons: - 99%, if not 100% of the ones I've ever seen try to build themselves are for libraries I **already had installed** - They almost never work properly because they all seem to be written by people who know next-to-nothing about CMake/Gnu Make/e.t.c - Building on the first point, they almost never have any capacity for overriding the library-to-be-linked with an existing path, or make any attempt whatsoever to search for an existing copy of the library. Nope, they just try, and often *spectacularly* fail to build the bundled sources! If your Rust crate requires the presence of a specific library, *just tell me what it is up front* in your readme or whatever, and let actually installing (if I *even need to do so*, which is rarely the case) be my problem.
If `array::IntoIter` was a thing your function would compile but you have a `slice::Iter` and slices never own anything. So you are trying to return a value that will get destroyed when the function ends and the compiler won't allow it (rightfully). You then have a few choices, you can return an owned collection (for example a `Vec`) like in the [ash's example](https://github.com/MaikKlein/ash/blob/master/examples/src/lib.rs#L181).\ If you always have the same number of strings you could also use the array_vec crate and return an `arrayvec::IntoIter`.
Thanks, I'll try Vec&lt;*const i8&gt;.
&gt; If, like me, you understand that the only acceptable way to install software is from your OS's package repository and the only OS with acceptable stability guarantees is Debian Stable Yeah, no. I've literally never done anything other than straight-up build Rust from source every ~3 days or so, and I see no reason to stop. Sure, sometimes the build is broken. In that case I just try again the next day. Not a big deal. (Yeah, yeah, I get why the core devs want to encourage people to use stable and all of that, but, really, nightly IMO is not **that** unstable.)
This doesn't work because "into_iter" isn't taking the array by-value; it actually resolves to &lt;&amp;[T] as IntoIter&gt;::into_iter, which returns the borrowing iterator `std::slice::Iter&lt;T&gt;`. This causes compilation to fail because you're trying to return an iterator borrowing from the value, but the value is dropped once the function returns and your borrow would outlive the value it references. In your case, your return values are completely known at compile time, you can just return a `'static` reference to the slice you are constructing, which would look something like this: ``` fn get_required_extensions(&amp;self) -&gt; VkResult&lt;&amp;'static [&amp;'static CStr]&gt; { match get_backend(self)? { Backend::Xlib { .. } =&gt; Ok(&amp;[khr::Surface::name(), khr::XlibSurface::name()]), Backend::Wayland { .. } =&gt; { Ok(&amp;[khr::Surface::name(), khr::WaylandSurface::name()]) } Backend::Win32 { .. } =&gt; Ok(&amp;[khr::Surface::name(), khr::Win32Surface::name()]), } } ```
&gt; at some point needs to create a new object that takes a Rc&lt;RefCell&lt;MyWrapper&lt;Box&lt;dyn Read&gt;&gt;&gt;&gt; That is an extremely specific bound. Coudn't it just accept an `T: Read`? Then your `Box&lt;dyn Read + Seak&gt;` will be viable to pass?
Check out glyph-brush. It is a glyph cache library that renders glyphs to a sprite sheet as needed on the fly, and will resize it for you and such. It uses rusttype to render the text and lets you do your own drawing however you want. Ignore harfbuzz for now. AFAIK there's three levels to doing text Right: first, just drawing the glyphs, which is what rusttype does. This is hard, but rusttype does it kinda decently, for European languages. Second, doing text layout such as line breaking, spacing, hyphenation and so on. This is *hard*, but there's pretty good algorithms for it out there. And third, doing text shaping, such as handling ligatures, figuring out what glyphs to use in complicated texts like Arabic, mixing RTL and LTR text semi-sensibly, etc. This is **hard**, and Harfbuzz is the only open source software brave enough to try. But Harfbuzz itself is big and complex and so using it is tricky. Focus on getting things working from easiest to hardest, so you keep making progress. An imperfect tool is still useful for some people. Just do some research and know what perfection might look like, so you have a goal to aim for and an idea of what the tradeoffs involve. This looks like a great project, so keep going. :-D
It should be available in debug as well, since it's a semantic change.
Features behave weirdly with workspaces. If you run `cargo build --manifest-path fetch --features arch` I would expect that to yield output that makes more sense. In general, however, you have an optional dependency declared in your Cargo.toml (lib_fetch), but you appear to have an unconditional `extern crate lib_fetch` declaration in the source. Those two facts are incompatible; either the dependency is not optional, or you need a `#[cfg(feature = "arch")]`.
Adding reflection to a language constrains its implementation in such a way that it may become very difficult to improve it later.
This is one place where TypeScript's gradual typing really shines. "First make it work, then make it safe."
Could you use a `static` [state object](https://crates.io/crates/state)? A simple boolean would suffice for whether the error had already been reported. It would eliminate message-passing as well.
I disagree with basically everything you've said here. The way I see it, unless you are some kind of corporate entity who strictly *must* use tools that come with some kind of official "stability" guarantee, there's no logical reason for you to not use nightly. I might think differently if nightly was constantly crashing or something along those lines, but that's not the case. Nightly is consistently just... a newer version of Rust with the all of the latest features ready for me to use right now. A tangible reason for me to not use it exclusively has never presented itself, and I doubt one ever will.
927
I read your post. I’m being polite and not making any assumptions about your experience. I’m familiar with all of these issues. I’ve shipped games that have dealt with all of them.
I see they already have 760 issues, many with no comments at all, which does't feel too encouraging to add more to it. Also, since I have never used rust, my issue might give a naive amateurish appeal and also might be ignored.
&gt; Ok, you made it sound like you used cargo build --error. Seems you didn't, so I retract that statement :) I am sorry for this unintended confusion, I wonder would there be any less confusing way to separate the command from response there?
That is the one I use the most often as a great example of really doing something cool with rust.
Fucking cool!
With Rust, Cargo works just as well with `no_std` as it does without. As such, many functions that would have to be written unsafely by hand already have (relatively) safe wrappers provided. For example it's possible to manipulate page tables in a type safe way with the only unsafety being changing the current table in place.
I can understand your worry! One thing to note is that the issues are used both for internal tracking and bug reporting. Many of the issues with no comments are ones filed by members of the cargo team, and are there to track improvements or fixes which they know need to happen. Hopefully this fact can shine a light on the state of the issues page? Mostly everything has at least one tag, like C-bug, too. Since only team members can add those tags, I think this means all of those reports have been written by or looked at by someone. I would submit an issue on your behalf, but since I'm not experiencing it I don't think I could provide the extra information they might ask for. Almost everyone is super friendly, though, and I don't think submitting an issue would be a waste. Even if it's naiveish and amateurish, they'll understand and know the exact right questions to ask to get to the bottom of it? Anyways, I guess this posts amounts to saying "I recommend posting an issue anyways, it should be alright and help" :p.
To be fair - i just checked on the reddit app on Android - and there is no such message. There is a rules link - but i also didn't notice anything there about Rust the game"
"Voxel generator"?
Short but sweet
Something like this [https://www.youtube.com/watch?v=js4jrSr7LRw](https://www.youtube.com/watch?v=js4jrSr7LRw) I think "engine" would have been a more appropriate word.
Ah, fair enough. I don't know much about Amethyst, but I'm the founding dev of /r/veloren, a voxel game written in Rust. If you're interested in hearing about how we do things, feel free to hop on our Discord.
Very cool! I joined your sub :)
A wrapper type sounds like the right way to go for this? The general way I know to solve this is to introduce a new object-safe trait, then to create a wrapper around `Box&lt;dyn NewTrait&gt;` which implements the original. You should be able to do something like: trait ObjectPeripheral: (object safe bounds...) { // copy all methods }; impl&lt;T: Peripheral&gt; ObjectPeripheral for T { // implement methods forwarding to Peripheral implementation } Then struct ErasedPeripheral(Box&lt;dyn ObjectPeripheral&gt;); impl Peripheral for ErasedPerpheral { // forward methods to ObjectPeripheral implementation } For cloning, the trick is to have an `fn clone_box(&amp;self) -&gt; Box&lt;dyn ObjectPeripheral&gt;` method on `ObjectPeripheral`, and then to manually implement `Clone` for the wrapper using it. Or you can use a helper crate like https://github.com/dtolnay/objekt which provides such a method. I think besides that, most of this should be straight forward? It's a lot of code, but it works, and doesn't require changing the library. Once written, it should be fairly easy to use, too. As an example of this in practice, https://github.com/dtolnay/erased-serde makes previously non-object-safe `serde::Serialize` and `serde::Deserialize` into object-safe traits.
too many vowels, not enough consonants
`foo.js`
This feels more like a memory barrier than a transaction to me?
I love std:: too. My favourite is are from utf8 combined with cow. Copy only on non utf8 is so fricken cool.
We don't livestream, sadly.
The name was Rustgui for a long while, and lui before when I used Lua, and some other unimaginative names too. I just took rust and gui and put them together because I couldn't think of something else.
....huh?
Thanks! Definitely! I had the idea while using Dear imgui on a somewhat large C++ code base. I tried positioning a "yes/no" button combination by moving things around pixel by pixel, recompiling, running, and then clicking my way back to the dialogue. It became tiring very quickly...
Wow... thank you for this dump
Having read *Programming Rust*, there actually isn't a lot of material that I'd consider out of date.
We're already calling into pure JavaScript. That part is sorted ;) My main concern is that we'd be using rust to gain performance, but calling across JavaScript is likely to be really slow. Unless we can find a way to have a lot of work done on one side at a time and Keep communication down I'm not sure it'll be worth it. Maybe we'll have to wait until wasm can call wasm.
Note that State&lt;T&gt; is a singleton instance of a type. You want a collection of Tokens / Keys I imagine. This kind of stuff usually goes in a db. Also you can have a request guard for such tokens where you can check &amp; refresh them and guarantee routes are only called with valid tokens. Just impl FromRequest on the type behind which you can either have a threadsafe collection, db, etc backing it.
&gt; No equivalent to `newtype` in Haskell for type safe aliases. If you want an ergonomic typed integer then you need to write a lot of boilerplate Isn't the actual issue here "no equivalent to `deriving` (and the various extensions to it) in Haskell"? There is an equivalent to `newtype`.
This is ignorant imo. &amp;#x200B; Lots and lots of GUI libraries use some templating language to help design the layout (HTML).
I think it depends on how much you want to think in terms of pointer-level semantics versus higher-level concepts. The O'Reilly book seems to me to be primarily targeted at C and C++ developers who are used to thinking about data structures in terms of stack size, contiguous vs non-contiguous layouts, pointer indirection, and so on. Towards that end, it attempts to explain not just *what* various language constructs do but *how* they can be implemented as zero-cost abstractions, and to do so it relies heavily on things like abstract diagrams of memory layouts. If these are the kinds of details you're interested in, I highly recommend it. I haven't read "The Book" yet (the one on the website, which is also available in "dead tree" form as *The Rust Programming Language*), but I've skimmed through it. It does explain how references work using similar sorts of diagrams as *Programming Rust*, but it is less focused on those low(ish) level details of memory layout than on the higher level concepts. (I've also been told by a senior developer with experience in embedded systems whose primary languages are C and C++ that he preferred *The Rust Programming Language*, at least based on the first few pages of each book, so the O'Reilly book isn't necessarily preferable even to the type of developers I described above.)
Is that a limitation like a lack of ready access to equipment/expertise, or more of a conscious decision, say to keep costs low so ticket prices are accessible?
Nice! I did not know about this but definitely have wanted to use something like this.
I've looked up Druid a bit and I can give you some points where Ruey differs: \- Ruey is not data oriented, its object oriented. So every GUI element implements a specific trait, and all interactions are done through the trait. Layouts know that it has a number of children (all of the trait's type), but has no clue what is inside them. \- Ruey is platform agnostic. It just outputs a vertex list for you to draw. In the future this will be a bit more complicated as things like HSV rendering is required eventually. \- Like I mentioned, no compiling. The GUI file is written in Rusty Object Notation and deserialized from disk, meaning you can reload it at any time. In the future I want to improve this with some smart "git diff"-like algorithm so state is preserved for any elements you did not update between reloads. &amp;#x200B; I'm not crazy about object orientation, and I realize that the performance will never be 100% optimal when jumping around in memory. I experimented with a more data-oriented approach when I wrote this in C++, but in the end I fell back to what I have now. I don't think modern CPUs will have many issues with the memory jumping paradigm that is OOP though. As OOP as it gets in Rust anyway.
I'm always excited about new developments in the Rust GUI space, so first of all congrats on reaching a milestone and I wish you the best loving forward! Reading through this project, one thing I'm not too keen on is having runtime checking of the UI. Being able to reload the UI is aprimary goal, which sounds cool, though I dont know the use cases besides rapid prototyping. I will say that one thing I very much enjoy about Rust and its libraries is that they're usually more about static checking of problems rather than deferring them to runtime. I think in looking for a GUI toolkit I'd want one that pushes for that as well. I don't think the benefit for rapid prototyping would be worth it.
A cool feature indeed, but why do you use a `&amp;` for the `println`? Another thing that feels weird, curly braces for macro calls, but that's probably a matter of taste.
You can also combine it with \`Iterator::step\_by\` to create non-overlapping windows. Unfortunately, this will make you skip at most \`n-1\` items at the end of the slice. \`slice.windows(n).step\_by(n)\`
No idea. I think it's tricky to get right (you need a much larger crew, etc). I don't know the details behind this decision, but my impression is that most confs do not live stream.
How good does this work?
Yeah, but it can cause a somewhat large hitch but I guess it's expected when you offset the position of each actor in the scene.
Thanks. I'm not in a hurry to implement it so i'll look at it when WASM support is done.
Isn't this what `slice.chunks(n)` solves?
I'm thinking about implementing a CLI application and/or cargo command which could try to deserialize the GUI and output any errors that occur, which would allow CI pipelines to verify the syntax, and also allow syntax checking as a custom compilation step. I haven't looked at the language server protocol, but perhaps a language server would not be too difficult to set up. What do you think about something like that? At this point though I feel that the syntax is easy enough to use, and since the GUI is reloaded in just a few milliseconds, any errors you make will quickly be fixed. Did you look at [the sample gui file](https://gitlab.com/DavidLyhedDanielsson/ruey/blob/master/data/testfile.gui.ron)? The sample application uses the notify crate to automatically reload the GUI on changes, which I've found very handy.
Looks pretty nice! I don't have any major complaints about the API design - big modules aren't necessarily bad, and it's always possible to put things in sub-modules and then re-export them as the module if things get too big. One thing which is a bit negative is that it's hard to tell exactly which structs I need to care about when approaching the API. After looking around, I can tell that `scryfall::card::Card` is an entry-point where I can make a lot of method calls, and probably what I want to be looking at first. But looking at the overall documentation, that isn't very obvious: `Card`, `CardFace`, `Price` and `RelatedCard` seem of equal importance, and there's no indication that I can actually call methods on `Card` to get results, and that the other three are just structures used for results. The easiest way to fix this would be to add more documentation! Particularly, examples of calling code, and an overview telling users what structs to look at to do various things. This is also nice to have even when things are more obvious looking at modules. Another alternative, which might or might not be right for the crate, would be to move the static methods for making API calls from `scryfall::card::Card` into `scryfall::card`, making them functions. This would put them front-and-center, and bring them out in front of the result type. But I can't say for sure if it'd be better? --- The other comment I have on the API design is that right now, all the structures and enums are pure-public. While this is nice, it also locks you in and makes adding new fields a breaking change. Having one private field per struct and `#[doc(hidden)]` variant per enum helps future proofing, and allows adding fields without it being a breaking change. See [futureproofing in the api-guidelines](https://rust-lang-nursery.github.io/api-guidelines/future-proofing.html#structs-have-private-fields-c-struct-private). Speaking of that, going through the [API Guidelines Checklist](https://rust-lang-nursery.github.io/api-guidelines/checklist.html) can be a good idea if you want to bring the total API quality up a notch. I don't see any glaring issues, but if you want, reading through the guidelines can be quite informative. --- Besides those things, I like it! The typed results look good to use, the code backing the API is solid and rusty, and the documentation is quite nice once I get down to the struct/enum/method level.
Ah, I only had a quick glance at [arewegameyet](http://arewegameyet.com/). Tons of libraries and frameworks on the way it seems!
No, pretty much every language that runs on a VM of some kind has an excellent dynamic linking story. It's really just native languages that suffer.
That's why I competed with Python.
I'd love to but I need a `MyWrapper` around the underlying file/socket (can't do with a raw `T: Read`). TBH I have more than one layer of wrappers here (separation of concerns, though I may have went overboard). What they do is basically split an incoming byte stream into frames, deserialize them and provide a peekable iterator over the frames. The peekable part is what makes the wrapper stateful (I can't just construct a new one from the underlying stream every time I need one), so there's where the `Rc&lt;RefCell&lt;&gt;&gt;` dance comes in as well. My file format is roughly: 1. Header 2. (optional, based on header) Data, Data, Data..., Footer 3. GOTO 1 Overall, what I hope to achieve is: 1. Given a `T: Read`, create an iterator returning `(Header, Option&lt;DataIter&gt;)`, where `DataIter: Iterator&lt;Item=Data&gt;` and also can return the footer after consuming all the data frames. The inner iterator will generally be consumed in full every time but if not, it will read and discard the data in `impl Drop`, so that the next read from the outer iterator will find the next header. 2. If the underlying reader supports seeking, my iterator should do so as well, so I can get any item I want by seeking to its header first (it's not a random access iterator but close, as I identify frames by the offset in the file, not by ordinal number). Now that I think about it (rubber duck debugging is the best), I could enforce the footer for every data stream (right now I'm trying to cope with not having one, which creates the peeking requirement). If I manage to do without peeking, the whole thing might be massively simplified and I might be able to just pass `T: Read` around, as you suggested.
&gt; error: failed to parse manifest at `/Users/dmitrizaitsev/test/rust1-test/Cargo.toml` Well, it's an empty file, so there's no surprise parsing fails. It tells you something related to the expected structure, but since you're in a tutorial, just put in what's told there (just as you did). &gt; either src/lib.rs, src/main.rs, a [lib] section, or [[bin]] section must be present That's pretty much it. The tutorial tells you how to make `src/main.rs`, and you didn't, so you hit this error. I suggest you start with the updated version of the tutorial, and follow the steps exactly, that should get you started. If you're interested in the details of `Cargo.toml`, see https://doc.rust-lang.org/cargo/guide/, but I suggest you skip this for now.
It is something vague for me. Obviously you need set properties of widget at runtime. `set_text`, `set_validator`, `set_enabled`, `set_toggle`. How it suppose to work, you serialize and deserialize some kind of json to achive this? If so, then you need 100% test coverage for your GUI, I don't think that `avoid recompilation` goal is worth it.
Thanks for the heads up.
Template instantiation isn't the biggest time sink in a C++ compiler. That gold medal goes to overload resolution. The reason templates are noticeable with regards to time needed to compile is because they are implemented in the header. This will be largely alleviated once C++20's modules become the norm.
FORTRAN also doesn't do name mangling, or at least older standards didn't. Not sure about something like FORTRAN 2015.
Why does this work: fn main() { let mut main_vec = vec![]; for num in 0..100 { main_vec.push(num); } } but this doesnt: use std::iter; fn main() { let mut main_iter = iter::empty(); for num in 0..100 { let iter_to_chain = iter::repeat(num).take(1); main_iter.chain(iter_to_chain); } } Error: error[E0382]: use of moved value: `main_iter` --&gt; src/main.rs:8:9 | 4 | let mut main_iter = iter::empty(); | ------------- move occurs because `main_iter` has type `std::iter::Empty&lt;i32&gt;`, which does not implement the `Copy` trait ... 8 | main_iter.chain(iter_to_chain); | ^^^^^^^^^ value moved here, in previous iteration of loop' Is there any way to avoid something like this: use std::iter; fn modify_iter&lt;T&gt;(main: &amp;mut impl Iterator&lt;Item=T&gt;, second: impl Iterator&lt;Item=T&gt; ) { main.chain(second); } fn main() { let mut main_iter = iter::empty(); for num in 0..100 { let iter_to_chain = iter::repeat(num).take(1); modify_iter(&amp;mut main_iter, iter_to_chain); } } Second question: If you only want an iterator of one element is there a simpler way than `iter::repeat(elem).take(1)`
Have you tried C++17 polymorphic allocators? I really like how they work, but so far only gcc 9 implements them.
Change the macros expansion engine to the experimental one from the settings(per project) makes it ultra faster for me.
&gt; It works the same here as in other languages that feature an iterator API. The fact that there’s no iterator *type*, only an iterator *trait* is a significant difference from almost every other language. From the languages I know, only C++ ranges API has the similar shape.
Indeed, I did not think of the 1 top-level item usecase, it makes sense now. Thanks for pointing out the release note from serde, it was very insightful. :)
What about other collections can be turned into slices? Anything with a Range impl?
Is there a crate to abort a program after a timeout? More or less like calling libc::alarm(), but cross platform?
This is awesome. I've been thinking about dabbling with some VST creation so I'm excited to check this out.
Yes, some sort of JSON is deserialized. Except it's not JSON, it's [Rusty Object Notation (RON)](https://github.com/ron-rs/ron), which is basically another flavour of JSON, YAML, XML, etc. Runtime configuration is done using providers. The [wiki](https://gitlab.com/DavidLyhedDanielsson/ruey/wikis/provders) has a short page on providers. The quick rundown is: let text = "Hello".to_string(); some_provider.insert("some_text_field_value", &amp;mut text"); And then you reference the value in the gui.ron file: ( type: "text", provider: "some_provider:some_text_field_value", )
There are only two games I know of where floating point bugs are noticed: Minecraft and Super Mario 64. In Minecraft, you have the famous "Farlands" and some jitteryness that happens as you get closer to them. You still have to go out of your way to find it though. In Super Mario 64, it causes a fish to eventually swim out of bounds in Wet Dry World. Again, no impact at all on standard gameplay.
I haven't used `polymorphic_allocator` specifically (due to lack of support as you mention), but it looks like it is pretty much exactly what people with specialized / heterogenous memory allocation needs usually end up doing anyway. As usual in C++, the interface is complicated a bit by non-obvious considerations with hard-to-understand rationales (like, what is a `monotonic_buffer_resource` even?), but I'm sure it's fine.
Discord
r/playrust
This is definitely not the subreddit you want. Normally I'd direct you to /r/playrust, but you're just going to get banned from there too.
Just FYI - your actix-irc link in the original post is 404'ing.
Did you look at the example in the crate? &gt; filesize abstracts platform-specific methods of determining the real space used by files, taking into account filesystem compression and sparse files. use filesize::{file_real_size, file_real_size_fast}; let realsize = file_real_size("Cargo.toml")?; // Save a stat() on Unix let also_realsize = file_real_size_fast( "Cargo.toml", &amp;std::fs::symlink_metadata("Cargo.toml")? )?; &gt; Now, please stop writing du clones that only take apparent size into account. How could this possibly be harder to use than what you already have in your code? You literally just plug it in and your program will work better for all the people using it, even if it isn't perfect (and it might be, I don't know how well it works).
&gt; I recall PyCon having something like that but I could be wrong. AFAIK pycon just posts the videos / replays fairly quickly (day after?) Kenneth Reiz floated "remote pycon" early this year but it was the other way around, a way of having remote *speakers* not attendance.
It's pretty much just vectors and arrays. Ranges are not backed by anything so you can't convert them to Rust slices (`&amp;[T]`), not without first "reifying" them to a vec of some sort anyway.
`monotonic_buffer_resource` is the simplest possible monotonic allocator. Apart from that, you also have `(un)synchronized_pool_resource` which is a multipool allocator. Essentially, it's the standardized version of https://github.com/bloomberg/bde/
Trying to build a Trait to abstract over many types of trees. You would only need to implement get_content() and children() and get many iterations and searches for free. Sadly the lack of impl Trait as return values of trait methods makes things not that convenient.
That'll make it unsafe when you dereference it. Just use a `Vec&lt;&amp;'static CStr&gt;`.
For a lazily evaluated version working with sny iterator, check out the itertools crate!
I wonder if this gets optimized properly with loop-vectorize and AVX512? If so, that’s awesome and probably runs at breakneck speeds.
I'll have a go at adding backward traversal of strings to the [unicode-linebreak](https://github.com/axelf4/unicode-linebreak) crate I was working on last week. After that I'll publish an updated version to crates.io.
The problem is that `x.chain(y)` doesn't actually _do_ anything to `x` iterator. It simply creates a new iterator which will return all elements from `x`, then all elements from `y`. Your `modify_iter` function is a no-op, and does not modify `main` at all. The reason the second one errors is that `chain` also, by default, takes the iterator "by value". Since `x.chain(y)` returns a new iterator which returns all values from `x`, it makes sense that `chain` moves `x`. You can't call `x.chain(y)` twice, because the first created chained iterator has already moved and is using `x`, so the second can't.
Ah yes, that branch got merged today. I'll update it, thanks!
One other important point is object safety. If you want your trait to be object safe (i.e. you can have `&amp;dyn YourTrait`), then it needs to take self by reference.
I don't know of any way for a general synchronous program. If you're working with async io, there's [`tokio::timer::Timeout`](https://docs.rs/tokio/0.1.21/tokio/timer/struct.Timeout.html), but that's not generally useful. I think it should be fairly simple to do using `std::thread::spawn`, `std::thread::sleep` and `std::process::exit`, though?
I released that after reading the docs. "Slices are a view into a block of memory represented as a pointer and a length." Although it's not clear to me why something that has indexes and iteration like a btree couldn't support the same methods. I guess a btree does not have a len, last and first that are accessible.
The problem is that a b-tree is not a single contiguous location in memory. Furthermore even for locations which are (eg hashmap) have locations in the middle which are empty / unset makes the conversion odd to impossible (i don’t know if hashbrown also has that, but even order-preserving hashmaps might use tombstones which have the same issue)
Putting the layout in data-files seems like a good strategy. It makes it easier to let translators/localizers update the GUI as needed for their language and locale. With Rust's slow compile times it also makes it much more pleasant to polish the GUI. It worked great for HTML and WPF for .Net seem quite popular.
Or the operations would be too slow without indexing the memory
Guys, the documentation linked in README is not working (404) - just saying. [https://rust-dsp.github.io/rust-vst](https://rust-dsp.github.io/rust-vst)
To be honest, that is the main reason I haven't been serious about learning rust yet. I want to learn it, I have the environment set up, but then I look at some tutorial and what do I see? fn main() { let world: &amp;'static str = "world"; println!("Hello {}!", world); } - Why `static`? - Why `str` and not `String`? - Is there a difference? - What's with `'` in front of `static`? - `&amp;`? Is `world` a reference? From a C++ point of view it looks like it is... - Why does `println` have a `!`? Reading the tutorial: - Oh, so `println!` is a macro... How do I define those? I heard they are more powerful than C macros. - Types can be inferred, so `let world = "world";` works, okay... - Unused function parameter is denoted as `_foo`, fine... - You're not going to talk about all those weird symbols in the declaration and function parameters? Reference: "Rust for C++ programmers" lesson 1: https://github.com/nrc/r4cppp/blob/master/hello%20world.md
I would wrap it in a closure that returns Option&lt;()&gt; and call is_some() on the closure
It may look more promising but will have some problems with cancellation (not being able to free the io buffer of the future is dropped abruptly). Cf. eg. http://www.randomhacks.net/2019/03/09/in-nightly-rust-await-may-never-return/
The Rust `std` is full of these gems. It's awesome!
Yes, that's what it was, something like day after videos, at the very least. Not live, but you didn't have to wait weeks, at least.
Star Citizen had to switch to f64 because they were lacking precision for planet-to-planet flights/landings.
The great thing is that the developers are listening and the documentation [is getting improved](https://github.com/rust-lang/rust/pull/61878).
So 2055 then? Old habits die hard, and that's especially true with C++. Most C++ devs I talk to are not even on C++11 yet, or they are but don't use it idiomatically (i.e. new/delete everywhere instead of RAII, no const correctness, ...).
That probably depends on the industry branch of people you're talking with. Google for open source project has a rule to require the latest standard that is 5+ years old, so Abseil is switching to C++14 right now. My hobby project will be switching to C++17 next year. I've heard quite a few companies engaging a switch to C++17 this year. &amp;nbsp; Now modules are a beast that will need to be tamed first and it will take a lot of time to get widely adopted, but I'm optimistic because MS and Google report up to an order of magnitude compile time decrease, which means companies will need smaller clusters used for compiling and developers will spend more time doing actual job, which means more money for a company - making modules a feature that should be easy to sell to CTOs.
Neat idea! It seems like it would give false removal recommendations to source files behind conditional-compilation flags (e.g. the sort usually gated by cargo feature flags). A slower, more advanced version of the script could attempt some/all of the feature-flag permutations rather than just the defaults.
Putting in some more work into [SetMod](https://github.com/udoprog/setmod). It's a Twitch bot that I'm building mostly on stream for myself and a couple of other streamers. It's mostly asynchronous with async/await, so nightly only right now.
No luck :/ I need something owned so I can return it in an object. I can't use the `T: Read` itself as I need to hold on to it. I can't use `Rc&lt;RefCell&lt;T&gt;&gt;` as then I cannot cast it to `Rc&lt;RefCell&lt;dyn Read&gt;&gt;` (see https://users.rust-lang.org/t/rc-refcell-box-struct-as-rc-refcell-box-trait/7719). A `RefMut&lt;T&gt;` would express the idea best (I think) but it 1) requires a lifetime that I can't get and 2) not sure if that's convertible to `RefMut&lt;dyn Read&gt;` anyway. It seems that I have it compiling most of the way but right now the major struggle is having a single function that would return objects using different underlying reader types (e.g. for reading from compressed/uncompressed files)
This looks outdated, as the `ClientWriter` struct appears to no longer exist.
I agree, but I'm not sure if it's worth the effort. Also, that wouldn't have removed all false positives, as some crates may have arch/OS-dependent compilation. My best bet would be to, given module `file.rs`, do full-text search for `mod file;` and for every result ask RLS or rust-analyzer whether this `mod` refers to the file I'm checking (there may be multiple `file.rs` in the project). Even then some crates using `build.rs` scripts could be a problem.
Hi there, I've asked a (probably beginner) question on r/learnprogramming , maybe you want to have a look at it : [https://www.reddit.com/r/learnprogramming/comments/c1l5ee/rust\_how\_to\_properly\_unbox\_a\_value\_to\_pattern/](https://www.reddit.com/r/learnprogramming/comments/c1l5ee/rust_how_to_properly_unbox_a_value_to_pattern/)
I disagree. It's not about easy and hard. It's about correct and incorrect. If you do not support text shaping, you do not support text rendering. Unless, you're rendering a specific/hardcoded text with a specific font. Which is fine for games, but not for GUI. It's like not supporting Unicode - absurd.
My guess is the return type arrow was made to make it feel more like Haskell and other functional languages. Rust is trying to be more functional than a typical procedural language, and looks like this arrow was one of the steps.
I imagine it means that those libraries are well-optimized for maximum performance
No. The fact that a library uses unsafe in its implementation does *not* mean that Rust is not mature enough in that area. That being said, numerical computation isn't quite Rust's strongest side. I mean, for the kind of computation with 2D or 3D points, vectors and matrices that happens in graphics, physics or games, Rust is solid. But for more general scientific computation (like N-dimensional matrices or generic numerical types), the fact that Rust doesn't have const generics, generic associated types or implied bounds is quite annoying.
I'm not sure why you're of the opinion that having unsafe code necessarily means immaturity, the standard library makes plenty use of unsafe. I assume both of these crates make use of unsafe to optimize some cases, like creating uninitialized structs.
&gt; IMHO, any GUI library must start with a text rendering. This is, as you note, your own opinion. Others may argue that they would rather focus on getting the data-flow right, and only when they are confident in the architecture, polish the details. There's more than one way to reach the same destination.
It does, but the implication is one way. In other words, if you `impl From&lt;Vec&lt;u8&gt;&gt; for MyType`, then Rust will arrange for `impl Into&lt;MyType&gt; for Vec&lt;u8&gt;` to exist (with the types swapped). To get both conversion directions, you need `impl From&lt;MyType&gt; for Vec&lt;u8&gt;`; Rust will then arrange for `impl Into&lt;Vec&lt;u8&gt;&gt; for MyType` to exist. You can also `impl Into&lt;Vec&lt;u8&gt;&gt; for MyType` directly, which will *not* cause `impl From&lt;MyType&gt; for Vec&lt;u8&gt;` to exist. This is why the docs recommend a type constraint of `Into&lt;T&gt;` in preference to `From&lt;T&gt;` - the orphan rules mean that you can't always make `From&lt;T&gt;` exist for a type.
I'm not sure, if I understand correctly, but the ? operator will happily convert Result types as long as there is a valid conversion for the Err Variant. The method in question could return just `Result&lt;(), Box&lt;dyn Error&gt;&gt;`. Later you can check with is\_ok(), if you don't care about the error. &amp;#x200B; \&gt; Another thing I am doing while printing the final prompt is something like: I'd use the [std::write](https://doc.rust-lang.org/std/macro.write.html) macro to write directly to the String.
`unsafe` is part of the language. Keep in mind that in C/C++, your whole program is implicitly surrounded by the equivalence of an `unsafe` block.
In Rust, unlike in almost any other language, I often try to do a certain thing only to then find out it's impossible (for now) in safe rust. In C++, if something isn't part of the language yet, you can usually work your way around it by using some template magic or some raw pointer manipulations. But in Rust, every function that you expose in an API has to be safe. And if the type system doesn't support a certain thing yet, there's often simply no way around it. If the thing you want to do requires generic associated types or some other higher-kinded type stuff, what you want to do is basically impossible. If the orphan rules say no, that's also a hard no. If you want to use const generics, again you're out of luck.
If your needs are relatively modest (no more than 4 elements at a time), the [tuple_windows](https://docs.rs/itertools/0.8.0/itertools/trait.Itertools.html#method.tuple_windows) method in Itertools will let you iterate over a sliding window into iterator with `Clone`able items. Since it returns a tuple instead of a slice, it also makes it easier to destructure (e.g. `for (a, b, c) in some_iterator.tuple_windows() {}`)
&gt; const generics, generic associated types or implied bounds What are these and why are they important to scientific computation?
In my opinion the existence of `unsafe` in a codebase means one of a few things: 1. The code has been carefully benchmarked and optimised using unsafe where doing so produced important and measurable performance gains. Clues for this one are: benchmarks exist and regress when you undo an optimisation. The optimisations are commonly stuff like `mem::uninitialized()` prior to filling in new allocation. 2. The code has been optimised blindly, 2fast2furious style. There's a can of nitrous bolted to every function whether it's hot or not. There's tons of `mem::transmute` even for tiny structures. There might be `mem::uninitialized()`-style initialisations for allocations that happen once per program. Clues for this one: no benchmarks, unsafe bits are liberally spread around the code and have no justification in comments. 3. The code is doing something fundamentally unsafe, like FFI. This is a common one, and easy to spot. 4. The code has been oxidised from another source base, and the conversion is incomplete. This is also easy to spot from large-scale use of pointer types, which are actually quite rare in hand-written rust.
Its seems that you have the wrong idea about the meaning of unsafe. I had it too when I first started to learn Rust. By Unsafe you can understand anything which the compiler can't keep track to uphold the guarantees. For example, dereferencing a raw pointer its an unsafe operation, because the memory address couldn't exist and the compiler can't know it. So in these case, the developer is responsible to check that is a valid memory address and uphold by himself some guarantees.
But you never dereference it, you just give it to [ash](https://docs.rs/ash/0.29.0/ash/vk/struct.InstanceCreateInfoBuilder.html#method.enabled_extension_names) and it expects a `&amp;[*const c_char]`, `c_char` and `i8` being the same. And the compiler won't go from `&amp;[&amp;CStr]` to `&amp;[*const c_char]` without help.
Brilliant!
Not sure about the latter two, but *const generics* are types and functions generic with regards to constant, compile-time values instead of types (and lifetimes). Today you can use Rust generics to express items generic over types and lifetimes like Rust collections and wrapper types, like `Vec&lt;T&gt;` (vector containing values of type `T`), or `Ref&lt;'b, T: ?Sized + 'b&gt;` – a structure wrapping a reference to type `T` with lifetime `'b`. With const generics you’d be able to also be generic over values, especially integers, to express eg. a generic `Matrix&lt;T, N, M&gt;` type to represent a `N` × `M` matrix of values of type `T`. This way you could use single type for any matrix operations, and just using the type system ensure that you can only eg. multiple a `Matrix&lt;T, 3, 5&gt;` by a `Matrix&lt;T, 5, M&gt;` and the result will be `Matrix&lt;T, 3, M&gt;`. Without const generics, numerical crates have to use hacks like declaring dummy types like `U1`, `U2`, `U3`, etc. for all possible sizes of vectors and matrices to be able to provide nice APIs for matrix computations. See [matrix API description of `nalgebra`](https://www.nalgebra.org/vectors_and_matrices/) and a [`typenum` crate](https://docs.rs/typenum/1.5.1/typenum/).
Minecraft also (used to) have issues due to using ints instead of floats in their network protocol so they got both sets of issues. The loss of precision from the conversion is what caused mobs to visually explode out of mob farms and item drops to appear in the wrong spot client side when they were on the edge of a block. They compromised on this by making entity teleport packets use doubles for the position and only using their short format for relative movement. They then have the server periodically send teleport packets to ensure the client stays mostly in sync. Lets them have the bandwidth savings from the short format most of the time while mostly removing the issues otherwise as the entities most likely to exhibit bugs from this format don't move much or at all.
Are there any good documentation/tutorial ressources on VST creation in Rust?
[Const generics](https://github.com/rust-lang/rfcs/blob/master/text/2000-const-generics.md), [implied bounds](https://github.com/rust-lang/rfcs/blob/master/text/2089-implied-bounds.md), [generic associated types](https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md). In short, those are features that streamline working and allow to efficiently express more complex concepts (such as N-dimensional matrices) as well as more compile-time evaluations.
The reason, why I got the impression, is \`Rust\` is for \`memory safety guarantee\` besides zero cost abstraction etc., And, as far my understanding goes, \`unsafe\` releases the \`memory safety\` lock during compile time opening the gates for the developer to take care of memory safety which is nothing less than what \`C/C++\` does. Under such a scenario I feel like \`Rust\` is similar to \`C/C++\`.
Oh yes, I forgot to mention str vs String! Granted this is a huge issue in Haskell too. String vs lazy Text vs strict Text vs several others...
Rust's motto is not to ban `unsafe` at all levels. There are some things that just cannot be handled safely (allocations for example, and more generally the internals of collections). Here `nalgebra` and `ndarray` are low-levels implementations wrapped in a safe API. What Rust brings you is that you can use these crates and not worry yourself about using `unsafe`, or questions like allocations or safety memory in general, because there are already part of the contract API of the crates. This is where Rust differs from C or C++.
I'm an absolute Rust noob, would you mind explaining why these things are wrong?
In response to "but there is unsafe somewhere in my dependencies so why bother?" I recommend reading: [https://www.reddit.com/r/rust/comments/a7kkw9/looking\_for\_someone\_to\_change\_my\_view\_on\_this/ec3r38n/](https://www.reddit.com/r/rust/comments/a7kkw9/looking_for_someone_to_change_my_view_on_this/ec3r38n/)
For many applications, logging is not a substitute for a good debugger.
Those all sound like reasonable mitigations, but it's a lot more extra work to support a feature that I dont find compelling. A GUI is already a lot of code, so adding this extra stuff will only increase the maintenance burden. I'm a tech writer and I'm also very focused on the new user experience. And having the default experience leading users to runtime failures rather and compile-time failures (which would surprise me given how Rust libraries tend to work) and then making the compile-time checking require new tools while also making CI more complicated to configure, would turn me away. Again, this is just my opinion. I'm sure there are users who will value the runtime reloading, but to me I don't see it as a benefit given the tradeoffs. However, this library is still nascent and I'm excited to see where this library goes!
Wow, thanks for a very thorough explanation. Do you know why Rust wouldn't have something like that? It seems like Rust's love of speed would be appealing to those in the scientific community.
formatting macros should borrow value implicitly, so there's no need to do this. And parens/brackets/braces in macro calls are all equivalent, it's just that they tend to be used to signify meaning of macro - function-like/sequence-like/block-like...
I have a simpler model to think of Rust's memory safety: It's just like static typing, at the boundary (I/O), data is just a bunch of meaningless bits, then you need to parse it, convert it, and most importantly abstract into the type you needed. The rest of your application can rely on the contracts provided by the type. Now, if there's an error in your parser code that let invalid data passed into your data structure, do you add check into your consumer function or you go fix the parser code? This is the different between C/C++ and Rust, the type system clearly declares a resource safety contract: move means you get to drop it or return it, `&amp;` means there can be others holding this same resource, `&amp;mut` means you are the only one who has access to the resource. Whereas in C/C++ world, the way to communicate those contracts will have to be team meeting, code comment, documentation, and a lot of CVEs proved they are not very effective. And usually, the user of an API have use assertion or runtime check to make sure that they are using the API correctly.
Formatting macros should borrow values implicitly, so you don't need to do that. And parens/brackets/braces, even when all equivalent in macro syntax, are usually used to signify meaning - function-like/sequence-like/block-like.
I guess this [is in London, UK][1]? It's probably a good idea to be as clear as possible about geography when talking to the Internet :-). [1]: https://www.meetup.com/Rust-London-User-Group/
I'll probably put some more work into [js_int](https://github.com/jplatte/js_int), a crate I built last weekend that provides integer types that are limited to the range of exactly-representable by `f64`. I created the crate for ruma, because the matrix spec it implements has uses this as its definition of an integer due to compatibility concerns with varying JSON libraries (this all comes from the fact that JavaScript only has one `Number` type that represents everything as a 64-bit float). I might also continue my work on [allowing non-capturing closures to coerce to extern fn pointers](https://github.com/rust-lang/rust/pull/61528) or write an RFC for that.
Looks like partition ([https://clojuredocs.org/clojure.core/partition](https://clojuredocs.org/clojure.core/partition)) &amp;#x200B; I recently wrote this for Elvish. ([https://github.com/doubleagent/rivendell/blob/master/fun.elv#L346](https://github.com/doubleagent/rivendell/blob/master/fun.elv#L346), [https://github.com/doubleagent/rivendell/blob/master/lazy.elv#L223](https://github.com/doubleagent/rivendell/blob/master/lazy.elv#L223))
Thanks, this solution works. A lot of boilerplate, but it works.
&gt;`impl&lt;R: Read + Seek&gt; Seek for Reader&lt;R&gt; { ... } // I need both seekable and non-seekable Readers` I have the feeling this is the problem. I don't think you can have both non-seekable and seekable Readers. The trait is either implemented or not. Whatever the situation may be, it needs to be solved at compile-time. &amp;#x200B; Would you have a minimal example of what you want to do, so we can have a better idea? How are you intending to use it? What is the contract you're expecting?
Rust doesn't have it because it's not done yet. It's quite a complicated feature with some far-reaching implications, so they're taking their time to get it right.
Contributing to rustc for the first time! This morning, I'm working on keeping my [pull request](https://github.com/rust-lang/rust/pull/60732) to enable the [`arbitrary_enum_discriminant`](https://github.com/rust-lang/rfcs/pull/2363) feature up-to-date. I'm also submitting a camera-ready to [ICER](https://icer.acm.org/) and starting work on this summer's improvements to [Pyret](https://www.pyret.org/)'s IDE!
I guess the reason is that it is not vital for the language to be productive (existence of the `typenum` crate shows that the community can create good enough work-arounds with what we have) and that const generics are a pretty huge language feature – you need to resolve a lot of issues to make them work well with the rest of the type system – come up with the syntax for it, decide what types can be used for const generic values (restrict it to unsigned integers? if so, which ones? only `usize`? what about `u8` or `u32`? why not signed integers? what about `char`s…?), decide rules for evaluating them – what expressions are valid as generic parameters (is it ok to create a `Matrix&lt;T, 2*2, 3*2&gt;` or only `Matrix&lt;T, 4, 6&gt;`?), if expressions are allowed, is it possible to call functions in generic parameters (is it ok to do `Matrix&lt;T, 2.pow(2), 3&gt;`?)? What const values should be considered equal (would types `Vector&lt;T, 2 * 2&gt;` and `Vector&lt;T, 2 + 2&gt;` and `Vector&lt;T, 4&gt;` the same or not?)? The last one apparently was a big issue. Most (if not all) those issues have been resolved and [the *const generics* RFC has been merged](https://github.com/rust-lang/rfcs/pull/2000) but it’ll still take time before it is implemented and usable in stable Rust. You can also read about the issues the language team was facing on [the internal forums thread about the feature](https://internals.rust-lang.org/t/lang-team-minutes-const-generics/5090).
They can even be 2 bytes, but it's currently something being worked on (see the rust-avr project, avr pointers are 16-bit).
Javascript / typescript lacks the concept of both windows and slices in its std, but they can be implemented in a few lines of code: class Slice&lt;T&gt; { private _arr: T[]; private _ini: number; private _len: number; constructor(arr: T[], ini: number, len: number) { this._arr = arr; this._ini = ini; this._len = len; } get(i: number): T | null { if (i &gt;= this._len) { return null; } else { return this._arr[this._ini + i]; } } [Symbol.iterator](): IterableIterator&lt;T&gt; { let self = this; function* gen(): IterableIterator&lt;T&gt; { for (let i = 0; i &lt; self._len; i++) { yield self._arr[self._ini + i]; } } return gen(); } to_vec(): T[] { let vec = []; for (let elem of this) { vec.push(elem); } return vec; } } function* windows&lt;T&gt;(arr: T[], size: number): IterableIterator&lt;Slice&lt;T&gt;&gt; { if (arr.length &lt; size) { return; } for (let ini = 0; ini + size &lt;= arr.length; ini++) { yield new Slice(arr, ini, size); } } function main() { let arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]; for (let win of windows(arr, 3)) { console.log(win.to_vec()); } } main(); // [ 1, 2, 3 ] // [ 2, 3, 4 ] // [ 3, 4, 5 ] // [ 4, 5, 6 ] // [ 5, 6, 7 ] // [ 6, 7, 8 ] // [ 7, 8, 9 ] // [ 8, 9, 10 ] Still Rust is really cool as there's no lifetime and borrow checker to ensure the validity of these slices, any modification to the underlying array in parallel to the iteration may cause puzzling errors.
I love the Rust community so much. I'm ignorant of all these things and yet there always seems to be someone willing to explain it to me. Thanks!
You could add: 5. The code implements a new container that isn't present in the standard library, as is the case here (matrices and n-dimensional arrays).
/r/playrustserver
There's a "beat mario 64 in the fewest presses of the a button" challenge, and one of the most advanced strategies involves triggering a floating point bug in the Wii Virtual Console port of the game. It handles rounding slightly differently than every other version...
We accepted the design in September of 2017. It took a few years to even settle on that. Then, there's been a \*ton\* of implementation work to be able to actually implement it. The absolute basics work on nightly as of a few weeks ago. It's something that's very much been desired, but practical issues make it tough. Soon though!
Implied bounds (details linked below) matter because these kinds of programs tend to have a \*lot\* of bounds, and so reducing the need to repeat them makes writing the code a lot easier.
&gt;And, as far my understanding goes, \`unsafe\` releases the \`memory safety\` lock during compile time Yes and no. Unsafe doesn't turn off anything; it adds extra unchecked options.
Livestreaming is \*expensive\*. Like, really, really expensive.
Until somebody audits the code and publishes the result, or unless you do it yourself, you'll never know if these unsafe are unsafe. But you'll have lots of opinions on the matter 😊
Semver maintainer, both for Rust and the spec, here. Semver doesn't specify matchers \*at all\*. Rust's implementation, and most others, have this behavior as part of how they define their matchers. Putting matches in the spec is a future goal of mine. It's gonna be a while, though.
You can take a look at the tutorial I wrote [here](https://vaporsoft.net/creating-an-audio-plugin-with-rust-vst/) although parts of it may be slightly out of date.
That is an unfortunate side effect of the move. I have to re-setup our CI again so it can have the correct permissions.
`ndarray` is, at its core, a library implementing a data structure. It comes equipped with a lot of useful functions for scientific work and implementing linear algebra on top. Because it is a library implementing a data structure it's not surprising that it has lots of unsafe code, because a lot of its operations are directly on memory regions, which are taken care of by a struct. This is a step lower than the abstraction that the borrow checker acts on, making it necessary to use `unsafe` if, for example, you want to act on disjoint memory locations at the same time, which however are addressed by a common name. The `split_at_mut` function of `std::slice` is similar to that. Also, for performance reasons `ndarray` frequently calls out to external functions like BLAS or LAPACK routines, which are also by definition unsafe. You could do most of these operations in safe rust, but probably with some performance loss (or lots of extra work).
Hi there and welcome to the team!
Thank you, and for everything the org has done for the rust audio space! Looking forwards to the future.
Thanks, regarding \`std::write\` you mean something like this: &amp;#x200B; [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=b41661be121f2c5401a0dff6b700ada3](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=b41661be121f2c5401a0dff6b700ada3) use std::fmt::Write; fn main() { let mut res = String::new(); for i in 0..5 { write!(&amp;mut res, "{},", i).unwrap(); } println!("{}", res); } I modified the example from: [https://stackoverflow.com/a/30714382/1135424](https://stackoverflow.com/a/30714382/1135424)
Completion-based APIs should work fine with buffers being owned by the reactor, rather than the future itself, for the duration of the operation. If the future is dropped, the buffer is freed immediately upon completion rather than returned to the future.
Oh yeah, how'd I forget about that one. For those curious, https://www.youtube.com/watch?v=MFxJuq3FRgI gives an explanation: On non-Wii VC, floats round towards nearest while on Wii VC, it rounds towards zero. This allows a platform to raise into the air slowly (takes three days before they can get off it).
&gt; Although it's not clear to me why something that has indexes and iteration like a btree couldn't support the same methods. Slices are *contiguous* memory blocks, BTree isnt, it has separate heap allocated nodes.
I'm a frequent contributor to nalgebra (most recently: a memory-safety related contribution). I think the other commenters have adequately explained why `unsafe` has nothing to do with maturity. If you have any questions about specific instances of `unsafe` in nalgebra, I'm happy to be of help!
Hi folks, Is there any way to write a generic function which accepts a `FnMut` type with any number of arguments? I can do this today on unstable rust with `#![feature(unboxed_closures)]` using the raw syntax for the `FnMut` trait, since its arguments are specified as a tuple: fn frobnicate&lt;Args, F: FnMut&lt;Args, Output=i32&gt;&gt;(f: F) { } Unfortunately I can't see any way to express this using the trait's stable syntax sugar, which is `FnMut(Arg0, Arg1) -&gt; Output`. Any ideas?
Ah, that looks great! I'll certainly keep that one around! Also, I didn't know macros were that easy in Rust, I'll certainly look more into that
As I am interested in the inner workings of rust GUI toolkits, do you have an explanation on how you handle widgets? Are widgets arranged in a tree structure? How do you handle mutability and events? Can widgets reference themselves? AFAIK there is still lots of experimentation going on in this space, so it is interesting to know about new projects.
&gt; Formatting macros should borrow values implicitly, so you don't need to do that. You assuming he passed arguments by reference. That's not what he's doing; this is: &gt; &amp;println!{"[{}, {}]", window[0], window[1]};
AFAIK you cannot do this as the static type system prevents something like this from happening. How would you call the function if you don’t know the number of arguments present?
AFAIK you cannot do this as the static type system prevents something like this from happening. How would you call the function if you don’t know the number of arguments present? Waiting for it to become stable and using the tuples seems to be your only option.
By now, you've got enough content for your own Rust MOOC
Ah, ok. That clears things up a bit, thanks.
Hehe, maybe one day! The tricky thing is finding the necessary spare time, as I am in theory also writing a Doctoral thesis over the next 12 months
\&gt; The O'Reilly book seems to me to be primarily targeted at C and C++ developers... In some ways "yes" and in other ways "no". They make a lot of comparisons (especially in the beginning) to C/C++ code, but they also reference Python/JS etc. a lot in the sense of "If you're coming from Python...". &amp;#x200B; Personally, I found that they struck a perfect balance of "we need to talk about memory..." and "keep it high-level enough..." for people like me whose professional experience is solely with dynamic, garbage-collected languages. Meanwhile, there are a lot of details that The Book just didn't have enough depth in to help understand/get over Rust's hardest learning points.
Yes that is what I meant. That stackoverflow post seems outdated though, these days you can implement [https://doc.rust-lang.org/std/ops/trait.AddAssign.html](https://doc.rust-lang.org/std/ops/trait.AddAssign.html) for the += operator (and String does implement this trait). The write! example is still good, I think.
What was the reason behind trying to hide the concept of items in the first place? Trying to simplify the explanation for newcomers? I probably wouldn't talk about items/statements/expressions at the beginning (even when talking about the AST in a talk I only talked about expressions, papering over items/statements, but I called out that it was an incomplete explanation), but it would be a good topic to revisit in the later chapters in order to incrementally improve the reader's mental model.
Items are jargon, and not super particularly relevant to learning the language. The statement/expression thing is extremely relevant, though.
This is great news! This issue in Rodio could use input from someone in RustAudio: https://github.com/tomaka/rodio/issues/227 About the sub-reddit, Is there really a need for /r/RustAudio when there’s already a Discourse forum? You’ll risk one taking oxygen from the other, ultimately strangling both communities.
I agree that it’s a very exciting time in Rust GUI land! I am working on tests, docs, and benchmarks for the core state and lifecycle pieces of moxie and will be writing about that soon. I do want to build my own framework(s?) — who doesn’t?! But my overall hope is to provide useful community infrastructure which can be reused in many GUI toolkits. I will be eagerly soliciting feedback from anyone who wants to use/offer a declarative [React-hooks](https://reactjs.org/docs/hooks-intro.html)-inspired API (also similar to Jetpack Compose or SwiftUI, but-I hope-Rustic) for whichever UI runtime they are using or building.
Can't echo enough other sentiments regarding the quality of *Programming Rust.* *The Book* is absolutely a great place to start. Aside from being free, it was (for me) a great introduction to a lot of the uniqueness and selling points of Rust and helped me to start thinking in 'the Rust way'. The problem I had was that it did not go into enough detail (for me, at least) to really help consolidate knowledge around ownership, borrowing, lifetimes, traits, etc. *Programming Rust* really shines here. My experience is mainly Python and JS, and this book had the detail I needed to really start jumping over a lot of the hurdles I'd been experiencing before, but it also felt approachable despite my lack of systems language (or even, for the most part, statically-typed, compiled languages) experience.
Creating a gui crate based on Containers and recursions instead of nodes. For now it has very fast perfomance and low cpu-memory. I called it [trgui](https://github.com/mrgaturus/trgui), i don't upload the examples yet
You could include it in the binary using `include_bytes`. If the assets are fairly large, this will make your binary fairly large. Otherwise you'll just have to distribute it with your binary in an archive or package format. You could automate this with a post-build script if it's a pain point for you. For your specific case, if your font is a font that's found on most systems, you could try searching for it in `/usr/share/fonts`.
The first version is more flexible because it lets you write "consuming" (de)serializers if you need them. It's also nice when implementing a giant trait, like in Serde, because you don't type `&amp;mut` as many times ;).
Continuing on with /r/roguelikedev's tutorial with libtcod. I have been doing it in rust and using `specs` to handle the entities instead of the big vector that the tutorial uses.
Amounts of unsafety in ndarray are [not reassuring](https://i.imgur.com/Ai3gyRf.png), but for nalgebra, `cargo-geiger` readings are [off the charts](https://i.imgur.com/zqKAeIl.png), and I genuinely can't tell if all of that unsafety is truly required or it's just Actix all over again. So I think OP's question still stands - why do they have so much unsafety?
Is there a nicer way to update a local variable name after doing an in-place mutation with a function that returns unit than just reassigning below the mutation to avoid assigning () to the new variable? Instead of : fn asdf() { let mut a : String = String::new(); mutate_returning_unit(&amp;mut a); let a_prime = a; another_function(a_prime); ... } Something closer to fn hjkl() { let mut a : String = String::new(); let a_prime = mutate_returning_unit(&amp;mut a); another_function(a_prime); ... }
Well, that's a good data point. I am very much one of those "think about how this abstraction is implemented" types, so the book seemed well tailored to my specific background; I wanted to give a fair assessment of why that won't necessarily be true for everyone, though.
I made [a slight edit](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=5cfa45ab5eea49b588b45e126390200d) to my playground which permits specifying a default value.
Nice, I liked it!!! The README is a little too much, I think most of it should go to github wiki. &amp;#x200B; Also, I would like to test it out and maybe add Haskell, Julia and Ocaml templates
Hey all, I use [tty-clock][0] fairly often and thought it might be fun to write my own digital clock in Rust. I think it now has enough features to be worth sharing, but I did run into some questions along the way, if anyone has any input: 1. What's the best way to restore the user's original terminal state, including all text? Currently I'm clearing everything, which seems intrusive. 2. Is there a simpler way to handle user input than manually setting VMIN and VTIME and polling `stdin`? Additionally, I was originally using the [termion][1] crate to handle things like raw mode and escape sequences, but raw mode also turns off signal translation (e.g. CTRL-C), and [`AsyncReader`][2] seems a little heavyweight for a simple clock program that doesn't expect to receive user input very often. So after some research, I ended up interfacing with libc directly, and would appreciate any vetting of unsafe code! [0]: https://github.com/xorg62/tty-clock [1]: https://github.com/redox-os/termion [2]: https://github.com/redox-os/termion/blob/master/src/async.rs
Yeah, I kinda dumped all the docs into the README for now...I'll create a proper wiki next. Sure, go ahead and try it out!
&gt; The optimisations are commonly stuff like `mem::uninitialized()` prior to filling in new allocation. Which, by the way, is a [terrible idea](https://gankro.github.io/blah/initialize-me-maybe/). And it's a dubious optimization because almost always `vec![0; len];` is exactly as fast because it requests already-zeroed memory from the OS. There is no tooling to reliably detect this class of bugs in Rust, so once you add `mem::uninitialized()` to your program there is basically no way to tell if you're using it correctly or not. I have found a [real-world vulnerability](https://medium.com/@shnatsel/how-ive-found-vulnerability-in-a-popular-rust-crate-and-you-can-too-3db081a67fb) in otherwise good code that dabbled in `mem::uninitialized()`. I only managed to do that by writing a [custom tool](https://github.com/Shnatsel/libdiffuzz), but it still doesn't catch all the bugs. `mem::uninitialized()` itself is now *deprecated* because it's a terrible idea. Don't do this.
Thanks for your quick response! While working on the same problem, I've come across another issue. This code triggers error E0207: "the type parameter \`T0\` is not constrained by the impl trait, self type, or predicates" trait Foo {} impl&lt;T0, T1, F: FnMut(T0, T1)&gt; Foo for F {} However, this code does work: trait Foo {} impl&lt;T0, T1&gt; Foo for Box&lt;dyn FnMut(T0, T1)&gt; {} I'm confused by the discrepancy. Why does the compiler accept the second impl but reject the first? Is there any way to make the first impl work, without introducing dynamic allocation or trait objects?
&gt;https://doc.rust-lang.org/std/ops/trait.AddAssign.html If I am right, I could use `+=` to append to the string but still need to use `format!` and `as_str()`, for example: fn main() { let mut res = String::new(); for i in 0..5 { res += format!("{},", i).as_str() } println!("{}", res); } For now, I will implement the `write!` but curious to know better alternatives.
The closest thing I can think of is let a_prime = { mutate_returning_unit(&amp;mut a); a }; but if your auto-formatter doesn't keep that expression on one line there really isn't any conciseness advantage.
Because the language is nice and easy to learn enough so people don't feel the need to join x y or z, whereas with Rust, you need to check google/reddit/stackoverflow for what ever shit you want to do, or to decipher the cryptic compiler error messages you get
I’m having trouble starting rust each time I try to play. I’m always met with a yellow screen when I try to load in and it usually crashes before or after I get to the main menu. Plz I need help
&gt; What's the best way to restore the user's original terminal state, including all text? Currently I'm clearing everything, which seems intrusive. You usually run your application in an "alternate" terminal. Both termion and crossterm support this feature.
You have a generic named F and you are implementing the trait on a struct also named F in the first example
I'm afraid you'll have to do per-object locking one way or another, so you will end up with `SomeCollection&lt;Mutex&lt;YourObject&gt;&gt;` or an equivalent construction, where SomeCollection is `std::HashMap` or `ccl::dhashmap` or `crossbeam::SegQueue` depending on your requirements. And use Mutex from parking_lot to get `try_lock()`. If the amount of objects is known in advance, you can drop the inner mutex: use SomeCollection&lt;YourObject&gt; and move the object out of the hashmap while it's in use, but put it back in while it's available. This way absence of object in the hashmap signals that it's "locked". As long as your hashmap stores pointers to objects instead of objects themselves, no memory will actually be copied to move them in and out.
Wrong sub. You want r/playrust
But that's not usually a problem; it's common in blanket trait implementations. For example, this compiles: trait Foo {} impl&lt;F: FnMut()&gt; Foo for F {}
That I'm unsure of. It seems as though the overlap between people who use Reddit and those who wish to use Discourse could be smaller than I imagine, given the requests I've seen for a dedicated subreddit. However, your point is definitely the biggest reason why I haven't created one already. Our Discourse instance (thank you for it, by the way!) seems to be more geared towards crate development, whereas a subreddit might be a more casual place to share project progress or content made with custom audio plugins. The Rust Audio community is certainly smaller than Rust as a whole, or even the Game Dev side of things, so I don't want to risk suffocating one community over another.
I'm leaning towards moving boxed trait objects out of the hashmap. I'll maintain a separate list of the keys that have been moved as opposed to just deleted, so we can tell the difference between something that's locked and something that's gone. The issue I have now is how to implement multiple concurrent readers. I looked into returning a [RwLockReadGuard](https://amanieu.github.io/parking_lot/parking_lot/struct.RwLockReadGuard.html), but the lifetimes get hairy real fast and that's just inherently dodgy. I guess we could go back to callbacks?
That falls under point #1
Interesting. I have no idea then, perhaps it’s something to do with the trait bounds being incompatible with the implementation then? Probably not, weird error, wish I could help you out.
Maybe you could ask klangner and include [https://github.com/klangner/dsp](https://github.com/klangner/dsp) into your community.
What is special about containers that make them impossible in safe rust?
From what you've described, it sounds like you're mutating the value type's state, rather than the structure of the hashmap. Do you need to to mutate the hash, or can you just implement interior mutability within the value type? If you can solve this by locking parts of your large value objects, then you can control the locking scheme and the lock granularity. Is there a way for you to farm out the object mutation to a separate thread pool where blocking isn't as harmful? If you were using actors, I'd suggest a pool of sync actors (actors that run in a separate thread pool that is sized to handle blocking workloads) that handle mutations to the concurrent data structure. That would provide a nice async abstraction between the async non-blocking code and the sync lock-and-block code.
Actually, yeah, I'm curious why there is so much `unsafe` going on. Usually the following strategies let you cut down on `unsafe` dramatically: 1. Write a safe abstraction and use it instead of ad-hoc `unsafe` blocks 2. Use optimizer-friendly abstractions like iterators, or do bounds checking up front and rely on LLVM to optimize them out from the inner loop At a glance, the fact that nalgebra has so much `unsafe` going on is alarming. Unless it's just a huge FFI to BLAS or some such.
[https://www.reddit.com/r/rust/comments/c1rbqu/super\_fast\_shortest\_path\_calculations\_on\_directed/?utm\_source=share&amp;utm\_medium=web2x](https://www.reddit.com/r/rust/comments/c1rbqu/super_fast_shortest_path_calculations_on_directed/?utm_source=share&amp;utm_medium=web2x)
Just a heads up, this could be confused with the [Tock operating system](https://github.com/tock/tock), which is also written in Rust.
I'm still in very early prototyping stages here, I certainly haven't ruled out using actors. So if I'm understanding you correctly, there'd be an async interface on top that doesn't directly reference the hash map at all, but just passes the information into a pool of actors. The actors then operate directly on the hash map in a synchronous manner and pass things back up to the async interface when done. I'd need an actor implementation for every different kind of operation, right? Or maybe I pass the object keys I need in to the actor along with a closure that takes the found objects as parameters?
Wow thanks for the long feedback! I did start looking at the guidelines today and I've streamlined the traits each struct derives. On the public part, I made this in a way that a breaking change in the Web api would reflect a breaking change in the crate. That's way everything is public (and because writing a getter for every field looked a bit pointless), I'll look at the future proofing section to see what I can improve. I'll also add some crate level documentation explaining where one should start looking to get around the crate.
It wasn't that I found bugs in termion, but both crossterm and termion use [cfmakeraw][0] internally to change to raw mode, and I wanted to set some flags differently. Thanks for the heads-up about the alternate screen buffer! I saw it in the API, but didn't realize what it was for. Just implemented swapping between it and the main buffer. [0]: https://linux.die.net/man/3/cfmakeraw
If you want multiple concurrent readers I'd stick with parking_lot RwLock and `try_lock!()`, actually. I cannot see a way to implement multiple concurrent readers without a multithreaded equivalent of RefCell, which is RwLock.
But that's where Rust is supposed to help, libraries that are safe and used by a lot of people. Right now it's more for applications and libraries used by Rust projects.
Shoot, I only checked crates.io for naming conflicts. It doesn't look like there's an easy way to rename a published project?
Looks cool! I'll try it out in the next couple of days. A suggestion for clarity. input_graph.add_edge(0, 6, 12); doesn't tell me anything about what these values *mean* without reading the docs. this would show intent input_graph.add_edge(Node(0), Node(0), Weight(12)); you could use [shrinkwraps](https://docs.rs/shrinkwraprs/0.2.1/shrinkwraprs/#cool-how-do-i-use-it) to make the type Node and Weight behave like (in this case) integers! &amp;#x200B; Shameless plug: just posted a [small command line tool](https://www.reddit.com/r/rust/comments/c1qcys/kick_kickstart_your_coding_project_looking_for/), maybe you'll like it.
Format! allocates a new String every time, so it's worse than write!.
for iteration methods, there's the [Iterator](https://doc.rust-lang.org/std/iter/trait.Iterator.html) trait. slices implement these in specific ways that take advantage of how a slice is known to be laid out in memory.
Wrong subreddit. You're looking for /r/playrust
The part I struggle with is that items are indeed not statements nor expressions. If explaining the language in terms of only those two constructs you end up having to qualify a lot of ("`mod`s have statements, but `let` statements can't go there" kind of things).
Sure. The problem is that this info is relevant way up front. If you spend too much time on these details, you totally de-motivate the reader. Most programmers don’t think about languages this deeply.
It's worth mentioning (as was mentioned in the article you linked to) that `MaybeUninit` is the replacement for `mem::uninitialized()`. `MaybeUninit` is still a *huge* can of worms but at least it's not fundamentally broken (as far as we know).
Yep, `MaybeUninit` is not instant UB, but you almost always want `vec![0; len];` instead anyway.
**THIS IS NOT WHERE YOU THINK IT IS**
Well, sometimes you just can't have that, when you're dealing with generic types for example. You're right though that when you're dealing with arrays of numerical types that not initializing them is not an optimization.
Win at what?
Right now it will be hard for me to extract a minimal example (it's a mess of non-building code in the middle of me trying to get it to work inside a larger project) but for the general idea, consider tar archives with an extension. First, you can have a tar or tar.gz file, which need different `T: Read` impls. The compressed files can be made seekable with some effort (or with more effort and more efficiency) so as long as I can seek through the compressed file, tar and tar.gz is equivalent. Then, you can have a tar/tar.gz file streamed in from stdin or a socket connection. No matter how hard you try, that one is not seekable unless you cache the whole thing (which I can't really do). At this point, I don't yet need `Seek` at all, but here comes the extension. There's also an index format that contains just pointers to members, which is roughly a list of (actual_filename, offset) pairs and it does need `Seek` to jump around the files efficiently. I end up needing both seekable readers (for the files underlying indexes) and non-seekable readers (for sequential reads from stdin/network).
cc u/dabreegster
Got it, thanks :)
For work, I finished the gruntwork of implementing a somewhat odd allocator that is meant to be quick and memory-efficient, as well as isolating allocated objects from metadata from and other objects, while behaving deterministically so one can reproduce the allocation pattern across program runs. I also got to test out [cbindgen](https://github.com/eqrion/cbindgen) on that project and was pretty happy with the results. Made FFI way less of a headache than I anticipated. Other than that, I'll be hacking on [rust-semverver](https://github.com/rust-dev-tools/rust-semverver) and hopefully get back to fiddling around with [loom](https://github.com/carllerche/loom).
Documentation and support for BLAS implementation in pure Rust. https://crates.io/crates/blasoxide
Yep, that’s the idea. Either of those should work. And you could always build something equivalent using channels and your own thread pool for execution. Actors are nice in that you get that from the framework.
u/easbar contacted me through my post and produced this crate in under two weeks. This is quite impressive, given they learned Rust for this project. :) I'm cutting over A/B Street's pathfinding to fast_paths now and am excited to post the results.
This post turned out be pretty long. I think it should answer your questions :) No explanation so far, but I am about to push a new wiki and readme... Basically, a GUI element is either a widget or a layout. A widget is something the user interacts with directly (button, dropdown, text field, etc.), and a layout's task is simply to place widgets. I've used sort of an object oriented approach, where there is a \`trait Element\` which both elements and layouts implement. "Layout" and "element" actually has no meaning in the code, it is simply a way to categorize structs implementing \`Element\`. When deserializing the gui.ron-file, each element has a "type" field which decides which type it is. A type can be either a layout or an element. The deserialization then translates the string type into a struct instance e.g. \`type: "Button"\` will instantiate a \`Button\` instance. \`button\_instance.parse\` is then called, and the button is allowed to deserialize the ron value in any way it sees fit. The GUI itself does not actually know anything about the Button type; only the button itself knows what's inside of it. Only windows (all elements must be inside a window, and windows cannot be nested) have special treatment since they need to be able to interact with other windows for docking and undocking. As far as the GUI is concerted, the GUI is only a list of windows. I think that's it for the layouts, except maybe the inner workings of windows. Shortly: a window has an internal tree structure made of a recursive enum to keep track of splits, tabs, and elements. Events are sent by the implementing application calling a key\_down/key\_up/etc. method, which propagates the event in the GUI until it is handled (or not). I'm not sure what you mean by widgets referencing themselves? Mutability is where I've "cheated" and used unsafe raw pointers and \`transmute\`. I kept unsafe usage closed internally until I introduced the "Direct-reference provider", which basically gives the GUI a raw pointer to a variable. Coming from C/C++ I am pretty comfortable with pointers and such, but I can see how it might deter some people. However, the DR providers makes the GUI pretty much invisible, and lets the user register a member variable (like a bool), and then check if a button is pressed by doing something like: let button\_pressed = false; Add button to provider, start gui, main loop, etc. etc. if button\_pressed { The button was pressed, do something } The user simply has to be a bit cautious and not just cowboy code the entire thing. Ruey is planned to be single-threaded, so some internal raw pointers don't bother me much. It is also possible to safely implement the library, but it means you cannot have stray variables; they have to be placed in a collection which implements one of the provider traits.
The most logical thing to do would be to ask in r/playrust.
You're looking for r/rustgame.
Thanks so much for sharing quality algorithms with the community!
Nice. I wondered if this was the result of that, but since there was no indication I wanted to make sure you were aware.
Containers allocate and manage memory. This is not a safe operation (all stdlib containers are built on unsafe code). But it's rust's biggest strength to be able to create safe interfaces over containers. In this case ndarray and nalgebra add containers not present in the stdlib.
`unsafe` and generic types together are such a minefield that I don't even want to come close, ever.
How do I narrow an object's lifetime? Example: struct Type&lt;'a&gt; { a: Option&lt;Box&lt;dyn Trait+'a&gt;&gt; }; impl&lt;'a&gt; Type&lt;'a&gt; { fn builder&lt;T: Trait+'b+'a&gt;(mut self, t: Trait) -&gt; Type&lt;'b&gt; { self.a = Some(t); a } } My type generally has `'static` (???) life, when I want to modify it with a builder function, it needs to get a narrower scope, that of the `Trait`'s. This code doesn't work, but I think it demonstrates that self is returned with a shorter lifetime.
Ah, didn't read the article - thanks for clarifying :)
Makes sense! I thought you had a great assessment. Your comment above regarding... &gt;... attempts to explain not just *what* ... but *how* ... ... is completely spot-on, too. There is such a wealth of detail around how various things are implemented, as well as how one can implement their own abstractions. What really amazed me, though, was that I could skip the parts that were over my head and still continue through the rest of the text. That is so rare and so remarkable that they accomplished a book like that. Returning to the harder bits inevitably made more sense later on, after I'd read (and written!) more.
Looking forward to a description of transferring the classes/interfaces model onto Rust. My biggest struggle right now. Let me explain. In java, you say a method takes or returns a class/interface. In its place you can put anything that “comes down from it”. Extremely simple mental model. In kotlin it’s even easier because primitives behave like classes as well. Makes it very easy to work with abstractions. “I want to take a Sequence here and don’t care about anything else”. In Rust... trait, trait object, impl trait, dyn trait, struct, combinations of above with boxed and god knows what else. I know Rust is awesome, right?, and it’s just me dumb for not understanding all of that. This is why I’d love for someone to explain how the simple java’s concepts map to Rust’s mechanics.
No Rust though.
&gt; compared to the standard Dijkstra algorithm What about Dijkstra with right heuristic, I mean A* algorithm?
You'll need to deconstruct the builder and recreate it, moving all field except the one you're replacing. This is necessary because the lifetime is part of `Type`'s type, and the type of an instance of a struct is fixed as long as it exists. As an example, this should work: fn builder&lt;'b, T: Trait + 'b&gt;(self, t: T) -&gt; Type&lt;'b&gt; { // pattern matching is nice for deconstructing let Type { a: _old_a, other, fields } = self; Type { a: Some(Box::new(t)), other, fields } } Incidentally, if you want the builder to be generic over a trait rather than storing a boxed version of it, this trick works the same for chasing from `Type&lt;T&gt;` to `Type&lt;U&gt;`, too.
I'm working to finish the first draft update to the [`actix.rs'](https://actix.rs) docs for `actix` v1.0.
My `Type` implements `Drop`, is there a convenient way to escape that? &gt; `cannot move out of type \`Type\`, which implements the \`Drop\` trait`
Your wiki link says: "This project has no wiki pages". But I get rough idea. So normally GUI application have many windows/forms/dialogs, and it would be very inconvenient to register all providers on start of application. So to check that all ok, you need run your application and open all 50-100 windows/forms/dialogs to make sure that ron file &lt;-&gt; provider mapping is done in right way? I can not see how in this situation JSON validation can help, there is need some kind of based on `syn` crate code to find all provider registration calls.
In simple terms, as I understand it, structs are your objects' state and traits are your objects' behavior. The behavior is always defined as an 'interface' of sorts -- except Rust traits of course include implementations. It's more data-driven than object-driven. First you define what your data is -- then you describe how different behaviors apply to your data.
Made my [`slice-group-by library`](https://github.com/Kerollmops/slice-group-by) support grouping mutable str.
I guess you want an ORM like [Diesel](https://diesel.rs).
How does memory usage compare?
Very interesting :). I'm just learning rust myself - wouldn't it be better to return a Result from calc\_path since any None is produced by invalid input?
Not really, the data-structure may be needed for a specific situation and unsafe is needed to dereference pointers, like AtomicPtrs... So it's not even about optimizations, it's about data-structure abstractions.
Can this be done with Bellman-Ford?? I'm really into it recently for a problem and that cost is killing me
You can use Diesel as just a query-builder too (or to execute custom SQL), so it's likely your best bet.
I updated (rewrote) the wiki just a few hours ago, so the link is now broken, yes. You can navigate to [the new examples page](https://gitlab.com/DavidLyhedDanielsson/ruey/wikis/examples) to see an example. Currently there is no support for modals or even dynamically opening or closing windows. Opening and closing windows is very easy to implement, modals perhaps not so much. Right now the entire GUI is deserialized in one go, so all providers are required to be registered before deserialization if a GUI element requires it during deserialization. If an element expects a provider that doesn't exist it can either create it for you if it makes sense for the element to do so, or it could return an error, which currently means the entire GUI does not get constructed. In the future I might make the deserialization continue even if an element returns an error, and replace the element with some error element. I would also like to present an error popup to the user, perhaps give them an in-line editor to fix the error, too. Basically, the GUI itself does not know about any of its elements, only that a few windows exists. The elements themselves only know about themselves and any direct children it has - no grand children and so on.
I'd go for input_graph.add_edge((0, 6), 12);
No convenient ones, that I know of, no. I guess you could make all the fields options and use `take()` on them to take them out? What you want to do depends on what exactly the `Drop` is for. If it works for your use case, I'd recommend making a separate builder type without the drop implementation, and just having a `finalize` method to create the actual type. Another option would be to make all your fields `Option`s, always populated, but possible empty when dropping. Then you could use `take` to remove the various values and drop the old 'self' with all the none values. Or, if you really need to keep this `Drop` impl, but don't want the overhead of options and are OK with not running `Drop` when destroying the structure inside a builder, you could use `unsafe { std::ptr::read(*mut self.field); }` to read all the fields (including the old_a, so it's properly dropped), use `std::mem::forget` on self to prevent the old self from being dropped, and then reconstruct the new one with those values. I'd definitely recommend the first option' and the second above the third, but all should work. There might be another way around this, but I don't know of it. Not many builders also implement Drop themselves, as far as I can tell.
Classes !== OOP. Rust is already an incredibly OOP language. Also, classical inheritance is terrible in many situations.
You can safely forget about dyn trait, trait objects, and anything else involving runtime dispatch unless you're doing fairly unusual things (the kinds of things that in C++ need rtti). And inheritance is not a thing at all, in Rust. For a first pass, start with structs and traits. Traits work much like Java's interfaces. To paraphrase vermiculus's comment, structs provide data and traits provide methods. If you want to accept any object that has a certain interface `Trait`, write something like `fn foo&lt;T: Trait&gt;(x: T)` (or `x: &amp;T` for a borrow). Separate from traits, there are also inherent methods on a type, which appear in an `impl ThatType { ... }` block. Those are similar to the methods defined directly within a class in Java.
I updated [archive-rs](https://github.com/MattsSe/archiveis-rs) last week and added a command line tool, which lets you archive links on [archive.is](https://archive.is) from the command line I'm about to merge a new update to [crossref-rs](https://github.com/MattsSe/crossref-rs), (which allows you to search academic publications using the Crossref search API ). The new update brings deep-paging support for long results and a cli app is also in the works. I'm also working towards an initial release of [rustika](https://github.com/MattsSe/rustika), which is similar to [tika-python](https://github.com/chrismattmann/tika-python) and brings bindings to the Apache Tika REST services.
Good idea as well
An ORM is very much overkill if all you want to do is to abstract over database connections.
should've called the crate fapper, duh!
Please get in touch with community@ - we had draft ideas for that back in 2017 but never quite the amount of manpower needed to run one. https://github.com/rust-community/team/milestone/4
A\* is faster than Dijkstra, especially with sophisticated heuristics like Landmarks, but still nowhere as fast as Contraction Hierarchies, the algorithm used by fast\_paths. Also the A\* heuristics often require geometrical information about the graph (say the coordinates of each node for the beeline heuristic), while CH is a purely graph-theoretical method. &amp;#x200B; An advantage of A\*/Dijkstra over Contraction Hierarchies is that they do not require you to run an expensive graph preparation before calculating shortest paths (unless of course your A\* heuristic requires such preparation, e.g. Landmarks/ALT).
Lets bring Java, but lets say that we do what the creator said he should have done [and remove class inheritance](https://www.javaworld.com/article/2073649/why-extends-is-evil.html). In other words all classes are final. So how would you code in this world? Well first of all you wouldn't have Abstract Base classes, nor Base classes at all. Instead you do a bunch of interfaces, and have the class definitions implement them. This, though, can become annoying, sometimes a bunch of classes share the same implementation, and just vary on some small methods. So we can create an interface that extends our base interface, and makes default methods for all the shared code, leaving the methods that need to be defined unexposed. Now comes a new issue. I created an interface and would like an external class to implement it. Right now I could make my own class that extends the outside class, and then have that implement my interface, everything else remaining the same. We can't do that now, that we removed `extends` from the Java language. So instead we allow you to describe how to implement an interface outside of the class, we use the format `impl INTERFACE for CLASS`. Now the problem is what happens if there's multiple implementations of the same class, to reduce the chance of this happening by accident, Rust has some rules called coherence, that make it a compile error to even allow this to happen. Not that Java's solution is better: what happens if two libraries have their own specialized class objects that are incompatible, though basically the same thing (I guess you could treat them as same base class, but you still can have unexpected surprises). But now there's an annoying problem, there's two ways to implement an interface: either inside the class, or outside. This makes it hard to decide what to write code. So lets remove the ability to implement interfaces inside classes. So now you have to implement them outside. It's weird that you can implement methods inside classes, people may become confused and write a method that was supposed to be for an interface inside the class, not realizing it should be on the block outside. To avoid confusion all methods that belong to the class (and are not part of an implementation) will be in their own `impl` block which simply will not have any trait specified. Then it becomes obvious. We don't need `@Override` anymore because the `impl` block tells us if it's overriding any interface method or not. Finally lets do one last thing: remove constructors. Constructors are only important because of inheritance, but now that this isn't a problem, we can just make a single default constructor that sets all members explicitly, and let programmers make factory functions to get nicer functions. You don't need to worry about constructors that can throw exceptions or anything like that anymore. Now lets do some cosmetic changes to make it be very close to what Rust is: * Make `class` into `struct`. * Make `interface` into `trait`. * Make everything `private` by default and remove private. The old package visible default becomes and explicit `pub(crate)` and `public` becomes just `pub`. Now lets add some new rules that don't make sense in Java. Variables now have to be the type of a class, you can't have interface types. This is mostly so the compiler can optimize things very very aggressively. Most of the time this works well enough. We can use generics to make objects be like interface objects in Java. You can also call something an `impl TRAIT` which basically makes the programmer have to code to an interface, and not be able to know the type behind it, allowing for polymorphic. Somewhere you do have to tell the compiler the true class of an object though. The times we do want something like a Java object with an interface, we can put the whole thing in a special `dyn INTERFACE` type. Because they work as the objects do on Java (choosing the method and everything *at runtime*) they're called trait objects. The thing is that at runtime objects may have different sizes, Java solves this by making all objects exist by reference, except value objects. Rust instead changes things, were everything starts like a value object, you can get a reference to it by borrowing. But of course what happens when you want a reference that owns itself? Rust's answer to that is the Box, which is really just that: a pointer/reference that owns itself (so deleting the reference/box deletes the object it points to). So now lets go backwards. What things from Java and OOP can lead to better Rust code? * Have traits do one thing and do it well. * Have traits "tell don't ask". Don't have methods that expose state as much as let you do things without needing to know how. * Structs are like value objects. Try to only use classes directly when it's data that you are dealing with. You will find that in Rust doing data classes (structs meant to be used directly) is cheaper and easier because value classes are very doable. * This leads to something new. Some interfaces explain what things can be done, but others instead describe some property of the data itself. The former is meant to be used as the type a lot (through generic or `impl trait` types) the latter is meant to be used through the class, abstracting over it whenever needed (e.j. you explicitly have a `List&lt;u32&gt;` but you can have a `sum` function that takes `List&lt;T&gt; where T:Add`). Rust doesn't have as good of a story for the first case, it'd be ideal to have something like `let VAR_NAME: impl TRAIT = CONCRETE_CLASS::new()`. * Many of the patterns still work. Builders, Factory methods are now functions, but factory interfaces can still be useful. Command, Iterator, Strategy, etc.
The reason is that you usually get access to the venue ~the evening before the conference. Running a guaranteed livestream with a crew willing to ensure it is, as /u/steveklabnik says, expensive. None of your equipment is allowed to fail and much of the equipment (mostly the venues) is not yours. RustFest is able to livestream because we have good ties to hackers willing to do that for fun. And even then we never commit on it, we just see if it works and put the page up if it does. We never announce it beforehands for those reasons.
I thought about this some more, and if someone were to drop a file without the magic bytes signature, the program wouldn't know whether to encrypt or decrypt it, as it could've been encrypted by the existing version of the program. Probably not a big deal as this has only been out for like a week and I doubt anyone's actually using it, but I still don't want to release a breaking change already. And I don't think that two radio buttons makes it not a "simple tool," though it certainly would've been better if I'd designed it with the magic bytes and without the buttons from the start. I suppose I could rely on just file extension as /u/Shnatsel recommended.
What is A/B Street?
fapper ?
No, None can also happen if two points of the graph are not connected (which by the time you are calling calc\_path you probably do not know)
Java's `interface` == Rust's `trait` (Not 100%, but close) If you want a predefined body you can bind the pub trait MyTrait: AsRef&lt;AType&gt; { fn simple_test_function(&amp;self) -&gt; bool { self.as_ref().does_this_pass_the_test() } /* * other methods * */ } Then your type that inheritances functionality: impl AsRef&lt;AType&gt; for MyOtherType { fn as_ref(&amp;self) -&gt; &amp;AType { &amp;self.inner_field } } impl MyTrait for MyType { } If you want `@override` impl AsRef&lt;AType&gt; for MyOtherType { fn as_ref(&amp;self) -&gt; &amp;AType { &amp;self.inner_field } } impl MyTrait for MyType { // in previous example we didnt define a body // but here we do fn simple_test_function(&amp;self) -&gt; bool { true } } Traits are a _bit_ more powerful, as they don't suffer from diamond pattern issues. The issue with this scheme is you have to nest the object you are inheriting from as an _internal_ field. But this isn't normally a massive problem as I often find that is the case.
The prepared graph has more edges than the original graph (for road networks expect a factor of around two) and the same number of nodes.
https://dpc.pw/the-faster-you-unlearn-oop-the-better-for-you-and-your-software
I started working on implementing Rust-to-Rust-ffi-safe non-exhaustive enums for abi\_stable.It will use a SmallBox-like type to ensure that the enum has a compatible layout in newer semver compatible versions of the same library.
Fortunately we won't obliterate you for posting on the wrong subreddit, but nevertheless you might want to post this to /r/playrust instead
&gt; No "const after construction", like the const keyword for struct members in C++, makes intent harder to communicate https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ee63da321474b0174997ed472047e605 I don't see how this is hard in Rust, a very simple wrapper type enforces this rather easily.
I think you might have meant to post this in r/PlayRust
 struct Foo { next: Option&lt;Rc&lt;RefCell&lt;Foo&gt;&gt;&gt; } let x = Rc::new(RefCell::new(Foo { next: None })); let y = Rc::new(RefCell::new(Foo { next: Some(Rc::clone(&amp;x)) })); *x.borrow_mut().next = Some(y) Is guaranteed to leak both `x` and `y`. So no reference counted solutions. :(
I also use C++ a lot, and I've found that `std::variant`, while not as ergonomic as Rust's `enum`, can serve as a decent substitute.
Is it possible to make it so rustc doesn't complain about dead code only during tests?
Correctness has a cost. Correctness also has utility. It's a spectrum of tradeoffs, and where on that spectrum is "fine" depends on the goals of the application. Having different tools that aim at different places on the spectrum is useful. The problems occur when people blindly flail around trying to make stuff without being aware of the spectrum or thinking about what tradeoffs they actually are trying to make.
Lmao I'm a dumbass, I legit just typed in Rust and didn't read the desc... jesus what am I. I'll delete this, you'll probably see it in the relevant subreddit... no doubt I added to your list of people who have done exactly this! Cheers
Add this to your `lib.rs` or `main.rs`: #![cfg_attr(test, allow(dead_code))]
Rust's Iterator trait also has \[a method called partition\]([https://doc.rust-lang.org/nightly/std/iter/trait.Iterator.html#method.partition](https://doc.rust-lang.org/nightly/std/iter/trait.Iterator.html#method.partition)),it collects an iterator into 2 collections,using a predicate to determine which one every element goes to.
Thank you :)
Except you can always build the same data structures in safe code with more heap allocation/more locking/etc. Ultimately the reason to use unsafe for a *data structure* can always be framed as a performance question.
There could be a type-level ordering requirement on references, such that cycles in the object graph are forbidden. More complexity but...
I showed a simple example, but how would you even track that? The current way to make these sorts of graphs an make sure that everything gets dropped is by using a `Vec&lt;_&gt;` and indicies into the `Vec&lt;_&gt;`. That way the only owner of the data is the `Vec&lt;_&gt;`. But if you want shared ownership, then you will have to allow leaks, because they become impossible to track in non-trivial applications.
https://en.m.wikipedia.org/wiki/Region-based_memory_management http://lambda-the-ultimate.org/node/5007
Can you post the relevant server-side code?
On first release, this crate just allowed casting from `dyn Any` to other dynamic trait objects. I have just published a new version that allows casting between arbitrary trait objects meeting the correct conditions. This is done via something like /u/chris-morgan's `mopa`, but in a slightly less powerful but more convenient way (you don't need to invoke a macro on the trait that you want to be able to convert from, just sub-trait `TraitcastFrom`). I have also separated out the 'magic' functionality: the use of the `inventory` crate, which allows declaring a global registry so that conversion 'just works'. One can now use the core functionality without relying on `inventory`. It means explicitly creating a registry and converting trait objects through this registry. This is less convenient but more powerful. I intend to turn this magic part into an optional feature too, in order to remove the dependency on `inventory` when it is not needed. https://docs.rs/traitcast/0.2.1/traitcast/
This looks like he is saying you can use Rust's memory model to get leak free code. Saying nothing on how to track reference counted solutions. Yes, you can restructure your program to get rid of `Rc` in pretty much all cases by using `Vec` and indices, and you will get leak freedom, but that doesn't answer my question. How would you track `Rc` to prevent leaks?
&gt;How would you track `Rc` to prevent leaks? Assigning to an Rc could come with a proof obligation that the Rc strictly outlives what it's pointing to.
A deathmatch in Doom!
How does ownership effect memory layout? As appose to a reference or a borrow which must just copy the memory location. Moving ownership of data from one struct to another must copy that data. What about if I only wrap data inside another struct with a single inner attribute? &amp;#x200B; And moving ownership into a method or function? Does this copy the memory along the stack?
Ok, so you would need lifetimes for `Rc`? So that you can enforce this DAG.
Right now DUA only has high-speed/multi-threaded access to standard file metadata. Making any other IO call in the main thread would probably bring it down to (less than) single-threaded performance, and thus is nothing I would want to do. What’s left is being smarter with the metadata we get, which could mean some logic of ‘filesize’ is used within DUA directly. Without support for `filesize` to avoid any IO calls but use existing metadata, I don’t think DUA can adopt it.
This looks like your first Rust project. Nice one! What do you think of the language? Any particular thoughts stand out to you in your experience working with it?
&gt; Rust does not have a stable ABI To be fair, C++ doesn't have a stable ABI either. A given implementation may provide a stable ABI, but the language as a whole does not.
I think Rust appears harder to learn than it actually is. I will admit my first week actually using the language was a little painful. But my second week I was able to write a good amount of code with very few borrow checker errors. I did have the luxury of asking a friend for help when needed. But if you don't have that, there are tons of people on their Discord channel that can help.
Moving owned data is generally a memory move, yes. LLVM can do some impressive optimizations, like if you have a huge struct it might pass a reference instead, but I don't think ever that's guaranteed. When you wrap a struct with 1 inner field, the outer struct is generally going to disappear at compile time, and it will have the same layout as the inner field. This is guaranteed if you use the `#[repr(transparent)]` attribute. Without that attribute, it is usually the same anyways, but the compiler could choose to do something different.
Hi, I just read the readme doc. What is the use case for this crate? Can it support arbitrary transactional resources like database?
It's because they're implementing new data structures, and doing so efficiently. Actix was a fairly immature web server, nalgebra is known and trusted matrix crate.
What I've tried to do is extract out a common function of atomic transactions which is normally filled by a write ahead log. So the easiest way I've tried to think about it is as an in memory write ahead log.
I can't think of any way in which ownership would affect memory layout. Could you clarify what kinds of ways you might be thinking? There are size considerations to make, and when one wants to box data on the heap, but they're similar to the considerations one would have when working in, e.g. C and C++, which lack ownership semantics. If you wrap a type in a struct with nothing else, the new type will be the same size as the old one, and will be moved similarly. These types are usually called newtypes, after the Haskell keyword that does the same thing. In general, a struct in Rust will occupy as much space as the sum of its constituent fields, plus any padding necessary for [alignment](https://en.wikipedia.org/wiki/Data_structure_alignment). Since padding is only necessary if there's more than one field, singleton structs are the same size as their contents. All moves are `memcpy`s, unless the compiler is smart enough to avoid it. Within a function, the `memcpy` can usually be avoided. Across function boundaries, things get trickier, and I know little enough about the inner workings of LLVM to speculate. Rust supports, but does not guarantee, Return Value Optimization, where if conditions are right a function will construct its return value in the calling function's stack frame. I wouldn't be surprised if this also works in the opposite direction: a pointer to the calling stack being passed into the function, and the `memcpy` deferred until necessary (if ever). Rust also inlines aggressively, making it easier for the optimizer to avoid `memcpy` calls in those cases. That said I don't think there are any cases where Rust *guarantees* the `memcpy` call will be elided.
What's the difference between parking_lot's `try_lock()` and std::sync's `try_lock()` (and `try_read()` for `RwLock`)?
It is, but it doesn't necessarily seem like anything less huge has been built to do this in Rust? Diesel has a large community behind it, and does allow running raw sql queries.
Apologies if this doesn’t help, as I haven’t used rocket, but it seems you mounted all routes under the /people path. Also your “list people” route looks like it will only work with GET, not POST. Try “GET /people/“?
Ah that's very clever, thank you.
Note that Diesel only supports MySQL, PostgreSQL, and Sqlite. Not Oracle as mentioned in the post.
fyi [cookiecutter](https://github.com/audreyr/cookiecutter) is a mature project in this space
The crate just wraps metadata calls
I am from Drupal ecosystem (Drupal is CMS/framework built in PHP). Drupal allows you to connect to multiple databases. You needs to specify the connections inside a local file called `settings.php` and you give a name to every connection. Then you can connect to the db using the name. The APIs for db connection is provided by Drupal. I am not aware of any such crate that does, but it would be nice to see a crate that does that. I think it is going to work under the Diesel ORM. More info on `settings.php` https://www.ostraining.com/blog/drupal/change-the-database-connection/
You really need to learn to read the subs you're about to post to. You want /r/playrust
From you? I mean, I've never heard the argument. Morality has nothing to do with rust.
This might be a dumb question, but are the stdlib containers actually unsafe in practice, or are they just not provably safe from the compiler's perspective?
Think it's in the Old Testament.
It’s a joke I think
It looks like Rust is the only systems language with extremely heavy emphasis on memory safe code. So wouldn't it be immoral to write systems that must be secure in an unsafe language like C?
I can't tell if this is about the inexplicably controversial [code of conduct](https://www.rust-lang.org/policies/code-of-conduct) or something actually related to the programming language. Nevertheless, it could be argued programming in an unsafe language is not moral, in the same manner as ignoring building codes is not moral. While I'm not sure that using Rust would actively prevent code design issues that actually place lives in danger like the Therac-25, Toyota brake failure or Boeing 747 Max disasters, it does reduce the risk of creating software with some very common categories of security vulnerability, i.e. the classic buffer overflow. Companies developing programs where security is critical, like financial software or web apps that handle sensitive information, certainly should be asked "Why aren't you using Rust" (or another language with a focus on safety, like Ada.)
What do you think morality means?
It’s was actually added as the 11th commandment but only on unstable.
Trolls.
We don’t have a proof of the former, but we believe it to be true. Some have been preliminarily verified. It’s hard work though. People generally mean the latter.
This is a meme in /r/programmingcirclejerk. The joke is focused around that because Rust is the only language that you can guarantee memory safety in, any other language is 'immoral' to program in because you're endangering your users.
That's a breaking change! Hope God is respectful of semver...
Looks fun and useful! What are the main differences in graph implementation in your create and that of [petgraph](https://github.com/bluss/petgraph/)? I recently wrote an Ant Colony Optimizer which can find one of many solutions to an NP-hard problem represented as a graph. I used petgraph for the graph representation, and it worked very well. However, if there are significant speed improvements, than I could be interested in switching over. P.S.: Sadly, it's unlikely that I get the authorization to publish this ACO in open source.
Thanks for doing this important work! (you somehow broke the link ... my guess is with the backticks \` which you started inside the \[ bracket but ended it outside after the "docs for" \` )
That's basically a limited group-by (https://clojuredocs.org/clojure.core/group-by)
I'd love to learn more about the algorithm! Is there a paper I can read?
So ch is only really worth it if your graph is seldomly updated/changed right?
Just wanted to add that for A\* to work properly, the heuristic needs to satisfy the triangle inequality, ie steps(A-&gt;B-&gt;C) &gt;= steps(A-&gt;C).
_FA_st _P_aths _P_roj_E_ct _R_ust Honestly I dont know what he meant :D
Yes. It is meant to be used in a scenario where you prepare the graph once and then execute many different calculations on it.
https://en.m.wikipedia.org/wiki/Contraction_hierarchies The reference section should lead you to the Thesis of Robert Geisberger who proposed this method.
Desktop link: https://en.wikipedia.org/wiki/Contraction_hierarchies *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^261469
I think this should be the first paper about it: [https://link.springer.com/chapter/10.1007%2F978-3-540-68552-4\_24](https://link.springer.com/chapter/10.1007%2F978-3-540-68552-4_24)
Well I have started this new experiment from scratch to list the error messages I'm getting, so if they are no surprise for you, it means my installation works correctly :) To catch the problem, I want to make the minimum steps and see where it occurs. And now I have added the *empty* file `src/main.rs` and the unhelpful message is back: $ cargo build error: Unknown option Replacing the empty file with the working one from the hello world tutorial leads to exactly same message. But as beginner, I regard such messages as unhelpful and feel puzzled about how such messages would even be allowed by the teams in any major project aiming to attract more people and make their experience better, if I understand correctly.
Hey, nicely done. Do you have a name for your graph data structure? I have been using the same structure for some time now and call it offset array. But I don't think that's the official name. It's been bugging me forever ;).
Feels like you would have a better time if you made the file format agnostic to the IO operations, and then implemented the IO as their own things.
&gt; To catch the problem, I want to make the minimum steps and see where it occurs Ok, so you're saying that the steps from the tutorial work for you, and you're now working out what happens when you do it differently? To check out the error messages and see if they're helpfull? &gt; ... unhelpful message is back: Here's my console session from trying to reproduce that: ```bash $cargo new hello --vcs none Created binary (application) `hello` package $cd hello $gnvim Cargo.toml $cargo build Compiling hello v0.1.0 (&lt;snip&gt;) Finished dev [unoptimized + debuginfo] target(s) in 0.92s $rm src/main.rs $touch src/main.rs $cargo build Compiling hello v0.1.0 (&lt;snip&gt;) error[E0601]: `main` function not found in crate `hello` | = note: consider adding a `main` function to `src/main.rs` error: aborting due to previous error For more information about this error, try `rustc --explain E0601`. error: Could not compile `hello`. To learn more, run the command again with --verbose. ``` If you need help, post your console session. If you're "just" investigating, great! &gt; I regard such messages as unhelpful and feel puzzled You should open an issue on the rust-lang repo then. Reports from beginners are appreciated, since everybody working on stuff is not a beginner and therefore does not face the same problems.
thank for all the answer: &amp;#x200B; so that is the current state: \-the non-stable ABI is still a problem and only solveable by using c-functions \-there are some ref-pointer implementations available \-rust does not try to solve heap-sharing in any way better than c/c++,... does - due to zero cost abstraction ambitions &amp;#x200B; so the only thing that can get better is the stability of the ABI in the future
Yes it was my first Rust project. Honestly, I am really amazed by Rust. I did a few years of C++ before and obviously Rust is a much nicer experience (but obviously this is not a fair comparison, since it is so much younger). I really like how it is using the 'right' defaults (like immutable by default). Cargo simplifies things a lot, because you do not need to spend much time to choose and setup your toolchain first (compare \*this\* to C++ haha). Also the rust book provides really nice documentation :)
Yes, you're correct
Here it is: [http://algo2.iti.kit.edu/schultes/hwy/contract.pdf](http://algo2.iti.kit.edu/schultes/hwy/contract.pdf)
I like 'offset array' I'll call it that from now :)
I'm hoping it makes it more pleasant to polish and experiment. I have a difficult time designing things in my head and want to be able to see and test things out, and recompiling really gets in the way of that.
petgraph does not allow a preparation phase to speed up the shortest path calculations. it is possible that I could use petgraph within fast\_paths and I tried this for a bit, but eventually decided there was not much value and setting up the graph does not take much code. Feel free to contact me if you have specific questions regarding your project.
Great. Will there be recordings of the talks available?
Yep, try magic bytes, otherwise fallback to extension, otherwise let the user choose
Thank you for the recommendation! Something like glyph-brush is what I'd most likely go for. I'm not really looking for something which will render 100% of UTF-8 with perfect kerning, hinting, sub-pixel anti-aliasing and so on. I'm fine with a monospaced font that gets the job done and looks alright. I think better text rendering is very low priority until a lot of users require it, and I know there is some time to spare for more fancy text rendering. Though, on the other hand. Now is the time to start thinking about - and planning for - if I'd want right-to-left writing... Great to hear you think it sounds like a good project! :)
That does look like https://github.com/Keats/kickstart except kick has built-in templates?
Can the prepared graph then be saved to disk and read quickly next time? Or must it be prepared in memory every time?
You can look at C and pretty much figure out Rust
Godbolt now supports demangling the new mangling sheme. It is really beautiful: * https://godbolt.org/z/WKT651 * https://i.imgur.com/GYjFyQX.png
I updated the readme with a "target audience" section. For now the target audience is \*not\* people who want to make a main menu or options menu which has flashy effects, animations, and good looks. I'm targeting people who need a GUI for debugging or for an in-game editor. I think it might be possible to use this library to implement animations, effects, and such, but for 1.0 I just want a functioning GUI. A functioning GUI with at least mosty left-to-right languages supported.
There are functions to load/save from disk, but you can also serialize it yourself.
Thanks for the quick response! I'm very new to all of this, so sorry if this question is trivial: does Contraction hierarchies allow to solve the resource constrained scheduling problem (which is somewhat like a multi-traveling salesman problem)? I'm using the ACO to optimize a schedule of space resources. Thanks
Hello! Author of ccl here. It would be trivial for me to add try_get functionality to DHashMap. I would gladly do so once I have some spare time.
No it does not or at least not directly. It is solving the shortest path problem on a directed graph (and it was designed to work best on road networks).
Hi, I'm currently doing the official rust-lang book and just entered chapter 3. The problem is: IntelliJ doesn't accept other files different than 'main.rs'. I have a Cargo project in which I want to put all files while going through the book. The problem I'm currently experiencing is that IntelliJ (with Rust plugin) can't seem to recognize other files different than '[main.rs](https://main.rs)'. It always states on top of the file 'File is not included in the module tree, analysis is not available'. Because of this, I don't have autocompletion or any other features. I re-imported the project severalt times, deleting all the IntelliJ files (\*.iml,...) and invalidated the cache. Did anyone have similiar issues?
True. I wanted to get to know the “sane” config file format and see what I could do with it, and learn rust, so I went out and built my own.
Looks cool! I wanted to work with “sane” configuration files, and learn rust, so I built this in my spare time.
Triple backticks don't work on old reddit. Please use indentation for code blocks: use std::convert::TryFrom; struct Hello; impl&lt;T&gt; TryFrom&lt;T&gt; for Hello where T: AsRef&lt;[u8]&gt; { type Error = &amp;'static str; fn try_from(value: T) -&gt; Result&lt;Self, Self::Error&gt; { Ok(Hello) } } - error[E0119]: conflicting implementations of trait `std::convert::TryFrom&lt;_&gt;` for type `Hello`: --&gt; src/lib.rs:5:1 | 5 | impl&lt;T&gt; TryFrom&lt;T&gt; for Hello where T: AsRef&lt;[u8]&gt; { | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | = note: conflicting implementation in crate `core`: - impl&lt;T, U&gt; std::convert::TryFrom&lt;U&gt; for T where U: std::convert::Into&lt;T&gt;; --- Now that the error message is readable, the issue becomes much more clear. The specific problem here is actually the compiler's fault for being overly cautious when checking for conflicting trait implementations. Since the compiler is afraid that there may be a type `U: Into&lt;Hello&gt; + AsRef&lt;[u8]&gt;`, even if one doesn't exist, it still disallows it because it would satisfy both implementations and it wouldn't be able to choose. The may be helped by specialization when it lands. In the meantime, I'd probably restrict the implementation to `impl &lt;'a&gt; From&lt;&amp;'a [u8]&gt; for Hello` and call `as_ref()` on the argument before passing it. If it implements `Deref` as well, then you would be able to just do `let h : Hello = s.into();`. --- I assume this is a prototype for a more complex conversion? As it stands, you should be implementing `From` rather than `TryFrom` since the conversion will never fail.
Yeah "stable ABI" might not be the correct term here, the Rust team has actually made quite good arguments for why you wouldn't want that. What is really desired is better infrastructure for dynamic linking and DLL/so distribution. Likely this is doable without a fully stable ABI, similar to how things are with Cpp.
&gt; CPU-bound tasks, however, don't benefit from this style of async task modelling. Instead, they need to use a CPU usage tuned task manager such as rayon if they want well-tuned defaults for their workload. Is there some fundamental reason for [rayon-futures](https://github.com/rayon-rs/rayon/tree/master/rayon-futures) to be necessarily slower than rayon proper? Having a single future-based abstraction for both IO-bound and CPU-bound probably leads to a stronger Rust ecosystem.
You don't need &lt;&gt; on impl, since your type (Hello) does not have a &lt;&gt;. I didn't know how to make the trait AsRef work for you where you need it to be, but I assume a &amp;[u8] might give you the same results. ``` use std::convert::TryFrom; struct Hello; impl TryFrom&lt;&amp;[u8]&gt; for Hello { type Error = &amp;'static str; fn try_from(value: &amp;[u8]) -&gt; Result&lt;Self, Self::Error&gt; { Ok(Hello) } } ``` https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c3ec27a85e885ad3a71d588351ea2fd8
In that case, why not consider having a custom error type, say for example FastPathError::MissingConnection(edge, edge) ?
I found the timer crate. It schedules a closure. I was hoping for something even nicer, but it was good enough for me. I guess spawn, sleep and exit would have been enough though. :)
Ah nice! Wish there was something even more self-contained too, but I guess that works. :)
It's a fairly different domain, so I wouldn't worry _too much_. But if you do change it, I think the best way is just to yank the old crate releases and publish as a new crate? After doing that it should be possible to transfer ownership of the old "crate", if you want. I don't think there's any way to actually rename a crate, though, and redirect the old name or anything like that.
Hmm, why would this be better ? When calling \`calc\_path\` you are asking for a path. There either can be a path or there can be no path, and I think this is exactly what \`Option&lt;ShortestPath&gt;\` represents.
You can take a look [here](https://github.com/gtk-rs/examples/) as well.
It is better to return a Result because as /u/sjoruk mentioned, the creation of a path can fail for a reason that you know, but might not always be the same. It is always better to give more context about a failure, so if the creation of a path has multiple reasons to fail, you should be explicit to the user about what did go wrong. It's just like if you entered your age on a website, put 20 for example and the website replies "something went wrong". You don't know what went wrong, do you ? You're either too old or too young, or maybe you typoed 20, you'll never know unless you give back the context of what went wrong.
&gt;the creation of a path can fail for a reason that you know, but might not always be the same no it can not. the only reason it can fail is that the two points are not connected on your graph. if they are you get None as result. None as in 'there is no such path'. I do not know what other information I would reasonably add to the the Result/Error
In that case, you could still for example give more information about what went wrong by adding the indexes of the two edges that were not connected :)
That's a question of semantic, I guess. When no path is found, this is not an error, that can legitimaly happen in a graph. An error would be an impossibility to find a result for whatever reason.
That doesn't make any sense. A pathfinding algorithm is not designed to provide suggestions for *creating* a path that doesn't already exist in the graph. It would be completely unintuitive for it to compute and return such information.
I dont agree, this is not about creating a path that doesn't exist, this is about correctly explaining what went wrong. It would be useful for it to compute it, e.g. to mark nodes on a GUI application.
Cool, so you could prepare the graph, serialize it, then next time you start the program, use the pre prepared one? That's very cool. Very useful. You should be really proud of this project!
There's @mmstick 's tutorial, which is already 2 years old, but still very nice [https://mmstick.github.io/gtkrs-tutorials/](https://mmstick.github.io/gtkrs-tutorials/)
I don't understand. Why is it MissingConnection(edge, edge)?
I think this happens when you create a file `foo.rs` but don't put `mod foo;` in `main.rs`. I also had this bug with test files (`tests/foo.rs`, where `mod foo;` is not needed) but it disappeared with the latest plugin update.
This was just an example, but OP mentioned somewhere in the other comments that the only way the creation of a path could fail is if two nodes were not connected. In that case one could just return a Result&lt;ShortestPath, (edge, edge)&gt; (and not a custom error type as I mentioned, since the error is unique), (edge, edge) being the tuple of edges that were not connected, in order to give context about the failure.
It can very well be that a path is not found, because the graph does not necessarily have to be fully connected (it can contain multiple components).
There's no reason to return the input to the function, especially considering the inputs are `Copy`.
You mean the nodes that were not connected. Yes this could be returned, but thats also exactly what you pass into calc\_paths :)
No, I meant the place where the Algorithm failed so for example taking the following graph : &amp;#x200B; 1 &lt;--&gt; 2 3 &lt;--&gt; 4 &amp;#x200B; calc\_paths(1, 4) will fail because of the missing connection between 2 and 3
Thanks @jswrenn. I am starting my `nalgebra` exploration. I have got a clear picture about `unsafe` and `Rust` as memory safety language now. Thanks to all the Rutaceans out here.
My experience in programming in general is that performance is always fine if you are doing these sort of calls very rarely, i.e only a few times per frame would be fine. Just don't call your rust code from inside a loop in your Unity code and you should be OK.
Stockfish is amazing though, and these engines taking this new approach are seen by chess experts to play in a more human-like way because they have strategies that make sense and work well for a wide variety of possible responses.
Why is the io-Result different from the other Results? std::io::Result&lt;()&gt; istead of Result&lt;(), ()&gt;
I'm still not sure what you're trying to get out of it, but it doesn't work. Example: a graph with 2 nodes and no edges.
I found looking at the [examples][1] quite helpful. Besides that, the official gtk (non-rust) documentation is usually also quite nice. Remember to import the lgpl docs! It's described in the [crates.io][2] page, and involves temporarily adding the `embed-lgpl-docs` feature. Then run `cargo doc` in your project to generate them locally. They will be located in `target/doc/gtk/index.html`, and you can open that file in your browser. Without embedding the lgpl docs, the documentation is very very poor. [1]: https://github.com/gtk-rs/examples [2]: https://crates.io/crates/gtk
How do you know that the problem wasn't the way that 1&lt;-&gt;3 aren't connected? Don't forget 2&lt;-&gt;4 is also missing. This is a Graph algorithm. It might not even realise that the graph is broken into two (or more) connected sub-graphs, since it is not trying to calculate that. Don't forget that you could get None back and then pass the graph into another algorithm that can give you such stats, or create links for you.
I'm just explaining myself poorly today. I meant to return the index of the two **nodes** that were not connected to give more context. Not edges.
Thanks that solved the issue! Now I got another quick question. Can I have runnable mains in other files than [`main.rs`](https://main.rs)? I would like to have for each chapter a runnable file. &amp;#x200B; Thanks
Sounds like it’s time to separate the backend parts of diesel into a dedicated crate then :)
One of the most compelling reasons I can think of to learn *any* new programming language is to extend your understanding of the general arena of programming. For example, whether or not you intend to do anything concrete in it, learning Haskell is worthwhile to help understand data flow through a program. Rust is excellent at teaching you about why knowing exactly who owns a piece of data is worthwhile. Learning C helps you understand the underlying system of a modern OS... I could go on. For me, I find programming in Rust has reignited my love for programming in a way that spending a few years in mostly Python and C had killed it off. But there's no guarantee that it'd have the same effect on any other person.
Rust is mainly a systems programming language. Usually you'd use it if you already have good understanding of what you want to achieve with your code. If you really want to have loads of performance (which is often even better than c) and don't care about building for every architecture separately then rust id for you. (Of course you can use it for almost anything but that's the primary use case). ;) And then there is the cool part with memory safety in rust... But if you want to use java or c++ that's as good as any other language, use the one you feel more comfortable with.
You can add the ```[[bin]]`` section to the [manifest](https://doc.rust-lang.org/cargo/reference/manifest.html#configuring-a-target) and then run each chapter using cargo run chapter1 etc..
My initial thoughts about \`Rust\` as a memory-safety language is being redefined and my understanding is getting better. I understand now that no matter what, dealing with memory has to be handled with utmost care, be it Rust or C/C++. On the use cases such as defining a new data-structure, the amount of care required is same as for C/C++. While this surprising for me, as I come from non computer science background, I chose \`Rust\` for its simplicity and ease of development (I find solving the same math problem with Rust is much easier than C, though I have some exposure to arrays and pointers of C before starting Rust). Now I understand that (as @levansfg said), Rust doesn't remove \`unsafe\` altogether rather provides better safe abstractions to deal with that for majority of programming tasks. I am going to go(!) with \`Rust\` (bit of a moronic sentence \^\_\^) as I determined to. Thanks everyone.
Ugh. Thanks for the explanation. Note that `try_from()` can still be implemented instead of `from()` for `&amp;[u8]`. Also, the lifetime bound isn't needed at least for this example: it might be later depending on what's done with the input slice.
FWIW, Rust isn't really "made by Mozilla", and definitely isn't targeted at web development (though you can do web development in Rust to some extent through WebAssembly). If you just want a sales pitch, check out [the website](https://www.rust-lang.org/), but if you have any more specific questions to ask, please do.
You probably want to use examples: create an `examples` folder in the project directory and create your main file as `examples/chapter01.rs`, then you can run it with `cargo run --example chapter01`. This is especially useful when building a library, since you can show potential use cases of your crate.
On a related note, is anyone else having problems with RLS and gtk-rs? The code completion doesn't work at all for me even on a simple project.
&gt; the two nodes that were not connected But there usually isn't a pair of canonical nodes that cause a path to not exist. In many non-connected graphs there will be a large set of pairs of nodes for any of which adding an edge to will make the graph connected.
&gt; I’ve heard of rust and it’s intentions of being good with graphics or something and it’s made by Mozilla which means web development. This is incorrect and extremely misleading. From the front page of rust-lang.org: * "Rust is blazingly fast and memory-efficient" (ie in the same performance category as C++) * "Rust’s rich type system and ownership model guarantee memory-safety and thread-safety — and enable you to eliminate many classes of bugs at compile-time." These are the two biggest objectives in Rust: performance, and making some types of bugs impossible. There are a ton of other things as well that make it an excellent language and ecosystem but these are the languages intentions. Mozilla is using Rust to build its browser, but that is not web development. See https://wiki.mozilla.org/Areweyet for various sites tracking specific problem domains.
I think it's great news for rust. Announcements like this is contagious and will make more people more willing to adopt Rust.
There's MIRI but that's not a silver bullet
There's necessarily some amount of overhead to talk between the async IO task pool and the CPU task thread pool. And if you don't need all of the e.g. Tokio reactor because you're only using the rayon thread pool for CPU bound tasks, then all of the async runtime is space and time overhead you don't need to be paying for. Rust (and core crates) prides itself on not paying for abstractions and features you don't use. Routing CPU pools through an async reactor doesn't follow that ideal.
Not really. If you read the nomicon, you'll see that a lot of Rust semantics \*still\* hold. You can't just magically use a shared ref as if it were mutable (Which is not to say you can't transmute it, though iirc that's instant UB). You just get access to a couple super dangerous operations. \*However\*, the fact that unsafe code can define safety guarantees in a way that the compiler understands for compile-time errors, and the fact that the safety guarantees that all safely-callable unsafe code should abide by are (Somewhat) clearly defined, is \*far\* better than just being what C/C++ does. I also personally think writing unsafe rust is a lot harder than C/C++ (There's a LOT of guarantees you need to uphold when writing safe abstractions, and unless you're familiar with llvm or rust at a low level, a lot things that might look like translated C-land things will blow up spectacularly, and there's a number of thing you need to account for that are just not present in C (Like when writing something generic, accounting for exotically sized types, or the whole thing about uninitialized memory and all-bit-patterns-are-valid types (Which brings me to another problem I sometimes see with rust: Some things are still not clearly defined and are just kind of in limbo))
I've read a couple times how there are 2 rust languages: Safe rust, and Unsafe rust. And the unsafe keyword is just a kind of ffi between them.
Ease of access [https://github.com/libra/libra](https://github.com/libra/libra)
"Move is a new programming language developed to provide a safe and programmable foundation for the Libra Blockchain." __ https://developers.libra.org/docs/move-overview
Ok since this is getting so many upvotes I might consider this. Too bad rust does not support function overloading so I would have to break the current api.
Well, Move is the scripting part of Libra for the users to allow various transaction types/smart contracts/....
If you read more, Move is seems intended to be the language for smart contracts in the blockchain. They mention bytecode and a virtual machine; the VM itself is probably going to be written in Rust (like the Hotspot JVM is written in C++).
It's great news like Fuchsia is great news - good because Rust is actually being used in a corporate place where it logically makes sense, but bad because Rust is being used to take over the world.
I hope they're not just planning to poach all the parity devs. On the one hand, good for those devs - having embraced two cutting edge technologies (rust and blockchain) now means that they would surely be shoe-ins for extremely lucrative jobs at Facebook, but on the other hand the community needs projects as high quality as parity and related projects...
Ultimately, you have to decide why you want to learn something. The reason I wanted to learn Rust was that I had studied Haskell, but I was continuously disappointed by how impractical it was. Especially with regard to how bad the tooling was (this was before Stackage) and how the community fetishized it's pseudo-mathematical foundations. When I saw Rust, I recognized a lot of the Good Parts(TM) of Haskell had been worked into the language. (People rant about monads and bullshit, but the reality is that Rust-style enums get you 80% of the benefit, the question mark operator gives you maybe 9%, and traits get you another 7%). The typesystem is novel and interesting. I found Rust's tooling is first-in-class. Cargo is leaps and bounds better than any other build system I've used. You just run `cargo run` and your program compiles and runs. (And is balls slow until you compile with `--release`). The ecosystem is young, but as someone who's just playing around with the language, it's more than big enough to get started. It has the same feel that Python's pypi has, where you can pick up just about any project, copy the example program from the README, compile, and it *just kind of works*. You can't do that shit with C++. Lastly, Rust is fucking fast. I have been working in Python so long that I had forgotten how fast a computer actually is. It was only after working with Rust that I really started to appreciate how long a nanosecond was. But despite the raw speed, I feel well-guarded against the minefields that C and C++ leave at your feet. The language's borrow checker makes sure that you don't leak memory unless you really work at it. And iterators make it so I never have to chant the mantra, "for int eye equals zero; eye is less than enn; eye plus plus". Rust isn't perfect. It's kind of an ugly language. You have to give it some love, and then it can be your ugly child. And you love your child, even though you have to admit, he's kind of ugly.
You're looking for /r/playrust.
Oh yea XD
The two other major FP languages used by Facebook (Haskell and Ocaml) are actually known for their run time performance, thanks to the heavy optimizations done by their compiler. And I doubt GC would be a problem for blockchain implementation, it is not exactly a hard real-time system.
I just cloned and fired up a node (std \`cargo build\` then run a script) as I was curious which crates from the Rust OSS community they use, the answer is most of them! Hopefully this means we'll see support (PRs or sponsorship) from FB for some of these if not already? Do any of the devs frequent this forums I wonder?
TBH, I don't think this would be a good use of overloading. Too similar ways of doing things.
Having used Diesel, I am unsure if it will fit the OPs goals. If by "either" they mean "the user of my software can choose what they will connect to" Diesel doesnt really have a mechanism for that. In fact, they seem to be so strictly typed that you need to pick a database and stick with it. Changing the database type later in code can lead to breakage...
It is interesting that they decided not to use WASM for the Smart Contract runtime and instead invent "Move" (nice nod to Rust there in the name!)
Dude, programming languages are tools. If you’re passionate about hammers you’re not lying around sleepless at night because someone out there uses it to bash a skull.
I mean, knife butters also were used by the nazis. It helped them to feed themselves to take over the world. Most tools will be used by evil if they have a purpose. C is used to program murder drones, that doesn't imply anything about C besides the fact that C exists simultaneously in a society guided by terrorists.
Haha ok yes I get it. Let's dont start this discussion here :)
Two other? Rust isn't functional
What is your end goal? It sounds like you're trying to do something weird.
I guess the main problem is that manipulating incompletely defined objects in rust (like you would pass interface types in Java) is very verbose.
&gt; *two* other major FP languages used by Facebook (**Haskell and Ocaml**)
There are a lot of blockchains in Rust already. I myself work on a Rust implementation of r/Nimiq. The Rust implementation is still beta though.
I was surprised that the Move language, as the name implies, is mostly based on move semantics and strong typing... very much inspired by Rust to have strong guarantees... right now, developing anything on other blockchain VMs is horribly error prone.
Wow, there are only 7 `unsafe` blocks in the whole repo.
My end goal is to have a generic function that accept a variety of different type restricted to the trait \`T\` and call functions specific to the \`struct A\`, not the trait. Does the compiler only know about the trait and not the type its related to?
Wow, there are only 7 `unsafe` blocks in the whole repo.
My end goal is to have a generic function that accept a variety of different type restricted to the trait \`T\` and call functions specific to the \`struct A\`, not the trait. Does the compiler only know about the trait and not the type its related to?
Oops, forgot the word there when rewriting the sentence.
Why is this downvoted? Rust is about as functional as Java imo.
The compiler knows things, _your function_ doesn't. Your generic bounds say that any type that implements `T` will be accepted. This means the only thing you know about the type inside the function is that it implements `T`. It can be an `A`, but it doesn't _have_ to be, and calling methods of `A` on it is not a valid operation.
Yep I figured, but I wasn't entirely sure \^\^' Thanks for your help!
Why should you learn any language? 🤷🏻‍♂️ I could talk about its resource usages and safety. Anecdotally we do see significantly better performance vs other languages, but they're not so important to us that we're forcing people to switch. When it comes down to it the only thing that matters is developer happiness (your happiness). Try it out, see if you enjoy it, if you do, that's why you should put more time in to it.
Thanks a lot for the nice feedback and also thanks a lot to u/abreegster without whom this crate would not have come to existence.
You call blockchains a cutting-edge technology so maybe you know if blockchain is good for anything but made-up money?
There is still the problem that the standard library likes to panic. That's a convenient way to handle errors, suitable for most cases, but it's a no-go for the robustness required in aerospace systems. Here comes an unbaked idea how to address this. We could put a library between `core` and `stdlib` that implements mostly the same things, but no function will ever panic and all failable operations return a `Result`. This would make a lint feasable, that warns if there exists a panic code path. And while we are at it, you also can specify your own allocator. This has the advantage that `stdlib` is still as convenient to use as ever, but everyone who needs more precice control can have it. `stdlib` would wrap that middle layer to avoid code duplication or bloating the binary size.
This subreddit is for the programming language called Rust, which has nothing to do with the game called Rust, except sharing the name (accidentally). If you want to discuss the game, try /r/playrust.
Ah, thanks :)
They are using upcoming async/await. For example: [https://github.com/libra/libra/blob/5e034dde19a5320d7e2bdc9da25114e816b4454d/network/src/protocols/peer\_id\_exchange.rs#L30](https://github.com/libra/libra/blob/5e034dde19a5320d7e2bdc9da25114e816b4454d/network/src/protocols/peer_id_exchange.rs#L30)
First time I looked at Haskell (maybe 15 years ago), it was because I'd seen some sort of performance comparison of programming languages online, and Haskell was dead last. I figured, well, it's got to have _something_ going for it.
Guns don't kill people, people kill people.
Well apart from made up money I also think it's got a promising future as actual money.
You want /r/playrust.
They are indeed tools. More than that, they're subject to the Zeroth Freedom. Things like Fuchsia and Libra, do make one wonder how to (borrowing your metaphor) make a rocket-assisted hammer and distribute that publicly; rather than releasing a simple carpenter's hammer publicly and then watching cronyist evildoers fasten rockets to their own hammers.
PLEASE TAKE A LOOK on what sub you're posting on.
You're right, guns don't kill people. People kill people. Armed people kill unarmed people. And Rust is immature enough that sending it into the world means that only cronyist corporations who can throw around billions of USD without breaking a sweat, can use Rust effectively. Meaning, we have unwittingly enacted the metaphorical equivalent of gun control.
If one doesn’t believe that the design of a tool makes a difference in its application, then how can one assert that it is Rust that forbids unsafety, and not the Rustacean who picked it up to go on a safety spree?
You realise Google, FB, etc. are currently using mature language to do all this, right?
Hey, my company is building cryptographic ledgers in Rust too. It's not just evil mega-corps.
That doesn't mean I can't complain about there being nazis up and about. (Metaphorically. Lots of people and corporations today may be lots of things, but "nazi" isn't one of them.)
You can `use crate::foo::bar::MyEnum` to bring it into scope.
We're using something closely related specifically to make financial institutions more transparent.
Painstakingly so, with mature languages. Rust, for reasons familiar enough to any Rust user, takes away enough of that pain, that with enough in-house libraries to patch the rest of the holes, it's a tremendous force-multiplier.
Rust is multi-paradigm.
I don't understand, I did not create a crate. Where in your example "foo" be declared?
Used as actual money, it's the best chance at sidestepping the foibles and evils of fiat currency and, well, fiat in general.
Any Cargo project is a crate. `foo::bar` would be a module inside your crate, like `lib::math` in your example.
This means that they are using nightly Rust for a corporate project. That doesn't seem the best idea, so I checked the repo and they actually use a fixed nightly release, `nightly-2019-05-22`: https://github.com/libra/libra/blob/5e034dde19a5320d7e2bdc9da25114e816b4454d/rust-toolchain
Yeah, but this project is in test stage until early 2020 and async/await will be stable long before that.
Ah, got it, thank you, this works!
There's actually a possible optimization with the current approach: since the add operation takes ownership of its input, it can re-use the underlying storage. That's the main difference with the == operator, which does not have to create the memory storage it must return. I don't find it that much of an argument in favor of the chosen approach, but it shows the two approaches are not equivalent.
I'm guessing it's code node / skillsmatter london liverpool st with a 6:30pm kick off.
This is for the rust programming language
This subreddit is for the rust programming language, you might be looking for r/playrust
GHC definitely matured well over the period. For some tasks it can easily match hand-written C in performance while maintaining safety. See the following for more info: * https://stackoverflow.com/questions/35027952/why-is-haskell-ghc-so-darn-fast * https://chrisdone.com/posts/fast-haskell-c-parsing-xml/ (with grain of salt)
&gt; And I doubt GC would be a problem for blockchain implementation, it is not exactly a hard real-time system. If they want good performance, actually they need to be quite fast and predictable - especially when taking part in consensus.
That's not the requirement at all, not sure why you're being upvoted. For A* to work properly (read: find the shortest path) the heuristic must be *admissible*, meaning it never overestimates the distance to the target. A* works perfectly fine for problems that do not have the triangle inequality property if you can find an appropriate heuristic.
Ernst &amp; Young just open sourced a [project](https://finance.yahoo.com/news/ey-open-sources-nightfall-code-142024265.html) to put corporate transactions on the public Ethereum blockchain with strong privacy. In the Philippines, an Ethereum-based system has paid people to [clean up](http://www.bbc.com/future/story/20190613-a-simple-online-system-that-could-end-plastic-pollution) Manila Bay, at a cost 15 times cheaper than the previous government-run system. Popular applications on Ethereum so far include a derivatives-based stable currency, a decentralized exchange, and a prediction market.
You really can't think of uses of a decentralized trustless "database"? &gt;made-up money Money and value are made-up human concepts. And humans decided the new made-up crypto money also has value. that's all there is to it. If people stop believing in bitcoin its value will crash - just like the value of dollar would crash if people stopped believing in it.
I guess we'd better take action and start making Rust a much *worse* language in order to limit its usefulness to tech giants...
Blockchain developer here; can confirm. We're rewriting Hyperledger Sawtooth in Rust (from Python) and the performance difference is substantial.
True, but you make it sound like somehow that’s related to the programing language. This cryptocurrency was going to be made with or without rust.
That is trivial to the point of irrelevance. It would always return the nodes you gave it, because connecting them directly would always give you the shortest path between those two nodes.
That’s interesting, thanks.
Yeah, I don't think it even was GHC in that comparison, It was Hugs.
Ah, sorry yes you are absolutely correct. I, ugh, had the pointers messed up. Yes this absolutely correct consistency isn't required. As long as the heuristic never overshoots, then A\* will indeed find the correct answer, if it does overshoot then A\* will behave like Uniform search with wrong distances and will pick the node it perceives as 'closer' only because it adds the heuristic and the distance to the node. Am I recalling it correctly?
real-time != performance. It simply means that you can guarantee timings. You don't need to guarantee timings for blockchain, you just need it to go fast. A good GC might even improve your throughput and therefore performance with specific loads. But if you need to make sure that data is processed at exactly some frame rate, or need to follow a law that says your CV algorithm must be done evaluating whether the car in front of you is braking within 0.5 seconds or otherwise emergency brake, pausing the application to perform GC every two minutes won't do.
post with /people writes! Thanks a ton.
Rust's advantage is that you can turn `unsafe` off by encapsulating it. There is no disadvantage to having it and using it, only an advantage by not having to use it. (Which you don't have to do when you use libraries like nalgebra and ndarray.)
Nalgebra's unsafety comes from basically two sources: - creating container types from uninitialized memory (which is soon-to-be overhauled) - exposing public `unsafe` indexing operations: https://www.nalgebra.org/rustdoc/nalgebra/index.html?search=unchecked The first is, unfortunately, necessarily unsafe. Something like the [zerocopy::FromBytes](https://docs.rs/zerocopy/0.2.4/zerocopy/trait.FromBytes.html) trait could give us a route to safety here if it ever makes it into the rust core library (I hope it does; `zerocopy` is a criminally under-appreciated crate). The second is an essential public API which we (iirc) rarely use internally. Most of nalgebra's procedures use checked, safe indexing operations. Because of the unique way nalgebra represents matrix dimensions, most functions _also_ begin with up-front size assertions, too. These all get optimized away in release builds! ...but not in debug builds. [This is increasingly a headache for us, as nalgebra and the rustsim family of crates makes its way into gamedev.](https://github.com/rustsim/nalgebra/issues/217#issuecomment-440804721) Using nalgebra should _not_ be a choice between bearable compile times and bearable frame rates. There is no clear solution to this. Since even the unsafe unchecked indexing operations have `debug_assert!`s, just exchanging the checked indexing operations for unchecked ones wouldn't solve the problem. --- I'm a huge fan of actually looking at assembly, but doing so with nalgebra is a huge pain. The library is _super_ generic, and most functions are never monomorphized in the course of compiling nalgebra itself. So, each time you want to actually dig into how rustc/llvm is optimizing a function, you need to create a call site where the function is monomorphized for particular generic parameters. Since nalgebra's operations are generic not only on the numeric type (i.e., `f32` or `f64`) but also the dimensions of the container types (which may be static typenums or `Dynamic`), you typically need to create many different instantiations of the function to get an adequate sense of how it's optimized. I'd kill for a version of `cargo-asm` that let me summon particular monomorphizations at particular opt levels on the fly.
Depending on the consensus algorithm used, you might need to be able to answer reliably within a quite narrow time window. This is maybe not performance critical on a single node, but performance critical for the network.
Can't get this to work due to lifetime issues: use std::cell::RefCell; struct GUI&lt;'a&gt;(RefCell&lt;Vec&lt;Box&lt;dyn FnMut() + 'a&gt;&gt;&gt;); impl&lt;'a&gt; GUI&lt;'a&gt; { fn register_callback(&amp;self, cb: impl FnMut() + 'a) { self.0.borrow_mut().push(Box::new(cb)); } fn quit(&amp;self) {} } fn main() { let cb_registry = RefCell::new(Vec::new()); let gui = GUI(cb_registry); let cb = || gui.quit(); gui.register_callback(cb); } Any suggestions?
I think there was a gov project about using blockchain to make a record of the origin and “journey” (can’t think of a better word) of food products. Could help with safety and stuff I guess
Maybe you could base this on the petgraph traits. There is the will to make petgraph an organization on github and separate the traits in a separate crate. I think this crate could join the organization once it is created, if you want to.
You have to pay taxes in dollars. Key difference.
&gt; Without support for filesize to avoid any IO calls but use existing metadata, I don’t think DUA can adopt it. That's precisely what `file_real_size_fast()` is for - on platforms where the metadata struct is sufficient it can just reuse it. On Unix, it reduces down to: std::os::unix::fs::MetadataExt let file_size = metadata.blocks() * 512; You'll be wanting to slurp that extension in anyway for the nlink()/ino() check. On Windows I'd *hope* the metadata needed will be cached by the directory read, but either way it's more important to be correct than fast.
Such a shame they used Rust to implement a shitcoin/scam. I hope we can at least get as many useful crates out of this as possible.
Stable Rust and nightly Rust are "competing" programming languages. Choosing one over the other is just another engineering trade-off to make. In a competitive market, if nightly Rust is a better language for your project, not choosing it is a bad engineering decision.
There's a one thing: defending real, good money from evils of local coercion gangs (AKA governments).
Go isn't just garbage collection based, it's garbage based
AFAIK money worked also thousands of years ago, when the thieves weren't that organized...
You can work around it by using `Rc` to reassure the borrow checker that `gui` will last at least as long as the callback: fn main() { let cb_registry = RefCell::new(Vec::new()); let gui = Rc::new(GUI(cb_registry)); let gui2 = gui.clone(); let cb = move || gui2.quit(); gui.register_callback(cb); } The biggest downside here is that now you have a memory leak from an RC cycle. You can break the cycle by clearing the contents of the cb registry, or by downgrading `gui2` to a `Weak` RC, and upgrading it every time you want to use it.
Thanks! Rc+Weak might be the way to go then. The example was actually an excerpt from a larger project, and I've been stuck at this for weeks. Sometime I was toying around with Rc/Weak refs, but found them cumbersome to specify for every callback. Was hoping there was a way around that. The most succinct version that I came up with from that rabbit hole was using an inline block like gui.register_callback({ let gui = /* Rc... */ gui.clone(); || gui.quit() }) Still hoping there is a less ugly way to do this :)
No, Diesel does not satisfy their requirements. It is not really possible to connect to different types of databases in one application, selected (presumably) via config file. Yes, Diesel supports different RDBMS's, but you need to pick one at compile time. This has always been a very serious shortcoming of Diesel (the benefit being, of course, that it's hopefully more efficient since it knows what RDBMS you're using at compile time). To be frank, I don't think there is a single Rust library that does this, which is unfortunate, since virtually all other languages have such a system (typically built on ODBC/JDBC/etc.).
That's not where the value comes from.
What do you mean? Like abstract classes?
Also, using a pinned nightly version means that there's no spontaneous breakage; it'll only break at the next upgrade attempt, and that attempt should be gated on build and tests passing...
Have you updated all your crates?
In [this](https://www.reddit.com/r/rust/comments/bx3pc1/a_question_about_idiomatic_rust/) thread I asked a question, but since the thread was quite old, I didn't get an answer, so I'm trying here: When reading a file the following works: let line = line?; let mut iter = line.split(","); but this doesn't: let mut iter = line?.split(","); ^^^^^ - temporary value is freed at the end of this statement | creates a temporary which is freed while still in use How come the first version works, but the second doesn't? My explanation would be, that `iter` holds a reference to `line`, but `line` doesn't live long enough, is this correct? If so I would still have thought that the compiler was smart enough to understand that it needed to keep `line` around? &amp;#x200B; This reminded me of an example from Programming Rust: &gt;For technical reasons, `io::stdin().lock()` doesn’t work. The lock holds a reference to the `Stdin` value, and that means the `Stdin` value must be stored somewhere so that it lives long enough: let stdin = io::stdin(); let lines = stdin.lock().lines(); // ok Is this the same principle in play here?
If you don't please the borrow checker you will.
I think you'll find things line a high performance BFT implementation delivering thousands of TPS has very complex network protocols that really prefer not to GC unpredictably if they don't have to. Not necessarily real time in that planes don't crash if deadlines are missed but probably retries and the such would have a negative impact on TPS. Impossible to say without looking at all the code though.
This sub is regarding the [Rust programming language](https://www.rust-lang.org). You might be looking for r/playrust.
The difference though between Rust vs something like OCaml is much smaller than the difference between Rust/OCaml &amp; Python. Obviously it is hard to benchmark, but https://benchmarksgame-team.pages.debian.net/benchmarksgame/ gives some idea.
But here we're not talking about Tokio but using Rayon as a reactor. Shouldn't Rust futures be zero cost, in that it compiles to the hand-rolled state machine you write anyway?
Learning Rust after OO-languages. I have method print() in trait Print that accepts &amp;self as parameter, so I can't write default trait implementation. Does it mean that if I want to have same print() (trait Print) implementations for different types I have to copy&amp;paste that implementation for each type? pub trait Print { fn print(&amp;self); } impl Print for Point { fn print(&amp;self) { println!("{}, {}", self.x, self.y); } }
Libra isn't "made up money" it is a stable coin currency that will be backed by a basket of other currencies. So like the dollar (or whatever) in your pocket it is a currency not money and the promise behind it is only as good as you trust those entities behind it. If you're a gold bug youv probably won't go near it, if you're one of the two billion FB customers and have a need for a fast and cheap payment system you might well use it. I mean you're already using Facebook, what's more compromise?
The Amazons and Facebooks of the world have use cases with unique constraints that might inform some of these choices. Andrei Alexandrescu brings up a really interesting point in this panel; (https://youtu.be/BBbv1ej0fFo?t=1880) he was working on some project at Facebook for which they evaluated using a GC'd language to ease development, but ruled it out after early benchmarks because the costs incurred just by the extra power consumption would be measured in millions of dollars annually, let alone the cost of additional hardware. Also it's a blockchain, so without reading the details of their specific thing, I would assume it's designed to run 24/7 on as many machines as possible.
It only checks that for a specific input, and well-formed inputs usually don't trigger it. You can try to find inputs that do via fuzzing, but miri is impractically slow for that.
Ah, probably none. I forgot that std has `try_lock()`.
Exactly what modern monetary theory says which is I'm sure what you're alluding to. Corporations advanced the idea that money is speech and have been quietly and effectively taking over the world since. So it's only logical that corporations create their own currency, and perhaps eventually actual money (just remove the requirement for backing government fiat currency deposits) and probably easily convince compliant governments to take it for paying taxes. In fact they will probably want to become the tax collectors since they will be able to track every single penny spent - especially when they also push a corporate identity system and a Facebook ID becomes ubiquitous if not actually mandatory across the world.
Thanks, should have added that myself. Including it as an edit.
Is there a way I can download external crates permanently in my repository, so I can deliver the repo to people without internet, who have cargo and rustc installed, so they can build it?
That's not really fair even qualitatively: Hugs is an interpreter, GHC has a compiler (and an interpreter).
When I initially read this, it seemed more like a hiatus in development than him canceling the project.
Others have basically elaborated the point, but I'll offer another angle. In Rust, when you design an API, you usually have to decide whether you care about the data (pass a struct or enum) or about the interface (pass a generic or trait object). OOP languages tend to let you not make this decision by always offering both of these as a class, so you get the data in the class itself and the interface through the hierarchy (or `interface`). You can always get the same kind of thing in Rust by exposing the data through a trait, thought it is perhaps more verbose. OOP languages tend to treat data as part of the interface, but not exposed through the interface directly as methods (though people often prefer accessor-style interfaces for encapsulation reasons.)
NP, Thanks for making us aware of such a project
&gt; I'd kill for a version of cargo-asm that let me summon particular monomorphizations at particular opt levels on the fly. Okay, you know what? I have a framework for parsing function signatures and automatically generating calls to them: https://github.com/Eh2406/auto-fuzz-test Well, calling it a "framework" is probably too pompous because it's like 60 lines of code. All it does is parse function and method signatures and provide them to a callback in a unified format, so you can easily build business logic on top. We're using it to experiment with fuzzing libraries with tons of calls, but it should also let you automatically generate tons of calls to any function. I haven't used it for generic-heavy code yet, though.
In my experience that's the best solution: you want all the people working on the code to have the same environment. Updating to the nightly everyday would be a nightmare. That's why I was surprised that they were using nightly, but with a pinned version it makes sense. But take a look at the issues in the Libra repo: most of them are from people that don't have the correct nightly version set up.
Wow, they use LALRPOP as the Move parser: https://github.com/libra/libra/blob/5e034dde19a5320d7e2bdc9da25114e816b4454d/language/compiler/src/parser/syntax.lalrpop