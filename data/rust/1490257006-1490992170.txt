&gt; Wouldn't it be more consistent if functions without where would also put the { on a new line? Consistent with what? With functions that have a big additional constraint lump in it's definition or with other more light weight expressions that use `{` like `if .. {`?
Yes, that was the original purpose, but it's somewhat expanded to mean "can be iterated, but is not currently in a state of iteration". One thing is the implementation on slices `&amp;[...]` allows `for x in y {}` loops to work directly. With this impl, you can do `for item_reference in the_slice { ... }` instead of having to do `for item_reference in the_slice.iter() { ... }`. To a greater extent, this can also be used to make a generic function which iterates over something providing references - you can do `fn do_thing&lt;T: IntoIter&lt;Item=&amp;str&gt;&gt;(x: T) { ... }`, using the existing trait for this only slightly different functionality.
That's a social/management problem, not a technical one. Lessening the friction is *one* way to lower the resistance to (gradually) rewriting everything. To easier it is the less resistance you'll get.
More like, if each company is reinventing their own solution to this problem, maybe we should solve it ecosystem wide somehow. Maybe if you find a company that needs to solve this problem, they might pay you to solve it and if they are nice, allow you to release it.
Yeah, on a second look it seems like my sample was skewed. Number 2 seems indeed more popular. First: 1. https://docs.rs/brotli2/0.2.2/brotli2/read/struct.BrotliEncoder.html 1. https://docs.rs/flate2/0.2.17/flate2/read/struct.DeflateEncoder.html 1. https://docs.rs/flate2/0.2.17/flate2/read/struct.GzEncoder.html 1. https://docs.rs/flate2/0.2.17/flate2/read/struct.ZlibEncoder.html Second: 2. https://docs.rs/zstd/0.4.4/zstd/stream/struct.Encoder.html 2. https://bozaro.github.io/lz4-rs/lz4/struct.Encoder.html 2. https://docs.rs/snap/0.2.1/snap/struct.Writer.html 2. https://docs.rs/deflate/0.7.5/deflate/write/struct.DeflateEncoder.html 2. http://docs.randomhacks.net/snappy_framed-rs/snappy_framed/write/struct.SnappyFramedEncoder.html 2. https://github.com/kali/snzip-rs/blob/master/src/framing.rs#L145 This settles my question, I'll go with number 2.
No. I am trying to share my thoughts on OO and to give some context so that people understand what I mean when I say things like "a good bit of time", because even though to me 8 years of my life is a long time, for someone that is say 50 years old then 8 years will not be as much relative to the amount of time they have lived.
Interesting, it's a more complete package than rand when it comes to distributions. Asking in favour of ndarray, - does it have any way to generate many draws from a distribution at a time (if that would be an improvement? - What's the best way to support f32?
I think there are a few factors: - First is threads. Both apps peg the CPU. The node version at 100%, the Rust version at 200%. There's a 2x speedup right there. - Then there is how strings work in JavaScript. It's basically impossible to pass a string around without copying it (passing it to a function will copy it). This makes it pretty inefficient for string-parsing tasks. It's possible I could have worked around that with Node's `Buffer` type. But then you lose all the benefit of unicode-aware methods. - There's probably an effect just from language speed (i.e. optimisations it's possible to do on Rust code, that you can't do with JS). It's worth noting that optimised (release) versions of the Rust program are ~10x faster than unoptimised(debug) builds. Some of it is probably just me writing inefficient JavaScript code (having never done any lower-level programming before starting with Rust, and not understanding what would cause perf problems). But one of the nice things about Rust is that high-performance code is idiotmatic and easy (i.e. I can use iterator methods just like I would use lodash in JS, and it will just magically be faster). It's pretty easy to accidentally shoot yourself in the foot when targetting a JavaScript VM.
Well I'm uncomfortable with bending over backwards to grease every squeaky wheel. Wait, you can't protect every single groups feelings simultaneously, so let's stop policing free speech. 
There's no "performance gap", Firefox has been competitive with Chrome for years now. It often wins in one benchmark and loses in another. There's no evidence that Chrome is faster overall.
Is the amount your employers pay what gets listed as your "salary"? In the US we don't even know how much of what our employers pay ends up going to whatever is equivalent to Swedish taxes. What you see as a salary in the US doesn't include what is officially paid by the employer for taxes, health care, retirement plans, and other benefits for the employee, but it does include the employer pays officially on behalf of the employee towards taxes, health care, retirement plans and other benefits. 
I don't like and have never liked the asymmetry in typing expressions: `a: A`. I think it should be symmetric, and preferably spaced (i.e. `a:A` or `a : A`). There are a couple of reasons for this: * It's what [Agda](https://github.com/agda/agda-stdlib/blob/master/src/Function/Equivalence.agda) does. * It's what [Coq](https://coq.inria.fr/distrib/current/stdlib/Coq.Numbers.Natural.Abstract.NLcm.html) does. * It's what [OCaml](https://github.com/ocaml/ocaml/blob/trunk/stdlib/list.mli) does. * It's what [Haskell](https://github.com/haskell/vector/blob/master/tests/Utilities.hs) _appears_ to do. * It's what [type theory literature](https://arxiv.org/pdf/1611.02108.pdf) does. * ~~I honestly don't know of any language _but_ Rust that does this.~~ Swift, Scala, and Pascal are examples that use Rust's style. * It conflicts with value assignment in normal struct constructors. I'm much more comfortable with this: ``` let x = List::&lt;i32&gt; { head: 0, tail: None }; ``` Because `0` and `None` are values, not types. Some counterarguments that I can imagine and my responses: * _Type assignment is not a symmetrical thing, so the operation should not appear as such._ Subtraction does not commute and thus loses some of it's syntactical symmetry, yet we still want `2 - 3` or `2-3` over `2- 3`. The same is true for exponentiation which is even worse in terms of swapping across the operator. * _We've been doing it forever so why should we bother changing it now?_ Changing how we handle style is completely different from changing an API, no code will be broken if we make the change going forward. * _Who cares what other people do, we're Rust._ We should start caring when it seems like just about everyone else that uses the typing syntax that Rust has adopted views it as a visually symmetrical syntax. * _It looks ugly._ I wager you're in the minority of the greater programming language user community. 
I don't understand?
Scala, Swift and Pascal are some examples of languages using the same style as Rust. And like Rust they have parameter lists, while your examples all use automatic currying.
You can write `fn my_other_computation(obj : SomeObject) -&gt; i32` and it will work. The downside is that once you hand over `obj` to that function, it's no longer yours to use.
Rust desugars (?) this to fn my_computation(obj: &amp;mut SomeObject) -&gt; i32 { my_other_computation(&amp;mut *obj) } So in fact they're exactly the same type but for convenience reasons the compiler inserts a reborrow. 
What languages are you familiar with? In the main function obj refers to the actual struct. When you call &amp;out and pass it into the my_computation you are not giving it a struct but the memory address of the struct in main so it can mutate it. The obvious alternative is if you pass in the struct itself with just : SomeObject which works if it implements Copy in that case you now have two objects that can be changed independently.
The Try traits looks great, I've been using a few functions that return a Futures and other odd things and can't wait to get rid of my macros in favour of `?`.
Everything after the colon is part of the type of the binding. `obj` is a *reference* to a SomeObject, or a borrow of a SomeObject, a safety-checked pointer, not the SomeObject itself. You then move that reference into my_other_computation, although that may indeed be syntactic sugar.
Yup, being able to publish to an internal server is what we're trying to figure out if people want :)
Will rust.vim ever include the integration with RLS ? Or is this definitely out of its scope ? 
People expressing discomfort with the choice of name is also free speech. The author of the crate took that into account and responded by changing the name. Sounds like the system is working as intended!
It's out of its scope; you'd use the regular language server plugins to work with RLS.
For checking errors at testing (using mainly `PartialEq`)
In particular: https://docs.rs/hyper/0.10.5/hyper/net/trait.NetworkListener.html / https://docs.rs/hyper/0.10.5/hyper/server/struct.Server.html#method.new. See also the impls of https://docs.rs/hyper/0.10.5/hyper/net/trait.NetworkStream.html
This is really exciting. I've been a dabbler in ATMegas and ATTinys, never ARM architecture, but I think I might look into getting one of these for my next project. Ever since first hearing about rust in 2015, I've always thought it'd be awesome for embedded projects. After a little reading it appears Tock OS can run processes of any language, but I'd definitely choose rust. I'd say the biggest downside atm is price ($60) especially when comparing against something like a raspberry pi. However the extras including accelerometer, magnetometer, BLE, temp/humidity sensor are awesome.
A DLL is a dynamic library, just a chunk of compiled code that can be 'linked' and used from other compiled code. Basically, you need to tell rustc/cargo how to find these DLLs. Installing, in this case, means moving the DLLs to a known place (Program Files, home directory, etc). Once you've done this, you will add that directory path to %PATH% and cargo will find them and be happy. You can add paths to %PATH% like so: `set PATH=C:\path to your dlls;%PATH%`
I always preferred the term meandering over bikeshedding. I propose we adopt meandering as the standard term over bikeshedding. I'll open an RFC. 
[PMing answer]
Fedora already had this version in updates-testing.
My understanding is that tokio-core is planning to support running a core on multiple threads in an N:M manner (although it doesn't currently), which should alleviate this issue :)
Tokio is different too, it's an async IO stack
Yes, my understanding is that you could spin up multiple Cores and work-steal between them.
I feel the way it's now is better, since that's how English and other languages do it. Let me give you an example: this is the example.
&gt; Calling both fsync and close still doesn't provide any true guarantees. The parent directory may not have written its link to the file yet, As noted in the `fsync` manual page, you have to `fsync` the parent directory to guarantee a newly-created file's link has been written. That's totally different from saying `fsync` provides no guarantees. &gt; the NAS may still keep the data in RAM, the disk could still keep the data in cache, No, on a properly-designed system, `fsync` must sync the modifications to permanent storage. This is guaranteed by POSIX. It's the whole point of the call. &gt; or the user could lose their USB stick. Sure, but that's a qualitatively different failure mode. Many systems use fsync as a barrier: one modification shouldn't proceed until another has. For example, SQLite can't remove a section of the write-ahead log until it has been successfully applied to the B-Tree. Thus it does an `fsync` on the B-Tree before truncating/overwriting/removing the relevant write-ahead log bytes. (Also note in that scenario, `fsync` on the parent directory is unnecessary for a transaction on a pre-existing database.) `fsync` provides a guarantee of ordering. Without this guarantee, you have no durability. The whole database (not just the current write) can be corrupted by power loss because pages are in an inconsistent state. &gt; Luckily, it's not about guarantees, it's about responsibility. ... if you don't check the return value of `close` (whether or not you call `fsync` first) you've violated the API contract and shirked your responsibility. Okay, I see your point about the system reporting failure after `close` in some fashion. I concede there might be cases where it's useful to know the system has taken over responsibility for error reporting. In general, though, I have a totally different view of API contracts. I see them as entirely for the benefit of the caller: if you make these calls, and the system/library returns this status, it guarantees that. I don't agree the caller has a responsibility to check return codes where this provides no additional guarantee. `close` after `fsync` is such a case.
It's always referred to as mofo internally, even by mofo folks themselves. I'm pretty sure it's an intentional joke, because there are many "XyMo" shortforms as well and they could have made it FoMo to avoid some connotations (FoMo has others, but more SFW).
Yeah, what you may expect in a stock bonus program is replaced by a kickass $$ bonus program. The corporation is wholly owned by the foundation and probably will never give out stock, to employees or via IPO. Quite possible that the legal makeup of the corporation forbids it from happening. Idk.
In the bay, lots. Well, in the bay there are lots of devs being paid to do Rust things, but many of them were previously (or still are) XYZ devs at the same company and weren't recently hired to do rust. I'm not sure about open job positions. A couple weeks ago we were having a discussion at the bay area meetup, and being paid to work on rust came up, and I realized that there was only one working person (not counting a student) left in the room that wasn't doing Rust at work, and at a broader level &gt;50% of folks I see at the rust meetup are using rust at work. That's pretty neat, and a major change from last summer. Outside of the bay it varies.
How to write a macro `foo!("a string")` that computes a function on a string at compile time? I believe this should be possible with procedural macros, but I couldn't find an example.
Would an `assert_match!` macro help?
With further knowledge on the state `a: A` I agree that more modern languages that use `:` for typing use `a: A`, but it should be clear that very few languages do this (i.e. use `:` for typing variables at all). Most languages use `:` for some kind of subtyping (inheritance or interfaces or whatever) in which case I see things like `A : B` more often then I see `A: B`. That's a bit larger of a crowed though so I don't know the general pattern among languages like C++, C#, etc. For the general programmer, who I assume is more used to seeing `A : B` (which I admit I could be wrong about) wouldn't it be more natural to see `a : A`? (This argument is coming from a place of familiarity, not a place of correctness)
Great board but way too expensive. When reading article I was thinking "if it's in 25$ range I will order two". When I saw price: "I will stay with 9$ C.H.I.P or STM32F family for realtime/IoT hacks".
Interesting, thanks!
Cool, yea the program was just written that way as a toy example to demonstrate my clarification. To pass in the object, you'd need to deref with * though right?
Many: C++, C#, Java, Python, etc. etc... Makes a lot of sense though, I think you're saying basically the same thing as me, so awesome!
Wow, that looks very convoluted. Is there any reason to use `From` instead?
Gotcha, yea that totally makes sense, thanks!
Wouldn't an implementation of `From` have the exact same "conflicting implementation" problem? Or what do you mean?
I hear you. The STM32 boards are pretty attractive (there are a few with similar sensors at very low prices, although no BLE), and we'd like to port Tock to those chips ASAP. The cost of this particular board is high because the sensors are fairly expensive but, more importantly, the volume is very low (~100) for now. Our hope is that if there is enough demand for the board we can start doing bigger runs and bring the cost down significantly.
Absolutely! There are a lot of things that would make this more ergonomic. From that first error alone, having either const params (`impl&lt;const n: usize&gt; ToFoo for &amp;[&amp;str; n]`), some more, implicit coercion from `&amp;[&amp;str; n]` to `&amp;[&amp;str]`, or just more helpful error messages explaining why `&amp;[&amp;str; n] != &amp;[&amp;str]` would be great. In the meantime, this post proposes as solution that works with Rust 1.16 :)
Is there any reason that `AsRef` is seperate from the `From` trait though? It feels like `AsRef` is a subset of `From` behavior. 
AsRef has a different directionality (&amp;self -&gt; &amp;T), which means orphan rules are different from From (T -&gt; Self).
Um, why would a sync error get reported later at close? That kind of defeats the whole purpose of sync.
[removed]
I don't quite see the problem. This is obviously a "tock enthusiast" board more then anything else, so it doesn't have to compete with other boards as long as we are not talking about large scale production. I'm thinking about either buying and imix or an hail, as I'd like to try out tock more then trying to make it work on the boards that I have around.
Well, if all you have is a reference, then you can't just dereference it and move the value into another function - that would violate ownership (the caller of your function excepts the object to be still usable after your function returns).
&gt;Also, the tree-style tabs add-on is awesome. This is the main reason I use Firefox over Chromium.
Thoughts from a quick glance at things: main.rs: the big if/else/else block could be a match statement. You often have this pattern: match blah { Ok(x) =&gt; x, Err(e) =&gt; { println!("Error {}", e); return; } } Since this shows up so often, I wonder if it might make more sense to use try! or ? instead, and then standardize the error handling. In general you seem to spend a lot of time in `Result`-handling boilerplate. Might be worth looking into `Result`'s various map and unwrap methods. Other than that things look reasonable to me, but hey, I'm very beginner myself! Kudos for building this and putting it out there!
If anyone is interested in help maintaining it, I'd be open to that! I haven't been merging PRs thanks to this work being outstanding, but in general, more committers would be good.
No, as you suspect, it isn't. Lets say the employer pays 100k SEK. About 30% (iirc?) goes to taxes. The remaining 70k is what's commonly listed as salary. From this, I'll pay about 31% in taxes. That leaves me with 48.3k. I'll be paying a 25% VAT on non-food, non-news/literature items. (EDIT: About 12% VAT on food, news, literature, iirc) Details [on Wikipedia](https://en.wikipedia.org/wiki/Taxation_in_Sweden) as always. One thing that's mentioned in the Swedish version of the wiki article but not the English one: It's hard to compare taxes between countries from these numbers alone. For example, German tax payers will pay additional insurance fees for unemployment, health care, and such. For Swedes, these are included in the calculations above.
You're right about inheritance, didn't think about it at all. Colon is all over the place :) Thank you for your answer!
I can second this. I recently resumed work on a Qt app I've been periodically updating for about 15 years, and was disappointed to discover that there has been no real progress in the last 4 years on improving native look and feel on the desktop platforms or achieving it on mobile. The vast majority of the current work on Qt is trying to get QML to feature parity with where QtWidgets was 5 years ago, improving support for 3D graphics applications, and working better for embedded applications where there isn't an established native look and feel (think cars, medical devices, and kiosks). It's still the best option for supporting multiple desktop platforms with a single code base, but that's mostly because everybody else gave up and decided to just write different native UI code for each supported platform. I have a passable version of my app working on Android now, but it's a little quirky in ways that reflect dozens of minor bugs in the framework that will each take hours to dig into and fix properly. Adding a QML-based UI (while continuing to maintain the QtWidgets one for desktop platforms) might make it a little better, but is almost as much work as just writing a proper native Android UI for it, and won't get me to anything vaguely resembling native look on iOS. I have the beginnings of an idea for a cross-UI-framework, cross-language UI definition schema which could be implemented widget-by-widget via a massively parallel development project that takes advantage of all the existing programming language bindings for various UI frameworks. I think that's the only way we'll ever get proper-looking cross-platform apps without case-by-case herculean coding effort, but just getting that started would take quite a bit of effort in itself.
Did you consider using serde\_json for the JSON bits? You have dozens of lines of code like `...and_then(|x| x.find("after"))` that are difficult to write and read, error-prone to update, and produce super unhelpful error messages ("error somewhere in the JSON"). I really think Serde would be a massive improvement here. I don't know what the data looks like exactly but the idea is you define ordinary Rust structs: struct AllComments { children: Vec&lt;Comment&gt;, } struct Comment { likes: bool, link_id: String, id: String, } And then Serde takes care of mapping the raw JSON document into your struct in a way that is efficient and produces amazing errors when the server response does not align with what your code expects.
To be honest I skipped over serde because I wasn't familiar enough with it. I just stuck to what I knew. I'll certainly look at serde for the future of this project, thanks!
Where are you getting it manufactured? I've done manufacturing runs of [these boards](https://www.ascension.engineering/collections/frontpage/products/apollo-v2), and our quantities are comparable to yours. The end product is rather different in scale, though, with mine being logically much more expensive to produce. If you want my advice, get [circuithub](https://circuithub.com/) to quote you a price with their instant quoting tool. It should be a lot less than $60 per each, even with a profit margin added for your sales. Another important cost saver is to get your pin headers directly from China. All of the ones on the US market are both expensive ($1.00 per each versus $0.01 per each) and total garbage. The Chinese-market pin headers are much higher quality in my experience.
Thanks! We'll give circuithub a try! We're using Macrofab for this run. I not sure if we're shipping with pin headers. By the way, it's all totally open source and open hardware, and we'd have no qualms with someone else figuring out how to make them cheaper and doing that! https://github.com/lab11/hail
I'm thinking about the same stuff. One of the Qt problems is that it's still a C++, which scares a lot of developers (even Dropbox uses PyQt, afaik). Yes, rust is much better and easier C++ alternative, but it's still a system language. It's not really suitable for GUI (at least for fast prototyping). The idea of the language independent UI definition schema is bothering me. But I can think only about few existing examples: Tcl/Tk, QML and HTML. - Tk is a strange animal leaving on its own. 26 year from the first release and still nowhere near to being popular (I know only 2 applications that use it). - QML has great ideas, but it's resource heavy and it supports software rendering only since 5.8. Now it's just a bit lightweight Electron alternative. - And HTML+JS+CSS is broken by design: too many features, too complex, too hard to implement (just look at any rendering engine or JS VM), etc. and still you need i7 to render a simple animation. Currently I'm thinking about a tiny-tiny html/css (like qml/qss) subset that should be designed specifically for one purpose - widgets-based UI.
You're right that true linear types, [in the mathematical sense](https://en.wikipedia.org/wiki/Linear_logic), can only exist if panics don't. However, for a real-life programming language like Rust that would be far too inconvenient. Personally, I'd like `File` to *have* an implementation of `Drop` (which calls `close` and forgets the return value just like today) but which only ever gets called on panic (or on explicit calls to `std::mem::drop`). `File` can still be linear on the happy path; i.e. fail to compile if it ever goes out of scope. 
Wowowow.. Hold on a moment. First you say &gt; Our goal is this: We want to have a function that can take both string slices as well a slice of string slices And your first attempt does precisely this. The problem is, you passed the function an array of string slices, not a slice of string slices. If you convert the last call from println!("{:?}", (&amp;["yay"]).to_foo()); to println!("{:?}", (&amp;["yay"][..]).to_foo()); That is, you first convert your array into a slice, [it compiles just fine](https://is.gd/Rf88jw). (It's still a neat trick, I just wanted to point out it didn't need to be so convoluted to accomplish your original goal)
Oh, sorry, I didn't explain my motivation for this. I'll add it. Basically this whole thing is about making this easy to use from a user's perspective. Having to add `[..]` is a solution, yes, but not an elegant one.
Thanks, that's a great explanation! I've linked to this in the post. &gt; I'm curious why the trait is parameterised. You are right, the last version does not need this. I just left it there after iterating on the code a bit and didn't think about it. I've pushed an update with much cleaner code. Thanks!
I'm 99% sure that you'd get the exact same error as in First Try section. Or did I misunderstand what you meant?
Current URL: https://silverwingedseraph.net/programming/2017/03/13/piston-a-game-library-in-rust.html
Looks pretty solid. In case it's helpful to you, here are some comments from a quick look over your code: I notice in board.rs at least that you implement a lot of functions independently that would make sense to put in a struct's `impl`. For example, pub fn reset (board: &amp;mut chessboard) { ... } I think this makes more sense to implement thus: impl chessboard { pub fn reset(&amp;mut self) { ... } } Then just replace every reference to `board` with a reference to `self`, and calls to `reset(board)` become `board.reset()`. Camel-casing struct and enum names would make this easier to read, too, IMHO. `chessboard` -&gt; `Chessboard`. That would also resolve your conflict with keyword `move` in `moves.rs`. `_move` -&gt; `Move`. In think.rs I see you're using `unsafe` to work with a mutable static field. I feel confident that you could dispense with these `unsafe` blocks. One way to do it would be to make `alpha_beta` return `(i32,bool)` where the second member of the tuple is equivalent to `time_up`. Then the caller (`start`) just checks what `alpha_beta` returns, rather than checking the static `time_up`. Looks like you do something similar in zobrist.rs. Many of these `static mut` variables seem like they would do well as members of a struct: struct ZobristHasher { zobrist: [[u64; board::full_board_size]; 13], castling: [u64; 16], side: u64, EP: [u64; 8] } Then all the functions in the module could go inside `impl ZobristHasher` and just refer to the state on the struct. Anyway, awesome that you built this!
Does Specialisation help here?
Yes, thank you. I couldn't figure out why all examples of userland apps were in c. This seems silly/unexpected given the kernel is written in rust! Oh well. One day I'll blink a light w/ some rust code.
[In limerick form](https://twitter.com/llogiq/status/844625989363793920)
Just to be pedantic: &gt; Now the Copy trait asserts that cloning the value is equivalent to a move (ie a memcpy). A `.clone()` is not really something special, and in fact can differ from the copy behaviour. The copy-trait is mostly part of the linear type-system and does not affect how the program behaves during execution. That being said, *moving* of values does not really exist, it's still a memcopy, but the type system ensures that the old value cannot be used anymore. 
For what it's worth. With elision that would be: `for Path:From&lt;&amp;T&gt;` or `for T: Into&lt;&amp;Path&gt;`. Which doesn't look to bad.
The first thing that comes to mind is nesting the NamedInterval inside the other struct. Dunno, maybe someone can come in with alternative ideas.
How? Unless I'm missing something, you need *explicit* extra bounds. And the extra bounds are in this case negative.
I ended up implementing a macro :). Turns out it wasn't as complicated as I thought, something like this: macro_rules! impl_interval { ($struct_ty:ty) =&gt; ( impl Interval for $struct_ty { fn start(u64) -&gt; u64 { self.start } fn end(u64) -&gt; u64 { self.end } fn with_coords(mut self, start: u64, end: u64) -&gt; $struct_ty { self.start = start; self.end = end; self } } ); } Which would then be used simply: ``impl_interval!(MyStruct)`` The error message is quite descriptive, too. For example if ``MyStruct`` somehow does not have a `start` field, the compiler says so. Until trait fields are implemented, this seems like is an acceptable solution.
&gt; No, on a properly-designed system, fsync must sync the modifications to permanent storage. This is guaranteed by POSIX. It's the whole point of the call. I've been following LWN and I can tell you that at least one hard drive brand has been observed setting their consumer-grade drives' firmware to lie about sync status to fudge their performance numbers. (It should be resettable with their standard, proprietary, Windows-only disk configuration/diagnostic utilities though.) I can't remember which one though. I'll have to look it back up when it's time to buy more drives.
I dunno man, seems less like abuse and more like directly stating exactly what you mean to me :P I mean, if you want something to work for `&amp;T` and `&amp;Y`, then you use `&amp;self` and impl for `T` and `Y`, or you use `self` and impl for `&amp;T` and `&amp;Y`. It just so happens that `T` and `Y` are `str` and `[&amp;str]` in this case.
Thanks! The point is describing the difference between `fn foo&lt;R: Read&gt;(mut r: R)` and `fn foo(mut r: Read)` which some people will find confusing. Are traits unsized only because they can be implemented by an unsized type, or is there another reason? I.e. if `fn foo(mut r: Read + Sized)` was legal couldn't the compiler generate the appropriate move?
Ah, it would, wouldn't it? My first thoughts are often wrong!
Keep on having second thoughts, then! They compile! 😄
I was giving it some thought, and I realized that wrapping `Read` makes sense if you want to avoid allocations because you can just write to the buffer you're passed, but looking at the types you linked, it doesn't look like that's what's happening; they all use intermediate buffers anyway. Then I realized that maybe they're protecting from partial writes, because the `Write` interface doesn't really have a provision for that: either a write is 100% successful or the type should roll-back to before the write, but there's no guarantee. By requiring a buffer to write to, the encoder can be sure that there's no partial writes and so the encoded byte stream remains consistent. But that really shouldn't be the encoder's concern because a writer type that fails after a partial write but retains the partially written data isn't really complying with the interface contract.
Addendum: it looks like /u/acrichto wrote all the types in the former category, maybe he can weigh in.
Looks like the top one had 124 "Errors" (whatever that means...) and Tokio is neck and neck with the next two, which are different versions of the same framework. 
Tokio is really topping the benchmark! Very impressive. Iron on the other hand appears with very low performance (5.5%), and some errors(58). Probably some bug going on... 
Good to see Tokio in top 3. Latency seems to be much higher compared to others. tokio-minihttp 459.7 ms
&gt; Are traits unsized only because they can be implemented by an unsized type It's not "only because", this is not a reason in the first place. That reason does apply to `R: Read`; except that there is an implicit `Sized` bound so that you don't have to specify it yourself. Unboxed trait objects themselves are an unsized type. `Read + Sized` would not help. I kind of feel like you are misunderstanding what unsized types _are_. Arrays are not unsized types. There are basically two kinds of unsized types in Rust, though you can create more. One is `[T]`. This is not an array or a vector. This instead means "contiguous memory containing an unknown number of copies of `T`". It can't exist on the stack, because it's an unknown number. It's really a partial type, and the full type only makes sense when you use it behind a pointer. `Box&lt;[T]&gt;` or `&amp;[T]` are pointers to contiguous memory, and the length is stored inline next to the pointer. The other kind is the trait object. That is `Trait` (e.g. `Read`). `Trait` on its own means "contains some object implementing trait `Trait`". However, we don't know the size of this object. It's not that the object could be an unsized one, it's that we know nothing about the size of the object so even if it is a sized one we don't know the size. Again, you use this behind a pointer (`Box&lt;Read&gt;` or `&amp;Read`), and a vtable ptr (which has type information and pointers to methods) will be stored inline alongside the pointer. `mut r: Read` doesn't make sense for the same reasons that `mut r: [u8]` doesn't, they both reference incomplete types.
I'm wondering if a bunch of issues could be logically combined into a single one with bullet points. If minor issues could be combined into a story that gives clear gain, it would help inspire people to contribute
Cross posted to /r/embedded already, will do the same for /r/electronics, thanks! I got to tell bunnie a bit about Tock last summer when I happened to be in Singapore for a conference, so he at least vaguely knows about it :)
Why is it "rus" under the Language column but "Rus" under the platform column? How would one file a bug to fix that?
I think we should differentiate between what the current version of one Rust compiler does vs. what the language is. &gt; For trait objects the Rust compiler must generate a vtable and do a dynamic lookup at runtime to find the read method. This is not true in general. The Rust compiler currently does do that, AFAICT, but it is possible to compile such code in various ways. In particular, some C++ compilers do “devirtualization” where they rewrite code written in “trait object” type into code written in “type parameterized” style. Conversely, in theory the Rust compiler could also do "virtualization" in many cases, where it would take a type-parameterized function and rewrites it as if it were written in trait object style. This could be useful, for example, if one is optimizing some generic code for size instead of speed.
Wow. I didn't think `vim` took in new stuff. Can we get Python to do a bloody `:setl et`?
protip: the Swift devs may be forced to fix llvm's alloca support to make their own polymorphically compiled functions efficient, and Rust might be able to steal that work. That said, it's unclear to me that doing these kinds of optimizations would ever fly in the Rust community...
These libraries are industrial grade. Give tokio some time and it'll catch up.
I work as a C++ developer in a latency sensitive industry, and have gone to program in Rust exclusively in my spare time since 2 years ago. I am the annoying evangelist in my company, but I also share some of the pain points mentioned in OP thread. Among others, the lack of constexpr equivalent and non-type generics are bothering a lot of people coming from C++ who want uncompromising performance. Sometimes these shortcomings, although temporary, are dealbreakers. If these can be improved soon, I'd expect the conversion rate from C++ would be much higher; you don't really have a lot of incentives to switch language if there are significant features absent in the new one. In the mean time, I would argue that C++ users are the most relevant users to be converted to Rust because these two languages have similar design philosophy (zero-cost abstraction, non-gc/RAII, low-level control) and use cases (high performance system/application, embedded, infrastructure). If we put too low a priority for these features, I am afraid the momentum would be lost in potential C++ users as the negative notation about Rust may stick.
The [other benchmarks](https://github.com/TechEmpower/FrameworkBenchmarks/blob/2be8a49dcd9b154301a21ee4d6e2e1a2bfa6eb80/frameworks/Rust/tokio-minihttp/src/main.rs#L53-L54) are both [database related](https://github.com/TechEmpower/FrameworkBenchmarks/blob/2be8a49dcd9b154301a21ee4d6e2e1a2bfa6eb80/frameworks/Rust/tokio-minihttp/src/main.rs#L82-L120) and hence rely on very different infrastructure than the plaintext/json benchmarks (which are just text flying around really). Currently the benchmark uses rust-postgres in conjunction with futures-cpupool, so it's not as "async as it could be" in the sense that we're up front paying for synchronization costs across threads which you otherwise wouldn't pay if you didn't need to have a thread pool. Other than that last I played around with these benchmarks the results are extremely sensitive to minor configuration such as [the number of thread pool threads](https://github.com/TechEmpower/FrameworkBenchmarks/blob/2be8a49dcd9b154301a21ee4d6e2e1a2bfa6eb80/frameworks/Rust/tokio-minihttp/src/main.rs#L145). That basically means the benchmark can serve 10 requests concurrently which is likely way lower than what some of the higher implementations are getting. All that's basically to say that I doubt it's Tokio itself slowing it down (as is also sort of proven by the plaintext/json benchmarks) but rather just architecturally using a thread pool can only get you so far.
In some of the comments in that thread, people talk about being put off by overbearing Rust evangelists. They have a point. I really like Rust and I find myself put off by some of the extreme cheerleading. It's OK for other people to not like Rust, for whatever reasons they want to have. If their reasons seem stupid or contrived but they don't seem interested in being convinced, all the more reason to back off and leave them be.
Libraries catch up because people work on it.
Is nobody working on Tokio what your implying?
&gt; If their reasons seem stupid or contrived but they don't seem interested in being convinced, all the more reason to back off and leave them be. In discussions, whether on the Internet or anywhere else, you write/talk for the non-participating audience, not for your fellow debaters: The latter have typically already made up their mind and will rarely change their opinion, while the former can still be influenced. Of course, this makes it even more important to not appear like a zealot or overenthusiastic fanboy.
&gt; [...] as the most optimal solution will depend heavily on NUM_BITS and the architecture in question. I actually wanted to test this, because as far as I knew shift-left followed by arithmetic shift-right ("shl-sar" hereafter) is the fastest in general. So I've put them to an excellent [Compiler Explorer](https://gcc.godbolt.org)... * GCC: https://godbolt.org/g/62gCtM * Clang: https://godbolt.org/g/dR4pqF * Rust: https://godbolt.org/g/1GJP3r Clang's result is same to Rust (at least in x86-64, there are no other architectures for them), which shows that shl-sar is indeed not that bad. ARM GCC also seems to agree. Surprisingly enough, however, x86-64 GCC gives somewhat different result for 3 bits. The relevant x86-64 assembly is as follows, where `esi` is being sign-extended: sal esi, 5 ; just in case, this is same to shl in x86 sar sil, 5 movsx esi, sil What it does is to do arithmetic shift-right in two phases: first on the lower 8 bits (`sil`) then extend this again to 32 bits. I cannot easily see why this happens, especially given that there seems no performance difference between 8-bit operand and 32-bit operand in `sar` for most recent architectures ([Agner Fog's latency and throughput tables](http://www.agner.org/optimize/instruction_tables.pdf) are really invaluable for this). `movsx` will depend on `sar` output so my wild guess is that this will result in more latency, but I may be missing something else. Anyway, as at least one popular backend (LLVM) agrees to a hand-written code in Rust, I think you can just use shl-sar for now. Note that if this "detour" is actually an optimization, then there is no reason for LLVM not to detect this sign-extension pattern and optimize it; in fact both GCC and LLVM do lots of analyses on the final assembly.
Your example also has a carriage return after the period, and other examples would have at least a space after each period.
It seems like I broke hyper benchmark ):
Isn't there some kind of linter for Rust that finds allocations or other performance code smells?
I also get only one result for exactly `rust+"std::net"+hyper`, but `rust std::net hyper` yields much more. I think you were artificially restricting yourself by using `+` and the quotes around `std::net`. As for why there aren't many results that are relevant, it's because `std::net` and `hyper` do fundamentally different things. See K900's post: `std::net` does tcp and udp sockets, `hyper` does a http / https client built on top of `std::net`.
Sorry about that! It's my first time posting a link to a Reddit page. Won't happen again.
It's no worries, in this case judging from the comments it generally good discussion from both sides so it's okay. It's just for future reference. :)
Isn't this just done by llvm, through constant propagation ?
Would be excellent if the hyper-tokio (master branch) version was benchmarked, I've done some testing with it and it seems really fast, but I only compared it against slower servers so I'm not sure how it compares to these ultra fast ones.
Yes, C++ has the same "problem", if you call it that. Even the core guidelines admit there is really no good solution, see the second Note in https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#c31-all-resources-acquired-by-a-class-must-be-released-by-the-classs-destructor .
Only composition but no inheritance is actually a plus for me. I think it will be even better after delegation lands. Not sure about what polymorphism you are referring to.
This is not a helpful comment. Please see rules 1, 2 and 4 in the sidebar.
&gt; Sometimes these shortcomings, although temporary, are dealbreakers. As someone coming from C++, I'm disappointed that so much energy is spent on things such as the `?` operator or making visibility rules more beginner friendly, while far too often I still have to fight against the lack of some features in Rust that wouldn't be a problem in C++. When I started Rust in ~~2014~~ EDIT: 2013 it was under the premise that these would come to the language sooner or later, but still no luck so far. 
You are right to ask about polymorphism, but I assumed we were talking about subtyping (or polymorphism that employs inheritance).
I made a PR https://github.com/TechEmpower/FrameworkBenchmarks/pull/2611
From the top of my head: - The biggest is probably the fact that it's impossible to safely put a borrowee and a borrower in the same struct. This has very deep consequences on API design. I'm glad this problem has been encountered in the RFC about generators, because now language designers are realizing that it is a real problem. (EDIT: I know you can use that trick with RefCell, no it's not a good solution and nobody has probably ever considered using it seriously) - No `decltype` is really a deal breaker as well. The core team has recently added the `-&gt; impl Trait` syntax because iterators and futures were too annoying to deal with. I'm manipulating [types that are ten times worse than iterators](https://twitter.com/tomaka17/status/832330520004530177), and I have to put them in my structs. Since I obviously can't (imagine having to explicitely write the type of the linked screenshot in a struct), I have to adjust all my traits to be boxable and introduce a big overhead (eg. methods have to return a `Box&lt;Iterator&gt;` instead of an associated type for example). This problem also has very deep consequences on API design and is in my opinion a performances killer. - Lack of integer generics and the way arrays are handled. Try manipulating an array of size &gt; 32 and you will quickly notice how weird it is. As an example I recently had lots of troubles handling the fact that they were Copy but not Clone. - Lack of placement-new and/or write-only pointers means that you can't create uninitialized memory and fill it. You either have to make your API unsafe or ask the user to pass a slice that you will copy yourself, which is not great. - No way to force a struct field to have a certain alignment. I write GPU code, and the GPU has stricter alignment requirements than the CPU. When translating in Rust I have to add dummy fields for padding. There are other things that are more minor (eg. `Deref` being unusable in unsafe code because it can return a different object every time, the lack of alloca/VLAs, the impossibility to implement a method for `Arc&lt;Self&gt;`, etc.), but if the problems in this list were fixed (especially the first two) it would make my life much easier. 
Don't be so tribal.
I know it's a detail, but I want to change this: r.read(&amp;mut buf)?; Ok(buf[0]) Into this: r.read(&amp;mut buf).map(|_| buf[0]) Just because it feels more "rusty". Not sure if you agree :-)
What is the main difference of this vs the standard [Command](https://doc.rust-lang.org/std/process/struct.Command.html) struct? I.e, when would one be tempted to use one over the other?
Nice work! Just used it the other day to get started on windows platforms. Worked like a charm.
Simpler API and handles sh syntax cross-platform
&gt; This cannot be done safely in C++ either, since the pointer becomes invalid if the struct ever moves or is copied to another location. The compiler allows it, sure, but it isn't safe. I don't understand that point. If you follow this logic, you should also say that you can't safely pass a reference to a struct or struct member in C++ either because the struct can be moved or destroyed, or that you can't safely write data to the heap because it may have been deallocated. C++ doesn't "solve" this problem, as it's out of scope of the language to solve safety problems. &gt; I can't think of a case where a boxed trait object in a struct couldn't be replaced with a type parameter on the struct, i.e. struct Struct&lt;T: Trait&gt; instead of struct Struct { x: Box&lt;Trait&gt; } When you write `struct Foo&lt;T: Trait&gt;` it's the user of the struct that choose what `T` is. In my code I have a very precise type that I want to put in the struct, I just can't express it in the source code because it's too long. I don't want the user to choose this type for me, this is totally difference. For example, take this code and try writing it as `struct Foo&lt;T: Iterator&lt;Item = i32&gt;&gt;`: https://is.gd/kdQFRV It's not going to work out.
Regarding your last point, C++ has `alignas` which is standard. C also has it.
&gt; Lack of integer generics and the way arrays are handled. Try manipulating an array of size &gt; 32 and you will quickly notice how weird it is. As an example I recently had lots of troubles handling the fact that they were Copy but not Clone. Yup, it's not even that hard to run into this and get the compiler to crash: fn main() { fn tricksy&lt;T: Copy&gt;(t: T) -&gt; T { t.clone() } let _ = tricksy([true; 33]); let _ = tricksy(drop::&lt;bool&gt;); } Despite the fact that `Copy` has extended `Clone` for a *long* time, it's still trivial to stumble upon types that are `Copy` but not `Clone`.
Strange.... then just try to add it.
I had to let it update itself once before it worked, at least according to about:support. That demo page still uses 100% CPU (on one core) and doesn't look quite as smooth as in Chromium. But Chromium is using 400% CPU, so...
Don't expect great performance at this point. The approach we are taking is to start with doing all of the rendering in gecko, then copy the rendered content in an image and pass it to webrender, which is extremely slow. Then, we integrate each rendering feature (sold color, borders, gradients, text, etc.) one after the other so that it is rendered in WebRender instead of Gecko. This means that as long as we haven't converted the majority of these items, we go through this unbearably slow process of copying a lot of pixels around. That said, the migration of the various display item types to be processed by WebRender instead of Gecko is advancing at a good pace.
Huh? I was under the impression that WebRender was still heavily under development and nowhere near ready to be shipped. I have yet to find anything that says otherwise. Is there any announcement about this?
I feel like the colon from english is the most familiar source of the syntax for most people. The example conveys a similar meaning to example: ExampleType; and the colon conveys the same meaning of "showing the details hidden behind the word/phrase". In any case, people encounter other uses of colon less often than in the language, so this is the most comfortable syntax. On the other side, operators like `-` and `=` are originated in math where there is no concept of whitespace, and the space on both sides is added for readability.
That's theoretically correct. But do you have a working example? [This](https://play.rust-lang.org/?gist=ec5e14ddaccfc092d9f3d4d9659ec72d&amp;version=nightly&amp;backtrace=0) still errors with a conflict. I couldn't get something working with `Borrow`s either. I don't know if it's already included in one of the specialization RFCs. But an interesting (and supposedly simple) extension to specialization would be to always consider a type more specific than a trait bound.
If I'm C++ programmer but not follower of r/cpp, it is still undesirable for me to vote?
Actually, the similarity to subtyping is more of a point against `a : B`. Since the meaning is different, the syntax should hint it's not exactly the same. When you want typing, `a: B` conveys the meaning in a clearer way.
The stabilization machinery has it for the stdlib, but not generally.
There's clippy for general lints. Not sure how many "performance smells" they have in there.
Btw: You can also use MSYS2's pacman to install other dependencies (SDL2, FreeType, etc.). See https://github.com/jhasse/ears/blob/master/appveyor.yml as an example (it installs OpenAL-soft and libsndfile).
I'd *definitely* believe there's room for improvement, and like with the benchmarks game PRs are of course always welcome! Locations for PRs would be: * [mio](https://github.com/carllerche/mio) * [tokio-core](https://github.com/tokio-rs/tokio-core) * [tokio-proto](https://github.com/tokio-rs/tokio-proto) * [tokio-minihttp](https://github.com/tokio-rs/tokio-minihttp) * [benchmarks game](https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Rust/tokio-minihttp) I suspect the TechEmpower folks would also love to receive PRs!
I found ECS tend to work really well with the rust way of doing things, but they can make it overly complex for a simple 2D game where you don't need the flexibility or performance. Will take a look at slide-rs. My main doubts come from games being different from a lot of other applications. Having some central state is very common in a game, almost the equivalent to a `static mut`. The restrictions and workarounds required to appease the rust gods make me doubt whether or not I should just be using C, or at least waiting for Jai to be released.
Perhaps a better approach might be to try to update the libui bindings, which are smaller, used a lot in Go, and cross-platform https://github.com/pcwalton/libui-rs
This isn't an ECS pattern, there are no components. This is just a parent entity, containing all the state of the game. I want to update an entity with respect to the rest of the state, but because the entity itsself is included in the state, it causes a hard time.
C++17 practically has sum types, with `std::variant`!
I would have expected better performance for the JSON serialization. Serde is fast, plaintext is fast also.
What's so "not safe for work" about medical terms? It's not like pussy-rs or fanny-rs or or cocksheath-rs or mowbox-rs or anything, it's a thing you can say and get away with it isn't it?
Generally voting is seen as an expression of the interests and views of the regular viewers of the subreddit.
OK, I'll try to un-vote (I've read your comment too late). Edit: done.
Why not r.read(&amp;mut buf).and(Ok(buf[0])) to avoid the lambda?
On the other hand, you find evangelists in every camp. So why not try navigating things yourself. Reach out, seek out knowledge. Rust solves programming issues but not ones with human nature. I think the Rust community is great, but people make mistakes. People want to talk about the things they are learning and often get things wrong, selling Rust as something it isn't. Every industry is like that, and the one that surrounds C++ is no different. Rust is a tool like any other, and while I like it very much, I won't want to use if for everything. At the end of the day you can do only so much for other people, and can't do much to stop others from being counter-productive. So be one person amongst many, don't try to carry the torch that is done by the community, and start seeking amongst the many for those who help carry the torch instead of just touting a facade. I know I'm too ignorant to sell rust in it's entirety, and I certainly don't want to be a face of the community. That's a responsibility that is thrust upon you by being undeniable in your contribution. Those that feel the need to desecrate what came before them tend not to value what got us to the point that allowed for Rust to come to fruition.
Just to disambiguate (we tend to say "shipped" when something hits the release user base and is enabled), in this case this just landed in Firefox nightly disabled by default. The work happens in a branch, which we want to merge into the nightly branch somewhat regularly to avoid the painful rebase conflicts that inevitably happen when two branches diverge for too long, but this is going to stay off by default for a while. I'm not even sure whether the beta/release populations will have this enabled in the build configuration at all (meaning they might not be able to turn it on even through manual tweaks in about:config until we feel the feature is in a good enough shape).
Wow, nice! This might help me [a lot](https://github.com/killercup/assert_cli/issues/32)!
Well, I suppose if you're a medical doctor (in particular, most likely, a OB-Gyn or something similar), I imagine talking about peoples' sex organs might be appropriate for your work. If you're not, then find your nearest female colleague and ask her how her clitoris is doing today. Record the results for us on video. Should be fun. I realize you're being deliberately dense in order to win some sort of philosophical point, but the thing is: this isn't a philosophical question, at least not purely. In most cultures (in particular most Western, English-speaking cultures) it's inappropriate and impolite to discuss sex-organs. It makes people uncomfortable, and technology industries in particular are already in many ways uncomfortable for women because they are so heavily male-dominated. Saying "things you can get away with" still isn't necessarily appropriate or welcoming to the people around you. But if you work at a company with an HR department, it strikes me as unlikely you'll "get away with" asking the nearest women about her clitoris at work. Unless you're a gynecologist.
Piping an expression twice is similar to calling `run` on it twice. You'll get two separate child processes. For a split pipe, where two readers get the same input bytes, you would need to sit in the middle yourself and copy the output bytes to both places. You could do that with `os_pipe`, by using duct's `stdin_handle` and `stdout_handle` methods to pass in the pipes and starting your expressions in parallel, but the copying-between-pipes part would be manual. That's probably similar to what you're doing in Python. You could also do it with just `os_pipe` + `std::process::Command`, if you use the `IntoStdio` conversion in `os_pipe` to pass in the pipes. One of the complexities of this kind of double piping is that you have to choose between either letting a slow reader block a fast reader, or buffering a potentially large amount of input in the middle. Which are you doing in Python?
I disagree. If your debaters are not willing to change their mind, you should not debate them. You can address audience without pretense of having a debate.
`Result::map` is generic over the lambda's type, so you can pretty much rely on it getting inlined.
Is there any news? Have you figured out what makes hyper slow?
I agree *somewhat*. I've found that I have vastly different preferences depending on where the type annotation appears. For me it all comes down to being able to quickly visually scan code to identify the different elements. let a:i32 = 0; // visually indistinct let a: i32 = 0; // not bad let a : i32 = 0; // not bad fn example(a: i32, b: TypeTwo) { // Very annoying. Quick visual scan, how many arguments // does the function take? 4? } fn example(a:i32, b:TypeTwo) { // It is obvious that the function takes 2 arguments. Spaces separate them // cleanly. Though this is broken by GenericThings&lt;i32, f64&gt; which become // too messy when they don't have spaces. This is often solved with // typedefs which are a good habit anyway. // // My editor's syntax coloring will cleanly seprate the name from the type // for me. } fn example(a:i32, b:TypeTwo) -&gt; i32 { // Gladly, it is obvious here that -&gt; should be surrounded by spaces. // In TypeScript, which uses : instead, this is non-obvious but after // about a year of coding in it, I've settled on spaces for the return // value, and no spaces for the function parameters. } EDIT: Formatting
Is there a higher order function in std that negates predicates? Something similar to this: ``` let non_alphanumeric = negate(char::is_alphanumeric) ```
Is there some kind of a tracking issue?
PR filed.
The first column in the benchmark results ("Class") indicates the nature of the framework being tested, legal values being "Micro", "Platform", and "Fullstack". tokio-minihttp is decidedly a microframework.
Congratulations! I tried it on Windows. There's a drawing and hit-test issue, text rendering looks different and the demo page performance isn't too great either. Is this WebRender 2 or 1?
Here are some ideas. If you iterate over pairs of entities then you don't have to pass the entire list of entities to each entity. That may solve the problem https://is.gd/1roE9W (fixed) In some situations you can loop over entities to gather data, and then you can subsequently use this data while looping over the entities for a second time. https://play.rust-lang.org/?gist=5489a499e984fe47a3fc50f730325a77&amp;version=stable&amp;backtrace=1 In a 2D scroller you can iterate over pairs of immutable positions to generate a list of collissions. These collisions are stored in a separate mutable vector. Subsequently you can iterate over collissions to update each entity. Alternatively it may help to store the position of each entity in one vector and store the rest of the state of each entity in a separate vector. This way you can iterate over immutable positions while accessing mutable states.
Huh, I really thought specialization handled that case.
&gt; I thought that writing the third biggest Rust codebase at that time all by myself (with glium, only behind rustc and servo) would give me some legitimacy, but it didn't. I guess it's a matter of priority, those issues were not seen as being as important as others. I don't even want to get into a debate of whether they were or not; to be honest, I don't think we have enough history to try that. And it would also be a somewhat pointless exercise I guess. I am happy however to see progress on #3 and #5 (for SIMD) since for the type of programs I work on those are the major pain points.
&gt; Many advanced C++ users are already doing the types of analysis and design that the Rust compiler forces you to do in order to ensure safety, so they wouldn't get as much benefit from switching to Rust. At the same time, I'm getting tired of looking at core dumps and chasing yet another use-after-free or data-race :(
The big reason for disallowing it is so that /r/rust can't link to a post on /r/golang where they say "Look we have a new feature!", but then the submission is flooded with rust users coming from /r/rust and saying "lol rust had this pre-WW2, go is shit, git gud" and downvoting all the native /r/golang users. (A silly example, obvs, but I think it gets the point across) This submission feels pretty different from that because it's cpp users talking about rust, so I think a good cross sub discussion could be had. I'd defer to /u/cleroth, but I think commenting should be fine but I'd refrain from voting. They can delete comments if it gets ugly, but they can't fix votes.
&gt; practically Except that they're really not as practical as real sum types. The lack of `match` *really* hurts. And for those who think that a variadic function can handle this; they've never tried using `break`/`continue`/`return` from a match arm...
I'm implementing a legacy data format, which is a maximally shared tree. Currently I have versions with and without sharing and with and without arena allocation because those have effects on the usability when building a tree programmatically. That's a lot of duplicate code because I can't abstract over the higher-kinded `Indirection` part of the tree that wraps around the recursive part of the tree type. Is there a different, more specific trick that I can do to get one one type definition? I was thinking in the direction of a tree type that leaves the recursive part open as a type variable, and instanciate the type with a recursive type alias, but that probably won't be liked by the compiler, right? (I should probably just try this stuff in an editor instead of asking here \^\^' )
No, you can't self-borrow like in C++. C++ has overloadable copy and move constructors, so you can always run the code to fixup pointers whenever the object's location changes. Overloadable move constructors cause a lot of suffering, so at least give them credit for what they _do_ enable.
My experience of working in a company which had this policy was that it would have been *absolutely sane to write all of those in One Standard Language in the first place*. We had a core of stuff in Java with a museum of relics from cool languages past - PHP, Groovy, and Clojure, already; i think Coffeescript too; Scala almost certainly joining the museum once people get into Kotlin, and R once it gets slow enough to need porting into a production-oriented language. Plus Perl and Ruby in the infrastructure world. Maintaining codebases in languages that nobody knew was not fun. Even trying to arrange interoperation and reuse between codebases in languages we did know was a distraction from real work. The idea that "using the best tool for the job" is a consistently major advantage is a mistaken and pernicious one. For general development stuff, skilled Java programmers writing Java and skilled Ruby programmers writing Ruby are about as productive as each other for pretty much any task, and they're both streets ahead of skilled Java programmers writing Ruby or vice versa. Having everyone on a small number of languages (and frameworks, etc) means you get more ROI on knowledge and tooling, too. The reason i'm interested in Rust is that it's the first decent language which is better enough in its domain that it really is worth using alongside whatever main language i use. My job involves some high-throughput, low-latency stuff, and we can do that in Rust; we actually just couldn't do it in any language with garbage collection. For general web and business logic stuff, having GC and more mature tools is nice, so we carry on using something else. 
It's not about the cost of living, it's about supply and demand, for people and for money. The US, and Silicon Valley in particular, has a lot of tech businesses, and so an insatiable demand for programmers. It also has an economy that throws off huge amounts of capital which needs to be invested, again, particularly in Silicon Valley, so there's a large supply of money to pay for them. Put those together, and you get high salaries for programmers.
oh right, thank you. just got started a few hours ago
 1. We basically have no idea how to do self-borrowing structs safely. 2. What part of `decltype` do you want exactly? 3. Integer generics - this is being worked on. I expect it to be done by EOY 2018 or so, but don't take my word. 4. There *is* the new box syntax. 5. This is coming soon - https://github.com/rust-lang/rust/pull/39999.
TIL about literal suffixes
It seems this does some of the things I was missing on Pelican (mostly the bit on how to organise a table of contents for a section, you don't always want reverse chronological order for a given category). I'd prefer swappable templating, and until it works under Windows I won't be able to try it, but it sounds like I may be using it soon. (Support for translations would be nice, as in dealing with an article which has versions in multiple languages.) 
So we now have - cobalt.rs for people wanting something like Jekyll - Gutenberg for people wanting something like Hugo - Misc other ones that are less mature Seems like Gutenberg has some nice features that are missing from cobalt.rs that will be nice to adopt. I'll have to dig into them more when I finish with some of my other cobalt work (mostly focused on getting closer to feature parity with Jekyll)
In general no, new environment variables created in a child process aren't visible to the parent. In your example, `source` probably isn't going to do what you want. What's going to happen is that Rust will execute the following command: /bin/sh -c "source myenv.sh" That `/bin/sh` child process will run all the commands in `myenv.sh`, and then it will exit. In particular, nothing in the Rust parent process will ever change. The child has its own list of env vars, separate from the parent, and that's the only thing that changes. However, if you tell that shell to do more things, you might be able to take advantage of the variables it's creating. Maybe something like this: sh("source myenv.sh &amp;&amp; ./another_script.sh") If instead you want to get those variables in the Rust parent process, you have two options. You can either set them before Rust ever starts (maybe by wrapping your Rust program in a script), or you can store them in some format that Rust can parse (like JSON). If you're parsing them, you have the option of applying them to the Rust process itself (using [`std::env`](https://doc.rust-lang.org/std/env/index.html)) and letting children inherit them, or passing them to children only (using e.g. the `env` function in duct). In short, duct won't be doing a lot for you here, since it doesn't fundamentally change how environment variables work. Mostly it'll just save you the trouble of writing `"/bin/sh", "-c", ...`.
I believe that WebRender 1 is long gone, but I'm not 100% sure.
Your parent's point is that while this is true today, it won't be true tomorrow.
No, I think the Firefox team would greatly appreciate any data you could get them. The entire purpose of release channels like these is to expand the lane for outside contributions.
Is there a way to explain "implicits" that doesn't assume I've read all the preceding chapters of a Scala tutorial?
I'm running the dev version `54.0a2` and `gfx.webrender.enabled` is true by default. Does this mean this is enabled by default or is this setting used for something else on previous Firefox versions?
I had this before the update. After I updated it switched itself to false.
Awesome! Fundamentally, the process is 1. find something that's less than awesome 2. make a PR or an issue 3. Done! Step one can take many forms. I linked a bunch of stuff in the blog post, but browsing the T-doc tag on github (here: https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AT-doc) is one way to find things people have already filed. You could also just open a random page of docs, and find something that way. Issues are great for noting that something isn't great if you don't have the time or inclination to fix them right then and there. Or if you want to start a discussion about it. As for sending in PRs, it's the usual GitHub stuff. If you're not used to that, I can help there too. Usually, the easiest way to find some docs to change is to search for the existing text; so say you wanted to improve https://doc.rust-lang.org/stable/std/env/fn.current_exe.html. I literally (rip)grep for "Returns the full filesystem path" and then find where it exists, make the change, and then make a PR. Honestly, I rarely bother actually building the docs unless it's some sort of big change. Everything is in Markdown, so you know how it's going to look already. Happy to elaborate on any of those details, but that's my initial brain dump!
I would say submit one usecase where you detail each of your datasets as well as conclusions. You don't know what is or isn't related to the same internal issues, so it's safer to give them the data in a format they can decompose as they need it. Of course, they may direct you otherwise, but IMO that's the best way to deliver data without knowledge of the internal process :)
&gt; * I think adding `decltype` is a misfeature, which will unnecessarily complicate the language. If implemented generally, the type inference pass would suddenly become equivalent to the halting problem; ... Rust's type system is already Turing complete, so it already has the halting problem. It would be a very useful feature, at least for me.
Yeah, I'm hearing you pain here. I guess I haven't run into this yet myself, but also the biggest library I've written had only ~20 tests, and the majority were just looking for the `Ok` case, never an error, so I could just do `assert_eq!(result.unwrap(), inner_ok_value); `. I want to try and find the best solution for your case though! One question: what exactly do you mean by 'when you have to refactoring so code'? I haven't found too much of a problem in refactoring, do you just bean needing to change all the error handling cases?
Are you saying that Rust will provide a lightweight way of having non-cooperative scheduling ?
I am saying that (in my understanding) the plan is to have work-stealing between Cores. So you have one Core per CPU core, and it balances out between them.
Thanks. Someone [has already filed the bug](https://bugzilla.mozilla.org/show_bug.cgi?id=1350408).
I don't think so. At least you're in the ballpark with subtyping, as opposed to _assigning values_ in default struct constructors. Moreover, Rust doesn't have inheritance, and sure you can subtype with Traits but you're still saying that an object belongs to a space (or is classified by a type).
I hope it stays like this, it's so much easier on the eyes.
Cool library! I'm trying to use it now to pipe some stuff out of curl. Could you elaborate a bit more on the difference between cmd and sh? E.g., fn main() { let curl_stdout = sh("curl https://google.com").read(); println!("{}", &amp;curl_stdout.unwrap()); } When used with sh, curl behaves exactly as it's supposed to. Whereas the following fails with a `No such file or directory` failure. fn main() { let curl_stdout = cmd!("curl https://google.com").read(); println!("{}", &amp;curl_stdout.unwrap()); } I tried changing curl to use /usr/bin/curl instead, but that didn't do the trick. So what exactly do we use cmd for over sh?
Cool! You could add your data to that bug, that would help the FF team get more insight into what's causing it :)
&gt; How much value is there in a complete beginner joining? From a certain perspective, beginners are the *most valuable* contributors. Non-beginner contributors can only *pretend* to be a beginner, and without real beginners' voices to keep us all grounded, we risk missing the hurdles that are preventing folks from learning Rust. For Rust to be successful, people need to learn it, so getting their feedback to make that process easier is essential. (Yes, I'm echoing what others have already said. That's OK!)
`cmd!` wants each argument as a separate string. As you have it there, it thinks the whole thing is the name of your program. Take a look at the example in the docs: https://docs.rs/duct/0.8.1/duct/macro.cmd.html#example I have [an issue open](https://github.com/oconnor663/duct.rs/issues/24) to add more info to these error messages, and I've made a note there. Right now, you're seeing the same error you'd see if you tried `std::process::Command::new("curl google.com")` (because `Command` also wants its arguments passed separately). The reason for having both `sh` and `cmd!` (and the `cmd` function), is that while the shell is convenient for hardcoded command strings, it's also very sensitive to whitespace and special characters. Say you have a `url` variable, and you try to do something like `sh(format!("curl {}", url))`. That's very likely to cause errors. A space in `url` will make curl read it as multiple arguments. If there's a semicolon in there, the shell will read it as _multiple commands_. Even quoting the argument isn't good enough, because the argument could contain quotes! Building shell code out of any non-constant input is very tricky. But `cmd!("curl", url)` will always do the right thing, because there's no shell involved.
it doesn't have text or that slightly brighter circle in the middle though
DeMorgan's law is a good idea, thank you. Closures seem a bit wordy for this type of thing, but I guess it's okay as long as they are zero cost.
I'll have to read up on how Hugo and other tools handle translating posts as I haven't needed that. My initial idea was to have a subsection like `/en/`, copy-paste the .md file in it and have some way to link both articles together in the front matter. I created an issue for it: https://github.com/Keats/gutenberg/issues/13 if you have time to comment. It *might* work on Windows right now, only the CI itself is failing. Building from git or crates.io might work as I don't think I'm doing anything platform specific.
I'm glad I'm not the only one who thinks the inability of a struct to self-borrow is the single largest expressiveness problem in the language currently. It's the first major hurdle I hit when learning the language 3 years ago, and continues to be a stumbling block even now. I've put my other projects on hold to attempt to address this better with a complete redesign of [rental](https://crates.io/crates/rental), but you can only do so much at the library level. The `'unsafe` lifetime RFC was postponed, which means some use cases will remain impossible to support for the time being, but I'm hopeful that even in a limited form the new version will do something to at least partially alleviate this problem. I'd like nothing better than for my crate to be rendered completely redundant by a language feature one day though. Incidentally, `decltype` would also be very useful in this effort, so I agree on that front as well
As I understand Webrender 1 was replaced and no longer on the radar.
Struct inheritance is not really a rust pattern (you possibly have heard of composition over inheritance). However, I think associated types would work well in your case: https://doc.rust-lang.org/book/associated-types.html
Can't you make your types Clone with a manual implementation for the same effect?
Yeah, it's also annoying that error-chain doesn't even have a way for you to make your errors support PartialEq ([issue](https://github.com/brson/error-chain/issues/134)).
Would it be possible to make it a macro like `println!` that only accepts a static string?
Let's just set the "FFI" part to the side; I don't see how it's relevant, anyway. I think the critical question here is how you expect this to be used. For example, I wrote a crate that was really, *really* hyper-specific about error conditions. I had something like 8 distinct error types. This was *great* because it meant you could always tell *exactly* how any given call could fail, and I could provide special-case methods that would statically remove an error condition (*i.e.* go from error enum `C` with three variants, to error enum `B` with two variants, by handling one variant). This was *terrible* because it meant every call had a different error type, and I had to have a zillion conversions implemented, and because users didn't care 99% of the time, I ended up with a catch-all "GenericError" type that had every condition, and everything just kinda decayed into that. And that sloppy error handling was *so* much less of a pain in the backside. Another example: you can write really tightly-typed builders that statically require you to set every required field, and only let you set optional fields exactly once. It's great because building a value incorrectly is a compile error. It's terrible because it makes it *impossible* to write simple code that reads values from a file and sets them as they come in by mutating a variable. How is your binding going to be used? If people are likely to want to have a single code path that multiple value types need to pass through, you probably want the slightly looser version using enums. If they're likely to be writing very specific code that should only ever be dealing with a single kind of value, you probably want the stricter trait version. Or, you can be crazy and do both. Then your problem is just explaining this in the documentation.
I had the curl issue on Appveyor earlier as well. While you might have seen it already, I found the change needed was adding`C:\Program Files\Git\mingw64\bin` to the path variable, as the location of it has changed. And whatever the equivalent is for the 32-bit version.
&gt; Struct inheritance is not really a rust pattern (you possibly have heard of composition over inheritance). I do feel like there has to be nice way to do this in Rust ... &gt; However, I think associated types would work well in your case: https://doc.rust-lang.org/book/associated-types.html ... but I'm still not exactly sure how this would be implemented. Would I then still have no access to the underlying struct data? Wouldn't the trait still have no access to the implementor's field? So something like `fn with_name(mut self, name: Option&lt;String&gt;) -&gt; Self;` can not be put in the trait itself?
Devirtualisation is the kind of thing people expect from a compiler: making the program faster but potentially slightly larger. This is also what happens when a compiler applies things like loop unrolling etc. The opposite is probably very much unexpected for people. In fact people feel comfortable using Rust's very high level API's *because* they can be confident that it will all compile down to static dispatch. And if you want virtual dispatch it's not like it's difficult to tell the compiler that explicitly. Edit: same applies to a lesser degree to optimizations that try to be too "clever" about making virtual calls faster. It's all about predictability, which is a very important requirement for a systems programming language. 
Contrary here, the fps are halfed by using webrender.
Works on OS X. Install LLDB extension, configure executable path (target/debug/somename) and off you go. There are some cases where it can't step into or crashes, but hey, it's still hugely useful. 
There was a time when literal suffixes were mandatory everywhere. We have come quite a way since then.
Not that I did, but since you're asking I guess people downvoted for the annoying "bad engineering" remark, which adds nothing to the conversation. :/ (the message is now at +16 fwiw)
Well, I'm pleased. Every author likes a beer, even if it's imaginary. (I don't know if there's a IETF protocol for transferring beer over the internet.)
a modification of this might work for beer also https://tools.ietf.org/html/rfc2549
Crashes for me, but I do have an OpenGL 2.1-only GPU …
Pigeons are great for data transfer but aren't very good drones for physical goods. We need an International Beer Token system, redeemable anywhere.
I personally prefer the first approach, because the closure doesn't use the argument it is passed.
I'm a beginner on rust too! And if you're looking for multilingual support, I can do it in portuguese!
Putting aside optimisations (which are really just "breaking the rules when no one will notice"), moves always involve taking a value at one place in memory and moving it to another place in memory. That said, "deallocate" implies you think there's heap access going on, which is not the case. Rust never puts anything on the heap that you didn't put there yourself. It's referring to things like returning a value from a function, or moving a value between variables, or from a variable into a struct field. You might think that this means it's safe for things like `String` or `Vec` that *are* on the heap, but that's also wrong. Rust doesn't understand what a heap is, and cannot reason about it. There's no such thing as a "heap lifetime". It can only reason about things in terms of either `'static` or stack lifetimes... which means something on the heap is, from the compiler's point of view, exactly the same as something on the stack, with all the same limitations. In particular, pointers to heap things use the lifetime of the "anchor" value used to reach them; so the lifetime of a `&amp;T` derived from a `Box&lt;T&gt;` is the lifetime of the variable used to store the `Box&lt;T&gt;` itself. And thus, we return to the original problem. The only way around this is `unsafe` code, which you should avoid for all the reasons Rust exists in the first place.
Luckily, my company only operates servers during working hours (give or a take a few hours). Not to say I don't have Mysterious Crashes that defy reproduction. They're infrequent, but staring at the core-dump for hours, all the while cross-checking the code, to end up in the best case with a commit message that reads "Should fix ..., hopefully" is kinda disheartening.
&gt; complete with Ominous Warnings :'( The only surefire way I can think of to spawn processes from a multi-threaded process is to spawn an "overseer" process from the main process before it starts other threads, and then play a game of delegating all process spawning operations to the "overseer" process, which is really annoying (you need an IPC between main and overseer that duplicates the operations you can use on spawned processes). Given how similar processes and threads are, it seems bizarre to have this unexpected hurdle when attempting to mix them :(
&gt; is this only to complete 2nd edition of the Rust book or beyond than that? Actually, the article refers to the Rust Documentation, which is different than the book: - the book explains mainly the Rust language, and a few bits of the standard library, - the documentation explains the API of the Rust standard library: struct by struct, function by function. For example, here is the [fmt module](https://doc.rust-lang.org/std/fmt/index.html); note how rich the API is!
&gt; borrowee Lender?
An enum is one of several values, decided at runtime. Traits (used as generic constraints) can be implemented on several types, but the specific type you use in a given piece of code is decided at compile-time. You can implement a method on an `Option&lt;T&gt;`, letting you use `None` or `Some(T)` at runtime. You can also implement a method in a trait on `()` and `T`, but you have to decide which one you're using at compile-time.
Probably the client then just not processing the results correctly.
Conceptually yes, different bindings/names refer to separate regions of memory, and a move involves making one region unusable and "non-meaningful", and putting the value that used to be there in a different region. (Which now becomes usable if it wasn't already) However, this is an idealised model where finding a blank region of memory to put a "new" binding takes no time, and we don't care about the time it takes to copy the values to their destination. In terms of what the machine's actually doing, a lot of this disappears after the compiler's optimisations. (RustC is very good at optimisation, to the extent that IME, you don't have to care at all about C-style micro-optimisations so long as you're doing the efficient thing on an algorithmic level) So long as you're not talking about variable-length containers like `String` and `Vec`, the compiler has already worked out the size of all your local variables after eliminating renames and other opportunities where the idealised "separate regions" can be put into the same space, so the "allocation" costs nothing in itself once you've got into the function body, even though on the source code level, it becomes possible to read from a variable when it wasn't before. e.g. if you have code that looks like this: fn g() { let u = f(); } fn f() -&gt; MyType { let a = MyType::new(); let b = &amp;a; let c = a; return c; } Then this will fail on the assignment `c = a`, because it would invalidate `b`, even though `a` and `c` are likely referring to what winds up being the same address in terms of actual machine code. This is because `b` is pointing to *a*, specifically, and not a's underlying memory as in C. Once we invalidate a by moving its contents, all pointers to it are similarly invalidated conceptually, even though concretely they might be pointing to a usable memory address. The compiler can't assure us in general at compile time that they will be pointing somewhere valid, so to rule out the existence of dangling pointers, it forbids you doing this at all, even in special cases it would work because of the specific machine code. (After all, we wouldn't want our code to break because something further up in the function changed and the optimisation of putting a and c in the same memory was no longer possible.) If you take the assignment out of the previous code and compile it, you'll get the machine code of something like fn g() { let u = MyType::new(); } because the compiler is smart enough to consolidate different names for the same data and eliminate intermediate "moves." (If you _are_ talking about containers like String and Vec, creating, cloning and dropping these values does involve heap alloc/deallocations, with all the runtime cost that implies. However, moving the containers without cloning them only moves their "handles", which are values on the stack that obey the rules above.)
&gt; And if you're looking for multilingual support, I can do it in portuguese! We don't have any good way to do this for API docs yet :( We will be doing it for the book, but need to land some work in mdbook first.
&gt; How would one go about doing that? Read available surrounding discussion? Read the source code and try to figure out what it does? Write some programs using it? Etc. Just wondering what would be recommended here / what process you actually expect people to go through. It depends, I'm not quite sure! When I did it, it mostly was "read the code and try to figure it out." Sometimes tests are helpful, as they show off how something is used. Sometimes I'd ask questions in IRC. I think there's lots of ways to go about this. &gt; I would argue that the way some of these issues are currently presented at Github is not very inviting for newbies. Yeah, I did them all in one big fell swoop over a couple of hours; as such, they might not be great. I figure it's a starting point, and I can elaborate on any of them, if needed. &gt; Some topics just seem difficult to tackle in general Totally, it really depends. &gt; I feel like the blurb you provided to outkaj should be there on the issue itself from the outset. So, this is actually why I did all of this. Originally, these issues were mostly for *me*, that is, I planned on doing all of this myself. but then, we decided to do the second edition of the book, and so I kinda fell off of it. Opening all of those issues itself was tough, so I kept it short. After I wrote that reply to outkaj, I realized that I should have done that for all of them at first, and went back in and back-filled them all. So agree 100%. In general, if an issue isn't clear enough, please leave a comment and I will certainly elaborate. &gt; Another thing: what's the preferred audience most of the time? I.e., should it be clear to someone who has already read the book (either edition), or also those who haven't? The audience is someone who already knows the language. But we don't assume that you know about the topic itself. Like, for example, https://doc.rust-lang.org/stable/std/primitive.char.html#note-on-locale is something that I believe should be included in the docs.
Sorry for missing some context, but: What is "Chalk"?
Apparently a "Prolog-ish interpreter". https://github.com/nikomatsakis/chalk/blob/master/README.md 
I would just include a warning in the docs. Lots of things are not secure and we don't name them insecure_fn
10am - 4pm PDT. Daylight Savings Time is expert level.
Writing experience is helpful, but not required. Basically, we will work through any issues like that in PRs; even those of us with lots of writing experience make mistakes, for example, I included a regionalism in my description of all of these issues, which has confused some non-native speakers already, heh :( (Where I come from, we say "needs x" rather than "needs to be x", so "needs finished" instead of "needs to be finished") So yeah, just open PRs with your best shot and we'll work on it. :) very very happy to do so. Honesty, the best way to improve writing is to just do more of it. And thanks :)
Any idea about performance compared to Hugo? I see you have a benchmark but no stats from it to compare with. Even though this still WIP I'd love to see some. 
Right on, I'll take a look. "Needs finished"... Midwest? I hear that in Pittsburgh now and then, even see it on the occasional sign: "needs vaccinated". Interesting to think about how that affects things like our technical docs. Thanks!
Always happy to hear feedback! I believe most of these issues are solved by the template engine itself. Tera has template inheritance (https://github.com/Keats/tera#inheritance) so it's easy to override only parts of a template, if the template is well written in the first place. Adding extra CSS/JS is just a question of having some predefined blocks as well. Here's an example from a random theme I took from Pelican for example: https://github.com/alexandrevicenzi/Flex/blob/5bc235cf579cb03bcc8f54b6029ff74493a0cb44/templates/base.html#L181 In your template, you can then just use `{% block extrajs %}&lt;link ..&gt;{% endblock %}` to load custom js scripts for example. You will still have to manually to do some manual diffs though if you want to update the original theme. There would be a way to keep a theme in a separate directory and override selected templates. That doesn't seem like a great experience though as you will still need to do a diff when updating anyway so it became more annoying for no good reason. I'm planning to make a few themes to get started once 0.1 gets closer to set some kind of standard on how they should be written, I can ping you at that time to see if that would ease that pain point. I typically write a new theme for each site so more insight on that is good!
It works on Fedora with standard gdb. You need to edit the launch.json to execute your executable. Something like { "version": "0.2.0", "configurations": [ { "name": "Debug", "type": "cppdbg", "request": "launch", "program": "/home/serge/Development/rust/four/target/debug/four", &lt;== replace by your app "args": [], "stopAtEntry": true, "cwd": "${workspaceRoot}", "environment": [], "externalConsole": true, "linux": { "MIMode": "gdb", "setupCommands": [ { "description": "Enable pretty-printing for gdb", "text": "-enable-pretty-printing", "ignoreFailures": true } ] }, To set a break point for the above you need to use something like four::main
Sure, I can take a look at it once you've got something :) Ideally I would be able to include all my modifications outside of the theme folder, to ease the upgrade process. This is a high point of the theme I'm currently using, because it allows me to just (in the config) give a name and path of the specific extra files I want loaded, so I don't have to worry about messing with the theme. Then I just use JavaScript to include the extra CDN hosted libraries I want, so I don't have to mess with the template. Template inheritance could do most of that I think (just extend the right template as you suggest), but I would still need to point Gutenberg to my template somehow.
I understand that, and in no way am I trying to spew hate here. But the show-stopper that will prevent me from using Rust to implement saleable and complex HTTP services is the case where I have N cores and exactly N requests come in which are dis-proportionally computationally expensive. Given I have 4 cores, and these 4 requests would take up a second of compute time on a given core, the rest of the thousand requests that are waiting to be served will be very unhappy. This can be solved by forcing each handler to be very 'iterative' and return as soon as possible, but the overhead that would incur is something one should investigate. Green threading however does solve this issue rather elegantly, as much as I despise writing Go. 
Sad reality is, people don't read docs. Quite often snipets of code are copy and pasted and so on. `insecure_` is too vague. `unescaped_` is the word hints the most important part of `sh` here, IMO.
:D &lt;3
That's very odd - Rust has neither Null or exceptions! It seems you've posted to the wrong sub. This is for the Rust programming language, while the sub for the Rust game is over at /r/playrust 
try /r/playust for some people who might actually be able to help you.
There's already a [crate](https://crates.io/crates/rouler) that I believe does that.
What's the best way to call a `strcpy`-like C function which puts a string of unknown length in a caller-provided buffer? It felt like it should be somehow possible with `CString` but I always ended up with memory corruption. My current solution looks like this (`strcpy` is just an example of a function with similar behavior): let mut buf: Vec&lt;u8&gt; = vec![0; 512]; strcpy(buf.as_mut_slice().as_mut_ptr() as *mut c_char, foo); if let Some(pos) = buf.iter().position(|&amp;b| b == 0) { buf.truncate(pos + 1); let result = CStr::from_bytes_with_nul(&amp;buf).unwrap().to_string_lossy().into_owned(); Some(result) } else { panic!("string not null-terminated"); } 
Again, how would it be solved then? Could you point me towards some documentation or discussion about this? if there's a plan to for this to be solved, colour me madly intrigued.
Trailing commas are coming very soon (2.12.2) =&gt; https://github.com/scala/scala.github.com/pull/533
And this crate uses a PEG parser (pest). /u/Byrhtno6, a PEG parser will definitely do this and the crate you refer to will do a good job of it in stable rust so you're on the right track. 
&gt; This cannot be done safely in C++ either C++ has no *concept* of safety. What you describe is undefined behaviour, and you have no way in C++ to statically check for it (and the run time checks like valgrind are very slow, not 100% reliable and sometimes only run on linux), while you can statically check for safety on Rust.
Yes, that's the whole idea of the `poll` method on futures. https://tokio.rs/docs/going-deeper/futures-model/
Has anyone made LV2 plugins?
How do you add breakpoints then? I got rls running, vscode-rust and cpp extensions working but something is lacking. Running on play runs my application but not sure if it just runs it or engages in debug mode without me having set proper breakpoints. 
1. `Immovable` trait &amp; placement new
Wow, that's much simpler than I would ever expect. How is the GUI done though? Is that automatically created by your DAW, or is the vst2 library providing a default GUI? Also, since I see the author is reading the comments, here's a typo. You repeated 'get_parameter_text', when one of these should actually read 'get_parameter_name': &gt; get_parameter_text - gets the text that should be displayed as the parameter's name in the host application &gt; get_parameter_text - gets the text that should be displayed as the parameter's value in the host application
Looks a bit more bare-bones/C API flavoured than the VST crate, but someone does appear to have done some work on LV2 in Rust: https://github.com/poidl/lv2
I am really interested to start contributing to the docs too. I've been contributing to the book over the past month (now starting the concurrency chapter), and when I finish it I intend to start going through stdlib docs, and hopefully make useful contributions there too! I second the idea for a more applied stdlib resource. Even though I understand C/C++ decently, I don't have any real-world experience with them, and getting started writing real Rust is kinda intimidating (background in Python). Maybe some other people are also interested in writing and documenting simple beginner applications? Could be the start of a "Real world Rust" resource ...
Its kinda cool that Theo de Raadt feels Rust is making inroads. I wonder what it would take to convince him to start a migration effort for OpenBSD's userland to move to Rust (i.e. small steps like - new tools should be built with Rust).
&gt; How do types last for anything other than 'static To be clear, 'types' don't even last past a certain phase of compilation. The lifetime here is associated with the *data*, and it *is* a type. The error this prevents is accessing data after it no longer exists. Static data lasts the lifetime of the program. The lifetime 'a gives you a label for how long some other data, a T in this case, lives.
This is Theo making a joke. Not a serious proposal.
Ah. I superficially understand, although I'm not sure why I'd want to do that in practice. I guess I haven't had data structures complicated enough to warrant it. (And the only time I haven't had the compiler infer them properly was when I had references that had to outlive the object that was containing them.) 
Note that the proposal here is a joke (see the other comments), but the whole thing actually reveals a lot that I didn't know about OpenBSD: I thought that OpenSSL was a subsidiary project of OpenBSD, and that Theo was OpenSSL's BDFL or something.
&gt; `cargo --explain E0309` So *that's* how you do that. I'd always try things like `cargo build --explain` and `cargo run --explain` (by analogy to `--verbose`) and then conclude it must be a message generated by `rustc` (and not usable via `cargo`) and resort to Google.
iirc there's been discussion among the lang team of making this bound inferred, because it's mostly uninteresting (and of course, the compiler knows whenever it's necessary, as demonstrated by the error message you got).
I think you're confusing r/OpenSSL with r/OpenSSH; it's OpenSSH that's part of the r/OpenBSD project, whereas the OpenSSL fork that OpenBSD team has been responsible for since the heartbleed is called r/LibreSSL.
That would be OpenSSH. OpenBSD made their own fork called LibreSSL partly due to licensing but mostly due to code quality.
One does not simply relicense code under the GPL. This is a joke.
So this is another build-environment container-orchestration tool in the vein of Travs/GitLabCI/Drone/Jet? Sounds interesting. Where's the main homepage/downloads/documentation?
&gt; One does not simply relicense code under the GPL. This is a joke. Or is it? * http://marc.info/?l=openbsd-tech&amp;m=149028593819547&amp;w=2 * /r/openbsd/comments/617one/tech_regarding_openssl_licence_change/
Slightly off-topic I guess, but IMO you'd have a significantly better experience using VSCode for Rust than Visual Studio-proper.
Am I off-topic or you? First post here lol I will look up what you mean by VSCode too, not sure what that is. Do you mean just use the text editor part of visual studio and compile with rustc?
I am, since I'm not helping with your Visual Rust problem. ;-] [Visual Studio Code](https://code.visualstudio.com/) is a separate product from Visual Studio. I find [its Rust plugin](https://github.com/editor-rs/vscode-rust) (using RLS) to be a superior experience to Visual Rust, personally.
This seems good, I'll see how well it works. (It has a spotify extension too lol! I hope this works xD) - Update: Yeah it works, now I just have to learn Rust. So what I'm doing is Editing the program in VSCode and then running "rustc" on it, then running the resulting .exe in the terminal to see the result. That what you do? 
Agh, regretting not buying tickets/ planning to go to this. These talks look really good. I'll look forward to the videos.
Very much know it's a joke but the part about Rust is unnecessary to the joke and as a result comes across as true. Hence my excitement that maybe rust can actually make in roads into OpenBSD projects. 
Would that be useful for me as a one-person project developer?
You should be using `cargo` (the standard build system/package manager) instead of `rustc` unless you're unable to for some reason (which really shouldn't be the case when you are just learning the language). `cargo new --bin` will set up the directory structure for you, `cargo run` will build (if it's not already built) and run the application for you, `cargo build` will just build it, `cargo check` will run typechecking without actually generating code (which is significantly faster). See [crates.io/index.html](http://doc.crates.io/index.html) for more information on cargo. I'm pretty sure you can run cargo from visual studio code, but personally I prefer running it in a terminal.
Nice, thanks! Interested to see how far you can take it when it comes to it.
Thanks! It helps a bunch, can't wait to actually do something cool with rust :D
How would I go about setting the commands to a macro/hotkey?
You will want to extract the contents of the `V4` (to get the `Ipv4Addr` type). match socket.ip() { ::std::net::IpAddr::V4(ref addr4) =&gt; for oct in addr4.octets() { .... }, ::std::net::IpAddr::V6(ref addr6) =&gt; for oct in addr6.octets() { .... }, } It's also worth noting that you cannot return `&amp;str` from this function, as the `String` will be destructed (and hence the referenced memory will be invalidated) when the function terminates
You're trying to call std::net::IpAddr::octets(), which does not exist (see https://doc.rust-lang.org/std/net/enum.IpAddr.html). The octets() method is implemented for IpV4Addr and IpV6Addr, not IpAddr. You need to match against the IpAddr enum first to extract the relevant enum variant: match socket.ip() { IpV4Addr(v4) =&gt; v4.octets(), IpV6Addr(v6) =&gt; v6.octets() }
Neato. Managed to make it do stuff (Same result as VS in one case. I think I got it though. Managed to freeze up my computer while editing the shortcuts... what's up with that?) I've gotta change the shortcuts because they A) Are partly what switches between my QWERTY and Dvorak layouts and B) Take screenshots with Gyazo. - **EDIT**: Build and run hotkeys, woo! Now why can't I type in the input? 
Although a `Box&lt;Trait&gt;` could live for the lifetime of a loaded dynamic library. Although it's not the type itself, but the vtable for the type. However this isn't really implemented in Rust (in anything I've seen). It's just assumed the only safe way to Dynamically load a library is to never unload it.
We infer variance through private fields already so I'm not sure that argument holds.
Good to see logic programming in rust being going on.
Hmm, this one I don't like at all, because `Ok(buf[0])` is always evaluated, even if reading failed. In this case buf is a static array and always initialized, so therefore it's harmless, but I imagine that scenarios where buf would be a vec and possibly have its length changed inside `read` to not be uncommon. And in such a scenario, what should have been a `None` turns instead into a "Index out of bounds" panic.
Yup, same experience here.
`Box&lt;Trait&gt;` is implicitly `Box&lt;Trait+'static&gt;` so yeah, it will cause issues if you unload the library it came from. But you can use `Box&lt;Trait+'a&gt;` to make sure that doesn't happen.
Sorry, yes in the same function I'm also reading the file which is the piece giving the IsDirectory error
In case you're having a déjà vu: Yes, we already added exception handling code in the ["Catching Exceptions"](https://os.phil-opp.com/catching-exceptions.html), ["Better Exception Messages"](https://os.phil-opp.com/better-exception-messages.html), and ["Returning from Exceptions"](https://os.phil-opp.com/returning-from-exceptions.html) posts. These posts used naked functions and a lot of inline assembly for exception handling. This new post uses the new [`x86-interrupt` calling convention](https://github.com/rust-lang/rust/pull/39832) instead, which hides most of the complexity and makes exception handling much easier and less error prone.
Also GCC contributions require copyright assignment, so they really can relicense everything -- instantly -- without having to track down all the contributors.
Sadly, 'reading' a directory gives an error with the `Other` error kind. `thread 'main' panicked at 'Error { repr: Os { code: 21, message: "Is a directory" } }', a.rs:15 ` You can see the inner representation having error code 21, which you can get from `io::Error` using [raw_os_error()](https://doc.rust-lang.org/std/io/struct.Error.html#method.raw_os_error). It *seems* to be [the same on OS X](https://webcache.googleusercontent.com/search?q=cache:l40-xk6JQkAJ:https://opensource.apple.com/source/xnu/xnu-344.2/bsd/sys/errno.h+&amp;cd=1&amp;ct=clnk&amp;gl=us&amp;client=ubuntu).
Are you trying to solve a specific problem? If you describe it here, then we may be able to give better advice.
You don't really need a full RPC framework here; you can just send a boxed function across the thread. RPC becomes necessary if processes are involved.
I think that's a good post, especially for beginners coming from languages with higher abstractions. I remember one of the first things I tried with Rust was to create a polymorphic vector similar as you would do it in Java or C#, and I had to learn that you can't just put trait objects into collections directly.
https://vagga.readthedocs.io/en/latest/ It's rather extensive, even.
This is by far one of the best tutorial series I've ever read! Even though I'm not following along myself, they're still really interesting (and make me realise just how little I understand about how my computer actually works).
 (Cross posting this from HN) I wish I had more spare time to help work on something like this. I've been reading all of these posts since the beginning, and they are all so excellent. I knew a lot of these things abstractly, but this explains it all in such solid detail, it's awesome. Thank you! Now a question for people in the know about micro-kernel architectures. One thing often claimed is that the message passing is too expensive, causing essentially double the work per system call. After reading this, I started wondering, and now want to read more about it: is it possible to use page faults and a handler to effectively build a message passing setup in the microkernel? Essentially using the pagefault as the mechanism to switch stacks from one kernel-service to another? Is this novel, stupid, or even faster than existing mechanisms? Obviously I need to go read how L4 and others do this. What's great about posts like this is that it makes me want to go learn about it... 
Missing the wonky but pragmatic solution trait CustomSvgWriter {...} enum Shape { Circle(...), Square(...), CustomShape(writer:CustomSvgWriter) }
You can still get tickets and plan to come ;)
It can be helpful to try to let multiple versions of a service run concurrently. Add versioning to the path of the requests. Turn off the old versions once they're no longer used. If changing code in a shared library necessitates all services being upgraded simultaneously it's either a bad design in the first place or otherwise should be a rare event.
Would someone please explain this in other words? "because we’re using traits, we cannot simply add structs to the vector because traits don’t have a fixed size."
When a dependency needs to make a backwards incompatible change: Issue |Unversioned in a monorepo | internal crates.io | msa -------|---------------------------------|---------------------|------ dependency | on checked in version | on only a major version number | on what's deployed backwards incompatible update method | maintainers fix their clients | require clients to update by a deadline | require clients to update by a deadline update risks | too free to make changes and publish prematurely; APIs are unstable and lower quality | clients refuse to update | clients refuse to update Ideally crates would only ever have major versions 0 and 1, and the commitment of the 1 version number in practice does reduce the likelihood of needing to make backwards incompatible changes versus the monorepo libraries. While the cost is greater if the updates don't go well, it's less likely to happen. The expected value of any of these probably depends on the company culture/scale/etc.
Are there plans to use Vulkan for it?
In the [winapi](https://github.com/retep998/winapi-rs) crate I see a number of references to authentication, but I'm not sure which specific module(s)/function(s) you need to use. Try asking in their IRC.
Thanks so much!
God bless you! I am trying to implement an algo coming from an OOP lang, this is timely :) 
I'm confused. Wouldn't it need to be CustomShape(Box&lt;CustomSvgWriter&gt;)?
Modules, in Rust terminology, are not the feature you're looking for. They sit somewhere between classes and namespaces in languages like Java. The dependencies between Rust modules are not explicit, and nothing prevents them from having circular dependencies. The modules that this article talks about are crates, in Rust terminology. Their dependencies are explicit, and cannot have cycles. Crates can also have their own release cycles, and their own repos.
&gt; I wish I had more spare time to help work on something like this. I've been reading all of these posts since the beginning, and they are all so excellent. I knew a lot of these things abstractly, but this explains it all in such solid detail, it's awesome. Thank you! You're welcome! Thanks so much for the kind words :). 
I am not a Firefox/WebRenderer dev but apparently both [Vulkan and OpenGL](http://gamedev.stackexchange.com/a/96016) are graphics APIs. WebRenderer uses OpenGL so I guess it does not really need Vulkan. Basically WebRenderer maps CSS properties to OpenGL instructions. It does not need anything fancy like a new game needs and Vulkan provides.
Apparently they god really good performance in Servo without Vulkan. I think they are going for low hanging fruit.
I guess, but I was asking about making it even better.
Thanks that actually worked. One more question, stepping out of main I get error of lacking the following files: Unable to open 'exe_common.inl': File not found (f:\dd\vctools\crt\vcstartup\src\startup\exe_common.inl). Create FileCancel ErrorUnable to open 'rt.rs': File not found (c:\projects\rust\src\libstd\rt.rs). Create FileCancel ErrorUnable to open 'lib.rs': File not found (c:\projects\rust\src\libpanic_unwind\lib.rs). These paths does not exist on my machine and never did, so I assume I inherited it from some of the installed projects (RLS or vscode-rust). Did you run into this? Looking at it, I agree though, using gnu is more expressive, I just like knowing that once I need to bind to a msvc compilation, I _can_ debug it. Thanks again.
My understanding of this is that WebRender uses various types of shaders supported both by OpenGL and Vulkan, and that Vulkan removes some limitations of a number of OpenGL implementations enabling more parallel rendering. However, OpenGL is more commonly supported and it makes more sense to support it as a primary focus. There's no reason that WebRender could not use Vulkan or other similar low-level graphics APIs such as Metal or DirectX 12.
&gt; It can be helpful to try to let multiple versions of a service run concurrently. This is exactly my concern. Let's say you release version `N+1` of `foo`, which contains a few breaking changes, to support a new feature in your `widget` tool. Your `widget` tool bumps its version of `foo`, but all other dependents of `foo` remain at version `N`. Semver works and all services continue to function normally. There are multiple versions of `foo` in use, but in principle, that shouldn't be a problem. ... except, six months later, your teammate is also working on a few improvements to `foo`, which also contain breaking changes, and therefore, they'd like to release `N+2`. But your teammate doesn't care about `widget`. Instead, their changes to `foo` are motivated by improving a different tool, `gadget`, which was previously using version `N` of `foo`. You go to update `gadget` to `N+2` of `foo`---to get your latest changes---only now you realize that version of `N+1` introduced *other* breaking changes that you are now also on the hook to fix inside of `gadget`. You look at the commit log and reach out to your teammate for advice, but that was six months ago. They moved on. --- This happens all the time. It's a normal part of development in semver. In the open source world, semver is necessary because everything is so open ended, so we pay this cost *by necessity*. I maintain enough open source projects to say with confidence that a non-trivial amount of time is dedicated towards managing semver in one form or another. But in your closed source proprietary code base, it's likely that you can actually enumerate exactly all dependents of `foo`. So you *could* fix all dependents if you *wanted* to, and certainly, that seems like the polite thing to do (if not the most efficient, since you have everything paged into context). But even if you wanted to, maybe you have so many microservices scattered across a billion repos that you might have missed some. And you have no idea that you missed any, because everything will continue to hum along, thanks to semver. There are various tools one can invent to alleviate these problems. Hell, the Rust community has its own version of said tool called `crater`. But now you need to maintain tooling. &gt; If changing code in a shared library necessitates all services being upgraded simultaneously it's either a bad design in the first place or otherwise should be a rare event. Somewhat agree... But bad designs are part of the Real World, and not necessarily because of incompetence or negligence. A design that was good six months ago may be bad today because our use cases and requirements evolve. We need to be able to manage "bad design" efficiently. Dismissing a problem because it's only caused by bad design is, IMO, equivalent to saying, "just don't make mistakes and it should work OK." I don't know about you, but I make mistakes *all the time.* I'd rather my development process be flexible enough to handle it.
Sorry, I [responded in a sibling comment](https://www.reddit.com/r/rust/comments/61l7zq/rusts_modules_instead_of_microservices/dffqq6w/) and it seem relevantish enough to just punt on a more targeted response to you. :-)
Given that I have an API endpoint `/is_prime/&lt;int&gt;`, after I'm done waiting on I/O, my next Future should be computing whether the integer is a prime. Should it then be implemented so that when it's polled, it advances the calculation by testing against the next integer, and returns NotReady if the current divisor fails to prove primality of the given number ? Even with such an implementation, could you not have enough computationally expensive requests to take over the whole cpupool ? 
There are multiple ways to mutably get at different vector elements at the same time. The most basic ones are [`iter_mut()`](https://doc.rust-lang.org/std/primitive.slice.html#method.iter_mut) (which allows to you extract element references, that exist independently, one at a time) and [`split_at_mut()`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut) (which allows you to extract two subslices, both mutable). To avoid borrowing `world` mutably, you'll likely have to have a method like `get-players(x, y)` returning a tuple of references.
I don't think CString is meant to provide an "uninitialized" (i.e. 0-filled) buffer. So what you're doing seems about right, except: * I think you can leave out the `as_mut_slice()` * Since you're finding the NUL terminator yourself there is no advantage to using `CStr::from_bytes_with_nul`, you can simple use `String::from_utf8` here.
Yeah for sure. Following everything. It was working with an earlier iteration of the code, but now Ableton doesen't see it
Try a Pine64 instead. Yeah, all Pi interfaces max out at 20MB/sec. Quite annoying for anything serious.
For the most part we prioritized speed over space. But, we also came from a BerkeleyDB environment, and made sure that LMDB always uses &lt;= BDB's space requirement.
You should go to r/playrust instead
I found the title a bit confusing, Rust supports polymorphism very well already through parametric polymorphism. The Java/OO type of polymorphism is subtype polymorphism. So it was a bit lost on me what he was trying to achieve.
Too bad. Watch out for the next one then ;)
In a `Vec`, every element needs to be the same size. With an `enum`, it's the size of the largest variant. With a trait, there's no upper limit, since somebody could do `impl SvgWrite for [u8; 1000000000]`, so it's impossible to make a `Vec` that can hold any struct that implements a given trait. Instead, you need to store references (either non-owning `&amp;`-references or owning `Box`es), since those are all the same size no matter what they're pointing to.
Sigh. I'm just happy that there are people realizing I'm not trying to make C++ look bad and persuade people to move to Rust for life. I do recall myself being defensive a while ago, too. I tried Rust two or three times and I stopped it at some point. First time because I was disappointed by the lack of backwards compatibility. I thought the language wouldn't see the day and removed rustc from my PC. One time because I couldn't make myself comfortable with the thought that I wouldn't use class inheritance like I used to, so I stopped using Rust. One more time because of function overloads and Tratis not being as powerful as C++ Templates are: I actually though that's a joke when I saw the specs of Tuple. There are few more things made me think Rust isn't worth a try I don't remember now.Thus, it took me more than three attempts to start using Rust more. I don't expect people to accept my point of view in a blink of an eye, but I'm a bit disappointed by the offensive way they're trying to express this, especially considering myself a C++ programmer first and just being enthusiastic about Rust while giving it a try. Thank you for the kind words, I'm sincerely happy you found this post good enough.
For sure.
It's my dream that we move away from passwords. In the limit a good password is indistinguishable from using cryptographic quality certificates. 
&gt; If another exception exception occurs while calling the exception handler, the CPU raises a double fault exception. This exception also occurs when 
I think I need you to proof read / edit my blog entries :)
...which we would still need to manage somehow. Moving to password managers first will make switching to certificates feasible in the first place. Because then the switch is not as big a jump as before. Offline managers, too.
Also, I'm a Debian contributor. If all works out well I'm planning to package this for Debian. We can collab there too.
As far as I know, rust-crypto is currently in need of a maintainer.
The reason this is a big deal in Java is because the classloader never had any defined access controls into libraries. This meant that when you make a class public, anyone importing your library had access to everything. There have been numerous attempts over the years to fix this, osgi is probably the best example, but was never fully adopted because of the complexity it added. The other was just best practice to split impls from apis, and always ship two libraries. One for compiling and one for runtime. In Rust I think we're pretty close to this, but you have to be careful. pub exports from a lib.rs are the only things visible by other crates using the library. In practice I've been finding that I'm exporting almost everything from a library. I wonder if there shouldn't be a more explicit pub identifier to make it more obvious, and less likely that you export things unintentionally. I'm not sure that it's needed, but maybe it will be. As a comparison, Java is really just catching up to Rust.
Yes, I think futures are perfect for this. You should look at: https://docs.rs/futures/0.1.11/futures/sync/oneshot/fn.channel.html And also: https://docs.rs/futures/0.1.11/futures/sync/mpsc/fn.channel.html
The official documentation doesn't work for you? https://doc.rust-lang.org/book/advanced-linking.html
Yes, you can. The catch is that the exact way greatly depends on the target (that `x86_64-pc-windows-msvc` thing). More specifically, in my testing, the `-gnu` target ~~always statically links~~ statically links to the standard library with minimal dependencies because it cannot guarantee that MinGW libraries are installed in the target system. For `-msvc` target ~~I thought `-C link-args=/MT` should do the job but it somehow didn't~~; in my Windows box with VS 2015 it always links to `vcruntime140.dll` for example. So if you need ~~the static linkage~~ the effect of the static linkage *today*, you can simply go to the GNU toolchain (and I hope the MSVC toolchain to work same in the future). Note that, you may already know, but ~~static linkage~~ including all dependencies will increase the binary size for many cases; my simple `hello.exe` is about 300KB ~~when statically linked~~, for example. *EDIT:* Damn, I should have mentioned that this is not the exact sense of "static linkage" (more like the effect of static linkage). /u/retep998 is totally right, you still link to `msvcrt.dll` and `kernel32.dll` (some may want to get rid of them for various reasons!) even when `-gnu` target is used. Also I've mistaken that `/MT` is also applicable to the linker (I don't use MSVC a lot so my memory was in flux).
That document is great for Linux but I wish it would explain about all Tier 1 platforms
Ah ok, Ring on the other hand is quite active and popular. Giving that a try.
Thanks! I send the gnu version to a friend and it did work on his machine, I just assumed he had the needed libraries installed. The Gnu version is only 20% bigger so did not look like static linked to me (https://github.com/JordiPolo/file_http_server/releases/tag/v0.0.5) I'm not particular partial to any of these chains, I'm just using appveyor for compilation so anything is ok with me.
For others who also didn't know what it was: &gt; Master Password simply uses your one password and the name of the site to generate a site-specific secret.
Beware that other crates may need external dependencies. [Dependency Walker](http://www.dependencywalker.com/) is probably the surest way to check the needed libraries (that is, of course, needed in the loading time) and that's how I've found the issue.
If you want your output file to be smaller, there are things you can do. [This post](https://lifthrasiir.github.io/rustlog/why-is-a-rust-executable-large.html) explains why a Rust binary has such a high base overhead and, using it and a few other sources, I managed to get a [boilerplate with much more in it](https://github.com/ssokolow/rust-cli-boilerplate) (eg. the clap argument parser) down below 200KiB. I've only targeted Linux so far but, assuming I'm not missing something, here are the steps which should apply to Windows too: 1. Set `lto = true` in your release profile 2. If you don't mind making `RUST_BACKTRACE=1` cause a crash when it tries to display the backtrace, the copy of GNU `strip` from Cygwin apparently knows how to remove debugging symbols from PE-format executables. (**EDIT:** MSVC builds already separate out debug info.) 3. If you don't need stack unwinding, set `panic = 'abort'` so LTO can remove that code. 4. Compress the binary using [UPX](https://upx.github.io/) (Takes one of my scripts from ~900K to ~300K.) 5. If you're willing to build on nightly... * ~~Opt for the system allocator instead of jemalloc~~ (It's default on Windows) * Set `opt-level = 'z'` (Optimize for size) (Aside from `opt-level = 'z'` (which I use a wrapper script to temporarily edit `Cargo.toml` for), all of this can be made conditional so it'll still build on stable with a larger output size.)
I feel like there are many ways to address this problem, but the majority of them would be a large design change. You could definitely make a get_players() function to get multiple mutable players as birkenfeld said, but that still seems somewhat like a compromise, and then what if you needed 3 players? One thing I would think of doing is making Player not contain the data itself, but rather just an ID for which player it refers to. This way world.get_player() would not return a mutable player, but rather just a player "Copy" that would not be lifetime bound to the World. With this thing, then, you'd have to pass in a reference to the World to any function which players modify. Like in this case, `player1.resolve_attack(player2, world);`. With that model, each player could do modifications on the world, while still having independent structures to model interactions between players. If you really wanted to go all out, there are quite a few other ways to manage entities and interactions that have been discussed in /r/rust_gamedev and #rust-gamedev on the mozilla IRC. One interesting way you could do this is via a mutable or immutable world, but with each entity (or player) only doing updates through "events" that are returned from the player update functions. Here's a slide for that that was linked in #rust-gamedev, it's written in Scala but it applies to Rust game programming pretty nicely: michaelshaw.io/game_talk/game.html#/.
&gt; How is ring compared to rust-crypto? I preferred it over rust-crypto, because the documentation is much better and the scope is more minimal (only decent crypto). It also seems more actively developed. It is not pure Rust though, because it forks parts of BoringSSL for performance and side-channel safety. The C code is slowly being replaced with Rust code though. &gt; Can we collaborate? Sure, gladly! I'll have a look at your code to see what can be merged. &gt; I really like the clear on drop aspect of your code. Not sure it actually works, it is a bit experimental and I did not really test it. There have been some crates popping up for that, I should probably use them.
Would someone mind explaining why they're downvoting me? I honestly don't know and, if I'm drawing a blank, I can't improve. **EDIT:** Is it that I got carried away with verbosity on something that's about the writing itself rather than the topic of the writing, when this isn't a subreddit about grammar?
First you need to answer the question of what "static linking" means. * Do you mean statically linking Rust crates? Rust crates are always statically linked when using Cargo. * Do you mean the C standard library? Aka msvcrt and vcruntime and the ucrt. With the `-gnu` targets, it will *always* dynamically link to `msvcrt.dll` which is ancient but ships with all versions of Windows. With the `-msvc` targets by default Rust will link to `msvcrt.lib` which, depending on what version of VC++ you have, will dynamically link to either `msvcrt120.dll` or `vcruntime140.dll` along with a bunch of UCRT DLLs. There is a `-Ctarget-feature=+crt-static` flag you can pass to rustc to instead link to `libcmt.lib` which statically links all of the CRT, however it is still unstable. It is slated to be stabilized however, and it should only be a few months before you can use it on stable. * Do you mean system libraries like `kernel32.dll` and friends? There is no way to statically link them, and there's no sane way to avoid depending on them either. They are always available however, so they're not a concern for portability. Although if you use a function only available on newer versions of Windows, then your program won't run on older Windows. * Do you mean C/C++ libraries pulled in by certain crates? You'd have to either provide a static version of that C/C++ library to be linked in, or tell that crate to build it statically.
&gt;Opt for the system allocator instead of jemalloc Windows already uses the system allocator by default. &gt;the copy of GNU strip from Cygwin knows how to remove debugging symbols from PE-format executables. This only applies to MinGW produced binaries. MSVC binaries have nothing inside them to be stripped, because debug info is stored in a separate `.pdb` file.
Thanks. :)
I started using ring too :) We can maybe form a common repo to merge? Also I inquired with the main dev that can this replace the C impl. He's open to that too given this performs well and implements all the algos. I have left place-holders in the source for older algos.
I guess it's because many people don't like others to give advices. At first I perceived your post as a critique too. But probably you just honestly wanted to help. And just in case, English is my second language. :)
It's a Rust subreddit. We're here to read stuff about Rust, not about OP's ESL certification or the politics behind (s)he/they/one.
Yeah. I'm not the most socially perceptive guy so I have a hard enough time just trying to not put my foot in my mouth. While I did get carried away, I was just trying to help. If I'm trying to attack someone, *they'll know it*. If I seem to be attacking someone subtly, it's much more likely that I'm either tired (and my ability to anticipate how others will see things has been compromised) or coming down with something (in which case I act cranky without realizing it until another family member points it out).
This might be tangential, but it would be cool if `rustup/cargo` could manage external documentation as well. We have cached external crate source, can generate docs from that, and then need a generated index so that `rustup doc --ext` will show us the docs for all installed crates. Eases one more little source of friction when needing something outside the stdlib.
So my guess was more or less correct then? I doubt people would have reacted that strongly if I'd said something short like this: &gt; If you don't mind my asking, is English your second language? &gt; &gt; If so, a quick tip: It comes across as "pronouns not agreeing" if you put in the effort to use something as "formal and genderless" as "one" but then use the gendered "his" to refer to the same referent in the same sentence.
Is that even possible on Wayland?
Others explained much of the stuff already but I noticed you probably want to do something else. From what I see, you want to convert IP to some string. If you just want to display the address, you may want to simply write `println!("Address: {}", sock_addr)` or `write!(output_stream, "Address: {}", sock_addr)` If you really want to create string, you can use `format!("{}", sock_addr)`. If you want to define your own formatting using `std::fmt::Display` trait you can create `struct AddrWithMyFormat(std::net::SocketAddr);` and implement `Display` for it. Then whenever you want to use your format, simply write `AddrWithMyFormat(sock_addr)` in those macros.
It wouldn't surprise me if there's also a bit of frustration at the idea that OpenSSL will probably get away with this, while the better fork (LibreSSL) will be stuck on the less appealing license as its thanks for being honest about what the law says.
Excellent series Phil! Will you be covering hardware IRQ handling in later articles? IO (APIC) IRQ handling and enumeration(?) are the parts I'm most hazy about. So I'm really looking forward to seeing how you'd break down the topic.
Apparently, it is, if you just implement it as a regular wayland client. I'll report back though. If I succeed, I'll post something in /r/rust, otherwise, I'll just respond to your comment :)
If you mean runtime dependency injection, I think one large thing is rust's lacking of a stable ABI. You can load rlibs, but they have to be built with the exact same rust version, or you risk it not being usable. This can be overcome with using the C abi, but that would still have to have unsafe code to interact with anything loaded. That being said, what would your use cases for dependency injection be? I'm not too experienced with many use cases for this or languages where this is common, so I would be interested to hear!
Yeah, it's a bit off-topic, but it's interesting and intended to help. Upvoted.
Aaah, that is so helpful, thank you! I'd already stumbled across the one from msp.ucsd.edu and was working through the first few chapters last night - will take a look at the rest of the links after work :) Not really sure what I'm planning to write yet - want to get a grasp of the fundamentals before I aim too high :p
Kris Jusiak's Boost.DI is a good example of zero-overhead C++ dependency injection: https://github.com/boost-experimental/di Something conceptually similar could make sense for Rust.
Do you feel the same way about the linux kernel? 
&gt; I've seen that someone already did this in Rust. Intriguing! What does that look like? I would like to see that. Do you have a link? I would like to see this in the standard library. It would help put my mind at ease [1] if the indices returned by, say, String::find, would be of a type that would make the compiled code able to safely avoid run-time bounds checking and UTF-8 boundary checking when used for indexing or slicing the string. Have anybody been working on this? (Links to RFCs?) [1]: I'm pretty sure it wouldn't meaningfully affect performance, though.
That's great to know! I'll definitely have a look at the Gentle Intro. It might indeed make more sense to expand an already existing resource with real world examples than to start another new one ... 
I would like `xcalib -i -a` to work under Wayland. Could you do that too?
Make client a trait for which impl is done via a configurable procedural macro fed by a configuration file and you've built the first rust di framework?
I worked on [`relm`](https://github.com/antoyo/relm), an asynchronous GUI library based on GTK+ and `tokio`/`futures`. Last week, I added a `#[widget]` attribute to simplify the creation of a `relm` widget. A `relm` widget, or component, is the composition of a view, model and `update()` function (function receiving a message and updating the model). Here is how it looks like: #[widget] impl Widget&lt;Msg&gt; for Win { fn model() -&gt; Model { Model { counter: 0 } } fn update(&amp;mut self, event: Msg, model: &amp;mut Model) { match event { Increment =&gt; model.counter += 1, } } view! { Window { gtk::Box { orientation: Vertical, Button { clicked =&gt; Increment, label: "+", }, Label { text: &amp;model.counter.to_string() }, }, } } } This is a simplified version of the `buttons-attribute` example. The idea of this attribute is to be able to declare the view in a declarative way, avoid having to update the view in the `update` function (the attribute adds the call to `set_property`, in this case `self.label1.set_text()`) and this attribute automatically adds the redundant piece of code (the widget struct, the trait `type` items and the `container` method). I still need to make it work for communication between components. This requires nightly for now, but I wrote this attribute using the `proc_macro` feature, so it will hopefully be stable soon. Please look at the [section in the readme](https://github.com/antoyo/relm#widget-attribute) for more details. This week, I'll be at the GNOME+Rust Hackfest!
Is that audited, proven, etc. properly? It somehow doesn't sound super secure. Convenient and better than the same password everywhere, but still...
Thanks! Yes, hardware IRQ handling is the plan for the next post. What do you mean with enumeration? Getting a list of connected devices and their IRQ mappings?
It's not traditionally dependency injection, but I did make a crate that allows you to inject alternate code implementations when unit testing. Sightly shameless self plug - https://github.com/craftytrickster/mock_me
Someone acknowledged Rust's existence?! *Light the signal fires of Gondor!* For anyone wondering, this is the entirety of the Rust-relevant material: &gt; Rust is one such alternative language [which curl could be rewritten in that is] commonly suggested. This isn't the case for not-Rust. It's the case for C89 specifically.
Are you saying that rustup should extend `cargo doc` to all locally cached crates, or were you simply not aware that `cargo doc` is a thing?
I agree with most of his points, except one: "Everyone knows C". There's more and more programmers that know multiple programming languages, but not C. I would consider myself one of them: I have some knowledge of it, but I wouldn't trust myself writing a larger program in it.
I'm very open to suggestions, since obviously I can't imagine what the specific pain points of _other_ people might be. (I still recall my first exposure to the docs and it was a bit ... bewildering.)
That sounds ~~hugely overcomplicated~~way too enterprise for my blood.
A dashboard app for my new Raspberry Pi setup. I have a cluster of four RPi 3s that I'm going to run Kubernetes on, and an original RPi Model B+ attached to the official 7" touch screen set up in a common area in my home. The dashboard will run in the k8s cluster and will be displayed on the touch screen using a browser in kiosk mode. The dashboard app is a simple Rust server with a front end written in Elm. Not much is done yet, but it's open source: https://github.com/jimmycuadra/dashl
Ah! I had tried to use Display method directly, which obviously didn't work, hadn't realised it is like Python Repr, and I can user format! directly! Thanks. So now I no longer need my function... Was still worth it, it forced me to re-visit match constructor and ownership.
&gt; And there is still the borrow-checker, which again would make it hard to inject (read: mutate) structs from the outside I don't understand why people use field injection (setting dependencies on fields after the object is created). Just instantiate the object with its dependencies via the constructor... no frameworks needed.
Thanks for the crate tip, very neat. I might use it in the future.
Yeah, this might be cool :)
There are a lot of people who think that memory safe c++ is practically achievable. It gets frustrating. I think that it isn't which is a better language but honestly at some point we have to stop using memory unsafe languages for certain tasks. That's not an attack on c++ as much as it is a plea for software engineering to take security more seriously.
The nested loops aren't really a problem but what I meant was that you can figure out where a pattern is without actually searching it. E.g. Hd3 occurs at (((7 * 26) + 3) * 10 + 3) * 3. It's slightly more complicated when you have matches that don't begin with a captial but it's doable.
Huh, I always thought the thing they call CamelCase was actually PascalCase and the thing they call mixedCase was camelCase (because there's humps in the middle). Am I wrong? Or are there multiple common definitions floating around out there?
Is that really necessary for a program to diagnose its own address space? From what I recall, the symbol tables and so on should be present in memory, and you can obviously dump the stack no problem.
If C compilers switched UB-sanitizers on by default that early sense of accomplishment would soon be replaced by a more realistic humility.
I don't know for sure, that's why I phrased it as a question. Doesn't hurt to try, right? 
Right, yeah, sorry, I'm not trying to criticize your suggestion. Definitely something worth trying. Just offering what I know.
Ah, i got ya, thanks
Well, there is no "you people". I'm not pcwalton. I can't speak for him or anyone else in the community and I doubt we all agree on everything. As for the definition of memory safety, I don't think we (personally - you and I) disagree. It is (at least) a property of code, and we use rustc to ensure it. But what I'm talking about is larger than Rust or C++ or any specific language. Security, in general, is not taken seriously in software engineering. That's a whole other discussion, as is the discussion of boost and C++'s ecosystem, and I'm not going to start down that road. I only bring it up because I know I personally get frustrated with C or C++ or any-other-unsafe-language developers who refuse to see the danger - the users at risk, the money lost, etc. It gets frustrating, I could see that comment being a symptom of that frustration, but I can't say for certain. I wouldn't take one comment and try to draw a conclusion about the community or even that person. &gt; It was also ironic that this comment took place a day or two before 1.15.1. I guess modern Rust written by experts is also not memory-safe... I've always said Rust isn't a silver bullet, only a step forward. Rust has plenty of security issues and it only tries to tackle on subset of security issues (albeit a very important one).
&gt; Should it then be implemented so that when it's polled, it advances the calculation by testing against the next integer, and returns NotReady if the current divisor fails to prove primality of the given number ? In general, `poll` should _never_ be blocking; it's part of the trait's specification. You'd determine how much computation counts as being blocked, though. But yes, that's the basic idea. &gt; Even with such an implementation, could you not have enough computationally expensive requests to take over the whole cpupool ? I am not totally sure what internal policies for the pool are, but I know `futures-cpupool` is pretty basic. But sure, this is just an inherent problem: if you have a lot of computational work to do, you need a lot of computational resources.
I think most injection tries to follow RAII and only injection things through constructors. It also appears that dependency injection is conflated with a magical framework that ties configuration together when it's perfectly reasonable to hand write in many cases.
I don't think you can do that without compositor support. See for example how Sway had to add a patch to get a (patched) version of redshift working. The WM/compositor controls the output, and so without a standard way to access those controls across all compositors (eg a standard Wayland protocol, which all it takes is someone to put forward) that doesn't sound possible without loads of conflicting implementations
I'm on `sway` (I'm sorry! :) ), which is based on `wlc`, and I still have no idea whether it's possible or not. If it's not possible, I see myself patching `wlc` until it actually works. For X &lt;-&gt; Wayland synchronisation, well, that's an entirely different story indeed. EDIT: I did however [submit an patch to `wayland-rs`](https://github.com/vberger/wayland-rs/pull/101), so my research wasn't completely useless if it's gonna fail :)
We're hosting on GitHub pages and they [had some problems today](https://status.github.com/messages)
I expect to really focus on getting Rust integrated into the Fuchsia build system, so that Rust binaries can be part of the world build. Nightly rust is now in the toolchain, a major step.
It _should_ be fine you're using trait objects. I do agree that replacing one implementation of a concrete struct with another concrete struct with the same name and `impl {pub fn}`s isn't likely to work, but I think that if you're expecting a trait object (and not changing the trait itself), anything that gives you a vtable for that trait object should be fine, right?
How do you do the ipv6 wide bind? I tried: Iron::new(ip).http("ip6-localhost::8080").unwrap(); Iron::new(ip).http("::8080").unwrap(); Neither compiles.
I'm looking forward to working together! It might take me a few weeks though, as I'm currently swamped with other work... But feel free to message me on github (@DavidDeprost).
I don't think I can, no. Compositor support is needed, and it's a lot more work in general than "just" a clipboard :)
C is also more subtle and complicated than a lot of people realize. For anyone who doesn't believe me, write a C compiler or static analyzer and you quickly see what I mean. This leads me to put very little value in assertions that C is common knowledge.
At 3 or 4 _additional_ dependencies, I'd start doubting my ability to adequately exercise the client, simply because of the sheer amount of state it potentially depends on. I'd no longer be confident that any service mocks I write would _interact_ in all the ways the real ones would. As an example, I'd say that something that uses a `DnsService`, a `TcpConnectionService`, and a `FilesystemService` (in order to download and save a file, say) is in dire need of being refactored into a `NamedTcpService` and a `FilesystemService` - because the _only_ thing being done with the DnsService is to feed its results into the TcpConnectionService, that behavior should be factored out. That then shrinks your state space from `DNS-fail | DNS-succeed-CNAME | DNS-succeed-A | DNS-succeed-AAAA | TCP-succeed | TCP-fail | FS-succeed | FS-fail` to `Connection-succeed | Connection-fail | FS-succeed | FS-fail`... and that's just going from 3 to 2, and ignoring a lot of DNS (such as DNAME). I honestly think that once you have 4 or 5 dependencies on external state (and that's what a service _is_), you are rapidly leaving the bounds of testability. Of course, aggressive factoring-out like that exposes a big weakness of (dynamic) DI: It's not a zero-cost abstraction by any means. Unlike doing DI-like things by way of generic parameters, doing it with trait objects imposes overhead on every level of "is a dependency". That acts as a counterpressure, encouraging poorly-factored clients with many direct dependencies for performance reasons. IMO, that alone makes (dynamic) DI hugely uninteresting to me, because it has _bad incentives_ for developers. Also, if you want to pass it in a constructor, that's as simple as this: impl Client { fn new(svc: Box&lt;Interface&gt;) -&gt; Client { Client { service: Some(svc) } } } Possibly even do away with the `Option` entirely, etc. You can also skip declaring the `Service` on a separate line, and just construct it in the argument list of `Client::new()`. I just chose the most explicit formulation, to show each step.
Learned a long time ago, forgot most of it by lack of use.
Camel Case usually involves classes Class LikeThis{...} And methods public void likeThis(){ ...} And local variables int likeThis Ex. java and Smalltalk C# has Pascal case where everything starts with uppercase
But that works against my point above: by delaying the sharp edges until later people get invested in the language.
Often someone is a bit overenthusiastic and advocates rewriting everything in Rust. This post discusses why you might not want to do that, so I think it is relevant even though there is not much Rust can do about the reasons discussed in the post.
It would be an interesting experiment to have a Rust fork that moves compile time errors to run time.
`Rc&lt;T&gt;` does that for borrowing.
try Iron::new(ip).http("[::]:8080").unwrap();
&gt; I'd also really like to look into similarity hashing to help create a tool to pre-sort files in a .tar archive so they compress better You run into *which* tar standard you're supporting. The newer ones pack a lot of meta-data into the space between files and pretend that it is file data. In [car](https://github.com/valarauca/car) I just started supporting Brotli and Zstd to have faster/better compression. 
Interesting, I've always said/been told CapsCase/PascalCase for types, camelCase for methods and variables in any Java I've ever worked with. Maybe this is a UK vs US thing?
&gt; I hope the C++ devs who read this will not be too defensive. There is no rust vs c++ holy war I can kind of sympathise why they would and why they would think there was. There's quite a lot of... enthusiasm ... in the rust community, which is great but it can also be very annoying to people who develop in other languages. Quite a lot of articles, comments and so on on this topic get written and posted (sometimes directly to c++ places like /r/cpp) which can get a bit tiresome.
and I've always heard `camelCase` and `TitleCase` (although my favorite names, purely from a good-name capacity, are `SCREAMING_SNAKE_CASE` and `kebab-case`), which all have different definitions in `heck`. Darn.
I've been working on my [web framework](https://git.nokaa.moe/hayaku/hayaku). I just added support for running multiple event loops which is pretty nice. I'm working on adding an easy way to serve static files, and I'm hoping to implement sendfile support this week.
Nevermind me. Sensible margins, good font sizes, nice code colours :)
You can look at the specification on their website. IIRC it was already posted over at /r/crypto and there wasn't any criticism on the cryptographic specification. I don't think there's been any formal audit though.
[RFC3493 3.7](https://www.ietf.org/rfc/rfc3493.txt) says that you can use IPv4 addresses on an IPv6 socket. The same RFC mentions a socket option in paragraph 5.3 (IPV6_V6ONLY) that you can use to disable or enable support for that on a socket. The system-wide default for combined mode used to be "on" on linux and "off" on *BSD, and modern Linux distros also set it to "off". So to be able to reliable use that feature, you must use setsockopt to turn IPV6_V6ONLY *off* for your listening socket, then bind to '::', and the socket will accept both v4 and v6 connections. I'm not sure how to actually do this, but I hope this helps.
I've expected just another rant like "C++ as safe as Rust because we have smart pointers now", but it's an actually praising article.
Nice! I think I still prefer the look of [my version](http://killercup.github.io/trpl-ebook/), but yours are far more up-to-date and probably not based on regex and LaTeX macros :) What's the paper format your PDFs are using? PS: From one TRPL PDF creator to another: I'd show more level of the TOC. Also, I was looking for that table of supported platforms with unicode tick marks to see how you managed to show that, only to notice that the current revision of the book doesn't have that any more… But the Stack and Heap tables look fine – good job! :)
Yeah… now that the books use mdbook and crowbook is a thing, this might actually be feasible (i.e., you don't need to cpan install a bunch of TeX modules).
At work, we used to have full fledged Spring annotations and field injection and what not, but now we just use JSR 330 (`@Inject`, `@Named`, `Provider&lt;T&gt;`) and constructor injection, so it can work with any framework or none at all easily, and anyone who wants to can hook things up manually for testing as needed.
&gt; Rust is not the language curl is already written in, it's not available on almost every general-purpose CPU in existence, it's not as old, and it's not ubiquitous. I personally often wonder if those reasons *actually make sense*. Mind you, they may very well for curl itself! Whenever I see someone arguing for portability, for example, I do a double take: - you are writing a server program: do you really need to support anything beyond x86/x64 and Linux? - you are writing a desktop application: do you really need to support anything beyond x86/x64 and Windows/OS X/Linux? - ... I mean, it's great to worry about portability, but do you really *need* it. To the point of completely ignoring other aspects? --- The other issues are similar: - curl is not written in Rust: well, Rust has excellent FFI support, so part of it could without touching the parts that aren't! - Rust is not as old: I think the author should have used "mature" here, because age isn't much of a criterion. - Rust is not as ubiquitous: true, but also a kind of circular argument. It cannot get ubiquitous without being used, after all. --- As I said, I understand that sticking to C may make sense for curl. But I don't agree with a number of the reasons given, for me the greatest reason is simply *inertia*. A great rewrite is costly.
I'm using a `HashSet` as an allocation site/ sharing cache. I need something like `fn insert_or_get&lt;T&gt;(set: &amp;mut HashSet&lt;T&gt;, value: T) -&gt; &amp;T where T: Hash + Eq`, but my current implementation makes borrowck yell (when are non-lexical lifetimes landing? ;_;) and requires a `clone`. Can someone help me appease borrowck and perhaps find a way to avoid the clone? Current broken implementation: pub fn insert_or_get&lt;T&gt;(set: &amp;mut HashSet&lt;T&gt;, value: T) -&gt; &amp;T where T: Hash + Eq + Clone { let option = set.get(&amp;value); option.unwrap_or_else(|| { set.insert(value.clone()); set.get(&amp;value).expect("insert_or_get: HashSet API is fubar, \ get after insert got us nothing...") }) }
A lot of the benefit of using DI frameworks is in the slightly more advanced features. For example, declarative scopes: Singleton scoped objects last for the duration of the application, Request scoped objects let you store request data in a side-channel, Prototype scoped objects are created fresh (possibly by a factory or something) for each injection, and custom scopes for whatever else. Mostly though, when you have a graph of hundreds of services declared over a dozen libraries with complex post-construct and pre-destroy behavior, its just a lot easier to have it "figure itself out" and compute the complex DAG of initializations and destructions on its own. If it can happen at compile time, then there isn't even any runtime overhead.
If it were strictly camel case, wouldn't "HELLOWorld" be segmented "H E L L O World"? If you keep it camel case this is fine of course, but you snake case it you get h_e_l_l_o_world. Treating the word boundary as immediately before the last capital might be *more useful* though. Hmmm
To your first question, different solutions with different tradeoffs (Static vs. dynamic dispatch), so we should be able to choose what fits our use case better. To your second question, yes, rustc forbids inexhaustive matches.
Thanks!
Yes but the rules of camel case, which are purely syntactic, don't support that kind of awareness because that's semantic information. Our word boundary rules have to be more complicated in how they handle multiple consecutive uppercase. I think your solution is more correct though than what it has now. If there are lowercase characters after the last uppercase character, the word boundary is before that uppercase character.
I'm not persuaded by the argument that curl's security bugs have mostly been at the application level. While that is true, the fact remains that once the investment is made to port curl into a language like Rust, code changes will not introduce any new bugs at the lower level, and that frees up developer time to concentrate on the application level, potentially facilitating the integration of a formal model checker into the process. My ideal software development stack (which I am trying to introduce into my own workflow) has Rust at the system level, Erlang/Elixir on top for process management and resiliency, Rustler in between them, and finally something in the family of TLA+/Alloy/CoQ for model checking of the application. That said, curl is a damn good product, and I can respect them not wanting to put the time to a port. 
&gt; Nice! I think I still prefer the look of my version, but yours are far more up-to-date and probably not based on regex and LaTeX macros :) Yeah, your PDFs are really nice, but I don't think there are exports for the second edition? (Part of my intent was "I'll make an EPUB quickly so I can look at it and maybe contribute more easily than by reading at computer screen", but I guess I underestimated the time it would took me) &gt; What's the paper format your PDFs are using? Oh, yeah, it's A5, I tend to use that by default because I'm more used to printing zines but it would make sense to also generate A4/letter version. &gt; PS: From one TRPL PDF creator to another: I'd show more level of the TOC. I'd totally do that.. except at this point the TOC is still a bit messy, so this way at least it's less visible :D Thanks for your feedback! 
Unsurprisingly the majority of comments on hacker news seem entirely relevant or directly about rust, so it seems fair to put it here.
Ahh, I see what you're saying! I guess I misunderstood the concept and thought it referred to a different part of the process. In that case I guess yeah, traits and generic objects have always allowed this to happen, with no runtime cost too for that matter.
They've got a great answer to what DI actually is, "[do I use dependency injection already?](http://boost-experimental.github.io/di/index.html#do-i-use-a-dependency-injection-already)"
I vote for A5, or even A6, as it's often read on screen anyway. For print you still can put 2 per page and fold, IMHO.
This is the relevant mailing list thread in the archives: https://mail.mozilla.org/pipermail/rust-dev/2013-August/005080.html And [in there](https://mail.mozilla.org/pipermail/rust-dev/2013-August/005101.html) it is also correctly mentioned that 2-letter acronyms are capitalized in .NET, e.g. [GC](https://msdn.microsoft.com/en-us/library/system.gc%28v=vs.110%29.aspx), [IO](https://msdn.microsoft.com/en-us/library/system.io.ioexception%28v=vs.110%29.aspx) and [IP](https://msdn.microsoft.com/de-de/library/system.net.ipaddress%28v=vs.110%29.aspx). So Rust did not go all-in on the .NET style given names such as [IpAddr](https://static.rust-lang.org/doc/master/std/net/enum.IpAddr.html).
I see. The `driver`, `device`, and some other bits and pieces (e.g. `event_buffer`) will eventually be accessed in a tight loop like ffi::poll(&amp;driver, &amp;device, &amp;event_buffer); // do stuff with events Will I suffer a performance penalty from having separately boxed these different pieces? When used in C, they are typically allocated right next to each other on the stack.
But this would also fall into your risk assessment.
Generally, no. You might see more cache misses on infrequent accesses but if these values are usually at the bottom of the stack anyways you won't notice much difference--a stale cache line is a stale cache line, regardless of where it's allocated. It's not something I'd really worry about unless you really start microoptimizing, and even then you should be doing it with the help of a profiler so you know exactly where the bottleneck is. As the other person commented, keeping them in the same struct will help ensure that they're on the same cache line, which should help amortize penalties from cache misses (you only pay them once per bunch of accesses rather than [potentially] one for each access), but if that's not really convenient (e.g. you want the user to be able to initialize them separately) then it's not that big of a deal; allocations that are close together in time will tend to be close together on the heap anyway. 
I think this is the strongest argument against a re-write of a prolific library. 
[Dagger 2](https://google.github.io/dagger/) is one framework that doesn't use reflection, but rather compile time information to generate the dependency graph. I think this approach would be amenable to rust's macro system.
&gt; The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that aren’t really language bound and they would not be fixed simply by changing language. &gt; &gt; Of course that leaves a share of problems that could’ve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C. I think this is an exaggeration. Of the list of known vulnerabilities, about half are definitely caused by memory safety errors (use-after-free, double free, or out-of-bounds reads/writes): https://curl.haxx.se/docs/security.html For example of the 20 most recent vulnerabilities, at least 9 fall into one of those categories.
If you've installed with rustup then you can add the source as a component for the toolchains you use. This will also keep the source updated with new versions. rustup component add --toolchain nightly rust-src Racer knows about the rustup install locations and should pick it up automatically. Otherwise you can set `RUST_SRC_PATH` to wherever you've downloaded the source files. The paths you've seen in guides are just where they had the source installed. The `$(rustc --print sysroot)/lib/rustlib/src/rust/src/` command resolves to where rustup installs the source files and can be used to set `RUST_SRC_PATH` in the event that it's not discovered automatically for some reason.
Thanks for finding that. I’d certainly forgotten some of the details of it. I think [my own post in that thread](https://mail.mozilla.org/pipermail/rust-dev/2013-August/005119.html) summarises some of the difficulties pertaining to conversion between forms; *all* of the commonly-used forms lose *some* information.
At least in my opinion, any DI discussion should probably link to the [custom allocators] discussion, since however the allocators get injected is basically going to define how idiomatic DI is done. [custom allocators]: https://github.com/rust-lang/rfcs/pull/1398
I've been musing on this over the week but been unable to respond until now. I think you want to make an iterator adapter, which means you own the iterator you want to adapt and provide the mapping/filtering in the `next` function. pub struct GitIter&lt;'a&gt; { statuses: git2::StatusIter&lt;'a&gt;, } impl&lt;'a&gt; GitIter&lt;'a&gt; { fn new(statuses: &amp;'a git2::Statuses) -&gt; Self { GitIter { statuses: statuses.iter(), } } } impl&lt;'a&gt; Iterator for GitIter&lt;'a&gt; { type Item = GitEntry&lt;'a&gt;; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { self.statuses.next().map(GitEntry::new) } } 
The post suggests VSCode but I prefer IntelliJ IDEA with the Rust plugin installed. I wish the Visual Rust project (plugin for Visual Studio) got more support. If we're going to use Visual Studio to debug then it makes sense to use it for editing too. I would actually pay for a version of Visual Rust if it worked as well as the IntelliJ plugin works.
&gt; It would be a reasonable optimization, perhaps, as a manual annotation. Ultimately, this is what is needed, IMO. 
&gt; Devirtualisation is the kind of thing people expect from a compiler: making the program faster but potentially slightly larger. Surely devirtualization is a no-brainer when it doesn't make the code larger. &gt; The opposite is probably very much unexpected for people. In fact people feel comfortable using Rust's very high level API's because they can be confident that it will all compile down to static dispatch. I disagree. Too much Rust code is written in the type parameterized style, which is inconvenient if you're optimizing for code size. Rather than rewriting all that code to reduce bloat, I'd rather have some way to ask the compiler to do it for me.
but Rust does work on both of those, even if they aren't "tier -1" status or whatever, and Rust will continue to improve its support for those platforms.
How does VSCode compare to Visual Studio? I only have experience with Visual Studio (C++, C# and C++.NET), and now I mostly use ViM for Rust development on Linux, but I hate ViM on Windows since the environment sucks for CLI tools.
Neat! Could this be added to mdbook? It's definitely [something mdbook would like](https://github.com/azerupi/mdBook/issues/88). If this functionality was added to mdbook, it would make it more likely that we'd publish official pdf and epub versions.
[From dependency injection to dependency rejection by Mark Seemann](http://blog.ploeh.dk/2017/01/27/from-dependency-injection-to-dependency-rejection/) 
Have you considered contributing to corrode?
Only when putting trait bounds on generics. When passing a struct of type `T` where `T: SomeTrait` into a function, the Rust compiler is usually smart enough to monomorphize the function (essentially what you mean by "de-virtualization"), resulting in static dispatch. However, when you pass in a `&amp;SomeTrait` or `Box&lt;SomeTrait&gt;` (referred to by Rustaceans as *trait objects*), the compiler has no way to figure out what the concrete type is at compile time, so it resorts to dynamic dispatch. TL; DR for the lazy: /// Compile-time static dispatch struct MyStruct&lt;T: SomeTrait&gt; { foo: T, } impl&lt;T: SomeTrait&gt; MyStruct&lt;T&gt; { pub fn frobnicate(&amp;mut self) { self.foo.frobnicate(); } } /// Runtime dynamic dispatch struct MyStruct { foo: Box&lt;SomeTrait&gt;, } impl MyStruct { pub fn frobnicate(&amp;mut self) { self.foo.frobnicate(); } }
I think the aop aspects are typically along the lines of "do something with everything that implements interface x", which makes some amount of sense to handle in the scope of a di framework. Introspection in particular is something I've been missing in dagger, eg printing the graph.
&gt; The post suggests VSCode but I prefer IntelliJ IDEA with the Rust plugin installed. Any particular reason as to why? What features do you find the IntelliJ rust plugin has that VSCode does not? I ask, as I do like IntelliJ IDEA for Java stuff, it's a pretty good editor overall. I tend to use VSCode for most of my work &amp; side projects.
Actually, in the example, we know that `from_utf8` will succeed, so there's no harm calling `unwrap()` on it, which means that function could just return `LengthError` instead of `Box&lt;Error&gt;`.
That also looks like it relies on calling the second function to pin the lifetime. You could probably hide it behind a macro but I'm not so sure. Instead, it might be better to initialize it privately and pass a reference to a user-provided closure--like the thread-local API, but passing a mutable reference since there's no concern with aliasing. Boxing is probably the more flexible solution, but it's also possible to provide both and let the user decide.
If you want a classic incrementing for loop, it's much simpler than that :) https://play.rust-lang.org/?gist=3675f8d1702a88d89c7a05bd0f5463d4&amp;version=stable&amp;backtrace=0
Well, the direct translation would be something like: fn main() { let mut number_list = vec![2u32; 5]; for iter in 0..number_list.len() { number_list[iter] = modulo_three((iter as u32) + number_list[iter]); print!("{:?}", number_list[iter]); } } But a more idiomatic version would be to use an iterator: fn main() { let mut number_list = vec![2u32; 5]; for (i, e) in number_list.iter_mut().enumerate() { *e = modulo_three((i as u32) + *e); print!("{:?}", *e); } } Or to use a functional map: fn main() { let number_list: Vec&lt;_&gt; = vec![2u32; 5] .into_iter() .enumerate() .map(|(i, e)| modulo_three((i as u32) + e)) .collect(); println!("{:?}", number_list); } To address some of your points: &gt; usize is different on different systems (in my case it is 64 bits which could overflow iter) This was already a problem with the C++ code. Porting to Rust doesn't change anything here: you have to deal with this yourself, somehow. &gt; I'm manually checking bounds which can easily lead to a panic at runtime *You're* not bounds-checking, the compiler is. If *you're* doing it, you can do something other than panic. That said, it's not really a concern in this case, since the loop is so short. If it is a concern, use one of the iterator forms. &gt; [...] let alone figure out the syntax to call a function rather than a closure. They use the exact same syntax, so I'm not sure what you're stuck on. Besides, what you're doing is *not* just passing the data to the function, so you wouldn't be able to use it directly anyway. **Edit**: I should also note that you'll get better answers if you're specific about what you don't understand; when you say something like "I wasn't able to figure out the syntax of those in this scenario", I don't know if that's because you don't understand method syntax, or you don't understand how to write a closure, or you don't understand how to read the docs, or don't understand how to *get* to that method from a `Vec`, *etc.* The answer above is mostly a shot in the dark that'll hopefully hit something.
This is exactly what I was looking for! Thank you so much! It's all so simple looking at this now. Never really thought about applying the mapping in the next function before. Thank you again.
It grows in proportion to the number of arcs, not the number of nodes.
Getting accolades from the noobs and conspiracy theorists at /r/crypto is very far from a seal of approval. In any case, [the whole concept is strictly worse than an encrypted password manager](https://www.reddit.com/r/programming/comments/60u4vw/lastpass_has_serious_vulnerabilities_remove_your/df9vnhw/).
**Here's a sneak peek of [/r/crypto](https://np.reddit.com/r/crypto) using the [top posts](https://np.reddit.com/r/crypto/top/?sort=top&amp;t=year) of the year!** \#1: [Wikileaks latest insurance files don't match hashes](https://np.reddit.com/r/crypto/comments/5cz1fz/wikileaks_latest_insurance_files_dont_match_hashes/) \#2: [DoJ Rule 41 passively changes this Thursday, Dec 1st; Using tools like VPN or anonymizers like Tor could land you on a watch list for exploratory scanning by FBI](https://np.reddit.com/r/crypto/comments/5figex/doj_rule_41_passively_changes_this_thursday_dec/) \#3: [Announcing the first SHA1 collision](https://security.googleblog.com/2017/02/announcing-first-sha1-collision.html) | [57 comments](https://np.reddit.com/r/crypto/comments/5vqe47/announcing_the_first_sha1_collision/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/5lveo6/blacklist/)
Are you looking for https://doc.rust-lang.org/std/io/trait.BufRead.html#method.lines maybe?
Hi there! I'm designing (and drafting) the next major version of Notify, the file notification crate. High-level goals are: - to make the code easier to hack on, with better-defined interfaces and lot more separation of concerns; - to provide the architectural basis for advanced backend patterns e.g. + runtime switching, + using several at the same time, + using a different one for high-latency filesystems, + using external backends running as daemons or services; - to remove as much boilerplate as possible and improve the developer experience around implementing backends; - to be much more testable. What I'm looking for by posting here: for some people to read through (feel free to just go and fly through it without much care!) and tell me [if they see something horribly wrong with it](http://jvns.ca/blog/2016/06/03/learning-to-like-design-documents/). I've pasted the issue in a word count thingie, and it told me it had a **10-15 minute reading time**. So if you can read it all, then yay! And if you can't, but just read the first section / bullet-point summary, yay! And otherwise, well, don't worry about it :) Thanks!
For spurious network error, check your firewall from antivirus software. Mine was V3 Internet Security(my company machines should install it) and disabling its firewall solved the error.
I have VS installed but I prefer to use emacs + racer + github for windows. I use `M-x eshell` as my command line. As far as command line environments go, it's pretty flawed but I like it. I use the Git Bash console when I need something a bit more traditional.
You have a reference to A that lives inside a B. (The reference itself is a member of B.) You need to tell the compiler that A lives long enough for that reference to remain valid for the entire lifetime of B. The "lifetime parameter" is the way to do that. You're passing the lifetime of A and telling the compiler to verify that A outlives B. 
Right. What I mean by "devirtualization" is in the "Runtime dynamic dispatch" case, sometimes the compiler *can* statically prove that the trait object points to a specific type, in which case it can skip the vtable and call the function directly.
It exists :) (well, Rust to C11 currently) https://github.com/thepowersgang/mrustc
Great! Thank you!
&gt; here have been numerous attempts over the years to fix this, osgi is probably the best example, but was never fully adopted because of the complexity it added. Semi-OT, but it's also worth noting that JDK 9 will add proper modularity at compile time and runtime, i.e. there will be no more classpath leaks, no sneaking around package boundaries via reflection, etc.
&gt; Run your application &gt; &gt; Attach the VS debugger using the ‘Attach…’ feature. You should be able to find your application in the list. Once you attach, you can hit pause, set breakpoints, and step as normal. You can also open your executable in VS and start it from there.
I heard snake_case too!
Except that you don't need microservices to scale out either - you can do [cookie cutter scaling](http://paulhammant.com/2011/11/29/cookie-cutter-scaling/). The one good reason i can think of to use microservices is fault isolation, including isolation of performance pollution. If you want some crucial service to keep on trucking when some other service is crashing and/or gobbling all available memory and CPU, the only way to do that is by putting them in separate services. Well, unless you're using Erlang or something! 
I know your example isn't trying to be industrial-strength, but I just wanted to make sure everyone's aware that: 1. It's possible to exactly mimic the given Ruby API in Rust by using a trait to define a new method on the built-in slice type. 2. There's a standard iterator method, `position`, that basically already does what your `find_index` method does. :) Here's what the code would look like taking both of the above into account: ["Adam", "Josh", "Jackson"].find_index("Jackson"); // Some(2) ["Adam", "Josh", "Jackson"].find_index("Mat"); // None trait FindIndex { fn find_index(&amp;self, element: &amp;str) -&gt; Option&lt;usize&gt;; } impl&lt;'a&gt; FindIndex for [&amp;'a str] { fn find_index(&amp;self, element: &amp;str) -&gt; Option&lt;usize&gt; { self.iter().position(|&amp;name| name == element) } }
Hmm, why isn't Visual Studio 2017 supported by Visual Rust? I can't even find the installation download for VS 2015.
Neat! Any chance you could generate files for the Rustonomicon?
I was hoping for [effect systems](https://github.com/yallop/effects-bibliography)! :D
&gt; I'm really happy that support for x86-interruptmade it into both LLVM and rustc Yeah, me too :). &gt; I may be misremembering, but this post seems more thorough than some of the earlier ones, since you go into the details of how the stack is laid out with (quite nice) diagrams even though the compiler abstracts away most of the details. I like it! Thanks! The stack layout diagrams are from the previous [“Returning from Exceptions”](http://os.phil-opp.com/returning-from-exceptions.html#returning-from-exceptions) post, so they're not new. But I'm quite happy with the structure of the new post, since the implementation details are more separated from the architecture information.
how does javascript compare to java? or grape to grapefruit? VSCode is a cross platform (linux/mac/windows) packaged web editor based on electron shell(atom's chromium wrapper) and microsoft's online editor. It's a text editor not an ide.
Yes, entirely optional and very much something in the future, but it's in the document because... it's something that I need to keep in mind. The daemon feature is meant to be an alternate way to use backends, not the primary one. Notify will stay, first and foremost, something you can use in a single (static or not) binary or another library or some other way of building applications (so long as you have an OS it can run on and a filesystem it can watch, obviously). It will always embed a set of backends, directly compiled in, and dependent on the compile target, as it is now. Edit: I've modified the section on the design doc to hopefully make it clearer.
You can't have the same project open in multiple windows as far as I know.
I care about the exact memory. If a `T` equal to `value` is already in`set`, I want a borrow of the pre-existing `T`. Only if it's not in the `set` do I move the given `value` into the `set` and take a borrow of it where it sits in the `set`. (If I always borrow the same exact memory then I can do cheap "pointer" equality checks later. )
This is very cool. What do you think the pros/cons of this approach would be? In particular, I'm worried that the extra lifetime parameter might hamper the usability of the library API further downstream? For this use-case, I don't need to be allocation-free, I just need to be fast in the `ffi::poll` loop, which presumably would be the case for either the boxed setup or the pinned setup.
Yes, that is what the piece of code I posted does. It's not clearly defined in the documentation for insert what it does when the element already exists, but it becomes clear when looking at [HashSet::replace](https://doc.rust-lang.org/std/collections/struct.HashSet.html#method.replace), which would basically be the same thing otherwise (modulo return value). I've also verified with the source code though: `HashSet` is implemented in terms of a `HashMap` with `()` values, `HashSet::insert` calls `HashMap::insert` which says in its documentation that the key is not replaced. I guess this calls for a documentation PR; I should do that when I get back home :)
Doesn't let me have multiple files from a project open in multiple windows...
As a reference point: MRuby had a "bug bounty" release where a investing company paid bug bounty for problems in their project. 500.000$ value: http://mruby.sh/201703270126.html
I really don't see an argument why C should be preferred over any other language.
If `a, b, c, d` are just floats, I believe you can get the same output with this: write!(f, "Matrix{:?}", match *self { Matrix(a, b, c, d) =&gt; (a, b, c, d) })
Yes exactly.
If it can compile, run and show command line output, then it's sufficient for me, bonus points for breakpoints.
&gt; let (a, b, c, d) = match *self { Matrix(a, b, c, d) =&gt; (a, b, c, d),}; You could also put `write!` directly after `=&gt;` or rewrite the `let` line as just: let Matrix(a, b, c, d) = *self; &gt; but the match would of course only return a single value argument, not the four that is needed. That's indeed the case. The macro expansion runs before the compiler knows what is the `Matrix` is at all and `write!` sees it's as just one argument. There's no syntax currently to do what you're trying to do, probably because the workaround is simple enough. The possible `*match` extension would have to be implemented as a `write!`-specific syntax or as totally new addition to the language. Remember that `*match...` is already valid Rust expression, so to keep backward compatibility probably some other syntax would have to be chosen.
Working on learning Rust and implementing audio LV2 plugins with it. One is a simple distortion with a feedback delay, the other is a 1:1 port of the ZynAddSubFX analog EQ to a Rust LV2. Currently both without GUI (this will be the next step). This is very slowly evolving, depending on the free time (and motivation to program outside of work). Link: [lv2plugins](https://github.com/oswald2/lv2plugins) 
https://www.grc.com/sqrl/sqrl.htm &lt; maybe time for you to write a rust client &amp; server so this can be used in rocket / etc? :)))))))))))))))))))))))))))))))
I'm using GDB from MSYS2: http://www.msys2.org/ You can install GDB in the MinGW64 shell via: pacman -S mingw-w64-x86_64-gdb In Visual Studio Code's `launch.json` then add: "windows": { "miDebuggerPath": "C:\\msys64\\mingw64\\bin\\gdb.exe" },
I doubt it would be easy, as I took quite a different approach than the mdbook's one (e.g. while crowbook uses pulldown-cmark too, it first convert its output to some kind of internal AST and than works on that, so there's no way to easily reuse code for mdbook). I tried making the code a bit more modular, moving some epub-related stuff to [a separate crate, epub-builder](https://crates.io/crates/epub-builder), so this could be used for EPUB rendering (I planned to try and see if I could write a EPUB renderer for mdbook but haven't got into it yet). 
Okay, I see what you mean by compositor support; it seems that a data source is only accessible while the application is running.
Yes, osgi solved this already, though the tooling sucked. I haven't played with Jdk9 yet, so we'll see if any of the same issues arise. It will be good for Java, but I wonder how many people will adopt it, and how long it will take for existing projects to be upgraded. Anyway, Java is getting better... I'm still a bigger fan of Rust.
I love XML so much, soooo much. And because of my great love to XML I figured I want a better XML library for Rust and built one. Like all the other XML libraries it only implements a tiny subset of what is possible and it's my very own subset. In fact it can only read XML files for now and only completely into memory. However it does do a few things: * It has a somewhat reasonable concept for dealing with namespaces (uses servo's string interning crate internally) * It has a somewhat okay-ish API to access attributes and children * It supports namespaces. NAMESPACES!!!1 If you share my never-ending love to XML I would love your feedback.
Do I see correctly that this is yet another xml library in Rust that does not even support the following? :p &lt;foo&gt; some text here &lt;child/&gt; some more text here &lt;/foo&gt;
No, but you can split the window, to see several side by side. Nit quite the same, of course, but covers most of the use cases I have for multiple visible file buffers.
I think monads are the next logical place to go if and when HKT are ever a reality. But the IO monad as in Haskell doesn't make a great deal of sense in Rust because 1) Rust is not lazily evaluated and 2) the utility of the IO monad is greatly diminished if you can drop any side-effecting code anywhere outside of the monad.
Yea, the /reverse_dependencies has been there, but not too well known, for a while now. But at some point it got added to the "Links" section for a crate, under "Dependent Crates": http://imgur.com/a/w6JsT
They exist. And some of us have to write code that reads it. 
That looks very sweet! If we talk about typography, what could be slightly improved (easily and also directly visible) is using protrusion: making commas, dots, etc. be slightly outside the lines to the right. It makes the main "wall of text" look actually better aligned on the right side.
thanks I'll give it a try
who in their right mind loves or even likes xml?
You can also probably enable hyphenation in hyperlinks like [this]( http://tex.stackexchange.com/questions/3033/forcing-linebreaks-in-url). And add a couple of custom hyphenation rules for the words like JavaScript, etc. (probably with the simplest *\hyphenation{Ja-va-Script}*). Also, googling "latex protrusion" revealed [these](http://tex.stackexchange.com/questions/82001/microtype-settings-for-dummies) [pages](http://tex.stackexchange.com/questions/82001/microtype-settings-for-dummies).
Could cargo detect VS2017 now?
If you want a reasonable complete/sane XML/HTML lexer you could look into ripping the lexer from https://github.com/YorickPeterse/oga. Having said that, it currently uses Ragel and porting over this logic might be a tad tricky.
I just got the impression when I saw [this](https://github.com/mitsuhiko/elementtree-rust/blob/master/src/lib.rs#L255) that there is no such thing as a text-element, and that `Element` can't keep track of where its text content was in relation to its children.
Stockholm syndrome perhaps? 
The tail attribute is the text following an element. 
WHO DOESN'T?
don't forget the "i sure hope this is encoded in utf-8" and "is whitespace part of the content?"
I guess it's great that Rust cross-compiles easily to ARM and BSD then :)
A coworker started a company around a similar idea. Eventually he changed business models because adoption was too challenging.
Why does rustc expect `()` instead of a `numeric::Tensor` unless I use `return` here? I thought `return` could be left off if I just omit the semicolon on the value I want to return. fn getdata(filename: &amp;str) -&gt; Tensor&lt;i32&gt; { let fptr = FitsFile::open(filename).unwrap(); let hdu = fptr.hdu(0).unwrap(); let image = hdu.read_image().unwrap(); if let HduInfo::ImageInfo { shape } = hdu.info { let shapearr: Vec&lt;isize&gt; = shape.iter().map(|&amp;e| {e as isize}).collect(); return Tensor::new(image).reshape(shapearr.as_slice()); } panic!("File does not contain an image HDU"); }
I'll start reading through this edition tonight and get back to you - I'll say already that just looking at the section layout I like it more than the first :). Thanks for the tip! As a new guy that doesn't program much I honesty think the biggest part of my confusion for Enumerate was the [Enumerate API doc page](https://doc.rust-lang.org/std/iter/struct.Enumerate.html) being a bit dense *looking* and having no notes/examples of usage like some other pages. Looking back the next day with a clearer mind and reading through the type returned and the traits it really wasn't a complicated page, I just needed to focus on following the types down the chain.
Probably doing that indeed. I'll let you know! In the meantime, I'm in #sway and #orbment on freenode, and ofcourse on the regular Mozilla channels.
It does, but why isn't that equivalent to just putting a panic after the `if` ends?
It's the ElementTree API so it supports this, but as it was mainly designed for non-mixed content (for which it is *really* convenient) the handling is a bit interesting: if the first child of a node is text it's set as the parent's `.text`, other text nodes are set as the `.tail` of their preceding (non-text) sibling. So given your document you'd have: Element { tag: "foo", text: "some text here" children: [ Element { tag: "child", tail: "some more text here" } ] } 
Also for UI descriptions, XML documents are pretty easy to manipulate specifically or generically, which means easy transformation pipelines which are pretty resilient.
As a general rule, the last statement in a block is the value of that block; but not necessarily the return value of that function. The return value of that function is the last statement of the function, which is here is a panic 
The only way I can see it happening on a meaningful scale is holding software companies accountable (e.g. fines) for exploits to software, which I don't see happening anytime soon.
To me "meme" means a self-contained idea that spreads virally through the medium of human minds, however they might be connected. (Rather than an animated GIF, or whatever, which seems the definition used here.)
How'd you link the Rust src to the debugger, if you did that at all? I'm getting 'can't find heap.rs' errors
What do you mean by SDL? Surely not Simple DirectMedia Layer.
&gt; Clippy works fine for me on Windows using rustup nightly (MSVC-based) and installing it from git rather than crates.io. Interesting, I have always been trying to install it via cargo install. &gt; Also, setting up Rust debugging in VSCode is pretty trivial; took me maybe a minute to get working. I tried it the other day and it was easy to setup, but breakpoints didn't work. Shrug. I need to get back to it and play more but setting up a Rust debugger hasn't been a high priority for me at all.
Governments will get involved the moment human life will get in danger.
I think security guys tend over overestimate what software needs to be secure. Very little software needs to be hardened, those on the border, but most sit inside a trusted environment that if logged and continuously monitor. I work in finance and few of our systems worry about complete hardening. 
Indeed. This definition is supported by the fact that people seem to understand my comment without it actually containing an image. And the "image macro 'meme'" is itself a meme.
What? Next you're going to tell me you don't like SOAP web services Go eat a bag of WSDLs
Security guys overestimate, most of the rest underestimate. 
Next, can you work on a SOAP server in Rust? We DESPERATELY need one. 
Memes is as memes does
except that you can't really express anything in DTDs and need to use XSDs, which are shit too, because they are overly complicated, so no one does either. ASN.1 on the other hand...
&gt;I do not see why that is necessary at all. Then I'm waiting to see your implementation of a modifying DOM because I'm very interested in it. &gt;Not really worth it. That's fine. Then I will continue to writing my library, which does this.
&gt; We say 'well developers need better tools', but developers disagree! They don't want better tools. They don't see any need. They don't think it's even an issue to start with. I think the majority of your post talks about attempting to replace C with Rust on the basis of memory safety. Maybe it happens, maybe not. But the part of your post I've quoted can be seen from another perspective - from the point of view of the vast majority of developers in the world, memory safety *isn't* a problem (or, more accurately, it isn't *their* problem) because they use safe languages (e.g. Python). But wait, Python itself is written in C! C is part of the bedrock, typically as low level as people go without extreme productivity penalties. Some people will never want to convert from C to Rust and that's up to them, but if Rust can replace C in parts of the bedrock, all of the developers writing Python etc who think memory safety isn't a problem can continue thinking that. This is precisely the point of Mozilla doing [Oxidation](https://wiki.mozilla.org/Oxidation) - full rewrites very rarely get buy in (Go a little bit hobbled by this and overcomes it in niches it's particularly strong in), incremental improvement is much easier to get buy-in for (and easier to do! I incrementally ported half of a binary from C to Rust, added a few features and left it like that because it worked fine). If we see a single shared library or binary written in Rust and installed by default in the next Ubuntu lts, I'd call that a success. (bit of a tangent, sorry)
&gt; Because you've just lost every IOT device out there, basically, as they're almost all made out of country. Good because it is all shit.
Software Development Lifecycle most likely.
&gt; So step 1, getting developers to admit there's a problem, I don't see this ever happening. I hate to be pessimistic, but nothing is new. Nothing has changed, not because of rust or anything else. Same problems, only more public, and we still see the same resistance. I'm an optimist. Naturally, I think this is achievable. I think the way to achieve it is to use Rust in widely deployed production environments with enough diversity to be immune from criticisms like "the author is a good programmer, so of course it will have fewer bugs." It needs to be enough to rival counterparts written in less safe languages. And then we need to collect data that *demonstrates* the improvement. For example, by counting CVEs. What we have right now are solid ideas and a smattering of examples. We need more. A lot more. But it's possible. We can't tell people they're wrong, we need to *show* them. :-)
The bottom line is that we need to collect data. Data collection is hard, but it is much easier than just convincing everyone they're wrong "because memory unsafety is bad, trust us." :-)
&gt; However, programmers utilizing state-of-the-art C tooling and best practices still constantly produce programs riddled with severe memory safety vulnerabilities. For all these tactics they are losing the memory safety war, because even with great tactics you can’t win a war with a bad strategy. This is a really great quote!
Ah that's right. It's certainly been long enough for me to forget the actual details, XSD is what I meant
I guess, it really does come down to disposition. But if you can convince some, it's worth it. And if convincing them means writing awesome rust projects and getting them adopted, seems like a win win to me.
Coming from Turbo Pascal and favouring C++ over C when I had the option to choose, I always approached C code with some kind of best practices from those languages. Which help to avoid minimizing the usual set of C errors. - Back in those days static analysers were too expensive, so as poor man's replacement, turn on all warnings and treat them as errors; - No #ifdef spaghetti for platform code, each platform gets its own file; - Follow the ADT (Abstract Data Type) programming model and treat each translation unit pair (.c/.h) as a module; - Expose all those "module" types via incomplete structs with accessor functions. - Using const and enumerations instead of #defines - Always make use of the safer memory and string manipulation functions - Applying best practices from CERT and MISRA guides - Always checking for errno and friends - Use the compiler and OS debug functions for testing pointer integrity, for each parameter, in debug builds. Still I managed to make it wrong a few times.
Memes (both image macros and more generally, like commenting "This") are often low signal and can be more useful with only a few extra seconds of effort (e.g. instead of "This" to agree with a comment about some feature of, say, tokio, maybe just upvote, or add a bit more: "I've found the same, when using both tokio and also std."), which hopefully improves the signal-to-noise ratio of the discussion.
I really wanted to write a good example of using tokio and nom together, while still allowing an implementation using mio, and now it's there :) With an API completely based on futures, and independent from the underlying transport. 
I did not actually expose that through the API. It's effectively always an empty string. I mostly did it because of how thebdata comes from xml-rs and me needing a default before filling the tail in. 
The reason forming the object is disallowed is so that trait objects and generics are more interchangeable (if Trait is object safe, then it can always be passed to a `T: Trait + ?Sized`): http://huonw.github.io/blog/2015/01/object-safety/#motivation
You could roll your own with pretty much any other format, and there are even pseudo-standards in place for several data types (e.g. [json-schema](http://json-schema.org/)). Also, with Protobufs (and competitive formats), you generate the data types in your language of choice from a common spec, so it solves that problem even better. There is nothing about XML that it is better at for expressing data, and even the name itself shows that: Extensible Markup Language. It's built for markup, *not* data. So yeah, there are plenty of add-on things to make working with XML less bad, but that doesn't change the fact that it's bad, and worse than nearly any other data format.
That the therac is mentioned in all discussions about software safety really speaks against the need for more secure software. Because if the impact was significant we would have better and bigger examples that aren't 30 years old :-P
Seconded.
Is there a reason you chose xml-rs over quick-xml? https://github.com/tafia/quick-xml
Are you posting this from one of those hardened border systems, or is Reddit part of your inside trusted environment?
Dunno. Went with what I found. I tried xmltree first but that did notbwotk with namespaces really so I took that xml dependency as a start. 
&gt; I really wish universities would teach you to harden C/C++ code so you can appreciate the protections other languages give you. I agree. But to play devil's advocate, I see all too frequently that there's a certain cultural laziness in development. In a shop that uses Java, for example, the sloppiness isn't in handling pointers, it's in over-reliance on the safety of the VM - swallowing exceptions and allowing software to barrel along in an undefined state, bad thread safety, poor logic that works fine in limited testing environments but isn't robust enough to handle all the situations where it might be used, and then just waiting to see if anyone ever reports a bug with that lurking known situation. And so on. Another example; I wrote a quick-and-dirty prototype/proof-of-concept Python module for a colleague to finish up while I went on vacation, even indicated in a comment where there's a TOCTOU in my code that needs to get fixed, provided hints on how to do that. I come back, find the code is about to get shipped, and they just ignored the possible TOCTOU. Security really is a mindset.
Not currently, but there are plans in the works to allow overriding the allocator on a per-container basis. Is there a particular reason you're trying to avoid heap allocation?
Thanks! :) that's one of my favorite tricks, and is why I love shadowing. Frankly, walkdir is the harder part, so being able to just use that is the key to this crate being simple. It's also why I like smaller crates; it's easy to understand them in isolation, and then you glue 'em together.
Not really. Just curiosity
Yes, to an extent. If you, for whatever reason, wanted to re-use an old `Rc`'s heap allocation you could do so with the unstable [`into_raw`](https://doc.rust-lang.org/std/rc/struct.Rc.html#method.into_raw) and [`from_raw`](https://doc.rust-lang.org/std/rc/struct.Rc.html#method.from_raw) functions - however, you can't allocate arbitrary memory when doing that and have to use memory allocated by another `Rc`. Still, that's probably not the best solution. If you wanted to do that you could accomplish the same thing by just re-using an old `Rc` without bringing it in and out of raw pointer form. If you're asking about doing `Rc`-like stuff entirely the stack, it would be easier and faster to just pass around immutable references, using [cells](https://doc.rust-lang.org/std/cell/) if you need the shared value to be mutable. In fact, the concept of `Rc` doesn't really make sense as a stack-allocated object, given that stack objects are de-allocated at specific points in the code whenever they fall out of scope, instead of based on the number of references to the variable (as `Rc` does).
Rust's type system goes well beyond just memory safety though. You can use it to catch a lot of logic errors too. (Though of course not *all* of them.)
That is a much more relevant example than the therac and the soviet nuclear alarm.
It's the great debate. What's good enough? Edit: Although, I'm a fan of eliminating categories of issues in a systematic way. For example, memory safety with Rust. ;)
Really? You're pointing out one application that we can all agree has a high bar for security because it interacts with the outside heavily. That didn't mean any of my internal apps such as guis interacting with trusted programs need them. That's a terrible argument. Where is your line for what needs to be hardened? I'm just saying it is highly variable (in a cost benefit sort of way) and security people tend to error way too far in the secured direction.
No, it's not a syscall. The underlying library is proprietary, and it's checking to see if a hardware device has updated some memory via DMA yet.
What it comes down to is that, unlike product-facing efforts, security hardening efforts are not easily measurable. So while teams arguably do care about both features *and* security at a fundamental level, features are the only thing they can *measure*, so the developer incentive to consider security is missing. When considering security means taking time away from the activity by which your performance is measured (feature output), only the most principled of developers are going to do it. It's the same reason we've fucked over the planet with global warming: everyone knows they're a part of it, but there are no individual repercussions so no one has changed their behaviour. IMO greater consideration of security amongst developers starts with having it directly affect their paycheques, but that's hard to do without creating perverse incentives.
&gt; Have you thought about making something that is like ElementTree but fixes little quirks like this? This quirk is literally the feature. The only alternative is what the DOM does which is to introduce a "text node" which comes which then causes all kinds of different issues for instance you can have multiple text nodes in there etc. The elementtree system is so neat as a result of just not supporting comments and having a tail attribute.
 trait Item { fn process(&amp;mut self); } struct Backlog { items: Vec&lt;Box&lt;Item&gt;&gt;, } impl Backlog { fn add(&amp;mut self, item: Box&lt;Item&gt;) { self.items.append(item); } } 
How about minesweeper? https://github.com/Vinatorul/minesweeper-rs
when is the deadline if one is interested in applying for this summer? I am afraid I am too late and perhaps they have already done their hiring process
We're also vulnerable to sleeper Soviet spies who have been in hiding since the Cold War.
It's possible to have a `text()` convenience method that can do something like return the text if it's the only child, or return the first text node, or the like, and also have an `elements()` convenience method that iterates over only the actual element children, while still preserving the full DOM for people who are interested in that. But it sounds like for your use case, that's just not what you're interested in. And that's fair. In fact, for most of the things I've ever manipulated XML from code for (which is, like you, editing small configuration files for the most part), the ElementTree API is perfectly sufficient.
what kind of tracing are you looking for? Both crates here use log, and if you enable the trace level, you'll see a lot of things, like the network frames going from sockets to parsing to the state machine and then the future polling the state machine for a result.
You should look at the `--explain` for that error code, it's extensive and explains exactly why the different classes of that error exist, and how to address each case. https://doc.rust-lang.org/nightly/error-index.html#E0038
&gt;where there's a TOCTOU in my code A what?
Time-of-check-to-time-of-use vulnerability.
I think they mean "make illegal states unrepresentable" like you get with enums, which just requires thoughtful domain modeling, not complex checking. 
Is there any thought to a CLI, or is that outside the scope of the project?
&gt; I love XML so much, soooo much. Love?! XML ought to be something you reluctantly put up with.
There is benefit in convincing *some people* to use safe languages over C, even though we'll never convince *anyone*. This comment takes a pessimistic tone, but it seems like its setting the bar for success unreasonably high.
First, when you install the IntelliJ-Rust plugin to IntelliJ, everything "just works" and can be figured out without reading any documentation, except for figuring out how to build from within the IDE. Getting VSCode + RLS working requires more work. VS Code also feels sluggish compared to both Visual Studio and IntelliJ. Also, I have a lot of experience with IntelliJ. There are many things about its ergonomics that “just work right” like no other IDE. Even though Rust support is new, a lot of it “just works right” already. BTW, IntelliJ-Rust uses IntelliJ's language analysis framework instead of using the Rust Language Server. I didn't know that until just now, but I could see why people might not want to promote IntelliJ-Rust for that reason. As a language tool developer I think there are significant pros and cons to both approaches. As an end-user I don't care whether a tool uses RLS or not as long as it works well.
In my tests with quick-xml it beats out libxml2 in parsing speed and it supports namespaces. For small files it probably wont matter much.
There's many many projects using XSD and Relax NG. Notable ones are MathML (XSD) and ODF (Relax NG).
It's not just getting developers to admit there's a problem. You also have to get their bosses to admit that there's a problem, and that it's worth fixing. The software I work on has numerous massive vulnerabilities. Every time I've mentioned that to my boss, the CEO, he basically says it's not as important as new features or fixing other bugs that are impacting customers. So we have these huge issues built in. They're bad enough that our customer support department actually relies on a local root escalation vulnerability to be able to easily send scripts to customers that do things as root without requiring authentication. So, we dutifully upgrade third party packages every time someone runs a security scanner against our system and complains about us running a vulnerable version of MySQL. But in the meantime, we have things like several different local root vulnerabilities that we rely on for our software to function (while writing this comment, I remembered a second privilege escalation issue that most of our software relies on), the same default password on probably 80% of our customers systems, and we use the same keys and certificates on every system we ship because dealing with getting customers to generate keys and distribute certificates between all of their servers and all of their clients would be a pain, and we can't rely on customers already having a PKI set up and in place. And I'm sure that's only scratching the surface of our vulnerabilities; there are a number more that I know of, and probably many more that I don't in our software, and then probably a bunch still in all of the base system software that we ship. The idea of actually getting the system secured is overwhelming, and there's little business justification in doing much more than occasionally updating packages to comply with some scanner someone ran looking for vulnerabilities, so it just continues to have some pretty egregious vulnerabilities and I just 🙈🙉🙊.
Performance tracking akin to tsung. One of the biggest issues with implementing protocols was always that most libraries in erlang expect a specific IO primitive and thus tsung mostly ships with its own implementations of protocols to implement things like performance tracking.
I mostly write servers, so print statements tend to be more useful than breakpoints, but to each their own.
You'd be surprised. If it gets you local shell access to the system, even as a regular user you can still do a lot of stuff. And once you have any kind of shell access you can then try kernel exploits for privilege escalation. Rely any program taking input should be hardened. So that's basically all of them. I mean containers and vms and jails could wall off hackers from the real machine who managed to get some kind of access. But what about memory constrained or embedded devices? Or car ecus? They can't run that stuff. Then a local exploit is effectively a root exploit. Networked thermostats that become rooted now become botnets...
XML can easily represent keys, values, and types, JSON can only represent one of key-value, type-value, or key-{"type": type, "value": value}. Unless you want to get really ugly, and use "type:key"-value. For example, I would rather write `&lt;window title="foo" width="42" height="99"&gt;contents&lt;/window&gt;` than `[{"type": "window", "title": "foo", "width": "42", "height": "99", "contents": [contents]}]`. Or `[{"window":{...}}]`, adding senseless layers of objects to work around the format's limitations. But at least that way ensures that the type is read before having to deal with an arbitrarily large contents block. Actually, now that I think about it long enough to write this post, I simply hate both. Especially when the wrong one is used for a given context.
I'm surprised that https://github.com/steveklabnik/dir-diff/blob/master/src/lib.rs#L66 is a `?` rather than an `unwrap`/`expect`: it seems like, if removing the prefix fails, there's something more fundamental that's gone wrong? That is, an entry from a listing of a directory should, presumably, always have that directory as a prefix. I suppose there could be something weird with hardlinks, but, in that case, propagating a raw `StripPrefixError` seems like it's rather user unfriendly, given that error type doesn't contain any specifics about what went wrong. Somewhat similarly, the comment and `?` on the next line of https://github.com/steveklabnik/dir-diff/blob/master/src/lib.rs#L81-L82 seem to contradict each other. I suspect the comment is misleading: the file could be concurrently (re)moved, between the directory listing and the reading.
Well, your example is using XML for markup, so that's a completely valid use case and is precisely what XML was designed for. When you start using XML for *data* is where the problems start. How would you encode your example in a struct? You can't serialize directly between structs and XML without losing features and without losing ergonomics. For serialization/deserialization, nearly any data format (JSON, Bincode, Protobufs, etc) is better than XML, yet XML is still widely used for data transfer for some reason.
DI tends to involve classes that accept objects of certain interface in the constructor like this (C#): public class PurchaseService: IPurchaseService { public PurchaseService(IDbService db, ILoggingService log) { this.db = db; this.log = log; } public Result MakePurchase(User user, Item item) { log.Log(Info, $"New purchase {item}"); var result = db.Table("Purchases") .AddRow() .Field("User", user.Id) .Field("Item", item.Id) .Save(); if (result.Failed) log.Log(Error, $"Error saving purchase {result}"); return result; } } Where IDbService and ILoggingServer are interfaces. The implementing class which is determined by configuration at run time. The frameworks for this handle nearly most of it automatically. To add a dependency you can just add it to your constructor. To add a new interface, just create a new interface following certain rules. (Inherits from some base dependency or has a certain name in a certain namespace). And too add a new implementation: just implement the interface (and possibly follow certain rules, like naming conventions) and that implementation can just be used. Best I can think of for rust is this: #[derive(DI)] struct PurchaseService { log: DIBox&lt;ILoggingService&gt;, db: DIBox&lt;IDbService&gt;, } With DI being: trait DI { fn new(di: &amp;DIResolver) -&gt; Result&lt;Self, DIError&gt;; } Not sure how to deal with Non-DI fields. 
Hmm. `Thing::new(main, fields) -&gt; Thing; Thing::inject(injection) -&gt; ThingDI` ? We define Thing, the DI macro expands it?
As I said in the other thread... We're talking about software patterns here. Of course nothing is exclusive to any one pattern. Many of them share a lot of overlap in capabilities and drawbacks, creating more of a spectrum than distinct points. However, we can talk about why people move to microservices. And the main impetus seems to be automated scalability and high availability. Which I don't think is incongruous with fault isolation.
That actually turns out to be one of the not-nice things about XML. Having a standard schema format for validating documents in a fairly general purpose format against a schema and possibly extra constraints is nice. Being able to specify that schema from within the document, especially in ways that can affect how it is interpreted, is not nice. If you are receiving a document, you should know what schemas you support. Having a URL to a schema embedded in the document, which causes all kinds of mistakes like trying to fetch that URL every time you parse a document from millions of embedded routers all over the world which will never be updated to fix that behaviors, does not help. Nor does having the schema embedded directly in the document help. If the schema turns out to be different than what you are expecting to read, what do you do? You can't do anything useful with that. But the person providing the document can cause mischief, like XML bombs. External schemas can be useful; Relax NG is probably the best one out there for XML, and it even has a non-XML syntax so it's not nearly so painful to write. But you can define schema languages for pretty much any flexible format like JSON or TOML. Relax NG being a decent schema language has nothing to do with XML, and everything to do with being something like the 4th generation of trying to solve the problem and finally getting something vaguely usable (SGML DTD, XML DTD, and XSD being earlier attempts, with probably many more that died by the wayside).
Why do you convert len() to u32? It's only makes code more complex. Or am I missing something?
You could go either way, OP had mentioned usize overflowing a u32, so you have to handle that somewhere in there
Not necessarily on the stack, just not **dynamically** allocated.
and also xml5ever https://crates.io/crates/xml5ever
Maybe: #[derive(DI)] struct PurchaseServiceImpl { table_name: String, log: DiBox&lt;LoggingService&gt;, db: DiBox&lt;DbService&gt;, } and it could be configured: &lt;diconfig&gt; &lt;DbService&gt; &lt;PostGresDbService conn="..." /&gt; &lt;/DbService&gt; &lt;PurchaseService&gt; &lt;PurchaseServiceImpl table_name="Purchase" /&gt; &lt;PurchaseService&gt; &lt;LoggingService&gt; &lt;JournalDLoggingService /&gt; &lt;/LoggingService&gt; &lt;diconfig&gt; Although Toml might be more Rusty Edit: and `String` would implement `From&lt;DiConfig&gt;` or something. 
Do you know why the decision was to require that the bound on object safe methods be opt-in with `where Self: Sized` as opposed to opt-out with `where Self: ?Sized`?
&gt; Different industries have different uses for software and obviously security necessity varies wildly between them. Pervasive wireless connections and cheap computing are blurring those lines, though clearly my fridge would have a harder time killing a bunch of people than my car.
Bring it up to your legal department and have your legal department explain the massive liability that will happen if somebody sues them over the known exploits?
Yeah. I admit I don't have a specific use case in mind, but where I work we do mostly embedded development (C++), and in some areas any dynamic allocation is frowned upon, so if we have a large object it usually is static so it won't blow up the stack.
https://github.com/dnaq/sodiumoxide 
I took a class on security and it focused on encryption and a little on exploits, but the biggest vulnerability in most code is poorly written code. Writing safe code is more important than using the right encryption IMO since encryption *will* be broken and code needs to be prepared for that.
The downside is that the behavior could be confusing. For example, people might create a Clone object, expecting to be able to call clone() on it. It would be weird if trait objects had different functionality from objects implementing the trait, with no warning.
&gt; it sounds like there isn't really a reason to ever write a function which takes a trait object? Apart from heterogenous collections as already mentioned, another big reason is to reduce code size and compilation times. Also, reducing code size can speed up the code due to fewer icache misses. Monomorphization isn't free, and so there are many cases where it makes more sense to use runtime dispatch. 
I would prefer an effect system tbh - but it would be tricky to get it to be zero-cost :/
There is almost zero chance of that actually happening though.
This got me excited to try AMQP again, and use Rust futures for the first time, but sadly for me the "the library is very early" disclaimer held true. :/ I was trying to use a hosted CloudAMQP instance, but it seems that a library using that needs to be able to deal with a `vhost`. Either way, I'm excited for the future of the crate!
The big problem is that people are *invested* in their C codebases. To them, talking memory safety sounds like preachings from the cult of Rust. I see this even in instances where Rust isn't mentioned, and the post that motivated OP throbs of cognitive dissonance regarding memory safety. Then there are some on the fringes of our community (or just a bit outside, it's hard to tell) who will suggest a Rust rewrite of just about everything to just about everyone. They are making matters worse. So while I agree with the premise of OP, I fear it will not fall on fertile ground. If we want to position Rust as a C alternative, we need to get our integration with OSs and distributions straight and allow for low-friction deployment on mobile &amp; embedded. Yes, that's a tall order. But I'm hopeful we can pull it off. 
please open an issue for this. It's very young on the number of features implemented, but the design makes it easy to add new things now :)
I think the grandparents point is that, theoretically, always passing the same trait object type as a type parameter for a generic function is the same as hard-coding the function to use that trait object type. Thus, using generics is no less expressive, but also gives the flexibility of letting callers opt-in to static dispatch if they want it. In practice, though, it differs slightly (e.g. a new copy of such a function in a library will be monomorphised into every downstream library that uses it), and using a generic seems somewhat likely to lead to mistakes/accidentally passing something that isn't a trait object.
It's essentially just a little binary crate that lists all the authors of all the dependencies of the current crate, meaning the crate in the current working directory. Comments and criticism are always welcome!
Not related to ElementTree, but... Could someone care to explain what the use case is for namespaces in an XML document? Is it some kind of standard way to indicate the format of the document? You should know that beforehand, right? Since you are parsing the document and querying its elements anyway...
Quote of the week? /u/nasa42
You tried to be accurate but you missed the main point 😛, It should be: MIR-to-C**89**.
This issue is missing that `associated const`s are finally being stabilized (yay!), the FCP is here: https://github.com/rust-lang/rust/issues/29646 The biggest changes are that: - `for&lt;T: Trait&gt; [_; T::CONST]` is not supposed to work (which is kind of sad), - and that `associated const`s should not be object safe. 
Awesome! Just yesterday I was wondering whether there's an AMQP library for tokio and here you are! I hope I can give this a spin soon :)
If you are talking about "Updates from Rust Core" section, it's because we only list PRs that are _merged_ last week. If you are talking about "Final Comment Period" section, it's because this issue is not in FCP ([not all reviewers have reached consensus yet](https://github.com/rust-lang/rust/issues/29646#issuecomment-289397164)). Along with [rust-lang/rfcs FCP](https://github.com/rust-lang/rfcs/labels/final-comment-period), I can also keep an eye on [rust-lang/rust FCP](https://github.com/rust-lang/rust/labels/final-comment-period), but seems like most of these are _tracking-issues_ for RFCs that have already been through FCP process in rust-lang/rfcs repo (and so likely already listed in TWiR in past). 
Thanks. Fixed.
&gt; `for&lt;T: Trait&gt; [_; T::CONST]` is not supposed to work (which is kind of sad) It doesn't work *right now* and that's what's being proposed for stabilization, but it's not something we want to keep broken forever, it might just come a bit later.
The thread that the first reply is about: https://github.com/rust-lang/book/issues/328
&gt; IIUC whether something is in FCP or not is orthogonal to whether it is an RFC or not, right? /u/steveklabnik1 ? Technically, FCP is only for actual RFCs. But some teams have started to use fcpbot to achieve asynchronous consensus on bigger issues, and so they end up getting an FCP as well. That's why there ends up being two of them; especially when there's been changes from the implementation, giving it another one is a good idea. That said, it's also true that this isn't in FCP yet; all team members sign off, *then* FCP, then resolution.
Thanks. This will avoid dependency on libsodium.
&gt; Is there a simple way to get at least the core Rust documentation in roff? $ rustup add component rust-docs And you'll get all the HTML documentation offline. $ rustup doc --open 
That would probably work better if we had a legal department. Also, pretty much all software is sold as-is, with no warranty express or implied. I don't think I've ever heard of a software company being sued over vulnerabilities; have you?
Sorry, you're right. I said DOM when I meant [infoset](https://www.w3.org/TR/xml-infoset/). My mistake. ElementTree doesn't preserve processing items or comments, which are part of the infoset. Also, the way text nodes are attached to their sibling elements, rather than their parent, is somewhat unintuitive and doesn't match the definition of `children` in the XML infoset. You are right that it doesn't lose information about the text, but it makes it easy to miss text content if you forget to look at the `tail` of the children, or get confused about where in the tree that text content actually is. Anyhow, not really relevant for this crate. It would be nice to have an XML API that represented the full infoset but was more pleasant to work with than DOM. That doesn't seem to be the intent of this crate, which is fine. If I feel strongly enough about this, I should probably try writing my own.
Yeah, you're absolutely right.
Like /u/mitsuhiko says, primarily for combining stuff. Suppose I have a "nice" xml scheme named alphabet, with the elements "a", "b", "c", ..., "z". I now want to embed some of my beautiful alphabet xml inside an xhtml element. Now when you encounter &lt;a&gt;, is it the alphabet letter "a", or a html hyperlink? With namespaces I could say that my alphabet lives in namespace www.example.com/alphabet, and declare `xmlns:alpha="www.example.com/alphabet"`, and then I could use `&lt;a&gt;` is a hyperlink, and `&lt;alpha:a&gt;`as the letter "a". Of course an alphabet xml schema doesn't really make sense.
A quick reverse image search shows that it is Tina Fey, possibly acting on the american sitcom *30 Rock* as lead character Liz Lemon. I assume it was chosen because in that moment, Tina Fey's character is attempting to give a high five. In the same way, the Rust maintainers are attempting to give you a high five.
Thank you!
Thank you!
Yup, 100% correct.
Here's the animated gif version! https://media.tenor.co/images/7c0aca89e85e83db5d83b1003772544a/tenor.gif
I'm surprised there was confusion in the first place, as the original post describes precisely the issue: how to use modules in the concept of executable crates rather than library crates, and where the answer is to do the same thing.
I think the confusion was because we never said "modules are exclusive to library crates", and so we assumed people would not assume that it was. We added a sentence about it at least, so hopefully that will address it in the future.
Did _nobody_ read the post? It's _not_ talking about "migrating" codebases. It explicitly says otherwise, twice: https://www.reddit.com/r/rust/comments/62093b/its_time_for_a_memory_safety_intervention/dfk865q/ It's not saying "you should move everything off C NOW". It's fine with folks writing in C. It's not fine with folks trivializing memory safety issues. Yes, it is a response to a post saying that "curl will always be in C", but it's not refuting that part, it's only focused on one particular section.
[Evo još](https://www.reddit.com/r/rust/comments/625bp6/this_week_in_rust_175/dfk6kof/?utm_content=permalink&amp;utm_medium=front&amp;utm_source=reddit&amp;utm_name=rust) :)
One thing I've learned from hanging around on beginners/reddit/etc and helping folks is that most problems can be boiled down to "you're doing it wrong", or "you're thinking about it the wrong way". In other words, a bad mental model. Of course, telling them "you're doing it wrong" is not great either, usually it's not their fault. What I try to do is, after solving their issue, always find out what their mental model is and what's wrong with it (if it wasn't already clarified when figuring out their issue), and then try to find out how they came upon such a model. Often it's an unstated assumption whilst reading the docs. In this particular case, I don't think this approach would have helped much, the user was in "I am always right"-mode (which is the opposite of most folks in beginners) and would not have responded well to such querying, but it's a good general rule.
and why is Bors' profile a shiba inu for Servo? and also please never change it.
Agreed on all points, thank you.
I have not, usually companies cover that in user agreements.
I got the impression that this person had trouble with the idea of "idiomatic" in the first place. They don't seem to acknowledge that idiomatic is relative to language. Then "that's not idiomatic" is heard as "you've been doing it wrong" rather than "this is how we prefer to do/teach it here". That said, the person did give a clear usecase for not splitting things into crates that is best addressed by not splitting into crates but into files. They did so rudely and abrasively but that valid usecase was not really acknowledged...
To state the obvious: Krycho is the author of The New Rustacean podcast, which was responsible for fueling my desire to learn Rust. I made a small contribution to the Rust Reference once. Will love to work with him and the community on the new repo.
This seems really cool. I'm a big fan of faster sorts! :D If you are interested, you can possibly improve some of your benchmark numbers for radix sort. You have a `rdxsort` crate linked, but I see lower times for sorting 10m random `u64` elements using [timely dataflow's radix sort](https://github.com/frankmcsherry/timely-dataflow/tree/master/sort): test rsort_u64_10m ... bench: 316,999,376 ns/iter (+/- 30,655,719) = 252 MB/s test rsortmsb_u64_10m ... bench: 365,665,499 ns/iter (+/- 53,858,402) = 218 MB/s test rsortswc_u64_10m ... bench: 297,896,921 ns/iter (+/- 13,431,841) = 268 MB/s These numbers are for lsb radix sort, msb radix sort, and lsb radix sort with software write combining. When I git cloned the pdqsort repo and put a 10m benchmark in, using sort_bench!(sort_huge_random, gen_random, 10000000); I was getting test sort_huge_random ... bench: 802,846,737 ns/iter (+/- 10,588,945) = 99 MB/s This isn't meant to take anything away from your stuff (which I hope lands soon and I can start using for sorting standard `Ord` data), especially as the timely dataflow sort isn't a drop in sort replacement, but I thought it might be interesting to point it out! *Edit*: Reading your benchmarking stuffs, you are including the data generation in the benchmark, is surely part of why the 800ns number looks big. I tweaked that to pre-gen the data and just do a `.clone()` each benchmark iteration and got the following improved numbers: test sort_huge_random ... bench: 405,149,796 ns/iter (+/- 47,347,781) = 197 MB/s *Edit 2*: I'm totally going to steal your benchmarking macro. Why did I copy/paste so much? T.T
Comfort. They have a way of building things, and a pattern that they enjoy to follow. All of Rust's tools are opinionated in how they should work. For some people it's very hard to be guided in a different direction, and they will kick and scream, until they realize that it just makes everything easier.
What can I say: C++ didn't lead to me to expect such extensive explanations for the compiler errors :p (I am seriously impressed by the information for this particular error)
Hi /u/superskip98! You're probably looking for /r/playrust. /r/rust is for those wishing to discuss the [Rust programming language](https://www.rust-lang.org/).
Yeah but I think by the time the sentence was added, the conversation had turned into the argument about what is idiomatic. 
I don't want to be rude but what donaldcallen tried to achieve really seems to be http://xyproblem.info/ …
:D
I'm the one responsible for highfive's avatar, and I was crushed to discover that Github doesn't allow them to be animated. :(
Sure, yes, but safety is not the only axis when deciding a language. If there are other reasons that you can't use Rust or whatever, at least use C++ (or D) instead of C. That's all I'm saying. "More safer than" does not make it safe, but it does mean less chances of shooting yourself in the foot.
I do think that looking for stuff in posts like this is a good idea, kudos. &gt; This would be great to dig into. We've been working actively with packagers for almost a year to make rust easier to package. However, because Rust is written in Rust, you need to bootstrap a Rust for your platform first, and then go from there. For platforms that we don't have builds for, this is more annoying than "it just works." Also, given that you need Cargo to build Rust, you have to bootstrap that too. This is more work than just "./configure &amp;&amp; make" and so it can make packagers grumpy. Which is understandable, but also not really fixable; we're not going to re-implement rustc in C. &gt; This still confuses me. I've personally never run into a feature I needed that only exists on nightly. Is this just misinformation? There are some things that need nightly: os dev, embedded... it's true that more and more stuff is available on stable, but also don't underestimate how big a jump 1.15 was; many people have opinions that are slightly outdated, since they don't actively follow Rust. &gt; Is this even true? I haven't noticed forward compatibility issues, did I miss something? Two things: 1. It hasn't been two years since Rust 1.0. That's May. 2. We have fixed some soundness things that were technically backwards incompatible and required small updates to fix. That you didn't notice means the process is working.
Yeah, that is true. I'm guilty of recklessly overflowing signed integers. :) I've fixed the benchmarks. Changing the type to `unsigned long long` didn't change the total running time.
&gt; The New Rustacean [Link](http://www.newrustacean.com/)
&gt; &gt; You have to use nightly for that &gt; This still confuses me. I've personally never run into a feature I needed that only exists on nightly. As a beginner, I run into this quite a lot. For example, when I was learning Serde, at the time you needed nightly to use the procmacro derive, or you had to set up a build.rs step to do code generation that was enough of a pain for me to just avoid using Serde until procmacros landed in stable. Inclusive ranges are another one. I ran into that issue while trying to implement a fully correct fizzbuzz -- one of the very first bits of code I wrote in Rust. I ended up just writing my own inclusive range so I could compile in stable. (yuck.) (Edit to elaborate here:) This was particularly annoying because I've seen Rust talks where people just use the inclusive range syntax (`...`) without mentioning that it's only available in nightly. I couldn't figure out why it wasn't working in my compiler. Then there are numerous libraries that are being developed and touted by the community that only work with nightly. [Rocket], is a recent example of this. [Rocket]: https://crates.io/crates/rocket It really gives the impression that stable is not yet functional enough for real-world software.
&gt; Sure, but this is a one time cost per platform, as opposed to every package maintainer needing to do this for each package, right? Handholding one person through it, and then everyone benefitting seems pretty straightforward. Yes, but it can still be annoying especially if you are that person :)
&gt; zero-allocation My library ([sxd-document](https://crates.io/crates/sxd-document)) is out then. I use string interning. &gt; fast Reading, parsing, outputting (to `io:sink`) 111MiB of XML takes ~4.6 seconds. xmllint does the same in 3 seconds. I'm always chasing after that extra time :-( However, I think I'm still the only crate that [supports XPath](https://crates.io/crates/sxd-xpath) \^_\^. Both crates have also been used in a WebAssembly context, which amuses me to no end.
Especially if every single language starts doing it!
In terms of what could have been done better, don't engage all of the other peripheral concerns, just ask him for clarification. By the time carols10cents asked him to show what he had figured out, the thread had already devolved into emotions on both sides. 
Also, as nobody gives her a high-five, she proceeds to overenthusiastically high-five herself
Thanks. I kinda wished we could have turned it around; that's why I was asking for feedback elsewhere in the thread.
`rustup doc` (no --open) or `rustup doc --std` brings up the Rust docs. `cargo doc --open` opens the docs for a particular crate and its dependencies.
Looking at it from an outside perspective, it's pretty easy to read the first 4 points y'all make to him as telling him he's wrong / that stuff is already in the book / that's not idiomatic. If you weren't even sure what he was trying to say, clarify before explaining.
I wouldn't characterize our explanations as "emotions on both sides" though. EDIT: Just reread again, and in my first comment the first thing I said was "I'm not entirely sure what you're referring to".....
This is also a great illustration of why contributors are so important; this work matters, but I'm only one human, and it's an issue that is really important in the long term but not very important in the short term. I actually attempted to do this pre-1.0, but didn't have the time to do it right, and so abandoned the effort. With some others being able to focus on it, we'll get it done, and it will be way better than me rushing it.
There are a lot of conflicting versions and options—a known version that worked for someone is the easiest way I've found to install VS, but it's not a showstopper
Anybody have experience using cargo-watch on semi-large projects? Especially with the new cargo-check I'm curious how well it works on cutting down on cycle time. Though it raises the question: where does the output of cargo-check go (at least with cargo-build it would produce artifacts that wouldn't need to be recompiled, so I guess I'm also asking if cargo-check reuses unchanged artifacts). Also, a questionable line from the readme: &gt; Cargo watch pairs well with dybuk, the compiler output prettifier: I wonder if that's still a good suggestion given the compiler error message overhaul that happened last year (which, like dybuk, was inspired by Elm), and indeed dybuk looks as though it hasn't been updated in almost a year.
Also, he seems to me to have thought that if you can divide a project into different files, they have to be different compilation units, and thus create different object files to be linked later. I think it is possible that it also somehow puzzled him (at first I thought his issue was that he did not know how to force `cargo`/`rustc` to create several linkable `.o` files).
Nuh uh. The S in IOT doesn't stand for shit, it stands for security ;)
Sounds like you need to release a crappy C port of ripgrep then lol
Just pushed my [metronome](https://github.com/alamminsalo/rust-metronome) to github. Seeing what everyone else is doing... Well I guess that's something!
I know you're joking, but if you restrict the comparison to, say, a single file search without using memory maps, then ripgrep and GNU grep will very very similar executions. You'll need to be a little careful around literal optimizations ("ripgrep used SIMD on this search while GNU grep used Commentz-Walter"), but the underlying regex engine (both use a lazy DFA) and the buffer handling are quite similar.
&gt; but it's too much for me. Would you mind explaining what "too much" means? If you are saying that you want just the ability to parse XML, without constructing an XML DOM, I actually have a reasonably fast [pull-parser](https://github.com/shepmaster/sxd-document/blob/3a930a92d1fee77973c28dc6c6b006f95014ab0c/src/parser.rs#L577), which *is* zero-allocation (well, very limited. I track error positions in a `Vec` that gets reused). It just isn't public.
Could you just toss AFL at grep and rg and see what pops out? Like given similar features enabled, just fuzz them both.
I have never delt with roff but any markdown -&gt; roff thing should work
Yes. I need only a tokenizer. You parser is similar to mine ([link](https://github.com/RazrFalcon/libsvgparser/blob/master/src/svg.rs)). But you using `peresil` and I'm using [my own](https://github.com/RazrFalcon/libsvgparser/blob/master/src/stream.rs), private string parser. The idea is to extract it into a tiny xml library.
Yeah it's a great way to put it, I just found it amusing because I distinctly remember going "okay! This will work now! Wait, what, permission...denied? But I'm..... oh. duh."
I've seen this countless times. Beginner asks why his Code X doesn't work and produces a compile error. Another User responds with "Add this [useless line] and that fixes the compile error". And I'm like "What are you trying to accomplish? Maybe try Code Y?" And always they are like "Oh yeah, that works so much better"
Which standard library are you using in C++? libc++? Also, are you using `-Ofast -DNDEBUG` ? Does `opt-level=3` create native targets (equivalent to `-march=native` in C++)?
Thanks for the tip on dybuk. I'll review and remove if needed. I admit, that was a community suggestion to add the tip, and I've never actually used dybuk myself.
Some applications require a streaming-capable parser, so that is worth bearing in mind if someone intends to make a widely reusable XML parsing component. (So I guess that means Futures, because it may have to wait for more data to arrive over the network to parse the next token.)
A library that keeps parsing state and can be fed additional data and triggers SAX callbacks would fit with futures. Such a library would not need to depend on futures itself. Actually, futures might be a great fit with [XSLT 3.0](https://www.w3.org/TR/xslt-30/): &gt; The primary purpose of the changes in this version of the language is to enable transformations to be performed in streaming mode, where neither the source document nor the result document is ever held in memory in its entirety.
0..(x+1) is the same as 0...x, even if it isn't as elegant, though.
Oooh, posting memes on /r/rust. Such bravery.
For things that don't require that, its great. For those who do, its useless.
&gt; encryption _will_ be broken That's not the problem at all. The encryption itself (almost certainly) won't be broken. But it might be bypassed, thanks to unsafe code opening up vulnerabilities that allow that.
&gt; I'm only one human That's exactly what an army of inhuman robots would say
If you want a pull parser i am very interested if you find a faster one than quick-xml (I'm the author).
Hey, I was just wondering what the best way to convert an std::string::String or std::ffi::CString to a C-style byte pointer (*mut u8)? The closest I've tried some something like let mut my_string = String::from("Hello World!"); let bytes: *mut u8 = my_string.as_bytes().as_mut_ptr(); But I get a complaint by the compiler that I `cannot borrow [my_string.as_bytes()] as mutable`. If it helps, I'm working on a project that interfaces with a C library that sends strings as uint8_t pointers.
Over a year ago, pcwalton mentioned that they were [Vulkan-ready, but nobody had done the port yet](https://news.ycombinator.com/item?id=11175258#11177168).
What is the distinction? I always thought that the IO monad was pretty tightly coupled to the effects system.
[added to the trophy case](https://github.com/rust-fuzz/cargo-fuzz/commit/cf8cdd6af8f0ba34abfc56750b30dc01988139eb) Would love it if you would add further fuzz findings to the trophy case!
Pardon me for being a skeptic, but every time I read one of these, I wonder how we can truly claim that Rust is a "very safe language". How are panics any better than segfaults? (I do agree that they're *signficantly* easier to avoid than segfaults, of course; Rust is a great language)
I'm surprised libFuzzer doesn't have an option for trying to reduce fuzz findings.
Because with the conditions that cause segfaults, sometimes you just get silent memory corruption instead. A segfault is how the memory management gods show mercy. 
Hey everyone. Have a pretty easy question that's been nagging me lately I've been looking through some code, and I keep seeing things like &lt;'a&gt; I know that &lt;&gt; specifies a type to be used with an object, and I *think* &lt;T&gt; means a generic...but &lt;'a&gt;? what exactly does that mean?
[`CString::into_raw`](https://doc.rust-lang.org/std/ffi/struct.CString.html#method.into_raw) and [`String::into_raw`](https://doc.rust-lang.org/std/string/struct.String.html#method.into_bytes) followed by [`Vec::as_mut_ptr`](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.as_mut_ptr) perhaps?
That's the [syntax for lifetimes](https://doc.rust-lang.org/book/lifetimes.html#syntax).
Segfaults are just *one* possible consequence of undefined behavior. When your program has memory unsafety bugs, it will only segfault *if you're lucky*. If you're unlucky, it will corrupt your database, send confidential customer information to attackers, or maybe something even worse. Segfaults come from the actual hardware level (the CPU is what creates segfaults), and do not know the rules of the language. A segfault means that your program tried to do something which is literally not possible in the hardware. A segfault will *not* be raised if you try to do something which is obviously wrong/undefined, yet technically possible to do (like in Heartbleed). Panics are not undefined, they're very well-defined. Panics *only* happen when a program calls the `panic!()` routine, and they always occur at some specific clearly-defined place in the program (when the programmer explicitly tells the program to panic). Panics are predictable, in that they always behave the same way when they happen. They are an informative and safe way to end the program when there's an error that can't be recovered from.
It has `-minimize_crash` (see [options](http://llvm.org/docs/LibFuzzer.html#options)), but I'm not sure how to specify it with cargo-fuzz.
Was going to do that after /u/burntsushi had a chance to look at the pull request. Thanks for adding it :)!
The master branch of cargo fuzz lets you specify options. Need to release, but I want to get CI working first. And have no time to do that :|
oh, thanks!
The problem with memory safety issues is not that they abort the application via a segfault. That's the _least_ harm they can do, be happy whenever memory safety issues just trigger SIGSEGV. Sometimes a memory safety issue actually involves access to a page owned by your process, even if that memory has been `free()`. This can happen; the kernel doesn't have a fine-grained idea of what memory your program currently owns, just at the page level, and dealing with the fine-grained stuff is up to `malloc()`/`free()` implementations. This means you can leak the wrong data, or write data to the wrong place, which can often be weaponized via NOPsleds to get remote code execution. Even if not an RCE, it still basically can lead to a lot of control for an attacker over the memory of your application, leading to leaking or tweaking of memory. Besides this, the optimizer may do Unholy Things to your code since most of the ways to cause a segfault are undefined behavior, and these Unholy Things may also be exploitable. All of this is Very Bad Stuff. SIGSEGV, on the other hand, is the absolute best way that such a bug will be handled -- it crashes the application, so that there's no ability to weaponize this. When we say "Rust has no segfaults" we're really saying "Rust does not have the memory safety issues that sometimes cause segfaults". Segfaults themselves are great, the memory safety issues behind them are not -- but it's just more convenient to treat the two as the same thing because a segfault is usually indicative of something much much worse lurking backstage. So, a panic is not much better than a segfault, in isolation. But the reasons why an application panics are (generally) much more tame than the reasons why your application segfaulted. And those reasons are what we care about.
Panics cause the process to exit and thus can't be exploited
It comes up pretty often with u8s.
I'm not sure, but this might be useful to add to [stdx-dev](https://github.com/llogiq/stdx-dev).
Nobody said trying to package all useful software was an easy job.
I've found cargo watch check to be a great combo, though I'm not sure how big the gains are on a really big repo.
Reallocating doesn't necessarily mean going anywhere else in memory; the allocator can often simply extend the current allocation, which doesn't require moving any data.
Testing that it actually runs (https://github.com/rust-fuzz/cargo-fuzz/pull/79). https://github.com/rust-fuzz/cargo-fuzz/pull/92 is my attempt at fixing it up, let's see how it goes.
I meant the encryption implementation, which includes all user code to implement it. My point is​ that you can't just rely on encryption to keep your code safe, you also need to make sure that your code is safe to limit damage if your system is compromised. Encryption *does* get broken from time to time, and with quantum computers potentially around the corner, this will become an even larger concern, especially with legacy systems still using old encryption.
That is false. Those are just the famous incidents; un-memory-safe programming has caused too many security vulnerabilities to count...
Nah, you only need *one* person smart enough to be able to exploit a bug in your code. Security is hard; but using a language that makes it harder is not smart.
Displaying a QR code on the command line is really clever! I can actually think of a need for such a thing, as niche as it may seem. :)
I definitely got that strong "not looking at it objectively" feel from it with the most recent post being particularly egregious. &gt;and for that reason firefox will become less portable in the future... I &gt; fear bye bye firefox on PPC, Sparc... even on Linux and of course worse &gt; on BSD or older version of MacOS. I don't know about MIPS but it will be &gt; in the same park. &gt; &gt; You loose years of of work on GCC and clang platform support that give &gt; your application portability! The "didn't do the research" aspect aside, Rust already has better platform support than any single operating system or distro, with Alpha, HP-PA, and Itanium being the only ones I know that are supported by a mainstream distro (Gentoo) but not Rust yet.
It only provides you with the doctype event but doesn't parse its content
Yeah, but doesn't that mean that I'd still have to specify it as follows:? pub struct BlockContent&lt;N&gt; where N: BlkSizeConstraints, N::ArrayType: Copy { content: GenericArray&lt;u8, N&gt;, } 
The simplest method is [`String::from_raw_parts`](https://doc.rust-lang.org/std/string/struct.String.html#method.from_raw_parts), which is unsafe, but efficient.
No, this should eliminate the need for the `N::ArrayType: Copy` predicate everywhere.
That "two narrow columns" blog layout really grates on me. Thankfully, it's using CSS columns, so a quick jaunt into the DOM Inspector and a couple of unchecks rendered it comfortably readable. (I'm guessing that others, who are used to remembering it exists, will just click the Reader View icon in the address bar to unroll it instead.) Complaints on the theming aside, your content seems like what I remember experiencing during my first month.
&gt; A segfault is how the memory management gods show mercy. saved
Oops, I forgot to mention that I need `BlockContent` to be `Copy` as well; in particular the following code doesn't compile: extern crate generic_array; use generic_array::ArrayLength; use generic_array::GenericArray; pub trait BlkSizeConstraints: ArrayLength&lt;u8&gt; + Copy + Eq + Ord where &lt;Self as ArrayLength&lt;u8&gt;&gt;::ArrayType: Copy { } impl&lt;N: ArrayLength&lt;u8&gt; + Copy + Eq + Ord&gt; BlkSizeConstraints for N where &lt;N as ArrayLength&lt;u8&gt;&gt;::ArrayType: Copy { } #[derive(Copy)] pub struct BlockContent&lt;N&gt; where N: BlkSizeConstraints { content: GenericArray&lt;u8, N&gt;, } 
Quote of the week material?
I was being *hella* sarcastic. I wasn't sure how well that came across. Maybe I should have put it in quotes. You're absolutely right those aren't isolated.
That still results in the same error: error[E0204]: the trait `Copy` may not be implemented for this type --&gt; src/lib.rs:15:10 | 15 | #[derive(Copy, Clone)] | ^^^^ ... 19 | content: GenericArray&lt;u8, N&gt;, | ---------------------------- this field does not implement `Copy` 
What you could do is change [this line](https://github.com/rust-fuzz/cargo-fuzz/blob/781934d035e6661eb0b17b7f2afff198c7cd419a/src/main.rs#L167) to a different sanitizer and reinstall locally and/or make a PR to add an arg for configuring this :)
&gt; Btw, what's the memory overhead of your radix sorts? They are each in-place, with the caveat that they take their input data as a sequence of batches, roughly `Vec&lt;Vec&lt;T&gt;&gt;` rather than `Vec&lt;T&gt;`. This .. makes some sense because it is actually what a computer does underneath (wrt virtual memory at least), and is how the host system (timely) delivers "to be sorted" data; having to coalesce it all into a `Vec&lt;T&gt;` would be an additional copy for me. &gt; [..] It'd be good to see it published on crates.io. :) It is! :D https://crates.io/crates/timely_sort &gt; Yours, on the other hand, seems to exhibit much better performance. Great job! To be clear, I stole all the ideas from recently published papers. There are even a few more ideas to steal. The recent re-interest and re-motivation was that folks determined that radix-sorting can be much better than many other (non-merge) sorts as you scale out on multiprocessors. The single-threaded performance is good, but when you have to worry about data movement between private L1 and shared L3, the more efficient radix sorts really start to look great. It is a bit hard to benchmark on a laptop, though.
I always hear that intrusive collections can't be done in Rust (either "can't be done safely" or "can't be done as performantly as C++"). Can you elaborate on this?
They're the safest way to indicate a failure, because they immediately crash the offending thread and/or program. That's not ideal to have happen in production, but neither is continuing in an undefined state. It's pretty common to mistake uptime for correctness (*cough* people who never reboot their Linux boxes *cough*), but that's just sweeping the bugs under the carpet rather than finding and fixing them.
It took a lot of pain and anger to reach that conclusion
👋 I'm the creator of linkerd. Happy to answer any questions.
I understand. Seeing that your original assumption of never receiving invalid octal numbers didn't hold in practice, wouldn't it have been better to replace this `expect` with proper error handling to fix this bug, along with possible future bugs?
I'm guessing that depends on the expected behaviour, here it looks like this was fixed by ignoring the spaces and thus have `\ 3` be a valid octal literal rather than a parsing failure.
Awesome posts, thanks a lot! I always wanted to write a raytracer in Rust myself, now I've got s.th. to play around with ;-)
It's not the same thing because: First, those columns are narrower than a two-column LaTeX layout. I'd consider that few words per line in a column to be an eyesore in print too. (Not to mention that, with that sidebar, the page is technically a layout of three roughly equal-width columns which in unappealing to me in and of itself.) Second, websites don't have a concept of fixed pages. When I open a PDF, I come in with an understanding that it may have columns with the vertical wrapping scoped to each page. A website is much more freeform, so the reading order and how the content relates to each other requires more mental effort to figure out. (And, when I first arrive, I don't know how far it goes before it wraps. I could have been looking at something where the top of the right-hand column continued from the very bottom of the document.) **EDIT:** In essence, it's the vertical version of the problem which columns solve in print. (Columns exist because, beyond a certain line length, it becomes onerous to keep your place while `\r\n`-ing your eyes.) A similar problem faces websites which use columns like this, but for the vertical return. (That's one reason many sites use a single-column layout with a maximum width to the container for the main content.)
Is it even possible to parse xml with no allocations?
maybe this could be copied/restated in the docs/repo somewhere, it's a great reasoning behind the things whereas the repo has "no" explanation? iirc at least... thank you for this explanation it's a good read either way
You know what they say in science, new ideas prosper not when they're introduced, but when the old generation of scientists go to the grave. I guess it's the same for PL.
Nice! (I'm a bit confused why you have a 370MB docker image with the complete rust compiler though, I expected it to be ~20MB with nothing but busybox, openssl and one the linkerd-tcp binary in it.)
You mean like google street view?
Really, because we rushed to push something before a talk I gave this week. We'll definitely need to fix this. As always, pull requests are encouraged!
How does this compare with `watchexec`?
Really not important but: fn to_hex_string(ba: &amp;[u8]) -&gt; String { ba.iter() .map(|b| format!("{:02X}", b)) .collect() } You don't need the `connect` here, you can directly collect into a `String`
Funny, I'm actually working on it too. Pretty fun. I'm using raytraicing from scratch book, but the recommended website seems to be a good resource too. For people more in the know about graphics programming : Is there some standard way to describe a scene without hard coding it? I was thinking about implementing it with json/XML, which would be easy enough for simple shapes. Also, what should I implement after a raytracer? 
This is way too hard to read.
Web development and GUIs are probably Rust's two weakest areas when comparing to what other other, more mature, ecosystems offer, but you can definitely do it. (Just don't judge Rust itself poorly for the youth of its webdev ecosystem.) [AreWeWebYet.org](http://www.arewewebyet.org/) will give you a run-down on the componentry that's available. As for frameworks, what's available depends on your requirements. If you don't mind relying on nightly versions of the Rust compiler, the [Rocket](https://rocket.rs/) framework is definitely the most comfortable. (It needs nightly because it depends on [some language features](https://github.com/SergioBenitez/Rocket/issues/19) that the Rust developers haven't yet committed to API stability on.)
Nice! In my opinion, one of the biggest paradigm shift when coming from C++ is the default move semantics (and the fact that non trivial copies must be explicit), which means that you can fearlessly pass or return objects such as vectors and strings without triggering heap allocations or any non-trivial logic implicitly. It greatly affects the style of code written in rust compared to C++. I think that it deserves a chapter of its own.
People who like the syntax exist, but we don't make as much noise as those who complain.
Is there anything you want that's missing from rustls? Or that you found annoying or unergonomic?
The expect is doing exactly what was intended: it's showing that an assumption made in the code was wrong and therefore buggy. "Proper error handling" presupposes that this case was anticipated. :-)
If you have an idea how to improve the CSS, feel free to send us a mod mail.
Meanwhile, in the real world people ignore safety/instruction manuals *all* the time. They'll jump straight to using something and only hit the manuals if something goes drastically wrong that they can't understand. UX designers are well aware of this.
Currently kuchiki does not support PI and Prefix, and can't be serialized to XML.
Try using .obj files.
Wrong sub. You want /r/playrust. This sub is for the Rust programming language.
Rocket looks cool, its website is a visual delight too. Thanks for sharing
https://github.com/myfreeweb/secstr I wrote this one a while ago… It actually supports both pure Rust and libsodium options (since I was using libsodium anyway in [Freepass](https://github.com/myfreeweb/freepass)) :)
i literally instantly closed the pages due to that layout. *shrug*
Getting past the handshake was quite difficult (a lot of tcpdump and trial-and-error), and I suspect [my solution](https://github.com/linkerd/linkerd-tcp/blob/master/src/lb/socket.rs#L264) may have some bugs. Other than that, quite easy.
I think this is a very high profile use that should be on [Friends of Rust](https://www.rust-lang.org/en-US/friends.html) page. Maybe contact pants-devel and ask them for a blog post that we can link?
I think a lot of it has to do with the FOV of the virtual camera EDIT: here is the final scene, rendered at 1080p with a 45deg FOV instead of the 90deg FOV that the author used: [Render](http://i.imgur.com/uDKxyrx.png) You can see how much less distorted the spheres look. [This](https://en.wikipedia.org/wiki/Field_of_view_in_video_games) is also worth looking at.
LaTeX academic papers don't have columns longer than my screen, so I don't have to scroll up and down and move from left to right while reading.
It is possible to write this code this way: https://play.rust-lang.org/?gist=4256853e1a9e966b910ab79b6e2b3733&amp;version=nightly&amp;backtrace=0
Actually it's against their rules too; OP wants /r/playrustservers
So, this question could be a few different things: 1. Why is the tests module in the same file as opposed to in an external one? 2. Why are they in each module as a sub-module? The former isn't as strong as of a convention; it's just easier when there aren't a ton of tests. The latter is a bigger deal; it lets you test private things if you want to.
Thank you, that is helpful. ~~Is it impossible to do this without allocating temporary vectors?~~ Edit: problem solved above. 
&gt; Does it support doctype parsing? Doctype parsing is a terrible idea. Unless, you are really careful, you can accidentally open yourself to [huge vulnerabilities](https://en.wikipedia.org/wiki/Billion_laughs).
See /u/dmitry_vk's [response](https://www.reddit.com/r/rust/comments/62e8xb/lifetimes_for_a_function_that_returns_impl/dflte7j/).
It is now (from 9 days ago) default on master, see [Enable v2 engine by default](https://github.com/pantsbuild/pants/pull/4340). I don't think there is firm schedule for stable release of 1.3.x, but it is very likely it will be within 2017. 
Ah neat!
Maybe add the tags "identifier" and/or "name", since it sounds primarily useful for converting programming language identifiers between forms.
Umm..
Actually, Travis arm-android builder does run complete set of tests, and it is required to pass. You are right in general, but not right about Android. (I did the initial work of running tests on Android.)
Well, I still have to parse it.
Comments are enabled on this document, and some of the linked documents are not public. This appears to be somewhat for internal consumption...
I've translated [Peter Shirley's series](http://in1weekend.blogspot.com/2016/01/ray-tracing-in-one-weekend.html) to Rust (very recommended to anyone looking for a quick intro to raytracing) - https://github.com/ehuss/raytracer. It's a pretty naive, straightforward translation from C++. I'm currently working to add multi-threading. It really is a fun exercise to learn a new language.
Yeah it looks like the layout in two columns ends up being the "worst of both worlds". When writing, I'm primarily viewing the blog on a 4K monitor, so I get 3 columns. On mobile I get one column. I've sized things so that it fits roughly in one "screen" without the need to scroll up or down in 4K, but in two columns you actually need to scroll a lot. I'm going to tweak the design so that perhaps it doesn't trigger two columns by default, and maybe offer a toggle. Thanks for the feedback :)
`Box&lt;T&gt;` automatically derefs to `T`, so you can use a boxed item directly as if it were that item. The println macro automatically borrows whatever you put in it, so your code actually expands to `&amp;*x` (borrow the deref of x, final type `&amp;i32`) with the asterisk. Without, it expands to `&amp;x` (final type `&amp;Box&lt;i32&gt;`), which println will then automatically deref once to reach the box, then once again to reach the i32. You do have to explicitly deref if you are attempting to do things that make no sense to do no the reference, but the reference is not in a situation that permits unambiguous automatic dereferencing. `let x = 5; let y = &amp;x; match y {}` requires either testing against `&amp;1`, `&amp;2` etc, or doing `match *y {}`. Similarly, `let mut w = 5; let z: &amp;mut w; z+= 1;` doesn't work because you can't perform arithmetic on references and besides, `z` is immutable; you have to do `*z += 1;`
Plus the dedicated submodule cuts down on the amount of `#[cfg(test)]` markers you need to strip tests from actual builds, yeah?
If you're putting this in static memory, it should never deconstruct, right? So then you wouldn't need `Rc`, and standard references *should* work. If not, wrapping it in a `Mutex` will give runtime r/w locks, without invoking the destructor when nobody is looking at it.
&gt; These actually achieve very different goals -- they're done the same way in C, but the implications of each are quite different. Agreed. Coming from a C and JavaScript background, however, getting used to these semantic nuances was a bit of a challenge. Both languages adhere to the "everything is a X" approach: in C everything is a pointer, and in JS everything is a "map" (object). It's easy to confound intent with implementation. &gt; Also, in decent "modern" C++ these would all be different too, aside from raw/borrowed being the same. Yeah, I haven't really worked with the more "modern" C++ (e.g. autopointers and other similar features) so that's definitely a blind spot for me. Someone with that background would probably have an easier first time in Rust. &gt; &gt; The plan is for commonly used, general purpose crates to be eventually merged into the standard library. &gt; &gt; This is not necessarily true. Oh, interesting. I got that impression from reading [this post](https://internals.rust-lang.org/t/psa-movement-of-rust-lang-crates/2671) but I guess I should have read the [actual RFC](https://github.com/rust-lang/rfcs/blob/master/text/1242-rust-lang-crates.md), too. I wonder what's the criteria for being included in `std`, then? There's some pretty advanced stuff in there, yet it's simultaneously missing things that I would consider to be more "basic". Is that a historical thing?
My only complaint with `rustfmt` is when it takes nested closures and does this: q_c.dispatch_sync(|| { q_c.dispatch_sync(|| { panic!("success"); }); }); It doesn't do that every time, and I haven't figured out how to disable that. 😕
Per our relevancy rule, please explain how this is relevant to Rust. Is it just because the subject encompasses linear types, or does the instructor actually plan on using Rust for the course?
&gt; What could have we done better? I must have re-read this 10 times - I understood it each time, but it took me a while to figure out why I wasn't grokking it...
Here I'm considering threads and mutexes to be "advanced", but perhaps that's not the case on a language designed specifically with concurrency in mind. 🙂 Compatibility aside, I could see the standard library shipping without threads. We'd have `Send` and `Sync`, to keep things consistent/compatible across libraries, but all the actual threading calls would be provided by crates, binding to something like `pthreads` behind the scenes. I guess keeping the unsafe-heavy stuff in std (like collections) is a good idea, since then third party crates don't need to use it as much.
Yup!
Whoops! Yeah those two words are backwards...
This is such a rare use-case that it is dubious you’ll have a crate (or even a C library) that has been tailored for this. If you end up finding a library that exposes C API, though, you can easily use it from Rust, though, so there’s that going for you :)
Syntax is almost always controversial. Maybe type type ascription should be done externally, like in Haskell. Maybe generics should use square braces like Scala, and arrays should use normal parens. Maybe there shouldn't be semicolons and squiggly braces and should be whitespace instead. Maybe there is too many magical symbols. Maybe shortened words like `fn` should be full words instead. Maybe lambdas and functions should have a unified syntax. Whatever, lots of people have strong opinions, and its all noise.
Thanks, that's a good idea (and that's exactly what I am using it for :-) ).
If they want to stick with C but get the advantages of memory safety (and then some) they could begin using formal verification tools for C. Two examples immediately come to mind. * CompCert * The tools used to verify sel4 If curl is really running on billions of devices, then I would say there is a tremendous value in such an exercise.
obj is pretty standard for meshes, which might be enough for a "scene", but there are also FBX and Collada. FBX is proprietary but it's become pretty standard as a scene description format. The official SDK is in C++ but Blender wrote an [unofficial spec](https://code.blender.org/2013/08/fbx-binary-file-format-specification/). Collada is an alternative and it's open, but from what I hear it's a bit of a pain to work with and hasn't been updated in a while. There are a few obj and fbx parsers written in Rust on GitHub.
It's fantastic that they are aware of these tools AND use them. ...But they do not provide the same level of assurance as formal methods.
Have you tried this in your rustfmt.toml? # How many lines a closure must have before it is block indented. -1 means never use block indent. closure_block_indent_threshold = -1
I just crashed IE6, but that may have been a wine bug...
That looks alright to me. But yes, the IO-free interface can make it annoying to get started. [tokio-rustls](https://github.com/quininer/tokio-rustls) might be a good option if it fits in with your uses though.
Thank you, that makes a lot more sense. I have one (possibly) related followup question though. In the following code, I can directly call the add method on the reference, presumably because calling a method on a reference automatically derefs. But in the docs, it says that the add method is used by the '+' operator. So, why would the plus operator not automatically dereference a &amp;mut i32 when using the add method does? use std::ops::Add; fn main() { let mut a = 1; let b = &amp;mut a; println!("{}",b.add(1)); println!("{}",b + 1); // Errors }
I think so.
When handling function calls, Rust automatically manages the refs/derefs needed to reach a valid call state. I'm gonna tap out and let someone who knows how Rust does operators take over from here; my best guess is "uh, just cuz?" Might be because Add requires LHS and RHS to be of the same type in the original syntax tree?
Note: actually Rust has an *affine* type system (it's leaky). The course does cover affine too.
The most difficult part is realizing that you are not at your best. I still slip up from time to time :(
safety precautions != instruction manuals. I'm all for Rust's push for ergonomics in making both the language itself and its libraries as easy to use without reading the docs as possible, but Rust does not have an off switch for the borrow-checker nor should it ever gain one. This is not a failure of Rust but rather a valuable feature. We just need to find other ways to increase willingness of new users to stick with Rust instead of relying on giving them false hopes as C does. 
I think you and I fundamentally disagree on a few points. You make a distinction between "delaying sharp edges" and "delaying a sense of pain". I don't. Yes, the user can be "bleeding out" as you put it, but you know what? - for many people *that doesn't happen often enough for them to care*. Rust *forces* you to deal with all of those issues right off the bat, and I feel like as long as that's the default it's always going to be a tough language to get into, and it will have an uphill battle wrt traction.
The issue here is that, C isn't really a bad choice for curl. It would nice if we lived in a world where it was a bad choice. But right now, curl builds and runs on a bunch of platforms modern languages don't. This fall, I was tempted to write to write a Go version just to bypass deployment issues a co-worker was having, but Go doesn't really support AIX yet. Curl does. 
Our usual policy is that the Friends page is intended to appeal to decision-makers at companies who are evaluating Rust, and so should list companies that are using Rust for something rather than listing awesome projects that are using Rust (a separate page has been proposed for that). So if Twitter et al are using this, then we should reach out to a representative of those companies to get their names on the Friends page (and of course our other policy is that Friends is opt-in, so we can't put their logo there just because we know through side-channels that they're using Rust).
As 3 columns, I really liked it. It was easy to skim headlines that interested me, kind of like a newspaper.
&gt; I don't get the reason people are bitching about cURL not being rewritten in another language... Who's bitching about that, exactly?
Yeah, as far a systems languages are concerned threads and mutexes are "basic". Plus Rust intends for concurrency to be as easy as other stuff. threads and mutexes are also unsafe-heavy.
As others said, people who do not care about safety IMO are maliciously negligent. It must be a requirement for infrastructural software. In exactly the same way you wouldn't want your house, or roads and bridges you use to be built without safety regulations in place. I work in application security and it is scary what can be done with not much effort. From stealing one's money/identity to hacking one's appliances to making one's car accelerate instead of break. Yes, it depends on the software domain and in other domains it could make sense to completely ignore safety aspects and perhaps this is the root of our disagreement, but in our world that becomes exponentially more interconnected with each passing day, with IoT spreading like wild-wire, I do want to believe that once my household appliances become internet-connected, I wouldn't need to worry about potential hackers breaking into my refrigerator... Just this week I was at a seminar where it was demonstrated how easy it is to gain root access to a device by downloading a freely available pre-made exploit that uses a buffer overflow in C code. 
I'd rather have and/or as in python instead of &amp;&amp;/|| if we are at it. All those non-alphabetical symbols break the flow of reading text for me.
They are considered primitives and you'll learn pretty quickly why. I may agree with delegating threads presence in stdlib to some trait definition, but that would probably require you to pass which implementation to use everywhere. Threads are meant to be used everywhere without giving it much thought.
It's not easy at all. I'm just positing that with 3 billion installed instances that they're approaching the threshold where I personally think the benefit would outweigh the effort. Now, it doesn't mean that the Curl team needs to be the one to accept this burden. It has the potential to be a cool project for some academics. 
This is preaching to the choir. We've had an explicit "no zealotry" policy since day one, and we're the first to tell overenthusiastic people to cool their jets and keep a pragmatic mindset.† I have no idea who these people are that are asking for rewrites in Rust, but if they were here on the subreddit they'd be smacked down by now. ^^†...except ^^on ^^meme ^^days. If you see people in the wild being silly about rewriting things in Rust, then tell them to cut it out. But conversely, if you see people hyperventilating about the "Rewrite It In Rust" crowd and constructing straw men to make their point, then tell them that they're just as full of shit as their imagined adversary.
[removed]
I've seen more people complaining about RIIR people than I've seen people recommending to RIIR. I almost wonder if people adding in to conversations something like "BTW, this type of error can't happen in Rust" strikes a nerve, because sometimes the C coder doth protest too much. 
You're right, it's a good result. That warm feeling is what Rust is all about :). Note that I didn't fuzz regex matching here, but I think others already have.
Reached out -- it's for public consumption. (But they now disabled the comments)
I've looked at 4/9 of those open "issues" and none has yet been a RIIR. An epidemic indeed. 
I've seen it on hn when glibc/binutils bugs come up
PCJ is that way --&gt;
I've definitely seen this happen a lot, especially on Hacker News. So much so that there's a *term* for it: [Rust Evangelism Strike Force](https://www.google.com/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=rust+evangelism+strikeforce&amp;*) - and not it a good way.
Which stems from a site that doesn't want to mention _anything_ in a good way. It highly aggrevates me that such bullshit catches on so fast in our community*. And unsurprisingly, most of the comments in your google search lead to that site for reference, the term isn't in widespread use. (* not Rust, but programming in general)
@r? me
Also congrats on your first PR to Rust! :D
Context: https://www.reddit.com/r/rust_gamedev/comments/5vqlln/shar_one_year_with_rust/ It's a Physics game implemented with an Entity System. It will be nice to have a Steam Game using Rust. Rust Gamedev will start to blur the lines between the "Rust Game" and the "Rust Programming Language" =p
I should probably have added the tag #sarcasm... ^^
Once we finally convince Facepunch to scrap Unity and rewrite their game in Rust, we can at last merge the subreddits and bring balance to The Force.
So true! (Laughed a lot at that). It will make hard for that project that used machine learning to categorize a post to the correct subreddit =p 
Also, high relevant: http://arewegameyet.com
Being open to new ideas including from outsiders is partly what open source projects are about, but sometimes a certain kind of people, those who feel they are very knowledgeable but in fact are not, show up and demand that a project undertakes a radical change towards X. This problem is not really Rust specific. Often these very unpleasant proponents are behind demands for "codes of conduct", or demand that C libraries should be replaced by C++, or think that a C++03 codebase should be moved to depend on C++11. That being said, unlike the other things I listed in the paragraph above, deploying Rust actually is advantageous, in many ways, including better safety. And yes I dream of a world where the memory unsafety plague caused by C and C++'s unsafety by default paradigm is gone. But that world won't be reached by harassing project owners who are often well aware of Rust's existence. Instead, you should try to contribute to an already existing Rust rewrite of a project, to improve it, or if you are bold, start a rewrite yourself.
Piggybacking with some shameless self-promotion: I launched a Greenlight campaign for my 100% Rust game earlier today – http://steamcommunity.com/sharedfiles/filedetails/?id=893373312 . It's not nearly as ambitious as SHAR, but that means I'll probably win the race to actually get it launched. :-) I'll be releasing it (regardless of whether it makes it onto Steam or not) in the next month or so. I already have a ton written up about my experience with trying to build a quasi-commercial game in Rust that I'll be sharing post launch. I also have a few libraries worth of code that I'll be extracting and sharing once I'm less focused on shipping.
First moderator for life: the person that showed up to RustFest with a Rust game t-shirt!
Great, looking forward to hearing about your experiences. :)
Oh man, I remember Stallman gave a talk at my college once, and I didn't know anything about him other than he was the "father of GNU", so I was pretty excited. Then he spent the whole time on this "all non-GPL software is malware" rant. I was pretty disappointed.
I feel like I'm reading a newspaper... And I'm not sure what order I'm supposed to read the pieces in.
maud and iron
I say this wouldn't have happend in xy quite often. if its language fuckup, i tell people it wouldn't have happend in lojban ;) in programming its rust, in physics its bsm-sg,... ;)
full ack. Maybe the underlaying problem has to do with concurrency and the data structure the iterator is pointing to go changed while the iterator was active ?
[relevant oglaf](http://oglaf.com/labyrinth/) [warning, site is nsfw in general]
[Rusoto](https://github.com/rusoto/rusoto/) generates docs for [only the crate and not dependencies](https://github.com/rusoto/rusoto/blob/master/.travis.yml#L57). I think this is causing issues when linking to `hyper`'s documentation, as it has a special format to have multiple versions of the docs available at once. This causes a dead link in our published docs: https://github.com/rusoto/rusoto/issues/567 . What can be done so any link to items from `hyper` go to the correct URL?
Ah, that makes sense. I don't write C++ much, so I didn't realize it is different from other languages that would most likely fail at runtime if you tried to call a method on null. It make sense that the method wouldn't necessarily fail in C++ if the method is not virtual though.
God I feel bad for the community for knowing this company person is willing to jump on some other project and demand change from their existing language and project just because he is unwilling to learn. I feel this removes any faith of the other workers at this "trustly.com" site for just allowing someone to make demands and badgering existing libraries being used by more than just rust users from the company email
What would I need to know if I wanted to help port rustc and cargo to iOS? 
`Result&lt;C, E&gt;` impls `FromIterator&lt;Result&lt;T, E&gt;&gt; where C: FromIterator&lt;T&gt;`. Maybe that's what you're looking for?
Rust community is as always very self-conscious one. :D "RIIR" term is just a reaction to a lot of people thinking Rust is awesome and talking about it. After all it eg. won the most loved language on SO, didn't it? So yeah, people will keep mentioning Rust here and there. Sometimes unrealistically, sometimes inappropriately. I bet most of them are not even that involved in Rust community. There is a perception among many people that by using Rust they could have a better, safer software. And they care about it. Some other people get upset about it, because... lots of reasons. They might not like Rust at all. It might seem like Rust over-enthusiasts are diminishing their hard work. Look at r/programming ... most submissions have less than 0 votes. Comments are not much different.
Try to get your prof to make their assignments as language agnostic as possible! I had a prof let me do a pl0 compiler / interpreter in rust instead of Java! And it never hurts to ask, worst case scenario they think you are really keen and tell you no.
A lot of people were complaining, that's true. But they weren't complaining about curl being written in C.
This isn't my project, open an issue with your suggestions I'm sure they'd love the feedback. 
It [does](https://trac.torproject.org/projects/tor/ticket/11331) [happen](https://trac.torproject.org/projects/tor/ticket/18621) occasionally outside Hacker News and on project bug trackers.
I really think this is a solid response. I think posts like this (and actions like the ones described within) come up whenever the new hotness comes around. I'm in my mid 20s and even I've seen a few different phases of this: - The wheel - Language (general communication) - Riding horses - PHP - Carriage/buggy - Ridin' dirty - Javascript - Marvel movies - RoR (which popularized the use of Ruby) - Git - Vagrant - Docker - Atom - VS Code Also, I spent a good three minutes reviewing your post for a spelling error, and couldn't find one. I really have to commend you for the impeccable display of orthography and grammar... but have you considered rewriting it in rust?
I see, thanks!
[In Limerick Form](https://twitter.com/llogiq/status/847701312598712320)
You know, Java has an Optional type. Just refuse to use nulls and use Optional.empty() instead. It's not quite as nice, but it's better then nothing. I've been slowly converting my coworders to wrapper types and optionals.
I got a copy, with the intention of working through it (I've written a raytracer previously), but I was having a hard time getting started. The book is like a literate C++ tour of their tracer. As such it starts with their command line parser. So one thing that is hard, is to tease out a good reduced/minimal version of their ideas. What I would prefer is a simple, but complete tracer that evolves into the final form in their book. I think the PBRT book is more suitable to people who have an existing tracer and want to make it photorealistic. In that regard, I would be better off applying specific chapters to my existing tracer, but I had been hoping to start over.
SS Rustwaffe "All other languages are inferior" You can wear it to the office. Once per job, but you can.
Unfortunately there's a little bit of overhead in that, and it gets to be a huge pain to carry around all that extra type information everywhere you carry it.
We normally don't meme, but as /u/kibwen has already allowed an oglaf link on this thread *shrugs*
Well, in Rust it *does* work fine...
Ha! I know that Isis and Henry are working on dalek in Rust for the bridge token thing, and someone mentioned other discussions happening. That's the extent of what I know -- anything more you can tell us about what's going on? I was quite pumped when I heard that y'all were going to use Rust, especially when I saw that it led to some high quality Rust crypto work happening :) Keep up the good work!
Sounds great, looking forward to seeing that post! :)
&gt; I am noticing a really disappointing trend in Tokio-based libraries where the reactor core is hidden away from the user. This makes it much more difficult to actually take advantage of Tokio to do multiple things on the same event loop (run multiple servers, set up an actor system, etc). Agreed. This was something that concerned me from the very beginning of mio and now tokio. I'm curious if there's a plan for making the various tokio/async libraries composable.
I really wish there was a great crypto story for rust; the current options can be a bit haphazard and all-over-the-place.
Yeah, "this wouldn't have happened in Rust" is something I say daily at work.
You want /r/playrust 
I'm surprised this didn't get caught by the filter
It happens all the time. I used to work on an open source game with a fairly big python code base (~70 kloc). We'd have people come into our IRC channel asking us to rewrite the game in C++ ("because games are written in C++") at least once a month. 
This feels weird. Adding a ton of annotations feels like a huge burden. Even in C++ you could create a `Mutex&lt;T&gt;` wrapper. The only thing I can think of is that this design was chose for ease of applying to an already existing (read: legacy) codebase. A `Mutex&lt;T&gt;` requires your data is structured in a specific way where as these annotations allow ad-hoc protection of specific data members.
Thanks for the pointer. I'll check out ioct then.
I'm impressed over how kindly the postgre people responded to that rather immense request. "I don't want to learn C" Is also, understandably, a rather rage inducing sentence coming from someone who wishes to write software for a C project.
I initially thought that this is no use because I have already disabled the ASAN and faced tons of linker errors. Turned out that you've actually said to change to a *different* sanitizer. This actually turned out to be correct, I've switched to ThreadSanitizer (plus `TSAN_OPTIONS=report_signal_unsafe=0` to avoid probably false positives from jemalloc?) and it really worked well! Thank you so much, I'm looking forward to file a PR :-D
Haha, that's golden. Thanks for immediately critizicing and undermining our most fundamental project decision.
Just, i think people fear the counter culture will grow larger than the pro movement.
We need a human written communication lingual version of rust, so we can start telling people to rewrite their comments in rust as well. 
We use SonarQube, so things like `@Nonnull Foo foo = null` won’t be allowed to merge. Unfortunately SonarQube doesn’t have a check for the existence of `@Nonnull` or `@Nullable`, so we cannot enforce that every single method is appropriately annotated, and some of them indeed aren’t. Also I sometimes forget to add that `@Nonnull` before parameter.
&gt; I literally had a "This wouldn't have happened in Rust" moment this afternoon. When it is clearly a compiler bug ? &gt; the compiler may unroll a couple of iterations of the loop &gt; so the compiler can assume this is never null A compiler cannot do both of these things, or rather, it cannot do both of these things while ignoring the nullptr condition. It might have totally legally been any other condition that marked the end of validity of calling the next iteration too, inc any one that doesn't rely on the pointer being invalid. &gt; C++ is a programming language that only pedantic language lawyers who have an in depth knowledge of compiler optimisations can use correctly. While there is some truth to it, this is not evident here. 
&gt; A compiler cannot do both of these things, or rather, it cannot do both of these things while ignoring the nullptr condition. It might have totally legally been any other condition that marked the end of validity of calling the next iteration too, inc any one that doesn't rely on the pointer being invalid. No, this is very clearly _not_ a compiler bug. * Member functions are not permitted to be called for an invalid object * Therefore `this` must be a valid object pointer inside a member function * Therefore `this` cannot be `nullptr`, because if it was `nullptr` then `this` would not be a valid object pointer * `iter` is always identical to `this` when entering the loop for the first time * Therefore `(iter == nullptr)` is always false when entering the loop for the first time So, _without_ unrolling, the loop can be rewritten from: while (iter != nullptr) { &lt;body&gt; iter = iter-&gt;next; } to: do { &lt;body&gt; iter = iter-&gt;next; } while (iter != nullptr); There is nothing wrong with the code in my example, nor is there anything wrong with the way that the code was compiled. If you can find specific language in the standard that prevents the compiler from making the inferences above, I would be very interested to read it.
That's really just something you can't do. In scala all types are implicitly just boxed which is why it works. You can do that as you've mentioned but obviously there is overhead.
r/programmingcirclejerk
No I mean Rust favors static dispatch, so you can have an impl with a method on pointer types that never derefs, then call that method on a null pointer (`std::ptr::null::&lt;T&gt;()`).
I can't generate code that would replicate the issue. What compiler did this? And have you got code that's closer to what you originally did? This explanation sounds... let's say I'm sceptical loop unrolling is optimised that way. 
This was GCC. /** * Returns the first EntList not of type join, starting from this. */ EntList * EntList::firstNot( JoinType j ) { EntList * sibling = this; cout &lt;&lt; "Sibling pointer " &lt;&lt; (void *)sibling &lt;&lt; endl; while( sibling != NULL &amp;&amp; sibling-&gt;join == j ) { sibling = sibling-&gt;next; } return sibling; // (may = NULL) } When compiled with `-O3`, this was failing by printing "Sibling pointer 0" and segfaulting. Compiling with `-O3 -fno-delete-null-pointer-checks` resolved the issue. I'm not sure which exact GCC version &amp; ABI was being used.
This is complete bull. Your argument would allow you to rewrite any for loop as a do loop moving the condition to the end and randomly crash or do wrong loops. Your claim that compiler is allowed to make assumptions about first iterations and change the semantics of code is entirely unsupported. 
This upcoming feature may be relevant to your interests: https://github.com/rust-lang/rfcs/blob/master/text/1522-conservative-impl-trait.md
I have a `Vec&lt;f64&gt;` inside a `struct`. I want to implement a method that, given an index, returns the element of this vector at that index. So far, so good. Let's say that I don't want to directly write the index, but instead the constructor of a numbered enum: `enum Indexes { One, Two, Three }`. I can still call the method with `Two as usize` for example. Ok. But now I don't even want to write `as usize` and just give the constructor. How can I do this? The `struct` will obviously need to be generic over enums since I want to be able to define a `struct` indexed by `enum ABC {A, B, C}` and another one indexed by `enum DEFG {D, E, F, G}`, etc.
Which compiler? I'd like to know because I wouldn't go near it with a barge pole.
&gt; Your claim that compiler is allowed to make assumptions about first iterations and change the semantics of code is entirely unsupported. Um, no? These are pretty well-established optimisations. I think you really underestimate the extent to which compilers are able to rewrite your code to make it faster. You should really watch [this talk from CppCon 2016](https://www.youtube.com/watch?v=g7entxbQOCc) which gives plenty of examples of how compilers use undefined behaviour to extensively rewrite code. Edit: As I've pointed out elsewhere, the fact you assume that I'm wrong and/or being deliberately obtuse about this really illustrates my point that C++ is not a good programming language for sane human beings to be using. Rust is far better, because it avoids the sort of undefined behaviour and weird language semantics that permit the effects that I describe.
Slightly off-topic: that code seems really strange to me; an object is calling methods from its *siblings*. I want to say that's bad code, but I've never seen anyone do that and haven't thought about why that might be necessary. Could you explain it to me a little? Maybe it makes more sense with context.
Maybe we need a `Rust Anti-Rust Evangelism Strike Force` formed by actual Rust users that patrols the internet and punish those who make comments like `rewrite it in Rust`.
Assumptions made by compiler make sense. The question that remains is why is `this` a `nullptr` when you call `doAll()`? IMO the only way it's null is when you're using an object pointer that is null and calling `obj-&gt;doAll()` on it (which is likely to work if `MyClass` is not a base class of this object and/or doAll is not virtual). So it seems to me that in this case, the problem is not caused by too eager compiler optimization, but a bug in your code.
&gt; a certain joke website You mean this one?
The thing is, that's *one* noisy asshole, not a group of militant RIIR fanatics. I honestly think the whole RIIR thing is a nebulous meme more than an actual group of people. 
There is some discussion about the interaction of the reactor with rayon as well. Somebody suggested that one should write reactor independent libraries, so that one can combine them and use the same reactor for multiple things (like sockets and rayon) instead of having multiple competing reactors in the system. Or also to use the same library with different reactors, when the library is used to solve different problems. Like one might want to handle some types of requests with a reactor that minimizes latency and some other types of requests with one that maximizes throughput. If the reactors are bundled inside the library... you are on your own. Its great to have a single easy to use stack for easy/simple/small web applications, but it would be even grater if the stack would scale to more complex systems. For some reason it seems like the tokio stack is built under the assumption that a perfect reactor for all applications exists when there is obviously no such thing.
Feel free to ask me to use Rust. I'd love to hear motivations and success stories...
Life Pro Tip: learn to recognize when someone actually has expert knowledge and knows what they're talking about. Instead of scoffing at an expert argument ("this is bull!!), learn from it ("...wow I didn't know compilers worked like that").
It follows the standard exactly, so all it proves is that you *do* have to be a language lawyer to use C++ safely. The compiler *can* make an assumption here about the first loop, because in the first iteration `iter` is `this`. Proving certain things about the code is a core tenet of compilers, and is how they are able to make advanced optimisations on code. This doesn't "allow you to rewrite any for loop as a do loop moving the condition to the end and randomly crash or do wrong loops", it can only do optimisations like that in cases where the compiler can prove certain conditions are true and follow certain things in the standard.
It does make sense, the standard says it's undefined behaviour to call a method on an invalid pointer, so the compiler legally makes an optimisation based on that. Now whether this sort of optimisation is going too far is what's really up for debate.
&gt; This isn't an "it wouldn't have happened in rust" moment but rather a "it wouldn't have happened in non-horribly written code" moment. &gt; Or a "it wouldn't have happened with a standard container instead of a bespoke linked list implementation" moment. That's certainly an interpretation, and you're not wrong; using a standard container (presumably "non-horribly written") would have prevented the problem. However, you're overlooking the fact that safe Rust doesn't have the undefined behaviour that permits that error to occur, i.e. the error can't happen _by language design_.
Benchmarking regex engines is super super hard, so I first want to say that I admire the OP's guts for doing it. I've wanted to do it myself for a long time, but I'm pretty sure I'd need to lock myself in a room for 3 months in order to do it in a way that would make me happy. The best I have so far is a hodge podge of benchmarks in the `regex` repo itself, which I use for ad hoc comparisons and more importantly, for doing performance improvements. (Sometimes, the notion that something *can* be faster is sufficient motivation to spend that extra day thinking extra hard about how to do it.) With that said, I'd like to clarify a few things. I will say though that the final results of the OP smell about right. &gt; The chart shows that the expressions `∞|✓` and `(?i)Twain` benefit by using the SIMD feature, but not the expression `[a-q][^u-z]{13}x`. This expression requires backtracking. The Rust regex crates uses a finite state machine based algorithm, which lacks for back-references and backtracking. The first two expressions are interesting, and the fact that they are slower than RE2 without SIMD probably suggests that there is a bug somewhere. (I recently fixed a small performance bug in `aho-corasick` that could impact this, but I don't know which version the OP used.) However, the `[a-q][^u-z]{13}x` expression is slow not because it "requires backtracking," but because it causes state explosion in the DFA. The DFA cannot allow state explosion to require exorbitant memory, so it will cause the DFA's bounded state cache to thrash. If it thrashes too much, then it drops down to one of the slower NFA based engines. (In this case, that's the PikeVM since the target string is too big for the bounded backtracker.) The interesting bit is that RE2 does better than Rust on this expression. I already know that the NFA engines have some catching up to do in that department. :-) Tangentially, I think the presence of a not-tiny counted repetition regex---a know tricky case for FSM implementations---should also come with a regex in the benchmark that is tricky for backtracking engines to handle efficiently. Otherwise, the results in the aggregate will be biased. But *of course* I would say that... ;-) &gt; Hyperscan returns more matches than other engines, e.g. 977 for the expression `Huck[a-zA-Z]+|Saw[a-zA-Z]+` whereas all other engines are finding 262 matches. Hyperscan reports all matches. The expression `Saw[a-zA-Z]+` returns the following matches for input Sawyer: Yup, this is [intended behavior on Hyperscan's part](http://01org.github.io/hyperscan/dev-reference/compilation.html#semantics). This behavior is motivated by the fact that Hyperscan's primary use case is to search streams, which will benefit from simply emitting matches as they are seen. (The *start* of a match in Hyperscan is only available by explicit request, since that implies some interesting things when matching on streams. This benchmark does ask for [start of match](https://github.com/rust-leipzig/regex-performance/blob/master/src/hyperscan.c#L24) from Hyperscan, which means Hyperscan can actually go faster if you don't need the start of a match.) In fact, this behavior is the more "natural" behavior of a FSM based engine. But, we live in a backtracking-dominated world, so our FSM implementations are designed to emulate them. (The [`aho-corasick`](https://docs.rs/aho-corasick/0.6.3/aho_corasick/) crate works more like a traditional FSM and can operate on streams.) &gt; To get comparable results, the Unicode support has to be enabled with the configuration option --enable-unicode. Hmm, looking at the benchmark, it doesn't look like [Unicode support is enabled for PCRE2 regexes](https://github.com/rust-leipzig/regex-performance/blob/master/src/pcre2.c#L33). I don't think `--eanble-unicode` is enough, I think it just makes the option available. I think you want to pass the `PCRE2_UCP` and `PCRE2_UTF` flags. (`man pcre2unicode` is somewhat murky to me on the behavior if neither `PCRE2_UTF` or `PCRE2_NOT_UTF_CHECK` are used. My intuition would say that `PCRE2_NOT_UTF_CHECK` is the default and therefore wouldn't need an explicit flag, but its presence, to me, implies some third state that I don't understand?) &gt; `\b\w+nn\b` The big thing missing from this benchmark is a test on predominantly non-ASCII data. If you had a benchmark on non-ASCII data, I think you'd see more variance in the match counts (because I think this benchmark doesn't completely control for Unicode support). For example, `\b` in Rust's regex engine will search for Unicode-aware word boundaries rather than the ASCII word boundaries that, say, RE2 or PCRE2 will use by default. You can ask for ASCII word boundaries in Rust with `(?-u:\b)`, but I don't see that construction used in the benchmark. &gt; The Rust regex crate is now something about 2 years old I think it was actually initially merged around [three years ago](https://github.com/rust-lang/rust/pull/13700). (Jimminy cricket! Has it been that long!?) It didn't really become fast in a large number of cases until [about a year ago](https://github.com/rust-lang/regex/pull/164).
haha ah yes. Funny enough, I am using Node.js now instead or Ruby.
Your point mainly illustrates you being obtuse. The standard actually says that a while loop of while ( test ) {statements} is equivalent to: label : { if (test) { statements; goto label; }} I am not assuming you are obtuse, I know you are. 
That was a very positive response :)
Yes, that's exactly how you would implement it in Rust, and it would be much cleaner. As I understand it, STEPcode is a very old (C++98?) codebase, and I think it was written in a very "object oriented" fashion. That would dictate that "code belongs to objects", but alas the original authors decided to avoid having separate abstractions for `EntList` and `Ent`. We add the necessary compiler flags to rule out the problematic optimisations, and we go on. But we should start thinking about using programming languages that don't have this kind of undefined behaviour in the first place -- like Rust.
Then you go punch a developer somewhere.
Java is always full of overhead, and you just have to pray for JIT compiler cleverness. But the pain of carrying around invisible "nullability" information in your head (as opposed to baked into the type) that Optionals are a pretty great benefit, even if it is only a baby step in the right direction.
My version of the rust evangelism strike force would just implement the rust and then tell people they did it verses leaving comments. 
I would recommend rewriting this post in Rust (or Rust-Lang?) for obvious safety and productivity reasons.
I feel like i have to clarify that i don't actually support using nazi imagery as a joke. And the post in it's entirety was hyperbolic and sarcastic. But i think i may have missed the mark. Also the response was mostly towards the post one step up.
If this problem every becomes serious enough, maybe we need a new language feature here... "impl enum trait", that rather then boxing creates a new enum type for all the possible types being returned and lets you keep it all on the stack. Not sure if you could make a macro for something like this. Might be a bit too magical though. Best to let people make enum manually (since they impose overhead) unless that pattern becomes too annoying.
Hey, i respect your low tolerance stance on the topic. 
&gt; I don't think you understand what Stallman tries to argue, yeah he's a nutjob, but he never argues that proprietary software is malware. I'm sorry, but he says so quite literally. It's a paraphrased quote from an op-ed in the guardian. https://www.theguardian.com/technology/2015/may/22/malware-viruses-companies-preinstall &gt; But proprietary developers in the 1980s still had some ethical standards: they sincerely tried to make programs serve their users, even while denying users control over how they would be served. &gt; [...] &gt; So many cases of proprietary malware have been reported, that we must consider any proprietary program suspect and dangerous. In the 21st century, proprietary software is computing for suckers.
I see were you're coming from. But what he says is that every piece of proprietary software could potentially be malware, which is entirely true. How would you know if something has malicious intent if you can't read the source code or aren't allowed to reverse engineer it? I'd argue that that's entirely different than "Stallman believes that all proprietary software is malware".
Every time I read one of your pieces on regex it makes me a little more interested in getting into this field. Stop it. ^^^continue
There have been some efforts, but Servo is probably too much of a moving target at the moment and they all seem to be abandoned. Maybe one day... I would like to see it as a GUI backend for Python for example
Hiding overhead in abstractions is a dangerous game. 
Its irrelevant what they demand. If you turn up as outsider and essentially say "your entire project is bad because you don't have X and please switch to it" and X is a basic change like adding a code of conduct or switching from C to C++ then it is the same thing. Of course, codes of conduct are about the community, while the other things are technological demands. What would you say if your project had a code of conduct and some outsider turned up and demanded the code of conduct to be removed? It would be equally annoying as some outsider turning up and demanding a code of conduct to be established.
No, he precisely widens his argument in the second paragraph to all proprietary software, especially after setting the baseline in the 80th where he considered people ethical. Also, you're all-out rebuttal of the parent makes me feel like those subtleties weren't what you wanted to interact with.
It's the same people who use the issue tracker to demand the removal of people from the project (apparently without being developers or users of the project). (;
One solution is to implement a small trait for your enums (done here with a macro to hide boilerplate): trait AsIndex { fn as_index(&amp;self) -&gt; usize; } macro_rules! index_enum { (enum $name:ident $body:tt) =&gt; { #[derive(Copy, Clone)] enum $name $body impl AsIndex for $name { fn as_index(&amp;self) -&gt; usize { *self as usize } } } } index_enum! { enum Indices { One, Two, Three } } Then you can bound your method with `T: AsIndex`.
It's been discussed a few times; it's unclear how to best introduce them and *actually make them work*. The problem is that all existing code is expecting affine types, so it would need to be opt-in. Which would require re-writing/adapting a whole lot of APIs. And for each API you would have to wonder: do we really want linear here, or are we blocking a potentially useful future evolution? I am not sure if we'll ever have it in Rust. It's not clear whether it's worth it.
Isn't C actually easier to learn than Rust? I haven't learned Rust myself (yet?) though.. so no idea. What might be hard about C are standard obscurities or undefined behavior edge-cases but both are mitigated by not writing clever code.
The main problem is that it occurred completely silently.
My comment has nothing to do with Stallman and everything to do with this particular figure of speech being not constructive.
Huh, well that's not encouraging. I honestly don't know that much about the technical details of the project, just PR stuff. Are the APIs not intuitive?
That's a pitty. Thanks!
&gt; Last summer, with the release of Firefox 48, we shipped the very first browser component to be written in the Rust programming language — an MP4 parser for video files. I don't quite understand why there's a press release now, for something that started last summer. Is there any specific *new* code that's worth announcing?
&gt; C++ is a programming language that only pedantic language lawyers who have an in depth knowledge of compiler optimisations can use correctly. I used to be quite adept with the C++ Standard (back when C++11 appeared). I still failed to write C++ correctly *all the time*. It only take one careless slip-up for a program to crash, or worse.
God only knows what inspires the marketing department to whip up a press release. It may very well be that they intended to have something like this released last summer but just forgot. Or alternatively maybe they were instructed to do something generic to attract volunteers to help with Project Quantum. Or maybe they were just bored one day and needed to write anything at all to meet their quota. :P
The only active project is https://github.com/paulrouget/servoshell. But that shows how to embed the whole browser and the features seem not to be on par with something like CEF at all, however this project also tracks the status of a lot of issues of the servo repository to make it more embedding friendly. servo was not designed with embeddability in mind or at least it was not given a very high priority it seems. Except of the api there are a lot of other issues, like setting up just a build environment that tracks the latest releases and nightly versions servo actually uses. Although this is certainly possible, its quite the maintenance burden to depend on servo in its current state. I expect this to be an issue for much longer, at least until most basic browsing works. And thats far from perfect on many sites: https://www.reddit.com/r/rust/comments/5zmgga/servo_screenshots_march_15th_2017_from_the/
It's funny, I almost made this post after the curl post, then I decided I was going to be too "preachy". Anyway, here's my comment, and it's related to a something I read a bunch of years ago, "The Four Agreements", and I propose an interpretation of those for Rust: 1) Be Impeccable with your word: Let's not mislead people; not make promises that Rust can not do; be honest that there is a reasonable learning curve; but at the same time let's definitely not allow people to misstate facts. 2) Don't take anything personally: The world would be a better place if everyone could do this; someone's slight of Rust is not a personal attack, they may be doing it because they are feeling defensive about their own language choice, etc; remember they may have invested more than 20 years of their life becoming proficient in the language of their choice, they won't let that go lightly. 3) Don't make assumptions: did you know there are still people out there who haven't heard of Rust? Did you also know that they may not even completely understand what memory safety, data races, or move semantics mean? Don't be preachy, but ask questions. 4) Always do your best: try to follow the above rules; and then we can start avoiding the RIIR reputation (though honestly, I often see that a lot of people who push this are not Rustaceans, or are new comers who don't fully grasp the entirety of their request). I have to say, one thing I really liked from a talk I saw from Jamey Sharp, maintainer of corrode, was something along the lines of; "make sure the project your looking at wants your help". They will not convert their code on their own; they may be interested in Rust, if you explain it to them; and they may allow you to show them how to integrate Rust into the project so that it can be incrementally converted. But they may not either, so be delicate in broaching this subject.
Note that the annotations are defined as macros. This allowed the author to introduce them into Google's codebase while he was working on them, even though gcc didn't support them. It's also purely static analysis, so you cannot accidentally modify the code behavior when introducing them. That being said. Yeah... just use proper types.
There's a distinction between "being able to write code" and "being able to write good code". https://www.reddit.com/r/rust/comments/4sdncw/why_were_starting_a_rust_consultancy/d599jkv/ is where I kind of ranted about the notion that "pointers are a simple concept". They, too, have these two facets -- they are a pretty simple idea, but _using_ pointers is not simple.
I'm not sure about "impl enum trait", but it would be nice to be able to return an impl trait rather than just specifying it in return position. That impl would be like a closure in that it could move variables visible in its scope so that they're visible inside its methods. You could even limit it to only implementing a trait with a single method, so that it was actually just sugar around a closure. For Future, that would look like this: fn example(...) -&gt; impl Future&lt;Item=..., Error=...&gt; { ... let variable = ...; let future_a = ...; let future_b = ...; impl Future&lt;Item=..., Error=...&gt; { fn poll(&amp;mut self) -&gt; Poll&lt;..., ...&gt; { if variable { future_a.poll() } else { future_b.poll() } } } } Which would be sugar for: (_$1 could be any compiler-generated name) struct _$1(FnMut() -&gt; Poll&lt;..., ...&gt;); impl Future for _$1 { type Item = ...; type Error = ...; fn poll(&amp;mut self) -&gt; Poll&lt;..., ...&gt; { self.0() } } fn example(...) -&gt; impl Future&lt;Item=..., Error=...&gt; { ... let variable = ...; let future_a = ...; let future_b = ...; _$1(move || { if variable { future_a.poll() } else { future_b.poll() } }) } I'm somewhat new to Rust, so there's probably a good reason why that won't work. But having worked in Java for a number of years, returning anonymous interface implementations is a Java feature I miss when writing Rust, so it would be nice to have something similar.
Great post. I love the composition examples. Looking forward to what you do with Channels...
This would make it hard for me to argue for using anything else.
Thanks a lot! This is exactly what I was looking for.
High-level GUI APIs depend on a layout component, and Servo's layout code is necessarily intertwined with HTML/CSS concerns. I can think of worse ways to define a GUI than with HTML/CSS, though.
Cargo isn't trying to be your OS package manager, which is what you should use to manage the contents of /usr/share.
It's still going to be a while before all of this is done, but this is a big step forward in terms of the book shipping! Oh, and picking a final project was really hard; let me know if you think this is a fundamentally bad one. Not being able to use external crates is tough.
I am super ready for this book to be done. Writing a book is hard, now I've done the same book twice. There are so many other things that could use my attention, and I'm excited to be able to work on them.
If you would benefit from things like WebRender and Pathfinder such that they would enable an app that couldn't work otherwise, I think it's probably worth investigating. That said, WebRender is pretty separated from Servo, so you could in theory build the drawing backend of a toolkit on top of that, though you'd still need to build something the developer interacted with that did simple layout and generated display lists for WebRender.
Yet, he wants it to stop being a "C project" so he can have a go.
Unknown horizons? 
Having `impl` used like that may get confusing when it comes ownership of the outer variables because of the borrow checker (if one if borrowed as mut is self borrowed as mut as well?), limiting to a single method may handle that though. You can do something like this already by using inner structs though [like this](https://play.rust-lang.org/?gist=01a32dc18db85af53e998089194b258e&amp;version=nightly&amp;backtrace=2)
I am currently in the middle of porting one of my C projects to Rust, and it made extensive use of intrusive lists (since that is the only sort of list you can have in C). In particular, there were many cases where an object belonged to multiple lists at once, which no other Rust intrusive crate supports. Also, I added a Cursor API (the idea is based on [this crate](https://github.com/contain-rs/linked-list), but significantly improved). This is a very powerful abstraction which allows mutating a collection (inserting/removing elements) while iterating through it.
Maybe we can sneak a wasm-to-C89 compiler into Cretonne ;)
I think that it is good to get some high-profile posts, like this one, here on /r/rust. Because there may be people who read /r/rust, but don't contribute much, who then do this on other projects. So, I think that it's OK to preach to the choir every once in a while; since some of the choir may be a little over-zealous about the evangelism, but mostly do that outside of the church, not within it.
Just a small typo in the text: &gt; What kind of **clousre** should we use? Also, you have `fn execute&lt;F&gt;(&amp;self, F)`, and given the context (with a compiler message showing a different signature moments later), I think this is supposed to be `fn execute&lt;F&gt;(&amp;self, f: F)`
It's non-trivial to add a language as a dependency.
That's what project Quantum is doing :)
&gt; "it wouldn't have happened in non-horribly written code" Meh, having null pointer method calls be UB is really crappy. It's not really appropriate to tell people it's their fault for being clumsy if you leave sharp knives all over the floor and they fall on one.
&gt; I admit to not knowing anything about pants before reading this document Heh
This has already generated some ill-will towards rust by reducing the number of plattorms firefox runs on.
Niko is redefining "supporting the community". It's one thing to give advice; it's a lot more work to create a PoC/prototype!
Unfortunately Rust doesn't support any mechanic to return a Dynamically Sized Type (which a trait is, down there). The simplest solution is to return `Box&lt;Trait&gt;`, it requires a single heap allocation, which is not that dramatic though a bit annoying. --- In the future, Rust could potentially gain the capability to return DST, however the mechanism to do so is yet unknown. The two most promising ways of achieving it that I've heard of, for now, are: 1. using a thread-local scratch buffer on the side, the callee stores in the buffer (extending as necessary) and the caller copies from the buffer to its stack; 2. using a special calling convention in which the callee returns a pointer + length to the caller, and the caller is free to decide whether to `memmove`/`memcpy` or not (depending on the gap in the stack, I'd guess). (1) is really simple, but has the disadvantage of sometimes requiring heap allocation (when extending) and always requiring a move (which hurts for largish DST). (2) is much better from a performance point of view, I'd wager, however it's also fairly more involved in terms of code generation. --- *If anyone knows of another promising method, I'm all ~~ears~~ eyes.*
Definitely, I also see Servo (or components of it) achieving something like [awesomium](http://www.awesomium.com/) for rust which would be really useful for games or other client applications.
Never thought I'd see a programming subreddit outlaw XKCD links.
Thanks, I will try to do that some time soon!
In this situation, I think it's pretty accurate to talk about a “Rust Evangelism Strike Force” ;).
It's scary isn't it? But having an automatic check for null there wouldn't be a zero-cost abstraction. It's frustrating to see things like this, because unlike lifetimes and such, a separation to nullable and non-nullable pointers (and enforcing the disipline) doesn't even need anything too fancy in the type system.
Thanks for all​ your work on this! Is there a way to preorder physical copies?
It's an insane amount of work with little payoff.
How's the project doing nowadays? I remember the IRC meetings. And the frequent questions about C / C++ rewrite. I think I also asked about that once. Sorry :)
I know, it was just funny to see this post under the "Stop asking people to RIIR" note.
Maybe because of [WebRenderer landing nightly](https://www.reddit.com/r/rust/comments/618p54/webrenderer_landed_in_firefox_nightly_here_is_how/) or [Rust finally being required to build](http://www.infoworld.com/article/3165424/web-browsers/mozilla-binds-firefoxs-fate-to-the-rust-language.html).